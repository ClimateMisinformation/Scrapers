"
Share this...FacebookTwitterA new paper by renowned Swedish sea level expert Prof. Axel Mörmer published in the International Journal of Earth & Environmental Sciences dumps lots of cold water on the premise that today’s sea level rise is caused by man and is unusual.
Mörner’s paper looks back at the last 500 years of sea level rise and shows that natural variables are the major drivers, and not man-made CO2-driven global warming.
Previously no study in the Fiji Islands had been devoted to the sea level changes of the last 500 years and so no serious prediction can be made. What was needed was a good understanding of the sea level changes today and in the past centuries. Mörner’s study helps to fill that gap and to answer questions concerning today’s sea level rise.
The Swedish scientist summarizes in the paper’s abstract that there is a total absence of data supporting the notion of a present sea level rise; on the contrary all available facts indicate present sea level stability.

Source: Mörner, Int J Earth Environ Sci 2017, 2: 137, https://doi.org/10.15344/2456-351X/2017/137
Sea level changes over the past 500 years at Ysawa Islands, Fiji, show that sea level was +70 cm high in the 16th and 17th centuries, -50 cm low in the 18th century and that stability (with some oscillations) prevailed in the 19th, 20th and early 21st centuries.
This, Mörner writes, is almost identical to the sea level change documented in the Maldives, Bangladesh and Goa (India), and thus would point to a mutual driving force.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The pattern is the same at other locations:

Source: Mörner, Int J Earth Environ Sci 2017, 2: 137, https://doi.org/10.15344/2456-351X/2017/137
The paper also states that the recorded sea level changes are anti-correlated with the major changes in climate during the last 600 years. Therefore, Mörner concludes that glacial eustasy cannot be the driving force.
The explanation behind the sea level changes, Mörner believes, seems to be rotational eustasy with speeding-up phases during Grand Solar Minima forcing ocean water masses to the equatorial region, and slowing-down phases during Grand Solar Maxima forcing ocean waster massed from the equator towards the poles.
The paper summarizes:
This means there are no traces of a present rise in sea level; on the contrary: full stability.”
About the author:
Nils-Axel (”Niklas”) Mörner took his Ph.D. in Quaternary Geology at Stockholm University in 1969. Head of the institute of Paleogeophysics & Geodynamics (P&G) at Stockholm University from 1991 up to his retirement in 2005. He has written many hundreds of research papers and several books. He has presented more than 500 papers at major international conferences. He has undertaking field studies in 59 different countries. The P&G institute became an international center for global sea level change, paleoclimate, paleoseismics, neotectonics, paleomagnetism, Earth rotation, planetary-solar-terrestrial interaction, etc.  Among his books; Earth Rheology, Isostasy and Eustasy (Wiley, 1984), Climate Change on a Yearly to Millennial Basis (Reidel, 1984), Paleoseismicity of Sweden: a novel paradigm (P&G-print, 2003), The Greatest Lie Ever Told (P&G-print, 2007), The Tsunami Threat: Research & Technology (InTech, 2011), Geochronology: Methods and Case Studies (InTech, 2014), Planetary Influence on the Sun and the Earth, and a Modern Book-Burning (Nova, 2015).
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIt’s safe to say that the only people who still believe the ultra-alarmist scenarios of the Potsdam Institute for Climate Impact Research are the leftist media and green activists. Even the government funders of this institute know they aren’t really true. After all Germany hasn’t cut CO2 emissions in close to 10 years.
Dr. Sebastian Lüning at Die Kalte Sonne exposes the latest dubious attempt by Potsdam scientist, Stefan Rahmstorf, to spread climate fear and to attack on journalist Daniel Wetzel of flagship daily Die Welt, who not long ago dared to question the science.
The method of attack used by Rahmstorf is every time the same:

Smear the dissenting journalist as a con-man.
Insist the science has long been settled (it isn’t).
Float out charts that use statistical trickery to mislead.

===================================
Again and again: Stefan Rahmstorf and his solar trick
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(Translated/edited by P Gosselin)
The Sherlock Holmes of climate sciences, Stefan Rahmstorf, at his climate blog post “Klimawandel XY Ungelöst” at Klimalounge, warned on 29 July 2017 – of climate con-men, fraudsters and hustlers:
The global CO2 increase: the facts and the tricks of con-men
The facts surrounding CO2 rise are clear, unequivocal and agreed on – yet Die Welt again and again gladly recycles old, worn-out climate skeptic myths. Are forests to blame for the CO2 rise?”
Here Stefan Rahmstorf’s rails against an article by Daniel Wetzel “Kurzschluss bei der Energiewende” [The Energiewende shorts out] in Die Welt, where Wetzel dared to question Rahmstorf’s favorite project. The main focus was man’s share of the total CO2 budget, which is a rather dry issue in itself. Also the article looked at the magnitude and its signficance. Depending on its toxicity, even small amounts can have an impact. The same old stuff.
But looking at his Figure 5, Rahmstorf’s seriousness really needs to be called into question. It involves his favorite chart which he regularly presents. Here it is (Fig. 2):


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Figure 2.  Chart from Rahmstorf’s Blog posting “The global CO2 rise: the facts and the tricks of the con-men” dated 29 July, 2017.
Rahmstorf*’s text concerning the chart follows:
Curves showing global temperature, CO2-concentration and solar activity. Temperature and CO2 are scaled so that they correspond to the expected CO2-effect on climate (e.g. the best estimation of climate sensitivity). The amplitude of the solar curve is scaled in such a way as to correspond to the observed correlation between solar data and temperature data. (Details are explained here). You can generate this chart here and copy a code there that allows you to install the chart as a widget on your own website (like at my home page) – where here every year it is updated with the latest data. Thanks to Bernd Herd, who programmed it).
First remark: Contrary to Rahmstorf’s claim, there is no “best estimate of climate senstitivity“. The 5th IPCC report intentionally left this value open as no agreement among the report’s authors could be reached. Instead a very broad range of 1.5°C to 4.5°C for a doubling of CO2 was given, which ranges from manageable to catastrophic.
Second remark: The scaling of the solar curve was designed so as to make it impossible to detect a trend. Also the solar curve that was purposely selected is not really representative if one looks at the solar reconstructions of isotopes and cosmic rays. A more scientifically robust version of the chart would look as follows:

Figure 2: Global temperature (GISS), CO2-concentration and solar activity (Steinhilber et al. 2009).
Rahmstorf complains about con-men and tricksters, but completely fails himself when put to the test. Is this person, who gladly speaks at Green Party campaign events, really as credible as he fancies himself to be?
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMid-Ocean Seismicity Portends Global Cooling

Image Source: Viterito, 2016
Since the peak of the 2016 El Niño warming event, global temperatures have fallen by a little more than 0.3°C.

Image Source: WoodForTrees.org
According to a new paper published in Environment Pollution and Climate Change by Dr. Arthur Viterito, changes in seismic activity from the Earth’s high geothermal flux areas (HGFA) are “a significant predictor of global temperatures (p<0.05) but CO2 is not (p>0.05) (Table 1).”

An Overview Of The HGFA→Climate Link
Last year, Dr. Viterito succinctly explained the processes connecting high geothermal heat flux areas to the climate system.
 Viterito, 2017
“Namely, increased seismic activity in the HGFA (i.e., the mid-ocean’s spreading zones) serves as a proxy indicator of higher geothermal flux in these regions. The HGFA include the Mid-Atlantic Ridge, the East Pacific Rise, the West Chile Rise, the Ridges of the Indian Ocean, and the Ridges of the Antarctic/Southern Ocean.”
“This additional mid-ocean heating causes an acceleration of oceanic overturning and thermobaric convection, resulting in higher ocean temperatures and greater heat transport into the Arctic. This manifests itself as an anomaly known as the “Arctic Amplification,” where the Arctic warms to a much greater degree than the rest of the globe.”
“[J]umps in HGFA seismic activity can amplify an El Niño event, a phenomenon referred to as a SIENA or a Seismically Induced El Niño Amplification.  Accurately predicting two of these amplified El Niños (i.e., the 2015/2016 event plus the1997/1998 episode) is an important outcome of the HGFA seismicity/temperature relationship.”

New Paper: By 2019, Global Temps Will Drop To Mid-1990s Levels
In a new paper, Dr. Viterito has continued using seismic pattern analysis to formulate a very precise near-term temperature prediction: Global temperatures will continue their ongoing descent to about -0.47 °C below the 2016 peak by the year 2019.
Viterito, 2018
“A striking development for this experiment is that 2017 marks the first three-year decline in HGFA seismic activity since 1979 (Figure 2).  Furthermore, the 2017 HGFA seismic count is 49% lower than the study period’s peak frequency in 2014, the year of the last “Super El Niño”. When viewed within the context of the entire time series, the 2017 dropoff mirrors the jump in HGFA seismic activity experienced in 1995, albeit in the opposite direction. The 1995 “tipping point” was significant as global temperatures spiked in lockstep two years later, followed by a 21-year ‘plateau’ in both global temperatures and HGFA seismicity, a.k.a. ‘The Pause’.”

“It is important to note that a two-year lag is factored into the analysis: The 1979 HGFA seismic frequency is paired with the 1981 global temperature, the 1980 HGFA frequency is paired with the 1982 temperature, and so forth, for the entire series.”
“It is reasonable to conclude that this recent “gapping down” may be a tipping point towards cooler global temperatures. Using HGFAseismic frequencies as the sole predictor of global temperatures going forward, there is a 95% probability that global temperatures in 2019 will decline by 0.47°C ± 0.21°C from their 2016 peak. In other words, there is a 95% probability that 2019 temperatures will drop to levels not seen since the mid-1990s.”

Image Source (Top): WoodForTrees
Share this...FacebookTwitter "
"
Share this...FacebookTwitterUnusually cold tropical Atlantic could suppress hurricane activity this year, says Colorado State University hurricane expert Phillip Klotzbach. However cold tropical Atlantic sea surface temperatures don’t necessarily mean reduced hurricane risk.
Colorado State University (CSU) hurricane expert Phillip Klotzback at Twitter commented that the tropical Atlantic sea surface temperatures are the 2nd coldest on record and that this could mean “significantly suppress Atlantic hurricane activity.”

Tropical Atlantic (10-20°N, 60-20°W) sea surface temperatures are currently 2nd coldest on record (since 1982).  Only year colder in early June was 1985.  Could  significantly suppress Atlantic #hurricane activity if anomalously cold SSTs persist. pic.twitter.com/9Rmobo9u3a
— Philip Klotzbach (@philklotzbach) June 6, 2018

Cold tropical Atlantic doesn’t mean fewer hurricanes hitting US!
However history shows that it is purely speculative that cold tropical Atlantic sea surface temperatures will act to suppress hurricanes hitting the US.
Klotzback notes that the coldest tropical sea surface temperatures seen in June were recorded in 1985, and looking at the 1985 US hurricane season Wikipedia tells us that season was in fact a rather nasty one for the entire east coast of the USA:
The 1985 Atlantic hurricane season featured eight landfalling tropical cyclones in the United States, including a record-tying six hurricanes, the most in a single year since 1916.“


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





 
1985 season record “destructive and disruptive”
Wikipedia writes that “the year featured average activity overall” but was “particularly destructive and disruptive for the United States, with damage amounting to a then-record US$4 billion.”
Further, Wikipedia adds: “The entire coastline from Brownsville, Texas, to Eastport, Maine, was under a gale warning at some point during the year and a portion of every state was under a hurricane warning.”
Bastardi warns of the “in-close” threat
Observing the 1985 hurricane chart, we see that the vast majority of the 11 named storms formed “in-close”, relatively near the US mainland.
Meteorologist Joe Bastardi warned in his May 26th WeatherBell Saturday Summary that warm waters near the coast needed real attention and harbored plenty of threat. In no way should people let themselves get casual about it.
So, don’t let all the cold tropical Atlantic surface water fool you into  thinking that the upcoming hurricane season is going to be on the light side for the US coast.
1985 shows us things can get pretty nasty even when the surface of the tropical Atlantic basin is cold.
===============================
Philip Klotzback is a meteorologist at CSU specializing in Atlantic basin seasonal hurricane forecasts. Avid runner, cyclist and hiker.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterConservationist/wind-energy protest group Rettet den Odenwald (Save the Forest of Odes) here writes that yet another endangered stork nest was recently destroyed at the forested location near a proposed JuWi wind park.
Controversy swirls over German wind park builder JuWi 
Normally the clearing of forest land to make way for industry is required to undergo an extremely strict permitting process involving very detailed environmental impact studies. Violations are usually punished extremely harshly. But when it comes to wind parks in Germany, the fox in the henhouse often seems to rule. This also may be the case at a proposed JuWi wind park location in the area of Donnersberg (Palatinate).
Back in 2016 the existence of a nest at the location of interest was proven. The nest belonged to a pair of rare black storks that later gave birth to three offsprings that year, and to four more in 2017. Normally with such a nest in the area, obtaining a permit to clear away forest and to set up an industrial complex would be totally out of the question.
Rare and legally protected black stork nest gets allegedly destroyed in what is suspected to be a criminal attempt to clear the way for a wind park construction permit. Photo see: Rettet den Odenwald
According to Rettet den Odenwald, the nest belonging to the pair of rare black storks appears to have been recently willfully and criminally destroyed.
Earlier, local citizens had worked closely with authorities to stop the construction of five JuWi wind turbines, which had been permitted to be built right close to what later was discovered as the nest belonging to the pair of protected black storks. The black stork pair had been expected to return to its nest by early March to produce offsprings.
Tree and nest destroyed
But then on February 10, 2018, Rettet den Odenwald broke the tragic news: the tree in which the nest had been perched had been singled out and  illegally cut down “by unknown attackers” using a power saw, thus preventing the stork pair from returning and successfully nesting this year.
The obstacle blocking the construction of the JuWi windpark in the area was in effect disposed of.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Destroyed tree in the Forest of Odes (Odenwald). Home to the nest of a pair of rare, legally-protected black storks was illegally cut down. Conservationists and wind park opponents suspect foul play by the wind industry. Photo see: Rettet den Odenwald
Path “reopens for greed”
The conservationist Rettet den Odenwald site writes:
This lawbreaking allows the permitting process for the planned and halted wind park to now appear in a new light. … The lawful protection that was established by the provision of facts was illegally undone and thus has again reopened the door for the greed of those with a stake in the wind park.”
The outrage by conservationists and wind park opponents came swiftly and loudly. Already on February 12 Rettet den Odenwald issued a press release in which they demand the Environment Ministry to assure that no permit be granted in the event of such criminal acts and that they take swift action.
JuWi condemns destruction
In a press release, JuWi stated that it “condemns the criminal act in the harshest terms”. Moreover the press release adds: “JuWi is filing criminal charges against unknown perpetrators for violating federal nature protection laws”.
The latest in a series of criminal environmental destruction acts
This is not the first time that nests and homes for protected species located in proposed wind park areas have been destroyed in Germany. Der Spiegel has reported on this before, e.g. see here.
Also read “wind power mafia” destroys stork’s nest here.  
When it comes to saving the planet, wind parks seem to get away with everything nowadays. Often times wind turbines get installed right up close to residents and thus make them sick from infrasound, or they ruin idyllic landscapes, destroy biotopes, cause hazards in the North Sea, shred migrating birds, etc. Environmental concerns from citizens be damned!
As far as the wind park in Odenwald is concerned, don’t be surprised if its construction ends up getting permitted soon. Greed disguised as green always gets its way in Germany.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter Already 14 New (2018)
Non-Hockey Stick Papers

During 2017, there were 150 graphs from 122 scientific papers published in peer-reviewed journals that indicated modern temperatures are not unprecedented, unusual, or hockey-stick-shaped — nor do they fall outside the range of natural variability.
Less than 3 weeks into the new publication year, the explosion of non-alarming depictions of modern climate change continues.



Blarquez et al., 2018


 Magyari et al., 2018
…its climatic tolerance limits were used to infer July mean temperatures exceeding modern values by 2.8°C at this time [8200-6700 cal yr BP] (Magyari et al., 2012).


White et al., 2018
Our data, together with published work, indicate both a long-term trend in ENSO strength due to June insolation [solar] forcing and high-amplitude decadalcentennial fluctuations; both behaviors are shown in models. The best-supported mechanism for insolation-driven dampening of ENSO is weakening of the upwelling feedback by insolation-forced warming/deepening of thermocline source waters. … Another potential source of decadal-centennial forcing is total solar irradiance, which varied more in the early Holocene than the mid- to late Holocene [Marchitto et al., 2010]. Changing solar irradiance is theoretically capable of affecting ENSO via ocean dynamical cooling [Emile-Geay et al., 2007], and is correlated with centennial-scale variations in early Holocene ENSO [Marchitto et al., 2010].


Song et al., 2018
[A] general warm to cold climate trend from the mid-Holocene to the present, which can be divided into two different stages: a warmer stage between 6842 and 1297 cal yr BP and a colder stage from 1297 cal yr BP to the present. … The general cooling trend may represent a response to decreasing solar insolation; however, the relative dryness or wetness of the climate may have been co-determined by westerlies and the East Asian summer monsoon (EASM). The climate had a teleconnection with the North Atlantic region, resulting from changes in solar activity.


Huang et al., 2018
A period of weak chemical weathering, related to cold and dry climatic conditions, occurred during the Little Ice Age (LIA), whereas more intense chemical weathering, reflecting warm and humid climatic conditions, was recorded during the Medieval Warm Period (MWP). Besides, an intensification of chemical weathering in Poyang Lake during the late Holocene agrees well with strong ENSO activity, suggesting that moisture variations in central China may be predominantly driven by ENSO variability. … Rao et al. (2016b) demonstrated that a humid late-Holocene in central China and an arid late-Holocene in southern and northern China were significantly related to strong ENSO activity. Thus, it seems that ENSO forcing may be likely dominant factor controlling moisture variations in central China.


Perner et al., 2018
[W]e find evidence of distinct late Holocene millennial-scale phases of enhanced El Niño/La Niña development, which appear synchronous with northern hemispheric climatic variability.
Phases of dominant El Niño-like states occur parallel to North Atlantic cold phases: the ‘2800 years BP cooling event’, the ‘Dark Ages’ and the ‘Little Ice Age’, whereas the ‘Roman Warm Period’ and the ‘Medieval Climate Anomaly’ parallel periods of a predominant La Niña-like state.
Our findings provide further evidence of coherent interhemispheric climatic and oceanic conditions during the mid to late Holocene, suggesting ENSO as a potential mediator.





<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Maley et al., 2018



Polovodova Asteman et al., 2018
The record demonstrates a warming during the Roman Warm Period (~350 BCE – 450 CE), variable bottom water temperatures during the Dark Ages (~450 – 850 CE), positive bottom water temperature anomalies during the Viking Age/Medieval Climate Anomaly (~850 – 1350 CE) and a long-term cooling with distinct multidecadal variability during the Little Ice Age (~1350 – 1850 CE). The fjord BWT [bottom water temperatures] record also picks up the contemporary warming of the 20th century, which does not stand out in the 2500-year perspective and is of the same magnitude as the Roman Warm Period and the Medieval Climate Anomaly.

 


Papadomanolaki et al., 2018  (Baltic Sea)
A large fraction of the Baltic Proper became hypoxic again between 1.4 and 0.7 ka BP, during the Medieval Climate Anomaly (MCA), when mean air temperatures were 0.9–1.4 °C higher than temperatures recorded in the period 1961–1990 (e.g. Mann et al., 2009; Jilbert and Slomp, 2013).

20th/21st Centuries Non-Warming

Yi, 2018
As measures of climate response, temperature and precipitation data from the north, east, and south-facing mountain ranges of Shennongjia Massif in the coldest and hottest months (January and July), different seasons (spring, summer, autumn, and winter) and each year were analyzed from a long-term dataset (1960 to 2003) to tested variations characteristics, temporal and spatial quantitative relationships of climates. The results showed that the average seasonal temperatures and precipitation in the north, east, and south aspects of the mountain ranges changed at different rates. The average seasonal temperatures change rate ranges in the north, east, and south-facing mountain ranges were from –0.0210 ℃/yr to 0.0143 ℃/yr, –0.0166 ℃/yr to 0.0311 ℃/yr, and  –0.0290 ℃/yr to 0.0084 ℃/yr, respectively, and seasonal precipitation variation magnitude were from –1.4940 mm/yr to 0.6217 mm/yr, –1.6833 mm/yr to 2.6182 mm/yr, and –0.8567 mm/yr to 1.4077 mm/yr, respectively. The climates variation trend among the three mountain ranges were different in magnitude and direction, showing a complicated change of the climates in mountain ranges and some inconsistency with general trends in global climate change.


Bereiter et al., 2018
Our reconstruction provides unprecedented precision and temporal resolution for the integrated global ocean, in contrast to the depth-, region-, organism- and season-specific estimates provided by other methods. We find that the mean global ocean temperature is closely correlated with Antarctic temperature and has no lead or lag with atmospheric CO2, thereby confirming the important role of Southern Hemisphere climate in global climate trends. We also reveal an enigmatic 700-year warming during the early Younger Dryas period (about 12,000 years ago) that surpasses estimates of modern ocean heat uptake.

(press release)
“Our precision is about 0.2 ºC (0.4 ºF) now, and the warming of the past 50 years is only about 0.1 ºC,” he said, adding that advanced equipment can provide more precise measurements, allowing scientists to use this technique to track the current warming trend in the world’s oceans.


 Purich et al., 2018
Observed Southern Ocean changes over recent decades include a surface freshening (Durack and Wijffels 2010; Durack et al. 2012; de Lavergne et al. 2014), surface cooling (Fan et al. 2014; Marshall et al. 2014; Armour et al. 2016; Purich et al. 2016a) and circumpolar increase in Antarctic sea ice (Cavalieri and Parkinson 2008; Comiso and Nishio 2008; Parkinson and Cavalieri 2012).  … [A]s high-latitude surface freshening is associated with surface cooling and a sea ice increase, this may be another factor contributing to the CMIP5 models excessive Southern Ocean surface warming contrasting the observed surface cooling (Marshall et al. 2014; Purich et al. 2016a), and sea ice decline contrasting the observed increases (Mahlstein et al. 2013; Polvani and Smith 2013; Swart and Fyfe 2013; Turner et al. 2013; Zunz et al. 2013; Gagne et al. 2015) over recent decades. … Our results suggest that recent multi-decadal trends in large-scale surface salinity over the Southern Ocean have played a role in the observed surface cooling seen in this region. … The majority of CMIP5 models do not simulate a surface cooling and increase in sea ice (Fig. 8b), as seen in observations.


Cerrone and Fusco, 2018
Compelling evidence indicates that the large increase in the SH sea ice, recorded over recent years, arises from the impact of climate modes and their long-term trends. The examination of variability ranging from seasonal to interdecadal scales, and of trends within the climate patterns and total Antarctic sea ice concentration (SIC) for the 32-yr period (1982–2013), is the key focus of this paper. The results herein indicate that a progressive cooling has affected the year-to-year climate of the sub-Antarctic since the 1990s. This feature is found in association with increased positive SAM and SAO phases detected in terms of upward annual and seasonal trends (in autumn and summer) and upward decadal trends. In addition, the SIC [sea ice concentration] shows upward annual, spring, and summer trends, indicating the insulation of Antarctica from the warmer flows in the midlatitudes.

Palmer et al., 2018

Share this...FacebookTwitter "
"
Share this...FacebookTwitterPaleoclimate data still spotty and incomplete, leaving climate models vague, uncalibrated and filled with uncertainty
Paleo-climatological data, used for the reconstruction of past climate from proxy records such as ice cores, tree rings, sediment cores etc., have not had adequate geographical coverage.

Lake Tanganyika, Tanzania, where a sediment core was extracted. Credit: Andreas31,  CC BY-SA 3.0.
For example although the Medieval Climate Anomaly has also been well documented in other parts of the world, there has been little data when it comes to the Arabian Peninsula and the African continent, which comprise about one quarter of Earth’s land surface.
Too often scientists reconstructing past climates have been overly eager in drawing far-reaching conclusions based only a few datasets, and attempted to adventurously apply them to neighboring regions or even globally.
Climate Anomaly in Africa and Arabia as well
Now a new paper published on Eos.org here by Lüning et al. attempts to fill this data chasm. Their publication “correlated and synthesized the findings of 44 published paleotemperature case studies” from across the Afro-Arabian region and mapped the resulting trends of the Medieval anomaly’s central period of about 1000 to 1200 CE.
The paper is titled: “Warming and Cooling: The Medieval Climate Anomaly in Africa and Arabia”.
“Uncalibrated” and “vague” models
“Enormous data gaps exist,” wrote Lüning in an e-mail. “A high impact study program is needed to close these gaps. Paleoclimate information is essential to validate climate models, which otherwise are not calibrated and remain vague.”
According to their findings, paleotemperature reconstructions from these published case studies show “the Afro-Arabian region experienced climate perturbations, including an extended period of anomalously warm conditions, during medieval times. Because this Medieval Climate Anomaly represents the closest analogue to modern warming, it defines a crucial baseline by which modern postindustrial climate trends can be compared.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Lüning wrote NTZ:
This work is based on a large numbers of valuable paleoclimate studies. We have mosaiced these data points together and found that the Medieval Climate Anomaly was characterized by warming in most of Africa and Arabia, therefore justifying the term “Medieval Warm Period” for the African land area. An exception was the southern Levant where its got cooler.”
In a nutshell, the findings suggest the majority of onshore Afro-Arabian sites also experienced warming during the Medieval Climate Anomaly, and thus the warming was not just a phenomenon confined to the North Atlantic and Europe, as some scientists have tried to suggest.
Outstanding resource
Lüning has spent years researching and compiling paleoclimate data, and as a result has produced a “Climate Reconstruction Map of the Medieval Warm Period“.
Link to solar and oceanic cycles
In some of the records in the newly published study the researchers found that cold spikes corresponded with periods of low decreased solar activity or declining ocean cycles. thus suggesting that solar forcing and changing ocean circulation are the most likely causes of medieval era climate change.
Lüning added:
Climate patterns never cover the whole globe, therefore it is important to first map out trends and understand the pattern distribution. Otherwise the meaning of purely mathematically stacked data series remains unclear.”
This study represents a step toward globally characterizing the Medieval Climate Anomaly, an improved understanding of which will help scientists refine global climate models and improve hind-casting.
Read more at Research Spotlight.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterPIK alarm story fails the test of science: Jet Stream will also meander as usual in the future
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated by P Gosselin)
Almost one year ago the Potsdam PIK Institute put out a press release, which warned of stalling Jet Stream waves. Due to man-made climate warming weather extremes would remain stuck in a position longer. Among the messengers of the alarm were Stefan Rahmstorf and hockey stich fabricator Michael E. Mann.
Next on February 20, 2018 the horror scenario suffered a setback at the University of Missouri. Using model simulations it was determined that the Jet Stream would also meander in the future as well. Climate alarm shut off once more. This is not the first time that Rahmstorf’s extreme claims have been dispelled in short order by his colleagues. See here, here, here, here, and here.
The University of Missouri press release follows:
Weather should remain predictable despite climate change
Simulations of jet stream behavior in a warming climate suggest ranges of forecasts in the mid-century will be similar to those in present day.
According to the Intergovernmental Panel on Climate Change, temperatures are expected to rise between 2.5 and 10 degrees Fahrenheit over the next century. This warming is expected to contribute to rising sea levels and the melting of glaciers and permafrost, as well as other climate-related effects. Now, research from the University of Missouri suggests that even as rising carbon dioxide levels in the atmosphere drive the climate toward warmer temperatures, the weather will remain predictable.
“The jet stream changes character every 10 to 12 days, and we use this pattern to predict the weather,” said Anthony Lupo, professor of atmospheric science in MU’s School of Natural Resources, which is located in the College of Agriculture, Food and Natural Resources. “We were curious about how this would change in a world with higher carbon dioxide levels. We found that in that warmer world, the variability of the jet stream remained the same.”
Lupo and Andrew Jensen, who earned his doctorate at MU, used an existing climate model to simulate jet stream flow in the Northern Hemisphere. The simulation monitored a variable that responds to jet stream flow changes and can indicate global-scale weather instability. Researchers used this variable to determine when the jet stream altered its flow. Since meteorologists can only accurately predict weather within the 10 to 12 days between jet stream flow changes, a shift in this time frame would directly impact weather predictability.
Over the course of a simulated 31 years, their observations indicated the jet stream would change its character about 30 to 35 times per year, a number that is consistent with current jet stream patterns. As the time frame used to predict weather did not change, the researchers concluded that weather would likely remain as predictable in a warmer world as it is today. The results do not address the effects of climate change on the nature or frequency of weather events but instead focus on the range of predictability afforded by the jet stream. In addition, the researchers did not extend the simulation past the mid-century to ensure their data was as accurate as possible. “Climate change will continue to create a lot of ripple effects, but this experiment provides evidence that the range of forecasting will remain the same,” Lupo said.
The study, “The Dynamic Character of Northern Hemisphere Flow Regimes in a Near-Term Climate Change Projection,” was published in Atmosphere. Other researchers involved in the study were Mirseid Akperov of the Russian Academy of Sciences, Igor Mokhov of Lomonosov Moscow State University and Fengpeng Sun of the University of Missouri-Kansas City.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNote: This post will remain an extra day…
=======================================
More than 70 recent scientific publications show that there is absolutely nothing unusual about the magnitude and rapidity of today’s sea level changes. These academically peer-reviewed papers show that sea levels were on average 2 meters higher earlier in the Holocene than they are today.
Before the advent of the industrial revolution in the late 18th to early 19th centuries, carbon dioxide (CO2) concentrations hovered between 260 to 280 parts per million (ppm).

Within the last century, atmospheric CO2 concentrations have risen dramatically.  Just recently they eclipsed 400 ppm.
Scientists like Dr. James Hansen have concluded that pre-industrial CO2 levels were climatically ideal.  Though less optimal, atmospheric CO2 concentrations up to 350 ppm have been characterized as climatically “safe”.  However, CO2 concentrations above 350 ppm are thought to be dangerous to the Earth system.  It is believed that such “high” concentrations could lead to rapid warming, glacier and ice sheet melt, and a harrowing sea level rise of 10 feet within 50 years.
To reach those catastrophic levels (10 feet within 50 years) predicted by proponents of sea level rise alarmism, the current “anthropogenic” change rate of +0.14 of a centimeter per year (since 1958) will need to immediately explode into +6.1 centimeters  per year.  The likelihood of this happening is remote, especially considering Greenland and Antarctica combined only contributed a grand total of 1.54 cm since 1958 (Frederiske et al., 2018).
70+ Papers: Sea Levels 2+ m Higher 9,000-4,000
Years Ago While CO2 Levels Were ‘Safe’ (265 ppm)
(Click the link above or at the right side bar)
• Are Modern ‘Anthropogenic’ Sea Levels Rising At An Unprecedented Rate?  No.
Despite the surge in CO2 concentrations since 1900, the UN’s Intergovernmental Panel on Climate Change (IPCC) has concluded that global sea levels only rose by an average of 1.7 mm/yr during the entire 1901-2010 period, which is a rate of just 0.17 of a meter per century.
During the 1958 to 2014 period, when CO2 emissions rose dramatically, a recent analysis revealed that the rate of sea level rise slowed to between 1.3 mm/yr to 1.5 mm/yr, or just 0.14 of a meter per century.
Frederiske et al.,2018  “Anthropogenic” Global Sea Level Rise Rate (1958-2014): +0.14 of a meter per century
“For the first time, it is shown that for most basins the reconstructed sea level trend and acceleration can be explained by the sum of contributors, as well as a large part of the decadal variability. The global-mean sea level reconstruction shows a trend of 1.5 ± 0.2mm yr−1 over 1958–2014 (1σ), compared to 1.3 ± 0.1 mm yr−1 for the sum of contributors.”
In the past few thousand years, in contrast, sea levels in some regions rose and fell at rates of + or – 0.5 to 1.1 meters per century., which is 4 to 7 times greater than the change since 1958.
Hansen et al., 2016
“Continuous record of Holocene sea-level changes … (4900 years BP to present). … The curve reveals eight centennial sea-level oscillations of 0.5-1.1 m superimposed on the general trend of the RSL [relative sea level] curve.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




•Other regions have also undergone profound sea level oscillations in the last few thousand years that far exceed modern changes.



Image Sources: Bracco et al., 2014   Whitfield et al., 2017    Strachan et al., 2014 
  Hein et al., 2014    Miguel et al., 2018
•Modern changes aren’t even detectable on graphs of long-term sea level trends.
  

Image Sources: Dura et al., 2016   Bradley et al., 2016
 Scheffers et al., 2012  Kane et al., 2017
 • ~15,000 – 11,000 Years Ago, Sea Levels Rose At Rates Of +4 to +6 Meters Per Century
Cronin et al., 2017   Global Sea Level Rise Rate: +4 meters per century (14,500 to 14,000 years ago)
“Rates and patterns of global sea level rise (SLR) following the last glacial maximum (LGM) are known from radiometric ages on coral reefs from Barbados, Tahiti, New Guinea, and the Indian Ocean, as well as sediment records from the Sunda Shelf and elsewhere. … Lambeck et al. (2014) estimate mean global rates during the main deglaciation phase of 16.5 to 8.2 kiloannum (ka) [16,500 to 8,200 years ago] at 12 mm yr−1 [+1.2 meters per century] with more rapid SLR [sea level rise] rates (∼ 40 mm yr−1) [+4 meters per century] during meltwater pulse 1A ∼ 14.5–14.0 ka [14,500 to 14,000 years ago].”
Abdul et al., 2017   Global Sea Level Rise Rate: +4 meters per century (11,450 to 11,100 years ago)
“We find that sea level tracked the climate oscillations remarkably well. Sea-level rise was fast in the early Allerød (25 mm yr-1), but decreased smoothly into the Younger Dryas (7 mm yr-1) when the rate plateaued to <4 mm yr-1here termed a sea-level “slow stand”. No evidence was found indicating a jump in sea level at the beginning of the Younger Dryas as proposed by some researchers. Following the “slow-stand”, the rate of sea-level rise accelerated rapidly, producing the 14 ± 2 m sea-level jump known as MWP-1B; occurred between 11.45 and 11.1 kyr BP with peak sea-level rise reaching 40 mm yr-1 [+4 meters per century].”
Ivanovic et al., 2017  Northern Hemisphere Sea Level Rise Rate: +3.5 to +6.5 meters per century (~14,500 years ago)
“During the Last Glacial Maximum 26–19 thousand years ago (ka), a vast ice sheet stretched over North America [Clark et al., 2009]. In subsequent millennia, as climate warmed and this ice sheet decayed, large volumes of meltwater flooded to the oceans [Tarasov and Peltier, 2006; Wickert, 2016]. This period, known as the “last deglaciation,” included episodes of abrupt climate change, such as the Bølling warming [~14.7–14.5 ka], when Northern Hemisphere temperatures increased by 4–5°C in just a few decades [Lea et al., 2003; Buizert et al., 2014], coinciding with a 12–22 m sea level rise in less than 340 years [3.5 to 6.5 meters per century] (Meltwater Pulse 1a (MWP1a)) [Deschamps et al., 2012].”
Zecchin et al., 2015 Regional Sea Level Rise Rate: +6 meters per century (14,500-11,500 years ago)
“[M]elt-water pulses have punctuated the post-glacial relative sea-level rise with rates up to 60 mm/yr. [6 meters per century] for a few centuries.”
It has become more and more apparent that sea levels rise and fall without any obvious connection to CO2 concentrations.  And if an anthropogenic signal cannot be conspicuously connected to sea level rise (as scientists have noted), then the greatest perceived existential threat promulgated by advocates of dangerous anthropogenic global warming will no longer be worth considering.
70+ Papers: Sea Levels 2+ m Higher 9,000-4,000
Years Ago While CO2 Levels Were ‘Safe’ (265 ppm)
(Click the link above or at the right side bar)
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
German text edited/translated by P Gosselin)
Satellite measurements of Antarctic sea ice do not go back even 40 years. That’s not very much, especially when we consider that many natural climate cycles have periods of 60 years and more.
Luckily we have the field of climate reconstruction. Using historical documents and sediment cores, the development of ice cover can be estimated. In November, 2016, Tom Edinburg and Jonathan Day examined shipping log books from the time of Antarctic explorers and published on ice extent in The Cryosphere:
Estimating the extent of Antarctic summer sea ice during the Heroic Age of Antarctic Exploration
In stark contrast to the sharp decline in Arctic sea ice, there has been a steady increase in ice extent around Antarctica during the last three decades, especially in the Weddell and Ross seas. In general, climate models do not to capture this trend and a lack of information about sea ice coverage in the pre-satellite period limits our ability to quantify the sensitivity of sea ice to climate change and robustly validate climate models. However, evidence of the presence and nature of sea ice was often recorded during early Antarctic exploration, though these sources have not previously been explored or exploited until now. We have analysed observations of the summer sea ice edge from the ship logbooks of explorers such as Robert Falcon Scott, Ernest Shackleton and their contemporaries during the Heroic Age of Antarctic Exploration (1897–1917), and in this study we compare these to satellite observations from the period 1989–2014, offering insight into the ice conditions of this period, from direct observations, for the first time. This comparison shows that the summer sea ice edge was between 1.0 and 1.7° further north in the Weddell Sea during this period but that ice conditions were surprisingly comparable to the present day in other sectors.”
The surprising result: with respect to sea ice extent 100 years ago things looked similar to what we have today, with the exception of the Weddell Sea. A study by Hobbs et al. 2016 also looked back at the last century, here using geoscientific sea ice reconstructions. Once again the strong discrepancies between the real ice development and model simulations were criticized:
Century-scale perspectives on observed and simulated Southern Ocean sea ice trends from proxy reconstructions
Since 1979 when continuous satellite observations began, Southern Ocean sea ice cover has increased, whilst global coupled climate models simulate a decrease over the same period. It is uncertain whether the observed trends are anthropogenically forced or due to internal variability, or whether the apparent discrepancy between models and observations can be explained by internal variability. The shortness of the satellite record is one source of this uncertainty, and a possible solution is to use proxy reconstructions, which extend the analysis period but at the expense of higher observational uncertainty. In this work, we evaluate the utility for change detection of 20th century Southern Ocean sea ice proxies. We find that there are reliable proxies for the East Antarctic, Amundsen, Bellingshausen and Weddell sectors in late winter, and for the Weddell Sea in late autumn. Models and reconstructions agree that sea ice extent in the East Antarctic, Amundsen and Bellingshausen Seas has decreased since the early 1970s, consistent with an anthropogenic response. However, the decrease is small compared to internal variability, and the change is not robustly detectable. We also find that optimal fingerprinting filters out much of the uncertainty in proxy reconstructions. The Ross Sea is a confounding factor, with a significant increase in sea ice since 1979 that is not captured by climate models; however, existing proxy reconstructions of this region are not yet sufficiently reliable for formal change detection.”
A paper published by Ellen & Abrams 2016 even looked back 300 years ago and showed that the increase in sea ice from 1979-2016 has been part of a long-term growth trend of the 20th century:
Ice core reconstruction of sea ice change in the Amundsen-Ross Seas since 1702 A.D.
Antarctic sea ice has been increasing in recent decades, but with strong regional differences in the expression of sea ice change. Declining sea ice in the Bellingshausen Sea since 1979 (the satellite era) has been linked to the observed warming on the Antarctic Peninsula, while the Ross Sea sector has seen a marked increase in sea ice during this period. Here we present a 308 year record of methansulphonic acid from coastal West Antarctica, representing sea ice conditions in the Amundsen-Ross Sea. We demonstrate that the recent increase in sea ice in this region is part of a longer trend, with an estimated ~1° northward expansion in winter sea ice extent (SIE) during the twentieth century and a total expansion of ~1.3° since 1702. The greatest reconstructed SIE occurred during the mid-1990s, with five of the past 30 years considered exceptional in the context of the past three centuries.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman skeptic and weather expert ‘Schneefan’ here writes how climate activist Mark C. Serreze recently announced this year’s sea ice extent was at the smallest all-time area. But since then Arctic temperatures have plummeted and sea ice area has grown to over 14 million square kilometers:
At the sea ice portal, the development is clearly shown.

Chart: University of Bremen
On March 103 2018 sea ice extent in the Arctic reached 14.55 million km² and so the end of Arctic sea ice growth had in fact not been reached.
The plunge in the mean temperature north of 80°N to -25°C can be seen in the plot by the DMI, and so a growth in sea ice was expected.

After an increase to about -10°C in February (due to a weather pattern) the average temperature above 80°N latitude has since fallen to -25°C. Source: DMI.
Naturally the German mainstream media such as ARD television pounced on the news and set off the climate catastrophe alarms, and thus ended up reporting totally falsely again on the real sea ice development in the Arctic: ARD: heat wave in Arctic.
A heat wave at a mean temperature of -10°C?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Below is what the ARD fake “heat wave” really looks like in the Arctic for the entire 2017/18 winter, shown by a plot of the NOAA reanalysis using measured and computed mean temperatures:

The NOAA reanalysis shows the mean 2m-temperatures for the northern hemisphere in the winter of 2017/18. Source: NOAA reanalysis
Perhaps the editors at ARD should have been more careful in checking where this faulty Arctic information came from before coming out with such climate-alarmist fake news.
A check in the Internet shows that the ARD report quoted Mark C. Serreze, a known climate activist, IPCC author and the person who coined the term Arctic sea ice “death spiral”.
He worked earlier together with the now embarrassed Peter Wadhams, who over the past years falsely forecast  the disappearance of Arctic sea ice on multiple occasions. What unfortunately has escaped the media, such as ARD, is the fact that the Arctic ice cap at the start of March 2018 is much thicker than it was 10 years ago, see the alternating charts that follow:

Impressive growth: sea ice volume (smaller chart, black curve) is greater in March 2018 than the two previous years and is near the average level (gray area) of the past years.
As everyone is aware, the multiple-year ice melts more slowly than the thinner one-year ice – and so we sill see how many Wadhams (1 Wadham = 1 million km²) will be left in September 2018.
This leads us to conclude that there is nothing left of the absurd, Al Gore envisioned, ice-free Arctic fantasies which were suppose to come true already in 2016.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterI thought the following paper was interesting. 
No, lead-author Prof. Pierre Gosselin is not me from NTZ. But he very likely is a descendent the same family line. The first Gosselin (Gabriel) left Normandy-France and landed in Quebec City way back in 1653. As a devout Catholic, Gabriel earnestly started what was the population of Gosselins over North America and beyond over the next 364 years.
=============================================
Effects of climate and fine particulate matter on hospitalizations and deaths for heart failure in elderly: A population-based cohort study
In a recent study a team of scientists led by Prof. Pierre Gosselin assessed 112,793 people aged 65 years and older who had been diagnosed with heart failure in Quebec between 2001 and 2011. Over an average of 635 days, the researchers measured the mean temperature, relative humidity, atmospheric pressure and air pollutants in the surrounding environment and studied the data to see if there was any relationship.
Their results: for each decrease of 1°C in the daily mean temperature of the previous 3 and 7 days, the risk of heart failure events is increased of about 0.7%. In other words, a drop of 10°C in the average temperature over 7 days, which is common in the province of Quebec because of seasonal variations, is associated with increased risk to be hospitalized or to die for the main cause of heart failure of about 7% in elderly diagnosed with this disease.
The paper’s abstract:
We measured the lag effects of temperature, relative humidity, atmospheric pressure and fine particulate matter (PM2.5) on hospitalizations and deaths for HF in elderly diagnosed with this disease on a 10-year period in the province of Quebec, Canada.
Our population-based cohort study included 112,793 elderly diagnosed with HF between 2001 and 2011. Time dependent Cox regression models approximated with pooled logistic regressions were used to evaluate the 3- and 7-day lag effects of daily temperature, relative humidity, atmospheric pressure and PM2.5 exposure on HF morbidity and mortality controlling for several individual and contextual covariates.
Overall, 18,309 elderly were hospitalized and 4297 died for the main cause of HF. We observed an increased risk of hospitalizations and deaths for HF with a decrease in the average temperature of the 3 and 7 days before the event. An increase in atmospheric pressure in the previous 7 days was also associated with a higher risk of having a HF negative outcome, but no effect was observed in the 3-day lag model. No association was found with relative humidity and with PM2.5 regardless of the lag period
Lag effects of temperature and other meteorological parameters on HF events were limited but present. Nonetheless, preventive measures should be issued for elderly diagnosed with HF considering the burden and the expensive costs associated with the management of this disease.
Lower risk of death in summer
The authors also found:
The results showed a higher risk of hospitalization or death in the winter period of the year (October to April) compared to the summer period (May to September).”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterPresident Donald Trump once again rejected “global governance” and rigid multi-nation trade deals before a packed and highly enthusiastic rally in Pensacola, Florida, yesterday.

Donald Trump leaves door wide open to a fair climate deal. Photo credit: Shealah Craighead, public domain photo.
The US President re-emphasized the importance of American national sovereignty and independence from “global bureaucrats” residing in foreign countries.
In his speech the President brought up the Paris Climate Accord, a deal he refused to sign early this year, thus setting off outrage among the UN, climate activists, global bureaucrats and Accord cash-beneficiary countries worldwide.
“Would have been one of the great catastrophes”
He reminded the packed audience that he had promised “to withdraw…from the horrible Paris climate accord” — another promise he has kept.
He said: “It costs us a fortune. China doesn’t start until 2030, I think. Russia doesn’t have to go back to like a recent date; they go back to somewhere like the 1990s, which was a high pollution time. Other countries we end up giving money to. This would have been one of the great catastrophes.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“I could come back to the Paris Accord”
But Trump left the door open for a better deal, one that would be much fairer: “And I can come back into the deal at a much better price. I could come back to the Paris Accord.”
Trump then repeated his commitment to “clean air” and “crystal clean water”. He said that if the USA pledged to accept the numbers set forth by the Paris Accord, “We would have to close factories and businesses in order to qualify by 2025. […] In the meantime some of those countries are spewing out stuff like you wouldn’t believe.”
US has already significantly cut emissions
Over the past decade the USA has already substantially cut back its “greenhouse gas” emissions, by an amount that equals Germany’s total annual output – something that never gets mentioned in the media. Paris Climate Accord-promoting Germany on the other hand, has not cut its emissions in almost a decade. Currently the USA emits roughly half as much as China does.
Performance by other climate protection-preaching western countries is not always what it is made out to be. Many western countries are meeting their targets by merely offshoring their CO2-emitting industries over to low environmental standards regions like China and India. The result: global CO2 emissions are in reality higher rather than lower.
Inefficient wind energy
Trump then mocked wind energy as being unreliable and inefficient, saying: “Windmills are wonderful. But you know when the wind doesn’t blow, they really do cause problems. ‘We have no energy this week! Well hopefully the wind will start blowing pretty soon!'”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHurricane activity trend declines significantly over the past 65 years
Dr. Sebastian Lüning and Prof. Fritz Vahrenholt posted here yesterday results showing that  hurricane activity has decreased over the past decades, despite all the hysteria we’ve been hearing from the usual suspects.

Data and studies show that Potsdam Institute thinly veiled claims that hurricanes are connected to man-made CO2 are spurious. Photo: Hurricane Isabel, NASA (public domain).
Taking a look at the recent literature, we find a paper authored by Ryan Truchelut and Erica Staehling appearing in the Geophysical Research Letters on December 8, 2017. They looked at the development of American hurricanes based on accumulated cyclone energy (ACE).
CO2 and hurricanes are not connected
The two authors found a statistically significant reduction in hurricane activity over the past 65 years. The relative inactivity of the past years (except for the very active 2017 season) was the most inactive phase of the examined time period. The abstract (emphasis added):
An Energetic Perspective on United States Tropical Cyclone Landfall Droughts
The extremely active 2017 Atlantic hurricane season concluded an extended period of quiescent continental United States tropical cyclone landfall activity that began in 2006, commonly referred to as the landfall drought. We introduce an extended climatology of U.S. tropical cyclone activity based on accumulated cyclone energy (ACE) and use this data set to investigate variability and trends in landfall activity. The drought years between 2006 and 2016 recorded an average value of total annual ACE over the U.S. that was less than 60% of the 1900–2017 average. Scaling this landfall activity metric by basin-wide activity reveals a statistically significant downward trend since 1950, with the percentage of total Atlantic ACE expended over the continental U.S. at a series minimum during the recent drought period.”
As CO2 in the atmosphere continuous to rise unabated, hurricane activity is decreasing. Obviously the two trends have little to do with each other.
Experts advise caution in assigning blame
Looking at the very clear body of facts, it is little wonder that the NOAA (via the Geophysical Fluid Dynamics Laboratory, GFDL) cautioned against linking the greenhouse gases and hurricanes in an official statement:
It is premature to conclude that human activities–and particularly greenhouse gas emissions that cause global warming–have already had a detectable impact on Atlantic hurricane or global tropical cyclone activity. That said, human activities may have already caused changes that are not yet detectable due to the small magnitude of the changes or observational limitations, or are not yet confidently modeled (e.g., aerosol effects on regional climate).”
Shrill in Potsdam
However in Germany, scientists scientists at the Potsdam Institute for Climate Impact Research (PIK) don’t accept the facts for what they are. For them t’s more important to be shrill and to set off alarms. For example in the wake of Hurricane Harvey, PIK scientist Anders Levermann gave a radio interview at Radio Eins on September 1, 2017. He said that when it’s warmer, more water vapour ends up in the air, and thus more rain and a hurricane with a flooding catastrophe in Houston. It’s just that simple, right? Then later in the interview Levermann added a “maybe”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




What Levermann committed here of course was an irresponsible misleading of the listeners. The clear decrease in hurricanes over the past 65 years contradicts his extraordinarily simplistic claims.
Poor urban planning
At the BBC the journalists were more serious with the subject, and did not stay silent regarding the complexity that is involved as it is known that a vast number of factors are at play. In Houston, for example, a blocking pattern was at work and thus led to a heavy rainfall over an urban area for a protracted time period. Anyone who claims that a part of the disaster can be attributed to man is unrealistically simplifying the system and ought to know better.
The answer to the question as to what the problem in Houston was is provided by an article by the BBC:
Climate change did not make people build along a vulnerable coastline so the disaster itself is our choice and is not linked to climate change.”
On ARD German public television, they too have gotten much more careful. TV meteorologist Donald Bäcker flatly dismissed the shot from the hip from Potsdam.
Forecasts thanks to link to AMO
In June, 2017, at the start of the hurricane season, Judith Curry and CFAN published a prognosis for the hurricane season. Here they anticpated an above-average hurricane activity season. They were right. If they are successful next year as well, then we’ll have an important forecasting method that will be of great use for society.
Other prognoses: Hurricanes have a certain development. Satellite photos allow the creation of storms to be tracked. But not all West African hurricane babies make it across the Atlantic and reach America. Tel Aviv University developed a model that allows us to determine which storms pose a risk and which ones will die off. Read the press release here.
Over the mid-term, hurricane activity can be forecast quite well because it is closely coupled to the Atlantic Multidecadfal Osciallation (AMO) ocean cycle, which has a periodicity of about 60 years. Michel de Rougemont reminds us in an essay appearing at WUWT.
Building in flood-prone areas is negligent
In Germany’s leading political daily FAZ of August 31, 2017, Winand von Petersdorff pointed out an important damage factor related to Hurricane Harvey. It was a man-made disaster in the sense that many homes and buildings had been built in classic flood-prone areas.

The enormous costs were foremost caused by the fact that the booming Houston metropolitan area, with its 6.5 million inhabitants, permitted building in grand style in areas where flooding and high water would occur.”

Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhat follows is one example why caution is absolutely essential when dealing with results and findings issued by (activist) government agencies.
Once popular diesel engines now public enemy no. 1
Nowhere in the world have the diesel engines enjoyed so much popularity as in Germany. Diesel engines had long been considered in Germany as being more environmentally friendly then the Otto type engines due to their much higher fuel mileage. Taxes on diesel fuel were and are today much lower.
But Germany has withdrawn its welcome mat for diesel engine. Like CO2, the government and environmental groups recently began waging full-scale war on diesel engines. The official reason for the crack down on diesel is the alleged high levels of dangerous emissions of nitrous oxides, and is what many suspect is mostly part of what is the overall war on the internal combustion engine and thus the effort to get people to switch to “clean” electric cars.
Ministry of Environment’s, media’s absurd claims
To underscore the risks of diesel fumes and to spread fear of diesel engines, Germany’s Ministry of Environment (UBA) recently released “new findings” claiming diesel engines are responsible for 6000 premature deaths every year. Unsurprisingly: the German press and activist groups went bananas uncritically reporting the findings in the most spectacular ways they could imagine.
For example: the Frankfurter Rundschau wrote:
Also diseases such as diabetes mellitus, high blood pressure, stroke and asthma are connected to irritant gas concentration. Eight percent of the diabetes mellitus illnesses in Germany in 2014 can be linked to nitrous oxide in the air outside: ‘That corresponds to some 437,000 cases,‘ said Myriam Tobollik, health researcher at the Ministry of Environment.”
“A political number” that “sounds like science”
Fortunately the hysteria and gross exaggerations did not escape the attention of the German press consumers, who have recently seen the value of their diesel engine vehicles plummet, and the few, still responsible journalists out there. It turns out the UBA report was based on exceptionally terrible science and the claims bordering on the absurd.
For example, Spiegel’s Jan Fleischhauer wrote here:
The made-up dead
Every year 6000 premature deaths from nitrous oxide – that’s how the Environment Ministry panicked the German citizenry. What sounds like science in truth is  a political number from a completely politicized government administration.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the Spiegel article Fleischhauer asks why aren’t other devices not targets: “A gas cooking stove during reaches peak values of 4000 micrograms per cubic meter. Where’s the campaign against the gas stove?”
It is a fact that many workplaces see routinely far higher nitrous oxide concentrations than what is measured near streets.
Measurement station folly (again), fake crisis
Fleischhauer also reminds readers that the EU directives specify that limit values for exhaust concentrations be measured at a distance of 25 meters from a busy intersection. After having looked through the UBA report, the Spiegel journalist adds:
Now I read the the measurement instruments in Germany are placed directly next to the roadway. I have not verified that. But if it’s true, then it should not be a surprise we find ourselves in a state of a diesel alarm.”
Diesel study “botched”
That the 6000 deaths a year figure was a fraud came to the attention of German mass daily Bild from its own readers. Bild was compelled on March 11 to publish the following headline:

Bild daily headline: “Reader anger over the botched diesel study”
The European Institute for Environment and Climate (EIKE) here commented that the German Environment Ministry “irrevocably ruined the reputation of the 1500-employee large agency behemoth”.
“Politicians lying, playing games”
One Bild reader, Wolfgang Bügener of Oberhausen, wrote: “It is peculiar how our politicians are playing games with and lying to us.”
Another added: “The real scam not only happened in Wolfsburg [VW headquarters] but also at the environmental organizations and Ministries, who throw around false and unproven claims.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany Temperatures Baffle: September Mean Shows Hardly Any Warming In 70 Years
By Josef Kowatsch and Dr. Sebastian Lüning
(Translated and edited by P Gosselin)
Temperatures are rising and rising and rising. That’s what we read in any case in the daily newspaper, and that’s what some television professors, activists and climate scientists are telling us. Strangely rarely are temperature curves ever shown. Why is this so? One example is the September mean temperature for Germany, which we use to illustrate this peculiar media documentation gap.
Here we use the official DWD German Weather Service data. When we look at the past 100 years we see a very modest warming of just a few tenths of a degree (Fig. 1). This is no surprise as we find ourselves in the warming phase since the Little Ice Age, the coldest phase of the last 10,000 years. It would have been terrible had the climate stayed at this non-representative low level.

Figure 1: Chart depicting Germany September mean temperature over the past 100 years. Data source: DWD. 
It is easy to see the long cycles in the temperature curve. Above we a cold phase between 1920 and 1930, followed by a warm period during the Nazi time, and then followed by a long-term cold dip.
Beginning in 1985, September began to warm up again before reaching a plateau that took hold just before the year 2000 and at which we currently find ourselves. Based on the past development one could speculate that we are headed towards a slight cooling.
Now let’s look at the period from the end of WWII until today, more than 70 years, the time of the last temperature plateau until today. Immediately we see that we are far from worrisome climate warming (Fig. 2):


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Figure 2: Chart depicting Germany September mean temperature over the past 70 years. Data source: DWD. 
Finally we take a look at the past 13 years (Fig. 3), i.e. the development since 2004. Again there has not been any significant warming. In fact there’s been some cooling. Everything other than a climate catastrophe.

Figure 3: Chart of September mean temperatures in Germany over the past 13 years. Data source: DWD. 
Getting back to the primary question of why isn’t the German media showing the real German temperature curve, obviously the real facts are just too inconvenient. A pert of the public could even lose its faith in the much-preached climate catastrophe and end up sharply criticizing the harsh sacrifices now being made because of the climate fear that has been instilled by policymakers.
It’s high time for the issue to be made transparent and to push back against the activism. What’s needed is a new environmental protection ethic, one which addresses all the problems.
The excessive focus on the climate question is no longer sustainable and is even counterproductive. Other more important problems that can be solved over the short term require greater attention — clean water, clean air and clean food being evenly distributed — would be a common ethical goal for mankind to strive for. The fear-mongering climate protection issue is a repeat of the earlier business model of sin and the sale of indulgences.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOne thing is clear: Germans were fooled and deceived by politicians and activists into thinking that the transition to renewable energies would not cost much, reduce pollutants, create a clean environment, improve the climate and create many jobs.
None of these have come true.
Electricity prices have skyrocketed, the landscape is being industrialized and Germany has not reduced its greenhouse gases in more than 7 years. Moreover the climate is still the same. Now Germany’s industrial base is eroding.
Today we will look at the first point: cost. Yesterday the online industry journal Deutsche Mittelstand Nachrichten (Midsize Company News) here carried the headline:
“Association of Energy: Electricity Prices To Rise Significantly”
So the bad news continue, and this will further adversely impact consumers, small businesses and the all-important Mittelstand.
And because the Mittelstand employ some 70% of all workers in Germany, most of them highly skilled and well-paid, the news is bad. The Mittelstand is already facing crisis on a number of fronts. First is the lack of skilled workers on the labor market. Second: many of these companies are now being handed down to the next generation, but there are no successors. In fact Chinese companies have been busily snapping up the companies along with their patents and technical expertise.
Now, thirdly, comes the extreme energy prices (and volatile supply) – thanks to Germany’s mad and poorly thought-out rush into utopian green energies.
Rising feed-in costs


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The main factor driving the higher prices remains the EEG green energy feed-in act, the site reports. Association head Christian Otto told German daily Bild that the feed-in subsidy will rise to 7 cents per kwh (currently 6.88 cents). 
Three of the four power transmission grid operators have already announced an increase in the grid fees.”
The four German grid operators are Amprion, TransnetBW, Tennet and 50Hertz. Only East Germany-based 50Hertz does not plan to raise the fees for the time being.
Uncompetitive
The higher feed-in surcharges make push German electricity prices to 30 cents a kwh, almost three times more expensive than power in the USA, for example. Little wonder that some are now calling to “make Germany great again”.
Moreover, citing analysts, the site reports that heating oil as well has become 11 percent more expensive, and warns more increases lie ahead as winter approaches.
Grid instability adding to costs
The Deutsche Mittelstand Nachrichten site cited the head of the BDEW energy association, Stefan Kapferer, who blasted the “constantly more frequent and expensive interventions that are needed to keep the grid stable due to the fluctuating feed-in of renewable energies“.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHere at NTZ we are glad to see that German weather and climate blogger Schneefan is back from his hiatus and this week he presents a couple of interesting posts, here and here.
Cold to grip Europe for rest of month
First he writes that the latest weather models and patterns are now pointing to an extended winter this year for Europe. For example the 14-day forecast for Hanover shows frosty conditions ahead.
Also a recent run by the European weather model shows severe cold potentially gripping Europe in 9 days:

February 1°C cooler than normal 
So far Germany has seen the first half of February come in almost 1°C cooler than normal, making it among the coldest in years, says meteorologist Dominik Jung of www.wetter.net.
Earlier projection was entirely wrong
According weather experts, March is also expected to be wintry and could be one of the coldest in years. That’s quite a turnaround given that the earlier CFS forecast made back in mid-January which showed blow torch temperatures cooking Europe in February:

The US National Weather Service (CFS) 2m surface temperature forecast made on 18 January, 2018, showed very warm conditions for February. That forecast has since been drastically revised.
La Nina dragging temperatures down
So why have we been hearing about so many harsh winter conditions all over the northern hemisphere this winter?
One reason likely has something to do with the fact that the globe has been cooling off substantially since the last El Nino ended in 2016. Currently we are now experiencing La Niña conditions:

Chart shows the weekly deviations from the mean for the El Niño-region 3.4 from May 2016 until the beginning of February 2018. Currently we find ourselves in the cool La Nina phase. Source: KNMI
Furthermore, the National Weather Service continues to show La Nina conditions persisting through most of 2018, which means a greater likelihood of a further cooling of the globe’s surface:

Over the past 2 years global surface temperatures as measured by satellites show steady cooling. Source: WoodForTrees.org.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Another longer term culprit suspected of being behind the cooling is the current solar cycle number 24, which has been abnormally weak over the entire current decade. The Cycle 24 was the weakest in 200 years. Low solar activity has been shown to lead to cooling surface temperatures.

Screenshot shows the number of spotless days on the sun up to February 14, 2018. Source: www.spaceweather.com/
Oceans cooling over past 3 years
Another sign that bodes especially ill for continued surface cooling is that the world’s oceans have been cooling. 71% of the earth’s surface is covered by water, which means these temperature changes will have significant impacts on the globe’s climate.
In January 2018 Ron Clutz reported at Science Matters on an unexpected phenomenon: the cooling of the global oceans over the past 3 years:
The chart below shows SST monthly anomalies as reported in HadSST3 starting in 2015 through December 2017.”


After a bump in October the downward temperature trend has strengthened. As will be shown in the analysis below, 0.4C has been the average global anomaly since 1995 and December has now gone lower to 0.325C.  NH dropped  sharply along with the Tropics.  SH held steady erasing the Oct. bump.  All parts of the ocean are clearly lower than at any time in the past 3 years.
For Reference:
Global SSTs are the lowest since 3/2013
NH SSTs are the lowest since 3/2014
SH SSTs are the lowest since 1/2012
Tropics SSTs are the lowest since 3/2012
[…]
The oceans are driving the warming this century.  SSTs took a step up with the 1998 El Nino and have stayed there with help from the North Atlantic, and more recently the Pacific northern “Blob.”  The ocean surfaces are releasing a lot of energy, warming the air, but eventually will have a cooling effect.  The decline after 1937 was rapid by comparison, so one wonders: How long can the oceans keep this up?”
Read the entire post at Science Matters.
“Bad times” for global warming alarmists
Ron also looks at the AMO ocean cycle. Schneefan summarizes it all in a nutshell:
Everything points to an imminent tipping of the AMO cycle. That’s going to pull global temperatures downward. For Rahmstorf and Co. bad times are starting.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSometimes you have to wonder which are the biggest fraud: Germany’s claim that its cars are clean, or its claim of being a leader in climate protection. Both, it turns out, are very fake and even downright frauds.
While German Chancellor Angela Merkel and German activists like going around and scolding Donald Trump for his “irresponsible” stance on “greenhouse” gas emissions, it is coming to light that Germany’s climate posturing is indeed a total swindle.
While USA’s greenhouse gas emissions have declined impressively over the past decade, Germany’s have gone nowhere.
Flat for 9 years
And now Cleanenergywire.org here reports that Germany again this year (2017) will again fail to reduce its CO2 equivalent emissions for the 9th year running. Ironically one of the reasons cited for this year by Cleanenergy.org is “cold weather” (again).

Germany’s CO2 equivalent CO2 greenhouse gas emissions in metric tonnes since 2009. This year (2017) CO2 equivalent emissions are expected to be slightly over those seen in 2016. Data taken from German Ministry for environment.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The reality is that Trump and America has nothing to learn from the Green-preaching Germans, except on how to deceive and mislead the public. Cleanenergy.org writes that the higher energy demand is “triggered by economic growth and colder weather“.
Cleanenergy.org cites the AG Energiebilanzen (AGEB), which said in a press release: “From January until September, energy demand was 1.9 percent higher than in the same period last year.” And thus the AG Energiebilanzen expects “energy-related CO2 emissions will rise slightly in 2017”.
“A disaster”
Merkel’s glaring failure, however, did not prevent her from taking a swipe at Trump, the Handelsblatt reports. Unfortunately for Merkel there is no disguising Germany’s failure to meet its own imposed targets. The Environment Ministry says the 2017 emissions figures are “a disaster for Germany’s international reputation as a climate leader.”
CO2 emissions reduction is pie-in the sky, another hoax
Whatever gets decided in Bonn will be pure meaningless self-deception. The fact remains that China, India and the rest of the developing world are going to continue boosting their fossil fuel energy consumption and CO2 emissions are going to keep rising for quite awhile. The recent OPEC report makes that very clear.
Some advice for Merkel: Forget the CO2 reductions. Cutting Germany’s puny 2% global share would theoretically lead to a temperature reduction of 1 or 2 hundredths of a degree Celsius, meaning some 100 trillion euros per °C. It’s pure economic insanity. Take the idea and discard it quickly into the dustbin for good.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterVolcano Agung in Bali is showing worrisome signs of a major eruption, writes German climate blogger Schneefan here. The highest level of activity with multiple tremor episodes were just recorded. You can monitor Agung via live cam and live seismogram.
The 3000-mter tall Agung has been at the highest warning level 4 since September 21.
Schneefan writes that the lava rise has started and that “an eruption can be expected at any time“.
So far some 140,000 people have been evacuated from the area of hazard, which extends up to 12 km from the volcano. Schneefan writes:
Yesterday ground activity by far exceeded the previous high level. Quakes have become more frequent and stronger, which indicates a stronger magma flow (see green in the histogram). Since October 13 there has been for the first time a “nonharmonic trembling (tremor), which can be seen in red at the top of the last two bars of the histogram.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The colors of the columns in the bar chart from bottom to top stand for perceptible earthquakes (blue) low eartnhquakes (green) surface quakes (orange . Just recently red appeared, signifying non harmonic tremors.  The seismogram below shows what are at times longer period quakes: meaning magma is violently flowing in the volcano. Source: https://magma.vsi.esdm.go.id/.
Since yesterday the seismogram for AGUNG has been showing powerful rumbling (red).

The seismogram of AGUNG shows powerful tremors (level RED). The seismogram is updated every 3 minutes: Source: Seismogramm
Because Agung is located near the equator, a major eruption with ash flying up into the stratosphere would have short-term climatic impacts that could last a few years.
Agung last erupted in 1963 with an explosivity index of VEI 5, sending a plume of ash some 25 km into the atmosphere before leading to a cooling of 0.5°C. The eruption of Pinatubo in the Philippines in 1991 led to a global cooling of 0.5°C.
 
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Swiss online SRF public television site here reports that German power engineering giant Siemens plans to eliminate some 6900 employees, half of them in Germany. Hit will be the conventional power plant and electric drive systems branch.
German energy sector in turmoil
The SRF writes that the power plant branch “is suffering due to the Energiewende“, Germany’s attempted transition to renewable energies. This branch alone will see 6100 job reductions. Turbine plants in Görlitz, Leipzig, Offenbach, Erfurt, Erlangen, Berlin and Mülheim (Ruhr) will be impacted. The announcement just before the start of the Christmas holiday season has angered trade unionists.
The Handelsblatt here reports that some of the impacted engineering workers are “in shock and in tears” over the news. Protests and strikes have been announced.
The news of the jobs cutbacks are the latest in a series of huge jobs reductions seen throughout the German energy sector. Over the past years, power giants such as RWE and Eon have announced the layoffs of thousands of its workers as the German Energiewende has eroded profits in the conventional energy sector and has led to skyrocketing electricity prices for consumers.
The misery has not only hit conventional energy jobs, but also renewable energy sector as well. Due to cheap imports from China and an uncertain investment future in the wind sector, most of Germany’s solar power equipment producers have become insolvent and thousands of jobs have been lost. Recently wind energy equipment producers such as Nordex have announced job cuts as well and the future for wind energy in Germany looks bleak.
As more volatile wind and solar energy capacity have come online, steam and gas turbines have become uneconomical to operate and investments in conventional power plants have taken a hit over the recent years.
The BBC has reported on the jobs cutback by Siemens, but made no made no mention of the Energiewende.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAustralian Bushfires Have Become Less Frequent Over The Past 15 Years
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
In the Australian state of Victoria, 50,000 km² of land have burned and 12 people and 1 million sheep and thousands of heads of cattle lost their lives. The regions hit by fire were near Portland, Westernport and in the Plenty Ranges, as well as the Wimmera and Dandenong districts. The burned regions extended over a quarter of the state. Conditions for the fires were made favorable by the long-lasting drought period, which changed the landscape into a tinderbox. Finally the fire was exacerbated by strong winds, which carried off a glowing ember from a campfire and ignited the adjacent grassy region.
What role did climate change play in the fire disaster? The Potsdam Institute for Climate Impact Research (PIK) and other alarmists remained surprisingly moot here. Normally climate alarmists rush to the microphones and claim that although such single events are not easily linked to climate change, the probability is in any case is much higher. Loaded dice.
Proponents of a climate catastrophe kept silent in the case of these Victoria fires because they had not been born yet.
The described above fires occurred in February, 1851 and are known as the ‘Black Thursday Bushfires‘.
There have always been bushfires in Australia. For example at the end of the 19th century and the start of the 20th century in New South Wales. Apparently that fact was not even known by the former General Secretary of the Climate Framework Convention of the United Nations (UNFCCC), Christiana Figueres, who in 2013 described in knee-jerk fashion that the fires in New South Wales (NSW) were a consequence of climate change. A classic gaffe – one that should never happen for someone occupying such a position.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The provincial government defended itself against such misinterpretations. The German business daily Handelsbatt wrote on October 25, 2013:
The new conservative government accuses environmental protection activists are exploiting the fires to oppose the planned repeal of of the CO2-tax. ‘Some people are trying to profit from all the tragedy and suffering of this week,’ said Environment Minister Greg Hunt. By the way, the CSIRO research authority just explained that there have been bushfires in Australia for millions of years.”
If one counts the damage from bushfires in NSW compared to the number of homes, then there has been no recognizable trend over the past 90 years.  In The Conversation, John McAneney presented the facts. Foremost he sees deficits with regards to land-use planning, which made the extent of the fire damage possible.
In July 2017 a study by Nick Earl und Ian Simmonds appeared in the Journal of Geophysical Research. The authors analyzed the Australian bushfire statistics from 2001-2015 and found a reduction in fires. Yet, they did find a large temporal and spatial variability which in part was controlled by ocean cycles such as the El Nino or the Indian Ocean Dipole. Abstract:
Variability, trends, and drivers of regional fluctuations in Australian fire activity
Throughout the world fire regimes are determined by climate, vegetation, and anthropogenic factors, and they have great spatial and temporal variability. The availability of high-quality satellite data has revolutionized fire monitoring, allowing for a more consistent and comprehensive evaluation of temporal and spatial patterns. Here we utilize a satellite based “active fire” (AF) product to statistically analyze 2001–2015 variability and trends in Australian fire activity and link this to precipitation and large-scale atmospheric structures (namely, the El Niño–Southern Oscillation (ENSO) and the Indian Ocean Dipole (IOD)) known to have potential for predicting fire activity in different regions. It is found that Australian fire activity is decreasing (during summer (December–February)) or stable, with high temporal and spatial variability. Eastern New South Wales (NSW) has the strongest decreasing trend (to the 1% confidence level), especially during the winter (JJA) season. Other significantly decreasing areas are Victoria/NSW, Tasmania, and South-east Queensland. These decreasing fire regions are relatively highly populated, so we suggest that the declining trends are due to improved fire management, reducing the size and duration of bush fires. Almost half of all Australian AFs occur during spring (September–November). We show that there is considerable potential throughout Australia for a skillful forecast for future season fire activity based on current and previous precipitation activity, ENSO phase, and to a lesser degree, the IOD phase. This is highly variable, depending on location, e.g., the IOD phase is for more indicative of fire activity in southwest Western Australia than for Queensland.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMore Wind Turbines,
More Habitat Harm, Loss
Scientists (Krekel and Zerrahn, 2017 ) report that the installation of wind turbines near human populations “exerts significant negative external effects on residential well-being” and a “significant negative and sizable effect on life satisfaction” due to “unpleasant noise emissions” and “negative impacts on landscape aesthetics”.
“We show that the construction of wind turbines close to households exerts significant negative external effects on residential well-being … In fact, beyond unpleasant noise emissions (Bakker et al., 2012; McCunney et al., 2014) and impacts on wildlife (Pearce-Higgins et al., 2012; Schuster et al., 2015), most importantly, wind turbines have been found to have negative impacts on landscape aesthetics (Devine-Wright, 2005; Jobert et al., 2007; Wolsink, 2007). … We show that the construction of a wind turbine within a radius of 4,000 metres has a significant negative and sizeable effect on life satisfaction. For larger radii, no negative externalities can be detected.”
If human well-being and life satisfaction is seriously compromised by the nearby presence of a wind turbine, imagine the physiological effects on birds, bats, and land-dwelling mammals in general.
Six new papers expose the systematic destruction of natural wildlife habitats via the installation of wind turbines.
1. A 20-Fold Loss Of Bat Habitat At Wind Turbine Sites … A ‘Worldwide Phenomenon’

Millon et al., 2018
“Wind turbines impact bat activity, leading to high losses of habitat use … Island bats represent 60% of bat species worldwide and the highest proportion of terrestrial mammals on isolated islands, including numerous endemic and threatened species (Fleming and Racey, 2009). … We present one of the first studies to quantify the indirect impact of wind farms on insectivorous bats in tropical hotspots of biodiversity. Bat activity [New Caledonia, Pacific Islands, which hosts nine species of bat] was compared between wind farm sites and control sites, via ultrasound recordings at stationary points [A bat pass is defined as a single or several echolocation calls during a five second interval.] The activity of bent winged bats (Miniopterus sp.) and wattled bats (Chalinolobus sp.) were both significantly lower at wind turbine sites. The result of the study demonstrates a large effect on bat habitat use at wind turbines sites compared to control sites. Bat activity was 20 times higher at control sites compared to wind turbine sites, which suggests that habitat loss is an important impact to consider in wind farm planning. …  Here, we provide evidence showing that two genera of insectivorous bat species are also threatened by wind farms.  … To our knowledge, this is one of the first studies quantifying the indirect negative impact of wind turbines on bat activity in the tropics. … The lower attractiveness of the foraging habitat under wind turbines, both in a tropical and in a temperate climate, indicates that the indirect impact of wind turbine is a worldwide phenomenon.”
2. A ‘Distinct Physiological Response’ (Stress) Caused by Wind Turbines’ ‘Disturbance Factors’
Lopucki et al., 2018
“Living in habitats affected by wind turbines may result in an increase in corticosterone levels in ground dwelling animals … Environmental changes and disturbance factors caused by wind turbines may act as potential stressors for natural populations of both flying and ground dwelling animal species. The physiological stress response results in release of glucocorticoid hormones. … The common vole showed a distinct physiological response − the individuals living near the wind turbines had a higher level of corticosterone [physiological stress affecting regulation of energy, immune reactions]. … This is the first study suggesting impact of wind farms on physiological stress reactions in wild rodent populations. Such knowledge may be helpful in making environmental decisions when planning the development of wind energy and may contribute to optimization of conservation actions for wildlife.”
3. Wind Farms’ ‘Known Impacts’: Mortality Increase, Habitat Destruction, Enhanced Human Interference, Reduced Breeding Opportunities
Ferrão da Costa et al., 2018
“According to a review by Lovich and Ennen (2013), the construction and operation of wind farms have both potential and known impacts on terrestrial vertebrates, such as: (i) increase in direct mortality due to traffic collisions; (ii) destruction and modification of the habitat, including road development, habitat fragmentation and barriers to gene flow; (iii) noise effects, visual impacts, vibration and shadow flicker effects from turbines; (iv) electromagnetic field generation; (v) macro and microclimate change; (vi) predator attraction; and (vii) increase in fire risks. … Helldin et al. (2012) also highlighted that the development of road networks associated with wind farms could promote increased access for traffic related to recreation, forestry, agriculture and hunting. The consequence, particularly on remote places, is the increase in human presence, affecting large mammals via significant disturbance, habitat loss and habitat fragmentation. These negative effects are expected to be particularly relevant for species that are more sensitive to human presence and activities, such as large carnivores. Large carnivores, such as the wolf, bear, lynx or wolverine, tend to avoid areas that are regularly used by humans and—especially for breeding—show a preference for rugged and undisturbed areas (Theuerkauf et al. 2003; George and Crooks 2006; May et al. 2006; Elfstrom et al. 2008; Sazatornil et al. 2016), which are often chosen for wind power development (Passoni et al. 2017). … Results have shown that the main impact of wind farms on wolves is the induced reduction on breeding site fidelity and reproductive rates. These effects, particularly when breeding sites shift to more unsuitable areas, may imply decreasing survival and pack viability in the short term.”
4. Installation Of Wind Turbines Have ‘Population-Level Effects’ For Rare, Endangered Species
Watson et al., 2018
“The global potential for wind power generation is vast, and the number of installations is increasing rapidly. We review case studies from around the world of the effects on raptors of wind-energy development. Collision mortality, displacement, and habitat loss have the potential to cause population-level effects, especially for species that are rare or endangered.”
5. An ‘Urgent Concern’: ‘Wind Power Has Negative Effects On Proximate Wildlife’ (Collision Fatalities, Habitat Loss)
Naylor, 2018
“While wind energy provides a viable solution for emission reductions, it comes at an environmental cost, particularly for birds. As wind energy grows in popularity, its environmental impacts are becoming more apparent. Recent studies indicate that wind power has negative effects on proximate wildlife. These impacts can be direct—collision fatalities—and indirect—habitat loss (Fargione et al. 2012; Glen et al. 2013). Negative impacts associated with operational wind farms include collision mortalities from towers or transmission lines and barotrauma for bats. Habitat loss and fragmentation, as well as avoidance behavior, are also consequences resulting from wind farm construction and related infrastructure. The potential harm towards protected and migratory bird species are an urgent concern, especially for wind farms located along migratory flyways. In terms of mortality, wind turbines kill an estimated 300,000 to 500,000 birds, annually (Smallwood 2013). The high speed at which the fan wings move and the concentration of turbines create a gauntlet of hazards for birds to fly through. … [T]he height of most wind turbines aligns with the altitude many bird species fly at (Bowden 2015). Birds of prey— raptors—are of particular concern because of their slow reproductive cycles and long lifespans relative to other bird species (Kuvlesky 2007).”
6. Wind Farms Negatively Affect Waterfowl Via Habitat Loss, Disturbance Displacement, Compromised Foraging Opportunities
Lange et al., 2018
“Results from our surface water extractions and aerial surveys suggest that the wind farm has negatively affected redheads through altered hydrology and disturbance displacement. Our surface water extraction analysis provides compelling evidence that the local hydrology has been greatly affected by the construction of the wind farm. … Our results suggest the occurrence of direct habitat loss and disturbance displacement of redheads from the wind farm along the lower Texas coast. Although our study was directed solely toward redheads, it is likely that this wind farm has affected other species that use these wetlands or migrate along the lower Texas coast (Contreras et al. 2017). Studies in Europe investigating the effects on waterfowl by wind turbines have reported similar results, showing that turbines have likely compromised foraging opportunities for waterfowl through disturbance displacement (Larsen and Madsen 2000).”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe extreme German leftists Die Linke (The Left) Party in Germany issued a press release blasting Angela Merkel’s decision not to personally attend the “One Planet Summit” in Paris.
Apparently climate change is not an issue important enough for the German chancellor to devote her time to.
Merkel “a total no-show”
German Leftist Party climate and energy politician Lorenz Gösta Beutin said:
Climate-politically Merkel is a total no show: In Paris the head of the German government could have sent a powerful signal in support of implementing the UN Climate Treaty, and against the unspeakable anti-climate protection course of President Donald Trump, who announced the USA’s withdrawal from the Climate Accord and requested renegotiations. Instead the federal government sent Environment Minister Barbara Hendricks, who had to explain that Germany would resoundingly miss its self-stated climate targets.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




International “faux pas”
The “One Planet Summit” in Paris was held by France, the United Nations and the World bank. Reutin commented further:
That Angela Merkel did not attend the climate conference – where over 50 state and government heads from all around the world wanted to push ahead the historic Paris climate protection accord from two years ago – is a disgrace par excellence. After an embarrassing appearance at the UN climate conference in Bonn, where the chancellor only delivered empty words instead of concrete measures, the self-proclaimed climate chancellor demonstrated a faux pas on the international stage.”
The neoliberal belief held by French President Emmanuel Macron that the free market and private capital would put the brakes on global warming and remove the damage to climate change caused by man and nature is faulty. Capitalism functions only through unbridled growth and the profit of a few. It is the cause, not the solution, of humanity-problem climate change.
The LINKE (LEFTISTS) demand the introduction of a financial transaction tax, whose revenue would in part be allocated to southern countries as climate change support funds. Also the industrialized countries must meet their obligations and pay 100 billion dollars annually  into the Green Climate Fund beginning in 2020, and do so without offsetting already existing development aid funds.“
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterQuartz.com here presents an interesting chart which tells us the green energy revolution of the past 30 years has resulted in practically nothing. It’s been a flop. Fossil fuels remain as wildly popular as ever.

Global fossil fuel use as a share of total energy has risen since James Hansen’s 1988 testimony. Chart: Quartz.com.
In the 1970s the big worry was that fossil fuels would soon run out, and so we should “use them wisely”. But in the 1980s the risk changed to one of an overheating planet, and so we should not use them at all.
Higher than 1988, when James Hansen testified
We can all recall a sweating James Hansen’s 1988 stage-crafted testimony before Congress, warning that increasing atmospheric CO2 concentrations would lead to spiraling global warming. And unless action was taken urgently, the ice caps would soon melt and the earth would sizzle.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Countries as a result mobilized 100s of billions of dollars to eliminate the use of these “dangerous, climate-killing” fossil fuels.
Today for all that money you’d think that tremendous progress in reducing fossil fuels would be the result. You couldn’t be more wrong.
The sad truth is that after hundreds of billions spent, and trillions committed, fossil fuels’ share of total energy consumption globally has in fact risen since Hansen’s doomsday testimony, see the figure above!
Bringing the dead back to life
What may be a surprise to many is that whenever we burn fossil fuels, which originate primarily from ancient plants that died and were naturally sequestered in the earth as “fossils” eons ago, we are in fact taking this once live carbon and recirculating it back into the current, living ecosystem. The result: More carbon-based life is getting produced today. The planet is greening. Now the earth is teeming with more life than it has seen in millions of years. That’s fundamental science.
So if you want the system to have more life, just add carbon to it. One way is to add old carbon (by burning fossil fuels) that’s been locked away in the ground.
On the other hand if you want to limit life, then remove the carbon from the eco-system. Funny how the alarmists claim to be worried about life being under threat on earth, yet are striving to remove its very source.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe abysmal track record of computer models in simulating climate trends has increasingly been highlighted in the scientific literature.  Recently published papers indicate that in some cases climate models actually get it right zero percent of the time (Luo et al., 2018; Hanna et al., 2018), or that hydrological models are off by a factor of 8 and 4 of 5 simulate trends opposite to real-world observations (Scanlon et al., 2018).  
Even the model-based assumption that positive water vapor feedback accompanies and amplifies CO2-forced temperature change is not supported by observations, with CO2 climate sensitivity overestimated by 200% (Ollila, 2018).  Simply put, climate modeling is increasingly being recognized in the scientific literature as lacking scientific merit.

ZERO Of The 126 Models Reproduce Recent Pacific Ocean Cooling
Luo et al., 2018
“Over the recent three decades sea surface temperate (SST) in the eastern equatorial Pacific has decreased, which helps reduce the rate of global warming. However, most CMIP5 model simulations with historical radiative forcing do not reproduce this Pacific La Niña-like cooling. Based on the assumption of “perfect” models, previous studies have suggested that errors in simulated internal climate variations and/or external radiative forcing may cause the discrepancy between the multi-model simulations and the observation…. Based on the total 126 realizations of the 38 CMIP5 model Historical simulations, the results show that none of the 126 model historical realizations reproduce the intensity of the observed eastern Pacific [1981-2010] cooling  and only one simulation produces a weak cooling (−0.007 °C per decade).”


ZERO Of 36 Models Capture Greenland’s Recent Blocking/Climatological Changes

Hanna et al., 2018
Recent changes in summer Greenland blocking captured by none of the CMIP5 models
“Recent studies note a signiﬁcant increase in high-pressure blocking over the Greenland region (Greenland Blocking Index, GBI) in summer since the 1990s. … We ﬁnd that the recent summer GBI increase lies well outside the range of modelled past reconstructions (Historical scenario) and future GBI projections (RCP4.5 and RCP8.5). The models consistently project a future decrease in GBI (linked to an increase in NAO), which highlights a likely key deﬁciency of current climate models if the recently-observed circulation changes continue to persist. Given well-established connections between atmospheric pressure over the Greenland region and air temperature and precipitation extremes downstream, e.g. over Northwest Europe, this brings into question the accuracy of simulated North Atlantic jet stream changes and resulting climatological anomalies […] as well as of future projections of GrIS mass balance produced using global and regional climate models.”

IPCC’s CO2 Climate Forcing Values 200% ‘Too Sensitive’, Water Vapor Feedback ‘Does Not Exist’
Ollila, 2018
“The temperature effects of the water and CO2 are based on spectral analysis calculations, which show that water is 11.8 times stronger a GH gas than CO2 in the present climate. … There are essential features in the long-term trends of temperature and TPW [total precipitable water], which are calculated and depicted as mean values 11 years running. The temperature has increased about 0.4°C since 1979 and has now paused at this level. The long-term trend of TPW [total precipitable water] effects shows that it has slightly decreased during the temperature-increasing period from 1979 to 2000. This means that the absolute water amount in the atmosphere does not follow the temperature increase, but is practically constant, reacting only very slightly to the long-term trends of temperature changes. The assumption that relative humidity is constant and that it amplifies the GH gas changes over the longer periods by doubling the warming effects finds no grounds based on the behavior of the TWP [total precipitable water] trend. The positive water feedback exists only during the short-term ENSO events (≤4 years).”
“The validity of the IPCC model can be tested against the observed temperature. It turns out that the IPCC-calculated temperature increase for 2016 is 1.27°C, which is 49 per cent higher than the observed 0.85°C. This validity test means that the IPCC climate forcing model using the radiative forcing value of CO2 is too sensitive for CO2 increase, and the CS [climate sensitivity] parameter, including the positive water feedback doubling the GH gas effects, does not exist.”
“The CO2 emissions from 2000 onward represent about one-third of the total emissions since 1750, but the temperature has not increased, and it has paused at the present level. This is worthy proof that the IPCC’s climate model has overestimated human-induced causes and has probably underestimated natural causes like the sun’s activity changes, considering the historical temperatures during the past 2000 years.”
“The RF [radiative forcing] value for the CO2 concentration of 560 ppm is 2.16 Wm−2 according to equation (3), which is 42 per cent smaller than 3.7 Wm−2 used by the IPCC. The same study of Ollila (2014) shows that the CS [climate sensitivity] parameter λ is 0.27 K/(Wm−2), which means that there is no water feedback. Using this λ value, equation (3) gives a TCS [transient climate sensitivity] value of 0.6°C only. This same result is also reported by Harde (2014) using the spectral analysis method. …There are both theoretical- and measurement-based studies showing results that can be explained only by the fact that there is no positive water feedback. This result reduces the CS [climate sensitivity] by 50 per cent. Some research studies show that the RF [radiative forcing] value of carbon dioxide is considerably smaller than the commonly used RF value, according to the equation of Myhre et al. (1998). Because of these two causes, the critical studies show a TCS [transient climate sensitivity] of about 0.6°C instead of 1.9°C by the IPCC, a 200 per cent difference.”

Observations Have ‘Factor Of Two’ Less Warming Than Modeled Projections
Christy et al., 2018
“All datasets produce high correlations of anomalies versus independent observations from radiosondes (balloons), but differ somewhat in the metric of most interest, the linear trend beginning in 1979. The trend is an indicator of the response of the climate system to rising greenhouse gas concentrations and other forcings, and so is critical to understanding the climate. The satellite results indicate a range of near-global (+0.07 to +0.13°C decade−1) […] trends (1979–2016), and suggestions are presented to account for these differences. We show evidence that MSUs on National Oceanic and Atmospheric Administration’s satellites (NOAA-12 and −14, 1990–2001+) contain spurious warming, especially noticeable in three of the four satellite datasets.”
“Comparisons with radiosonde datasets independently adjusted for inhomogeneities and Reanalyses suggest the actual tropical (20°S-20°N) trend is +0.10 ± 0.03°C decade−1. This tropical result is over a factor of two less than the trend projected from the average of the IPCC climate model simulations for this same period (+0.27°C decade−1). … Because the model trends are on average highly significantly more positive and with a pattern in which their warmest feature appears in the latent-heat release region of the atmosphere, we would hypothesize that a misrepresentation of the basic model physics of the tropical hydrologic cycle (i.e. water vapour, precipitation physics and cloud feedbacks) is a likely candidate.”

Climate Models Are Conceptual And We Don’t Understand The Mechanisms 
Collins et al., 2018
“Here there is a dynamical gap in our understanding. While we have conceptual models of how weather systems form and can predict their evolution over days to weeks, we do not have theories that can adequately explain the reasons for an extreme cold or warm, or wet or dry, winter at continental scales. More importantly, we do not have the ability to credibly predict such states. Likewise, we can build and run complex models of the Earth system, but we do not have adequate enough understanding of the processes and mechanisms to be able to quantitatively evaluate the predictions and projections they produce, or to understand why different models give different answers. … The global warming ‘hiatus’ provides an example of a climate event potentially related to inter-basin teleconnections. While decadal climate variations are expected, the magnitude of the recent event was unforeseen. A decadal period of intensified trade winds in the Pacific and cooler sea surface temperatures (SSTs) has been identified as a leading candidate mechanism for the global slowdown in warming.”


Hydrological Modeling Off By A Factor Of 8, With 4 Of 5 M0dels Yielding Opposite Trends Vs. Observations
Scanlon et al., 2018
“The models underestimate the large decadal (2002–2014) trends in water storage relative to GRACE satellites, both decreasing trends related to human intervention and climate and increasing trends related primarily to climate variations. The poor agreement between models and GRACE underscores the challenges remaining for global models to capture human or climate impacts on global water storage trends. … Increasing TWSA [total water storage anomalies] trends are found primarily in nonirrigated basins, mostly in humid regions, and may be related to climate variations. Models also underestimate median GRACE increasing trends (1.6–2.1 km3/y) by up to a factor of ∼8 in GHWRMs [global hydrological and water resource models] (0.3–0.6 km3/y). Underestimation of GRACE-derived TWSA increasing trends is much greater for LSMs [global land surface models], with four of the five LSMs [global land surface models] yielding opposite trends (i.e., median negative rather than positive trends).”
“Increasing GRACE trends are also found in surrounding basins, with most models yielding negative trends. Models greatly underestimate the increasing trends in Africa, particularly in southern Africa. .. TWSA trends from GRACE in northeast Asia are generally increasing, but many models show decreasing trends, particularly in the Yenisei.  … Subtracting the modeled human intervention contribution from the total land water storage contribution from GRACE results in an estimated climate-driven contribution of −0.44 to −0.38 mm/y. Therefore, the magnitude of the estimated climate contribution to GMSL [global mean sea level] is twice that of the human contribution and opposite in sign. While many previous studies emphasize the large contribution of human intervention to GMSL [global mean sea level], it has been more than counteracted by climate-driven storage increase on land over the past decade.”
“GRACE-positive TWSA trends (71 km3/y) contribute negatively (−0.2 mm/y) to GMSL, slowing the rate of rise of GMSL, whereas models contribute positively to GMSL, increasing the rate of rise of GMSL“

Share this...FacebookTwitter "
"
Share this...FacebookTwitterI lived in Arizona for a few years and I remember flash floods occurring regularly during the rainy summer season. Good to see things are getting less extreme there. Thanks, global warming! -PG
===================================
Researchers surprised: extreme rainfall in Arizona has decreased over the past 50 years despite climate warming
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated and edited by P Gosselin)
Climate change leads to more extreme rainfall events and worse flooding. That’s the common claim that gets made before one looks at the data.
Bit by bit, however, researchers are filling in the data gaps and finding one surprise after another. For example the University of Bristol put out a press release last October on the extreme rainfall trends in Arizona: In summary: Extreme rainfall has decreased over the past half century despite climate warming.
Moreover, total rainfall fortunately has risen. The alarmist general assumption of increased extreme rainfall events has failed to materialize. The press release follows:
Rainfall trends in arid regions buck commonly held climate change theories
The recent intense hurricanes in the Atlantic have sharply focused attention on how climate change can exacerbate extreme weather events. Scientific research suggests that global warming causes heavier rainfall because a hotter atmosphere can hold more moisture and warmer oceans evaporate faster feeding the atmosphere with more moisture. However, this link between climate warming and heavy rainfall has only been examined in particular regions where moisture availability is relatively high. Until now, no research has been undertaken that examines this relationship in dryland regions where short, sharp rainstorms are the dominant source of precipitation and where moisture availability on land is extremely limited.




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




To explore the links between climatic warming and rainfall in drylands, scientists from the Universities of Cardiff and Bristol analysed more than 50 years of detailed rainfall data (measured every minute) from a semi-arid drainage basin in south east Arizona exhibiting an upward trend in temperatures during that period. The analysis demonstrated a decline in rainfall intensity, despite an increase in total rainfall over the years. Interestingly, the study shows that there is a long-term decline in heavy rainfall events (greater than 25 mm/h) and an associated increase in the number of smaller storms each delivering less rainfall. This result is contrary to commonly held assumptions about rainfall trends under climate change.
Lead author, Dr Michael Singer from School of Earth and Ocean Sciences at Cardiff University, said: “In drylands, convective (or short, intense) rainfall controls water supply, flood risk and soil moisture but we have had little information on how atmospheric warming will affect the characteristics of such rainstorms, given the limited moisture in these areas.” Co-author, Dr Katerina Michaelides, from the School of Geographical Sciences and Cabot Institute at the University of Bristol, said: “Our findings are consistent with previous research in the Colorado Basin which has revealed a decline in runoff in the upper part of the Basin. “Our work demonstrates that there is a more regional decline in water resources in this dryland region, which may be found in other dryland regions of the world.”
Since trends in convective rainfall are not easily detected in daily rainfall records, or well-simulated by global or regional climate models, the researchers created a new tool to assess the effects of climate change on rainfall patterns and trends in dryland areas. Their new model, STORM, simulates individual rainstorms and their expression over a river basin, and it can represent different classes of climate change over many decades. Drs Singer and Michaelides employ STORM to show that the historical rainfall trends likely resulted in less runoff from this dryland basin, an effect they expect to have occurred at many similar basins in the region. Dr Singer added: “We see this model as a useful tool to simulate climate change in regions and cases where traditional models and methods don’t capture the trends.”
Paper: ‘Deciphering the expression of climate change within the Lower Colorado River basin by stochastic simulation of convective rainfall’ by M. Bliss Singer and K. Michaelides in Environmental Research Letters.”
In May 2015 extensive flooding occurred in Texas and Oklahoma due to heavy rainfall. This was not caused by a hurricane, but rather by an El Nino, which indeed leads to extreme rainfall events, according to a study by Wang et al. 2015.
In another study by Wang et al. 2014, researchers found a flooding pattern in the region of the Missouri River which happened to follow a Pacific Ocean cycle. Knowledge of this link now allows better forecasts to be made and preventive efforts to be taken. Washington University in St. Louis reminded that not everything can be attributed in knee-jerk fashion to climate change. Extreme rain at the end of 2015 in Missouri led to terrible flooding. Part of the blame here was assigned to the changes in building in flood-prone areas of the river which led to an obstruction of the outflow.
In another study the University of Colorado in Denver was able to show that also the state of Colorado is poorly prepared for flooding. Important bridges and infrastructure urgently need to be upgraded. Damage that occurred in a flood in 2013 would have been much less had the structures been strengthened and better taken care of.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterSchneefan at German weather and climate analysis site wobleibtdieerderwaermung.de here brings us the latest on atmospheric temperatures.
First we note that the middle troposphere (7,500 meters) as measured by NASA has seen recently a sharp cooling off since the start of April:

The chart shows the daily mean temperature at about 7,500 meters altitude, i.e. middle troposphere (400 mb/hPa). Here we see that temperatures have dived (pink curve) and reached a near 17-year low for this time of the year. Source: https://ghrc.nsstc.nasa.gov/amsutemps/
An enlargement shows a comparison to last year, last updated April 9, 2018.

Temperature at 7,500 m altitude have dived steeply since early April. Source: https://ghrc.nsstc.nasa.gov/amsutemps/
Near surface temperatures sharply down
Also the global 2m surface temperature is showing a strong downward trend:

The plotted data have already been adjusted (falsified?) with the NASA/GISS factor, and so may actually be even lower. Source: http://www.karstenhaustein.com/climate.php
Should the cold temperatures persist, April, 2018, could fall below the zero anomaly for the first time since 2012, foremost with the UAH  satellite data. The following UAH chart shows lower tropospheric temperatures (1500) continuing their decline after the warm peak caused by the natural El Niño phenomenon:

Source: UAH Global Temperature Update for March, 2018: +0.24 deg. C


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In March, 2018, lower tropospheric temperatures (1500m) over the oceans (71% of the earth’s surface) also saw a further drop:

Source: climate4you.
More cooling over the coming months
The following chart shows the El Niño Southern Oscillation (ENSO) 3.4 plot, i.e. the ocean surface temperature anomaly of the western equatorial Pacific region, since July 2016.

Source: climexp.knmi.nl/start.cgi
Much of the last 2 years has been in the globe-cooling La Niña phase (blue). And as satellite instrument temperatures tend to lag the El Niño temperature anomalies by some 4 months, further surface cooling is expected to show up in the satellite data over the coming months.
ENSO indicates more cooling ahead
The Southern Oscillation Index (SOI) is an indicator for the development of the easterly trade winds at the equatorial Pacific and thus tells us what’s ahead for the ENSO. Recall that the ENSO has a powerful impact on global surface temperatures. SOI values over +7.0 indicates La Niña conditions 2 months ahead, while an SOI under -7.0 points El Niño conditions.
Currently the following chart shows the SOI is at +13.7, which means the globe-cooling La Niña should continue on two months from now, and thus means cooler satellite measurements showing up 6 months later.

The Southern Oscillation Index (SOI) is currently at +13,7, thus pointing to La Niña conditions 2 months from now. Source: www.bom.gov.au/climate/enso/
Recently some scientists have postulated that the ENSO is impacted by solar activity, which currently is at a low (earth-cooling) level. The next solar cycle is expected to be a weak one, thus boding more cooling and tough winters ahead.
It’s got nothing to do with trace gas CO2.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhile global warming alarmists continue to fantasize crude oil use getting drastically reduced already starting next year, OPEC sees it totally differently. German online. center-left weekly Die Zeit reports “OPEC anticipates growing oil demand until 2040.”
This poses a huge dilemma for the activists and alarmists who are urgently pressing to transform society –based on the fear and belief that the globe will warm rapidly if we don’t act now.
The other fear is that rising oil consumption over the next 25 more years accompanied stalling global temperatures will forever expose climate science as a ruse.
Still decades away from peak oil consumption
Die Zeit writes that OPEC is sure that the planet is still years away from peak oil demand, and the reason is because cars will continue to be mostly powered by petroleum even beyond 2040. Obviously a number of leading energy experts believe electric cars will remain a pipe dream for quite some time.

Chart: OPEC
Oil consumption will climb almost 20%
Firstly OPEC sees the world population growing from 7.6 billion today to 9.2 billion by 2040 and global GDP growing by a whopping 126%. That’s all going to require lots of reliable and efficient energy. The good news is that overall energy efficiency will increase, as only 96% more energy will be needed to power the 126% GDP boost.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Most of the energy increase will come from India and China. Moreover, the global average standard of living will also grow strongly as the per capita energy use will be much higher. OPEC projects that much of the added energy demand will be supplied by natural gas (see chart above). Part of the increased demand will be met by coal and oil.
OPEC also foresees continued domination by the internal combustion engine for passenger cars, even in 2040:

Chart: OPEC
Electric mobility still decades away
OPEC also projects there will be more than 2 billion automobiles on the world’s roads by 2040, almost double today’s number. Over 80% of these will continue to be powered by internal combustion engines. The electric vehicle age appears to be something for the late 21st century. Visions of a near zero carbon society within the next 30 years are more fantasy than reality.
Not surprisingly, most of the increased energy demand will come from Asia and Africa. The richer, developed OECD countries will see little growth in energy demand.
The OPEC video summarizes by saying that it is “committed to reducing energy poverty“. That target of course would make a huge contribution to alleviating the overall misery that still plagues many poor countries. Oil, coal and gas will continue to play the leading role.
Of course, jet-setting climate activists and alarmists would like to deny poor countries access to affordable and reliable energy.
Good luck with that.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterFirst, at Twitter here Swiss high-profile meteorologist Jörg Kachelmann presented a video on how he thinks German public television failed to adequately warn the public before North Sea storm Xavier barreled through northern Germany on October 5.

Swiss meteorologist Jörg Kachelmann says he believes German media (image above) inadequately informed the public of the danger of storm ‘Xavier’. Seven Germans lost their lives to a storm that was “nothing out of the ordinary”. Image: ZDF German Public Television.
Media warnings of storm were inadequate
As a result 7 people were killed by falling limbs and trees. Some of these deaths could have been prevented had the media issued stronger warnings of the storm’s danger before it hit, believes Kachelmann, who in his twitter video pointed out that Xavier was not an unusual storm by any means and that there should not have been so many deaths.
Kachelmann said:
Why it happened has a bit to do with the media and what they could do. That’s the big difference to the USA when you look at the reporting there concerning hurricanes or even tornadoes, where the main reporting does not come after everything has happened — after all the deaths, injuries and everything laying around — but the main reporting is before where people are helped and told what to do and accompanies the people during this time with reporters out there in the storm with microphones, which here is ridiculed. But it helps.”
Kachelmann says the media here could have done this too to make the danger clear to people: “They could have done this here too. The storm did not just come as a surprise.”
The media hype comes afterwards, when it’s too late
As to why the German press did so little to warn the people of the storm, Kachelmann can only speculate: Maybe they were just “infinitely lazy“. Kachelmann thinks that had the media given stronger warnings, some of the lives would have been spared.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The average observer could say that German public media seems to have a habit of underrating storms before they hit, and then exaggerating them after they leave. For example, on Monday earlier this week – after Ophelia had already hit Ireland – North German NDR radio presented Ophelia as something that no one in Ireland “could recall ever happening“.
Certainly a bit of hyperbole here.
Here one could successfully argue that this is an exaggeration and that the German media are simply just too lazy to look back into the archives, or just aren’t interested in presenting accurate reports. Joe Bastardi at Weatherbell on Tuesday highlighted Ophelia in his Daily Update and showed that Ophelia “was not as bad as Debbie in 1961“.

Track of Hurricane Debbie in 1961, which was worse than Ophelia. Source: cropped from Weatherbell Saturday Summary.
Maybe the pre-storm downplaying and post-storm hyping is unwittingly intended by the German media. By neglecting to warn people beforehand, they get to blare out bigger, more spectacular headlines of death and destruction after the storm passes.
Of course no one seriously thinks it’s intentional on the German media’s part, yet the bottom line is that the German public is getting a distorted reporting both before and after the storm. They deserve far better for their exorbitant mandatory public television and radio fees.
Ophelia not unprecedented
And at his Saturday Summary of October 14, the veteran meteorologist blasted the hurricane hysteria coming from the usual US activists. He shows how Hurricane Faith in 1966 remained a hurricane far north of Ireland, and didn’t peter out until it reached the North Pole! There’s nothing unusual about Ophelia. Bastardi added:
I feel very strongly about these people who are using these storms […] for their agenda, and so what I’m doing here is that I’m letting you know that I’m showing you beforehand that there is visible evidence that this has happened before.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe online German business daily Handelsblatt here writes that European wind energy company Siemens Gamesa will eliminate 6000 jobs.
That means the German-Spanish company will shed more than a fifth of it 26,000 workers. This is the latest bad news slamming the green energy industry in Germany and Europe. Over the years Germany has seen almost every major solar panel and equipment manufacturer become insolvent. Spain too has been hit hard by renewable energy insolvencies.
Once ballyhooed as the sector for the future, German solar and and wind energy industry has taken huge hits. The country’s last remaining major solar manufacturer, Bonn-based Solarworld, earlier this year announced it would file for bankruptcy. Solarworld’s demise was the last of a spectacular series of solar manufacturer bankruptcies that swept across Germany over the past years, with names like Solon, Solar Millenium and Q-Cells going under.
Now the bloodbath is expanding to the wind industry, a branch of green energy that looked far more feasible in Germany than solar energy did.
The announcement by Siemens-Gamesa coincides with the COP 23 Bonn climate conference now taking place, which is calling for more wind and sun energy at a time the industry is collapsing at full speed in Germany.
According to Siemens-Gamesa Board Chairman Markus Tacke: “Our business result is still not at the level where we would like to see it.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Last year Spanish Gamesa and German Siemens combined their wind power operations to form one of the world’s largest producers of wind turbines.
Handelsblatt writes the Siemens daughter company was reacting to “changing market conditions” and that the move will impact 6 countries.
The company also expects to see its revenue for the coming fiscal year fall to 9 billion euros from almost 11 billion.
The Handelsblatt also reports that “no improvement is foreseen in the new fiscal year“.
Other links in English:
– www.expatica.com/de/news/country-news/Germany-layoffs
– http://uk.businessinsider.com/r-siemens-gamesa-to-6000-jobs=T
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterDr. Ryan Maue here reports at Twitter that although the Atlantic hurricane season “is going gangbusters“, the Pacific is in fact seeing “one of quietest Typhoon seasons on record“.
Last month in the media, amid the aftermath of Harvey and Irma, the public heard a long stream of hysterical reports claiming that the tropical storms were sure sure signs of man-made climate change.
Yet, according to Dr. Maue, the globe has seen significantly below average cyclone activity, despite the near record hurricane activity observed in the Atlantic this season.


Chart above shows cyclone activity globally being well below normal in a year awash with media hurricane hysteria. Status: October 10, 2017. Source: http://wx.graphics/tropical/

Though the North Atlantic is running at 240% of normal, the entire northern hemisphere is near normal at 98%. Astonishing is the fact that Southern Hemisphere cyclonic activity is near record-breaking low of 47%.
Globally the figure is mere 86%. This is an embarrassment and highly baffling to the media and climate alarmists, who have recently been giving false impressions of “unprecedented” storm activity this year.
“WHERE have all the cyclones gone?”
Even the Australian news site www.news.com.au here asks: “WHERE have all the cyclones gone?
Scientists are puzzled as to how global warming is having the opposite effect on storms from what is often claimed.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Dr. Maue’s following chart shows that the overall hurricane trend has been downward over the past quarter century:

Figure:  Global Hurricane Frequency (all & major) — 12-month running sums. The top time series is the number of global tropical cyclones that reached at least hurricane-force (maximum lifetime wind speed exceeds 64-knots). The bottom time series is the number of global tropical cyclones that reached major hurricane strength (96-knots+). Adapted from Maue (2011) GRL. Source: http://wx.graphics/tropical/.
Record-low Southern Hemisphere
In his last chart chart at the above website, shown is how the southern hemisphere has been trending down to a near record low.
In fact the abstract of a recent peer-reviewed paper appearing at the Geophysical Research Letters, confirms the trends, writing (emphasis added):
In the pentad since 2006, Northern Hemisphere and global tropical cyclone ACE has decreased dramatically to the lowest levels since the late 1970s. Additionally, the frequency of tropical cyclones has reached a historical low. Here evidence is presented demonstrating that considerable variability in tropical cyclone ACE is associated with the evolution of the character of observed large-scale climate mechanisms including the El Nino Southern Oscillation and Pacific Decadal Oscillation.”
Reckless media neglect
This is information and data that alarmist climate scientists like Dr. Michael E. Mann or media such as the AP’s Seth Borenstein apparently recklessly neglected to examine before making hysterical statements to the public.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOutgoing director of the Potsdam Institute for Climate Impact Research (PIK) believes mankind, through its activities, is headed for a “mass extinction” event and an anthropogenic calamity comparable to a geological scale asteroid hit.

Outgoing Potsdam Institute director Hans-Joachim “John” Schellnhuber tells German national daily that mankind has run out of time and faces “mass extinction” and calamity of geological proportions. Photo: PNAS. 
In an online article titled Climate Change Like An Asteroid Strike appearing in Germany’s national daily Süddeutsche Zeitung (SZ), journalist Alex Rühle reports on the outgoing director of Germany’s alarmist Potsdam Institute for Climate Impact Research (PIK), Prof. Hans-Joachim “John” Schellnhuber.
Prof. Schellnhuber, widely known in Germany as the Climate Pope, is considered in Europe as the leading climate science authority and the architect of the Master Plan for transforming global society – dubbed The Great Transformation – which aims to make global society climate compatible by applying draconian, surrealistic measures. Moreover the plan calls for all of it to happen in just a matter of a couple of decades!
A number of critics have characterized the whole idea as detached from economic reality and dystopian.
Risks mounting “by the hour”
Schellnhuber is also the father of the “2°C climate target”, a warming he claims that the world must never exceed, lest it’ll tip hopelessly into a state of rapid, irreversible climatic collapse.
The SZ article reports how the outgoing Schellnhuber believes the planet is in fact approaching the climatic catastrophe at “a crazy speed” and that the risks “are mounting quasi by the hour”.
The alarmist Potsdam Institute professor has been known for a number of shrill comments made in the past, but in this most recent SZ article, Schellnhuber’s shrillness arguably reaches a whole new level that shoots beyond the realms of reason.
Rapid, epic disaster of geologic dimensions
Now that Schellnhuber is stepping down as director of the Potsdam Institute after 25 years as its director, he reflects back, telling the SZ how he feels about the overall public “disinterest with regards to the consequences of climate change” that has taken hold globally.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In Schellnhuber’s view, world leaders are moving far too sluggishly to avert what he sees is a climatic disaster of epic geological proportions, and compares it to earlier calamities which the earth witnessed tens of millions of years ago.
100 times faster than Permian–Triassic extinction event
The Potsdam director tells the SZ that the globe’s temperature today is rising at a rate of 5°C per century! – or “100 times faster than during the time of the Permian–Triassic extinction event” which occurred some 250 million years ago and is believed to have wiped out 90% of all land life on the planet at the time.
According to Rühle, Schellnhuber compares today’s climate change to the “largest mass extinctions in the history of the earth.”
Comparable to the Cretaceous–Paleogene extinction event!
If one mass extinction event was not enough to illustrate what in Schellnhuber’s mind is climatically in store for humanity, the former PIK director piles on with yet another geological catastrophe to describe the course on which he claims man has put the planet on. He tells the SZ:
What man is doing today is similar to the asteroid strike known as the Cretaceous–Paleogene extinction event.”
According to the SZ, Schellnhuber says, “We’ve shirked our responsibility much too long”.
He then compares the situation to a sinking ship that urgently demands top priority:
If we don’t get climate change under control, and if we can no longer keep the ship afloat, then we won’t need to think about distribution of income, racism and good taste any longer.”
Embarrassing climate science even more
Luckily Schellnhuber’s dire claims are very much in dispute and considered extreme outliers, but do provide much fodder to the media. If anything is certain, it is that Schellnhuber is definitely not leaving his post a minute too soon. His most recent claims are an embarrassment to science.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAt Die kalte Sonne site here, geologist Dr. Sebastian Lüning and Prof. Fritz Vahrenholt comment on the controversy surrounding allegations of Big Oil “covering up” knowledge of the impacts their products could have on climate.
For example on April 16, 2018, renowned German weekly Spiegel reported on how “a confidential Shell study” showed the oil company “kept knowledge over climate change secret” and how “Shell knew already in detail 30 years ago about the greenhouse gas effect – and decided to keep silent.”
Now just a couple of weeks later, we find out that back then oil companies like Shell in fact didn’t know any more about climate change than other climate experts. The clandestine “Shell study” summarized:
–A thorough review of climate science literature, including acknowledgement of fossil fuels’ dominant role in driving greenhouse gas emissions. More importantly, Shell quantifies its own products’ contribution to global CO2 emissions.
–A detailed analysis of potential climate impacts, including rising sea levels, ocean acidification, and human migration.
–A discussion of the potential impacts to the fossil fuel sector itself, including legislation, changing public sentiment, and infrastructure vulnerabilities. Shell concludes that active engagement from the energy sector is desirable.
–A cautious response to uncertainty in scientific models, pressing for sincere consideration of solutions even in the face of existing debates.
–A warning to take policy action early, even before major changes are observed to the climate.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




At the time of the Shell study, the history of the earth’s climate over the past 2000 years had been poorly understood, and so Lüning and Vahrenholt find the cover-up accusations against Shell a bit strange. Overall the two German scientists say the whole story tells us just how weak the accusations of the activist side really are.
Natural factors have been proven
Some three decades later, the two German scientists note that far more is known today: for example the important roles played by natural ocean cycles and the global phenomenon of the Medieval Ice Age, which now is acknowledged and make the climate models look obsolete. Moreover, CO2 climate sensitivity has been dialed back with each passing year.
Lüning and Vahrenholt add:
Over the coming months and years the IPCC will have to admit to some changes in its understanding of the climate.”
The real scandal is the cover-up of natural factors
But the real intent of the climate activists turning to litigation is about generating publicity, as plainly admitted by German site Klimafakten on 16 April 2018:
Going to court for more climate protection – and for more transparency
Everywhere across the world activists are fighting against climate change by using litigation. Experts already count about one thousands court proceedings in 24 countries. For the litigants it’s not only about getting a ruling, but about publicity: The suits are  a means for strategic communication.”
The real deal, say Lüning and Vahrenholt, is that natural climate factors have been known as real drivers for over a decade, and activists, scientists and the IPCC continue to cover them up.
In fact, Lüning and Vahrenholt say that this is the real story that needs to be the subject of litigation. The real scandal is
How activists and the IPCC covered up knowledge of natural climate change.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitter“We now seriously need a Schellnhuber timeout. […] We do hope the new PIK leadership will correct the extreme direction the institute is currently on and rapidly puts an end to the flow of climate-alarmist press releases.“
At their Die kalte Sonne site here, Dr. Sebastian Lüning and Prof. Fritz Vahrenholt comment on Prof. Hans-Joachim Schellnhuber’s stepping down as director of the alarmist Potsdam Institute for Climate Impact research (PIK).

Prof. Hans-Joachim Schellnhuber stepping down as head of the Potsdam Institute (PIK). Photo: PIK.
Schellnhuber is often worshipped by the fringe-element climate alarmists as a sort of Climate Pope, whose every uttered word is to be regarded as infallible.  Now he may be paying the price for his entrenched, radical positions on climate change.
========================================
From Die kalte Sonne here, by Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(Translated by P Gosselin)
Hans-Joachim Schellnhuber is stepping down later this year in autumn and consequently will relinquish his position as director at the Potsdam PIK Climate Institute. The successors have already been named. Over the past years Schellnhuber had increasingly become a burden for the institute. Parts of the German political spectrum had already requested his removal from the “Scientific Advisory Council for Environmental Change” (WBGU) for representing a direction leading to a green dictatorship. In the end it was likely a direct decision by the Chancellor that saved him. Recently there had been a mysterious spree publications by Schellnhuber appearing in the journal of the National Academy of Science. The suspected secret is that he was allowed to choose his peer reviewers himself as a member of the society.
Parts of the press also reported what many already suspected. Spiegel on Hans-Joachim Schellnhuber: “One is getting the impression that he has become more activist than physicist”. Here his role as a ghostwriter for the Pope fits very well as he basically put all the words of his choice into the Pope’s mouth. He almost totally ignored all the uncertainties climate science is afflicted by. His aim: The unconditional destruction of the fossil fuel industry. And as a direct advisor to the chancellor, he pushed this message to the highest levels. History over the coming years and decades will be decided by Schellnhuber’s role in the climate debate and the overly hasty rush into renewable energies. We now seriously need a Schellnhuber timeout. We do hope the new PIK leadership will correct the extreme direction the institute is currently on and rapidly puts an end to the flow of climate-alarmist press releases. What really is now needed is a balanced and rational presentation of the results, without the constant pressure of having to do missionary work.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Russian Arctic in 1920-1940 was warmer than today
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P. Gosselin)
The topic today is the temperature trend in the Arctic. Of special interest are the hard facts. At Climate4You we find the satellite measured temperature development (UAH) of the Arctic:

 Figure 1: Temperature chart of the Arctic over the past 40 years (satellite measurement). Data: UAH. Chart: Climate4You
Arctic temperatures today “similar” to 1980
We do see a warming over the past 4 decades. Since the El Nino-induced peak of 2016, the temperature has fallen gradually. The coldest temperatures were recorded at the end of the 1980s and early 1990s.
At around 1980 similar temperatures as those of today were measured. Unfortunately there is no satellite data for the time before 1979, and so not even a full 60-year ocean cycle is covered, and thus this makes it really difficult to assign warming to man or to natural causes over the recent decades.
Russian Arctic just as warm in the 1930s as today!
But of course there were weather stations before 1979, and these showed a warming phase in the Arctic already in the 1930s and 1940s, a time when it was just as warm as it is today. Example: Opel et al. 2009 reconstructed the temperature history in the Russian Arctic for the last 100 years using ice cores. The warm maximum occurred in the 1930s and not today:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




115 year ice-core data from Akademii Nauk ice cap, Severnaya Zemlya: high-resolution record of Eurasian Arctic climate change
From 1999 to 2001 a 724 m deep ice core was drilled on Akademii Nauk ice cap, Severnaya Zemlya, to gain high-resolution proxy data from the central Russian Arctic. Despite strong summertime meltwater percolation, this ice core provides valuable information on the regional climate and environmental history. We present data of stable water isotopes, melt-layer content and major ions from the uppermost 57 m of this core, covering the period 1883–1998. Dating was achieved by counting seasonal isotopic cycles and using reference horizons. Multi-annual δ18O values reflect Eurasian sub-Arctic and Arctic surface air-temperature variations. We found strong correlations to instrumental temperature data from some stations (e.g. r = 0.62 for Vardø, northern Norway). The δ18O values show pronounced 20th-century temperature changes, with a strong rise about 1920 and the absolute temperature maximum in the 1930s. A recent decrease in the deuterium-excess time series indicates an increasing role of the Kara Sea as a regional moisture source. From the multi-annual ion variations we deduced decreasing sea-salt aerosol trends in the 20th century, as reflected by sodium and chloride, whereas sulphate and nitrate are strongly affected by anthropogenic pollution.”

Figure 2: Temperature chart Severnaya Zemlya (Russian Arctic) over the past 130 years. Upper peaks = warm. Source: Opel et al. 2009
A part of the warming by the way, has to do with measures that keep the air clean in Europe. The anthropogenic sulfate particle kept the Arctic cool for many years, so reports that University of Stockholm (via Science Daily). Should we get back to being dirty for reasons of climate change?

European clean air policies unmask Arctic warming by greenhouse gases
[…] The drastic cut in sulfate particle emissions in Europe partly explains the amplified Arctic warming since the 1980s, shows a new study published in Nature Geoscience. The team, which consists of scientists from Stockholm University and the Norwegian Meteorological Institute, say that their surprising finding highlights an even more urgent need for reducing greenhouse gas emissions to mitigate Arctic climate change. Human activities, such as industrial production, transport, power generation, and wood burning emit large amounts of tiny pollutant particles containing, for example, soot and sulfate, into the atmosphere. High airborne amounts of these particles, also known as aerosol particles, cause about 400,000 premature deaths every year in Europe and can be transported over long distances. Aerosol particles have different sizes, as well as chemical and physical properties, all of which determine their climate effects.

“Soot particles absorb solar radiation and warm the climate, in a similar way as greenhouse gases, such as carbon dioxide, do. Sulfate particles, on the other hand, reflect solar radiation and act as seeds for cloud droplet formation, cooling the climate as a result,” says Juan Acosta Navarro, PhD student at the Department of Environmental Science and Analytical Chemistry (ACES) and the Bolin Center for Climate Research, Stockholm University, and co-author of the study. He continues: “The overall effect of aerosol particles of human origin on climate has been a cooling one during the last century, which has partially masked the warming caused by the increase in greenhouse gas emissions.” […]
J. C. Acosta Navarro, V. Varma, I. Riipinen, Ø. Seland, A. Kirkevåg, H. Struthers, T. Iversen, H.-C. Hansson, A. M. L. Ekman. Amplification of Arctic warming by past air pollution reductions in Europe. Nature Geoscience, 2016; DOI: 10.1038/ngeo2673“

But also later alterations to the measurement data make the Arctic look warmer today than it actually is (see here and here). A nice summary of climate change in the Arctic can be found at Judith Curry’s site.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterUsing a comparison, Japanese skeptic blogger Kirye at KiryeNet drives home how “the real Arctic sea ice volume is much higher than in 2008.”

Source of images: DMI: http://ocean.dmi.dk
Using images and data from the Danish Meteorological Institute (DMI), Kirye put together and posted a comparator showing the immense March/early April sea ice volume increase the Arctic has seen since 2008. It totally defies the panicky claims of a “melting” Arctic, she tweeted.
You can see the animation comparator Kirye put together in action here at Twitter.

Arctic sea ice volume surges a whopping 3000 cubic kilometers since March 1st. Chart: DMI.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Kirye comments that although we have not once seen alarmists’ climate predictions come true, they continue to threaten us with sea ice doom.
Amid rapidly growing Arctic sea ice volume, they continue to cling to the claim it’s melting. That’s irrational.
Media hyperbole
Yesterday Anthony Watts posted here on the Arctic, remarking that the media claims of earlier this year of an unprecedented Arctic warmth had much more to do with hyperbole than with reality. Lately the Arctic has been a generous source of fake news from the global mainstream media giants, all claiming something that is not real, or making something that’s happened many times before look “unprecedented”.
Warm 12°C temperature spikes more than 70 times!
Back in January, 2016, I wrote here how “the Washington Post screamed bloody murder that the North Pole was in meltdown as temperatures at that singular location rose some “50 degrees above normal”, making it sound like this event had been an unprecedented phenomenon.
For that post I had gone back and examined DMI data Arctic temperatures above 80°N latitude going back some 58 years. Here’s what I found:
And examining all the years since 1958 we see that a temperature spike of some 12°K or more in a matter of a few days (during the November to March deep winter period) occurred more than 70 times! And over 100 times for spikes of 10°K and more.”
Once again, hat-tip: KiyreNet.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOver the recent days we’ve been hearing about record snowfall in Montana, record low temperatures in Minnesota and Ontario, New York City “blowing away” a 103-year old record, vicious cold gripping  Lebanon, PA. Moreover, Arctic sea ice and Greenland ice have surprised climatologists with a comeback over the past year.
UPDATE: And now the UK braces for 3 weeks of unusual cold.
What is more, the NOAA has just officially announced the return of the La Niña, after earlier this year an El Niño had been forecast instead.
“Gangbusters cold” in the works
And lately we’ve been hearing a number of meteorologists warning of a harsh coming winter for both Europe and USA.
At his Friday Daily Update, veteran meteorologist Joe Bastardi warns of a “fierce cold” being on the table for this winter for the United States. Bastardi says he does not believe the US climate models at all, and instead could even be as harsh of the notoriously cold 2013 winter.

Bastardi believes the month of December will in fact turn out to be the opposite of what was projected by the US weather models, which foresaw a warm December. See his latest Saturday Summary at Weatherbell.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In his Friday Daily Update Bastardi thinks the cold will be “gangbusters” and that there is a real chance for a “December to remember”. All in all, the Pennsylvania State University meteorologist sees an excellent ski season in the works for the USA.
-40°C for Christmas In Central Europe?
Over in Europe, there have been a growing number of warnings of a “winter of the century“. For example the German nachrichten.de here reports Christmas temperatures of -40°C!
Naturally such forecasts need to be viewed with great skepticism as they are highly speculative. Long-term prediction methods may indicate which way a winter is tending, but I wouldn’t believe any forecast 6 to 8 weeks out.
Nachrichten.de cites information from the Augsburg Meteorological Institute and the Hamburg Weather Warning station. The Federal Office for Weather Observations advises citizens “to prepare for an ice cold Christmas.”“Snowmageddon”?
The express.co.uk warns of a “SNOWMAGEDDON”, thanks to a La Niña bringing a “Big Freeze”. The express.so.uk  writes that “winter weather 2017 is set to be the harshest for years“.
For the winter of 2017/2018 the PDO will bring a winter of deadly blizzards and killer freezes as a perfect storm of catastrophic weather systems gather. Analytical meteorologist Tyler Sotock suggested America was facing Snowmaggedon. And spokesman for another YouTube weather channel Hurricane and Winter Tracker warned of chaos.”
While wild speculation swirls, one thing seems certain: just as Joe Bastardi shows at his Saturday Summary, the US forecasts of a warm November/December period across Canada and the US East are looking more flawed than ever.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterPublic opinion of wind energy in Germany, once unanimously high, has eroded considerably over the past years as more people begin to realize that the country’s once idyllic countryside is turning into a blighted industrial landscape.
The earlier visions of environmental purity are instead turning out to be illusions by con-artists. The reality is an environmental hell.
In an opinion piece at German flagship daily Die Welt, Wolfgang Büscher wrote:
Wind energy is destroying the country more than any other industry.” 
Blighted landscape…everything “blinking and rotating”
And the irony could not be more glaring. German environmentalists used to be devoted to all things that protected forests and rural countryside against the ravages of industrialization. But now, Büscher writes, “It’s the same activists who are blandishing the blighting of the landscape.”
Büscher describes the views of wind parks in Bavaria as “massively appalling”. While German industry once only ruined local areas of the country, such as the Ruhr industrial region, Büscher adds:
The wind industry is not satisfied with that. It wishes to subject the entire country to its moral galvanized industry. Whether it’s Magdeburg or Warburg Saxony Anhalt regions, whether it’s Holstein or the lower Harz region – everything is rotating and blinking, the further north you go, the worse it is.”
Büscher forgot to mention “whooshing” and “shredding”.
Germany’s march into environmental insanity
Yet, in the eyes of the wind industry, Büscher laments, “The wind industrialization of Germany is not only without alternative, it is an aesthetic benefit. The industry truly believes the entire country needs to by planted with turbines from border to border.”
As incredible as it may be that a country managed to get its citizens to march into the murderous folly of Nazism some 85 years ago, a similar phenomenon is happening today on the environmental front: there’s now the mad march into environmental murder. The collective German conscience still truly believes it’s all going to rescue the planet from a climate calamity which a group of (false) prophets foresee arriving in the year 2100. Environmental purity awaits!
Back on the eerie path of self-destruction


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Of course wind industrialization cannot be compared to Nazism on the scales of murder and destruction, but the path and development stages of the two insanities are the eerily similar. Both proceeded as follows: 1) visions and promises of purification, 2) the mad, blind rush into the project 3) critics silenced, 4) signs of mounting failure ignored, 5) denial, retreat to the bunkers and 6) in evitable self-destruction. In both cases it’s all brought on by intoxicated leaders, one-sided media apparatus, crony industries, dogmatist institutions and unscrupulous banks.
Once madness goes collective, it becomes very difficult to stop.
When Germany gets an obsession in its head, the only thing that is left to stop it is the act of letting it play out and until it destroys itself. We may soon be witnessing the Rise and Fall of The Environmental Reich. Currently we find ourselves somewhere between phases 4 and 5.
Fortunately there are shimmers of hope that leading politicians are beginning to understand, as the newly formed Merkel-led government seems to be in no hurry to keep promoting big wind at any cost.
Former federal minister: “high price to pay”
Not only is the environmental price mentioned by Büscher excruciatingly high, but so is the financial price of the Energiewende, this according to former German Transportation Minister, Peter Ramsauer, now Chairman of the Committee for Economic Cooperation and Development.
In a recent interview with the Passauer Neuen Presse (PNP), Ramsauer slammed Germany’s rapid march into the Energiewende, telling the Bavarian online daily: “We have a high price to pay for the Energiewende.”
“Object lesson to other countries”
Ramsauer warned against the hasty shutdown of half of the country’s nuclear power plants in the wake of the Fukushima disaster back in 2011, “but no one wanted to listen”.
The PNP writes that it was “a fundamental mistake to believe that it would be possible to adequately replace the nuclear power”. Ramsauer told the PNP:
Germany is paying a high price for it and offers an object lesson to other countries.”
The PNP summarizes: “There’s no going back. The deadline for shutting down the remaining nuclear reactors is 2022. Ramsauer says that Germany will have to get used to high electricity prices and dependency on Russian gas. The folly will then be complete.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA few days ago I posted on how brutal cold and snow were gripping the northern hemisphere from every direction. Prominently featured was the western Pacific country of Japan.
“Amazingly cold”
Not only had it been cold and brutal in January, but the story was the same already back in mid December as well, as Japanese skeptic blogger Kirye here tweeted:

Image cropped from Twitter
On December 10th, the Japanese blogger tweeted here:
This year early December in Japan amazingly cold throughout the country. In particular, the daily mean temperature in Sapporo city has been well below 1981-2010 average.”
Coldest October in 46 years
Already back in October Kirye had been tweeting of Japan getting started on the very cold side as she noted how Tokyo had seen its coldest October in almost 50 years:
October 2017 in Tokyo the mean monthly temperature was 16.8℃, the coldest October since 1971.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In fact the cold in Japan started even well before October, 2017. Already in September Japan had had a colder than normal month when Kirye informed me that “Japan’s temperature anomaly for September, 2017, was -0.22C,” and then added she expected the coming winter to be “very interesting”.
And interesting it’s been.
Unusual cold and snow persisting in February 
And now that we find ourselves well into February, there are still no signs of the brutal winter conditions letting up in Japan, let alone of the famous cherry blossoms making their debut any time soon.
According to the English language Asahi Shimbun here on February 8, seven people had been killed and public roads and services had been crippled “as record snowfall kept traffic at a standstill across much of the Hokuriku region of northwestern Japan.”
The Asahi Shimbun added:
Authorities said that 1,400 or vehicles got stuck from Feb. 6, creating a line that stretched about 20 kilometers.”
At her blogsite, Kirye reports here that so far this year 59 stations (out of 928 stations) in Japan marked an all-time temperature low in 2018. In Ohtake in Hokkaido Prefecture, for example, the mercury plummeted to – 24.9°C.
The Mainichi here reported of “cold air” and “heavy snow” along the Sea of Japan coast and added: “The city of Fukui in the region had over 130 centimeters of snow for the first time in 37 years.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterEngineering Prof. Questions Temperature
Record, Models, CO2 Climate Sensitivity 

Photo California Baptist University

 Pontius, 2017  
Sustainable Infrastructure: 
Climate Changes and Carbon Dioxide 
Temperatures Record ‘Unreliable’, ‘Arbitrarily Adjusted’, And Of ‘Poor Data Quality’
Temperature measurement stations have been installed at various locations across the globe. The number of temperature monitoring stations is decreasing and many areas across the globe do not have any temperature monitoring stations. Consequently, average surface temperature is an unreliable metric for assessing global temperature trends.
Computer models are used to analyze data sets. In science and engineering (and this paper) the term “data” refers to actual physical measurement at a point in time and space. In some temperature data sets, however, computer simulated values have been added in or data may have been arbitrarily adjusted long after the physical measurement was taken. Such practices undermine the credibility of the data set.   Computer generated values are estimates, projections, or simulations and are of a different quality than physical measurements. Physical measurements represent a physical quantity whereas computer simulations represent numerical calculation.
The HADCRU, GISTEMP, and NOAA surface temperature archives rely on the same underlying input data and therefore are not independent data sets. Limitations of the GHCN affect all data sets. Sampling discontinuities, urbanization and land use changes have decreased the quality of GHCN data over time. Differences in data processing methods between research teams do not compensate for poor underlying data quality inherent in the GHCN data. A similar situation exists with historical Sea Surface Temperature (SST) data sets which are derived primarily from the International Comprehensive Ocean-Atmosphere Data Set (ICODADS).
Climate Models ‘Unreliable For Long-Term Climate Prediction’
Computer simulations involve mathematical models implemented on a computer imitating one or more natural processes. Models are based on general theories and fundamental principles, idealizations, approximations, mathematical concepts, metaphors, analogies, facts, and empirical data (Peterson, 2006, Meehl et al., 2012). Judgments and arbitrary choices must be made in model construction to apply fundamental laws to describe turbulent fluid flow. The large size and complexity of the atmosphere prohibit the direct application of general theory.
In general, ensemble model forecasts have been found unreliable for long-term climate prediction (Green and Armstrong, 2007, Mihailović et al., 2014).
“The forecasts in the [IPCC] Report were not the outcome of scientific procedures. In effect, they were the opinions of scientists transformed by mathematics and obscured by complex writing. Research on forecasting has shown that experts’ predictions are not useful in situations involving uncertainly and complexity. We have been unable to identify any scientific forecasts of global warming. Claims that the Earth will get warmer have no more credence than saying that it will get colder.”  –  Green and Armstrong, 2007.
“This analysis, set into context of the climate modeling, points out the fact that there exists set of domains where the environmental interface temperature cannot be calculated by the physics of currently designed climate models.” – Mihailović et al., 2014

Climate Sensitivity To Changing CO2 Concentrations
Global
The global atmospheric system is dynamic and is constantly in a state of change and adjustment. The sun is the primary climate change driving force.   
Using a Climate Sensitivity best estimate of 2°C, the increase in [global] temperature resulting from a doubling of atmospheric CO2 is estimated at approximately 0.009°C/yr which is insignificant compared to natural variability.
CO2 is a non-toxic trace gas constituting approximately 0.04% of the earth’s atmosphere. The global atmospheric concentration of CO2 increased from a pre-industrial value of about 280 ppmv to 379 ppmv in 2005 . The average CO2 concentration at the monitoring station at Mauna Loa, Hawaii for May 2017 is 409.65 ppmv.  A rising concentration of atmospheric CO2 will contribute to warming of the Earth’s atmosphere. The physics of CO2 in the atmosphere is very different than the physics of the heating effect occurring in a physical “greenhouse” for growing plants. The term “greenhouse effect” is commonly used to refer to the warming of the earth from “greenhouse” gases such as CO2 in the atmosphere. The term “greenhouse” is not used here to refer to the Earth’s warming to avoid equivocation.
Estimates of climate sensitivity differ widely suggesting that this characteristic of the climate system is not well-understood (Schwartz et al., 2014). 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




A simple model predicts that a doubling of the CO2 concentration in the atmosphere would result in a small increase of the Earth’s surface temperature, from approximately 0.[5] to < 0.7°C  (Kissin, 2015).
“[A] doubling the CO2 concentration in the Earth’s atmosphere would lead to an increase of the surface temperature by about +0.5 to 0.7 °C, hardly an effect calling for immediate drastic changes in the planet’s energy policies.” – Kissin, 2015
A best estimate of 2.0°C (Otto et al., 2013) is assumed here. If CO2 increases at the current rate of approximately 2 ppmv per year, a temperature increase of approximately 0.009°C/yr could be expected.
To date the impact of CO2 is assessed universally within a global reference frame. Although atmospheric CO2 has steadily increased the average satellite global temperatures have flattened since approximately 1995. 

 From such trends, it must be inferred that changes in global lower troposphere average temperature correspond to fundamental changes in the climate system beyond internal variability.
Riverside, California
The impact of future atmospheric CO2 warming on the Riverside locational reference frame must be estimated.  GCMs [climate models] could be applied to project future global temperatures and those projections could be downscaled to the Riverside area. However, such efforts would be potentially misleading because of the limitations of GCMs discussed previously.  Detailed assessments of the CO2 effect have been performed analyzing the Earth’s energy balance in the total atmosphere column and the reduction of the upward infrared radiation emission at the tropopause. The impact of CO2 on warming of the Earth is expressed in terms of “climate sensitivity,” which is the amount of warming that could be  expected as a result of doubling of the CO2 concentration.
Available temperature data from both the Riverside Fire Station No. 3 and the Riverside Municipal Airport demonstrate horizontal trends within a wide band of  variability. Historical evidence of a significant increase in surface temperatures due to increases in atmospheric CO2 is absent from these data.   [C]limate models are useful but limited in their representation of underlying physical processes.  Uncertainties and other limitations discussed previously render such models unreliable for long-term global temperatures or local climate change prediction.
Climate sensitivity may be applied to estimate the warming effect of CO2 on the locational reference frame.  Factors affecting Climate Sensitivity are not well-understood and estimates differ among researchers. Alternatively, a site-specific model could be developed to estimate the future impact of CO2 warming on a particular location. If atmospheric CO2 continues to increase at its current rate the small annual temperature increase expected at Riverside will likely be insignificant (e.g. < 0.01°C/yr) compared to natural temperature variability.
A slight increase in minimum daily temperature is noticeable at Riverside Fire Station No. 3 after 1998 (Figure 8, lower) with a corresponding slight decrease in the daily temperature range (Figure 9). This trend is most likely due to the urban heat island effect (Tam et al., 2015) resulting from increased development within and around downtown Riverside over this extended period.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterMedia in typhoon-prone Japan ignore new important findings suggesting hurricanes and typhoon intensification speed depends mostly on natural oceanic cycles, and not related to atmospheric CO2. 
Recently I posted on the surprising and science-realistic German DLF national public radio report on how hurricanes are intensifying more quickly today than they did 30 years ago.
Findings by scientists from the US Department of Energy (DOE) and the Pacific Northwest National Laboratory show it all has to do natural oceanic cycles that change every 30 years.

Hurricane intensification speed depends on natural ocean cycles, scientists recently determined. Yet much of the media remained silent over the findings – even cyclone-prone Japan. Photo image: NASA, public domain
Cyclones of great importance for Japan
And now that NTZ is committed to putting some focus on climate news and developments coming from Japan, I naturally wondered how these new, sober findings were received by the media there. After all, Japan is a country that regularly gets hit by typhoons, and so the subject of tropical cyclones and their genesis and future trends ought to be of great public and civic interest. Moreover, better long-term forecasting is crucial and could save lives.
Yet, no real media reporting by Japanese media
So I asked Japanese blogger Kirye of KiryeNet climate blog to do a quick Google search of the Japanese sites for reports on these findings, which she kindly did. Regrettably I’ve got to report that her search did not find a single report from any major Japanese media outlet on these latest findings.
She informed: “There seems to be no link of those articles published in the Japanese version of Google this year.”
Why would the media in a typhoon-prone country like Japan not find the recent finding worthy of reporting? This is somewhat mind-boggling (unless of course the media’s aim there is to just keep its own people in the dark when it comes to climate facts).
Kirye also wrote that the Japanese media generally have remained steadfast in their promotion of climate alarmism, and that skeptics don’t get any coverage in Japan.
Japan typhoons show no link to “global warming”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Not only do the recent DOE findings show that Atlantic hurricane intensification speed depends on natural ocean cycles, and thus these cycles need to be examined in the Pacific as well, but also the climate-science critical Japanese blogger mentioned other good news concerning cyclones earlier at her blog, namely the number of landings in Japan show no link at all to “global warming”.
Citing the Japanese Meteorological Agency, she wrote:
The number of typhoons formed decreased and the number of landings in Japan has been flat since 1951:
And Kirye provided the following chart:









Chart of typhoon non-alarmism. Courtesy of KiryeNet. 
Here she is in fact being somewhat modest because as you will notice the reality is that trend for the number of typhoons forming has been clearly downward, and thus it defies all the earlier predictions of more storms made by the “climate experts”. Things were considerably worse back in the 1960s when the planet was cooler and atmospheric CO2 lower.
In summary it is puzzling that the Japanese media would so recklessly handle the critical topic of typhoons and mislead the public of Japan in the face of glaring facts.
It’s the sort of information management one would come to expect for Japan’s nearby foe, which the world is currently grappling with.
Link to natural cycles provides useful forecasting tool
By having found a strong link between ocean cycles and tropical storm development, a very useful, longer-term forecasting tool emerges – if only it were acknowledged.
Sometimes it takes awhile before truth trumps obstinance.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThere’s capital to be derived from climate change, and now spiritual leaders and organized religion are getting in the act. And they offer a real Hell you can believe in – even certified by science!
Religion comes up with an all new, improved Hell
As enlightenment over the past decades and centuries have led the masses to doubt the once colorful concept of Hell — that fire-filled place reserved for the incorrigibly unvirtuous and run by reptilian demons — spiritual leaders have seen their clout in modern society erode. No longer is it so easy for them to control people’s behavior with feelings of guilt and threats of eternal damnation.
Recently, however, spiritual leaders have uncovered a new instrument to gain back some control over the masses: climate change – the new, and this time real Hell – yes, that’s been confirmed by 97% of the climate prophets – so disbelieve at your own risk!
Holy Words
This was demonstrated not long ago by Pope Francis’s Laudato si, His second encyclical. According to Wikipedia: “In it, the Pope critiques consumerism and irresponsible development, laments environmental degradation and global warming, and calls all people of the world to take ‘swift and unified global action’.”
The new Hell certified by “leading scientists”!
In a nutshell, do as they say or perish in climate hell. Laudato si was authored in large part by the Pope of Climate Doom himself, Prof. Hans-Joachim Schellnhuber of the ultra-alarmist Potsdam Institute for Climate Impact Research (PIK).
And just earlier this week, according to the online thecourier.com here  now the orthodox Christians are getting in on the act too. Once again Orthodox leaders too can let themselves stand morally above all others and preach to us on our sinful ways. And should we, the masses, not heed their Holy Science-Certified Words, then the new Hell (climate change) will ferociously engulf us as never seen before.
Hat-tip: a reader


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Frustrated scientists: message “not reaching people”
According to The Courier, leading climate change experts and campaigners gathered in Greece so that they could “work with the leaders of the Orthodox Church and other religions to fight global warming”.
Apparently activists and scientists are frustrated that their message is not reaching people fast enough. The two-day conference was inaugurated by “Green Patriarch” Bartholomew.
If science fails – then move on to faith!
Of course in attendance was the former PIK director and now accepted prophet Hans-Joachim (John) Schellnhuber. He told those in attendance:
Faith can help us because we scientists have tried everything. We can’t say what’s happening in a more compelling way when we warn about the end of civilization.”
According to the Courier, “hundreds of islanders” greeted Bartholomew “upon his arrival by boat”. The conference also included “long-breaded Orthodox priests” who got around in “golf carts and horse-drawn carriages”.
Climate visionaries and dignitaries
Also in attendance was a climate adviser to the Pope: Bill McKibben of 350.org; Jane Lubchenco, former NOAA head under Obama; Patricia Espinosa, UNFCC replacement for Christiana Figueres; Christiana Figueres herself, now Mission 2020; WAPO journalist Juliet Eilperin; and Jeffrey Sachs, economist, Columbia Earth Institute and climate adviser to the Pope.
No word if they came in on row boats, or horse-drawn carriages.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterDo Supernova Events Cause
Extreme Climate Changes?
“Global warming will not be reduced by reducing man made CO2 emissions”

In recent years, mass die-offs of large animals – like the sudden deaths of 211,000 endangered antelopes within a matter of weeks – have been described as “mysterious” and remain largely unexplained.
Determining the cause of the retreat to ice ages and the abrupt warmings that spawned the interglacial periods has remained controversial for many decades.
William Sokeland, a heat transfer expert and thermal engineer from the University of Florida, has published a paper in the Journal of Earth Science and Engineering that proposes rapid ice melt events and ice age terminations, extreme weather events leading to mass die-offs, and even modern global warming can be traced to (or at least correlate well with) supernova impact events.
The perspectives and conclusions of researchers who claim to have found strong correlations that could explain such wide-ranging geological phenomena as the causes of glacials/interglacials, modern temperatures, and mysterious large animal die-offs should at least be considered…while maintaining a healthy level of skepticism, of course.
Discovery – if that is potentially what is occurring here – is worth a look.

Sokeland, 2017
Scientists generally state that debris from supernova does not impact our planet.  They have no concept that incoming particles from exploding stars are focused by our sun’s gravity and the magnetic fields of the sun and earth.
[M]any harmful effects are possible in the Supernova and Nova Impact Theory, SNIT, including extreme changes of the climate.
Supernova Impacts and Solar Activity, Global Warming Correlation
The scattering of solar energy due to the small particles of supernova debris is also reflected in TSI data as shown in Fig. 3. The timing of impact for supernova debris streams allows the identification of the times and duration time periods for supernova debris streams impacting our planet. Fig. 3 indicates the duration of a single supernova debris stream flowing past our planet is at least 50 years and at times more than 100 years.

Fig. 3 shows an excellent correspondence between sunspot minimums, irradiance depressions, and supernova impact times. The six smaller dips in TSI generated by nova WZ Sagittae in the red portion of the TSI curve of Fig. 3 beginning with the Dalton minimum indicate we have been impacted by six different debris streams from the nova. The last one was in the 1965 to 1970 time region and it is the debris stream of Nova WZ Sagittae that started our current global warming episode near 1966.
Supernova Impacts and Ice Ages, Ice Sheet Melts, and Warm Period Correlations
Incoming supernova debris streams cause warming and melting ice caps that produce increased sea levels.  The increase in sea levels that correlates with supernova impact times is shown in Table 5. 
Termination of the last ice age results due to melting of numerous supernova impacts that correlate time of impact by changing sea level and geothermal energy released for 2,800 years from the exit crater of Dr. J. Kennet’s nano-diamond meteor theory and part of the process involves Dr. O’Keefe’s tektite theory. Correlation of Dr. Frezzotti’s ice melt Antarctica data with supernova impact times over the past 800 years establishes the Global Warming model in conjunction with the November 2016 Antarctic sea ice melt.
Supernova 393 debris impacted earth near 857 AD and started the Medieval Warming Period. When the warm part of the supernova oscillation or cycle stopped and the cooling occurred, the Little Ice Age began near 1250 AD. Supernova 393 also caused the decline of the Mayan Empire near 900 AD. Supernova 393 is proposed to have caused a gamma ray attack upon earth 1,200 years ago.
Two supernovas, G299 and G296.7-0.9, impacted the earth to produce first the Roman warming period shown in Fig. 4 with the normal cooling and then a third unknown supernova created some warming with a lot of cooling dropping temperature to a minimum near 1,100 years ago (900 AD). This cold period produced the Dark Ages. Then SN 393 occurred causing more warming than cooling, but the end result was the Little Ice Age. The Dark Ages and the Little Ice Age were very disastrous periods of time for our planet’s human populations. It should be concluded that the increase in CO2 caused by supernovas 1006 and 1054 that is currently being observed is a boon to mankind and will protect us from the coming cold phase that will be caused by these currently impacting supernovas. 
Consider the Minoan Warming of Fig. 4. The incoming carbon from supernova G29.6+0.1 causes the warm up as shown by the increased Greenland ice core temperatures.
Supernova Impacts and Timings of Megafauna Extinctions and Civilization Collapses
Noted megafauna extinctions in the past 50,000 years are correlated with the times when the debris of supernova explosions impact earth. The time of extinction should be near the time of impact of a supernova debris stream. The time of impact is derived from the time the light of the supernova explosion was seen on earth by adding a correction for the fact that the debris from the explosion moves slower than the speed of light and is shown in the second equation. The severity of the extinction will depend on the distance of the supernova from our planet, the type supernova that indicates the power of the explosion and the surroundings of the supernova when it explodes.  In general, most major disturbances of earth’s biosphere can be attributed to the explosion of supernovas.
Due to the scattering of light for small particles, the sunspots will tend to disappear when a hollow sphere of small particles enters our solar system between the sun and the earth. Other signs of the presence of the small particles are the increase of animal die offs for birds, bees, and fish and a decrease in TSI (total solar irradiance).
Recent outstanding examples of animal and human die offs due to the incoming debris were the Saiga antelope in Asia in May of 2014 and people dying in  India in May of 2015-2016.  These die offs were caused by SN 1006 and would have been called megafauna extinctions if the populations were restricted to small island land areas.  The deaths of the destructive hollow spheres for supernovas 1054 and 1006 will be minimal in the beginning but will increase in intensity as the years of higher particle mass and densities are approached.  Since these supernovas are over 7,000 light-years away from our planet, the effects should not be as severe as the extinctions listed in Table 2 that were due to supernova remnants that were closer to our planet.
Supernova G32.0-4.9 impact time of 4,530 ya corresponds to the fall of Egypt’s fourth dynasty in 2494 BC. It is reported that Ancient Europeans vanished 4,500 years ago. Could supernova debris actually destroy the structure of an empire and change DNA in Europe? An impact time of 4,210 years ago matches the 4.2 Kiloyear Event.
Supernova W50 with an impact time of 17,600 ya and a declination +4 appears to have caused rapid melting of the Patagonian ice sheet 17,500 years ago and corresponds to the last glacial maximum of 18,000 years ago.
Supernova G31.9+0.0 impact time of 8,092 ya produces another correlated woolly mammoth extinction event at Lake Hill on St Paul Island in the Bering Sea 7,600 years ago. The climate change produced by this supernova caused these mammoth to die due to lack of fresh water or drought.
Supernova W51C provides the impact time of 8,130 years ago and this date coincides with the end of the 8.2 Kiloyear Event.
The W50 meteor at 12,800 ya matches the beginning of deglaciation in Antarctica 12,500 years ago. Supernova Vela has a range of impact times shown in Table 1 and Fig. 7 suggests the change of temperature date of 11,700 years ago should be used. Vela’s thermal impact in the northern hemisphere was large because it is the second closest supernova to our planet.
Supernova G82.2+5.3 in Table 3 with an impact time of 5,903 ya produced the 5.9 Kiloyear Event and it is so close in time to the Piora Oscillation that the two different events due to different supernovas are often considered the same event 
The SNIT [Supernova and Nova Impact Theory] Model vs. Climate Models
Any model that claims to know the energy source for global warming must predict the past effects like Antarctic melts in Fig. 3a. Then the model can be successfully used to predict global warming effects in the future. If the proposed model cannot predict past global warming events from previously recorded independent data, the model is useless.
The SNIT model shows unusual and distinct conditions for beginning and ending ice ages. To start an ice age, a close supernova explosion like SN Monogem Ring must produce an extreme amount of iron on earth’s surface. To end an ice age a meteor from a supernova explosion must penetrate earth’s mantle and release geothermal energy over a long period of time to melt the ice.
Applying Occam’s razor, supernova debris impact is the simplest method that explains all these extinction and biosphere disturbance events because the only assumption is all debris streams travel at the same velocity from the remnant to our planet.
What Can We Do?
The debris streams of supernovas 1006 and 1054 have already began to destroy life on earth. When President Obama received a rough draft of this work, he issued an executive order to NASA stating, “Space weather has the potential to simultaneously affect and disrupt health and safety across entire continents”.
Since supernovas 1054 and 1006 are currently incoming, the planet’s average temperatures should continue to increase, global warming. Global warming will not be reduced by reducing man made CO2 emissions and in reality the only defense is to move to a cooler hemisphere, harvest CO2 from the atmosphere, or stop the incoming particles.  
Share this...FacebookTwitter "
"
Share this...FacebookTwitterTornadoes have become less frequent since 2010: Pacific ocean cycles control storm frequency
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
We haven’t heard much about tornadoes lately. For a while they were the favorites among climate activists. When did the love affair end? Here we cast a look at the official NOAA tornado statistics:

Fig. 1: Cumulative curve showing the number of tornadoes. Chart: NOAA.
Here we see 2017 was (fortunately) only average. The tornado trend over the past 60 years below shows the comparisons clearly. From 2005-2010 we saw an increased frequency of tornadoes in the USA, but they’ve since become less frequent. That’s bad news for the purveyors of catastrophe stories.

Fig. 2: Number of tornadoes in the USA since 1950. Source: NOAA.
With respect to the dangers of tornadoes, Hannes Stein asked in 2013 at German daily Welt, why Americans do not build build more stable structures, for example homes made of stone instead of wood:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Tornado damage is terrible – so why don’t Americans build better homes? That’s what Europeans ask, and thus prove their ignorance and arrogance.”
By the way, one finds an excellent display of global winds at ventusky.com.
So why does tornado activity fluctuate so much over the course of decades? Scientists at the University of Missouri found the answer: Tornadoes are influenced by the Pacific Decadal Oscillation (PDO), as explained in a press release dated October 10, 2013:
Pacific Ocean Temperature Influences Tornado Activity in U.S., MU Study Finds
Meteorologists often use information about warm and cold fronts to determine whether a tornado will occur in a particular area. Now, a University of Missouri researcher has found that the temperature of the Pacific Ocean could help scientists predict the type and location of tornado activity in the U.S.
Laurel McCoy, an atmospheric science graduate student at the MU School of Natural Resources, and Tony Lupo, professor and chair of atmospheric science in the College of Agriculture, Food and Natural Resources, surveyed 56,457 tornado-like events from 1950 to 2011. They found that when surface sea temperatures were warmer than average, the U.S. experienced 20.3 percent more tornados that were rated EF-2 to EF-5 on the Enhanced Fuijta (EF) scale. (The EF scale rates the strength of tornados based on the damage they cause. The scale has six category rankings from zero to five.). McCoy and Lupo found that the tornados that occurred when surface sea temperatures were above average were usually located to the west and north of tornado alley, an area in the Midwestern part of the U.S. that experiences more tornados than any other area. McCoy also found that when sea surface temperatures were cooler, more tornadoes tracked from southern states, like Alabama, into Tennessee, Illinois and Indiana.
“Differences in sea temperatures influence the route of the jet stream as it passes over the Pacific and, eventually, to the United States,” McCoy said. “Tornado-producing storms usually are triggered by, and will follow, the jet stream. This helps explain why we found a rise in the number of tornados and a change in their location when sea temperatures fluctuated.” In the study, McCoy and Lupo examined the relationship between tornadoes and a climate phenomenon called the Pacific Decadal Oscillation (PDO). PDO phases, which were discovered in the mid-1990s, are long-term temperature trends that can last up to 30 years. […]. “In the warm phase, which lasted from 1977 to 1999, the west Pacific Ocean became cool and the wedge in the east was warm.”
Also the El Ninos and the La Ninas (ENSO) impact tornadoes, as documented by Lepore et al. 2017:
ENSO-based probabilistic forecasts of March–May U.S. tornado and hail activity
Extended logistic regression is used to predict March–May severe convective storm (SCS) activity based on the preceding December–February (DJF) El Niño–Southern Oscillation (ENSO) state. The spatially resolved probabilistic forecasts are verified against U.S. tornado counts, hail events, and two environmental indices for severe convection. The cross-validated skill is positive for roughly a quarter of the U.S. Overall, indices are predicted with more skill than are storm reports, and hail events are predicted with more skill than tornado counts. Skill is higher in the cool phase of ENSO (La Niña like) when overall SCS activity is higher. SCS forecasts based on the predicted DJF ENSO state from coupled dynamical models initialized in October of the previous year extend the lead time with only a modest reduction in skill compared to forecasts based on the observed DJF ENSO state.”
There are also tornadoes in Germany from time to time. However, there has been no discernable trend over the past 15 years as shown by he Figure 7 in the DWD report.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHey, we just saw something similar from Japan. 
===============================================
On Spitzbergen it was as warm 70 years ago as it is today
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated by P Gosselin)
Newspapers like to write about heat and melt records in the Arctic, which supposedly had never happened before. That really sparks fear among the citizens. However an examination of the facts regularly brings amazing things to light, for example weather records from a German station on Spitzbergen during World War 2 for the period of 1944-1945.
In the journal International Journal of Climatology Rajmund Przybylak and his colleagues evaluated the data. Summary: Back then it was similarly warm as it is today. Abstract:
Air temperature conditions in northern Nordaustlandet (NE Svalbard) at the end of World War II
This article presents the results of an investigation into air temperature conditions in northern Nordaustlandet (NE Svalbard) based on meteorological observations made by German soldiers towards the end of World War II (1944/1945) and 4 months after its end. Traditional analysis using mean monthly data was supplemented by a detailed analysis based on daily data: maximum temperature, minimum temperature and diurnal temperature range. The latter kind of data made it possible to study such aspects of climate as the number of “characteristic days” (i.e., the number of days with temperatures exceeding specified thresholds), day‐to‐day temperature variability, and duration, onset and end dates of thermal seasons. The results from Nordaustlandet for the warmest period of the early 20th century warming period (ETCWP) were compared with temperature conditions both historical (the end part of the Little Ice Age) and contemporary (different sub‐periods taken from the years 1981–2017) to estimate the range of warming during the ETCWP.
Analysis reveals that the expedition year 1944/1945 in Nordaustlandet was, in the majority of months, the warmest of all analysed periods, that is, both historical and contemporary periods. The study period was markedly warmer than 1981–2010 (mean annual −6.5 vs. −8.4 °C) but colder than the periods 2011–2016 (−5.7 °C) and 2014–2017 (−5.8 °C). The majority of mean monthly air temperatures in the ETCWP lies within two standard deviations of the modern 2014–2017 mean. This means that values of air temperature in the study period lie within the range of recent temperature variability. All other thermal characteristics show changes in accordance with expectations associated with general warming of the Arctic (i.e., a decrease in diurnal temperature range and number of cold days, and an increase in number of warm days). The latter days were most common in the ETCWP.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterJosef Kowatsch and Stefan Kämpfe at the European Institute for Climate and Energy (EIKE) here have been looking at temperatures in Central Europe, foremost Germany, over the past 30 years.

 Heavy snow blankets Germany in January, 2018. Photo: Stefan Kämpfe
The German media like to say that Germany has been warming rapidly due to global warming, especially winter. Yet a look at the data tells a different story. Although January, 2018 was a mild one at a mean of 3.8°C, as measured by the German DWD national weather service, the overall January trend is COOLING.
The warm January, 2018, did little to curb Germany’s overall January cooling trend, as data from the DWD show. Kowatsch and Kämpfe have plotted the January data over the past 31 years along with the computed linear trend line:

Figure 1: January mean temperatures for Germany have been cooling over the past 31 years. Chart: Josef Kowatsch, based on data from the DWD.
This winter’s mild Central European weather has been attributed to a series of lows that have pumped in mild air from the Atlantic and kept much of Europe out of the ice box. Also heavy precipitation has been associated with the lows, and higher elevations have seen heavy snowfalls as a result — especially in the mountain regions and Alps.
Trend contradicts the CO2
Looking at different locations in Germany, the East German station of Erfurt/Weimar shows the same January cooling trend despite rising CO2 concentrations.

Figure 2: January temperature trend (blue) over the past 31 years  in Erfurt (316m elevation) compared to CO2 concentrations (green). Chart: Stefan Kämpfe.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This cooling has been occurring despite urbanization and added waste heat. Currently 100 hectares of building and asphalt are being added daily.
Substantial cooling at the high elevations
Getting away from urban areas, Kowatsch and Kämpfe looked at the mean January temperature atop Germany’s highest peak, the Zugspitze, and at Amtsberg in the East German Erzgebirge near Chemnitz.
The following chart shows the 31 year trend for the Zugspitze, some 2960 m above sea level:

Figure 3: January’s mean temperature on the summit of Germany’s highest mountain, Zugspitze, has trended significantly downward over the 31 years: from -8.3°C in 1988 to over -11°C in 2018 (using the linear trend). That’s about 1°C per decade! Chart source: Josef Kowatsch.
Urban heat island likely skewing the real cooling
Next we look at the station Amtsberg at the foot of the Erzgebirge in East Germany. Here over the past 30 years the mean January temperature has fallen modestly and shows no signs at all of any warming.

Figure 4: Rural station Amtsberg (blue curve) near Chemnitz is similar to the trend observed across Germany (red curve). Chart source: Josef Kowatsch.
Kowatsch and Kämpfe write that they believe the urban heat island (UHI) effect has not been adequately accounted for in the DWD data, and thus the cooling may actually be even stronger.
So if you’re looking for warming, you won’t find it in Central Europe — despite all the fake climate news you might be hearing.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterDr. Sebastian Lüning and Prof. Fritz Vahrenholt show that sea level rise at the Fiji Islands is being hyped up in order to generate money.
====================================================
Fijigate
Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(Translated/edited by P. Gosselin)
The COP23 climate conference in Bonn had originally been planned to take place in the Fiji Islands. But in order to comfortably accommodate the approximately 25,000 representatives(!) from every country in the world, it was decided to hold it in Bonn.
It was reported in Spiegel about how the islands are becoming victims. At the start of the article author Axel Bojanowski referred to the rise in sea level and linked to an NOAA-website. But later throughout the rest of the article there was no mention of climate change submerging the islands.
Bojanowski was completely correct to emphasize that the most important reasons for the erosion of the islands is solely the fault of the island inhabitants. The uncontrolled deforestation reduces stability and resistance to the sea. Even persons who sail in the area report that there are 3-meter waves even in the absence storms in the region.
But let’s get back to sea level rise in the area. At the NOAA website there is also the possibility to download the data. And that is what we did.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 1: Sea level rise at the Fiji Islands, 1990-2011. Data: NOAA. The linear trend is 6 mm per year.
The available NOAA data go back (with some gaps) to 1972, but the station was moved in March 1989 and this led to an upwards jump of about 10 cm. Thus we look only at the period from 1990 to the end of 2011, where unfortunately the data series ends. However we supplement the data for the area from satellites (see here:

Figure 2: Sea Surface Height (SSH at the Fiji Islands from satellite measurement. Source here.
After a peak in 2012 the level went down by about 10 cm by mid 2017. It is very much related to natural variations, in sync with the El Ninos (low levels) and La Ninas (high levels).
So what remains of the climate change horror stories in connection to the Fiji Islands? In the article, a 40-year old woman tells about her youth (i.e. around 1990), when she viewed the water as her friend and how today (2017) she regards it as an enemy. But just what should an approximately 8 cm rise (and not the often cited 17 cm that was generated by the powerful 2011/12 La Nina) lead to in 27 years with waves of 3 meters?
The contribution to erosion coming from climate change is certainly hardly noticeable by the residents. However for PR work, it works great for shaking down money.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA new study shows that the Antarctic Ice Shelf has been thickening – in times of global warming. Logic: Global warming cannot be the driving factor for Antarctic ice shelf mass, let alone CO2.
=====================================
West Antarctic Ice Shelf: El Nino takes, La Nina gives
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P. Gosselin)

Antarctic ice shelf. NASA photo (Chris Larsen) – public domain.
Whenever a chunk of ice breaks off the Antarctic ice shelf, the guilty party is immediately found by the media: man. He did it with his SUVs, his planes and his container ships.
But what makes everything all the more surprising is a recent press release from Scripps Institution of Oceanography from 8 January 2018. Weather phenomenon El Niño is causing the ice shelf in the Amundsen Sea to melt from underneath.
Additional snowfall is unable to compensate for the loss. During a La Niña phase the opposite occurs: The ice sheet grows. It’s natural variability at work. Gradually we are beginning to understand how it works. The press release follows:
New Study Reveals Strong El Niño Events Cause Large Changes in Antarctic Ice Shelves
Oscillations of water temperature in the tropical Pacific Ocean can induce rapid melting of Antarctic ice shelves. A new study published Jan. 8 in the journal Nature Geoscience [Paolo et al. 2018] reveals that strong El Niño events can cause significant ice loss in some Antarctic ice shelves while the opposite may occur during strong La Niña events.
El Niño and La Niña are two distinct phases of the El Niño/Southern Oscillation (ENSO), a naturally occurring phenomenon characterized by how water temperatures in the tropical Pacific periodically oscillate between warmer than average during El Niños and cooler during La Niñas. The research, funded by NASA and the NASA Earth and Space Science Fellowship, provides new insights into how Antarctic ice shelves respond to variability in global ocean and atmospheric conditions.
The study was led by Fernando Paolo while a PhD graduate student and postdoc at Scripps Institution of Oceanography at the University of California San Diego. Paolo is now a postdoctoral scholar at NASA’s Jet Propulsion Laboratory. Paolo and his colleagues, including Scripps glaciologist Helen Fricker, discovered that a strong El Niño event causes ice shelves in the Amundsen Sea sector of West Antarctica to gain mass at the surface and melt from below at the same time, losing up to five times more ice from basal melting than they gain from increased snowfall. The study used satellite observations of the height of the ice shelves from 1994 to 2017.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




‘We’ve described for the first time the effect of El Niño/Southern Oscillation on the West Antarctic ice shelves,’ Paolo said. ‘There have been some idealized studies using models, and even some indirect observations off the ice shelves, suggesting that El Niño might significantly affect some of these shelves, but we had no actual ice-shelf observations. Now we have presented a record of 23 years of satellite data on the West Antarctic ice shelves, confirming not only that ENSO affects them at a yearly basis, but also showing how.’
The opposing effects of El Niño on ice shelves – adding mass from snowfall but taking it away through basal melt – were at first difficult to untangle from the satellite data. ‘The satellites measure the height of the ice shelves, not the mass, and what we saw at first is that during strong El Niños the height of the ice shelves actually increased,’ Paolo said. ‘I was expecting to see an overall reduction in height as a consequence of mass loss, but it turns out that height increases.’
After further analysis of the data, the scientists found that although a strong El Niño changes wind patterns in West Antarctica in a way that promotes flow of warm ocean waters towards the ice shelves to increase melting from below, it also increases snowfall particularly along the Amundsen Sea sector. The team then needed to determine the contribution of the two effects. Is the atmosphere adding more mass than the ocean is taking away or is it the other way around?
‘We found out that the ocean ends up winning in terms of mass. Changes in mass, rather than height, control how the ice shelves and associated glaciers flow into the ocean,’ Paolo said.  While mass loss by basal melting exceeds mass gain from snowfall during strong El Niño events, the opposite appears to be true during La Niña events. Over the entire 23-year observation period, the ice shelves in the Amundsen Sea sector of Antarctica had their height reduced by 20 centimeters (8 inches) a year, for a total of 5 meters (16 feet), mostly due to ocean melting. The intense 1997-98 El Niño increased the height of these ice shelves by more than 25 centimeters (10 inches). However, the much lighter snow contains far less water than solid ice does. When the researchers took density of snow into account, they found that ice shelves lost about five times more ice by submarine melting than they gained from new surface snowpack.
‘Many people look at this ice-shelf data and will fit a straight line to the data, but we’re looking at all the wiggles that go into that linear fit, and trying to understand the processes causing them,’ said Fricker, who was Paolo’s PhD adviser at the time the study was conceived. ‘These longer satellite records are allowing us to study processes that are driving changes in the ice shelves, improving our understanding on how the grounded ice will change,’ Fricker said.
‘The ice shelf response to ENSO climate variability can be used as a guide to how longer-term changes in global climate might affect ice shelves around Antarctica,’  said co-author Laurie Padman, an oceanographer with Earth & Space Research, a nonprofit research company based in Seattle. ‘The new data set will allow us to check if our ocean models can correctly represent changes in the flow of warm water under ice shelves,’ he added. Melting of the ice shelves doesn’t directly affect sea level rise, because they’re already floating. What matters for sea-level rise is the addition of ice from land into the ocean, however it’s the ice shelves that hold off the flow of grounded ice toward the ocean. Understanding what’s causing the changes in the ice shelves ‘puts us a little bit closer to knowing what’s going to happen to the grounded ice, which is what will ultimately affect sea-level rise,’ Fricker said. ‘The holy grail of all of this work is improving sea-level rise projections,’ she added.”
Meanwhile the Potsdam Institute (PIK) continues to work from the alarmism playbook.
Surprisingly there is also a finding from the Ross ice shelf. There researchers carried out a bore sample through the ice. Amazingly the ice  appears to be growing instead of melting for the time being. National Geographic reports on the unexpected result:
Deep Bore Into Antarctica Finds Freezing Ice, Not Melting as Expected
[…] The surprises began almost as soon as a camera was lowered into the first borehole, around December 1. The undersides of ice shelves are usually smooth due to gradual melting. But as the camera passed through the bottom of the hole, it showed the underside of the ice adorned with a glittering layer of flat ice crystals—like a jumble of snowflakes—evidence that in this particular place, sea water is actually freezing onto the base of the ice instead of melting it.”
Read the entire article at National Geographic.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe online fuldainfo.de here reports of mores woes in the German offshore wind industry. It’s turning out that offshore wind power is expensive, and often plagued by technical difficulties.

The offshore Trianel Borkum wind park severely hampered by spiraling costs, lower than expected winds. Photo credit: Trianel
Just days ago I wrote here of another recent technical folly suffered by the North Sea Riffgat wind park, where its power transmission underwater cable worked its way out of the seabed to become exposed and thus at risk of becoming ensnarled with anchors or fishing nets.
“Rosy wind projections”
The fuldainfo.de now writes of “high losses” incurred by aanother nearby wind park: the Trianel Windpark operated by Rhönenergie. This is “not surprising” to FDP Free Democrats Party Chairman Mario Klotzsche:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




We brought up our concerns again and again in the committees, and also in public, because the economic precariousness was foreseeable at a very early stage. That’s why the city of Flensburg left the project already in 2014. That’s what we also wish to do so that Rhönenergie can avoid getting saddled with additional burdens.”
Offshore installation costs more than doubled
A major reason for the losses seen by the Trianel Borkum park today, according to Klotzsche, were the “rosy wind projections”, which he reports was also the case for “many other wind projects“. He is quoted in the fuldinfo.de:
Originally 80 turbines with 400 megawatts of capacity should have been installed for 1 billion euros. In the end only 40 turbines and 200 megawatts of capacity were built for 1.1 billion euros.”
Multiple delays
Klotzsche also spoke of “repeated delays” with respect to hook up to the power grid, and even after the park was put into operation.
Moreover, the winds that were projected never materialized. “There was less wind than what was assumed,” according to Klotzsche. “The responsible persons calculated the project using rosy numbers.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA documentary dubbed “The Weather Machine” produced in 1975 – long before NASA fiddled with the data – warned of an impending ice age (10:35), and maintained that the globe is cooling. Hat-tip: reader The Indomitable Snowman.
The documentary attempted and succeeded at presenting the latest on climate change at the time.
Changing climate accepted as normal
It is true that back in 1975 climatologists already knew that the climate behaved cyclically, as evidenced by the ice cores and tree ring sets extracted from the American Southwest.
Climate change back then was known to be a normal, natural phenomenon. Moreover, after 3 decades of temperature decline, scientists indeed were concerned that the globe was cooling at a worrisome rate.

Part 1: Weather Machine. Exiled Czech climate scientist Dr. George Kukla said in the 1970s: “The ice age is now due any time.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Also, contrary to what was suggested by Michael Mann”s notorious hockey stick chart, the little Ice Age did in fact exist and was clearly evidenced by old historical records from ships, The Weather Machine documentary tells us.
And note that the documentary stated that the Jet Stream also changed its course naturally, just as it does today, and that there was much more to it than just Arctic sea ice extent, on which today some scientists are trying to blame for the frigid winter we are now witnessing.
In Part 2, viewers are told how the ocean cycles have a major impact on the weather cycles, something today that is ridiculously being blamed on trace gas CO2 from human activity.
Little Ice Age warnings…
At the 6 minute mark of Part 2 again we are warned of cooling and the potential of a little ice age, or worse.

Prof. George Denton, University of Maine at Orono, warned we could easily return to Little Ice Age conditions.
Humans may be causing cooling
Later into Part 2 Dr. Reid Bryson of the University of Wisconsin claims that man’s activity may be contributing to the cooling through the “Human Volcano” spewing aerosols into the atmosphere that “blots out” the sun.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterScience journalist Axel Bojanowski at German flagship, center-left news weekly Spiegel here dismissed a recent study published by Columbia University scientists Wolfram Schlenker and Anouch Missirian, who had claimed climate warming was driving masses of environmental refugees to Europe.
The two scientists claimed in Science to have found a relationship between weather disasters and refugees migrating to Europe.
However, the far-fetched conclusions by the two scientists has since been met with sharp and harsh criticism for its loose use of statistics. The study was financed by the JRC of the European Union. One member of the JRC, Juan-Carlos Ciscar, said it was time for policy makers to act.
Paper gets “crushing assessment” from other scientists
However, Spiegel’s Bojanowski reports that a number of leading experts dismissed the paper’s claims. For example Thomas Bernauer and Vally Koubi the Zurich-based ETH said: “Politicians would be ill-advised to orient themselves based on this study.”
Bojanowski added that other experts SPIEGEL ONLINE asked gave it “a damning verdict“.
“Dumbest use of statistics”
The Spiegel journalist also took jabs at other leading media outlets, such as the Guardian, Reuters and AP, implying they uncritically used the study for hype.
Bojanowski then cited statistics expert William Briggs of Cornell to assess the methodology used by the study:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The dumbest, most idiotic use of statistics that I’ve seen in a long time.”
Tobias Ide of the Georg Eckert Institute also warned against simplifying “the relationship between warmer temperatures and migration“, Bojanowski wrote, and that Jonas Vestby of the Peace Research Institute in Oslo was surprised the paper ever got by peer-review.
Christiane Fröhlich of the University of Hamburg is considering a rebuttal at Science, Spiegel’s Bojanowski wrote.
Confusion
Fröhlich says the Columbia University authors confused environmental refugees with political refugees. In Europe refugee status is given to persons who are politically oppressed and persecuted and not to those moving due to the environment. Critics of the study also called the projections and correlations claimed by Schlenker and Missirian as “highly speculative“.
Fröhlich also told Spiegel the paper “ignored numerous studies” on migration and warming. Briggs added that the two authors based their assumptions on only “15 years and in only one region” and “ignored 6000 years of human history“.
Bojanowski cited Briggs:
Just how important it would have been to include other regions was made clear by Briggs using one provocative question: ‘Why then don’t asylum applications in cool Chile rise after heat waves in the warm neighboring countries?'”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterJapanese skeptic blogger Kirye posted here at Twitter the latest news on Arctic sea ice volume, which earlier this spring took a sudden and unexpected jump upwards – adding some 2 trillion cubic meters.
What follows is the latest chart from the Danish Meteorological Institute (DMI):

Source: DMI.
As the chart shows, Arctic sea ice volume hasn’t really budged that much since it peaked back inApril.
Less than 4% below the mean
And when one looks at the chart closely, it is seen that the mean Arctic se ice volume for this time of year is just under 25,000 cubic kilometers. Currently we see that volume is the same as it was in 2014, at some 24,000 cubic kilometers.
The deviation from the mean is less than 1000 cubic kilometers, i.e. less than 4%. That means sea ice volume is well within the range of natural variability.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Predictions of an ice-free Arctic go back decades
Two days ago the Deplorable Science Blog here reminded us: “Sixty years ago, the New York Times predicted ships would be sailing over the North Pole ‘within the lifetime of our children.’”
The false prophets
In the same article Steve Goddard brings up a 2008 article by the AP’s Seth Borenstein, who quoted climate alarmist, Massachusetts Senator Ed Markey, who then called James Hansen a “climate prophet”.
Both Al Gore and former NASA GISS director James Hansen warned –“echoing work by other scientists” — that the Arctic would be ice-free in the summer by now!
So, add two more names to False Prophets Hall of Fame.
Skeptics right
Ironically the real “prophet” turns out to be Oklahoma Senator, global warming skeptic Sen. James Inhofe, who in 2008 dismissed all the predictions as media doom, and said that Americans weren’t buying it.
Ten years later Senator Inhofe turns out to be right.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIt’s the food, stupid!
Something off topic today, and intended as food for thought. It’s my infrequent post on nutrition. Yes, I also would like my readers to be healthy and happy.
Stress, lifestyle, pollution are over-rated factors
In western societies, when asked why so many people are getting sick with chronic diseases today, and thus die prematurely, too many medical experts like to blame it on stress!, genetics, pollution, lifestyle, or just plain bad luck. So take my pills!
However, these often cited reasons are all too often bogus explanations designed to get you to accept horrendously costly treatments instead of opting for effective prevention. Prevention and cure, after all, are bad for Big Pharma’s bottom line. The big money is in lifetime treatment.
And in western societies, far too little is being done to drive home the point that the junk-food contaminated Western nutrition is the root cause of many chronic diseases and thus our food supply needs to be revamped radically and rapidly. If this were done, much misery and high costs could be spared.
Life-shortening disease often food-related
What a lot physicians won’t tell you is that many of these diseases are in fact nutrition-related and gradually emerge after years of poor quality (low-nutrient) diets. Many common chronic diseases could be prevented, or at least delayed by years, simply by eating high-nutrient foods. The most important thing you can do to live longer and healthier is to eat correctly, and to start doing so immediately.. Your doctor can tell you to reduce stress and to go for walks all he wants, but unless you wean yourself off the junk food, you’ll very likely end up chronically ill and forever connected to the miserable Big Pharma lifeline.
High stress Japan has highest life expectancy!
To illustrate how stress is an over-rated factor in causing chronic illness, one only needs to check out the countries with the highest life expectancies. Many happen to be high stress environments, like Japan and Europe. Of course stress is generally to be avoided, but is it really the big silent killer everyone makes it out to be? Statistics show us the answer is no. The big killer is junk food.

High stress, urbanized Japan No. 1 in life expectancy. Source: WHO. 
Anyone who has ever visited Japan will tell you that most people there live in high-stress, urban environments and work among the longest number of hours annually. Most Japanese in fact do not spend their time meditating in harmonious Zen rock gardens.
Japanese and Mediterranen diets lead to long lives


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Arguably the most important factor to Japan’s excellent collective health is its nutritional culture. Whereas in western culture many people stuff themselves with sugary, processed junk foods, snacks, sodas and sweets and bad oils, the Japanese diet is rich in vegetables, high-nutrient carbs, fish, fermented foods, antioxidant super-foods and green tea to name a few.


American (sick) lives simply dragged out by Big Pharma
But what about USA’s relatively high life expectancy? First, it really isn’t that high, and actually ranks a lowly 31st on the WHO list above!
And although the American diet is among the world’s most notorious, American’s do live about 80 years, and so food can’t be the big factor one might argue. Though Americans live relatively long, we need to keep in mind that huge numbers of them are plagued by chronic disease, and many are simply kept alive in a state of limited health or outright misery for years by Big Pharma. The average American today spends some $10,000 annually on health care alone.
Here’s what some countries spend on health care per capita:

The USA spends the most by far on health care, yet does not even make the Top 30 on the list for life expectancy. On the other hand, high stress, urbanized Japan spends near the OECD average on health care, yet has the highest life expectancy. Italy also sees a good life-expectancy-to-healthcare-spending-ratio, arguably in large part due to its health Mediterranen diet. Chart: OECD Data: Health resources – Health spending.
A longer life at a fraction of the healthcare cost
Also we note that poorer Mediterranean countries such as Greece, Cyprus, Spain and Malta spend a mere fraction on healthcare of what Americans spend, yet live longer. It’s the food that makes the difference.
Big Junk driving Big Pharma
According to statista, the U.S. pharmaceutical market represents over 45 percent of the global pharmaceutical market, valued at around 446 billion U.S. dollars in 2016.
With that kind of spending, the country should be way up the top of the list for life expectancy, but at a lowly 31st place it’s not even close to the top. One reason is because bad American junk food is creating sickness and thus a big demand for health care. Big Junk is feeding Big Pharma.
To live longer and healthier, good food is the key. Eat healthy, and the rest will take care of itself.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter…EU enacts law to regulate the color of potato and grain-based foods with the aim of protecting public from high cooking temperatures

Too dark! EU now regulating bread color from baking at too high temperatures. Photo credit: Fritzs, Creative Commons Attribution-Share Alike 3.0 Unported.
The following should be a viewed as a shot across the bow concerning the extent and zeal to which the EU is capable of when it comes to regulation. Just imagine if they were given a free hand to regulate all things related to CO2 and climate change. It’s getting frightening.
I’ve gotten used to the high levels of regulation here in Europe, and it’s gotten tough to surprise me. Yet, EU bureaucrats never fail at finding new ways to do so.
Nanny state
The latest pertains to the color of bread. The most recent news on EU regulation is reported for example by the Austrian online Wochenblick here, which writes: “EU regulation: Effective immediately our bread is not allowed to be too dark”!
The risk, according to the EU, is acrylamide, a carcinogenic compound that can form on starchy food if the cooking temperature is too high (some studies suggest).
European nannies are afraid some people could get sick from eating overly dark bread.
Meanwhile, it’s business-as-usual for the obviously dangerous product sugar, whose consumption in Europe has reached dangerous levels with diabetes becoming an epidemic. But the days of unregulated sugar use may also be coming to an end. Regulating sugar would make sense.
Aim is to curb acrylamide from high temperature cooking


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The dark-bread regulation went into effect last Wednesday, and appears to be a part of the regulation package to ban golden, crispy french fries as well.
Wochenblick reports that the regulation are for all products based on potatoes, grains, and also coffee. The EU intends to conduct food inspections in the future.
Regulating living down to the detail
The new highly intrusive regulations are the latest rules aimed at limiting coffee machines, restricting wood-burning stoves, vacuum cleaner power ratings, and lawn mower emissions, to name a few.
A Google search already shows that EU regulations for outdoor barbecues are likely in the works. Readers can look into that themselves to determine if that’s the case or not. Just imagine what that would look like.

The EU is only just getting started with all the regulation-mania.
More background here.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn an opinion piece at the Mittel Bayerische daily, Harry Neumann, National Chairman of the environmental group Naturschutzinitiative e.V. declares Germany’s Energiewende (transition to renewable energies) a failure and writes: “The wind power industry and nature protection cannot be reconciled.”
Moreover Germany’s EEG green energy feed-in act is doing more harm than good, writes Neumann: “The EEG is impeding the research of environmentally compatible technologies.”
Neumann also notes that despite having installed close to 30,000 wind turbines, Germany’s “CO2 emissions are not dropping, but rather are rising again.” He adds:

During the expansion of renewable energies, they failed from the start to set impact limits too protect nature, species, forests and landscapes.”

He also blasted what he calls the “political-industrial complex“, which he says has nothing to do with nature and climate protection, “but rather with the full exploitation of billions in subsidies“.
In Neumann’s view, the wind industry and nature protection “cannot be reconciled” and thus calls for the immediate repeal of the EEG feed-in act.
Veteran journalist: German energy policy fraught with absurdities


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On another note, veteran German science journalist Michael Miersch explains in an interview conducted by Dr. Benny Peiser of the Global Warming Policy Foundation the sheer absurdity and widespread damage German renewable energies are having on the environment.

When asked about the current status and dialogue surrounding the Energiewende, Miersch tells Peiser:
I would like the debate to be less ideological and to be held with less moral rigor. Nowadays you cannot criticize the Energiewende without being put into a corner and being accused of not caring about global climate change.”
He cites the U.S. as a model of how to go about energy policy:
If you think about the US for example, they have achieved a lot in terms of CO2 reduction with gas power plants. There are very few gas power plants in Germany. They are building hardly any new ones.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Sun in November 2017
By Frank Bosse and Prof. Fritz Vahrenholt
(Translated and edited by P Gosselin)
In November the sun was unusually quiet with respect to activity. The observed sunspot number (SSN) was merely 5.7, which is only 14% of what is typically normal for month number 108 into the cycle. The current cycle number 24 began in December 2008. The sun was completely spotless 19 of 30 days in November.
At the end of the month some activity appeared, but only at a very low level. The following chart depicts the current cycle’s activity:

Figure 1: The monthly SSN values for the current solar cycle 24 (red) 108 months into the cycle, the curve for the mean of the previous 23 cycles (blue), and the similar solar cycle number 5 (black).
The next chart shows a comparison of all observed solar cycles thus far:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 2: The monthly accumulated anomalies of the cycles up to 108 months into the cycle. Cycle number 24 has taken third place for the most inactive.
The situation thus remains unchanged: such a weak solar cycle has not been witnessed in 200 years. It is anticipated with quite high certainty that also the upcoming solar cycle number 25 will be about as weak, because the sun’s polar fields are about as strong as they were during the minimum between cycle number 23 and cycle number 24.
The very weak solar north pole so far has recovered significantly over the past few months since June. What this means now and for the future can be seen graphically at the chart posted here. You can find the latest information at www.solen.info/solar.
LaNina is here
An update to our last post here is surely of interest. We were sure of a La Nina by the end of December, and in the meantime the Australian Bureau of Meteorology officially announced a La Nina in its most recent bulletin. The current model forecast shows continued falling sea surface temperatures along the equatorial eastern Pacific until about February, 2018:

Figure 3: The model for El Nino/La Nina in the Pacific, Source: NOAA. All forecasts point to a moderately strong La Nina event until spring. A powerful La Nina such as the one observed in 2011/12 is currently not projected by the models (which incidentally did not even forecast a La Nina just a few months ago).
The impacts on global temperatures lag behind by about 3 to 4 months, and so we should expect a La Nina dip by spring.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNew York Times journalist Erica Goode misses a mountain of polar bear research, instead lets herself get swept up by alarmist polar bear activism.
The New York Times recently published an article penned by Erica Goode on the controversial Harvey et al paper, where 14 scientists (sophomorically) attacked polar bear researcher Susan Crockford and climate science skeptics.
If the Harvey publication makes anything clear, it is that its authors are deeply frustrated by the large share of the public who reject their alarmist climate science. But instead of looking at themselves and the mountain of blunders they have made in the past to see what they could improve, the Harvey scientists chose to lash out and blame their woes on mean-spirited “deniers”. The inconvenient reality, however, is that alarmist climate and polar bear science (and journalism) has not been clean, and at times it’s been outright sloppy, deceptive and shrill. That’s the real big reason skeptics have been so successful.
Sloppy biased journalism
So it is no surprise that Erica Goode at the New York Times sided up with the 14 scientists of the Harvey publication to attack the so-called climate “denialists” in her most recent article. Unfortunately Goode made the fatal journalistic error of failing to keep a healthy distance from the alarmist side and as a result was blinded from seeing the glaring mountain of scientific research showing polar bears are in fact doing fine.
As a result Goode’s work couldn’t have been sloppier.
 A mountain of recent scientific publications gets missed
The reality is that there are many polar bear scientists out there who have produced a considerable body of recent scientific findings, which show that the polar bear populations are in reality stable or even thriving. How could Goode have missed it?
Whatever the reasons, it appears to be to a classic case of journalistic negligence.
Had the seasoned New Times journalist done just the minimum of research one expects of even a beginner journalist, she would have discovered, for example, two very recent papers on polar bears published in the journals Ecology and Evolution and Polar Record, and many others. According to expert polar bear scientists (other than Dr. Susan Crockford) there is no evidence to support recent claims polar bears as a species are in grave danger due to climate change and thinning sea ice.
Somehow Goode allowed herself to be talked into the absurd idea that Susan Crockford is the only skeptic polar bear scientist out there, and so did not bother to check for others, so it seems. And the only crises we find are those from dubious computer-modelled 2050 scenarios.
1) York et al 2016
One scientific publication by York et al in 2016 found that given the paleoclimate record of a much warmer (+4 to + 7.5 °C) Arctic, there was much more reduced sea ice thickness and extent in the past relative to today. They concluded: “it seems unlikely that polar bears (as a species) are at risk from anthropogenic global warming.”
The authors wrote in their summary:
Considering both [observations from native populations] and scientific information, we suggest that the current status of Canadian polar bear subpopulations in 2013 was 12 stable/increasing and one declining (Kane Basin).”
We do not find support for the perspective that polar bears within or shared with Canada are currently in any sort of climate crisis.”
Why didn’t Goode contact these scientists and present their results? There are many other scientists who share Crockford’s view.
2) Wong et al 2017
Another published scientific paper by Wong et al., 2017, “Inuit perspectives of polar bear research: lessons for community-based collaborations”, the authors investigated Inuit observations. Here’s an excerpt of their findings:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Wong, a researcher at the Department of Ecology and Evolutionary Biology, University of Toronto, and her team also found in early 80s, and mid 90s: “there were hardly any bears” and “there’s too many polar bears now”.
Also they noted: “Bears foraging for land-based foods have been reported in the literature prior to recent concerns over climate change (Russell 1975; Derocher and others 1993; Gormezano and Rockwell 2013a).” Also: “Observations of bears consuming garbage are not uncommon (Russell 1975; Lunn and Stirling 1985; Gormezano and Rockwell 2013b)”
More fuel for skeptics
One has to wonder if the activist Harvey team of scientists and the New York Times live in an alternative universe. It is precisely that kind of gross omission and one-sidedness that has been fuelling the skeptics over the years.
And there’s much more that they ignored.
Laforest et al., 2018
A publication by Laforest et al titled Traditional Ecological Knowledge of Polar Bears in the Northern Eeyou Marine Region looked at the perception of communities in Quebec on the prevalence of problem polar bears. Results: One-third of participants reported that polar bears will be unaffected by, or even benefit from, longer ice-free periods. A majority of participants indicated that the local polar bear population was stable or increasing.
Moreover they cited the fact that polar bears are capable of hunting seals in open water as a factor contributing to the stable body condition of the bears. and that none of the participants explicitly linked the effects of a warming climate to specific impacts on polar bears.
The publication also states that a recent aerial survey of the Southern Hudson Bay subpopulation found that the abundance of polar bears has remained steady since 1986 (943 bears; SE: 174) (Obbard et al., 2015).
11 more recent papers show bears survive without ice
Not long ago Kenneth Richard reported on almost a dozen papers showing that polar bears easily survived ice-free and far warmer conditions than those seen today or those expected by mid century.
Even more research shows that polar bear population is up 42% since 2004.
Russia “scientists know little or nothing” 
Goode’s non-researched article also mentions that “scientists know little or nothing” about the situation in Russia and other remote areas (and so it’s got to be bad?). If it is unknown, then how can one be either rationally alarmed or relieved about the situation there? Yet, given the positive situation from Canada and Alaska, there is no rational reason to assume all is bad in Russia.
New York Times’ image of bias
So what can we take home from this? Why did Goode ignore so much polar bear research, and why has she unconditionally lapped up everything handed down to her by the alarmist clique? We can only speculate it’s about activism.
Erica Goode and New York Times again shot themselves in the foot on this one and reaffirmed their reputation for bias.
Had Goode resisted getting distracted from the “us” versus “them” narrative and actually dug a little into the actual scientific results –  and the scientists behind them – like honest journalists do, she would not have produced such a piece of journalism.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Not climate change: forest fires in the USA controlled by El Nino, arson and land use changes
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
Droughts increase the risk of forest fires; that’s logical. However it is false to reflexively assign every forest fire to climate change. There have always been droughts and forest fires. Anyone wishing to shift the blame over to climate change first has to show that the trend has already deviated from the range of natural variability. For many, that is simply too much work.
Thus they prefer to claim something and hope that nobody will bother to fact check the claim. They don’t like climate skeptics because they have the silly habit of carefully examining the facts. They prefer the silent, non-questioning audience who immediately say yes and amen in response to all alarmist claims.
And when the facts indeed do contradict their alarmist claims, they get personal. They attack the occupation of the skeptic, or education, or skin color, or, or, or.
Nowadays we can find a load of facts in the Internet. Example: forest fires in the USA. The size of the areas ravaged by forest fires is provided by a table from the National Interagency Fire Centers. Strangely the data are not offered in graphical form. You are forced to make your own, which is no problem. Most people however simply are left in the dark. Steven Goddard (Tony Heller) shows such a charts at his Real Science blog.


2004 – 2014 burn acreage trend is falling. Chart source: Tony Heller.
One cannot always just pull climate change at of his magic hat every time a forest fire appears. The University of Colorado at Boulder recently calculated that 84% of all forest and bush fires in den USA are caused by humans. Read the press release from February 2017:
Humans have dramatically increased extent, duration of wildfire season
Humans have dramatically increased the spatial and seasonal extent of wildfires across the U.S. in recent decades and ignited more than 840,000 blazes in the spring, fall and winter seasons over a 21-year period, according to new University of Colorado Boulder-led research. After analyzing two decades’ worth of U.S. government agency wildfire records spanning 1992-2012, the researchers found that human-ignited wildfires accounted for 84 percent of all wildfires, tripling the length of the average fire season and accounting for nearly half of the total acreage burned. The findings were published today in the journal Proceedings of the National Academy of Sciences.
“There cannot be a fire without a spark,” said Jennifer Balch, Director of CU Boulder’s Earth Lab and an assistant professor in the Department of Geography and lead author of the new study. “Our results highlight the importance of considering where the ignitions that start wildfires come from, instead of focusing only on the fuel that carries fire or the weather that helps it spread. Thanks to people, the wildfire season is almost year-round.”  The U.S. has experienced some of its largest wildfires on record over the past decade, especially in the western half of the country. The duration and intensity of future wildfire seasons is a point of national concern given the potentially severe impact on agriculture, ecosystems, recreation and other economic sectors, as well as the high cost of extinguishing blazes. The annual cost of fighting wildfires in the U.S. has exceeded $2 billion in recent years.
The CU Boulder researchers used the U.S. Forest Service Fire Program Analysis-Fire Occurrence Database to study records of all wildfires that required a response from a state or federal agency between 1992 and 2012, omitting intentionally set prescribed burns and managed agricultural fires. Human-ignited wildfires accounted for 84 percent of 1.5 million total wildfires studied, with lightning-ignited fires accounting for the rest. In Colorado, 30 percent of wildfires from 1992-2012 were started by people, burning over 1.2 million acres. The fire season length for human-started fires was 50 days longer than the lightning-started fire season (93 days compared to 43 days), a twofold increase. “These findings do not discount the ongoing role of climate change, but instead suggest we should be most concerned about where it overlaps with human impact,” said Balch. “Climate change is making our fields, forests and grasslands drier and hotter for longer periods, creating a greater window of opportunity for human-related ignitions to start wildfires.”
While lightning-driven fires tend to be heavily concentrated in the summer months, human-ignited fires were found to be more evenly distributed across all seasons. Overall, humans added an average of 40,000 wildfires during the spring, fall and winter seasons annually—over 35 times the number of lightning-started fires in those seasons. “We saw significant increases in the numbers of large, human-started fires over time, especially in the spring,” said Bethany Bradley, an associate professor at University of Massachusetts Amherst and co-lead author of the research. “I think that’s interesting, and scary, because it suggests that as spring seasons get warmer and earlier due to climate change, human ignitions are putting us at increasing risk of some of the largest, most damaging wildfires.” “Not all fire is bad, but humans are intentionally and unintentionally adding ignitions to the landscape in areas and seasons when natural ignitions are sparse,” said John Abatzoglou, an associate professor of geography at the University of Idaho and a co-author of the paper. “We can’t easily control how dry fuels get, or lightning, but we do have some control over human started ignitions.”
The most common day for human-started fire by far, however, was July 4, with 7,762 total wildfires started on that day over the course of the 21-year period. The new findings have wide-ranging implications for fire management policy and suggest that human behavior can have dramatic impact on wildfire totals, for good or for ill. “The hopeful news here is that we could, in theory, reduce human-started wildfires in the medium term,” said Balch. “But at the same time, we also need to focus on living more sustainably with fire by shifting the human contribution to ignitions to more controlled, well-managed burns.” Co-authors of the new research include Emily Fusco of the University of Massachusetts Amherst and Adam Mahood and Chelsea Nagy of CU Boulder. The research was funded by the NASA Terrestrial Ecology Program, the Joint Fire Sciences Program and Earth Lab through CU Boulder’s Grand Challenge Initiative.”
In July 2017 the Institute for Basic Science explained that the risk of forest fires on the US Southwest was strongly dependent on the temperature differences between the Pacific and Atlantic Oceans. Ultimately the ocean cycles are the real drivers. Press release (via Science Daily):

Atlantic/Pacific ocean temperature difference fuels US wildfires
New study shows that difference in water temperature between the Pacific and the Atlantic oceans together with global warming impact the risk of drought and wildfire in southwestern North America
An international team of climate researchers from the US, South Korea and the UK has developed a new wildfire and drought prediction model for southwestern North America. Extending far beyond the current seasonal forecast, this study published in the journal Scientific Reports could benefit the economies with a variety of applications in agriculture, water management and forestry.

Over the past 15 years, California and neighboring regions have experienced heightened drought conditions and an increase in wildfire numbers with considerable impacts on human livelihoods, agriculture, and terrestrial ecosystems. This new research shows that in addition to a discernible contribution from natural forcings and human-induced global warming, the large-scale difference between Atlantic and Pacific ocean temperatures plays a fundamental role in causing droughts, and enhancing wildfire risks.
‘Our results document that a combination of processes is at work. Through an ensemble modeling approach, we were able to show that without anthropogenic effects, the droughts in the southwestern United States would have been less severe,’ says co-author Axel Timmermann, Director of the newly founded IBS Center for Climate Physics, within the Institute for Basics Science (IBS), and Distinguished Professor at Pusan National University in South Korea. ‘By prescribing the effects of human-made climate change and observed global ocean temperatures, our model can reproduce the observed shifts in weather patterns and wildfire occurrences.’
The new findings show that a warm Atlantic and a relatively cold Pacific enhance the risk for drought and wildfire in the southwestern US. ‘According to our study, the Atlantic/Pacific temperature difference shows pronounced variations on timescales of more than 5 years. Like swings of a very slow pendulum, this implies that there is predictability in the large-scale atmosphere/ocean system, which we expect will have a substantial societal benefit,’ explains Yoshimitsu Chikamoto, lead author of the study and Assistant Professor at the University of Utah in Logan.
The new drought and wildfire predictability system developed by the authors expands beyond the typical timescale of seasonal climate forecast models, used for instance in El Niño predictions. It was tested with a 10-23 month forecasting time for wildfire and 10-45 for drought. ‘Of course, we cannot predict individual rainstorms in California and their local impacts months or seasons ahead, but we can use our climate computer model to determine whether on average the next year will have drier or wetter soils or more or less wildfires. Our yearly forecasts are far better than chance,’ states Lowell Stott, co-author of the study from the University of Southern California in Los Angeles.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Bringing together observed and simulated measurements on ocean temperatures, atmospheric pressure, water soil and wildfire occurrences, the researchers have a powerful tool in their hands, which they are willing to test in other regions of the world: ‘Using the same climate model configuration, we will also study the soil water and fire risk predictability in other parts of our world, such as the Mediterranean, Australia or parts of Asia,’ concludes Timmermann. ‘Our team is looking forward to developing new applications with stakeholder groups that can benefit from better soil water forecasts or assessments in future fire risk.’
Paper: Yoshimitsu Chikamoto, Axel Timmermann, Matthew J. Widlansky, Magdalena A. Balmaseda, Lowell Stott. Multi-year predictability of climate, drought, and wildfire in southwestern North America. Scientific Reports, 2017; 7 (1) DOI: 10.1038/s41598-017-06869-7″



Ocean cycles (El Nino, La Nina) were also identified by Mason et al. 2017 as the forest fire drivers in the USA:
Effects of climate oscillations on wildland fire potential in the continental United States
The effects of climate oscillations on spatial and temporal variations in wildland fire potential in the continental U.S. are examined from 1979 to 2015 using cyclostationary empirical orthogonal functions (CSEOFs). The CSEOF analysis isolates effects associated with the modulated annual cycle and the El Niño–Southern Oscillation (ENSO). The results show that, in early summer, wildland fire potential is reduced in the southwest during El Niño but is increased in the northwest, with opposite trends for La Niña. In late summer, El Niño is associated with increased wildland fire potential in the southwest. Relative to the mean, the largest impacts of ENSO are observed in the northwest and southeast. Climate impacts on fire potential due to ENSO are found to be most closely associated with variations in relative humidity. The connections established here between fire potential and climate oscillations could result in improved wildland fire risk assessment and resource allocation.”
El Nino also plays a large role in the US Northwest for controlling driving forst fires, according to Barbero et al. 2015:
Seasonal reversal of the influence of El Niño–Southern Oscillation on very large wildfire occurrence in the interior northwestern United States
Satellite-mapped fire perimeters and the multivariate El Niño–Southern Oscillation index were used to examine the impact of concurrent El Niño–Southern Oscillation (ENSO) phase on very large fire (VLF) occurrences over the intermountain northwestern United States (U.S.) from 1984 to 2012. While the warm phase of ENSO promotes drier and warmer than normal conditions across the region during winter and spring that favor widespread fire activity the following summer, a reduction in VLFs was found during the warm phase of ENSO during summer concurrent with the fire season. This paradox is primarily tied to an anomalous upper level trough over the western U.S. and positive anomalies in integrated water vapor that extend over the northwestern U.S. during summers when the warm phase of ENSO is present. Collectively, these features result in widespread increases in precipitation amount during the summer and a curtailment of periods of critically low-fuel moistures that can carry wildfire.”
Overall forest fires in the USA have decreased significantly compared to the previous century (see article by Larry Kummer at Fabius Maximus).
In Colorado no forest fire trend could be found over the past centuries, see the press release from the University of Colorado issued in 2014:
Colorado’s Front Range fire severity today not much different than in past, says CU-Boulder study
The perception that Colorado’s Front Range wildfires are becoming increasingly severe does not hold much water scientifically, according to a massive new study led by the University of Colorado Boulder and Humboldt State University in Arcata, Calif. The study authors, who looked at 1.3 million acres of ponderosa pine and mixed conifer forest from Teller County west of Colorado Springs through Larimer County west and north of Fort Collins, reconstructed the timing and severity of past fires using fire-scarred trees and tree-ring data going back to the 1600s. Only 16 percent of the study area showed a shift from historically low-severity fires to severe, potential crown fires that can jump from treetop to treetop.
The idea that modern fires are larger and more severe as a result of fire suppression that allowed forest fuels to build up in the past century is still prevalent among some, said CU-Boulder geography Professor Thomas Veblen, a study co-author. ‘The key point here is that modern fires in these Front Range forests are not radically different from the fire severity of the region prior to any effects of fire suppression,’ he said. A paper on the subject was published Sept. 24 in the journal PLOS ONE. The study was led by Associate Professor Rosemary Sherriff of Humboldt State University and involved Research Scientist Tania Schoennagel of CU-Boulder’s Institute of Arctic and Alpine Research, CU-Boulder doctoral student Meredith Gartner and Associate Professor Rutherford Platt of Gettysburg College in Gettysburg, Pa. The study was funded by the National Science Foundation.
‘The common assumption is that fires are now more severe and are killing higher percentages of trees,’ said Sherriff, who completed her doctorate at CU-Boulder under Veblen in 2004. ‘Our results show that this is not the case on the Front Range except for the lowest elevation forests and woodlands.’ One important new finding comes from a comparison of nine large fires that have occurred on the Front Range since 2000 — including the 2002 Hayman Fire southwest of Denver, the 2010 Fourmile Canyon Fire west of Boulder and the 2012 High Park Fire west of Fort Collins — with historic fire effects in the region. ‘It’s true that the Colorado Front Range has experienced a number of large fires recently,’ said Schoennagel. ‘While more area has burned recently compared to prior decades – with more homes coming into the line of fire – the severity of recent fires is not unprecedented when we look at fire records going back before the 1900s.’
In addition, tree-ring evidence from the new study shows there were several years on the Front Range since the 1650s when there were very large, severe fires. The authors looked at more than 1,200 fire-scarred tree samples and nearly 8,000 samples of tree ages at 232 forest sample sites from Teller County to Larimer County. The study is one of the largest of its kind ever undertaken in the western United States. The team was especially interested in fire records before about 1920, when effective fire suppression in the West began in earnest. ‘In relatively dry ponderosa pine forests of the West, a common assumption is that fires were relatively frequent and of low severity, and not lethal to most large trees, prior to fuel build-up in the 20th century,’ said Veblen. ‘But our study results showed that about 70 percent of the forest study area experienced a combination of moderate and high-severity fires in which large percentages of the mature trees were killed.’
Along the Front Range, especially at higher elevations, homeowners and fire managers should expect a number of high-severity fires unrelated to any kind of fire suppression and fuel build-up, said Schoennagel. ‘This matters because high-severity fires are dangerous to people, kill more trees and are trickier and more expensive to suppress.” “Severe fires are not new to most forests in this region,’ said Sherriff. ‘What is new is the expanded wildland-urban interface hazard to people and property and the high cost of suppressing fires for society.’ In addition, a warming Colorado climate — 2 degrees Fahrenheit since 1977 — has become a wild card regarding future Front Range fires, according to the team. While fires are dependent on ignition sources and can be dramatically influenced by high winds, the team expects to see a substantial increase in Front Range fire activity in the low and mid-elevations in the coming years as temperatures continue to warm, a result of rising greenhouses gases in Earth’s atmosphere.”
2016 was a bad year of forest fires in California. Al Gore immediately pointed the finger at climate change. But later it was discovered that a series of arsons was behind most of the fires. The house of climate alarm quickly collapsed. Also the University of Arizona found that the fires were promoted by poor land use practices. Press release:

Forest Fires in Sierra Nevada Driven by Past Land Use
Changes in human uses of the land have had a large impact on fire activity in California’s Sierra Nevada since 1600, according to research by a UA researcher and her colleagues.
Forest fire activity in California’s Sierra Nevada since 1600 has been influenced more by how humans used the land than by climate, according to new research led by University of Arizona and Penn State scientists. For the years 1600 to 2015, the team found four periods, each lasting at least 55 years, where the frequency and extent of forest fires clearly differed from the time period before or after. However, the shifts from one fire regime to another did not correspond to changes in temperature or moisture or other climate patterns until temperatures started rising in the 1980s. ‘We were expecting to find climatic drivers,’ said lead co-author Valerie Trouet, a UA associate professor of dendrochronology. ‘We didn’t find them.’
Instead, the team found the fire regimes corresponded to different types of human occupation and use of the land: the pre-settlement period to the Spanish colonial period; the colonial period to the California Gold Rush; the Gold Rush to the Smokey Bear/fire suppression period; and the Smokey Bear/fire suppression era to present. ‘The fire regime shifts we see are linked to the land-use changes that took place at the same time,’ Trouet said. ‘We knew about the Smokey Bear effect — there had been a dramatic shift in the fire regime all over the Western U.S. with fire suppression. We didn’t know about these other earlier regimes,’ she said. ‘It turns out humans — through land-use change — have been influencing and modulating fire for much longer than we anticipated.’
Finding that fire activity and human land use are closely linked means people can affect the severity and frequency of future forest fires through managing the fuel buildup and other land management practices — even in the face of rising temperatures from climate change, she said. The team’s paper, ‘Socio-Ecological Transitions Trigger Fire Regime Shifts and Modulate Fire-Climate Interactions in the Sierra Nevada, USA 1600-2015 CE,’ was scheduled for publication in the online Early Edition of the Proceedings of the National Academy of Sciences this week. Trouet’s co-authors are Alan H. Taylor of Penn State, Carl N. Skinner of the U.S. Forest Service in Redding, California, and Scott L. Stephens of the University of California, Berkeley.
Initially, the researchers set out to find which climate cycles, such as the El Niño/La Niña cycle or the longer Pacific Decadal Oscillation, governed the fire regime in California’s Sierra Nevada. The team combined the fire history recorded in tree rings from 29 sites all along the Sierra Nevada with a 20th-century record of annual area burned. The history spanned the years 1600 to 2015. However, when large shifts in the fire history were compared to past environmental records of temperature and moisture, the patterns didn’t match. Other researchers already had shown that in the Sierra, there was a relationship between forest fire activity and the amount of fuel buildup. Team members wondered whether human activity over the 415-year period had changed the amount of fuel available for fires.
By using a technique called regime shift analysis, the team found four distinct time periods that differed in forest fire activity. The first was 1600 to 1775. After 1775, fire activity doubled. Fire activity dropped to pre-1775 levels starting in 1866. Starting in 1905, fire activity was less frequent than any previous time period. In 1987, fire activity started increasing again. However, the frequency of forest fires did not closely track climatic conditions, particularly after 1860. The researchers reviewed historical documents and other evidence and found the shifting patterns of fire activity most closely followed big changes in human activity in the region. Before the Spanish colonization of California, Native Americans regularly set small forest fires. The result was a mosaic of burned and unburned patches, which reduced the amount of fuel available to fires and limited the spread of any particular fire.
However, once the Spanish arrived in 1769, Native American populations rapidly declined because of disease and other causes. In addition, the Spanish government banned the use of fire. Without regular fires, fuels built up, leading to more and larger fires. The influx of people to California during the Gold Rush that began in 1848 reduced fire activity. The large numbers of livestock brought by the immigrants grazed on the grasses and other plants that would otherwise have been fuel for forest fires. In 1904, the U.S. government established a fire suppression policy on federal lands. After that, fire activity dropped to its lowest level since 1600. Starting in the 1980s, as the climate warms, fire frequency and severity has increased again. Fires now can be ‘bad’ fires because of a century or more of fire suppression, according to lead co-author Taylor, a professor of geography at Penn State. ‘It is important for people to understand that fires in the past were not necessarily the same as they are today,’ Taylor said. ‘They were mostly surface fires. Today we see more canopy-killing fires.’”

Share this...FacebookTwitter "
"
Share this...FacebookTwitterCO2 as the major climate driver looks shakier than ever.
Scientists confirm clouds and their changes have a huge impact on the earth’s surface temperature…

Anna Possner’s research shows clouds and their changes have a real impact on earth’s surface temperature, a Goethe University press release confirms. Photo source: annapossner.com, Carnegie Science.
According to Germany’s Goethe University, Carnegie Institution for Science climatologist Anna Possner’s research on layered clouds in the lower atmosphere shows that clouds “act as a semi-transparent parasol” and “reflect a significant portion of incoming sunlight” and “have a cooling effect on Earth’s surface.” …and that cloud changes “can result in significant changes to Earth’s surface temperature”.

Clouds like a semi-transparent parasol
Released at: Wed, 09 May 2018 13:40:00 +0200 (024)
FRANKFURT. Following the Paris Climate Agreement, Germany and France created the program “Make Our Planet Great Again,“ to promote climate change research. One of 13 researchers selected by an expert jury of the German Academic Exchange Service (DAAD) is coming from the USA to the Goethe University in a few months.
The climate change researcher Dr. Anna Possner is leaving the renowned Carnegie Institution for Science in Stanford and will join the Department for Atmospheric and Environmental Sciences at the Goethe University. Thanks to a one million euro grant, she will start her own research group in Frankfurt. This group will cooperate with the Frankfurt Institute for Advanced Studies (FIAS), where it will also be located.
Anna Possner’s research focuses on layered clouds in the lowest kilometres of the atmosphere, which act as a semi-transparent parasol for Earth’s surface. They reflect a significant portion of incoming sunlight, but only marginally affect Earth’s heat emission. They thus have a cooling effect on Earth’s surface. Any sheet of low-level cloud may span hundreds of kilometres and all together they span around one fifth of Earth’s oceans. Changes in their areal extent or reflective properties can result in significant changes to Earth’s surface temperature.
In some regions of the globe, the mid-latitudes and the Arctic, these clouds consist not only of water drops, but may contain a mixture of ice particles and water drops. The proportion of water drops to ice crystals affects the clouds’ reflective properties. “While we have hypotheses about how the radiative properties may be affected within a single cloud,” Anna Possner explains, “we are limited in our understanding of how the presence of ice crystals impacts the areal coverage and reflective properties on the scale of an entire cloud field.” She will use satellite retrievals and sophisticated numerical models to help answer this question.
Since completing her doctoral dissertation at the ETH Zurich, Anna Possner, who was born in Jena, has studied the impact of particles on the reflective properties of clouds. During this time she focused in particular on low-lying clouds over the oceans, where she quantified and evaluated the impact of ship emissions on clouds. During her postdoc years at the ETH Zurich and the Carnegie Institution for Science in Stanford, she extended her analyses to include mixed-phase clouds.
The German-French program “Make Our Planet Great Again“ seeks to support the creation of solid facts as a basis for political decisions in the fields “climate change”, “earth system research” and “energy transformation”. Of the 13 scientists selected for Germany, seven are in the US, two were most recently working in Great Britain and one each is in Switzerland, Canada, South Korea and Australia. They were selected during a two-stage process out of approximately 300 applications.
Further Information: Prof. Joachim Curtius, Department for Atmospheric and Environmental Sciences, Faculty for Geosciences / Geography, Riedberg Campus, Tel.: +49 (0) 798-42058, curtius@iau.uni-frankfurt.de.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA new research institute in Switzerland set to rock the climate science boat…will investigate natural causes of climate change. Director calls claims CO2 the main driver and a pollutant “absurd”.

Swiss institute director and climate scientist Hans-Joachim Dammschneider says natural factors in large part behind recent climate change. Photo credit: IFHGK
The Swiss Basler Zeitung (BZ) reported on April 13, 2018, that a new research institute opened at Lake Aegeri in Switzerland last year: the Institute for Hydrography, Geo-ecology and Climate Sciences (IFHGK), which will focus on the natural causes of climate change.
Contrary to the other government-funded institutes, the IFHGK focusses on the natural causes of climate change: the Institute for Geo-ecology and Climate Sciences wishes to show that CO2 is not necessarily the main driver behind global warming and thus goes against the alleged broad consensus among mainstream researchers, the Baseler Zeitung writes.
A real climate scientist
The new institute, founded at the start of 2017, is located in Oberägeri, Switzerland is directed by Hans-Joachim Dammschneider. who according to the BZ explained:
Unlike many others who speak on the subject of global warming, I’m actually a climate scientist.”
The institute consists of scientists who work on a volunteer basis and operates on a shoestring. Decisive in the founding of the institute was Dr. Hans-Joachim Dammschneider’s encounter with Dr. Sebastian Lüning, who together with Prof. Fritz Vahrenholt wrote the Spiegel bestseller “Die kalte Sonne“,  which upset German mainstream climate science. Lüning also runs the Die kalte Sonne climate site, where he posts daily.
Looking at climate science with “calm, common sense and reason”
Dr. Lüning, a geologist, long ago concluded that the mainstream climate scientists have navigated themselves into a dead end. Dammschneider told the BZ that the institute will look at the issues with “calm, common sense and understanding.”
Dammschneider, who considers himself a climate realist, says that it is absurd that CO2 has been designated a pollutant and that the substance is mainly to blame for es climate change. Dr. Dammschneider is a leading German expert in the field of geography, climate research, oceanography and geology.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The BZ reports that already Dammschneider has published some papers in their own publication series and that he specializes in the field of periodic temperatures changes of the oceans, which have a direct impact on the atmosphere. He told the BZ:
The atmospheric temperatures tend to correspond with the oscillations of the oceans and are subject to a comparable pattern.”
Today’s warmth “not unique”
The German-born researcher believes it is essential to record these changes and to see if the climate changes are normal, or if they only have existed since man started burning fossil fuels.
His research and the findings of Sebastian Lüning for the North African region show that during the period of the year 1000 to 1200 A.D. it was similarly as warm as it is today. The BZ writes:
The works of Lüning and his team show that during this period very optimal climate conditions predominated. They also indicate that today’s warm period is not unique.”
The fear to dissent
On the future success of the institute, the BZ writes that Dammschnei­der is aware that it’s going to be a long and difficult road, saying that “young climate scientists as a rule cannot afford to question asserted truths if they do not want to endanger their careers. Thus the new climate science skeptic institute will have to rely on support from independent scientists and retired professors who are free to speak without the fear of harsh consequences.
Funding needed
The BZ writes that the institute is working to gain public attention, but is in need of funding. However: “business sponsors look promising, and so it hopes to employ some workers,” the BZ reports.
Concerning the widespread alarmism over man-made climate change, Dammschneider told the BZ:
Sooner or later they will have to soften the positions they’ve held so far.”
Read the entire story in German at the Basler Zeitung
Share this...FacebookTwitter "
"
Share this...FacebookTwitterDuring 2017, there were 150 graphs from 122 scientific papers published in peer-reviewed journals indicating modern temperatures are not unprecedented, unusual, or hockey-stick-shaped — nor do they fall outside the range of natural variability.  We are a little over 4 months into the new publication year and already 81 graphs from 62 scientific papers undermine claims that modern era warming is climatically unusual.



Zheng et al., 2018
“In this study we present a detailed GDGT data set covering the last 13,000 years from a peat sequence in the Changbai Mountain in NE China. The brGDGT-based temperature reconstruction from Gushantun peat indicates that mean annual air temperatures in NE China during the early Holocene were 5–7°C higher than today.  Furthermore, MAAT records from the Chinese Loess Plateau also suggested temperature maxima 7–9°C higher than modern during the early Holocene (Peterse et al., 2014; Gao et al., 2012; Jia et al., 2013). Consequently, we consider the temperatures obtained using the global peat calibration to be representative of climate in (NE) China. … The highest temperatures occurred between ca. 8 and 6.8 kyr BP, with occasional annual mean temperatures >8.0 ± 4.7°C, compared to the modern-day MAAT of ∼3°C.”


Anderson et al., 2018
“We estimate that air temperatures were 2.5–3.0 °C higher during the Holocene Thermal Maximum than the local 1960–1990 average. … Between 1700 and 1925 CE temperatures were likely 0.6–0.8 °C lower than the 1950–2015 reference temperature.“


Harning et al., 2018
“Iceland’s terrestrial HTM [Holocene Thermal Maximum] has previously been constrained to ~7.9 to 5.5 ka based on qualitative lake sediment proxies (Larsen et al., 2012; Geirsdottir et al., 2013), likely in association with progressive strengthening and warming of the Irminger Current (Castaneda et al., 2004; Smith et al., 2005; Olafsdottir et al., 2010). Numerical modeling experiments for Drangajokull suggest that peak air temperatures were 2.5 – 3°C warmer at this time relative to the 1961-1990 CE average (Anderson et al., 2018). … During the Little Ice Age (LIA, 1250-1850 CE), the Vestfirðir region entered the lowest multi centennial spring/summer temperature anomalies of the last 9 ka. Based on recent numerical  modeling simulations, this anomaly is estimated to be 0.6-0.8°C below the 1950-2015 average on Vestfirðir (Anderson et al., 2018).”



Grieman et al., 2018
“[C]limate anomalies appear to be reflected in the Tunu VA [vanillic acid] record, with elevated VA [vanillic acid] during the warm periods and lower levels during the colder periods. The data suggest a positive correlation between North American fire and hemispheric mean temperature. This relationship could be due to climate-driven changes in temperature or precipitation on burning extent, frequency, or location, as well as to changes in atmospheric transport patterns. …  … [E]levated VA [vanillic acid] early in the record [Roman Warm Period] and around the MCA [Medieval Climate Anomaly]. It also emphasizes the decreasing trend from 1200-1900 CE [Little Ice Age] and the increase during the 20th century [Current Warm Period].”



Thornalley et al., 2018


Maley et al., 2018


Polovodova Asteman et al., 2018
“The record demonstrates a warming during the Roman Warm Period (~350 BCE – 450 CE), variable bottom water temperatures during the Dark Ages (~450 – 850 CE), positive bottom water temperature anomalies during the Viking Age/Medieval Climate Anomaly (~850 – 1350 CE) and a long-term cooling with distinct multidecadal variability during the Little Ice Age (~1350 – 1850 CE). The fjord BWT [bottom water temperatures] record also picks up the contemporary warming of the 20th century, which does not stand out in the 2500-year perspective and is of the same magnitude as the Roman Warm Period and the Medieval Climate Anomaly.”



Wündsch et al., 2018


McGowan et al., 2018
“Our reconstructed Tmax [temperature maximum] for these warmer conditions peaks around 1390 CE at + 0.8 °C above the 1961–90 mean, similar to the peak Tmax during the RWP [Roman Warm Period]. These results are aligned with the findings that show the period from 1150 to 1350 CE to be the warmest pre-industrial chronzone of the past 1000 yrs for southeast Australia.”


Wu et al., 2018


Hanna et al., 2018
“Reconstructed temperatures are generally coolest between 300 and 800 CE (Tavg = 2.24 ± 0.98°C), displaying three temperature minima centered at 410 CE (1.34 ± 0.72°C), 545 CE (1.91 ± 0.69°C), and 705 CE (1.49 ± 0.69°C). Temperatures then rapidly increased, reaching the warmest interval (800–1000 CE) in the approximately 1700-year record. During this interval, average temperatures were 3.31 ± 0.65°C, with a maximum temperature of 3.98°C.”


Li et al., 2018
“There are also other studies that suggest that the recent climate warming over the southeastern TP actually began in the 1820s (Shi et al., 2015). However, a few reconstructions from the west and northwest parts of Sichuan or from the southeastern TP indicate that there were no obvious increase of temperature during the past decades (Li et al., 2015b; Zhu et al., 2016).”
 


Qin et al., 2018     


Allen et al., 2018
“The longest sustained period of relatively high temperatures in the reconstructions is the post 1950 CE period although there are clearly individual years much earlier that were warmer than any in the post-1950 period.”


Li et al, 2018   (North China)


Levy et al., 2018
“The three historical moraine crests indicate that there were at least three ice-margin stillstands or advances during historical time. Summer temperature records from North lake (Axford et al. 2013) and Lake N3 (Thomas et al. 2016) broadly register cooling in the past 200 years in western Greenland, which likely influenced the advance to the historical moraines.”


Perner et al., 2018
“From c. 1.5 ka BP onwards, we record a prominent subsurface cooling and continued occurrence of fresh and sea‐ice loaded surface waters at the study site.”



Zhang et al., 2018



Guo et al., 2018


Belle et al., 2018


Lemmen and Lacourse, 2018
“The early Holocene was marked by relatively stable temperatures that exceeded modern by ~2 to 3°C. Inferred temperatures generally decrease through the remainder of the Holocene.”




Oppedal et al., 2018


Blundell et al., 2018     


Badino et al., 2018     
“Between ca. 8.4-4 ka cal BP [8,400 to 4,000 years before present], our site [Italian Alps] experienced a mean TJuly of ca. 12.4 °C, i.e. 3.1 °C warmer than today [9.3 °C]. … Between 7400 and 3600 yrs cal BP, an higher-than-today forest line position persisted under favorable growing conditions (i.e. TJuly at ca. 12 °C).”



Song et al., 2018
“[A] general warm to cold climate trend from the mid-Holocene to the present, which can be divided into two different stages: a warmer stage between 6842 and 1297 cal yr BP and a colder stage from 1297 cal yr BP to the present.”


Blarquez et al., 2018


Perner et al., 2018
“[W]e find evidence of distinct late Holocene millennial-scale phases of enhanced El Niño/La Niña development, which appear synchronous with northern hemispheric climatic variability. … Phases of dominant El Niño-like states occur parallel to North Atlantic cold phases: the ‘2800 years BP cooling event’, the ‘Dark Ages’ and the ‘Little Ice Age’, whereas the ‘Roman Warm Period’ and the ‘Medieval Climate Anomaly’ parallel periods of a predominant La Niña-like state.”


 Magyari et al., 2018
“…its climatic tolerance limits were used to infer July mean temperatures exceeding modern values by 2.8°C at this time [8200-6700 cal yr BP] (Magyari et al., 2012).”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Mikis, 2018


Kelley et al., 2018
“Historical and remote-sensing records indicate that Nordenskiöld Gletscher has been stable or advancing since AD 1950 (Weidick, 1968, 1994).”


Papadomanolaki et al., 2018  (Baltic Sea)
“A large fraction of the Baltic Proper became hypoxic again between 1.4 and 0.7 ka BP, during the Medieval Climate Anomaly (MCA), when mean air temperatures were 0.9–1.4 °C higher than temperatures recorded in the period 1961–1990 (e.g. Mann et al., 2009; Jilbert and Slomp, 2013).”

Leonard et al., 2018  (Great Barrier Reef, Australia)
“Coral derived sea surface temperature (SST-Sr/Ca) reconstructions demonstrate conditions ∼1 ◦C warmer than present at ∼6200 (recalibrated 14C) and 4700 yr BP, with a suggested increase in salinity range (δ18O) associated with amplified seasonal flood events, suggestive of La Niña (Gagan et al., 1998; Roche et al., 2014).”

Suvorov and Kitov, 2018 (Eastern Sayan, Siberia)
“The authors examined the variability of activity of modern glaciation and variation of natural conditions of the periglacial zone on climate and on dendrochronological data. Results of larch and Siberian stone pine growth data were revealed at the higher border of forest communities. …  It is believed that the temperature could be 3.5 °C warmer at the Holocene optimum than at the present time (Vaganov and Shiyatov 2005). … Since 2000, there has been growth of trees instability associated with a decrease in average monthly summer temperatures. …  Since the beginning of 2000, decrease in summer temperatures was marked.”

Lozhkin et al., 2018 (East Siberia)
“The postglacial occurrence of relatively warm/dry and warm/wet intervals is consistent with results of a regional climate‐model simulation that indicates warmer than present temperatures and decreased effective moisture at 11 000 cal. a BP and persistence of warm conditions but with greater moisture and longer growing season at 6000 cal. a BP.”

Xu et al., 2018 (Northern South China Sea)
“This study provides evidence that thermal coral bleaching events have occurred in the warmer mid-Holocene (where maximum monthly summer SST was 2 °C higher than at present) in Hainan island.  … [C]oral bleaching events under high SST conditions have already occurred in the mid-Holocene and are by no means a new ecological phenomenon of current global warming.”

20th/21st Centuries Non-Warming

Lansner and Pepke Pedersen, 2018
“In locations best sheltered and protected against ocean air influence, the vast majority of thermometers worldwide trends show temperatures in recent decades rather similar to the 1920–1950 period. This indicates that the present-day atmosphere and heat balance over the Earth cannot warm areas – typically valleys – worldwide in good shelter from ocean trends notably more than the atmosphere could in the 1920–1950 period. … [T]he lack of warming in the OAS temperature trends after 1950 should be considered when evaluating the climatic effects of changes in the Earth’s atmospheric trace amounts of greenhouse gasses as well as variations in solar conditions.”













Partridge et al., 2018
“We present a novel approach to characterize the spatiotemporal evolution of regional cooling across the eastern U.S. (commonly called the U.S. warming hole), by defining a spatially explicit boundary around the region of most persistent cooling. The warming hole emerges after a regime shift in 1958 where annual maximum (Tmax) and minimum (Tmin) temperatures decreased by 0.46°C and 0.83°C respectively.”



Payomrat et al., 2018
“During the third segment (1870–2001), the maximum temperature pattern seemed to be constant compared to the changing rate (+0.004 °C/decade). … The short fourth segment, which occurred from 2002 to 2013, showed a deceasing trend at a rate of -0.12 °C/decade.”


Mikkelsen et al., 2018


Westergaard-Nielsen et al., 2018
“Here we quantify trends in satellite-derived land surface temperatures and modelled air temperatures, validated against observations, across the entire ice-free Greenland. … Warming trends observed from 1986–2016 across the ice-free Greenland is mainly related to warming in the 1990’s. The most recent and detailed trends based on MODIS (2001–2015) shows contrasting trends across Greenland, and if any general trend it is mostly a cooling. The MODIS dataset provides a unique detailed picture of spatiotemporally distributed changes during the last 15 years. … Figure 3 shows that on an annual basis, less than 36% of the ice-free Greenland has experienced a significant trend and, if any, a cooling is observed during the last 15 years (<0.15 °C change per year).”


Smeed et al., 2018


 Ahn et al., 2018


Eck, 2018     
“[A] majority (12/14) of the regions within the SAM [Southern Appalachian Mountains] have experienced a long-term decline in mean winter temperatures since 1910.  Even after removing the highly anomalous 2009-2010 winter season, which was more than two standard deviations away from the long-term mean, the cooling of mean winter temperatures is still evident. … Higher winter temperatures dominated the early 20th century in the SAM [Southern Appalachian Mountains] with nine of the ten warmest winter seasons on record in the region having occurred before 1960. The 1931-1932 winter season, the warmest on record, averaged 8.0°C for DJF [December-February], nearly 4.7°C higher than the 1987-2017 normal mean winter temperature of 3.3°C. … Despite the 2016-2017 winter season finishing with the highest mean temperatures (5.7ºC) observed in the SAM [Southern Appalachian Mountains]  since 1956-1957, there have been several years of anomalous negative temperature anomalies, with the 2009-2010 (0.3ºC) and 2010-2011 (1.2ºC) winter seasons finishing as two of the coldest on record for all regions.”


Yi, 2018


Nicolle et al., 2018     



Purich et al., 2018     
“Observed Southern Ocean changes over recent decades include a surface freshening (Durack and Wijffels 2010; Durack et al. 2012; de Lavergne et al. 2014), surface cooling (Fan et al. 2014; Marshall et al. 2014; Armour et al. 2016; Purich et al. 2016a) and circumpolar increase in Antarctic sea ice (Cavalieri and Parkinson 2008; Comiso and Nishio 2008; Parkinson and Cavalieri 2012).  …  Our results suggest that recent multi-decadal trends in large-scale surface salinity over the Southern Ocean have played a role in the observed surface cooling seen in this region. … The majority of CMIP5 models do not simulate a surface cooling and increase in sea ice, as seen in observations.”


Palmer et al., 2018


Clem et al., 2018
“This study finds recent (post-1979) surface cooling of East Antarctica during austral autumn to also be tied to tropical forcing, namely, an increase in La Niña events. … The South Atlantic anticyclone is associated with cold air advection, weakened northerlies, and increased sea ice concentrations across the western East Antarctic coast, which has increased the rate of cooling at Novolazarevskaya and Syowa stations after 1979. This enhanced cooling over western East Antarctica is tied more broadly to a zonally asymmetric temperature trend pattern across East Antarctica during autumn that is consistent with a tropically forced Rossby wave rather than a SAM pattern; the positive SAM pattern is associated with ubiquitous cooling across East Antarctica.”


Kim et al., 2018     
“Recent surface cooling in the Yellow and East China Seas and the associated North Pacific climate regime shift … The Yellow and East China Seas (YECS) are widely believed to have experienced robust, basin-scale warming over the last few decades. However, the warming reached a peak in the late 1990s, followed by a significant cooling trend.  … The most striking evolution pattern is that a robust warming trend at a rate of +0.40°C per decade reached a peak in the late 1990s, and then it turned downward at a rate of  −0.36°C per decade. The positive and then negative trends are estimated throughout the YECS for the periods 1982−1997.”


Shu et al., 2018
“The link between boreal winter cooling over the midlatitudes of Asia and the Barents Oscillation (BO) since the late 1980s is discussed in this study, based on five datasets. Results indicate that there is a large-scale boreal winter cooling during 1990–2015 over the Asian midlatitudes, and that it is a part of the decadal oscillations of long-term surface air temperature (SAT) anomalies.”


Mallory et al., 2018


Jones et al., 2018


Burger et al., 2018
“Previous studies have identified spatial and temporal trends in temperature and precipitation in Chile over recent decades. Temperature rose significantly during the mid to late 20th century in coastal locations between 18 to 33 °S (Rosenblüth et al., 1997), but then started to decrease, with a cooling trend up to -0.20ºC decade-1 dominating over the past 20-30 years (Falvey and Garreaud, 2009).”
 

Hrbáček et al., 2018
“Active layer monitoring in Antarctica: an overview of results from 2006 to 2015 … Air temperatures showed significant regional differences within the study areas. In the western Antarctic Peninsula region, Vestfold Hills and northern Victoria Land, a slight air temperature cooling was detected, while at other sites in Victoria Land and East Antarctica the air temperature was more irregular, showing no strong overall trend of warming or cooling during the study period (Figure 2). The Antarctic Peninsula region has been reported as the most rapidly warming part of Antarctica (e.g. Turner et al., 2005, 2014), but cooling has been reported since 2000 (Turner et al., 2016). Relatively stable air temperature conditions during the past 20 years were reported in Victoria Land (Guglielmin & Cannone, 2012).”


Ramesh and Soni, 2018
“The present paper reviews the progress of India’s scientific research in polar meteorology. The analysis of 25 years meteorological data collected at Maitri station for the period 1991–2015 is presented in the paper. The observed trend in the temperature data of 19 Antarctic stations obtained from READER project for the period 1991–2015 has also been examined. The 25 years long term temperature record shows cooling over Maitri station. The Maitri station showed cooling of 0.054 °C per year between 1991 and 2015, with similar pronounced seasonal trends. The nearby Russian station Novolazarevskaya also showed a cooling trend of 0.032 °C per year. … The temperature trend in average temperature of 19 Antarctica stations is also examined to ascertain the extent of cooling or warming trend (Supplementary Table_S1). The majority of stations in East Antarctica close to the coast show cooling or no significant trend. … Turner et al. (2016) using stacked temperature record found a significant cooling trend for the Antarctic Peninsula for the period 1999–2014.”


Gennaretti et al., 2018
 

Liu et al., 2018


Tang et al., 2018
“The study of Antarctic precipitation has attracted a lot of attention recently. The reliability of climate models in simulating Antarctic precipitation, however, is still debatable. This work assess the precipitation and surface air temperature (SAT) of Antarctica (90°S to 60°S) using 49 Coupled Model Intercomparison Project phase 5 (CMIP5) global climate models”


 Cerrone and Fusco, 2018  (Antarctica)
“Compelling evidence indicates that the large increase in the SH sea ice, recorded over recent years, arises from the impact of climate modes and their long-term trends. The examination of variability ranging from seasonal to interdecadal scales, and of trends within the climate patterns and total Antarctic sea ice concentration (SIC) for the 32-yr period (1982–2013), is the key focus of this paper. The results herein indicate that a progressive cooling has affected the year-to-year climate of the sub-Antarctic since the 1990s.”
Fernandoy et al., 2018  (Antarctic Peninsula)
“As shown by firn core analysis, the near-surface temperature in the northern-most portion of the Antarctic Peninsula shows a decreasing trend (−0.33°C year−1) between 2008 and 2014 [-1.98°C].”
Vignon et al., 2018  (Antarctica)
“The near‐surface Antarctic atmosphere experienced significant changes during the last decades (Steig et al., 2009; Turner et al., 2006). In particular, the near‐surface air over the Western part of Antarctica exhibits one of the major warming over the globe (Bromwich et al., 2013a), with heating rates larger than 0.5 K per decade at some places. Despite a significant warming in the end of the 20th century, the Antarctic Peninsula has been slightly cooling since 1998, reflecting the high natural variability of the climate in this region (Turner et al., 2016). East Antarctica has experienced a slight cooling trend (Nicolas & Bromwich, 2014; Smith & Polvani, 2017) particularly marked during autumn.”
Lei et al.,2018 (N, NE, SE China)
“The authors analyzed the observed winter surface air temperature in eastern mainland China during the recent global warming hiatus period through 1998-2013. The results suggest a substantial cooling trend of about -1.0°/decade in Eastern China, Northeast China and Southeast China.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterElectric Vehicle Emissions 27-50% Greater
Than Internal Combustion Engine Vehicles

Image: Qiao et al., 2017
Sales of electric vehicles (EV) in China have exploded in recent years.
According to the New York Times (October, 2017), between 2014 and 2017, annual EV purchases by China’s citizens more than doubled, from 145,000 in 2014 to 295,000 (projected) for 2017.   By 2019, the annual sales of EVs are expected to swell to 814,000 for China alone, which will eclipse the expected EV sales for the rest of the world combined (602,000).
Good news for the climate, right?  After all, driving an EV is green.  Driving an EV reduces CO2 emissions.   Driving an EV is sustainable.  Right?
Well, no.  According to recently published scientific papers, driving an EV in China dramatically increases CO2 emissions relative to driving an internal combustion engine vehicle (ICEV).
Why?  Because China’s electricity grid is overwhelmingly powered by fossil-fuels (i.e., 88% of China’s energy consumption  (2015) is derived from coal, oil and gas).   Therefore, the energy used to charge up an electric vehicle in China is derived from a rapidly growing fossil fuel-based electrical grid.
Fossil fuel-powered electricity grids are growing in prevalence across the world.  And this will continue to be the case as “1,600 coal plants are planned or under construction in 62 countries” which will “expand the world’s coal-fired power capacity by 43 percent” (New York Times, July, 2017).
As long as EVs continue to be predominantly powered by the growing fossil fuel infrastructure in China (“Chinese corporations are building or planning to build more than 700 new coal plants at home and around the world”), driving EVs will not reduce CO2 emissions relative to driving ICEVs.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Put another way, purchasing and driving a conventional internal combustion engine vehicle will actually reduce China’s CO2 emissions.
According to Barkenbus (2017), “when EVs receive electricity with emission levels exceeding 559 gCO2/kWh, they, unfortunately, are net contributors to climate change when compared with conventional vehicles.”
China’s EVs receive electricity with emissions levels of 712 gCO2/kWh, which is 27% greater than the emissions associated with driving the average ICEV.

Image: Barkenbus, 2017
Not only that, but as the introductory image above indicates, the manufacture of battery-powered EVs emit 50% more greenhouse gas emissions (CO2) than ICEVs do.
Qiao et al., 2017
“In this study, the life cycle energy consumption and greenhouse gas emissions of vehicle production are compared between battery electric and internal combustion engine vehicles in China’s context. … Greenhouse gas emissions of battery electric vehicles are 50% higher than internal combustion engine vehicles.”
“Electric Drive Vehicles (EDVs) are considered to be environmentally-friendly and have attracted much attention worldwide, and Battery Electric Vehicles (BEVs) are the most popular vehicles among all kinds of EDVs. In China, the country with the world’s largest automotive market, the government is determined to develop BEV industry and produced over 250 thousand BEVs in 2015, and the annual growth rate was 420%. In addition, according to the production plan, the cumulative output of BEVs in China will reach 5 million in 2020, meaning that BEVs will gradually replace Internal Combustion Engine Vehicles (ICEVs).  BEVs [Battery Electric Vehicles] are designed to obtain more environmental benefits, but the energy consumption and GHG emissions of BEV production are much larger than those of ICEV [Internal Combustion Engine Vehicles] production in China.”
So why is it that advocates of CO2 emissions reductions so readily extol the explosion of EV purchases and use worldwide?
Share this...FacebookTwitter "
"
Share this...FacebookTwitter‘Two-Thirds Of Climate Warming’ 
Since 1750 Due To ‘Solar Causes’
– Dr. Alan D. Smith, Geoscientist

Though advocates of the dangerous anthropogenic global warming (AGW) narrative may not welcome the news, evidence that modern day global warming has largely been driven by natural factors – especially solar activity – continues to pile up.
Much of the debate about the Sun’s role in climate change is centered around reconstructions of solar activity that span the last 400 years, which now include satellite data from the late 1970s to present.
To buttress the claim that solar forcing has effectively played almost no role in surface temperature changes since the mid-20th century, the IPCC has shown preference for modeled reconstructions of solar activity (i.e., the PMOD) that show a stable or decreasing trend since the 1970s.  Why?  Because if the modeled results can depict steady or decreasing solar activity since the last few decades of the 20th century – just as surface temperatures were rising – then attributing the post-1970s warming trend to human activity becomes that much easier.
The trouble is, satellite observations using ACRIM  data (which have been affirmed to be accurate by other satellite data sets and are rooted in observation, not modeled expectations) indicate that solar activity did not decline after the 1970s, but actually rose quite substantially.  It wasn’t until the early 2000s that solar activity began to decline, corresponding with the denouement of the Modern Grand Maximum.

ACRIM Composite Is ‘Data Driven’, While The PMOD Composite Is ‘Model Driven’

Willson, 2014
• Comparison of the results from the ACRIM3, SORCE/TIM and SOHO/VIRGO satellite experiments demonstrate the near identical detection of TSI variability on all sub-annual temporal and amplitude scales during the TIM mission.   A solar magnetic activity area proxy [developed in 2013] for TSI has been used to demonstrate that the ACRIM TSI composite and its +0.037 %/decade TSI trend during solar cycles 21–23 [1980s-2000s] is the most likely correct representation of the extant satellite TSI database. 
• The occurrence of this trend during the last decades of the 20th century supports a more robust contribution of TSI variation to detected global temperature increase during this period than predicted by current climate models.
• One of the most perplexing issues in the 35 year satellite TSI database is the disagreement among TSI composite time series in decadal trending. The ACRIM and PMOD TSI compostite time series use the ERB and ERBE results, respectively, to bridge the Gap. Decadal trending during solar cycles 21–23 is significant for the ACRIM composite but not for the PMOD.  A new [2013] TSI-specific TSI proxy database has been compiled that appears to resolve the issue in favor of the ACRIM composite and trend. The resolution of this issue is important for application of the TSI database in research of climate change and solar physics.
• The ACRIM TSI composite is data driven. It uses ACRIM1, ACRIM2, ACRIM3 and Nimbus7/ERB satellite results published by the experiments’ science teams and the highest cadence and quality ACRIM Gap database, the Nimbus7/ERB, to bridge the ACRIM Gap. 
• The PMOD TSI composite, using results from the Nimbus7ERB, SMM/ACRIM1, UARS/ACRIM 2 and SOHO/ VIRGO experiments, is model driven. It conforms TSI results to a solar-proxy model by modifying published ERB and ACRIM results and choosing the sparse, less precise ERBS/ERBE results as the basis for bridging the ACRIM Gap (Frohlich and Lean 1998).
• The Earth’s climate regime is determined by the total solar irradiance (TSI) and its interactions with the Earth’s atmosphere, oceans and landmasses. Evidence from 35 years of satellite TSI monitoring and solar activity data has established a paradigm of direct relationship between TSI and solar magnetic activity. (Willson et al. 1981; Willson and Hudson 1991; Willson 1997, 1984; Frohlich and Lean 1998; Scafetta and Willson 2009; Kopp and Lean 2011a, 2011b)  This paradigm, together with the satellite record of TSI and proxies of historical climate and solar variability, support the connection between variations of TSI and the Earth’s climate.   The upward trend during solar cycles 21–23 coincides with the sustained rise in the global mean temperature anomaly during the last two decades of the 20th century. 

Assessment Of The Sun’s Climate Role Largely Depends On The TSI Model Adopted

Van Geel and Ziegler, 2013
• [T]he IPCC neglects strong paleo-climatologic evidence for the high sensitivity of the climate system to changes in solar activity. This high climate sensitivity is not alone due to variations in total solar irradiance-related direct solar forcing, but also due to additional, so-called indirect solar forcings. These include solar-related chemical-based UV irradiance-related variations in stratospheric temperatures and galactic cosmic ray-related changes in cloud cover and surface temperatures, as well as ocean oscillations, such as the Pacific Decadal Oscillation and the North Atlantic Oscillation that significant affect the climate.
• [T]he cyclical temperature increase of the 20th century coincided with the buildup and culmination of the Grand Solar Maximum that commenced in 1924 and ended in 2008.
• Since TSI estimates based on proxies are relatively poorly constrained, they vary considerably between authors, such as Wang et al. (2005) and Hoyt and Schatten (1997). There is also considerable disagreement in the interpretation of satellite-derived TSI data between the ACRIM and PMOD groups (Willson and Mordvinov, 2003; Fröhlich, 2009). Assessment of the Sun’s role in climate change depends largely on which model is adopted for the evolution of TSI during the last 100 years (Scafetta and West, 2007; Scafetta, 2009; Scafetta, 2013). 
• The ACRIM TSI satellite composite shows that during the last 30 years TSI averaged at 1361 Wm-2, varied during solar cycles 21 to 23 by about 0.9 Wm-2, had increased by 0.45 Wm-2 during cycle 21 to 22 [1980s to 2000s] to decline again during cycle 23 and the current cycle 24 (Scafetta and Willson, 2009). 
• By contrast, the PMOD TSI satellite composite suggests for the last 30 years an average TSI of 1366, varying between 1365.2 and 1367.0 Wm-2 that declined steadily since 1980 by 0.3 Wm-2.

Total Solar Irradiance Increased By 3 W m-2 Between 1900 And 2000

Van Geel and Ziegler, 2013 (continued)
• On centennial and longer time scales, differences between TSI estimates become increasingly larger. Wang et al. (2005) and Kopp and Lean (2011) estimate that between 1900 and 1960 TSI increased by about 0.5 Wm-2 and thereafter remained essentially stable, whilst Hoyt and Schatten (1997) combined with the ACRIM data and suggest that TSI increased between 1900 and 2000 by about 3 Wm-2 and was subject to major fluctuations in 1950-1980 (Scafetta, 2013; Scafetta, 2007). 
• Similarly, it is variably estimated that during the Maunder Solar Minimum (1645- 1715) of the Little Ice Age TSI may have been only 1.25 Wm-2 lower than at present Wang et al., 2005; Haig, 2003; Gray et al., 2010; Krivova et al., 2010) or by as much as 6 ± 3 Wm-2 lower than at present (Shapiro et al., 2010; Hoyt and Schatten, 1997), reflecting a TSI increase ranging between 0.09% and 0.5%, respectively.

Graph Source: Soon et al., 2015

After Removing Instrumental ‘Adjustments’, Urban Bias, Temperatures Follow Solar Activity

The combined Hadley Centre and Climatic Research Unit (HadCRUT) data set — which is featured in the Intergovernmental Panel on Climate Change (IPCC) reports — underwent a revision from version 3 to version 4 in March of 2012.  This was about a year before the latest IPCC report was to be released (2013).  At the time (early 2012), it was quite inconvenient to the paradigm that HadCRUT3 was highlighting a slight global cooling trend between 1998 and 2012, as shown in the graph below (using HadCRUT3 and HadCRUT4 raw data from WoodForTrees).  So, by changing versions, and by adjusting the data, the slight cooling was changed to a slight warming trend.

Source: WoodForTrees
As recently as 1990, it was widely accepted that the global temperature trend, as reported by NASA (Hansen and Lebedeff, 1987), showed a “0.5°C rise between 1880 and 1950.”
Pirazzoli, 1990
This 0.5°C rise in global temperatures between 1880-1950 (and 0.6°C between 1880 and 1940) can clearly be seen in the NASA GISS graph from 1987:

Schneider, S. H. 1989. The greenhouse effect: Science and policy. Science 243: 771-81.
Today, it is no longer acceptable for the NASA global temperature data set to graphically depict a strong warming trend during the first half of the 20th century.  This is because anthropogenic CO2 emissions were flat and negligible relative to today during this abrupt warming period.
So as to eliminate the inconvenience of a non-anthropogenic warming trend in modern times, NASA has now removed all or nearly all the 0.5°C of warming between 1880 and 1950.

NASA GISS graph

 

Soon et al., 2015   
• [B]etween 65-80% of the apparent warming trend over the 1961-2000 period for the Beijing and Wuhan station records was probably due to increasing urban heat islands.  [T]he temperature trends increase from +0.025°C/decade (fully rural) to … +0.119°C/decade (fully urban). … If we assume that the fully rural stations are unaffected by urbanization bias, while the other subsets are, then we can estimate the extent of urbanization bias in the “all stations” trends by subtracting the fully rural trends. This gives us an estimate of +0.094°C/decade urbanization bias over the 1951-1990 period [+0.38°C of additional non-climatic warmth]– similar to Wang & Ge (2012)’s +0.09°C/decade estimate.
•We have constructed a new estimate of Northern Hemisphere surface air temperature trends derived from mostly rural stations – thereby minimizing the problems introduced to previous estimates by urbanization bias.  
• Similar to previous estimates, our composite implies warming trends during the periods 1880s-1940s and 1980s-2000s. However, this new estimate implies a more pronounced cooling trend during the 1950s-1970s. As a result, the relative warmth of the mid-20th century warm period [1930s-1950s] is comparable to the recent [1980s-2000s] warm period – a different conclusion to previous estimates. Although our new composite implies different trends from previous estimates, we note that it is compatible with Northern Hemisphere temperature trends derived from (a) sea surface temperatures; (b) glacier length records; (c) tree ring widths.
• However, the recent multi model means of the CMIP5 Global Climate Model hindcasts failed to adequately reproduce the temperature trends implied by our composite, even when they included both “anthropogenic and natural forcings”. One reason why the hindcasts might have failed to accurately reproduce the temperature trends is that the solar forcings they used all implied relatively little solar variability. However, in this paper, we carried out a detailed review of the debate over solar variability, and revealed that considerable uncertainty remains over exactly how the Total Solar Irradiance has varied since the 19th century. 
• When we compared our new composite to one of the high solar variability reconstructions of Total Solar Irradiance which was not considered by the CMIP5 hindcasts (i.e., the Hoyt & Schatten reconstruction), we found a remarkably close fit. If the Hoyt & Schatten reconstruction and our new Northern Hemisphere temperature trend estimates are accurate, then it seems that most of the temperature trends since at least 1881 can be explained in terms of solar variability, with atmospheric greenhouse gas concentrations providing at most a minor contribution. 
• This contradicts the claim by the latest Intergovernmental Panel on Climate Change (IPCC) reports that most of the temperature trends since the 1950s are due to changes in atmospheric greenhouse gas concentrations (Bindoff et al., 2013).


New Paper: Since 1750, About 0.8°C – 0.9°C Of CET Increase Is Due To Solar Forcing

Smith, 2017
Yearly mean temperatures in the CET [Central England Temperature] record show an increase in temperature of approximately 1.3°C degrees from the end of the 17th Century to the end of the 20th Century/beginning of 21st Century.  …  Subtle difference in timing between the warming/cooling phases between the Central England record and the other localities may reflect local climate variation, but the similarity in events between continents suggests the CET [Central England Temperature] record is recording global temperature patterns.
Records of sunspot numbers began in 1610 such that detailed estimates of solar variation for the years covered by the CET record can be made without resort to the use of proxy data. Reconstructions of TSI [e.g. 16-18] differ in magnitude (Table 1), but there is agreement in form with 4 peaks and 4 to 6 troughs occurring over the time-scale of the CET record (Fig. 4). These are: a minimum in TSI associated with the Maunder Sunspot Minimum in the latter half of the 17th Century; a peak, possibly bi-modal approaching modern TSI values during the 18th Century; a well-defined trough corresponding with the Dalton Sunspot Minimum between 1800- 1820; a poorly defined TSI peak in the mid 19th Century; a reduction in TSI during the late 19th Century; increasing TSI during the early 20th Century; a decrease in TSI from around 1950- 1975; and a second phase of TSI increase in the late 20th Century [1980s-2000s]. There is good correspondence with TSI throughout the CET record, with warm events correlating with high TSI and cool phases correlating with plateaus or decreases in TSI .
However, for temperature increases from the beginning of the Industrial Revolution (Maunder Minimum and Dalton Minimum to end of 20th Century), high TSI models can account for only 63-67% of the temperature increase. This would suggest that one third of Global Warming/Climate Change can be attributed to AGW. … Approximately two-thirds [0.8°C to 0.9°C] of climate warming since the mid-late 18th Century [1.3°C] can be attributed to solar causes, suggesting warming due to anthropogenic causes over the last two centuries is 0.4 to 0.5°C.


All Over The Globe, Trends In Solar Forcing Correlate With Temperature Changes



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Christiansen and Lungqvist (2012)


Stoffel et al., 2015


Schneider et al., 2015  and  Wilson et al., 2016


Kim et al., 2017


Yamanouchi, 2011


Box et al., 2009


Southern Hemisphere

Schneider et al., 2006


De Jong et al., 2016
“[T]he period just before AD 1950 was substantially warmer than more recent decades.”


de Jong et al., 2013


Zinke et al., 2016


Turney et al., 2017


Elbert et al., 2013


“[I]n the framework of empiric [observable] models, the estimate of the solar activity contribution in the variation in the air global temperature in the 20th century is about 70%.” – Kovalenko and Zherebtsov, 2014
Share this...FacebookTwitter "
"
Share this...FacebookTwitterCO2 Climate Sensitivity So Low It’s ‘Impossible 
To Detect Or Measure In The Real Atmosphere’

“In particular, formula 5 (and 6) as presented here, totally rules out
any possibility that a 33°C greenhouse effect of the type proposed
by the IPCC in their reports can exist in the real atmosphere.”
– Holmes, 2017

In a new peer-reviewed scientific paper published in the journal Earth Sciences last December (2017), a Federation University (Australia) Science and Engineering student named Robert Holmes contends he may have found the key to unlocking our understanding of how planets with thick atmospheres (like Earth) remain “fixed” at 288 Kelvin (K), 740 K (Venus), 165 K (Jupiter)…without considering the need for a planetary greenhouse effect or changes in atmospheric CO2 concentrations.
The Greenhouse Effect ‘Thought Experiment’ 
Perhaps the most fundamental conceptualization in climate science is the “thought experiment” that envisions what the temperature of the Earth might possibly be if there was no greenhouse effect, greenhouse gases, or atmosphere.
Dr. Gavin Schmidt, NASA  
“The size of the greenhouse effect is often estimated as being the difference between the actual global surface temperature and the temperature the planet would be without any atmospheric absorption, but with exactly the same planetary albedo, around 33°C. This is more of a ‘thought experiment’ than an observable state, but it is a useful baseline.”
Simplistically, the globally averaged surface temperature clocks in at 288 K.   In the “thought experiment”, an imaginary Earth that has no atmosphere (and thus no greenhouse gases to absorb and re-emit the surface heat) would have a temperature of only 255 K.  The difference between the real and imagined Earth with no atmosphere is 33 K, meaning that the Earth would be much colder (and uninhabitable) without the presence of greenhouse gases bridging the hypothetical “heat gap”.
Of that 33 K greenhouse effect, 20.6 K is imagined to derive from water vapor droplets in the atmosphere (1,000 to 40,000 parts per million [ppm] by volume), whereas 7.2 K is thought to stem from the “natural” (or pre-industrial) 200-280 ppm atmospheric CO2 concentration (Kramm et al., 2017).
As a “thought experiment”, the critical heating role for water vapor droplets and CO2 concentrations lacks real-world validation.  For example, the Earth’s oceans account for 93% of the planet’s heat energy (Levitus et al., 2012), and yet no real-world physical measurements exist that demonstrate how much heating or cooling is derived from varying CO2 concentrations up or down over a body of water in volume increments of parts per million (0.000001).  Consequently, the CO2 greenhouse effect is a hypothetical, model-based conceptualization.
And in recent years, many scientific papers have been published that question the fundamentals of not only the Earth’s hypothetical greenhouse effect, but the role of greenhouse gases for other planets with thick atmospheres (like Venus) as well Hertzberg et al., 2017, Kramm et al., 2017, Nikolov and Zeller, 2017 , Allmendinger, 2017, Lightfoot and Mamer, 2017, Blaauw, 2017, Davis et al., 2018).   The Holmes paper highlighted here may just be among the most recent.
‘Extremely Accurate’ Planetary Temperature Calculations With Pressure/Density/Mass Formula
Holmes has argued that the average temperature for 8 planetary bodies with thick (0.1 bar or more) atmospheres can be precisely measured with “extreme” accuracy — an error range of just 1.2% — by using a formula predicated on the knowledge of 3 parameters: “[1] the average near-surface atmospheric pressure, [2] the average near surface atmospheric density and [3] the average mean molar mass of the near-surface atmosphere.”
Holmes used the derived pressure/density/mass numbers for each planetary body.   He then calculated the planets’ temperatures with these figures.
Venus’ temperature was calculated to be 739.7 K with the formula.  Its measured temperature is 740 K.  This indicates that the formula’s accuracy is within an error range of just 0.04% for Venus.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Given Earth’s pressure/density/mass, its calculated temperature is 288.14 K using Holmes’ formula.  Earth’s measured temperature is 288 K, an exact fit.
Saturn’s calculated temperature is 132.8 K.  Its measured temperature is 134 K — an error range of only 0.89%.
The impressive accuracy of the formula is illustrated below in Table 1. and Figure 2.

Atmospheric Pressure/Density And Surface Temperature
In large part, the density of a planet’s atmosphere is a primary determinant of its temperature.   Planets with thick atmospheres are hotter.  Planets with thin atmospheres are cooler.  The further away from the surface, the less gravity/pressure there is and the cooler it gets.  And vice versa.
Sciencing.com
“In general, the weaker the gravitational pull of a planet, the thinner the atmosphere will be. A planet with weak gravity will tend to have less mass and allow more atmosphere to escape into space. Thus the thickness or thinness of the atmosphere depends upon the strength or weakness of gravity. For example, the gravity on Jupiter is 318 times greater than Earth, and thus Jupiter’s atmosphere is much thicker than Earth’s. Gravity gets weaker the further away it is from a planet, so the atmosphere will be thicker near the surface.”
A facile illustration of the effects of atmospheric pressure on the surface temperatures of a planet like Earth can be found in the Grand Canyon, Southwestern U.S.  There, the North Rim is about 1,000 feet (305 meters) higher in elevation than the South Rim.  Interestingly, the North Rim is also about 9 degrees Fahrenheit colder than the South Rim due to the influence of atmospheric pressure/gravity.   The bottom of the canyon reaches temperatures 20-25 degrees warmer than the top.  The stark temperature difference is unrelated to the greenhouse gas concentrations for the two locations, nor is it connected to sunlight.   It’s the gravitational pressure that creates the heat divergence.
Subia, 2014
“Elevation and season of the year determine average temperatures at the the Grand Canyon. Elevations at top of the South Rim average around 7,000 feet. The North Rim averages about 8,000 feet. The higher the elevation, the cooler the temperature. At any given time, the North Rim will average 8-10 degrees Fahrenheit cooler versus the South Rim. … [T]he very bottom of the canyon can increase 20 to 25 degrees warmer than the top of the respective rims.”
Sensitivity To CO2 Concentration Changes ‘Extremely Low’
Holmes points out that the implications of his precise calculations for planetary temperatures necessarily lead to the conclusion that there is no need to have a greenhouse effect or greenhouse gases to bridge a hypothetical “heat gap.”  Instead, he writes that “planetary bodies with thick atmospheres cannot be mainly determined by the ‘greenhouse effect’, but instead most likely by an effect from fluid dynamics, namely, adiabatic autocompression.”
This effectively rules out the possibility that CO2 is a predominant climate driver.
In fact, Holmes’ calculation for CO2 climate sensitivity (doubling the atmospheric CO2 concentration from 0.03% to 0.06%) is -0.03°C.
As he ostensibly understates in his conclusion, “This climate sensitivity is already so low that it would be impossible to detect or measure in the real atmosphere.”

Holmes, 2017
Molar Mass Version of the Ideal Gas Law 
Points to a Very Low Climate Sensitivity
Introduction
Presented here is a simple and reliable method of accurately calculating the average near surface atmospheric temperature on planetary bodies which possess a surface atmospheric pressure of over 10kPa [a thick atmosphere, 0.1 bar or more]. This method requires a gas constant and the knowledge of only three gas parameters: [1] the average near-surface atmospheric pressure, [2] the average near surface atmospheric density and [3] the average mean molar mass of the near-surface atmosphere. The formula used is the molar version of the ideal gas law.
It is here demonstrated that the information contained in just these three gas parameters alone is an extremely accurate predictor of atmospheric temperatures on planets with atmospheres >10kPa. This indicates that all information on the effective plus the residual near-surface atmospheric temperature on planetary bodies with thick atmospheres, is automatically ‘baked-in’ to the three mentioned gas parameters.
This formula proves itself here to be not only more accurate than any other method heretofore used, but is far simpler to calculate.  It requires no input from parameters previously thought to be essential; solar insolation, albedo, greenhouse gas content, ocean circulation and cloud cover among many others.
Given this, it is shown that no one gas has an anomalous effect on atmospheric temperatures that is significantly more than any other gas.
In short, there can be no 33°C ‘greenhouse effect’ on Earth, or any significant ‘greenhouse effect’ on any other planetary body with an atmosphere of >10kPa.
The Formula: An ‘Extremely Accurate Predictor’ Of Planetary Temperatures

[T]he hypothesis being put forward here is that in the case of Earth, solar insolation provides the ‘first’ 255 Kelvin – in accordance with the black body law [11]. Then adiabatic auto-compression provides the ‘other’ 33 Kelvin, to arrive at the known and measured average global temperature of 288 Kelvin. The ‘other’ 33 Kelvin cannot be provided by the greenhouse effect, because if it was, the molar mass version of the ideal gas law could not then work to accurately calculate planetary temperatures, as it clearly does here.
It is apparent that this simple formula calculates the ‘surface’ temperatures of many planetary bodies in our Solar System accurately (Figure 2).
Specifically, those which have atmospheres thick enough to form a troposphere (i.e. possessing an atmospheric pressure of over 10kPa or 0.1bar). These are: Venus, Earth, Jupiter, Saturn, Titan, Uranus and Neptune. All calculated temperatures are within 1.2% of the NASA reported ‘surface’ temperature (except for Mars, which is excluded because it has a much lower atmospheric pressure than 10kPa).
This accuracy is achieved without using the S-B black body law, or the need to include terms for such parameters as TSI levels, albedo, clouds, greenhouse effect or, for that matter, adiabatic auto-compression. All that is required to be able to accurately calculate the average near-surface atmospheric temperature, is the relevant gas constant and the knowledge of three variable gas parameters.
The Implications: CO2 Climate Sensitivity (-0.03°C) ‘Extremely Low’
Some reflection upon the simplicity and accuracy of these results will bring an unbiased person to the obvious implications of this work. These are that the residual (residual being the difference between S-B law results and actual) near-surface atmospheric temperatures on planetary bodies with thick atmospheres cannot be mainly determined by the ‘greenhouse effect’, but instead most likely by an effect from fluid dynamics, namely, adiabatic autocompression.
Another implication leads directly to the conclusion that the climate sensitivity to, for example, a doubling of the atmospheric carbon dioxide concentration has to be operating instantaneously, and also must be extremely low. Under this scenario, the climate sensitivity to CO2 cannot be very different to the addition of a similar quantity of any other gas.
In particular, formula 5 (and 6) as presented here, totally rules out any possibility that a 33°C greenhouse effect of the type proposed by the IPCC in their reports [23] can exist in the real atmosphere. The reason is that the IPCC state in their reports that a 0.03% [300 ppm] increase in atmospheric CO2 (i.e. a doubling from pre-industrial levels) must result in a global temperature rise of ~3°C; (a range of 1.5°C to 4.5°C, which has hardly changed since 1990) [24]. This is the so-called ‘climate sensitivity’. Anything like this magnitude of warming caused by such a small change in gas levels is completely ruled out by the molar mass version of the ideal gas law.
Calculate for a doubling of CO2 from the pre-industrial level of 0.03% [300 ppm]:
Calculated temperature after doubling of CO2 to 0.06% ≈ 288.11K. Climate sensitivity to CO2 is ≈ 288.14 – 288.11 ≈ – 0.03K.
The change would in fact be extremely small and difficult to estimate exactly, but would be of the order -0.03°C. That is, a hundred times smaller than the ‘likely’ climate sensitivity of 3°C cited in the IPCC’s reports, and also probably of the opposite sign [cooling]. Even that small number would likely be a maximum change, since if fossil fuels are burned to create the emitted CO2, then atmospheric O2 will also be consumed, reducing that gas in the atmosphere – and offsetting any temperature change generated by the extra CO2. This climate sensitivity is already so low that it would be impossible to detect or measure in the real atmosphere, even before any allowance is made for the consumption of atmospheric O2.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter 

A remarkably unsophisticated paper was published a few months ago curiously entitled Internet Blogs, Polar Bears, and Climate-Change Denial by Proxy.  Among the list of co-authors of Harvey et al. (2017) are two rather familiar names in climate science circles: Michael E. Mann and Stephan Lewandowsky.
The 14 authors liberally utilize name-calling and broad-brushed accusation (i.e., “unsubstantiated opinions of climate-change deniers”) to make the claim that “climate-change deniers” have no scientific backing for their “opinions”, and so they consequently use the same scare-mongering rhetorical devices and tactics as creationism apologists to advance their cause.
“Proponents of creationism and intelligent design use the same strategy [as climate-change deniers]: Instead of providing scientific evidence in favor of their opinions, they instead focus selectively on certain lines of evidence for evolution and attempt to cast doubt on them (Nisbet 2009).”
“Rhetorical devices to evoke fear and other emotions, such as implying that the public is under threat from deceitful scientists, are common tactics employed by science-denier groups (Barry et al. 2008).”
The purpose of their paper is to make the case that widely-read “denier blogs” like Watts Up With That and Climate Depot have cherry-picked an anthropogenic global warming (AGW) icon, the polar bear, and then proceeded to hand-wave by denying the “well established” science that says these bears’ survival and ability to obtain food (i.e., hunt seal) is threatened by reductions in sea ice.   In denying that these animals are endangered by sea ice losses, the polar bear has become a “proxy” or “keystone domino” for denying all the other dire consequences associated with AGW.
“Here, focusing on Arctic sea ice and polar bears, we show that blogs that deny or downplay AGW disregard the overwhelming scientific evidence of Arctic sea-ice loss and polar bear vulnerability. By denying the impacts of AGW on polar bears, bloggers aim to cast doubt on other established ecological consequences of AGW.”  
Indeed, Harvey et al. (2017) authors claim that the evidence is both “overwhelming” and “well established” that polar bears can only hunt and catch their main prey, seals, “from the surface of the sea ice”.   They can not catch seals in the open water.  Consequently, as long as there is less sea ice available, “AGW assures that all polar bears ultimately will be negatively affected.”
Inuit Observations, And Scientists Who Record Them, Are Now ‘Climate-Change Denial’
The native Inuit peoples who have lived in the Arctic and observed polar bear hunting practices for generations are apparently deserving of the “climate-change denier” moniker.
For that matter, the audacious scientists who risk the ire of the AGW gatekeepers to interview these community leaders and then publish their results in scientific journals apparently must be classified as “climate-change deniers” too.
Why?  Because there appears to be widespread agreement among Inuit observers that polar bears are skilled swimmers who can catch seals in open water (and not just from sea ice surfaces).   This observation wholly contradicts the “well established” and “overwhelming” scientific evidence identified in Harvey et al. (2017) that says polar bears can only catch seals from a sea ice platform.
“The [native populations’] view of polar bears as effective open-water hunters is not consistent with the Western scientific understanding that bears rely on the sea ice platform for catching prey (Stirling and McEwan, 1975; Smith, 1980). The implications of this disagreement are paramount, given that scientists suggest that the greatest threat to polar bears associated with a decrease in sea ice is a significant decrease in access to marine mammal prey (Stirling and Derocher, 1993; Derocher et al., 2004).” — Laforest et al., 2018
‘There’s Too Many Polar Bears Now’
Not only do the generational observations indicate that polar bears’ hunting practices are not duly harmed by sea ice reduction, but community participants consistently report thriving and growing polar bear populations — especially in recent years.
An extensive analysis by York et al. (2016), relying heavily on native reports, concluded that 12 of 13 Canadian Arctic sub-populations have been stable or growing in recent decades.   Wong et al. (2017) recorded Inuit community members reporting “there’s too many polar bears now.”
Even aerial analysis has revealed stable to growing polar bear populations across wide swaths of the Arctic.  Aars et al. (2017), for example, report that there is “no evidence” that reduced sea ice has led to a reduction in polar bear population size.  To the contrary, these scientists found that polar bears living near the Barents Sea increased in number by 42% — from 685 to 973 — between 2004 and 2015.
Unconvincing Claims Of ‘Overwhelming Scientific Evidence’ 
The fact that the real-world observations of seal-hunting in open water can be collaborated by stable to growing population sizes would appear to support the Inuit version of polar bear science and to simultaneously undermine the Harvey et al. (2017) version of polar bear science.
If Michael E. Mann, Stephan Lewandowsky, and the other authors of the Harvey et al. (2017) polemic wish to characterize those who reject observational evidence (i.e., science) as “deniers”, perhaps they should first get their own “facts” straight.
As a requisite, Mann and his colleagues should seek to persuade Inuit community members that they have not actually witnessed polar bears hunt seals in open waters, or that they have not actually observed an increase in polar bear population size in recent decades.
After this insidious “denialism” permeating Inuit communities has been eradicated, the 14 authors of Harvey et al. (2017) might then have a leg to stand on in going after the “denier blogs” and their creationist-style tactics and scare-mongering rhetorical devices.

Aars et al., 2017
The number and distribution of polar 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




bears in the western Barents Sea
“In August 2015, we conducted a survey in the Norwegian Arctic to estimate polar bear numbers and reveal population substructure. … Mainly by aerial survey line transect distance sampling methods, we estimated that 264 (95% CI = 199 – 363) bears were in Svalbard, close to 241 bears estimated for August 2004. The pack ice area had an estimated 709 bears (95% CI = 334 – 1026). The pack ice and the total (Svalbard + pack ice, 973 bears [in 2015], 95% CI = 334 – 1026) both had higher estimates compared to August 2004 (444 and 685 bears [in 2004], respectively), but the increase was not significant.”
“There is no evidence that the fast reduction of sea-ice habitat in the area has yet led to a reduction in population size.”


Laforest et al., 2018
Traditional Ecological Knowledge 
of Polar Bears […] Québec, Canada
“Communities also differed in their perception of the prevalence of problem polar bears and the conservation status of the species, with one-third of participants reporting that polar bears will be unaffected by, or even benefit from, longer ice-free periods. A majority of participants indicated that the local polar bear population was stable or increasing.”
“[Participants] indicated that polar bear body condition is stable; they cited the fact that polar bears are capable of hunting seals in open water as a factor contributing to the stable body condition of the bears. … None of the participants explicitly linked the effects of a warming climate to specific impacts on polar bears.”
“Five participants indicated that polar bears are adept swimmers capable of hunting seals in open water. Residents of communities along Baffin Bay have also expressed this viewpoint (Dowsley and Wenzel, 2008), whereas Inuvialuit of the Western Arctic had variable perceptions of the ability of bears to catch seals in open water (Joint Secretariat, 2015). The [native populations’] view of polar bears as effective open-water hunters is not consistent with the Western scientific understanding that bears rely on the sea ice platform for catching prey (Stirling and McEwan, 1975; Smith, 1980). The implications of this disagreement are paramount, given that scientists suggest that the greatest threat to polar bears associated with a decrease in sea ice is a significant decrease in access to marine mammal prey (Stirling and Derocher, 1993; Derocher et al., 2004).”
“A recent aerial survey of the Southern Hudson Bay subpopulation concluded that the abundance of polar bears has remained steady since 1986 (943 bears; SE: 174) (Obbard et al., 2015). The survey included the entire coastal range and offshore island habitat of the Southern Hudson Bay subpopulation, except for the eastern James Bay coast. Taken together, the results of the aerial survey and the participant responses from Wemindji and Chisasibi indicate that the local population has remained stable. However, the unanimous responses from participants in Whapmagoostui/Kuujjuarapik suggest that there has been a localized increase in the number of bears near Whapmagoostui/Kuujjuarapik.”

Wong et al., 2017
Inuit perspectives of polar bear research:
Lessons for community-based collaborations
“All [Inuit] participants reported having more bear encounters in recent years than in the past. Some participants indicated that the bears they have encountered are healthy.”
Inuit observations: “Last year he said that there’s more bears that are more fat … they rarely see unhealthy bears … the only time they would see one is when it’s pretty old … it won’t hunt—hunt as much … and it’s skinny. (AB9)  … Our elders, they say, they migrate, into other area… for years, and then they come back … that’s what we’re experiencing now … back in early 80s, and mid 90s, there were hardly any bears … there’s too many polar bears now.  Bears can catch seals even—even if the—if the ice is really thin … they’re great hunters those bears … they’re really smart … they know how to survive”

York et al., 2016
Demographic and traditional knowledge perspectives on 
the current status of Canadian polar bear subpopulations
“Considering both [observations from native populations] and scientific information, we suggest that the current status of Canadian polar bear subpopulations in 2013 was 12 stable/increasing and one declining (Kane Basin).”
“We do not find support for the perspective that polar bears within or shared with Canada are currently in any sort of climate crisis.”
“We show that much of the scientific evidence indicating that some polar bear subpopulations are declining due to climate change-mediated sea ice reductions is likely flawed”
“Reduction in the heavy multiyear ice and increased productivity from a longer open water season may even enhance polar bear habitat in some areas.”
“It seems unlikely that polar bears (as a species) are at risk from anthropogenic global warming.”

Dowsley and Wenzel, 2008
“The Time of the Most Polar Bears”
“In the interviews, Inuit reported numerous changes in polar bears over the past 10 – 15 years [1990s to 2000s].”
“During the Inuit knowledge survey in the Baffin Bay area, Inuit knowledge varied significantly between communities on whether there was any change in the population of polar bears (p = 0.010) (Dowsley, 2005, 2007). In the northern community of Pond Inlet, all 14 respondents indicated a population increase. In the central community of Clyde River, 16 of 17 respondents reported an increase. In the most southern community of Qikiqtarjuaq, 9 of 15 reported an increase. The other six respondents in Qikiqtarjuaq reported either that they did not know, or that no change was observed. No respondent in any of the communities reported a decrease in the bear population.”

Dowsley, 2007
Inuit Perspectives on Polar Bears (Ursus maritimus)
and Climate Change in Baffin Bay, Nunavut, Canada
“A significant difference between communities was also observed regarding the number of polar bears. Only 60% of respondents in Qikiqtarjuaq felt the bear population had increased over the past 10-15 years, compared to over 90% of respondents in the other two communities.”
“No, because polar bears can go and follow the seals further [if sea ice retreats], so they won’t have trouble hunting. Also the snow covers the [seals’] breathing holes but polar bears can still hunt, it’s just for people.”
“There is more rough ice, more thin ice. But it won’t affect polar bears’ hunting.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterUPDATE:Hat-tip: Kenneth
Graph showing increasing Adélie penguin numbers during 1982-2015
Che-Castaldo et al., 2017
“We found a marked and steady increase in [Adélie penguin] abundance around the rest of the Antarctic continent, including both Eastern Antarctica and the Ross Sea [during 1982-2015].”
Scientists have historically determined that increasing Adélie penguin numbers seem to coincide with warm periods, whereas cooling periods elicit population declines (Emslie et al., 2007; Huang et al., 2009).
===============================================
Once again I’m bringing you today another one from Lüning’s and Vahrenholt’s Die kalte Sonne, this one concerning a recent study claiming the “king penguin populations are at heavy extinction risk under the current global warming predictions“.

With dire (phony) study claims of king penguins being threatened by global warming, climate science and media once again do their usual number on the public. Image source here. CC BY-SA 3.0
=====================================================
What did the king penguins do 1500 years ago when it was warmer than it is today?
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
The online Swiss daily Luzerner Zeitung reported on 27 February 2018:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




King’s penguin threatened by climate change
Climate change is threatening more than 70 percent of the king penguin colonies. So writes an international team of scientists in the journal ‘Nature Climate Change’. The animals have to move further south and thus into colder areas. […] The king penguin (aptenodytes patagonicus) is the second largest type of penguin after the emperor penguin. According to the study, the population is currently 1.6 breeding pairs. Over thousands of years the king penguins have been able to rely on the Antarctic polar front, the researchers write. That is a system of currents the transports masses of water from the depths to the surface and so provides for a large fish supply for a relatively small area. Because of climate change, the polar front is shifting to the south and is leaving the Crozet Islands, the Kerguelen and Marion Island on which the penguins live.”
Read more at the Luzerner Zeitung.
Once again we have the fairy tale that everything in the past was stable and that today it’s warmer than ever before. But just one look at Stenni et al. 2017 would have sufficed:
Antarctic climate variability on regional and continental scales over the last 2000 years
[…] Our new reconstructions confirm a significant cooling trend from 0 to 1900 CE across all Antarctic regions where records extend back into the 1st millennium, with the exception of the Wilkes Land coast and Weddell Sea coast regions. Within this long-term cooling trend from 0 to 1900 CE, we find that the warmest period occurs between 300 and 1000 CE, and the coldest interval occurs from 1200 to 1900 CE. Since 1900 CE, significant warming trends are identified for the West Antarctic Ice Sheet, the Dronning Maud Land coast and the Antarctic Peninsula regions, and these trends are robust across the distribution of records that contribute to the unweighted isotopic composites and also significant in the weighted temperature reconstructions. Only for the Antarctic Peninsula is this most recent century-scale trend unusual in the context of natural variability over the last 2000 years. […]”
Let’s take a look at the temperature chart for all of Antarctica over the past 2000 years:

Temperature curve for Antarctica over the past 2000 years. Source: Stenni et al. 2017.
As we see, it has not even been 1000 years ago since the penguins were forced to leave the area where they currently find themselves due to oncoming cold. We would gladly provide the activists with a new pair of spectacles that would correct their climate-historical myopia.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter Cooling, Not Warming, Leads To
  Weather and Climate Instability 

Image Source: Loisel et al., 2017

1. Significant Decreasing Trend In Severe Weather Since 1961
Zhang et al., 2017
Based on continuous and coherent severe weather reports from over 500 manned stations, for the first time, this study shows a significant decreasing trend in severe weather occurrence across China during the past five decades. The total number of severe weather days that have either thunderstorm, hail and/or damaging wind decrease about 50% from 1961 to 2010. It is further shown that the reduction in severe weather occurrences correlates strongly with the weakening of East Asian summer monsoon which is the primary source of moisture and dynamic forcing conducive for warm-season severe weather over China.

2. Most Frequent Climate Instability During Global Cooling/Reduced CO2 Periods
Kawamura et al., 2017
Numerical experiments using a fully coupled atmosphere-ocean general circulation model with freshwater hosing in the northern North Atlantic showed that climate becomes most unstable in intermediate glacial conditions associated with large changes in sea ice and the Atlantic Meridional Overturning Circulation. Model sensitivity experiments suggest that the prerequisite for the most frequent climate instability with bipolar seesaw pattern during the late Pleistocene era is associated with reduced atmospheric CO2 concentration via global cooling and sea ice formation in the North Atlantic, in addition to extended Northern Hemisphere ice sheets.

3. Hurricane Activity Is ‘Subdued’ During Warm Periods (1950-2000)
Heller, 2017


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The hurricane analysis conducted by Burn and Palmer (2015) determined that hurricane activity was subdued during the [warm] Medieval Climate Anomaly (MCA) (~900-1350 CE) and became more produced during the [cold] Little Ice Age (LIA) (~1450-1850 CE), followed by a period of variability occurred between ~1850 and ~1900 before entering another subdued state during the industrial period (~1950-2000 CE). In general, the results of this study corroborate these findings … [W]hile hurricane activity was greater during the LIA, it also had more frequent periods of drought compared to the MCA (Burn and Palmer 2014), suggesting that climate fluctuations were more pronounced in the LIA compared to the MCA. The changes in the diatom distribution and fluctuations in chl-a recorded in this study starting around 1350 also indicate that variations in climate have become more distinct during the LIA and from ~1850-1900.
[C]limate variability has increased following the onset of the Little Ice Age (~1450-1850 CE), however it is difficult to distinguish the impacts of recent anthropogenic climate warming on hurricane activity from those of natural Atlantic climate regimes, such as ENSO.

4. Surface Warming Weakens Cyclone Activity
Chen et al., 2017
Results indicate that the midlatitude summer cyclone activity over East Asia exhibits decadal changes in the period of 1979–2013 and is significantly weakened after early 1990s. …  Moreover, there is a close linkage between the weakening of cyclonic activity after the early 1990s and the nonuniform surface warming of the Eurasian continent. Significant warming to the west of Mongolia tends to weaken the north–south temperature gradient and the atmospheric baroclinicity to its south and eventually can lead to weakening of the midlatitude cyclone activity over East Asia.

5. More Hydroclimatic Variability During Cold Periods…Models Say Warming Causes More Instability, So The 21st Century Will Be Like The Little Ice Age, With More Instability/Megadrought
Loisel et al., 2017
Our tree ring-based analysis of past drought indicates that the Little Ice Age (LIA) experienced high interannual hydroclimatic variability, similar to projections for the 21st century. This is contrary to the Medieval Climate Anomaly (MCA), which had reduced variability and therefore may be misleading as an analog for 21st century warming, notwithstanding its warm (and arid) conditions. Given past non-stationarity, and particularly erratic LIA, a ‘warm LIA’ climate scenario for the coming century that combines high precipitation variability (similar to LIA conditions) with warm and dry conditions (similar to MCA conditions) represents a plausible situation that is supported by recent climate simulations. … Our comparison of tree ring-based drought analysis and records from the tropical Pacific Ocean suggests that changing variability in El Niño Southern Oscillation (ENSO) explains much of the contrasting variances between the MCA and LIA conditions across the American Southwest. The Medieval Climate Anomaly (MCA, ~950–1400 CE) is often used as an analog for 21stcentury hydroclimate because it represents a warm (and arid) period. The MCA appears related to general surface warming in the Northern Hemisphere, prolonged La Niña conditions, and a persistent positive North Atlantic Oscillation mode. It has been referred to as a stable time interval with ‘quiet’ conditions in regards to low perturbation by external radiative forcing. In this study, we demonstrate that the Little Ice Age (LIA, ~1400–1850 CE) might be more representative of future hydroclimatic variability than the conditions during the MCA megadroughts for the American Southwest, and thus provide a useful scenario for development of future water-resource management and drought and flood hazard mitigation strategies.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterHere’s something you don’t witness very often…German national public radio telling listeners that natural factors are behind observed changes in something related to climate.
I can’t tell you how many times I’ve heard the German media claim storms are linked to our disdainful energy gluttony. So it comes as quite a shock when you hear something about climate that doesn’t conform to Potsdam Institute dogmatism.
At their Die kalte Sonne site here, Dr. Sebastian Lüning and Prof. Fritz Vahrenholt bring up an example of how German DLF national radio. I’ve translated the German text:
=====================================
Hurricanes are developing more quickly today than 30 years ago due to the Atlantic ocean cycle
A team of researchers at the US Department of Energy and the Pacific Northwest National Laboratory recently made an exciting discovery: Apparently hurricanes are developing more quickly today than they did 30 years ago. Earlier it took longer, but now maximum strength is reached sooner.
The scientists have found the culprit – drum roll – no, it’s not the wanton activity of mankind, rather it’s the Atlantic AMO ocean cycle, which fluctuates with a period of 60 years. During the course of the AMO cycle, hurricanes change accordingly.
Here’s the press release from May 9, 2018:

Powerful hurricanes strengthen faster now than 30 years ago
The storms intensify more rapidly today due largely to a natural climate phenomenon
Hurricanes that intensify rapidly — a characteristic of almost all powerful hurricanes — do so more strongly and quickly now than they did 30 years ago, according to a study published recently in Geophysical Research Letters, a journal of the American Geophysical Union. While many factors are at play, the chief driver is a natural phenomenon that affects the temperature of the waters in the Atlantic where hurricanes are powering up, according to scientists at the U.S. Department of Energy’s Pacific Northwest National Laboratory and the National Oceanic and Atmospheric Administration. They found that a climate cycle known as the Atlantic Multidecadal Oscillation or AMO is central to the increasing intensification of hurricanes, broadly affecting conditions like sea temperature that are known to influence hurricanes.
Stronger hurricanes in a day’s time
Last year’s lineup of powerful storms — Harvey, Irma, Jose and Maria — spurred the scientists to take a close look at the rapid intensification process. This occurs when the maximum wind speed in a hurricane goes up by at least 25 knots (28.8 miles per hour) within a 24-hour period. It’s a rite of passage for nearly all major hurricanes, including the big four of 2017. The team, comprised of Karthik Balaguru and Ruby Leung of PNNL and Greg Foltz of NOAA, analyzed 30 years’ worth of satellite hurricane data encompassing 1986 through 2015. Information came from NOAA’s National Hurricane Center and the U.S. Navy’s Joint Typhoon Warning Center. Consistent with other studies, the scientists did not find that rapid intensification is happening more often nowadays.
But the scientists also looked closely at just how much the storms are strengthening. They found a sizeable jump in the strength of fast-growing storms — the storms are getting more powerful more quickly within a 24-hour period than they were 30 years ago. The team found that the average boost in wind speed during a 24-hour intensification event is about 13 mph more than it was 30 years ago — on average about 3.8 knots (4.3 mph) for each of the three decades studied. Several factors play a role when a hurricane gains more power rapidly, including the temperature of the surface of the ocean, humidity, characteristics of the clouds, the heat content in the ocean, and the direction of the wind at the surface compared to miles above. Among the biggest factors affecting the increase in magnitude in the last 30 years, according to the team’s analysis:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




–The amount of heat available in the uppermost layer of the ocean, known as the ocean heat content. The warmer the upper ocean, the more powerful a hurricane can become.
–Wind shear: The less the vertical wind shear — the difference in the direction and force of the winds at the surface compared to several miles into the air — the more powerful the hurricane can become.The influence of the Atlantic Multidecadal Oscillation
The team found that the biggest factor explaining the increasingly rapid intensification is the AMO. The result comes in part from analyses using 16 separate climate models to isolate the impact from global warming. “This was a surprise, that the AMO seems to be a bigger influence in rapid intensification than other factors, including overall warming,” said Balaguru, the first author of the paper.
The AMO governs how the temperature of the waters in the North Atlantic cycles between warmer and cooler, with each period typically lasting a decade or more. The cycling occurs for reasons scientists don’t completely understand, but it has broad effects on the environment. For example, it plays a big part in determining the heat content of the oceans, an important factor powering hurricanes. The AMO has generally been “positive” — causing warmer waters — since the late 1990s.
Balaguru noted that while rapid intensification historically has occurred more often in the western Atlantic, that’s not where the team found the increasing strength of the last 30 years. Rather, the phenomenon is strengthening more in the central and eastern Atlantic, especially to the east of the islands of the Lesser Antilles, which includes the Virgin Islands and Saint Kitts. That’s the same area where the AMO creates warmer waters and boosts ocean heat content, in the central and eastern Atlantic. That’s exactly the alley where hurricanes Irma, Jose and Maria powered up rapidly last year. It’s a proving ground of sorts where many of the most powerful hurricanes strengthen dramatically. Balaguru notes that teasing out the effects of the AMO from broader effects of global warming was beyond the scope of the current study but is a focus for scientists.”
Even the IPCC-trumpeting Deutschlandfunk (DLF) found this worth reporting. On May 9, 2018, listeners indeed heard on the daily program “Forschung Aktuell” (Current Research) the following points:
1) Despite climate change, hurricanes have not become more frequent (which totally contradicts the usual DLF claims on this subject).
2) The current faster strengthening of hurricanes has NOTHING to do with anthropogenic global warming (AGW), but rather it depends on the AMO phase.
3) The causes of the AMO cycles are unknown and have nothing to do with AGW.
Yet, it is a pity that these revolutionary climate-realist claims (by DLF standards) were presented in just a very short report and that the inconvenient facts were not reported on in greater detail…you can listen to this small DLF revolution here (starting at 1:33).
==================================
Don’t hold your breath thinking this is a new media awakening happening in Germany. Expect Stefan Rahmstorf of the alarmist Potsdam Vatican to order the science illiterate DLF editors to be led deep down somewhere in the catacombs, and be made to recant the heresy.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Graph from Perner et al. (2018) that shows modern-day Arctic sea ice (furthest left navy trend line) is still only slightly lower than during the Little Ice Age (LIA), and much more extensive (more ice) than during the Medieval Climate Anomaly (MCA), Roman Warm Period (RWP), and nearly all of the last 7,000 years.

Song et al., 2018
[A] general warm to cold climate trend from the mid-Holocene to the present, which can be divided into two different stages: a warmer stage between 6842 and 1297 cal yr BP and a colder stage from 1297 cal yr BP to the present.
The general cooling trend may represent a response to decreasing solar insolation; however, the relative dryness or wetness of the climate may have been co-determined by westerlies and the East Asian summer monsoon (EASM). The climate had a teleconnection with the North Atlantic region, resulting from changes in solar activity.




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Perner et al., 2018
[W]e find evidence of distinct late Holocene millennial-scale phases of enhanced El Niño/La Niña development, which appear synchronous with northern hemispheric climatic variability. 
Phases of dominant El Niño-like states occur parallel to North Atlantic cold phases: the ‘2800 years BP cooling event’, the ‘Dark Ages’ and the ‘Little Ice Age’, whereas the ‘Roman Warm Period’ and the ‘Medieval Climate Anomaly’ parallel periods of a predominant La Niña-like state. 
Our findings provide further evidence of coherent interhemispheric climatic and oceanic conditions during the mid to late Holocene, suggesting ENSO as a potential mediator.



Share this...FacebookTwitter "
"
Share this...FacebookTwitterVolatile winds, burning generators, failing blades and buckling towers: these are just some of the technical problems plaguing wind power and thus making it a highly undependable and unreliable source of electricity.
Now we hear from NDR German public broadcasting reported of yet another problem plaguing the North Sea Riffgat offshore wind park located off the coast of the island of Borkum: an exposed underwater power transmission line.
Apparently the huge underwater cable delivering the green power from Riffgat to the mainland had been embedded below the seabed, but for some reason last April it somehow worked itself up above the seabed and is now exposed – vulnerable to North Sea maritime traffic.
Today a ship and a crew remain standing guard at the sea surface above the exposed cable in what the NDR calls “probably the most boring job on the planet”.
Riffgat is 15 kilometers northwest of Borkum and just north of the bustling shipping channel in the southern North Sea. Its 30 wind turbines are built over an area of 6 square kilometers and have a total capacity of 113 megawatts.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




It’s not the first time that Riffgat has seen big problems. Between November 2015 and April 2016, transmission troubles kept Riffgat from exporting power.
According to NDR, the Dutch “Faxaborg” patrol ship manned by a crew of four has been floating at the site since April in order to “warn ships of an unusually dangerous area of hazard”.
NDR writes that some 200 meters of the transmission cable became exposed above the seabed one year ago, a condition that has been confirmed by grid-operating company Tennet.
According to NDR, the 50 kilometer long cable was laid with great effort 3 meters below the seabed and that the 200-meter section was washed away by the turbulent North Sea. Tennet says the exposed cable poses no hazard, but the Faxaborg ship was dispatched to stand guard as “a precautionary measure” to make sure “no fishing nets or anchors get caught with the cable”. The cable is only 8 meters below the sea surface at the location.
Guarding the cable is expected to continue indefinitely, at least until summer when the cable can be buried again. But a real solution remains elusive, NDR writes, adding:
Finding the right solution is no easy task. Just how much the entire affair will cost – indirectly to the consumers – was not stated by the Tennet spokesperson. That’s a company secret.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIt has long been established in the scientific literature (and affirmed by the IPCC) that CO2 concentration changes followed Antarctic temperature changes by about 600 to 1000 years during glacial-interglacial transitions throughout the last ~800,000 years (Fischer et al., 1999; Monnin et al., 2001; Caillon et al., 2003; Stott et al., 2007; Kawamura et al., 2007).
In contrast, two new papers cite evidence that the timing of the lagged CO2 response to temperature changes may have ranged between 1300 and 6500 years in some cases.  It would appear that a millennial-scale lagged response to temperature undermines the claim that CO2 concentration changes were a driver of climate in the ancient past.  

Koutavas et al., 2018
Temperature correlations between the eastern equatorial 
Pacific and Antarctica over the past 230,000 years
“The EEP [eastern equatorial Pacific] stack shows persistent covariation with Antarctic temperature on orbital and millennial timescales indicating tight coupling between the two regions. This coupling however cannot be explained solely by CO2 forcing because in at least one important case, the Marine Isotope Stage (MIS) 5e–5d glacial inception, both regions cooled ∼5–6.5 thousand years before CO2 decreased. More likely, their covariation was due to advection of Antarctic climate signals to the EEP by the ocean.”
“The discovery that atmospheric CO2 covaries with Antarctic temperature and global ice volume (Lorius et al., 1990; Lüthi et al., 2008; Petit et al., 1999) has propelled CO2 to the forefront as climatic “globalizer”.  However, the processes governing CO2 variability are themselves poorly understood, and likely require an oceanic/climatic trigger in the first place (Adkins, 2013; Ferrari et al., 2014; Sigman et al., 2010).”
“Antarctic ice core records are furthermore ambiguous with regard to the causal relationship between CO2 and temperature. Phase relationships show CO2 lagging behind temperature in the obliquity band (Jouzel et al., 2007) and across some major transitions (Caillon et al., 2003; Fischer et al., 1999; Kawamura et al., 2007; WAIS Divide Project Members, 2013), most prominently during the Marine Isotope Stage (MIS) 5e–5d boundary, i.e. the last glacial inception. Antarctic cooling at this time was associated with a major Milankovitch signal, and appears to have transpired almost entirely before the change in CO2 concentration. It remains unclear whether the temperature lead was restricted to Antarctica or was broader.”

Uemura et al., 2018
Asynchrony between Antarctic temperature and CO2
associated with obliquity over the past 720,000 years

“Precise knowledge of the relationship between changes in temperature, atmospheric CO2 and solar insolation is essential to understanding Earth’s climate system. The values of a temperature proxy, the hydrogen isotopic composition (δD), in the Antarctic EDC ice core have varied in parallel with CO2 concentrations over the past 800 thousand years (kyr; r2 = 0.82). However, δD [temperature] apparently leads CO2 variations.”
“The lead is ca. 2000 years at a West Antarctic site.”
“Over the past 420 kyr, the Vostok ice core shows that the Antarctic δD temperatures lead the CO2 variations by 1.3 ± 1.0 kyr.”
“During the lukewarm interglacials (430–650 kyr BP), Antarctic δD [temperature] leads CO2 by 1900 years, and the correlation between CO2 and δD is weaker (r2 = 0.57), as determined from the EDC core.”
“Although the mechanisms underlying the coupling and the phase lags remain unclear, the Southern Ocean region, rather than Antarctica, is thought to play the central role in regulating CO2 variations. A box model, for example, estimated a ca. 60% increase in CO2 during TI that is attributable to direct and indirect temperature effects, such as changes in sea ice cover and vertical mixing in the Southern Ocean. On millennial time scales, a multi-proxy study suggests that an antiphased hemispheric temperature response to ocean circulation changes resulted in Antarctic temperatures leading global temperatures and CO2 during TI [the last glacial termination].  … [O]ur data suggest that the lead in Antarctic δD temperatures (i.e. temperature without correcting for source effects) over CO2 is partly attributable to the effects of the moisture source on δD temperatures over the past 720 kyr in the obliquity band. These results suggest that the importance of moisture source effects for the obliquity signal in δD. Thus, the source effect must be considered in future research about the relationship between Antarctic temperatures and CO2.”
“Within the obliquity frequency band, our analyses suggest that temperature variations in Antarctica have led ocean temperatures throughout the past 720 kyr. This phenomenon is most likely explained by the strong influence of local AMI on ΔT. … During TI [the last glacial termination], CO2 rose at ~18 kyr BP, which is related to the melting of the Northern Hemisphere ice sheet and the subsequent weakening of the Atlantic meridional overturning circulation (AMOC). Thus, the timing at which CO2 begins to rise during a termination would be determined by when the Northern Hemisphere ice sheet begins to melt. When eccentricity is small, the summer insolation maxima are small. Thus, if obliquity rises beyond the threshold of melting, a moderate climate forcing could cause warming enough that the southern margin of the North American ice sheet begin to retreat.”

Studies Indicating Temperature-CO2 Lag Was 600-1000 Years

IPCC (2007)
“Atmospheric CO2 follows temperature changes in Antarctica with a lag of some hundreds of years.”

Stott et al., 2007
Southern Hemisphere and Deep-Sea Warming Led Deglacial Atmospheric CO2 Rise and Tropical Warming
“Deep sea temperatures warmed by ~2C between 19 and 17 ka B.P. (thousand years before present), leading the rise in atmospheric CO2 and tropical surface ocean warming by ~1000 years.”

Caillon et al., 2003
“The sequence of events during Termination III suggests that the CO2 increase lagged Antarctic deglacial warming by 800 ± 200 years and preceded the Northern Hemisphere deglaciation.”

Fischer et al., 1999
“High-resolution records from Antarctic ice cores show that carbon dioxide concentrations increased by 80 to 100 parts per million by volume 600 ± 400 years after the warming of the last three deglaciations.”

Monnin et al., 2001
“The start of the CO2 increase thus lagged the start of the [temperature] increase by 800 ± 600 years.”

Indermuhle  et al., 2000
“The lag was calculated for which the correlation coefficient of the CO2 record and the corresponding temperatures values reached a maximum. The simulation yields a [CO2] lag of (1200 ± 700) yr.”

Kawamura et al., 2007    
“Our chronology also indirectly gives the timing of the CO2 rise at [glacial] terminations, which occurs within 1 kyr of the increase in Antarctic temperature.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGame over for green energies and CO2 reductions? 
Journalist Daniel Wetzel of German national daily Die Welt here presents a devastating commentary on Paris Accord and Germany’s so far “illusionary” CO2 reductions targets. The German failure is a signal that could have significant global consequences.
Wetzel not only calls the targets illusionary, he also believes the existing Energiewende (transition to green energies) is “at an end”.
2030 target completely illusionary
According to Wetzel, “The Energiewende and climate change are not among the priorities of the government” and that Germany reaching its self-imposed targets is achievable only if “everyone were forced to switch off every boiler, oven, motor. Completely illusionary.”
Lots of talk, no action
While German political leaders like to continue pretending they are taking real action to combat climate change, the reality is that the German government has been rolling back subsidies for green energies such as wind and sun over the past years. And many localities have made the permitting of wind parks far more stringent.
The days of unfettered support for green energies are over.

Germany’s CO2 equivalent greenhouse gas emissions in millions of tonnes (Source: UBA Federal Office of Environment)
The result: Germany has not reduced its CO2 equivalent emissions for close to a decade (see chart above). Wetzel writes that everyone agrees that it is unrealistic to think that Germany will somehow make the sudden downward trend turn.
German Energiewende “at the end”
The Die Welt journalist adds: “Practically all renowned environmental analysts and government experts have already determined that the German Energiewende structurally has reached the end and that a system change is needed.”
Humans burning fuel one million years
In his commentary Wetzel also reminds that humans have been using fire for some one million years, and that it cannot be expected that they will just stop doing so during the course of one single generation.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Wetzel compares the Energiewende to the Apollo space program, which put man on the moon after 12 years and 120 billion dollars of investment. He notes that compared to the great transformation which Energiewende would entail, this was peanuts.
He warns that implementing the Energiewende could cost the country a back-breaking three trillion euros (without mentioning the impact on climate would be negligible) and doubts the public would ever accept such a large-scale, draconian transformation of society.
German credibility takes a blow
Wetzel also comments the Germany’s failure to make the 2020 targets has tarnished the country’s image as a leader in climate protection, and adds: “The coalition agreement and the German Federal Budget for 2018 robbed all remaining credibility.”
In short Germany’s is not serious about reducing CO2.
Environmental groups and the Potsdam Institute, for example, are fuming, yet keep insisting it’s still not too late and achieving the target is still possible. But Wetzel injects sobriety and realism: “In the meantime we know that Germany will not only fail resoundingly to meet its self-imposed 2020 targets, but also those of the EU itself.”
With Germany as Europe’s largest economy, and regarded as a role model for all things green, the country’s failure would send a devastating message to the rest of the continent and the world: The Green Revolution was mostly a dream and was in fact never attainable. If tech-savvy Germany can’t do it, who can?
“No reality basis”
Yet, German officials continue to insist they can meet the 2030 target! But Die Welt’s Wetzel notes that doing so would mean Germany cutting it’s CO2 equivalent emissions by some 40%, or 350 million tonnes, within the next 12 years. That would mean radical and painful transformations. Recall that Germany has not managed to emissions at over the past decade (see chart above). Wetzel asks: “How credible is this target?”
Die Welt’s Wetzel summarizes:
The feasibility rhetoric of policymakers as a rule has no reality basis.”
Finally, he reminds that Germany going it alone will never work, and that climate protection has to be “organized internationally – or not at all”.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn Germany there is one weather station that has be intact and unchanged for some 138 years. 
It has never been moved and never been corrupted by the urban heat island (UHI) effect. Moreover it has consistently used the same instrumentation and computation method over the entire period, thus making it rare indeed. Few station can boast having those instrumentation qualities.
That measurement station is one operated at the Klostergarten of the St. Stephan Abbey in Augsburg just northwest of Munich.
44-year veteran German meteorologist Klaus Hager reports the following results of this station (reproduced with permission):
======================================
A look at the January mean temperature in Augsburg from 1879 – 2017 ( 138 years)

The chart below shows the chaotic ups and downs of the mean value of the January temperatures measured in the Klostergarten of the St. Stephan Abbey in Augsburg:

First it’s important to note:

The measurement location has not changed since 1879, nor has it been relocated. The garden area remains 1 hectare in size, and thus is completely representative of the Augsburg inner city area.
The mean temperature was computed by halving the sum of the high temperature and the low temperature.
The measurements were always done using glass thermometers – a mercury thermometer for the maximum and an alcohol thermometer for the minimum – inside an official so-called Stevenson screen.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Thus real continuity with respect to measurement is assured.
Over the entire 138-year observation period the measurements were carried out according to the same technical requirements, which is something that unfortunately can only be said about very few measurement stations.
As the chart above shows, one can see considerable temperature fluctuations from year to year. The deviations from the 138-year mean of -1.0°C are shown in red for above-mean temperatures and in blue for those below the mean. Of course since the end of the 1980s, positive deviations have been far more common, but there remains no detectable relationship with the continuously rising CO2 in the air.
Because nature – as is the case with temperature – is constantly undergoing fluctuations, one ought to be especially careful when it comes to making projections into the future. Unfortunately nature’s complexity also does not allow it to be modelled adequately.
January of 2017 was the seventh coldest since 1879, posting a mean of – 6.1°C.
Finally let’s not forget to thank the fathers of the St. Stephan Abbey for having recorded the temperatures every day until today.
 

Share this...FacebookTwitter "
"
Share this...FacebookTwitterWe’ve heard about all the cold and icy weather reports and results coming from all corners of the planet lately, and so naturally most of us sense that it just doesn’t jive with all the alarmist global warming claims and rhetoric we hear.
Tremendous ice growth
For example over the past winter the Arctic ice cap did see unusually warm surface temperatures, yet Arctic sea ice did not shrink as some would intuitively expect it to do.
The truth is that Arctic sea ice volume has gained close to 2 trillion cubic meters over last year alone, and over 2016 – using the data provided by the Danish Meteorological Institute here.
Obviously Arctic sea ice has a lot more to do with other factors than just surface air temperatures in the region. Clearly other major factors must be at play in causing this huge increase.
Japanese skeptic blogger Kirye provided at Twitter a nice animation showing the recent development from April 20 – to May 10:

From April 20 to May 10, 2018, Arctic sea ice volume has been greatest in the last four years.ʕ´•ᴥ•`ʔσDMI:https://t.co/UKdL3sM4Y8~#気候変動 #温暖化? #地球温暖化？ #ClimateChange pic.twitter.com/ET2d3PJ5HR
— キリエ (@KiryeNet) May 12, 2018

As one can see, there’s about 2000 cubic kilometers (2 trillion cubic meters) more ice volume than there was a year earlier and in 2016.
Enormous amount of energy
To put this in perspective, 2 trillion cubic meters of ice are enough to…
– Provide every single human being on the planet with 250 tonnes of ice!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




– Cover entire United States with more than 20 cm of solid ice.
– Cover 67,000 Manhattans with almost a meter of ice!
– Circle the earth with 1 cubic meter blocks 50,000 times!
– Stack 1 m³ blocks to make a pile high enough to reach the sun…13 times!
Imagine: 250 tonnes of ice for each and every person. I’d have to run through the numbers, but I don’t think the average person could freeze that amount of water with the total power he/she uses in a year. We’re talking some serious energy here.
So where could all the ice have come from when we consider that the Arctic surface air temperatures have been so warm?
And what about all the heat that had to be extracted from the water to form the ice? Where did it all go? Most of it of course go radiated out into space and so is forever gone and lost.
Surface temperatures not decisive
As discussed above, surface atmospheric temperatures of course do not play the only major role when it comes to the Arctic sea ice show. Obviously other very powerful factors play huge roles, such as natural oceanic cycles and weather patterns over all Arctic atmospheric layers.
Complex, poorly-understood oceanic-atmospheric system
And vice versa, it also implies that these factors also play a role during the summertime when the Arctic sees unusual summer time melt. Surface temperature cannot be the one and only explanation here, as global warming alarmists like to insist it is. Here as well the oceans, winds and clouds, to name a few, play crucial roles.
Polar sea ice depends on the entire oceanic-atmospheric polar “weather” system — from seabed to upper stratosphere — which sober scientists have long realized is an extremely complex one and is still very poorly understood.
===================================
Check out latest on Southern Hemisphere here.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGreen energy opposition becoming formidable force in Germany
As Germany’s established CDU and SPD “mainstream” parties find themselves imploding, the smaller parties who oppose Germany’s out-of-control Energiewende (transition to green energies) are rapidly becoming a formidable force and making their presence felt in Germany’s national parliament like never before.
For example Germany’s FDP Free Democrats, who refused to forge a coalition government together with CDU/CSU and Green parties, have become increasingly vocal critics of Germany’s green energy scheme.
Politicians ignoring the concerns of its citizens
Last month in her first speech ever in the German Parliament, FDP parliamentarian Sandra Weeser slammed the struggling Energiewende and the latest signals to promote it even further.

In her speech Weeser points out that despite the rapidly growing green energy capacity being installed, the effort to reduce CO2 has failed, and what’s left is an unpredictable power grid that often produces energy when it is not needed (waste energy) and thus costing Germans hundreds of millions annually.
She also accuses the established politicians of ignoring citizens as they ruin Germany’s landscape with wind parks.
Interestingly it is often Green party voters who we find themselves among wind park protesters. In their daily lives these people are recognizing that what is being sold as green electricity in fact has nothing to do with being green. They are rejecting the industrial turbines in forests.”
Weeser then tells that the expansion of the green energies is totally out of proportion with the existing power infrastructure, and that even the most perfect grid will not be able to handle the volatile wind and solar energies.
Electricity “outrageously expensive”
Weeser also dismisses claims by the Green Party that wind energy is “the most inexpensive” on the market, asking them directly: “If that is really true, then why do they need subsidies? Why are we paying 25 billion euros annually for their feed-in?”
Green engineering debacle
Finally she mentions that an array of expert panels have determined that wind energy is not leading to more climate protection, but rather is only making electricity outrageously expensive. In her final comment, Weeser says:
Policymakers should set up the framework conditions, but please leave the engineering to engineers.”
Anti-wind/solar energy AfD soars to 15% in polls


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Also Dr. Rainer Kraft of the Germany’s newly minted rightwing AfD party recently demolished the Energiewende in his first speech before Parliament in Berlin:

According to Kraft, the Parliamentary session on renewable energy requested by the Greens is welcome because it exposes their “incapability to comprehend the factual and physical interrelationships” of the subject.
Policy of a fool…eco-socialist economy
Kraft slams the government’s climate-protection approach of spending “15 euros to avoid 1 euro of damage” as apolicy one would expect from “a fool”. Adding: “there just couldn’t be less scientific understanding than that.”
Echoing Donald Trump’s ideas on international treaties, Kraft also sees them as being ruinous to German industry, and that the ultimate target of climate protection is to establish “an eco-socialist centrally-planned economy” and that climate protection is the “instrument” to bring it about.
He then labeled the Greens’ energy policy as “eco-populist voodoo”.
With so much going wrong with the Energiewende, the FDP and AfD today are having an easy time capitalizing politically on the issue and portraying the government and the Greens as inept.
Vocal green energy critics make up 25% of Parliament
According to recent polls, the FDP and AfD now combine to make up a quarter of Germany’s voters. And now that this anti-Energiewende voice is finally being democratically heard in Parliament and viewed by millions on television screens nationally, expect the traditional established parties to continue seeing the unheard of erosion among their disenchanted voter bases. Never has postwar Germany seen a political shift on such a massive scale.
Tipping point
Though 25% may not sound impressive, it is amazing when one considers that only a decade ago there was virtually universal parliamentary support for green energies. Those days are over.
And now as the failure of the Energiewende becomes ever more glaring, reaching the political tipping point on the issue of the Energiewende is just a question of a few more years.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWe’re always hearing from the European media how winters supposedly have been getting warmer. Yet when we look out the window and look at the hard data, the claim crumbles.
Atlanta ice box, 8-15 cm of snow!
Today snow is forecast across much of Europe. In the US Dr. Ryan Maue tweets if there is any place other than southern Florida where it is not snowing, and: “Atlanta suffering from 3-6″ of global warming today.”
Record low in Hokkaido
Kirye from Japan tweeted telling us that Ikutahara, Hokkaido Prefecture saw with a reading of -24°C the coldest December 9 temperature in at least 40 years:

Hokkaido temperatures giving CO2 the cold shoulder. Data Source: JMA.
-12°C and snow in the UK!
Meanwhile the UK Met Office has issued the amber warning as temperatures are forecast to plummet to -12°C and snow to pile up to 20 cm.
Of course all of the above do not come as any surprise to those who ignore the media climate propaganda and focus on the real data.
Cooling Central Europe winters past 30 years
The European Institute for Climate and Energy Friday posted on Germany mean winter temperature over the past 30 years. A vastly huge majority of Germans would tell you that Germany winters have gotten warmer – because of “global warming” – and so confirm they are only parroting the fake German news.
Yet, EIKE writes what the reality in Germany really is: “Winter has been giving global warming the cold shoulder“.
A chart of the last 30 winters from data from the German DWD national weather services show that German winters in fact have been cooling:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Chart: Josef Kowatsch.
Going back more than 100 years, since 1910, it is also clear that German mean winter temperatures have nothing to do with CO2:

Germany mean winter temperatures with smoothed polynomial trend curve. Chart: Josef Kowatsch.
So before the German DWD weather services and media blurt claims that winters are becoming warmer, they first ought to look at their own data. There hasn’t been any warming since “global warming” started being an issue at the end of the 1980s.
No winter warming elsewhere
The following charts of winter mean temperature depict locations well beyond Germany, showing Central England, Sapporo Japan, Östersund in Central Sweden, and Oymyakon, Eastern Siberia respectively:



No warming trends seen over the past 30 years at these locations. And the eastern Siberian permafrost is not going anywhere anytime soon, Stefan Krämpfe’s chart tells us.
Of course global temperatures as a whole have warmed since 1980, but it’s nothing that comes close to what the alarmists would like to have us believe. The truth is that there’s been very little warming at all since the late 1990s.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAnthropogenic Influence On Arctic Climate
 ‘Too Small To Be Detected’

Source: Haine, 2016

The evidence compiled in scientific papers continues to rapidly accumulate.
An anthropogenic signal in the regional Arctic climate is still too small to be detected.
Temperature, glacier melt, and sea ice changes are all well within the range of natural variation for the Arctic region.  The changes that do occur have identifiable origins that are unrelated to atmospheric CO2 concentrations or human emissions.
Below is a brief summary of some of the latest research that underscores the lack of connection between anthropogenic influences and climate-related changes in the Arctic.

Arctic Temperature And Ice Retreat Mechanisms
1. Arctic Warming Since 1990s ‘Dominated By Natural Variability’ (NAO)
Orsi et al., 2017
The recent warming trend in North Greenland  … We find that δ 18O [temperature/climate proxy] has been increasing over the past 30 years, and that the decade 1996-2005 is the second highest decade in the 287-year record (Figure 4). The highest δ 18O values were found in 1928, which is also an extreme year in GISP2 and NGRIP ice cores, and in a coastal South Greenland composite [Vinther et al., 2006; Masson-Delmotte et al., 2015], but the decadal average (1926-1935) is not statistically different from the decade (2002-2011).
The surface warming trend has been principally attributed to sea ice retreat and associated heat fluxes from the ocean [Serreze et al., 2009; Screen and Simmonds, 2010a, b], to a negative trend in the North Atlantic Oscillation (NAO) since 1990, increasing warm air advection on the West Coast of Greenland and Eastern Canada [Hanna et al., 2012; Fettweis et al., 2013; Ding et al., 2014], and to an increase in the Greenland Blocking Index [Hanna et al., 2013]. These latter mechanisms could be dominated by natural variability rather than forced response to the anthropogenic increase in greenhouse gases [Fettweis et al., 2013; Screen et al., 2014].
2. Arctic Ice Melt Since 1995 Due To Natural Cloud Cover Decrease, NAO
Hofer et al., 2017
Decreasing cloud cover drives the recent mass loss on the Greenland Ice Sheet … The Greenland Ice Sheet (GrIS) has been losing mass at an accelerating rate since the mid-1990s. … We show, using satellite data and climate model output, that the abrupt reduction in surface mass balance since about 1995 can be attributed largely to a coincident trend of decreasing summer cloud cover enhancing the melt-albedo feedback. Satellite observations show that, from 1995 to 2009, summer cloud cover decreased by 0.9 ± 0.3% per year. Model output indicates that the GrIS summer melt increases by 27 ± 13 gigatons (Gt) per percent reduction in summer cloud cover, principally because of the impact of increased shortwave radiation over the low albedo ablation zone. The observed reduction in cloud cover is strongly correlated with a state shift in the North Atlantic Oscillation promoting anticyclonic conditions in summer and suggests that the enhanced surface mass loss from the GrIS is driven by synoptic-scale changes in Arctic-wide atmospheric circulation. … Th[e] strong correlation between summertime NAO index and the MAR-based cloud cover could be used to forecast whether the observed reduction in cloud cover during summer, and the associated increase in GrIS melt, is likely to continue.

3. Geothermal Heat Flux From ‘All Over’ Greenland The ‘Primary Process’ Behind Temperature Changes
Rysgaard et al., 2018
The Greenland ice sheet (GIS) is losing mass at an increasing rate due to surface melt and flow acceleration in outlet glaciers. … Recently it was suggested that there may be a hidden heat source beneath GIS caused by a higher than expected geothermal heat flux (GHF) from the Earth’s interior. Here we present the first direct measurements of GHF from beneath a deep fjord basin in Northeast Greenland. Temperature and salinity time series (2005–2015) in the deep stagnant basin water are used to quantify a GHF of 93 ± 21 mW m−2 which confirm previous indirect estimated values below GIS. A compilation of heat flux recordings from Greenland show the existence of geothermal heat sources beneath GIS and could explain high glacial ice speed areas such as the Northeast Greenland ice stream. … Geothermal springs with source water temperatures above 0 °C have been found all over Greenland, especially around Disko Island in West Greenland, where several thousands of such springs have been identified. … Therefore, we assume that vertical turbulent mixing and GHF [geothermal heat flux] are the primary processes behind the observed salinity and temperature change.
4. Recent Winter Arctic Warming Driven By Planetary Scale Waves
Baggett and Lee, 2017
The dynamical mechanisms that lead to wintertime Arctic warming during the planetary-scale wave (PSW) and synoptic-scale wave (SSW) life cycles are identified by performing a composite analysis of ERA-Interim reanalysis data. The PSW life cycle is preceded by localized tropical convection over the Western Pacific. Upon reaching the mid-latitudes, the PSWs amplify as they undergo baroclinic conversion and constructively interfere with the climatological stationary waves. The PSWs [planetary scale waves] flux large quantities of sensible and latent heat into the Arctic which produces a regionally enhanced greenhouse effect that increases downward IR and warms the Arctic two-meter temperature. The SSW life cycle is also capable of increasing downward IR and warming the Arctic two-meter temperature, but the greatest warming is accomplished in the subset of SSW events with the most amplified PSWs. Consequently, during both the PSW and SSW life cycles, wintertime Arctic warming arises from the amplification of the PSWs [planetary scale waves].
5. Recent Canadian Arctic Warming (1988-1996) And Cooling (1997-2016) Driven By The AO
Mallory et al., 2018
The AO [Arctic Oscillation] has positive and negative phases that infuence broad weather patterns across the northern hemisphere (Thompson et al. 2000). For example, during the positive phase of the AO, atmospheric pressure over the Arctic is lower than average, which tends to result in warmer and wetter winters in northern regions as warmer air is able to move further north (Thompson et al. 2000; Aanes et al. 2002). …  From 1988 to 1996, the summer intensity of the AO was largely in the positive phase, with a mean value of 0.207 (± 0.135 SE), and this was a period of population stability or growth for each of the three herds that we examined here. In contrast, from 1997 to 2016 the summer AO has remained largely in the negative phase [cooling], with a mean value of − 0.154 (± 0.077 SE), and over this period the Bathurst, Beverly, and Qamanirjuaq herds declined in abundance. … We found that positive intensities of the Arctic Oscillation (AO) in the summer were associated with warmer temperatures, improved growing conditions for vegetation, and better body condition of caribou.
6. Greenland Glacier Retreat, Growth Linked To The NAO
Bjørk et al., 2017     
Changes in Greenland’s peripheral glaciers linked to the North Atlantic Oscillation … [W]e map glacier length fluctuations of approximately 350 peripheral glaciers and ice caps in East and West Greenland since 1890. Peripheral glaciers are found to have recently undergone a widespread and significant retreat at rates of 12.2 m per year and 16.6 m per year in East and West Greenland, respectively; these changes are exceeded in severity only by the early twentieth century post-Little-Ice-Age retreat. Regional changes in ice volume, as reflected by glacier length, are further shown to be related to changes in precipitation associated with the North Atlantic Oscillation (NAO), with a distinct east–west asymmetry; positive phases of the NAO increase accumulation, and thereby glacier growth, in the eastern periphery, whereas opposite effects are observed in the western periphery. Thus, with projected trends towards positive NAO in the future, eastern peripheral glaciers may remain relatively stable, while western peripheral glaciers will continue to diminish.
7. Arctic’s Polar Vortex Changes ‘Primarily A Result Of Natural Internally-Generated Climate Variability’
Seviour, 2017
Weakening and shift of the Arctic stratospheric polar vortex: Internal variability or forced response? … By comparing large ensembles of historical simulations with pre-industrial control simulations for two coupled climate models, the ensemble mean response of the vortex is found to be small relative to internal variability. There is also no relationship between sea-ice decline and trends in either vortex location or strength. Despite this, individual ensemble members are found to have vortex trends similar to those observed, indicating that these trends may be primarily a result of natural internally-generated climate variability.
Arctic Temperature Changes In Recent Decades
8. No Net Warming Since 1940s/1950s In Alaska, Subarctic North Atlantic, Siberia…Climate Trends Consistent With 50-90 Year AMO
Nicolle et al., 2018
Persistent multidecadal variability with a period of 50– 90 years is consistent between the subarctic North Atlantic mean record and the AMO over the last 2 centuries (AD 1856–2000). … In the North Atlantic sector, instrumental sea surface temperature (SST) variations since AD 1860 highlight low-frequency oscillations known as the AMO (Kerr, 2000).  …  The LIA is, however, characterized by an important spatial and temporal variability, particularly visible on a more regional scale (e.g., PAGES 2k Consortium, 2013). It has been attributed to a combination of natural external forcings (solar activity and large volcanic eruptions) and internal sea ice and ocean feedback, which fostered long-standing effects of short-lived volcanic events (Miller et al., 2012).



9. Greenland Has Been Cooling Since 2001
Westergaard-Nielsen et al., 2018
Here we quantify trends in satellite-derived land surface temperatures and modelled air temperatures, validated against observations, across the entire ice-free Greenland. … Warming trends observed from 1986–2016 across the ice-free Greenland is mainly related to warming in the 1990’s. The most recent and detailed trends based on MODIS (2001–2015) shows contrasting trends across Greenland, and if any general trend it is mostly a cooling. The MODIS dataset provides a unique detailed picture of spatiotemporally distributed changes during the last 15 years. … Figure 3 shows that on an annual basis, less than 36% of the ice-free Greenland has experienced a significant trend and, if any, a cooling is observed during the last 15 years (<0.15 °C change per year).

10. Greenland Has Been Cooling Since 2005
Kobashi et al., 2017 
For the most recent 10 years (2005 to 2015), apart from the anomalously warm year of 2010, mean annual temperatures at the Summit exhibit a slightly decreasing trend in accordance with northern North Atlantic-wide cooling.  The Summit temperatures are well correlated with southwest coastal records (Ilulissat, Kangerlussuaq, Nuuk, and Qaqortoq).

11. No Net Warming In Greenland For The Last 90 Years
Kobashi et al., 2017


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Arctic Sea Ice Changes 
12. Arctic Sea Ice Expanding Since 1988 (Bohai Sea), AO & NAO ‘Primary’ Climate Factors 
Yan et al., 2017
Afforded by continuous satellite imagery, evolution of sea ice cover over nearly three decades from 1988 to 2015 in the Bohai Sea [North China] as a peculiar mid-latitude frozen sea area is reported for the first time. An anomalous trend of slight overall increase of 1.38 ± 1.00% yr–1 (R = 1.38, i.e. at a statistical significance of 80%) in Bohai Sea ice extent was observed over the 28 year period. …  Correlation with decreasing Arctic Oscillation (AO) index (r = –0.60, p < 0.01) and North Atlantic Oscillation (NAO) index (r = –0.69, p < 0.01) over the study period suggested AO and NAO as the primary large-scale climate factors for Bohai Sea ice.

13. Arctic Sea Ice Oscillates…Not Significantly Lower Now Than In The 1940s
Connolly et al., 2017
According to this new dataset, the recent period of Arctic sea ice retreat since the 1970s followed a period of sea ice growth after the mid 1940s, which in turn followed a period of sea ice retreat after the 1910s. Our reconstructions agree with previous studies that have noted a general decrease in Arctic sea ice extent (for all four seasons) since the start of the satellite era (1979). However, the timing of the start of the satellite era is unfortunate in that it coincided with the end of several decades during which Arctic sea ice extent was generally increasing. This late-1970s reversal in sea ice trends was not captured by the hindcasts of the recent CMIP5 climate models used for the latest IPCC reports, which suggests that current climate models are still quite poor at modelling past sea ice trends.

14. Arctic Sea Ice Extent Only Slightly Lower Now Than During Little Ice Age, Much Higher Now Than Most Of Last 7,000 Years
Perner et al., 2018
[W]e find evidence of distinct late Holocene millennial-scale phases of enhanced El Niño/La Niña development, which appear synchronous with northern hemispheric climatic variability. Phases of dominant El Niño-like states occur parallel to North Atlantic cold phases: the ‘2800 years BP cooling event’, the ‘Dark Ages’ and the ‘Little Ice Age’, whereas the ‘Roman Warm Period’ and the ‘Medieval Climate Anomaly’ parallel periods of a predominant La Niña-like state. Our findings provide further evidence of coherent interhemispheric climatic and oceanic conditions during the mid to late Holocene, suggesting ENSO as a potential mediator.

15. Solar Forcing Drives Arctic Sea Ice Trends, Sea Ice Higher Now Than Nearly All Of The Last 8,000 Years
Yamamoto et al., 2017
Millennial to multi-centennial variability in the quartz / feldspar ratio (the BG [Beaufort Gyre] circulation) is consistent with fluctuations in solar irradiance, suggesting that solar activity affected the BG [Beaufort Gyre] strength on these timescales. … Multi-century to millennial fluctuations, presumably controlled by solar activity, were also identified in a proxy-based BSI [Bering Strait in-flow] record characterized by the highest age resolution. … Proxy records consistent with solar forcing were reported from a number of paleoclimatic archives, such as Chinese stalagmites (Hu et al., 2008), Yukon lake sediments (Anderson et al., 2005), and ice cores (Fisher et al., 2008), as well as marine sediments in the northwestern Pacific (Sagawa et al., 2014) and the Chukchi Sea (Stein et al., 2017).

16. Southwest Greenland: Sea Ice Increasing Since 1930s, No Net Change In Temperature Since 1600
Kryk et al., 2017     
Our study aims to investigate the oceanographic changes in SW Greenland over the past four centuries (1600-2010) based on high-resolution diatom record using both, qualitative and quantitative methods.  July SST during last 400 years varied only slightly from a minimum of 2.9 to a maximum of 4.7 °C and total average of 4°C. 4°C is a typical surface water temperature in SW Greenland during summer.
The average April SIC [sea ice concentration] was low (c. 13%) [during the 20th century], however a strong peak of 56.5% was recorded at 1965. This peak was accompanied by a clear drop in salinity (33.2 PSU).

17. Arctic Sea Ice Trends Linked To The AMO, NAO, Sea Ice Lower Than Today During Medieval Climate Anomaly
Kolling et al., 2017     
[O]ur reconstructions reveal several oscillations with increasing/decreasing sea ice concentrations that are linked to the known late Holocene climate cold/warm phases, i.e. the Roman Warm Period, Dark Ages Cold Period, Medieval Climate Anomaly and Little Ice Age. The observed changes seem to be connected to general ocean atmosphere circulation changes, possibly related to North Atlantic Oscillation and Atlantic Multidecadal Oscillation regimes. Furthermore, we identify a cyclicity of 73–74 years in sea ice algae and phytoplankton productivity over the last 1.2 kyr, which may indicate a connection to Atlantic Multidecadal Oscillation mechanisms.

18. Arctic Amplification, Sea Ice Loss Not Explained By CO2 Forcing
Kim et al., 2017
Understanding the Mechanism of Arctic Amplification and Sea Ice Loss
Sea ice reduction is accelerating in the Barents and Kara Seas. Several mechanisms are proposed to explain the accelerated loss of polar sea ice, which remains an open question. … [T]he role of upward and downward longwave radiations in Arctic amplification is vague and not fully understood.
[CO2 is not mentioned in the paper as a mechanism responsible for Arctic amplification or sea ice loss.]
Long Term Changes In Arctic Region Temperatures
19. Greenland 1°C to 3°C Warmer Than Now For Most Of The Last 8,000 Years
Kobashi et al., 2017
After the 8.2 ka event, Greenland temperature reached the Holocene thermal maximum with the warmest decades occurring during the Holocene (2.9 ± 1.4 °C warmer than the recent decades) at 7960 ± 30 years B.P.

20. Arctic-Wide Temperatures Warmer Than Now During The Medieval Warm Period
Werner et al., 2017
[S]tatistical testing could not provide conclusive support of the contemporary warming to supersede the peak of the MCA [Medieval Climate Anomaly] in terms of the pan-Arctic mean summer temperatures.

21. Northern Alaska Warmer During Medieval Times
Hanna et al., 2018
Here, we utilize one such sediment archive from Simpson Lagoon, Alaska, located adjacent to the Colville River Delta to reconstruct temperature variability and fluctuations in sediment sourcing over the past 1700 years. Quantitative reconstructions of summer air temperature […] reveal temperature departures correlative with noted climate events (i.e. ‘Little Ice Age’, ‘Medieval Climate Anomaly’). … Reconstructed temperatures are generally coolest between 300 and 800 CE (Tavg = 2.24 ± 0.98°C), displaying three temperature minima centered at 410 CE (1.34 ± 0.72°C), 545 CE (1.91 ± 0.69°C), and 705 CE (1.49 ± 0.69°C). Temperatures then rapidly increased, reaching the warmest interval (800–1000 CE) in the approximately 1700-year record. During this interval, average temperatures were 3.31 ± 0.65°C, with a maximum temperature of 3.98°C.

Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Source: American Geophysical Union Fall Meeting
At next month’s American Geophysical Union (AGU) Fall Meeting in New Orleans (US), an independent researcher named Trevor Underwood will be presenting an equation-rich analysis that thoughtfully undermines the perspective that increases in CO2 concentrations are a fundamental variable affecting climate.
Instead, Underwood argues that the absorption band where CO2 emissivity could have an effect is likely already saturated, precluding the capacity of increased CO2 concentrations to produce atmospheric warming.
He also advances the position that solar irradiance changes can explain modern temperature variations, which is consistent with other recent analyses.
It seems that more and more of these papers questioning the “consensus” view on the efficacy of the CO2 within the greenhouse effect are being considered in scientific circles.  Several previous examples are listed below.
The volume of contrarian analyses would seem to suggest that the climate’s specific sensitivity to CO2 concentration changes is not yet settled.
And so the debate rages on.

•   Another New Paper Dismantles The CO2 Greenhouse Effect ‘Thought Experiment’
•   New Paper: CO2 Has ‘Negligible’ Influence On Earth’s Temperature
•   3 Chemists Conclude CO2 Greenhouse Effect Is ‘Unreal’, Violates Laws Of Physics, Thermodynamics
•   Ph.D. Physicist Uses Empirical Data To Assert CO2 Greenhouse Theory A ‘Phantasm’ To Be ‘Neglected’
•   Swiss Physicist Concludes IPCC Assumptions ‘Violate Reality’…CO2 A ‘Very Weak Greenhouse Gas’
•   Recent CO2 Climate Sensitivity Estimates Continue Trending Towards Zero
•   A Swelling Volume Of Scientific Papers Now Forecasting Global Cooling In The Coming Decades
•   Russian Scientists Dismiss CO2 Forcing, Predict Decades Of Cooling, Connect Cosmic Ray Flux To Climate
•   2 New Papers: Models ‘Severely Flawed’, Temp Changes Largely Natural, CO2 Influence ‘Half’ Of IPCC Claims
•   Leading Heat Transfer Physicists/Geologists Assert The Impact Of CO2 Emissions On Climate Is ‘Negligible’
•   New Atmospheric Sciences Textbook: Climate Sensitivity Just 0.4°C For CO2 Doubling
•  U of Canberra Expert: Doubling Atmospheric CO2 Would Increase ‘Heating By Less Than 0.01°C’
•   Uncertainties, Errors In Radiative Forcing Estimates 10 – 100 Times Larger Than Entire Radiative Effect Of Increasing CO2
•   New Paper Documents Imperceptible CO2 Influence On The Greenhouse Effect Since 1992



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Underwood, 2017
No Increase in Earth’s Surface Temperature From Increase in Carbon Dioxide 
A critical look at these different in situ measures of the Earth’s surface temperature identified a divergence between land and marine surface temperatures, with land surface air temperatures showing a significant and increasing rate of warming of around 0.5°C between 1880 and 1981, and 0.7°C between 1982 and 2010, whilst marine air temperatures show little if any change between 1880 and 2010 (Underwood (1) 2017). Recent academic literature is also beginning to question the accuracy of the adjusted in situ data (Kent et al. 2017).
In order for an increase in carbon dioxide or other greenhouse gas concentration in the atmosphere to result in an increase in the surface temperature of the Earth, it must be able to increase the absorption of infrared radiation emitted from the surface. This would result in an increase in the absorption factor, f. However, as seen above f is currently around 0.9444. Absorption of infrared radiation by molecules of greenhouse gases, involves increasing the internal energy of the molecule by changing the quantum state of the molecules, which can only occur at particular wavelengths, known as absorption bands. 
These absorption bands can be extended by what is referred to as pressure broadening (Strong and Plass 1950; Kaplan 1952), but when all of the emitted infrared radiation within these absorption bands has been absorbed by greenhouse gas molecules in the atmosphere, no further absorption of the terrestrial radiation is possible. The radiation with wavelengths falling outside of the absorption bands passes through the atmosphere and escapes into space.
Absorption of solar radiation in in the stratosphere is almost 100% efficient in the ultraviolet due to electronic transitions of oxygen (O2) and ozone (O3) and a significant amount of solar radiation is absorbed by water vapor (H2O) in the lower atmosphere. It is primarily the visible radiation that is absorbed at the Earth’s surface. In the infrared, absorption is again almost 100% efficient because of the greenhouse gases, but there is a window between 8 and 13 mm, near the peak of terrestrial emission, where the atmosphere is only a weak absorber except for a strong ozone feature at 9.6 mm. This atmospheric window allows direct escape of radiation from the surface of the Earth to space and is of importance in determining the temperature of the Earth’s surface (Jacob 1999).
Additional leakage could occur if the greenhouse gas concentration in the atmosphere were insufficient to absorb all of the infrared radiation in the absorption bands emitted by the Earth’s surface, but due to the extent of the atmosphere and its known unsaturated state, it is more likely that the current leakage corresponds to radiation in the part of the infrared spectrum that does not fall in the greenhouse gas absorption and emission bands, referred to as the “infrared window”. As a consequence, even in the case where there is leakage of infrared radiation from the Earth’s surface directly into space, as long as the atmosphere is able to absorb all of the upwelling infrared radiation in the greenhouse gas absorption bands, neither the amount of this leakage nor the amount of the absorption will depend on concentration of greenhouse gases in the atmosphere. From the emission spectra (a) and absorption percentages (b) in the diagram above (Fig. 2.6, Yang 2016), where the 255°K blackbody curve represents the terrestrial radiation, it appears that at the current surface temperature and absorption factor of 0.9444 all of the radiation within the emission bands is fully absorbed, and that the remaining 5.56 percent of the infrared emission represents radiation with wavelengths within the atmospheric window. If this is true, there can be no further increase in f [absorption], and no increase in the surface temperature with an increase in carbon dioxide.
Increase In Solar Forcing Explains Recent Warming
The difference between the minima showed an increase of 0.2812 W/m-2 for VIRGO; 0.4701 W/m-2 for ACRIM; and 0.2650 W/m-2 for ACRIM + TIM over the 11.6 year solar cycle 23 beginning in May 1996 and ending in January 2008; or 0.24 W/m-2 per decade for VIRGO, 0.40 W/m-2 per decade for ACRIM, and 0.23 W/m-2 per decade for ACRIM + TIM (pmodwrc website
 2016).
These decadal increases in TSI [Total Solar Irradiance] from ACRIM, SARR, VIRGO and ACRIM + TIM are sufficient to explain the whole of the increase in surface temperature estimated from in situ data during the last 100 years. They compare with the six published model-based estimates of forcing examined in Schwartz (2012) that showed forcing by incremental greenhouse gases and aerosols over the twentieth century ranging between 0.11 and 0.21 W/m-2 per decade.
Summary
Solution of the Greenhouse Effect equations based on a more realistic atmospheric model that includes absorption of solar radiation by the atmosphere, thermals and evaporation, and an examination of the fraction of terrestrial infrared radiation absorbed whilst passing through the atmosphere, suggests that the contribution of greenhouse gases to the surface temperature is close to its upper limit. Any further contribution would depend on an increase in the infrared absorption factor of the atmosphere from its current level of around 0.9444, which seems unlikely. As this appears to correspond to total absorption of all black body infrared emission from the Earth’s surface at wavelengths at which there are greenhouse gas absorption bands, including for water vapor, it seems likely that we are close to the thermodynamic limit of greenhouse warming for the current luminosity of the sun, and that any further increase in carbon dioxide concentration in the atmosphere will have little or no effect on the surface temperature of the Earth. Questions about the reliability of in situ measurements of surface temperatures also raise questions about current estimates of global warming. Moreover, recent evidence from satellite measurements of solar irradiance, indicate that any recent warming could be due to increasing solar irradiance.

A conference paper with a similar conclusion regarding the emissive/warming limitations of increased CO2 concentrations was presented by a molecular physicist, Dr. N. Doustimotlagh, at the World Conference On Climate Change in October, 2016.



Doustimotlagh and Mirzaee, 2016


So because of the limited values of electromagnetic waves that come from Earth and limitation of  absorption of greenhouse gasses, the greenhouse effect of greenhouse gasses should be limited.  In other words, after absorbing of all the IR waves that come from Earth by greenhouse gasses in the atmosphere, there are no IR waves to cause greenhouse effect. It means that “two things that cause greenhouse effect are greenhouse gasses and IR waves in absorption spectrum of these gasses, so if greenhouse gasses increases but there are no IR waves, it is natural that there is no greenhouse effect”.

If the concentration of CO2 in atmosphere increases until absorbs all the values of  electromagnetic waves that are absorbable for CO2, additional values of CO2 should not have greenhouse effect.



Share this...FacebookTwitter "
"
Share this...FacebookTwitterUpdated: The Shrinking 
CO2 Climate Sensitivity

A recently highlighted paper published by atmospheric scientists Scafetta et al., (2017) featured a graph (above) documenting post-2000 trends in the published estimates of the Earth’s climate sensitivity to a doubling of CO2 concentrations (from 280 parts per million to 560 ppm).
The trajectory for the published estimates of transient climate response (TCR, the average temperature response centered around the time of CO2 doubling) and equilibrium climate sensitivity (ECS, the temperature response upon reaching an equilibrium state after doubling) are shown to be declining from an average of about 3°C earlier in the century to below 2°C and edging towards 1°C for the more recent years.
This visual evidence would appear to indicate that past climate model determinations of very high climate sensitivity (4°C, 5°C, 6°C and up) have increasingly been determined to be in error.  The anthropogenic influence on the Earth’s surface temperature has likely been significantly exaggerated.

Scafetta et al., 2017   “Since 2000 there has been a systematic tendency to find lower climate sensitivity values. The most recent studies suggest a transient climate response (TCR) of about 1.0 °C, an ECS less than 2.0 °C and an effective climate sensitivity (EfCS) in the neighborhood of 1.0 °C.”
“Thus, all evidences suggest that the IPCC GCMs at least increase twofold or even triple the real anthropogenic warming. The GHG theory might even require a deep re-examination.”

An Update On The Gradually Declining Climate Sensitivity


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The graph shown in Scafetta et al. (2017) ends in 2014, which means that papers published in the last 3 years are not included.   Also, there were several other published climate sensitivity papers from the last decade that were excluded from the analysis, possibly because they did not include and/or specify TCR and/or ECS estimates in isolation, but instead just used a generic doubled-CO2 climate sensitivity value (shown in purple here).
Below is a new, updated graph that (1) includes some of the previously unidentified papers and (2) adds the 10 – 12 climate sensitivity papers published in the last 3 years.  Notice, again, that the trend found in published papers has continued downwards, gradually heading towards zero.  The reference list for the over 20 additional papers used for the updated analysis is also included below.
For a more comprehensive list of over 60 papers with very low (<1°C) climate sensitivity estimates, see here.



Smirnov, 2017 (~0.4°C)
It is shown that infrared emission of the atmosphere is determined mostly by atmospheric water. One can separate the flux of outgoing infrared radiation of the atmosphere from that towards the Earth. The fluxes due to rotation-vibration transitions of atmospheric   CO2  molecules are evaluated. Doubling of the concentration of  CO2 molecules in the atmosphere that is expected over 130 years leads to an increase of the average Earth temperature by (0.4±0.2) K mostly due to the flux towards the Earth if other atmospheric parameters are not varied.

Smirnov, 2016
[W]e take into account that CO2 molecules give a small contribution to the heat Earth balance and, therefore, one can use the altitude distribution of the temperature for the standard atmosphere model [1], and a variation of the CO2 concentration does not influence this distribution.  …  [I]njection of CO2 molecules into the atmosphere leads to a decrease of the outgoing radiation flux that causes a decrease of the average Earth temperature. But this decrease is below 0.1K that is the accuracy of determination of this value.  Thus, the presence of carbon dioxide in the atmosphere decreases the outgoing atmospheric radiative flux that leads to a decrease of the Earth temperature by approximately (1.8 ± 0.1) K. The change of the average temperature at the double of the concentration of atmospheric CO2 molecules is determined by the transition at 667cm−1 only and is lower than 0.1K.
In particular, doubling of the concentration of CO2 molecules compared to the contemporary content increases the global Earth temperature by ΔT = 0.4 ± 0.2K. … From this we have that the average temperature variation ΔT = 0.8 ◦C from 1880 up to now according to NASA data may be attained by the variation of the water concentration by 200ppm or Δu/u ≈ 0.07, Δu = 0.2. Note that according to formula (2) the variation of an accumulated concentration of CO2 molecules from 1959 (from 316ppm up to 402ppm) leads to the temperature variation ΔT = 0.15°C. One can see that the absorption of a water molecule in infrared spectrum is stronger than that of the CO2 molecule because of their structures, and the injection of water molecules in the atmosphere influences its heat balance more strongly than the injection of CO2 molecules.



Reinhart, 2017 (<0.24°C)
Our results permit to conclude that CO2 is a very weak greenhouse gas and cannot be accepted as the main driver of climate change. … The assumption of a constant temperature and black body radiation definitely violates reality and even the principles of thermodynamics. … [W]e conclude that the temperature increases predicted by the IPCC AR5 lack robust scientific justification. … A doubling [to 800 ppm] of the present level of CO2 [400 ppm] results in  [temperature change] < 0.24 K. … [T]he scientific community must look for causes of climate change that can be solidly based on physics and chemistry. … The observed temperature increase since pre-industrial times is close to an order of magnitude higher than that attributable to CO2.

Abbot and Marohasy, 2017  (0.6°C equilibrium)
The largest deviation between the ANN [artificial neural network] projections and measured temperatures for six geographically distinct regions was approximately 0.2 °C, and from this an Equilibrium Climate Sensitivity (ECS) of approximately 0.6 °C [for a doubling of CO2 from 280 ppm to 560 ppm plus feedbacks] was estimated. This is considerably less than estimates from the General Circulation Models (GCMs) used by the Intergovernmental Panel on Climate Change (IPCC), and similar to estimates from spectroscopic methods.
The proxy measurements suggest New Zealand’s climate has fluctuated within a band of approximately 2°C since at least 900 AD, as shown in Figure 2. The warming of nearly 1°C since 1940 falls within this band. The discrepancy between the orange and blue lines in recent decades as shown in Figure 3, suggests that the anthropogenic contribution to this warming could be in the order of approximately 0.2°C. [80% of the warming since 1940 may be due natural factors].

 Harde, 2016 (0.7°C equilibrium)
Including solar and cloud effects as well as all relevant feedback processes our simulations give an equilibrium climate sensitivity of CS = 0.7 °C (temperature increase at doubled CO2) and a solar sensitivity of SS = 0.17 °C (at 0.1 % increase of the total solar irradiance). Then CO2 contributes 40 % and the Sun 60 % to global warming over the last century.

Bates, 2016  (~1°C)
Estimates of 2xCO2 equilibrium climate sensitivity (EqCS) derive from running global climate models (GCMs) to equilibrium. Estimates of effective climate sensitivity (EfCS) are the corresponding quantities obtained using transient GCM output or observations. The EfCS approach uses an accompanying energy balance model (EBM), the zero-dimensional model (ZDM) being standard. GCM values of EqCS and EfCS vary widely [IPCC range: (1.5, 4.5)°C] and have failed to converge over the past 35 years. Recently, attempts have been made to refine the EfCS approach by using two-zone (tropical/extratropical) EBMs. When applied using satellite radiation data, these give low and tightly-constrained EfCS values, in the neighbourhood of 1°C. … The central conclusion of this study is that to disregard the low values of effective climate sensitivity (≈1°C) given by observations on the grounds that they do not agree with the larger values of equilibrium, or effective, climate sensitivity given by GCMs, while the GCMs themselves do not properly represent the observed value of the tropical radiative response coefficient, is a standpoint that needs to be reconsidered.

Evans, 2016 (<0.5°C equilibrium)
The conventional basic climate model applies “basic physics” to climate, estimating sensitivity to CO2. However, it has two serious architectural errors. It only allows feedbacks in response to surface warming, so it omits the driver-specific feedbacks. It treats extra-absorbed sunlight, which heats the surface and increases outgoing long-wave radiation (OLR), the same as extra CO2, which reduces OLR from carbon dioxide in the upper atmosphere but does not increase the total OLR. The rerouting feedback is proposed. An increasing CO2 concentration warms the upper troposphere, heating the water vapor emissions layer and some cloud tops, which emit more OLR and descend to lower and warmer altitudes. This feedback resolves the nonobservation of the “hotspot.” An alternative model is developed, whose architecture fixes the errors. By summing the (surface) warmings due to climate drivers, rather than their forcings, it allows driver-specific forcings and allows a separate CO2 response (the conventional model applies the same response, the solar response, to all forcings). It also applies a radiation balance, estimating OLR from properties of the emission layers. Fitting the climate data to the alternative model, we find that the equilibrium climate sensitivity is most likely less than 0.5°C, increasing CO2 most likely caused less than 20% of the global warming from the 1970s, and the CO2 response is less than one-third as strong as the solar response. The conventional model overestimates the potency of CO2 because it applies the strong solar response instead of the weak CO2response to the CO2 forcing.

Gervais, 2016 [full]  (<0.6°C transient)
Conclusion: Dangerous anthropogenic warming is questioned (i) upon recognition of the large amplitude of the natural 60–year cyclic component and (ii) upon revision downwards of the transient climate response consistent with latest tendencies shown in Fig. 1, here found to be at most 0.6 °C once the natural component has been removed, consistent with latest infrared studies (Harde, 2014). Anthropogenic warming well below the potentially dangerous range were reported in older and recent studies (Idso, 1998; Miskolczi, 2007; Paltridge et al., 2009; Gerlich and Tscheuschner, 2009; Lindzen and Choi, 2009, 2011; Spencer and Braswell, 2010; Clark, 2010; Kramm and Dlugi, 2011; Lewis and Curry, 2014; Skeie et al., 2014; Lewis, 2015; Volokin and ReLlez, 2015). On inspection of a risk of anthropogenic warming thus toned down, a change of paradigm which highlights a benefit for mankind related to the increase of plant feeding and crops yields by enhanced CO2 photosynthesis is suggested.

Marvel et al., 2016 (1.8°C transient, 3.0°C equilibrium)
Assuming that all forcings have the same transient efficacy as greenhouse gases, and following a previous study, the best estimate (median) for TCR is 1.3°C. However, scaling each forcing by our estimates of transient efficacy (determined from either iRF or ERF), we obtain a best estimate for TCR of 1.8°C. This scaling simultaneously considers both forcing and ocean heat uptake efficacy. Other estimates of TCR which differ slightly due to choices of base period and uncertainty estimates and the aerosol forcing used, are similarly revised upward when using calculated efficacies.  We apply the same reasoning to estimates of ECS. Using an estimate4 of the rate of recent heat uptake Q = 0.65 ± 0.27 W m-2, we find, assuming all equilibrium efficacies are unity, a best estimate of ECS = 2.0°C, comparable to the previous result of 1.9°C.  However, as with TCR, accounting for differences in equilibrium forcing efficacy revises the estimate upward; our new best estimate (using efficacies derived from the iRF) is 2.9°C. If efficacies are instead calculated from the ERF, the best estimate of ECS is 3.0°C. As for TCR, alternate estimates of ECS are revised upward when efficacies are taken into account.

Soon, Connolly, and Connolly, 2015 [full] (0.44°C)
Nonetheless, let us ignore the negative relationship with greenhouse gas (GHG) radiative forcing, and assume the carbon dioxide (CO2) relationship is valid. If atmospheric carbon dioxide concentrations have risen by ~110 ppmv since 1881 (i.e., 290→400 ppmv), this would imply that carbon dioxide (CO2) is responsible for a warming of at most 0.0011 × 110 = 0.12°C over the 1881-2014 period, where 0.0011 is the slope of the line in Figure 29(a). We can use this relationship to calculate the so-called “climate sensitivity” to carbon dioxide, i.e., the temperature response to a doubling of atmospheric carbon dioxide. According to this model, if atmospheric carbon dioxide concentrations were to increase by ~400 ppmv, this would contribute to at most 0.0011 × 400 = 0.44°C warming. That is, the climate sensitivity to atmospheric carbon dioxide is at most 0.44°C.

Lewis and Curry, 2015 (1.33°C  transient, 1.64°C  equilibrium)
Energy budget estimates of equilibrium climate sensitivity (ECS) and transient climate response (TCR) are derived using the comprehensive 1750–2011 time series and the uncertainty ranges for forcing components provided in the Intergovernmental Panel on Climate Change Fifth Assessment Working Group I Report, along with its estimates of heat accumulation in the climate system. The resulting estimates are less dependent on global climate models and allow more realistically for forcing uncertainties than similar estimates based on forcings diagnosed from simulations by such models. Base and final periods are selected that have well matched volcanic activity and influence from internal variability. Using 1859–1882 for the base period and 1995–2011 for the final period, thus avoiding major volcanic activity, median estimates are derived for ECS of 1.64 K and for TCR of 1.33 K.

Johansson et al., 2015 (2.5°C  equilibrium)
A key uncertainty in projecting future climate change is the magnitude of equilibrium climate sensitivity (ECS), that is, the eventual increase in global annual average surface temperature in response to a doubling of atmospheric CO2 concentration. The lower bound of the likely range for ECS given in the IPCC Fifth Assessment Report was revised downwards to 1.5 °C, from 2 °C in its previous report, mainly as an effect of considering observations over the warming hiatus—the period of slowdown of global average temperature increase since the early 2000s. Here we analyse how estimates of ECS change as observations accumulate over time and estimate the contribution of potential causes to the hiatus. We find that including observations over the hiatus reduces the most likely value for ECS from 2.8 °C to 2.5 °C, but that the lower bound of the 90% range remains stable around 2 °C. We also find that the hiatus is primarily attributable to El Niño/Southern Oscillation-related variability and reduced solar forcing.

Kissin, 2015 (~0.6°C)
[A] doubling the CO2 concentration in the Earth’s atmosphere would lead to an increase of the surface temperature by about +0.5 to 0.7 °C, hardly an effect calling for immediate drastic changes in the planet’s energy policies. An increase in the absolute air humidity caused by doubling the CO2 concentration and the resulting decrease of the outgoing IR flux would produce a relatively small additional effect due to a strong overlap of IR spectral bands of CO2 and H2O, the two compounds primarily responsible for the greenhouse properties of the atmosphere.

Kimoto, 2015  [full] (~0.16°C)
The central dogma is critically evaluated in the anthropogenic global warming (AGW) theory of the IPCC, claiming the Planck response is 1.2K when CO2 is doubled. The first basis of it is one dimensional model studies with the fixed lapse rate assumption of 6.5K/km. It is failed from the lack of the parameter sensitivity analysis of the lapse rate for CO2 doubling. The second basis is the Planck response calculation by Cess in 1976 having a mathematical error. Therefore, the AGW theory is collapsed along with the canonical climate sensitivity of 3K utilizing the radiative forcing of 3.7W/m2 for CO2 doubling. The surface climate sensitivity is 0.14 – 0.17 K in this study with the surface radiative forcing of 1.1 W/m2.

Ollila, 2014 (~0.6°C equilibrium)
According to this study the commonly applied radiative forcing (RF) value of 3.7 Wm-2 for CO2 concentration of 560 ppm includes water feedback. The same value without water feedback is 2.16 Wm-2 which is 41.6 % smaller. Spectral analyses show that the contribution of CO2 in the greenhouse (GH) phenomenon is about 11 % and water’s strength in the present climate in comparison to CO2 is 15.2. The author has analyzed the value of the climate sensitivity (CS) and the climate sensitivity parameter (l) using three different calculation bases. These methods include energy balance calculations, infrared radiation absorption in the atmosphere, and the changes in outgoing longwave radiation at the top of the atmosphere. According to the analyzed results, the equilibrium CS (ECS) is at maximum 0.6 °C and the best estimate of l is 0.268 K/(Wm-2 ) without any feedback mechanisms.

Loehle, 2014  (1.1°C  transient, 2.0°C  equilibrium)
Estimated sensitivity is 1.093 °C (transient) and 1.99 °C (equilibrium).  Empirical study sensitivity estimates fall below those based on GCMs.

Skeie et al., 2014  (1.8°C  equilibrium)
Equilibrium climate sensitivity (ECS) is constrained based on observed near-surface temperature change, changes in ocean heat content (OHC) and detailed radiative forcing (RF) time series from pre-industrial times to 2010 for all main anthropogenic and natural forcing mechanism. The RF time series are linked to the observations of OHC and temperature change through an energy balance model (EBM) and a stochastic model, using a Bayesian approach to estimate the ECS and other unknown parameters from the data. For the net anthropogenic RF the posterior mean in 2010 is 2.0 Wm−2, with a 90% credible interval (C.I.) of 1.3 to 2.8 Wm−2, excluding present-day total aerosol effects (direct + indirect) stronger than −1.7 Wm−2. The posterior mean of the ECS is 1.8 °C, with 90% C.I. ranging from 0.9 to 3.2 °C, which is tighter than most previously published estimates.

Scafetta, 2013 (1.5°C)
A quasi 60-year natural oscillation simultaneously explains the 1850–1880, 1910–1940 and 1970–2000 warming periods, the 1880–1910 and 1940–1970 cooling periods and the post 2000 GST plateau. This hypothesis implies that about 50% of the ~ 0.5 °C global surface warming observed from 1970 to 2000 was due to natural oscillations of the climate system, not to anthropogenic forcing as modeled by the CMIP3 and CMIP5 GCMs. Consequently, the climate sensitivity to CO2 doubling should be reduced by half, for example from the 2.0–4.5 °C range (as claimed by the IPCC, 2007) to 1.0–2.3 °C with a likely median of ~ 1.5 °C instead of ~ 3.0 °C.

Asten, 2012 (1.1°C)
Climate sensitivity estimated from the latter is 1.1 ± 0.4 °C (66% confidence) compared with the IPCC central value of 3 °C. The post Eocene-Oligocene transition (33.4 Ma) value of 1.1 °C obtained here is lower than those published from Holocene and Pleistocene glaciation-related temperature data (800 Kya to present) but is of similar order to sensitivity estimates published from satellite observations of tropospheric and sea-surface temperature variations. The value of 1.1 °C is grossly different from estimates up to 9 °C published from paleo-temperature studies of Pliocene (3 to 4 Mya) age sediments. 

Lindzen and Choi, 2011 (0.7°C)
As a result, the climate sensitivity for a doubling of CO2 is estimated to be 0.7K (with the confidence interval 0.5K – 1.3K at 99% levels). This observational result shows that model sensitivities indicated by the IPCC AR4 are likely greater than the possibilities estimated from the observations.

Florides and Christodoulides, 2009 (~0.02°C)
A very recent development on the greenhouse phenomenon is a validated adiabatic model, based on laws of physics, forecasting a maximum temperature-increase of 0.01–0.03 °C for a value doubling the present concentration of atmospheric CO2. 

Gray, 2009 (~0.4°C)
CO2 increases without positive water vapor feedback could only have been responsible for about  0.1 – 0.2 °C of the 0.6-0.7°C global mean surface temperature warming that has been observed since the early 20th  century.  Assuming a doubling of CO2 by the late 21st  century (assuming no  positive water vapor feedback), we should likely expect to see no more than about 0.3-0.5°C global surface warming and certainly not the 2-5°C warming that has been projected by the GCMs [global circulation models].

Chylek et al., 2007 (~0.39°C)
Consequently, both increasing atmospheric concentration of greenhouse gases and decreasing loading of atmospheric aerosols are major contributors to the top-of atmosphere radiative forcing. We find that the climate sensitivity is reduced by at least a factor of 2 when direct and indirect effects of decreasing aerosols are included, compared to the case where the radiative forcing is ascribed only to increases in atmospheric concentrations of carbon dioxide. We find the empirical climate sensitivity to be between 0.29 and 0.48 K/Wm-2 when aerosol direct and indirect radiative forcing is included.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Comedy clubs aren’t usually thought of as venues for serious debate about controversial topics like climate change.
And yet in a rare debate opportunity, Harvard-Smithsonian Center astrophysicist Dr. Willie Soon took full advantage of the short time he had available to him.  He critiqued “consensus” science, the ocean acidification narrative, the poverty-inducing reliance on wind and solar energies, and climate change alarmism in general.
Dr. Jon Christensen, his opponent, an adjunct assistant professor in the Institute of the Environment and Sustainability, emphasized the “consensus” and the “existential threat” of climate change, extolled the expansion of renewable energy sources like wind and solar in California, and insisted that politicians in the Golden State are focused on not burdening poor people with their “green” policies.
A summary highlighting some of the more interesting exchanges and their corresponding timelines follows.

(1) Dr. Soon: CO2 a benefit, minimal sea level rise awaits
Dr. Christensen: CO2 rise an existential, apocalyptic threat
2:25 Dr. Willie Soon “They try to demonize carbon dioxide as if this is something that’s going to kill everybody.  Which is really not true. …  CO2 has a lot of potential benefit[s].  There are some potential negatives.  If it’s [CO2] going to cause sea levels to rise,  we’re going to have 4 inches or 8 inches or 12 inches…per century.”
3:30 Dr. Jon Christensen “The way I like to think about all this is…sunny with a chance of apocalypse. … (3:59) There is an existential threat out there. (5:40)  Everybody…who is under 40 is going to experience the effects of climate change, global warming, increase in sea level rise, flooding…in their lifetime.”
What the science says…
1. During 1958 to 2014, global sea levels rose at a rate of 1.3 mm per year to 1.5 mm per year, which is a rate of just over 3 inches per century; the Greenland and Antarctica ice sheets have combined to add just 0.59 of an inch of melt water to sea level rise since 1958 (Frederiske et al.,2018).   There has been “a recent lack of any detectable acceleration in the rate of sea level rise” (Parker and Ollier, 2017).  
2. Since the 1980s, coastal land area across the globe has been expanding, meaning that more land are is above sea level today (2015) than in 1985 (Donchyts et al., 2016).
“Coastal areas were also analysed, and to the scientists’ surprise, coastlines had gained more land – 33,700 sq km (13,000 sq miles) – than they had been lost to water (20,100 sq km or 7,800 sq miles). ‘We expected that the coast would start to retreat due to sea level rise, but the most surprising thing is that the coasts are growing all over the world,’ said Dr Baart.  ‘We were able to create more land than sea level rise was taking (press release).'”
3. Hurricane frequencies and intensities have been declining (Truchelut and Staeling, 2018, Zhao et al., 2018, Klotzbach et al., 2018).
4. Extreme weather events (floods, droughts) have decreased in frequency and intensity (or showed no detectable change) (Zhang et al., 2017, McCabe et al., 2017, Cheng et al., 2016, Hodgkiins et al., 2017, McAneney et al., 2017).
5. In recent decades 92% of Canadian polar bear subpopulations have remained stable or increased, leading scientists to conclude that “it seems unlikely that polar bears (as a species) are at risk from anthropogenic global warming” (York et al., 2016).  Local Inuit populations even report that there are “too many polar bears now” (Wong et al., 2017).   There has also been a “marked and steady increase“ in penguin populations between 1982 and 2015 (Che-Castaldo et al. 2017). 

(2) Dr. Soon: Ocean acidification is a myth.
Dr. Christensen: Ocean acidification is science.
11:21 Dr. Willie Soon “Can I say something about ocean acidification?  It’s a myth. … The ocean has something you can measure.  Basically, it’s called ion of the hydrogen.  It’s called [the] pH scale. You have 0 to 14.  Seven is neutral.  Seven to 0 is acidic.  Seven to 14 is called basic.   The ocean is right about 8.03, 8.04 [non-acidic].  But deep inside the ocean, about 2,000 meters down, it’s actually very acidic.  If you wanna talk about ocean acidification – it’s one of the most dangerous myths that there is.  A very radical one.  It’s not sensible.  Who created this myth, actually…?”
12:23 Dr. Jon Christensen “They call it [ocean acidification] science.”
12:25 Dr. Willie Soon “No, it’s not even science, excuse me, because… Do you know what the pH of rainwater is?  It’s 5.5. (Wikihow.com:  “Ordinary rainwater is naturally acidic with a pH between 5.0 and 5.5.”) …  [T]hat means you have to outlaw all the [naturally acidic] rain that’s falling down?  You want to outlaw all the slightly acidic water that is sitting on the bottom of the ocean?”
13:05  Dr. Jon Christensen “No….It’s not that hard to actually read the science.  It can seem a little bit daunting but anybody who can read can work their way through many of these papers and you can see that there’s a wide variety of findings and results and conclusions…  There is in science a fair degree of certainty on a lot of things. …  What we know is that there’s a wide spectrum of results here and we need to look at the data and the whole big picture of the science and not just write it off one way or the other.”
15:08 Dr. Willie Soon “Jon, my whole point is that ocean acidification is an extreme.  It is one of the most extreme things they could come up with because they are not able to find the fingerprint of the carbon dioxide warming of the atmosphere so then they started to come up with this new scheme [ocean acidification].  Next thing…they’re going [to claim] carbon dioxide is killing all of the polar bears.  It’s going to melt all the ice sheets.  It’s completely not even true.”
What the science says…
McElhany, 2017
“Documenting an effect of OA [ocean acidification] involves showing a change in a species (e.g. population abundance or distribution) as a consequence of anthropogenic changes in marine carbonate chemistry. To date, there have been no unambiguous demonstrations of a population level effect of anthropogenic OA [ocean acidification], as that term is defined by the IPCC. … [I]t is important to acknowledge that there are no studies that directly demonstrate modern day effects of OA [ocean acidification] on marine species.”
Duarte et al., 2014
“[T]here have been a few claims for already realized impacts of ocean acidification on calcifiers, such as a decline in the number of oysters on the West Coast of North America (Barton et al. 2012) and in Chesapeake Bay (Waldbusser et  al. 2011). However, the link between these declines and ocean acidification through anthropogenic CO2 is unclear.    Corrosive waters affecting oysters in hatcheries along the Oregon coast were associated with upwelling (Barton et  al. 2012), not anthropogenic CO2. The decline in pH affecting oysters in Chesapeake Bay (Waldbusser et al. 2011) was not attributable to anthropogenic CO2 but was likely attributable to excess respiration associated with eutrophication. Therefore, there is, as yet, no robust evidence for realized severe disruptions of marine socioecological links from ocean acidification to anthropogenic CO2, and there are significant uncertainties regarding the level of pH change that would prompt such impacts.  [D]espite the strong mechanistic or physiological basis for a role of warming in coral bleaching and coral growth, a robust demonstration of a direct causal link between global warming and global coral bleaching over decadal time scales has not yet been produced.”
Wei et al., 2015
“It is worth noting that the errors of these estimates are fairly large with RSD of 65% for that these two time-series do not show significant decreasing trend for pH. Despite of such large errors, estimated from these rates, the seawater pH has decreased by about 0.07–0.08 U over the past 200 years in these regions. … The average calculated seawater pH over the past 159 years was 8.04 [with a] a seawater pH variation range of 7.66–8.40.”


(3) Dr. Soon: Thank God for fossil fuels.
Dr. Christensen: We may fly planes with bio-gas.
8:27 Dr. Willie Soon “You gotta stick to the facts.  Wind and solar – oh boy, so useful.  Every time I look at this sad situation of all these landfalling hurricanes (Irma, Harvey)…the only thing I have to say about that is ‘Thank God for fossil fuels’.  … Fossil fuels offer the most energy density.  There is no viable energy replacement.  Wind and solar could never do anything…”
9:25 Bryan Dey “You’re never gonna get a plane off the ground with wind and solar.”
9:30 Dr. Jon Christensen “You may [get a plane off the ground] with bio-gas, though.”
What the science says…
DeCicco et al., 2016
“Biofuels increase, rather than decrease, heat-trapping carbon dioxide … The researchers conclude that rising biofuel use has been associated with a net increase—rather than a net decrease, as many have claimed—in the carbon dioxide emissions that cause global warming.”

(4) Dr. Christensen: In CA, we believe, we’re
doing something, and we’re helping the poor
17:03 Dr. Jon Christensen “The majority of people in every congressional district in the United States believes that climate change is real, it’s caused by people, it will harm people in the future, and we should do something about it.  […] Great vast majorities of people in California [are believers], where we have decided we’re going to do something about it…we’re on that path which I call the California way or the Paris way where we continue to make commitments, continue to raise our commitments, continue to ratchet down…”
17: 49 Bryan Dey “But all the [green] solutions that come from the Left are really going to be punishing poor people the most…”
17:54  Dr. Jon Christensen “No, they’re not, actually…”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




17: 56 Bryan Dey (adamant) “Yes, they will!  It’s poor people that are going to suffer the most!”
Californians in the audience clap and cheer
18:00 Panelist “We’ve got people [in the audience] who love poor people.”
18:03 Dr. Willie Soon “Oh, poor people are clapping.  Can I say something?”
18:12 Dr. Jon Christensen “Look at the laws in California.  Every single law that is being passed about climate change, cap-and-trade, environmental… has explicit language that is to make those benefits go to poor, disadvantaged communities…”
Californians in the audience shout “No, not true!”
18:30 Bryan Dey “If your electric bill goes up by 20 percent…”
18:34 Dr. Jon Christensen (to audience) “I don’t know who’s saying that [green policies don’t help poor people] but I can show it to you — this is what I do my research on.”
28:20 Question from audience “Do you think it’s appropriate for the government to use force and tax penalties which really affect middle income and lower income people based on climate science that is obviously hotly contested?”
28:50 Dr. Jon Christensen “In California, anyway, … [politicians] make sure that those burdens do not fall on lower income people.”
What the science says…
Environmental Progress (February, 2018)
“The burden of higher cost electricity and benefits of renewable energy subsidies fall unevenly on Californians. Between 2007 and 2014, the highest-income 40 percent of California households received three times more in solar subsidies — valued between $10,000 and $20,000 per household — as the lowest-income 40 percent. California households with over $100,000 in annual income benefited from energy efficiency subsidies at twice the rate of households whose income was under $50,000.”
Poorest households hit hardest by UK climate change levy despite using least energy (March, 2018)
“We found that, in a year, the richest households each consumed on average the same amount of energy that would be produced by 12.7 tonnes of oil, compared to 3.3 tonnes for the poorest households. But the poorest spent a much greater proportion of their income (10%) on energy than the richest (3%). And the energy used for heating and powering their homes – the part that their climate change levy bill is measured on – represented a much greater proportion of their overall energy use.”
“This means that adding the climate change levy to household energy bills hits the poorest households hardest. Energy bills account for a much greater share of their household income and more of their energy use is charged. In fact, the levy only affects a quarter of the total energy consumption of the richest households, compared to 53% for the poorest households. As a result, the richest homes use nearly four times more total energy than the poorest but only pay 1.8 times more towards energy policy costs.”

(5) Dr. Christensen: CA economy is growing
25:55 Dr. Jon Christensen “California’s economy has been growing while emissions have been decreasing.”
What the science says…
Los Angeles Times (January, 2018) 
“Guess which state has the highest poverty rate in the country? Not Mississippi, New Mexico, or West Virginia, but California, where nearly one out of five residents is poor.”

(6) Dr. Soon: Science does not work by consensus
19:13 Dr. Willie Soon “I’m very, very sorry.  Science does not work by consensus.  …  This nonsense about consensus…”
19:50 Dr. Willie Soon “This 97 percent consensus… We have published a peer-reviewed paper (Legates et al., 2013) that shows that it’s only 41 papers out of 12,000.  So it’s only 0.3 percent.”
What the science says…
Legates et al., 2013
“Cook et al. (2013), after a subjective review of only the abstracts of 11,944 papers on climate change which ‘‘matched the topics ‘global climate change’ or ‘global warming’’’ (p. 1), conclude that 97.1 % of those that expressed an opinion endorsed the hypothesis as defined in their introduction (i.e., the standard definition). However, 66.4 % percent of the abstracts had expressed no position. Thus, 32.6 % of the entire sample, or 97.1 % of the 33.6 % who had expressed an opinion, were said to be in agreement with the standard definition. However, inspection of the authors’ own data file showed that they had themselves categorized only 64 abstracts, just 0.5 % of the sample, as endorsing the standard definition [a majority of the warming since 1950 was human-caused]. Inspection shows only 41 of the 64 papers, or 0.3 % of the sample of 11,944 papers, actually endorsed that definition.”

(7) Dr. Soon: CO2 increase is greening the planet
21:20  Dr. Willie Soon “One of the most powerful effects of carbon dioxide is not on temperature because if you talk about greenhouse gases it’s water vapor that’s more important [than] CO2. […]  The only proof we have so far is that it [CO2] is greening the planet.  Twenty to fifty percent of the [Earth’s] vegetated area has been greening, only 4% has been showing a little browning.  That tell[s] you that the overwhelming effect of this [increase in CO2] is fertilization of the atmosphere. […] We’re [currently] in a CO2 starvation state.  Today our air has only 400 parts per million.  If you don’t know what that means, it’s 4 cents for every hundred dollars.”
What the science says…
Zhu et al., 2016
“Global environmental change is rapidly altering the dynamics of terrestrial vegetation, with consequences for the functioning of the Earth system and provision of ecosystem services.  Yet how global vegetation is responding to the changing environment is not well established. Here we use three long-term satellite leaf area index (LAI) records and ten global ecosystem models to investigate four key drivers of LAI trends during 1982–2009. We show a persistent and widespread increase of growing season integrated LAI (greening) over 25% to 50% of the global vegetated area, whereas less than 4% of the globe shows decreasing LAI (browning). Factorial simulations with multiple global ecosystem models suggest that CO2 fertilization effects explain 70% of the observed greening trend, followed by nitrogen deposition (9%), climate change (8%) and land cover change (LCC) (4%). CO2 fertilization effects explain most of the greening trends in the tropics, whereas climate change resulted in greening of the high latitudes and the Tibetan Plateau.”

(8) Dr. Christensen: The goal is to increase the cost of carbon
29:30 Dr. Jon Christensen “A lot of what’s happening is figuring out ways to use the market to increase the cost of carbon…  (Audience: No! No!) …to take into account the cost that we’re paying in health and environmental effects…which are externalities that have not been factored in. … Those revenues [from increasing the cost of carbon] are used to benefit the whole state of California with particular attention to people who are lower income.”
What the science says…
Environmental Progress (February, 2018)
“Between 2011 and 2017, California’s electricity prices rose five times faster than they did nationally. Today, Californians pay 60 percent more, on average, than the rest of the nation, for residential, commercial and industrial electricity.”

“California’s high penetration of intermittent renewables such as solar and wind are likely a key factor in higher prices.”
“Economists agree that “the dominant policy driver in the electricity sector [in California] has unquestionably been a focus on developing renewable sources of electricity generation.”
“High levels of renewable energy penetration make electricity expensive around the world, not just in California. As Germany deployed high levels of renewables over the last 10 years it saw its electricity prices rise 34 percent. Today, German electricity costs twice as much as that in neighboring France.”
“As wind and solar capacity climbs, the returns of usable power diminish because of increasing curtailment during surges that the grid cannot absorb. More and more intermittent capacity has to be pushed onto the grid to get less and less additional renewable electricity. The dynamic of soaring overcapacity and falling prices is the inevitable result of the fundamental inability of intermittent wind and solar generators to efficiently match supply to demand.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGlobal Warming Theory ‘Completely 
Disconnected From the Observations’


Extensive analysis of temperature trends in the Arctic reveals that there has been no detectable long-term change since the beginning of the 20th century, and thus predictions of a sea ice-free Arctic in the coming decades due to dramatically rising temperatures are not rooted in observation.


Butina, 2015  
IS THE ARCTIC MELTING?  
THEORY VS. OBSERVATIONS
Abstract
[T]he Arctic Circle is the most extreme place on our planet where seasonal changes can range from +35.0°C in July and -65.0°C in February; […] on average 75% of the year is spent below the melting point of water [and] on average the Arctic will be covered by ice/snow for the same proportion of time, i.e., 75% or 9 months of the year.
The same seasonal extreme variations in air temperatures are also observed in ice cover variations observed in the Arctic where the winter‘s ice cover can be between 14- 16 million km2, while during summer the area covered can vary between 4 and 8 million km2.  Based on observations, dating back to 1900, it can be concluded that it is physically impossible for the Arctic to be ice/snow free in the foreseeable future since the air temperatures were as cold in 2013 as they were in 1900.
Since ice cannot melt below 0.0°C, all these observations point towards the Arctic remaining ice-covered for the next 100 years. It must also follow that any theory predicting imminent melting of the Arctic ice cap cannot be based on thermometer-recorded data and, therefore, must be wrong and will merely be an artefact of using the term temperature where there is no true association with the calibrated thermometer, the instrument used to measure temperature in all physical, medical and engineering sciences.
Conclusion
So, what are the hard facts about Arctic that are based on the observations made by calibrated thermometers at 20 stations across the Arctic Circle and which conclusions can be made based on those observations?
1. Temperatures in the Arctic between 1900 and the present day are a long distance below 0.0°C for at least 9 months per year and can be as low as -64.0°C
2. It is impossible to separate the youngest from the oldest years using thermometerbased daily or monthly Tmax/Tmin data
3. The total ranges observed in daily Tmax/Tmin data can be as high as 100.0°C and as low as 75.0°C making the Arctic Circle the most variable and extreme area on our planet therefore making any accurate forecasting of future temperature patterns and trends impossible
4. The switches between the extreme hot to extreme cold temperatures are very frequent and very unpredictable and can occur within the same month, same year or between two consecutive years
5. The large observed ice gain/loss variations are pre-determined by the large observed variations in air temperatures
6. Since the air temperatures are chaotic in nature it must follow that the extent of the ice cover has to be chaotic as well and, since we cannot predict future events of a chaotic system, we cannot predict future trends of either air temperatures or ice cover patterns
Based on the facts above only one conclusion can be made in reference to the putative melting of the Arctic: historical thermometer-based data tells us that between 1900 and 2014 arctic temperatures were for 75% of the time consistently long distance below 0.0°C; the ice cover in the winter months is still consistently more than 14,000,000km2 and, therefore, it is physically impossible for the Arctic to be already melting since nothing has changed since 1900 till present day. The only sensible forecast for the future would be to expect the same extreme events to continue until thermometer-based evidence tell us otherwise.
Let me conclude this paper by answering the question asked in the first part of the title by a categorical No, the Arctic is not melting. As long as temperatures remain the same as they have been for the last 100 years the Arctic will remain frozen in the long winter months and partly melt during very short summer months.
The answer to the second question is that the theory of global warming is completely disconnected from the observations since their definition of temperature is based on some theoretical number that has nothing to do with the temperature that is measured by calibrated thermometer and, most importantly, used as an international standard by the scientific community. Since the theory is clearly wrong about forecasting the temperature patterns in the Arctic, all other predictions made by the theory must be wrong too.


New Paper: No  Greenland Temperature Or Sea Ice Changes Since 1600 Either

Kryk et al., 2017     
“Our study aims to investigate the oceanographic changes in SW Greenland over the past four centuries (1600-2010) based on high-resolution diatom record using both, qualitative and quantitative methods.  July SST during last 400 years varied only slightly from a minimum of 2.9 to a maximum of 4.7 °C and total average of 4°C. 4°C is a typical surface water temperature in SW Greenland during summer. … The average April SIC was low (c. 13%) [during the 20th century], however a strong peak of 56.5% was recorded at 1965. This peak was accompanied by a clear drop in salinity (33.2 PSU).”


Greenland Ice Sheet In Balance…Melt Added  Just 1.5 cm (0.6  Inch) To Sea Levels Since 1900

Fettweis et al ., 2017
“[T]he integrated contribution of the GrIS [Greenland Ice Sheet] SMB [surface mass balance] anomalies over 1900–2010 is a sea level rise of about 15 ± 5 mm [1.5 cm], with a null contribution from the 1940s to the 2000s“

Like The Arctic, Antarctica Has Not Warmed In The Last Century Either

Stenni et al., 2017
“[N]o continent-scale warming of Antarctic temperature is evident in the last century.”

Antarctica’s Ice Sheet Has Been Gaining Mass Since 1800

Thomas et al., 2017
“Our results show that SMB [surface mass balance] for the total Antarctic Ice Sheet (including ice shelves) has increased at a rate of 7 ± 0.13 Gt decade−1 since 1800 AD…”

Antarctica’s Mass Gains Have Reduced Sea Levels By -0.04 mm-¹ Per Decade Since 1900

Thomas et al., 2017
“…representing a net reduction in sea level of ∼ 0.02 mm decade−1 since 1800 and ∼ 0.04 mm decade−1 since 1900 AD.  The largest contribution is from the Antarctic Peninsula (∼ 75 %) where the annual average SMB during the most recent decade (2001–2010) is 123 ± 44 Gt yr−1 higher than the annual average during the first decade of the 19th century.”

In sum, there is nothing thermally unusual occurring today in either the Arctic or Antarctic, precluding the clear detection of an anthropogenic temperature or ice-melt signal in the polar regions.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterRecently German SAT1 television broadcast a documentary on the state of the European and German increasingly green power grid: “How secure are our power grids?” Due to the volatile and unpredictable supply of wind and solar energy, the grid has become far more unstable, the documentary warns. The news is not good.
At best: the consumers are getting a far lousier product at a much higher price.
At the 17-minute mark, Bernd Benser of GridLab-Berlin tells viewers that while grid operator Tennet had to intervene only 3 times in 2002 to avert grid instability, last year he says the number was “over 1000” times — or “three times daily”.
These intervention actions, known as redispatching, cost the consumer about a billion euros last year alone, says Benser.  The SAT 1 voice-over warns that more power transmission lines are urgently needed if the Energiewende is to avoid “becoming a sinking ship“. However over the years acceptance by citizens has swung from a generally warm welcome to ferocious opposition. Politicians need to start noting that green energies have overstayed their welcome.
Major grid instability
And as wind and solar power capacity gets added to the grid without expanding transmission capability to offset the ever more wild fluctuations, grid operators are now constantly scrambling to keep the grid from spiraling out of control. At the 21-minute mark, Klaus Kaschnitz of the operations management of Austrian Power Grid remarks:
These fluctuations in the system that we now see have increased dramatically and are ultimately a product of weather events.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The fluctuations are having a profound impact, Kaschnitz explains. It is especially difficult to keep the grid at 50 Hz frequency, which makes keeping the grid from collapsing harder and the powering of modern industrial systems highly challenging. At the 25-minute mark, the report then switches the focus to the grids’ vulnerability to hackers.
Swiss daily: “danger of a blackout rising”
Also the Swiss online Baseler Zeitung (BaZ) here reports on major power grid woes in Switzerland, warning: “The danger of a blackout is rising” and that power grid operator Swissgrid “must intervene increasingly more often in the power grid“.
According to the BAZ, in 2011 Swissgrid had to intervene only twice over the entire year. But since then the grid has become far more unstable, and that at the current rate it will be necessary to intervene 400 times in 2017!
In summary, the green energies have resulted in two outcomes for citizens: 1) a supply that is now far more unstable and 2) power that is far more expensive. In a nutshell: Far less quality for a lot more money.
That’s the expected result whenever you have the wrong people (activists and politicians) deciding how to run complex technical systems.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe article that follows below is from the UK online Independent here.
Regrettably the editors screwed up and inserted the wrong English text in the video and misidentified the participants as well. The discussion is in fact about CO2 being the sole real driver of global climate. Moreover, the talk round took place in London, and not Egypt.
This is not fake news, but merely a case of human error on the part of the Independent. It happens. 🙂
As a public service, we at NTZ have corrected the article by the Independent (below). Again, pay no attention to the erroneous English text in the video, which is really about a climate skeptic, James Delingpole, at a Talkshow presenting an alternative theory on why the globe is warming a bit.
================================
Corrected version of the Independent article: 
Climate denialist kicked off live Climate TV show for ‘inappropriate’ ideas: ‘Go straight to a psychiatric hospital’
‘We cannot promote such destructive ideas…you set a very bad example for the World’s youth’

A climate skeptic has been kicked off a live TV show taped in London after the host accused him of being ‘confused and unreliable’ and being in need of psychiatric treatment.
James Delingpole was presenting his reasons for being climate science skeptic on Current TV (co-founded by Al Gore) when host George Abd Al-Halim Monbiot told him he was being ‘inappropriate’.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Sheikh of Al Mahmoud Gore, who was also on the programme, agreed, telling him: ‘Look dear James, you need psychiatric treatment. Many young people today suffer from mental illnesses due to material or mental circumstances.’
When Delingpole suggested ‘the sun‘ as an explanation for climate change, George Abd Al-Halim Monbiot exploded and demanded that he ‘stop using difficult words’ and reminded him that he was ‘addressing simple people and to not use big words for no reason’.
George Abd Al-Halim Monbiot then accused James: ‘You deny the existence of CO2 as the climate driver and reject our religion and science.’
Next Mr. Al-Halim Monbiot demanded Mr. Delingpole to leave, saying: ‘We cannot promote such destructive ideas…you set a very bad example for the world’s youth.’
He added: ‘I advise you to leave the studio and go straight to a psychiatric hospital.’
Blasphemy and denialism are illegal in climate science, and prosecution is routinely recommended by NASA GISS, PIK and NOAA if people should insult or defame Climatism and CO2 under proposed climate science RICO laws.
======================================
We at NoTricksZone are glad to have been able to get this cleared up. As you can see, the video now makes perfect sense.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterKenneth set to show in just minutes what a sham all the sea level rise alarmism really is. (Now busy setting the troll filter on high!)

NASA photo – public domain
Stay tuned! 🙂
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGeologist Dr. Norman Page left a comment which I’ve decided to upgrade to a post. In it he writes solar and La Nina observations fit well with his recent paper showing that climate is controlled by natural orbital and solar activity cycles.
Dr. Page is among a growing number of scientists who share the general view that natural solar and oceanic cycles are mostly driving the climate, just as they always have in the past.
Warming has already peaked, cooling ahead
And as a result, Dr. Page believes that the millennial temperature cycle peaked at about 2003/4 and the earth is now in a cooling trend, which will last until about 2650. Read background here.
Recently he published a paper titled: “The coming cooling: usefully accurate climate forecasting for policy makers“.
Models “unfit for purpose”
His paper argues that the methods used by the establishment climate science community are not fit for purpose and that a new forecasting paradigm should be adopted. A number of papers have been published over the recent years pointing out that climate models have been far short of reliable.
In the paper’s abstract Dr. Page writes that the Earth’s climate is the result of resonances and beats between various quasi-cyclic processes of varying wavelengths and that it is not possible to forecast the future unless there’s a good understanding of where the earth is in time in relation to the current phases of those different interacting natural quasi periodicities.
“Temperature decline in the coming decades and centuries”
He presents evidence specifying the timing and amplitude of the natural 60+/- year and the all important 1,000 year periodicities (observed emergent behaviors), which he and other scientists maintain are so obvious in the temperature record.

Fig. 8, HadSST3 temperature anomaly: “Over the last 135 years an approximate 60 year periodicity is clearly present in the temperature data.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




He projects cyclic trends forward and predicts a probable general temperature decline in the coming decades and centuries.
Large divergence by 2021
He also estimates the timing and amplitude of the coming cooling, writing: “If the real climate outcomes follow a trend which approaches the near term forecasts of his working hypothesis, the divergence between the IPCC forecasts and those projected by his paper will be so large by 2021 as to make the current, supposedly actionable, level of confidence in the IPCC forecasts untenable.”
The 1991 millennial solar activity peak is seen in Figure 10 neutron data.
Dr. Page notes that there is a varying lag between the solar activity peak and the corresponding peak in the different climate metrics because of the thermal inertia of the oceans. In the abstract he writes:
It has been independently estimated that there is about a 12-year lag between the cosmic ray flux and the temperature data – Fig. 3 in Usoskin (28).”
Page says this correlates with the millennial temperature peak seen at 2003/4 in the RSS data in Fig 4,

Fig 4. RSS trends showing the millennial cycle temperature peak at about 2003 (14)
Page also says that since the strong El Nino peak anomaly of 2016, the temperature has “declined rapidly” and: “The cooling trend is likely to be fully restored by the end of 2019.”
======================================
Dr. Norman J. Page    
 Email: norpag@att.net
 DOI: 10.1177/0958305X16686488
 Energy & Environment
 0(0) 1–18
 (C )The Author(s) 2017
 journals.sagepub.com/home/eae
Share this...FacebookTwitter "
"
Share this...FacebookTwitterParts of Germany’s political leadership appear to be waking up to the harsh realities of green energies (wind and sun) and their inefficiencies.
Hat-tip: Die kalte Sonne
“Economic Minister accepts true condition of Energiewende”
The website of German national daily “Welt” here reported last month that Germany’s powerful Minister of Economics, Peter Altmaier “accepts the true condition of the Energiewende [transition to green energies]”.
In the Welt commentary, veteran journalist Daniel Wetzel wrote that Altmaier “avoided every mention of Germany functioning as a leader or role model”” for the world when it comes to green energies today. That’s change of course from what we used to hear.
Some ten years ago Germany boasted non-stop about being the global leader in green energies. Today, after seeing years of skyrocketing electricity prices and an increasingly destabilized power grid, the country has visibly backed off its once lofty green goals, which were aimed at making Germany 90% reliant on green energies by 2050. Lately it’s been dawning that this target was far too utopian.
Energiewende “no solution for single countries”
Wetzel quotes Altmaier, who was speaking before dozens of green business leaders at the international Energiewende Conference, stated that “the Energiewende will survive only if it is global” and that it is “no solution for single countries.”
In a nutshell, Altmaier admitted the Energiewende is a failure because it is already known that many other countries, like USA and China” are not going to adopt it and so will always have access to cheap, reliable energy and Germany will thus have no chance to compete internationally should it opt to stay on the green course.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Altmaier said it only made sense if it’s implemented worldwide. But today everyone knows worldwide implementation is a pipe dream and so Germany needs to start forgetting about its once ambitious Energiewende..
Wetzel then comments:
Altmaier’s sober message to the international eco-electricity scene: An Energiewende is more difficult than one thinks, and it takes longer than many think it does.”
Only efficient when everyone else accepts being inefficient
So why would Altmaier state that only a global Energiewende would make sense? To answer that one has to read between the lines. His claim in fact confirms that green energies are terribly inefficient, and thus uncompetitive, which means going it alone only makes the country inefficient and uncompetitive.
So according to Altmaier in order for the Energiewende to be “efficient in a country, all othe rcountries must adopt it and become energetically inefficient. Only when all countries become inefficient can Germany’s Energiewende be “efficient”.
No hurry to go green
Under the bottom line: Germany is no longer in a hurry to transform its energy supply system into a green one because it knows big competing coutries aren’t going to do it.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter A Disgraceful Chasm Between Real-World
Observations & Climate Science Reporting

Injecting frightening scenarios into climate science reporting  has seemingly become a requisite for publication.
In a new Nature Geoscience editorial, a common scare tactic is utilized by the (unidentified) author so as to grab readers’ attention.
Nature Geoscience, 2018
The East Antarctic ice sheet is currently the largest ice mass on Earth. If it melted in its entirety, global sea levels would rise by more than 50 metres.
Wow.  50 meters.  That would be catastrophic.
But then we read about real-world observations for East Antarctica.  And they don’t even come close to aligning with the catastrophic scenario casually tossed into the editorial.
First of all, East Antarctica is not losing mass and adding to sea levels.  The ice sheet is gaining mass and thus removing water from sea levels. The surface mass gains have been occurring not only since 1800 (Thomas et al., 2017), but for the recent decade (2003-2013) too (Martín-Español et al., 2017).  Even the author of the Nature Geoscience editorial acknowledges this.
Nature Geoscience, 2018
“The East Antarctic ice sheet may be gaining mass in the current, warming climate. The palaeoclimate record shows, however, that it has retreated during previous episodes of prolonged warmth.”
Not only has East Antarctica been gaining mass, the author goes on to say that it would take 100s of thousands to millions of years for Antarctica to even exhibit partial retreat.  So much for the “if it melted in its entirety” warning we read earlier.
“In terms of immediate sea-level rise, it is reassuring that it seems to require prolonged periods of lasting hundreds of thousands to millions of years to induce even partial retreat.”
So if the editorial department at Nature Geoscience realizes that it would take 100s of thousands to millions of years to even witness a partial retreat of the ice sheet, is there any scientific justification for the inclusion of the sea-levels-would-rise-50-meters-if-East-Antarctica-melted commentary?  Since when do imaginary scenarios pass as science?
A ‘Staggering’ 9 Trillion Tons Of Greenland’s Ice Has Been Lost Since 1900!  That’s A Sea Level Contribution Of Less Than 1 Inch


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




It’s frightening to learn that the Greenland Ice Sheet has lost a “staggering” 9 trillion tons of ice since 1900, which is what the Washington Post warned us about in 2015.
It’s not frightening to learn that 9 trillion tons of ice losses actually amounts to less than 1 inch of sea level rise contribution from Greenland meltwater in 115 years.

Since a total sea level rise contribution of 1 inch in 115 years from the Greenland ice sheet isn’t scary, the author of the Washington Post article (Chris Mooney) finds it necessary to offer his readers a macabre thought experiment: What if that additional 1 inch of water sitting atop the world ocean were to be collected somehow and then dumped onto all the United States interstate highways?   Now that would be scary.  It would mean that 1 inch of sea level rise turned into 98 feet of sea levels rise (63 times over) in very same imaginary world where additional sea water is dumped onto U.S. interstate highways.
This is how the modern version of climate science works.
Below are a few more examples of glacier melt and sea level rise observations from recently-published papers casting doubt on the tragic, alarmist, and attention-seeking headlines that are so prevalent today.

1. ‘Pine Island Glacier Is The Largest Current Antarctic Contributor To Sea Level Rise’ – But Has ‘Not Shown Any Clear Trend Over 68 Years’ (1947-2015)
Arndt et al., 2018
“Pine Island Glacier is the largest current Antarctic contributor to sea level rise. Its ice loss has substantially increased over the last 25 years through thinning, acceleration and grounding line retreat. However, the calving line positions of the stabilizing ice shelf did not show any trend within the observational record (last 70 years) until calving in 2015 led to unprecedented retreat and changed alignment of the calving front. … Despite the thinning and flow acceleration of PIG [Pine Island Glacier], and sustained, rapid thinning of the ice shelf over at least the past 25 years the position of the ice front had not shown any clear trend over 68 years of observations prior to 2015 (Bindschadler, 2002;MacGregor et al., 2012;Rignot, 2002).”

2. More Land Area Above Sea Level In 2014 Than In 1971 In The Tropical Pacific
Kench et al., 2018
“We specifically examine spatial differences in island behaviour, of all 101 islands in Tuvalu, over the past four decades (1971–2014), a period in which local sea level has risen at twice the global average (Supplementary Note 2). Surprisingly, we show that all islands have changed and that the dominant mode of change has been island expansion, which has increased the land area of the nation. … Using remotely sensed data, change is analysed over the past four decades, a period when local sea level has risen at twice the global average [<2 mm/yr-1] (~3.90 ± 0.4 mm.yr−1). Results highlight a net increase in land area in Tuvalu of 73.5 ha (2.9%), despite sea-level rise, and land area increase in eight of nine atolls.”


3. More Land Area Above Sea Level In 2015 Than In 1985 For The Entire Globe
Donchyts et al., 2016
“Earth’s surface water change over the past 30 years [1985-2015] … Earth’s surface gained 115,000 km2 of water and 173,000 km2 of land over the past 30 years, including 20,135 km2 of water and 33,700 km2 of land in coastal areas.”
 (press release)
Coastal areas were also analysed, and to the scientists’ surprise, coastlines had gained more land – 33,700 sq km (13,000 sq miles) – than they had been lost to water (20,100 sq km or 7,800 sq miles).
“We expected that the coast would start to retreat due to sea level rise, but the most surprising thing is that the coasts are growing all over the world,” said Dr Baart.  “We were able to create more land than sea level rise was taking.”

4. Greenland And Antarctica Combined Contributed A Total Of 0.59 Of An Inch To Sea Level Rise Between 1958-2014
Frederiske et al.,2018


5. ‘Recent Lack Of Any Detectable Acceleration In The Rate Of Sea-Level Rise’
Parker and Ollier, 2017
“The loud divergence between sea-level reality and climate change theory—the climate models predict an accelerated sea-level rise driven by the anthropogenic CO2 emission—has been also evidenced in other works such as Boretti (2012a, b), Boretti and Watson (2012), Douglas (1992), Douglas and Peltier (2002), Fasullo et al. (2016), Jevrejeva et al. (2006), Holgate (2007), Houston and Dean (2011), Mörner 2010a, b, 2016), Mörner and Parker (2013), Scafetta (2014), Wenzel and Schröter (2010) and Wunsch et al. (2007) reporting on the recent lack of any detectable acceleration in the rate of sea-level rise. The minimum length requirement of 50–60 years to produce a realistic sea-level rate of rise is also discussed in other works such as Baart et al. (2012), Douglas (1995, 1997), Gervais (2016), Jevrejeva et al. (2008), Knudsen et al. (2011), Scafetta (2013a, b), Wenzel and Schröter (2014) and Woodworth (2011).”
“[T]he information from the tide gauges of the USA and the rest of the world when considered globally and over time windows of not less than 80 years […] does not support the notion of rapidly changing mass of ice in Greenland and Antarctica as claimed by Davis and Vinogradova (2017). The sea levels have been oscillating about a nearly perfectly linear trend since the start of the twentieth century with no sign of acceleration. There are only different phases of some oscillations moving from one location to another that do not represent any global acceleration.”
“The global sea-level acceleration is therefore in the order of + 0.002  ± 0.003 mm/year², i.e. + 2 ÷ 3 μm/year², well below the accuracy of the estimation.”

Share this...FacebookTwitter "
"
Share this...FacebookTwitterGovernments promote biofuels as renewable, carbon-neutral resources that serve to reduce CO2 emissions.  Meanwhile, scientists have determined that biomass burning generates more CO2 emissions per kWh than burning coal does, and the projected rapid growth in biofuel use will only serve to ‘increase atmospheric CO2 for at least a century’. 

Sterman et al., 2018
“[G]overnments around the world are promoting biomass to reduce their greenhouse gas (GHG) emissions. The European Union declared biofuels to be carbon-neutral to help meet its goal of 20% renewable energy by 2020, triggering a surge in use of wood for heat and electricity (European Commission 2003, Leturcq 2014, Stupak et al 2007). … But do biofuels actually reduce GHG emissions?”
“[A]lthough wood has approximately the same carbon intensity as coal (0.027 vs. 0.025 tC GJ−1 of primary energy […]), combustion efficiency of wood and wood pellets is lower (Netherlands Enterprise Agency; IEA 2016). Estimates also suggest higher processing losses in the wood supply chain (Roder et al 2015). Consequently, wood-fired power plants generate more CO2 per kWh than coal. Burning wood instead of coal therefore creates a carbon debt—an immediate increase in atmospheric CO2 compared to fossil energy—that can be repaid over time only as—and if— NPP [net primary production] rises above the flux of carbon from biomass and soils to the atmosphere on the harvested lands.”
“Growth in wood supply causes steady growth in atmospheric CO2 because more CO2 is added to the atmosphere every year in initial carbon debt than is paid back by regrowth, worsening global warming and climate change. The qualitative result that growth in bioenergy raises atmospheric CO2 does not depend on the parameters: as long as bioenergy generates an initial carbon debt, increasing harvests mean more is ‘borrowed’ every year than is paid back. More precisely, atmospheric CO2 rises as long as NPP [net primary production] remains below the initial carbon debt incurred each year plus the fluxes of carbon from biomass and soils to the atmosphere.”
“[P]rojected growth in wood harvest for bioenergy would increase atmospheric CO2 for at least a century because new carbon debt continuously exceeds NPP.”
“[C]ontrary to the policies of the EU and other nations, biomass used to displace fossil fuels injects CO2 into the atmosphere at the point of combustion and during harvest, processing and transport. Reductions in atmospheric CO2 come only later, and only if the harvested land is allowed to regrow.”

Fanous and Moomaw, 2018
“These nations fail to recognize the intensity of CO2 emissions linked to the burning of biomass. The chemical energy stored in wood is converted into heat or electricity by way of combustion and is sometimes used for combined heat and power cogeneration. At the point of combustion, biomass emits more carbon per unit of heat than most fossil fuels. Due to the inefficiencies of biomass energy, bioenergy power plants emit approximately 65 percent more CO2 per MWH than modern coal plants, and approximately 285 percent more than natural gas combined cycle plants.”
“Furthermore, the Intergovernmental Panel on Climate Change (IPCC) states that combustion of biomass generates gross greenhouse gas (GHG) emissions roughly equivalent to the combustion of fossil fuels. In the case of forest timber turned into wood pellets for bioenergy use, the IPCC further indicates that the process produces higher CO2 emissions than fossil fuels for decades to centuries.”
 

Share this...FacebookTwitter "
"
Share this...FacebookTwitterRecently I wrote about 7 signs showing that the earth has been cooling and likely will continue to cool.
To back this up, Kenneth Richards commented in a reply that this year has seen 7 new peer-reviewed papers that show us that the earth’s surface temperature at the poles and elsewhere has been cooling since about a decade. What’s worrisome is that the southern hemisphere surface is mostly ocean.
Eastern North Atlantic cooling since 2010
The first paper is Gladyshev et al., 2017  which states in its abstract that there’s been “a sharp and stable freshening and cooling of SPMWs [Subpolar Mode Water] in the eastern part of the North Atlantic since 2010 . In the years 2010–2016, the mean temperature of the SPMW [Subpolar Mode Water] core in the Rockall Trough dropped by -0.73°C (-0.12°C/yr); in the Iceland Basin it dropped by -2.12°C (-0.35°C/yr), and salinity decreased by 0.12 psu (0.02 psu/yr) and 0.23 psu (0.04 psu/yr), respectively.”
Subpolar North Atlantic trend reversal in 2005
In another paper, Piecuch et al., 2017,  the authors notes that subpolar North Atlantic (SPNA) is subject to strong decadal variability and found that in 2004–2005 the SPNA decadal upper ocean and sea-surface temperature trends reversed from warming during 1994–2004 to cooling over 2005–2015.
Southern Ocean now cooling
On the other side of the planet at the South Pole the story is pretty much the same. A study this year by Kusahara et al., 2017 showed that in contrast to a strong decrease in Arctic sea ice extent, the overall Antarctic sea ice extent has modestly increased since 1979. The paper’s abstract adds:
Concomitant with this positive trend in Antarctic sea ice, sea surface temperatures (SSTs) over the Southern Ocean south of approximately 45°S have cooled over this period.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Remaining at the South Pole, a new paper by Turney et al., 2017 here states that the Southern Ocean, which occupies a massive 14% of the world’s surface, plays a fundamental role in ocean and atmosphere circulation — and thus climate — and found that it has produced a cooling trend since 1979.
Cooling since 1999
Also Oliva et al., 2017 points out that a recent analysis by Turner et al., 2016 has shown that “the regionally stacked temperature record for the last three decades has shifted from a warming trend of 0.32 °C/decade during 1979–1997 to a cooling trend of − 0.47 °C/decade during 1999–2014“. Oliva et al tell us that “this recent cooling has already impacted the cryosphere in the northern AP [Antarctic Peninsula], including slow-down of glacier recession, a shift to surface mass gains of the peripheral glacier and layer of permafrost in northern AP islands“.
Fernandoy et al., 2017 here also points out:
The firn stable isotope composition reveals that the near–surface temperature at the Antarctic Peninsula shows a decreasing trend (−0.33 °C y−1) between 2008 and 2014.”
“No evidence” of snow decline
Finally, moving on land to the Tibetan Plateau, a recent paper appearing in Nature by Wang et al. 2017 shows there’s been “no evidence of widespread decline of snow cover on the Tibetan Plateau over 2000–2015“.
That’s 7 fresh papers telling us that large, important areas of the earth’s surface have stopped warming and begun cooling. Time is running out for the global warming hoaxsters.
Note: Recently desparate climate warming trolls have been appearing in force (trying to keep their sham alive). Serious comments are welcome, but trolling comments will be deleted.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBefore getting to the subject of climate models, first two small points worth bringing up:
Eco-Trumpism spreading
Firstly, it appears that Trump’s policies are sending powerful political impulses worldwide. For example ultra-alarmist German climate and energy site klimaretter here bemoans that leading socialist Sigmar Gabriel seems to be turning into an “Eco-Trump”. Gabriel actually had the audacity to remind Germany that economics need have as great as or greater priority than climate change does, something causing a bit of political indigestion at klimaretter.
Fears of German companies moving to USA
Secondly, German business daily Handelsblatt here cites a study that tells us Germany will likely see jobs lost due to Trump’s tax reforms. It is feared that a number of German companies may opt to flock over to USA to take advantage of lower taxes, cheaper energy and less stringent regulation. Germany helping MAGA!
===================================
Climate models totally fail in practice: Can atmospheric circulation be simulated at all?
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated / edited by P Gosselin)
A large part of international climate policy is based on prognoses delivered by climate models. Here the key players act as if they are highly robust and thus serve as a good basis for policy decision making. But what hardly ever makes it through the media filter is the rather hectic discussion taking place behind the scenes among climate modelers.
In September 2014 Theodore Shepherd of the University of Reading summarize the entire extent of the problems in an article published in Nature Geoscience. The models simply fail to grasp the atmospheric circulation. And Shepard feels that will remain the case also in the future:
Atmospheric circulation as a source of uncertainty in climate change projections
The evidence for anthropogenic climate change continues to strengthen, and concerns about severe weather events are increasing. As a result, scientific interest is rapidly shifting from detection and attribution of global climate change to prediction of its impacts at the regional scale. However, nearly everything we have any confidence in when it comes to climate change is related to global patterns of surface temperature, which are primarily controlled by thermodynamics. In contrast, we have much less confidence in atmospheric circulation aspects of climate change, which are primarily controlled by dynamics and exert a strong control on regional climate. Model projections of circulation-related fields, including precipitation, show a wide range of possible outcomes, even on centennial timescales. Sources of uncertainty include low-frequency chaotic variability and the sensitivity to model error of the circulation response to climate forcing. As the circulation response to external forcing appears to project strongly onto existing patterns of variability, knowledge of errors in the dynamics of variability may provide some constraints on model projections. Nevertheless, higher scientific confidence in circulation-related aspects of climate change will be difficult to obtain. For effective decision-making, it is necessary to move to a more explicitly probabilistic, risk-based approach.”
Also accounting for solar irradiance is causing a lot of problems, as Zhou et al. 2015 point out:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On the incident solar radiation in CMIP5 models
Annual incident solar radiation at the top of atmosphere should be independent of longitudes. However, in many Coupled Model Intercomparison Project phase 5 (CMIP5) models, we find that the incident radiation exhibited zonal oscillations, with up to 30 W/m2 of spurious variations. This feature can affect the interpretation of regional climate and diurnal variation of CMIP5 results. This oscillation is also found in the Community Earth System Model. We show that this feature is caused by temporal sampling errors in the calculation of the solar zenith angle. The sampling error can cause zonal oscillations of surface clear-sky net shortwave radiation of about 3 W/m2 when an hourly radiation time step is used and 24 W/m2 when a 3 h radiation time step is used.”
Currently the author teams for the planned 6 IPCC climate report are getting together. Are the considerable problems surrounding climate models resolved? No sign of that. On October 11, 2017, Stony Brook University set off the alarms: The models still are not running properly! And the German press prefers to keep silent about this. The Stony Brook press release follows:
Study Reveals Need for Better Modeling of Weather Systems for Climate Prediction
Computer-generated models are essential for or scientists to predict the nature and magnitude of weather systems, including their changes and patterns. Using 19 climate models, a team of researchers led by Professor Minghua Zhang of the School of Marine and Atmospheric Sciences at Stony Brook University, discovered persistent dry and warm biases of simulated climate over the region of the Southern Great Plain in the central U.S. that was caused by poor modeling of atmospheric convective systems – the vertical transport of heat and moisture in the atmosphere. Their findings, to be published in Nature Communications, call for better calculations in global climate models.
The climate models analyzed in the paper “Causes of model dry and warm bias over central U.S. and impact on climate projections,” included a precipitation deficit that is associated with widespread failure of the models in capturing actual strong rainfall events in summer over the region. By correcting for the biases, the authors found that future changes of precipitation over the US Southern Great Plain by the end of the 21st Century would be nearly neutral. This projection is unlike what has been predicted as a drying period by the majority of current climate models. The correction also reduces the projected warming of the region by 20 percent relative to projections of previous climate models.
“Current climate models are limited by available computing powers even when cutting-edge supercomputers are used,” said Professor Zhang. “As a result, some atmospheric circulations systems cannot be resolved by these models, and this clearly impacts the accuracy of climate change predictions as shown in our study.” Professor Zhang and colleagues believe climate models will become more accurate in the coming years with the use of exsascale supercomputing, now in development worldwide.”
Already in 2014 Mauri et al complained of enormous discrepancies between the real and simulated developments for precipitation and temperature in Europe 5000 years ago. Modelling of the past, i.e. the calibration, didn’t work at all. With so much disappointment one has to ask where all the confidence surrounding models being reliable forecasters comes from.
The paper’s abstract follows:
The influence of atmospheric circulation on the mid-Holocene climate of Europe: a data–model comparison
The atmospheric circulation is a key area of uncertainty in climate model simulations of future climate change, especially in mid-latitude regions such as Europe where atmospheric dynamics have a significant role in climate variability. It has been proposed that the mid-Holocene was characterized in Europe by a stronger westerly circulation in winter comparable with a more positive AO/NAO, and a weaker westerly circulation in summer caused by anti-cyclonic blocking near Scandinavia. Model simulations indicate at best only a weakly positive AO/NAO, whilst changes in summer atmospheric circulation have not been widely investigated. Here we use a new pollen-based reconstruction of European mid-Holocene climate to investigate the role of atmospheric circulation in explaining the spatial pattern of seasonal temperature and precipitation anomalies. We find that the footprint of the anomalies is entirely consistent with those from modern analogue atmospheric circulation patterns associated with a strong westerly circulation in winter (positive AO/NAO) and a weak westerly circulation in summer associated with anti-cyclonic blocking (positive SCAND). We find little agreement between the reconstructed anomalies and those from 14 GCMs that performed mid-Holocene experiments as part of the PMIP3/CMIP5 project, which show a much greater sensitivity to top-of-the-atmosphere changes in solar insolation. Our findings are consistent with data–model comparisons on contemporary timescales that indicate that models underestimate the role of atmospheric circulation in recent climate change, whilst also highlighting the importance of atmospheric dynamics in explaining interglacial warming.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter 
In assessing the global-scale trends in near-surface (0-20 m) ocean temperatures between 1900 and 2010, Gouretski et al. (2012) determined that the world’s oceans warmed by about 1.1°C between 1900 and 1945 (~0.24°C per decade), but then only warmed by an additional net 0.3°C between 1945 and 2010 (~0.046°C per decade), including a cooling trend between 1945 and 1975.
The early 20th century warming was therefore about 4 to 5 times greater both in magnitude and rapidity as the post-1945 warming.
Gouretski et al., 2012
“Both time series show a temperature increase from 1900 to about 1945, a slight decrease to the mid-1970s, and a temperature rise to the end of the record.”


Image: University of Hamburg, Gouretski et al., 2012
Interestingly, Gouretski et al. (2012) also point out that large regions of the oceans have been cooling since the 1990s.
“Decadal mean SST and 0–20 m layer anomalies calculated relative to the reference decade 2001–2010 give evidence of the general warming of the global ocean since 1900. However, large regions of the oceans have experienced cooling since the 1990s. Whereas cooling in the tropical Eastern Pacific ocean is associated with frequent La Nina events in the past decade, the cause of the cooling within the Southern Ocean remains unknown.”
According to Riser and 26 co-authors (2016), the globe’s oceans have warmed in some places, cooled in others, and the overall net change has been a warming of a little less than 0.2°C (0-1000 m) since about 1950, or about 0.03°C per decade.

The achievement of a few tenths of a degree of added warmth over the course of the last 6 ½ decades has been realized largely because the regions of the world where the oceans have been warming have slightly exceeded the cooling regions in volume.
The net difference between the warming and cooling trends for the globe is oddly referred to as global warming even though the warming trends have not been global, but regional.
Riser et al., 2016
“Most regions of the world ocean are warmer in the near-surface [0-700 m] layer than in previous decades, by over 1° C in some places. A few areas, such as the eastern Pacific from Chile to Alaska, have cooled by as much as 1° C, yet overall the upper ocean has warmed by nearly 0.2° C globally since the mid-twentieth century.”  
According to climate models and anthropogenic global warming theory, it has been expected that a long-term, gradually rising warming trend in the world-wide ocean would follow the trends associated with the rise of CO2 emissions.
The the oceans have not cooperated.
Instead, the world’s regional oceans have followed a decadal-scale variability, with pronounced warming and cooling episodes.   The lack of consistency with climate models has thus led scientists to conclude that it is “very difficult to determine whether significant anthropogenic change in [regional 0-2000 m ocean temperatures] … have occurred” (Yashavaev and Loder, 2017).
Below are several examples of the wide swaths of the Earth where ocean cooling (or non-warming) has been ongoing for at least the last decade to last several decades, including the North Atlantic Ocean, Pacific Ocean, Southern Ocean, and Indian Ocean.

North Atlantic

Yashayaev and Loder, 2017
“As a result of this intermittent recurrence of intensified Labrador Sea Water formation, the annual average temperature and density in the region’s upper 2000m have predominantly varied on a bi-decadal time scale, rather than having a long-term trend as might be expected from anthropogenic climate change. … [I]ntermittent recurrence of enhanced deep convection periods in the Labrador Sea, and the associated formation of major LSW classes, are contributing to a predominant decadal-scale variation in hydrographic properties which makes it difficult to determine whether anthropogenic changes are occurring. … This strong, apparently natural, decadal-scale variability makes it very difficult to determine whether significant anthropogenic changes in LSW formation and properties have occurred.”



Robson et al., 2017     
“In the 1990s anomalously strong ocean heat transport convergence dominates the SPG [Subpolar Gyre, North Atlantic] warming. … The cooling of the SPG [Subpolar Gyre, North Atlantic] after 2005 is dominated by a reduction in ocean heat transport convergence, particularly in the eastern SPG. The reduced ocean heat transport is largely due to a weakening ocean circulation.  By focusing on three independent case-studies of North Atlantic decadal change events the analysis presented here gives further support to the important role of ocean heat transport and ocean circulation in driving the observed changes in North Atlantic ocean heat content in the recent past.”


Gladyshev et al., 2017 
“After 2010, a sharp and stable freshening and cooling of SPMWs [Subpolar Mode Water] started in the eastern part of the North Atlantic. In the years 2010–2016, the mean temperature of the SPMW [Subpolar Mode Water] core in the Rockall Trough dropped by -0.73°C (-0.12°C/yr); in the Iceland Basin it dropped by -2.12°C (-0.35°C/yr), and salinity decreased by 0.12 psu (0.02 psu/yr) and 0.23 psu (0.04 psu/yr), respectively.”

Kim et al., 2017


de Jong and de Steur, 2016


Rosenthal et al., 2017


Pacific Ocean

Cheung, 2017


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Wilson et al., 2017


Li, 2017     
“In the Southern Ocean, the increasing trend of the total OHC slowed down and started to decrease from 1980, and it started to increase again after 1995. In the warming context over the whole period [1970-2009], the Pacific was losing heat, especially in the deep water below 1000 m and in the upper layer above 300 m, excluding the surface 20 m layer in which the OHC kept increasing through the time.”


Southern Ocean

Kusahara et al., 2017 
“In contrast to a strong decrease in Arctic sea ice extent, overall Antarctic sea ice extent has modestly increased since 1979. Several hypotheses have been proposed for the net Antarctic sea ice expansion, including atmosphere/ocean circulation and temperature changes, sea ice-atmospheric-ocean feedback, increased precipitation, and enhanced basal meltwater from ice shelves. Concomitant with this positive trend in Antarctic sea ice, sea surface temperatures (SSTs) over the Southern Ocean south of approximately 45°S have cooled over this period [since 1979].”

Latif et al., 2017
“The Southern Ocean featured some remarkable changes during the recent decades. For example, large parts of the Southern Ocean, despite rapidly rising atmospheric greenhouse gas concentrations, depicted a surface cooling since the 1970s, whereas most of the planet has warmed considerably. In contrast, climate models generally simulate Southern Ocean surface warming when driven with observed historical radiative forcing. The mechanisms behind the surface cooling and other prominent changes in the Southern Ocean sector climate during the recent decades, such as expanding sea ice extent, abyssal warming, and CO2 uptake, are still under debate. Observational coverage is sparse, and records are short but rapidly growing, making the Southern Ocean climate system one of the least explored. It is thus difficult to separate current trends from underlying decadal to centennial scale variability.”

Turney et al., 2017     
“Occupying about 14% of the world’s surface, the Southern Ocean plays a fundamental role in ocean and atmosphere circulation, carbon cycling and Antarctic ice-sheet dynamics. … As a result of anomalies in the overlying wind, the surrounding waters are strongly influenced by variations in northward Ekman transport of cold fresh subantarctic surface water and anomalous fluxes of sensible and latent heat at the atmosphere–ocean interface. This has produced a cooling trend since 1979.”


Jones et al., 2016


Indian Ocean

Zinke et al., 2016


Yan et al., 2015


Both The Cooling And The Warming Trends For Recent Decades Follow Natural Oscillatory Patterns, Not Trends In Anthropogenic CO2 Emissions

Gong et al., 2017
“The inter-annual relationship between the boreal winter Arctic Oscillation (AO) and summer sea surface temperature (SST) over the western tropical Indian Ocean (TIO) for the period from 1979 to 2015 is investigated. The results show that the January–February–March AO [Arctic Oscillation] is significantly correlated with the June–July–August SST and SST tendency. … The multi-month SST tendency, i.e., the SST difference of June–July–August minus April–May, is correlated with the winter AO at r = 0.75.Investigation of the regional air–sea fluxes and oceanic dynamics reveals that the net surface heat flux cannot account for the warming, whereas the oceanic Rossby wave plays a predominant role. During positive AO winters, the enhanced Arabian High causes stronger northern winds in the northern Indian Ocean and leads to anomalous cross-equatorial air-flow. … The winter AO-forced Rossby wave propagates westward and arrives at the western coast in summer, resulting in the significant SST increase.”


Belohpetsky et al., 2017
“It is well known that most short term global temperature variability is due to the well-defined ENSO natural oscillation (see: Wang and Fiedler, 2006). During strong El Niño events global average temperature rises by a few tenths Kelvin and reverts back subsequently. … The residual dynamics left after adjusting global surface temperature anomalies (1950-2014) for short-term variability from El Niño Southern Oscillation (ENSO) and volcanic eruptions have a staircase pattern. Linear trends for three quasi-stable periods 1950-1987, 1988-1997 and 1998-2014 are near zero with nearly all warming occurring during two step-like shifts in the years 1987/1988 and 1997/1998.  A notable consequence of the staircase dynamics of recent warming is that observed temperature anomalies (HadCRUT4.5) from 1950 till 2014 could be almost reproduced as the linear sum of only two factors(!) : ENSO variability and the staircase function.”

Gong et al., 2017
“During the past three decades, the most rapid warming at the surface has occurred during the Arctic winter. By analyzing daily ERA-Interim data, we found that the majority of the winter warming trend north of 70°N can be explained by the trend in the downward infrared radiation (IR). This downward IR trend can be attributed to an enhanced poleward flux of moisture and sensible heat into the Arctic by poleward propagating Rossby waves, which increases the total column water and temperature within this region.”

He et al., 2017 
“As pointed out by Cohen et al. (2014) that continental winter SAT [surface temperature] trends since 1990 exhibit cooling over the midlatitudes. The negative trends extend from Europe eastward to East Asia, with a center of maximum magnitude to the west of the Baikal.  As reviewed above, the AO/NAO [Arctic Oscillation/North Atlantic Oscillation] shows an in-phase relationship with the SAT [surface temperatures] over Eurasia. … [T]he negative trend in the AO/NAO might explain the recent Eurasian winter cooling. … Additionally, the relationship between the winter AO and surface-climate anomalies in the following spring might be modulated by the 11-year solar cycle (Chen and Zhou, 2012). The spring temperature anomalies in northern China related to the previous winter AO were larger and more robust after high solar cycle winters. However, spring temperature anomalies became very small and insignificant after the low solar cycle winters. … Numerous atmospheric scientists have documented that the AO could impact significantly the climate over Europe and Far East. …  It is evident that a positive winter AO causes warmer winters over East Asia through enhancing Polar westerly jet which prevents cold Arctic air from invading low latitudes.”


Wu et al., 2017
“The enhanced warming observed in the Eastern China Coastal Waters (ECCW) during the last half-century has received considerable attentions. However, the reason for this warming is still a subject of debate. Based on four different Sea Surface Temperature datasets, we found that the most significant warming occurred in boreal winter during 1982–1998, although the warming trends derived from these datasets differ in magnitude. We suggest that the rapid warming during winter is a result of the asymmetry in the El Niño–Southern Oscillation teleconnection, through which El Niño events induce significant warming over the ECCW at its peak, whereas La Niña events fail to do the opposite that would completely reverse the trends; in addition, there were more El Niño than La Niña events during the recent decades. All these contribute to the winter warming during 1982–1998.”

Mermelstein, 2017     
“[T]he 1940-1978 decrease in CONUS [continental U.S.] temperatures was caused more by the negatively trending oscillatory modes of the AMO/PDO than other factors, and the 1978-2001 increase in temperatures was caused more by the positively trending oscillatory modes of the same oscillations. The small increase, or rather stagnant nature in U.S. CONUS temps since 2001, was likely due to peaking positive modes of the AMO/PDO. In the same way that the AMO and PDO can modify the regional temperatures, we see the same types of effects on precipitation, snowfall and drought in the different regions of the U.S. … It was not until 2003 (Anastasios, Swanson, & Kravtsov, 2003, 2007) that models were created that suggested that these cycles, namely the Pacific Decadal Oscillation (PDO) and the Atlantic Multidecadal Oscillation (AMO) synchronized with each other. Using this as a base, we can explain the major climate shifts that have occurred since scientists began collecting data in the late 1800’s: 1908, 1932, 1973, and 2000. While the most noticeable change in these shifts was on global temperature, effects on the regional, sensible weather in the U.S. were also identified in these same time frames. Through analysis it has been theorized that these shifts are caused by the oceans, and are in fact the main drivers of the climate, and the sensible weather experienced in the United States (Klotzbach & Gray, 2009).”

Fan and Yang, 2017
“The wintertime Arctic temperature decreased from 1979 to 1997 and increased rapidly from 1998 to 2012, in contrast to the global mean surface air temperature [which] increased between 1979 and 1997, followed by a hiatus… A recent study suggests a possible role of the Pacific Ocean decadal oscillation in regulating wintertime climate in the Arctic (Screen and Francis 2016).  … The ‘‘greenhouse effect’’ of water vapor and clouds [CO2 not mentioned as contributing to the GHE] may amplify the effect of winds on Arctic winter climate. …  The objectives of this study are to assess how much natural–internal variability has contributed to climate changes in these [Arctic] regions from 1979 to 2012 … In summary, the correlation analyses presented in this paper shows a natural mode of Arctic winter variability resulting from the Nordic–Siberian seesaw of meridional winds […] is associated with two-thirds of the interannual variance [cooling-warming] of winter-mean Arctic temperature between 1979 and 2012, and possibly contributed a substantial fraction of the observed Arctic amplification [1998-2012 warming] in this period.”


Piecuch et al., 2017
“The subpolar North Atlantic (SPNA) is subject to strong decadal variability, with implications for surface climate and its predictability. In 2004–2005, SPNA decadal upper ocean and sea-surface temperature trends reversed from warming during 1994–2004 to cooling over 2005–2015. … Over the last two decades, the SPNA has undergone a pronounced climate shift. Decadal OHC and SST trends reversed sign around 2004–2005, with a strong warming seen during 1994–2004 and marked cooling observed over 2005–2015. These trend reversals were pronounced (> 0.1 °C yr−1 in magnitude) in the northeastern North Atlantic (south and west of Iceland) and in the Labrador Sea. … To identify basic processes controlling SPNA thermal variations, we diagnose the SPNA heat budget using ECCOv4. Changes in the heat content of an oceanic control volume can be caused by convergences and divergences of advective, diffusive, and surface heat fluxes within the control volume.  [Advective heat convergence] explains 87% of the total [ocean heat content] variance, the former [warming] showing similar decadal behavior to the latter [cooling], increasing over 1994–2004, and decreasing over 2005–2015. … These results demonstrate that the recent SPNA decadal trend reversal was mostly owing to advective convergences by ocean circulation … decadal variability during 1993–2015 is in largest part related to advection by horizontal gyres.”


Cheung, 2017
“The sea surface temperature (SST) of the Eastern Equatorial Pacific (EEP) exerts primary control on global surface temperature (e.g. Halpert and Ropelewski 1992; Wigley 2000) and regional climate (e.g. Ropelewski and Halpert 1987) through different modes of climate variability including the El Niño Southern Oscillation (ENSO) and the Pacific Decadal Oscillation (PDO). With such profound impacts, it is important to understand the evolution of SST in EEP, specifically the dynamics of these climate modes. Rigorous studies over the past decades have shed insights on these two climate modes. ENSO is known to affect regional and global climates on interannual timescales. During an El Niño event, a weakening of easterly trade wind stimulates propagation of Kelvin waves from the western equatorial Pacific to the EEP, which in turn reduces the slope of the thermocline and suppresses upwelling. The decrease in pressure gradient reinforces the weakening of the trade winds through the Bjerknes feedback and ultimately creates an El Niño condition (e.g. Collins et al. 2010). The reorganization of the ocean and the atmosphere due to El Niño raises the global mean surface temperature (e.g. Halpert and Ropelewski 1992; Wigley 2000) and alters regional climate, for example causing drought in Australia (Cai et al. 2011), pluvial in Southwest United States (Ropelewski and Halpert 1987), and changing tropical cyclone frequencies in the Western North Pacific (Camargo and Sobel 2005; Chan 1985). The opposite spatial pattern and teleconnections happen during a La Niña event.”

Wang et al., 2017
“The driving forces of climate change were investigated and the results showed two independent degrees of freedom —a 3.36-year cycle and a 22.6-year cycle, which seem to be connected to the El Niño–Southern Oscillation cycle and the Hale sunspot cycle, respectively. … Solar variability has been shown to be a major driver of climate in central Europe during the past two millennia using Δ14C records. Furthermore, this result is essentially in good agreement with the findings of Scafetta e.g. refs 17, 18, 19, who found that the climate system was mostly characterized by a specific set of oscillations and these oscillations (61, 115, 130 and 983 years) appeared to be synchronous with major astronomical oscillations (solar system, solar activity and long solar/lunar tidal cycles).”
Share this...FacebookTwitter "
"
Share this...FacebookTwitter‘Marked And Steady Increase’ 
In Modern Penguin Abundance

Perhaps because of their unique visual appeal and heavy representation in children’s books and movies (and climate blogs), penguins may subjectively rank second only to polar bears in their polar popularity.
The Polar Bear As ‘Global Warming’ Icon
Advocates of climate alarm have historically used images of forlorn and starving polar bears stranded on melting ice floes to spur human guilt and policy action.  In 2008, polar bears were even classified as endangered due to modeled expectations of their imminent demise.
According to recently published peer-reviewed scientific papers, however, polar bears have been defying the narrative that says dangerous anthropogenic global warming (DAGW) is targeting them for extinction.
That’s because in recent decades 92% of Canadian polar bear subpopulations have remained stable or increased, leading scientists to conclude that “it seems unlikely that polar bears (as a species) are at risk from anthropogenic global warming” (York et al., 2016).  Local Inuit populations even report that there are “too many polar bears now” (Wong et al., 2017).
How About Penguins?
Since the Arctic’s polar bears have not been cooperating with the DAGW narrative (by failing to die off in greater numbers), perhaps penguins, another beloved polar species, could take their place.  After all, the plight of Antarctica’s penguins has not received nearly as much worldwide attention or sympathy.
But scientists have found that penguins have not been cooperating with DAGW expectations either.
In recent decades, and over the course of the last 200 years, penguin numbers have either increased or remained stable.
Penguin Population Dynamics And Climate
Scientists have historically determined that increasing Adélie penguin numbers seem to coincide with warm periods, whereas cooling periods elicit population declines (Emslie et al., 2007;  Huang et al., 2009).
According to Yang et al. (2018), however, increases in penguin abundance coincide with cooling periods.  They note that there were higher Adélie penguin numbers in the Ross Sea region during the Little Ice Age (1600s to early 1800s) than during the 19th and 20th centuries.
Interestingly, though, these scientists also found that there has been no net change in penguin population since the 1800s, a determination that would not appear to fit the perspective that modern climate changes are unprecedented or even unusual.
Furthermore, when it’s considered that there has been no significant regional temperature change between the 1880s and mid-2000s, and that the Ross Sea has undergone a dramatic cooling trend (-1.59°C per decade) since 1979 (Sinclair et al., 2012), any decreasing population trend in recent decades would necessarily coincide with a cooling rather than warming climate.

In another paper published in the journal Nature Communications a few months ago, Che-Castaldo et al. (2017) analyzed 267 Adélie penguin colonies residing on the Antarctic continent and found their numbers have undergone a “marked and steady increase“ between 1982 and 2015.
Reindeer, Perhaps?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




With both polar bears and penguins perpetually failing to support the narrative invoking deep concern about the species-depleting effects of anthropogenic global warming, perhaps a new animal icon foreshadowing the dangers of climate change will emerge at some point.
Reindeer are polar animals that are seasonally quite popular.   Perhaps they could take the place of polar bears and penguins.
Or not.
Bårdsen et al., 2017     The Pursuit of Population Collapses: Long-Term Dynamics of Semi-Domestic Reindeer in Sweden … We investigated the population dynamics of Swedish semi-domestic reindeer from 1945 to 2012 at the reindeer herding district-level (Sameby) to identify possible population collapses or declines […] but found no evidence of large-scale reindeer population declines and no visible synchrony across adjacent populations. Our findings were unexpected as both reindeer populations and the pastoral lifestyle face increased habitat loss, predation, fragmentation and climate change.

Pan-Antarctic analysis aggregating spatial
estimates of Adélie penguin abundance…
Che-Castaldo et al., 2017
[A]ggregated abundance [for 267 Adélie penguin colonies] across all sites in this region showed extended periods of both increasing and decreasing abundance over the last three decades [1982-2015]. 
We also find a long-term decline in abundance in the South Orkney Islands, following an initial period of increase in the early 1980s. In contrast, we found a marked and steady increase in abundance around the rest of the Antarctic continent, including both Eastern Antarctica and the Ross Sea.
Commensurate with other studies [Lynch et al., 2013], we find that the population of Adélie penguins on the Antarctic Peninsula declined between 2000 and 2008, though we found an unexpected rebound in abundance starting in 2008. This regional increase in abundance may, in part, be driven by sites in the Marguerite Bay area, where Adélie penguins are stable or even increasing. However, this increase may also reflect a cessation of regional warming on the Antarctic Peninsula since the late 1990s [Turner et al., 2016], which may benefit ice-dependent species like the Adélie penguin. 
We find that while Eastern Antarctica appears to have been increasing steadily in abundance since at least 1982, the increasing abundance of Adélie penguins in the Ross Sea is more recent, beginning in 2002.
 


Oceanographic mechanisms and penguin population increases 
during the Little Ice Age … southern Ross Sea, Antarctica
Yang et al., 2018
Adélie penguin populations as inferred from […] southern Cape Bird declined slightly from ∼1450 to ∼1600 AD, began to rise afterward and reached their highest level in ∼1700 AD, then declined with fluctuations to the lowest levels through ∼1900 AD. For the past 100 yr, Adélie penguin populations experienced a sharp rise and drop. 
Monitoring data have shown that Adélie penguins at Cape Bird had an increasing trend in the 1970s, likely linked with changes in sea-ice extent and polynya size, but also with variation in competition with minke whales (Ainley et al., 2005; Wilson et al., 2001). Our study suggests that the penguin populations increased in the 1960s as well, consistent with their research.
Over the past 500 yr at Cape Bird, Adélie penguin populations increased during the cold period (∼1600–1825 AD), which is inconsistent with the general pattern in other studies, for example, penguin populations increased when climate became warmer, and vice versa (Emslie et al., 2007; Huang et al., 2009; Sun et al., 2000).


Share this...FacebookTwitter "
"
Share this...FacebookTwitterFirst a note:
If you haven’t already picked up a copy of the The Politically Incorrect Guide to Climate Change, please do get your hands on one.
According to its author Marc Morano, people have been snatching them up and a third printing has started. The book even made the Amazon top 100 best selling books for awhile.
It also ranked first in a number of categories. In his book, NoTricksZone gets mentioned 4 times and even took up one full page at one spot!
So now on to today’s post…
Less heat days near Tokyo
As in Germany, a heat day in Japan is defined as one reaching 30°C or higher.
And according to the manmade CO2 theory, global temperatures are supposed to be rising rapidly and hence we should be seeing many more “heat days” than say 50 or 100 years ago.
Yet Japanese blogger Kirye presents data over Hachijo Island, out to sea east of Tokyo, a location shielded from the urban heat island effect, which tell us that more heat days is not the case at all:

On Hachijo Island, Tokyo, the number of days over 30℃ has not trended since 1926. Source: www.data.jma.go.jp/
Examining the above chart, we see that the number of “heat days” since 2000 is a bit below that of the period from 1940 to 1960. Note the cool 1970 to 1990 period, which likely can be explained by natural oceanic oscillations.
Another chart Kirye provides at Twitter breaks it down in more detail:
 Source: www.data.jma.go.jp/




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Kirye writes, when looking at the past 111 years, the trend in Hachijo Island’s number of days over 30℃ from 1906 to 2017 “denies the anthropogenic global warming hypothesis” and that it does not support the myth of a widespread man-made climate change.
No trend in the city of Tokyo
Also the last 24 years in the city Tokyo show no trend, and even a declining trend since 2010:


Data source: Japanese Meteorological Agency (JMA)
What follows is the month-by-month breakdown, May to October:

Data Source: www.data.jma.go.jp/
Urban heat island
Kirye also presents here a comparison of the Tokyo and Hachijo Island temperature course over the past 111 years. Note urban Tokyo has risen while the island off the coast has risen only very slightly:

Data source: JMA
Urban heat island effect? Kirye notes:

The mean daily maximum temperatures for Tokyo and Hachijo Island differed by more than 2C with the early trend during the period from 1907 to 2015, but temperature difference of close to 0.7C with the trend in the latter period.”




Share this...FacebookTwitter "
"
Share this...FacebookTwitterCO2 emissions exert no detectable effect on Arctic, Antarctic temperatures. The Arctic region is no warmer in recent decades than it was some 80 years ago, or before CO2 emissions began rising significantly.

Graph Source: Mikkelsen et al., 2018
According to the IPCC, the Arctic and Antarctic regions warm more than the rest of the globe — a phenomenon branded as polar amplification.
Further, it is conclusively stated (with “high confidence”) that this enhanced polar warming occurs largely in response to increases in atmospheric CO2 concentration.

Image Source: IPCC AR5 
A 2015 Scientific Paper Affirms CO2 Forcing Is ‘Weak’ To Negligible At The Poles
In late 2015, four climate scientists published a groundbreaking paper (Schmithüsen et al.,[2015]) in the highly-regarded Geophysical Research Letters scholarly journal.
Although obligatorily insisting their research did not undermine the main tenets of anthropogenic global warming (AGW) theory at one turn, the authors nonetheless landed a devastating blow to the conceptualization of a CO2-amplified polar climate – and thus to the narrative that says the ice sheets and sea ice are melting primarily due to increases in anthropogenic CO2 emissions.
Schmithüsen and colleagues reached the conclusion that CO2-forcing is “rather small” and even “weak“ at the poles.  They found the planet’s tiniest warming signal from CO2 occurs for central Antarctica; they characterized the CO2-forcing for the Arctic region as “comparatively weak”.    For example, quadrupling CO2 concentrations over the Antarctic Plateau is poised to yield a net radiative forcing value of just 1 W m-2.
The authors even assert that increasing CO2 concentrations causes atmospheric cooling in some areas above the Antarctic continent.  They characterize this as a “negative greenhouse effect” due to the “increased long-wave energy loss to space, which cools the Earth-atmosphere system”.
Key points from the paper are highlighted below.

Schmithüsen et al., (2015)
 

 

Warming From Increased CO2 Is ‘Comparatively Weak‘ For The Arctic Region


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





‘Polar Amplification’ From Increased CO2 Not Detectable For Antarctica
Consistent with the conceptualization that “polar amplification” from increasing human CO2 emissions has gone unrealized, the temperature records for the Antarctic continent do not suggest warming has occurred in recent decades.

Graph Sources: Climate4you, Miles et al., 2013, Turner et al., 2016
Increasing CO2 Emissions Has Exerted No Detectable Effect On The Arctic Region
Consistent with the conceptualization that “polar amplification” from increasing CO2 has gone unrealized, the temperature records for the Arctic region also do not suggest a discernible net warming has occurred in response to the rapid increase in anthropogenic CO2 emissions since the mid-1940s.  The Arctic region is no warmer in recent decades than it was ~80 years ago, or before CO2 emissions began rising significantly.  This would support the conclusion that CO2 emissions increases have exerted no detectable effect on the Arctic region’s temperatures.

Graph Source: Hanhijärvi et al., 2013

Graph Source:  Hanna et al., 2011
‘Weak’ To Negligible CO2 Forcing At The Poles Lands A Devastating Blow To AGW Alarm
If the warming effect from increasing CO2 concentrations is only “weak” to negligible for both the Antarctic and Arctic regions, then the justification to endorse the most alarming tenets of the anthropogenic global warming conceptualization may be thoroughly undermined.
For example:
1. The decline in Arctic sea ice since the late 1970s may no longer be predominantly attributed to CO2-induced Arctic warming.
2. Mass ice losses for both the Antarctic and Greenland ice sheets in the modern era may no longer be predominantly attributed to CO2-induced polar warming.
3. The net ice melt contribution to sea level rise from the Antarctic and Greenland ice sheets in the modern era may no longer be predominantly attributed to CO2-induced polar warming.
4. The post-1980s temperature warming for the Arctic region (that has significantly affected the overall global warming trend) may no longer be predominantly attributed to CO2-induced Arctic warming.
In sum, affirming the Schmithüsen et al.,(2015) analysis leaves little room for continued insistence that rising CO2 emissions are a profound and existential planetary threat.

Update: A just-published paper, Flanner et al., 2018, cites the negative CO2 greenhouse effect conceptualization introduced by Schmithüsen et al.,(2015).  At no time do the authors challenge the relatively quite weak radiative forcing values (~1 W m-2) for the CO2 greenhouse effect in the polar regions as depicted in the colorized graph above.  Instead of challenging these very small CO2-forcing values for polar regions, the authors only challenge the less consequential concept of whether or not a cooling would occur at the poles in response to increases in greenhouse gases (GHGs) in general, and not CO2 in particular.   It would appear the weak CO2 forcing (W m-2) values for the polar regions as determined by Schmithüsen et al., (2015) are accepted by mainstream climate science.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNew Paper Spurns Anthropogenic CO2 Warming,
Unveils Natural Explanation For Climate Change

University of California (Santa Cruz) Professor W. Jackson Davis (Ph.D.), President of the Environmental Studies Institute, has published a new paper with colleagues in the journal Climate that thoroughly undermines the conceptualization of a dominant role for anthropogenic CO2 in the global warming since 1850.
Davis points out that CO2 and global temperature have been “decoupled” throughout much of geological history, and that the amplification of CO2 concentrations yields increasingly smaller radiative effects, meaning that the higher the CO2 concentration rises, the weaker its influence.
He even suggests that the reason why the anthropogenic global warming (AGW) hypothesis (it has not reached theoretical status) has been popularized is because there are reputed to be no convincing alternative explanations.
But Davis and two other University of California (SC) scientists have proposed a newly-termed alternative explanation for the 0.8°C global temperature change since 1850.  The Antarctic Centennial Oscillation (ACO) has been identified as varying in sync with solar cycles (orbital), and correlates with glacial-interglacial transitions, the 1,500-year abrupt, global-scale temperature changes (Dansgaard-Oeschger cycles), and, as the name suggests, century-scale fluctuations in global temperature.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Consequently, as the authors conclude, properties of the ACO “can explain the current global warming signal”.

Davis et al., 2018
Introduction:
[T]he contemporary global warming increase of ~0.8 °C recorded since 1850 has been attributed widely to anthropogenic emissions of carbon dioxide (CO2) into the atmosphere. Recent research has shown, however, that the concentration of CO2 in the atmosphere has been decoupled from global temperature for the last 425 million years [Davis, 2017] owing to well-established diminishing returns in marginal radiative forcing (ΔRF) as atmospheric CO2 concentration increases. Marginal forcing of temperature from increasing CO2 emissions declined by half from 1850 to 1980, and by nearly two-thirds from 1850 to 1999 [Davis, 2017]. Changes in atmospheric CO2 therefore affect global temperature weakly at most.
The anthropogenic global warming (AGW) hypothesis has been embraced partly because “…there is no convincing alternative explanation…” [USGCRP, 2017] (p. 12).
The ACO provides a possible alternative explanation in the form of a natural climate cycle that arises in Antarctica, propagates northward to influence global temperature, and peaks on a predictable centennial timetable.
Abstract:
We report a previously-unexplored natural temperature cycle recorded in ice cores from Antarctica—the Antarctic Centennial Oscillation (ACO)—that has oscillated for at least the last 226 millennia. Here we document the properties of the ACO and provide an initial assessment of its role in global climate. We analyzed open-source databases of stable isotopes of oxygen and hydrogen as proxies for paleo-temperatures. We find that centennial-scale spectral peaks from temperature-proxy records at Vostok over the last 10,000 years occur at the same frequencies (±2.4%) in three other paleoclimate records from drill sites distributed widely across the East Antarctic Plateau (EAP), and >98% of individual ACOs evaluated at Vostok match 1:1 with homologous cycles at the other three EAP drill sites and conversely.
The period and amplitude of ACOs oscillate in phase with glacial cycles and related surface insolation associated with planetary orbital forces. We conclude that the ACO: encompasses at least the EAP; is the proximate source of D-O oscillations in the Northern Hemisphere; therefore affects global temperature; propagates with increased velocity as temperature increases; doubled in intensity over geologic time; is modulated by global temperature variations associated with planetary orbital cycles; and is the probable paleoclimate precursor of the contemporary Antarctic Oscillation (AAO). Properties of the ACO/AAO are capable of explaining the current global warming signal.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNever mind the severe cold hitting the Super Bowl this year, or scientists lecturing us on global warming while their host resort Davos got buried in snow.
There’s been a lot of cold gripping all over the northern hemisphere this winter – much more than many of us expected. Europe has also joined in on the freeze-fest as the harsh winter spreads across the old continent and even into Africa:

Cold is forecast to keep Europe shivering this week. Image cropped from wetter.online.de.
Cooling globe
One reason for this could be due to the rapidly falling global surface temperatures  as recorded by satellite data. In January the global mean temperature anomaly dropped to +0.26°C, with the tropics (where most of the heat is found) posting a nippy -0.12°C anomaly, according to Dr. Roy Spencer.
Other cooling factors include the current La Nina and possibly the low solar activity playing a role. IceAgeNow here reported last July that solar activity was at its most rapid decline in 9300 years.
Europe
In Northern Europe cold winter are normal, but the recent forecast for the Finnish region of Lapland warned of temperatures down to -40°C. This Finnish website here writes:
Temperatures have been low all winter in Finnish Lapland, but the cold dip expected this week could see record-breaking extremes.”
Snow and cold are also forecast across UK as the Express here reports: “Britain set for FOOT of heavy snow NEXT WEEK in COLDEST freeze for decade.”
Spain, North Africa get frostbitten and snowed on
The wintry conditions will likely impact agriculture and the European food markets. Fruitnet.com here writes: ” The cold snap gripping much of the Spanish peninsula is likely to reduce the availability of vegetables and salads on the European market during the coming weeks.”
The extreme cold has even extended beyond southern Europe and into Africa! For example Southern Morocco saw snow for the first time. And so has the Canary island of Tenerife seen its landscape get blanketed with the white stuff.
Stunning Sahara snow
Also The Mail here reports snowfall in the Algeria – the Sahara Desert. Up to December 2016 it had not snowed there in 37 years. Now according to The Mail it has snowed 4 times since, and it’s the second time this year already. “Locals were stunned to see snow on the sand dunes in the Sahara Desert yesterday.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Records in Japan
Japanese blogger Kirye here tweeted that minimum temperature dropped to -17.2 ℃ on February 2, 2018, in Ikarigaseki, Aomori Prefecture. “It is the coldest daily minimum temperature since records began on November 24, 1976! The previous record low was -16.6 ℃, set on January 18, 2014.”
Kirye also tweeted: “The minimum temperature in Fuchu, Tokyo dropped to minus 8.4 ℃ on January 25, 2018. It is the lowest daily minimum temperature since records began on December 15, 1976. The previous record low was minus 8.2 ℃, set on February 8, 1984.”
Moreover, Japan’s mean temperature anomaly for January 2018 was a chilly -0.22 ℃. Kirye writes that there’s been no warming trend for January from 1986 to 2018.
The English language NTV of Japan writes: “This winter’s harshest cold wave continues in Japan with freezing temperatures in central Tokyo recorded two days in a row for the first time in 55 years.”
Kirye adds: “The minimum temperature dropped to -3.1℃ on January 26 in Tokyo. It is the coldest daily minimum temperature for January 26 since 1965.”
Russian Snowmageddon…minus 67°C
As I already highlighted here earlier, a number of locations across the northern hemisphere are seeing surprising brutal winter conditions. Another example: media outlets have reported widely that Moscow just saw a record snowfall. Also read here.
And in the Siberian region of Yakutia, the temperature fell as low as minus 67 Celsius.
Australia and New Zealand
Even the southern hemisphere has not been spared. The weatherzone.com.au here reports “many towns in south-east Queensland have experienced their coldest February day on record”  and that “Archerfield managed only 21°C and Coolangatta on the Gold Coast 21.6°C”.
According to a local meteorologist: “These are the coldest February days that we’ve ever experienced in those places and some of those records date back quite some time.”
Finally Ice Age Now here writes that Tasmania even recorded a “summer blizzard.”
That’s a lot of winter, snow and cold for a planet that is supposedly warming rapidly.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAtmospheric Scientists Slam Fundamentals
of the Anthropogenic Global Warming Theory

Scafetta et al., 2017    Natural climate variability, part 1: Observations versus the modeled predictions
[T]he AGWT [Anthropogenic Global Warming Theory] was globally advocated by the IPCC in 2001 because it appeared to be supported by the ‘infamous’ Hockey Stick temperature reconstructions by Mann et al. [10]* and by specific computer climate models mainly based on radiative forcings [4,11]. Those temperature reconstructions claimed that only a very modest change in the Northern Hemispheric climate had occurred during the pre-industrial times from A.D. 1000 to 1900, while an abrupt warming did occur just in the last century. Energy balance and general circulation climate models (GCM) were used to interpret the Hockey Stick climatic pattern as due mostly to anthropogenic greenhouse gas emissions such as CO2 because of coal and oil fuel consumption, which has been accelerating since the beginning of the 20th century [11].
However, since 2005 novel Northern Hemisphere proxy temperature reconstructions were published revealing the existence of a large millennial oscillation that contradicts the Hockey Stick temperature pattern
* see reference list



Wilson et al., 2016

Wilson et al., 2016


Abrantes et al., 2017

The new findings were consistent with alternative climatic and solar activity records showing that a quasi-millennial oscillation occurred throughout the entire Holocene for the last 10,000 years [16, 17].
The severe discrepancy between observations and modeled predictions found during the 1922-1941 and 2000-2016 periods further confirms, according to the criteria proposed by the AGWT advocates themselves, that the current climate models have significantly exaggerated the anthropogenic greenhouse warming effect.
In 2009 AGWT advocates acknowledged that: “Near-zero and even negative trends are common for intervals of a decade or less in the simulations, due to the model’s internal climate variability. The simulations rule out (at the 95% level) zero trends for intervals of 15 year or more, suggesting that an observed absence of warming of this duration is needed to create a discrepancy with the expected present-day warming rate” [24]. Thus, according to the AGWT advocates’ own criteria, a divergence between observations and climate models occurring at the bi-decadal scale would provide strong convincing evidences that the GCMs used to support the AGWT are severely flawed.
In conclusion, the temperature records clearly manifest several fluctuations from the inter-annual scale to the multidecadal one. Detailed spectral analyses have determined the likely existence of harmonics at about 9.1, 10.5, 20 and 60- year periods [7, 8, 9]. By contrast, the CMIP5 GCMs simulations used by the IPCC (2013) to advocate the AGWT show a quite monotonic accelerating warming since 1860, which is at most temporarily interrupted by volcano eruptions and only slightly modulated by aerosol emissions. Thus, the models are not able to reproduce the natural variability observed in the climate system and should not be trusted for future energy planning [33].


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




It has been suggested that non-radiative physical processes connected with solar activity and the “resonant” orbital motions of the moon and the planets can cast light on the otherwise incomprehensible temperature fluctuations [34, 35]. In fact, the magnetic activity of the sun and, probably, also the planetary motions modulate both the solar wind and the flux of the cosmic rays and interstellar dust on the earth with the result of a modulation of the clouds coverage.

Scafetta et al., 2017  Natural climate variability, part 2: Observations versus the modeled predictions

Several studies based on general circulation model (GCM) simulations of the Earth’s climate concluded that the 20th century climate warming and its future development depend almost completely on anthropogenic activities. Humans have been responsible of emitting in the atmosphere large amount of greenhouse gases (GHG) such as CO2 throughout the combustion of fossil fuels. This paradigm is known as the Anthropogenic Global Warming Theory (AGWT).
[S]ince 2001 AGWT was actually supported by the belief that the “hockey stick” proxy temperature reconstructions, which claim that an unprecedented warming occurred since 1900 in the Northern Hemisphere, were reliable [2,5] and could be considered an indirect validation of the available climate models supporting the AGWT [6]. However, since 2005 novel proxy temperature reconstructions questioned the reliability of such hockey stick trends by demonstrating the existence of a large millennial climatic oscillation [7-10]. This natural climatic variability is confirmed by historical inferences [11] and by climate proxy reconstructions spanning the entire Holocene [12, 13]. A millennial climatic oscillation would suggest that a significant percentage of the warming observed since 1850 could simply be a recovery from the Little Ice Age of the 14th – 18th centuries and that throughout the 20th century the climate naturally returned to a warm phase as it happened during the Roman and the Medieval warm periods [9, 11, 14-16].
We … critically analyze the year 2015-2016, which has been famed as the hottest year on record. We show that this anomaly is simply due to a strong El-Niño event that has induced a sudden increase of the global surface temperature by 0.6 °C. This event is unrelated to anthropogenic emissions. In fact, an even stronger El-Niño event occurred in 1878 when the sudden increase of the global surface temperature was 0.8 °C.
Herein, the authors have studied the post 2000 standstill global temperature records. It has been shown that once the ENSO signature is removed from the data, the serious divergence between the observations and the CMIP5 GCM projections becomes evident. Note that Medhaug et al. [28] claim that the models agree with the post 2000 temperature trend. However, these authors did not remove the ENSO signal and used annual mean temperature records up to 2015 that camouflage the real nature of the 2015-2016 ENSO peak.
Moreover, a semi-empirical model first proposed in 2011 based on a specific set of natural oscillations suggested by astronomical considerations plus a 50% reduced climatic effect of the radiative forcing, which includes the anthropogenic forcing, performs quite better in forecasting subsequent climate changes. Thus, the GCMs used to promote the AGWT have been also outperformed [by a natural oscillation/astronomical/anthropogenic “semi-empirical” model][15]. This result is indeed consistent with recent findings. In fact, although the equilibrium climate sensitivity (ECS) to CO2 doubling of the GCMs vary widely around a 3.0°C mean [3,4], recent studies have pointed out that those values are too high.
Since 2000 there has been a systematic tendency to find lower climate sensitivity values. The most recent studies suggest a transient climate response (TCR) of about 1.0 °C, an ECS less than 2.0 °C [20] and an effective climate sensitivity (EfCS) in the neighborhood of 1.0 °C [29].
Thus, all evidences suggest that the IPCC GCMs at least increase twofold or even triple the real anthropogenic warming. The GHG theory might even require a deep re-examination [30].

Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn the wake of a fall storm ‘Xavier’ that struck Germany and claimed 7 lives, one of Germany’s most popular TV Talkshows, Maischberger 1 on ARD German public television, recently featured climate change in discussion round bearing the title: “Xavier and the weather extremes: has our climate reached the tipping point?”

Cologne and Berlin under water! Backdrop on set for ARD German television discussion round on climate change. Image cropped from Maischberger 1 here.
The discussion round included, among others, Prof Hans-Joachim Schellnhuber, high profile Swiss meteorologist Jörg Kachelmann, who by the way is a warmist, and Swiss science journalist Alex Reichmuth.
Not surprisingly, talk show moderator Sandra Maischberger introduced the show with dramatic scenes of a climate in collapse, and then asked the round if this if the recent storms Xavier and now Orphelia are unprecedented. So dramatic in fact were the images of Maischberger’s intro that even German daily Die Welt here commented that “ARD had allowed itself to be inspired a bit by Hollywood“.
When asked by Maischberger about the recent storms, Kachelmann immediately dumped cold water on the notion that they were unusual, noting that storm Xavier seemed worse because it hit in October when trees are still fraught with foliage and thus cause far more wind resistance and cause tress to fall more often. Overall, Xavier was just a normal fall storm, Kachelmann told the audience.
“Storms don’t come with a label”
When asked if this year’s heavy rains were due to global warming, Kachelmann responded:
“We don’t know case by case because all the thunderstorms and storms don’t come with a label stating: ‘I’m here only because of you, or your actions, to say it correctly’. The problem is that we don’t know.”
No detectable increase in storm frequency
Kachelmann went on to explain that experts evaluated the data from the German Weather Service and concluded there has been “no increase in frequency in these events“. He added:
Also with tropical storms, looking at it globally, from the data of the American weather agencies, up to now we see no increase in frequency.”
A few seconds later he responded to Maischberger’s inquiry about the “monster hurricanes” hitting the Caribbean and USA:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Yes, this is an active season. But it is not a record season. It is not anything that has not happened before. When we look back at the last 50 or 60 years, we see no trend.”
During the course of the Talkshow, moderator Maischberger globetrotted across the entire planet, it seemed, going from one weather disaster to the next. She pressed Kachelmann about the fires in northern California. Here too the Swiss veteran meteorologist dismissed the notion that it’s unusual, reminding the audience that California is a dry state and these things have always happened before:
When you look at the archives, we see no increase in frequency.”
Kachelmann also reminded that anyone can make a list of 100 disasters in any year.
Like Jehovah Witness
At about the 16-minute mark, Maischberger turned to Swiss journalist Alex Reichmuth, who like Schellnhuber studied physics and mathematics. Journalist Reichmuth, however, is far more critical of climate change,and told the audience that climate science is more a religion than science and that it all reminded him of the Jehovah Witness sect.
This is about a religious conversion – ride your bicycle more and we’ll be redeemed.”
Reichmuth reminded the audience that even the IPCC stated that there is no clear trend regarding weather extremes.
From 97% to 99%?
Reichmuth then slammed Schellnhuber for his outlandish predictions of the future, telling the “renowned” Potsdam professor that he “has clearly deviated from the scientific approach“. Just a minute earlier Schellnhuber had seemed to claim that 99% of the scientists agree with him.
Surprisingly guest Dorothee Bär of the conservative CSU party said she doubted that man was all responsible for the 1°C warming of the past century and that economy and well-being of the citizen had to be placed at the forefront of any energy policy. But later in the show the CSU politician hopped on the politically correct “we have to do something” facade – as did Kachelmann.
At the 34-minute mark, the talk switched to Trump’s backing out of the Paris Accord and whether the fight against the climate would hurt the economy. Most of the discussion was filled Marxist-brand utopian platitudes with few in the round grasping the technical implications of green energies. For example, suddenly Schellnhuber poased as an expert and leading authority on transportation technology, agriculture and economics, and gave the impression storage systems are all ready to go!
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
A new scientific study says surface temperatures in the Northeastern U.S. (Appalachian Mountains) have undergone a significant long-term cooling trend since the early 20th century, complicating the detection of a clear anthropogenic global warming (AGW) signal for the region.
According to Eck (2018), the two coldest Appalachian winters since 1910 were recorded in recent years (2009-’10 and 2010-’11), and 9 of the 10 warmest winters occurred prior to 1960.
In the early 1930s, Appalachian winters were 4.7°C warmer than they have been during the last 30 years (1987-2017).
Several other recently-published papers also reveal a long-term cooling trend not only for the Northeastern U.S. (Eck, 2018), but the Southeastern U.S. (Rogers, 2013; Christy and McNider, 2016), the Central U.S. (Alter et al., 2017), and the Southwestern and Northwestern U.S. (Loisel et al., 2017; Steinman et al., 2016).
In other words, the regions in the continental United States that are less affected by urbanization biases and artificial instrumental heating may not be responding to “global” warming or to the rise in anthropogenic CO2 emissions as climate models have suggested.

Eck, 2018
“[A] majority (12/14) of the regions within the SAM [Southern Appalachian Mountains] have experienced a long-term decline in mean winter temperatures since 1910.   Even after removing the highly anomalous 2009-2010 winter season, which was more than two standard deviations away from the long-term mean, the cooling of mean winter temperatures is still evident.”
“Higher winter temperatures dominated the early 20th century in the SAM [Southern Appalachian Mountains] with nine of the ten warmest winter seasons on record in the region having occurred before 1960.”
“The 1931-1932 winter season, the warmest on record, averaged 8.0°C for DJF [December-February], nearly 4.7°C higher than the 1987-2017 normal mean winter temperature of 3.3°C.”
“Despite the 2016-2017 winter season finishing with the highest mean temperatures (5.7ºC) observed in the SAM [Southern Appalachian Mountains]  since 1956-1957, there have been several years of anomalous negative temperature anomalies, with the 2009-2010 (0.3ºC) and 2010-2011 (1.2ºC) winter seasons finishing as two of the coldest on record for all regions.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->







Central U.S. Cooling (-0.35°C) Since 1910
Alter et al., 2017
“In the central United States … observational data indicate that rainfall increased, surface air temperature decreased, and surface humidity increased during the summer over the course of the 20th century concurrently with increases in both agricultural production and global GHG emissions.”
“From 1910- 1949 (pre-agricultural development, pre-DEV) to 1970-2009 (full agricultural development, full-DEV), the central United States experienced large-scale increases in rainfall of up to 35% and decreases in surface air temperature of up to 1°C during the boreal summer months of July and August … which conflicts with expectations from climate change projections for the end of the 21st century (i.e., warming and decreasing rainfall) (Melillo et al., 2014).”
“Thus, it seems that GHG emissions do not contribute greatly to the regional changes in summer climate that have been observed in the central United States.”


Southeastern U.S. Cooling Since 1890s
Rogers, 2013

Christy and McNider, 2016


Long-Term Cooling Trend In The Western U.S.
Loisel et al., 2017

Steinman et al., 2016

Share this...FacebookTwitter "
