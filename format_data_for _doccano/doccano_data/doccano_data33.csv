"
Share this...FacebookTwitter
While it has understandably not received much, if any, media attention, the North Atlantic Ocean has been rapidly cooling since the mid-2000s, or for more than 10 years now.   The longer the cooling trend continues — and scientists are projecting more cooling for the coming decades  —  the more difficult it will be to ignore.   The North Atlantic Ocean is, after all, a key trend-setter for hemispheric- and perhaps even global-scale climate changes.
In their new paper, for example, Reynolds and colleagues (2017) point out that natural fluctuations in heat transport initiated by the Atlantic Meridional Overturning Circulation (AMOC) are “directly linked” to precipitation and warming/cooling temperature trends in Africa, Brazil, North America, and Europe.   Not only that, but the authors explain that a centennial-scale reduction in surface heat transport (AMOC) can explain the dramatic reduction in surface temperatures from the warmth of the Medieval Warm Period to the frigid Little Ice Age, which, of course, could imply that centennial-scale increases in surface heat transport could explain warming periods.

Reynolds et al., 2017       Evidence derived from instrumental observations suggest that Atlantic variability, associated with changes in SSTs and fluctuations in the strength of the Atlantic Meridional Overturning Circulation (AMOC), is directly linked with broader scale climate variability, including Brazilian and Sahel precipitation (Folland et al., 1986 and Folland et al., 2001), Atlantic hurricanes and storm tracks (Goldenberg et al., 2001 and Emanuel, 2005), and North American and European temperatures (Sutton and Hodson, 2005, Knight et al., 2006 and Mann et al., 2009). Furthermore, evidence derived from palaeoceanographic records suggests that a reduction in the meridional heat transport through the surface components of the AMOC was in part responsible for the reductions in temperatures associated with the Medieval Climate Anomaly (MCA; 1000–1450) to Little Ice Age (LIA; 1450–1850) transition (Lund et al., 2006, Trouet et al., 2009, Trouet et al., 2012, Wanamaker et al., 2012 and Moffa-Sánchez et al., 2014).

Examining the Reynolds et al. (2017) graph of North Atlantic sea surface temperatures since the early 1800s, we notice that temperatures (shown to have declined by about -0.45 °C since 2005) are colder now than they were in the 1940s and 1950s, and that even the early 1800s had warmer temperatures than now.

Serykh (2016) points out that the warming enjoyed across Europe and Asia between the 1970s and late 1990s may have been associated with natural decadal-scale oscillations in heat transport.   Similar to Reynolds et al. (2017), Serykh’s graph of ocean heat content reveals no net warming in the last 60 years.

Serykh, 2016       A dipole structure of inter-decadal variations in the heat content of the ocean and heat fluxes from the ocean to the atmosphere has been detected in the North Atlantic. The following fact deserves special attention: the cyclonic and anti-cyclonic atmospheric circulation anomalies, as well as the decrease and increase in the ocean heat content, take place concurrently and quasi-synchronously in the Iceland minimum and Azores maximum regions. Owing to this, the western heat transport anomalies along the 50th parallel increase or decrease the transport of heat from the Atlantic Ocean to the Euro-Asian continent, and the climate in Europe and Siberia becomes more marine or more continental. The very fast climate warming of the Euro-Asian continent that began in the 1970s may be associated with the enhanced heat transport from the North Atlantic in this period. This is evident from the fields and time series obtained in the present paper. The hiatus of this warming after 1999 may be due to the decreased heat transfer from the North Atlantic Ocean to the Eurasian territory.



Dramatic Cooling In the North Atlantic (Affecting Global Climate) Linked To Natural Variability, Not Human Influence
Scientists first began highlighting the North Atlantic cooling trend a few years ago.  Hermanson et al. (2014), for example, pointed out that the AMOC modulates the water temperatures in the North Atlantic by driving the transport of warmer (cooler) ocean water on decadal scales.   Using data that extended through 2012, they (correctly) forecast the cooling trend that had begun in the mid-2000s would continue.  It has.

Hermanson et al., 2014       The observed 5 year mean temperature averaged over the upper 500 m of the SPG [Subpolar Gyre, North Atlantic Ocean] [shows] a marked cooling in the late 1960s followed by a period with below average temperatures, and a warming in the 1990s followed by a period with above average temperatures. … The forecasts that were initialized between 2008 and 2012 (crosses) all show a general trend for further decreases in temperature, continuing the observed [cooling] trend. The 2012 forecast spread suggests that the chance of the observed warm SPG mean temperature anomaly of 2003–2007 (0.53) occurring again in 2013–2017 is less than 6%.
To gain further confidence in this forecast we examine the physical mechanisms that control SPG [North Atlantic Ocean] temperatures. Previous studies showed that the 1990s SPG warming was driven by increased convergence of ocean heat transport resulting from an increase in the AMOC, and the 1960s cooling was driven by reduced ocean heat transport convergence following a reduced AMOC. The hindcasts show changes in ocean heat transport convergence, consistent with these earlier events. The forecasts show a continued decrease in ocean heat transport convergence, consistent with a cooling SPG [Subpolar Gyre, North Atlantic Ocean].

A year ago, Robson et al. (2016) published a paper in Nature explaining that the previous warming trend (1995-2005) had “reversed” to a -0.45 °C cooling trend since 2005 (through 2015), and, like Hermanson et al. (2014) and Reynolds et al. (2017), they attributed both the 1995-2005 warming trend and the current cooling trend to the vagaries of the Atlantic Meridional Overturning Circulation, even pointing out that the trends are not consistent with an anthropogenic influence.

Robson et al., 2016       In the mid-1990s the North Atlantic subpolar gyre warmed rapidly, which had important climate impacts such as increased hurricane numbers and changes to rainfall over Africa, Europe and North America. Evidence suggests that the warming was largely due to a strengthening of the ocean circulation, particularly the Atlantic Meridional Overturning Circulation. Since the mid-1990s direct and indirect measurements have suggested a decline in the strength of the ocean circulation, which is expected to lead to a reduction in northward heat transport. Here we show that since 2005 a large volume of the upper North Atlantic Ocean has cooled significantly by approximately 0.45 °C or 1.5 × 1022 J, reversing the previous warming trend. … The observed upper ocean cooling since 2005 is not consistent with the hypothesis that anthropogenic aerosols directly drive Atlantic temperatures.


As the introductory graph of the North Atlantic trend shows above, Duchez and colleagues (2016) report that today’s temperatures are colder than they were in the 1950s — up to 2 °C colder than average — and the “most extreme in the modern record [1948-2015].”.
Duchez et al., 2016       [C]old ocean temperatures were the most extreme in the modern record [since 1948] over much of the mid-high latitude North-East Atlantic. … we consider the exceptionally cold ocean surface anomaly that was already in place prior to the onset of the 2015 heat wave. The SST anomaly field for June 2015 shows temperatures up to 2 °C colder than normal over much of the sub-polar gyre with values that are the coldest observed for this month of the year in the period 1948–2015 indicated by stippling. The cause of this cold anomaly has been the subject of widespread interest in the media, we now show for the first time that it can be attributed to a combination of air–sea heat loss from late 2014 through to spring 2015 and a re-emergent sub-surface ocean heat content [cold] anomaly that developed in preceding years.

Chafik et al. (2016) connect the warming-cooling-warming-cooling oscillatory patterns in the North Atlantic to the natural atmospheric forcing associated with the North Atlantic Oscillation (NAO) (which is symbiotically connected to the AMOC), and they also highlight the recent cooling trend in their graph (ending in 2012).   They further agree with other scientists that the North Atlantic region is “important for global mean temperature warming,” meaning that what happens in the North Atlantic may have broad implications for climate.
Chafik et al., 2016       The multidecadal variability of the North Atlantic Ocean has a strong signal in the sea surface temperature with many global climate linkages [Enfield et al., 2001; Knight et al., 2006]. An even stronger multidecadal signal can be found in the subpolar temperatures and salinities, where the Atlantic Water inflow variations constitute an essential part in the variability [Hátún et al., 2005; Häkkinen et al., 2011a; Reverdin, 2010]. The atmospheric forcing in the subpolar North Atlantic Ocean is dominated by the variability of the North Atlantic Oscillation (NAO), i.e., the leading mode of atmospheric variability in the North Atlantic sector, which modulates the atmosphere-ocean momentum and heat exchanges on a range of temporal scales. The subpolar ocean variability thus appears to be tightly connected to atmospheric forcing and associated basin-scale circulation changes, which together force the subpolar ocean properties toward extremes [Lozier et al., 2008, 2010], either to warm-saline or cold-fresh conditions on multidecadal scales. These regime changes have recently been argued to be important for global mean surface temperature warming acceleration and hiatus [Chen and Tung, 2014; Drijfhout et al., 2014].



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Koenigk and Brodeau (2016) point out that Arctic sea ice area and volume changes (decline) in the last 30 years are “dominated by” the natural variability in heat transport (AMOC), and that a cooling trend may be in the works through 2030.

Koenigk and Brodeau, 2016       Decadal variations of Arctic sea ice extent and ice volume are of the same order of magnitude as the observed ice extent reductions in the last 30 years and are dominated by the variability of the ocean heat transports through the Barents Sea Opening and the Bering Strait. Despite a general warming of mid and high northern latitudes, a substantial cooling is found in the subpolar gyre of the North Atlantic under year-2015 and year-2030 conditions. This cooling is related to a strong reduction in the AMOC, itself due to reduced deep water formation in the Labrador Sea.

Still more scientists — Barcikowska et al. (2016) — observe a North Atlantic/tropical Pacific cooling-warming-cooling trend that may presage global temperature implications (cooling) for the coming decade(s).

Barcikowska et al., 2016       If the observations-based component of variability originates from internal climate processes, as found in the model, the recently observed (1970s-2000s) North Atlantic warming and eastern tropical Pacific cooling might presage an ongoing transition to a cold North Atlantic phase with possible implications for near-term global temperature evolution.


The North Atlantic Is Much Colder Now Than When CO2 Levels Were Much Lower
Because it is important to consider context, it should be pointed out that the 1995-2005 warming that occurred in the North Atlantic was not only well within the range of AMOC-driven natural variability, the relative warmth in that decade was still comparatively cold when considering the long-term temperatures for the North Atlantic region.  In fact, scientists have recently determined that the modern temperatures for the North Atlantic are still among the coldest of the last several thousand years — even the last few hundred.
The conspicuous lack of a net warming trend is significant because it is often claimed that anthropogenic CO2 emissions are the predominant cause of warming global ocean waters.  But there is no correlation between net ocean heat or surface temperature changes in the North Atlantic and the dramatic rise in anthropogenic CO2 emissions since the 1950s.  Or since the 1850s.   Or since Medieval times.  Or since the Holocene began.
The Last 165 Years…
de Jong and de Steur, 2016

The Last 1,200 Years…
Rosenthal et al., 2017

The Last 10,000 Years….
Mark, 2016


The Ultimate Cause Of Oceanic Temperature Shifts, Climate Change: Solar Variability
In their Nature paper entitled “Solar forcing of North Atlantic surface temperature and salinity over the past millennium”, Moffa-Sánchez et al. (2014) point out that North Atlantic sea surface temperatures have risen and fallen by as much as 3.5°C within only multi-decadal- to century-long time periods several times during the last millennium.  This magnitude and rapidity of oceanic change — which occurred without any significant changes in atmospheric CO2 — is obviously far more pronounced than the tenths-of-a-degree net change (if that) over the last 100 years in the North Atlantic.  It is also wholly inconsistent with the climate modeled presumption that natural variability in ocean temperatures is so small, and the anthropogenic forcing of recent decades is so dominant, that natural variability can be clearly separated from anthropogenic forcing.
Our results reveal abrupt multidecadal to centennial shifts in the temperature and salinity of the NAC [North Atlantic Current] waters of ∼3.5 °C and ∼1.2 °C, respectively, during the past millennium.   
Indeed, the massive increase in anthropogenic CO2 emissions since 1950 have occurred during the same period of time that the North Atlantic has undergone essentially zero net temperature changes (as the papers and graphs above illustrate), strongly suggesting that anthropogenic CO2 climate forcing has exerted little to no influence on North Atlantic water temperatures.  This would also effectively rule out a significant anthropogenic influence on hemispheric- and even global-scale climate changes considering the North Atlantic’s seminal role as a climatic pace-setter.
Not only that, but as Smeed et al. (2014) affirm, the abrupt change (reduction) in the AMOC heat transport since the mid-2000s is far more pronounced in magnitude (ten times greater) and rapid than climate models have projected to accrue due to anthropogenic forcing, which also strongly suggests the AMOC (and oceanic heat transport in general) is not modulated by CO2 emissions.
Smeed et al, 2014       Model simulations predict a decrease of the AMOC in the 21st century in response to increasing greenhouse gases of the order of one half a Sverdrup per decade (IPCC, 2007). Our observations indicate that the actual change over the last decade is much greater. The magnitude of the observed changes suggests that they are a part of a cyclical change rather than being directly linked to the projected anthropogenic AMOC decrease.  … We have shown that there was a slowdown in the AMOC transport between 2004 and 2012 amounting to an average of −0.54 Sv yr−1 (95 % c.i. −0.08 to −0.99 Sv yr−1 ) at 26◦ N, and that this was primarily due to a strengthening of the southward flow in the upper 1100 m and a reduction of the southward transport of NADW below 3000 m. This trend is an order of magnitude larger than that predicted by climate models associated with global climate change scenarios, suggesting that this decrease represents decadal variability in the AMOC system rather than a response to climate change.
So if anthropogenic CO2 emissions are not the North Atlantic’s climate control knob, what mechanism does modulate the AMOC, which, in turn, leads to abrupt multi-decadal- to centennial-scale warming and cooling periods?   Returning to Moffa-Sánchez et al. (2014), we find that there has been a robust correlation between the undulations in the AMOC and the variability in solar irradiance for the last 1,000 years.
Moffa-Sánchez et al., 2014       There were several centennial-scale fluctuations in the climate and oceanography of the North Atlantic region over the past 1,000 years, including a period of relative cooling from about AD 1450 to 1850 known as the Little Ice Age. These variations may be linked to changes in solar irradiance, amplified through feedbacks including the Atlantic meridional overturning circulation. … The reconstructed centennial-scale variations in hydrography correlate with variability in total solar irradiance. We find a similar correlation in a simulation of climate over the past 1,000 years. [L]ow solar irradiance promotes the development of frequent and persistent atmospheric blocking events, in which a quasi-stationary high-pressure system in the eastern North Atlantic modifies the flow of the westerly winds. … Our results reveal abrupt multidecadal to centennial shifts in the temperature and salinity of the NAC [North Atlantic Current] waters of ∼3.5 °C and ∼1.2 °C, respectively, during the past millennium. The magnitude of the hydrographic variability is substantial and comparable to that recorded in a lower resolution record spanning the present interglacial from a nearby site, which highlights the similarities in the ocean variability on a diverse range of timescales. The timing of the hydrographic shifts shows a strong correlation with total solar irradiance (TSI) variability. Periods of solar minima (maxima) generally correspond to cold and fresh (warm and salty) conditions in the NAC.
Recently published scientific papers have documented that the Modern Grand Maximum of very high solar activity ended in the early 21st century, and this has, in turn, led to many predictions of global-scale cooling in the coming decades (Abdussamatov, 2016, Torres and Guzmán, 2016, Yndestad and Solheim, 2016, Mörner, 2015, Evans, 2016).   The recently observed trends in the North Atlantic ostensibly support these projections of near-term solar- and AMOC-forced multi-decadal cooling, as they are in phase with the dramatic decline in North Atlantic heat content and surface temperatures since the mid-2000s documented above.   If historical trends repeat, and if the North Atlantic continues to act as a harbinger of what is to come climatically, we may be on the cusp of cold period reminiscent of yet another Little Ice Age – the 19th in the last 7,500 years.
For the sake of humanity and the rest of the biosphere, let’s hope these near-term global cooling projections are inaccurate, as warmth is much preferred to cooling.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWild market prices
Firstly, wind energy protest organization vernunftkraft.de posted a chart showing the sheer absurdity of relying on the haphazard electricity supply that wind and solar energies are.
Last Sunday Germany saw windy and sunny conditions, meaning the country’s installed wind and solar systems were running at high capacity. This however led to excess power flooding into the German grid, and thus a plummet in exchange electricity prices.

Market exchange price of electricity on the EEX Leipzig exchange. On April 30 and May 1st 2017, wholesale prices went deeply negative. Source: EEX Marktdaten Strom, by Rolf Schuster. www.vernunftkraft.de/uploads/Ahlborn.pdf
The chart above shows that electricity was in fact sold at negative prices, dipping to an astonishing low of almost 75 euros per megawatt hour.
Unfortunately the money to pay people to “buy” the electricity never gets paid to the consumer. Rather it gets paid mostly to foreign wholesalers. Yet, the German grid operator needs to recoup the money it paid to have the wholesalers to accept the power. In the end, the domestic consumers in Germany wind up with the bill.
How much did the negative prices seen over the past weekend end up costing the German consumers? One reader calculated it and came up with the figure of over 41 million euros! And because May 1st was a national holiday, the demand for German power was low, and there was no use for all the extra power flooding into the grid. It’s like cooking dinner – after everyone has already eaten. And because there is no fridge, the garbage man has to be called and paid to dispose of it. So far electricity cannot be stored on a meaningful scale.
Wild supply variability
Continuing on the folly of Germany’s renewable energy, engineering expert Dr. Detlef Ahlborn authored a post at the European Institute for Climate and Energy (EIKE), declaring the transition to renewable energies a failure and that it will remain so as long as a solution for storing the energy is not found.
Again the huge problem is the extremely erratic, uncontrolled supply of the power, as the following German wind energy supply chart clearly illustrates:

Figure 3: Wind power production Germany from 2011 to 2016. Installed rated capacity rose from about 27 GW to about 48 GW. However the power that was actually produced (dark blue) is in fact often only a tiny fraction. Overall, Germany’s demand hovers about 70 GW. Source: Rolf Schuster, data from EEX Leipzig.
More variable then rolling a die


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Dr. Ahlborn describes the extreme variability of wind power in Germany as follows:

The variability of German wind power production is about 70% greater than the numbers you’d see rolling a die. If German power providers ran their plants like throwing a die, the power would flow more uniformly. [1]”

Of course wind energy proponents like to say that the solution is a European-wide integrated network where if the wind is not blowing in one region, then excess power in another region can fill in the gap. After all, “the wind is always blowing somewhere in Europe” they like to say. However, the following chart plainly illustrates that this is far more a fallacy than a truth.

Wind production by the 15 European countries (dark blue) and by Germany (light blue). Chart by Rolf Schuster 
Very often when there’s plenty of wind in Germany (or very little), the case is the same in the rest of Europe. With that kind of supply, good luck trying to balance any grid that is overly dependent on wind energy.
Ahlborn writes that combining the power grids to form one large one only serves to add up the variability and not reduce it.
“Unworthy” for Germany
Summarizing Ahlborn calls the total result of wind energy so far “bitter”:
This Energiewende [transition to renewables] is unworthy for a country with such a tradition in science and technology. We could have known if we had just given it a bit of thought. But who wanted to know?
We’ll find out at the latest when we start looking for those who are responsible for this debacle, and policymakers attempt to run from taking responsibility for this disaster. Our former economics minister has already taken the first step.”
To that, EIKE added: It can only be hoped that the former economics minister (Sigmar Gabriel) will cause less damage in his new position as foreign minister.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterPhysicist Dr. Peter Heller wrote at the German language Science Skeptical here how the election of Donald Trump could mean “the return to reason in climate policy” and that there may be a course change: “one away from trying to do what’s good for the climate, to one that does what is good for man.”

Physicist Dr. Peter Heller. Photo: FDP
He writes:
This is neither dangerous nor unscientific – rather it is optimistic. It holds the promise for a better future that offers more than just the energy savings variant of the present.”
Heller views both opposite extreme positions taken by the radical elements on either side of the debate as irreconcilable and are in fact “nonsense that have more to to do with belief than with science.”
Heller then adds that if the climate alarmists had their way, they “would not only destroy our current prosperity, but also rob mankind of all options to further prosper in the future.”
Today Heller sees hope for a return to reason in climate policy given the “current developments“. One reason for hope he cites is the recently watered down Climate Plan 2050 submitted by the German government at the recent Climate Conference in Morocco. Ultimately Germany was not ready to deindustrialize after all. Heller believes:
Thirty years of climate diplomacy where tens of thousands of taxpayer-funded politicians, bureaucrats and scientists jetted to large conferences and congresses at attractive touristic locations were useless. […] After the election Donald Trump to President of the United States, the gate for better policy has finally opened endlessly wide.”
In his analysis Heller of course agrees that man has an impact on climate and that the greenhouse effect is real, but that this does not necessarily mean climate change is climate catastrophe. He thinks climate sensitivity is closer to 1°C per doubling of CO2. He calls the claims that climate is only worsening “pure speculation” and the claim that man-made climate change is taking us to a climate catastrophe is based on “numerous assumptions“.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Heller also thinks that human ingenuity with respect to adapting to new conditions is being hugely underestimated, reminding readers that humans have adapted to and mastered every climate zone on the planet.
Even in regions where there are frequent drought periods, powerful storms or flooding, man did not retreat. His ingenuity overcame all obstacles. The temperature range within which civilization spread went far beyond the range of 2°C.”
As part of this adaptation, Heller calls fossil energies “a moral necessity” because we use them to generate our prosperity and to produce products of every type that benefit our lives.
In many applications they are indispensable and some are not so easily replaceable, as the 2°C target demands. In summary their advantages substantially outweigh their disadvantages. […] Fossil fuels not freed humanity from feudal exploitation and slavery because they provide an efficient and effective supply through machines, they have foremost enabled us to refrain from consuming biomass as a form of energy and thus prevented the destruction of the environment. In the 18th century when charcoal was substituted by coke in iron smelting, forests once again were able to expand.”
Heller sees Donald Trump as a “new start”, someone who will expand the production of fossil fuels and end the climate protection policy of Obama, and thus with it usher in a series of economic, social and political advantages.
This could introduce the end of international climate diplomacy in its current form, as countries like Russia, China or India are also poised for a reorientation.”
The German physicist calls the howls and gnashing of teeth now taking place within the German mainstream media “over-the-top and wrong”.
He summarizes:
From the very beginning it was a fundamental mistake by climate policy to allow political activists from climate research to have the say. Donald Trump’s program puts the setting of guidelines where it really belongs: in a policymaking that that does not focus on the welfare of the climate, but rather on the welfare on mankind. Climate protection through decarbonization does not offer anything to anyone. In the end even its proponents are left with nothing except a good feeling.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA Growing Volume Of Evidence
Undercuts ‘Consensus’ Science


During the first 6 months of 2017, 285 scientific papers have already been published that cast doubt on the position that anthropogenic CO2 emissions function as the climate’s fundamental control knob…or that otherwise question the efficacy of climate models or the related “consensus” positions commonly endorsed by policymakers and mainstream media.
These 285 new papers support the position that there are significant limitations and uncertainties inherent in our understanding of climate and climate changes.  Climate science is not settled.
Modern temperatures, sea levels, and extreme weather events are neither unusual nor unprecedented.  Many regions of the Earth are cooler now than they have been for most of the last 10,000 years.
Natural factors such as the Sun (84 papers), multi-decadal oceanic-atmospheric oscillations such as the NAO, AMO/PDO, ENSO (31 papers), decadal-scale cloud cover variations, and internal variability in general have exerted a significant influence on weather and climate changes during both the past and present.  Detecting a clear anthropogenic forcing signal amidst the noise of unforced natural variability may therefore be difficult.
And current emissions-mitigation policies, especially related to the advocacy for renewables, are often costly, ineffective, and perhaps even harmful to the environment.  On the other hand, elevated CO2 and a warmer climate provide unheralded benefits to the biosphere (i.e., a greener planet and enhanced crop yields).
It should be noted that the rate of inclusion on this year’s “Skeptic Papers” list at the halfway point is slightly ahead of last year’s pace.  That’s because in 2016 there were 500 peer-reviewed scientific papers published in scholarly journals (Part 1, Part 2, Part 3) challenging “consensus” climate science.
Below are the two links to the list of 285 papers as well as the guideline for the lists’ categorization.
Skeptic Papers 2017 (1)
Skeptic Papers 2017 (2)

(Parts 1 and 2 are on the same page).  
Part 1. Natural Mechanisms Of Weather, Climate Change  
Solar Influence On Climate (84)
 ENSO, NAO, AMO, PDO Climate Influence (31)
 Modern Climate In Phase With Natural Variability (10)
 Cloud/Aerosol Climate Influence (5)
 Volcanic/Tectonic Climate Influence (2)
The Theoretical Greenhouse Effect As Climate Driver (4)
Part 2. Unsettled Science, Failed Climate Modeling
Climate Model Unreliability/Biases/Errors and the Pause (19)
Failing Renewable Energy, Climate Policies (8)
Wind Power Harming The Environment, Biosphere (4)
Elevated CO2 Greens Planet, Produces Higher Crop Yields (4)
Warming Beneficial, Does Not Harm Humans, Wildlife (3)
Warming, Acidification Not Harming Oceanic Biosphere (3)
Decreases In Extreme, Unstable Weather With Warming (3)
No Increasing Trends In Intense Hurricanes (3)
No Increasing Trends In Drought/Flood Frequency, Severity (2)
Natural CO2, Methane Sources Out-Emit Human Source (4)
Miscellaneous (8)
Part 3. Natural Climate Change Observation, Reconstruction
Lack Of Anthropogenic/CO2 Signal In Sea Level Rise (22)
No Net Warming During 20th (21st) Century (11)
A Warmer Past: Non-Hockey Stick Reconstructions (33)
Abrupt, Degrees-Per-Decade Natural Global Warming (4)
A Model-Defying Cryosphere, Polar Ice (18)
Recent Cooling In The North Atlantic (1)
Share this...FacebookTwitter "
"
Share this...FacebookTwitterLast Wednesday evening, Florida State University graduate student Levi Cowan showed at his Tropical Tidbits site his analysis of what was later to develop into tropical storm Nate in the Gulf of Mexico.
His analysis exposed the great differences – thus huge uncertainty – between the US GFS and the European ECMWF models for the early projected tracks of Nate.
Levi shows the two different model projections below:

In the above figure, the NOAA’s GFS model run takes the storm track over Louisiana (left) while the European showed landfall occurring some 400 miles away to the east at the start of the Florida panhandle (right). If that doesn’t illustrate the huge uncertainty within models, then what does? Source: Image cropped from Tropical Tidbits.
Keep in mind that these two projections for Nate coming from two different models are for just 4 days out, despite being generated by super computers that have been fed with reams of data.
In Levi’s latest analysis here, he shows that the latest storm track now favors the GFS and that the European had been flawed.
Great uncertainty even with forecasts just hours ahead


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Meanwhile on Thursday storm Xavier passed through Northern Germany. Mid morning on Thursday the German DWD national weather service tweeted here how the forecast track of the storm over northern Germany over the coming 6 hours was still uncertain!

In the chart above the low pressure system Xavier designated by “T” was centered just over the North Sea just west of Hamburg and moving eastward. The DWD chart above shows the uncertainty of the storm’s projected path with a range of some 150 km upon reaching the Polish border just hours later. Models cannot even predict storm location even 6 hours in advance!
Too much emphasis on models?
Surely meteorologists will be the first to admit that the complexity of storm systems is still far too great to allow predictions of any reliable certainty.
In a recent daily summary at Weatherbell Analytics, veteran meteorologist Joe Bastardi even cautioned against relying too heavily on models, which he said sometimes flip flop between scenarios in just 6 hours. Bastardi feels there has to be greater emphasis on patterns observed over the decades. Already two weeks earlier on September 22 Bastardi warned of a Gulf storm developing between October 1 and October 10. He was right. His forecast was based on patterns, and made long before models sniffed out the storm. Models indeed still have a very long way to go.
If a 6-hour projection is uncertain, then projections out 20 years are worthless
This gives us an idea of what to expect of climate models going out 20, 50 or even 100 years in the future, which woefully lack long-term historical data from major climate drivers such as the oceans, continents, sun and atmosphere. Little wonder that IPCC climate model temperature projections made 10 years ago are already wrong.
But if you happen to be someone who is still sold on the projections made by these climate models, then I’ve got a great deal on a bridge in Brooklyn for you.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterI’ve written on a couple of occasions about how some in the German government are demanding that Germany start banning the internal combustion engine already by 2030 and switch to electric cars — a radical proposal to say the least.
Some two weeks ago the online FOCUS magazine commented on this here, writing, however, that “the electric car is an economic disaster” and that some experts believe that the “German automotive industry has no chance to survive“.
It needs to be mentioned that the German auto industry is the backbone of the German economy, as it is directly and indirectly responsible for 1 of every 5 jobs. This makes it the logical place to begin for any anyone harboring a desire to destroy the German industrial base.
FOCUS quotes future expert Stephan Rammler:
Replacing 40 million internal combustion engine cars with 40 million electric cars makes no sense. As long as we have no closed loop economy, the electrification and digitalization will lead to an economic disaster.”
Rammler then goes on to predict that the German auto industry would never survive such a transformation because the competition in Asia is already able to make products that are just as good, citing Borgward or Lynk & Co., who are already planning to sell in Germany.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to auto industry expert Professor Ferdinand Dudenhöffer, 250,000 German jobs of a total of 800,000 directly in the auto industry are at risk, especially jobs with mid-size automotive suppliers.
In a video posted by FOCUS here, Sebastian Viehmann explains that the lost jobs would result from the simplification of the cars. For example an internal combustion engine has some 1200 parts, while an electric motor has only 17. Suppliers for the individual parts and assemblies would no longer be needed. Also electric cars would become such a simple product that they could be snapped up at a supermarket in the same way a shopper buys a toaster. Automotive dealerships and repair shops would become redundant.
When looking at self-driving, autonomous cars, the insurance industry would also end up losing lots of business. In the event of an accident, the manufacturer would be liable, and not the driver. Many drivers would likely welcome that.
A lot of these changes of course can be viewed as advantages for the consumers, and highly skilled workers would be freed up to focus on other technical challenges and development.
But there are still the questions surrounding range and batteries, and the environmental impacts the manufacture and disposal of the batteries would have. Moreover, does it make sense to rush in a panic into a technology that is still a long way from being feasible? Perhaps a gradual, flexible transition over 50 – 75 years would make more sense.
Furthermore, internal combustion engines have made great strides when it comes to efficiency and cleanliness. In some categories they offer huge advantages.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterPermainan Poker Online sama saja seperti permainan Poker Online. Bedanya cuma di permainan Poker online,kalian mampu jadi bandar dgn syarat duit taruhan kalian mencukupi,contohnya di dalam meja 1000 – 5000 kalian mesti mempunyai modular jumlahnya 10x lipat dari wager most extreme meja taruhan 50.000 utk sanggup jadi bandar.
system jadi bandar di taruhan judi online poker online adalah system keliling. menjadi pemain manapun yg mempunyai duit jumlahnya 10x lipat dari nilai meja bisa jadi bandar. 
panduan & kiat main POKER ONLINE paling baru 
Permainan Poker Online nyaris seluruh peraturan permainan nya sama. yg membedakan yaitu system jadi bandar. Di dalam permainan Poker Online tiap-tiap pemain yg telah memenuhi syarat jadi bandar yg telah disebutkan di atas mempunyai( modular 10x lipat dari wager most extreme meja) sehingga dapat berwenang jadi bandar & sistemnya bakal bergantian maupun berputar se arah jarum jam. seandainya di permainan Bandar Poker Online,bandar tak mampu digantikan tidak cuma bandar berdiri & di duduki orang lain. 
apabila kalian tetap kurang paham dgn trik main Poker Online, kalian bisa baca di arahan Poker Online. Kami anggap kalian telah membaca & mengerti trick main-main Poker Online, sehingga kita serta-merta saja ke inti dari artikel ini ialah kiat gampang Menang main Poker Online sbg berikut : 
Sebelum kalian main-main, coba buat memperhatikan permainan itu lalu. tonton bandar & pemain,jika bandar memiliki nilai tinggi (7 – 9) dengan cara 3x berturut – turut sehingga kalian masuk ke dalam permainan & pasang taruhan max wager. Insignificant kemenangan yg telah kami mencoba hingga dgn 75%. 
apabila kalian mau main-main jadi bandar,kalian jangan sampai lupa utk mempunyai modular yg tidak sedikit & pintar menyimpan taruhan kepada kala kalian jadi pemain. jikalau kalian mempunyai modular yg tidak sedikit janganlah sempat takut utk kalah di dalam permainan poker online lantaran, kekalahan bandar cuma 20% saja seandainya( mempunyai bekal yg tidak sedikit) dikala kalian sedang jadi pemain,kalian sanggup memasang insignificant wager saja. 
KEBERUNTUNGAN main-main POKER ONLINE 
utk bisa mengetahui peruntungan kalian,hal ini wajib kalian jalankan sebelum kalian bermain,cobalah main di meja mungil dulu,lihat peruntungan kalian di sana. bila card kalian keren tetap menerus maupun card kalian rendah namun konsisten menang. aspek itu telah amat pass buat bisa membuktikan kalian sedang ada angin (Hoki) sehingga kalian segera saja berganti meja yg agung & capai keuntungan yg amat tidak sedikit. namun jikalau kalian mengalami kekalahan konsisten menerus telah amat bisa dijamin kalian sedang tak ada hoki menjadi lebih baik kalian berakhir main & mencoba kepada ke esokan harinya. 
dgn kiat berpindah lokasi duduk maupun meja permainan,trik ini yaitu salah satu kiat gampang Menang main Poker Online. seandainya kalian mengalami kekalahan 5x berturut – turut saja,cobalah utk berpindah ruangan duduk atau meja dalam permainan. jikalau kalian tetap terus kalah sehingga seperti pembahasan no 3 tadi,cobalah ke esokan harinya. 
cara enteng Menang main Poker Online yg kami memberi ini merupakan dari pengalaman kami sendiri. Kalian mampu membuktikannya sendiri dgn memakai kiat ini & rasakan sendiri apa yg di sanggup dari cara ini. seandainya kalian telah coba trick ini & tak berhasil,itu mampu lantaran website agen Poker Online yg kalian sukai. Buktinya kami & sohib – sahabat kami telah membuktikan sendiri cara ini
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAccording to the most highly-cited estimate of recent (1992 – 2011) polar ice sheet melt rates, the land ice on Greenland and Antarctica has been contributing to sea level rise at a rate of 0.59 mm/year in the modern era, which means the equivalent of 5.9 centimeters (2.3 inches) per century of sea level rise might eventually accrue if the polar ice sheets continue melting at current rates for the next 10 decades.
Shepherd et al., 2012

Since 1992 [through 2011], the polar ice sheets [Antarctica and Greenland] have contributed, on average, 0.59 ± 0.20 millimeter year−1 to the rate of global sea-level rise.

Of course, a sea level rise rate contribution from Greenland and Antarctica that amounts to a little more than 2 inches per century is not particularly alarming.  And when observed sea level rise contribution rates from melting ice sheets don’t elicit the headlining attention they deserve, it’s time to promulgate climate modeling catastrophes that might occur at some point in the distant future.
For example, earlier this year Slate‘s resident meteorologist Eric Holthaus excitedly embraced the James Hansen ice-melt catastrophe paper (Hansen et al., 2016) as a welcome tenet of a supposedly authoritative scientific canon: “James Hansen’s Bombshell Warning Is Now Part of the Scientific Canon”.
The paper, which has undergone some wording revisions since the original version appeared in July, 2015, apparently “concludes” that the polar ice sheets will soon melt catastrophically, and that this ice sheet melt contribution will in turn result in sea level rise of “at least 10 feet in as little as 50 years“.
Eric Holthaus, Slate:

“The study—written by James Hansen, NASA’s former lead climate scientist, and 16 co-authors, many of whom are ered among the top in their fields—concludes that glaciers in Greenland and Antarctica will melt 10 times faster than previous consensus estimates, resulting in sea level rise of at least 10 feet in as little as 50 years.“

Again, the combined Greenland and Antarctica ice sheet melt contribution to sea level rise was 0.59 mm/year during 1992 – 2011 (Shepherd et al., 2012), or about 6 cm (2.3 inches) per century.  To achieve James Hansen’s claimed sea level rise prediction of 10 feet (3.05 meters) within 50 years due to rapidly melting Greenland and Antarctica ice sheets, the current melt rates would have to increase by a factor of 100.  Instead of the polar ice sheet contribution rate of 0.23 of an inch per decade for 1992-2011, the rate in the next 50 years will need to average 23 inches per decade — two orders of magnitude more than presently observed.
And for the record, the observed melt-rate contribution from the Greenland and Antarctic ice sheets of 0.59 mm/yr for 1992 – 2011 is very likely an overestimate.  For one, NASA has reported that there was an overall ice mass gain for Antarctica during this same period (1992-2008), and thus a reduction in sea level rise equivalent to -0.23 mm/yr (rather than a net positive contribution of +0.19 mm/yr as determined by Shepherd et al., 2011).  Secondly, in current datasets the baseline period for establishing the surface mass balance (SMB) of the Greenland ice sheet is the 1961-1990 tricade.  However, those 30 years were notoriously cold in Greenland, a full 1.5 degrees C colder than the 1920-1940s period, when Greenland was actually as warm or warmer than recent decades.  If the baseline data were not centered on the coldest decades of the century, but instead included the 1920s-1940s warm period, the record of net “loss” for the Greenland ice sheet since the 1990s would be significantly reduced, and there may have been an overall net mass gain relative to the 1920s-’40s for recent decades.  Succinctly, different baseline data would yield an even more negligible Greenland ice sheet contribution to sea level rise for 1992-2011 than reported by Shepherd et al., 2011 (0.4 mm/yr, or 1.6 inches per century).
Considering Paleoclimate Data, Sea Level Rise Projections Of Even 1 Meter Per Century Are ‘Sheer Nonsense’, ‘Demagoguery’
World-renown scientist Dr. Nils-Axel Mörner, a sea level expert who has authored hundreds of peer-reviewed scientific publication during his career, has recently weighed in on the preposterousness of claiming sea levels will rise even 1 meter in the next 100 years — let alone over 3 meters in the next 50, as James Hansen claims.  Using past records of sea level rise rates from the earliest decades and centuries of the Holocene (~11,000 years ago), Mörner concludes that it is not possible for modern sea levels to rise at rates of 10 mm/year (1 meter/century) — or faster than they did during a time when much of the Northern Hemisphere was still buried kilometers-deep in ice and temperatures were rising far more rapidly than today.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Mörner,  2016

Sea level is globally varying between ±0.0 and +1.0 mm/yr (0.5 ± 0.5 mm/yr). … At 11,000 BP we had enormous amounts of ice still left in the huge continental ice caps of the Last Ice Age. In Canada, the ice front was in St. Lawrence lowland, and in Scandinavia, the ice margin was at Stockholm. At the warming pulse ending the Pleistocene and starting the Holocene, ice melted at an exceptionally strong forcing. Today, there is neither ice nor climate forcing that in any way can be compared to what happened 11,000 – 10,000 BP. The conclusion is obvious; we can never in present time have any ice melting and sea level rise as strong- and certainly not stronger-than that occurring at the Pleistocene/Holocene transition. Therefore, a rate of sea level rise of +10.0 mm/yr or 1.0 m per century can be held as the absolutely ultimate value of any present day sea level rise. Any present rise in sea level must be far below this value to be realistic in view of past records and the physical factors controlling ice melting. Therefore, we can also dismiss any claim of sea level rise exceeding 1 m in the next century as sheer nonsense and unfounded demagoguery.


Sea Levels Currently Rising Between 0 – 1 mm/yr; Modeled ‘Corrections’ To Sea Level Rise Data Artificially And Erroneously Raise Rates
A year ago, Dr. Mörner detailed his comprehensive critique of the alterations to observed data (euphemistically referred to as “corrections”).  He determined that if the “corrections” (i.e., modeled adjustments that artificially raise sea levels) for the satellite data are removed, sea levels only rose at a rate of 0.45 mm/year (2 inches per century) between 1992-2015, which is about 1/7th of the rate of rise reported by altimetry datasets.
Mörner,  2015

The satellite altimetry records are claimed to be “a proxy for ocean water volume changes”, but behind the curves are unspecified “corrections” hidden, applied by NOAA and CU in order to obtain the product they personally assumed to be the correct “proxy of ocean water volume changes”. There is a major problem, however: their satellite altimetry records differ by 100% to 800% from observed tide gauge measurements. With the removal of GIA corrections … from the satellite altimetry data, we finally obtain agreements among global tide gauge data, costal morphology data and satellite altimetry data; all agreeing on a mean global eustatic sea level factor somewhere within the zone ±0.0 to +1.0 mm/yr.
The mean of 182 sites (excluding a few outliers) scattered all over the globe is 1.6 mm/ yr. Because of long-term subsidence of many river mouth sites and site-specific compaction problems, this value may, in fact, represent a slightly too high value. The key sites here discussed provide values of about 0.0 mm/yr, and the Kattegatt and North Sea records give firm values around 1.0 ± 0.1 mm/yr. This data set is in deep conflict with the high rates proposed by the IPCC and satellite altimetry. The differences in rates can only be understood in terms of errors and mistakes. The true mean global eustatic component is likely to be found in the zone ranging from +2.0 mm/yr to ±0.0 mm/yr, and most probably in the lower half of this zone; i.e. within 1.0 – 0.0 mm/yr. The error was found to be in the satellite altimetry values for reasons of incorrect “corrections”
The only data set which hangs far above the others is the IPCC predictions. Those data, however, refer to assumptions and model out-puts, and are, by no means, anchored in observational facts. … [I]t is high time to abandon the idea of global isostatic adjustment, and to stop all kinds of GIA corrections of records of sea level changes (i.e. satellite altimetry, GRACE, tide gauges, etc.).


The reported rates exceeding 3 mm/year are based on models instead of direct observational measurements.  Echoing a 2015 paper from Beenstock et al., two more new papers (another by Mörner) indicate that observations (i.e., non-modeled, non-adjusted measurements from tide gauges from all over the world) of global sea level rise range somewhere between 0 and 1 mm/yr, or a few inches per century.
Beenstock et al., 2015

Using recently developed methods for nonstationary time series, we find that sea levels rose in 7 % of tide gauge locations and fell in 4 %. The global mean increase is 0.39–1.03 mm/year.

Mörner,  2016

Observational facts recorded and controllable in the field tell a quite different story of actual sea-level rise than the ones based on model simulations, especially all those who try to endorse a preconceived scenario of disastrous flooding to come. “Poster sites” like Tuvalu, Vanuatu, and Kiribati in the Pacific have tide gauge stations indicating stable sea-level conditions over the last 20–30 years. The Maldives, Goa, Bangladesh, and several additional sites in the Indian Ocean provide firm field evidence of stable sea-level conditions over the last 40–50 years. Northeast Europe provides excellent opportunities to test regional eustasy, now firmly being set at +1.0 ± 0.1 mm/year. Other test areas like Venice, Guyana–Surinam, Qatar, and Perth provide a eustatic factor of ±0.0 mm/year. We now have a congruent picture of actual global sea-level changes, i.e., between ±0.0 to +1.0 mm/year. This implies little or no threat for future sea-level problems.

Parker and Ollier, 2016

Tide gauges provide the most reliable measurements, and best data to assess the rate of change. We show as the naïve averaging of all the tide gauges included in the PSMSL surveys show “relative” rates of rise about +1.04 mm/year (570 tide gauges of any length). If we consider only 100 tide gauges with more than 80 years of recording the rise is only +0.25 mm/year. This naïve averaging has been stable and shows that the sea levels are slowly rising but not accelerating. …The satellite altimetry returns a noisy signal so that a +3.2 mm/year trend is only achieved by arbitrary “corrections”.
We conclude that if the sea levels are only oscillating about constant trends everywhere as suggested by the tide gauges, then the effects of climate change are negligible, and the local patterns may be used for local coastal planning without any need of purely speculative global trends based on emission scenarios.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman physicists: “CO2 plays only minor role for global climate”
In a just published study in The Open Atmospheric Science Journal here, German scientists Horst-Joachim Lüdecke and Carl-Otto Weiss have used a large number of temperature proxies worldwide to construct a global temperature mean over the last 2000 years, dubbed G7, in order to find out more about the sun’s role on climate change.
Their results drop a huge surprise on the laps of scientists who have long believed the earth is warming due to human-emitted CO2.
The analysis by the German scientists shows the strongest climate cycle components as 1000, 460, and 190-year periods. The G7 global temperature extrema coincide with the Roman, Medieval, and present optima, as well as the well-known minimum of AD 1450 during the Little Ice Age.
Correlation 0.84
Using further complex analyses, they constructed a representation of G7, which shows a remarkable Pearson correlation of 0.84 with the 31-year running average of G7.
The authors used extensive local temperature proxy data [2 – 6] together with Britain’s Hadley CRU temperature records since 1870 and the recent satellite measurements, and combined them to make up the global temperature time series G7 for the last 2000 years.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In accordance to the definition of climate, the blue curve in the paper’s Fig. 3, shown above, depicts the climate history as the 30-year running average of the grey curve. Noteworthy, the historically known temperature extrema are well reproduced by the blue climate curve: The Roman Optimum (~0 AD), the Medieval Optimum (~1000 AD), the Present Optimum, as well as the Little Ice Age (~1500 AD),
Also the pronounced minimum of 1450 AD, when the vines in southern France were killed by cold. Also clearly shown by the climate curve is the warming from 1850 to 1995.
The detailed analysis of the local records show in general a multitude of peaks, the authors say, and the G7 however shows only 3 dominant peaks, which correspond to cycles known from local studies, of approx. 1000, 500, 200-year periods. The combination of local records to a global record apparently averages out local cycles and emphasizes global cycles.
The sum of these three dominant cycles (red curve in Fig. 3) reproduces the measured climate (blue curve in Fig. 3) with a remarkable correlation of 0.84.
In particular the sum of the three cycles shows the temperature increase from 1850 to 1995 as a result of the three natural cycles, the German researchers say, adding: “Thus one can conclude that CO2 plays only a minor role (if any) for the global climate.”
Lüdecke and Weiss note that the present maximum of the cycle sum corresponds well with the world temperature stagnation since 1995 AD, the stagnation unexplained by current climate models. As the dominant cycles have persisted for an extended time, one can assume that they will persist for the near future. They write: “This allows to predict cooling until 2070 AD.”
The authors provide the following references:
[1] https://benthamopen.com/FULLTEXT/TOASCJ-11-44
[2] Christiansen and Ljungqvist, Clim Past, 8, 765-786, 2012
[3] Büntgen et al., Science, 331, 578-582, 2011
[4] McKay and Kaufman, Sci Data, 1: 140026, 2014
[5] Villalba et al., Nat Geosci, 5, 793-798, 2012
[6] Petit et al., Nature, 399, 429-436, 1999
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGreenland’s Ice Melt Contribution To 
Sea Level Just 1.5 cm For 1900-2010

As the HadCRUT4 temperature data indicate, there has been no net warming trend in the Arctic for the last 80 years.  In fact, from the early 1940s to the mid-1990s, the Arctic cooled.


HadCRUT Arctic Temperature 1920-2017 (Climate4You)

Due to its Arctic location, Greenland temperatures have likewise followed a similar trend as the rest of the region — warming during the 1920s to 1940s, cooling from the 1940s to 1990s, and then warming (commensurate with the 1930s) since the 1990s.

van As et al., 2016


Climate Alarm Advocates: Arctic Will Contribute 19-25 cm To Sea Levels By 2100

Despite the relatively unremarkable temperature trends in the Arctic in general or Greenland in particular in the last 100 years, the narrative that says man-made CO2 emissions are causing catastrophic Arctic ice melt and consequent sea level rise has gained widespread popularity in media circles.
For example, in yet another alarmist headline from this last week it was claimed that some Arctic glaciers will “disappear completely” in the next 83 years and this “extreme” Arctic ice melt will lead to 19 to 25 centimeters of sea level rise by 2100.


“By the end of this century, as some glaciers disappear completely, the Arctic’s contribution to global sea level rise will reach at least 19 to 25 centimeters, according to the report by the Arctic Council’s Arctic Monitoring Assessment Program (AMAP).”


New Paper Concludes Greenland Contributed Just 1.5 cm To Sea Levels Since 1900

A new scientific paper published in The Cryosphere last week indicates that the Greenland Ice Sheet (GIS) gained mass during much of the 1940s to 2000s period — especially 1961-1990, the common reference period when it was previously assumed the GIS was stable.
In fact, the scientists conclude that the overall GIS melt for the entire 1900-2010 period contributed a negligible 1.5 centimeters (about half an inch) to sea levels during that entire 110-year period.



Fettweis et al ., 2017
“Results from all MAR simulations indicate that the period 1961–1990, commonly chosen as a stable reference period for Greenland SMB [surface mass balance] and ice dynamics, is actually a period of anomalously positive SMB (∼ +40 Gt yr−1 ) compared to 1900–2010. … [T]he ERA-20C forced simulation suggests that SMB [surface mass balance] during the 1920–1930 warm period over Greenland was comparable to the SMB of the 2000s, due to both higher melt and lower precipitation than normal.”
“The period 1961–1990 has been considered as a period when the total mass balance of the Greenland ice sheet was stable (Rignot and Kanagaratnam, 2006) and near zero. However, at the last century scale, all MAR reconstructions suggest that SMB [surface mass balance] was particularly positive during this period [1961-1990] (SMB was most positive from the 1970s to the middle of the 1990s), suggesting that mass gain may well have occurred during this period, in agreement with results from Colgan et al. (2015).”
“Finally, with respect to the 1961–1990 period, the integrated contribution of the GrIS SMB anomalies over 1900–2010 is a sea level rise of about 15 ± 5 mm [1.5 cm], with a null contribution from the 1940s to the 2000s, suggesting that the recent contribution of GrIS to sea level change (van den Broeke et al., 2016) is unprecedented in the last century.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Between 1920-1930, Greenland Warmed By 2 to 4°C In Less Than 10 Years

Chylek et al., 2004
“A significant and rapid temperature increase was observed at all Greenland stations between 1920 and 1930. The average annual temperature rose between 2 and 4 °C in less than ten years. Since the change in anthropogenic production of greenhouses gases at that time was considerably lower than today, this rapid temperature increase suggests a large natural variability of the regional climate.”

Glacier Melt Rapid, Contribution To Sea Level Rise Substantially Higher Before 1950

Gregory et al., 2013


Fernández-Fernández et al., 2017
“The abrupt climatic transition of the early 20th century and the 25-year warm period 1925–1950 triggered the main retreat and volume loss of these glaciers since the end of the ‘Little Ice Age’. Meanwhile, cooling during the 1960s, 1970s and 1980s altered the trend, with advances of the glacier snouts.”
“During the period 1898–1946, the snout of Gljúfurárjökull retreated 635 m, almost two-thirds of the total distance from the LIA maximum (1898–1903) to 2005, at an average rate of 13.2 m yr−1. … The trend in Western Tungnahryggsjökull during the first half of the 20th century was a more rapid retreat, showing the highest average rates of the whole period (19.5 m yr−1). By 1946, this glacier had retreated almost 90% of the total recorded between the LIA maximum (1868) and 2005. … Just as in the glaciers described above, the retreat of the Eastern Tungnahryggsjökull from its LIA position was more intense during the first half of the 20th century, and in 1946 its snout was only 200 m from its current position.”

Conclusion: Abrupt Arctic Warming, Cooling, Ice Melt Uncorrelated With CO2 Emissions

Implicit in the alarmist projection that rapid Arctic warming and ice melt will raise sea levels by 19 to 25 centimeters during the next 8 decades is the assumption that the Arctic’s post-1990s warming trend and ice melt has been driven by anthropogenic CO2 emissions — which are expected to continue to rise without dramatic energy policy changes.  However, this assumption ignores the nearly 100 years (1900 to mid-1990s) of non-correlation between CO2 emissions and the Arctic climate.
Succinctly, during the 1920s to 1940s period the (a)  Arctic warmed rapidly (~3°C per decade), the (b) Greenland ice sheet melted rapidly, and the (c) glacier melt contribution to sea level rise was explosive.  This occurred while anthropogenic CO2 emissions were both flat and negligible (10 times smaller than today’s emissions).
Then, just as CO2 emissions began to rise at an accelerated pace after 1940, the (a) Arctic cooled (for nearly 60 years), the (b) Greenland ice sheet surface mass balance was positive with a “null” contribution to sea level rise (1940-2000), and (c) the Arctic-wide ice melt contribution to sea level rise abruptly decelerated.
For the 110 years between 1900 and 2010, the Greenland ice sheet contributed just 0.6 of an inch (1.5 cm) to sea levels despite a 10-fold increase in anthropogenic CO2 emissions during that period.  Therefore, the very mechanism (human CO2 emissions) assumed to be driving a projected 19 to 25 centimeters of Arctic ice melt contribution has not been observed to be a driving mechanism previously.
The observational evidence indicates that variations in anthropogenic CO2 emissions do not drive Arctic warming (or cooling), ice sheet surface mass balance, or sea level rise from retreating glaciers.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterOceans Warmed 6 Times Faster Than 
Modern Rates During The Mid-Holocene

Annotated graph from Rosenthal et al. (2013) illustrating the steep amplitude of natural variations in ocean heat
It has long been acknowledged by scientists that significant changes in deep ocean heat content have occurred in the past in the absence of changes or forcing from CO2.  Stott et al. (2007), for example, conclude that deep ocean temperatures rose by 2°C within a 2,000-year time span (19,000 to 17,000 years ago) about a 1,000 years before CO2 concentrations (and surface temperatures) began to rise.
Stott et al., 2007

Deep sea temperatures warmed by ~2C between 19 and 17 ka B.P., leading the rise in atmospheric CO2 and tropical surface ocean warming by ~1000 years.

Similarly,  Demezhko and Gornostaeva (2015) found that the heat energy change in the deep oceans during the climate transition from the last ice age to this current interglacial occurred “2-3 thousands of years” before the increases in surface temperature and CO2, and that “the increase of carbon dioxide may be a consequence [rather than a cause] of temperature increasing”.  The authors then acknowledge that this suggests that there was “no significant contribution of CO2 forcing to climatically caused heat flux and thus to the temperature increase during the Pleistocene-Holocene warming”.
Demezhko and Gornostaeva, 2015

Despite the substantial dispersion of CO2 estimations, a character and a chronology of CO2 concentration changes are much closer to temperature changes rather than to heat flux variations. It may mean no significant contribution of CO2 forcing to climatically caused heat flux and thus to the temperature increase during Pleistocene–Holocene warming. About 10 kyr BP the increase of carbon dioxide concentration was replaced by its fall which ended about 8 kyr BP. This local minimum [in CO2 concentration] is not consistent with either GST [ground surface temperature] or SHF [surface heat flux] histories.  … The reconstructed surface heat flux reflects impact of all possible sources of radiative forcing. In addition to solar insolation, greenhouse gases (such as CO2) can be a source of additional forcing. On the other hand the increase of carbon dioxide may be a consequence of temperature increasing. Comparing the chronology of surface flux, temperature and carbon dioxide concentration changes, we can draw some conclusions about the causes of climate change. …  The increase of carbon dioxide concentrations occurred 2–3 thousands of years later than the heat flux increase and synchronously with temperature response. 

Scientists Ellis and Palmer (2016) get right to the point and conclude CO2 plays “little or no” role in forcing the warming during interglacial periods…

Conclusion: [I]nterglacial warming is eccentricity and polar ice regrowth regulated, Great Summer forced, and dust-ice albedo amplified. And the greenhouse-gas attributes of CO2 play little or no part in this complex feedback system.

….while scientists Douglass and Knox (2014) identify the source of modern deep ocean temperature forcing that has an “unquestionably solar origin” manifested by El Niño/La Niña phenomena.

Global ocean temperature time series from the surface to depths of 2000 m since the year 2000 are found to agree in detail with those of other diverse climate indices. It is asserted that these systems are driven by a forcing unquestionably of solar origin that has two manifestations: (1) a direct phase-locked response to what is identified as a solar forcing at a frequency of 1.0 cycle/yr for the whole time series; (2) a second phase-locked response at a period of two years or three years. With these findings it is becoming clear that the entire climate system is responding to the varying incident solar radiation… The most prominent manifestations of the pattern are found in the El Niño/La Niña phenomena.

Advocates of the assumption that CO2 variations are a primary cause of changes in deep ocean heat content (i.e., those who author government-sponsored IPCC reports and activists for the anthropogenic global warming cause) have necessarily believed that past natural variations in deep ocean heat content are very slow and gradual.  They have presumed that the forcing from Milankovitch cycles (changes in solar radiation absorbed by the Earth’s surface due to orbital variations) are the cause of deep ocean changes over time, but that these changes occur only as slowly as orbital variations occur — on millennial scales (“several thousand years“), not in decades to centuries.  In this way, they can deny that the Sun plays a role in modern climate changes…despite burgeoning evidence to the contrary.  The Stott et al. (2007) finding that deep oceans warmed at a rate of 1°C/1,000 years referenced above would be consistent with these assumptions.

New Paper: ‘Rapid variations in deep ocean temperature detected in the Holocene’



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Brown University geologist Samantha Bova and her colleagues reach a different conclusion, however, in a paper just published online for the prestigious journal Geophysical Research Letters.  These scientists have found that, in the absence of any significant CO2 concentration changes or human influence during the Holocene (i.e., the last ~10,000 years), the deep oceans naturally warmed by more than 2°C in a span of just 200 years, which is several times the rate in which they are alleged to have warmed in the last ~60 years of the supposedly dominant anthropogenic influence on climate.  In fact, Bova et al. (2016) conclude that deep ocean temperature changes for the last 200 years are apparently so negligible they are “below the detection limits”.
Bova et al., 2016
The observational record of deep-ocean variability is short, which makes it difficult to attribute the recent rise in deep ocean temperatures to anthropogenic forcing. Here, we test a new proxy – the oxygen isotopic signature of individual benthic foraminifera – to detect rapid (i.e. monthly to decadal) variations in deep ocean temperature and salinity in the sedimentary record. We apply this technique at 1000 m water depth in the Eastern Equatorial Pacific during seven 200-year Holocene intervals. Variability in foraminifer δ18O over the past 200 years is below the detection limit [a change in ocean heat cannot be detected in the past 200 years], but δ18O signatures from two mid-Holocene intervals indicate temperature swings >2 °C within 200 years.
According to the IPCC (2013), 93% of the heat energy in the climate system claimed to be due to anthropogenic global warming is found in the oceans (AR5, Chapter 3).  Levitus et al. (2012) estimate that the heat energy change (converted to temperature) amounted to an increase of just +0.09°C between 1955 and 2010 in the upper 2000 meters of the ocean, or less than one-tenth of one degree over 55 years.
Levitus et al., 2012

The World Ocean accounts for approximately 93% of the warming of the earth system that has occurred since 1955. … The heat content of the World Ocean for the 0–2000 m layer increased by 24.0 ± 1.9 × 1022 J (±2S.E.) [over 1955-2010] corresponding to a rate of 0.39 W m−2 (per unit area of the World Ocean) and a volume mean warming of 0.09°C.

Again, natural variation in ocean temperatures may reach amplitudes of + or – 1°C every 100 years without any external forcing from anthropogenic CO2 emissions.  So if 93% of the change forced by the alleged human climate influence  has only produced a temperature change of hundredths to tenths of a °C in the deep oceans since 1955, or since CO2 concentrations rose by about 75 parts per million (315 ppm in 1955 to 390 ppm in 2010), this would clearly indicate that it is extremely difficult if not effectively impossible to confidently attribute the practically imperceptible change in ocean temperature to anthropogenic CO2 emissions, or to CO2 in general.
More succinctly, if deep ocean temperatures can naturally rise by 1°C in 100 years without any change in CO2, then attributing changes in ocean temperature that are already “below the detection limit” for the last 200 years (or just ~0.1°C since 1955) to anthropogenic CO2 forcing is highly presumptuous at best.
And if 93% of the heat from “global warming” cannot be attributed to humans with any degree of confidence, then there is necessarily no such conceptualization of anthropogenic global warming that could be claimed to have been affirmed scientifically.  Effectively, if we cannot detect an anthropogenic signal in deep ocean heat data, anthropogenic global warming would necessarily be characterized as a belief, not a scientifically confirmed hypothesis.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterTwo recent papers dispelling claims often made by global warming alarmists have been presented by the Die kalte Sonne site. here.
===============================================
No. 1
Insidious preindustrial warm phase: 4000 years ago glaciers in Norway had  almost completely melted away
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
The University of Bergen in Norway reported 14 February 2017 on the climate in Norway 4000 years ago, when in the summertime it was on average two to three degrees warmer than today. Most glaciers in the country at the time had almost completely melted away and gone. Instead of examining these what for many are unexpected warm phases, the team of authors in the press release chose to focus the public’s attention on concern and fear for the future.
And this time – for sure – the glaciers are never coming back again, even though they did so after the last warm phase. Instead the scientists worry about the hydropower business. No glacier, no hydro-power. What follows is the press release:
Norwegian ice cap ‘exceptionally sensitive’ to climate change

How will future climate change affect our glaciers? By looking into the past 4000 years, a new study lead by Henning Åkesson at the Bjerknes Centre finds an ice cap in southern Norway to be ‘exceptionally sensitive’ to climate change.

Hardangerjøkulen is over 300 m thick, but has a flat topography an is vulnerable for rising temperatures. Photo: Atle Nesje, 2015
The team of researchers from the Bjerknes Centre for Climate Research, the Netherlands and the US took a glance into the past to understand how the ice cap Hardangerjøkulen in southern Norway responds to climate change. The authors simulated the history of the ice cap over the last 4000 years, from a period called the mid-Holocene, when summer temperature at high northern latitudes were two to three degrees warmer than today. Most if not all glaciers in Norway melted away during this period, Hardangerjøkulen included. 
Henning Åkesson, a PhD candidate at the Bjerknes Centre and University of Bergen, used a glacier computer model developed at NASA-Jet Propulsion Laboratory and University of California, Irvine to simulate Hardangerjøkulen’s history. To inform model simulations, he used information on past climates and glacier variations from lake sediments receiving meltwater from the ice cap.
Contest between snow and snowmelt
“Present day Hardangerjøkulen is in a very vulnerable state, and our study of its history over the last several thousand years shows that the ice cap may change drastically in response to relatively minor changes in climate conditions”, says Åkesson. Every year, snow covers a glacier in winter, and melts away to a varying extent the following summer. At a certain altitude on the glacier, the competition between snow accumulation and snowmelt is balanced; glaciologists call this the Equilibrium Line Altitude (ELA). “What is special with Hardangerjøkulen and other similar ice caps”, Åkesson explains, “is their flat topography. Anyone skiing up Hardangerjøkulen to celebrate Norway’s national day on May 17th can testify; first it’s steep, but once you’re higher up things get a lot easier.”
A large part of Hardangerjøkulen’s area is close to the present ELA. This means that a small change in the competition between winter snow and summer melt will affect a very large part of the ice cap. Åkesson says “the topography and present climate is such that we soon expect yearly net melt over the entire ice cap. This has already happened a few times in recent years. In the near future we expect this to occur much more often, and with this, the demise of Hardangerjøkulen will accelerate.”  “Today the ice is more than 300 m thick at places, which may sound like a lot. But the implication of our study is that if climate warming continues, this ice cap may disappear before the end of this century. I don’t think most people realize how fast glaciers can change, maybe not even us as scientists,” says Åkesson.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Hydropower from glacier meltwater
“The economic and cultural implications of disappearing glaciers in Norway are considerable for tourism, natural heritage and the hydropower industry”, Kerim Hestnes Nisancioglu at the Bjerknes Centre, co-author of the study, adds. Practically all of Norway’s electricity is generated from hydropower, of which 15 % depend on glacier meltwater. “The hydropower industry needs to plan for these changes, and we need to work together to find out how fast this transition will happen”, Nisancioglu says. What is more, “if Hardangerjøkulen melts away completely, it would not be able to grow back again given today’s climate”, Åkesson concludes. The study was published in the open-access journal The Cryosphere on January 27th. Read the full study here.
Reference: Åkesson, H., Nisancioglu, K. H., Giesen, R. H., and Morlighem, M.: Simulating the evolution of Hardangerjøkulen ice cap in southern Norway since the mid-Holocene and its sensitivity to climate change, The Cryosphere, 11, 281-302, doi:10.5194/tc-11-281-2017, 2017
No. 2
What happened on the sun 7000 years ago?
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt

(German text translated/edited by P Gosselin)
At the end of January 2017 a team of scientists led by Fusa Miyake described in PNAS an unexpected solar event on the sun that ended up being registered in 7000 year old tree rings. What follows is the press release from Nagoya University:
What Happened to the Sun over 7,000 Years Ago? Analysis of tree rings reveals highly abnormal solar activity in the mid-Holocene
An international team led by researchers at Nagoya University, along with US and Swiss colleagues, has identified a new type of solar event and dated it to the year 5480 BC; they did this by measuring carbon-14 levels in tree rings, which reflect the effects of cosmic radiation on the atmosphere at the time. They have also proposed causes of this event, thereby extending knowledge of how the sun behaves.
When the activity of the sun changes, it has direct effects on the earth. For example, when the sun is relatively inactive, the amount of a type of carbon called carbon-14 increases in the earth’s atmosphere. Because carbon in the air is absorbed by trees, carbon-14 levels in tree rings actually reflect solar activity and unusual solar events in the past. The team took advantage of such a phenomenon by analyzing a specimen from a bristlecone pine tree, a species that can live for thousands of years, to look back deep into the history of the sun.
“We measured the 14C levels in the pine sample at three different laboratories in Japan, the US, and Switzerland, to ensure the reliability of our results,” A. J. Timothy Jull of the University of Arizona says. “We found a change in 14C that was more abrupt than any found previously, except for cosmic ray events in AD 775 and AD 994, and our use of annual data rather than data for each decade allowed us to pinpoint exactly when this occurred.”
The team attempted to develop an explanation for the anomalous solar activity data by comparing the features of the 14C change with those of other solar events known to have occurred over the last couple of millennia. “Although this newly discovered event is more dramatic than others found to date, comparisons of the 14C data among them can help us to work out what happened to the sun at this time,” Fusa Miyake of Nagoya University says. She adds, “We think that a change in the magnetic activity of the sun along with a series of strong solar bursts, or a very weak sun, may have caused the unusual tree ring data.” Although the poor understanding of the mechanisms behind unusual solar activity has hampered efforts to definitively explain the team’s findings, they hope that additional studies, such as telescopic findings of flares given off by other sun-like stars, could lead to an accurate explanation.
The article “Large 14C excursion in 5480 BC indicates an abnormal sun in the mid-Holocene” was published in PNAS at: www.pnas.org/cgi/doi/10.1073/pnas.1613144114.”
Could this solar event also have left climatic traces?
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAmericans’ beliefs about climate change were recently surveyed by the Pew Research Center, and the results were made public a few days ago.  Pew pollsters found that a combined 51% of Americans agree that (a) there is no clear evidence the Earth is warming, or (b) natural factors are the main cause of climate changes.  Therefore, just 48% of Americans believe the Earth is getting warmer, and this warming is mostly caused by humans.  This belief percentage has essentially remained unchanged for the last 10 years, or since the survey was first conducted in 2006.

One key question in the survey pertained to Americans’ perception of the scientific “consensus”.   The Pew Research Center found that just 27% of Americans believe that “almost all” climate scientists maintain the belief that changes in climate are mostly caused by humans.
Of course, the presupposition underpinning this opinion question is the claim that upwards of 97% climate scientists — translated into “almost all” for the Pew survey — believe that climate changes since the mid-20th century have been mostly (i.e., more than 50%) caused by humans.   This oft-cited 97% figure was derived from a subjective abstract-counting exercise conducted by “Skeptical Science” blogger John Cook and colleagues (Cook et al., 2013, “Quantifying the Consensus…”).  Selected abstracts from 11,944 scientific papers published between 1991 and 2011 were used for the sample size, and of those papers just 65 (0.5% of the 11,944) were classified by Cook and his fellow raters as endorsing the specified Category 1 position that “Explicitly states that humans are the primary cause of recent global warming” (Legates et al., 2013).  This wouldn’t do, of course.  So, to ultimately reach the 97% endorsement percentage the Cook team had set out to obtain in the first place, they intentionally combined the (65) Category 1 quantified “consensus” statement papers  with the (934) Category 2 and (2,933) Category 3 endorsement papers that only needed to state (2) or just imply (3) that humans are a cause of climate changes.  These Category 2 and 3 papers did not quantify the contribution or indicate humans are a primary (>50%) cause of climate change, but they were nonetheless combined with Category 1 papers anyway.
Of course, nearly all scientists would agree that a human contribution greater than 0% exists, or that humans can be a cause — however modest  — of some degree of climate change.  So by combining the very high endorsement rates from Categories 2 and 3 (that even most skeptics acknowledge, as they agree humans contribute to climate change to some degree) with the negligibly small endorsement rates for Category 1 (just 65 papers), and by excluding many hundreds of papers from consideration that were published by scientists questioning the theory, Cook et al. (2013) were ultimately able to get away with proclaiming that 97% of scientists believe that climate changes since 1950 have mostly been caused by humans.
But as the evidence from the Pew survey  indicates, despite their best efforts, John Cook and cohorts have not been able to convince the general public that subjective abstract-counting exercises are a sound or scientific means to gauge “consensus.”  As mentioned, only 27% of Americans believe that “almost all” (i.e., 97%) climate scientists maintain the belief that humans are the primary cause of changes in the climate system.  Not only that, just 28% Americans agree that climate scientists even understand (“very well”) what factors cause climate changes.

And Americans may be right.  According to analysis found in the peer-reviewed scientific literature (Prokopy et al., 2015, Lefsrud and Meyer, 2012, Stenhouse et al., 2016), surveys of professional climatologists, engineers, geologists, and agronomists indicate that the percentage of these scientists who believe that changes in the climate system are primarily caused by humans falls abysmally short of the claimed 97%.  In fact, these studies reveal that only 53% of climatologists and meteorologists, 36% of professional engineers and geoscientists, and 19% of agronomists believe that changes in the climate system are mostly human-caused.
53% Of Climatologists Believe, 19% Of Agronomists Believe
In a survey of Midwest-based climatologists and agronomists (here called “extension educators” who have “at least a Masters degree” in agronomic sciences), just 53% of climatologists and 19.2% of agronomists believe that changes in the climate system are primarily caused by humans.
Prokopy et al., 2015
“In 2012, a total of 22 state and extension climatologists were selected through a purposive sample to represent main outlets of publicly available and location-specific climate information in the region. … About 53% attributed climate change primarily to human activities.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Extension educators are a unique set of agricultural advisors who serve to connect and translate research from universities to farmers in order to decrease risk to the farm enterprise and increase productive capacity and resilience. Typically, Extension educators have at least a Masters degree and are trained in agronomic sciences, which may not include climate sciences. … [O]ver 19% attribut[e] climate change primarily to human activities.”

36% Of Engineers, Geoscientists Believe
Among professional engineers and geoscientists trained in the physical sciences, only 36% are believers in the “consensus” position that humans are the “main or central” cause of changes in the climate system.
Lefsrud and Meyer, 2012
“The largest group of APEGA respondents (36%) … express the strong belief that climate change is happening, that it is not a normal cycle of nature, and humans are the main or central cause.”

53% Of Professional Meteorologists Believe
Stenhouse et al., 2016
Conflict about Climate Change at the American Meteorological Society: Meteorologists’ Views on a Scientific and Organizational Controversy
“A web-based survey was sent to all professional (i.e. non-student) members of the AMS in December 2011. …  Members who said the global warming of the last 150 years was mostly caused by human activity (53% of full sample).  … Members who are convinced of largely human-caused climate change expressed that debate over global warming sends an unclear message to the public.  Conversely, members who are unconvinced of human-caused climate change often felt that their peers were closed-minded, and were suppressing unpopular views.”
Ninety-Seven Percent Bunk
To summarize, the American public is about as likely to believe that climate changes are mostly caused by humans as are meteorologists and climatologists (48% vs. 53%, respectively).  And Americans in general are much more likely to believe that humans are the primary cause of climate changes as professionals trained in the physical sciences: 48% of U.S. citizens are believers, whereas ~20-35% of professionals with physical science degrees (engineers, Earth scientists, agronomists) are believers.
To put it non-delicately, the claim that “almost all” scientists (i.e., 97%) believe that most changes in the climate system are caused by humans is … bunk.
And most Americans already knew that.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterJohn Stossel conducted an unusual interview, one where the head of NASA GISS, Gavin Schmidt, refused to appear together on the set with skeptic Dr. Roy Spencer, climatologist at the University of Alabama.

According to Stossel about a dozen scientists had been invited to debate Spencer, but they refused to do so on air.
Great uncertainty
At the start Spencer tells Stossel that scientists in his opinion do not have a clue at this stage just how much of the warming can be attributed to man, saying it could be 10% or 90%.
Next a fidgety Gavin Schmidt appeared, insisting that the climate signatures of methane and CO2 “are very very clear“.
He then absurdly claimed that humans built its cities and infrastructure near the sea with the assumption that climate would not change and because “we didn’t expect the sea level to rise“.
Concedes Obama was mistaken
Surprisingly, at the 3:30 mark, Schmidt even conceded (reluctantly) that President Obama had been mistaken when he claimed hurricanes were increasing. When pressed by Stossel, the NASA GISS head was forced to admit that hurricane activity has in fact been showing no trend.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Problem is in the future
The inconvenient chart presented by Stossel actually suggests hurricane activity has been decreasing, which seemed a bit embarrassing to the NASA scientist. But Schmidt insisted the problem remained in the future (i.e. models): “Now what’s going on in the future, that is what we are concerned about.”
Ducks debate
When asked why not stay on the set and debate Spencer, Schmidt said: “I’m not interested.” And walked away.
Spencer returned and summed up telling viewers that the proposed green energy solutions were unrealistic and expensive, and that they would be far more damaging and deadly to the poor than the problem of climate change itself.
CO2 actually a good thing
Spencer told viewers that it is amazing how little CO2 there is in the atmosphere: “My long-term prediction is that eventually we are going to realize that more CO2 in the atmosphere is actually a good thing,” Spencer said.
Spencer ended the interview by telling that many scientists in fact agree with him, but that they are afraid to speak up about it for fear of losing funding.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterCO2 Contribution:
0.15°C Since 1959
 – Dr. B. Smirnov, Microphysics of Atmospheric Phenomena

Image Source: Springer

Purveyors of the viewpoint that rising CO2 emissions pose a grave threat to the planet via dangerous global-scale warming presuppose that the surface temperatures of the Earth are highly sensitive to parts per million (ppm) variations in atmospheric CO2 concentrations.
And yet the accumulation of scientific publications documenting a far less consequential role for CO2 in the climate system just keeps growing and growing — especially in recent years.
An incomplete compilation of at least 75 scientific publications now document a very low climate sensitivity to CO2 concentration changes.   Summarizing, doubling modern era CO2 concentrations from 280 ppm to 560 ppm may only raise surface temperatures by tenths of a degree – if that.
75 Scientific Papers Affirm Very Low Sensitivity To CO2
Expanding upon a 2016 scientific paper published in Europhysics Letters, Dr. Boris M. Smirnov, an atomic physicist, uses his field expertise in authoring another textbook entitled Microphysics of Atmospheric Phenomena.  The volume is one of 20 physics books Smirnov has published over the last two decades.
In chapter 10, Smirnov asserts that infrared emission from water vapor dwarfs the atmospheric contribution from CO2 within the greenhouse effect, as CO2 only “contributes in small portions“.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In fact, Smirnov finds that doubling the modern era CO2 concentration will only result in a temperature increase of 0.4°C.
He further calculates that the increase in CO2 concentration from 1959 (316 ppm) to the present (402 ppm) has only contributed 0.15°C to surface temperatures.  This means, of course, that the bulk of the temperature changes that have occurred in the last 55 to 60 years are not of human origin.
Steadily and gradually, the “consensus” position that says the climate is highly sensitive to variations in anthropogenic CO2 emissions continues to unravel.

Smirnov, 2017
It is shown that infrared emission of the atmosphere is determined mostly by atmospheric water. One can separate the flux of outgoing infrared radiation of the atmosphere from that towards the Earth. The fluxes due to rotation-vibration transitions of atmospheric  CO2  molecules are evaluated. Doubling of the concentration of  CO2 molecules in the atmosphere that is expected over 130 years leads to an increase of the average Earth temperature by (0.4±0.2) K mostly due to the flux towards the Earth if other atmospheric parameters are not varied.



Smirnov, 2016
[W]e take into account that CO2 molecules give a small contribution to the heat Earth balance and, therefore, one can use the altitude distribution of the temperature for the standard atmosphere model [1], and a variation of the CO2 concentration does not influence this distribution.  …  [I]njection of CO2 molecules into the atmosphere leads to a decrease of the outgoing radiation flux that causes a decrease of the average Earth temperature. But this decrease is below 0.1K that is the accuracy of determination of this value.  Thus, the presence of carbon dioxide in the atmosphere decreases the outgoing atmospheric radiative flux that leads to a decrease of the Earth temperature by approximately (1.8 ± 0.1) K. The change of the average temperature at the double of the concentration of atmospheric CO2 molecules is determined by the transition at 667cm−1 only and is lower than 0.1K.
In particular, doubling of the concentration of CO2 molecules compared to the contemporary content increases the global Earth temperature by ΔT = 0.4 ± 0.2K. … From this we have that the average temperature variation ΔT = 0.8 ◦C from 1880 up to now according to NASA data may be attained by the variation of the water concentration by 200ppm or Δu/u ≈ 0.07, Δu = 0.2. Note that according to formula (2) the variation of an accumulated concentration of CO2 molecules from 1959 (from 316ppm up to 402ppm) leads to the temperature variation ΔT = 0.15°C. One can see that the absorption of a water molecule in infrared spectrum is stronger than that of the CO2 molecule because of their structures, and the injection of water molecules in the atmosphere influences its heat balance more strongly than the injection of CO2 molecules.


Share this...FacebookTwitter "
"
Share this...FacebookTwitterAs mentioned here yesterday, Germany saw sunny and very windy conditions last Sunday and the following national holiday Monday –leading to a huge power surge into the German power grid. But because many industries were closed during these two days, demand for electricity was low, see chart below:

German consumption (blue line), wind power dark and light blue shaded area) and solar power (yellow shaded area). Source: Agora here.
The chart above also shows both the very high infusion of solar, onshore and offshore wind into the German power grid on April 30th and early May, and the low overall demand.
The result: Huge supply + little demand = crashing prices.
The huge feed-in of wind and solar energy did not occur without problems, especially in the southern state of Bavaria, the German online BR24 reports here.
BR24 writes that for the first time ever in Bavaria “wind turbines had to be shut down on a large scale – because there was too much power in the grid,” this according to the Bundesverband Windenergie (Federal Association for Wind Energy). There was also criticism that the wind turbines were shut down instead of the state’s nuclear plants.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




BR24 adds that “many wind turbines in Bavaria had to stop for hours because no one wanted to take the power” and that this was the first time this had ever happened in Bavaria.
According to the Fraunhofer Institute, “two thirds of Germany’s conventional power production was switched off” on Sunday in order to prevent the grid from turning into a giant toaster.
And because the base load (the grid’s backbone) cannot be adjusted rapidly or taken offline line to meet the rapid changes, the BR24 adds:
But the coal power plants continued to operate – despite the negative power prices of minus ten cents per kilowatt-hour.”
It’s not possible to turn off the coal plants because once you do, the critical baseload disappears and the grid risks becoming an uncontrollable wild bronco.
And when you are forced to sell your very own product at a negative price (minus ten cents per kilowatt-hour) just to get rid of it, then you get a pretty good idea of just how obscenely distorted the market has become because of wind and solar.
Yet the energy masterminds of Germany and Europe intend to double or even quadruple this folly in the future.
So what about the losses incurred from the negative prices? You guessed it! They will be passed along to the German consumers, who already pay among the highest electricity rates in the world.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s Energiewende is faltering badly.
At least that’s what Christoph Eisenring of the Zurich based daily NZZ writes here, claiming the Energiewende (transition to renewable energies) is a false model for the rest of the world.
The truth is that the Energiewende is on the same path as the construction of the Berlin BER airport – racing down the highway to total debacle – something that everyone is doing their damnedest to ignore and wishing it would just go away.
Moreover, Eisenring writes, it is causing “collateral damage” to Germany’s neighboring countries, as huge supply fluctuations threaten to destabilize their grids and electricity markets.
Only 1% of rated capacity!
The Energiewende has led to some of the most expensive electricity prices in the world, and it is not difficult to understand why. Eisenring uses the example of German power production on January 24, 2017 when at 7 a.m. German demand was at 70 gigawatts but the country’s 84 gigawatts of installed solar and wind capacity were putting out a mere 0.8 gigawatts, i.e. only about 1% of capacity.
That means doubling or even ten-folding German solar and wind capacity would still not be enough at times. That in turn means that Germany is forced to run two separate systems: a renewable one and a conventional system. “That’s costly,” Eisenring comments.
Highly inefficient
The highly erratic supply of wind and sun means the conventional power plants are constantly being slowed down or cranked up in a desparate race to keep the grid stable. Eisenring illustrates:
It is as if you would constantly be putting on the brakes and accelerating on the highway while driving from Bern to Zürich: It is a highly inefficient way of production.”
Adding more renewables is only going to mean more hours of oversupply when the wind blows and the sun shines, Eisenring reminds. It will lead to even greater inefficiency and instability.
1000 hours of negative prices possible annually
To unload the excess power, wholesale prices have been increasingly falling into the negative range, which means the grid operator has to pay buyers to “buy” the unwanted power. Eisenring reports that last year German power prices on the wholesale exchange markets were negative for 97 hours, which is close to 2 hours a week. But that figure will only grown as more wind and solar come online. Eisenring writes:
However, there are estimates that this could be the case for 1000 hours by 2022.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




That comes out to be about 20 hours a week. No market can survive that.
Another problem, Eisenring writes, is the havoc that Germany’s bucking bronco power grid is wreaking on the grids of neighboring countries like the Czech Republic, Poland, France, Austria or Switzerland, to name a few – all caused by the “exorbitant subsidization of renewables.”
€520 billion per year by 2025!
Germany’s Energiewende and its high costs are hammering consumers, many of whom are no longer able to pay their electric bills and are thus losing power by the tens of thousands of households. Eisenring cites one study that estimates the Energiewende cost Germany 150 billion euros in 2015 alone, and by 2025 it could cost 520 billion euros.
Storage still a pipe dream
Storing surplus electricity is also currently unfeasible, noting that German renowned economist Hans-Werner Sinn calculated 125 million Tesla automobile batteries would be needed. Yet, even such a huge quantity of batteries still would not be enough to allow wintertime driving, Sinn calculates!
Eisenring also writes that so far Germany’s Energiewendehas led to very little protection of the environment, as much of the CO2 emissions have been offshored and have fallen only 6% in the electricity sector since the feed-in act was enacted in 2000.
Eisenring writes that Germany will not meet its 2020 40%-emissions-reductions target. Currently the country has reduced emissions by 27% since 1990, but most of that coming from shutting down the shoddy old industries of former communist East Germany after the 1989 fall of the Berlin Wall.
Government still insisting it’s “our success story”
Yet, this glaring failure has not made any impression on the German government, as it recently released a propaganda brochure extoling the virtues of the Energiewende, calling it “our success story“, “sustainable and safe“, affordable and plannable” and “reliable and intelligent“.
Eisenring comments on the government’s propagandist self-assessment:
With this assessment Berlin is quite alone.”
Early this year Germany’s federal budget office determined that “the Ministry of Economics had in fact no overview of the financial impacts of the Energiewende” and that policymakers had “underestimated the impacts of renewable energy on the entire energy system“.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterProf. Fritz Vahrenholt was interviewed by Switzerland-based Basler Zeitung concerning Germany’s ‘Energiewende’ (transition to renewable energies), and energy issues in Switzerland, on February 18, 2017.

Prof. Fritz Vahrenholt. Image credit: GWPF
Vahrenholt was once the head of RWE’s renewable energy arm, Innogy, and responsible for the installation of offshore wind parks. However, after years of poor performance, discovering that the climate science was unclean, and learning of the harm wind parks pose to the environment, Vahrenholt has since been calling for a fundamental energy policy course correction in Germany.
Vahrenholt has called the German Energiewende “a disaster” so far, foremost because the supply of wind and sun is far too unstable and that everyone knows by now that it cannot work.
He also thinks Germany is making a huge mistake in the decision to phase out nuclear power, and calls Switzerland’s decision to keep nuclear power online “wise”.
The German professor also reminds that adding more capacity will not solve any of the supply problems: “No, even if we triple wind energy capacity, power generation will remain near zero when the wind stops blowing. The situation is similar for solar energy, especially at night. Solar energy only works full time 8% of the year.”
No viable storage technology
Tripling capacity would also result in chaos on windy and sunny days, Vahrenholt explains. On such days, with a tripled capacity, so much power would surge into the power grid that the surplus power would have to be given away, or “sold at negative prices”:
When too much power is fed in, grid operators order wind parks to shut down — yet they continue to be paid even when they do not produce. That is now costing one billion euros a year, and that is indeed absurd!”
Vahrenholt reiterates that sun and wind will not function until a solution is found for the storage problem. Currently no large-scale solution is anywhere near in sight. Dumping surplus power into the power grids of neighboring countries only wreaks havoc in those countries. Already countries are installing so-called phase shifters to keep surplus energy from the German grid from spilling uncontrollably into neighboring power networks, Vahrenholt explains.
Also a topic of the interview was the rising price of electricity for end consumers, which has seen German power become at near 30 euro-cents per kilowatt-hour among the world’s most expensive.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Vahrenholt says that policymakers made great errors in implementing wind and solar power, stating that storage technology should have been first developed. “We shouldn’t put the cart before the horse.”

For the time being, many energy-intensive industries in Germany have been exempted from having to pay the feed-in tariffs that are passed on to consumers. This leaves the regular private consumers to pick up the tab. But there is the risk that industry will soon be called on to pay their fair share. Vahrenholt adds:
One does not invest in a country when he/she is not sure how energy prices will develop. In addition to the price, supply stability also plays an important role. It decreases with every new wind turbine.”
“Enormous” impact on wildlife
Vahrenholt also points out the wind turbines are a real hazard to endangered wildlife: “The impacts on the biosphere of plants and animals are enormous.”
And why aren’t environmentalists and Green Party politicians being more vocal against wind turbines? Here Vahrenholt says that years ago they made the Energiewende the centerpiece of their platform. “In reality in Germany they were never an environmental party, but rather an anti-capitalist party that dedicated itself to protesting nuclear power and industry.”
Green energy for the urban elite
Yet, Vahrenholt sees “an enormous citizens’ protest potential” that reminds him of the anti-nuclear power industry from decades ago. He summarizes:
The dream of the urban elite of a supposedly clean energy supply is being realized on the backs of the rural population, who are losing their homeland.”
All in all Vahrenholt says green energies have been a real bonanza for rich property owners, and a real financial burden on the poor. He believes that the current development cannot be sustained and that it will need to be corrected: “At the latest when the first power grid failure occurs.” and that, “The longer it takes, the greater the difficulties will be.”
The full interview in German is at the Basler Zeitung.
 

Share this...FacebookTwitter "
"
Share this...FacebookTwitterGlobal Temperature ‘Truth’ Changes With The Times
In the early 1950s, the accepted scientific truth — as determined by thermometer records available at the time — was that global mean temperatures had risen by 0.7°C between 1860 and 1940.
 

Willett, H. C. 1950. “Temperature Trends of the Past Century” Centenary Proc. Royal Meteorol. Soc., pp. 195-206.

As recently as 1980, it was still considered “consensus” science that the Northern Hemisphere had warmed by “nearly 1.0°C”  between 1880 and 1940, and then cooled by a “nearly comparable” amount from 1940 to the late 1970s.

Agee, 1980


The Temperature ‘Truth’ Changes After The 1980s

The raw thermometer or instrumental temperature data available in the 1950s have not changed in the last 35 years.  In other words, daily high and low temperature numbers from thermometer accounts that were not available in the 1870s or 1910s or 1930s did not subsequently become available, or appear, in the years following the early 1980s.  And yet after the 1980s, the thermometric instrumental record accepted during the 1950s to 1970s was fundamentally changed to reflect a new truth that aligned with climate models.  For instead of a global warming +0.7°C between 1860 and 1940, the Met Office decided that the 1860-1940 warming trend should be +0.3°C instead.  Again, no new raw thermometric evidence had emerged.  And yet about 0.4°C of warming was lopped off the previously accepted trend anyway.


Source

New Paper’s Ice Core Evidence Indicates Globe Was Similarly Warm In 1920s, 1930s

Interestingly, when graphs of regional temperatures using geophysical proxy evidence (ice cores, tree rings, etc.) are reconstructed for the last few centuries or millennia, the results look rather different than the current instrumental records do.  Instead of a sharp warming trajectory after the 1950s, for example, many regions do not show a significant warming trend at all.  In fact, more and more, temperature reconstructions using proxy evidence indicate that there has been no unusual or remarkable warming trend in recent decades that strongly aligns with the abrupt increase in anthropogenic CO2 emissions after the 1940s.
To illustrate, consider the 60 papers published in 2016 (or the 17 papers already published in 2017) that display no clear evidence of an unusual warming trend after the 1940s — or in the last 100+ years relative to the last few thousand.  Instead, many reconstructions of regional temperatures using proxy evidence show that a large portion of modern era warming occurred prior to the 1940s, and not after it.
For example, consider the glacier melt rate in the 1920s to 1950s relative to recent decades in Gregory et al. (2013) below.  Could this explosive glacier melt rate have occurred with only modest warming as depicted in the highly altered instrumental record?

Gregory et al., 2013


Now, in a new paper, Steiger et al. (2017) have constructed graphs using compilations of ice core proxies to represent the globe.  As might be expected, there are notable differences in the reconstructions of global temperature using geophysical evidence when compared to the instrumental thermometer record (Berkley Earth).  Namely, (a) the instrumental record warms up the post-1970s period substantially relative to the ice core record (which shows an incompatible non-trend or cooling after the 1990s), and (b) the ice core record shows much more warming than the instrumental record does in the early 20th century.
In the graphs below, the instrumental (black) and isotope record (blue) appear together (as they do in the paper), and then the instrumental trend is removed in the subsequent representation.

Steiger et al., 2017
“Through several idealized and real proxy experiments we assess the spatial and temporal extent to which isotope records can reconstruct surface temperature, 500 hPa geopotential height, and precipitation. We find local reconstruction skill to be most robust across the reconstructions, particularly for temperature and geopotential height, as well as limited non-local skill in the tropics.  These results are in agreement with long-held views that isotopes in ice cores have clear value as local climate proxies, particularly for temperature and atmospheric circulation.”



 


Temperature ‘Truth’ Pivots Upon One’s Presuppositions, Biases

Convinced we have already obtained the truth about global temperatures, the Steiger et al. (2017) scientists possess the certitude to encapsulate that very word in their graph keys:



Considering scientists 30 years ago were documenting an artificial (urbanization) warming bias of more than 0.1°C per decade already existed in the post-1970s instrumental records, that 1/3rd of the oceans hadn’t even been sampled (temperatures) yet as of the 1990s, or that overseers of temperature datasets acknowledged that they just “made up” temperatures in places where there was no data,  can we really know the Earth’s true temperature?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Take a locality like Greenland.  When we consider that just a tiny fraction of the Greenland ice sheet has instrumental temperature readings available for both recent decades and for the beginning of the 20th century (see illustration below), just how certain can we be that we have the truth anyway?

Peterson and Vose, 1997


Or consider the below graphic of competing early 20th century temperature trends for Greenland.  Reeves Eyre and Zeng (2017) indicate modeling biases may reach 5°C for Greenland, and they point out that widespread temperature monitoring has only been available since the 1990s.
Of the spaghetti of trends depicted in the graph below, which one is the truth?  For those who believe the warming in recent decades is dangerously unprecedented, the lower early 20th century temperature trends are truth.  For those skeptical that the modern climate is unusually warm or that the Earth’s climate undulates in concert with CO2 emissions, the truth is likely that the 1920s and 1930s had warmer temperatures.  Which conceptualization is the “right” one?  Probably neither.

Reeves Eyre and Zeng, 2017
“Ice sheet-average annual mean SAT [surface air temperatures] from different datasets are highly correlated in recent decades, but their 1901–2000 trends differ even in sign [some show cooling, some show warming]. Compared with the MERRA2 climatology combined with gridded SAT analysis anomalies, thirty-one earth system model historical runs from the CMIP5 archive reach ~5°C for the 1901–2000 average bias and have opposite trends for a number of sub-periods. … Due to its remoteness and extreme climate however, continuous widespread climate monitoring over the GrIS has been carried out for only about the last two decades, and even then with rather sparse coverage in some geographic areas and glaciological regimes. … Box (2002) found a pattern of warming from ~1900 to ~1940, cooling from ~1940 to ~1990, and warming from ~1990 onwards. In addition, inter-annual variability was found to be closely related to the North Atlantic Oscillation (NAO). …Biases vary by season and by region of the ice sheet: in the ablation region (demarcated here by the 1500 m elevation contour) during summer, most reanalyses have a ~1°C positive bias (though 20CR and ERA–20C have negative biases) while CRU and Berkeley Earth gridded SAT analyses have larger positive biases.”

 

Before It Was Ignored, The Scientific ‘Consensus’ Was That Explosive Warming Occurred Prior To The 1940s

At the time, there wasn’t any disagreement among geologists.  The late 19th century to early 1940s was considered a period of unprecedented warming.  The highest temperatures on record.
The Arctic winter warmed by 7.7°C.  Antarctica warmed by nearly 3°C.  Sea levels rose at a clip of 8 mm/yr in the Atlantic.  Glaciers melted “catastrophically”. Dozens of animal species migrated north to escape the warmth.  Crops could be grown in regions where they hadn’t before.
At the time, this was the climate truth.   Below is a summary of accepted climatic trends as they existed in 1959, compiled by Princeton geologist Dr. Erling Dorf.

Dorf, 1959:  “CLIMATIC CHANGES OF THE PAST AND PRESENT”

•A 14°F (+7.7°C) winter mean warming in the Arctic (North Pole region) between the early 1900s and 1950, with ice-free ports 7 months out of the year rather than the mere 3 months per year that were common at the turn of the century.
“It has been observed, however, that the greatest temperature increases during the last hundred years have been in the Arctic regions. In Spitsbergen, only about 10 to 12 degrees from the North Pole, the mean winter temperatures have risen about 14° F. since 1910 (Willett, 1950). Ice-free ports there are now open to navigation about 7 months of the year as compared with only 3 months fifty years ago (Ahlmann, 1953, p. 32). If the warming trend of the north polar region should continue at its present rate, it has been estimated that the entire Arctic Ocean would be navigable all year long within about a hundred years.”
•A 5°F (+2.8°C) warming in Antarctica since the early 1900s.
“At the opposite end of the world, according to recent reports from the Weather Bureau (Wexler, 1958), the Antarctic region has undergone a rise of about 5°F. in average temperature in the last fifty years.”
•“Catastrophic” and “violent” wasting away of glaciers since 1900, with Muir Glacier retreating 2 miles (3.2 km) in 10 years.  The retreat began in the 1700s, with severe wasting between the 1920s and 1940s.
“What have been some of the notable results of this warming trend during the last hundred years? Glaciers throughout the world have been melting away at a rapidly increasing rate. Brooks (1949, p. 24). the eminent British paleoclimatologist, stated that “Since the beginning of the 20th Century glaciers have been wasting away rapidly, or even catastrophically.” In the Juneau region of Alaska, all but one of the numerous glaciers began melting away as far back as 1765. Muir Glacier, for example, has retreated as much as two miles in 10 years. Baird and Sharp (1954, p. 143) have referred to the “alarming retreat of glaciers” in the Alaskan region; along the Pacific Coast of North America and in Europe they believe the glacial melting “appears to be progressing violently.”   In only a few regions of the world, such as the Pacific Northwest, are there any records of glaciers advancing during the past century, and these have been mostly since 1950 (Hubley, 1956).”


Ahlmann, 1953
•Due especially to the massive glacier-melting during the 1920s to 1940s, there was as much as a 6-inch (15 cm) rise in sea level between 1930 and 1948, a rate of about 32 inches (+80 cm) per century, or 8 mm per year, which is 5 times the overall rate of rise for the entire 1901-2010 period (1.7 mm/yr) according to the IPCC (2013) and a “six-fold” increase relative to the 19th century rate.
“Believed in large part to be the result of the melting of the world’s glaciers, sea level has been rising at a rapidly increasing rate, amounting to as much as a 6-inch rise from 1930 to 1948 (Marmar, 1948). This is about four times the average rate of sea level rise during the past 9000 years [~2 mm/yr], as recorded by Shepard and Suess (1956). It should be noted that more than a six-fold increase in the rate of sea level rise occurred in the mid-1920’s at the same time there was a striking change in the rate of glacial melting in the north (Ahlmann, 1953, Fig. 11).”

•Agricultural crop lines shifted 50 to 100 miles (80 to 161 km) northward, with 10-day longer growing seasons.  Tree lines moved 65 feet (20 meters) up the mountains in Sweden.
“Changes in vegetation brought about by the warmer temperatures include the encroachment of trees into the subpolar tundra as recorded in Alaska, Quebec, Laborador, and Siberia. In the Canadian prairies the agricultural crop line has shifted from 50 to 100 miles northward as a result of the lengthening of the growing season by as much as ten days. In parts of northern New England and eastern Canada the birch trees have been dying off over large areas, and the spruces and balsams have begun to suffer as a result of the rise in summer temperatures. In Sweden the timberline has moved up the mountain slopes as much as 65 feet since 1930 (Ahlmann, 1953, p. 35).”
•Many birds and mammals extended their habitats northwards; about 25 species of birds advanced from the south up into a warmer   Greenland; codfish replaced seals along the coasts of Greenland, which led “Greenland Eskimos” to switch to cod-fishing rather than seal-hunting.
“In the animal world many southern types of both birds and mammals have been extending their habitat ranges northward as a result of the warming trend. The cardinal, the turkey vulture, the tufted titmouse, and the blue-winged warbler, as well as the warmth-loving opossum, have slowly moved their ranges into the northern United States. A good many central European species of animals have been shifting their ranges northward into Scandinavia, Greenland, Iceland, and the Faero Islands. Twenty-five species of birds alone are reported to have invaded Greenland from the south since 1918 (Jensen and Fristrup, 1950). Codfish from the Atlantic have replaced the seals in the waters along the coast of Greenland. It is reported that compared to a shipment of 5 tons of codfish from Greenland in 1913, the 1946 shipment had risen to over 13,000 tons; the Greenland Eskimos have become cod fishermen instead of seal fishermen (Kimble, 1950). Farther south tunafish have moved northward into the waters off New England, and tropical flying fishes have become increasingly common off the coast of New Jersey.”

The ‘Truth’ About Past Climates…Is What We Want It To Be


But the truth about the climate as it existed in the 1950s is no longer accepted or acceptable.  And that version of the truth is to be ignored.  Why?  Because if we accept that dramatic and rapid warming (and glacier melt and sea level rise) could occur while anthropogenic CO2 emissions were flat and rather negligible (prior to the 1940s), then we would have to acknowledge that modern climate changes may not be predominantly influenced by human activity.  And that couldn’t be the truth.  So . . . it isn’t.
And 2016 was the Earth’s hottest year on record.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAnalyses show that global temperatures continue their rapid cooling trend, as Schneefan here writes. What follows are excerpts of his recent comprehensive analysis.
The cooling comes naturally in the wake of the moderate La Nina conditions that have ruled over the past months.
In April surface temperatures 2 meters above the ground plummeted as the following NCEP chart shows:

Source: weatherbell.com/temperature.php
Global satellite temperature anomaly from the mean measured by the University of Alabama in Huntsville (UAH) rebounded a bit after a large March drop.

Source: UAH Global Temperature +0.27 deg. C.
Foremost the atmosphere above the oceans cooled the most during March, 2017. This is clearly depicted by the UAH: an anomaly of +0.29°K to +0.09°K compared to the WMO 1981-2010 mean.


Plot UAH satellite temperatures von UAH in the atmosphere 1500 m altitude (TLT) over the oceans. Note the rose colored curve shows the ARGO ocean buoys’ mean of the sea temperature to a depth of 2.5 m, with 37-month smoothing. Source: www.climate4you.com/, sea surface temperature estimates: UAH.
Global RSS satellite data show a rapid cooling since early 2016:

Moreover despite the powerful warming El Niño event of 2015/16, the unfalsified satellite data in 2016 show that no new significant global heat record was seen when compared to the El Niño year of 1998. We are talking about hundredths of a degree, completely within the boundaries of uncertainty.
No significant warming in 20 years


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The powerful linear global cooling continued in April 2017 and will continue for the time being, Schneefan writes.
What does that mean for the global warming? Schneefan adds:
The IPCC global warming claimed by the climate models has been missing for almost 20 years. And that despite the constantly rising atmospheric CO2 concentrations!”
And just days ago, Kenneth Richards here showed that there hasn’t been any warming over the entire southern hemisphere at all. The warming of the past decades is not even global.
What is now becoming glaringly obvious is that the IPCC has wildly overestimated its projected global warming for the future. When the IPCC models from the various IPCC reports are compared to the observations, the result gets vividly illustrated by the following chart showing the satellite observed temperatures from January 2001 to June 2016:

The Global Warming Speedometer for January 2001 to June 2016 shows observed warming on the HadCRUT4 and NCEI surface temperature datasets as below IPCC’s least prediction in 1990 and somewhat on the low side of its 1995 and 2001 predictions, while the satellite datasets show less warming than all IPCC predictions from 1990 to 2001. Later IPCC predictions are too recent to be reliably testable. Source : Is the Reuters “news” agency committing fraud?
Massive Arctic ice thickness growth
The growth in so-called multiyear Arctic sea ice has been considerable over the past nine years. The Chukchi Sea and the East Siberian Sea had little thick multiyear ice back in February 2008. But by February 2017 there was a lot. Massive Growth In Thick Arctic Sea Ice:

Source: DMI Modelled ice thickness, Real Climate Science.
Also Greenland has seen impressive gains in surface snow and ice mass. Kirye at Twitter posted the following chart which shows recent record surface mass gain for 2017:

Source: DMI.
If the Arctic is the climate canary in the coal mine, as many alarmists used to like claiming, then we probably ought to start worrying about cooling.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterUnfortunately it has taken a huge disaster in London to wake up the many German politicians who have been self-drugged up on their green ideology for too long. Now they have been forced to face the harsh reality of their green gross negligence. While millions of endangered birds and animals remain threatened by windmills, it appears that the spectacular inferno may have finally gotten through on another front.
The German ruhrkultur.de here writes in an article titled Insulation madness brings home residents in wanton danger:
The Grenfell Tower fire catastrophe in London, with some 80 lives lost, has finally caused the public to become aware of a problem that has been ignored and swept under the carpet for too long: The insulation madness has led in principle and in large part to death in new buildings and renovated buildings.”
In a mad rush to rescue the planet from a dubiously theoretical year 2100 climate Armageddon, Germany over the years has been vigorously supporting the installation of exterior plastic foam insulation on many buildings over the past years. Unfortunately it is turning out that these materials laid on the exterior of buildings is a fire and health hazard.

Policymakers and bureaucrats had been warned, but in their cause of saving the climate and rescuing humanity, the warnings were smugly dismissed. The state would instead take its orders from Potsdam Institute (PIK) Science.
Photo: ruhrkultur.de
German “death traps”
London, it turns out, is only the tip of green insulation fire hazard ice berg. Recently German authorities were forced to clear out an entire residential block in the western city of Wuppertal due to the inflammable insulation material placed earlier on the building. Frankfurt’s fire chief said that German residential buildings recently insulated in a like manner are not safe, contradicting what politicians, industry groups and insulation experts claimed in the aftermath of the Grenfell Tower inferno.
With the millions of homes that have been fitted with the insulation to meet green energy requirements, many residents are in fact residing in “death traps” waiting to spring, ruhrkultur.de writes.
Facade fires “especially dangerous”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The ruhrkultur.de adds that since the exterior “insulation madness” began, firefighters have noted a strong increase in so called facade-fires, which are “especially deadly because they spread extremely rapidly and give residents hardly any time to escape.” It appears that long standing fire codes and regulations against the use of such building materials were not enforced so as not to impair the green national insulation endeavor. Now lives are at risk.
Driven by “climate rescue-campaign”
As mentioned earlier, a number of German experts warned of the high danger posed by the exterior insulation used to make residential buildings more energy efficient. But politicians of all parties and most of the public, ruhrkultur.de writes, were convinced otherwise, due to the “current, incredible massively driven ‘climate-rescue-campaign’ and the supposedly ‘necessary mass insulation measures’.”
The insulation campaign involves plastering large blocks of polystyrol or polyurethane based insulation material on exterior walls (see photo above), which ruhrkultur.de writes is tantamount to storing large amounts of gasoline in your home.
Toxic gases hazard
The inflammability of the material is not the only danger posed by the exterior foam-type insulation, but in many cases it has been treated with possibly toxic fire retardants, such as tetrabrombisphenol A (TBBA), hexabromcyclododecane (HBCD) and a variety of polybromide diphenylethers (PBDEs).
Also the campaign to weatherproof homes has led to a growing occurrence of dangerous, health-threatening black mold forming inside homes.
So what happens now?
Suddenly homeowners find themselves in houses made in a way that threatens them. How shall they be compensated for? Who has to be held accountable?
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter New Paper: Experiment Reveals No Detectable
‘Greenhouse’ Difference Between CO2 And Air
 
Below is a very abridged quoted summary of a new scientific paper published by Dr. Thomas Allmendinger, a physicist (chemistry, quantum mechanics) who uses a real-world experiment to document a glaring lack of empirical support for the position that CO2 is a dominant agent of atmospheric warming.
One-sentence summary: Shortwave radiation heats both CO2 and air only up to a limited temperature threshold, and there is no observed difference between the heat absorption/emission of  air vs. CO2.  


Dr. Thomas Allmendinger (2017)
Original Greenhouse Theory Not Backed By Experimental Data
The starting point of the here referenced research was the generally accepted greenhouse thesis which assumes that the present climate change is mainly due to the observed growing amount of the so-called greenhouse gases in the atmosphere, particularly of carbon-dioxide in spite of the fact that, unlike a greenhouse, the Earth atmosphere doesn’t exhibit a transparent roof …  This [greenhouse effect] idea takes its source in Fourier’s treatise made in 1827, exhibiting no empirical data or physical calculations and experimental data.
The first results were delivered by Tyndall in the sixties of the 19th century, using artificial IR (= infrared) radiation. His photometric [light-measuring] apparatus consisted of metallic tubes as gas vessels and Leslie cubes as heat radiation sources, entailing comparatively low temperatures, namely 100°C and lower. In the [eighteen] nineties, Arrhenius continued such measurements. He established the greenhouse thesis claiming that, unlike air, carbon-dioxide considerably absorbs infrared-radiation. Thereby we distinguish between near IR (λ = 0.8 – 3μm), emitted at high temperatures (> 1000 K), and medium IR (λ = 3 – 50μm) occurring at lower temperatures as usual thermal radiation, while IR-radiation with larger wavelengths (λ = 50 – 1000μm) is defined as far IR.
[O]verall, the greenhouse thesis has been commonly settled even if […] its empiric basis appears poor while several theoretical presumptions are speculative.  … there is reason enough to examine the current climate theory, and in particular the greenhouse thesis, regarding fundamental scientific principles and possibly to question the usual assumptions.
The analytic methods applied in climatology were exclusively photometric [light-measuring] ones. … Thermal measurements have never been made, except those by pyranometers comprising the whole spectrum, so that direct coherences between light absorption and warming-up effects at matter have not been detected yet.
The natural laws which were used for constructing the theory were confined to the temperature law of Stefan-Boltzmann (1), Planck’s distribution law (2), both being solely valid for black bodies, and BeerLambert’s absorption law (3), being unequivocally valid solely for visible light, and not compellingly for IR radiation (see below). These laws were often impermissibly generalized and used in an incorrect way leading to wrong conclusions.
Questioning The CO2-IR-Warms-The-Atmosphere Assumption
[A]ccording to this [greenhouse theory] model the assumption is made that any warming-up of the atmosphere is exclusively due to a partial absorption of medium-wave IR-radiation while any short-wave IR-absorption can be excluded since it has never been detected spectrometrically.
Against this, at least the following [5] arguments may be alleged [just the 1st , 4th, and 5th arguments are included here in very condensed form]:
1. As already found within a previous investigation [12], the greater part – namely at least 60% – of the energy being emitted from a warmed plate to the surrounding atmosphere is transferred by heat conduction, and not by heat radiation [i.e., via the greenhouse effect] obeying Stefan-Boltzmann’s law which is only valid in the vacuum. That part is even enhanced when the air convection is enhanced. Moreover, near the ground the molar concentration of water vapour is much higher than that one of carbon dioxide letting assume that its absorbance of heat radiation is much stronger. (e.g. at 20°C and 60% rel. humidity, the molar concentration of water vapour is 36 times larger than that one of carbon-dioxide being 0.038 volume%). Hence it can be assumed that the major part of the heat transfer between Earth surface and atmosphere occurs near the ground while the greenhouse theory neglects that part solely regarding the radiative absorption by CO2 passing the whole atmosphere.
4. Between the energetic absorption of electromagnetic radiation by gases and their resulting warming-up no empirical – and also no
theoretical – coherence is known which would be needed to carry spectroscopic results onto thermodynamic properties. There is no good reason to assume that absorbed IR-radiation will be entirely transformed into heat. Rather it is conceivable that a part of it is re-emitted, to wit in all directions. But the link between the two phenomena is not known.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




5. The question of radiation emission by hot gases is related with it since it is obvious that any gas, also air, begins to radiate to such an extent as it is warmed-up. This question arises when the so-called radiative energy transfer is studied. But instead of empiric measurements, complicated theories were developed [15-17] starting from the abstruse assumption that the atmosphere behaves like a black body obeying Stefan-Boltzmann’s emission law, and disregarding the kinetic gas theory.
Overall it must be assessed that the atmospheric theory is on a shaky ground. widely missing empiric key methods to check the principles and their consequences.
Air Vs. CO2 Experiment: ‘The Final Proof That The Climate Theory Cannot Be True’
Beyond, there is an aspect which hitherto has been overlooked, and which delivers the final proof that the climate theory cannot be true. It is the topic of the here reported author’s work [Allmendinger, 2016] concerning thermal measurements instead of spectroscopic ones, and delivering the evidence that any gas absorbs IR-radiation – but in the short wavelength range -, with the consequence that air is warmed up by direct solar insolation – as well as by artificial IR-light – up to a limiting temperature due to radiative emission, and leading to an equilibrium state.
Preliminary tests for the present investigation were made with solar light using square twin-tubes from Styrofoam (3 cm thick, 1 m long, outer diameter 25 cm), each equipped with three thermometers at different positions, and covered above and below by a thin transparent foil (preferably a 0.01 mm thick Saran-wrap). The tubes were pivoted on a frame in such a way that they could be oriented in the direction of the solar light (Figure 3). One tube was filled with air, the other with carbon-dioxide. Incipiently, the tubes were covered on the tops with aluminium-foils being removed at the start of the experiment.
The primary experimental result was quite astonishing in many respects.
Firstly: The content gases warmed within a few minutes by approximately 10°C up to a constant limiting temperature. This was surprising – at least in the case of air – for no warming-up was anticipated since sunlight is colourless and allegedly not able to absorb any IR-radiation. However, the existence of a limiting temperature is conceivable since a growing radiative emission has to be expected as far as the temperature rises.
Secondly: The limiting temperatures were more or less equal at any measuring point. This means that the intensity of the sun beam was virtually not affected by the heat absorption in the gas tube since the latter one was comparatively weak.
And thirdly: Between the two tubes [one filled with air, the other with CO2] no significant difference could be detected.  Therefore, thanks to this simple experiment a special effect of carbon dioxide on the direct sunlight absorption could already be excluded.
As evident from Figure 8, any gas absorbs IR-light – even the noble [non-greenhouse] gases argon, neon and helium do so – while there is no significant difference between argon and carbon dioxide, but only a small difference between carbon-dioxide and air.

Conclusion/Summary
Besides a critical discussion of the convenient atmosphere theory profoundly questioning the greenhouse thesis by disclosing several basic errors, the here reported investigation reveals the discovery of direct absorption of shortwave IR-radiation by air. It is part of the incident solar light, but also of artificial light which enables a more exact detection. It is caused by another effect than the one which is responsible for the longer-wave absorption being observed at carbon dioxide, and it is not detectable by IR-spectroscopy since its absorption coefficient is too low. However, it is clearly detectable by means of the here applied apparatus leading to a distinct temperature elevation up to a limiting temperature which depends on the radiative emission. The limiting temperature depends on the gas kind, whereby practically no difference between air and carbon-dioxide could be found.
Nevertheless, that direct absorption effect [shortwave] which was discovered thanks to this method probably contributes significantly to the warming up of the atmosphere while the warming-up due to carbon-dioxide can be neglected.
But since the direct absorption cannot be influenced, the surface albedo must be focused as the governing factor providing the only [anthropogenic] opportunity to mitigate the climate, or at least the microclimate, by changing colour and structure of the surface, particularly in urban areas. However, a prediction seems not feasible since the global climate is too complex. But the greenhouse theory turns out to be a phantasm delivering the wrong diagnosis for the climate change, and a wrong diagnosis cannot enable a healing.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA tsunami of outrage swept across Germany right after President Donald Trump announced dropping out of the Paris Accord (and not to transfer billions of taxpayer money over to the UN each year).
It appears the President’s bold and courageous move is leading to potentially dangerous pockets of energy policy and climate science uprising in Germany.
A reader just pointed out something a bit stunning: Germany’s flagship ARD television, the country’s version of the BBC, reported here how a group of conservative politicians from Angela Merkel’s CDU party known as the Berliner Kreis has just voiced its strong opposition to the party’s climate and energy policy course.

A group from Angela Merkel’s CDU party recently released its “Climate and Energy Political Demands”, calling for a science and energy policy “without ideology”, an end to “moral extortion”, and an exit from the “climate saving circus”, pdf here.
According to the ARD report, the group of conservatives is disputing the “‘solitary role’of the greenhouse effect in global warming’ – and is demanding a change in direction in the chancellor’s climate policy“.
The Berliner Kreis, led by Philipp Lengsfeld and Sylvia Pantel, issued an official declaration (German), see pdf here.
“World rescue circus”
The Berliner Kreis declaration demands a return to science “without ideology”, a “fact-based” discussion — one free of “moral extortion” –, and calls for a “reform of the IPCC”, which “has not been as scientifically sound as an advising body needs to be”.
The Berliner Kreis declaration adds that the science must not become “a sort of world rescue circus”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Christian conservative group also casts Germany’s CO2 reductions policy into question, noting that so far the country has cut back its CO2 emissions by less than half a billion tonnes while the rest of the plant has increased it by 14 billion tonnes, i.e. 30 times more than what the country has saved.
Germany’s CO2 emissions represent only 2% of the globe’s output, but its energy policy has been 100% pain.
Alinsky-type target?
Now that the Berliner Kreis position has become public, already it has come in the cross-hairs of major media outlets, setting off a wave of reports, e.g. here, here and here.
It remains to be seen what the real ARD intent of their report was: Whether to show that there is dissent in on the climate topic in Germany and that policy needs to take a step back, or if it is to identify and single out unwanted voices Alinsky style (Rule 13).
Lately the approach used by the media and entrenched establishment in Germany concerning unwanted dissenting voices on sensitive issues – such as Europe, immigration and climate – has followed the labelling formula of: dissent = extremism = Nazi. Many feel intimidated by it and thus are afraid to speak up.
What becomes of the dissident Berliner Kreis will remain a question. Expect Merkel to mobilize forces to shut them up, and down. The Berliner Kreis would be well-advised to quickly forge channels and networks with international dissenting groups, as they may be about to find out what the real price of civil courage is.
German publicist Dirk Maxeiner here, who knows first-hand the cost of civil courage, applauds the move by the group of CDU dissenters, commenting (with sarcasm):
A group of CDU parliamentarians that calls itself the ‘Berliner Kreis’ dares to think for itself on the climate issue. The Tagesschau comments on this atrocity with the headline: ‘CDU right wingers attack Merkel’s climate direction.’ Skepticism, thought, realism, facts – all right wing.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter‘Adjustments’ To Create Spurious Sea Level Rise 
Have Now Infected The PSMSL Tide Gauge Data


In a new paper published in Earth Systems and Environment this month, Australian scientists Dr. Albert Parker and Dr. Clifford Ollier uncover evidence that Permanent Service for Mean Sea Level (PSMSL) overseers appear to have been engaging in the “highly questionable” and “suspicious” practice of adjusting historical tide gauge data to show recent accelerated sea level rise where no such acceleration (or rise) exists.
Extensive evidence from “tide gauges, coastal morphology, stratigraphy, radiocarbon dating, archaeological remains, and historical documentation” all suggest that sea levels in the Indian Ocean have effectively been stable in recent decades.
The authors expose how PSMSL  data-adjusters make it appear that stable sea levels can be rendered to look like they are nonetheless rising at an accelerated pace.
The data-adjusters take misaligned and incomplete sea level data from tide gauges that show no sea level rise (or even a falling trend).  Then, they subjectively and arbitrarily cobble them together, or realign them.   In each case assessed, PSMSL data-adjusters lower the earlier misaligned rates and raise the more recent measurements.  By doing so, they concoct a new linearly-rising trend.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This adjustment of tide gauge data to yield a rising sea level trend where none exists is not occasional or episodic.  Instead, for every adjustment of raw data analyzed, “the adjustments are always in the direction to produce a large rise in sea level.”
The suspicious perpetuity of this pattern strongly suggests that there is an agenda driving these arbitrary and subjective realignments.
From all appearances, the data-adjusters at PSMSL are attempting to “correct” the sea level rise data that do not support the conceptualization of a rapidly-rising sea level trend in response to rising human CO2 emissions.
As Drs. Parker and Ollier conclude: “It is always highly questionable to shift data collected in the far past without any proven new supporting material.”
Apparently not even tide gauge measurements can be spared from those who tendentiously fiddle with raw data to satisfy an agenda.

Parker and Ollier, 2017
‘Multiple Lines Of Evidence’ Affirm Sea Levels Are Stable In The Indian Ocean
The tide gauge result of Aden is perfectly consistent not only with the tide gauge results for Karachi and Mumbai. It is also consistent with the multiple lines of evidence, tide gauges, coastal morphology, stratigraphy, radiocarbon dating, archaeological remains, and historical documentation, for a stable sea level of about zero mm/year experienced over the last 50 years in all the key sites of the Indian Ocean (Mörner 2007, 2010, 2014, 2015a, b, 2016a, b).
Contrary to the adjusted data from tide gauges and the unreliable satellite altimeter data, properly examined data from tide gauges and other sources such as coastal morphology, stratigraphy, radiocarbon dating, archaeological remains, and historical documentation indicate a lack of any alarming sea-level rise in recent decades for all the Indian Ocean.
The new alignment of the data 1878–1936 and 1937–1994 seems by far superior to the one proposed by PSMSL. The aligned metric data 1878–1994 show a trend of − 0.05 mm/year, i.e., nearly perfect stability.

Stable Sea Levels Are Transformed Into Positive Trends Via Arbitrary Adjustments To Past Data
What is proposed as a single record in databases such as the Permanent Service for Mean Sea Level (PSMSL) is often the composition of data collected by different instruments, sometimes in different locations or over different time windows, with significant gaps in between one measurement and the others.  … While adjustments are certainly necessary to produce a tide gauge record that may be analysed to infer a trend of the local relative sea level, the way that the alignment is performed may introduce rising or decreasing trends even where the true sea level is oscillating without any trend. How can we perform a proper alignment of data when there are gaps of years and the tide gauge has been moved, destroyed, or replaced?

This is the case of the Aden, Yemen tide gauge that is the only tidal location of the Arabian Peninsula spanning a time window long enough to infer a trend and acceleration of the relative sea level (assuming there was continuous measurement and no quality issue). In Aden, similar to Karachi and Mumbai and other tide gauges of the area, a single-tide gauge record is the result of multiple sets of data subjectively coupled together. While a new tide gauge is recording since about 2007, the alignment of the previous data is continuously changing.
The sea levels in India, including Mumbai, and in Karachi, Pakistan, have been recently analysed and discussed in Parker and Ollier (2015) and in Parker (2016). In both cases, it was shown that the latest positive trends in the PSMSL RLR [revised local reference, adjusted] data are only the result of arbitrary alignments, and alternative and more legitimate alignments reveal very stable sea-level conditions.
The metric (raw) data show misaligned results. The metric data are the data as originally provided, or suffering from historical adjustments. What are more dangerous are the corrections recently introduced to the past to magnify the sea-level trend or the acceleration. As shown in the prior section, the adjustments introduced by PSMSL to make the RLR [revised local reference, or adjusted data] are arbitrary in Aden, Karachi, and Mumbai.
It is always highly questionable to shift data collected in the far past without any proven new supporting material. In the case of Aden, we analyse the PSMSL alignments starting from the unaligned metric data, introducing possible break-points when there has been a change of tide gauge or there has been a suspicious alignment, and enforcing break-point alignment when connecting sets of data spanning sufficiently long-time windows.
While the metric data do not tell us, which is the correct trend, they tell us that the alignments made to produce the RLR [revised local reference, or adjusted data] are very likely wrong, because they are inconsistent with the individual measurements components, none of which showing any sign of increasing sea levels, and because the adjustments are always in the direction to produce a large rise in sea level.

Examples Of Stable/Negative Sea Level Trends Re-aligned To Create Positive Trends
Realignments of past data and addition of new data possibly misaligned have, therefore, increased the trend to + 3.02 mm/year from + 1.21 mm/year.
Differences with prior studies in the literature based on data sets not available any more are even more striking.  Pirazzoli (1986) noticed that the record for Mumbai between 1952 and 1962 reversed the entire rising trend for the previous 30 years.  Per Douglas (1991), the sea-level trend in Mumbai over the time window 1930–1980 was negative, − 0.3 mm/year.  In the latest PSMSL RLR, over the same time window, it is + 0.52 mm/year.
The RLR data for Aden, Yemen, show that the misaligned measurements have been composed to produce a high trend, high acceleration record. After the latest PSMSL corrections and addition to generate the RLR data, there is a trend of + 1.28 mm/year and a large acceleration of + 0.0164 mm/year2 in the 134 years long but 50% complete tide gauge record.
Within the short time window 1937–1969, the trend has been increased to + 2.60 mm/year from the + 1.89 mm/year of the previously misaligned data. One would have expected the data 1937–1956 to be shifted up vs. the data 1957–1969. The adjustment has done just the opposite, and the data are being shifted down. Similarly, the data before 1937 have all been shifted down. The data collected since 2007 have not been moved vs. the data collected 1957–1969.
Notice especially that the data 1878–1936 are closed by the December month, and the data 1937–1994 start with the January month, so there is virtually no time gap, yet there is a 677-mm sudden difference between the measurements collected before and after the so-called break-point. From the raw data, Mumbai exhibits a very small rate of rise since 2005. If we look at the metric raw data, we may notice that the trend 1878–1936 is a + 0.60 mm/year, while the trend 1937–1995 is largely negative, − 0.72 mm/year. Combining the two trends, one would expect over the longer time window 1878–1936 a small negative trend.
In the RLR data, the small negative trend 1878–1995 is transformed [into] a + 0.68 mm/year positive trend, that with the latest data 2005–2011 further increases to + 0.80 mm/year.
Karachi seems to suffer from the same issues as Aden, with four misaligned sets of data: 1916–1920; 1937–1948; 1957–1995; 2007–2014.  These data show individually very little rise, and a lowering in the longest continuous record. Then, the RLR has a large trend introduced by arbitrary alignment. The metric trend 1957–1995 is negative, − 2.67 mm/year. In the RLR, the trend 1916–2014 is now + 1.85 mm/year. This is the result of the measurements 1916–1920 having been shifted down, the data 1937–1948 shifted down vs. 1957–1995, and the data from the novel tide gauge relocated in another place claimed to be aligned with the old tide gauge.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterI was a bit hesitant to write about this because it could lead to trouble for the person with the courage to speak up. After all, we’d hate to see riots, violence and rabid fits of shouting.
But the good fight must be fought, and we must never be forced into silence – even when our livelihoods depend on it.
German Parliamentarian and physicist Dr. Philipp Lengsfeld of Angela Merkel’s (once) conservative CDU party gave a short talk last year at the 10th IKEK international climate and energy conference late last year in Berlin.

Dr. Lengsfeld, the son of human rights, anti-Communism activist Vera Lengsfeld, sees the green movement for what it really is: an oppressive system designed to strip the individual liberties from citizens.
Skeptics, EIKE, doing “a service to science and democracy”
The European Institute fro Climate and Energy, which co-hosted the conference and posted the video, wrote:
He compares the ideals of communism to those of the climate rescue ideology, namely rescuing mankind from itself and leading it collectively to paradise conditions – if only it would surrender its rights and the dignity of individualism. Both of these can be achieved only by dictatorship and Lengsfeld calls them criminal – even with respect to those stated in climate ideology.”
At the 1:50 mark he thanks EIKE and reminds the audience that “science and democracy thrive from the same basis: freedom, creativity and competition”…
Autocracy, on the other hand, lives from conformity, solidarity and brutal selfishness when it comes to asserting their own interests. Therefore it is totally clear to me that you are performing a service to science and to democracy.” And for that my deepest thanks.”
He then adds that the skeptics are indeed “up against an autocratic system” of the likes of the former Communist regimes and that there are in fact many similarities between the climate movement and the communist regimes.
Climate science a dangerous mixture of dogma


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




He warns that the climate science is fraught with “belief and dogma“, what he calls “a very dangerous mixture“. He adds that although renewable energy sources have positive points, we now find ourselves in “a system of dogmas that has become complete certainty and that any thing else is wrong“.
He says that Germany’s attempt to be a leader in renewable energy has completely missed the target and has failed.
We are surrounded by interest-driven dogmatists who have staked a claim on morality and belittled anyone who challenges.”
His advice to skeptics on this is to continue doing what we are doing, but warns:
Please stay scientific. Do not make the mistake of multiplying everything by minus one. That is not going to work. You may get some short term success here and there, but I think it is not the right strategy.”
Let’s get loud
He then calls “evidence-driven policy” and illusion:
If you are honest, policymaking means evidence considering. […] Evidence-driven implies already an eternal truth, it already implies that one sole solution is needed and that it is only necessary to give it to the Parliamentarians and insist that it is what you have to do and everything will be fine. But it doesn’t work that way. That’s not how the world is. That is not how people are. That’s not how science is.”
Lengsfeld advises skeptics to continue with a “fair discussion, a balanced discussion, but certainly not with a quiet discussion“.
Lengsfeld is optimistic, and believes the skeptics actually will have an easy time because the opponents have “run afoul.”
Look like “idiots”
Lengsfeld believes that climate science likely will go the same way as continental drift, where continents were once believed to be fixed on the globe, and that Alfred Wegener was eventually proven to be correct by claiming they were moving. Today, Lengsfeld said, everyone says that the scientists insisting on static continents now look like “idiots.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterLearning from the climate’s history: the Arctic heat waves of the 1930s and 40s
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
[German text translated/edited by P Gosselin]
Climate alarm at the World Meteorological Organisation (WMO) was reported on 21 March 2017 at the German online derwesten.de:

Heat waves in the Arctic – climate scientists sound the alarm
[…] During the winter in the Arctic temperatures reached near the melting point. It wasn’t the only weather extreme that climate scientists reported on. Such a heat wave occurred in the Arctic at least three times at the start of 2017, so reported the World Weather Organisation (WMO) in Geneva. Mighty Atlantic currents had delivered warm, moist air to the Arctic. At the peak of winter in the period when it should be freezing, temperatures reached near freezing on some days. The polar jet stream – a wind current that circles the planet at high altitudes – thus impacts the global weather.”

Do we really find ourselves on the verge of disaster? Is it getting hotter and hotter in the Arctic?
Let’s look at the HadCRUT4 temperatures in Arctic (Fig. 1). One clearly sees the warming phase of 1990-2005. Before and after that there were a bit wavy temperature plateaus. There hasn’t been any significant warming in the Arctic in 10 years.

Fig. 1: Arctic temperature since 1957. Data: HadCRUT4, Chart: Climate4You.
Now let’s extend the time scale and look back 100 years. What a surprise: In the 1930s and 1940s there were two heat decades in the Arctic which were almost as warm as today (Fig. 2). This is just a small fact that went missing in the WMO press release and in the derwesten.de article.

Fig. 2: Arctic temperature since 1920. Data: HadCRUT4, Chart: Climate4You.
The earlier Arctic heat years are impressive when we look at the temperature plot of the island city of Akureyri (Fig. 3):


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Fig. 3: Temperature plot of the Arctic location of Akureyri since 1880. Source: NASA/GISS.
Now what could have caused it to warm up in the 1930s and 1940s? Here it is enough to look back at the 60-year Atlantic Multidecadal Oscillation (AMO). This is easily done at the NOAA website (Fig. 4).

Figure 4: AMO
The curves at Wikipedia or elsewhere are perhaps more colorful, but they often don’t include the last years. The main drive behind the Arctic warming of the 1990s and 2000s was the simultaneously strong rise in the AMO.
The heat waves reported by the WMO happen to fit very well with the current high plateau of the AMO (Fig. 4). You don’t need to be a fortune teller to realistically estimate what remains ahead: the AMO plateau could continue for a few more years. A continued massive warming is not expected because the AMO peak has already been reached.
Eventually sometime in the coming years the drop in the AMO will begin. And correspondingly so will the Arctic temperatures . A look back at the climate history really pays off.
Winston Churchill long knew:

The further one looks back in the past, the further one sees into the future.

Some day the ladies and gentlemen at the news media will realize this. The art of fact-checking seems to have been left on the wayside since the invention of the copy-and-paste function.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterPlenty of superlatives have been used to describe President Donald Trump’s speech to the nation on Februrary 28.
Fox News called it “one for the ages” as the newly elected President spoke on a wide range of pressing issues and daunting problems the nation faces, like immigration, drugs, crime, runaway debt, urban decay, economic stagnation, over-regulation, education, terrorism…to name a few.

Not among the pressing issues was “climate change”. Not once did the President bring up the issue, which some on the opposition side have long been calling “the greatest threat to civilization“.
What can we gather from this as the President undertakes to work hard to mobilize and find the scrace resources needed to fix the out of control messes Washington has created over the past couple of decades? Expect the President to (finally) take the chainsaw to government programs promoting the climate hoax.
First place to start is to cut off the money pipeline to the non-problems and to divert it over to the matters that are really pressing, i.e. real problems mentioned above. The President thinks very little of climate change being a problem, and so did not mention it once. Rather, he mentioned coal and growth.
The climate scare and hoax are about to lose their last legs.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAfter days of uncertainty, Hurricane Matthew finally took a track taking it directly to Florida. It’s the first major category hurricane to hit the sunshine state (and the US, if I’m not mistaken) in almost 11 years.
The last major hurricane to strike was Wilma in 2005. This 4000-day hiatus is a record since hurricane statistics began to be recorded in the 19th century. This all flies in the face of claims made by global warming believers and alarmists, who crystal-balled hurricane activity would become more frequent and ferocious over time. Yet, globally there has been no trend in global cyclone activity.
The reality is that Matthew will be the first major hurricane to hit that millions of children 12 years old and under can remember. And already no child on the planet under 18 years of age has seen any real global warming at all. Climate scientists could not have been more wrong.
Many more hurricanes when CO2 was low!
Veteran meteorologist Joe Bastardi at Weatherbell reminds us that hurricane activity was far worse in Florida some 70 years ago, in the 1940s, back when atmospheric CO2 concentrations were down near the 310 ppm level:

6 major hurricanes in 7 years with CO2 at 310 ppm!
Count them! Six major hurricanes in only 7 years. Imagine the hysteria if that were to happen during the present time. Instead we are getting the first one in over 10 years – an unusual period of calm.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Clearly this tells us that there’s a heck of a lot more to it than just a trace gas. Of course ocean and solar cycles are the major climate factors.
Everyone’s prepared – except for Trump!
The table is already being set for the upcoming Presidential debate. And I’m ready to bet my last dollar that Trump is going to fall in the trap and make a terrible impression like he did in the first debate. The trap this time: climate change and Hurricane Matthew.
Hollywood megastar Leonardo DiCaprio has already launched it by declaring that anyone who denies climate change is unfit for public office. Hurricane Matthew is now slamming into Florida, and Hillary Clinton is already blaming it on man. The timing just before the debate couldn’t be better. The debate is already rigged: It is going to feature climate change prominently, and Hillary is being prepared well for it. They are going to make Trump look like an uninformed fool – if he allows it.
Trump can avoid this:
1. He has to acknowledge that climate is always changing.
2. Man, however, is playing only a small role.
3. 97% consensus is phony – the science is hotly disputed.
4. Already 750 published papers since 2014 dismissing catastrophic AGW.
5. Temperature trend is far below what scientists projected in 2000.
6. Fact: NASA’s Gavin Schmidt has been altering the historic data.
7. Hurricanes are less frequent today then they were 50, 60 years ago.
He should then ask Hillary directly: Can you honestly promise less storms and nice weather in exchange for more regulation and taxes? If so, then she’s a weather charlatan.
It should take Trump about 60 seconds to say this. But, expect him to come in unprepared and to babble a bunch a nonsense and look bad.
In this debate I expect to see Trump fumble in his own end-zone. You just watch.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWind turbines are ugly, litter the landscape, endanger wildlife, generate erratically, destabilize power grids and even cause health problems. They also have a habit of coming apart and self destructing — thus creating a hazard to persons and property.
The Saxony online daily Sächsische Zeitung (SZ) here reports how a wind turbine collapsed near Leisnig just days ago. An investigation revealed how one of three blades failed catastrophically, thus creating a huge imbalance that caused the tower to buckle 15 meters above the ground and led to the structure to come crashing down. The site reports:
Through the force of the impact, the gearbox unit was driven almost 2 meters into the earth.”
The following short video surveys the damage. Note how one blade had totally come apart.

Earlier in December, Germany’s BILD daily reported how in the Mecklenburg Pommeria town of Süderholz a wind turbine tower snapped in half and crashed to the ground. An investigation is now underway. Süderholz mayor Alexander Benkert ordered the other remaining turbines to be thoroughly inspected.
Bild reports the tower simply snapped 25 meters up but that no one was injured.
Collapsing even when not in operation
In neighboring Denmark one wind turbine shows us that turbines can come apart even when they are not operating. Danish vejr.tv2.dk television site here reports how the blade of one turbine simply “tore off” during a recent storm.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Also here the English Manchester Evening News here reports how a recent storm ripped off all three blades from a turbine one afternoon in England, almost killing a man who happened to be taking his dog for a walk.
Mounting opposition to ugly, unreliable wind power projects
The seemingly collapse-prone turbines are likely yet just another reason on a long list why people now resist them. Once welcome and viewed as a source of clean energy, huge protests are now organizing and mobilizing against wind park projects. Germany’s online nordkurier.de here reports how an online survey found only 15% were in favor of installing more turbines in the Uckermark region.
In the Rhine-Main region, the Frankfurter Neue Presse (FNP) reports on how authorities in Darmstadt recently rejected the building of wind turbines on the Taunuskamm mountain, citing “groundwater protection” needs. The local Green Party, of all people, fumed at the rejection.
Sabotage
The resistance to wind energy in Germany has grown to such an extent that some people are now sabotaging them. In Fulda a person, or persons, broke into a tower and destroyed the electrical gear, causing the unit to halt. The wind park operator suspects wind energy opponents.
First the suspect(s) had on two earlier occasions stopped the turbine by simply pressing the emergency STOP button. In the third attempt on December 26 the switchbox was opened and its contents destroyed. The online Fuldaer Zeitung writes at the end of the article:
Indeed the opposition against further wind turbines in the Eiterfeld area was large in the past.”
Wind energy in Germany is no longer welcome.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSchneefan at his excellent German climate and weather site wobleibtdieerderwaermung.de here reports that Arctic sea ice has grown in mass recently, defying the doomsday scenarios that a re-hyperventilating Al Gore has been hawking lately.
Schneefan writes that Arctic sea ice volume at the start of August at about the mean of the 2004 – 2013 values (see black line below in chart).

Source: http://polarportal.dk/en/havisen-i-arktis/nbsp/sea-ice-extent/
The current ice volume is well above that seen in the previous two years, 2015 and 2016. Greenland surface mass balance also shows significantly more snow and ice this year.
Arctic summer melt slows down
Arctic sea ice area at the end of July 2017 showed an unusual levelling off (curve correction?), as indicated by the red curve inside the black circle in the following chart and thus shows a far less likelihood of setting a new low, which a number of experts had been speculating earlier this year.

Source: arctic-roos.org/observations/ice-area-and-extent-in-arctic
Another point is central Arctic sea ice extent, which in 2017 was at the highest July level in 2017 seen in the past 5 years, Schneefan points out:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Source: nsidc.org/data/masie/masie_plots
After a mild winter, Arctic temperatures north of 80°N latitude have been below normal since April, according to data and he chart by by the Danish Meteorological Institute (DMI) below.

With this development in mind, Schneefan writes that Arctic sea ice extent is virtually unchanged since 2006/2007, and:
There is nothing to the almost ice-free Arctic projections by 2016 at the latest and the ridiculous prognoses made by Al Gore and Peter Wadhams!”
2-m surface temperature satellite data of Antarctica in the following chart showed a sub-cooled South Pole in July, 2017 (left) and also in June 2017 (right):


South polar temperature anomaly for July (left) and June (right) 2017 with respect to the WMO 1981-2010 mean. The circle indicates the area of the Larsen C Ice Shelf where a large chunk of ice broke off due to calving recently. Source: www.karstenhaustein.com/climate.php.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWe often hear claims from the media of how president-elect Donald Trump unfairly got help from Vladimir Putin and the Russians to win the election, and that it’s outrageous a foreign government would meddle with and influence the US political process. (Never mind these allegations continue to be based on practically nothing.)

Germany’s Federal Ministry for the Environment donated between $1 million and $5 million to the Clintons during the third quarter of 2016. 
And just days ago Germany’s CDU and CSU parties issued a warning to Russia not to interfere with the affairs and political processes in other countries, especially as Germany prepares for next year’s national election.
Surprise: it turns out that if any country has been attempting to skew the US election, it is Germany itself.
The country’s Federal Ministry for the Environment, a powerful arm of the German government, is reported here to have made a donation to the tune of 1 – 5 million dollars to the Clinton Foundation in the third quarter of 2016, i.e. right at the very peak of the presidential campaign.
Daniel Wetzel at the online national daily Die Welt here reports:
According to a donor list from the ‘Clinton Foundation’ the Ministry transferred between 1 million and 5 million dollars.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Wetzel asks:
Why does Germany have to finance the US election campaign?”
The donation has come under fire from critics — Wetzel writes — such as former parliamentarian Vera Langenfeld at her blog:
Why is a German federal ministry supporting the election campaign of an American candidate? Obviously the German taxpayers have to finance Hillary Clinton’s campaign without their knowledge of it.”
The Ministry, however, denies the charge of having meddled with the US election, stating that it “fundamentally does not make donations” and that the money was for financing projects “within the scope of international climate protection”.
However, the timing of the donation makes the appearance all the more dubious. During the campaign, Clinton was attacked massively by Trump for the huge and frequent donations coming from an array of outside special interests. Trump went on to accuse Clinton of being up for sale.
Overall the German government and press have been openly hostile to Donald Trump’s election victory. In the current Trump-German relations, it has to be said that Germany drew first blood by unfairly smearing Trump as a racist, misogynist and an out-of control rabble-rouser, and refusing to congratulate him or to give him a chance.
As it stands, there’s no reason for Trump to be extend the hand of friendship to the German government, or especially to the media. Germany enjoys a huge trade deficit with the USA and so don’t be surprised if Trump answers by luring German industry to America by offering lower taxes, less red tape and far cheaper energy. Already German electricity rates are approximately three times higher than those in USA.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterRecent SRF German public broadcasting commentary on climate change has reached a new low in quality and new high in activism, two respected German scientists say. 
=============================================
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(Text translated/edited by P Gosselin)
“Climate-alarm propaganda day”
November 29, 2017, was once again a climate alarm propaganda day in the German public television and radio stations of SRF (Süddeutsche Rundfunk). But it was even more shocking to see the primitive level of argumentation used there to fan fear among the public. For example this video clip here, designed to refute climate skeptics, unfortunately in fact represents an intellectually subterannean SRF alarmism theater, which uses arguments as a “hammer against skeptics”.
1) Shrinking mountain glaciers
Bingo. Yet no one is challenging that it has been getting warmer since the end of the Little Ice Age beginning in 1850. But why was nothing said about how the melting glaciers of today are uncovering tree trunks from even warmer periods of the Holocene and that as a result the glaciers back then were at much higher elevations and smaller in size than they are today?
2) Climate change was not invented by the Chinese
OMG! – just recently – and was that meant for real?
3) There has been no climate change pause
However the diagram ends at the peak of the last El Nino of 2016. The decrease in temperature since then and the term El Nino are not mentioned at all in the explanation.
4) The polar bears are doing just fine
…but they are really not doing okay because of the supposedly melting ice. The chart shown interestingly looks only at a few areas where the numbers are expected to fall, and ignores the fact that the populations have developed normally or well over the recent years, despite the reduced ice coverage.
5) Skeptical scientists are only 12% environmental scientists
…who according to the SRF are the only ones who should speak up publicly on the matter, and only 0.1% are climate scientists. More than 90% however are convinced climate alarmists. Missing here is only the famous 97% from Cook et al. Here we suspect that the word got around even at SRF studios that the magical 97 percent figure is a merely senseless bogus number…
The manipulative character of the agitation is demonstrated by the fact that the most important arguments held by climate skeptics find no mention whatsoever, for example the fluctuating long-term solar activity in combination with the amplification mechansim as to Svensmark, the oscillating ocean currents on decadal scales , the obviously hyped CO2 climate sensitivity in the IPCC models, the refuted water vapor feedback and – last but not least – the inability by the CO2 alarmists to successfully model the strong natural variations of the Holocene climate.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
A Human Influence On Precipitation
 ‘Has Yet To Be Detected’

“Climate model output suggests decreasing rainfall as a consequence of anthropogenic greenhouse gas radiative forcing.”
“[I]f anthropogenic forcing has impacted the [regional rainfall pattern], the signal has yet to be detected above the level of natural climate variability.” – Lachniet et al., 2017

According to climate models, precipitation trends were supposed to have intensified as a consequence of human activity.
And yet after compiling decades of observational and proxy (paleoclimate) evidence, it has been determined there has been no detectable global-scale human influence on rainfall patterns in the last hundred years (even hundreds of years).  Instead, any variability in the hydrological cycle can be strongly linked to non-anthropogenic forcing mechanisms, namely solar activity and natural oceanic/atmospheric oscillations (NAO, PDO, AMO, ENSO).

Miralles et al., 2013
The hydrological cycle is expected to intensify in response to global warming. Yet, little unequivocal evidence of such an acceleration has been found on a global scale. This holds in particular for terrestrial evaporation, the crucial return flow of water from land to atmosphere. Here we use satellite observations to reveal that continental evaporation has increased in northern latitudes, at rates consistent with expectations derived from temperature trends. However, at the global scale, the dynamics of the El Niño/Southern Oscillation (ENSO) have dominated the multi-decadal variability. 

Modern Precipitation Trends Similar To Past Centuries

Verdon-Kidd et al., 2017
Overall, the inter-annual and inter-decadal variability of rainfall and runoff observed in the modern record (Coefficient of Variation (CV) of 22% for rainfall, 42% for runoff) is similar to the variability experienced over the last 500 years (CV of 21% for rainfall and 36% for runoff). However, the modern period is wetter on average than the pre-instrumental (13% higher for rainfall and 23% higher for runoff). Figure 9 also shows that the reconstructions contain a number of individual years (both wet and dry) of greater magnitude than what has been recorded in the instrumental record.


Kostyakova et al., 2017
A nested July–June precipitation reconstruction for the period AD 1777–2012 was developed from multi-century tree-ring records of Pinus sylvestris L. (Scots pine) for the Republic of Khakassia in Siberia, Russia. … The longest reconstructed dry period, defined as consecutive years with less than 25th percentile of observed July–June precipitation, was 3 years (1861–1863). There was no significant difference in the number dry and wet periods during the 236 years of the reconstructed precipitation.


Shi et al., 2017
Five of the six coupled ocean-atmosphere climate models of the Paleoclimate Modeling Intercomparison Project Phase III (PMIP3), can reproduce the south-north dipole mode of precipitation in eastern China, and its likely link with ENSO. However, there is mismatch in terms of their time development. This is consistent with an important role of the internal variability in the precipitation field changes over the past 500 years.


Conroy et al., 2017
20th century precipitation variability in southern Tibet falls within the range of natural variability in the last 4100 yr, and does not show a clear trend of increasing precipitation as projected by models. Instead, it appears that poorly understood multidecadal to centennial internal modes of monsoon variability remained influential throughout the last 4100 yr. … Until we have a predictive understanding of multidecade to multi-century variability in the Asian monsoon system, it would be wise to consider the risk of prolonged periods of anomalously dry and wet monsoon conditions to be substantial (Ault et al., 2014). Such variability may also explain why the predicted anthropogenic increase in Asian monsoon precipitation is not widely observed.

Clarke et al., 2017
Corresponding ~4-8 year periodicities identified from Wavelet analysis of particle size data from Pescadero Marsh in Central Coast California and rainfall data from San Francisco reflect established ENSO periodicity, as further evidenced in the Multivariate ENSO Index (MEI), and thus confirms an important ENSO control on both precipitation and barrier regime variability.


McCabe et al., 2017
In this study, a monthly water-balance model is used to simulate monthly runoff for 2109 hydrologic units (HUs) in the conterminous United States (CONUS) for water-years 1901 through 2014. … Results indicated that … the variability of precipitation appears to have been the principal climatic factor determining drought, and for most of the CONUS [conterminous US], drought frequency appears to have decreased during the 1901 through 2014 period.

Lachniet et al., 2017
[M]onsoon dynamics appear to be linked to low-frequency variability in the ENSO and NAO, suggesting that ocean-atmosphere processes in the tropical oceans drive rainfall in Mesoamerica. … Climate model output suggests decreasing rainfall as a consequence of anthropogenic greenhouse gas radiative forcing (Rauscher et al., 2008; Saenz-Romero et al., 2010). Our data show, however, that the response of the monsoon will be strongly modulated by the changes in ENSO and the NAO mean states … Our data also show that the magnitude of Mesoamerican monsoon variability over the modern era when the anthropogenic radiative forcing has dominated over solar and volcanic forcings (Schmidt et al., 2012) is within the natural bounds of rainfall variations over the past 2250 years. This observation suggests that if anthropogenic forcing has impacted the Mesoamerican monsoon, the signal has yet to be detected above the level of natural climate variability, and the monsoon response to direct radiative forcing and indirect ocean-atmosphere forcings may yet to be fully realized.

Past, Modern Precipitation Patterns Modulated By Solar Forcing

Lei et al., 2017
The precipitation variability on decadal to multi-centurial generally always reflects changes in solar activity and large-scale circulation, e.g., the ENSO and the EASM [East Asian Summer Monsoon] (Chen et al., 2011; Vleeschouwer et al., 2012; Feng et al., 2014). [D]uring the MWP [Medieval Warm Period], the wetter climate in this region was consistent with more frequent ENSO events, stronger EASM and higher solar activity, whereas the opposite was found for the LIA. In particular, d13Cac fluctuations on multi-decadal to centennial scales is consistent with the changes in solar activity, with fewer dry intervals corresponding to periods of minimum solar activity within dating errors, which are referred to as the Oort Minimum (AD 1010-1050), Wolf Minimum (AD 1280-1340), Sporer Minimum (AD 1420-1530), Maunder Minimum (AD 1645-1715) and Dalton Minimum (AD 1795-1820).


Warrier et al., 2017
Climatic periodicities recorded in lake sediment magnetic susceptibility data: Further evidence for solar forcing on Indian summer monsoon … The results obtained from this study show that solar variations are the main controlling factor of the southwest monsoon.

Zhang et al., 2017
The frequencies represent the influence of the Pacific Decadal Oscillation (PDO) and solar activity on the precipitation from the southwestern United States. In addition, solar activity has exerted a greater effect than PDO on the precipitation in the southwestern United States over the past 120 years. By comparing the trend of droughts with the two fundamental frequencies, we find that both the droughts in the 1900s and in the 21st century were affected by the PDO and solar activity, whereas the droughts from the 1950s to the 1970s were mainly affected by solar activity.

Munz et al., 2017
Decadal resolution record of Oman upwelling indicates solar forcing of the Indian summer monsoon (9–6 ka) … We use geochemical parameters, transfer functions of planktic foraminiferal assemblages and Mg /  Ca palaeothermometry, and find evidence corroborating previous studies showing that upwelling intensity varies significantly in coherence with solar sunspot cycles. The dominant  ∼  80–90-year Gleissberg cycle apparently also affected bottom-water oxygen conditions.

Zhai, 2017
The time series of sunspot number and the precipitation in the north-central China (108° ∼ 115° E, 33° ∼ 41° N) over the past 500 years (1470–2002) are investigated, through periodicity analysis, cross wavelet transform and ensemble empirical mode decomposition analysis. The results are as follows: the solar activity periods are determined in the precipitation time series of weak statistical significance, but are found in decomposed components of the series with statistically significance; the Quasi Biennial Oscillation (QBO) is determined to significantly exist in the time series, and its action on precipitation is opposite to the solar activity; the sun is inferred to act on precipitation in two ways, with one lagging the other by half of the solar activity period.

Sun et al., 2017
[A]t least six centennial droughts occurred at about 7300, 6300, 5500, 3400, 2500 and 500 cal yr BP. Our findings are generally consistent with other records from the ISM [Indian Summer Monsoon]  region, and suggest that the monsoon intensity is primarily controlled by solar irradiance on a centennial time scale.

Zhu et al., 2017
Abrupt enhancements in the flux of pedogenic magnetite in the stalagmite agree well with the timing of known regional paleofloods and with equatorial El Niño−Southern Oscillation (ENSO) patterns, documenting the occurrence of ENSO-related storms in the Holocene. Spectral power analyses reveal that the storms occur on a significant 500-y cycle, coincident with periodic solar activity and ENSO variance, showing that reinforced (subdued) storms in central China correspond to reduced (increased) solar activity and amplified (damped) ENSO. Thus, the magnetic minerals in speleothem HS4 preserve a record of the cyclic storms controlled by the coupled atmosphere−oceanic circulation driven by solar activity.

Zielhofer et al., 2017
Western Mediterranean Holocene record of abrupt hydro-climatic changes … Imprints of North Atlantic meltwater discharges, NAO and solar forcing …Early Holocene winter rain minima are in phase with cooling events and millennial-scale meltwater discharges in the sub-polar North Atlantic. … [A] significant hydro-climatic shift at the end of the African Humid Period (∼5 ka) indicates a change in climate forcing mechanisms. The Late Holocene climate variability in the Middle Atlas features a multi-centennial-scale NAO-type pattern, with Atlantic cooling and Western Mediterranean winter rain maxima generally associated with solar minima.

Matveev et al., 2017
An increase in atmospheric moisture for the warm period of the year (May–September) since 1890s, and mean annual temperatures since the 1950s was identified. During the same time period, there was a marked increase in amplitude of the annual variations for temperature and precipitation. … These fluctuations [atmospheric moisture, mean annual temperatures] are consistent with 10–12-years Schwabe–Wolf, 22-years Hale, and the 32–36-years Bruckner Solar Cycles. There was an additional relationship found between high-frequency (short-period) climate fluctuations, lasting for about three years, and 70–90-years fluctuations of the moisture regime in the study region corresponding to longer cycles.

Luthardt and Rößler
The 11 yr solar cycle, also known as Schwabe cycle, represents the smallest-scaled solar cyclicity and is traced back to sunspot activity (Douglass, 1928; Lean, 2000), which has a measurable effect on the Earth’s climate, as indicated by the Maunder minimum (Usoskin et al., 2015). Global climate feedback reactions to solar irradiance variations caused by sunspots are complex and hypothesized to be triggered by (1) variation in total energy input (Cubasch and Voss, 2000), (2) the influence of ultraviolet light intensity variation on composition of the stratosphere (Lean and Rind, 2001), (3) the effect of cosmic rays on cloud formation (Marsh and Svensmark, 2000; Sun and Bradley, 2002), and/or (4) the effect of high-energy particles on the strato- and mesosphere (Jackman et al., 2005). …  [L]ike today, sunspot activity caused fluctuations of cosmic radiation input to the atmosphere, affecting cloud formation and annual rates of precipitation.

Park, 2017
[S]olar activity drove Holocene variations in both East Asian Monsoon (EAM) and El Niño Southern Oscillation (ENSO).

Shi et al., 2017
Our results imply that the synchronous change in the Asian–Australian monsoon may be caused by inherent solar variations, further strengthening previous findings.

Past, Modern Precipitation Patterns Modulated By AMO/PDO/NAO/ENSO

Macdonald and Sangster, 2017
Statistically significant relationships between the British flood index, the Atlantic Meridional Oscillation and the North Atlantic Oscillation Index are identified. The use of historical records identifies that the largest floods often transcend single catchments affecting regions and that the current flood-rich period is not unprecedented. … Solar forcing can manifest itself in a variety of different ways on flood patterns through modification of the climate (Benito et al., 2004). Several series indicated increased flood frequency during the late eighteenth century corresponding to the Dalton Minimum (AD 1790–1830), with notable flooding across catchments in the 8-year period AD 1769 1779, which was a climatic period considered to include the sharpest phases of temperature variability during the “Little Ice Age” (Lamb, 1995; Wanner et al., 2008).

Malik et al., 2017
[W]e investigate the impact of internal climate variability and external climate forcings on ISMR on decadal to multi-decadal timescales over the past 400 years. The results show that AMO, PDO, and Total Solar Irradiance (TSI) play a considerable role in controlling the wet and dry decades of ISMR [Indian summer monsoon rainfall]. Resembling observational findings most of the dry decades of ISMR occur during a negative phase of AMO and a simultaneous positive phase of PDO.

Valdés-Pineda et al., 2017
This study analyzes these low-frequency patterns of precipitation in Chile (>30 years), and their relationship to global Sea Surface Temperatures (SSTs), with special focus on associations with the Pacific Decadal Oscillation (PDO) and the Atlantic Multi-decadal Oscillation (AMO) indices. … We conclude that a significant multi-decadal precipitation cycle between 40 and 60 years is evident at the rain gauges located in the subtropical and extratropical regions of Chile. This low-frequency variability seems to be largely linked to PDO and AMO modulation.

Reischelmann et al., 2017
We document that long-term patterns in temperature and precipitation are recorded in dripwater patterns of Bunker Cave and that these are linked to the North Atlantic Oscillation (NAO).

Lapointe et al., 2017
This paper investigates an annually-laminated (varved) record from the western Canadian Arctic and finds that the varves are negatively correlated with both the instrumental Pacific Decadal Oscillation (PDO) during the past century and also with reconstructed PDO over the past 700 years, suggesting drier Arctic conditions during high-PDO phases, and vice versa. These results are in agreement with known regional teleconnections, whereby the PDO is negatively and positively correlated with summer precipitation and mean sea level pressure respectively.

Lim et al., 2017
Our study demonstrated that flood frequency and climate changes at centennial-to-millennial time scales in South Korea have been coupled mainly with ENSO activity, suggesting that the hydrologic changes, including flooding and drought, in East Asia are coupled to the centennial-to-millennial-scale atmospheric-oceanic circulation changes represented by the ENSO pattern.

Reynolds et al., 2017
Evidence derived from instrumental observations suggest that Atlantic variability, associated with changes in SSTs and fluctuations in the strength of the Atlantic Meridional Overturning Circulation (AMOC), is directly linked with broader scale climate variability, including Brazilian and Sahel precipitation (Folland et al., 1986 and Folland et al., 2001), Atlantic hurricanes and storm tracks (Goldenberg et al., 2001 and Emanuel, 2005), and North American and European temperatures (Sutton and Hodson, 2005, Knight et al., 2006 and Mann et al., 2009).

Park et al., 2017
According to our results, the central Mexican climate has been predominantly controlled by the combined influence of the 20-year Pacific Decadal Oscillation (PDO) and the 70-year Atlantic Multidecadal Oscillation (AMO).

Bianchette et al., 2017
Seven periods of increased water level, varying in duration, occurred during the backbarrier period, with El Niño-Southern Oscillation (ENSO) likely the main climatic mechanism causing these periodic shifts in the paleo-precipitation levels. We suggest that the deepest water levels detected over the last ~3200 years correlate with periods of increased ENSO activity.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterModern ‘Science’ Blames Humans 
For California Weather…If It’s Bad

Image Source: Cook et al., 2010

In the present era of agenda-driven journalism, major news outlets often attempt to persuade readers that weather events occurring now have never happened before…and they are worsened by human-caused climate change.

In 2015, Humans Caused Drought, Too Little Rainfall In California

Global Warming Brought on California’s Severe Drought
Humans to Blame for Catastrophic Drought in California, Scientists Say
Study: Human-caused global warming behind Calif. drought
Long-suffering California can blame drought on global warming, experts say
“Scientists predict that “enhanced drought” will continue in California throughout this century because global warming has ‘substantially increased’ the likelihood of extreme droughts in the state.”

In 2017, Humans Causing Floods, Too Much Rainfall In California

Heavy California rains par for the course for climate change
With Climate Change, California Is Likely To See More Extreme Flooding
GLOBAL WARMING MEANS CALIFORNIA WILL SEE A LOT MORE ‘PINEAPPLE EXPRESS’ [RAIN]STORMS
Bill Nye Blames Global Warming For Devastating Floods In Northern Cali

Even the editor of the prominent scholarly journal Science has just claimed that the abundance of rainfall in California is now a trend brought on by human-caused climate change.  Since when is a 7-month precipitation record a trend?
Science (June 30, 2017) – Estimating economic damage from climate change
“Episodes of severe weather in the United States, such as the present abundance of rainfall in California, are brandished as tangible evidence of the future costs of current climate trends.”


Attempting to clarify how humans are simultaneously responsible for too much and too little rainfall, Michael Mann explains why warming causes more intense rainfall and widespread drought at the same time, and how this is ironic but not a contradiction.


“With warming, water is cycling more vigorously through our atmosphere. As it turns out, that implies more frequent, very heavy rainfall events, more intense weather potentially as a result of this amplified hydrological cycle. And ironically – although the atmosphere can hold more water vapor and can therefore produce larger amounts of rainfall in a given event – it turns out that these events become less frequent and the warmer surface also causes more evaporation of water into the atmosphere, drying soil surfaces, drying land surfaces. So in this warmer climate with an amplified hydrological cycle we actually see increased rainfall, intense rainfall flooding. But we can also see more widespread drought over continental regions. It might seem like a contradiction, but in fact both predictions follow from the intensification of the hydrological cycle.”


Long-Term Context Matters



It wasn’t all that long ago that journalists actually reported on climate change and weather events while considering a long-term context of natural variability rather than characterizing year-to-year weather change as unprecedented, the worst on record, and caused by humans.
 .
For example, in 1992 the New York Times actually published an article indicating Medieval-era droughts were much more severe than now, lasting hundreds of years.   The modern period has been “relatively wet” compared to the past in that region.



New York Times, 1992
“BEGINNING about 1,100 years ago, what is now California baked in two droughts, the first lasting 220 years and the second 140 years. Each was much more intense than the mere six-year dry spells that afflict modern California from time to time, new studies of past climates show. The findings suggest, in fact, that relatively wet periods like the 20th century have been the exception rather than the rule in California for at least the last 3,500 years, and that mega-droughts are likely to recur.”
“Dr. Scott Stine, a paleoclimatologist at California State University at Hayward, used radiocarbon dating techniques to determine the age of the trees’ outermost annual growth rings, thereby establishing the ends of drought periods. He then calculated the lengths of the preceding dry spells by counting the rings in each stump. This method identified droughts lasting from A.D. 892 to A.D. 1112 and from A.D. 1209 to A.D. 1350. Judging by how far the water levels dropped during these periods — as much as 50 feet in some cases — Dr. Stine concluded that the [Medieval-era] droughts were not only much longer, they were far more severe than either the drought of 1928 to 1934, California’s worst in modern times, or the more recent severe dry spell of 1987 to 1992.”

The Historical Southwest U.S. Climate: 3.2°C Warmer During Medieval Times

Millar et al., 2006
“The paleoclimate modeled for Whitewing [Sierra Nevada, CA] during the Medieval period was significantly warmer and slightly drier than present . Medieval mean annual minimum temperature was warmer than current by 3.2°C, with large differences in winter (+3.5°C, January) and summer (+4.0°C, July). Mean annual maximum temperature was also greater in the Medieval period (+2.3°C), with greater differences in winter (+3.2°C, January) than summer (+2.6°C, July). Annual precipitation was less by 24 mm.”

Scuderi, 1993
“Long-term trends in the temperature reconstruction are indicative of a 125-year periodicity that may be linked to solar activity as reflected in radiocarbon and auroral records. The results indicate that both the warm intervals during the Medieval Warm Epoch (A.D. 800 to 1200) and the cold intervals during the Little Ice Age (A.D. 1200 to 1900) are closely associated with the 125-year [solar activity] period.”


Medieval Drought Lasted Hundreds Of Years And Was Much More Severe

Whitehouse et al., 2010
“Paleoclimatic and model data indicate increased temperatures in western North America [∼AD 900–1300] of approximately 1 °C over the long-term mean. This was a period of extensive and persistent aridity over western North America. Paleoclimatic evidence suggests drought in the mid-12th century far exceeded the severity, duration, and extent of subsequent droughts.”


Kirby et al., 2014


Cook et al., 2010


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Scientists: Natural Variability Dominates In Southwestern U.S. Drought

Cheng et al., 2016
“The current California drought has cast a heavy burden on statewide agriculture and water resources, further exacerbated by concurrent extreme high temperatures. Furthermore, industrial-era global radiative forcing brings into question the role of long-term climate change on CA drought. How has human-induced climate change affected California drought risk?  … The results thus indicate the net effect of climate change has made agricultural drought less likely, and that the current severe impacts of drought on California’s agriculture has not been substantially caused by long-term climate changes.”

Prein et al., 2016
“Projected changes of a poleward extension of the subtropical dry zones simulated by climate models and the corresponding decrease of precipitation in the U.S. Southwest have not been found in observations to date because of the large natural climate variability.”

Seager et al., 2015
“The causes of the California drought during November to April winters of 2011/12 to 2013/14 are analyzed using observations and ensemble simulations with seven atmosphere models forced by observed SSTs. …[T]he precipitation deficit during the drought was dominated by natural variability, a conclusion framed by discussion of differences between observed and modeled tropical SST trends.”

Diaz and Wahl, 2015
“An analysis of the October 2013–September 2014 precipitation in the western United States and in particular over the California–Nevada region suggests this anomalously dry season, while extreme, is not unprecedented in comparison with the approximately 120-yr-long instrumental record of water year (WY; October–September) totals and in comparison with a 407-yr WY precipitation reconstruction dating back to 1571. Over this longer period, nine other years are known or estimated to have been nearly as dry or drier than WY 2014. The 3-yr deficit for WYs 2012–14, which in California exceeded the annual mean precipitation, is more extreme but also not unprecedented, occurring three other times over the past approximate 440 years in the reconstruction.”

Scientists: Natural Variability Dominates In Continental U.S. Drought

Seager et al., 2009   (Southeastern U.S.)
“Tree-ring records show that the twentieth century has been moist from the perspective of the last millennium and free of long and severe droughts that were abundant in previous centuries.  The recent drought, forced by reduced precipitation and with reduced evaporation, has no signature of model-projected anthropogenic climate change.”
Stambaugh et al., 2011 (Midwestern U.S.)
“[D]rought conditions over the period of instrumental records (since 1895) do not exhibit the full range of variability, severity, or duration of droughts during the last millennium.  Thirteen decadal to multidecadal droughts (i.e., ≥10 years) occurred during the last millennium – the longest lasting sixty-one years and centered on the late twelfth century.”
Andreadis and Lettenmaier, 2006 (Continental U.S.)
“Droughts have, for the most part, become shorter, less frequent, and cover a smaller portion of the country over the last century.”

Scientists: Natural Variability Dominates In Global-Scale Drought

Cook et al., 2015
“Megadroughts reconstructed over north-central Europe in the 11th and mid-15th centuries reinforce other evidence from North America and Asia that droughts were more severe, extensive, and prolonged over Northern Hemisphere land areas before the 20th century, with an inadequate understanding of their causes.”

Hoerling et al., 2010 
“In this study, the nature and causes for observed regional precipitation trends during 1977–2006 are diagnosed. It is found that major features of regional trends in annual precipitation during 1977–2006 are consistent with an atmospheric response to observed sea surface temperature (SST) variability. This includes drying over the eastern Pacific Ocean that extends into western portions of the Americas related to a cooling of eastern Pacific SSTs, and broad increases in rainfall over the tropical Eastern Hemisphere, including a Sahelian rainfall recovery and increased wetness over the Indo–West Pacific related to North Atlantic and Indo–West Pacific ocean warming. It is further determined that these relationships between SST and rainfall change are generally not symptomatic of human-induced emissions of greenhouse gases (GHGs) and aerosols.”

Sheffield et al., 2012
Little change in global drought over the past 60 years
“Here we show that the previously reported increase in global drought is overestimated because the PDSI uses a simplified model of potential evaporation that responds only to changes in temperature and thus responds incorrectly to global warming in recent decades. More realistic calculations, based on the underlying physical principles that take into account changes in available energy, humidity and wind speed, suggest that there has been little change in drought over the past 60 years.”

Cai et al., 2014
“Recent drought in 1993–2008 was still within the frame of natural climate variability based on the 306 yr PDSI reconstruction.    The dry and wet phases of Lingkong Mountain were in accordance with changes in the summer Asian-Pacific oscillation and sunspot numbers, they also showed strong similarity to other tree-ring based moisture indexes in large areas in and around the CLP, indicating the moisture variability in the CLP [Chinese Loess Plateau] was almost synchronous and closely related with large-scale land–ocean–atmospheric circulation and solar activity.”

McCabe and Wolock, 2015
“Monthly precipitation (P) and potential evapotranspiration (PET) from the CRUTS3.1 data set are used to compute monthly P minus PET (PMPE) for the land areas of the globe. The percent of the global land area with annual sums of PMPE less than zero are used as an index of global drought (%drought) for 1901 through 2009. Results indicate that for the past century %drought has not changed, even though global PET and temperature (T) have increased.”

Roderick and Farquhar, 2004
“Contrary to expectations, measurements of pan evaporation show decreases in many parts of the Northern Hemisphere over the last 50 years. When combined with rainfall measurements, these data show that much of the Northern Hemisphere’s terrestrial surface has become less arid over the last 50 years. However, whether the decrease in pan evaporation is a phenomenon limited to the Northern Hemisphere has until now been unknown because there have been no reports from the Southern Hemisphere. Here, we report a decrease in pan evaporation rate over the last 30 years across Australia of the same magnitude as the Northern Hemisphere trends (approximately −4 mm a−2). The results show that the terrestrial surface in Australia has, on average, become less arid over the recent past, just like much of the Northern Hemisphere.”

IPCC, 2007 (AR4):
“Warming the troposphere enhances the cooling rate, thereby increasing precipitation, but this may be partly offset by a decrease in the efficiency of radiative cooling due to an increase in atmospheric CO2 (Allen and Ingram, 2002; Yang et al., 2003; Lambert et al., 2004; Sugi and Yoshimura, 2004). This suggests that global mean precipitation should respond more to changes in shortwave forcing than CO2 forcing, since shortwave forcings, such as volcanic aerosol, alter the temperature of the troposphere without affecting the efficiency of radiative cooling. This is consistent with a simulated decrease in precipitation following large volcanic eruptions [which cause cooling] (Robock and Liu, 1994; Broccoli et al., 2003), and may explain why anthropogenic influence has not been detected in measurements of global land mean precipitation (Ziegler et al., 2003; Gillett et al., 2004b), although Lambert et al. (2004) urge caution in applying the energy budget argument to land-only data.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterElectric car proponents keep insisting that breakthroughs in electric car battery technology are just around the corner, and that soon electric cars will no longer be hampered by limited range and long charging times. Thus we should start banning internal combustion cars soon.
Leading experts, on the other hand, are far less optimistic about the prospects of battery powered vehicles. For example, the online Badische Neueste Nachrichten (BNN) here presents an interview with Prof. Albert Albers, Director for Product Development at the German Karlsruhe Institute for Technology (KIT), where he researches vehicle and machinery drive systems.
Too much green populism
Albers says he is annoyed by media and policymakers who insist electric batteries are feasible, and who cite “phony experts” who do not know the subject material very well. The result he tells the BNN:
For this reason the citizens instead get too few facts and too many populist opinions.”
Battery’s huge ecological fingerprint
On the subject of electric cars and batteries, he notes that the ecological fingerprint of an e-car with battery “is not so good at all“, reminding readers that after everything gets calculated, “the ecological expenditure is 60 percent higher than that of a combustion engine auto.”
According to Albers, the driver first has to run the vehicle 80,000 km before it catches up to the internal combustion engine, a point where the lifetime of the battery is pretty much exhausted, he says.
No manufacture today is ready to guarantee a battery for 200,000 km (10 years) which is what is normal for regular combustion engines.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Pleads for a return to sobriety
On the future for electric mobility, Albers pleads for a return to sobriety, saying that by 2030 there’s going to be “significantly more internal combustion vehicles on the roads than today”, and that for this reason “it is highly dangerous when policymakers villainize a technology.”
Despite all the anti-diesel rhetoric now being loudly expressed in Germany, Albers thinks the diesel engine still has a future, because there is still room for much improvement in diesel combustion technology.
“Considerable” fire and short circuit risks
The Karlsruhe researcher doesn’t believe there is future for batteries as a widespread solution, citing that the infrastructure challenges are too great and that there’s a “considerable risk” of short circuits involved with the use of lithium cells.
Overall Albers believes that “we have to remain open” to all solutions, for example synthetic fuels, power-to liquid-technology, or hydrogen gas powered engines. He does see a use for battery technology, but  in certain niche markets.
Albers says a more rational solutions-oriented discussion needs to take place, and there’s a need to get away from the generation of attention grabbing “populist headlines”.
800,000 German automotive jobs at risk
We must not discuss the issue in a state of daily panic and campaign populism and put the 800,000 jobs of the German automobile industry at risk.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Germany-based European Institute for Climate and Energy (EIKE) here recently reminded readers of two things: 1) renewable energies are performing woefully and temperature trends for Germany are pretty much flat, meaning they do not even remotely resemble anything you’d expect from a rapidly warming globe.
=================================================
A look at the “climate-rescuing” new energies
By Helmut Kuntz
(Translated/edited by P Gosselin)
This comment pretty much remains the same as the last one posted for October. Also in November the new energies have proven their uselessness. Supposedly they are already delivering 35% of the electric power demand – however only in the rare times that it actually gets produced.
Overall there are still no signs of a “reliable supply” and baseload capability to be seen anywhere.

Germany’s November plots for demand (red), wind power (blue) and solar power (yellow). Often both sun a wind were practically AWOL. Source: R. Schuster
If the installed green power capacity were to be tripled, then the result would look like that shown in the following chart. Consumption would still not be able to be covered – even using (currently unavailable) storage capacity. What’s glaring is the low level power yield seen in November with regards to the installed capacity. The power grids have to be designed to handle the rated installed capacity.
One can already imagine the feed-in act-related installation madness that remains ahead for Germany.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Germany November plots for the new energies multiplied by 3 and consumption (Verbrauch).The upper red line at 270,000 MW represents the tripled installed capacity. Source: R. Schuster.
The above chart clearly shows that even a tripling of installed rated capacity to 270,000 MW would still not even come close to covering Germany’s electricity needs.
Very little warming in November since 1962
On temperature in Germany, the following chart shows the mean temperature for November, starting in 1962. A rapid heating looks much different.

Germany DWD national weather service November-temperatures for Germany from 1962 to 2016 (blue), 30-year mean value (brown). Chart produced from DWD data by Helmut Kuntz
Summary
Also November shows an unbelievable normalcy with respect to climate. The great breakaway change predicted by computer simulations is still nowhere in sight.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterContrary to what is often claimed, Arctic sea ice is not in a death spiral, and has been stable for the past 10 years.
Yesterday Japanese skeptic blogger Kirye informed at Twitter that the sea ice volume and area rates of growth for September and early October this year are astonishingly rapid and at a pace we are accustomed to seeing in late October and November:
Chart: DMI
Volume is now well near normal level at over 9000 cubic kilometers. Sea ice area can be seen here.
Although Arctic sea ice reached a rather low level this year, September’s rate of volume growth was nothing less than spectacular, skyrocketing from some 6000 cubic kilometers to a bit over 9000 cubic kilometers in just a matter of three weeks! The impressive rate of growth is shown graphically by the next chart:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Image cropped from DMI
As shown the recent rate of growth is something that we commonly see in late October and in November. Usually the rate of growth is only about half as much.
Using the global warming theory on Arctic sea ice extent, i.e. it’s due to temperature, this year’s impressive growth would tell us that the Arctic must have been unusually frigid over the past three weeks. But looking at the Arctic temperature above 80°N latitude here, we see that temperatures have in fact been well above average. So what’s going on?
How can ice be forming so rapidly when it’s been mild over the past few weeks? What can we deduce from all this?
It tells us that Arctic sea ice extent has a lot more to do with other factors other than surface temperature. Critical factors include, ocean currents and cycles, wind conditions from weather patterns, and so on. So the next time an alarmist tries to tell us that sea ice loss is proof of warming, then just point out that there’s a lot more to it than just surface temperature. This year shows that in a very profound way.
The system is far more complex than just a trace gas (one, by the way, that happens to be a convenient vehicle to mass regulation).
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWikipedia and the Hamburg Forsythia Patch
by Dr. Sebastian Lüning and Josef Kowatsch
(Translated and rewritten by P Gosselin)
At the Hamburg Binnenalster near the Lombard Bridge, one finds a particular patch of forsythia, which blossoms every year when spring arrives at the north German port city. And just days ago on March 24, 2017, the famous patch blossomed again as it does every year.
So what’s the big deal about a spring flower patch blossoming in the spring?
It turns out that this particular patch is in fact one of great scientific interest as it has been scientifically observed since 1945. The dates at which the flowers blossom have been carefully recorded each year.
In the age of “rapid, unprecedented global warming”, you’d think that the blossoms would be appearing earlier and earlier as the global climate heats up like NASA insists it is. So it is all the more surprising that the data show that the opposite is in fact happening: the trend over the past 30 years is that this particular patch is blossoming later and later, indicating harsher and harsher winters.
Despite this year’s seemingly early spring in Europe, the most recent 2017 data point of the Hamburg Lombard Bridge forsythia blossoms in fact fits right with the overall 30 year trend.

Figure 1: The blossoming date of the Hamburg Lombard Bridge forsythia patch over the past 30 years with linear trend. The Y-axis is the number of days from the start of the year (January 1st). Spring at the site is arriving 3 weeks later!
The reason for the increasingly delayed spring blossoms likely has much to do with the trend of colder months of February over the past 30 years:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 2: February mean temperatures in GERMANY over the past 30 years. Data from the German DWD National Weather Service. Chart by Josef Kowatsch.
Wikipedia censors, cherrypicks and disinforms
Lüning and Kowatsch add that because of the Lombard Bridge forsythia patch’s significance, it even has its own Wikipedia page.
The two authors at the Die kalte Sonne site note that Wikipedia makes no mention whatsoever of the later blossoms trend. In fact one skeptic who wishes to remain anonymous actually logged in the Wikipedia site and suggested the following important addition on the now famous Hamburg forsythia blossoms:
Over the past 50 years there’s been a detectable trend of earlier blossoming. However since 1988 the blossoming date of the Hamburg forsythia has been again coming later.[3]“
This is a perfectly legitimate scientific statement that notes fairly both a trend of earlier blossoms on one hand, and on the other hand the current trend of the past 30 years, where the blossoms have been appearing later. The official long-term dataset since 1945 can be viewed at this DWD website (second chart, yellow curve).
So did the Wikipedia editors allow the added information? Lüning and Kowatsch write:
It did not even take a half hour, before the additional information was taken down. The reason according to page editor “DeWikiMan”: The trend of later blossoming over the past 30 years is not sufficiently statistically established.”
Lüning and Kowatch refer readers to Figure 1 above, and of course characterize DeWikiMan’s reasoning as somewhat absurd, before going on to show that the Wikipedia editor is in fact an activist and a “classic gatekeeper”: Wikipedia profile here. They depict DeWikiMan as a cherry-picker and purveyor of disinformation, and suggest that Wikipedia ought to take a much closer look at this editor.
Lüning and Kowatsch summarize:
It is a pity that the original excellent concept of a voluntarily written online encyclopedia has been hijacked by political activists and rendered useless in a number of sensitive subjects areas”
Share this...FacebookTwitter "
"
Share this...FacebookTwitter“In science and philosophy, ad hoc means the addition of extraneous hypotheses to a theory to save it from being falsified. Ad hoc hypotheses compensate for anomalies not anticipated by the theory in its unmodified form.  Scientists are often skeptical of scientific theories that rely on frequent, unsupported adjustments to sustain them. Ad hoc hypotheses are often characteristic of pseudoscientific subjects such as homeopathy.”   — Wikipedia on the scientific definition of ad hoc hypotheses
Observational evidence indicates that Antarctic sea ice has been advancing in recent decades, a trend that has puzzled climate modelers who assume that a warming globe will inhibit sea ice growth.  About 86% of all climate models have indicated that sea ice would show a declining trend for Antarctica, and just 14% (1 out of every 7) concluded sea ice extent would advance.  The average observed growth has been +1.29 (x 105 km2/decade) during the satellite era (since 1979), whereas the models projected a decline of -3.36  (x 105 km2/decade) on average.
Shu et al., 2015 

Forty-nine models, almost all of the CMIP5 climate models and earth system models with historical simulation, are used. For the Antarctic, multi-model ensemble mean (MME) results can give good climatology of sea ice extent (SIE), but the linear trend is incorrect. The linear trend of satellite-observed Antarctic SIE [sea ice extent] is +1.29 (±0.57) × 105 km2 decade−1 ; only about 1/7 CMIP5 models show increasing trends, and the [modeled] linear trend of CMIP5 MME is negative with the value of −3.36 (±0.15) × 105 km2 decade−1 .

Not willing to countenance the fact that their modeling was so terribly wrong, advocates of alarming anthropogenic global warming recently decided it was time to get creative in explaining why their modeling could still be quite right after all.  Of course, these advocates could not and would not admit that decades of growing sea ice trends would indicate that Antarctica and the surrounding Southern Ocean have not been warming, but cooling, during the last 3 decades in concert with the facile principle that cooler surface waters allow more sea ice to form.
Ackley et al., 2015

Sea-ice growth and melt are determined by the heat balance between the OHF [ocean heat flux] and the conductive heat transfer through the overlying ice cover. … Low atmospheric temperatures drive sea-ice formation, while relatively high ocean temperatures that can limit ice growth are a principal cause of sea-ice melt in the Antarctic.

Acknowledging that the southern pole has been cooling since the 1980s would serve to undermine the paradigm that says the entire globe has been steadily warming due to human activity.  In other words, a cooling Antarctica and Southern Ocean doesn’t advance the cause.
So instead of acknowledging that Antarctica and the surrounding Southern Ocean have been not been warming recently (as observational evidence clearly indicates), these advocates decided to issue a convoluted explanation about why sea ice grows in a warming world.  Well, in the Southern Hemisphere, anyway.  In the Northern Hemisphere, it is wholly accepted that warming causes sea ice to decline, which has been observed in the Arctic in recent decades.  In the Southern Hemisphere, warming causes sea ice to grow.  Confused?  We’re just getting started.
As mentioned, advocates of the position that human-caused global warming causes sea ice to grow in the Southern Hemisphere first deny that Antarctica and the Southern Ocean have been cooling in recent decades (despite the observational evidence).  Instead, they claim that the region has continued to warm, consistent with climate modeling and anthropogenic global warming expectations.  They then can claim that a warming Southern Ocean and Antarctic continent have led to enhanced land ice melt along the coasts of Antarctica.  This enhanced land ice melt has meant that the seas near the coasts have had new “cold, fresh layer” (from additional land ice meltwater) gliding over the surface of the ocean.  This “cold, fresh layer” of run-off water from enhanced land ice melt keeps the warming oceans from warming up too much, and this “cold, fresh layer” travels far and wide, suppressing the ability of the warming surface waters to limit sea ice growth.   In this way, the warming waters with a “cold, fresh layer” on top from all the additional land ice meltwater could be said to have caused the sea ice to grow.  Again, this process only works in the Southern Hemisphere.  It doesn’t work in the Northern Hemisphere, where the enhanced land ice melt in the Arctic does not result in sea ice growth, but a dramatic sea ice decline.
Surely this convoluted, ad hoc “explanation” for why anthropogenic global warming causes sea ice growth would not be taken seriously.  Right?  Well, actually, it has been taken very seriously.  No less than the journal Nature embraced it.  NSIDC’s director Mark Serreze promoted this makeshift conceptualization too.  And, of course, the usual suspects in the print media were all to eager to agree that human CO2 emissions cause sea ice to grow in Antarctica (and simultaneously shrink in the Arctic).
Nature News, 2013

Global warming expands Antarctic sea ice: In a polar paradox, melting land ice helps sea ice to grow.
Ocean warming may be a major driver of sea-ice expansion in the Antarctic, researchers report today in Nature Geoscience. … Scientists have known for several years that meltwater from ice sheets can form a cold, fresh layer on the ocean surface that protects sea ice from the warmer waters below. … “The paradox is that global warming leads to more cooling and more sea ice around Antarctica,” says Richard Bintanja, a climate researcher at the Royal Netherlands Meteorological Institute in Utrecht.

UK Daily Mail (2014)

Global warming is creating MORE ice: Antarctic levels reach a record high because of climate change, scientists claim
Claim was made by Mark Serreze, director of the National Snow and Ice Data Centre … Shift is caused by water melting from beneath the Antarctic ice shelves … Scientists claim it is then re-frozen back on surface, increasing sea ice

New Paper Debunks Claim That Humans Cause Antarctic Sea Ice To Advance
A new paper shreds this ad hoc explanation linking human activity to sea ice growth in the Southern Hemisphere.  Pauling et al. (2016) find that internal dynamics could explain the cooling and increase in sea ice extent in recent decades, and that an enhancement of the “freshwater input by an amount within the range of estimates of the Antarctic mass imbalance did not have any significant effect on either sea ice area magnitude or trend” — even if one assumes that anthropogenic forcing causes a decline in sea ice to offset the hypothetical growth trend due to enhanced “freshwater input”.
Pauling et al., 2016
The possibility that recent Antarctic sea ice expansion resulted from an increase in freshwater reaching the Southern Ocean is investigated here. … Two sets of experiments were conducted from 1980 to 2013 in CESM1(CAM5), one of the CMIP5 models, artificially distributing freshwater either at the ocean surface to mimic iceberg melt or at the ice shelf fronts at depth. An anomalous reduction in vertical advection of heat into the surface mixed layer resulted in sea surface cooling at high southern latitudes and an associated increase in sea ice area. Enhancing the freshwater input by an amount within the range of estimates of the Antarctic mass imbalance did not have any significant effect on either sea ice area magnitude or trend. 
A Better Explanation: Antarctica, Southern Ocean Have Been Cooling Since The 1980s
As mentioned above, Antarctica and the Southern Ocean have not been cooperating with anthropogenic “global” warming models.  The region has been cooling for decades.  And a cooling Southern Ocean has led to increasing sea ice trends.  In other words, no convoluted explanations are necessary.
Fan et al., 2014

[A]ll of these studies reported a close relationship between [sea ice extent] and sea surface temperature (SST) whereby sea ice gain is associated with lower SSTs and vice versa. … Cooling is evident over most of the Southern Ocean in all seasons and the annual mean, with magnitudes approximately 0.2–0.4°C per decade or 0.7–1.3°C over the 33 year period [1979-2011].

Doran et al., 2002

[O]ur spatial analysis of Antarctic meteorological data demonstrates a net cooling on the Antarctic continent between 1966 and 2000, particularly during summer and autumn.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Turner et al., 2016

Here we use a stacked temperature record to show an absence of regional [Antarctic Peninsula] warming since the late 1990s. The annual mean temperature has decreased at a statistically significant rate, with the most rapid cooling during the Austral summer.


Jones et al., 2016

Over the 36-year satellite era, significant linear trends in annual mean sea-ice extent, surface temperature and sea-level pressure are superimposed on large interannual to decadal variability. Most observed trends, however, are not unusual when compared with Antarctic palaeoclimate records of the past two centuries. With the exception of the positive trend in the Southern Annular Mode, climate model simulations that include anthropogenic forcing are not compatible with the observed trends. This suggests that natural variability overwhelms the forced response in the observations, but the models may not fully represent this natural variability or may overestimate the magnitude of the forced response.



During 1950s – 1980s, Antarctica, Southern Ocean Warmed, And Sea Ice Declined
In the Northern Hemisphere, Arctic sea ice declines during warm phases (e.g., the 1920s to 1940s and the 1990s to present), and Arctic sea ice increases during cooling phases (like it did during the 1950s to 1980s).  Similarly, when the Southern Ocean and Antarctic continent warmed during the 1950s to 1980s, sea ice declined.  Since the 1980s, Antarctica and the Southern Ocean have cooled, and, consequently, sea ice area has grown.  Not only that, but a majority of East Antarctic glaciers have been advancing since the 1990s.  Again, no convoluted, ad hoc explanations are necessary.  Cooling contributes to ice growth trends, and warming contributes to declining ice trends.
IPCC (2001):

Another analysis of a 21-station data set from Antarctica by Comiso (1999) found a warming trend equivalent to 1.25°C per century for a 45-year record beginning in the 1950s but a slight cooling trend from 1979 to 1998. The slight cooling trend for this later 20-year period also was confirmed via analysis of surface temperatures over the whole continent, as inferred from satellite data.

Fan et al., 2014

[S]ea surface temperatures and surface air temperatures decreased during 1979–2011, consistent with the expansion of Antarctic sea ice. In contrast, the Southern Ocean and coastal Antarctica warmed during 1950–1978.

Sinclair et al., 2014

We present the first proxy record of sea-ice area (SIA) in the Ross Sea, Antarctica, from a 130 year coastal ice-core record. High-resolution deuterium excess data show prevailing stable SIA [sea ice area] from the 1880s until the 1950s, a 2–5% reduction from the mid-1950s to the early-1990s, and a 5% increase after 1993.

Miles et al., 2013

Despite large fluctuations between glaciers—linked to their size—three epochal patterns emerged: 63 per cent of glaciers retreated from 1974 to 1990, 72 per cent advanced from 1990 to 2000, and 58 per cent advanced from 2000 to 2010.  … Indeed, several studies report increasing sea-ice concentrations in the study region from approximately 1980 to 2010, which is consistent with the predominance of glacier advance since 1990, when above-average sea-ice and fast-ice concentrations could have suppressed calving by increasing back-pressure on glacier termini. In contrast, reduced sea ice concentrations from the 1950s to the mid 1970s are consistent with glacier retreat during the 1960s and 1970s, when air temperatures were also increasing along the Pacific coast.


Sea Ice Trends In Antarctica Are Incompatible With An Anthropogenic Or CO2 Influence
The reason why advocates of an alarming anthropogenic influence on climate are so intent on “explaining” why warming causes sea ice to grow in the Southern Hemisphere is simple: what has been observed with Antarctic sea ice undermines the claim that anthropogenic global warming is predominantly responsible for polar sea ice trends.  And the observation that Antarctica warmed during the 1950s to 1980s, when CO2 levels were in the “safe” range (under 350 ppm), but it has cooled since the 1980s as CO2 levels exploded past 400 ppm, is also very incompatible with the conclusion that humans determine the ice trends in the southern polar climate with their CO2 emissions.
Of course, what has been happening in Antarctica is entirely consistent with what would be expected with natural or internal variability, and not what would be expected from models of rapidly growing CO2 concentrations.
Latif et al., 2013

During phases of deep convection the surface Southern Ocean warms, the abyssal Southern Ocean cools, Antarctic sea ice extent retreats, and the low-level atmospheric circulation over the Southern Ocean weakens. After the halt of deep convection, the surface Southern Ocean cools, the abyssal Southern Ocean warms, Antarctic sea ice expands, and the low-level atmospheric circulation over the Southern Ocean intensifies, consistent with what has been observed during the recent decades. 

At some point it must be acknowledged that something is seriously wrong with climate models that presume anthropogenic influences dominate the trends in polar sea ice.  One wonders what the next makeshift “explanation” will be for a likely increase in Arctic sea ice extent at some point in the near future, or as the warming phase in the Arctic draws to a close in the coming years.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA new paper just published online asks a timely and poignant question as the U.S. Presidential election splatters the headlines this week: What does the Paris Agreement actually do?  The author succinctly answers his own question, concluding that the Paris Agreement allows countries like China and India “permission to emit as much [CO2] as they see fit,” and therefore the international pact “makes the policy of mitigation of global warming impossible.”
Campbell, 2016
What does the Paris Agreement actually do?
“Though very widely believed to be inadequate in the target it sets, the Paris Agreement is commonly thought actually to set a binding target of reducing global CO2e emissions so as to limit global warming to 2℃. Proper legal interpretation of the Agreement shows it to set no such target. It rather gives the newly industrialising countries such as China and India a permission to emit as much as they see fit. These countries have been principally responsible for the huge growth in emissions since 1990 and they will be responsible for their continued huge growth until 2030. The Paris Agreement therefore makes the policy of mitigation of global warming impossible. However, this policy has been impossible over the whole of the now more than a quarter century of international climate change policy.”
To expand on this point, consider that global-scale CO2 emissions were still only 6.5 gigatons per year (GtC/yr) in the year 1999, but they grew to 7.5 GtC/yr by 2005, 8.5 GtC/yr by 2008, and 10.1 GtC/yr by 2014.  Here’s what that explosive growth in CO2 emissions looks like:

 
Notice the exponential expansion in climate change mitigation laws and policies from 1997, 2009, and 2014, and how they are negatively correlated with global-scale CO2 emissions growth (source: London School of Economics).  In other words, the more laws are passed that attempt to mitigate the growth in CO2 emissions, the sharper the growth in CO2 emissions.
London School of Economics, 2015
Three-quarters of the world’s annual emissions of greenhouse gases are now limited by national targets
“53 countries, including the 28 Member States of the European Union, have national targets that set either absolute or relative limits on annual emissions of greenhouse gases across their economies. … 98 countries and the European Union together had 804 climate laws and policies at the end of 2014, compared with 426 in 2009, when a previous attempt was made in Copenhagen, Denmark, to reach an international agreement. In 1997, when the Kyoto Protocol was agreed, these countries had just 54 climate laws and policies between them. … 47 countries, including the 28 Member States of the European Union, have introduced carbon pricing through either a carbon tax or a cap-and-trade system.”
According to an analysis by the Washington Post, Gigawatt-hours (GWh) from fossil fuels (coal, gas, oil) grew from 5.8 GWh in 1980 to 15.4 GWh in 2012.  Gigawatt-hours from renewables rose from 1.8 GWh in 1980 to 4.8 GWh in 2012.  This means that total consumption of fossil fuel energies grew more than 3 times faster than renewables did (9.6 GWh vs. 3 GWh) between 1980 and 2012.
Washington Post (2015):

As appetite for electricity soars, the world keeps turning to coal
“[T]wo-thirds of the world’s electricity is still produced by burning fossil fuels, mostly coal — a proportion that hasn’t budged for 35 years. Emissions of carbon dioxide from power plants have more than doubled since 1980 as the world’s demand for electricity keeps rising.”
And fossil fuel use will continue rising – no matter how many more laws are passed.
India and China alone plan to build 1617 new coal power plants by 2030.
Between 50 and 86 new coal plants are planned for Turkey in the next few years.
Russia plans to rapidly expand their coal industry (source):



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“The Russian government has endorsed a long-term coal industry development program, featuring an increase in coal production and coal-powered generation – a day after adopting a brand-new climate action plan.   The refurbished program sees coal production in Russia increase to 410-480 million tons by 2030, and exports are expected to grow by some 70 million tons.”
Japan is currently building 43 new coal plants.
South Korea is also adding more coal-fired energy according to a report from Reuters.com:
“Less than a week since signing the global climate deal in Paris, Japan and South Korea are pressing ahead with plans to open scores of new coal-fired power plants, casting doubt on the strength of their commitment to cutting CO2 emissions.   Even as many of the world’s rich nations seek to phase out the use of coal, Asia’s two most developed economies are burning more than ever and plan to add at least 60 new coal-fired power plants over the next 10 years.  Officials at both countries’ energy ministries said those plans were unchanged.”
The Netherlands…
“Dutch energy companies are burning more coal than ever, despite efforts to produce more green and sustainable energy, according to research by news agency De Persdienst. It says coal-fired power stations in the Netherlands used over seven million kilos of coal in the first nine months of last year, a 15% increase on 2013 and a 36% increase on 2012.”
World Research Institute assesses that ten developing countries are or will be building new coal plants.
“New coal-fired plants have been proposed in 10 developing countries: Cambodia, Dominican Republic, Guatemala, Laos, Morocco, Namibia, Oman, Senegal, Sri Lanka, and Uzbekistan. Currently, there is limited or no capacity for domestic coal production in any of these countries.”
According to a report from The Guardian, the only two wealthy countries that did not expand coal production and consumption since 2009 are the United States and Canada.  For Germany, France, Italy, Japan, and the UK, coal consumption rose by 16% between 2009 and 2013.
“Britain, Germany, Italy, Japan and France together burned 16% more coal in 2013 than 2009 and are planning to further increase construction of coal-fired power stations. Only the US and Canada of the G7 countries meeting on Monday in Berlin have reduced coal consumption since the Copenhagen climate summit in 2009.”
The Paris Agreement was, is, and will be an exercise in futility.  It will not reduce global-scale CO2 emissions, as emissions rates will continue to grow on a net global scale, especially since Asian and Middle Eastern countries continue to “emit as much as they see fit”.
Analysts have suggested that our efforts to mitigate CO2 emissions “will almost surely fail,” and they may “actually make matters worse.”
Jones and Warner, 2016
Efforts to curtail world temps will almost surely fail
“To even come close to achieving the goals of the Paris Agreement, 50 percent of our energy will need to come from renewable sources by 2028, and today it is only 9 percent, including hydropower. For a world that wants to fight climate change, the numbers just don’t add up to do it.”
Kelly, 2016
“[A]ll the actions taken together until now to reduce our emissions of carbon dioxide will not achieve a serious reduction, and in some cases, they will actually make matters worse.”
Bannaga, 2016
“It is evident that UN efforts to combat climate change are not effective because past experience shows that CO2 generation cuts weren’t near enough.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA former NOAA meteorologist and 40-year veteran of hurricane predictions believes Irma will continue to move move west toward Florida and reach near the southern tip of the Florida Peninsula around Sunday, September 11th, as a major category 4 hurricane.

Irma eerily similar to Hurricane Donna’s (1960) track. Public Domain image.
Both David Dilley of Global Weather Oscillations and the National Hurricane Center now believe Irma will make landfall near the southern tip of Florida, from near or just west of Miami to just west or near Jacksonville and then run up the coast into eastern Georgia.
Dilley adds: “It all depends on exactly when it makes the turn to the north – just 20 miles makes a big difference. Historical tracks favor a landfall near or south of Miami.”
Predictions based on natural cycles
Dilley had predicted a harsh hurricane season already back in early February, long before most forecasters were ready to go public with their forecasts.
In his February forecast, he predicted that the USA’s record 12-year run without a major hurricane hit would end in a big way.
He also predicted that the southern tip of Florida would be hit by a major hurricane, one that would move northward through the state after making landfall, and that this southern Florida zone overall would enter the strongest and most active hurricane cycle since the period from 1945 to 1950 (65 to 70 years ago).
Dilley wrote in an e-mail that during this 6-year active period, five out of the 6 years had hurricanes, and some years had multiple landfalls, adding:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




There were a total of 8 hurricanes during this 6-year period, and 6 of the 8 hurricanes were major Category 3 to 5 hurricanes.”
So far his predictions for the current season have been impressively accurate. Dilley says he is tracking 4 historical analog years that are like the 2017 season, noting that hurricane patterns have a strong tendency to repeat in cycles.
He reminds us that three of the 6 landfalls from 1945 to 1950 were major hurricanes, with 2 of them being strong Category 4 hurricanes. There were also two category 3 hurricanes – and only one hurricane was a Category 1.
The analog years he used for forecasting the current season go back to 1910.
The bottom line, says Dilley: “This Southern Florida zone has entered the most active and dangerous cycle in 65 to 70 years. About 70% of the hurricanes that strike this zone are major hurricanes.” This year mostly likely will not be any luckier.
No global warming – “all using natural cycles”
On what’s behind the hurricanes, the 40-year veteran does not believe it has anything to do with manmade global warming and higher atmospheric CO2 concentrations. According to Dilley: “I nailed it 8 months in advance and the likely Texas hurricane – all using natural cycles of the earth-moon-sun interactions – and No Global Warming.”
While most models predict little danger from now forming José, Dilley wrote that it will develop into a hurricane and that there’s a chance José “could pose a New England threat near the 21st“.
A New England hurricane hit was also among Dilley’s predictions from earlier this year.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s DWD national weather service just issued the preliminary results for the country’s January 2017 mean temperature.
According the DWD’s approximately 2000 stations scattered across the country, January’s mean temperature came in 2.7°C colder than the 1981-2010 mean. Especially southern Germany was cold, as was its neighbor Austria, see below.
The lowest recorded temperature in Germany was measured in Reit im Winkl: -26.3°C. Most of the precipitation this past January, which was 27% below normal, fell as snow.
The DWD attributed the colder temperatures to a wintry weather pattern.
No warming
The European Institute for Climate and Energy (EIKE) has analyzed the German data for the Erfurt-Weimar station and has found that there has been no warming in January over the past 45 years (since 1973):

Despite rising atmospheric CO2 concentration, January temperature at the Erfurt-Weimar station has remained flat since 1973. Chart: Stefan Kämpfe, EIKE.
Josef Kowatsch also analyzed Germany’s January temperature trend and found that the month has in fact cooled almost 2°C over the past 25 years. I’ll see if I can chase down his chart.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




EIKE also looked at the Central England January temperature record and found that there has only been a slight warming over the past 105 years!
In fact the warmest years in Central England were recorded in the early part of the 20th century.

Chart source: (EIKE)
Frigid Austria
Meanwhile Austria’s ZAMG national weather service reports that January 2017 in the country was “extraordinarily cold”, the second coldest in 30 years, with the preliminary mean coming in at 3.0°C below the long term 1981-2010 mean.
The chart shows the temperature deviation from the mean.

Temperature January 2017: deviation from the 1981-2010 mean. Computed using SPARTACUS data through 29 January 2017. Source: ZAMG
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy now, after some 30 years of dire warnings, you’d think that the warming of the globe and ice mass reduction would be much further along than it actually is. Yet there are a number of major signs that show the opposite (cooling and freezing) are happening:
1. Arctic ice has stabilized over the past decade
Tony Heller at realclimatescience.com here reports that Arctic sea ice volume is in fact up 15%, from 13,000 km³ to 15,000 km³ and that there has been a huge expansion of thick ice into the East Siberian Sea. The following is Heller’s comparator showing the difference between today and 10 years ago:

2007     2017
Obviously over the past 10 years Arctic sea ice was supposed to do the opposite, i.e. shrink 15%. Climate scientists, who warned the melting of the 2000s would accelerate, are now left baffled and speechless.
2. Equatorial Pacific La Nina will usher in cooling 
The EL Nino Southern Oscillation (ENSO), a measure of equatorial Pacific sea surface temperatures, is at its coldest level in years, boding that more global cooling lies ahead for the planet in the months ahead. Just months ago, experts were predicting another warming El Nino. They were wrong. Moreover, the latest forecast sees La Nina conditions extending into next spring:

3. Rapid Pacific surface cool down:
Surface temperatures at the equatorial Pacific (where it really counts) have plummeted by 1-2°C since June of this year, hurricane expert Phillip Klotbach tweeted recently:
And because there is a lag of about 6 months between the ocean surface temperature and satellite global lower troposphere temperatures, the La Nina will ensure that 2018 will be a cooler year at the surface globally.
4. Siberia sees unusual November cold
Moving to Siberia, we see that an unexpected cold gripped the region, with temperatures in many parts of Siberia recently plummeting 20°F below normal. The Weather Channel reports here: “Parts of Siberia are Colder Than Minus 60 Degrees Fahrenheit, and It’s Only November“.
Forecasters are now warning that this cold could soon shift over to North America and Europe.
5. Greenland’s ice mass budget continues to surprise
Greenland, often claimed by climate alarmists to be the “canary in the coal mine”, has seen its ice sheet gain 250 billion metric tonnes since September 1, 2017. This is 40 billion tonnes above the 1981-2010 average.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Top: The total daily contribution to the surface mass balance from the entire ice sheet (blue line, Gt/day). Bottom: The accumulated surface mass balance from September 1st to now (blue line, Gt) and the season 2011-12 (red) which had very high summer melt in Greenland. For comparison, the mean curve from the period 1981-2010 is shown (dark grey). More here: DMI. Source: Danish Meteorological Institute. 
Warming is not supposed to create 40 billion tonnes of ice. That’s almost 6 tonnes for each person on the planet.

6. Northern Hemisphere fall snow and ice cover rising
Northern Hemisphere snow and ice cover for the month of October finished 20% above the mean. In fact the mean of the past 5 years for October has been the highest for any 5-year period since measurements began 50 years ago.

Source: Rutgers University Global Snow Laboratory (GSL)
The same is true for the month of November: it too has seen a robust upward trend in snow and ice cover over the past 30 years.
7. Solar activity near 200-year low
In the current solar cycle 24 sunspot activity is now at the lowest level in almost 200 years. In the early 1800s the Earth found itself in the grips of the Dalton Minimum, a cold period with similarly low solar activity:
The accumulated sunspot anomaly from the mean of the previous 23 cycles – 107 months into the cycle.
The current solar cycle 24 is the third weakest since the systematic observation of solar cycle activity began in 1755. Only solar cycles nos. 5 and 6 (1798…1823 during the Dalton Minimum) were weaker. A number of distinguished scientists and dozens of scientific publications warn that the planet may in fact be entering a period of global cooling. The upcoming solar cycle 25 also is expected to be a weak one.
Major eruption of Agung?
In summary, there are other signs showing cooling taking place or coming up; above is just a sampling. Let’s not forget the possible eruption of Agung in Indonesia. A major eruption would send global temps into the fridge for a couple of years.
The bottom line: Don’t let all the hype about runaway warming make you think the planet is roasting. There’s plenty of unexpected cold around – cold that was never supposed to be. And the only thing you’re going to hear from the alarmists to explain this are a lot of excuses.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Below is a commentary addressing the YouTube response to the late October Breitbart headline that claimed the 400 papers (now 485) compiled here at NoTricksZone say that “Global Warming Is A Myth“.
While the headline at Breitbart was presumably assembled for the expressed purpose of attracting readership (mission accomplished, if so), it will be explicitly stated here that this compilation certainly does not assert that “Global Warming Is A Myth”.  It isn’t.  Large regions of the Earth have undergone a warming trend in the last century, rising out of the depths of the Little Ice Age.
It is also true that these papers are not claimed to literally “debunk” any positions currently held by those who advocate for the main “consensus” positions related to anthropogenic global warming.   Instead of using such ambitious and affirmative language, the nuanced words used to describe what this list is proposed to accomplish were carefully chosen so as not to assert it does more (or less) than actually claimed.
What the papers and graphs in this compilation actually do is support many of the main skeptical positions which question climate alarm.   Namely, they support the position(s):
N(1) natural mechanisms play well more than a negligible role (as claimed by the IPCC) in the net changes in the climate system, which includes temperature variations, precipitation patterns, weather events, etc., and the influence of increased CO2 concentrations on climatic changes are less pronounced than currently imagined;
N(2) the warming/sea levels/glacier and sea ice retreat/hurricane and drought intensities…experienced during the modern era are neither unprecedented or remarkable, nor do they fall outside the range of natural variability, as clearly shown in the first 150 graphs (from 2017) in this volume;
N(3) the computer climate models are not reliable or consistently accurate, and projections of future climate states are little more than speculation as the uncertainty and error ranges are enormous in a non-linear climate system; and
N(4) current emissions-mitigation policies, especially related to the advocacy for renewables, are often ineffective and even harmful to the environment, whereas elevated CO2 and a warmer climate provide unheralded benefits to the biosphere (i.e., a greener planet and enhanced crop yields).
In sharp contrast to the above, the corresponding “consensus” positions that these papers do not support are:
A(1) Close to or over 100% (110%) of the warming since 1950 has been caused by increases in anthropogenic CO2 emissions, leaving natural attribution at something close to 0%;
RealClimate.org: “The best estimate of the warming due to anthropogenic forcings (ANT) is the orange bar (noting the 1𝛔 uncertainties). Reading off the graph, it is 0.7±0.2ºC (5-95%) with the observed warming 0.65±0.06 (5-95%). The attribution then follows as having a mean of ~110%, with a 5-95% range of 80–130%. This easily justifies the IPCC claims of having a mean near 100%, and a very low likelihood of the attribution being less than 50% (p < 0.0001!).”
A(2) Modern warming, glacier and sea ice recession, sea level rise, drought and hurricane intensities…are all occurring at unprecedentedly high and rapid rates, and the effects are globally synchronous (not just regional)…and thus dangerous consequences to the global biosphere and human civilizations loom in the near future as a consequence of anthropogenic influences;
A(3) The climate models are reliable and accurate, and the scientific understanding of the effects of both natural forcing factors (solar activity, clouds, water vapor, etc.) and CO2 concentration changes on climate is “settled enough“, which means that “the time for debate has ended“;
A(4) The proposed solutions to mitigate the dangerous consequences described in N(4) – namely, wind and solar expansion – are safe, effective, and environmentally-friendly.
The 400+ papers compiled so far support the N(1)-N(4) positions, and they undermine or at least do not support the “consensus” A(1)-A(4) positions.  The papers do not do more than that.   Unreasonable expectations that these papers should do more than support skeptical positions and undermine “consensus” positions to “count” are rooted in straw man argumentation.
Specifically, claiming that a scientific paper must assert that CO2 does not play a major role in climate to be characterized as a paper supporting a skeptical positions in N(1)-N(4) is disingenuous at best.   The opposite wouldn’t ever stand, of course.   Let’s say an author of a scientific paper did not explicitly state that she disagrees that natural factors play a significant role in modern climate change.  Would that mean that we could say the paper affirms that climate changes are significantly natural?  Of course not.  And yet this very same non-sequitur is employed here with regularity when disingenuously arguing that these papers do not do what they claim to do – especially since what they are claimed to do has not been accurately characterized.
As an aside, if we were to look at the papers that Cook et al. (2013) used to concoct the 97% “consensus” document we would find that Cook and his colleagues actually classified papers (and magazine articles) about cooking stoves in Brazil, phone surveys, asthma-related ER visits in Montreal, TV coverage . . . as scientific papers “endorsing” the position that all or nearly all of the global warming occurring since 1950 has been human-caused (the “consensus” statement).  Of course, none of the papers identified in the link below that were categorized as “endorsing” the clearly defined anthropogenic/post-1950 “consensus” statement actually used those specific words.   And yet they were curiously counted anyway.
http://www.joseduarte.com/blog/cooking-stove-use-housing-associations-white-males-and-the-97
“The Cook et al. (2013) 97% paper included a bunch of psychology studies, marketing papers, and surveys of the general public as scientific endorsement of anthropogenic climate change.”
With that lengthy (but necessary) introduction, I will now take the time to carefully construct a response to the YouTube video critique of the 400+ papers list as authored by potholer54, who I shall hereafter refer to as PH54 for lack of a better title.

1. After having thoroughly criticized James Delingpole’s analysis and style for the first few minutes, PH54 digs in and correctly suggests that the NoTricksZone headline and emboldened first paragraph is more “nuanced” than Breitbart‘s.   He attempts to summarize what the 400+ papers represent by claiming they are meant to cast doubt on the conclusion that CO2 is a major driver of climate change — and no more.  Of course, as described above, there is far more to it than that, but soundbites are to be expected in short videos like this.

2. PH54 then, for reasons that are not clear, returns to using the Breitbart interface instead of using the NoTricksZone article and paper reference lists — which have far more detail and may include graphs that correspond to the paper.   Perhaps the reasons why will become apparent.

3. PH54 spends some time providing visuals of electric heaters warming an indoor room.   CO2 and the Sun are assumed to be just like two equally powerful heaters.   The Sun drives climate when the CO2 is stable, which it was during much of the Holocene.   Low solar activity causes cooling and high solar activity causes warming.   And in modern times, PH54 asserts, the Sun has been “turned down” just as the CO2 heater has been turned up.   So, during the modern era, CO2 drives climate.  The Sun used to drive warming and climate changes, but it no longer does.

4. Li et al. 2017 is the first paper directly discussed.  PH54 identifies what he calls the key words in the paper: Late Holocene.  He writes that the paper only addresses the last 2200 years, and it does not address the impacts of solar activity on modern climate.  He notes that solar forcing is not even mentioned in the title.   (CO2 isn’t either.)
PH54 then starts in on his main theme (as introduced in 2. above).  Yes, the Sun drives climate in the Late Holocene, and not CO2.   How do we know this?   Because CO2 was stable during the last 10,000 years – coasting between 250 ppm and 280 ppm.   So PH54 agrees, apparently, that the cold temperatures occurring during centennial-scale solar minima (Maunder, Dalton) would allow us to conclude that the Sun was a main driver of climate during those periods.  Likewise, the Medieval Maximum, a period of high solar activity, led to warm temperatures during the Medieval Warm Period, or Medieval Climate Anomaly (as it is preferred).

But it’s at that point – the Late Holocene – where the Sun apparently stops driving temperatures.   Why?  Because the CO2 heating machine took over.

5. But let’s get back to the Li et al. (2017) paper.  Now, because PH54 used the Breitbart article for a reference instead of the more detailed NoTricksZone visuals, he apparently missed the graphs shown below that appeared in the paper.  The top graph (red trend line) is a solar activity reconstruction for the last millennium.   Notice the sharp uptick in solar activity during the modern era.  This is referred to as the Modern Grand Maximum, with the levels of solar activity exceeding those occurring the Medieval Warm Period.  Now notice the bottom graph (gold).   It’s a graph of Northern Hemisphere temperatures.   Interestingly, there appears to be a very close correlation between the solar activity and the hemispheric temperature, including during the 20th century, when CO2 is said to have been the temperature driver.

Vieira et al., 2011


6. Another aspect of this Li et al. (2017) paper that was ostensibly missed by PH54 (apparently because he chose to use Breitbart‘s one- or two-sentence summary rather than NoTricksZone’s much more detailed summary complete with graphics) is the commentary about the impact of CO2 forcing relative to solar forcing.  The authors conclude that CO2 may play a role in “partly affecting climate variability” in North China, but that the overall long-term control on temperature is “solar-dominated.”
“High volumes of greenhouse gases such as CO2 and CH4 during the recent warming periods, may also play a role in partly affecting the climatic variability in NC, superimposing on the overall solar-dominated long-term control (e.g., Wanner et al., 2008; Tan et al., 2011; Kobashi et al., 2013; Chen et al., 2015a,b).”

7. The Li et al. (2017) paper also contains a graph of North China that shows the modern temperatures (which have been flat since about 1950) are no warmer now than they were during Medieval times.  And, like the Northern Hemisphere in general, they appear to follow the general pattern of solar activity.  In other words, this paper supports both N(1) and N(2), and it does not support A(1) and A(2).   That’s why it was included on the list.

8.  Then, continuing the Holocene-only theme introduced in 2. and 4. above, PH54 addresses the second paper on the Breitbart list (again ignoring what is shown on NoTricksZone), Yndestad and Solheim (2017) .  He again claims these scientists were only talking about the Holocene in their paper, not the modern period.  He even includes a visual of the abstract with underlined red lines over the years 1000 AD and 1700 AD.  Had PH54 decided to read the rest of the paper – or even look at the NoTricksZone summary – he would have seen that the authors clearly referred to the modern period (multiple times), and they even referenced the coming solar minimum for the coming decades.  They especially made note of the millennial-scale uniqueness of the very high solar activity for the 1940 to 2000 period, referring to it as a rare event with levels exceeding all but the grand maximum events of 4,000 and 8,000 years ago.
“Deterministic models based on the stationary periods confirm the results through a close relation to known long solar minima since 1000 A.D. and suggest a modern maximum period from 1940 to 2015.  Studies that employ cosmogenic isotope data and sunspot data indicate that we are currently leaving a grand activity maximum, which began in approximately 1940 and is now declining (Usoskin et al., 2003; Solanki et al., 2004; Abreu et al., 2008). Because grand maxima  and minima occur on centennial or millennial timescales, they can only be investigated using proxy data, i.e., solar activity reconstructed from 10Be and 14C time-calibrated data. The conclusion is that the activity level of the Modern Maximum (1940–2000) is a relatively rare event, with the previous similarly high levels of solar activity observed 4 and 8 millennia ago (Usoskin et al., 2003).   Periods with few sunspots are associated with low solar activity and cold climate periods. Periods with many sunspots are associated with high solar activity and warm climate periods.”

9.  Here is the solar activity reconstruction featured prominently in the Yndestad and Solheim paper (and in NoTricksZone):

Notice how well solar activity correlates with reconstructions of Northern Hemisphere temperature (Stoffel et al., 2015):


Schneider et al., 2015 also show an oscillation (warming-cooling-warming) in Northern Hemisphere temperatures for the 20th century.

Using 126 tree ring records, Xing et al. (2016) reconstruct Northern Hemisphere temperatures that follow trends in solar activity, as shown below.
The Extratropical Northern Hemisphere Temperature Reconstruction during the Last Millennium Based on a Novel Method (Xing et al., 2016)



10. Ignoring the Yndestad and Solheim TSI graph from the paper itself, which alternatively shows a net +3 W m-2 increase in solar forcing between 1900 and 2000, PH54 produced a graph showing declining sunspot numbers that did not appear in the Yndestad and Solheim paper.  Why not use the Yndestad and Solheim reconstruction?  Probably because it showed the opposite of what his graph of declining solar activity showed: That we have experienced a Modern Grand Maximum of solar activity, +3 W m-2 of forcing, since the beginning of the 20th century and continuing on through to about 2000.  It’s rather odd that the author of a video “exposing” that a paper doesn’t say what is claimed would proceed to refuse to actually read the paper itself (that references the modern period), or that he would avoid using the graph that was provided in the paper or by NoTricksZone.   Instead, PH54 chose to comment using a preferred graph of solar activity that supports his own viewpoints…and a summary provided by Breitbart.

11.  PH54 concludes: “[Yndestad and] Solheim doesn’t debunk the theory that CO2 is a major driver of climate.  It’s quite consistent with it.”
This is odd.  The authors don’t comment on CO2 as the “major driver of climate” in their paper.

12.  Then, after commenting on just those two papers (which were selected by James Delingpole), both of which suggest that solar activity has indeed contributed to modern climate in a significant way, PH54 states: “You get the point.  The highlighted papers just looking at past warming…when CO2 levels were stable.”
This is false.  While it’s true that many of the papers on the list do indeed only refer to past climates in asserting that solar activity drove centennial-scale temperature changes, there are also many that refer to the significant influence of solar activity on the modern climate, including the first two discussed by PH54.

13. PH54: “You can check the [Delingpole] list yourself.  It’s not that hard.  All you have to do is look at Delingpole’s summary.”
Delingpole only provided a handful of the examples from the papers.   The full list of 110 solar-influence papers, with more complete summaries and temperature graphs, are found on the NoTricksZone list.   It’s interesting that PH54 accuses Delingpole of not reading the papers himself, or relying on others to do the reading and summarizing for him…and then he goes ahead and relies on Delingpole for summaries of what the papers say.

14. PH54: Delingpole writes “Modern climate in phase with natural variability.  But the two papers he cites are talking about precipitation.”
Interestingly, PH54 has ostensibly decided that precipitation patterns are not sufficient to count as climate.  Apparently climate is about temperature, and temperature only.    Drought periodicity isn’t indicative of climate.   Decadal-scale flood events aren’t about climate.   Variability in the East Asian Monsoon and their connection to ENSO events don’t qualify as climate.   In ice cores, precipitation levels are often used as a proxy for temperature, with warmer/cooler temperatures corresponding to more/less precipitation.  How odd to take this stance.

15. PH54: “Neither paper [chosen by Delingpole] is talking about global temperature.”
Of course these two papers weren’t talking about global temperature.  The two papers selected from the compilation on natural variability were addressing regional rainfall patterns and their robust connections to solar activity.  Nor was it ever claimed that these two papers were talking about global temperature.   According to “consensus” science, though, drought and flood events and precipitation in general are expected to undergo significant shifts…due to changes in CO2 concentrations.
Miralles et al., 2014     “The hydrological cycle is expected to intensify in response to global warming. Yet, little unequivocal evidence of such an acceleration has been found on a global scale.”
These two papers, which do not support the A(2) “consensus” position, instead support the N(2) position that there is nothing unusual about the modern climate (precipitation) relative to past periods, when CO2 concentrations were much lower.

16. PH54: “During a period of La Nina, the Pacific ocean sucks in heat from the atmosphere, and during El Nino, it spits it back out.”
This is actually an incorrect way of putting it.  The heat for ENSO events isn’t sourced by atmospheric heat.  The heat source is from the ocean itself, and the ocean is heated by the Sun.  The atmosphere contains just 1% of the Earth system’s heat.  Therefore, the heat flux sequence is almost always from ocean to atmosphere, and not the other way around.  The heat redistribution during ENSO events are from the deeper waters to the ocean surface and vice versa.

17. PH54: “None of these papers [Delingpole selected] suggest CO2 is not a major driver of global temperature.”
This is the same non-sequitur referred to in the introduction.   Unless a paper expressly states that CO2 is not a major climate driver, it does not count as a paper supporting a skeptical position on climate alarm.  This does not follow.

18. PH54: “Further down the list, the papers get more bizarre.  Papers about bats being harmed by wind turbines and blade disposal.   I’m struggling to see how any of these papers are casting doubt on CO2’s role in global warming.”
The non-sequitur, repeated.   But this comment appears most disingenuous, as PH54 should probably understand that these particular papers addressing the harm to the environment and ineffectiveness of renewables-promoting policies were not selected from the literature to cast doubt on CO2’s role in climate change.   Instead – and one would assume that most readers would understand this – these papers were selected because they support the position that the “consensus”-endorsed response to the perspective that humans are the dominant cause dangerous global warming is to promote  wind and solar energies, and these may not be either effective or environmental friendly.
All PH54 needed to do was look at the introduction to the NoTricksZone article that addressed what these papers were designed to do, or to support.  These papers have nothing to do with CO2’s role in global warming.  They shouldn’t be expected to.
“Current emissions-mitigation policies, especially related to the advocacy for renewables, are often costly, ineffective, and perhaps even harmful to the environment.  On the other hand, elevated CO2 and a warmer climate provide unheralded benefits to the biosphere (i.e., a greener planet and enhanced crop yields).”

19. Addressing the Tejedor et al. (2017) paper, PH54 once again wrongly claims that the paper only addresses the past climate, and makes no reference to the current one.  Had he read the entire paper, or even the summary provided by NoTricksZone, he would (should) have noticed (since it is highlighted in bold red) that the paper does, in fact, mention the  high solar activity of the last few decades.  It also mentions that high solar activity is  associated with periods with high temperatures, such as the warming occurring during 1986-2012.
“Reconstructed long-term temperature variations match reasonably well with solar irradiance changes since warm and cold phases correspond with high and low solar activity, respectively. … The main driver of the large-scale character of the warm and cold episodes may be changes in the solar activity. The beginning of the reconstruction starts with the end of the Spörer minimum. The Maunder minimum, from 1645 to 1715 (Luterbacher et al., 2001) seems to be consistent with a cold period from 1645 to 1706. In addition, the Dalton minimum from 1796 to 1830 is detected for the period 1810 to 1838. However, a considerably cold period from 1778 to 1798 is not in agreement with a decrease in the solar activity. Four warm periods – 1626–1637, 1800–1809, 1845– 1859, and 1986–2012 – have been identified to correspond to increased solar activity.”
Then, after asserting the paper fails to address the modern era, PH54 highlights (using red underlining) the mention of “anthropogenic forces” in the paper.  Curiously, he claims that this particular sentence, as it reads, asserts that CO2 is a “major driver” of climate change.
“The study area [is] a potentially vulnerable region to anthropogenic climatic changes by anthropogenic forces, i.e,., increasing concentrations of greenhouse gases.”
But if this one rather mild sentence from the paper supports the position that CO2 is a major driver of climatic changes (and perhaps it does), then surely one can agree that the statement asserting the “main driver” of “warm periods” may be increases in solar activity (and the 1986-2012 period is specifically referred to in the paper as a warm period that “corresponds to increased solar activity”) could also be interpreted as support for the position that the Sun has more than a negligible role in modern temperatures for the region.

20.  The NoTricksZone compilation contains two graphs from the Tejedor et al. (2017) paper, both of which would appear to support the N(1) position that the modern climate has been impacted by the high solar activity (notice how the warming and cooling events match up rather fittingly with solar activity)…

…and that there is nothing unusual or unprecedented about modern temperatures in the Iberian region to suggest that they have fallen outside the range of natural variability, an N(2) position.




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




21. Interestingly, the Rydval et al. (2017) paper contains several graphs from the Northern Hemisphere, all of which correspond quite well to the changes in solar activity, including the Medieval Maximum and Modern Grand Maximum.   They generally show no net warming since the middle of the 20th century due to a severe cooling period between the 1940s and 1960s (wiping out much of the early 20th century warming), which is consistent with the pattern of solar activity shown earlier.




22. The strongest part of the video response is the section citing 4 or 5 other papers that, in addition to concluding that the Sun plays a role in climate changes, also conclude that CO2 concentrations play an important role too.  Some of the identified papers even say that CO2 plays a larger role than natural factors do.   While this may appear to fully destroy the position that these papers “debunk” global warming as a myth — a claim which has not been made here — these statements still do not seem to assert that the only, 100% cause of climate changes since 1950 is anthropogenic CO2 emissions.  Indeed, even as they claim a significant role for CO2, they do not dismiss natural factors as having any role in climate changes.  This is, after all, the “consensus” position as espoused by the IPCC.   To support the consensus, then, there should be effectively no role for natural factors in climate change after 1950.  Papers that allow natural factors to at least contribute some to the climatic changes would therefore not be supporting the “consensus”.   That is why papers like these may still be included, despite the apparent inconsistency.

23. Williams et al. (2017) assert that temperatures warmed more and warmed faster (1.1°C, 0.008°C per year) from the 1660s to the 1800s — when CO2 did not change — than they did during the 1860 to 2007 period (0.8°C, 0.005°C per year).  This would not be consistent with the perspective that CO2 emissions are a more dominant climate forcing factor than the non-CO2 factors eliciting temperatures changes during the 17th to 19th centuries.   It undermines the A(2) position, and it would be consistent with N(2).  Also, while Williams et al. (2017) do state that global temperatures “are exceeding estimates of natural variability”, this is not remotely the same thing as concluding that natural factors do not play a role in climate changes after 1950.  Indeed, the opposite is said: natural factors are included as factors playing a role in climate changes “for the last 342 years.”
“Reconstructed SSTs significantly warmed 1.1 ± 0.30°C … from 1660s to 1800 (rate of change: 0.008 ± 0.002°C/year), followed by a significant cooling of 0.8 ± 0.04°C …  until 1840 (rate of change: 0.02 ± 0.001°C/year), then a significant warming of 0.8 ± 0.16°C from 1860 until the end of reconstruction in 2007 (rate of change: 0.005 ± 0.001°C/year).”
“[T]hese data suggest a complex combination of solar irradiance, volcanic activity, internal ocean dynamics and external anthropogenic forcing explain the variability in Aleutian SSTs for the past 342 years.”

24.  Zawiska et al. (2017) write that human emissions of CO2 are “considered” to be “the most important factor” in modern climate change.  They do not conclude that CO2 emissions are effectively the only factor.   Furthermore, they conclude that profound temperature changes for the region occurred far more abruptly between 1800 and 1875 than they have since, when the temperature changes have been slower and largely flat for the past 100 years (despite rising CO2 emissions).  The abrupt warming event — 4.3°C within 75 years — for the region was said to be forced by “increased solar activity“ and the NAO.  Again, this would appear to support the significant role of natural factors in climate changes, and less so the anthropogenic influence, thus supporting both N(1) and N(2).   In the graph, notice how closely temperatures correspond to increases and decreases in solar activity.
“The temperature reconstruction from Lake Atnsjøen indicates that recent and ongoing climate warming began already in 1800 CE following the LIA. Temperatures increased very fast, from 8.5 to 12.8 °C during the first 75 years [1800-1875], but in the 20th century the increase became less pronounced.”


25.  Abrantes et al. (2017), refer to the Modern Grand Maximum (1940-2000) of very high solar activity, and, like the other authors above, suggest solar activity is a driver of cooling and warming events.
“The coldest SSTs are detected between 1350 and 1850 CE, on Iberia during the well-known Little Ice Age (LIA) (Bradley and Jones, 1993), with the most intense cooling episodes related with other solar minima events, and major volcanic forcing and separated by intervals of relative warmth (e.g. (Crowley and Unterman, 2013; Solanki et al., 2004; Steinhilber et al., 2012; Turner et al., 2016; Usoskin et al., 2011). During the 20th century, the southern records show unusually large decadal scale SST oscillations in the context of the last 2 millennia, in particular after the mid 1970’s, within the Great Solar Maximum (1940 – 2000 (Usoskin et al., 2011))”
It would not appear that Abrantes et al. (2017) are dismissing solar activity as having any role at all in climate changes, which is what the “consensus” asserts.
Also, this paper provides multiple reconstructions from the region and for the entire Northern Hemisphere that would support N(2), and would not support A(2), as they show that modern temperatures do not fall outside the range of natural variability.   All three graphs below even show a cooling trend beginning in the late 20th century, which would appear to be inconsistent with the perspective that CO2 changes are driving climate synchronously on a global scale.   Most of the modern warming is shown to have occurred during the first half of the 20th century, when CO2 emissions were but a fraction of what they were after 1950.  Again, this would not be consistent with the perspective that CO2 is driving up post-1950 temperatures at an unprecedented rate.


 

26.  Wang et al. (2017) characterize the impact of GHGs on the regional signal for the last 1000 years as a “reasonable speculation”.   “Reasonable speculation” that the millennial-scale changes may have been affected by GHGs would not appear to be a ringing endorsement.  Furthermore, millennial-scale changes would appear to be distinct from the changes after 1950, as human emissions could not have been driving climate on that timescale.    The authors also agree that their findings are consistent with Dr. Scafetta’s work, a scientist who has taken the position that the Sun has played a major role in climate changes, including during the modern era.
“The driving forces of climate change were investigated and the results showed two independent degrees of freedom —a 3.36-year cycle and a 22.6-year cycle, which seem to be connected to the El Niño–Southern Oscillation cycle and the Hale sunspot cycle, respectively. … Solar variability has been shown to be a major driver of climate in central Europe during the past two millennia using Δ14C records. Furthermore, this result is essentially in good agreement with the findings of Scafetta e.g. refs 17, 18, 19, who found that the climate system was mostly characterized by a specific set of oscillations and these oscillations (61, 115, 130 and 983 years) appeared to be synchronous with major astronomical oscillations (solar system, solar activity and long solar/lunar tidal cycles).”
27. Other than natural vs. anthropogenic attribution for warming temperatures, PH54 does not address any of the other positions detailed in the 400+ papers compilation…other than to poke fun at the bat extinction and turbine waste issues.  The papers asserting the inadequacies of the models go unaddressed, as do the papers on the cryosphere, cloud variations and surface solar radiation.  The much higher temperatures and sea levels of years past, when CO2 concentrations were in the “safe” range, would appear to be a topic with some cogency when discussing global-scale warming.   None of the ~140  papers on the 2nd list were even touched on.
Apparently it is believed that all that is needed to “debunk” a compilation such as this is to point out that only a handful of the papers (Smirnov, 2017, Hertzberg et al., 2017, Kramm et al., 2017, Nikolov and Zeller, 2017, Harde, 2017, Lightfoot and Mamer, 2017. Blaauw, 2017,  Allmendinger, 2017, Abbot and Marohasy, 2017 ) explicitly denounce anthropogenic CO2 as a main climate driver.
I disagree…for reasons that are nuanced.

04.11.17 Update 
A Response To potholer54’s Response

A commenter here has brought to my attention that potholer54 (for brevity, I will continue using PH54) has replied to my response to his rather underwhelming YouTube critique of our list of 400+ papers (which will likely reach 500 by year’s end).
Apparently PH54 still is under the impression that he has (a) correctly interpreted what the papers say about CO2 emissions as the main climate driver (even though many don’t even mention CO2 or anthropogenic influences), and (b) he doesn’t have to address what the bulk of the papers and graphs are supporting: that there is nothing unusual or remarkable about modern day climate changes (temperatures, glacier melt, sea level rise, weather events, precipitation patterns, etc.), and thus many of the modeled expectations that indicate there should be a clearly recognizable anthropogenic signal in the above parameters have been thoroughly undermined.   I’ll address both points here.
PH54 writes: “Richards shows quite neatly in his rebuttal that they [the papers] don’t even say what Richards himself claims they say.”
Obvioiusly I will need to again address PH54’s claim that he has correctly interpreted what the papers say.  We’ll start with his claim that Yndestad and Solheim (2017) have only referred to the Holocene in their paper.  (In the video, he underlines in red the years 1000 A.D. and 1700 A.D. found in the abstract so as to support this contention.)  PH54  claims these scientists do not refer to the current era.  To support his claim that Yndestad and Solheim were only referring to the Holocene, PH54 decided to omit or ignore the part of the abstract where it says:
Deterministic models based on the stationary periods confirm the results through a close relation to known long solar minima since 1000 A.D. and suggest a modern maximum period from 1940 to 2015. The model computes a new Dalton-type sunspot minimum from approximately 2025 to 2050 and a new Dalton-type period TSI minimum from approximately 2040 to
2065.
So the authors not only refer to the 20th and 21st century in the paper’s abstract, they forecast a solar minimum and cooler temperatures for the coming decades.   Nowhere in the paper are there references made to CO2 or anthropogenic influences on climate, as PH54 falsely contends.  Furthermore, one of the scientists’ main points is that the very high solar activity that we have enjoyed in recent decades is only now declining.   The Modern Grand Maximum did not begin to decline in the 1950s, as claimed, but only after the year 2000.  In fact, the year 2000 is characterized as the peak of the current grand maximum.
“[T]he activity level of the Modern Maximum (1940–2000) is a relatively rare event, with the previous similarly high levels of solar activity observed 4 and 8 millennia ago (Usoskin et al., 2003). … A cold period was also observed during the time of the Dalton minimum. The Maunder and the Dalton minima are associated with less solar activity and colder climate periods. …  Studies that employ cosmogenic isotope data and sunspot data indicate that we are currently leaving a grand activity maximum, which began in approximately 1940 and is now declining (Usoskin et al., 2003; Solanki et al., 2004; Abreu et al., 2008).  … A visual inspection of the TSI wavelet spectrum reveals the dominant periods in the TSI data series in the time window between 1700 and 2013. The long wavelet period has a maximum in 1760, 1840, 1930, and 2000, with a mean gap of approximately 80 years”
Not only this, but contrary to PH54’s claims that Yndestad and Solheim do not connect solar activity to modern-day temperatures, these scientists indicate that the Hoyt-Schatten/Scafetta-Wilson TSI reconstruction shows  a “strong correlation“ with Northern Hemisphere temperatures extending from 1880 to 2013, citing the work of Soon et al. (2015) in affirming a “a strong solar influence on the temperature of the Northern Hemisphere“.
“Periods with few sunspots are associated with low solar activity and cold climate periods. Periods with many sunspots are associated with high solar activity and warm climate periods.  … The Hoyt-Schatten irradiance model has been calibrated and extended with the newest version of ACRIM TSI observations (e.g. Scafetta and Willson, 2014, Fig. 16); it is employed in this analysis. In the following section, this reconstruction is referred to as TSI HS. A mostly rural Northern Hemisphere composite temperature series 1880–2013 shows strong correlation with the TSI-HS reconstruction, which indicates a strong solar influence on the temperature of the Northern Hemisphere (Soon et al., 2015).”

It should be noted that Soon et al. (2015) found a very strong correlation between solar activity and Northern Hemisphere rural temperatures since 1880 – as the rural instrumental data are less affected by artificial or non-climatic warming.
“Finally, we compare our new composite to one of the solar variability datasets not considered by the CMIP5 climate models, i.e., Scafetta & Willson, 2014’s update to the Hoyt & Schatten, 1993 dataset. A strong correlation is found between these two datasets, implying that solar variability has been the dominant influence on Northern Hemisphere temperature trends since at least 1881.”


PH54 writes:
“The first paper Richards cites in his rebuttal – a paper by Li et al. – is itself a good example of this.  Citing that paper, Richards concludes: “There appears to be a very close correlation between the solar activity and the hemispheric temperature, including during the 20th century, when CO2 is said to have been the temperature driver.  “There APPEARS to be” means this is what Richards thinks – it is not the conclusion of the paper.”

PH54 also once again claims that Li et al. (2017) support his claim that CO2 emissions from humans are what have driven temperature increases for the region since about 1950, and that solar activity has not driven the temperature increase.  But, as mentioned above, the authors cite a graph of temperatures for North China that, yet again, does not show any net warming since about 1940.   While this is somewhat problematic in supporting the contention that CO2 has driven the warming trend there, the authors also point out that the increase in greenhouse gases may “partly” play a role in the variability during “the recent warming periods”, but that partial role in influencing variability is only superimposed on the solar-dominated control.   Once again, this would not appear to support PH54’s claim that Li et al. (2017) endorse the position that CO2 increases are the main, close-to-100% control on temperature changes for the region during the “recent warming periods”.
“[H]igh volumes of greenhouse gases such as CO2 and CH4 during the recent warming periods, may also play a role in partly affecting the climatic variability in NC, superimposing on the overall solar-dominated long-term control (e.g., Wanner et al., 2008; Tan et al., 2011; Kobashi et al., 2013; Chen et al., 2015a,b).”
“[T]he 103, 50, and 22 year periods for TANN [annual temperatures] correlate well with the 100, 50, 23 and 22 year cycles for the solar activity observed in various solar parameters (e.g., Wilson et al., 1996; Li et al., 1996; Chowdhury et al., 2009; Zhang et al., 2014), therefore implying an in-phase relationship between the climatic oscillation in NC [North China] and solar activity.”

PH54: “The reason Richards got it wrong is that he was trying to discern solar fluctuations over the last 50 years in a graph that spans 1,000 years, so the curves over that narrow period are very small and indistinct. Perhaps Richards wasn’t wearing his glasses.”
As shown in the initial response above, several other reconstructions of Northern Hemisphere temperature show strong consistencies with trends in solar activity.  The above criticism assessing an inability to discern solar fluctuations would not appear to be valid here.

Stoffel et al., 2015


Christiansen and Lungqvist (2012)


But these graphs, and the main problem with PH54’s analysis in general, is that he thinks that by directly referencing a grand total of 9 papers in his video, he has comprehensively assessed and correctly interpreted the entire volume of 400+ papers accurately, and that they all affirm his presuppositions that in about 1950 CO2 emissions became the dominant cause of climate change, and the natural factors that used to be the dominant causes of climate change figuratively took a backseat.  That’s why he curiously writes, without obviously having even read even close to “many” of these papers, that:
PH54: “Many of the 400 papers explicitly ENDORSE the conclusion that CO2 is a powerful greenhoue gas.”   
Of course, this claim is an assumption, not rooted in actual analysis of the 400+ papers.  It’s also an example of how the definition of what is necessary to affirm an endorsement of the “consensus” changes mercurially to fit the presupposition.  Now all that’s needed to affirm that these papers are invalid as evidence supporting a skeptical position on climate alarm is that an author need only write (explicitly) that CO2 is a “powerful greenhouse gas.”   PH54 claims that there are “many” such papers here…after having “analyzed” about 9 of them.  Of course, whether or not CO2 is a “powerful greenhouse gas” — interestingly, water vapor is also a “powerful greenhouse gas” — is not even the question being affirmed or questioned here.  It’s just moving the pea.

The question is this: To what extent, or how much, are trends in weather extremes, surface temperatures, ocean heat content, glacier melt, sea level rise, floods, droughts, etc., influenced by parts per million (0.000001) changes in atmospheric CO2 concentrations and human emissions vs. the extent to which identifiable trends vary naturally, or without anthropogenic influence?
The “consensus” position, as endorsed by the IPCC, is that close to 100% of the climate change that has occurred since 1950 is human caused.
If that’s the case, then human-caused climate change doesn’t look much different than the one produced by natural variations.  The changes in modern climate indices are so negligible, so trivial, that finding an anthropogenic signal amid the noise of natural variability is quite difficult.   That’s what most of these papers say.  And that’s exactly what PH54 writes nothing about in his “critique” of our list.
And yet PH54 apparently thinks that all he must do is claim that “many” of the papers support (actually, “explicitly ENDORSE”) the position that CO2 is a “powerful greenhouse gas”, and, just like that, the 400+ papers will . . . go away.
No, that’s just not how it works.
The following are just a tiny fraction of the papers from 2017 supporting a skeptical position on climate alarm . . . that PH54 never even bothered to read.

350 Non-Hockey Stick Graphs, With The First ~120 From 2017
• There has been no detectable long-term acceleration in sea level rise (Parker and Ollier, 2017), and sea levels may only be rising between 0.25 and 1.04 mm/year.
“[L]ocal sea-level forecasts should be based on proven local sea-level data. Their naïve averaging of all the tide gauges included in the PSMSL surveys showed ‘‘relative’’ trends of about + 1.04 mm/year (570 tide gauges of any length). By only considering the 100 tide gauges with more than 80 years of recording, the average trend was only + 0.25 mm/year [2.5 centimeters per century].”
“….does not support the notion of rapidly changing mass of ice in Greenland and Antarctica“
“loud divergence between sea level reality” and “the climate models [that] predict an accelerated sea-level rise driven by the anthropogenic CO2 emission.”

• The melting of the Greenland ice sheet that could possibly be attributed to humans is still “too small to be detected”. (Haine, 2016, Orsi et al., 2017)
“Notably, the three studies [Jackson et al., 2016;  Böning et al., 2016; Robson et al., 2016] report an absence of anthropogenic effects on the AMOC, at least so far: the directly observed AMOC weakening since 2004 is not consistent with the hypothesis that anthropogenic aerosols have affected North Atlantic ocean temperatures. The midlatitude North Atlantic temperature changes since 2005 have greater magnitude and opposite sign (cooling) than those attributed to ocean uptake of anthropogenic heat. The anthropogenic melt from the Greenland ice sheet is still too small to be detected.
“The recent warming trend in North Greenland  … We find that δ 18O [temperature/climate proxy] has been increasing over the past 30 years, and that the decade 1996-2005 is the second highest decade in the 287-year record. The highest δ 18O [temperature/climate proxy] values were found in 1928, which is also an extreme year in GISP2 and NGRIP ice cores, and in a coastal South Greenland composite (Vinther et al., 2006; Masson-Delmotte et al., 2015), but the decadal average (1926-1935) is not statistically different from the decade (2002-2011). … The surface warming trend has been principally attributed to sea ice retreat and associated heat fluxes from theocean (Serreze et al., 2009; Screen and Simmonds, 2010a, b), to a negative trend in the North Atlantic Oscillation (NAO) since 1990, increasing warm air advection on the West Coast of Greenland and Eastern Canada (Hanna et al., 2012; Fettweis et al., 2013; Ding et al., 2014), and to an increase in the Greenland Blocking Index [Hanna et al., 2013]. These latter mechanisms could be dominated by natural variability rather than forced response to the anthropogenic increase in greenhouse gases (Fettweis et al., 2013; Screen et al., 2014).”
• The Greenland ice sheet (GIS) has been melting so slowly and so negligibly in recent decades that the entire ice sheet’s total contribution to global sea level rise was a mere 0.39 of a centimeter (0.17 to 0.61 cm) between 1993 and 2010 (Leeson et al, 2017).
• The Western Antarctic Peninsula has been rapidly cooling since 1999 (-0.47°C per decade), reversing the previous warming trend and leading to “a shift to surface mass gains of the peripheral glacier” (Oliva et al., 2017).
• Since 1800, the Surface Mass Balance for the entire Antarctic Ice Sheet has increased.  (Thomas et al., 2017).
“Our study suggests an overall increase in SMB [surface mass balance] across the grounded Antarctic ice sheet of ~ 44 GT since 1800 AD, with the largest (area-weighted) contribution from the Antarctic Peninsula (AP).”
• There has been no continent-scale warming trend for Antarctica since CO2 emissions began rising. (Stenni et al., 2017)
“[N]o continent-scale warming of Antarctic temperature is evident in the last century.”

• According to Fettweis et al. (2017), the Greenland ice sheet contributed a grand total of 1.5 centimeters of sea level rise between the years 1900 and 2010, with most of that contribution coming prior to 1940 (since there was no contribution at all between 1940 and 2000). The ice sheet gained mass between 1961 and 1990, or during the same period of time that CO2 emissions were skyrocketing.
“The period 1961–1990 has been considered as a period when the total mass balance of the Greenland ice sheet was stable (Rignot and Kanagaratnam, 2006) and near zero. However, at the last century scale, all MAR reconstructions suggest that SMB [surface mass balance] was particularly positive during this period [1961-1990] (SMB was most positive from the 1970s to the middle of the 1990s), suggesting that mass gain may well have occurred during this period, in agreement with results from Colgan et al. (2015). … Finally, with respect to the 1961–1990 period, the integrated contribution of the GrIS SMB anomalies over 1900–2010 is a sea level rise of about 15 ± 5 mm [1.5 cm], with a null contribution from the 1940s to the 2000s”
• Greenland is currently about 3 degrees C colder than it was just a few thousand years ago (Kobashi et al., 2017).

“Greenland temperature reached the Holocene thermal maximum with the warmest decades occurring during the Holocene (2.9 ± 1.4 °C warmer than the recent decades [1988-2015]) at 7960 ± 30 years B.P.”
• The Greenland ice sheet has been cooling (slightly) since 2005 (Kobashi et al., 2017).

“For the most recent 10 years (2005 to 2015), apart from the anomalously warm year of 2010, mean annual temperatures at the Summit exhibit a slightly decreasing trend in accordance with northern North Atlantic-wide cooling.”
• The Southern Ocean has been cooling since 1979 (Turney et al., 2017, Kusahara et al., 2017).
“Occupying about 14% of the world’s surface, the Southern Ocean plays a fundamental role in ocean and atmosphere circulation, carbon cycling and Antarctic ice-sheet dynamics. … As a result of anomalies in the overlying wind, the surrounding waters are strongly influenced by variations in northward Ekman transport of cold fresh subantarctic surface water and anomalous fluxes of sensible and latent heat at the atmosphere–ocean interface. This has produced a cooling trend since 1979.”

“Concomitant with this positive trend in Antarctic sea ice, sea surface temperatures (SSTs) over the Southern Ocean south of approximately 45°S have cooled over this period [since 1979].”
• Sea ice for the entire Southern Hemisphere has been growing, defying climate models (Comiso et al., 2017).
“The Antarctic sea ice extent has been slowly increasing contrary to expected trends due to global warming and results from coupled climate models.”

• Sea ice for the Northern Hemisphere has undergone an oscillation in the last 80 years, consistent with temperature trends for all of the Arctic (Connolly et al., 2017, Hanhijärvi et al., 2013).
“According to this new dataset, the recent period of Arctic sea ice retreat since the 1970s followed a period of sea ice growth after the mid 1940s, which in turn followed a period of sea ice retreat after the 1910s. Our reconstructions agree with previous studies that have noted a general decrease in Arctic sea ice extent (for all four seasons) since the start of the satellite era (1979). However, the timing of the start of the satellite era is unfortunate in that it coincided with the end of several decades during which Arctic sea ice extent was generally increasing. This late-1970s reversal in sea ice trends was not captured by the hindcasts of the recent CMIP5 climate models used for the latest IPCC reports, which suggests that current climate models are still quite poor at modelling past sea ice trends.”


HadCRUT4 Data – Graph Source: climate4you

•The North Atlantic has been rapidly cooling since 2005 (Piecuch et al., 2017)
“The subpolar North Atlantic (SPNA) is subject to strong decadal variability, with implications for surface climate and its predictability. In 2004–2005, SPNA decadal upper ocean and sea-surface temperature trends reversed from warming during 1994–2004 to cooling over 2005–2015.”

Share this...FacebookTwitter "
"
Share this...FacebookTwitterNormally even the German conservative media have been supportive of Germany’s shift from fossil fuels over to green energies, and most leading conservative media outlets accept that climate change is mostly man-made and thus needs to be taken seriously.
Climate science skepticism is scorned in Germany.
So it’s all the more surprising that one of Germany’s leading center-right dailies, Die Welt, came out with an article seriously challenging Germany’s Energiewende (transition to green energies).
Citing a 20-page report by McKinsey, Die Welt writes that the Energiewende risks becoming “an economic disaster” (it in fact already has) and that the opinions on the Energiewende by McKinsey are totally opposite of those held by the German government. This shows two things: the growing chasm between the German government’s view and reality, and 2) the government’s stubborn refusal to acknowledge that their energy policy has become a dismal failure.
According to Die Welt, a team of McKinsey experts examined 15 criteria and concluded: “The costs will continue to rise“, and thus contradict the German government’s claim of “stable prices”.
In fact 11 of the 15 criteria that were examined had worsened. According to the report:
The current figures available show that the previous success of the Energiewende for the most part has come from expensive subsidies. At the same time goals whose fulfilment do not depend on direct financial support are becoming increasingly more unrealistic.”
Die Welt writes that McKinsey’s conclusion “must be really painful for the government“, which had hoped to see reductions in CO2 emissions. The bitter reality is that CO2 emissions have in fact risen over the past years and today they are more than 13% over the original target.
Green jobs eroding
The Energiewende has also failed on the jobs creation front, Die Welt writes. Proponents claimed earlier that renewable energies would lead to a jobs boom. But that too has not materialized in any way, shape or form. Jobs in the sector have fallen “for the 4th year in a row – falling from 355,400 to 330,000“. The leading German national daily adds that the biggest job losses came from the onshore wind and solar sectors where 15,000 jobs were lost.
McKinsey warns that the number employed in green energy could even fall below 2008 levels!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And not only “green energy” jobs are being slashed. McKinsey also found that for the first time in 2016 jobs in energy-intensive industries were lost. Die Welt reports:
In March 2016 there were in total 15,000 jobs less than a half year earlier.”
Cost of electricity production to jump 40%
The total cost of producing electricity for the country has also surged due to the Energiewende, McKinsey writes:
The cost of supplying electricity in Germany will rise from 63 billion euros today to 77 billion euros annually by 2015. In 2010 the cost was 55 billion euros.”
This means much higher prices for consumers, who have seen their electricity prices rise to 30.38 euro-cents per kilowatt-hour. For the average German household this will translate into 335 euros of more costs every year by 2025.
Meanwhile the average European electricity price has dropped.
47.3 percent more expensive than average European power
Currently German electricity prices are on average almost 3 times more than what consumers in the USA pay.
The McKinsey report found:
In the meantime the price level for German household power is 47.3 percent above the European average.“
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGrape Harvest Date Evidence: 
No Significant Modern Warmth

Public domain photo. Source here
In a late February (2017) interview on a U.S. news program, mechanical engineer Bill Nye claimed that the settled science says humans have been warming the planet at a rate that is  unnaturally and “catastrophically” fast since the year 1750 .
“It’s a settled question. The speed that climate change is happening is caused by humans.  Instead of climate change happening on timescales of millions of years or 15,000 years, it’s happening on the timescale of decades, and now years. …  Humans are causing it [climate change] to happen catastrophically fast.   [Without human activity], the climate would be like it was in 1750.”
When pressed to identify the signature change affirming this rapid human-caused acceleration, Nye immediately cited viticulture evidence, or grape-growing practices in England and France.
“Britain would not be very well suited to growing grapes as it is today [if not for human activity].  French winemakers would not be buying land to the north, as they are now [if not for human activity].”
Apparently Bill Nye believes it is quite unusual to grow grapes in England. Or maybe he believes that this has never happened before given his perceptions of the unprecedentedly fast pace of climate change since 1750. Perhaps he doesn’t realize that grape vineyards have been growing in England for thousands of years, or that grape harvesting occurred 100s of kilometers further north than it does today as recently as during the latter stages of the Medieval Warm Period (~1100 to 1300 A.D).
Considering how very sensitive grapes are to climate conditions, and that grapes can only be harvested successfully after ripening in climates that average a specified number of warm days per year, the use of grape harvest dating as a proxy for temperature has long been thought to be both promising and reliable.
Unfortunately for Bill Nye and those who believe modern warmth is exceptional, or that the climate has changed at a catastrophically fast pace since 1750, scientists who use grape harvest dates to reconstruct historical temperatures have not found that modern warmth is either unusual or unprecedented.  In fact, grape harvest date evidence suggests the opposite conclusion reached by Bill Nye is more accurate: there is nothing unusual about the modern climate and its “well-suitedness” to grape harvesting.  In fact, there were several periods of greater warmth than today (and thus better suitability for grape harvesting) during the multi-centennial (~1400-1900 A.D.) Little Ice Age — which had the coldest temperatures of the last 10,000 years.
In other words, there is nothing unusual, unprecedented, or remarkable — let alone “catastrophically fast” — about either the pace or degree of warmth in the modern climate.

Grape Harvesting 500 Kilometers North Of Present From 1100 – 1300 A.D.

Easterbrook, 2011
“The Medieval Warm Period (MWP) was a time of warm climate from about 900 A.D. to 1300 A.D. when global temperatures were apparently somewhat warmer than at present. Its effects were evident in Europe where grain crops flourished, alpine tree lines rose, many new cities arose, and the population more than doubled. The Vikings took advantage of the climatic amelioration to colonize Greenland, and wine grapes were grown as far north as England where growing grapes is now not feasible and about 500 km north of present vineyards in France and Germany. Grapes are presently grown in Germany up to elevations of about 560 m, but from about 1100 A.D. to 1300 A.D., vineyards extended up to 780 m, implying temperatures warmer by about 1.0-1.4°C (Oliver, 1973). Wheat and oats were grown around Trondheim, Norway, suggesting climates about 1°C warmer than present (Fagan, 2000).”

Grape Harvest Dating From 1300s -1500s A.D. Suggest Temperatures Were 1-2°C Warmer Than 20th Century

Pfister, 1988
“In 1420 wine harvest in Western and Central Europe began at the end of August, even on altitudes of 500 to 700 m (Bern, Toggenburg). This is the earliest date ever recorded. …  In 1420 the warm phase started in February. In March summer began already. The vine bloom was two weeks earlier than in 1893- the most advanced year within the instrumental period.”
“The comparison of the phenophases in 1420 and 1540 with the corresponding extremes documented with thermometrical evidence suggests that in 1420 all months from February to August (in 1540 from April to August) may have been 2 to 3 degrees above the 1901-60 average.  … [I]n 1270 and 1304 the early burgundy grapes were ripe at about the same time as in 1540, whereas in 1331 the ripening of the first cherries in Western France and the beginning of the wine harvest in Paris coincided roughly with the corresponding phenophases in 1420.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“In 1420 the first ‘new wine’ from these grapes was drunk at the beginning of August, in 1540 on August 15, about twenty days before the wine harvest was opened. If this delay was the same in ordinary years, the mean grape harvest date would be around September 1st in the High Middle Ages, which is a few days earlier than in the warmest summers documented with thermometric measurement. From a regression approach comparing the decennial means of wine harvest dates and temperatures from 1370 to 1850 it has been estimated that an opening of the harvest on September 1st corresponds to a mean temperature from April to September that is 1.7 (+ -0.2) degrees above the average for 1901-60.”
“In the four years 1774, 1777, 1779, 1781, the only ones documented by thermometrical measurement, temperatures in August and September were 2.0 degrees above the 1901-60 average. From 1269 to 1339 positive anomalies [like these] occurred more than once every decade on average; this suggests that they were part of the “normal” climatic pattern; after 1340 their frequency drops to a level of 5%, after 1400 they became very rare. Not a single occurrence is measured for the seventeenth century. Since 1781 they have not been recorded any more. Undoubtedly the early fourteenth century marks a climatic watershed. The frequent occurrence of high maximum densities before 1330 can be interpreted in the context of a warm climate to which an advance in the beginning of the grape harvest is connected. It may be hypothesized that summers which were outstanding according to the standards of later periods, such as those of 1420, 1473 or 1540 were within the normal range of fluctuations during the High Middle Ages.”

Grape Harvest Dating Only Mildly Different Now Than During The 1600s – 1800s

Chuine et al., 2004
“Figure 1 [below] shows two early warm decadal fluctuations: one in the 1380s (0.72 °C) and one in the 1420s (0.57 °C), both above the 95th percentile. The warm period of the 1420s was followed by a cold period that lasted from the mid-1430s to the end of the 1450s (0.45 °C, under the 10th percentile). Our series also reveals particularly warm events, above the 90th percentile, in the 1520s and between the 1630s and the 1680s. These decades were as warm as the end of the twentieth century. The high-temperature event of 1680 was followed by a cooling, which culminated in the 1750s (under the 5th percentile) — the start of a long cool period that lasted until the 1970s.”


Menzel, 2005


Guillet et al., 2017


20th/21st Century Grape Harvest Dates Have Not Undergone Significant Change

Moreno et al., 2016 
“This paper reports a climatic reconstruction approach for the Minho region (NW of Portugal) using grape harvest dates (GHD) as proxy of surface air temperature. … The major external forcing of the climate system derives from the Sun. A solar signature has been found in global mean surface temperatures, with evidence directly related to two noticeably different features of the Sun’s dynamics: its short-term irradiance fluctuations and secular patterns of 22-year and 11-year cycles (Scafetta and West, 2008). … [I]t is recognized that solar forcing manifestations denote a strong spatial and seasonal variability (Usoskin et al., 2006), and this would be the reason why it might be illusive to seek a single global relationship between climate and solar activity (de Jager, 2005). Thus, Le Mouël et al. (2009) stated that a regional approach may allow one to identify specific forms of solar forcing, where and when the solar input is most important. … [S]olar footprints on terrestrial temperatures [are] due to the strong non-linear hydrodynamic interactions across the Earth’s surface, and the accepted longer-term solar activity influence creating temperature oscillations for tens or even hundreds of years (Scafetta and West, 2003, 2007, 2008). … These spectral analysis results appear to support a solar forcing with regards to Minho GHD [grape harvest dates].”

 

Etien et al., 2008

 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterFormer Supervisory Board Chairman of German chemicals giant BASF Jürgen Hambrecht has “sharply criticized” the German government for “deceiving the public and giving them the runaround” when it comes to the Energiewende, reports the online N24/Die Welt here
Hambrecht, considered one of Germany’s most influential executives, gave an interview to N24/Die Welt together with FDP politician Volker Wissing.
German government putting out fake information
The German daily wrote in the photo caption that Hambrecht “is furious about government political information being totally disconnected from reality“.
He describes the German political environment as one that has been hijacked by emotional thinking and fear, with facts being left on the wayside.
The 70-year old executive, who recently joined the FDP Free Democrat Party, told N24/Die Welt that German competitiveness “is acutely at risk” — and what is especially irritating is the massive taxpayer-paid disinformation recently put out by the the Ministry of Economics in a brochure claiming page after page that the country’s Energiewende [transition to renewable energies] was a “success story”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Energiewende in reality a “huge botch”
Yesterday this blog wrote here how in just one year more than 330,000 German households had their power supply cut-off because electricity had become too expensive, and how German energy-intensive companies — like chemicals — were hurting.
On the brochure put out by Ministry of Economics, Hambrecht commented to N24/Die Welt:
‘Our success story’ is its title. Then there many pages of praise over falling electricity prices and stable supply.”
Hambrecht says the brochure in fact “has little to do with reality” and that the truth is:
The Energiewende is a huge botch. The costs continue to rise and the supply stability will be at extreme risk if we phase out coal and gas after ending nuclear. That annoys me a immensely as the citizens are being deceived and given the runaround.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSchneefan here reports that the Alps are seeing heavy snowfall down to 1800 meters elevation: live-video.
And if there’s a sure sign that fall is arriving in Europe, it is that the Zugspitze, Germany’s highest peak, is forecasting snow for the next 7 consecutive days:

Source: www.wetteronline.de/wetter/zugspitze
Some may be asking what remains ahead for Europe over the next few months: Can we expect more warm summerlike weather, or should we expect a chilly fall?
Looking at the NOAA CFSv2 weather model for the coming 3 months, signs point to a colder than normal season (click to enlarge). 


Meteociel/CFS projection made on August 30th, temperature deviation from the mean at 850 hPa (approx. 1500m) in Europe for fall 2017. Source: www.meteociel.fr/modeles/cfsme_cartes.php. 
Frigid winter?
The projection for the coming European 2017/2018 winter for now looks frigid:

Meteociel/CFS made on August 30th, temperature deviation from the mean at 850 hPa (approx. 1500m) in Europe for winter 2017/18. Source: www.meteociel.fr/modeles/cfsme_cartes.php.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




What’s behind the frigid forecast? Schneefan explains:
At the end of August in Eastern Siberia there was an unusual snowfall, which led to widespread power outages and the enactment of a state of emergency.
Early snowfall in Siberia often indicates a higher likelihood of harsher European winters. Do keep in mind, however, that seasonal forecasts are fraught with much uncertainty.
Another factor that bodes ill is that solar activity has since entered into a quiet phase. Studies have shown that European winters tend to be harsher during periods of low solar activity.
Arctic sea ice “death spiral” dies
Arctic sea ice area is currently at the mean of the past decade or so. This means that Arctic sea ice has pretty much stabilized at a low level and does not show signs of shrinking further over the mid-term. The once claimed Arctic sea ice “death spiral” has lost its life.
Greenland snow and ice mass “embarrassment”
Joe Bastardi at the latest Weatherbell Analytics Saturday Summary also looks at the situation in Greenland, which has not been getting any mention from the global warming weather-ambulance-chasing alarmists lately.

Top: The total daily contribution to the surface mass balance from the entire ice sheet (blue line, Gt/day). Bottom: The accumulated surface mass balance from September 1st to now (blue line, Gt) and the season 2011-12 (red) which had very high summer melt in Greenland. Source: DMI here. 
In his video, the 40-year veteran meteorologist says Greenland snow and ice mass balance is “way, way, way above normal” and that it is the “climate story nobody is talking about it because it’s an embarrassment given what was being said two years ago, really“.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Expert software engineer and climate science blogger/critic Tony Heller just posted a video commenting on the just newly released National Climate Assessment (NCA) report:

“Utter garbage”
Heller starts by pointing out that “there’s a huge number of problems” with the report and that the content contradicts itself, even on the same page.
Heller says that the claim that the number of record hot days is on the rise “is simply not true” and he wonders how peer review “allows this sort of utter garbage to get through“.  Heller makes it clear that this report belongs in the garbage can of science.
Wildly fraudulent
Heller methodically explains how the NCA report used faulty computational methods to make it appear as if more record hot days have been occurring, when in fact the trend has been the opposite.
The National Climate Assessment graph is wildly fraudulent. Not only have record maximum temperatures plummeted in the US, but record minimum temperatures have plummeted too. The US climate is getting milder, not more extreme.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




 Record minimum daily temperatures (blue) and record daily maximum temperatures (red) have been falling “tremendously”, thus contradicting NCA report claims. Chart: Tony Heller here.
The computational methodology used by the NCA report authors is so dubious that Heller even goes on to wonder how “this sort of scientific garbage” ever got through peer-review. 
Consistent poor quality
Heller then singles out one of the authors of the report, known Texas Tech University climate activist/alarmist Katharine Hayhoe, reminding viewers that he has examined her work many times in the past and that the NCA report’s poor quality is consistent with that he has seen from Hayhoe in the past.
Heller’s makes his frustration with government funded climate science clear: “Government funded climate science is the biggest fraud in history.”
That statement by Heller could be disputed, however, as the history of government science fraud is long, tragic and has cost tens of millions of lives just in the last century alone. Other examples of government science fraud include eugenics, science of race, Lysenkoism, and the carbohydrate-promoting nutritional guidelines of the late 20th century, to name a few.
History indeed tells us to be very careful and skeptical about government-funded science.
One for the dustbin
President Trump should send this report to a thorough review by a panel of independent critical scientists.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterImportant Success: Clouds as a Climate Amplifier of Atlantic Ocean Cycles Confirmed
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
In September 2016 an exciting paper by a team led by Katinka Bellomo was published in the Geophysical Research Letters.
It described a climate amplifier for the Atlantic Multidecadal Oscillation (AMO) based on clouds. According to the study, the cloud effect accounts for up to one third of the AMO associated temperature change. The abstract:
New observational evidence for a positive cloud feedback that amplifies the Atlantic Multidecadal Oscillation
The Atlantic Multidecadal Oscillation (AMO) affects climate variability in the North Atlantic basin and adjacent continents with potential societal impacts. Previous studies based on model simulations and short-term satellite retrievals hypothesized an important role for cloud radiative forcing in modulating the persistence of the AMO in the tropics, but this mechanism remains to be tested with long-term observational records. Here we analyze data sets that span multiple decades and present new observational evidence for a positive feedback between total cloud amount, sea surface temperature (SST), and atmospheric circulation that can strengthen the persistence and amplitude of the tropical branch of the AMO. In addition, we estimate cloud amount feedback from observations and quantify its impact on SST with idealized modeling experiments. From these experiments we conclude that cloud feedbacks can account for 10% to 31% of the observed SST anomalies associated with the AMO over the tropics.”
In the same journal already in February 2016, an article by Tianle Yuan et al appeared on the same topic. The authors called out that the climate models were not able to reproduce the AMO ocean cycle in the tropics. They then described amplification mechanism through low-lying clouds that could incorporate the AMO into the models. The abstract follows:
Positive low cloud and dust feedbacks amplify tropical North Atlantic Multidecadal Oscillation
The Atlantic Multidecadal Oscillation (AMO) is characterized by a horseshoe pattern of sea surface temperature (SST) anomalies and has a wide range of climatic impacts. While the tropical arm of AMO is responsible for many of these impacts, it is either too weak or completely absent in many climate model simulations. Here we show, using both observational and model evidence, that the radiative effect of positive low cloud and dust feedbacks is strong enough to generate the tropical arm of AMO, with the low cloud feedback more dominant. The feedbacks can be understood in a consistent dynamical framework: weakened tropical trade wind speed in response to a warm middle latitude SST anomaly reduces dust loading and low cloud fraction over the tropical Atlantic, which warms the tropical North Atlantic SST. Together they contribute to the appearance of the tropical arm of AMO. Most current climate models miss both the critical wind speed response and two positive feedbacks though realistic simulations of them may be essential for many climatic studies related to the AMO.”
While on the subject of clouds, for German speakers the following 2 videos can be viewed until January 21, 2017 can be watched on ZDF German television:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Operation Cloud Lab: Cloud Chasers
A team of scientists flies over the USA inside the world’s largest aircraft and carry out a series of unusual experiments for understanding the atmospheric phenomena.
See video.
The second video:
Operation Cloud Lab: The sky lives
Scientists study the life of the earth’s atmosphere at an extreme elevation in their “flying lab” over the USA. What impact does man have on the atmosphere?
See video.
[Note: The originals are in English, and so with a little searching they likely can be found in the Internet.]
Share this...FacebookTwitter "
"
Share this...FacebookTwitter“EU regulation madness” knows no limits
What follows is a story that really reminds us why Britain opted out of the EU: British citizen (except for some Scots) don’t want every single bloody detail of their private lives regulated by a nanny super-state. They have had it!
EU bureaucrats think the Europeans are first-graders, and need proper upbringing.

Too brown! says the EU Kommisars. Photo credit: Popo le Chien – CC BY-SA 3.0. 
Recently reported by the online Die Welt here, the EU is now aiming to ban crispy, darker-colored french fries (darker-coloured chips for those living on the island). The reason: your safety!
“Crazy demands”
It’s just the latest damn excuse for more intrusive regulation. The EU’s regulation madness knows no limits. Just when you think it possibly couldn’t get more extreme, it does!
Our message back to EU bureaucrats: Us citizens do read, and we do know what is good for us and what isn’t. If we want our fries crispy brown from time to time, it’s for us to decide and not you clueless nanny bureaucrats in Brussels. Remember who pays you.
Past food guidelines made many of us sick
The fact of the matter is that decades-long we indeed did listen to you telling us what to eat: “high carb, low-fat”. That turned into a monumental health disaster and fiasco. And now you want to order us what to eat?
According to Die Welt:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Our fries may be golden yellow, and not darker. The EU has drawn up health-promoting rules for food processors, among them cooking instructions. The restaurant business is talking of ‘crazy demands’.”
The reason for the new laws, the EU claims, is that cooking fries and starchy products at high temperatures leads to acrylamide, a compound that studies have found increases the risk of cancer.
According to Die Welt, the EU countries have even approved the draft measure from the EU Commission. Speaking of the EU Commission, does anyone really know the name of s single person on it? Most people don’t, and it is so by design. No face, no target at which to aim criticism.
“EU regulation madness”
The law would apply to food manufacturers, restaurants and bakers. While consumer nanny groups view this as “an important step to health protection” the food and gastronomy industry are calling it “EU-regulation madness“, reports Die Welt.
If the EU wants to start doing something that really improves health, then they ought to start by taxing sugar and toxic sweeteners big time.
According to EU Health Kommissar Vytenis Andriukaitis (boy, that’s a name that’s easy to remember):
Today we have taken an important step in protecting the health and well-being of the citizens.“
No you haven’t. You have taken a step in confirming just how crazy you regulators have become.
The EU is also taking aim at the potato industry, where it intends to order potato farmer to grow “low starch potatoes” and regulate potato processors to remove starch from potatoes before frying them.
The law is planned to go into effect in Spring, 2019, Die Welt reports.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhat follows is another paper to add to the list of 400 peer-reviewed papers published this year which show claims surrounding man-made global warming are in fact hyped up. 
==================================
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
On July 4 in the journal Atmospheric and Climate Sciences an article by Maxim Ogurtsov, Markus Lindholm  and Risto Jalkanen appeared and addressed an important issue. The warming of the last 150 years after the Little Ice Age is often gladly viewed as having 100% anthropogenic causes. Of course this makes little sense because the Little Ice Age was the coldest period of the last 10,000 years and was caused by natural factors such as solar weak phases and volcanic eruptions.
“IPCC makes a large mistake”
And when the sun again strengthens and volcanic eruptions remain at low levels, the earth warms up again. That there is an anthropogenic warming component of course should not be disputed. The warming of the last 150 years is due to a mix of natural and anthropogenic causes. Here the IPCC makes a large mistake when it assumes that the warming has been 100% anthropogenic.
In the study, Ogurtsov and fellow scientists compare the modern warming to the temperature history of the last 10,000 years. Here they find that there had been only a few similar warming phases when looking at the warming of the past 135 years. If one however considers that only half of that warming was natural, then similar warming phases occur on average every few centuries. The authors conclude that the natural component in the models must be taken into account much more. And conversely the role anthropogenic factors must be reduced correspo0ndingly so that a more accurate picture is attained when compared to the real temperature development.
The Abstract:
On the Possible Contribution of Natural Climatic Fluctuations to the Global Warming of the Last 135 Years
A number of numerical experiments with artificial random signals (the second order autoregressive processes), which have important statistical pro- perties similar to that of the observed instrumental temperature (1850-2015), were carried out. The results show that in frame of the selected mathematical model the return period of climatic events, analogous to the current global warming (linear increase of temperature for 0.95˚C during the last 135 years) is 2849-5180 years (one event per 2849-5180 years). This means that global warming (GW) of the last 135 years can unlikely be fully explained by inherent oscillations of the climatic system. It was found however, that natural fluctuations of climate may appreciably contribute to the GW. The return period of climatic episodes with 0.5˚C warming during the 135 years (half of the observed GW) was less than 500 years. The result testifies that the role of external factors (emission of greenhouse gases, solar activity etc.) in the GW could be less than often presumed.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIt appears leftists have made it a habit of comparing anyone who disagrees with their views to Hitler/Nazis.
Of course climate science skeptics know this very well, as they are routinely referred to as “climate deniers”, which by reverse logic wrongly puts denying the Holocaust on the same level as doubting global warming science.
Last Friday I wrote here how German flagship ZDF national TV compared President Trump to Hitler.
This is no small matter, as the ZDF in Germany is comparable to the BBC in England.
Germany’s ZDF public television may be regretting its comparison of Trump to Hitler. German Jews call on US authorities to investigate for possible “criminal proceedings”.  Image: ZDF Frontal 21.
Now, just days later, it appears there could be potentially serious consequences for that tasteless, hatred-inciting brand of journalism.
The Germany-based online Jüdische Rundschauua has published an open letter by its publisher, Dr. Rafael Korenzecher, addressed to the head of the ZDF, Kurt Beck. 
I’ve taken the liberty to make a general translation:
==================================================



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Dear Herr Beck
We take the liberty to bring your attention to the ZDF show ‘Frontal 21’, broadcast on 24 January, 2017, and one of its segments on newly elected US President Donald J. Trump, which in our view was completely defamatory.
Using suggestive, selected film footage and accompanying audio, the President of our most important ally and the leading western democracy was in spirit and in fact put in the same proximity as Adolf Hitler.
This is not only untruthful and completely defamatory, it also trivializes the historical assessment of an unprecedented crime committed by German war criminals and those responsible for the murder of 6 million European Jews.
We bring this case up because we assume that the broadcasting of this deliberate false content got by you, and so you did not exercise the input of your political and ethical responsibility for the broadcast content of this institution of public television.
With all regards for how essential freedom of the press is for democracy, we are convinced that the irresponsible dissemination of false historical references and defamatory content cannot and must not be a part of programs that are transmitted by public broadcaster ZDF. We therefore hereby request your corresponding and appropriate action to correct this scandalous situation and to be sure that this type of incident is effectively prevented from occurring again in the future.
For the sake of good order, we further point out that we have notified the appropriate US authorities for the possibility of legal proceedings concerning the appalling poor behavior of the “Frontal 21“ editorial board and to check for the possibility of launching a criminal proceeding against the responsible persons.
Yours truly
Dr. Rafael Korenzecher 
Publisher “Jüdische Rundschau” and “Evrejskaja Panorama”

==============================================
Share this...FacebookTwitter "
"
Share this...FacebookTwitterProfessor: Climate Journalism Awash In 
‘Emotional Propaganda’, ‘Mythological Constructs’
Too Much Reliance On Models, ‘Consensus’

A University of Wollongong (Australia) investigative journalism professor with a research interest in ecological science and exposing environmental fraud has just published a scathing indictment of the climate science journalism industry in the academic journal Asia Pacific Media Educator.
Pulling no punches, Dr. David Blackall lambastes the modern climate science journalism practice of relying more on theoretical models, “expert” predictions, and authoritative “consensus” than on empirical observation and real-world physical measurements in reporting stories on global warming.
Instead of evaluating alarming claims of impending climate catastrophe with reasonable skepticism and critical review, today’s journalists not only reflexively accept the planetary meltdown narratives they promulgate, they simultaneously conceal the growing body of scientific evidence that may ameliorate the scariness of the modern climate narrative.

Journalists Refuse To Report Non-Alarmist Scientific Evidence

(1) Multiple papers have been published within the last year (Turner et al., 2016, Oliva et al., 2017) indicating that the rapid warming trend observed during the late 20th century for the Antarctic Peninsula (AP) has now reversed, and the AP has been dramatically cooling (-0.47 °C per decade) and glaciers have stopped receding in the region since 1999.   This cooling trend has not been reported by mainstream media outlets.
(2) Earlier this year, a paper (Fettweis et al ., 2017, with a review available here) was published in The Cryosphere indicating that the Greenland Ice Sheet melt had (a) contributed just 1.5 cm (0.6 of an inch) to sea levels between 1900 and 2010; (b) there was no net ice sheet loss during the 60 years between 1940 and 2000 despite explosive growth in anthropogenic CO2 emissions during that period; and (c) net ice sheet losses were similar to today during the 1930s, when CO2 concentrations were about 100 ppm lower.  This long-term Greenland Ice Sheet mass balance in an era of “alarming” warmth has not been reported by mainstream media outlets.
(3) In the 2007 IPCC report, it was claimed that glaciers in the Himalayas were melting so rapidly that the “likelihood is very high” that they would “disappear” by the year 2035.   And yet many published scientific papers have shown (here, here, here, here, here, here, and here) that the Himalayan region has not only not been warming in recent decades, but 88% of the glaciers in the region are either stable or advancing, with a net change of just 0.2% since 2000 (Bahuguna et al., 2014, Bolch et al., 2016, Holzer et al., 2015, Zhang et al., 2016).
(4) About a year ago, a NoTricksZone review of 8 recently published scientific papers revealed (a) land area across the world is expanding more rapidly than sea levels are rising; (b) climate change (warming) is not the primary determinant of sea level changes (coastal erosion and accretion, tectonic uplift and subsidence are more influential); (c) globally, sea levels are only rising by about 1 mm per year according to tide gauges; and (d) an anthropogenic signal could not be detected in regional sea level rise trends.  Of course, no mainstream media outlet publicized these scientific findings.  They don’t support the alarmist narrative.
(5) There were 133 peer-reviewed scientific papers published in 2016 linking solar forcing to climate changes.  There have already been 84 Sun-Climate papers published thus far in 2017.   More and more solar scientists are predicting a Grand Solar Minimum and concomitant global cooling in the coming decades.  Journalists have not been inclined to report on these developments in solar science.  The Sun-Climate link does not fit with narrative that humans are the predominant cause of climate changes.
(6) Finally, a collection of over 300 graphs of reconstructed historical (Holocene) temperatures has been made available in recent months. These graphs, taken from hundreds of peer-reviewed scientific papers, reveal that modern warming trends are neither unusual or unprecedented, and they do not even fall outside the range of natural (pre-anthropogenic influence) variability.   And yet what do mainstream journalists report in their headlines on a routine basis?   That today’s temperature changes are “shocking”, “stunning” and “unprecedented”.
Would it be so difficult for journalists to actually seek scientific verification of their claims before publishing?
Or is the pursuit of real-world scientific confirmation too much to expect from journalists and media sources bent on advancing an agenda in this “Post Truth World”?

Blackall, 2017


‘Forlorn’ Polar Bears An Example of  ‘Emotional Propaganda’, ‘Fake News’ Reporting

“One particularly emotive story line attached to this topic is the so-called pending extinction of the polar bear (Ursus maritimus) population. In recent times, there have been a number of claims that polar bears are threatened with extinction because global warming was melting their habitat. Yet the scientific evidence suggests to the contrary: population counts conducted between 2007 and 2017 suggest that bear numbers are on the increase. This has led Crockford (2017a) to label such claims as emotional propaganda. In the last decade, cherrypicked and unverified photographic material, ‘emotional’ videos, even animation, then used in news, of forlorn bears floating on ice was the practice (Crockford, 2016; Rode, 2014). This is a good example of ‘fake news’.”

Climate Models Not Confirmed, Harmonious Pre-Industrial Climate A ‘Mythical Construct’

“Scientific uncertainty arises from ‘simulations’ of climate because computer models are failing to match the actual climate. This means that computer models are unreliable in making predictions. Published in the eminent journal Nature (Ma, et. al., 2017), ‘Theory of chaotic orbital variations confirmed by Cretaceous geological evidence’, provides excellent stimulus material for student news writing. The paper discusses the severe wobbles in planetary orbits, and these affect climate. The wobbles are reflected in geological records and show that the theoretical climate models are not rigorously confirmed by these radioisotopically calibrated and anchored geological data sets. Yet popular discourse presents Earth as harmonious: temperatures, sea levels and orbital patterns all naturally balanced until global warming affects them, a mythical construct. Instead, the reality is natural variability, the interactions of which are yet to be measured or discovered (Berger, 2013).”

A Non-Warming Climate Doesn’t Fit The Narrative – So It’s Unreported, Manipulated

“Contrary to news media reports, some glaciers throughout the world (Norway [Chinn et al., 2005] and New Zealand [Purdie et al., 2008]) are growing, while others shrink (Paul et al., 2007). New Zealand’s National Institute of Water and Atmospheric Research and Victoria University found that ‘regional cooling’ over 25 years had correlated with growing glaciers (Mackintosh et al., 2017).”
“Sea levels too have not been obeying the ‘grand transnational narrative’ of catastrophic global warming. Sea levels around Australia 2011–2012 were measured with the most significant drops in sea levels since measurements began. This phenomenon was due to rainfall over Central Australia, which filled vast inland lakes. It was not predicted in the models, nor was it reported in the news. The 2015–2016 El-Niño, a natural phenomenon, drove sea levels around Indonesia to low levels such that coral reefs were bleaching. The echo chamber of news repeatedly fails to report such phenomena and yet many studies continue to contradict mainstream news discourse.”


Scientific Uncertainty Replaced By ‘Consensus’ (Post-Normal) Science, Model ‘Validation’

“Scientists test, measure, observe and retest, and they must be able to verify and repeat results (Errington et al., 2014). Uncertainty is always present (van Der Sluijs, 2005), but when uncertainty is replaced by ‘consensus’ (post-normal science), a culture of gatekeeping ensues (Lindzen, 2009). Post-normal science is said to be appropriate when ‘traditional methodologies are ineffective. In those circumstances, the quality assurance of scientific inputs to the policy process requires an ‘extended peer community’, consisting of all those with a stake in the dialogue on the issue’ (Funtowicz & Ravetz, 1993). Then, and dangerously, dissenters are silenced so that chosen and ‘necessary’ discourses arrive in journals, conferences and boardrooms. In such a climate, it is difficult for the assertion to be made that there might be other sources, than a nontoxic greenhouse gas called carbon dioxide (CO2), that could be responsible for ‘climate disruption’. A healthy scientific process would allow such a proposition.”
“Journalism conveys a ‘professional authority’—touting its discourse as ‘fact checked’, within ‘editorial consensus’—its validation process. However, ‘validation’ in climate science means something completely different—a model is validated, ‘acceptable for its intended use’, because it meets specified computer performance requirements (Rykiel, 1996).”

Correcting Climate Journalism’s ‘False Narratives’: Offer Public Alternative Perspectives

‘An online survey revealed similarity between climate change deniers and believers in terms of preference for climate change news sources and rating of reliability of authorities. It was also discovered that both groups do not believe in conspiracy theories. Thus the results show that participants on both sides in the discussion on climate change are similar, rational, and are basing their judgments by using similar types of sources.’ (Grabbe, 2015)
“As there is uncertainty with greenhouse gas theory, students should be given alternative perspectives to help find ways to publish stories that question, challenge and enlighten. With technological change in the traditional newsroom, which brings ‘heightened accountability’ (Bivens, 2008), and instantaneous research capability, there are plenty of opportunities to correct false narratives.”
An Alternative Perspective Example: Clouds As Climate Control Mechanism
“One avenue is to suggest the alternative narrative: clouds are crucial in climatic control, yet their role and production is not thoroughly understood. Clouds control terrestrial and ocean surface temperatures and this has been known for decades—in agronomy, geography and meteorology.  Could the great environmental catastrophe instead involve clouds and the water cycle?”

20+ New Papers Affirm The Failures Of Climate Modeling

Hedemann et al., 2017  (full paper)
“During the first decade of the twenty-first century, the Earth’s surface warmed more slowly than climate models simulated. This surface-warming hiatus is attributed by some studies to model errors in external forcing, while others point to heat rearrangements in the ocean caused by internal variability, the timing of which cannot be predicted by the models. The observed trend deviated by as much as −0.17 ◦C per decade from the CMIP5 (Coupled Model Intercomparison Project Phase 5) ensemble-mean projection—a gap two to four times the observed trend. The hiatus therefore continues to challenge climate science.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Power et al., 2017
“All of the model simulations examined simulate multi-decadal warming in the Pacific over the past half-century that exceeds observed values.”

Zhou and Wang, 2017
“Land surface air temperature (Ta) is one of the fundamental variables in weather and climatic observations, modeling, and applications. Despite the ongoing increase in atmospheric greenhouse gases, the global mean surface temperature (GMST) has remained rather steady and has even decreased in the central and eastern Pacific since 1998. This cooling trend is referred to as the global ‘warming hiatus’“

Xie et al., 2017
“As the recent global warming hiatus has attracted worldwide attention, we examined the robustness of the warming hiatus in China and the related dynamical mechanisms in this study. Based on the results confirmed by the multiple data and trend analysis methods, we found that the annual mean temperature in China had a cooling trend during the recent global warming hiatus period, which suggested a robust warming hiatus in China.”

Xian and Fu, 2017
“Despite continually increasing concentrations of greenhouse gas, there has been a hiatus in rising global temperatures during the 21st century.”

Liu and Zhou, 2017
“[C]limate models designed to represent the physics and dynamics of the climate system project that GMST [global mean surface temperature] continued to rise in the early 2000s. Dominant mechanisms proposed to understand the hiatus included the internal climate variability and ocean heat uptake and transport; however, the differences in the atmospheric footprint of recent warming slowdown remains unclear in terms of the dynamical and physical processes.”

Rosenblum and Eisenman, 2017
“Observations indicate that the Arctic sea ice cover is rapidly retreating while the Antarctic sea ice cover is steadily expanding. State-of-the-art climate models, by contrast, typically simulate a moderate decrease in both the Arctic and Antarctic sea ice covers. … [T]he models are not consistent with the observations.”

Zanchettin, 2017
“[U]ncertainties and gaps of knowledge in the characterization of forced decadal climate responses remain large, and only a few studies have systematically tackled the implication of these forcing agents for decadal predictability and prediction. For all forcing agents, major limitations in understanding arise from incompleteness and shortness of the instrumental observations concerning the forcing as well as the climate response. Further issues concern the deficient representation of key processes in climate models and limitations inherent to reconstructed evidence.”

Kravtsov, 2017
“[S]tate-of-the-art global models used to predict climate fail to adequately reproduce such multidecadal climate variations. In particular, the models underestimate the magnitude of the observed variability and misrepresent its spatial pattern. Therefore, our ability to interpret the observed climate change using these models is limited.”

Zhang et al., 2017
“Climate models, including typical regional climate models, do not directly simulate all extreme rainfall producing processes, such as convection.”

Zuidema et al., 2017
“The ‘double ITCZ’ error is further implicated in the simulated Hadley circulation, seasonal cycle and winds on the equator, and equatorial modes of variability, such as El Niño–Southern Oscillation (ENSO) in the Pacific, casting doubt on the ability to model and predict both regional and global climate. … OAFlux allows for more ocean warming than is observed, an error that implies the CMIP5 model net flux biases are even larger, by at least 10 W m−2 …  Mean CMIP5 net CRE biases are very large, up to 40 W m−2, relative to CERES values. … The CMIP5 models generally continue to underestimate subtropical stratocumulus cloud cover relative to observations“

Ahlström et al., 2017
“Our results suggest that climate biases could be responsible for a considerable fraction of the large uncertainties in ESM [Earth system models] simulations of land carbon fluxes and pools, amounting to about 40% of the range reported for ESMs. We conclude that climate bias-induced uncertainties must be decreased to make accurate coupled atmosphere-carbon cycle projections.”

Zhou et al., 2017
“The evaluation results show that 5 out of 30 climate models can well capture the observed APO [Asian-Pacific Oscillation]-related features in a comprehensive way, including the strengthened South Asian high (SAH), deepened North Pacific trough (NPT) and northward East Asian jet (EAJ) in the upper troposphere.” [25 of 30 climate models cannot capture the APO features comprehensively.]

Comiso et al., 2017
“The Antarctic sea ice extent has been slowly increasing contrary to expected trends due to global warming and results from coupled climate models. After a record high extent in 2012 the extent was even higher in 2014 when the magnitude exceeded 20 × 106 km2 for the first time during the satellite era. … [T]he trend in sea ice cover is strongly influenced by the trend in surface temperature [cooling]. …  [T]he ability of current climate models to forecast sea ice trend can be improved through better performance in reproducing observed surface temperatures in the Antarctic region.”

Stenni et al., 2017
“A recent effort to characterize Antarctic and sub-Antarctic climate variability during the last 200 years also concluded that most of the trends observed since satellite climate monitoring began in 1979 CE cannot yet be distinguished from natural (unforced) climate variability (Jones et al., 2016), and are of the opposite sign [cooling] to those produced by most forced climate model simulations over the same post-1979 CE interval. …  [L]ack of confidence in climate model skill for the Antarctic region (Flato et al., 2013). … [N]o continent-scale warming of Antarctic temperature is evident in the last century.”

Büntgen et al., 2017
“Little agreement is found with climate model simulations that consistently overestimate recent summer warming and underestimate pre-industrial temperature changes. … [W]hen it comes to disentangling natural variability from anthropogenically affected variability the vast majority of the instrumental record may be biased.”

Schroeter et al., 2017
“Antarctic sea ice extent has increased by approximately 1.5 % per decade since satellite observations began in 1979 (Parkinson and Cavalieri, 2012; Turner et al., 2015). [M]odels in the Coupled Model Intercomparison Project Phase 5 (CMIP5) exhibit decreasing sea ice trends in all months (Turner et al., 2013a). The reasons for the disparity between observed and modelled trends are not yet well understood (Bindoff et al., 2013; Hobbs et al., 2016).”

Stouffer et al., 2017
“There are a number of systematic model biases that appear in all phases of CMIP that remain a major climate modeling challenge. These biases need increased attention to better understand their origins and consequences through targeted experiments. Improving understanding of the mechanisms’ underlying internal climate variability for more skillful decadal climate predictions and long-term projections remains another challenge for CMIP6.”

Barcikowska et al., 2017
“How global temperature will evolve over the next decade or so remains unclear (Knutson et al. 2016), although the most recent warming hiatus, observed in surface temperature records over the period 1998–2014, has challenged the scientific community in terms of consistency of models versus observations and in the attribution of the phenomena (Kosaka and Xie 2013; England et al. 2014; McGregor et al. 2014; Fyfe et al. 2012).”

Hope et al., 2017
“Comparison of the observed rise in GMST [global mean surface temperature] over the past 32 years with GCM output reveals these models tend to warm too quickly, on average by about a factor of two. Most GCMs [general circulation models] likely represent climate feedback in a manner that amplifies the radiative forcing of climate due to greenhouse gases (GHGs) too strongly.”

Crockford, 2017
“Data collected between 2007 and 2015 reveal that polar bear numbers have not declined as predicted and no subpopulation has been extirpated. … [T]he hypothesis that repeated summer sea ice levels of below 5 mkm2 will cause significant population declines in polar bears is rejected. This result indicates that the ESA and IUCN judgments to list polar bears as threatened based on future risks of habitat loss were hasty generalizations that were scientifically unfounded, which suggests that similar predictions for Arctic seals and walrus may be likewise flawed, while the lack of a demonstrable ‘sea ice decline = population decline’ relationship for polar bears invalidates updated survival model outputs that predict catastrophic population declines should the Arctic become ice-free in summer.”

McKinley et al., 2017
“The current inability to accurately quantify the mean CO2 sink regionally or locally also suggests that present-day observational constraints are inadequate to support a detailed, quantitative, and mechanistic understanding of how the ocean carbon sink works and how it is responding to intensifying climate change. This lack of mechanistic understanding implies that our ability to model (Roy et al. 2011, Ciais et al. 2013, Frolicher et al. 2015, Randerson et al. ¨ 2015), and thus to project the future ocean carbon sink, including feedbacks caused by warming and other climate change, is seriously limited. … [I]t is not yet possible to directly confirm from surface observations that long-term growth in the oceanic sink is occurring. … [T]his CESM-LE analysis further illustrates that variability in CO2 flux is large and sufficient to prevent detection of anthropogenic trends in ocean carbon uptake on decadal timescales.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterDawning on Scientists: Atlantic Ocean Cycles Drive
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P. Gosselin)
The oceans are the world’s largest water reservoirs, and over 60-year cycles they swallow heat three decades long, and release over the 30 years or so that follow. In the Atlantic this phenomenon is called the Atlantic Multidecadal Oscillation (AMO).
Climate models have not been able to correctly account for them, and thus the climate prognoses are fraught with uncertainty.
However, much has been done in the area of ocean cycles research over the past years. The systematic climate impact has finally been accepted by the scientific community. A good example is a paper authored by Dan Seidov et al appearing in the Geophysical Research Letters in May.
Multidecadal variability and climate shift in the North Atlantic Ocean
Decadal variability of ocean heat content (OHC) and temperature trends over ~60 years in the North Atlantic Ocean were analyzed using a new high-resolution ocean climatology based on quality-controlled historic in situ observations. Тwo ~30 year ocean climates of 1955–1984 and 1985–2012 were compared to evaluate the climate shift in this region. The spatial distribution of the OHC climate shift is highly inhomogeneous, with the climate shift being the strongest southeast of the Gulf Stream Extension. This may be caused by the Atlantic Meridional Overturning Circulation slowdown in conjunction with heaving of warm subtropical water. The 30 year climate shift shows higher OHC gain in the Gulf Stream region than reported in shorter timescale estimates. The OHC change is generally coherent with the Atlantic Multidecadal Oscillation index. This coherence suggests that quasi-cyclicity of the OHC may exist, with a period of 60 to 80 years, superimposed on the slow basin-wide warming trend.”
Finally climatic mid-term prognoses are able to benefit from the ocean cycles, which some five years ago – when our book “The Neglected Sun” was published – we were viciously attacked by the somewhat humiliated climate establishment.
Today we are far better informed. In Ireland temperatures and precipitation are 90% related to the AMO, as McCarthy et al. documented in the journal ‘Weather‘ in July 2015:
The influence of ocean variations on the climate of Ireland
The influence of the ocean circulation on the climate of Ireland is more subtle than it first appears. Temperatures in Ireland are warmer than similar Pacific maritime climates. It is heat – carried primarily in the Atlantic overturning circulation – released over the Atlantic that provides this additional warmth. We investigate variations in Irish climate using long-term station-based time series. The Atlantic multidecadal oscillation (AMO) explains over 90% of the pronounced decadal temperature and summer precipitation variation. Understanding the impact of these ocean variations when interpreting long climate records, particularly in the context of a changing climate, is crucial.”
The natural decadal variability of the Irish climate is two times more than the warming trend the study shows. In the years of 1990-2002 variability contributed to the trend. It is not stated, but it is warned of the other downward side of the temperature signal flank:
Otherwise, decades of cooling can be seen as a contradiction to increased surface temperature trends (in response to continually increasing greenhouse gas emission) when natural ocean variability may be the cause.”
Models that well reproduce the rising flank of the AMO, and attribute it solely to CO2, overestimate CO2. Even if the full knowledge of the different reasons cannot be fully named, the profound importance of the ocean cycles and their contribution to the warming phases is emerging more and more.
A paper Bowene et al appeared in the PNAS in May, 2017. In it the authors did not dare to examine the current cycle and instead chose to look at an earlier cycle. Their message: The warming of the early 20th century in the Arctic was enhanced by ocean cycles. What follows is the press release from Kyoto University (via Science Daily):
Scientists uncover a cause for early 20th century Arctic warming
Is a warmer Arctic a canary of global warming?
Since the 1970s the northern polar region has warmed faster than global averages by a factor or two or more, in a process of ‘Arctic amplification’ which is linked to a drastic reduction in sea ice. But then how to explain a similar rapid warming that occurred during the early 20th century, when the effects of greenhouse gases were considerably weaker than today? And what can we prove about the period, given the scarcity of usable data and observations prior to the 1950s? Now scientists from Kyoto University and UC San Diego have discovered that this phenomenon occurred when the warming phase — ‘interdecadal variability mode’ — of both the Pacific and Atlantic Oceans coincided. The team’s findings appeared recently in the journal PNAS.
“We found that early 20th century sea surface temperatures in the tropical Pacific and North Atlantic had warmed much more than previously thought,” explains lead author Hiroki Tokinaga of Kyoto. “Using observations and model simulations, we’ve demonstrated that rising Pacific-Atlantic temperatures were the major driver of rapid Arctic warming in the early 20th century.” Previous explanations for early Arctic warming have including decreased volcanic aerosols and increased solar radiation, but none of these have been able to simulate observed conditions from the period.
Tokinaga’s team found that when the interdecadal rise in sea surface temperatures was included in simulation calculations, the results properly reflected early Arctic conditions. “Coupled ocean-atmosphere simulations also support the intensification of Arctic warming,” continues Shang-Ping Xie of UCSD, “which was caused by a concurrent, cold-to-warm phase shift of Pacific and Atlantic interdecadal modes.” The researchers explain that these new findings can help constrain model climate projections over the Arctic region.
“It is likely that temperatures in the Arctic will continue to rise due to anthropogenic global warming,” concludes Tokinaga. “Our study does not deny this. We are rather suggesting that Arctic warming could accelerate or decelerate due to internal variability of the Pacific and the Atlantic.” “It is a challenge to accurately predict when the next big swing of multidecadal variability will occur. Careful monitoring is essential, given the enormous impact on the Arctic climate.”
Gabriel J. Bowene et al. Early 20th-century Arctic warming intensified by Pacific and Atlantic multidecadal variability. PNAS, May 2017 DOI: 10.1073/pnas.1615880114“
In September 2015 Judith Curry discussed a paper by McCarthy et al., which projected an imminent change of the AMO to the negative, cooling AMO phase:
Ocean impact on decadal Atlantic climate variability revealed by sea-level observations
Decadal variability is a notable feature of the Atlantic Ocean and the climate of the regions it influences. Prominently, this is manifested in the Atlantic Multidecadal Oscillation (AMO) in sea surface temperatures. Positive (negative) phases of the AMO coincide with warmer (colder) North Atlantic sea surface temperatures. The AMO is linked with decadal climate fluctuations, such as Indian and Sahel rainfall1, European summer precipitation2, Atlantic hurricanes3 and variations in global temperatures4. It is widely believed that ocean circulation drives the phase changes of the AMO by controlling ocean heat content5. However, there are no direct observations of ocean circulation of sufficient length to support this, leading to questions about whether the AMO is controlled from another source6. Here we provide observational evidence of the widely hypothesized link between ocean circulation and the AMO. We take a new approach, using sea level along the east coast of the United States to estimate ocean circulation on decadal timescales. We show that ocean circulation responds to the first mode of Atlantic atmospheric forcing, the North Atlantic Oscillation, through circulation changes between the subtropical and subpolar gyres—the intergyre region7. These circulation changes affect the decadal evolution of North Atlantic heat content and, consequently, the phases of the AMO. The Atlantic overturning circulation is declining8 and the AMO is moving to a negative phase. This may offer a brief respite from the persistent rise of global temperatures4, but in the coupled system we describe, there are compensating effects. In this case, the negative AMO is associated with a continued acceleration of sea-level rise along the northeast coast of the United States9, 10.”
Let’s take a look at the current AMO curve from the NOAA:

Fig. 1: The AMO ocean cycle curve. Status: 1 September 2017. Source: NOAA.
When one looks at the previous AMO cycle, a peak in the AMO could last another decade, just as we projected in our “The Neglected Sun” book. However the PDO (Pacific Decadal Oscillation) is already falling, which will mean cooling globally over the coming years.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Climate publicity seeker Mojib Latif is by the way also a co-author of a study by Klöwer et al. from 2014. In the paper the authors projected similarly as we did in our “The Neglected Sun” book, namely that the AMO plateau would continue with a slight downward trend, i.e. slight cooling:

Fig. 2: AMO prognosis by the Latif group (from: Klöwer et al. 2014)

Fig. 3: AMO prognosis from our “The Neglected Sun” (book 2012).
So why doesn’t Latif mention this when speaking before the next industry group? Here’s the paper’s abstract:
Atlantic meridional overturning circulation and the prediction of NorthAtlantic sea surface temperature
The Atlantic Meridional Overturning Circulation (AMOC), a major current system in the Atlantic Ocean, is thought to be an important driver of climate variability, both regionally and globally and on a large range of time scales from decadal to centennial and even longer. Measurements to monitor the AMOC strength have only started in 2004, which is too short to investigate its link to long-term climate variability. Here the surface heat flux-driven part of the AMOC during 1900–2010 is reconstructed from the history of the North Atlantic Oscillation, the most energetic mode of internal atmospheric variability in the Atlantic sector. The decadal variations of the AMOC obtained in that way are shown to precede the observed decadal variations in basin-wide North Atlantic sea surface temperature (SST), known as the Atlantic Multidecadal Oscillation (AMO) which strongly impacts societally important quantities such as Atlantic hurricane activity and Sahel rainfall. The future evolution of the AMO is forecast using the AMOC reconstructed up to 2010. The present warm phase of the AMO is predicted to continue until the end of the next decade, but with a negative tendency.”
The authors write in the paper’s highlights:
North Atlantic sea surface temperature will stay anomalously warm until about 2030.”
But they could have just as well written:
The North Atlantic will cool considerably by 2030.”
Just how the AMO works is a fundamental question, similar to the “hen and the egg”, and remains to be explained. The modelers have not been able to robustly duplicate the cycle. That’s been embarrassing.
In the scientific community a controversial discussion has since broken out. Example: Amy Clement et al in October 2015 in Science:
The Atlantic Multidecadal Oscillation without a role for ocean circulation
The Atlantic Multidecadal Oscillation (AMO) is a major mode of climate variability with important societal impacts. Most previous explanations identify the driver of the AMO as the ocean circulation, specifically the Atlantic Meridional Overturning Circulation (AMOC). Here we show that the main features of the observed AMO are reproduced in models where the ocean heat transport is prescribed and thus cannot be the driver. Allowing the ocean circulation to interact with the atmosphere does not significantly alter the characteristics of the AMO in the current generation of climate models. These results suggest that the AMO is the response to stochastic forcing from the mid-latitude atmospheric circulation, with thermal coupling playing a role in the tropics. In this view, the AMOC and other ocean circulation changes would be largely a response to, not a cause of, the AMO.
Significance:
Ocean circulation changes not needed
What causes the pattern of sea surface temperature change that is seen in the North Atlantic Ocean? This naturally occurring quasi-cyclical variation, known as the Atlantic Multidecadal Oscillation (AMO), affects weather and climate. Some have suggested that the AMO is a consequence of variable large-scale ocean circulation. Clement et al. suggest otherwise. They find that the pattern of AMO variability can be produced in a model that does not include ocean circulation changes, but only the effects of changes in air temperatures and winds.”
What follows is the corresponding press release from the University of Miami Rosenstiel School of Marine & Atmospheric Science, dated 15 October 2015:
New Study Questions Long-Held Theories of Climate Variability in the North Atlantic
UM Rosenstiel School researchers suggest atmosphere drives decades-long climate variations.
A University of Miami (UM) Rosenstiel School of Marine and Atmospheric-led study challenges the prevailing wisdom by identifying the atmosphere as the driver of a decades-long climate variation known as the Atlantic Multi-decadal Oscillation (AMO). The findings offer new insight on the causes and predictability of natural climate variations, which are known to cause wide-ranging global weather impacts, including increased rainfall, drought, and greater hurricane frequency in many parts of the Atlantic basin.
For decades, research on climate variations in the Atlantic has focused almost exclusively on the role of ocean circulation as the main driver, specifically the Atlantic Meridional Overturning Circulation, which carries warm water north in the upper layers of the ocean and cold water south in lower layers like a large conveyor belt. “The idea of the ocean as the driver has been a powerful one.” said UM Rosenstiel School Professor Amy Clement, the lead author on the study. We used computer models in a new way to test this idea, and find that in fact there is a lot that can be explained without the ocean circulation.”
While the overall rise in average temperature of the Atlantic is caused by greenhouse gases, this study examines the fluctuations occurring within this human-related trend. Identifying the main driver of the AMO is critical to help predict the overall warming of the North Atlantic Ocean in coming decades from both natural and man-made climate change. Recent research suggests that an AMO warm phase has been in effect since the mid-1990s, which has caused changes in rainfall in the southeastern US, and resulted in twice as many tropical storms becoming hurricanes than during cool phases.
Using multiple climate models from around the world, Clement’s research team removed the ocean circulation from the analysis to reveal that variations in the Atlantic climate were generally the same. The AMO results in a horseshoe-shaped pattern of ocean surface temperatures in the North Atlantic Ocean that have been naturally occurring for the last 1000 years on timescales of 60-80 years. This new analysis shows that the pattern of the AMO can be accounted for by atmospheric circulation alone, without any role for the ocean circulation.
“These results force us to rethink our ability to predict decade-scale temperature fluctuations in the Atlantic and their associated impacts on land. It may be that many of the changes have limited predictability, which means that we should be prepared for a range of climate outcomes associated with global warming,” said Clement.
The study, titled “The Atlantic Multidecadal Oscillation Without a Role for Ocean Circulation,” was published in the Oct 16 issue of the journal Science. The co-authors include Clement, Katinka Bellomo and Lisa N. Murphy from the UM Rosenstiel School; Mark A. Cane of Lamont-Doherty Earth Observatory of Columbia University; and Thorsten Mauritsen, Gaby Rädel and Bjorn Stevens from Max Planck Institute for Meteorology in Germany. The work was support by grants from the Department of Energy and the National Oceanographic and Atmospheric Administration.”

Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe German SAT.1 NRW site brings our attention to yet another glittering jewel of climate and environmental folly. This ranks close to the weed-covered solar park we reported on a few years back.
SAT.1 reports how a revolutionary zero-carbon, “sustainable” green home went from being an example for the future of green home architecture, to a hazardous waste site in just a matter of months.
2.4 million euro dream
The “unique” self-reliant house located in Lippstadt, Germany, was constructed entirely of “organic materials”, costing 2.4 million euros ($2.6 million). Building began in 2014. However during 2015 the house became completely infested with dangerous mold — and has since been condemned and now will need to be gutted out.
Initially the house had been the dream of its owners, Lars and Antje Rühe. Today, having put the family’s wealth into the house, the Rühe’s now find themselves on the brink of financial and marital ruin, SAT.1 reports.
Rain soaked during construction
The house is equipped with its own water supply, solar power, and a battery storage system costing over 100,000 euros and is capable of storing power for months. During the course of construction, the organic wood-based material used for insulating the house in place of traditional fiberglass got soaked with rainwater and quickly became a hotbed for mold.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Now a hazardous material site
The mold and its spores spread through the entire building and contaminated the insulation, which now has to be removed piece by piece and disposed of as hazardous material. So toxic did the house become that it had to be fenced off to keep the public off limits. Two million spores were measured in the air of the house – the limit is only 200.
Things got far worse: In order to keep the dangerous spores from making the neighbors ill, it is now deemed necessary to build an airtight, vacuum enclosure structure around the entire house – all equipped with an air filtering system. That alone, according to SAT.1, will run another half a million euros.
To be demolished, handled as hazardous waste
It’s not even sure if the house can be salvaged at all. According to the engineer who designed the home’s energy system, “every part will need to be packed and sealed, and then disposed of as hazardous waste“.
Germany’s No.1 daily Bild writes here that the house will in fact need to be demolished, which will cost 50,000 euros.
Next comes the legal battle to determine exactly who is responsible for the debacle. Apparently the building crew covered the house with a large tarp during its construction, but according to SAT.1, it leaked and the organic insulation soaked the water up “like a sponge“.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterFirst vigorous support
 followed by cheers
 But then came silence
 and then denial,
 Followed by downplaying
 Today, outrage is exploding
That’s the story of Germany’s attempted Energiewende (transition to renewable energies).
The mood has turned 180° since the early days. Once welcome, Germany’s Energiewende is now being met with shock and outrage as the envoiornmental destruction takes on unforeseen dimensions.
Even German envivonrmentalists, once huge proponents of renewable energies like wind and solar, are no longer able to take it any more as the Energiewende ravages the country’s environment and turns the notion of environmental protection into a fiasco.
Hat-tip: Alessandra Eck and Martina Knoedl at FB.
Now that Germany’s Energiewende has been in full swing for a number of years, many leading environmentalists are in a state of shock as huge areas of the country are being deforested and landscapes disfigured to make way for hundreds of wind turbines.
Environmentalist Georg Etscheit is a regular contributor at Germany’s leading climate alarmism site, Klimaretter, and he as well has had enough. Etscheit will be releasing a book in early November.

New, soon-to-be released book slams Germany’s Energiewende: “Sacrificed Landscapes – How the Energiewende Is Destroying our Landscapes.” Image: Heyne Verlag.
The title of the book: “Sacrificed Landscapes – How the Energiewende Is Destroying our Landscapes.” 
In the book’s promotion video here, a number of Germany’s leading environmental experts are seen denouncing Germany’s Energiewende, as they are aghast at what is going on.
Prof. Dr. Niko Paech, sustainability scientist, says:
What’s awful about the destruction of the landscapes and the government is that all of it has a legitimization.”
and
The German Energiewende has become a justification for destroying our last remaining natural landscapes.”
Dr. Gerhard Gronauer, pastor:
Climate protection that uses technical means against nature is a contradiction in itself.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Greatest fraud project”
Jörg Rehmann, journalist and author:
If we want to survive on this planet, we need an Energiewende. But what the policymakers have made of it is not an Energiewende, rather it is the greatest fraud project since the end of the second world war.”
Prof. Dr. Niko Paech, later adds:
Science is legitimizing a rampage against nature. We destroy the landscape while we claim it is serving the ecology. It’s a cannibalism by the measures. Climate protection is the aim that justifies the means to destroy all other remaining environmental media.”
Jörg Rehmann adds:
Serious science has long proven that the Energiewende cannot in any way reach its targets. Society has to bear billions in costs, already energy prices are exploding, and policymakers are driving us further into a nuthouse in the clouds.”

Image cropped from promotion video, Heyne Verlag. 
Rehmann continues and says the proponents are decieving the public into thinking it’s a green free-market capitalism. Paech reminds that despite all the destruction and money, no CO2 has been saved.
“No climate goals have been reached despite the billions invested,” says Rehmann.
Unprecedented amount of cronyism
Rehmann piles on even more:
Under the guise of a planned economy, there is now an unprecedented amount of cronyism and wasted money. It is shocking how far into a legal gray zone communities have gone with respect to the permitting in natural areas. It really reeks of corruption.”
Prof. Dr. Werner Nohl says that wind parks have no place in natural environments.
At the end Etscheit calls for an immediate stop to the “landscape and nature-destroying project” and that a whole new discussion needs to be taken up again.
My feeling is that the zeitgeist is right, and this book will do very well. It needs to be written in English (soon!) so that it can reach an international audience and hopefully help prevent the German blunder from being repeated elsewhere. -PG
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s DWD national weather service has the preliminary September 2017 report out. According to the result of the data measured by the country’s 2000 weather stations, last month was cooler than normal.
September 2017 in Germany saw a mean temperature of 12.7°C, which was 4.2°C cooler than last year’s record warm September (16.9°C). This means that the month came in 0.8°C colder than the 1981-2010 mean.
September in Central Europe was also cloudier and wetter than normal. The cool, autumn-like weather was caused by low pressure systems pumping cool air from northern Europe.
The DWD also reports some regions in Germany saw frost, for example Deutschneudorf-Brüderwiese recorded a temperature -1,5 °C on the morning of September 19.
Austria sees coolest September in 10 years
Also Austria’s ZAMG national weather service reported that September in the mountainous country recorded the coldest September in 10 years, and that in the mountains it was even the coldest in over 15 years. The following ZAMG chart shows the country’s temperature anomaly from the mean:

Temperature anomaly chart for Austria, September 2017. Source: ZAMG.
 Austria’s preliminary September data is based on measurements taken from 270 stations scattered across the country using SPARTACUS .
Austria’s September 2017 is summed up by the ZAMB in three words: cool, rainy and dreary. The mean temperature was 1.5°C below the long-term mean and was the coolest since 2007.
New snowfall records in Austria


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




ZAMG climatologist Alexander Orlik reported:
There were also some new record snowfalls. For example at the Villacher Alpe, 2140 meters above sea level, it was the the snowiest September since snowfall measurements began in 1925. Over the month some 78 cm of fresh snow fell.”
Cool weather, heavy snow forecast for early October
The colder temperatures are expected to continue through early October, according to Schneefan at climate and weather site wobleibtdieerderwaermiung.de here, citing meteociel. The following meteociel chart depicts the projection for October, 2017.
According to meteociel on September 28, cold weather is projected to dominate Central and Eastern Europe in October (850 hPa – approx. 1500 m). Source: www.meteociel.fr/modeles/cfsme_cartes.php
The US GFS also confirms this cool projection.
Heavy snowfall forecast for the Alps
Finally Schneefan writes that “heavy snowfall is forecast for the week ahead across Austria and Switzerland!”

Up to 1 meter a new snow (orange/yellow) in the Alps of Southern Germany, Austria and Switzerland over the coming week. Source: www.bergfex.de/schneevorhersage/.

This fall global warming is taking a big break, at least over much of Central Europe.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Atlanta Falcons and Roger Goodell have got to be feeling like Hillary Clinton right now.

I have to admit I went to bed after it was 21 – 0 (2 a.m. Central European Time) thinking it was over — and not caring at all for the likely idiotic halftime show.
Much to my delight, this morning felt a lot like November 9 last year.
And Drudge this morning (Germany) has number of good headlines:

Kenneth Richard will be posting soon later. Have a good one today, fellow patriots!
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Swiss online Basler Zeitung (BaZ) writes that critics of Donald Trump are wrong with their apocalyptic hype and exaggerations surrounding the President’s rejection of the Paris climate accord.
Worthless Accord
The BaZ writes that Trump is right because the Paris Accord is “a document that has gone off track in every way” and that it is an accord “soaking with hatred of the West” and makes “grotesque, empty promises” to developing countries.
The BaZ commentary calls the Paris Accord as a whole a “paper without value” because it contains no legally binding obligations and only includes toothless “intended nationally determined contributions” (INDCs), which means each country can determine on its own how much CO2 it intends to cut back on, without any enforcement mechanisms.
“A farce”
The BaZ commentary slams the Paris Accord for allowing China and India to continue emitting as usual until 2030, and then only gradually cutting back thereafter. It goes on to say that the commitments pledged by some of the industrial countries would be “fully unrealistic to achieve” and that it makes the accord “a farce”.
It won’t have in any way, as scientists at MIT […] have already calculated, any effects. Even if all 195 countries fulfilled what they said they would and achieved all their INDCs, the temperature would rise perhaps 1.9 to 2.6°C by 2050 and maybe 3.1 to 5.2°C by 2100. […] In fact the accord sought to limit the rise to ‘significantly’ less than 2°C. […] According to the MIT – and depending on the numbers used – the planet would warm up a whole 0.2°C less if the Paris Accord was adhered to.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Disrupts a circle of elitists”
The BaZ opinion then reminds readers how the science is filled with uncertainty and involves complex computer simulations, and what is really going on is that Donald Trump is massively disrupting a “circle of elitists”. The BaZ comments further:
Things were so wonderful at the conferences and global summits – until that elephant smashed everything that was in his way. China in the china cabinet? No, he simply stamped out all the hot air. (Basler Zeitung)”
=============================
P.S. by NTZ
The following chart shows why the Paris Accord would be the first step to the greatest investment failure in human history. Assuming the science was true, trillions of dollars for a few hundredths of a degree Celsius.

Source: Bjorn Lomborg – Impact of Current Climate Proposals DOI: 10.1111/1758-5899.12295
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIf you happened to read or hear the German and international headlines from just over a week ago, you’d think the million-population port city of Hamburg, Germany, had been hit by a devastating tornado on June 22, leaving a path of destruction in its wake.
What follows is a great example of how the media will run with anything, without checking, as long as it fits their climate and extreme weather narrative. The German media over the years have been tending to hype up every weather anomaly — to get the message into people’s heads that climate change is real and is happening.
The following story is almost unbelievable. A local gust of wind toppling over a few trees somehow managed to morph within the media into a headline-making super-tornado that supposedly ripped through a large city. Fake news at its best.
On June 22 a cold front swept across Hamburg, Germany, accompanied by severe weather, so “severe” that hundreds of media outlets, domestic and foreign, reported it has headline news.
Skeptical, Spiegel science journalist Axel Bojanowski decided to investigate to see what really happened, and subsequently reported here the result. It turns out it was 99% fake news. Bojanowski wrote:
Residents spoke of heavy damage, the media reported. However the body of evidence is thin. […] the search for evidence has proven to be difficult.”
It turns out that the “tornado” that supposedly hit Hamburg in broad daylight, a city of some 1 million residents, so far has found only one single (dubious) witness. Yet, it was all the media needed to unleash sensational headlines globally: “A tornado rips through the city of Hamburg“.
DWD sets off confusion
According to Bojanowski “the storm of confusion” over the “tornado” was started around lunch time by the German DWD national weather service, which tweeted: “Tornado over Hamburg! About 10 km SSW from the city center. Lasted about 5 min.”
This in turn was followed by the German DPA press agency (Germany’s version of the AP) releasing at 2:34 pm: “Tornado leaves devastation in its wake south of Hamburg.” Here the German DPA relied on a sole eyewitness report from firefighter Stefanie Engelke, who reported witnessing up close a powerful gust of wind uprooting some trees that toppled onto a building, causing damage to its roof.
Shortly thereafter, however, the Hamburg Fire Department disputed that a “tornado” had ever occurred, tweeting later it had “no knowledge over any tornado“. Yet the DPA stuck to its story, Bojanowski writes. And the DWD weather service also reiterated having witnessed a tornado.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Wind gust morphs into “devastating tornado”
But then veteran high-profile meteorologist Jörg Kachelmann tweeted his doubts about the “tornado eye-witness fire fighter” which the DPA relied on for its report of “devastation”. Kachelmann tweeted:
Clueless fireman, who saw no tornado but damage like you see on TV, yet suffices for a total fabrication @dpa. https://twitter.com/dpa/status/877910082452901888 …“
But it was already too late. By then that powerful wind gust, which had uprooted some trees, quickly managed to morph into a full fledge super tornado in the media, and got reported internationally. The World News Media here tweeted:
Tornado tears through #Hamburg following extreme heat wave https://on.rt.com/8fpu …”.
By Thursday evening, the DWD backed off its original “5-minute tornado” account, tweeting that it had witnessed the “tornado” near the middle of the city instead. Later at Facebook the DWD even released a photo of the “tornado” it had “seen”:

DWD tweet n English:
As reported earlier today, the DWD colleagues of the Aviation Advisory Center North at the Hamburg airport saw a very short-lived tornado about 10 km ssw of the airport at 11:37 a.m. It had ground contact less than 5 minutes  (visible by the rotating dust cloud beneath the funnel cloud). Magnitude estimated at F0, and indeed did not cause any damage.”
That hardly looks like a tornado in the photo. And so not surprisingly even that DWD account got disputed later by a witness. At Twitter Hamburg resident Kerrag posted a 1:55 minute video showing no ground contact at all!
That’s the story of how the Hamburg “tornado”, which was merely a gust of wind, wound up making international headlines as a “devastating” tornado that had flattened part of a major European city.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterVeteran meteorologist Joe Bastardi at Weatherbell gave permission to publish the following, which he writes had appeared behind a paywall at Weatherbell Analytics. Part of what Joe writes was brought up at his Saturday Summary video.
(Correction: Red curve in first figure is 2011/12 year, and not 2016 as Joe originally wrote).
=========================================
Greenland is a Canary in a Coal Mine
By Joe Bastardi, Weatherbell Analytics
(Editing by P. Gosselin)
Nowhere on the planet is there a better example than Greenland of how nature, and not man, is master of the planet’s fate. It demonstrates the process by which there is a natural cap to warming.
How so? Well, first of all let’s look at what’s an amazing 5-year recovery in Greenland snow and ice:

The pinkish line is how far above average we are, the extra yellow tacked on means pink and yellow is the increase since 2012.
I want you to look at that. Suppose it had gone the other way, and instead had DROPPED to 2012 levels from where it is now. Just what do you think would be reported today in the climate media?
Now this is all in the midst of what is the warmest 2-year stretch of temperatures in the satellite era. Let’s not kid around or make excuses; it is by UAH:

It is by the NCEP initialization criteria, which has been doing well in tracking the ups and downs:

This makes some sense because Greenland is a very cold place, even when it’s warmer, and so with more water vapor available from the warmed oceans, it snows more where it’s cold enough to snow. That is simple intuition and proven fact, and I didn’t need any big grant money to come up with that. So increases of water vapor in very cold places produce more snow, and CO2 is not causing more or less snow.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The idea that CO2 can suddenly warm the planet and create these situations is nonsense. At the very most, and this is a stretch, stored CO2 in the lower levels does have some warming effect by influencing the air around it, but quantifying it against the large scale drivers is by no means settled science.
Greenland colder this year
The oceans today are not a product of the increase of 1 molecule of CO2 out of every 10,000 of air over 100 years, but instead large scale events that can be centuries in the making. So someone can claim that warming leads to more snow (by the way that was taught in my climate classes in the 70s), which in turn leads to cooling since more snow makes winters last longer in areas where sun angles are low.  Nature’s version of Le Chateliers, or the old adage: for every action, there is a reaction!
Predictably, Greenland in 2017…

…is cooler than it was in 2016:

But the history of Greenland shows that the current warming does not match other warm periods shown by the ice core sampling:

Above is another proxy for global temps, and it is showing a current “hockey stick” look, which certainly backs that idea. The problem is that in the cherry-pick world of climate hysteria, scientists ignore the rest of the periods, thinking that somehow it’s valid global proxy when it agrees with them, and not when it doesn’t. But whether tree rings in Mongolia or wherever, or ice cores in Greenland, the earth shows a wide and varied, always acting and reacting climate system that is independent of whatever minute influences man might offer.
Harsh winter threatening Europe?
To say there is no influence at all to me is folly, anything and everything contributes to the system, but the question lies in its weight. To say CO2 is the climate control knob in the face of what we know and see, seems beyond folly, almost a religious fanaticism. Greenland is indeed a canary in the coal mine as I have heard it put when snow and ice was melting. Problem is that it’s like nature: it’s a canary that changes its tune. Anyone listening?
Tell you what. If there’s blocking over Greenland this winter and I am in Europe, I’d really look out.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNew Paper Uses Physics Laws To
Disassemble Greenhouse Theory

Eight years ago, 2 physicists published a comprehensive 115-page scientific paper entitled “Falsification Of The Atmospheric CO2 Greenhouse Effects Within The Frame Of Physics” in the International Journal of Modern Physics.
Gerlich and Tscheuschner, 2009


Buttressed by a reference list of over 200 scientific publications, the authors addressed the merits of commonly held greenhouse “conjectures” as they relate to the laws of physics.
“By showing that (a) there are no common physical laws between the warming phenomenon in glass houses and the fictitious atmospheric greenhouse effects, (b) there are no calculations to determine an average surface temperature of a planet, (c) the frequently mentioned difference of 33°C is a meaningless number calculated wrongly, (d) the formulas of cavity radiation are used inappropriately, (e) the assumption of a radiative balance is unphysical, (f) thermal conductivity and friction must not be set to zero, the atmospheric greenhouse conjecture is falsified.”
From pages 35 to 44, Gerlich and Tscheuschner critiqued 14 different “fictitious” manifestations of the greenhouse effect theory as they have appeared over the course of the last several decades.


In a newly-published scientific paper, meteorologist and physical chemist Dr. Martin Hertzberg (and two other chemists) provide a condensed update to the Gerlich and Tscheuschner appraisal of the theoretical greenhouse effect.
Hertzberg  and colleagues also apply the standard laws of physics to critique 6 current theoretical explanations for the role of greenhouse gases (CO2) in presumably keeping the Earth 15°C warmer than it would otherwise be.
Included below is an abridged, less-technical version of the paper in an ostensibly user-friendly format.
It should be noted that the conclusions may be controversial even for skeptics of anthropogenic global warming (AGW) alarm.  That’s because the vast majority of climate skeptics at least accept the basic tenets of the greenhouse effect theory.  Instead, the existing skepticism focuses on the climate’s sensitivity to CO2 forcing in particular (low vs. high), not on whether the greenhouse effect as conventionally expressed is “real” or meets the standards applied by the laws of physics.
It is widely assumed that that the common understanding of how greenhouse gases operate in the climate system (the atmosphere and oceans) is both real and supported by scientific observation and physical tests.  This paper, like Gerlich and Tscheuschner (2009), may challenge this assumption.

Role of greenhouse gases in climate change
Hertzberg et al., 2017
This study examines the various definitions of the greenhouse effect for compatibility with the laws of physics.

Definition 1
A greenhouse is a glass/plastic enclosure, warmed by sunlight, facilitating plant growth. Several definitions argue that the effect in the atmosphere is analogous to a greenhouse. It is stated that sunlight transmitted into an enclosure through transparent glass warms the interior of the enclosure, increasing the Infra Red (IR) radiation. As glass is partly opaque to IR radiation, it cannot freely pass outward through the glass and is thus retained within the enclosure. Several definitions infer the radiation is being ‘trapped’ and it is argued that atmospheric gases such as CO2 are analogous to the glass pane action of a greenhouse and this serves to ‘trap’ IR radiation within the atmosphere and obstruct radiative cooling.
The Critique
An early test of the ‘trapped’ radiation theory was conducted by R. W. Wood.  He constructed two enclosures, one covered with a glass plate and the other covered with an IR transmitting rock salt plate. When adjusted so that both were exposed to the same solar input radiation, they both reached the same temperature of 55°C with ‘scarcely a difference of one degree between the temperatures of the two enclosures’. His experiment clearly showed that it was the presence of the enclosure itself that enabled the warming. Therefore, it is the heat generated by absorbed sunlight that becomes ‘trapped’. In the absence of an enclosure, the warmed air near the ground would rise by buoyancy and be replaced by cooler air from the surroundings thus cooling it. This natural convective cooling process is restricted and suppressed by the enclosure. It is the same process that generates a cooling afternoon sea breeze on a beach with cooler air from the ocean replacing rising warmer air over land. To argue that an open gaseous atmosphere confines in the way that the top and sides of a greenhouse enclosure does is not valid. To the contrary, a gaseous atmosphere is conducive to the convective cooling that occurs in the absence of an enclosure. It could be argued that CO2 along with the other gaseous components of the atmosphere in fact helps to cool the Earth’s surface.

Definition 2
Another common theme among the various descriptions of the effect is that the ‘greenhouse gases’ serve as a ‘blanket’ keeping the earth warm.
The Critique
A simple experiment to test the validity of this argument is to appear naked outside on a cold evening and observe how long the blanket of ‘greenhouse gases’ in the atmosphere keeps you warm. Air warmed by body heat rises by buoyancy and is replaced by cooler air from the surroundings, causing rapid cooling down and shivering. An actual blanket is a flexible insulating enclosure that reduces the rate at which body heat is lost to the surroundings. Thus the atmosphere is more given to being an agent for cooling by way of natural convection.

Definition 3
A regular description of the ‘greenhouse gas’ heating mechanism is that referred to as ‘back radiation’. Atmospheric gases such as CO2, having a dipole moment, absorb some incoming solar radiation and some of the IR radiation the Earth’s surface radiates toward free space. According to the Environmental Protection Agency, ‘re-radiated energy in the IR portion of the spectrum is trapped within the atmosphere keeping the surface temperature warm’. This ‘trapping’ is assumed to occur as the surface radiates to the atmosphere and the atmosphere radiates back to the surface.
The Critique
The radiation emitted from the warmer surface absorbed by the colder atmosphere is readily detected by orbiting satellites. However, back radiation from the colder atmosphere to the warmer surface heating the surface further violates the Second Law of Thermodynamics.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




There are two problems with that amount of down-welling radiation: the atmosphere is not a blackbody with unit emissivity and equally, is not radiating toward a receptive absorber. Yet it is depicted as radiating heat downwards to the warmer Earth’s surface in direct violation of the Second Law.
The flow of heat is always from the hotter surface to the colder surface as required by the Second Law of Thermodynamics. Nowhere in the radiation field between the two surfaces is the flux of radiant energy equal to that which either surface would emit if they were facing a complete void. Thus, the simple use of the Stefan-Boltzmann term, δT4 to characterize the emission from a source of radiation in the manner that depends only on the temperature of the source without considering the temperature of the surroundings receiving the radiation, is a misapplication of the equation and the notion that a colder source can transfer radiant energy to a warmer object is a misapplication of the Stefan-Boltzmann equation and a violation of the Second Law of Thermodynamics.
It would therefore be clear that the application of the Stefan-Boltzmann term to simply characterize radiant energy being transferred from an object to its surroundings without reference to the conditions of the surroundings in radiative contact with that object is a misapplication of the equation.
It would be incorrect to talk in terms of radiation exchanging, since transfer occurs only from warmer to cooler matter, from higher energy level to lower energy level.

Definition 4
A proposed new definition of the greenhouse theory to overcome the objections raised against warming by back radiation argues that IR absorbing ‘greenhouse gases’ hinder radiative transport from the Earth’s surface upwards and aid to keep the surface warm and warmer than it would otherwise be in the absence of those gases.
The Critique
The definition ignores the fact that those gases themselves emit radiation to free space adding to radiation loss from the system.  Radiation loss to free space from the earth’s surface and its atmosphere is essentially the same with or without presence of absorbing gases for the following reasons: the cooling by radiation to free space is a one-step process; in the presence of an atmosphere, it is a two-step process with the same loss, with or without, the absorbing and emitting gaseous atmosphere. When talking about radiation, it is absorbed radiation or emitted radiation that is being considered.

Definition 5
In many of the various definitions, attempt is made to prove that ‘greenhouse gases’ in the atmosphere keep the Earth warm, warmer than it would otherwise be in the absence of an atmosphere as conveyed by the following [enviropedia.org] quote:
“This process (radiation trapping) makes the temperature rise in the atmosphere just as it does in the greenhouse. This is the Earth’s natural greenhouse effect and keeps the Earth 33°C warmer than it would (otherwise) be without an atmosphere, at an average of 15°C.”
The Critique
Logically that argues that if the Earth had no atmosphere, its average temperature would be -18°C rather than its current temperature of 15°C. Such a temperature is based on calculated ones, that is ‘otherwise’ ones. The calculations arise from several mistaken assumptions. The most obvious one diminishes the solar radiation input by 37% from the Earth’s cloud albedo while simultaneously taking no account of any lessening of the IR radiation emitted to free space by the same blocking clouds. Equally, all IR radiating entities on the surface are assumed to be blackbodies with unit emissivity. The calculation that yields the -18°C temperature is obviously mistaken. The question is considered and covered in detail in the ‘Cold Earth Fallacy’.
Further argument used to illustrate the greenhouse effect of CO2 is the atmosphere of Venus, which is almost entirely [965,000 ppm] CO2. Based upon its distance to the Sun relative to that of the Earth, and using the Earth’s average temperature, Venus surface temperature should be about 280°C. Yet the measured value is about 465°C. This difference is attributed to the strong greenhouse effect of its higher CO2 concentration. The difference is more correctly attributable to Venus’ high surface pressure and the adiabatic compression of the atmosphere adjacent to its surface. Venus’ surface temperature would be just as warm if its atmosphere consisted of any gas whose compressibility was the same as that of CO2. The temperatures in the Mohave Desert and the Dead Sea are higher than the temperatures of surrounding areas at sea level. That is not a greenhouse effect but is caused by adiabatic compression of the higher pressures at their elevations below sea level.

Definition 6
All atmospheric gases that are believed to be ‘greenhouse gases’ absorb IR radiation emitted from the Earth’s surface. Their absorption spectra are well known and it is relatively easy to calculate the radiation flux, those gases absorb from the Earth’s IR emission.
The Critique
The problem arises when those radiation fluxes are translated into a resultant temperature rise while ignoring the fact that atmospheric gas is being simultaneously cooled by radiating to the unlimited sink of free space.

Epilogue 
In one of science’s first ‘thought experiments’ Pierre Prevost (1751–1839) conjectured that a hot body absorbed less radiation from a cold body than the reverse, and that both would eventually reach the same temperature. Thus, the theory of radiant exchanges came into being, a view that predated the more thorough understanding of the Laws of Thermodynamics that came later. Yet it is noted that aspects of Prevost’s 200-year-old theory continue to be applied in regard to ‘net flow’ of heat – a concept that radiation flows both downhill and uphill. The latter flow is a violation of the Second Law, which informs us that a hot body can absorb no radiation from a cold body to make it warmer still.
Radiative greenhouse supporters have theorized a blackbody as an all-absorbing entity, capable of absorbing and retaining its own radiation to elevate its temperature and have used radiant exchanges in support of their arguments.
[S]o far no way has been found to be able to readily transpose or correlate experiments conducted in the contained, static, isothermal and isobaric conditions of a laboratory to the great vastness of earth’s atmosphere.

Conclusion 
The various stated definitions of the greenhouse effect have been subjected to the rigorous scrutiny and application of the fundamental laws of physics and thermodynamics. They were found to be unreal, and unless some new definition can be put forward that satisfies and complies with those laws, it can only be concluded that the concept of a ‘greenhouse gas’ or a ‘greenhouse effect’ has not been demonstrated and is thus without merit.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWay back in February, Global Weather Oscillations (GWO) veteran meteorologist David Dilley predicted that the 2017 Atlantic hurricane season would be “the most dangerous and costliest in 12 years for the United States.”
Photo: David Dilley, GWO
In the wake of Harvey, and with an eye on the now growing threat posed by Irma, that prediction is emerging to be spot on.

Irma takes aim. Chart source (1 Sept 2017 9:00 CET): earth.nullschool.net/.
Dilley, a 40-year veteran and a former NOAA meteorologist, said the season would be influenced by a Climate Pulse Hurricane Enhancement Cycle – which is characterized by the lack of El Niño or La Niña conditions. Recently the El Nino Southern Oscillation (ENSO) has been hovering near neutral territory.
Ideal oceanic conditions
Dilley based his February prediction on natural cyclic factors, namely on the fact that ocean water temperatures would “continue to run warmer than normal across most of the Atlantic Basin and especially in the Caribbean region and the Atlantic near the United States” this year, which would “make conditions conducive for tropical storms and/or hurricanes forming and/or strengthening close to the United States“.
So far that too has been spot on as well. This scenario has also been supported by Joe Bastardi of Weatherbell Analytics. Bastardi, also a 40-year veteran meteorologist, points to similarities with hurricane patterns of the mid 20th century.
120-year trend clearly downward
Hurricane activity as a whole has been on a downward decline over the past 120 years, according to the NOAA – something that often gets no mention in the media.


Hurricanes trending downward over the past 120 years. Chart source: NOAA

Dilley also predicted that the Bermuda-Azores High Pressure Center would be weaker this summer, and thus would allow “more named storms to maintain strength – or strengthen as they move from east to west across the Atlantic toward the United States” – a pattern that Irma is following to a tee.
In his February forecast he wrote that the United States would have the potential for 6 named storms making landfall, the most most since 2005.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Global warming has no influence”
In an e-mail response to NoTricksZone on whether hurricane Harvey’s intensity was related to global warming,  Dilley wrote:
Global warming has no influence – we have had major impact hurricanes in the past when it was cooler – it is all cyclical.
Dilley also said that Harvey will with very high likelihood not be the last to strike the USA, saying that a number of hurricane zones need to prepare for the worst this season.
Perfect conditions for Irma
Concerning Irma the 40-year veteran meteorologist says that the hurricane “is in an area having perfect conditions” and that he expects “4 major hurricanes in 2017 due to a stronger hurricane cycle year that occurs in conjunction with warm Atlantic Ocean water following a period that did not have a La Niña – less wind shear and good positioning of the Bermuda high“.
Texas hurricane hiatus is over
Dilley had predicted that Texas had a “good shot at coming out of their quiet hurricane cycle” as -there have been 7 quiet periods for Texas during the past 130 years, writing that “the typical quiet period lasts 8 to 10 years and 2017 was year 9 since their last hurricane”.
Florida and New England are due as well
He warns that “other prediction zones such as the peninsula of Florida and New England are likewise on the verge of breaking out of their quiet periods” and that they are “all cyclical based on electromagnetism of the earth-moon-sun gravitational cycles influencing the Bermuda high, ocean temperatures via an El Niño or no El Niño and individual hurricane landfall cycles for each zone.” He sums up:
Bottom line – Irma will be a major United States impact hurricane and not the last land-falling hurricane of the season.”
2018 will be a quieter season?
One bright note: Dilley believes that the 2018 season will be less harsh, in part because of more favorable natural ocean cycle effects in the Pacific and Atlantic.
For Dilley, hurricanes are part of the natural weather and climate cycles and that it is something we’ll have to relearn getting used to. In the early 20th century things were much worse than what we’ve grown accustomed to seeing over the past decade.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter   Fake Warming + A Neglected Sun
=  Man-Made Climate Change

In late 2015, Soon, Connolly, and Connolly (hereafter SCC15) published a  comprehensive (101 pages) analysis of how the modern anthropogenic global warming (AGW) paradigm has been constructed.  The paper, published in  Earth Science Reviews, is entitled Re-evaluating the role of solar variability on Northern Hemisphere temperature trends since the 19th century.
What follows is a very brief summary of some of the graphical highlights in SCC15 as well as the fully cited conclusion.  Succinctly, the paper can be divided into 2 parts.
1. The instrumental temperature record has undergone heavy adjustments (a utilization of an urban temperature station siting bias) to allow a better fit with climate models that  presume CO2 emissions drive temperature.
2..  CO2-based climate models do not adequately correlate with Northern Hemisphere (NH) temperature trends of the last 130 years; solar activity changes do correlate well with NH trends — especially when urban bias has been removed from the temperature record.

Urban Bias Artificially Adds ~0.09 °C Per Decade To Land Temperatures



SCC15:
“[A]lthough there are 126 fully rural stations with data during the 1951-1990 period, there are only 13 and 17 fully rural stations during the 1907-1950 and 1991-2014 periods respectively, and none of the stations with records before 1907 are still fully rural. … For individual urban stations and areas in China, the temperature records can be very strongly affected by urbanization bias. For instance, Ren et al. (2007) found that between 65-80% of the apparent warming trend over the 1961-2000 period for the Beijing and Wuhan station records was probably due to increasing urban heat islands.  [T]he temperature trends increase from +0.025°C/decade (fully rural) to … +0.119°C/decade (fully urban). … If we assume that the fully rural stations are unaffected by urbanization bias, while the other subsets are, then we can estimate the extent of urbanization bias in the “all stations” trends by subtracting the fully rural trends. This gives us an estimate of +0.094°C/decade urbanization bias over the 1951-1990 period – similar to Wang & Ge (2012)’s +0.09°C/decade estimate.”



Rural Temperature Stations That Show Minimal Warming Are Removed



There are now fewer U.S. rural stations contributing to the Global Historical Climatology Network (GHCN) than there were in 1900.



According to McKitrick (2010), 75% of temperature stations across the globe have been removed since the 1970s, mostly from rural or non-urban areas.  Temperature stations located in urban areas — where paved roads and industrialized waste heat artificially warm the surface – have been allowed to remain.

McKitrick, 2010


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






The Consequence Of Urban Bias: Artificial Land Warming Since 1980


NOAA Global Land and Sea


HadCRUT Land vs. Ocean Temperature Anomalies

Warming Since The 1980s On Par With Pre-1950s Warming Using Rural-Only Stations



CO2-Based Climate Models Do Not Explain The Pre-1980 Temperature Trends



Pre-1950s Warmth Removed, Post-1950s Warmth Added…To Make The Data Fit The Models



Solar Variability Correlates Well With The 1880s-Present NH Temperature Record 




Conclusion/Summary From Soon, Connolly, &  Connolly, 2015

1.  “We have constructed a new estimate of Northern Hemisphere surface air temperature trends derived from mostly rural stations – thereby minimizing the problems introduced to previous estimates by urbanization bias. Similar to previous estimates, our composite implies warming trends during the periods 1880s-1940s and 1980s-2000s. However, this new estimate implies a more pronounced cooling trend during the 1950s-1970s. As a result, the relative warmth of the mid-20th century warm period is comparable to the recent warm period – a different conclusion to previous estimates. Although our new composite implies different trends from previous estimates, we note that it is compatible with Northern Hemisphere temperature trends derived from (a) sea surface temperatures; (b) glacier length records; (c) tree ring widths.”
2.   “However, the recent multi model means of the CMIP5 Global Climate Model hindcasts failed to adequately reproduce the temperature trends implied by our composite, even when they included both “anthropogenic and natural forcings”. One reason why the hindcasts might have failed to accurately reproduce the temperature trends is that the solar forcings they used all implied relatively little solar variability. However, in this paper, we carried out a detailed review of the debate over solar variability, and revealed that considerable uncertainty remains over exactly how the Total Solar Irradiance has varied since the 19th century. When we compared our new composite to one of the high solar variability reconstructions of Total Solar Irradiance which was not considered by the CMIP5 hindcasts (i.e., the Hoyt & Schatten reconstruction), we found a remarkably close fit. If the Hoyt & Schatten reconstruction and our new Northern Hemisphere temperature trend estimates are accurate, then it seems that most of the temperature trends since at least 1881 can be explained in terms of solar variability, with atmospheric greenhouse gas concentrations providing at most a minor contribution. This contradicts the claim by the latest Intergovernmental Panel on Climate Change (IPCC) reports that most of the temperature trends since the 1950s are due to changes in atmospheric greenhouse gas concentrations (Bindoff et al., 2013).”
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Solar Forcing Of Modern, Historic Arctic Sea Ice
Only Slightly Less Sea Ice Now Than Little Ice Age

In a new paper (Stein et al., 2017), scientists find that Arctic sea ice retreat and advance is modulated by variations in solar activity.
In addition, the sea ice cover during the last century has only slightly retreated from the extent reached during coldest centuries of the Little Ice Age (1600s to 1800s AD), which had the highest sea ice cover of the last 10,000 years and flirted with excursions into year-round sea ice.
The Medieval Warm Period sea ice record (~900 to 1200 AD) had the lowest coverage since the Roman era ~2,000 years ago.
Of note, the paper makes no reference to carbon dioxide or anthropogenic forcing as factors modulating Arctic sea ice.



Stein et al., 2017
The causes that are controlling the decrease in sea ice are still under discussion. In several studies changes in extent, thickness and drift of Arctic sea ice are related to changes in the overall atmospheric circulation patterns as reflected in the North Atlantic Oscillation (NAO) and Arctic Oscillation (AO). The NAO and AO are influencing changes of the relative position and strength of the two major surface-current systems of the Arctic Ocean.
The increase in sea ice extent during the late Holocene seems to be a circum-Arctic phenomenon, coinciding with major glacier advances on Franz Josef Land, Spitsbergen and Scandinavia.  The increase in sea ice may have resulted from the continuing cooling trend due to decreased solar insolation and reduced heat flow from the Pacific.
The increase in sea ice extent during the late Holocene seems to be a circum-Arctic phenomenon as PIP25-based sea ice records from the Fram Strait, Laptev Sea, East Siberian Sea and Chukchi Sea  display a generally quite similar evolution, all coinciding with the decrease in solar radiation.
The main factors controlling the millennial variability in sea ice and surface-water productivity are probably changes in surface water and heat flow from the Pacific into the Arctic Ocean as well as the long-term decrease in summer insolation, whereas short-term centennial variability observed in the high-resolution middle Holocene record was possibly triggered by solar forcing.

Robust substantiation for the trends documented in this new Arctic sea ice record comes from a 2005 paper by Lassen and Thejll entitled “Multi-decadal variation of the East Greenland Sea- Ice Extent: AD 1500-2000.”   Shown below is an annotated graph from the paper revealing Iceland’s sea ice cover during the last millennium.  These scientists also link sea ice variations to solar activity, namely solar cycle length.  Notice the direct correspondence between the Arctic trends as a whole (from Stein et al., 2017) and the trends for Iceland.



Lessen and Thejll, 2005
[W]e find that the recently reported retreat of the ice in the Greenland Sea  may be related to the termination of the so-called Little Ice Age in the early twentieth century. We also look at the approximately 80 year variability of the Koch [sea ice] index and compare it to the similar periodicity found in the solar cycle length, which is a measure of solar activity. A close correlation (R=0.67) of high significance (0.5 % probability of a chance occurrence) is found between the two patterns, suggesting a link from solar activity to the Arctic Ocean climate.
The ’low frequency oscillation’ that dominated the ice export through the Fram Strait as well as the extension of the sea-ice in the Greenland Sea and Davis Strait in the twentieth century may therefore be regarded as part of a pattern that has existed through at least four centuries. The pattern is a natural feature, related to varying solar activity. The considerations of the impact of natural sources of variability on arctic ice extent are of relevance for concerns that the current withdrawal of ice may entirely be due to human activity. Apparently, a considerable fraction of the current withdrawal could be a natural occurrence.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterReader David Reich left a comment  in response to Kenneth Richard’s post on grape harvests and climate.
I’ve decided to upgrade it as a post below. Both stories show that today’s climate is well within the range of our climate’s natural variability over the past 100 and 1000 years, and that today’s weather events aren’t unusual.

By USDA photo by Scott Bauer, United States Department of Agriculture, Public Domain
================================================
Washington DC Cherry Blossoms, By David Reich
This [Grape Harvest Date Evidence: No Significant Modern Warmth] reminds me of the Washington Post (WaPo) story that ran a story a few days ago about the earlier than normal Washington DC cherry blossoms hitting their “peak day”. It was stated by the National Park Service that the blossoms are now blooming “on average about 5 days earlier than normal” since records have been kept by NPS.
So, I went back and checked the data. Turns out that the data have been kept for 96 years going back to 1921. The average day of hitting “peak” during the decade of the 1920’s was day 93 into the year – April 3 in a non-leap year, April 2 in a leap year. The average in this decade so far is………92 days. So, how does the Park Service come up with “about 5 days”?
If you average all 96 days, you do get close to 94 days largely because during the 1950’s and 1960’s, the peak date in those 2 decades was over 97 days. So, the recent data is only 2 days earlier than the average. BUT, since the 50’s and 60’s decades which many people remember, the average has in fact gone down about 5 days. Of course no mention that the average went up from 93 days in the 1920’s to 97 in the 1950’s and 1960’s.
Equally egregious with both the WaPo article and also the NPS claim is the complete ignoring of the fact that the standard deviation of all 96 data points is well over 7 days (1990 was the earliest peak at day 74 while 1958 was the latest at day 108) so the data varies wildly. So, even if a 5 day trend were valid, such a trend is well within the normally expected variation in the “peak” day and is thus no trend. No change.
Nothing but lies and statistical manipulation by the WaPo and the NPS.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn a recently released video interview by journalist Jörg Rehmann, University of Magdeburg economics professor Joachim Weimann explains why renewable energies have been a terrible idea for Germany so far.
Recently a high ranking expert commission set up by the German government even sharply criticized the German Energiewende (transition to renewable energies), saying it was leading the country down the wrong path. But as Prof. Weimann explains, the commission’s results fell on deaf ears.

Weimann starts the interview by explaining that the target of the Energiewende is to replace carbon-dioxide-emitting fossil fuels in order to protect our climate. One instrument used to achieve that target was Cap and Trade, in combination with the Energiewende, which Weimann says has not worked well at all. The U. of Magdeburg professor says that every cut that gets achieved in Germany gets offset elsewhere, and so net CO2 gets saved at all.
Weimann says that over the years policymakers promised and obstinately insisted that renewables were the way to go, and so ended up putting themselves in a position of which it is now impossible to back out. What leading politician is going to step forward and tell us that it was all a big mistake? “We find ourselves in quite a bind, says Weimann.
Weimann recommends that citizens step up and tell their leaders that what is currently happening is not in their interest, and that they need to exert influence media reporting on the issue. Weimann says:
It is very very difficult. Currently we have over 1000 citizens intiatives against wind power in Germany, yet they practically go unmentioned in media reporting. Compared to the resistance to nuclear energy, it is a crass disproportion. This shows us just how difficult it is to bring the issue to the forefront.”
Weimann hopes that the protests will grow until a critical mass is reached, and can no longer be ignored.
The professor points out that for years a number of institutions and experts have shown that the feed-in act is not functioning properly, that it wastes resources, and is bad policy that is having no impact on climate protection. He adds that the feed-in act entails extremely high costs, not only in terms of capital but also in terms of damage to the country’s landscape. “That means we are producing costs, and no yields. That is not good policy,” says Weimann.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Policymakers, in Weimann’s view, have long been ignoring what the scientific data and experts have told us with respect to renewable energies, but that they are refusing to back out it because they are so far deep into it and that it would be too embarrassing to do so.
Public kept in the dark by media, policymakers
According to Weimann, 80% of the German population are still in favor of renewable energies because they are not aware of the near zero-impact it is having on CO2 emissions and because they are poorly informed. It is in fact only when a wind park gets proposed nearby does a citizen really begin to get interested in what really is at stake and finds out what the true implications are. “Then they suddenly recognize the nonsense that is in fact happening.”
In Weimann’s view, renewable energy topics and calculations are far too complicated for the average citizen to deal with when they don’t feel they have to.
Total destruction of our landscape
Weimann notes that according to the Ministry of Environment, wind and solar energy in 2016 made up only 3.3% of Germany’s primary energy supply and that so far it represents only a “thimble” of the energy that is needed. And “when you compare it to the cost needed for it, not only financial, but also in terms of the burdens to the citizens who have these energy systems next door, we have to say it is first totally disproportional, and secondly that if we wish to meet our targets using wind, it would mean the total destruction of our landscape.”
So far only 3.3% of our primary energy need is being supplied by wind (28,000 turbines so far) and solar. Weimann asks us to imagine what it would take to reach the 95% target. He says the entire German landscape would be profoundly and fundamentally transformed into one massive industrial park that would lose all its attraction. In short: It’s a policy calamity.
Those were just some of Weimann’s comments and claims in just the first 17 minutes of the interview. More on this soon.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Climate science is supposed to be settled, right?
We are told that there is an overwhelming agreement, or consensus, among scientists that most weather and climate changes that have occurred since the mid-20th century have been caused by human activity — our fossil fuel burning and CO2 emissions in particular.  We are told that natural mechanisms that used to dominate are no longer exerting much of any influence on weather or climate anymore.  Humans predominantly cause weather and climate changes now.
For example, we are told that extreme weather (hurricanes, droughts, floods, storms) frequencies and intensities have increased since about 1950 primarily due to the dramatic rise in anthropogenic CO2 emissions since then.  Humans are now melting glaciers and ice sheets and (Arctic) sea ice at an alarmingly accelerated rate — reminiscent of an impending “death spiral“.  Humans now  heat up and acidify the oceans down to depths of thousands of meters by burning fossil fuels.   Humans are now in the process of raising sea levels so that they will catastrophically rise by 10 feet in the next 50 years.   Because of our CO2 emissions, humans are now endangering the long-term survival of 100s of thousands of animal species (especially polar bears), and climate models say we will cause a million species extinctions over the next 33 years with our CO2 emissions.   The Earth is even spinning slower, or faster, no, slower, well, faster — due to human activities.  Again, this is all settled science.  Only those who possess the temerity to deny this science (“climate deniers”) would disagree, or refuse to believe.
But what if much of what we have been told to believe is not actually true?   What if scientists do not overwhelmingly agree that humans have dominated (with ~110% attribution) weather and climate changes since about 1950, which is what we have been told by the UN IPCC?   What if scientists do not overwhelmingly agree that natural factors exert effectively no influence on weather and climate changes anymore — now that humans have taken over?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




These are compelling questions.  Because in 2016 alone, 500 peer-reviewed scientific papers published in scholarly journals seriously question just how settled the “consensus” science really is that says anthropogenic or CO2 forcing now dominates weather and climate changes, and non-anthropogenic (natural) factors no longer exert much, if any, role.
Instead of supporting the “consensus” science one must believe in (to avoid the “climate denier” label), these 500 papers support the position that there are significant limitations and uncertainties inherent in climate modeling and the predictions of future climate catastrophes associated with anthropogenic forcing.  Furthermore, these scientific papers strongly suggest that natural factors (the Sun, multi-decadal oceanic oscillations [NAO, AMO/PDO, ENSO], cloud and aerosol albedo variations, etc.) have both in the past and present exerted a significant or dominant influence on weather and climate changes, which means an anthropogenic signal may be much more difficult to detect in the context of such large natural variability.  Papers questioning (and undermining) the “consensus” view on paleoclimate (Medieval) warmth, ocean acidification, glacier melt and advance, sea level rise, extreme weather events, past climate forcing mechanisms, climate sensitivity to CO2, etc., are included in this collection.
Because of the enormous volume of new papers available that support a skeptical position on anthropogenic climate change alarm, the list of 500 scientific papers with links has been divided into 3 sections, each with its own page (Part 1, Part 2, Part 3).   There are 68 graphs included in the volume, most of which are used to demonstrate that “hockey-stick” reconstructions of past temperatures and sea levels relative to today are not supported by available evidence.
Despite its size, this list will hopefully be user-friendly and easy to navigate as a bookmarkable reference volume due to its outline (below) and organized categorization.  Each paper has an embedded link under the authors’ name(s).
Finally, there are 132 papers linking solar activity to weather and climate change (in addition to another ~90 that link natural oceanic/atmospheric oscillations [ENSO, NAO, etc.], clouds, volcanic activity . . . to climate change).  This is of special note because the IPCC has, since its inception, insisted that solar factors play almost no role in modern climate change.  Apparently scientists agree less and less with that “consensus” position.

Click any of the 3 links below
Part 1. Natural Mechanisms Of Weather, Climate Change (236 papers)
Part 2. Natural Climate Change Observation, Reconstruction (153 papers)
Part 3. Unsettled Science, Ineffective Climate Modeling (112 papers)

Part 1. Natural Mechanisms Of Weather, Climate Change
I. Solar Influence On Climate (132)
II. Natural Oceanic/Atmospheric Oscillation (ENSO, NAO, AMO, PDO, AMOC) Influence On Climate (45)
III. Natural Ozone Variability and Climate (3)
IV. A Questionable To Weak Influence Of Humans, CO2 On Climate (11)
V. Low CO2 Climate Sensitivity (4)
VI. Modern Climate In Phase With Natural Variability (17)
VII. Cloud/Aerosol Climate Influence (14)
VII. Volcanic/Tectonic Climate Forcing (9)

Part 2. Natural Climate Change Observation, Reconstruction
I. Lack Of Anthropogenic/CO2 Signal In Sea Level Rise/Mid-Holocene Sea Levels Meters Higher (34)
II. Warmer Holocene Climate, Non-Hockey Sticks (41)
III. No Net Regional Warming Since Early- Mid-20th Century (15)
IV. Abrupt, Degrees-Per-Decade Natural Global Warming (D-O Events) (8)
V. The Uncooperative Cryosphere: Polar Ice Sheets, Sea Ice (34)
VI. Ocean Acidification? (14)
VII. Natural Climate Catastrophes – Without CO2 Changes (4)
VIII. Recent Cooling In The North Atlantic (3)

Part 3. Unsettled Science, Ineffective Climate Modeling
I. Failing/Failed Renewable Energy, Climate Policies (10)
II. Climate Model Unreliability/Biases and the Pause (34)
III. Elevated CO2 Greens Planet, Raises Crop Yields (10)
IV. Wind Turbines, Solar Utilities Endangering Wildlife (7)
V. Less Extreme, Unstable Weather With Warming (15)
VI. Heat Not Hazardous To Polar Bears, Humans (3)
VII. No Increasing Trends In Intense Hurricanes (3)
VIII. No Increasing Trends In Drought Frequency, Severity (7)
IX. Urban Surfaces Cause (Artificial) Warming (4)
X. ‘Settled’ Science Dismantled (3)
XI. Natural CO2, Methane Sources Out-Emit Humans (3)
XII. Fires, Anthropogenic Climate Change Disconnect (5)
XIII. Miscellaneous (4)
XIV. Scientists: We Don’t Know (4)
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhether Hillary wins or not, things are looking grimmer and grimmer for the Democratic Party with each passing day. The Hillary organization is now taking four major blows, simultaneously, and likely will shatter the Clinton backbone to pieces.

Four of Clinton’s biggest nightmares: Jonathan Gruber (Photo: MIT); Julian Assange (Photo: Free Assange); James Comey (Photo: FBI); James O’Keefe (Photo: Project Veritas). Also add a relentless Trey Gowdy to the mix. 
The Democrats would be doing the country a huge and honorable favor in withdrawing the Clinton candidacy – or making sure she does not get elected. This would spare the nation a great crisis. Some even warn of a Constitutional crisis.
The four back-breaking body blows:
1. Skyrocketing Obamacare costs
The runaway costs of healthcare insurance are turning into a grand debacle, one that will plague and enrage Americans for months to come. Nationwide Americans are bracing for an average 25% increase in healthcare premiums starting next year. The authors of this debacle: Obama, Clinton and the Democrats. The upward spiral is only the beginning.
2. Wikileaks
The whiz hackers behind these “illegal” leaks will wear down the Clintons for many more months. The e-mail exchanges expose the inner workings and shady dealings of the Clinton circle. You can view The Top 100 most damaging Wikileaks emails – so far – hat-tip Andrew Bolt.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Wikileak dump number 25 just occurred, and very few of us know how many more are on the way and what’s potentially in store. This alone will be a slow political death by a thousand paper cuts for the Clintons. Clinton’s problems are only beginning.
3. FBI reopened investigation
Right now the 650,000 e-mails discovered on the device of sex pervert (ex-husband of Clinton top aide Huma Abedin, Anthony Weiner, are likely only the tip of the iceberg.
Moreover, one senses there’s a real desperation to keep the e-mails concealed, and that the dam of corruption is about to break. This is a classic situation where when one digs deeper, the more one finds massive rot. Therefore Hillary’s troubles risk growing exponentially. And not only is the scandal reaching the very top levels of the US government, it has the potential of expanding internationally and ensnaring the UN, foreign governments and institutions. And once key players start feeling the heat, they’ll start ratting each other out and cause the dominoes to fall uncontrollably.
One thing is already clear: Clinton illegally managed confidential e-mails, lied to the FBI, and obstructed justice. The rest is just more icing. She is a lawbreaker no matter how you look at it.
4. Project Veritas revelations
The hidden cameras of James O’Keefe reveal voter fraud, intimidation and corruption within Democratic Party. The sleaze uncovered by James O’Keefe only further tarnishes whatever may be left of Clinton’s reputation.
We’re looking at many months, even years, of corruption-caused chaos and scandals. The only hope that the Democrats might overcome the tsunami may be to boldly implement a massive crackdown of the sort are now witnessing in Turkey. That’s a hugely tall order. We wish Hillary and the Democrats lots of luck with that, should they decide to go for it.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe DPA German press agency reported yesterday on the rapidly spreading energy poverty now engulfing the country.
The main driver is Germany’s skyrocketing electricity prices – primarily due to the legally mandatory feeding-in of wind and solar power. Currently regular household consumers are paying nearly 30 cents a kilowatt-hour – almost three times the rate paid in the USA.

Germany’s energy poverty. Over 330,000 German households saw their electric power service cut off in 2015. Photo cropped here.  
Back to the 19th century
Many households are no longer able to afford electricity and are seeing themselves catapulted back to the 19th century. According to t-online.de here, “More than 330,000 households in Germany have seen their electricity cut off over the past year alone.”
The German site writes that those hit the hardest are households on welfare, i.e. society’s poorest and most vulnerable.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




German politician Eva Bulling-Schröter of the Left Party has called it “a silent catastrophe“.
Not only have the poor been broadsided by the high electricity prices, but so have energy intensive industries. This all makes many average workers uneasy. Over the past years a number of German plants have been moving their operations to less expensive locations abroad, especially in the chemical industry. Traditional power companies have also been getting creamed, seeing billions of losses and thousands of layoffs.
6.2 million threats to cut off service were made!
T-online cites the German Bundesnetzagentur, adding that in 2015 also 44,000 households saw their natural gas turned off. T-online adds that millions more have been threatened with the loss of electric power: “Power cut-offs were threatened 6.2 million times. The average outstanding amount that electricity providers demanded from the impacted households was 119 euros.”
According to Bulling-Schröter: “Energy poverty in Germany is a silent catastrophe for millions of people, especially in the cold and dark winter months.”
T-online.de calls letting hundreds of thousands of “children, the elderly, and the sick” go without power while the country posts record electricity exports an “injustice” and that the German government “does not want to see the energy poverty” that is rampant throughout the country.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe online daily Abendblatt here and media all over Germany report that the country will not pass its climate protection act, which was supposed to be voted on tomorrow, thus meaning the Germany will come to the Marrakesh world climate conference later this month without any plan for decarbonizing its society.
Last June German Environment Minister Barbara Hendricks put forth the Climate Protection Plan 2050 with the aim of starting the “climate-friendly transformation of society”. The plan called for reducing CO2 emissions 40% by 2020 (compared to 1990 levels) and 80 – 95% by 2050.
However the plan was quickly and “radically” gutted out by Chancellor Angela Merkel’s Office, Economics Minister/Vice Chancellor Sigmar Gabriel, Transportation Minister Alexander Dolbridt and Agriculture Minister Christian Schmidt. The plan’s rejection sent a loud signal that the country was deeply divided on the issue, and that there were in fact other priorities far outweighing “climate protection”.
Plan withdrawn from a vote
The Ministry of Environment’s Climate Protection Plan 2050 was designed to systematically decarbonize German energy production, industry, transportation and agriculture by 2050, and was scheduled to be ratified by the German Bundeskabinett tomorrow, just in time for the world climate conference in Morocco, which starts next week.
However Minister Hendricks announced that she was withdrawing the latest plan, and thus it will not go up for a vote tomorrow. The reason, according to Klimaretter here: “It’s not ready for ratification.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The move to allow the plan to fall apart sent a wave of surprise across the country as it signals that Germany will come to Morocco with no official commitment to substantially reduce CO2 emissions. Hendricks will attempt a new vote in December, long after the end of the Morocco conference.
“Unscientific hodgepodge of measures”
This is a devastating signal coming from a country often viewed as one of the leading proponents of CO2 reduction and climate protection. Initially Germany wanted to showcase it’s commitment to CO2 reductions, and so in Morocco serve as an example for responsible behavior to the rest of the world. Now Europe’s most powerful economy will have nothing to show, and Europe’s leadership on the issue appears seriously compromised.
According to the Abendblatt, Michael Fuchs of Merkel’s CDU party called Hendricks’s draft plan “an unscientific hodgepodge of measures” and that climate strategy has to be foremost focused on innovation and technology.
“Embarrassment”
Leading environmental groups and environmental activists blasted the government’s gutting out and opposition to the climate protection plan, calling it an “embarrassment” that Germany will show up in Morocco with no official intention of cutting back its emissions.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterCold German October
Germany’s Deutsche Wetterdienst (DWD) weather service reports the preliminary weather data for October. At a mean of 8.6°C, the month came in 0.6°C colder than normal (compared to the 1981-2010 mean) and even came in 0.4°C colder than the 1961-1990 mean.
The DWD hints that natural variability factors are to blame for the cool month, writing:
An unusually strong high pressure area in October 2016 blocked the train of Atlantic lows towards Eastern Europe.
The October mean was calculated from data collected from Germany’s approximately 2000 weather stations across the country. October 2016 was also wetter and less sunny than normal.
Cold and cloudy in Austria
The situation was similar over Germany’s southeastern neighbor, Austria. The Austrian ZAMG weather service writes here that the Alpine country saw a much cloudier than normal month with a mean temperature 0.4°C below the 1981-2010 mean:

October-2016 temperature anomalies for Austria. Source: ZAMG.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Several cold snaps provided for wintery conditions especially at higher elevations. Austria had experienced a string of warmer-than-normal months, but that streak has ended. Already there are signs that November may be colder than normal as well.
Near record northern hemisphere snow cover
The wetteronline site here just reported that for this time of the year “snow cover in the northern hemisphere reached the second highest level in about 50 years“. Snow cover has extended to 31.48 million square meters. Only 1976 was higher. Over the past few days a vast area of Russia has seen temperatures fall well below normal. Because of the early and widespread snow cover , the air cools and results in significantly colder than normal temperatures.
What does this mean for the coming weeks? Wetteronline reports the massive snow cover will likely have consequences for Europe and North America. Widespread snow cover over northern Asia can lead to the formation of a powerful cold high system over Siberia, which in turn can weaken the polar vortex. The result:
The weaker it becomes, the more probable it becomes that there will be blasts of polar air over Central Europe.”
This was also the case over the past winters, yet Europe escaped with mild winters.
“Snowiest winter on record”
Not only Central Europe could be slammed by cold winters due to massive snow cover over Russia, also Eastern North America could get hit as well according to Weather Underground here. The site writes that some Siberian locations have seen “their snowiest winter on record“. Weather Underground reports that the current conditions for producing a hard winter “are the best they’ve been in years“.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterClimate Damaging Palm Oil: Rain Deficit in Amazon Due To Deforestation
By Dr. Sebastian Lüning And Prof. Fritz Vahrenholt
[German text translated/edited by P Gosselin]
In a press release on March 13, 2017, the Potsdam Institute for Climate Impact Research (PIK) presented model results on the impacts of drought on the Amazon rainforest. What follows is the the full text, much of which is correct but mixed with some questionable points:
Vicious circle of drought and forest loss in the Amazon

Logging that happens today and potential future rainfall reductions in the Amazon could push the region into a vicious dieback circle. If dry seasons intensify with human-caused climate change, the risk for self-amplified forest loss would increase even more, an international team of scientists finds. If however there is a great variety of tree species in a forest patch, according to the study this can significantly strengthen the chance of survival. To detect such non-linear behavior, the researchers apply a novel complex network analysis of water fluxes
‘The Amazon rainforest is one of the tipping elements in the Earth system,’ says lead-author Delphine Clara Zemp who conducted the study at the Potsdam Institute for Climate Impact Research, Germany. ‘We already know that on the one hand, reduced rainfall increases the risk of forest dieback, and on the other hand, forest loss can intensify regional droughts. So more droughts can lead to less forest leading to more droughts and so on. Yet the consequences of this feedback between the plants on the ground and the atmosphere above them so far was not clear. Our study provides new insight into this issue, highlighting the risk of self-amplifying forest loss which comes on top of the forest loss directly caused by the rainfall reduction.’ This study results from the  German-Brazilian Research Training Group on Dynamical Phenomena in Complex Networks at (IRTG1740) hosted by Humboldt Universität zu Berlin.
Self-amplifying effect comes on top of the forest loss directly caused by reduced rainfall
Under a dry-season halving of rainfall, at least 10 percent of the forest might be lost due to effects of self-amplification alone, adding to the substantial direct forest losses from reduced water availability. Computer simulations built by the scientists suggest that this has already happened in the Amazon about 20,000 years ago, in accordance with evidence from the Earth’s past. Still, they stress that the uncertainties are considerable. Taking into account the puzzlements of the vegetation-atmosphere-feedback, self-amplified forest dieback could amount up to 38 percent of the Amazon basin. In combination with the direct effects of the droughts, in fact most of the Amazon forest might eventually be at risk.
The study cannot provide information about the time scales of the processes, it is rather a sensitivity analysis.
Strikingly, the huge tropical woods produce much of the water they need themselves by evaporating moisture which then rains back onto them. ‘The Amazon water cycle is of course pure physics and biology, but it is also one of nature’s great wonders,’ says co-author Henrique M.J. Barbosa from the Universidade de São Paulo, Brazil. ‘As powerful as the cycle is, it is also surprisingly susceptible to environmental changes – and humankind is imposing massive perturbations on Amazonia by both cutting down the trees and heating up the air with greenhouse gases, which reduces large-scale moisture transport and precipitation, and end up affecting even the untouched patches of the forests.’
Even if average rainfall is stable, extended dry periods increase the risk of tipping


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




‘Today, the wet season is getting wetter and the dry season drier in Southern and Eastern Amazonia due to changing sea-surface temperatures that influence moisture transport across the tropics,’ says Anja Rammig from Technische Universität München (TUM) and PIK. ‘It is unclear whether this will continue, but recent projections constrained with observations indicate that widespread drying during the dry season is possible in the region.’
Even if average rainfall might not drastically change, extended drought events might tip parts of the Amazon forest into self-amplifying forest loss, eventually turning them into a savanna. ‘Projected rainfall changes for the end of the 21st century will not lead to complete Amazon dieback,’ says co-author Carl Schleussner from Berlin-based scientific think tank Climate Analytics and PIK. ‘But our findings suggest that large parts of it are certainly at risk.’
Interestingly, the more diverse the Amazon vegetation is, the less vulnerable it seems to be.  Diversity has the potential to decrease the effects of self-amplified forest loss. ‘Since every species has a different way of reacting to stress, having a great variety of them can be a means for ecosystem resilience,’ says Marina Hirota from the Federal University of Santa Catarina, Brazil. ‘Preserving biodiversity may hence not just be about loving trees and weeds and birds and bugs; it may also be a tool to stabilize key elements of the Earth system.’
Article: Delphine Clara Zemp, Carl-Friedrich Schleussner, Henrique M. J. Barbosa, Marina Hirota, Vincent Montade, Gilvan Sampaio, Arie Staal, Lan Wang-Erlandsson, Anja Rammig (2017): Self-amplified Amazon forest loss due to vegetation-atmosphere feedbacks. Nature Communications [DOI:10.1038/NCOMMS14681]”


It is plausible that droughts burden rainforests. On the subject of rain trends, we wish to take a closer look. In the press release we read:
Today, the wet season is getting wetter and the dry season drier in Southern and Eastern Amazon…”
Less rain during the dry period is a problem in the southern and eastern Amazon regions. But what is happening in the west and north? Is rainfall perhaps increasing there during the dry period or remaining steady? The remaining trend statements looks at the future, based on questionable modelling that in the past has seldom been reliable.
An important aspect was brought up only briefly at the start of the article, namely the destruction of rain forests through the supposedly green palm oil barons.
The anthropogenic deforestation under the guise of climate protection, according to one study by Spracklen & Gardcia-Carreras (2015) in the Geophysical Research Letters with respect to a reduction in precipitation:
The impact of Amazonian deforestation on Amazon basin rainfall
We completed a meta-analysis of regional and global climate model simulations (n = 96) of the impact of Amazonian deforestation on Amazon basin rainfall. Across all simulations, mean (±1σ) change in annual mean Amazon basin rainfall was −12 ± 11%. Variability in simulated rainfall was not explained by differences in model resolution or surface parameters. Across all simulations we find a negative linear relationship between rainfall and deforestation extent, although individual studies often simulate a nonlinear response. Using the linear relationship, we estimate that deforestation in 2010 has reduced annual mean rainfall across the Amazon basin by 1.8 ± 0.3%, less than the interannual variability in observed rainfall. This may explain why a reduction in Amazon rainfall has not consistently been observed. We estimate that business-as-usual deforestation (based on deforestation rates prior to 2004) would lead to an 8.1 ± 1.4% reduction in annual mean Amazon basin rainfall by 2050, greater than natural variability.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAt the site of the European Institute for Climate and Energy (EIKE) Josef Kowatsch and Stefan Kämpfe look at the frosty spells that typically occur in mid May, the so-called “Ice Saints“, which are widely reported on by the German media each year.

The German DWD national weather service, once a model for meteorology and climate, has over the years taken on a more activist global warming role, with some even claiming that it too has joined the propaganda army of the man-made global warming movement.
Not surprisingly, the DWD management has been claiming in the press that the so-called Eisheilige (Ice Saints) have been getting less intense over the years and that they may wind up disappearing altogether. Because of global warming!
Often typical in mid May, a weather pattern involving a high located over the North Atlantic near Iceland feeds blasts of polar air across Europe. This happened last year on May 14, 2016 – see following chart:


Figure 1: A high over Iceland pumped polar air (blue arrow) across Europe, 2016.
Unfortunately, the DWD has been spreading false information on Europe’s Ice Saints, the two authors at EIKE write, and that their article is to make German readers aware that the DWD top management has been “regularly telling complete falsehoods to the media over the past years in the week before may 11“.
Kowatsch and Kämpfe add.

The DWD Chairman has claimed that over all the previous years:
1) The “Ice saints” recently have been getting continuously warmer and that they will soon become the Hot Saints, which the press then gladly called the Sweating Saints, and
2) the Ice Saints have practically disappeared on account of climate warming.”
These claims of course aroused the suspicions of Kowatsch and Kämpfe, who decided to go back and look at the DWD’s own data. What they found is that the DWD had been misleading the media and the public with statements of warmer Ice Saints periods, and that in fact the very opposite has been occurring: the Ice Saints have been getting colder!
The following charts show the mean May 11-15 temperature for Potsdam, which is home of the notoriously alarmist Potsdam Institute for Climate Impact Research (PIK), headed by global warming pope, Prof. Dr. Hans-Joachim Schellnhuber.




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 1: The Ice Saints (May 11-15) for Potsdam, Germany since 1985 – going back more than 30 years. The mid-May frosty period has in fact been getting colder, not warmer as the DWD has claimed. Chart: Josef Kowatsch
Kowatsch and Kämpfe also present the trend for Dresden-Klotzsche, an official station of the DWD. It too shows a cooling trend. So why would the media be reporting that the “Ice Saints” have been disappearing? Baffling, to say the least.

Figure 2: DWD station Dresden Klotzsche. Blue curve shows the May 11-15 mean temperature with linear trend, 1985 – 2016. Brown shows the maximum high temperatures, gray shows the minimum temperatures and yellow shows the 5 cm surface temperature. Chart: Samuel Hochauf. For 2016 the mean temperature was 12.88°C, i.e. right on trend.
Kowatsch and Kämpfe summarize:

All four trend lines [in Figure 2] show that the Ice Saints have been getting colder since 1985, and not warmer. All four trend lines show that the statements from the DWD management are false. The Ice Saints in Germany are getting colder.
Kowatsch and Kämpfe also look at another DWD weather station, which has been in operation since 1996: Goldbach bei Bischofswerda. Here as well the Ice Saints have been getting steeply colder:

This makes it all the more puzzling that the DWD higher-ups would be using the terms “recently has been“, or “is currently” getting” when telling the public the Mid May frost periods are disappearing. Example here.
Kowatsch and Kämpfe write that this year the DWD spoekespeople should make major changes in the next press releases on the subject of mid May cold spells, suggesting: “The month of May is getting colder and the Ice Saints are getting even colder” and that he should add the remark: “The Ice Saints soon will be as cold as they were in the mid 20th century, some 60 years ago when scientists worried about a new ice age.”
Why are May cold snaps in Europe getting colder?
Kowatsch and Kämpfe suspect that solar activity may be a major factor in the may cooling, as it is known that it has an impact on large weather patterns over Europe. Solar activity has been dwindling over the past 2 decades. Another factor maybe the Atlantic Multidecadal Oscillation (AMO), which now appears to be coming down from its warm peak. CO2 obviously is having no effect at all.
Josef Kowatsch is an independent nature and climate researcher. Stefan Kämpfe is an agricultural engineer and also an independent nature and climate researcher.
============================
PS: This year it appears that the Ice Saints will be right on schedule, with even winter conditions (snow!) across Scandinavia and Eastern Europe.

Share this...FacebookTwitter "
"
Share this...FacebookTwitter“The current eager acceptance of oceanic thermal lag as the ‘explanation’ as to why CO2 warming remains undetected, reemphasizes that the atmosphere cannot warm until the oceans do. The logical implication follows that most current climate models are lacking in relevance; they have not been constructed with ocean surface temperature as the fundamental variable. When the problem is attacked from this view, sensitivity to CO2 is significantly reduced; a position also strongly supported by the available palaeoclimatic data.”  — Ellsaesser, 1984

According to the IPCC (2013), 93% of the heat energy change from global warming can be found in the oceans (AR5, Chapter 3).  Only a tiny fraction of climate change can be accounted for in the atmospheric record, as the heat capacity of the oceans is more than a thousand times greater than the heat capacity of the air.  In other words, the widely-publicized surface air temperature change of about +0.6° to +1.0°C since the 19th century is not the main barometer of whether or not global warming has occurred – – and if it has, by how much.  Global warming (or cooling) is primarily accounted for as a change in ocean heat content, not surface air temperatures.
Climate models that prognosticate what the temperature of the global climate system might be 100+ years from now, or when atmospheric CO2 concentrations reach 560 ppm (doubled pre-industrial levels) are fundamentally flawed, for they presume that CO2 concentration rise (or decline) is a primary determinant of changes in atmospheric temperature change.  It is not.  Because of the magnitude of difference in heat capacity, it is the global ocean that determines the temperature of the air (predominantly), not the other way around.
It therefore needs to be established that (1) CO2 variations and ocean heat content changes are correlated (when CO2 falls, ocean heat/temperatures fall, and vice versa); and if they are correlated, then it still needs to be scientifically established (i.e., via experimental observation and measurement) that (2) ocean heat/temperature changes are primarily caused by CO2 variations.  Just because there is a correlation between two variables does not necessarily mean that one variable is the cause of the other.
So, as mentioned, first we need to establish a correlation before we can even consider causation.  And when it comes to a correlation between CO2 variations and ocean heat content variations, we don’t have one.  According to scientific studies of long-term ocean heat content, for 99.975% of the last 10,000 years, there has effectively been no significant correlation between rising or falling CO2 concentrations and rising or falling ocean heat.  As will be clarified below, the only period in the last 10,000 years in which CO2 and ocean heat/temperatures sharply rose or fell in concert was the period between 1975 and 2000.
Just 0.09°C – 0.18°C Of Net Warming In 0-2000 m To 0-700 m Ocean Since 1955
Levitus et al. (2012) estimate that, between 1955 and 2010, the global ocean heat energy change (converted to temperature) amounted to an addition of a blistering +0.18°C in the 0-700 m layer, and +0.09°C in the upper 2000 meters of the ocean.  That’s less than one-tenth of one degree over 55 years in the 0-2000 m layer.
Levitus et al., 2012
“The World Ocean accounts for approximately 93% of the warming of the earth system that has occurred since 1955. … The heat content of the World Ocean for the 0–2000 m layer increased by 24.0 ± 1.9 × 1022 J (±2S.E.) [over 1955-2010] corresponding to a rate of 0.39 W m−2 (per unit area of the World Ocean) and a volume mean warming of 0.09°C. … The heat content of the World Ocean for the 0–700 m layer increased by 16.7 ± 1.6 × 1022 J corresponding to a rate of 0.27 W m−2(per unit area of the World Ocean) and a volume mean warming of 0.18°C.”
Below the 2000 m depth (and 52% of the ocean waters reside below 2000 m), the “entirety” of the Pacific and Indian Oceans as well as the Eastern Atlantic have been cooling for the last few decades, largely off-setting the already modest change in the 0-2000 m layer.
Wunsch and Heimbach, 2014
“Over the 20 yr of the present ECCO state estimate, changes in the deep ocean on multiyear time scales are dominated by the western Atlantic basin and Southern Oceans. … In those same regions, a longer-term general warming pattern occurs below 2000 m. A very weak long-term cooling is seen over the bulk of the rest of the ocean below that depth, including the entirety of the Pacific and Indian Oceans, along with the eastern Atlantic basin.”

But let’s consider the contextual magnitude of the 0.18°C of warming in the 0-700 m layer since 1955.  Below is a graph taken from the Rosenthal et al. (2013) paper published in the journal Science documenting the changes in 0-700 m Pacific Ocean heat content during the Holocene.   Pictured are the last 1,200 years (800 C.E. to 2010) of ocean heat changes, including the added blue dotted line on the right extending from 1955 to 2010 (+0.18°C).
As indicated by the black trend bars, notice (a) the amplitude of the rise for the 1900-2010 period is not as steep as 11 previous decadal- and centennial-scale demarcated warming periods during the last 1,200 years.  Also notice that (b) the overall sharp drop in ocean heat since the Medieval Warm Period ended (encompassing the 1200 C.E. to 1900 Little Ice Age) was not accompanied by a sharp decline in CO2 concentrations, and that the Medieval Warm Period had flat, not rising, CO2 levels,  indicating that CO2 variations could not have been a causal factor in the ocean heat content changes during this entire period (800 C.E. to 1900).  Finally, notice that (c) modern temperatures are still tenths of a degree cooler than they were during the 1300 to 1500 C.E. period, when CO2 concentrations still hovered around 280 ppm.  In sum, the data in this graph indicate that there has been no significant correlation between CO2 and ocean heat temperature variations for nearly all of the last 1,200 years.

Non-Correlation Between Human CO2 Emissions & Ocean Heat For Most Of The 1900-2010 Period


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And yes, the non-correlation includes the 1900-2010 period.  There are very few reconstructions of global-scale ocean heat content prior to 1950 available in the scientific literature.  However, in a paper entitled “Consistent near surface ocean warming since 1900,” Gouretski et al. (2012) provide a comprehensive look at available evidence for the near-surface (0-20 m) change in ocean heat content for the early 20th century.  The supplemental graph below (using the available link [red] from the University of Hamburg) was made available upon the release of the paper.
Gouretski et al., 2012
http://icdc.cen.uni-hamburg.de/uploads/pics/hc_fig2.jpeg
Taking a closer look, the graph shows that the amplitude (+1.3°C) and rate (+0.27°C per decade) of the 1900-1945 ocean warming period was about 4 to 5 times as large as the 1945-2010 warming period (+0.3°C, +0.055°C per decade).

In the paper, Gouretski and co-authors point out that the twenty-first century has experienced a general cooling in large regions of the global ocean — just as anthropogenic CO2 emissions (and atmospheric CO2 concentrations) were rising most dramatically.
“[T]he first decade of the 21st century (2001–2010) was not uniformly warmer than previous decades. Before about 1920, the global ocean was almost everywhere colder than the reference decade of 2001–2010. After 1920, several regions of the global ocean were warmer than the reference decade [2001-2010]. … [A] rather abrupt cooling since the end of 1990s both in the East Pacific (connected to the weakening of El Nino and the shift to the negative phase of the Pacific Decadal Oscillation) and in the Southern Ocean may have contributed to a flattening of the global temperature anomaly series after about 2000. …Decadal mean SST and 0–20 m layer anomalies calculated relative to the reference decade 2001–2010 give evidence of the general warming of the global ocean since 1900. However, large regions of the oceans have experienced cooling since the 1990s. Whereas cooling in the tropical Eastern Pacific ocean is associated with frequent La Nina events in the past decade, the cause of the cooling within the Southern Ocean remains unknown.”
The much larger amplitude and rate of warming that occurred in the early 20th century was not accompanied by a commensurate large change (increase) in anthropogenic CO2 emissions.  In fact, throughout the entire 1900 to 1945 period, human emissions only averaged about 1 gigaton of carbon per year (GtC/yr).  In contrast, human emissions rates rose sharply to 4 GtC/yr by the 1970s, 6 GtC/yr by the 1990s, and over 10 GtC/yr by 2014.  Atmospheric CO2 followed a similar trajectory, as concentrations rose by just 15 ppm in the 40 years between 1900 and 1950 (295 ppm to 310 ppm), whereas concentrations rose by 85 ppm in the 65 years after 1950, including 22 ppm just between the years 2000 and 2010 alone (Feldman et al., 2015) — a decade when near-surface ocean heat “flattened” according to Gouretski et al. (2012).  And despite this explosive increase in human CO2 emissions and atmospheric CO2, the near surface ocean heat content actually cooled between 1945 and 1975, and the rate of warming since 1975 has been much less pronounced than during the 1900-1945 period.

If we were to visually combine the record of the explosive rise in human CO2 emissions since 1945 with the record of near-surface ocean heat content for the entire 1900-2010 period, it would be evident that the only decadal-scale period in which CO2 emissions steeply rose in concert with ocean temperature was during the 25 years between 1975 to 2000.  For 1900-1975 and 2000-2010, there was no obvious correlation between rapidly rising CO2 and ocean heat content.

No Correlation Between CO2 Variations And Ocean Heat For The Entire Holocene
And not only is there a lack of correlation between rising CO2 and rising ocean heat content for all but the 1975-2000 period during the years 800 C.E. through 2010, there is also no correlation between rising CO2 and rising ocean heat for the entirety of the Holocene.  Actually, the general long-term trend is for there to be an inverse correlation: as CO2 rises, ocean heat content declines.   The following Rosenthal et al. (2013) graph of the Pacific Ocean’s 0-500 m layer demonstrates this.


Conclusion
To summarize, in the last 10,000 years, there was one 25-year period (1975-2000) in which CO2 levels and ocean heat content rose in concert.  Other than that, the rest of the last 10,000 years contained no obvious correlation between ocean heat content variations and the rise and fall of CO2 concentrations.  Without a significant long-term (or short-term) correlation between these two variables, we cannot even begin to address the causality question.
Simply put, the presumption that variations in CO2 concentrations cause global warming — net increases in global-scale ocean heat content — has not been established.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe online Die Welt here reports that storm “Herwart” which swept across Germany late last month – with wind gusts of up to 140 kilometers per hour  – led to a wholesale electricity “price collapse” and thus “exposed the madness of the Energiewende“.
“Negative prices”
As storm Herwart waged, wind parks across Germany over-flooded electricity grids with power that was not needed, and thus forced electricity prices on the exchange to go deep into negative levels within just minutes. In a nutshell: grid operators were forced to pay to get rid of the surplus power. But that payment won’t go to consumers, as Die Welt writes:
The consumers get no benefit from this. For them it will even be more expensive.”
This is because as grid operators are forced to pay large buyers to accept the power that no one needs or wants, they will incur added costs, which of course will be passed on to the regular German consumers. Germans are already saddled with almost the highest rates in the world. This is despite the preposterous comments made by some media outlets suggesting that German consumers could even get paid for the disposal of waste power.
Market forces disabled
Die Welt presents a chart depicting wholesale power prices. It shows the price falling to -52.11 euros per megawatt hour. Moreover, the chart shows that these extreme negative prices have become more frequent over the past 18 months. Die Welt comments:
‘Herwart’ shows in a sobering manner the astounding design deficiency of the German Energiewende [transition to green energies]. “
Die Welt blames Germany’s Energiewende and the green energy feed-in act, which “systematically disable market forces”.
Thousands Of Older Wind Turbines To Be Dismantled



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On another note, the Kiel, German-based Kieler Nachrichten (KN) reports “thousands of wind turbines will be supposedly dismantled over the coming decade because the state subsidies will run out“. “And according to the Berlin-based specialty company Energy Brainpool, these turbines will not be replaced if energy prices do not increase.
Subsidies running out
Economists of the Helmholtz Center for Environmental Research also expect a decommissioning of a considerable number of older turbines. The 2020s could be a decade where Germany may start to see the end of the wind energy madness. It all depends on the price of electricity in beginning in 2021. Wind turbines originally were guaranteed fixed feed-in rates for a period of 20 years. Now that these early systems are approaching that lifetime and the feed-in tariffs expire, it is questionable that they will continue to operate.
Too expensive to keep in operation

Many old turbines are likely to be put out of commission because they require greats amounts of costly maintenance and repairs, and so likely will not be profitable to operate. The KN writes:

The current wholesale electricity price of 3 euro-cents per kilowatt-hour will not be enough to keep the turbines in operation…”.

The KN cites the Bundesverband Windenergie (German Association for Wind Energy) which estimates that some 14,000 MW of installed capacity face being shut down by 2023. “That would be more than a quarter of the currently installed onshore wind energy capacity getting removed.”
A monument to an industrial folly
The question that remains is what will happen to these thousands of shut down turbines. Will they be abandoned and thus leave the country’s idyllic landscape a mass junkyard – a monument to one of the greatest industrial follies man has ever witnessed?
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWinter in the US refuses to yield as snow falls in the Rockies and in New England. More is on the way.

April Fools on global warming. Snow blankets parts of New England on April 1st. Photo: Reader Snowman.
And according to veteran meteorologist Joe Bastardi at Weatherbell, more surges of cold and snow are forecast later this week from Pennsylvania to the Smokies, and in California and Colorado, which is forecast to be hammered by a snowstorm. Even Chicago could get snow later in the week.
So winter obviously still has a ways to go and many ski lifts will be operating into Easter, which this year is in mid April.
Dramatic ocean sea surface cooling
Later Joe notes that the ocean sea surface temperature has seen a “dramatic cooling” since last year – especially the Indian Ocean, which may act to feed another El Nino.
Bumper crop – “very little drought area”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The warm Estern Gulf of Mexico will serve to bring more rain over central USA, which Joe says will help lead to a “great growing season” this summer in the United States. Bastardi also says he expects: “very little drought areas this year” and adds: “I think we’re going to see a bumper crop in the Plains in whatever you want to grow“.
Below normal Atlantic hurricane season forecast
On the hurricane season forecasting front, Joe expects a somewhat below normal hurricane season for the Atlantic this year:

Joe Bastardi predicts generally below average hurricane activity for the 2017 season. Along the eastern seaboard, western Gulf of Mexico and western Atlantic the forecast is for above normal activity (red area). Chart source: Weatherbell Weekend Summary
Joe’s forecast is different from what veteran meteorologist David Dilley here issued earlier this year. In it Dilley warned it’ll probably be one of the worst in years. But Joe emphasized that this year’s forecast “is tricky” and harbors uncertainty. Yet overall he thinks the season will be more on the gentler side.
US months of February have been cooling
At 9 minutes into the Saturday Summary, Joe debunks claims that the months of February have been getting warmer over the years (a claim that is also often made about Europe, which is false). Joe shows that the recent 10 years (2007 – 2017) in fact “have been getting colder” and were much cooler than the previous 1996 – 2006 years.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Ocala, FL (PRWEB) Global Weather Oscillations (GWO) veteran meteorologist David Dilley says in his early forecast that the 2017 Atlantic hurricane season will be stronger than last year – with the potential for 6 named storms making United States landfalls.
It will also be the most dangerous since the 2005 season, which saw 5 hurricane landfalls and 2 tropical storms.
GWO has issued the most accurate preseason predictions of any organization the past 8 years, including last years’ prediction that the “Atlantic Basin” (which includes the Caribbean Sea and Gulf of Mexico) – would enter a Climate Pulse Hurricane Enhancement Cycle in 2016.
David Dilley, Senior Meteorologist for Global Weather Oscillations (GWO) – correctly predicted months in advance that GWO’s prediction zones for the Florida Panhandle and Florida’s East Coast northward to North Carolina – would experience hurricane and/or strong tropical storm conditions in 2016, with multiple strikes likely (see GWO’s 2016 hot-spot predictions graphic).
Here is the GWO’s prediction from last year.
As it turned out – 5 named storms made United States landfalls with Hurricane Hermine making landfall on the Florida Panhandle in the Eastern Upper Gulf (see Hot Spots graphic). But more importantly was Hurricane Matthew – a major hurricane that moved north across Haiti and the Western Bahama’s – then hugged the coastal areas from Florida to North Carolina. 1,739 people died from hurricanes in 2016, most of which were from Hurricane Matthew in the Caribbean. The last time the death toll was that high was in 2005 when nearly 4,000 people were killed by hurricanes.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The official hurricane season begins on June 1 and ends December 1. The Atlantic Basin on average has 12 named storms, 6 hurricanes and 2.7 major hurricanes. As predicted by GWO, the 2016 hurricane season was more dangerous and costlier than average. The official season (minus Hurricane Alex in January) – had 14 named storms, 6 hurricanes and 3 major hurricanes – and the United States experienced much above normal activity with 5 out of the 14 named storms making landfall in GWO’s predicted Hot Spots, 2 of which were hurricanes (Mathew and Hermine).
2017 prediction
GWO’s Climate Pulse Hurricane Model indicates that 2017 will once again be influenced by a Climate Pulse Hurricane Enhancement Cycle – with very conducive conditions for hurricane development due to the lack of an El Niño, or La Niña conditions. In addition ocean water temperatures continue to run warmer than normal across most of the Atlantic Basin (red and orange in the graphic), and especially in the Caribbean region and the Atlantic near the United States. This warmer ocean water will be conducive for tropical storms and/or hurricanes forming and/or strengthening close to the United States.
Mr. Dilley, a 40-year veteran, also expects the Bermuda-Azores High Pressure Center will be weaker this summer – thus allowing more named storms to maintain strength – or strengthen as they move from east to west across the Atlantic toward the United States.
He believes the upcoming 2017 hurricane season will be stronger than last year, and it will be the most dangerous and costliest in 12 years for the United States.
The upcoming season will have 16 named storms (14 last year), 8 hurricanes (6 last year), and 4 major hurricanes (3 last year). In addition the United States will have the potential for 6 named storms making landfall, the most since the 2005 season that saw 5 hurricanes and 2 tropical storms make landfall.
GWO also expects 3 out of the 6 landfalls will be hurricanes – with 1 or 2 having the potential for being a major impact hurricane. More information is available at GlobalWeatherOscillations.com, or GlobalWeatherCycles.com.
GWO is the only organization that issues detailed predictions two years into the future for 11 United States prediction zones stretching from New England to Texas. GWO’s hot spot zone predictions for the United States have been nearly 87 percent accurate since 2006 – with GWO correctly predicting 1 to 3 years in advance – the occurrences of Hurricane Ike (2008), Irene (2011), Sandy (2012), Matthew and Hermine (2016). Detailed zone and hot spot predictions for the 2017 and 2018 hurricane seasons can be obtained through GlobalWeatherOscillations.com, or GlobalWeatherCycles.com.
GWO and Senior Meteorologist/Climatologist David Dilley is an expert on climate cycles and climate change. A “free” climate change e-book “Earth’s Natural Climate Pulse” (authored by Mr. Dilley) can be acquired through the Global Weather Oscillations web site.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe latest forecast shows snow and cold moving across much Germany this weekend, again. Despite Germany ‘s ruddy CO2 emissions, winter keeps coming.
German public broadcasting, here for example, reports today that despite all the green, climate-preaching, Germany will miss its 2020 CO2 reductions by a mile. More embarrassingly, the country has not reduced its CO2 equivalent emissions in 9 years when 2017 is counted in the statistics.

2017 Co2 equivalent greenhouse gas emissions are are projected to be at about 906 million tonnes this year (2017). Data taken from German Ministry of Environment. 
The online site of German NTV public televisions reports that the results of a study by the Prognos Institute tell us that not only is the country going to miss its 40% CO2 reduction target compared to 1990, but that also “energy efficiency is significantly below the expected development requirements of the energy concept“. In fact energy efficiency has worsened over 2016, NTV writes.
Although Germany is a country that likes to preach to countries about their obligations and responsibility to boost green energies and cut back on “dirty” fossil fuels, it itself has failed miserably to make any progress of its own.
NTV adds:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The German government has fell way short of all its major targets when it comes to the Energiewende.” 
High costs with no results
The NTV later continues:
Regardless of subsidies in the triple digit billions for the expansion of renewable energies, the emissions of climate-damaging carbon dioxide have not decreased as planned, but rather have stagnated since 2014.
Actually CO2 equivalent emissions in Germany have been stagnant for 9 years now, as mentioned above.
“Fundamentally a disaster”
Germany’s EEG feed-in surcharges are currently costing more than 24 billion euros annually, according to the German Energie- und Wasserwirtschaft (Water and Energy Management).
In terms of what the citizens are getting for their money, the Union of Bavarian Economy President Alfred Gaffal has called it “fundamentally a disaster“.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterLike so many (highly subsidized) green energy projects in Germany the Kalina geothermal power plant in Unterhaching, Germany, was put into operation with great fanfare some 8 years ago in 2009.
Look at all the great things we’re doing, high ranking politicians seemed to say as the cut the opening ribbon.
Today the online Merkur.de reports that the “prestige project of Germany” has been out of operation since summer, and so “possibly forever“. According to the Merkur, the plant has produced as much trouble as it has energy. Efforts to rescue the project have failed.

To produce power at the low temperature range between 90 and 200 °C, a complex and special power plant process is used. In Unterhaching, just south of Munich, the first Kalina geothermal power plant technology was used. Recently it was reported that the project may be be permanently shut down due to costs and technical problems. 
According to the company’s promotional video here, the plant was designed to produce 3.4 megawatts of electric power and 38 megawatts of district heating “for thousands of households“…”emissions-free, sustainable and renewable.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The partner for the district heating part of the Unterhaching plant, the community of Grünwald, has invested in cooperation with Unterhaching already 23.5 million euros over the past five years. Credits were also given by Grünwald and Unterhaching in an attempt to save the project from insolvency, but the geothermal plant has since turned into “a bottomless pit” and members of the town councils spoke of “an immense burden” and a “failed project” due to the losses from the electricity generation part of the plant.
According to the Merkur, the technical problems are not related to the Kalina technology itself, but rather due to material used for the heat exchangers of the power plant.
As soon as the plant was switched on for the first time just after its opening by then German Environment Minister Sigmar Gabriel, it began to stink like ammonia just a half hour later. At the time the heat exchanger leaked and rubber seals did not help. It had to be welded. Other technical problems plagued the plant.
The Merkur points out that the district heating part of the plant, which is the main part, “functions excellently“, adding: “More than 50% of the households in the community were provided with a hook-up to the geothermal plant in 2015.”
Yet, for the tens of millions of euros invested, that may be a very tiny consolation. Alternative energy seems to be burning cash rather than generating power.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s online Der Spiegel here reports that Germany once again will fail to reduce its CO2 emissions this year, 2017.
This is a profound embarrassment for Germany, a country that has been a staunch preacher of climate protection and one of the world’s most vocal critics of President Donald Trump’s decision to back out of the Paris Climate Accord.
Rise of 5 million tonnes
According to the leftist Spiegel, greenhouse gas emissions in Germany rose by 5 million CO2 equivalent tonnes in the first half of 2017, hitting 428 million tonnes. That’s a jump of 1.2%. Experts say that the rise is likely due to increased petroleum consumption. According to Spiegel, diesel fuel sales are up 6.5 percent.
Part of the increased petroleum probably is due to low fuel prices, and the unusually colder than normal weather in January and April. Germany is failing horribly to reach its emissions targets, as the following chart shows:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




German equivalent Co2 emissions fell from 1,251 million tonnes in 1990 to 906 million tonnes in 2016. However, there has not been reductions in 8 years. Source: UBA
And if this year’s trend keeps up, it’ll mean that Germany’s emissions will have remained flat for 9 consecutive years. A decade of failure. It will also mean that the country’s greenhouse gas emissions will rise for a third consecutive year. More here.
Germany’s anti-diesel movement will end up raising CO2 emissions
The bad news for the climate-protection-preaching Germany is that greenhouse gas emissions reductions are likely going to get far tougher, as once again the country’s leaders are managing to shoot themselves in the foot in the comedy that has become the Energiewende.
One of the country’s leading Green Party politicians, Winfried Kretschmann, has just warned that the current movement to ban the diesel engine will have serious climate target consequences, reports the online Die Welt. As the publicity against the diesel engine cranks up, people will opt for the gasoline-powered cars instead. The problem here is that diesel engines get far better fuel mileage than the Otto engines, and so German consumers will only end up spewing more CO2 in the atmosphere.
Also Germany’s flood of immigrants, who have other worries on their minds, will add to make the German targets an even bigger fairy tale.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA SUNDAY MORNING BOMBSHELL
UPDATE: “Being retired sure is liberating.” – John Bates. Read: https://judithcurry.com/2017/02/04/climate-scientists-versus-climate-data/#more-22794
===================================
According to a just published article by the Online Mail of the UK here, a “high-level whistleblower” has disclosed that America’s National Oceanic and Atmospheric Administration (NOAA) “breached its own rules on scientific integrity” and “duped” world leaders with manipulated global warming data.
The result of the manipulated data was to exaggerate the computed global warming. The aim was to make “the maximum possible impact on world leaders including Barack Obama and David Cameron at the UN climate conference in Paris in 2015,” the Sunday Online Mail writes.
Manipulated data and the breaching of scientific rule have long been an accusation made against the NOAA in the climate science community, especially in the wake of the 2009 leaked Climategate e-mails, which showed scientists colluding to manipulate climate data and to unethically suppress scientific dissent. The ensuing whitewash was equally controversial.
“Irrefutable evidence”
The latest revelation, according to Online Mail, comes from “impeccable” NOAA scientist Dr. John Bates, who has shown “irrefutable evidence” that an NOAA paper showing accelerating global warming was rushed to be published just before the Paris Conference in 2015, and was “based on misleading, ‘unverified’ data“. The paper became to be known as the “Pausebuster” and was central in spurring the 2015 Paris Treaty.
Central African data made up entirely
On another matter, the NOAA has just come under massive fire as climate science skeptic Tony Heller presented at his realclimatescience blog strong evidence that the government agency manipulated December 2016 data in order to make it “red hot” in Central Africa, “with record heat“. However, the problem is that there are no measurement stations whatsoever located in the vast region, and so the NOAA simply made up and filled in the hot data.
Heller notes that full-surface temperature measurement by satellites in fact show that “the NOAA’s record hot regions in Africa were actually close to normal“.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure above: The heated data that the NOAA reported to the public.

NOAA data actually recorded by thermometer (Source of above charts: realclimatescience.com.
Heller, a prolific critic of climate science, commented that the NOAA “reported” map (first chart) above “is fake” and that the “NOAA has almost no temperature data from Africa, and none from central Africa. They simply made up the record temperatures.”
Flawed datasets
Concerning the just challenged NOAA’s 2015 ‘Pausebuster’ paper, the Online Mail writes that it is based on “two new temperature sets of data“, both of which were “flawed.” The Online Mail adds that the paper used “unreliable methods which overstated the speed of warming” and that “revised data will show both lower temperatures and a slower rate in the recent warming trend“.
What is worse about the paper is that the data used to produce its results weren’t archived and made available, which violated NOAA rules and proper scientific methodology. The Online Mails adds:
Before he retired last year, he continued to raise the issue internally. Then came the final bombshell. Dr Bates said: ‘I learned that the computer used to process the software had suffered a complete failure.’ The reason for the failure is unknown, but it means the Pausebuster paper can never be replicated or verified by other scientists.“
Read more: www.dailymail.co.uk/.
=================================
PS: Comments denying the scandal without substantiation will be promptly deleted.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAs Europe and USA brace for more frigid weather, some are asking if this is what we need to expect to cope with in the future.
Now it’s clear that the recent “record warm” 2 years had little to do with CO2, and instead were almost entirely due to the well-known El-Nino phenomenon over the past two years.
And now that the recent El Nino has disappeared, temperatures globally are in a free fall and back at levels of the previous decade and indications show a further  drop.

The ENSO now in cool phase
Unfortunately even that enhanced layer of CO2 we have in the atmosphere was not able to trap any of the recent heat. The 20-year pause remains pretty much intact, and will be extended as the El Nino Southern Oscillation (ENSO) hovers near the cooling La Nina territory.
Note that it will take the cooler equatorial Pacific surface temperatures a few months to make there way into the lower tropospheric satellite data. Don’t be surprised if this year we see a repeat of 1999.
Last El Nino not really warmer than 1998
Dr. Roy Spencer here wrote that 2016 will in fact NOT be statistically warmer of any significance compared to 1998.
According to global warming theory, the earth is supposed to warm some 2.0 to 4.5°C by 2100, which means 0.2 – 0.45°C per decade. So shouldn’t the recent El Nino have warmed the globe some 0.4 to 0.8°C more than 1998? Not even close, as the speedometer below shows! For hardcore warmists, it is increasingly becoming a huge challenge to explain the glaring lack of warming so far this century.

German weather and climate analysis site wobleibtdieerderwaermung here writes on this:
The IPCC climate models for the temperature development have been way too high with their estimation as the comparison of the model calculations to the real, observed development recorded by satellite for January 2001 to Juni 2016.
The Global Warming Speedometer for January 2001 to June 2016 shows observed warming on the HadCRUT4 and NCEI surface temperature datasets as below IPCC’s least prediction in 1990 and somewhat on the low side of its 1995 and 2001 predictions, while the satellite datasets show less warming than all IPCC predictions from 1990 to 2001. Later IPCC predictions are too recent to be reliably testable. Source: Is the Reuters “news” agency committing fraud?“
North Atlantic is cooling
Things also do not bode well for the global warming alarmists in the Atlantic as well, as Kenneth Richard pointed out here yesterday: “North Atlantic Cooling Has Plunged Below 1950s (And 1800s) Levels – And Scientists Project More Cooling“.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The sun enters period of cool activity
Solar activity is also now at a low point as the current cycle winds down. meanwhile a majority of scientists are confident the next cycle will also be a weak one. Periods of weak solar cycles are associated with periods of global cooling.

Trend over one solar cycle (sunspot number). Now we are ending solar cycle 24. International sunspot numbers. 
Greenland on record ice mass rampage 
And although Arctic temperatures have been well above normal this winter, Greenland’s surface ice mass continues at its rampage record level:

Top: The total daily contribution to the surface mass balance from the entire ice sheet (blue line, Gt/day). Bottom: The accumulated surface mass balance from September 1st to now (blue line, Gt) and the season 2011-12 (red) which had very high summer melt in Greenland. For comparison, the mean curve from the period 1990-2013 is shown (dark grey). Source: DMI. 
Greenland ice mas is now some 100 gigatons (cubic km) above normal.
Intense cold across Europe and North America
Currently Europe is being gripped by an intense cold wave, one that has sent temperatures in Germany to as low as -27°C this morning.

A number of stations recorded readings under -20°C. Image: Wetter24.
USA is also bracing for a cold wave — one that is going to intensify and send temperatures far below normal over the coming days.

Temperatures in the southwest close to 40°C below (6 a.m. EST). Image cropped from earth.nullschool.net
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman public radio DLF here  reports an astonishing finding by scientists: Global wind speeds globally are slowing down! 
A number of European scientist groups and a European science magazine of the EU Commission just reported on this.

Global wind speeds are slowing down, European researchers believe. Image: anemometer, NOAA public domain photo.
According to the researchers, worldwide wind speeds have slowed down by about half a kilometer per hour since the 1960s.
The phenomenon is known as “stilling”, and scientists are not sure why it is happening. They speculate that it may have something to do with urbanization, climate change and cumulus clouds. But then the report admits: “Or it could be due to ageing wind speed instruments producing inaccurate results.”
Normally this should come across as being good news amid the claims that “global warming” is leading to more powerful and destructive storms. With slower wind speeds, one would naturally assume less storm destruction.
But instead the researchers see only dark clouds ahead and warn that this could have “terrible consequences for things like agriculture” and that weak winds “also mean that smog over cities will stick around longer”. It adds:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And while it may sound deceptively calm, it could be a vital, missing piece of the climate change puzzle and a serious threat to our societies.”
We are damned no matter what happens.



Send more funding
Naturally there’s the thinly veiled call for MORE MONEY as University of Gothenburg climatologist Dr. Cesar Azorin-Molina “believes there is an urgent need to determine the causes of stilling in a changing climate“.
Ironically, another problem the report hints at is that wind farms may also see less output as a result. Now aren’t windfarms supposed to make the weather tamer in the first place? This is like blaming harsher winters for obstructing the fight against warming because people have to emit more CO2 to keep warm. maybe wind farms are a factor in slowing down winds as they extract energy from the wind.
Not surprisingly, the results of the researchers are getting only tiny blurbs of reporting in the media. For years people have been brainwashed into thinking man-made global warming is leading to stronger winds. But now they are supposed to believe the opposite is happening? The public must never hear that winds are calming down.
All the contradictions climate science has put out are starting to catch up and cast the field’s credibility into serious question.
The junk science never ceases to amaze us.
 



Share this...FacebookTwitter "
"
Share this...FacebookTwitter650+ Skeptic Papers
Published Since 2016


During the first 3 months of 2017, over 150 papers have already been published in scientific  journals that cast doubt on the position that anthropogenic CO2 emissions function as the climate’s fundamental control knob.
Skeptic Papers 2017 (1)
Skeptic Papers 2017 (2)
The 2017 publication rate (~50 scientific papers per month) is slightly ahead of last year’s pace.  That’s because in 2016 there were 500 peer-reviewed scientific papers published in scholarly journals (Part 1, Part 2, Part 3) challenging the “consensus” claim that weather and climate changes are significantly determined by changes in atmospheric CO2 concentrations.
These 150 new papers support the position that there are significant limitations and uncertainties inherent in our understanding of climate, and that natural factors — the Sun, multi-decadal oceanic oscillations (NAO, AMO/PDO, ENSO), cloud and aerosol albedo variations  — have exerted a significant or dominant influence on weather and climate changes during both the past and present.

The guideline for the list of 150 scientific papers with links and summaries and graphs has been divided into 3 parts on 2 pages (Parts 1 and 2 are on the same page).  
Part 1. Natural Mechanisms Of Weather, Climate Change  
Solar Influence On Climate (38)
ENSO, NAO, AMO, PDO Climate Influence (20)
 Modern Climate In Phase With Natural Variability (8)
 Cloud/Aerosol Climate Influence (3)
 Volcanic/Tectonic Climate Influence (1)
Part 2. Unsettled Science, Failed Climate Modeling
Climate Model Unreliability/Biases/Errors and the Pause (12)
 Failing Renewable Energy, Climate Policies (2)
 Warming Beneficial, Does Not Harm Humans, Wildlife (3)
 No Trends In Extreme, Unstable Weather In Recent Decades (3)
 Natural CO2 Sources Out-Emit Humans (2)
 Fires, Anthropogenic Climate Change Disconnect (1)
 Miscellaneous (5)
Part 3. Natural Climate Change Observation, Reconstruction
Lack Of Anthropogenic/CO2 Signal In Sea Level Rise (9)
 No Net Warming During 20th (21st) Century (10)
 A Warmer Past: Non-Hockey Stick Reconstructions (21)
 Abrupt, Degrees-Per-Decade Natural Global Warming (1)
 A Model-Defying Cryosphere, Polar Ice (10)
Share this...FacebookTwitter "
"
Share this...FacebookTwitterClaims that the earth is rapidly heating up because of man-made CO2 and thus heading for a “climate catastrophe” have taken a serious body blow over the past three years as a huge and fresh body of science emerges.

More than 1000 peer-reviewed papers published over the last 3 years expose climate alarmism as fake science.
1000 papers in three years
Yesterday Kenneth Richard published his list of 500 climate catastrophe skeptic papers appearing in scientific journals in 2016 alone. It is the latest addition to the 282 papers published in 2015, and the 248 papers published in 2014, bringing the total number of peer-reviewed papers published over the past three years to more than 1000.
As a result the once many dramatic hockey-stick shaped curves put out by some climate scientists over the past two decades showing the earth is headed for disaster have been exposed as fake science, which of course had spawned some 20 years of nonstop fake news – much of it designed to spread panic among the population.
Needlessly hyped
According to Richard, the vast collection of fresh papers show that natural factors play a much larger if not a dominant role when it comes to climate change. The expected global warming has been needlessly hyped, experts are now saying.
Puts IPCC to shame
Harvard astrophysicist Dr. Willie Soon thinks the UN Intergovernmental Panel on Climate Change (IPCC) has strayed way off track. “I’m not surprised by the large number or empirical evidence that rejects the CO2 dangerous global warming alarmism,” wrote Soon in an e-mail. “This sort of literature review ought to put the sort of biased, if not anti-science, reports by the UN IPCC to shame.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Dr. Soon has long been a sharp critic of the mainstream institutionalized climate science. He added: “It is high time for the wider public to not only bear witness to the unbalance and corruption of our science institutions, but also to demand answers on why there has been such a disregard for truth and fact.”
Climate well within natural variability
Many among the 1000 peer-reviewed scholarly papers show that extreme weather events are in fact NOT increasing in any unusual manner, that they were also common in the past, and that today they are still well within the range of natural variability.
Other papers show that biodiversity is not under any serious threat. Hundreds of other papers have found that solar activity and oceanic cycles are in fact the driving factors behind climate change. In short the latest fresh batch of scientific literature is telling us that all the past alarmism likely has been needlessly shrill and that it’s time to take a step back and to seriously refocus.
Although most of the papers listed by Richard do not refute global warming and that man plays a role – they do cast undeniable doubt over the cause of the warming, especially the warming over the past 35 years. The recent literature clearly shows that natural factors indeed play a major role, and CO2 much less so.
Climate science a UN charade
Not mincing any words, Canadian climatologist Dr. Tim Ball feels that global warming became a charade years ago and that it has gone on too long.
He offers an even harsher assessment of the UN climate science, writing that the IPCC is made up of “bureaucrats” who harbor a political agenda. “Extreme bias of climate research was deliberately created through the Intergovernmental Panel on Climate Change (IPCC) to prove rather than disprove the hypothesis that human CO2 was causing runaway global warming,” he wrote to NTZ in an email.  “The political message and funding were directed to only research that proved their hypothesis. Only journals that favored the objective were used and encouraged, so the preponderance of research and publications supported the predetermined message. It is a classic case of Lysenkoism”
Dr. Ball authored the climate science critical book: Human Caused Global warming – The Biggest Deception in History.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterLeading German climate activist/alarmist site Klimaretter (climate rescuers) here has an opinion piece telling readers that there is in fact little difference between Donald Trump and Hillary Clinton when it comes the energy policy. “Eco-green or coal-black? It really isn’t that simple.”
Klimaretter writes that while it may appear Trump wishes to save the American coal industry and Clinton promises to promote “clean energies”,  the two candidates have many more similarities’ than what meets the eye:
In fact there are more common points between the two than what their rhetoric would have us believe. Both Clinton and Trump wish to hold on to the controversial fracking technology for natural gas  and crude oil. The same is true for nuclear power.
Trump has long since added on to his pro-coal course by coming out in favor of ‘all types of energy’. Also solar and wind energy would also play a role under his administration. It’s a balancing act for the billionaire: Of course he wishes to gain the votes from the many unemployed coal workers, however he has in fact understood that renewable energies has become a good economic engine, and in the meantime offers more jobs than the coal industry.
Trump even appears to be worried that there might indeed be something behind climate change: One of his companies wants to build a protective wall around his golf course on the Irish coast. Rising sea level and increasing erosion necessitate it…”
Klimaretter’s opinion could be the case of a climate alarmist trying to see a silver lining in a Trump presidency. Let’s recall that Trump said he would stop payments to the UN climate programs, not sign the climate treaty, and rev up the American economic engines (hence more CO2 emissions).
Clinton would do the opposite.
Hillary Clinton would also very likely shackle the economy with massive environmental regulation and possibly even impose a carbon tax. These are points that Klimaretter would surely welcome.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNew Paper: Modern Sea Levels Rising  
20-30 Times Slower Than The Past


Currently, sea levels are “believed to be” rising at a rate of 1.7-1.8 millimeters/year.

This modern rate  –  just 0.17-0.18 of a meter per century – has remained relatively unchanged from the overall 20th century average, and there has been no statistically significant acceleration in the sea level rise rate (just 0.0042 mm/yr-²) since 1900.
Wenzel and Schröter, 2014     “Global mean sea level change since 1900 is found to be 1.77 ± 0.38 mm year on average. … [T]he acceleration found for the global mean, +0.0042 ± 0.0092 mm year-², is not significant“
In a new paper just published in the journal Climate of the Past, 7 scientists detail the long-term context for the modern rates of sea level rise.  Between 16,500 years ago and 8,200 years ago, the average rate of global sea level rise was 1.2 meters per century (12 mm/yr), which is about 700% faster than the rate achieved during the last 115 years. … Included in that rate average is the “meltwater pulse” epoch around 14,500 years ago, when sea levels rose at rates of 4 meters per century (40 mm/yr).
Cronin et al., 2017     “Rates and patterns of global sea level rise (SLR) following the last glacial maximum (LGM) are known from radiometric ages on coral reefs from Barbados, Tahiti, New Guinea, and the Indian Ocean, as well as sediment records from the Sunda Shelf and elsewhere. … Lambeck et al. (2014) estimate mean global rates during the main deglaciation phase of 16.5 to 8.2 kiloannum (ka) [16,500 to 8,200 years ago] at 12 mm yr−1 [+1.2 meters per century] with more rapid SLR [sea level rise] rates (∼ 40 mm yr−1) [+4 meters per century] during meltwater pulse 1A ∼ 14.5–14.0 ka [14,500 to 14,000 years ago].”
Other scientists recently suggested that hemispheric-scale sea levels rose by 12 to 22 meters in just 340 years 14,500 years ago, which is 3.5 to 6.5 meters per century.  This explosive sea level rise coincided with a Northern Hemisphere-wide warming event of 4 to 5 °C within a span of a few decades, but it did not coincide with a change in CO2 levels.
Ivanovic et al., 2017    “During the Last Glacial Maximum 26–19 thousand years ago (ka), a vast ice sheet stretched over North America (Clark et al., 2009). In subsequent millennia, as climate warmed and this ice sheet decayed, large volumes of meltwater flooded to the oceans (Tarasov and Peltier, 2006; Wickert, 2016). This period, known as the “last deglaciation,” included episodes of abrupt climate change, such as the Bølling warming [~14.7–14.5 ka], when Northern Hemisphere temperatures increased by 4–5°C in just a few decades (Lea et al., 2003; Buizert et al., 2014), coinciding with a 12–22 m sea level rise in less than 340 years [3.5 to 6.5 meters to per century] (Meltwater Pulse 1a (MWP1a)) (Deschamps et al., 2012).”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




J.F. Donoghue (2011) puts the historical magnitude of the “more than 20 times that of today” sea level rise rates into perspective.  Shorelines would have necessarily retreated by as much as 40 meters per year – 75 centimeters per week – during those centuries of obscene sea level rise.
Furthermore, Donoghue specifies that during the last 20,000 years, the overall average sea level rise has been 6 mm/yr, which is more than 3 times the rate of the last century.   In other words, modern rates of sea level rise have significantly decelerated compared to the overall long-term trend.
Donoghue, 2011     “For much of the period since the last glacial maximum (LGM), 20,000 years ago, the region has seen rates of sea level rise far in excess of those experienced during the period represented by long-term tide gauges. The regional tide gauge record reveals that sea level has been rising at about 2 mm/year for the past century, while the average rate of rise since the LGM has been 6 mm/year, with some periods of abrupt rise exceeding 40 mm/year [4 meters per century].”
“Sea level has at times risen at rates more than 20 times that of today, more than 40 mm/year. At such rates, the regional shorelines would have retreated by as much as 40 m/year, or more than 75 cm/week.”
UK geologist Dominic Hodgson and colleagues have determined that sea levels rose at rates of 1.2 to 4.8 meters per century near East Antarctica about 10,000 years ago, when sea levels were 8 meters higher than they are now.
Hodgson et al., 2016     Rapid early Holocene sea-level rise in Prydz Bay, East Antarctica … The field data show rapid increases in rates of relative sea level rise of 12–48 mm/yr between 10,473 (or 9678) and 9411 cal yr BP in the Vestfold Hills and of 8.8 mm/yr between 8882 and 8563 cal yr BP in the Larsemann Hills. … The geological data imply a regional RSL [relative sea level] high stand of c. 8 m [above present levels], which persisted between 9411 cal yr BP and 7564 cal yr BP, and was followed by a period when deglacial sea-level rise was almost exactly cancelled out by local rebound.
And Zecchin et al. (2015) have suggested that “episodic” and “rapid” sea  level rises could reach 6 meters per century (60 mm/yr) for hundreds of years at a time.   That’s about 35 times the current rate.
Zecchin et al., 2015     “The evidence presented here confirms drowned shorelines documented elsewhere at similar water depths and shows that melt-water pulses have punctuated the post-glacial relative sea-level rise with rates up to 60 mm/yr. [6 meters per century] for a few centuries.”
In sum, there has been nothing unusual about the modern rates of sea level rise over the last century.
Actually, sea levels are currently rising at less than a third of the average rate (6 mm/yr) of the last 20,000 years (Donogue, 2011).
The continuance of this long-term deceleration during an era of allegedly significant anthropogenic climate influence strongly suggests that abrupt sea level rise (and fall) occurs independently of the variations in the atmospheric CO2 concentration.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s online it.times.de here writes that wind turbine manufacturer Nordex has seen sales begin to drop off for the first time, signaling that the country’s days of growth in the wind industry are likely over: “Growth phase of wind turbine producers are over?”
After years of steady growth at Nordex, sales over the first quarter of 2017 have fallen compared to a year earlier, the site reports. Market analysts expect takeovers to occur as the industry consolidates under the harsher market conditions.
it.times.de writes: 
Also on the results side things are not running so well for Nordex S.E.. Both the operative Cash-Flow and the Free Cash-Flow have not been able to keep up with the sales growth of the company.”
Nordex S.E. OCF margins have been falling for two years, and are now well under 5%.
Milk for 50 dollars a gallon!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Meanwhile subsidies for wind and solar energy have increasingly come under fire with one wind protest group director, who recently blasted their extravagance.
According to the kreisbote.de here, Reinhold Faulhaber, Chairman of nature protection group Initiative Landschaftsschutz Kempter Wald and Allgäu e.V. (ILKA), demanded an end to the crazy subsidies for wind turbines at a membership meeting, saying that they do not lead to any CO2 savings, damage nature and that they are horrifically expensive:
If the milk business were subsidized like wind turbines are by the EEG feed-in act, our farmers would be getting 11.30 euros for every liter!“
That translates to near 50 US dollars a gallon – for the farmer! Imagine the retail price.
This illustrates just how out of whack the whole renewable energy movement has become. Economic sense has long been thrown overboard.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHalf The Planet Has Not Cooperated
With The ‘Global’ Warming Narrative

According to overseers of the long-term instrumental temperature data, the Southern Hemisphere record is “mostly made up”.  This is due to an extremely limited number of available measurements both historically and even presently from the south pole to the equatorial regions.
Below is an actual e-mail conversation between the Climate Research Unit’s Phil Jones and climate scientist Tom Wigley.  Phil Jones is the one who is largely responsible for making up the 1850-present temperature data for the Met Office in the UK (HadCRUT).



According to Peterson and Vose (1997), in 1901 the representation of maximum/minimum instrumental temperature stations in the Southern Hemisphere (SH) up through the equatorial regions (South Asia, North Africa, Central America) was negligible.  Only coastal Australia had substantial instrumental representation in the early 20th century.   The rest of the temperature data for the SH and equatorial regions needed to be made up to extend “global” instrumental temperature data back to 1850.

 

To measure the historical temperature record for the bottom half of the planet, then, scientists use proxy evidence from such sources as ice cores or alkenones to reconstruct past climates.  When they do that, a common theme emerges.  The proxy evidence used in temperature reconstructions suggests that there has been no significant changes in temperature from Antarctica to the regions near or just above the equator in the last few centuries.  In other words, half the globe has not been following along with the anthropogenic “global” warming narrative.
Listed below are about 75 graphical reconstructions indicating no obvious warming trend during the last few hundred years of assumed anthropogenic influence on surface temperatures.

Delong et al., 2012


Ault et al., 2013
 


Wei et al., 2015


Rosenthal et al., 2017




Rosenthal et al., 2013
“We show that water masses linked to North Pacific and Antarctic intermediate waters were warmer by 2.1°C and 1.5°C, respectively, during the middle Holocene Thermal Maximum than over the past century. Both water masses were ~0.9°C warmer during the Medieval Warm period than during the Little Ice Age and ~0.65° warmer than in recent decades.”


Jalali et al., 2016


Cheung, 2017




Fischel et al., 2017


Shevenell et al., 2011


Bird et al., 2017


Zhang et al., 2017


Dechnik et al., 2017


Kolansky et al., 2015


Dodrill et al., 2017


South America

Elbert et al., 2013



de Jong et al., 2013


von Gunten et al., 2009


De Jong et al., 2016
“[T]he reconstruction…shows that recent warming (until AD 2009) is not exceptional in the context of the past century. For example, the periods around AD 1940 and from AD 1950–1955 were warmer. … [B]ased on tree ring analyses from the upper tree limit in northern Patagonia, Villalba et al. (2003) found that the period just before AD 1950 was substantially warmer than more recent decades.”


Bertrand et al., 2014


Neukom et al., 2011


Silveira and Pezzi, 2014




Caniupán et al., 2014


Rebolledo et al., 2015


Sepúlveda et al., 2009 


Shevenell et al., 2011


Goni et al., 2004


Kilian and Lamy, 2012


Massaferro and Larocque-Tobler, 2013


South Africa

Tyson et al., 2000
“The climate of the interior of South Africa was around 1°C cooler in Little Ice Age [AD 1300 to 1800] and may have been over 3°C higher than at present during the extremes of the medieval warm period [AD 1000 to 1300].”
“It was variable throughout the millennium, but considerably more so during the warming of the eleventh to thirteenth centuries.  The lowest temperature events recorded during the Little Ice Age in South Africa are coeval with the Maunder and Sporer Minima in solar irradiance.  The medieval warming is shown to have coincided with … the Medieval Maximum in solar radiation.”


Sánchez-Sesma, 2015


Zinke et al., 2014






<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Dupont et al., 2004


Weldeab et al, 2005


Powers et al., 2005


Australia, New Zealand

Parker and Ollier, 2017
“In the centre of Australia, all the stations available in a circle of radius 1,000 km were showing very little or no warming, as still acknowledged in the GHCN v2 data set up to October 2011 (Fig. 6). … Table 1 presents the warming trend for the 30 longest temperature records of Australia collected in a single location, with measurements started before 1900 and continued until after 1985.  … In the 30 locations, the monthly mean maximum temperature is warming 0.0004°C/year, or 0.04°C/century. “




O’Donnell et al., 2016


Tyson et al., 2000


de Frietas et al., 2015
 


Cook et al., 2002


Cook et al., 2006


Saunders et al., 2013




Jara et al., 2017


South Asia

Sunkara and Tiwari, 2016


Yan et al., 2015


Fan et al., 2009 


Munz et al., 2015


Zinke et al., 2016


Thapa et al., 2015
“[T]emperature in Central Asia and northern Hemisphere revert back towards cooling trends in the late twentieth century.”




Böll et al., 2014


Loomis et al., 2015


Southern Ocean

Turney et al., 2017
“Occupying about 14% of the world’s surface, the Southern Ocean plays a fundamental role in ocean and atmosphere circulation, carbon cycling and Antarctic ice-sheet dynamics. … As a result of anomalies in the overlying wind, the surrounding waters are strongly influenced by variations in northward Ekman transport of cold fresh subantarctic surface water and anomalous fluxes of sensible and latent heat at the atmosphere–ocean interface. This has produced a cooling trend since 1979.”



Jones et al., 2016




Markle et al., 2017


Bostock et al., 2013


Foster et al., 2016


Antarctica

Stenni et al., 2017


Schneider et al., 2006


Miles et al., 2013


Doran et al., 2002
“[O]ur spatial analysis of Antarctic meteorological data demonstrates a net cooling on the Antarctic continent between 1966 and 2000, particularly during summer and autumn.”


Mayewski et al., 2017


Turner et al., 2016


Fudge et al., 2016




Masson-Delmotte et al., 2004


Kilian and Lamy, 2012


Mulvaney et al., 2012
“A marine sediment record from off the shore of the western Antarctic Peninsula also shows an early Holocene optimum during which surface ocean temperatures were determined to be 3.5°C higher than present. Other evidence suggests that the George VI ice shelf on the southwestern Antarctic Peninsula was absent during this early-Holocene warm interval but reformed in the mid Holocene.”


Chu et al., 2017


Albot, 2017

Share this...FacebookTwitter "
"
Share this...FacebookTwitterHere’s more from Schneefan at his climate and weather site wobleibtdieerderwaermung.de here where he reports on mischief by Germany’s DWD national weather service.
The now climate-activist DWD has developed a habit over the past years of issuing warmed up “preliminary” monthly summary reports to describe the month’s weather.
Usually these reports get issued 2 or 3 days before the end of the month, and so Germany’s mean temperature for the month is an estimated value, and later gets revised after the final data come in. So what better opportunity for activists to fudge the preliminary figures on the warm side, and feed the press with them? Later of course the temperature results get quietly revised downward.
One especially egregious example is the DWD’s press release for the preliminary summary of the April 2017 weather. In it they write (emphasis added):

The high pressure conditions of March continued at the start of April, with nearly all areas of Germany enjoying very warm and dry weather. Then, moister and increasingly cold air from the north arrived for the second third of the month. The middle of the month and Easter brought slight to moderate frost and, in some cases, snow even in lowland areas. Overall, temperatures and sunshine duration in the middle of the month were within the normal range.”

In the press release the last 10 days of April, which were bitterly cold, get left out. Schneefan writes that the last ten days of April “were totally left out and they reported on the first 20 days, even though only the last three days of data were missing“.
The media of course act accordingly, and report of warm, balmy conditions. This is how communication of science gets (intentionally?) distorted by sloppy, irresponsible and warming-obsessed officials.
In the DWD press release you have to read down a ways to find out that the mean temperature for April, 2017, in Germany reportedly ended up being 0.8°C below the 1981-2010 mean value, making it the coldest in 16 years.
And lo and behold, later that figure was indeed revised downward: Schneefan writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




By the way: April 2017 in Germany in contradiction to the – as always hasty and mostly false –  DWD press release of April 28, 2017 a mean temperature of only 7.4°C instead of the given 7.5°C.”
Europe springtime ice box
Not only Germany was icy, but many other countries in Europe as well. The following chart shows the temperature anomalies for the 2nd half of April (mostly ignored by the DWD’s April 28 preliminary report).

Schneefan also reminds that January 2017 in Germany was among the coldest in 20 years, coming in 2.7°C below the 1981-2010 mean.
Also October and November 2016 came is colder than the mean, recording an anomaly of -0.7° and -0.6°C respectively, according to the data from the DWD.
Overall spring has not been arriving earlier in Germany and Central Europe, as many like to have us believe. March mean data has been trending slightly downward in Germany over the past 30 years:

Germany’s comprehensive 2000 stations scattered across the country have been showing no warming over the past decades.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAt his Environmental Progress site here, Michael Shellenberger writes that Stanford University Professor Mark Z. Jacobson is suing a “prestigious team of scientists for Debunking 100% renewables.
This reminds us of the 17 or so attorneys general who sought to use the US Racketeering Influenced and Corrupt Organizations Act (RICO) in order to go after and silence climate science skeptics, accusing them of perpetuating fraud by daring to question the flakey science underpinning the manmade global warming theory.
Shellenberger wrote that professor Mark Z. Jacobson had “filed a lawsuit, demanding $10 million in damages, against the peer-reviewed scientific journal Proceedings of the National Academy of Sciences (PNAS) and a group of eminent scientists (Clack et al.) for their study showing that Jacobson made improper assumptions in order to claim that he had demonstrated U.S. energy could be provided exclusively by renewable energy, primarily wind, water, and solar.”



Cropped from Jacobson’s complaint. Source Environmental Progress.  


“Speechless”…climate-energy debate needs to get “a direction of sanity”
Climatologist Prof. Judith Curry at her Climate Etc site wrote that she was “speechless”, adding:
In many ways, this is much worse than any of Michael Mann’s lawsuits alleging defamation of character [link] — Jacobson’s lawsuit seeks to settle a genuine scientific disagreement in the courts.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




However, Prof. Curry does not see “a good ending” for Jacobson: “There will undoubtedly be a countersuit and he stands to lose a lot of money (not just his lawsuit)”.
Many observers feel this is just the latest attempt to shut down free speech within the realm of science — a highly worrisome development that reminds us of brutal totalitarian regimes.
Curry notes: “Possibly, there will be sufficient backlash against this that will steer the overall climate-energy debate back towards a direction of sanity.”
This can only be hoped for.
Blogger Shellenberger calls the move by Jacobson “unprecedented”, adding:
Scientific disagreements must be decided not in court but rather through the scientific process. We urge Stanford University, Stanford Alumni, and everyone who loves science and free speech to denounce this lawsuit.”
This of course would be expected from almost any higher education institution in any other free-speech-abiding, democratic state. But with flakey, culturally neurotic California, nothing can be ruled out.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterEmissions trading was set up to entice fossil fuel intense companies to reduce their CO2 emissions, and thus in this way help bring atmospheric CO2 concentrations to a standstill, and thus rescue the climate, according to the man-made global warming theory.

New report by Carbon Market Watch shows large corporations raking in billions in CO2 emissions trading scheme.
However, things aren’t quite working out that way. Spiegel here cites a comprehensive report by the non-government organization Carbon Market Watch (CMW), which concludes that large companies are in fact making billions from free emissions certificates, and CO2 emissions aren’t improving at all.
The European large industry have managed to squeeze out 25 billion over the past years through special rights in the EU emissions trading system.”
The study looked at the 20 strongest countries from 2008 to 2015, Spiegel writes.
Easy money
Agnes Brandt of the CMW comments:
The figures show how easy it is to make money from pollution and just much the lobby-watered-down CO2 trading system has failed.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Little wonder that so money companies happily adopted the climate protection and CO2 scam. Many have gotten rich from it without having to produce anything tangible for society to benefit from.
And who pays for the 25 billion? Billy Bob Blow and Jane Blow, of course.
Little wonder voters are voting to “blow up the whole goddamn system” with a “human Molotov cocktail“. And why not, after all? It. Is. Corrupt.
Growing resentment
In Europe too there is an intensifying aura out there that is telling us that more politicians are about to get the message, loud and clear –and big time. The energy system in much of Europe has gotten dearly expensive, unstable and now poses a real and gathering threat to the jobs and livelihoods of millions in the working class. The citizenry has been deceived and screwed over by a climate science scam, and they are not going to take it much longer.
Already tens of thousands of highly skilled, well-paid workers in the automotive and energy industries in Germany alone are seeing their jobs get slashed. And they do have a means of delivering the second biggest FU in history – with a vote for Le Pen in France, or for the emerging hard right wing parties in Germany, Austria and elsewhere.
The biggest earners from the scam, according to the report and Spiegel, are the steel and iron industry, cement, refineries and petrochemicals – to name a few. They are closing down and moving out their operations, and getting paid to do so.
And the working class? They’re getting angry, yet being scolded for doing so — being cast out as “deplorables” or irredeemables”, or even far worse. This can’t and won’t continue.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterLittle Ice Age as a suitable reference point for the warming of the last 150 years?  The case of Mont Blanc
By Uli Weber
(Translated/edited by P Gosselin)
On October 29 television station ARTE broadcast the documentary “Laboratory Mont Blanc“ (94 Min.). It’s available at Arte.tv until November 6, 2016.  The description at ARTE:
On a 6-day expedition three scientists climbed the Mont Blanc, which is considered the heart of the European Alps. At approximately 4810 meters tall the ‘white giant’ is a natural wonder of nature. Climbing the large mountain is a unique experience and is considered as a look at the past 240 million years of evolution…”
Of course the problem in the documentary all gets back to man-made climate change. Yet between the 37 minute and 45 minute marks, we found some rational documentation: The Mont Blanc glacier had retreated just as much during the Medieval times as much it has today. Back then a small town near what today is Chamonix (Le Chatelard?) was covered in 1643 by the Mer de Glace (sea of ice) glacier and destroyed. In 1860 – the end of the Little Ice Age – the Mer de Glace reached its greatest extent, which is documented by photos and other means.
Since then the Mer de Glace has been in retreat, as the following satellite photo from Google-Maps clearly shows:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




 
Also other sources report of glacier advance during the Little Ice Age, e.g. the Blog History of Geology on October 8, 2016:
… In the year 1644 in the Mont Blanc region, a procession to the glacier was organized at the village Les Bois because supposedly it had advanced to only 120 meters away from the village and it was threatening. The bishop of Geneva blessed the Les-Bois-glacier personally…“
Wikipedia on the Mer de Glace, quote:
„… Earlier the glacier flowed over a steep part and into the valley of Chamonix, and right up to the settlement Les Bois. This part of the glacier was named the Glacier des Bois and used to be an attraction of old Chamonix. At the elevation of Montenvers the glacier used to be 130 meters thicker than today. Crossing the right bank was free of trouble. People even drove the herds of sheep over it…“
It is most astonishing that the mean temperature at the end of the Little Ice Age (usually 1850, but in the ARTE documentary 1860) gets misused as the “natural” yardstick for measuring our current warming, and thus used as proof of a “man-made” global warming – even though that it is clearly shown by the ARTE documentary and without a doubt as simply part of the ongoing natural cycle since the Medieval time.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s Energiewende threatens to follow a similar path as the Berlin-Brandenburg airport debacle, but on a far greater scale. When bureaucrats take over project engineering...
Berlin-Brandenburg BER airport: Construction began in 2006 with operation scheduled to begin in 2011. And now as 2017 nears the end, BER is not even close to opening. Currently it is well over 2000 days behind schedule. Massive technical deficiencies with the airport’s safety systems plague the entire project, and now it is questionable whether the airport will even open in 2021.
Bureaucrat run airport-project turns into national embarrassment
BER’s original estimated price tage was 2.5 billion euros, but since then the costs have ballooned to 6.6 billion euros today. Worse: billions more are expected, nobody knows when the project will be completed, and there’s even talk the project might be abandoned altogether! It is undoubtedly the country’s greatest construction and engineering debacle so far this century. The joke today: It would be cheaper to move the entire city of Berlin to another airport then to sort through the catastrophe that is the BER airport.
What happened? Ideological bureaucrats took over project engineering
At the early design and construction stages, the project was run by Berlin’s socialist-green bureaucrats – who thought they could handle it better than real builders. These bureaucrats unfortunately failed to adequately involve the necessary technical and engineering experts during the crucial early stages and the result was a plan that was so flawed that today it looks more like an animal begging to be put out of its misery.
Naturally their airport concept and plans sailed through the approval process and construction started in earnest. But before long it was discovered that the BER design was fraught with technical and safety deficiencies, and it’s opening has been pushed back every year since 2011. The truth is that no one knows how to resolve the huge flaws.
BER is a classic case of what can happen if the right people are not running the job and ideology takes over.
Energiewende: a potential folly 200 times greater than BER
As hard as it may be to believe, a similar German-made engineering catastrophe but of far greater dimensions looms: the revamping of the country’s electricity supply infrastructure so that it is “green” – the so-called “Energiewende“. Like BER, the Energiewende too was managed by bureaucrats, who in the wake of the Fukushima disaster ordered Germany’s top power generation experts at the country’s leading power companies to stand back and keep silent as the country fast-tracked from nuclear and fossil fuel power over to clean, green energies.
Merkel government decides to run the power industry
The rush decision was made by Angela Merkel and her CDU/CSU party. Power engineering experts were not invited on the board commissioned to launch it and thus they had no input or say on the matter. The politicians were warned of the risks of flooding the existing grid with unstable energy, but they obstinately brushed the warnings aside and went full throttle into the Energiewende. They believed they knew better.
Today, some 6 years later, the Energiewende is looking a lot like the BER debacle: an engineering embarrassment and looming catastrophe. The major grid infrastructure revamping is still decades off and the power grid already frequent teeters on the brink of collapse. While BER is the airport without adequate fire and safety systems, Germany’s Energiewende is the nation’s power supply without a proper grid. In both cases the costs are spiraling out of control and no one knows if it’s ever going to work at all. It is wild experimentation, and not engineering.
172,000 outages last year
To illustrate how far along the road to disaster Germany’s once impeccably stable grid has come, the online hessenschau.de here reports that for the second time in a just few days the central city of Wiesbaden has seen its power black out. It writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On Saturday evening in parts of Wiesbaden the power went out for 2 hours. […]. It is the second power outage within just a few days.”
Over the past years the German state of Hesse has been plagued by power outages, Hessen public television (HR) reported here, as it pondered why Hesse has become so prone to blackouts. HR cites the Bundesnetzagentur (Federal Grid Agency), which says there are over 172,000 power outages annually, which is some 470 daily, and that last winter multiple power plants had to be switched simultaneously because “the German grid was on the brink of collapse.”
Volatile wind and sun
Prof. Peter Birkner blames the volatile supply of green energies: “The wind does not ask what we want, what we consume, and just blows as it wills” and that “the power grid is not designed for it“.
While the BER debacle has cost over 6 billion euros so far, the Energiewende has already committed close to 200 times that amount of money: over 1 trillion euros!
According to Frankfurt’s Fire Department spokesman Andreas Mohn, the city’s 27 mobile power generators would not be able to handle a power outage and citizens would have to “fend for themselves“:
That starts with a few candles, food, water and maybe a possibility of something for heating, a gas cooker or something.”
Government information pamphlet on what to do in the event of a blackout
Little wonder that in 2015 the BBK – Germany’s version of FEMA – released a pamphlet advising citizens on how to proceed in the event of power outages.
State media has “diesel generators” on stand-by
Even German HR public television has taken precautions against power outages and has “large diesel generators on hand in the event of a blackout” which would switch on within 14 seconds.
According to Hesse HR public broadcasting:

Short periods of time would be bridged over by thousands of batteries. Then diesel would take over. With over 40,000 liters in the tank, HR would be able to broadcast completely on its own for up to two weeks”.

It’s nice to hear that public funded German broadcasting would keep warm and running in a blackout. The citizens, on the other hand, would be left out in the cold. This is the utopia that green bureaucrats are bringing to Germany.
Other countries should think twice before heading down this path of folly.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
CO2 Concentration Changes 
Do Not Drive Sea Levels

From about 7000 years ago to 2000 years ago, or from the Mid- to Late-Holocene, atmospheric CO2 concentrations varied between only about 260 and 270 parts per million, or ppm.  Such low CO2 concentrations are believed to be “safe” for the planet, as they are significantly lower than today’s levels, which have eclipsed 400 ppm in recent years.  These high CO2 concentrations are believed to cause dangerous warming, rapid glacier melt, and catastrophic sea level rise.
And yet, despite the surge in anthropogenic CO2 emissions and atmospheric CO2 since the 20th century began, the UN’s Intergovernmental Panel on Climate Change (IPCC) has concluded that global sea levels only rose by 1.7 mm/yr during the entire 1901-2010 period, which is a rate of less than 7 inches (17 cm) per century.   A new paper even suggests the global trend is better represented as closer to 1.3 mm/yr, or about 5 inches per century:
McAneney et al., 2017     “Global averaged sea-level rise is estimated at about 1.7 ± 0.2 mm year−1 (Rhein et al. 2013), however, this global average rise ignores any local land movements. Church et al. (2006) and J. A. Church (2016; personal communication) suggest a long-term average rate of relative (ocean relative to land) sea-level rise of ∼1.3 mm year.”
According to Wenzel and Schröter (2014), the acceleration rate for the sea level rise trend since 1900 has been just +0.0042 mm/yr, which is acknowledged by the authors to be “not significant” and well within the range of uncertainty (+ or – 0.0092 mm/yr) to put the overall 20th/21st century sea level rise acceleration rate at zero.
Further complicating the paradigm that contends changes in CO2 concentrations drive sea levels is the fact that ice core evidence affirms CO2 levels remained remarkably constant (fluctuating around 255 to 260 ppm) during the same period that there was an explosively fast rate of sea level rise — between 1 and 2 meters per century (about 10 times today’s rates) — between 12,000 to 8,000 years ago.    Sea levels rose by ~60 meters during those 4,000 years while CO2 levels effectively remained constant.
And casting even more doubt on the assertion that variations in CO2 drive sea level rise is the fact that there is robust paleoclimate evidence to suggest that today’s mean sea levels as well as today’s sea level rise rates are both relatively low (from a historical standpoint) and also well within the range of natural variability.  Nothing unusual is happening to sea levels today.  For even though we have evidence that modern CO2 concentrations (~405 ppm) are historically high relative to the last 10,000 years, we also possess a growing body of evidence that modern sea levels are still about 1 to 2 meters lower than they have been for most of the last 7,000 years.
The fundamental problem for the CO2-rise-causes-sea-level-rise paradigm, then, is that rising CO2 concentrations have not been correlated with rising sea levels for nearly all of the last 12,000 years.  In fact, the opposite has been observed during the last 2,000 years, or during the Late Holocene: CO2 levels have risen (gradually, then rapidly) while sea levels have fallen overall, with recent changes so modest (inches per century) that they do not override the overall trend.   In the 8,000 years before that, sea levels rose rapidly while CO2 concentrations remained flat.  Simply put, the supposed anthropogenic “signal” in sea level rise trends has largely gone undetected — a point that has been affirmed by more and more scientists.
Listed below are a collection of 35 scientific papers published since 2014 that indicate sea levels were, on average, about 1 to 2 meters higher than they are now throughout the Mid-Holocene (7,000-2,000 years ago) and even into the last millennium, with lower-than-now sea levels largely confined to the Little Ice Age period (~1300 to 1900 AD).  Links to the papers are embedded in the authors’ names and the regional locations for mean sea level are notated.

Dechnik et al., 2017 (Tropical Western Pacific)
[I]t is generally accepted that relative sea level reached a maximum of 1–1.5 m above present mean sea level (pmsl) by ~7 ka [7,000 years ago] (Lewis et al., 2013)

Zondervan, 2016    (Great Barrier Reef, Australia)
Preserved fossil coral heads as indicators of Holocene high sea level on One Tree Island [GBR, Australia] … Complete in-situ fossil coral heads have been found on beach rock of One Tree Island, a small cay in the Capricorn Group on the Great Barrier Reef. Measurements against the present low-tide mark provide a [Holocene] high stand of at least +2.85 m [above present sea levels], which can be determined in great accuracy compared to other common paleo sea-level record types like mangrove facies. The sea level recorded here is higher than most recent findings, but supports predictions by isostatic adjustment models. … Although the late Holocene high stand has been debated in the past (e.g. Belperio 1979, Thom et al. 1968), more evidence now supports a sea level high stand of at least + 1- 2 m relative to present sea levels (Baker & Haworth 1997, 2000, Collins et al. 2006, Larcombe et al. 1995, Lewis et al. 2008, Sloss et al. 2007).

Prieto et al., 2016  (Argentina, Uruguay)
Analysis of the RSL [relative sea level] database revealed that the RSL [relative sea level] rose to reach the present level at or before c. 7000 cal yr BP, with the peak of the sea-level highstand c. +4 m [above present] between c. 6000 and 5500 cal yr BP [calendar years before present] … This RSL [relative sea level] curve was re-plotted by Gyllencreutz et al. (2010) using the same index points and qualitative approach but using the calibrated ages. It shows rising sea-levels following the Last Glacial Termination (LGT), reaching a RSL [relative sea level] maximum of +6.5 m above present at c. 6500 cal yr BP [calendar years before present], followed by a stepped regressive trend towards the present.


Hodgson et al., 2016  (East Antarctica)
Rapid early Holocene sea-level rise in Prydz Bay, East Antarctica … The field data show rapid increases in rates of relative sea level rise of 12–48 mm/yr [1.2 to 4.8 meters per century] between 10,473 (or 9678) and 9411 cal yr BP in the Vestfold Hills and of 8.8 mm/yr between 8882 and 8563 cal yr BP in the Larsemann Hills. … The geological data imply a regional RSL [relative sea level] high stand of c. 8 m [above present levels], which persisted between 9411 cal yr BP and 7564 cal yr BP [calendar years before present], and was followed by a period when deglacial sea-level rise was almost exactly cancelled out by local rebound.


Dura et al., 2016  (Vancouver)
In northern and western Sumatra, GIA models predict high rates (>5 mm/year) of RSL [relative sea level] rise from ∼12 to ∼7 ka [12000 to 7000 years ago], followed by slowing rates of rise (<1 mm/year) to an RSL [relative sea level] highstand of <1 m (northern Sumatra) and ∼3 m (western Sumatra) between 6 and 3 ka [6,000-3,000 years ago], and then gradual (<1 mm/ year) RSL fall until present.


Spotorno-Oliveira et al., 2016  (Brazil)
At ~7000 cal. years BP the sea level in the bay was approximately 4 m below the present sea level and the upper subtidal benthic community was characterised by fruticose corallines on coarse soft substrate, composed mainly of quartz grains from continental runoff input. The transgressing sea rapidly rose until reaching the ~ +4 m highstand [above present] level around 5000 years BP.

Lee et al., 2016  (Southeast Australia)
The configuration suggests surface inundation of the upper sediments by marine water during the mid-Holocene (c. 2–8 kyr BP), when sea level was 1–2 m above today’s level.


Yokoyama et al., 2016  (Japan)
The Holocene-high-stand (HHS) inferred from oyster fossils (Saccostrea echinata and Saccostrea malaboensis) is 2.7 m [above present sea level] at ca. 3500 years ago, after which sea level gradually fell to present level.

May et al., 2016  (Western Australia)
Beach ridge evolution over a millennial time scale is also indicated by the landward rise of the sequence possibly corresponding to the mid-Holocene sea-level highstand of WA [Western Australia] of at least 1-2 m above present mean sea level.

Mann et al., 2016  (Indonesia)
Radiometrically calibrated ages from emergent fossil microatolls on Pulau Panambungan indicate a relative sea-level highstand not exceeding 0.5 m above present at ca. 5600 cal. yr BP [calendar years before present].

Clement et al., 2016   (New Zealand)
In North Island locations the early-Holocene sea-level highstand was quite pronounced, with RSL [relative sea level] up to 2.75 m higher than present. In the South Island the onset of highstand conditions was later, with the first attainment of PMSL being between 7000–6400 cal yr BP. In the mid-Holocene the northern North Island experienced the largest sea-level highstand, with RSL up to 3.00 m higher than present.


Long et al., 2016  (Scotland)
RSL [relative sea level] data from Loch Eriboll and the Wick River Valley show that RSL [relative sea level] was <1 m above present for several thousand years during the mid and late Holocene before it fell to present.

Chiba et al., 2016  (Japan)
Highlights: We reconstruct Holocene paleoenvironmental changes and sea levels by diatom analysis.  Average rates of sea-level rise and fall are estimated during the Holocene.  Relative sea level during Holocene highstand reached 1.9 m [higher than today] during 6400–6500 cal yr BP [calendar years before present].  The timing of this sea-level rise is at least 1000 years earlier in the Lake Inba area by Holocene uplift than previous studies.  The decline of sea-level after 4000 cal yr BP may correspond to the end of melting of the Antarctic ice sheet.

Leonard et al., 2016  (Great Barrier Reef, Australia)
Holocene sea level instability in the southern Great Barrier Reef, Australia … Three emergent subfossil reef flats from the inshore Keppel Islands, Great Barrier Reef (GBR), Australia, were used to reconstruct relative sea level (RSL). Forty-two high-precision uranium–thorium (U–Th) dates obtained from coral microatolls and coral colonies (2σ age errors from ±8 to 37 yr) in conjunction with elevation surveys provide evidence in support of a nonlinear RSL regression throughout the Holocene. RSL [relative sea level] was at least 0.75 m above present from ~6500 to 5500 yr before present (yr BP; where “present” is 1950). Following this highstand, two sites indicated a coeval lowering of RSL of at least 0.4 m from 5500 to 5300 yr BP which was maintained for ~200 yr. After the lowstand, RSL returned to higher levels before a 2000-yr hiatus in reef flat corals after 4600 yr BP at all three sites. A second possible RSL lowering event of ~0.3 m from ~2800 to 1600 yr BP was detected before RSL stabilised ~0.2 m above present levels by 900 yr BP. While the mechanism of the RSL instability is still uncertain, the alignment with previously reported RSL oscillations, rapid global climate changes and mid-Holocene reef “turn-off” on the GBR are discussed.


Sander et al., 2016  (Denmark)
The data show a period of RSL [relative sea level] highstand at c. 2.2 m above present MSL [mean sea level] between c. 5.0 and 4.0 ka BP [5,000 to 4,000 years before present].  After that, RSL drops by c. 1.3 m between c. 4.0 and 3.4 ka BP to an elevation roughly 1 m above present MSL. Since then, RSL has been falling at more or less even rates. … Yu et al. (2007) present evidence for a sea-level ‘jump’ of several meters occurring at 7.6 ka bp [7600 years before present] in SE Sweden, and data suggesting RSL changes with a similar timing and magnitude were obtained for a field site in the southern Gulf of Finland (Rosentau et al., 2013). The suddenness of the RSL change has been attributed to the collapse of parts of the Laurentide Ice Sheet (Blanchon and Shaw, 1995; Carlson et al., 2007), though the global indications and the potential triggers of such a eustatic event remain inconclusive (Törnqvist and Hijma, 2012).

Bradley et al., 2016  (China)
In general, the data indicate a marked slowdown between 7 and 8 kyr BP, with sea level rising steadily to form a highstand of ~2-4 m [above present sea level] between 6 and 4 kyr BP [6000 and 4000 years before present]. This is followed by a steady fall, reaching present day levels by ~1 kyr BP.


Accordi and Carbone, 2016  (Africa)
Then, the skeletal carbonate storage on the shelf reached its maximum 5 to 4 ka BP [5000 to 4000 years before present] (Ramsay, 1995) during a highstand about 3.5 m above the present sea level, when shallow marine accommodation space was greater than at present. … A detailed sea level curve of the last 9 ka BP is reported for the Southern African coastline by Ramsay (1995), who indicates a sea level similar to that of the present (at about 6.5 ka). Ramsay also indicates successive, frequent oscillations below and above the present sea level, between a maximum of +3.5 and a minimum of -2 m. Sea level positive pulses since 7 ka BP are also documented in Siesser (1974), Jaritz et al. (1977) and Norstrom et al. (2012) for the Mozambique coast. Along the Kenyan coast, a sea level stand above the present one during the mid-Holocene is documented in many places along the coast by various authors (Hori, 1970; Toyah et al., 1973; Åse, 1981, 1987; Oosterom, 1988), where the sea level might have reached +6 m above the Kenyan Datum between 2 and 3 ka BP [2000 and 3000 years before present].


Hansen et al., 2016  (Denmark)
Continuous record of Holocene sea-level changes … (4900 years BP to present). … The curve reveals eight centennial sea-level oscillations of 0.5-1.1 m superimposed on the general trend of the RSL [relative sea level] curve [relative sea levels ~1.5 m higher than present from 1400 to 1000 years ago].




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Macreadie et al., 2015  (Austalia, Eastern)
[R]esults from other studies … suggest that high-stand, at perhaps 2 m above present msl [mean sea level] was achieved as early as 7000 radiocarbon years BP [before present] (7800 cal. years BP) and that sea-level has exceeded the present value for much of the mid- to late-Holocene [~7000 to ~1000 years ago].

Lewis et al., 2015  (Australia, Northeastern)
Thick (> 10 cm) fossil oyster visors above the equivalent modern growth suggest higher relative sea-levels in the past (i.e. > 1200 cal. yr BP [prior to 1,200 years before present]). … [D]ata show a Holocene sea-level highstand of 1–2 m higher than present which extended from ca. 7500 to 2000 yr ago (Woodroffe, 2003; Sloss et al., 2007; Lewis et al., 2013). The hydro-isostatic adjustment is thought to account for these 1–2 m sea-level changes [falling] to present levels over the past 2000 yr (Lambeck and Nakada, 1990; Lambeck, 2002). … [R]eliable SLI data such as coral pavements and tubeworms from Western Australia suggest that relative sea-level was 0.86 m and 0.80 m above present at 1060 ± 10 and 1110 ± 170 cal. yr BP [~1100 calendar years before present], respectively (Baker et al., 2005; Collins et al., 2006).

Lokier et al., 2015  (Persian Gulf)
Late Quaternary reflooding of the Persian Gulf climaxed with the mid-Holocene highstand previously variously dated between 6 and 3.4 ka. Examination of the stratigraphic and paleoenvironmental context of a mid-Holocene whale beaching allows us to accurately constrain the timing of the transgressive, highstand and regressive phases of the mid- to late Holocene sea-level highstand in the Persian Gulf.  Mid-Holocene transgression of the Gulf surpassed today’s sea level by 7100–6890 cal yr BP, attaining a highstand of > 1 m above current sea level shortly after 5290–4570 cal yr BP before falling back to current levels by 1440–1170 cal yr BP.  These new ages refine previously reported timings for the mid- to late Holocene sea-level highstand published for other regions. By so doing, they allow us to constrain the timing of this correlatable global eustatic event more accurately.


Harris et al., 2015   (Great Barrier Reef, Australia)
This hiatus in sediment infill coincides with a sea-level fall of ∼1–1.3 m during the late Holocene (ca. 2000 cal. yr B.P.), which would have caused the turn-off of highly productive live coral growth on the reef flats currently dominated by less productive rubble and algal flats, resulting in a reduced sediment input to back-reef environments and the cessation in sand apron accretion. Given that relative sea-level variations of ∼1 m were common throughout the Holocene, we suggest that this mode of sand apron development and carbonate production is applicable to most reef systems.
Microatoll death was most likely caused by a fall in sea level that stranded the microatolls on the reef flat due to their location in open-water unmoated environments. This suggests that paleo–sea level between 3900 and 2200 cal. yr B.P. was 1–1.3 m higher than present (based on an offset from MLWS tidal level to fossil microatoll elevation; Fig. 2). This paleo–sealevel elevation is similar to the ranges of 1–1.5 m suggested by Lewis et al. (2013) and Sloss et al. (2007) and data from Moreton Bay in southern Queensland of an elevation of 1.3 m (Leonard et al., 2013).


Hein et al., 2015  (Brazil)
In southern Brazil, falling RSL [relative sea level] following a 2–4 m [above present sea level] highstand at 5 to 6 ka [5,000 to 6,000 years ago] forced coastal progradation. … Relative SL [sea level] along the southern Brazil coast reached a highstand elevation of 1–4 m above MSL [mean sea leve] at ca. 5.8 ka [5800 years ago].

Barnett et al., 2015  (Arctic Norway)
Relative sea-level fell at −0.7 to −0.9 mm yr−1 over the past 3300 years in NW Norway. … Prior to 3000 cal yr BP the marine limiting date represents an important constraint for the late Holocene sea-level trend and yields a minimum RSL [relative sea level] decline of approximately 2.2 m over 3200 years when assuming a linear trend. The maximum possible linear decline constrained by the data is approximately 2.6 m in 2800 years, providing an estimated late Holocene sea-level trend of 0.7 to 0.9 mm yr (shown by the grey shaded region in Fig. 8A).  [Relative sea level was 2.2 to 2.8 m higher ~3,000 years ago in Arctic Norway]


Engel et al., 2015  (Western Australia)
The foredunes overlie upper beach deposits located up to >2 m above the present upper beach level and provide evidence for a higher mid-Holocene RSL [relative sea level]. …  [O]bservations made near Broome by Lessa and Masselink (2006) [indicate] the deposition of backshore deposits up to c. 1.5 m above present MHW [mean high water] between c. 2100–800 cal BP [2100-800 calendar years before present].


Reinink-Smith, 2015  (Kuwait)
[B]ased on bottle characteristics, glass bottles within the debris zonemwere manufactured mostly between 1940 and 1960 (some as early as the 1920s), indicating high tides were more common in the recent past. … The normal tidal cycle affects only a narrow 0.6–0.7 km-wide band parallel to the coast when the prevailing wind (the Shamal) is from the northwest (Gunatilaka, 1986). Within this narrow zone, washed-up glass bottles were manufactured more recently than ~1960 and are not frosted. None of these new [made after 1960] bottles were found near the beach ridges … [A]ssuming the tidal ranges were similar in the middle Holocene, a rough estimate of the MSL [mean sea level] during the middle Holocene highstand is 5.2 m − 1.7 m = +3.5 m above the present MSL [mean sea level]. … The +3.5 m highstand estimate in northeastern Kuwait derived in this study is also higher than the previously reported maximum estimates of +2 to +2.5 m responsible for other Holocene beach ridges in the Arabian Gulf (Gunatilaka, 1986; Lambeck, 1996; Kennett and Kennett, 2007; Jameson and Strohmenger, 2012). Some beach ridges in Qatar and Abu Dhabi are at elevations of 2–4 m above MSL [present mean sea level] as far as 5-15 km inland (Alsharhan and Kendall, 2003).

Rashid et al., 2014  (French Polynesia)
Upon correction for isostatic island subsidence, we find that local relative sea level was at least ~1.5±0.4 m higher than present at ~5,400 years ago.


Strachan et al., 2014  (South Africa)
During the last 7000 years, southern African sea levels have fluctuated by no more than ±3 m. Sea-level curves based on observational data for southern Africa indicate that Holocene highstands occurred at 6000 and again at 4000 cal years BP, followed by a lowstand from 3000 to 2000 cal years B P. The mid-Holocene highstands culminated in a sea-level maximum of approximately 3 m above mean sea level (MSL) from 7300 to 6500 cal years BP [calendar years before present] and of 2 m above MSL at around 4000 cal years BP.  Thereafter, RSL dropped to slightly below the present level between 3500 and 2800 cal years BP.  Sea-level fluctuations during the late Holocene in southern Africa were relatively small (1-2 m); however, these fluctuations had a major impact on past coastal environments.  Evidence from the west coast suggests that there was a highstand of 0.5 m above MSL from 1500 to 1300 cal years BP [calendar years before present] or possibly earlier (1800 cal years BP), followed by a lowstand (-0.5 m above MSL) from 700 to 400 cal years BP [during the Little Ice Age].


Yamano et al., 2014 (Southwest Pacific Ocean)
Mba Island initially formed around ~ 4500 cal yr B.P. [4500 calendar years before present], when sea level was ~ 1.1 m higher than at present. 


Kench et al., 2014  (Central Pacific Ocean)
[T]he mid-Holocene [sea level] highstand is reported to have peaked at approximately +1.1 m above present and was sustained until approximately 2000 years B.P. [before present] in the Marshall Islands.


Hein et al., 2014  (Brazil)
Along the eastern and southern Brazilian coasts of South America, 6000 years of sea-level fall have preserved late-stage transgressive and sea-level highstand features 1–4 m above present mean sea level and several kilometers landward of modern shorelines.


Bracco et al., 2014  (Uruguay)
Highlights:  We present a sea level change curve for mid Holocene in Uruguay.  Sea level reached 4 m amsl [above present mean sea level] between 6000 and 5500 yr BP [before present].   A rapid sea level fall to about 1 m amsl [above present mean sea level] was inferred for 4700-4300 yr BP.  A further sea level increase to about 3 m amsl [above present mean sea level] was inferred after 4300 yr BP.  After 4300 yr BP there was a constant sea level a decline.


Holocene Sea Levels Rose Much Faster With Stable CO2 Levels

Khan et al., 2017  (Caribbean)
Only Suriname and Guyana [Caribbean] exhibited higher RSL [relative sea level] than present (82% probability), reaching a maximum height of ∼1 m at 5.2 ka [5,200 years ago]. … Because of meltwater input, the rates of RSL change were highest during the early Holocene, with a maximum of 10.9 ± 0.6 m/ka [10.9 meters per 1000 years, 1.9 meters per century] in Suriname and Guyana and minimum of 7.4 ± 0.7 m/ka [7.4 meters per 1000 years, 0.74 meters per century] in south Florida from 12 to 8 ka [12,000 to 8,000 years ago].

Zecchin et al., 2015 (Mediterranean)
Episodic, rapid sea-level rises on the central Mediterranean shelves after the Last Glacial Maximum: A review … The evidence presented here confirms drowned shorelines documented elsewhere at similar water depths and shows that melt-water pulses have punctuated the post-glacial relative sea-level rise with rates up to 60 mm/yr. [6 meters per century] for a few centuries. 

Boski et al., 2015 (Brazil)
A rapid sea-level rise, at an averaged rate of approximately 6.1 mm/yr [0.6 m per century], occurred between 8300 and 7000 cal. yr BP [8300-7000 calendar years before present]. Since then, the pace of relative sea-level rise slowed and non-eustatic factors, namely terrigenous sediment supply and coastal dynamics, became dominant in the evolution of the estuary.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThis post is one for the wind-energy-clingers, who refuse to admit how bad it really is.
A new German paper assesses wind energy in Europe . The results are devastating. It concludes that wind energy requires almost 100% backup and that the more capacity that gets installed, the greater the volatility.
The paper appearing at the VGB, authored by Thomas Linnemann and Guido Vallana, finds that “the total wind fleet output of 18 European countries extending over several thousand kilometers in north-south and east-west direction is highly volatile and exhibits a strong intermittent character.”
In other words the power supply across the European grid fluctuates wildly and thus cannot work well. The paper’s abstract continues:
An intuitively expectable smoothing of this wind fleet output to an amount, which allows a reduction of backup wind power capacity, however, does not occur. In contract a highly intermittent wind fleet power output showing significant peaks and minima is observed not only for a single country, but also for the whole of the 18 European countries. Wind energy therefore requires practically 100% back-up. As the (also combined) capacities of all known storage technologies are (and increasingly will be) insignificant compared to the required demand, backup must be provided by conventional power plants, with their business cases fundamentally being impaired in the absence of capacity markets.”
Extreme volatility
The paper then provides a solid analysis, and charts showing why this is the case. Below their Figure 1 illustrates the extreme volatility of onshore and offshore German wind energy over the year 2016:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Germany’s wind energy output ranges from over 30,000 MW to almost zero. Source: ENTSO
Germany’s wind parks have produced only a fraction of their rated installed capacity, rarely ever reaching 20% annually with an average of 17% since 1990:

The capacity utilization of German Windparks from 1990 to 2016. Source: BMWi
The paper concludes:
The available (secured) permanent electrical output of the German wind parks thus remains always below 1% of the installed rated capacity, or expressed in other words: Every year there was at least a quarter hour in which 99% of the rated capacity of the German wind parks was not available and where practically 100% of plannable backup energy dominated.”
Moreover an anylsis of weak wind phases over the 2010 to 2016 period shows that “there were at least 160 phases 5 days long or more where the output from German wind parks fell below 5000 megawatts and a 10-14 day phase of weak wind days occurred every year.
Read (German) entire study here.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWind Energy Expansion: Endangering Wildlife

Photo from Ferrão da Costa et al., 2017
When pondering the future of wind power and its ecological impacts, it is well worth re-considering this seminal analysis from Dr. Matt Ridley.

[W]orld energy demand has been growing at about 2 per cent a year for nearly 40 years. Between 2013 and 2014, […] it grew by just under 2,000 terawatt-hours.
If wind turbines were to supply all of that growth but no more, how many would need to be built each year? The answer is nearly 350,000, since a two-megawatt turbine can produce about 0.005 terawatt-hours per annum. That’s one-and-a-half times as many as have been built in the world since governments started pouring consumer funds into this so-called industry in the early 2000s.
At a density of, very roughly, 50 acres per megawatt, typical for wind farms, that many turbines would require a land area half the size of the British Isles, including Ireland. Every year. 
If we kept this up for 50 years, we would have covered every square mile of a land area half the size of Russia with wind farms. Remember, this would be just to fulfill the new demand for energy, not to displace the vast existing supply of energy from fossil fuels, which currently supply 80 per cent of global energy needs.  

The profound costs to wildlife of future-planning to expand wind energy to the levels demanded by “green” advocates — just to meet the world population’s additional energy demands with 350,000 more turbines each year — has been increasingly documented by scientists.
The last remaining vulture species native to southeastern Europe is “likely” faced with extinction in the next few decades due to an “eight to ten times greater” mortality rate associated with the rapid expansion of wind energy projects in the region (Vasilakis et al., 2017).
Bat species can be found dwelling in a wide variety of terrestrial habitats, including deserts and along sea coasts. Each species may play a fundamental role in its local ecosystem.  For example, Kuntz et al., (2011) indicate that 528 different plant species rely on bat pollination and seed dispersal for sustainability.  Boyles et al., (2011) estimated that by controlling pest populations (insects), the agricultural benefits of bats may reach $22.9 billion (U.S.D.) annually in the continental U.S. alone.
In addition to White Nose Syndrome, deaths  connected to collisions with wind turbines are now the leading cause of multiple mortality events in bats (O’Shea et al., 2016).  Roughly 25% of North American bats are now classified at risk for extinction (Hammerson et al, 2017), in large part due to the explosion of wind turbines across the landscape.   If the expansion of wind turbines continues at its current pace, the hoary bat population is projected to be reduced by 90% (Frick et al., 2017) within the next 50 years.   As Hein and Schirmacher (2016) conclude, the “current and presumed future level of fatality [for bat populations] is considered to be unsustainable.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Even large mammals like the already endangered Portuguese wolf  (“between 200 and 400 individuals” left) has had its reproduction rates reduced by the recent addition of nearly 1,000 new turbines in their shrinking habitat range (Ferrão da Costa et al., 2017 ).
So what, exactly, are we gaining in exchange for increasingly endangering critically important wildlife species?  Slightly above nothing.
According to the IEA, wind energy provided for 0.39% of the world’s total energy demands as of 2013.
At what point may we ask: Are the benefits of wind energy worth the ecological and wildlife costs?

Vasilakis et al., 2017
Numerous wind farms are planned in a region hosting the only cinereous vulture population in south-eastern Europe. We combined range use modelling and a Collision Risk Model (CRM) to predict the cumulative collision mortality for cinereous vulture under all operating and proposed wind farms. Four different vulture avoidance rates were considered in the CRM.  Cumulative collision mortality was expected to be eight to ten times greater in the future (proposed and operating wind farms) than currently (operating wind farms), equivalent to 44% of the current population (103 individuals) if all proposals are authorized (2744 MW). Even under the most optimistic scenario whereby authorized proposals will not collectively exceed the national target for wind harnessing in the study area (960 MW), cumulative collision mortality would still be high (17% of current population) and likely lead to population extinction.

Hammerson et al, 2017
Conservationists are increasingly concerned about North American bats due to the arrival and spread of the White-nose Syndrome (WNS) disease and mortality associated with wind turbine strikes. To place these novel threats in context for a group of mammals that provides important ecosystem services, we performed the first comprehensive conservation status assessment focusing exclusively on the 45 species occurring in North America north of Mexico. Although most North American bats have large range sizes and large populations, as of 2015, 18–31% of the [North American bats] species were at risk (categorized as having vulnerable, imperiled, or critically imperiled NatureServe conservation statuses) and therefore among the most imperiled terrestrial vertebrates on the continent.

Frick et al., 2017
Large numbers of migratory bats are killed every year at wind energy facilities. However, population-level impacts are unknown as we lack basic demographic information about these species. We investigated whether fatalities at wind turbines could impact population viability of migratory bats, focusing on the hoary bat (Lasiurus cinereus), the species most frequently killed by turbines in North America. Using expert elicitation and population projection models, we show that mortality from wind turbines may drastically reduce population size and increase the risk of extinction. For example, the hoary bat population could decline by as much as 90% in the next 50 years if the initial population size is near 2.5 million bats and annual population growth rate is similar to rates estimated for other bat species (λ = 1.01). Our results suggest that wind energy development may pose a substantial threat to migratory bats in North America. If viable populations are to be sustained, conservation measures to reduce mortality from turbine collisions likely need to be initiated soon. Our findings inform policy decisions regarding preventing or mitigating impacts of energy infrastructure development on wildlife.

Hein and Schirmacher, 2016
Two recent attempts were made to estimate bat fatality in the United States for 2012. Hayes (2013) followed a similar approach to Cryan (2011) and based his analysis primarily on the limited dataset from Arnet et al. (2008). Hayes (2013) indicated that >600,000 bats were killed at wind energy facilities in 2012 and suggested that this was a conservative estimate. Smallwood (2013) estimated up to 888,000 bats were killed in the United States in 2012. … We suggest that each of these be considered an order of magnitude estimate; taken together, they highlight the almost certain large number of bats being killed (i.e., on the order of hundreds of thousands per year) in the United States and Canada. Given that bats have a low reproductive rate—typically only having 1 or 2 pups/year—and require high adult survivorship to avoid population declines (Barclay and Harder 2003), this level of impact presumably puts bat populations at risk. Moreover, many species were thought to be declining prior to the onset and expansion of wind energy development, including species impacted by white-nose syndrome (Winhold et al. 2008, Frick et al. 2010). Although population data are sparse or lacking for many bat species, current and presumed future level of fatality is considered to be unsustainable, and actions to reduce impact of wind turbines on bats should be implemented immediately.

Ferrão da Costa et al., 2017
Over the last 15 years, more than 900 wind turbines were built inside the range of the Portuguese wolf. Due to the endangered status of this large carnivore in Portugal, several monitoring plans were conducted, resulting in a reasonable amount of information being collected on the effects of wind farms on wolves. We reviewed the methodological approaches, compiled major findings and summarised the mitigation/compensation measures used in Portuguese wind farms. The overall outcomes show increasing human disturbance in wind farm areas, resulting in lower wolf reproduction rates during construction and the first years of operation, as well as shifts in denning site locations of more than 2.5 km away from the wind farm. … According to a review by Lovich and Ennen (2013), the construction and operation of wind farms have both potential and known impacts on terrestrial vertebrates, such as: (i) increase in direct mortality due to traffic collisions; (ii) destruction and modification of the habitat, including road development, habitat fragmentation and barriers to gene flow; (iii) noise effects, visual impacts, vibration and shadow flicker effects from turbines; (iv) electromagnetic field generation; (v) macro and microclimate change; (vi) predator attraction; and (vii) increase in fire risks.
Share this...FacebookTwitter "
