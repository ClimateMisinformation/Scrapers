"
Share this...FacebookTwitterIf you take the annual CO2 atmospheric content, and differentiate it, that is calculate the year-to-year change, then you get a plot that looks a lot like the ocean temperature. This has led many people to think that the ocean is the source of the additional CO2. This is not the case.
The additional CO2 is from about one-half of our emissions. The year-to-year “noise” is from the year-to-year change in ocean temperature riding on the change from our emissions. Changes in our emissions are somewhat filtered by the time constant of CO2 biosphere absorption. Here is what happens.
Many of you will be familiar with the concept of “half-life” from radioactive decay. For a radioactive element, half of the radioactivity will decay in a certain period of time, then half again in the next period, and so on until the radioactivity can no longer be detected. The same principle applies to absorption. Half of a compound will be absorbed in a certain period, then another half in the next period, then another half, and so on. Here is the curve for a pulse of CO2 absorbed into the biosphere.

Figure 1 is the absorption curve for a single pulse of CO2 emitted into the atmosphere. The half-life of that pulse is a bit over 8 months. It is undetectable after about six years.
Imagine that you have just taken a deep breath, held it until the maximum CO2 has been exchanged, then exhaled. Half of the CO2 in that puff will be gone from the atmosphere in 8 months, 33% will remain in a year, only 11% will be around in 2 years, and so on. The series is actually 1/3, 1/9, 1/27, 1/81… Now add up all breathing for many years, or all the fossil fuel emissions.

In Figure 2 above the top gold trace is the summation of all the individual annual half-life traces. For instance, year one is the sum of the remainders from year -4 to year zero. It is the sum of 1/243 + 1/81 + 1/27 + 1/9 + 1/3 = very close to 1/2. The CO2 fraction that we observe is close to 0.5. If emissions completely ceased in year six, the extra CO2 added to the atmosphere would be nearly zero in year 10.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 3 is a plot of annual fossil fuel emissions and the amount of those emissions that annually remain in the atmosphere. The remainder plot has been corrected for half-life.

Figure 4 is a plot of the fraction of emissions that remain in the atmosphere, the ocean temperature anomaly (from UHA satellite data), and the change (delta) in emissions with the data corrected for half-life using the fraction change data. (The half-life has been decreasing over time by 2.8% per decade). The left scale is for both the remaining fraction and temperature anomaly. The right scale applies to the delta emissions (the annual change in added emissions). This is scaled to match the fraction change. On a year-to-year basis the ocean temperature changes overwhelm the emission changes, but not the emissions themselves.

Figure 5 is a plot of  change: SST, CO2, and annual emissions added since 1980. This is the annual delta (differential) of all three. The Mt. Pinatubo cooling and the 1998 and 2010 El Niño warming is clearly visible in the CO2 data. It looks like the CO2 increase is due to ocean temperature, but this is an illusion. The annually added emissions are much larger than the ocean temperature CO2 flux change.

Figure 6 is a scatter plot of CO2 and SST anomaly with a linear trend applied. The trend is 17,239 million metric tonnes of CO2 emitted per degree C of SST change. Now look back at Figure 6. The long term change in temperature is about 0.3°C. This would be equivalent to about 5 billion tonnes of CO2. But the increase in CO2 over that time period was 483 billion tonnes, about 100 times that amount. The long-term CO2 increase is due to emissions, not ocean temperature. Temperature drives only the short-term changes.
About half of fossil carbon emissions appear to be responsible for the atmospheric CO2 rise, and that fraction is decreasing. The year-to-year changes in the CO2 rise are mostly due to ocean temperature changes, but those changes should be considered weather.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIf you weren’t convinced by Lüning’s and Vahrenholt’s essay on the failures of climate models posted here two days ago, then here’s more!
=======================================
More fun with climate models: Nowhere do they fit reality
By Sebastian Lüning and Fritz Vahrenholt
(Translated/edited by P Gosselin)
In March 2013 journalist Joachim Müller-Jung put it aptly in an article in the FAZ:
Whoever simulates the world, has not understood the truth
How much reality is in the models? Fact is: The complexities increase, but so do the uncertainties. How can science remain credible here?”
Read more at the faz.net.
Today once again we wish to take a cruise through the world of modeling. The field currently finds itself deep in crisis. Earlier they had energetically produced a number of models but the numerous misses are now taking a heavy toll. A first wave of self-criticism is sweeping across the field. by far not everything is as rosy as what the state funders once claimed.
On February 21, 2013 the University Göteborg issued a press release with the title: “Climate models are not good enough“. Within the framework of a promotion project, it was discovered that climate models have been unable to reproduce the observed changes in extreme rainfalls in China over the last 50 years:
Climate models are not good enough
Only a few climate models were able to reproduce the observed changes in extreme precipitation in China over the last 50 years. This is the finding of a doctoral thesis from the University of Gothenburg, Sweden. Climate models are the only means to predict future changes in climate and weather. “It is therefore extremely important that we investigate global climate models’ own performances in simulating extremes with respect to observations, in order to improve our opportunities to predict future weather changes,” says Tinghai Ou from the University of Gothenburg’s Department of Earth Sciences. Tinghai has analysed the model simulated extreme precipitation in China over the last 50 years. “The results show that climate models give a poor reflection of the actual changes in extreme precipitation events that took place in China between 1961 and 2000,” he says. “Only half of the 21 analysed climate models analysed were able to reproduce the changes in some regions of China. Few models can well reproduce the nationwide change.”
Problems with the rainfall modeling are found at every location. Also in the USA models have failed to reproduce the historical precipitation development, as Mishra et al. (2012) and Knappenberger and Michaels (2013) were able to show. Stratton & Stirling (2012) and Ramirez-Villegas et al. (2013) found the same at the global level. Here’s an excerpt of the latter:
Climatological means of seasonal mean temperatures depict mean errors between 1 and 18 ° C (2–130% with respect to mean), whereas seasonal precipitation and wet-day frequency depict larger errors, often offsetting observed means and variability beyond 100%. Simulated interannual climate variability in GCMs warrants particular attention, given that no single GCM matches observations in more than 30% of the areas for monthly precipitation and wet-day frequency, 50% for diurnal range and 70% for mean temperatures. We report improvements in mean climate skill of 5–15% for climatological mean temperatures, 3–5% for diurnal range and 1–2% in precipitation. At these improvement rates, we estimate that at least 5–30 years of CMIP work is required to improve regional temperature simulations and at least 30–50 years for precipitation simulations, for these to be directly input into impact models. We conclude with some recommendations for the use of CMIP5 in agricultural impact studies.”
Soncini & Bocchiola (2011) examined snowfall in the Italian Alps. Also here they found the same: the real, measured development cannot be reproduced by models. What’s even worse: the future projections of various models deviate widely from each other. Here’s an excerpt from the noteworthy paper:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




General Circulation Models GCMs are widely adopted tools to achieve future climate projections. However, one needs to assess their accuracy, which is only possible by comparison of GCMs’ control runs against past observed data. Here, we investigate the accuracy of two GCMs models delivering snowfall that are included within the IPCC panel’s inventory (HadCM3, CCSM3), by comparison against a comprehensive ground data base (ca. 400 daily snow gauging stations) located in the Italian Alps, during 1990–2009. The GCMs simulations are objectively compared to snowfall volume by regionally evaluated statistical indicators. The CCSM3 model provides slightly better results than the HadCM3, possibly in view of its finer computational grid, but yet the performance of both models is rather poor. We evaluate the bias between models and observations, and we use it as a bulk correction for the GCMs’ snowfall simulations for the purpose of future snowfall projection. We carry out stationarity analysis via linear regression and Mann Kendall tests upon the observed and simulated snowfall volumes for the control run period, providing contrasting results. We then use the bias adjusted GCMs output for future snowfall projections from the IPCC-A2 scenario. The two analyzed models provide contrasting results about projected snowfall during the 21st century (until 2099). Our approach provides a first order assessment of the expected accuracy of GCM models in depicting past and future snowfall upon the (Italian) Alps. Overall, given the poor depiction of snowfall by the GCMs here tested, we suggest that care should be taken when using their outputs for predictive purposes.”
Out of thin air?
In June 2013 Axel Lauer and Kevin Hamilton in the Journal of Climate looked at cloud models. Also here nothing is different: Every model does its own thing and the real development simply refuses to play along. Next is the abstract of the paper:
Clouds are a key component of the climate system affecting radiative balances as well as the hydrological cycle. Previous studies from the Coupled Model Intercomparison Project Phase 3 (CMIP3) showed quite large biases in the simulated cloud climatology affecting all GCMs [global climate models] as well as a remarkable degree of variation among the models, which represented the state-of-the-art circa 2005. Here we measure the progress that has been made in recent years by comparing mean cloud properties, interannual variability, and the climatological seasonal cycle from the CMIP5 models with satellite observations and with results from comparable CMIP3 experiments. We focus on three climate-relevant cloud parameters: cloud amount, liquid water path, and cloud radiative forcing. We show that intermodel differences are still large in the CMIP5 simulations. We find some small improvements of particular cloud properties in some regions in the CMIP5 ensemble over CMIP3. In CMIP5 there is an improved agreement of the modeled interannual variability of liquid water path as well as of the modeled longwave cloud forcing over mid and high latitude oceans with observations. However, the differences in the simulated cloud climatology from CMIP3 and CMIP5 are generally small and there is very little to no improvement apparent in the tropical and subtropical regions in CMIP5. Comparisons of the results from the coupled CMIP5 models with their atmosphere-only versions run with observed SSTs show remarkably similar biases in the simulated cloud climatologies. This suggests the treatments of subgrid-scale cloud and boundary layer processes are directly implicated in the poor performance of current GCMs [global climate models or general circulation models] in simulating realistic cloud fields.”
No matter which modeling parameter one looks at, the result is off. Another example is ground moisture ground moisture, which according to an analysis by Tim Ball is not correctly given in the IPCC models. There are also problems with thunderstorms, as Anthony Watts at WUWT showed. Or take a look at atmospheric pressure. According to Przybylak et al. 2012, it has not changed much since the beginning of the 19th century. The models, on the other hand, foresaw a significant trend, which scientists sold as an “anthropogenic fingerprint”. That is now turning out to be completely wrong.
Also when looking back further into the geological past, climate models do not make a good impression at all. During the last interglacial, i.e. the warm period of 120,000 years ago, it was warmer than today. Yet, for whatever reason, climate models are unable to reproduce this, as a paper appearing in the 29 August 2014 Climate of the Past journal criticized:
We find that for annual temperatures, the overestimation is small, strongly model-dependent (global mean 0.4 ± 0.3 °C) and cannot explain the recently published 0.67 °C difference between simulated and reconstructed annual mean temperatures during the LIG thermal maximum. However, if one takes into consideration that temperature proxies are possibly biased towards summer, the overestimation of the LIG thermal maximum based on warmest month temperatures is non-negligible with a global mean of 1.1 ± 0.4 °C.”
Another paper that appeared just days before by Dolan et al. looked at the Pilocene 3 million years ago. The task for the 9 modeling groups was to calculate the ice cover over Greenland for the conditions of the Pilocene warm period. Back then it was considerably warmer than today and the sea level was higher, i.e. about the same conditions that are predicted by today’s climate models for the end of the 21st century. The study ended with a big surprise: Everything between “ice-free” and “ice somewhat like today” were given by the models. The reason for the divergence: Every model simulated the local albedo properties in Greenland differently. Yet this is decisive for the ice cover extent of the island. In summary future modeling resembles playing the lottery.
Finally we go back yet another step further, to the mid-Milocene 14 million years ago. A paper by Goldner et al. from March 2014 found that the climate models were off by a full 4°C. Among other things, the authors suspect that certain climate factors are missing in the models. An interesting thought…
What follows is an excerpt from the abstract of that paper:
The mid-Miocene climatic optimum (MMCO) is an intriguing climatic period due to its above-modern temperatures in mid-to-high latitudes in the presence of close-to-modern CO2 concentrations. We use the recently released Community Earth System Model (CESM1.0) with a slab ocean to simulate this warm period, incorporating recent Miocene CO2 reconstructions of 400 ppm (parts per million). We simulate a global mean annual temperature (MAT) of 18 °C, ~4 °C above the preindustrial value, but 4 °C colder than the global Miocene MAT we calculate from climate proxies. […] Our results illustrate that MMCO warmth is not reproducible using the CESM1.0 forced with CO2 concentrations reconstructed for the Miocene or including various proposed Earth system feedbacks; the remaining discrepancy in the MAT is comparable to that introduced by a CO2 doubling. The model’s tendency to underestimate proxy derived global MAT and overestimate the Equator to pole temperature gradient suggests a major climate problem in the MMCO akin to those in the Eocene. Our results imply that this latest model, as with previous generations of climate models, is either not sensitive enough or additional forcings remain missing that explain half of the anomalous warmth and pronounced polar amplification of the MMCO.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterI was out of town for the weekend, enjoying the record warm weekend, which is why the blogging was on the slow side. Now that I’m back, I see the world is still as kooky as ever. Here’s a short one from the DkS site:
===================================
Highly Urgent Topic: Presentation “Gender division of labor in climate change” at the University of Bremen on 12 November 2014
By Sebastian Lüning and Fritz Vahrenholt
(Translated/edited by P Gosselin)
On November 12, 2014 a colloquium by the artec research centre for sustainability is taking place at the University of Bremen at 4 pm. The colloquium focuses on a topic that has long been a pressing issue and has been the source of many sleepless nights:
Value creation and value appreciation: Gender division of labor in climate change
Speaker: Dr. Sybille Bauriedl, Bayreuth Academy of Advanced African Studies”
So what could possibly be behind this title? Is the suspected climate change going to lead men to finally getting off their lazy butts and helping out with the ironing and laundry? Or is the looming heat going to lead men to not being able to help out at all because they’ll be confined to sweating profusely on a hammock? Lots of questions, but no answers.
At the speaker’s website we happen to come across another important presentation from a year ago:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Social construction of climate change. How and what can feminist research contribute to gendered climate policy?”
This is something we have always asked ourselves. Or what about this presentation here by Bauriedl from 2012:
Climate justice and gender justice: women in the climate trap”
Women in the climate trap. The insidious climate catastrophe apparently has had the world of women in its sights. Unfortunately the site does not offer any presentation files, which we would have loved to have a look at.
It is truly interesting to observe where our tax dollars are going. For Ms Bauriedl and her occupation, it would certainly be catastrophic if it ever turned out that everyone had over-estimated climate change for years and if the dreaded catastrophe never materialized.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGreen Party Tübingen Mayor unhinged over dissent – “damn stupid blather!“
By Michael Limburg, EIKE
[Translated, edited by P. Gosselin]
Tübingen mayor Boris Palmer is considered as one of the Green Party’s more moderate realists. However when it comes to the facts about the pie-in-the-sky “Energiewende” (transition to renewable energies), the moderate realism comes to an abrupt end. Suddenly it turns to bad-mounting and insults, as one citizen in the beautiful region of Stauferfeld found out when bringing up the laws of nature – which in fact also apply even to green ideology. Idyllic Stauferfeld is planned to receive an array of wind turbines.
Though we are not the New York Times, we took the liberty of publishing Palmer’s disrespectful e-mail.
Photo: Tübingen mayor, Green Party member, Boris Palmer. Photo by: Manfred Grohe

It all started with a concerned citizen sending an e-mail to Tübingen’ s honorable burgermeister Herr Boris Palmer:
From: XXXXXXX
Sent: Tuesday, 28 April 2015 11:09 p.m.
To: Palmer, Boris, University City Tübingen
Subject: AW: FAZ article of 2 April 15: Industrialization of our landscape with wind energy machinery
Dear Ladies and Gentlemen,
At the former military depot 3 units will be installed, and the other 3 will be installed in untouched nature 700 meters away from the Adelberg Convent and the Herrenbachstausee nature recreation centre, right in the middle of beautiful Stauferland!
The military depot is indeed an untouched paradise for red kite birds, bats, and for rare woodcocks.
In Baden-Württemberg you can install as much wind energy and for as long as you can, and the only thing that we will surely get for it is a high number of installed capacity. However you will never get a base load capacity with renewable energies because we still do not have a sensible storage technology.
What we are getting: a huge amount of waste electricity when the wind blows, which we have to get rid of in foreign countries at a high expense. And when there is little or no wind blowing, we get the power from coal or nuclear.
Unfortunately: zero times as much installed wind capacity as you want always equals zero!
Please convince us of the opposite!
The expansion of renewable energies will certainly not fail because of resistance from citizens, but rather because of the laws of nature. It is not possible to plan wind and solar energy. They can be stored only minimally, and they will not meet the demand peaks of consumption!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




But maybe we first have to first completely cover Germany with wind turbines, corn fields and solar fields in order to comprehend this.
Hopefully in this case at least the nuclear power plants in our neighboring countries are safe enough so that us German do-gooders do not perish some time soon because of a French or Polish nuclear catastrophe!
Yours sincerely,
XXXXXXX
The Green mayor Herr Palmer was hardly amused by the dissent over the planned wind project, even becoming unhinged, and viciously lashed out with the following response:
From: Palmer, Boris, University City Tübingen [mailto:boris.palmer(at)tuebingen.de]
Sent: Wednesday, 29 April 2015, 10:16
Subject: FAZ article 2 April 2015; Industrialization of our landscape with wind energy machinery
Dear Frau XXXXXXX,
to be loud and clear about it: In the termionology of the Rems Valley, your egotistical and unknowledgeable blather deserves only one characterization: damn stupid nonsense.
Zero knowledge times zero willingness to be responsible = zero importance.
To conclude with natural laws that we should not use what is in fact an endless supply of an energy type so that we can instead use up the last remnants of coal and gas from the earth requires a blindness that is certainly beyond any cure.
Feel free to send this e-mail to the New York Times.
Yours sincerely,
Boris Palmer
Mayor
University City Tübingen
City Adminsitration im Blauen Turm
Friedrichstraße 21, 72072 Tübingen
Tel. (0 70 71) 204 – 1200; Fax (0 70 71) 204 -1000
www.tuebingen.de
To which the dissident citizen promptly responded:
Sent: Wednesday, 29 April 2015 11:22
To: ‘Palmer, Boris, University City Tübingen’;
Subject: AW: FAZ article from 27 April 15, Industrialization of our landscape with wind turbine machinery
Dear Herr Palmer,
You may of course portray me as egotistical and damn stupid, but it does not bother me at all.
In any case you are going to find it increasingly difficult to counter my arguments and those of many other citizens, except by using defamation and polemic.
With warm greetings from the beautiful wind-energy free Stauferland in lovely Tubingen.
XXXXXXXX”
Obviously the green movement has started getting awfully testy about the rapidly growing dissent over the failing wind and renewable energy dream in Germany.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhat follows is Professor Fritz Vahrenholt’s reaction to German power giant E.ON’s decision to split off its fossil fuel and nuclear power generation operations, and Russia’s announcement it has cancelled the construction of South Stream gas supply pipeline to Europe.
=========================
This week two events have occurred and will have serious impacts on the European and German energy market: 1) the withdrawal from conventional power generation by Europe’s and Germany’s largest power company, E.ON, and 2) Russia’s canceling the construction of the South Stream gas pipeline. The public reaction in Germany was quite subdued. That in itself shows how little the German public comprehends the issue of power supply stability.
But this is exactly what these two events are all about.
E.ON accepts that there is no longer any future for coal and nuclear power in Germany, as this is the will of the federal government and the German public. That is indeed suicidal for Germany as a location for business, and E.ON knows it. The forced shutdown of nuclear power plants, without compensation, and the loss-intensive relegation of coal and gas power plants to serve as uneconomical back-up power plants for the most-unstable renewable energies, has left a deep impression on the bottom lines of German power producers.
E.ON will place all its conventional operations into a subsidiary company, which will then be put on the auction block. E.ON’s abandonment is striking proof that a market-oriented commitment in Germany’s energy sector is politically unwelcome. Ultimately it is E.ON’s silent wish that in the end – with political guarantees from the German government – a buyer will take over the risk of producing conventional energy in Germany. If it is not the state-controlled companies in France or Russia, then it will be the German state itself who will take over the supply of energy, and certainly over the coming years – after one of the feared brown-outs. That of course will be because of politics. But the political reaction will claim: The energy supply has to be placed in the hands of the state because the market failed. Perhaps the managers at E.ON saw it coming, and so are now attempting to salvage a part of the capital.
With regards to Russia’s sudden cancellation of the South Stream pipeline project, this is also a question of securing an uninterrupted supply. In the wake of geopolitical tensions Russia is pulling out, surely in part because of the pressure from the falling oil and gas prices which are making the project increasingly uneconomical. Russia is turning to China for a solution.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And also here the German public has been surprisingly subdued. As politics pretty much has blocked the possibility of producing its own shale gas, a major part of the political left is busily attempting to torpedo the planned TTIP trade agreement with the USA, which also would include natural gas. Yet Germany continues on as if it’s business as usual, because the overwhelming majority believes wind and sun will suffice. A look out the window can be enlightening. Just as I am writing this, the PV production in Germany is zero – it’s dark outside – and the wind is hardly blowing…I’d estimate producing a maximum of 5000 MW in total, a tiny fraction of Germany’s total demand. Who is going to supply the other 50,000 MW that will power the German Rail, steel mills, subways, water supply, and my desk lamp and laptop?
One thing is now certain: It’s not going to be E.ON.
Fritz Vahrenholt
=================================
Fritz Vahrenholt is Honary Professor of Chemistry at the University of Hamburg, former Environment Senator of Hamburg, was on the board of Deutsche Shell AG 1998 – 2001, CEO of REpower Systems AG wind turbine company 2001 – 2007, and RWE Innogy renewable energy from 2008 to 2012, and co-author of the climate science skeptical book Die kalte Sonne (English version: The Neglected Sun).  In 2012 Vahrenholt was elected chair of the Deutsche Wildtier Stiftung, a German foundation for the preservation of wildlife in Germany. He is also a member of the London-based Global Warming Policy Foundation.
Photo credit: Die kalte Sonne.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNot only do the hysterical global warming bedwetters want us to do it with the lights off in unheated room with all our clothes on, now they are poised to request senior citizens to leave their cars in the garage and get around in the rain and snow by foot with their Rollators.
Hat-tip: DirkH
The Hannoversche Allgemeine Zeitung (HAZ) reports on a regional Hanover study that found senior citizens are responsible for harming the climate because “they like driving their cars“. According to the HAZ, the study was conducted by the GGR expert assessment office based in Hamburg, on behalf of the Hanover regional government.
Seniors putting climate targets in jeopardy
The report finds that many senior citizens in the Hanover region “are driving their cars longer and more frequently than in the past” and as a result “the region’s own climate protection target in the area of transportation is in jeopardy“.
Obviously the enlightened Hanover government officials are afraid that the climate gods will be angered if old people do not start behaving properly.
One has to be concerned, if not frightened, that such ridiculous studies are being commissioned and used by governments to justify policy in the first place. The study was commissioned by Hanover’s regional government.
Apparently they feel it is their business to find out who is driving around too much. And under the guise of “climate protection”, the state now believes it has the authority to intrude into our private bathrooms, kitchens, bedrooms, our cars and every aspect of our lives and boss everyone around.
The HAZ writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the city of Hanover there is a positive development among the citizenry in the direction of climate-friendly behavior. However the figures in the surrounding area are stagnating, the GGR claims.”
Despite the “positive development” in Hanover in reaching climate protection targets, mostly through the herding of people into public transportation and bikepaths, the GGR has discovered that seniors living in the surrounding areas outside of Hanover are using their cars far more than they should. The HAZ quotes the GGR report:
Today’s generation of seniors have a driver license more than ever before. In the meantime older ladies are driving with an automobile almost as often as men are.”
God forbid. The increased mobility of grandmothers, the report concludes, means that they are “as a whole producing more emissions even though the cars are more environmentally friendly.”
As policymakers fly to a climate conference for the 20th time, grandma will have to use the Rollator
The report strongly suggests that poor grandmother should use her Rollator more to get around instead of driving her car, or wait 3 hours for the next bus to come by.
The HAZ writes:
In the whole region people are walking less than they did a decade ago. However, a need for action here has not been mentioned up to now.”
Meanwhile, German politicians, NGOs, and activists are all flying (some in first class) and burning tons of jet fuel (at taxpayer expense) all the way to South America – for the 20th climate conference which is aimed at finding ways to protect the climate.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe coming age of power cannibalism…Germany on the verge of committing energy suicide
By Fred F. Mueller
German politicians see themselves as the saviors of our climate. In the early 1990s German politicians started the policies that ultimately culminated in the “Energiewende”, which aims to eliminate nuclear power generation and some 76% of the fossil fuel power generation. By 2050 some 80% of power generation should come from “renewable” green sources such as wind, solar, biomass, waste incineration and hydro. Since the volatile sources of wind and solar power will have to contribute the lion’s share, politicians reluctantly concede 20% of the energy coming from reliable fossil power sources.
Germany’s endeavor is indeed breathtaking. A look at Figure 1 shows in detail how massively Germany had once relied upon fossil and nuclear power sources to secure a highly reliable power supply. These sources were controllable and highly reliable. And because Germany’s topology offers only limited possibilities for hydropower, that renewable source is minimal.

Figure 1: In 1990 the German grid was able to count on conventional power sources which were controllable and highly reliable. Renewable hydropower accounted for only 3.6 %
Today, after some two decades of massive green energy policy, the situation has changed dramatically. Wind, solar, biomass and waste incineration plants have been promoted to such an extent that together with hydropower, the share of “green energy” today has reached 25.8 % of the country’s total electric power production. This resulted from Germany’s EEG renewable energy feed-in act which guarantees producers fixed rates for 20 years and forces power companies to buy up all the renewable power produced, regardless of the market conditions. The result has been a massive oversupply which has led to steep price drops on power trading floors, which in turn have pushed fossil fuel utilities to and beyond their profitability limits. Surplus production has been repeatedly dumped onto neighboring markets and resulted in massive disturbances for the respective national power grids. Readers interested in a more detailed description of the policy might have a look at the article of Marita Noon [NOON].
Capacity without control
The problem with the “renewable” power sources of wind and solar is their intrinsic volatility coupled with their poor capacity utilization rates of only 17.4% for wind and 8.3% for solar (average values for Germany).
That poor utilization rate means one has to build up huge overcapacities in order to achieve a certain amount of power production. Worse, the power source fluctuates wildly according to weather conditions. As a consequence, Germany has to maintain a dual power generation infrastructure that comprises a grossly overinflated capacity of “renewable” wind and solar power plants shadowed by a full scale backup set of conventional plants. These conventional power sources must always be on standby, ready to take over when weather conditions aren’t favorable. The production-fluctuation range of the “renewables” wind and solar is incredibly wide and volatile. For example in Germany there is an installed nameplate capacity of nearly 73,000 MW. Yet the minimum power output in Germany in 2014 from both sources was a meager 29 MW (only 0.04% of installed capacity) while the maximum value was 38,000 MW (48%).
The massive buildup in wind and solar power has already resulted in a considerable nominal overcapacity of “renewable” power sources.
The combined rated capacity of all “renewable” power sources already reaches about 87,000 MW, which is the maximum power consumption the grid has been designed to secure. Additionally, a minimum conventional power station capacity of some 28,000 MW has to be constantly connected to the grid in order to secure supply stability. As a result the risk of the grid reaching an oversupply situation if weather conditions are favorable for both wind and solar power plants is growing with every additional “renewable” plant that comes online. Currently 5,000 – 6,000 MW are getting added each year. That situation is aggravated by the fact that there exists no technology to absorb and store any noticeable quantities of oversupply. Neighboring countries are already taking measures to fend off surplus-power-dumping that could destabilize their grids.
Power cannibalism has already started
The result is a grid which at times is so oversupplied with power that something will have to give. Fossil fuel power plants have been throttled to the point where they are no longer profitable and many power companies have started mothballing them, so quickly in fact that Germany had to pass legislation forcing producers to keep their fossil plants on stand-by, and to do so even if they lost money. Even the reliable “classic” renewable power sources – e.g. hydropower – are starting to suffer because most are not supported by government schemes.
As the build-up in renewable capacity continues, even the subsidized “renewable” power sources will sooner rather than later be forced into fierce competition for access to the grid whenever the weather conditions turn favorable. One can speculate that within just a couple of years, the first “renewable” energy sources will slowly be driven out of the market because of oversupply. Eventually the renewable power producers will be forced to cannibalize each other in an increasingly fierce competition for privileged access to the power grid as the unwanted events of over-supply become increasingly more frequent.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Things are set to get much worse
Normally, one would think that a government confronted with such a situation would stop at this point and wait for a technically and commercially viable solution for storing the increasing amounts of produced surplus electric energy – for use during times when weather conditions are less favorable. Unfortunately no such storage solution is currently available at the required scale, and anything being proposed so far is either much too expensive or has efficiency factors that are not worth discussing.
Yet Germany has a unique peculiarity: its leaders sometimes exhibit a stunning inability to recognize when the time has come to abandon a lost cause. So far €500 billion has already been invested in the “Energiewende”, which is clearly emerging as a failure. Yet all political parties continue to throw their full weight behind the policy rather than admitting it is a failure (which would be tantamount to political suicide). Instead, the current government coalition has even decided to shift into an even higher gear on the path to achieving its objective of generating 80% of German electric power from “renewable” sources by 2050. If the situation is practically unmanageable now with 25% renewable energy, it’ll be an uncontrollable disaster when (if) it reaches 80%.
If the government sticks to its targets, the share of the different power sources will probably appear as in Figure 2. Currently just 26% has been achieved so far, and the existing biomass share of some 7% is more or less doomed and thus will also have to be replaced by wind and solar. One can easily see how daunting the task that still lies ahead really is.

Figure 2. The official goal of achieving 80% power supply from “renewable” sources by 2050 requires further massive investments in wind and solar power technologies. Imagine the huge power supply fluctuations one can expect to see from wind and sun. 
Waiting for the grand finale
The real risks that lie ahead for the German power generating infrastructure become more recognizable if one looks at the nameplate capacity buildup that has taken place, e.g. just over the past five years, and compares it to what will additionally be needed by 2050, see Figure 2. Keeping in mind that €500 billion have already been contracted and will have to be paid by the consumer, one gets an idea of the proportions of the task still to be tackled in the coming years.

Figure 3. The installed nameplate power production capacities for wind, solar and biomass as of 2014 has already severely burdened the German consumer with costs of about €500 billion. That will dwarfed by what lies ahead, if politicians don’t change course. Note how 376,000 MW of wind and sun capacity may be installed to ensure meeting the country’s roughly 70,000 MW of demand.
Apart from the sheer dimensions of the costs that lie ahead, the additional cannibalism aspect will grow to enormous proportions. Since an installed wind and solar capacity of some 73,000 MW in 2014 yielded a combined maximum power output of 38,000 MW, the 376,000 MW that are to be installed by 2050 will generate a peak output of 196,000 MW to a grid that might just be able to take up between 40,000 and 90,000 MW. That means, depending on the weather, between 106,000 and 156,000 MW will have to be dumped somewhere else.
In the fight to get power into an often times severely overloaded grid, that’s when cannibalism amongst “renewable” power sources will really become intense. Will wind farmers sabotage solar plantations? Will solar owners sabotage wind turbines? Time will tell, maybe much sooner than we think.
Fred F. Mueller
Sources
[NOON] Marita Noon: Germany’s “energy transformation:” unsustainable subsidies and an unstable system www.cfact.org/2014/12/16/germanys-unsustainable-subsidies-and-an-unstable-system/
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterCorrection: Yesterday I had the wrong chart up (2013). Now the 2014 winter chart is up.
======================================
This September is bringing with it already the first hints of winter for North America with snow predicted to fall over a vast area of the upper western USA, perhaps as far south as Denver, says meteorologist Joe Bastardi at his latest Saturday Summary.
Parts of Europe have already seen their first notes of winter, with snowfalls recorded in Austria, Germany, and Great Britain – read here.
About ten years ago many climatologists, those obsessed with the hypothesis of global warming, were already writing the last will for winter weather in many regions. They were convinced by their computer models and simulations, which foresaw a rapid rise in global warming. But then came the global warming pause, followed by about 8 years of modest global cooling, all accompanied by an unexpected string of nasty winters.
And listening to the latest forecasts for the coming winter, Mother Nature is once again set to defy the warming climate models.
First Joe Bastardi gives us a brief preview of his winter forecast for North America starting at the 11:52 mark of Weatherbell’s latest Saturday Summary.

Chart: Weatherbell Analytics Saturday Summary.
The above chart shows Weatherbell’s projected temperature anomaly for the upcoming winter.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Joe says they had already issued the forecast back in April and bases it on weather patterns already observed in the past. He thinks that the models used by climatologists don’t consider all the factors or underestimate some of them. Today he says their models are now also pointing to a colder and snowier winter for large parts of the US with the likelihood how heavy snows near the northern Southeast.
“Frigid conditions”
The US Farmers Almanac also came out predicting a brutal winter for much of the USA. Managing editor Sandi Duncan says Americans need to prepare for a “shivery and shovelry” winter. “We’re calling for some frigid conditions, bitter conditions,” she said.
The American National Weather Service (NWS) currently is pointing to a normal winter for USA, with warmer than normal temperatures out west, cool in the south, and normal in the east.
Central Europe (Germany) winter forecast
The German language www.wetterprognose-wettervorhersage.de site writes that long-term models point to the September, October and November autumn as too dry but with near normal temperatures.
For winter the site writes:
December will be slightly too warm, January and February for the most part normal temperatures with a tendency for higher precipitation. In other words, this variant points to a slightly warmer than normal, but in some regions a very snowy winter.”
Sounds like a potentially good ski season in the Alps!
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOne of the last remaining bastions of the global warming scare is sea level rise.
Unsurprisingly, a handful of alarmists are still desperately clinging to accelerating sea level rise, insisting that it is just around the corner. However a new analysis on the subject by veteran meteorologist Klaus -Eckard Puls of the European Institute of Climate and Energy (EIKE) shows that sea level rise is not accelerating, and that there are signs showing a deceleration. That bastion is on the verge of collapse.
The EIKE review first starts by focusing on German coastal sea level rise, sections 1-4, before shifting on global sea level rise, section 5-10. The focus here is on the latter.
Concerning global sea level data, Puls starts by looking at a peer-reviewed tide gauge analysis conducted by distinguished Swedish scientist Nils-Axel Mörner who evaluated 182 tide gauges scattered around the world, some going back more than 200 years.
Mörner’s results uncovered gaping differences when he compared the tide gauge results to those reported by the TOPEX/POSEIDON/JASON satellite. His conclusion:
Removing outliers of obvious uplift or subsidence, there are 182 records left, which forms a nice Gaussian distribution around a mean value of +1.65 mm/yr.
Satellite altimetry is a new and important tool. The mean rate of rise from 1992 to 2013 is +3.2 ±0.4 mm (UC, 2013). This value is not a measured value, however, but a value arrived at after much “calibration” of subjective nature (Mörner, 2004, 2011a, 2013a). The differences between the three data sets (±0, +1.65 and +3.2 mm/yr ) are far too large not to indicate the inclusions of errors and mistakes.”
He adds:
The evaluation of worldwide 182 tide gauges yields a mean secular sea level rise of 16 cm, without a GIA [Glacial Isostatic Adjustment] correction. A secular acceleration in rise was not found, and thus there is no AGW-CO2 climate signal.”
Puls also quotes an article by Dr. Sebastian Lüning and Prof. Fritz Vahrenholt at DkS:
Despite the satellite measurements, naturally the tide gauge measurements were continued. And they don’t mislead in any way as they stubbornly stick to their old course of being significantly below 2 mm/year.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Puls provides three charts showing the glaring discrepancy:

 Chart: climatesanity.wordpress.com/sea-level-rise/
“Amazing agreement between tide gauge data and GRACE”
So which is right? TOPEX/POSEIDON/JASON or the observed tide gauges? Next Puls looks at the data obtained from the GRACE satellite, which show they are practically in exact agreement with the tide gauge measurement. Puls writes, citing multiple sources of peer-reviewed literature:
Both extremely different measurement methods of tide gauges [1.7 mm/yr] and gravity measurements (GRACE satellite [1.6 mm/yr]) agree with each other amazingly well at [near] 1.7 mm/yr, They are off by only a millimeter!  That leads us to the question we often find in the literature of why the TOPEX/POSEIDON/JASON satellite measurement method – the only one of all methods – yields values that are almost double.”
From this Puls summarizes at the end:
The constant stream of alarmist announcements of a supposed dramatic sea level rise now taking place and in the future cannot be confirmed. Rather it is even refuted by the measurement data. Worldwide neither the tide gauge data (200 years) nor the satellite data (20 years) indicate an acceleration in sea level rise. This is in stark contradiction to all the former and current claims of the IPCC, some institutes and a number of climate models. Moreover there is evidence that indicate the satellite data have been ‘overly corrected'[28]: “Instead of the satellite data being adjusted to match the real measured data at the surface and being adjusted downwards, there is now a discrepancy between the tide gauge and satellite measurements, unfortunately even today. And it appears to bother no one. A mysterious case.”
Puls is telling us that if you wish to have the true story on sea level rise, then look at the tide gauge data and to be very careful with the (calibrated) data from TOPEX/POSEIDON/JASON. Again some, it would appear, are playing it very loose with the data.
Overall the review by Puls is comprehensive and an English version would be extremely useful, especially for the scientists at the IPCC.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhether it’s war, rape, storms, depression, etc., there’s almost nothing that doesn’t get blamed on CO2 nowadays.
One of the favorites in the climate blame-game is the alleged dying off of coral reefs due to global warming from man-made CO2..
But that is turning out to be false, too. The online Frankfurter Allgemeine Zeitung writes today that climate change is not responsible for the dying off of the Caribbean coral reefs after all, citing a new report by the International Union for the Conservation of Nature (IUCN).
The IUCN writes (emphasis added):
Climate change has long been thought to be the main culprit in coral degradation. While it does pose a serious threat by making oceans more acidic and causing coral bleaching, the report shows that the loss of parrotfish and sea urchin – the area’s two main grazers – has, in fact, been the key driver of coral decline in the region. An unidentified disease led to a mass mortality of the sea urchin in 1983 and extreme fishing throughout the 20th century has brought the parrotfish population to the brink of extinction in some regions. The loss of these species breaks the delicate balance of coral ecosystems and allows algae, on which they feed, to smother the reefs. […]
‘Even if we could somehow make climate change disappear tomorrow, these reefs would continue their decline,’ says Jeremy Jackson, lead author of the report and IUCN’s senior advisor on coral reefs.”
Surprise. Another climate myth gets debunked.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Climate change: “an excuse for doing nothing”
Next is a nice video featuring the report’s lead author Jeremy Jackson who explains the significance of the report. He makes a surprising comment on climate change.

At the 3.48 mark, Jackson states:
There’s nothing in my report, except the realization that climate change hadn’t been as severe as we feared so far, that’s new.  The fact and the thing about climate change is that it is an excuse for doing nothing. You know if it’s all those goddamn gringos in the north that made things bad, then I don’t have to do my job.”
He’s right. What Jackson hopefully realizes is that with just a fraction of the money that is spent on the bogus problem of climate, it would likely be enough to solve all the Caribbean coral reef problems.
Also read here at WUWT.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSwindlers are out there trying to sell us that bad weather is something new and happening because atmospheric CO2 concentration are “too high”. If only we paid carbon taxes and gave them more regulatory power, then we could prevent bad weather from happening and return to a Garden of Eden.
To some us all this sounds silly, of course. But many dimwitted people actually believe it.
Steve Goddard at Twitter brought my attention to the following newspaper clipping (I’ve cut and pasted piecemeal below) from the Perth Australia Daily News, dated 1936. As you will read, the scale of the disaster and the extremes are beyond anything we have ever witnessed today.




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->







Weather like we had back when CO2 was only 310 ppm? No thanks!
Source: http://trove.nla.gov.au/ndp/del/page/8424077?zoomLevel=1
Also read Europe’s disaster of 1540 here.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterPress release from the International Energy Agency
===========================================
Around $80 billion wasted on power for online devices in 2013
Simple measures can keep problem of inefficient ‘network standby’ from worsening in years ahead, IEA report says
 2 July 2014 Paris
Today, the world’s 14 billion online electronic devices – such as set-top boxes, modems, printers and game consoles – waste around USD 80 billion each year because of inefficient technology. By 2020, the problem will considerably worsen, with an estimated USD 120 billion wasted. But a report by the International Energy Agency points to a different path, identifying simple measures that can be implemented now to improve energy efficiency in networked devices, resulting in massive savings of energy and money.
The report, More Data, Less Energy: Making Network Standby More Efficient in Billions of Connected Devices, shows that electricity demand of our increasingly digital economies is growing at an alarming rate. While data centre energy demand has received much attention, of greater cause for concern is the growing energy demand of billions of networked devices. In 2013, a relatively small portion of the world’s population relied on these devices to stay connected. But energy demand is increasing as a growing share of the world’s population becomes wired and as network connectivity spreads to devices and appliances that were previously not connected, such as washing machines, refrigerators, lights and thermostats.
‘The proliferation of connected devices brings many benefits to the world, but right now the cost is far higher than it should be,’ said IEA Executive Director Maria van der Hoeven. ‘Consumers are losing money in the form of wasted energy, which is leading to more costly power stations and more distribution infrastructure being built than we would otherwise need – not to mention all the extra greenhouse gases that are being emitted. But it need not be this way. If we adopt best available technologies we can minimise the cost of meeting demand as the use and benefits of connected devices grows.’


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




As the report explains, much of the problem boils down to inefficient ‘network standby’ – that is, the maintaining of a network connection while in standby. In many devices, standby is a misnomer: it suggests that the device has gone to sleep and is almost off. In reality, most network-enabled devices draw as much power in this mode as when activated to perform their main tasks.
In 2013, the world’s networked devices consumed around 616 terawatt hours (TWh) of electricity, the majority of which was used in standby mode. Of that total, around 400 TWh – equivalent to the electricity consumed annually by the United Kingdom and Norway combined – was wasted because of inefficient technology.
‘The problem is not that these devices are often in standby mode, but rather that they typically use much more power than they should to maintain a connection and communicate with the network,” said Ms. Van der Hoeven. ‘Just by using today’s best available technology, such devices could perform exactly the same tasks in standby while consuming around 65% less power.’
The report describes technologies and technical solutions as well as a range of policy options that are available to reduce energy waste. It projects that if better energy efficiency measures were applied to online devices in the coming years, 600 TWh of energy would be saved. That’s equivalent to shutting 200 standard 500MW coal-fired power plants, which would cut emissions by 600 million metric tons of CO2
In the report, the IEA calls on policy makers, standards development organisations, software and hardware developers, designers, service providers and manufacturers to work together to reduce energy demand. To achieve this, the agency urges an international initiative to enhance standards, as the issue is global.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterYesterday I wrote here about how parts of Europe woke up to snow! Global warming alarmists have been telling us that winters would get milder and that spring would arrive earlier and earlier each year.
For example just two years ago Potsdam Institute for Climate Impact Research (PIK) scientist Friedrich-Wilhelm Gerstengarbe told German ZDF television that spring would be arriving earlier and earlier – because of global warming.
Unfortunately this is turning out not to be the case. The opposite is in fact happening.
Josef Kowatsch and Stefan Kämpfe at the European Institute for Climate and Energy (EIKE) write that spring in Central Europe has been cooling for almost 30 years now – and not warming – and it’s been arriving later and later.
To determine the spring trends, Kowatsch and Kämpfe looked at the mean temperature for February in Germany, which is a country that is ideally situated in Central Europe. Cold and snow at the end of February have a considerable impact on when vegetation starts to blossom. What follows is a chart depicting the February mean temperature for Germany over the last 28 years.

Figure 1: Data from the DWD German Weather Service show that the February trend has been cooling more than 0.5°C per decade over the last 28 years.
Figure 1 does not show any signs of spring coming earlier in Central Europe. The next chart looks at the Germany February trend for the last 22 years:

Figure 2: The 22-year February trend for Germany also shows a marked decline in temperature. Cold weather naturally acts to delay the onset of spring.
Kowatsch and Kämpfe write that if it were not for urban sprawl, the cooling trend would be even more pronounced:

Without population growth, industrialization and urbanization, the temperature measured today in Germany would be about 1°C cooler because almost every weather station is sited near the edge of a city or even in the city or airports. They are benefitting from various warming effects, which we will not look into in this article.”

The Germany February temperature trend for the last 17 years also shows a stark cooling:

Figure 3: Germany February temperature trend over the last 17 years.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Okay, February is only a single month that is crucial in determining how quickly spring in Central Europe gets started. Kowatsch and Kämpfe also posted the DJF winter temperature trend. Here we also see no warming over the last 28 years:

Figure 4: Winter mean temperature trend for Germany. Data taken from the DWD German Weather Service. We should be calling it cooling, and not warming!
How often do the German media show the above charts? Never. Kowatsch and Kämpfe write that the media have been warming-brainwashed, and the data clearly show that “spring has been starting later and later over the past 30 years“.
Not only do the temperature data show spring coming later and later, but so does the vegetation. Kowatsch and Kämpfe at EIKE provide the following chart:

Figure 5: Between 1990 and 2015 the budding of wild goose berries is now happening about 10 days later because the high winter months January and February (blue) have cooled. The green curve shows when the wild goose berries began to blossom, example in 2013 they did not blossom until after 1 April.
An analysis of the month of March in Germany also shows a cooling trend, Kowatsch and Kämpfe have determined:
 Figure 6: March mean temperature for Germany has fallen more than a degree Celsius over the last 27 years.
This year February and March have been relatively mild, but Kowatsch and Kämpfe write that they have been near the mean of the last 30 years. They also write that behavior of various animal species also show spring coming later.
They summarize:

Winter and pre-spring have gotten somewhat cooler since the late 1980s, especially February. The temperature trend lines are negative. Therefore the start of spring is currently being delayed and is coming later than the relatively warm 1990s.
Overall the start of spring 2015 is at the mean of the last 120 years and corresponds to claims made in the biological literature, spring literature, and in German spring songs.
After almost 30 years of winter cooling we see: In the open unbuilt areas of Germany, where today there are no longer any weather stations, the following remains valid: Spring awakens in March. 
Spring awakens in March as it did 150 years ago at the end of the Little Ice Age.”


Share this...FacebookTwitter "
"
Share this...FacebookTwitterA few days ago I wrote about how Google was researching into changing how it ranks websites during searches, claiming that the aim was to give sites that are loose with the truth a lower ranking and to favor sites deemed to be reputable.
But the possibility of abuse in such a system is worrisome.
So I asked some leading climate figures by e-mail what they thought and have gotten some responses. Here’s what they wrote (some editing):
Prof. Nir Shaviv (astrophysicist)
It is just a research project. The Fox News article says ‘A Google spokesperson told FoxNews.com that the fact-based-rankings are, at this point, just a research project.’
I can’t imagine Google will do anything like that. It is so wrong on so many levels it would be shooting themselves in the leg.”
Lubos Motl (physicist):
I don’t believe that it’s technically possible to design an algorithm that could reasonably accurately assign the truth value to all pages on the Internet (it’s just very hard to evaluate all the billions of statements that are out there – quite often, one really knows the answer) – I would be impressed if they proved me wrong; and I don’t believe that Google will impose filters that would selectively and significantly skew results in a direction that is political.
I don’t believe that Google plans to suppress or eliminate skeptical blogs about the climate from the rankings, and I don’t even think that this follows from any media reports on Fox News or elsewhere, so I view these fears as nut job conspiracy theories.
It’s my belief that they’re doing a good job. Some said that the solution to these censorship fears (which seem unjustifiable to me themselves) is to create a competition to Google, or something like that. Even if some folks in Google have politically extreme, left-wing opinions etc., they’re still primarily a technological company that has done amazing things that even some of the best people in big competing companies such as Microsoft couldn’t have matched (and I am a fan of Microsoft). Of course if Google searches turned out to be unusable due to political censorship or something like that, people like me would try to switch to a competition.
Google is an extremely important company and it is assessing its importance sensibly. Generally I am not going to join the bashing of Google based on conspiracy theories. My cooperation with the company (talking about AdSense) has been good for many years and as an ordinary user, I am impressed how many services Google has done for the users basically for free. Even if they wanted to use their search engine to push politics or the climate debate in some direction, they clearly have the right to do so, but because it would mean to throw away the value of the company which has grown into a rather standard corporation, I don’t believe that it will really take place, regardless of the opinions of some officials at various places.
Dr. Holger Thuss (President of EIKE)



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Without a doubt, there are a lot of lies out there. However if Google really thinks a truth formula is the right way to promote ‘truth’, it will backfire on them because there simply is no such thing as absolute truth. Hence I believe this step would be entirely unnecessary. It will not stop promoters of ‘inconvenient truths’ such as climate realists from doing what they are doing, and it would cost Google large parts of its credibility. On the other hand, it would slow down important political and scientific debates. I also don’t see how, in the future, Google will convince organizations to pay for its advertising services if its reputation is damaged and people go away to other search engines. Nobody likes to listen to truther organizations.”
Dr. Benny Peiser (Chairman, GWPF)
I very much doubt that Google will implement the proposal to rank websites according to their “truthfulness.” Such a potentially self-destructive move would make Google look like George Orwell’s ‘Ministry of Truth’ who was responsible to falsify historical events or rewrite predictions. One only has to think about the way Google would deal with Michael Mann’s ‘Hockey Stick’ and the elimination of the Medieval Warm Period from history to realise the potential for abuse and manipulation.”
Dr. Hans H.J. Labohm (Dutch publicist)
Nobody should claim to possess the monopoly on truth. Therefore let people decide for themselves what information they deem trustworthy. And remember: ‘Du choc des opinions jaillit la vérité!’ Consequently Google should drop this initiative and bury it, covering it with a tombstone with the inscription: R.I.P.
Dr. Sebastian Lüning (Die kalte Sonne)
 Who would be the referees in this process, and how impartial could they be?
Dr Sonja A Boehmer Christiansen (Editor, Energy & Environment)
On whether Google would be able to control the Truth:
NO that would take a long time to emerge if ever…many scientific disputes took centuries to be resolved. Truth is likely to establish itself, temporarily, if combined and advertised in combination with solutions, like AGW.
There are short-term truths of course, what people act on in the hope that it is the truth, but then they usually have another motive to back up the truth like greed, personal advantage, getting research funds, pleasing ‘mates’. If they went ahead, they would be taking on a divine role. A warning!”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMany readers and myself have become quite dismayed by the Vatican’s new position on the junk climate science-based, anti-humanity movement against fossil fuels.
Interestingly today I read a report in the Catholic Herald here where it is clearly miffed by how Britain’s UKIP party “now commands the support of an estimated one in six Catholics” and is “causing increasing alarm among Church leaders.” My, how could that be!
Well, we all understand that things move glacially slow at the Vatican, and we don’t expect them to see the light any time soon, even though it’s staring at them straight in the face. These things can take centuries.
Catholics reject intolerance and hatred
One reason Catholics are rejecting the positions held by the Church is no better illustrated than by the following article appearing in the The Daily Mail:
I’ve never supported the British National Party or the Ku Klux Klan. I’ve never belonged to the Paedophile Information Exchange, or denied the Holocaust, or made a penny from the banking crash.
But if you read The Guardian newspaper’s website, you might think otherwise. A commentator on it urged my own children to murder me.
He did so because of one of the many stories I’ve written for this newspaper about climate change. I first reported on the subject nearly six years ago: my article was about the ‘climategate’ scandal, where leaked emails…”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




[…]
…”But ultimately, where are they taking us? Citing climate change is certainly an effective way of making schoolchildren feel fearful and guilty, much as preachers once used to.”
Read more at the Daily Mail.
Leaders will have to learn to face one fact: thanks to the Internet followers are much better informed today and many can see the cliff up ahead which their leaders are blindly leading them to. The Catholic Church is part of that green movement.
Catholics want nothing to do with and are appalled by the hate and bigotry that gets aimed at honest dissenters such as David Rose. And we reject the deception-riddled plot to deny the world of life-giving fossil fuels as well as the mentally ill hysteria of a world coming to an end.
If anything what we need is an encyclical on the necessity of fossil fuels.
It’s truly stunning that the Church can be so tolerant of the bigotry and intolerance on one side of the debate, yet be so quick to condemn honest dissent on the other.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe online center-left Die Zeit features an interview with Prof Hans von Storch, Professor at the Meteorological Institute of the University of Hamburg and Director of the Institute for Coastal Research at the Helmholtz Research Centre in Geesthacht, Germany.

Hans von Storch photo credit: European People’s Party, licensed under the Creative Commons Attribution 2.0 Generic license
The focus was on mainly storm activity and its possible link to man-made climate change.
In the end the very green-oriented Die Zeit did not get the sound bites it likely had hoped to get.
All within natural varibility
In the interview, in response to the question of storm frequency and intensity, von Storch, a renowned climate scientist with 40 years of experience, says:
We see no intensification in storm activity at our latitudes, and our climate models also indicate that we cannot expect it.
Also since 1950 they have not become systematically more frequent or stronger. Therefore we believe that Christian [October 2013 North Sea storm] moved within the range of normal variability.”
Von Storch also tells Die Zeit that storms do not occur with a rather regular periodicity, saying that “sometimes there are decades when they rumble a lot, and some decades when they don’t.”
The north German professor also tells Die Zeit it is very difficult to make comparisons between the storms of today and those of decades ago because the data recorded back then are nowhere near as complete:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




If you simply compared the pressure values with those from a few decades ago, then you would reach the conclusion: Yes, the storms have become more powerful. But that would be a faulty conclusion.”
The reason for this, von Storch explains, is that the measurement of the storms core pressure was very inadequate and readings were often taken by ships that were not located near core of the storm. Today satellites provide very reliable data for comparisons.
Climate models do not indicate future intensification
On the future of storms and increased intensity, von Storch tells Die Zeit no one can rule it out, of course, but thinks it’s “implausible“. “Our climate models do not lead us to expect it.”
Von Storch also cautions against putting too much emphasis on model results:
Ultimately, however, observations and not climate models decide. We always have to expect that we will know the truth only afterwards. We can’t predict everything with certainty.”
“Pause” has led to more attention on natural fluctuations
Next Die Zeit looks at the warming pause, which it writes it has been confirmed “by some scientists” and asks if the “pause” has ended. Von Storch replies:
At least one finds no strong evidence showing that the long-term warming pause in the climate system has ended. The debate over this postulated ‘pause’ in the end has had a good side: Natural fluctuations have gotten more attention. We understand the climate a little bit better.”
In summary, von Storch sees 1) no data supporting a trend of stronger, more frequent North Sea storms, 2) models do not show an increasing trend, 3) recent storms have been within the range of natural variability, and 4) the pause has been substantial enough that it has shifted more focus onto natural factors.
The AGW theory of catastrophic warming has taken a significant blow.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThis story is a perfect illustration of how today’s journalists will print anything they told by swindling climate scientists.
==========================================
Bremen’s Weser Kurier daily is very sure: “Climate change is damaging organs”
By Sebastian Lüning and Fritz Vahrenholt
(Translated, edited by P Gosselin)
The newspaper of the German port city of Bremen, the Weser Kurier surprised its readers on September 8 with almost unbelievable news:
Climate change is damaging organs
It sounds like a paradox, but the consequences of climate change were visible to see with the St. Andreas Church organ a few weeks ago. ‘The instrument was beset by mold and mildew“, says organ builder Martin Hillebrand from Isernhagen. For about six weeks he and his team have been working in the church to meticulously clean the organ and to fine-tune the pipes.”
We already suspected climate change for many things, but its role as a vandal of church organs is something new. So how does it cause mold and mildew to infest the organ? How does that work? The Weser Kurier tells us:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The mold infestation in the instrument is not a single occurrence – quite to the contrary. According to Hillebrand about 70 percent of the organs in so-called village churches are under attack. ‘This involves mainly churches where the people congregate for mass only every other week or less often. These churches are thus heated less and so in the wintertime they quickly become very prone to moisture,’ said the expert. Fungus attacks are also helped by warm, moist climate in the summertime. ‘Research instituites have shown that this and the relative humidity will increase in the future,’ says Hillebrand.”
So it’s not really due to climate change, but moreso people are going to church less and less? Those who do not heat have to expect mold – that’s been a well-known rule for a very long time. Warm, humid summers in Germany are also known. In summer it’s warm, and in winter it’s cold. What’s new? Only the relative humidity remains. Has it really risen over the last decades because of climate change? Here we take a look at the data from Braunschweig at the norddeutschen Klimamonitor website (Figure 1).
Oh dear, the relative humidity has actually trended downwards over the last 50 years. Climate change is not guilty! The problem actually appears to be caused by the lack of heating in churches, which promotes mold infestation. The climate-activist Weser Kurier once again regrettably has told its readers nonsense. The editors would surely welcome some letters from readers. Here is their contact page.

Figure 1: Trend of relative humidity in Braunschweig. Source: norddeutscher Klimamonitor.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMany of us are familiar with climate jihadist/ambassador Leonardo DiCaprio’s über-hypocritical lifestyle of cruising on billionaire mega yachts, private jets and living in huge mansions. Well, it doesn’t end there by any means.
There are times when DiCaprio actually has to slum it, and put up with travel on the road, along with the rest of the world’s lowly mortals.
To help the Hollywood superstar cope with such horrible hardships, a “rolling palace” gets used, this according to Steve Austin of WQYK here. Hat-tip Graeme No.3.
DiCaprio’s monster-size vehicle is reportedly supplied by KING KONG Production Vehicles Inc.
According to the company, it is a 53-foot “celebrity suite” that includes extra capacity air conditioning and heating systems, large hot water heating system, heated floors, fireplace, home theatre, and plasma TV. According to the KING KONG website:
No expense will be spared on the luxurious interior, with only the finest fabrics, fixtures, appliances and floor coverings hand picked by our interior designers.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




These are precisely the sorts of things the rest of the world’s citizens are to shun if there is any chance of rescuing the planet. The following YouTube video unabashedly boasts about all the features the rolling palace sports, such as a $50,000 shower!

The total price tag for the “celebrity suite” is $1.5 million and probably consumes by itself as much energy (diesel fuel) as three American homes. And even if it did use renewable power, the manufacture and transport of all the components to assemble the palace leaves a carbon footprint that is as big as a crater.
What’s really amazing is that DiCaprio expects us to take him and his planet-saving message seriously. It’s all worse than a B-rated comedy.
These people are truly spoiled phonies with a few loose screws.
Also read here bikinis and boats.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn Germany protests over a broad range of issues have been heightening.
In Dresden citizens have been turning out by the thousands in “Monday demonstrations” to protest the perceived threat of the Islamification of Europe and the so-called “liar media”, which they no longer trust. Since the Paris attacks by radical Islamic terrorists, the protesters have only become more emboldened.
Citizens are also clearly beginning to feel they are being misled by the “liar media” and politicians regarding wind energy. The glaring difference between what was promised and what is actually being delivered can no longer be ignored. Enough is enough!
Germany’s online SVZ.de writes that the “conflict over wind turbines is escalating” and that “criticism and fears are becoming louder” and that “citizen protest groups are forming at many locations“.
What does it mean? It means that wind and solar power are nothing like they were once cracked up to be. They are poor performers, costly, and are creating a nationwide blight that risks permanently scarring Germany’s once idyllic landscape and natural heritage.
Everything and anything can now be sacrificed at the alter of climate protection. Recently Die Welt published a scathing commentary on the “immensely dangerous power of the eco-cartel“, writing that “totalitarian undercurrents are plainly visible” and that the movement is all about power and money, and less so about environmental protection. Germany’s green movement has been corrupted to the bone.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the state of Mecklenburg-Pomerania the SVZ.de site writes how an organization called Freier Horizont was established last November and serves as the umbrella for 40 citizens initiatives. “They are protesting against what they see as the uncontrolled expansion of wind energy and speak of horror landscapes.”
Freier Horizont Chairman Norbert Schumacher worries that wind energy will have negative impacts on the region’s coastal tourism. Citizens are concerned that Germany’s cherished Baltic Sea coast will be “blighted” and believe political leaders and wind energy developers are not taking their concerns seriously.
They aren’t, of course. It’s all about money. Even the most self-professed Greens are selling out to the big money of wind energy. For example Die Welt writes of German Green Party honcho Boris Palmer, someone “who grew up protesting the installation of power transmission towers is – no joke – demanding that natural parks and reserves be opened for the 200-meter tall rotating monsters, even if they are located right next World Heritage Sites.”
Greens like Palmer no longer have qualms about that, and so it should not surprise us that they are ready to trample and permanently damage heritage locations – e.g. like the Nazca Lines in Peru. It’s all in the name of the Green Allah: Climate Protection. Green madness has taken over in Germany, but citizens are waking up.
=======================
German readers may wish picking up a copy of “Alles grün und gut? Eine Bilanz des ökologischen Denkens“, by Dirk Maxeiner and Michael Miersch.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA recent publication in Nature purported it had finally detected the radiative forcing of increasing atmospheric CO2.
German physical chemist Dr. Siegfried Dittrich slams the media’s assertions of proof that CO2 was guilty of the warming, claiming they are faulty and that they were passed on uncritically by German news weekly FOCUS ONLINE. Here’s the translation:
==================================
Climate Warming From Carbon Dioxide?
By Dr. Siegfried Dittrich, on the DPA German News Agency release appearing at Focus-Online 27 February 2015: “Climate warming through carbon dioxide: The proof: CO2 is indeed guilty of the greenhouse effect“.
‘The real guilt by CO2 for the greenhouse gas effect is finally proven.’ This was the subheading of a DPA release appearing at FOCUS Online on 27 February.
Later in the text it is written: ‘For the first time we are seeing the enhancement of the greenhouse effect in nature’, and at the Hamburg-based Max Planck Institute for Meteorology it was gleefully added that finally also the magnitude of the anthropogenic impact has become visible.
It all goes back to the latest surface radiation measurements recently published in an essay in Nature (details here and here). However no one seems to have noticed that the measurements actually showed the exact opposite of what is claimed to have been proven above, namely nothing other than what serious climate critics have always been saying about anthropogenic greenhouse effect.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The number for the increase in CO2-dependent back radiation given by Nature of 0.2 watt/m2 per decade is indeed in reality nothing more than trifle. Why would the earth be shocked when 1367 watts per square meter strikes the surface at noon along the equator? The ever-changing deviations from this so-called solar constant mean value are in fact considerably greater than the above given 0.2 watts/m2.
According to the IPCC, the surface radiative forcing increase in the event of a doubling of atmospheric CO2 concentration is exactly 3.7 Watt/m2, a figure that has been independently confirmed on multiple occasions. Over the last decade the atmospheric CO2 concentration increased some 20 parts per million. Currently it stands at about 400 ppm. Here any undergraduate student is able to compute that the resulting surface radiative forcing increase is approximately 0.2 watt/m2, which has been confirmed by the above mentioned measurements.
Also the resulting global temperature increase can be computed using one of the IPCC equations, which also can be derived from the Stefan-Boltzmann radiation law.
In Nature it is expressly remarked that the measured difference in surface radiative forcing of 0.2 watt/m2 is solely for cloud-free zones on earth. With an average 40% cloud cover and a 30% overlap between the present water vapor and CO2 absorption spectrum, the above calculated temperature value gets reduced from 0.06°C to 0.03°C. Here in reality we are talking about an effect that is barely measureable, and one that has no dramatic impact when combined with the fictional water vapor amplification, which incidentally the superfluous ‘Energiewende’ is based on ad absurdum. It is more than regrettable that FOCUS uncritically passed on these misinterpretations. A correction should be made immediately.
Dr. rer.nat. Siegfried Dittrich



Share this...FacebookTwitter "
"
Share this...FacebookTwitterSo much for Germany’s transformation to “green” energies.
Germany’s Bun­desnet­za­gen­tur (Federal Network Agency for Electricity, Gas, Telecommunications, Post and Railway) is the federal authority overseeing and regulating the German electrical power grid, among other networks.
At its site it has a link to an expert assessment report that analyzes the needs of and risks to the German power grid for the coming 2014/15 winter.
The name of the report: “Examinations for the winter of 2014/15 with respect to risks for system security and the necessity for reserve power plants”.
The 102-page highly technical assessment examines a variety of scenarios in order to see how well Germany’s electrical power grid will hold up this winter. Looking at the report’s conclusion, one can only conclude that the power grid is more unstable and prone to a collapse than at any time in Germany’s post-war period. It’s a debacle knocking at the door.
In the summary on page 97 for example it writes (link added):
Scenarios were parameterized on the basis of historical data and realistically form expected critical situations, but do not necessarily show the worst-case scenario.
Considered scenarios show massive threats to the security and reliability of the electric power supply system which are not manageable without a substantial intervention by the ÜNB and the use of a secured redispatch-potential.
There are no safety reserves for managing additional critical or unexpected situations.”
On page 98 the report re-emphasizes.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In critical situations a substantial threat to system security is to be feared.”
The report’s summary adds: “Ssecure management of the expected critical situations requires comprehensive measures.”
This all means that on a cold winter day, Germany’s power grid could could very well collapse and citizens be left in the cold and dark for hours or even days. Parts of the report have been blacked out, which is hardly reassuring to the reader.
So why has Germany’s power grid, once one of the world’s most stable, become so vulnerable? An editorial piece at the Financial Times sums it nicely. It writes: “Merkel’s decision to phase out nuclear power has been a huge mistake.”
The FT piece writes that Germany has added a huge amount of intermittent wind and solar energy. Not only does this energy act to destabilize the power grid, but it also is costing German citizens and the economy a bundle. What a bargain: Poor quality for high cost! The FT writes that the Energiewende is “designed to make the economy predominantly dependent on renewable sources such as wind and solar power“, and adds that these are “burdens on households and businesses“, something that “Germany can ill afford”, the FT writes.
What’s worse for clean-energy-minded Germans is that the elimination of nuclear energy has led to an increase in coal burning. In the end, Germany’s power system is now dirtier, more unstable than ever, and now costs consumers far more. Does that sound like a great deal? Sounds to me like a monumental mismanagement.
Those of us living in Germany may want to consider installing a wood-burning stove in the weeks ahead as winter quickly approaches.
Hat-tip: 2 readers
Share this...FacebookTwitter "
"
Share this...FacebookTwitterJosef Kowatsch and Stefan Kämpfe at the European Institute for Climate and Energy (EIKE) analyze the winter data from Germany’s DWD Weather Service an conclude that winters have been cooling.
The two authors present a lengthy analysis of German winter trends and what factors impact them the most. Today I will focus on the first part of their article, i.e. winter trends in Central Europe – mainly Germany. What follows is an abbreviated summary version.
Because of Western Europe’s proximity to the Atlantic, mild winters are nothing unusual and have occurred many times in the past. Two mild winters in a row occurred from 1909/10 to 1912/13, 1918/19 to 1920/21, 1934/35 to 1936/37, 1947/48 to 1949/50, 1987/88 to 1989/90. The article by Kowatsch and Kämpfe looks at if German winters are really getting warmer and less snowy, as is frequently claimed. They are not.
Now trend in snow coverage
An important indication for the character of a winter in Germany is the number of days with a snow cover on the ground that is at least 1 cm. That can be traced back thanks to the records of the Potsdam station, which goes back to 1893/94. There snow can fall already in October and well into April, and so it makes sense to look at the seasonal snow coverage days, where by the season goes from October 1 to April 30:

Figure 1: The number of snow coverage days – which fluctuates wildly – has been unchanged over the long-term. There’s no indication of reduced snow coverage days for Potsdam. The low snow year 2014/15 in the German lowlands is not included in this chart; yet it will show significantly more snow coverage days than the extremely low snow winter of 1974/75. (Source: PIK).
When one considers only the meteorological winter (DJF), no trend is detectable for snow coverage. However there are periodic fluctuations (Figure 2):

Figure 2: In the 1910s to the 1930s 1910er as well as at the end of the 20th century, there were generally fewer snow coverage days, instead the winters were wetter, milder. (Data source: PIK). 
Over a large regional scale (entire northern hemisphere) reliable data on snow cover are available since 1967. During this almost 50-year period snow coverage fluctuated strongly, yet there is no declining trend:

Figure 3: Since 1967 there has been no reduction in wintertime snow cover days over the northern hemisphere (Source: NOAA).
German winter temperatures – cooling!
Next we will look back at German winters over the past 28 and 18 years, and do so without considering the urban heat island effect despite the ongoing landscape alteration by man: Every day some 108 hectares are being built upon in Germany and thus creating growing heat islands around temperature measurement stations.
Germany’s winter of 2015 is currently pegged by the German DWD Weather Service as being 1.8°C above normal. Thus it’s the second warmer than normal winter in a row. However, the German DWD neglects to tell the public one thing: Over the long-term winter temperatures have dropped. It’s getting colder. See Figure 4. Data come from the German DWD Weather Service in Offenbach.

Figure 4: Winter temperatures have been falling in Germany for almost 30 years. The two recent mild winters have not changed that trend.
Result: Despite the alleged “global warming”, which is supposed to make itself evident especially in the winters, German winters are ignoring the forecasts made by the so-called climate scientists. It’s going to take an impressive series of mild winters just to flatten the trend.
This is proving to be terribly inconvenient for climate scientists who banked on warming. In the meantime cooling phases are being ignored, or data are even being falsified.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




With the German winter temperature, the trend downwards would be even steeper if the UHI were properly accounted for. Yet, already some scientists are seizing upon the fact that the last 2 winters have been mild as “proof of warming”.
Next the single winter months (DJF) are examined individually (all data come from the DWD). Here’s December for the last 30 years:

Figure 5a: The trend is slightly downward, mainly owing to the especially cold December of 2010.
If one factored in the UHI, then the trend would be even more pronounced.
What follows is the 28-year trend for January:

Figure 5b: January has gotten markedly cooler over the years.
January also shows no warming in sight. One finds warming only in the climate models, and nowhere else. The next chart depicts the trend for February:

Figure 5c: Here the downward trend is unmistakable.
The February trend tells us one thing: Springtime is not arriving earlier. February 2015 in Germany was just a bit above normal.
Fairy tale models – truth being covered up
Kowatsch and Kämpfe summarize: “Winter in Germany is taking on a course of its own and is ignoring the forecasts made by the IPCC and the PIK. Warming? Where? In any case they are not to be found in German winters.” The two authors ask:

Where is the global warming which we are supposed to be massively combatting in Germany over the last ten years? Foremost the winter months were supposed to especially warm up. We were warned that there would be no more snow in the flatlands and that winter sports would be possible only at high elevations. […] It turns out these were forecasts from the category of Germany fairy tales. However, what’s worse is that this truth is being covered up and hidden from the German public. Not a single one of our charts is being shown by the media.”

No warming in Central England in 30 years
Kowatsch and Kämpfe also show the same is true in Central England; no temperature rise in 30 years:

Figure 6: No increase in 30 years, which is a climate-relevant period.
Tomorrow I will post on the factors that Kowtsch and Kämpfe say drive western European winters: Ocean cycles (and not Arctic sea ice).

Share this...FacebookTwitter "
"
Share this...FacebookTwitterNow climate politics are becoming a real threat to the very defense of our freedom, democracy and western civilization.

The real enemy, according to some German politicians, activists. Copyright: Eurofighter, Geoffrey Lee, Planefocus Limited.
Germany’s socialists, pacifist greens and anti NATO activists (who are well represented in German government) have found a new excuse for shirking their NATO defense responsibilities and reason for shutting down important military operations thus unwittingly playing into the hands of our enemies – many of whom are at Europe’s very own doorstep!
“Eurofighter Typhoon is a climate-killer”
Their latest claim: “the Eurofighter Typhoon is a climate killer” and so it needs to be grounded. Protecting the climate is much more important than defending the freedom and democracy of the very citizens they were elected to represent.
According to the doomsday-obsessed, leftist Klimaretter here: the Eurofighter’s CO2 footprint is intolerable and represents a real reason to stop its use. It writes: “For the climate the Eurofighters are real poison.”
Klimaretter explains how leftist Parliamentarian Eva Bulling-Schröter sent a query to the German government concerning the Eurofighter Typhoon of the 74th Neuburg Fighter Wing in Bavaria on July 16, 2014. The German government in turn sent its reply on July 31.
Of fourteen questions three are of particular interest: Nos. 3, 4, and 7.
3. How high was the fuel consumption (kerosene) of the Neuburg Fighter Wing in 2013?
In 2013 at the tactical 74th Neuburg a.d. Donau Fighter Wing, 12,751,000 liters of jet fuel were given out to the EUROFIGHTER. That is an equivalent of approximately 10,200 tonnes of jet fuel.
4. How high was the CO2 emission of the Neuburg Fighter Wing in 2013?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Based on the fuel consumption of then tactical 74th Neuburg a.d. Donau Fighter Wing in connection with the average conversion factor for kg jet fuel to emitted kg CO2 of 3.15, in the year 2013 approximately 32,130 tonnes of CO2 were emitted.
7. How high was the CO2 emission of the “Eurofighter” weapon system per flight hour?
One EUROFIGHTER per flight hour needs average 3.5 tonnes of fuel. Using the conversion factor of 3.15 for kg jet fuel to emitted kg CO2 yields an average CO2 emission per EUOFIGHTER flight hour of approx. 11 tonnes.”
Klimaretter promptly points out that flying a Eurofighter for a single hour produced as much Co2 as one citizen does in an entire year. It adds:
‘The Eurofighter weapons system is also a climate killer as the fighter jet emits as much carbon dioxide as a German citizen does in one year,’ assesses Eva Bulling-Schröter the results of her query. ‘Weapons only bring death and suffering; they also damage our environment and climate.'”
When compared to global natural and man-made total emissions, the 10,000 tonnes emitted by the Eurofighter is a mere drop in the ocean, and theoretically has an impact on the climate than can be measured only in pico-degrees.
Klimaretter does not stop at pushing for a grounding of the Eurofighter at the Neuburg base, but even implies that the military all over the world contributes substantially to climate damage, posing the question under the photo it posted:
US American soldier in the Iraq War: Just how much the military contributes to climate change worldwide has been hardly studied so far.”
Yes, this needs to be studied, the leftists are demanding. And should the military emit too much CO2, then it too will have to be grounded all over the world.
Oblivious to gathering threat from extremists worldwide
Indeed Islamic fanatics, the ISIS, Taliban, Boko Haram, Russian rebels and a host of other menacing threats to our western civilization and freedom probably could not find better, unwitting allies in Germany than the leftwing socialist/green parties – and kooky climate-doomsday websites like Klimaretter.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterToday parts of the German mainstream media have begun reporting on the 9th Extreme Weather Conference in Hamburg, which began today and is slated to end on Friday. The direct link to the program-pdf here. Of course the focus of the Congress will be on the claimed “increasing frequency of extreme weather events”.
In all 3000 experts are attending, along with 2500 Hamburg school pupils.
What especially raises eye brows is the fact that the event is sponsored by the Munich Re reinsurer, the biggest in the world. The Munich-Germany-based reinsurer of course stands to profit handsomely from the spreading of extreme weather fear; it makes it it a lot easier to jack up premiums (see “Spiegel Online doubts the catastrophe scenarios of the Munich Re“).
Also very murky is the identity of the organizer of the Congress: Institute for Weather and Climate Communication” (IWK). At their Die kalte Sonne website here, German skeptics Sebastian Lüning and Fritz Vahrenholt looked into who is behind the mysterious IWK? They write:
The result is sobering: Apparently the institute really does not have its own Internet platform. So we took a look at the legal page of wetterspiegel.de. Here indeed the “Institute for Weather and Climate Communication GmbH” is given. Listed as the managing directors are Frank Böttcher and Alexander Hübener. Frank Böttcher? Indeed we’ve written about him as well: “Extreme weather “expert” Frank Böttcher does not not know about the latest literature: Latest research results on global cyclone activity are damaging is climate-alarmist business“. Without climate fear and extreme weather alarm, the number of visitors for the commercialized Extreme Weather Congress would certainly be limited. Thus it’s little wonder that Böttcher, because of promotional reasons, is fervently preaching climatic doomsday to attract visitors into his auditorium.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Lüning and Vahrenholt also look at a list of persons slated to appear: “Paul Becker of the German Weather Service, a climate alarmist to the bone. Peter Höppe of the Munich Re reinsurer will attend the introductory press conference, thus getting his sponsoring money’s worth.”
No skeptic was invited to the present at the Extreme Weather Congress. For the second year in a row Lüning and Vahrenholt were denied the opportunity to present there.
Vahrenholt and Lüning also ask themselves whether Mojib Latif will be able to muster the courage to disclose some inconvenient things that up to now he only has quietly admitted in the scientific literature. See “Mojib Latif: the proof of an anthropogenic climate contribution is difficult because the natural ocean cycles dominated” and “Mojib Latif in the presentation in USA: CO2 sensitivity was set too high by the IPCC“.
There is a bit of hope: “honest broker” and alarmism-critic Hans von Storch has also been invited, and so maybe he will infuse a little sobriety into the Hamburg climate panic-fest, see “Climate scientist Hans von Storch: Climate models possibly do not take solar activity sufficiently into account” and “Judith Curry prognosticates warming pause until the 2030s: Hans von Storch in such a case demands a vote of no-confidence against CO2“.
Overall, however, in view of the sponsorship by the world’s biggest player in the re-insurance industry, the murkiness surrounding the event’s organizers, and their exclusion of scientists with other views and data, the event has everything to do with serving corporate special interests rather than those of science.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterScreaming bloody murder over nothing? Keep in mind that RSS recently released the satellite measured global temperature for 2014 and found it is not even close to a new record. Three days ago one of Germany’s leading climate science sites Science Skeptical issued the following comment.
============================
Global Temperature Record 2014?
By Michael Krueger
(Translated, edited by P Gosselin)
A new temperature record for Germany has been announced by the DWD German Weather Service. With 10.3°C the warmest year since 1881 has been measured. Here are the facts.
2014 was the warmest year in Germany since 1881, but the warmest 12-months occurred from July 2006 to June 2007 with a mean of 11.3°C. Therefore the annual mean for 2006/2007 as 1°C over the current annual mean.

Chart depicts Germany’s temperature since 1761. Rose line is the annual mean temperature and the dark red line depicts the 5-year smoothing. 
Moreover since 2000 Germany’s temperature has barely risen – in contradiction to atmospheric CO2 concentrations.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




How does the global temperature appear?
There are different datasets available for global tempertaure. I’m selecting the most alarmist, which comes from NASA. The gray shading shows the monthly mean values and the red curve is the smoothed annual mean (over 12 months).

Since 1880 the global temperature has risen about 0.8°C, i.e. not even a full degree. Since 1998 (a powerful El-Nino-year) there’s been practically no rise. What follows is a blow-up for the recent period.

In 2007 and 2010 it was just as warm as in 2014, or even warmer. We’re talking about 1/100 °C, which is deep inside the range of uncertainty. Yet the concentrations of atmospheric CO2 continued their steady rise. Based on these data, spreading climate alarmism is complete hyperbolism.
Very likely in the days ahead NASA will be announcing a global temperature record that in reality never was.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNew paper by Brandt et al on increased precipitation has been greening the Sahara since 1980. Yet another IPCC model projection that is headed off in the wrong direction. Hat-tip DkS.
Press Release No. 121/2014 of the University of Bayreuth, Germany  dated 30 June 2014. My emphasis:
==============
New research works show: Not global climate change alone, but rather foremost the local actions of people impact the face of the environment
Are the earth’s deserts continuously expanding? Or is green vegetation now spreading into regions that were once barren deserts? The West African section of the Sahel zone located at the southernmost edge of the Sahara, which extends from the Atlantic to the Red Sea, has been the source of reason for a wide variety of prognoses over the recent years. Extreme periods of drought during the 1970s and 1980s were considered as indices of growing desert regions across the globe. “Desertification” was the buzzword. However, over the last two decades a rise in precipitation has been observed across the West African Sahel. As a result there has been talk about the blanket perception that “the desert is greening”.
With this controversy as the backdrop, an international research team led by geographer Martin Brandt of the University of Bayreuth examined the vegetation development in the West African Sahel more closely. High and coarse resolution satellite data as well as wide range of measurement results from the last decades enabled conclusions to be drawn on climate and vegetation trends and field research brought regional and local particularities to light. Here some determinations were made: There is no uniform development in the West African Sahel. Not only the climate but also especially various forms of land-use – farming, forestry management or village development – are mostly responsible for the way the landscape there appears, and which resources it offers the people.
In the journal “remote sensing”researchers from Bayreuth (Germany), France, Spain and the Senegal report on their results. “The activity of man on location, for example the sustainable cultivation of selected green plants or the reforestation of forests, can impact the face of the landscape considerably,” says Martin Brandt. “Such initiatives and measures by the local population are far less dependent on large-scale climatic trends than what was earlier assumed. For this reason environmental and climate research should not be one-sidedly guided by blanket buzzwords such as ‘desertification’ or ‘greening Sahel’.”
Regional differences due to land and forest management – case studies in Mali and in the Senegal
Thanks to  satellite time series analyses , the scientists were able to determine that the vegetation density in the West African Sahel increased from 1982 to 2010. This development is especially pronounced in the Senegal and in western Mali. Here there are clear regional differences with respect to plants that have multiplied over time: Not only does one observe the wild growth of trees, bushes and grass, but also foremost the expansion of crops and plants due to farm and forest management measures. In total one notices that in the West African countries, with the exception of Gambia and the Ivory Coast, the forest levels have decreased markedly even though the vegetation density has increased as a whole.
The field research work by Martin Brandt (left) concentrated on two regions: the Senegal and Mali: The region surrounding the city of Bandiagara in southern Mali has seen a complete transformation of its vegetation over the last 50 years: Many tree and bush types that were still common in the 1960s have disappeared. Periods of drought did not alone damage the plants through a lack of water, but also it was because income from agriculture fell due to poor harvests, and so the people tried to compensate by felling trees and selling lumber. However in the meantime, a vegetation-rich landscape has since appeared – and not only because the precipitation amounts have been increasing for two decades and extended periods of droughts have failed to occur. “A targeted reforestation and planting of trees on agricultural land have changed the landscape considerably,” reports Brandt, and adds: “Without a sound botanical and ecological knowledge by the local population, this development would not have been possible.”
The transformation to an agricultural landscape  was also found by the scientists from Bayreuth at another region – one located in the Senegal, north of the city of Linguère. This region is mainly settled by nomads belonging to the Fulbe ethnic group who practice intensive pasture farming. In order to feed their livestock with leaves during dry periods, they cut or fell trees and bushes during dry periods. Nevertheless, state-sponsored reforestation and protective measures have led to a considerable increase in vegetation over the last two decades and it has become more adaptable to climate fluctuations. Today three especially robust tree types make up more than 90% of the vegetation found in the region surrounding Linguère. “Alone in the immediate proximity of the city there is a fenced-in area of at least 5000 hectares on which a special species of acacia has been placed,” says Martin Brandt. However he also points to the unmistakable damage in some places arising from the overuse of the tree stock. This completely bare ground is very difficult to regenerate – an example of how intervention into the vegetation by man can be destructive when it is not approached with ecological farsightedness.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Intervention by man stimulates a differentiated agricultural landscape – Plea for research without blanket buzzwords
The newly published scientific results refute the claims that the West Sahel is being hit by a growing desert that is a consequence of a global climate change. However they also refute the suggestion that the “greening of the desert” will take off by itself due to the increasing annual precipitation. The moderate trend reversal after a severe period of drought indeed does entail an increase in vegetation density. But it neither means a return to the conditions that existed before these extreme climatic events, nor does it automatically mean a widespread growth of green vegetation. Moreover, anthropogenic factors – and conversely their absence – have had a decisive impact on landscape and vegetation. Targeted farm and forest management measures that are oriented on scientific knowledge can significantly foster a differentiated man-made landscape.
Martin Brandt, who will soon receive his doctorate at the University of Bayreuth, also here sees reason for hope: “Should the climate prognoses of the UN IPCC do come true, the living conditions in some arid and semi-arid regions of West Africa – foremost in the region of the Sahel zone – will worsen. Appropriate concepts for land and forest management and for environmental protection however do offer the opportunity to adapt quickly enough to such climate developments in order to soften the impacts on poeple..”
International support project
The research works in Mali and in the Senegal were part of an international project: “Climate Change, Environmental Changes and Migration: Social-Ecological Conditions of Population Movements with the Example of the Sahel Countries Mali and Senegal (micle)”. The “micle” research project was funded from 2010 to April 2014 by the German Ministry for Education and Science (BMBF) and coordinated by the Institute for Social Ecological Research (ISOE) in Frankfurt. The Geographical Institute of the University of Bayreuth – together with the Institute for Geography and Regional Research of the University of Vienna – was involved as an associated partner. The leadership of the sub-project “Physical Geographical Perspectives ” was done by Prof. Dr. Cyrus Samimi, who today leads the research group for climatology at the University of Bayreuth. Prof. Dr. Martin Doevenspeck , Professor Regional-Related Conflict Research at the University of Bayreuth, was responsible for the sub-project “Social-Geographic Perspectives”.
Publication:
Martin Brandt, Aleixandre Verger, Abdoul Aziz Diouf, Frederic Baret and Cyrus Samimi, Local Vegetation Trends in the Sahel of Mali and Senegal Using Long Time Series FAPAR Satellite Products and Field Measurement (1982–2010), in: Remote Sensing 2014, 6, pp. 2408-2434 DOI:10.3390/rs6032408.
Photos: U of Bayreuth
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterUPDATE: Ed Caryl provided the following:

Based on GISS data
========================================
Even though IPCC climate models and expected climate trends have proven themselves to be completely false and useless, see here and here, parts of the Austrian media and state sector have no qualms using them, and in doing so they are misleading the public.
A recent example is the climate-alarmist Vienna-based Der Standard online daily in a recent piece titled: Climate in Vienna: More heat days, new plants.
The whole premise of the story is based on the climate models being right, which in fact today we know they have been universally wrong.
Palm trees in Vienna in a few decades!
In the article written by Christa Minkin and Julia Schilly, it is claimed that palm trees are to be expected in “a few decades in the Viennese forest – thanks to climate change,” citing ecologist Franz Essl of the Austrian Federal Ministry of Environment.
Minkin and Schilly also warn that Vienna is going to be hot in the future, all exacerbated by the urban heat island effect, citing “a new Austrian expert report on climate change“.
In 1910 there were only two heat days – i.e. temperatures over 30°C. In 2000 already 17 were measured.”
Der Standard also looks very deeply into the climate crystal ball…all the way to the year 2070 to 2100. Minkin and Schilly write:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




For the period of 2070 to 2100 researchers anticipate a rise to more than 35 heat days per year on average. At the same time nights in Vienna will cool down less.”
Moreover, foreign plants will begin their invasion and displace domestic ones, the experts warn.
Slight cooling over the last 16 years
So with all the warnings of more unbearable heat days in the future, one might assume that temperatures in Austria must be currently on the rise. I searched the Internet for the temperature data series for Vienna, but unfortunately I wasn’t successful finding it. So I contacted the European Institute for Climate and Energy to see if they might be able to help out. They answered promptly by e-mail (slightly paraphrased):
Unfortunately we do not have the more recent data because the Austrian Weather Service does not make them public, only up to 2003. That’s why it’s not possible to show the last 15 years graphically, and so climatologists in Austria can claim whatever they want.”
Fortunately, EIKE was able to provide the recent data for Graz city center. Here we see despite the urban location there’s been a slight cooling.

Mean annual temperature for Graz city center over the last 16 years.
The trend in Graz matches the overall trend of a slight cooling over central Europe over the last two decades.
So with the IPCC models having performed so horrendously, and in view of the fact there has been no warming trend in Austria for 16 years, it is truly a mystery how anyone could claim that summer heat days will just keep on rising linearly until the end of the century.
When the models are failures, then the future projections based on them are worthless.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSpiegel science journalist Axel Bojanowski here looks at the new paper “Climate change in the Fertile Crescent and implications of the recent Syrian drought,” PNAS, March 2, 2015 by Kelley et al, which claims the 2007−2010 drought contributed to the war in the region.
A number of major news outlets, such as the New York Times and the AP were quick to uncritically dispense it as gospel truth.
Anthony Watts provides good background here.
Spiegel’s view is much more critical and skeptical of the paper’s findings and overall methodology when compared to the New York Times or AP. The online German magazine writes:
An alarming study has created a commotion worldwide. The authors claim that climate change contributed to the drought and civil war in Syria. However this claim is hardly tenable.”
Models in wide disagreement
Bojanowski writes that the decisive evidence in the paper is based on climate models, which show drier conditions for Syria as the greenhouse effect intensifies. However Bojanowski later points out that the climate system in Syria is highly complex and that even the IPCC questions the capability of models reliably simulating the climate system of Syria and that the models are in wide disagreement:
The region lies on the boundary of three climate regions where the weather patterns are hardly understood, the IPCC report says. Foremost the climate simulation models diverge widely from each other when it comes to precipitation. It thus appears unwarranted to use the results of models as a way of confirming the effect of greenhouse gases, believes [William]Briggs.”
Sparse data
Another problem with the study, Spiegel reports, is that the data used were way too sparse, and quoted climate scientist Tim Brücher of the Max Planck Institute for Meterology: “The data should have been handled more critically.”
“Renders a poor service on behalf of climate science”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Probably seeing the paper more as an embarrassment rather than a contribution to science, even warmist institutes were unable to refrain from critique. Bojanowski quotes Thomas Bernauer, a conflict researcher at ETH in Zürich: “The entire paper is problematic as it renders a poor service on behalf of climate science.”
“Study is problematic at a number of levels”
In total Bojanowski says scientists criticize the paper on five aspects, saying that after the criticism, nothing is really left of the paper. According to Spiegel, University of Hamburg expert Tobias Ide says, “The study is problematic at a number of levels.” Peace scientist Christiane Fröhlich of the same university says the civil war “had more to do with wealthy citizens provoking it“.
“A distraction” from the real causes
Francesca De Châtel, Syria expert at Radboud University in Nijmegen, called the paper “a distraction” from the real causes of the war, and pointed out that drought periods are more the norm for the region. The problems stem foremost from land mismanagement and shoddy agricultural practices. Bojanowski quotes De Châtel: “The role of climate change is not only irrelevant, emphasizing it is even damaging.”
No evidence linking drought to civil war
Also Norwegian doctoral candidate Ole Magnus Theisen states that there is no evidence of a relationship between drought and conflict, Spiegel writes.
Bojanowski adds that “the climate argument allows politicians to blame others outside of the country for the hunger.” The Spiegel journalist sums up the science of tying climate change to war in general:
The main causes of civil wars are political. The future security of Africa does not depend on climate, rather on political and economic development.”
In summary one would not be wrong in concluding that the PNAS was definitely asleep during the review of the paper. Hard to get any shoddier.
Spiegel report here.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterVienna Climate Waltz More Data
By Ed Caryl
This is my comment on the Vienna Climate Waltz article Pierre just posted. I found the Vienna temperature data from GISS. It is listed under Wien/Hohe War, whatever that is.
My map application drops the pin nearly in the center of downtown from the GISS latitude and longitude numbers (which are notoriously inaccurate). The data file is complete from 1880 to the present, which is unusual. There are only two files in the GISS database, GHCN data before and after GISS homogenization. Here is a plot of those two files.

Figure 1 is a plot of Vienna annual temperature data before and after GISS homogenization, with the difference (the green trace). The difference scale is on the right, all scales in °C.
The homogenization has warmed the past and left the last 10 years unadjusted. This is unusual, as GISS usually cools the past and warms the present with their adjustments. The adjustment is probably for urban heat island effects, though they should be cooling the present and leaving the past alone.

Figure 2 is a plot of the last 16 years with trend lines.
There is a tenth of a degree adjustment for homogenization in the years 1998, 1999, and 2000. These adjustments change the cooling trend by more than 50%.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Curious George requested a 10-year average plot. Here is a centered 9-year average plot on the annual data. (It preserves the time accuracy better.)

Figure 3 is the annual homogenized temperatures with a 9-year centered average.


Figure 4 is a plot of seasonal temperatures (homogenized data).
While all seasons have gotten warmer in the last century, winter has the largest variation, but not much of a trend. I didn’t add the trends to Figure 4, but the numbers are: spring 1.29°/century, summer 1.41°/century, fall 0.73°/century, and winter 1.14°/century.

Figure 5 is a plot of the seasonal trends over the last 16 years.
The cooling in the last 16 years is all from the winters getting colder, at -0.382°C per decade.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSince last week the NoTricksZone site has been experiencing technical difficulties, which all seem to be rooted to WordPress version updates. The new updates just don’t seem to be working well anymore with the Hybrid theme I’ve been using for almost 5 years now.
Last weekend the site was down over 30 hours. This, according to the hosting company, was due to a “faulty htaccess file” in the new WordPress version, which the hosting company thankfully eliminated.
Then a few days ago I noticed the NTZ was not using the latest WordPress version, and so I updated the site to the newest available version: 4.2.1. Unfortunately since then the reader comments function has stopped working. Readers are able to write a comment, but the “Submit Comment” button is missing.
Other sites Using WordPress have had the same problem as well. Normally updates are supposed to improve the sites. Now they seem to be wreaking havoc instead.
Concerning the missing “Submit comment” button, there now appears to be a fix that takes care of the problem.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Unfortunately it involves editing the site code, something I’m very very wary of attempting because I’m not a programmer, and I’m not sure where the piece of code belongs. Surely there is the risk I’d makes things worse.
So for the time being, until I find someone who can safely repair the problem, it will not be possible for readers to leave comments.
Another solution is changing the WordPress theme. This is the one I’m leaning to. I’ve been using the current theme almost 5 years, and now is probably as good a time as any to change to a new, fresher one. I’ve looked into it, but here too the task does not look very straight forward and harbors the potential for major messiness. I’ve previewed several newer WordPress themes, and they all have no problems with reader comments. However, many of my sidebars (e.g. Archives, Blogroll, Categories, etc.) fail to appear in the preview. I need to look into this in greater detail.
In summary, readers have to expect changes coming to the site, and possible potholes along the way. Big Oil hasn’t sent any checks and I don’t have the luxury of bringing in a programming specialist.
Originally I started out doing this with the purpose of getting involved in the climate debate – and not the technical programming of WordPress sites, which now seems to be more and more frequent. If anyone out there has expertise in this and is willing to help out, send me an e-mail (see contact page).
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterUpdate 01/09/2014 19:18 CET: The opinion poll presented at the Plenum link below just seems to be too wrong. To me it appears to be a national poll, and not of Saxony. The Plenum story does not specify exactly the region the poll was taken.
====================================
Germany’s version of the UKIP Party in the UK is the so-called Alternativ für Deutschland (Alternative for Germany), or AfD Party.
The AfD party has been very critical of euro, green-energies, and mega bailouts. Some its members have expressed doubts on climate science. Disenchanted voters view the AfD as the alternative to what they see as entrenched arrogance that has long pervaded over the other established parties; CDU, SPD, Greens, Links (Communist), and FDP.
Yesterday state elections were held in the German eastern state of Saxony with results showing the AfD party taking in 10% of the vote. The unexpectedly high result for the AfD took many pollsters by surprise.
Final result:
CDU (conservatives) 39.4%
SPD (socialists): 12.4%
Links (communists): 18.9%
Greens: 5.7%
AfD (alternative): 9.7%
Just a week before yesterday’s election, some opinion surveys by polling institutes were showing the AfD struggling to reach the 5% hurdle, which is necessary for a party to take seats in parliament.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




For example on August 20 a survey commissioned by Stern-RTL showed the AfD barely at the critical 5% mark, the SPD social democrats all the way at 24%, and the German environmentalist Greens even at 10%. The Plenum site actually does not specify exactly the region the poll was taken – only mentioning that it was done in the run-up to the Saxony election. The figures seem to reflect the national sentiment.
The online Fulda info here presents the results of a national survey by renowned polling institute Emnid conducted about 10 days ago, commissioned by flagship daily Bild am Sonntag. It showed the AfD as a marginal party at only 4%!
Needless to say, the media reaction was one of shock and awe, and indicates that both the established parties and media do not have their finger on the pulse of public sentiment. The opinion survey seem to more reflect the wishes of the establishment, and not the reality.
Repeated, widespread campaigns had been launched by the established parties and the media in attempt to portray the critical AfD as a fringe, right-wing party. The 10% result shows, however, that the attempts failed and that the AfD voters think very little of the shenanigans.
In the Saxony elections the newly minted AfD soared past a number of parties and picked up 10% of the vote, surprising pollsters and the sending a sharp signal to the established parties that the days of political consensus on major issues such as the euro, the role of the EU, mega-bailouts, and renewable energy may be coming to an end.
With war breaking out to the east and south of Europe, the European economy struggling, energy prices spiraling out of control, citizens are demanding that their wishes be taken seriously.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter

The editor-in-chief of the Iserlohner Kreisanzeiger und Zeitung daily Thomas Reunert dedicated an entire page on the topic of wind energy last Sunday, bearing the headline: “The Norwegians Are Giving Us The Finger!”
It is an interview with a former professor from the University of Bielefeld, Dr. Kurt Gehlert, 75, an expert in mining. It focusses on the state of Germany’s Energiewende (transition to green energies), particularly wind power and the illusions of energy storage technology.

The sub-heading reads
Dr. Kurt Gehlert is certain that the Energiewende has already failed. Or we will drown and cover ourselves in wind turbines.”
Germans pushing the Energiewende are aiming to see 80% of Germany’s energy needs being met by green energies by 2050. Some are even calling for doing away with natural gas, in addition to coal and oil.
But the monster-sized insurmountable obstacles loom as German policymakers begin to scramble in a confused state of denial.
Germany’s alternative baseload-capable sources, such as hydro and biogas, are severely limited and account for only 11.5% of Germany’s total energy supply today. Moreover there still does not exist a viable technology for storing the irregular supply of wind and solar power. Gehlert says these technologies are nowhere near being capable of taking on the role of providing a reliable baseload.
The 75-year old professor points out that although there is a huge capacity of wind and solar energy already in place, often both are not available because they are weather-dependent. Gehlert tells the IKZ that the media like to give the public the impression that the technology is not far away, but the reality is that it is nowhere near in sight.
Energy storage concepts such as accumulators, power-to-gas, compressed air storage are plagued by low efficiencies and sky-high costs. He reminds readers that using electric car batteries as a storage media is also a pie-in-the-sky-vision. Gehlert tells IKZ:
It sounds like a good idea and so let us illustrate it using a rough calculation. In 2020 it is planned to have 1 million electric cars on the roads in Germany. If we tap into them and remove 50% of the average 25 kwh charge capacity, then we will extract enough power from them (12.5 x 1000000 =12.5 gigawatt-hours) to cover Germany’s needs each day for 25 minutes and 17 seconds; Germany’s total daily consumption is 712 gigawatt-hours. And then all the electric car owners will have only 50% of the range available for their next trip.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Gehlert also tells the IKZ that pump-storage is also not a solution for Germany, calculating:
In Germany about 125 times more storage lakes than what exists today would need to be constructed by 2050. This area and topography simply does not exist at all.”
On the idea of using Norway’s, Switzerland’s or Austria’s mountainous regions to build the necessary pump-storage capacity, Gehlert tells the IKZ:
The Swiss are reacting allergically, and the Norwegians are giving us the finger.”
Go ruin your own landscape, and leave ours alone.
And even if it was possible to use pump-storage in foreign countries, Gehlert tells the IKZ that in order to bring the power from the above-mentioned mountainous countries to the big consumption centers in Germany’s industrial heartland, it would require the construction of about 70 high voltage power lines ranging from 300 to 1200 km in length!
Gehlert also scoffs at the idea of using wind-power-to-gas as a method for storing energy, which would be used to fire gas turbines to produce electricity in times of low-winds. And expanding the calculation to 50% constant electrical power from wind energy would require about 470,000 German wind turbines (Currently there are about 25,000). Gehlert elaborates:
The figure is difficult to fathom. Germany has an area of approximately 360,000 square kilometers. That means each of the 470,000 wind turbines would have 0.76 sq km.. The city of Iserlohn alone has an area of 125.5 square kilometers and so would have 165 wind turbines.”
The IKZ asks Gehlert to summarize:
The Energiewende under the given conditions in Germany is a failure […]. The policymakers state in a worried manner: Our predecessors have left behind a disillusioned population.”
 


Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Nonoy Oplas
The Philippines enacted the Renewable Energy (RE) Act of 2008 (Republic Act 9513), which contains various subsidies for renewable energies such feed-in-tariffs (FIT).
Photo: Nonoy Oplas
While it was signed into law in December 2008, FIT was not implemented until July 2012 because many sectors including manufacturing opposed higher price on already expensive Philippine electricity rates. But the World Wildlife Fund (WWF), Greenpeace and other environmental groups in the country lobbied hard to implement the FIT and the Energy Regulatory Commission (ERC) was pressured to give in to their lobbying, but at a lower rate as requested by the National Renewable Energy Board (NREB).

Figure 1. Proposed vs approved FIT in the Philippines, pesos per kWh. (Rates approved in mid-July 2012).
Prior to July 2012, there were not many renewable plants that were put up because of the uncertainty when the FIT would be granted and implemented. After July 2012, there was certainty and more renewables were put up.
The ERC started public hearings regarding how much would be added to the monthly bill of electricity consumers in the Philippines when FIT is reflected. In August 2014, the National Transmission Corporation (Transco), the FIT administrator according to the law, said that the forecast annual payout for renewable energy companies based on the FIT petition would be P8.5 billion ($192.3 million) for 2015 and P10.25 billion ($231.9 million) for 2016. Wow! (Source: Philippine Star).
Last February, Manila Electric Cooperative (Meralco) and all other electric cooperatives and distribution utilities in the Philippines started collecting the introductory FIT of PHP 0.04 per kWh. If this rate is retained throughout the year, the projected collection by Transco to be distributed to the renewable firms will be PHP2.7 billion. If the 12 percent VAT is included, this will be a P3.02 billion (US$ 68.3 million, at prevailing P44.2/$ exchange rate) siphoning from the pockets of electricity consumers nationwide.
FIT rate will be adjusted and rising through time as more renewables are added to the country’s power generation mix.
Rising FIT has happened and continues to happen in Germany, which probably has one of the world’s most elaborate renewables subsidy schemes. The FIT keeps rising as more renewables, wind and solar especially, are added yearly to the energy mix and electricity distributors are forced to buy them even when cheaper electricity from coal, natural gas, nuclear and hydro are available.

Figure 2. FIT paid by consumers in Germany, in Euro cents per kWh. Source: BMU: Germany’s Electricity Price More Than Doubles…Electrocuting Consumers And Markets, 7 December 2014.
So electricity prices in Germany keep rising. This will happen to the Philippines too, no thanks to RA 9513 the renewables cronyism law.

Figure 3. Cost paid by households in Germany, Euro cents per kWh. Source: BDEW: Germany’s Electricity Price More Than Doubles…Electrocuting Consumers And Markets, 7 December 2014


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




What makes FIT a formula for ever-rising price  of electricity? As contained in Section 7 of RA 9513, the FIT forces the following:
(a) Priority connections to the grid for electricity generated from emerging renewables such as wind, solar, ocean, run-of-river hydropower and biomass power plants,
(b) Priority purchase and transmission of, and payment for, such electricity by the grid system operators;
(c) Fixed tariff to be paid to renewables producers  for 20 years; and
(d) Compliance with the renewable portfolio standard (RPS).
The RPS as contained in Section 6 of the law, is the minimum percentage of generation from eligible renewable energy resources to be set by the NREB.
So combining FIT and RPS, this means that even if cheaper power from say Quezon coal or Sual coal, Magat or Pantabangan hydro, Sta. Rita or Ilijan natural gas are available especially during non-peak hours, but wind power from Ilocos are available, Meralco and the various provincial electric cooperatives of the Luzon grid are forced to buy from the expensive wind power plants.
While many environmental activists were among the groups that opposed electricity price hikes in the past, it is sure they will rein in their noise and militance now that their beloved renewables will be among the major contributors to rising electricity prices in the country. Double talk can happen anytime.
Recently, the Department of Energy (DOE) announced 14 renewable energy projects with combined capacity of 304 MW, which have been endorsed as qualified for the FIT program. The DOE has issued certificates of endorsement (CoE) to five biomass, three small hydro, two solar and four wind power  projects.
This means that the resulting power capacity will be dispatched to the grid at a fixed rate over a period of 20 years.
The installations for RE power totaled 750 MW: run-of-river hydro and biomass projects at 250 MW each, wind power at 200 MW, and solar power at 50 MW, but may soon be raised to 500 MW.
Aside from FIT and RPS, RA 9513 gives many other subsidies or relaxation of regulations and taxation to the renewable producers, privileges that are denied to producers of conventional but cheaper power sources. These privileges include: (a) income tax holiday for 7 years; (b) duty-free importation of renewable energy machinery, equipment and materials within the first 10 years; (c) special realty tax rates; (d) net operating loss carry over (NOLCO) to be carried for the next 7 years; (e) 10% corporate tax rate (not 30%); (f) tax exemption of carbon credits; and (g) tax credit on domestic capital equipment and services.
This author is not against renewable sources per se. They are fine, along with geothermal, big hydro, coal and natural gas. What is objectionable is the cronyism and favoritism granted to the renewables which results in ever rising electricity prices in the country. The case of Germany is already a guide for us. The same pattern is happening too in Spain and UK.
Government intervention and cronyism in energy policy is wrong and counter-productive. Governments should get out of electricity pricing and stop forcing grid operators and electricity distributors to buy from renewables when their rates are expensive. RA 9513 needs major amendments to remove the FIT and RPS schemes.
Nonoy Oplas is a free marketer in Manila who runs the funwithgovernment.blogspot.com.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhat follows is the press release by GEOMAR on the very recent Muscheler et al paper showing the sun’s profound impact on northern hemispheric climate. Other sites touched on this paper, here and here.

Now I’ve translated the entire GEOMAR press release from the German. The results of the study are impressive:
=================================
The sun controlled climate during the ice age
Irregularities in solar activity impacted the climate 20,000 years ago.
04 Sept 2014/Kiel. In a model study, climate scientists of the GEOMAR Helmholtz Center for Ocean Research in Kiel reconstructed the relationship between solar activity and climate during the last ice age. With their climate-chemical model, they were able to make a considerable contribution to a study by the Swedish Lund University published in the international journal Nature Geoscience.
A known pattern of behavior of the sun is its irregular solar activity. The most well-known activity cycle is the 11-year sunspot cycle where every 11 years there is a switch between sunspot maximum and sunspot minimum. There are also other known fluctuations of other timescales. Sunspots are places on the sun’s surface that appear to be darker because the solar radiation is emitted into the universe with reduced strength. At the same time high energy radiation, foremost in the UV range, leaves the sun. During a sunspot minimum there are fewer sunspots and thus less energy-intensive radiation reaching the earth. When sunspots reach maximum activity, precisely the opposite is true.
More solar radiation, particularly in the UV range, during a sunspot maximum leads to a warming of the stratosphere (between 15 – 50 km) in the tropics and lead to an increased ozone production. Through complicated interactive mechanisms this in turn leads to atmospheric circulation changes which are perceived at the earth’s surface. The mechanisms on how changes in solar activity impact the atmosphere are still the subject of ongoing research. There is especially much speculation on the relationship between large sunspot minima and cold, snowy winters or on whether the current low sunspot activity might be responsible for the pause in global warming.
Scientists of Lund University (Sweden), in cooperation with GEOMAR climate scientists Prof. Dr. Katja Matthes and Dr. Rémi Thiéblemont, have succeeded in reconstructing solar activity back in the last ice age. The study was published in August in the international journal of Nature Geoscience.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Ice cores from Greenland were used to get information on solar activity for that period, a time when Sweden and North Germany were under a thick sheet of ice. The evaluation principle works in a similar manner as with tree-rings: The ice cores contain many layers from which information on temperature and precipitation conditions can be derived. The radioactive, cosmic molecules of beryllium and carbon play an important role here. Namely they are created in the atmosphere when the solar magmatic field around the earth is weak and thus allow lots of cosmic radiation to come through. When the ice core contains lots of radioactive beryllium and carbon, it means there was a weak protective shield, and so indicates weak solar activity.
A combined analysis of ice cores and dripstones allowed the scientists of Lund University to reconstruct solar activity until the end of the last ice age. It shows that the 11-year sunspot cycle also existed at the time, displaying a typical pattern of solar activity. “First of all we have succeeded in producing a high resolution record of solar activity,” says Prof. Matthes. “With our climate model, which transfers the solar signal from the stratosphere to the earth’s surface more accurately than other models, we were able to reconstruct typical atmospheric circulation patterns for a solar minimum, thus enabling us to infer possible temperature and precipitation patterns over Greenland that correspond very closely to the conditions at the end of the last ice age. The agreement is impressive and allows us to suspect that the mechanism for influence on climate by solar activity back then and today function very similarly.”
The results confirm the evidence from other studies showing years with low solar activity are associated with harsh winters over the Northern Hemisphere. One example are the strong winter outbreaks connected with snowfall and storms, as experienced in 2008 and 2010 in North Europe and North America. During these years we found ourselves in a sunspot minima.
“The effect of solar activity on regional climate fluctuations is very revealing. Estimations of future solar activity could lead to more precise climate forecasts over the next deacades,” explains Prof. Matthes.
Study done by:
 Adolphi, F., R. Muscheler, A. Svensson, A. Aldahan, G. Possnert, J. Beer, J. Sjolte, S. Björck, K. Matthes, R. Thiéblemont (2014): Persistent link between solar activity and Greenland climate during the Last Glacial Maximum, Nature Geoscience, http://dx.doi.org/10.1038/NGEO2225
Photos:
Shown are sunspots at a time of a solar minima. Photo: SOHO (ESA & NASA)
This ice core was extracted in Greenland as part of the National Ice Sheet Project of the National Science Foundation. It comes from a depth of 1837-1838 Metern and provides a record of the climate of the last thousands of years. Photo: USGS via Wikimedia Commons.
Contact:
 Prof. Katja Matthes (GEOMAR, FB1-Ozeanzirkulation und Klimadynamik), kmatthes(at)geomar.de
 Jan Steffen (GEOMAR, Kommunikation & Medien), Tel.: 0431 600-2811, jsteffen(at)geomar.de
Share this...FacebookTwitter "
"
Share this...FacebookTwitterLet no one deceive himself. If anyone among you thinks that he is wise in this age, let him become a fool that he may become wise.   – 1 Corinthians 3:18
A wave of commotion has just been unleashed by the very recent FOX News report on Google’s contemplating of changing the way it ranks website pages with its famous search engine. Also read here.

Towering arrogance from speech-rights midgets? The self-appointed gate-keepers of the Truth: Image cropped here.
Rather than ranking websites on their popularity, a Google research group is looking into ranking websites based on how “factual” they are. If implemented, it would literally mean Google taking on the gatekeeper role of who deciding fact from fiction. Google has already created a “knowledge vault” containing “commonly believed facts”. In summary sites found to deviate from what Google considers facts, would be automatically down-ranked in searches. Result: dissident opinions would surely get buried.
Though the system may have some merits, it is chock-full of pitfalls and it risks the establishment of an information dictatorship – a so-called Orwellian Ministry Of Truth. In other countries such information control programs are the sort of things one associates with tyrannies and dictatorships, like Iran, North Korea, Red China, Russia, Venezuela or Islamic fundamentalist states. Note in all these states, leaders are convinced it’s for the overall good of the people.
“That is very troubling,” writes Jim Lakely, Director of Communications of the Chicago-based think-tank The Heartland Institute in an e-mail. He thinks there is no doubt that the ‘facts’ of politicized sites who clearly have a defined agenda will get favorable treatment in Google’s ‘knowledge vault’ while dissident sites will be locked out.
“I worry about this issue greatly… My site gets a significant portion of its daily traffic from Google,” Anthony Watts told FoxNews.com. “It is a very slippery and dangerous slope because there’s no arguing with a machine,” he added.
While Google maintains this project is only in the development phase, others are not so sure. One climate science dissident, who wishes to remain anonymous for the time being, believes that Google is already “heavily biased and directing traffic away” from climate science skeptic sites.
When it comes to science, the move reveals that Google seems oblivious to how the discipline works. It that is so, it makes the omnipotent company all the more dangerous. Science is always hotly disputed. For example is used to be a universal “fact” that saturated fats were bad for human health – before dissidents forced a rethinking. With Google’s new proposed policy, dissident voices would never see the light of day and progress would be stunted as a result. Dissidence is the life blood of science itself. By removing dissidence, as Google unwisely moves to do, science itself would de facto get starved and be catapulted back to the Dark Ages and the times of the Inquisition.
Global warming alarmists have long been working to get Google to suppress dissident voices on the subject of climate change. In 2009 conservative news site Newsbusters here wrote:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Former Vice President Al Gore a few years ago advised Internet behemoth Google about “aspects of search quality.”Such was reported by the New Yorker in its October 12 issue (subscription required). […] given the ongoing concerns about Google’s political leanings and how its search algorithms might be manipulated to favor liberal news outlets over conservative points of view, the very idea that Gore might have had any input to this process is worrisome to say the least.”
Thus we see that the Google project has long been in the works, and so the preparation appears to be grand and fundamental in scale. It cannot be that an organization with the power and might of Google would take it upon itself to police the world’s body of knowledge and to decide who is trustworthy and who isn’t. This borders on dangerous megalomania.
Censorship can be fought
The irresponsible and arguably arrogant deeming of “unreliable sources” is not something that Google alone is contemplating, but was already once reality among some powerful government institutions worldwide just months ago. For example Germany’s Federal Ministry of Environment issued a 123-page publication that singled out German and American journalists and scientists who it claimed were responsible for “spreading doubt and false information“ on climate change. Among them: Fred Singer, Sallie Baliunas, Willie Soon, Frederick Seitz, Joe Barton, Pat Michaels, John Christy and Ross McKitrick.
Fortunately the German journalists and scientists who were targeted did not take the state-sponsored attack lying down. The brochure is no longer available. A small victory for the freedom of scientific dissent.
So will Google and its many backstage operators be successful?
If anything, the move confirms yet again that the globalist alarmists have lost the argument and that the public debate has become unwinnable for them. This is the reason for the “state-of-emergency” scale move. Despite their huge advantages in the media and state funding, they are unable to explain the harsh winters, the models’s failure, the sea ice growth and the many other warmer Holocene periods. Now they are forced to shut down dissidents, a-la-Inquisition.
But it will never work. Every lie has a short shelf-life and can be propped up only for so long. Eventually it gets stale, and no one is left to swallow it.
Google’s move, however, is indeed extremely worrisome and very serious. The new US Congress needs to move swiftly and forcefully, and to put these obviously out-of-control Google executives on the hot seat for a serious grilling or two and a little schooling on the virtues of un-monopolized dissent. The human right to be heard, and to not be silenced, is at stake here. Sympathetic lawmakers need to be contacted.
Kennedy aptly concludes: “Whoever controls the Truth, controls the world“.
The power to determine the truth belongs to the people, and not to Google.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSome days ago I wrote about how German news weekly Der Spiegel had resorted once again to catastrophe-hopping when it recently rolled out its print edition whose front cover featured a burning planet caused by human climate change.
Skeptics in Europe reacted harshly, but at the same time dismiss the doomsday piece as a desperate sensationalism stunt in a bid to stem its hemorrhage of readers.
Alarmist views “wrong, completely naïve”
Some criticism even came from rather hefty figures in the climate scene. For example Swedish professor Lennart Bengtsson, former IPCC climatologist and former head of the German Max Planck Institute for Meteorology in Hamburg.
Hat-tip: Hans Labohm
Bengtsson posted a commentary concerning the Spiegel doomsday piece at the Swedish Anthropocene site here. He calls the alarmist views of book author Naomi Klein, which Spiegel cited in its article: “not only wrong, but also hopelessly naïve.”
No basis showing weather has gotten more extreme
Bengtsson, who has gravitated from being an regular alarmist to a non-alarmist luke-warmer over the years, thinks that the growing emission of greenhouse gases is a problem over the long term, but that it is not an urgent problem. He writes there is no scientific basis showing the weather has become more extreme.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The storms are not worse than before, and they will be fewer in a warmer climate as a result of the polar regions warming up.”
No urgency
On sea level Bengtsson writes that it is now rising at about 3 mm per year, but has not accelerated over the past 23 years. It makes no sense to rush and to make “hasty and inaccurate decisions“. He writes: 
The reason for the increased emissions of carbon dioxide is the increasing earth‘s population and the desire of all the poor to live a life that is a little better and more hopeful, and perhaps someday even take a taxi at any time – surely among some of Naomi Klein’s environmental sins.”
Bengtsson calls the belief that a non-capitalist system can solve the earth’s energy and environmental problems “completely naïve” and uninformed, citing past failed experiments in socialism.
If anyone ought to be familiar with the costs needed to solve the problems left behind by communist East Germany, it is Spiegel. The Elbe River was a dead river at the time of the German reunification. Now, thanks to the capitalist system, it has returned to life.”
As an example of a successful approach to lower CO2, emissions, Bengtsson uses the United States: “In fact, one of the few countries that has significantly reduced CO2 emissions are the United States, through its growing gas exploration!” 
Bengtsson adds: 

The only hope to solve the planet’s long-term environmental problems is via the open and free society, not least of all by a socialist dictatorship on a global scale. This at least Spiegel’s editors ought to know.”


Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Ric Werme
Many have been watching the gradual development of Andreas Rossi’s “E-Cat,” a device Rossi claimed to produce heat from fusing nickel and hydrogen at commonly used temperatures, as opposed to those in core of a star.
Photo: NASA
The next big event, the release of a paper reporting on a month-long test in March by a group independent from Rossi and his partner, Industrial Heat, happened today. The results are pretty much what I was expecting and essentially completely positive.
In a nutshell, the device produced so much energy that only a nuclear reaction can explain it, reaction products were seen, but no nuclear radiation was detected.
The test ran with an E-Cat cell in three phases:
1) no fuel charge
This was to verify the test setup measurement equipment could accurately measure both the electrical power into the cell and the heat released from the cell by convective heating and black body radiation.
2) approximately 800 W input power for 10 days, this produced some 1600 W excess power.
3) approximately 900 W for the rest of the test, this produced some 2300 W excess power.
This confirms what supporters expected. While the COP (ratio of output power to input power) was lower than expected, the authors make it clear that they deliberately ran the cell at low power to reduce the chance of thermal power.  They point out that the adding a little more than 100 W input power increased output by about 700 W.  That incremental amount is more in line with what was expected.
That’s mostly all that’s important – put power in, get significantly more power out. From what I’ve read, Industrial Heat has not yet used E-Cats to make high pressure steam and then electricity.  That may merely mean they haven’t settled on the mechanical design of the reactor, there’s no point in making a boiler until then.
The most interesting part of the report is the isotopic analysis of the fuel before the test run and the “ash” afterwards. The bottom line is that the reviewers have no idea what is happening during the test run.  They are utterly mystified and reject most of their speculation.
The fuel charge, only one gram, was assayed before the start of the test. The key components were determined to be nickel (Ni), lithium (Li), aluminum (Al), iron (Fe), and hydrogen (H).  (Two assay methods found carbon (C) and oxygen (O), but the paper seems to dismiss them citing the tiny granules of powder they used.)  The Ni and H were expected per Rossi’s descriptions in the past.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




He also referred to a catalyst, saying it was inexpensive and not an impediment to wide scale deployment. The assay suggests the catalyst is
LiAlH4 which releases monoatomic hydrogen when it is heated, fitting the speculation about the catalyst’s role.
Each element was found to have the naturally ocurring ratios of its isotopes.
There had been speculation that Rossi used nickel enriched with particular isotopes, but apparently not.
The ash after the test run was also assayed. The small samples involved seem to preclude measuring the actual weight of various isotopes, so the paper concentrates on the percentages.  It would have been nice to have accurate weights.
Natural nickel is primarily 58Ni and 60Ni. Those were nearly completely consumed, and the nickel in the ash was nearly all 62Ni.  I had expected Ni + H leading to Cu, but several of the relevant Cu isotopes are radioactive, 62Ni is stable.
Lithium may not be a catalyst at all – natural Li is nearly all 7Li, a surface assay of the ash showed the lithium was nearly all 6Li. I’m no nuclear physicist, I’ll refrain from any speculation.  The authors explore a couple paths, but ultimately throw up their hands and simply say more study is needed.  Hydrogen wasn’t assayed – did it even participate?
All in all, this is a great, maybe historic, result. There has been plenty of evidence that the E-Cat works, but Rossi has always been directly involved.
Now we have an independent team working in their own space and with tools from their universities. They see it work and present multiple lines of evidence confirming it is a nuclear process.
That there is no explanation for the process is annoying, but won’t block commercialization of the E-Cat. The shouting isn’t over, the science has barely begun, but we may be at the start of civilization’s next major energy source.
Interesting times.
The paper is at http://www.sifferkoll.se/.pdf
The best starting point is www.e-catworld.com report-released/
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA heated exchange has just taken place at Twitter between Spiegel science journalist Axel Bojanowski and some of Germany’s leading climate alarmism politicians and ideologues who are pushing for a fast-track green coup d’état.
The row swirls around a critical opinion piece written by Bojanowski – on the roadmap-for-politicians IPCC final Synthesis Report. The Spiegel piece is titled: “Final IPCC Report: At the IPCC alarm comes before accuracy“. 
In it Bojanowski identifies a number points where the IPCC misleads the public and needlessly sounds the alarms. At Twitter Bojanowski calls these points “gross problems” that “need to be discussed”. 
In summary, the ever inquisitive Spiegel journalist writes that the IPCC final report “should rationally inform of the science  – rather it suppresses central contradictions“. He also adds that “the new synthesis report suppresses important scientific findings“. 
Bojanowski brings up some gross examples of IPCC factual suppression and how the UN body made glaring contradictions. The first concerns the subject of species extinction. In the 2013 IPCC main report, no predictions were made on to what extent species were threatened, demonstrating that too little is known to make reliable forecasts. But the latest synthesis report claims species have already began dying off due to climate change.
Bojanowski also points out that the latest synthesis report writes of numerous species having been forced to relocate because of climate change. But the main 2013 report writes: “There’s very little confidence in the conclusion that already some species may have gone extinct due to climate change.”
Another misleading claim by the new synthesis report is that today’s climate change is happening faster than at any time from natural causes over the last 1 million years – thus stressing out species. But learned-geologist Bojanowski cites the main IPCC report’s real findings:
At the end of the ice age, as the first part of the UN climate report shows, in large parts of the world climate fluctuations of 10°C in 50 years, i.e. 20 times faster than in the 20th century, took place and large climate-caused species extinctions are not documented.”
The Spiegel journalist also writes how the IPCC is not really being truthful with its predictions for the future. In the new synthesis report for policymakers the IPCC warns of a 4°C warming by the end of the century, and that this will be a formidable threat to species. Here the IPCC even asserts “high confidence”.
However, Bojanowski reminds Spiegel readers what the experts wrote in the main IPCC report (translated from the German):
Climate models are unable to illustrate key processes with respect to species development which foremost impact the susceptibility of species with respect to climate change.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In a nutshell Bojanowski comes down hard on the IPCC report – for blatantly putting alarmism ahead of scientific accuracy.
Some German activists and Green politcians have reacted irritably to Bojanowski’s article. Green Party honcho Dr. Hermann Ott tweeted:
@GYGeorg …sad! Dear@Axel_Bojanowski, we have discussed so often about climate change – for what? @sven_giegold“

 Bojanowski replied (not sure what he means with “twse”):
@GYGeorg@sven_giegold Dear @Hermann_Ott ,IPCC without critique, even if sometimes make mistakes like for example twse the Synthesis Report, would be sad, would it not?
Ott responds:
@Axel_Bojanowski (3) ..and when we destroy confidence in science then the door and gate are open to chaos, see USA @GYGeorg@sven_giegold“
Bojanowski replies:
(1)Dear @Hermann_Ott also science has to earn its trust,gross problems like those in the S’report have to be discussed @sven_giegold“
Looks like the IPCC was caught red-handed playing it fast, loose and alarmist with the science, and now the howls of objection from the warmist ideologues are beginning in earnest.
 

Share this...FacebookTwitter "
"
Share this...FacebookTwitterA reader posted a comment, which I’ve upgraded to a post (with some editing).
================================
Why there is global warming
by Harold Faulkner
People in the USA are being told by the U.S. government and media that global warming is man-made. If that is true, how can the government and media explain the high temperatures the Earth has experienced in past years when there were far fewer people?
Let us look back in the world’s history: for example, between roughly 900 AD and 1350 AD the temperatures were much higher than now. And, back then there were fewer people, no cars, no electric utilities, and no factories, etc. So what caused the Earth’s heat? Could it be a natural occurrence? The temperature graph shows the temperatures of the Earth before Christ to 2040.

In the book THE DISCOVERERS published in February 1985 by Daniel J. Boorstin, beginning in chapter 28, it goes into detail about Eric the Red, the father of Lief Ericsson, and how he discovered an island covered in green grass.
In approximately 983 AD, Eric the Red committed murder, and was banished from Iceland for three years. Eric the Red sailed 500 miles west from Iceland and discovered an island covered in GREEN grass, which he named Greenland. Greenland reminded Eric the Red of his native Norway because of the grass, game animals, and a sea full of fish. Even the air provided a harvest of birds. Eric the Red and his crew started laying out sites for farms and homesteads, as there was no sign of earlier human habitation.
When his banishment expired, Eric the Red returned to congested Iceland to gather Viking settlers. In 986, Eric the Red set sail with an emigrant fleet of twenty-five ships carrying men, women, and domestic animals. Unfortunately, only fourteen ships survived the stormy passage, which carried about four-hundred-fifty immigrants plus the farm animals. The immigrants settled on the southern-west tip and up the western coast of Greenland.
After the year 1200 AD, the Earth’s and Greenland’s climate grew colder; ice started building up on the southern tip of Greenland. Before the end of 1300AD, the Viking settlements were just a memory. You can find the above by searching Google. One link is: www.greenland.com/en/about-greenland/erik-den-roede.aspx. 
The following quote you can also read about why there is global warming. This is from the book EINSTEIN’S UNIVERSE, Page 63, written by Nigel Calder in 1972, and updated in 1982:
The reckoning of planetary motions is a venerable science. Nowadays it tells us, for example, how gravity causes the ice to advance or retreat on the Earth during the ice ages. The gravity of the Moon and (to a lesser extent) of the Sun makes the Earth’s axis swivel around like a tilted spinning top. Other planets of the Solar System, especially Jupiter, Mars and Venus, influence the Earth’s tilt and the shape of its orbit, in a more-or-less cyclic fashion, with significant effects on the intensity of sunshine falling on different regions of the Earth during the various seasons. Every so often a fortunate attitude and orbit of the Earth combine to drench the ice sheets in sunshine as at the end of the most recent ice age, about ten thousand years ago. But now our relatively benign interglacial is coming to an end, as gravity continues to toy with our planet.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The above points out that the universe is too huge and the earth is too small for the Earth’s population to have any effect on the earth’s temperature. The earth’s temperature is a function of the sun’s temperature and the effects from the many massive planets in the universe, i.e.:
The gravity of the Moon and (to a lesser extent) of the Sun makes the Earth’s axis swivel around like a tilted spinning top. Other planets of the solar system, especially Jupiter, Mars and Venus, influence the Earth’s tilt and the shape of its orbit, in a more-or-less cyclic fashion, with significant effects on the intensity of sunshine falling on different regions of the Earth during the various seasons.”
Read below about carbon dioxide, which we need in order to exist. You can find the article below at: www.geocraft.com/ice_ages.html.
FUN FACTS about CARBON DIOXIDE
– Of the 186 billion tons of carbon from CO2 that enter the Earth’s atmosphere each year from all sources, only 6 billion tons are from human activity. Approximately 90 billion tons come from biologic activity in earth’s oceans and another 90 billion tons from such sources as volcanoes and decaying land plants.
– At 380 parts per million CO2 is a minor constituent of the Earth’s atmosphere–less than 4/100ths of 1% of all gases present. Compared to former geologic times, the Earth’s current atmosphere is CO2-impoverished.
– CO2 is odorless, colorless, and tasteless. Plants absorb CO2 and emit oxygen as a waste product. Humans and animals breathe oxygen and emit CO2 as a waste product. Carbon dioxide is a nutrient, not a pollutant, and all life– plants and animals alike– benefit from more of it. All life on Earth is carbon-based and CO2 is an essential ingredient. When plant-growers want to stimulate plant growth, they introduce more carbon dioxide.
– CO2 that goes into the atmosphere does not stay there, but continuously recycled by terrestrial plant life and earth’s oceans– the great retirement home for most terrestrial carbon dioxide.
– If we are in a global warming crisis today, even the most aggressive and costly proposals for limiting industrial carbon dioxide emissions and all other government proposals and taxes would have a negligible effect on global climate!
The government is lying, trying to use global warming to limit, and tax its citizens through “cap and trade” and other tax schemes for the government’s benefit. We, the people, cannot allow this to happen.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNo, you have not landed on the wrong site.
NoTricksZone has simply switched to a new WordPress theme. The old hybrid theme was getting too many problems with each WordPress version update and so it was high time to change.
I know the new look will take some getting used to, but as far as function is concerned it should be trouble-free for a good while.
A couple of weeks ago the site with the old theme was inaccessible for some 32 hours. Then about 10 days ago readers were able to write comments, but there was no longer a “Submit comment” button.  These things of course can be fixed, but I just don’t know enough about programming the script, so I said the hell with it.
There will be some slight appearance changes in the future, but what you see is pretty much what you will get.
The good thing is that readers are now able to submit comments once again, and this is what really give the blog life.
Looking forward to hearing from the readers once again!
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Die kalte Sonne
(Translated/edited by P Gosselin)
On July 7, 2014, at the blog ‘Media Matters for America‘ appeared an article by Alexander Zaitchik on the 9th International Climate Conference in Las Vegas titled: Climate Denial Goes Vegas.
Among other things, the focus was to shine a bad light on the speakers and to portray them as paid hacks of the coal industry. But this flopped. Just take a look at Zaitchik’s part on Sebastian Lüning:
Sebastian Luning
Day Job: Senior geologist with the oil and gas company RWE Dea in Hamburg; Co-author of Die Kalte Sonne (The Cold Sun), which argued climate change is the result of solar flares and cycles.
Industry Ties: Heartland Institute. His co-author on The Cold Sun was Fritz Vahrenholt, CEO of his energy firm.
Climate Expertise: None


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




(1) Lüning has been not been working for RWE Dea since 2012.
(2) In our book Die kalte Sonne / The Neglected Sun, we argue that also CO2 plays a role, but has a significantly lower climate sensitivity than what is claimed by the IPCC. This “complexity” likely was too much for Alexander Zaitchik to grasp.
(3) Lüning did not receive any speaking fee from the Heartland Institute for his presentation in Las Vegas. Moreover the speakers who came to Vegas did so because they saw deficits in the public climate discussions and wished to bring the debate back onto a scientifically sound basis. Lüning also does not receive any financial compensation for his time-consuming daily blog work. Here asserting the “paid hack” theory is absurd.
(4) Zaitchik completely left out the fact that Vahrenholt was the CEO for a RENEWABLE energy company.
(5) Lüning has no climate expertise? Dr. Lüning is a geologist, a field that is an integral component of the climate science and that unifies a number of natural sciences. Moreover, Lüning has published a number of papers that examined sea level rise, the oxygen content of the oceans, and biological productivity, among other topics.
With such a sloppily researched essay, Alexander Zaitchik would not have received a grade at a University. The personal veil hiding that he is an IPCC spear carrier is so thin that obviously untalented activists from the very back rows are leading the cause.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIt is indeed stunning. A must-watch. It’s as damaging a performance on behalf of a cause that you will ever see.
EPA chief Gina McCarthy also says she doesn’t even know whose models policy is being based on.

She says that the models diverging from actual observations “on the whole makes no difference to the validity in the robustness of climate science that is telling us that we are facing an absolute challenge that we must address …blah blah blah…”
Sorry, but it makes all the difference in science. McCarthy thus confirms observational data mean nothing and that climate science is a religion at the EPA.
“Whose models? What projections?” she asks – as if she has no idea what’s going on at all. This is as incompetent as you will ever see.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterClimate cycles and their extrapolation into the future
By Dr. Dietrich E. Koelle
(Translated/edited by P Gosselin)
As the reconstruction of the climate’s development in the past by proxy data shows, there’s a series of temperature cycles that appear to be unknown, or ignored by many climate scientists. Among these are the larger climate cycles of 150 million to 180 million years (see Part 1 and Part 2), but also the shorter and for us the more important following cycles:
1000 years (900-1100)    Suess cycle with +/-  0.65°C
230 years (230-250)        deVries cycle with +/-  0.30°C
65  years (60-65)              Ocean cycles with +/- 0.25°C
In principle these cycles are sinusoidal in behavior as depicted in Figure 1. Bob Tisdale has also shown how the temperature increase of the 65-year cycle from 1975 to 1998 led to the assumption that it is due CO2 emissions because they too happened to be parallel. This has been naively extended all the way to the year 2100 and forms the basis for the climate models and the invention of the so-called “climate catastrophe”.

Figure 1:  Sine wave characteristic of the 60/65-year ocean cycle (Source: Bob Tisdale at WUWT).
In this analysis we will attempt to see how the temperature development could be over the next 700 years, assuming of course that the mentioned climate cycles of the past will continue on into the future. This should not be (mis)understood as a forecast for the future climate. Up to now there is only the IPCC forecast that the global temperature will rise by 2 to 5°C by the year 2100 – based only on the expected CO2 increase. However that theory has failed to work over the last 18 ears because the various natural climate factors and cycles never got considered, or they were not allowed to be considered in the climate models. Included among these factors are the mean cloud cover (albedo) and the resulting effective solar insolation (watts per sqm) at the earth’s surface, or the sea surface, which is decisive for the temperature development.Next Figure 2 below depicts the 1000-year cycle and the 230-year cycle, which have been reconstructed from historical proxy data. They stem from a combination of results from various publications in the field of paleoclimatology over the last years. The diagram of the last 3200 years distinctly shows a 1000-year cycle; the last 2000 years of which are confirmed by historical documents. In fact this cycle goes back all the way to the end of the last ice age, i.e. some 9000 years. The reason for the cycle is still unknown today, yet its existence is undisputed.
The current warm period is no “anthropogenic product”, rather it is the natural result of a repeating 1000-year cycle that goes back far into the past. Today’s warm period does not even reach the temperatures seen in the past warm periods, which at times were 1 to 2°C higher. Moreover it is important to note that during both of the past temperature maxima of 1000 and 2000 years ago, the CO2 values were at 280 ppm while today they are at 400 ppm. This indicates that the earlier warmer periods likely were related to natural solar activity and not to a rise in CO2 because there was no CO2 rise during those warm phases.

Figure 2: Global temperature over the last 3200 years shows a distinct 1000-year cycle along with the 230-year cycle.
Of historical significance is the fact that over the course of human history warm periods were always times of economic and cultural prosperity. The cooler periods always led to serious problems that led to starvation and huge waves of human migration in Europe. Here it becomes undeniably clear that the alarmist claims that “the earth has a fever” made by politicians such as Al Gore are patentedly preposterous. 
The “ideal” 1000-year cycle is varied by the 230-year cycle, which in turn gets varied by the 65-year oceanic cycle, which is depicted in Figure 1. Added to these cycles are the various typically non-cyclical events such as the ENSO, volcanic eruptions, etc. Figure 3 shows the temperature curve for the last 165 years along with the 230-year cycle and the effect of the 65-year ocean cycle. The current temperature values fluctuate by plus/minus 0.2°C due to the effects of ENSO, sunspot activity, volcanic eruptions, etc.

Figure 3:  The 230-year cycle over the last 165 years has been superimposed by a 65-year cycle as well as by other effects like the irregular ENSO events and large volcanic eruptions.
The temperature rise of 0.6°C during the 1975-1998 period, which has triggered all the current climate hysteria, was of the same magnitude as the previous increase that occurred in the 1910 to 1940 period, which in turn had nothing to do with CO2 because back then the concentration in the atmosphere rose by only some 10 ppm (from 297 to 308 ppm). Also the temperature increase of 1.5°C over the last 150 to 250 years is also nothing “out of the ordinary” or “dangerous”, as we are often told in the media. Instead it is only the natural recovery from the Little Ice Age (LIA) that had gripped the planet from 1400 to 1750. The LIA not only led to the Thames River and Baltic Sea freezing over, but resulted in severe hunger in Europe and caused a mass migration to America.
The figures also show that all three climate cycles reached their maximum shortly after the end of the last millennium. With that in mind, we actually should have expected even higher temperatures than those seen in previous warm periods. Here perhaps the fact that the global temperature has seen a negative overall trend since the Holocene Maximum plays a role. That means that the global temperature has fallen by 2°C over the past 8000 years.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Based on historical climate fact, it is possible to extend the trend into the future to form a possible climate scenario. Figure 4 depicts the extrapolation of the 1000-year and 230-year cycle along with the generally expected trend. Added to this are the fluctuations of the 65-year ocean cycles, the impacts of the ENSO-events, sunspot cycles and volcanic eruptions, which result in additional fluctuations of a few tenths of a degree – just as they have in the past.

Figure 4:  Extrapolating the 1000-year and 230-year cycles 700 years into the future.
Figure 4 shows the real global temperature development of the past 1000 years and its theoretical continuation over the next 700 years. This is not a forecast, but rather it is the extended possible course of the over all temperature trend, which over the mid-term in the next 100 years could see a drop of approx. 0.3°C  and a 2°C drop in global temperature in 350 years – which would mean conditions just like those seen in the Little Ice Age from 1450 to 1700. In about 1000 years the 1000-year cycle will again take on its warm phase and temperatures like those of today can be expected.
In the next 50 years there would be no temperature increase, but rather a slight temperature decrease is expected. In the decades before and after the year 2300 a powerful temperature drop could occur because both the 230-year cycle and 100-year cycle would be dropping rapidly together in parallel.
References:
1 J.R.Petit et al.: Climate and atmospheric history of the past 420 000 years from the Vostok ice core, Antarctica, Nature Vol.399, June 1999
2 Th.Steuber et al.: Low-latitude seasonality of Cretaceous temperatures in warm and cold episodes, NATURE Vo.437, 27 Oct.2005
3 W.S.Broecker and G.H. Denon: What Drives Glacial Cycles ? Scientific American, Jan.1990
4 H.Kawamura et al.: Antarctic Dome C Temperature Reconstruction, Nature, 23 Aug.2007
5 J.Veizer et al.: Evidence for decoupling of atmospheric CO2 and global climate during the Phanerozoic eon, NATURE Vo.408, 7 Dec.2000
6 K.Kashiwaya et al.: Orbit-related long-term climate cycles revealed in a 12-MYr continental record from Lake Baikal, NATURE Vol410, 1 March 2001
—————
Note from the Die Kalte-Sonne editors: The main point of this post is to provide any analysis of natural cycles and their logical extension into the future. Unaccounted in the projection shown in Figure 4 is the climate impact of CO2, whose role in climate today is hotly disputed. In our book “The Neglected Sun” we presented two CO2 climate sensitivity scenarios: 1.0°C and 1.5 °C warming for a CO2 doubling. Current studies have corrected the original IPCC value of 3°C strongly downwards (see our articles “Studies from 2014 provide hope: warming effect of CO2 is considerably over-estimated. Official correction is imminent“). It will be exciting to watch how research will develop with respect to climate sensitivity over the coming years.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s formidable green/climate movement is deeply deflated over the GOP’s grand midterm election success.
Especially the many German greens and socialists are struggling to fathom what happened and are only left to conclude that Americans must be just too stupid to appreciate all that President Obama and the Democrats have done and to understand the climate risks that threaten ahead.
For the reaction of Germany’s formidable climate alarmism movement, a good one is presented by klimaretter.info, an online alarmist site on climate and energy policy run by a motley crew of activist journalists with no scientific background.
“It could not have been any worse”
For the analysis of and reaction to the US midterm election results, klimaretter.info presents an interview with Liane Schalatek, climate and energy expert at the North American Office of the Heinrich Boll Foundation. The title of the interview: “It could not have been any worse“. Klimaretter.info writes in it’s introduction:
The election debacle by the Democrats in the USA is a catastrophe for climate protection. The outlook for a global climate treaty has dropped considerably.”
Well, that is indeed good news for the many and growing number among us who equate climate protection to climate swindle.
In the interview Frau Schalatek thinks it is likely the US Congress will move to cut EPA funding.
$85 million “a drop in the bucket”
On the $85 million spent on the election campaigns by environmental and climate protection organisations, klimaretter.info asks if perhaps that money could not have been better spent. Schalatek responds:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




That amount of donations is only a drop in the bucket when you look at how much money flowed into the elections in total: over 3 billion dollars. Foremost from people with an anti-environment agenda. It’s a good thing that the environmental organisations stood up. The political weighting however clearly was against the environmental organisations.”
Don’t you love the smell of the enemy’s money burning? The 85 million probably hurt them more than it helped. Nothing like putting kookiness on display for the whole country to see.
Global climate treaty “to be a lot harder”
klimaretter.info asks if the chances of a binding climate treaty have now fallen. Schalatek:
Yes. It is now going to be a lot harder for Obama to advance ambitious national obligations.”
Schalatek also believes it is going to be a lot tougher for Obama to make commitments to the green climate funds because Congress has a say on the matter. She also believes that a GOP controlled Congress at best would agree only to an “extremely watered down” climate treaty that would have “little legal power and obligation“.
“…could not have come at a worse time”
Klimaretter comments that the election result “thus could not have come at a worse time“, just one year before Paris. And for advancing real climate policy, Schalatek thinks that “it’s a very negative signal” and confirms it indeed could not have come at a worse time.
Thank you, democracy!
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNow that a couple of surface temperature data sets are showing 2014 was a “record warm year,” people are wondering if it means the warming pause is over, and if so, how much climate sensitivity to CO2 there really is.
Online Spiegel science journalist Axel Bojanowski (a geologist) has an analysis of 2014’s “record warm year” and asks if it means global warming has resumed after “a pause since the end of the 1990s”. He describes how climate scientists have been dumbfounded by the “unexpected warming pause”. A number of scientists blame the oceans for absorbing the heat out of the atmosphere. Japan’s meteorological services report that global surface temperature has risen 0.7°C in one hundred years, he writes.
On the significance of the warm year, the Spiegel science journalist quotes the German Climate Consortium: “The following years will allow us to judge the extent global warming at the surface of the earth has resumed.” And even the most alarmist organizations are conceding the global warming pause is real. For example the World Meteorological Organization (WMO) indirectly admits to Spiegel that the global temperature has paused, but reminds us that the 14 warmest years on record occurred over the past 15 years.
On the future of warming, Bojanowski describes a science fraught with uncertainty when it comes to future projections:
The UN IPCC continues to predict a hefty global warming should carbon dioxide emissions not be drastically reduced. But there are major uncertainties in the calculations and for this reason short-term fluctuations will remain unexplainable.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Readers should note at this point that this too also has to apply for “short-term” warm fluctuations, such as the one from 1980-1998. That one too must have been in large part due to natural factors.
Bojanowski sums up his analysis by pointing out there is also uncertainty not only at the earth’s surface, but in the troposphere as well, writing that “satellite meaurements are astonishing” researchers:
Moreover satellite measurements for upper air levels, which have been taken since the mid 1990s, show hardly any warming. Because of this, scientists are debating if the sensitivity of air temperature with respect to greenhouse gases is possibly less than assumed.”
Bojanowski also points to conflicting scientific literature and papers when it comes to the stability of the Antarctic and Greenland ice sheets. He adds, “The uncertainties show that the decisive questions about the future cannot be answered using short-term fluctuations.” And:
A warm record here, a warming pause there – the concerns and questions surrounding climate change remain the same.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA couple of days ago NoTricksZone turned 5. The first post was published on April 2, 2010.
This blog was inspired by Donna Laframboise of No Frakking Consensus after I had been part of a group of volunteers who helped her check the literature on which the conclusions of the IPCC 4th Assessment Report were based on. Those results rocked the IPCC.
The beginnings of NoTricksZone were humble, and my expectations were to perhaps reach a few hundred readers per day after a year or so. I didn’t even have any social media buttons. Yet within a few weeks traffic started coming in, in large part thanks to the big sites like Marc Morano Climate Depot, Anthony Watts WUWT and Tom Nelson who linked to NTZ stories. A year later the site reached 1 million views. Now, 5 years later, the 10 million views has been surpassed. Not bad for something that is a hobby on the side for me.
I’m also proud of having been mentioned by Justin Gillis in The New York Times, getting a link at Drudge, being on the Who’s Who List of Climate denialists” and having worked helped out Dr Sebastian Lüning and Prof. Fritz Vahrenholt’s climate science critical book Die kalte Sonne (The Neglected Sun), which shook the German climate science establishment.
The main idea behind this blog is to get stories from Germany and Europe that the world would otherwise never hear about out to the broader public. The progress of Germany’s Energiewende is an important issue and other countries worldwide need to get all the information about it before they uncritically accept its rosy, utopian promises. Germany’s Energiewende arguably has become a debacle of immense dimensions. See the side bar under Alternative Energies.
The German Energiewende has even reached my home state of Vermont, and the consequences are catastrophic to the scenic region where I was born and raised. Entire mountain tops have been permanently blasted, disfigured and deforested to make way for industrial wind turbines that now stand more as monuments to a pathological obsession with a computer-generated fictitious climate Armageddon than they do as a real solution. The damage in northern Vermont is irreversible. It’s going to take the ice sheets of the next ice age (that was the scare 40 years ago) to grind off the scars left behind by Vermont’s green eco-madness.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




My hope is that others will take a more serious, unemotional look at the real situation in Germany (as well as Spain and Great Britain) and not repeat the German blunders.
The focus of NoTricksZone is also to keep readers up-to-date on what is going on at the prestigious German institutes such as the Max-Planck-Institute for Meteorology or the Potsdam Institute for Climate Impact Research (PIK). Both are highly influential, but in my view highly irresponsible for having adopted a dangerously ideological position that is completely foreign to the discipline of science. Today they are practicing activist-science in its purest and most virulent form.
NoTricksZone will also continue providing stories brought up by EIKE, DkS and Science Skeptical and many other German sites. The main focus of NoTricksZone will be to continue writing about climate news in Germany and Europe so that people can get stories and insights that they might not otherwise see.
Also thanks to the guest writers who contributed, namely Ed Caryl (I know I’m missing a person or two here, so please forgive me) and all the readers for dropping by regularly. Readers are always welcome to contribute as guest writers.
As a final note, this blog is strictly voluntary and has not received any money at all from Big Oil and industry – not a penny. But of course antagonists are more than welcome to waste their time looking for any links.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMood change in climate modeling: Trust in the scientific community is disappearing
By Sebastian Lüning and Fritz Vahrenholt
(German text translated/edited by P Gosselin)
In the last few days we wrote two posts on the shocking deficits seen in the current climate models (see here and here). In our last part today we will look at how scientists estimate the modeling situation and look to see if there are new ideas to solve the problems.
In August 2014 a lead author of the 5th IPCC climate report, Richard Betts, publicly commented in a surprising manner. Betts directs the climate impact department of the UK Met Office, and at his website he describes himself as a climate modeling expert. In a comment at Bishop Hill, Betts wrote:
Bish, as always I am slightly bemused over why you think GCMs are so central to climate policy. Everyone* agrees that the greenhouse effect is real, and that CO2 is a greenhouse gas. Everyone* agrees that CO2 rise is anthropogenic. Everyone** agrees that we can’t predict the long-term response of the climate to ongoing CO2 rise with great accuracy. It could be large, it could be small. We don’t know. The old-style energy balance models got us this far. We can’t be certain of large changes in future, but can’t rule them out either.”
In a footnote Betts added the 2 comments:
*OK so not quite everyone, but everyone who has thought about it to any reasonable extent
**Apart from a few who think that observations of a decade or three of small forcing can be extrapolated to indicate the response to long-term larger forcing with confidence.”
Betts no longer gives climate models a central role in climate policy. There are still too many unknowns, he admits. Quite obviously even IPCC authors are now getting cold feet and are no longer able to exclude that CO2 may have only a minor impact on climate.
A month earlier in July 2014 in the Wall Street Journal climate modeler Robert Caprara conceded that a variety of freely selectable parameters exist in climate models, which allow the desired result to be “modeled in”. Caprara writes:
My first job was as a consultant to the Environmental Protection Agency. I was hired to build a model to assess the impact of its Construction Grants Program, a nationwide effort in the 1970s and 1980s to upgrade sewer-treatment plants. […] When I presented the results to the EPA official in charge, he said that I should go back and “sharpen my pencil.” I did. I reviewed assumptions, tweaked coefficients and recalibrated data. But when I reran everything the numbers didn’t change much. At our next meeting he told me to run the numbers again. After three iterations I finally blurted out, “What number are you looking for?” He didn’t miss a beat: He told me that he needed to show $2 billion of benefits to get the program renewed. I finally turned enough knobs to get the answer he wanted, and everyone was happy.”
In the climate debate Caprara recommends having an open discussion and listening to the arguments of the other side instead of cursing the other side in an attempt to disqualify them:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So here is my advice: Those who are convinced that humans are drastically changing the climate for the worse and those who aren’t should accept and welcome a vibrant, robust back-and-forth. Let each side make its best case and trust that the truth will emerge. Those who do believe that humans are driving climate change retort that the science is “settled” and those who don’t agree are “deniers” and “flat-earthers.” Even the president mocks anyone who disagrees. But I have been doing this for a long time, and the one thing I have learned is how hard it is to convince people with a computer model.”
Already in a paper from October 2012 a team of scientists led by Clara Deser in Nature Climate Change admitted that the strong natural climate variability that had been underestimated had been poorly accounted for by the climate models and so the models could not fulfill the high expectations of the political decision makers. The paper’s abstract states:
Communication of the role of natural variability in future North American climate
As climate models improve, decision-makers’ expectations for accurate climate predictions are growing. Natural climate variability, however, poses inherent limits to climate predictability and the related goal of adaptation guidance in many places, as illustrated here for North America. Other locations with low natural variability show a more predictable future in which anthropogenic forcing can be more readily identified, even on small scales. We call for a more focused dialogue between scientists, policymakers and the public to improve communication and avoid raising expectations for accurate regional predictions everywhere.”
Also well-known climate scientist Judith Curry has little trust in climate modeling. In October 2013 she complained in her blog about the missing estimations of climate historical studies – to the benefit of climate models. Huge sums had been invested in the models, without a correct result. The falsely claimed consensus by the IPCC catapulted the climate sciences backward at least a decade, said Curry:
My point is that ambitious young climate scientists are inadvertently being steered in the direction of analyzing climate model simulations, and particularly projections of future climate change impacts — lots of funding in this area, in addition to high likelihood of publication in a high impact journal, and a guarantee of media attention. And the true meaning of this research in terms of our actual understanding of nature rests on the adequacy and fitness for purpose of these climate models. And why do these scientists think climate models are fit for these purposes? Why, the IPCC has told them so, with very high confidence. The manufactured consensus of the IPCC has arguably set our true understanding of the climate system back at least a decade, in my judgment. The real hard work of fundamental climate dynamics and development and improvement of paleo proxies is being relatively shunned by climate scientists since the rewards (and certainly the funding) are much lower. The amount of time and funding that has been wasted by using climate models for purposes for which that are unfit, may eventually be judged to be colossal.
A more precise knowledge of paleoclimatology is essential and should have absolute priority ahead of free-style modeling because historical data are important calibration and check data for climate models. When the formulae are not correct, then even the largest super-computers are unable to deliver anything useful.

Also astrophysicist Richard Lindzen of the Massachusetts Institute of Technology (MIT) has no trust in climate models, as he explained at an event at Sandia National Labs, a research and development facility of the US Department of Energy.
The IPCC should finally open itself up to alternative models. In our “The Neglected Sun” book we presented a semi-quantitive approach where solar and ocean cycles played an important role. The awful accuracy rate of the IPCC models shows that it is time for a change. A serious check of the ideas of IPCC critics has to be conducted. Here models by Nicola Scafetta and Frank Lemke, which reproduce the temperature curve better than the IPCC forecasts, must be given serious attention. When it comes to oceans cycles, scientists have already given in and have even started to insert them into the models, thus making reliability of the climate prognosis dramatically better. An approach is for example DelSole et al. 2013 in a paper in the Geophysical Research Letters.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterTwo years ago at about this time of year the media were overflowing at the brim with apocalyptic stories of high-speed Arctic meltdown. Everywhere the media used words like “dramatic”, catastrophic”, “accelerated”, “tipping point” and so on.
Except for the story of an overall long-term trend claimed by one paper from the Alfred Wegener Institute (AWI) claiming a long-term accelerated ice melt at both poles, the media have been eerily silent on news about sea ice extent in the Arctic.
Right now the media silence is so deafening that you can hear a pin drop on the Arctic ice.
This year so far has indeed been a bad year for weather catastrophes. The pickings have gotten awfully meager for the alarmists and the media, who have had to content themselves with hyper-inflating anecdotal weather events to keep the climate scare living, albeit in a coma.
Tornadoes have been well below normal, cold temperatures have prevailed over many populated areas this summer, hurricanes have been scarce (not even a tropical storm on the globe today), Antarctica is at near record high sea ice levels, global temperatures stagnant almost two decades now…and now even the Arctic has moved into the skeptic column. Nothing is going the way the alarmists had projected years ago.
That’s why we’re getting phony weather forecasts for year 2050. There’s nothing else!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Arctic may have already reached low point – 2 weeks early
Some charts are showing that the Arctic sea ice may have already reached its low point in late August…more than two weeks early:

Source: www.ijis.iarc.uaf.edu/seaice/png
The chart above shows this year’s late summer extent could be higher than half a dozen other years on the recent record. So it’s no wonder that the climate catastrophe-cheerleaders in the media have been dead silent on the Arctic this year. Nowhere in the German media are there  catastrophic, dramatic Arctic meltdown stories announcing the tipping of the climate system. All gone this year.
For that we will have to wait until next year, perhaps. Or maybe the year after, or maybe when the missing heat comes out of hiding – a time that no climate model is able to tell us so far.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGeologist Dr. Sebastian Lüning and Professor of Chemistry Fritz Vahrenholt also posted today on the BBC’s lapse away from democratic principles: the right to free and open debate on important issues.
===========================
Fear of a serious factual discussion: Climate alarmists pressure BBC to censorship of the public climate debate
By Fritz Vahrenholt and Sebastian Lüning
(German passages translated by P Gosselin)
In February 2014 Lord Nigel Lawson, former Chancellor of the Exchequer under Margaret Thatcher, took part in a climate debate on BBC Radio. In it he represented climate-realistic positions while his discussion partner Sir Brian Hoskins defended the climate alarmist direction. The debate was moderated by Justin Webb of the BBC. What follows is an excerpt (via GWPF):
Lord Lawson: No measured warming, exactly. Well that measurement is not unimportant. But even if there is some problem, it is not going to affect any of the dangers except marginally. What we want to do is focus with the problems there are with climate – drought, floods and so on. These have happened in the past – they’re not new. As for emissions, this country is responsible for less than 2% of global emissions. Even if we cut our emissions to 0 – which would put us back to the pre-industrial revolution and the poverty that that gave – even if we did that, it would be outweighed by China’s increase in emissions in a single year. So it is absolutely crazy this policy. It cannot make sense at all.
Sir Brian Hoskins: I think we have to learn two lessons from this. The first one is that by increasing the greenhouse gas levels in the atmosphere, particularly carbon dioxide, to levels not seen for millions of years on this planet, we are performing a very risky experiment. We’re pretty confident that that means if we go on like we are the temperatures are going to rise somewhere between 3-5 degrees by the end of this Century, sea levels up to half to 1 metre rise.
Justin Webb: Lord Lawson was saying there that there had been a pause – which you hear a lot about – a pause of 10 / 15 years in measured rising of temperature. That is the case isn’t it?
Sir Brian Hoskins: It hasn’t risen very much over the last 10-15 years. If you measure the climate from the globally averaged surface temperature, during that time the excess energy has still been absorbed by the climate system and is being absorbed by the oceans.
Justin Webb: So it’s there somewhere?
Sir Brian Hoskins: Oh yes, it’s there in the oceans.
Lord Lawson: That is pure speculation.
Sir Brian Hoskins: No, it’s a measurement.
Lord Lawson: No, it’s not. It’s speculation.”
As a consequence, some BBC listeners complained that a climate realist should have never been invited on the show. Supposedly people became afraid when they noticed Lawson’s arguments came across as far more convincing than those from Hoskins. In a look back at the event in the Daily Mail, Lawson commented on am 9 July 2014:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The BBC was overwhelmed by a well-organised deluge of complaints — many of them, inevitably, from those with a commercial interest in renewable energy, as well as from the Green Party — arguing that, since I was not myself a scientist, I should never have been allowed to appear.”
Over the following months the complaints were reviewed by the BBC Complaints Office. In June 2014 an egregious step was taken: The complaints were upheld by the BBC. They claimed in short that Lawson had made false arguments. In reality a faulty accusation, as Lawson explains in his Daily Mail piece:
In fact, there was nothing I said in the entire Today programme discussion that was incorrect, nor, indeed, did Sir Brian Hoskins suggest otherwise. This can be confirmed by reading the full transcript, still available on my foundation’s website at thegwpf.org/Hoskins-vs-lawson-the-climate-debate-the-bbc-wants-to-censor, and possibly also on the BBC’s website, if they have not removed it out of embarrassment. The only untruth came from the unreliable Mr Chong of the Green Party who accused me of claiming on the programme that climate change ‘was all a conspiracy’. Needless to say, I said nothing of the sort, as the transcript makes clear.”
It appears the BBC will no longer be providing the climate realistic side any broadcast time. Already one can hear cheers from the climate-alarmists: Finally no more annoying discussions! Enough with democratic wastes of time, long live the IPCC dictatorship! Lawson explained in a piece in the Daily Mail:
The head of the BBC’s Editorial Complaints Unit, a Mr Fraser Steel, whose qualifications for the job are unclear and whose knowledge of the complex climate change issue is virtually non-existent, has written to a little-known but active Green Party politician called Chit Chong to apologise for the fact I was allowed to appear on the programme and to make clear this will not happen again. Among the reasons given in Mr Steel’s letter for upholding Mr Chong’s complaint and over-ruling the BBC’s head of news programmes is the mind-boggling statement that: ‘As you have pointed out, Lord Lawson’s views are not supported by the evidence from computer modelling.’ Evidence? However useful computer models may be, the one thing they cannot be is evidence. Computer climate models are simply conjectures, expressed in the form of mathematical equations (the language of computers), which lead to forecasts of future global temperatures, which can then be compared with the evidence on the ground.”
The director of the Global Warming Policy Foundation, Benny Peiser, criticized the decision by the BBC in an interview in the iai news (excerpt):
IAI: So do you think that, when it comes to the media, it is a one-sided kind of alarmist perception of risk that comes into question?
PEISER: Of course, because they are well-known for pointing out everything that is alarming and being silent on reports that show it is not as alarming. So you have a bias in favour of alarm, and a kind of ignoring any evidence that suggests that it might not be that alarming.
It’s about people who think we are facing doomsday, and people who are thinking that the issue of climate change is exaggerated. And if you deny anyone sceptical of the apocalyptic doomsday prophecies, then you get in a position where the BBC is so biased that MPs are beginning to consider cutting the license fee, or abolishing the license fee altogether, because people are beginning to be upset by the BBC’s bias.
This is a self-defeating policy; the BBC is digging its own grave by annoying half of the population who are known to be sceptical about the alarmist claims which are not substantiated, which are not founded on any evidence. They are only based on on some kinds of computer modelling, which is not scientific evidence.
IAI: So scientific evidence, such as computer modelling and research, is being used as an instrument in the rhetoric?
PEISER: Well there is a big difference between observation, what you actually observe in reality – that’s what I would call evidence – and computer models that try to model the climate in 50 or 100 years time. I wouldn’t call that evidence. There is a difference between evidence and people saying, “if we don’t act now then in 50 or a 100 years time we will face mega catastrophe”. That’s not evidence, it is speculation.”
Read the complete interview at the iai news.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAt the print edition of Swiss news weekly “Weltwoche”, science journalist Markus Schär writes that not only has the global temperature trend suspiciously been tampered with, but so have the datasets of the Swiss Meteorological Service:

View of print Weltwoche article on global temperature “adjustments”.
To illustrate Weltwoche shows two datasets in its article from two different locations in Switzerland:

The chart above shows the mean annual temperatures and trends for Sion and Zurich before (left) and after “adjustment” (right). The “adjustments” resulted in a doubling of the temperature trend.
At the start of the article Schär characterizes Thomas Stocker’s claim that the “so-called” 18-year global temperature pause is misleading information spread by “lobbyists” as scientifically invalid, and does so for three reasons: 1) It’s not “so-called” because datasets show there’s been no warming in over 18 years, 2) the pause is acknowledged by leading experts, and 3) IPCC experts have already acknowledged it, and have even come up with “over 50 explanations” to explain it.
Schär then focusses on the reports of temperature adjustments at various locations around the world that have led to a depiction of more rapidly warming global temperatures:
The Australian last year uncovered that state meteorologists adjusted an 80-year temperature series of Australia so that a cooling of 1°C per century was changed to a warming of 2.3°C.”
Schär also wrote of NASA’s dataset:
British science journalist Christopher Booker, who called the manipulation of temperature data ‘the biggest science scandal ever’, showed how among other things that the record value for 2014 came about because the responsible NASA institute had flipped the data trend for rural measurement stations in Brazil or Paraguay.”
According to Schär at Weltwoche, also Swiss temperature data have been adjusted to show stronger warming, calling the work a “propaganda trick, and not a valid trend“.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Schär calls into question the basis used for justifying the upwards adjustment, especially with respect to the fact that stations today are more urbanized and under influence of the urban heat island effect. He writes of the Swiss data:
It is correct that meteorologists homogenize their data, i.e. filter out external influences. But here the question is: How and with what intention are they doing this? […]
The meteorologist significantly lowered the data from the 19th century and strongly raised those of around 1980.”
The result, Schär writes; was a doubling of the temnperature increase rate. Schär also reports on how German meteorologist Klaus Hager earlier determined that the newer electronic measurement instruduced since the 1980s showed “on average 0.93°C higher temperatures.”
So why the upward adjustments when we have all the instrumentation and siting issues?
Schär writes that the Swiss meteorologists have rejected Hager’s claim that the new electronic instrumentation is delivering warmer temperatures, insisting that “the thermometers in the new automatic network are showing ‘slightly lower temperatures’ than those in the ‘poorly ventilated’ Stevenson screens.” Schär continues:
The corrections, however, appear so massive that they represent half of the entire temperature increase.”
Despite the data fudging by Swiss meteorologists (and those worldwide), no one is able to hide the fact that winters in Switzerland and in Central Europe have gotten colder over the past 20 years, defying predictions of warming made earlier by climatologists.
But that’s no problem for the climatologists, Schär writes.
Temperatures no longer have to rise in order to spread the fear of climate catastrophe. In the science magazine ‘Einstein’ on Swiss television, Stephan Bader of the Swiss Meteorological Service showed that winters in the Alps were getting cooler over the past years: But he also added that it was due to climate warming: Scientists at the Alfred Wegener Institute ‘suspect’ the cold snaps came from the melting of Arctic ice (which has stopped).”
Propaganda trick, anyone?
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWeatherbell Analytics presents its latest Saturday Summary featuring the one and only Joe Bastardi.
There used to be a time when meteorologists truly admired and trusted the work and data put out by national weather services. After all if you couldn’t trust them, who could you trust!
But those days are becoming a thing of the past.
I don’t want to give the impression that Joe Bastardi doesn’t admire and respect these institutions, I’m sure he still does so very much, but if his latest video is anything to go by, he is adding reservations to that trust – at least when it comes to the National Snow and Ice Data Center (NSIDC).
Starting at the 6:60 mark Joe focusses attention on global sea ice, showing that right now globally it’s about 1 million square kilometers above average…in a world that is supposedly in the midst of runaway global warming.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Global sea ice on the rebound. Image cropped from Weatherbell Saturday Summary.
Then at the 8:56 mark Joe brings up the recent (some would call absurd) claim made that Antarctic sea ice is expanding to record high levels because of global warming. (With that kind of logic one could hypothesize that the snowball earth episodes occurred when the earth was a hot house). Bastardi:
Now the guy, I believe the guy that was saying that the Arctic was in a death spiral, now he’s saying that it’s global warming that’s causing the Antarctic to have more ice. It is absolutely astounding to me…the National Snow and Ice Data Center …that no matter what happens, the answer is global warming. That by itself should make you suspicious, okay.”
To me that sounds like “buyer beware” if you are getting your information from certain leading individuals at the NSIDC.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAntarctic Sea Ice is Growing – Because of Global Warming?
By Ed Caryl
Short answer: No. Antarctic sea ice has been growing, especially in the last three years. This has been largely ignored by the AGW crowd because it opposes their narrative. They needed badly to come up with an excuse. A recent article in the Daily Caller, quoted below, was recently discussed in this blog. See here.
A quote from the article: “The primary reason for this is the nature of the circulation of the Southern Ocean —water heated in high southern latitudes is carried equatorward [sic], to be replaced by colder waters upwelling from below, which inhibits ice loss,” Mark Serreze, director of the National Snow and Ice Data Center, told author Harold Ambler in an email. Read more: http://dailycaller.
It is a bit difficult for me to swallow this in light of the temperature trend in the southern ocean:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 1 is the annual temperature trend in the Southern Ocean according to GISS.
It is also opposite the well understood thermohaline current flows in both the Arctic and Antarctic, where warm currents flow from the equator to the poles, is cooled, surface evaporation increases salinity, and the cold, dense, more saline water sinks, to rise again closer to the equator. The southern ocean is getting colder, not warmer, opposite to the trend stated above.

Figure 2 is the Southern Hemisphere sea ice anomaly inverted to match the temperature curve.
Note how closely these curves match, even though one is annual average data and the other is daily ice anomaly. Just how is it that this high southern latitude supposed heated water is getting colder, not warmer. I’m sorry, but my credulity doesn’t stretch this far.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterYesterday I published a piece by Fred F. Mueller on Germany’s out-of-control renewable energy transition and how it is in fact transitioning over to a disaster.
What follows below is a graphic that proponents of the offshore wind energy industry don’t want anyone to see. It tells the whole story about how (in)efficient and (un)reliable German offshore wind energy really is (Hat-tip: www.achgut.com):

Chart shows the installed nameplate offshore wind capacity (shaded green) and the actual output (blue shaded area) since 2009. Wind’s poor performance and unreliable, wildly fluctuating supply disappoint and risk sinking Germany’s “Energiewende”. Chart source: R. Schuster.
The above chart was prepared by Rolf Schuster, an industrial engineering designer, who during his free time has started a wind power databank in order to check the rosy claims being made by the wind power lobby. The results are not something any fast-talking salesman would want any potential buyer to see. The power that was input (blue) is a mere fraction of the rated capacity (green).
Schuster writes:
If you divide the power fed in (blue) by the rated capacity (green) you get the percent of the rated capacity that actually gets fed into the grid. The linear trend shows a negative tendency – towards 20 percent of the rated capacity. That means: Despite the massively increased capacity in 2014, hardly more power has ended up getting delivered compared to the start of the year. Only one fifth of the rated capacity actually gets fed in.”
Many proponents used to argue that the wind is always blowing at the North Sea, and so a steady supply was a sure thing. Now we have real results coming in. That “steady” wind is only delivering 20% of the installed rated capacity. A fiasco.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Schuster also says that offshore turbines have serious technical problems as well. Foundations are being washed out from underneath; there’s corrosion, and overloads that lead to turbine shutdowns. The harsh conditions of the North Sea a proving much tougher to handle.
There are also major problems with the high-voltage direct current systems that have yet to be solved, Schuster writes. One entire North Sea wind park has been disconnected from the grid as a result. This, Schuster says, “makes one ask if the installation of a major power transmission line from North Germany to South Germany would be a high risk gamble for the German energy supply“.
Green power goes AWOL again!
Also a look at online energy portal Agora here also tracks renewable energy that gets fed into the German power grid. A look at today’s graphic for the last 31 days tells us that once again wind and solar have gone AWOL, and so conventional fuels such as gas, nuclear and coal have to jump in to bail out.

The above chart shows German energy supply and consumption for the last 31 days. Solar power that was fed into the grid is shown in yellow. Wind power is shown in blue. Cropped from Agora. 
Yesterday, February 4, we saw very little wind power getting fed into the grid, less than a gigawatt from a nameplate capacity of some 55 gigawatts of installed capacity – less than 2%! On February 4 wind and solar together virtually fed in almost nothing into the grid. If it had not been for coal, gas and nuclear, the country would have gone dark.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBefore he retired, Professor Fritz Vahrenholt was the CEO of RWE Innogy, the biggest investor of renewable energy. However during his time as CEO, he realized that the renewable energy systems did not live up the promises made by their manufacturers and promoters.
In the July 2014 edition of top agrar, a commentary by Fritz Vahrenholt on Germany’s renewable energy feed-in act (EEG) appeared:
From Die kalte Sonne
(Translated/edited by P Gosselin)
Prof. Vahrenholt: The EEG feed-in subsidy is an obsolete model!
By Fritz Vahrenholt
Berlin has slammed the brakes on biogas. That is overdue. Biogas has distorted the farmland leasing prices, led to ecological damage and put a burden on private households and companies through high electricity prices. The EEG surcharge is at 24 billion euros. That’s 250 euros for every household. That’s why citizens are now looking at green energies far more critically.
And support will decrease when the costs rise further, when industry moves to regions where energy prices are more affordable, and when grid stability is no longer controllable due to the unstable supply from wind and sun.
No wonder economics minister Sigmar Gabriel sees the transition to renewable energy as on being on the brink of failure. Why are we installing in a country that gets as much sunshine as Alaska a photovoltaic capacity of 52,000 MW? Many systems are working only 800 full hours per year. But one year has 8760 hours! In the meantime we are producing at times so much green power that we have to pay money Austria, Netherlands, Poland and the Czech Republic to get rid of it for us. Our neighbors aren’t even happy about it because the surplus unwanted German green energy is making their own power production unprofitable.”
Continue reading [in German] at topagrar.com
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterI spent a few days with my wife in Amsterdam, and so blogging was a bit on the light side. Today’s story is a short one about acid rain and forest die-off. Most people over 40 will certainly recall that one.
Whenever scientists are completely wrong, they hope no one will notice years later and that all will be forgotten.
Such is the case of the 1970s forest die-off scare (acid rain). Back then a “consensus” of scientists warned that the Earth’s forests were being wasted away because of acidic rain produced by man’s emissions from the burning fossil fuels. Lots of background info on this here,
The first warnings of an acid rain induced forest die-off in Germany were sounded by scientist Bernhard Ulrich, who warned that polluted rain was causing the soil to become too acidic for trees, which in turn would soon get very ill and die. Moreover by 1983 there was a claimed consensus. The Frankfurter Allgemeine Zeitung (FAZ) recently wrote on the forest die-off scare:
In the year 1983, an extremely informative study that recently appeared and maintained that during the course of this alarm debate, that there was not a single forest scientist in Germany who did not agree with this diagnosis.”
The leading German daily then summarizes that the acid rain, forest die scare turned up in the end being just a wave of hysteria that had gripped the scientific community. Today nobody hears about the acid rain; the problem has literally just vanished from existence. FAZ writer Jürgen Kaube even asks in his piece: “What ever happened to forest die-off?”
We suspect the same will be true of global warming in about 20 years time. Maybe sooner – especially when we look at the recent record high sea ice levels, recent cooling weather sweeping across the USA and the dozens of predictions of a coming climate cool-down coming from experts.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIt’s early November and now is a good time to look at some of this year’s global crop harvest results. Let’s recall that global warming models projected poor harvests and hunger in the future due to droughts (and floods).
But that is hardly the case…at least certainly for this year. And recall how Joe Bastardi last spring projected a “Garden of Eden” harvest for the US Great Plains. Looks like he was right. The story is similar many places worldwide, and not just the US.
10-foot corn
For example Bloomberg here reports of a record US corn harvest in 2014, writing:
From Ohio to Nebraska, thousands of field inspections this week during the Pro Farmer Midwest Crop Tour show corn output in the U.S., the world’s top producer, will be 0.4 percent above the government’s estimate. Months of timely rains and mild weather created ideal growing conditions, leaving ears with more kernels than normal on 10-foot (3-meter) corn stalks and more seed pods on dark, green soy plants.”
All-time high of 3.631 billion bushels of soybean
Bloomberg also writes here that the US production of soybean “will jump 10 percent this year to an all-time high of 3.631 billion bushels, and inventories before the 2015 harvest will be double a year earlier.”
In Europe the story is the similar. Last May the online marktkompass here already wrote of record wheat harvests:
In all regions of Central and Eastern Europe the weather for growth was close to being optimal and the yield potential has drastically improved.”
“All-time records” in Europe
In Germany’s agricultural state of Mecklenburg West-Pomerania, corn and barley reached record harvests. The online bauwesta reports that both winter and summer barley harvests set all-time records. Overall across Europe Crop Site reports this year’s cereal harvest “has generally been strong in Europe and Ukraine“.
Doom and gloom media silent on bumper crop yields
Moreover, numerous analysts report of falling grain and commodity prices. All of this, of course, is great news for consumers and a planet that still has close to a billion people who do not get enough to eat. Yet the good news is generally not getting reported by the doom-and-gloom obsessed media.
“Bounty of wheat, barley and oats”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Almost every country one looks at in Europe, one is finding record bumper crops this year. The usually gloom-obsessed UK Guardian also reported in September on UK 2014 harvests:
Long sunny spells after a mild winter and early spring delivers a bounty of wheat, barley and oats. […] 2014 could be the biggest yield ever for wheat when the final data is released in October.”
If climate change is supposed to be resulting in poor harvests, higher food prices and acute hunger for the poor, as many experts have warned incessantly, then the opposite must mean that climate change is not happening at all, or that it is having a profoundly beneficial effect for man instead.
Glut of apples
The Guardian also reports of bumper apple harvests and that “growers still face losses due to glut of apples and supermarket price wars.” The Guardian adds, “A cold winter gave the trees a good rest, then plenty of rain – especially in August – helped plump up the fruit, and then a dry September allowed the picking to get started early.”
If anything, all the bumper crops are leading to only one single food crisis: the rock bottom prices farmers are getting for their crops!
“bumper world harvest this year”
thompsonslimited.com here reports that the bumper-crop low-price crisis has also not spared Canada for almost everything from apples to zucchini. It writes that the “world commodity prices are worryingly low for arable farmers following a bumper world harvest this year.”
Russia “in awash in grain”
www.martellcropprojections.com here writes that Russia “is awash in grain from a bumper harvest in the growing season just ended.  The 2014 grain harvest increased to 105 million tonnes threatening to break a record.”
The Crop Site also reports of record rice production in Bangladesh, and bumper maize harvests in Pakistan. Even Scotland’s 2014 cereal harvest “is estimated to be the largest in 20 years, with favourable conditions expected to produce more than three million tonnes of cereals.”
So, if you are not moping about all the good news on this year’s global harvest, and failed predictions of catastrophe, and wish instead to celebrate the good news with glasses of cheer, the wine-searcher here reports that France is “looking forward to a bigger and better wine harvest“. Indeed all the natural ingredients needed for fermenting or brewing your favorite spirit appear to be in bountiful supply this year.
Visions of Ehrlichian-style widespread crop failures and mass starvations postponed yet again. And they show absolutely no signs of ever materializing any time soon.
In fact one could easily argue that the world is better fed today than at any time in human history. We can in part thank higher CO2 concentrations and warmer climate for that.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe descriptions of urban warming dwell on the heating of the air by the local infrastructure. There is more to it than simple conduction to the air mass from warmed surfaces.
In the far infrared, where the peak radiation wavelength is determined by the temperature, much of the energy from warmed surfaces is absorbed by the greenhouse gases in the atmosphere within a meter or so. These gases then re-radiate to any other nearby surfaces or gases further away and conduct by collisions with other air molecules to heat the air. There are also windows in the infrared spectrum that let warm surfaces radiate directly to other surfaces. Thus for a temperature measuring instrument, the temperature measured is a combination of the air temperature conducted to the thermometer by air flowing past it and IR heating from nearby surfaces. This is why in the polar regions when measuring very low temperatures, a person approaching the thermometer will raise the temperature reading.
This second source of increased temperature causes “urban warming” even where the location is strictly rural. A measuring station at an isolated research station or farm can have “urban warming” when the thermometer is in close proximity to just one heated building.

Figure 1 is a visible and FLIR IR image of the MMTS station at the Perry, Oklahoma Volunteer Fire Department. The image is from an article by Anthony Watts here, used by permission.
Painting the MMTS white only reduces direct heating by sunlight at visible wavelengths. In the long wavelength IR, any paint, black, white, or any other color, has the same emissivity, more than 0.9, and will absorb IR equally well. In Figure 1, the west-facing uninsulated door is very warm compared to the north-facing wall. It is being heated both by the sun and the building interior. The MMTS is slightly warmer (perhaps 2 or 3 degrees) than the mounting pipe. The pipe is unpainted, somewhat shiny, with a lower emissivity, reflecting more of the IR. Thus it appears black, where the MMTS is a warmer dark purple.
Pierre has posted on a German study of the temperature shifts with the installation of electronic thermometers here. This shift is due to the different way a glass thermometer in a wooden shelter responds to IR in the vicinity and the way a compact modern MMTS responds. There is also the issue of the need for cabling that leads to a distance bias to the nearest building.
Every weather station should be checked for IR emissions in the “view-shed”, the surrounding surfaces and buildings. This should be done at several hours of the day, to catch sunlight warming all the surfaces, and internal building heating variations.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterLooks as if Europe’s thing of the past, wintertime snow, has once again become a thing of summertime in Switzerland…at least down to 6000 feet in elevation. Cool weather swept across parts of Central Europe this week bringing snow in the Swiss Alps.
Although summertime snowfall high up in the Alps is not an unusual occurrence, snowfall down to 6000 feet elevation IN JULY is something that wasn’t supposed to happen nowadays – especially with increased concentrations of “heat-trapping” greenhouse gas CO2.
20 inches of snow
Last Tuesday, July 8, the Swiss online Blick here reported meteorologists were predicting snowfall down to 1800 meters elevation (6000 ft.), warning that up to 50 cm (20 inches) of snow in the Canton of Valais. Blick writes that the snowfall presented a problem for grazing cattle, which would either have to be brought down to lower elevations or housed in mountain shelters stocked with feed.
Passes closed, avalanche warnings
By evening, the online Südostschweiz.ch reported that the Furkapass had been closed.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




By evening the passes over Susten and the Furka were closed, the TCS Traffic Information reported. The Matterhorn Gotthard railway (MGB) allowed additional car wagons to travel through the Furka Tunnel due to snowfall Tuesday evening at the Furka.
Snowfall fell to elevations of approximately 2000 meters, according to the Swiss Met. At elevations of 2000 meters there was a blanket of snow by evening. There was more snow in the high mountain elevations over 2500 meters.”
By Wednesday, July 9th, the online Blick here reported Swiss authorities had issued elevated avalanche warnings for elevations near 3000 meters. At Germany’s Zugspitze, the country’s highest peak, 15 cm of fresh snow fell. German meteorologists point out that snow at such elevations at this time of year are not unusual. Well, if the “usual” is happening, then the climate can’t be changing that much.
“Snowed in”
Today, public SRF Swiss Radio reports here that mountain excursions and tours are being cancelled due to the cold and snowy weather, thus delaying the start of the season.
In Switzerland there are an estimated 1500 mountains guides. Many of them have jobs on the side, and so when tours are cancelled they have other work. But the guides are also hit by the bad weather. A part of the 150 mountain shelters of the Swiss Alps Club SAC are even snowed in.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMichael Krüger of the German climate blog Science Skeptical here has an analysis of Germany’s electrical power cost development since its renewable energy feed-in act was enacted in 2000. Germany’s Feed-in Act, the so-called EEG Gesetz, requires power companies to buy at exorbitant rates all renewable energies produced. Result: sky-rocketing prices.
I’ve shortened the text somewhat while translating.
===================================
Germany’s electricity price just behind leader Denmark in the EU: Since the introduction of its Feed-in Act in 2000, the electricity price has more than doubled!
 By Michael Krüger
 (Translated, edited by P Gosselin)
Since the EEG renewable Feed-in Act took effect in 2000, it has been promised by green energy proponents time and again that the power price would fall in Germany. So what does the reality look like today? On this subject I have found the news from the Bundesnetzagentur (Federal Network Agency) on the latest power prices in the daily media.

The first chart above is a comparison of the per kilowatt-hour price of power for all EU countries. Germany (Deutschland) now has the second highest electricity prices after Denmark. The second chart shows the per kilowatt-hour feed-in surcharge levied on consumers. The final chart shows the cost of one kilowatt-hour of electricity households must pay – currently at 29.13 cents per kilowatt-hour.
In 2000, when the Feed-in Act was introduced, Germans paid only 13.94 cents per kilowatt-hour, which at the time had hardly changed since German reunification in 1991. After the liberalization of the power market in 1998, the price of power even dropped some. Today, in 2014, the price is now 29.21 cents per kilowatt-hour, i.e. it has more than doubled in 14 years. The cost-driver is the EEG Feed-in Act surcharge, which has risen from 0.41 cents in 2003 to 6.24 cents today. It represents 22% of the cost of a kilowatt-hour.
Conventional power plants inefficient in standby mode
Because of the expansion of renewable energies and because they must be bought first by the power companies, the conventional power plants no longer operate at full-capacity. If the wind blows briskly and the sun is shining, then the conventional power plants must reduce their production. And when the wind dies down and the sun doesn’t shine, then the conventional power production must ramp up again. As a result the capacity utilization and the output of the conventional power plants is substantially reduced and generation becomes inefficient and more costly. A businessman who is only allowed to sell when the weather is bad of course cannot earn anything and would soon go bankrupt. The very same is true today with conventional power in Germany. 
Moreover, the situation is getting worse as renewable energy continues to expand. Conventional power plants have since become so uneconomical that power plant operators prefer not to build any new ones and to switch off the old ones. New plants are no longer being planned and old power plants are being left on because the federal government has made it illegal to shut them down in attempt to keep the supply intact. Naturally all the added costs ultimately have to be borne by the power consumer.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Windparks to nowhere
Renewable energy producers are paid compensation to the full amount – even when their power is unneeded and cannot be fed into the grid because no line is available to feed the power into the grid. This is the case because grid expansion is progressing too slowly to keep up with the expansion of renewable energies. There exists windparks for example, that are located away from any grid feed-in point and are unable to feed in the power. However, the consumer still has to pay for the power they never feed in. Other costs that need to be passed on to the consumer are the expansion of the power grid, which is necessary for transmitting the renewable energy, for example to bring the wind power produced at the North Sea to southern Germany and to deliver solar energy produced in the south to northern Germany.
Another cost driver is the Emissions Certificates Trading introduced for CO2 in 2005. Currently CO2 emission certificates cost about 5 euros per tonne, but were as high as 30 euros. These were costs that naturally got passed on to the consumer. German environmental activist group BUND announced with glee that expected rising costs of emissions trading certificates would add another 2-4 ct/kwh. Super.
Cost of green energies: social and environmental blight
Summary: The points listed above have resulted in Germany’s electricity prices more than doubling since 2000. An end to the rising price spiral is nowhere sight despite more promises from the renewable energy proponents. Power consumers in Germany now have to pay almost twice as much as the consumers in neighboring France (which relies heavily on nuclear power) and more than double than consumers in the USA. The EEG renewable energy Feed-in Act does not decrease the prices, rather it causes them to skyrocket. It is only a question of time as to how long Germany can keep this up.
Proponents of renewable energy often like pointing to the social costs of conventional energy, but they ignore the social costs of renewable energies, which take up lots of natural space, crowd out wildlife and litter the landscape. Then there are the economic costs and social damage that high power costs inflict. Production and jobs move to foreign countries where energy and labor are cheaper.
Electricity is increasingly becoming a luxury
Consumers are seeing less money in their wallets, which in turn impacts buying power. Electricity is increasingly becoming a luxury, and energy poverty is spreading. The number of consumers getting their power shut off is on the rise in Germany. Just in 2011 in Germany, 6 million households (15% of all German households in Germany) were threatened with a power cut-off. The energy supply cut-off to 1 million households had already taken place. The power was turned off for 300,000 households. The trend is upwards.
The blame of course for all the misery gets placed on the evil power companies, grid operators, and the former conservative-free democrat government of the previous years.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Kelley et al study is increasingly looking like a politically bought panic paper, designed to send out a certain message and mislead the public.
What is especially tragic about the whole nonsense is that the paper only serves to shift the focus away from the real causes behind the worsening tragedy in the Syrian region.
A couple of days ago I wrote about a Spiegel piece that shredded the paper and exposed it as very shoddy work of science.
At Twitter the author of the Spiegel piece, Axel Bojanowski, got a reply from another rather high caliber German journalist, Gabor Paal, who confirms that the situation in Syria has much less to do with climate change, and much more to do with lousy land-use and agricultural practices.

.@Axel_Bojanowski ich war 2008 in syrien. Forscher aquirierten Gelder mit Verweis auf ""klimawandel"". Landnutzung war eindeutig größeres Prob
— Gabor Paal (@GaborPaal) March 9, 2015

On March 7 Bojanowski wrote:
Did climate change really spark the Syria War as claimed? The basis for that is flimsy.”
On March 9, Paal responded to Bojanowski:
@Axel_Bojanowski I was in Syria in 2008. Scientists acquired funding with reference to ‘climate change’. Land-use was clearly the bigger problem.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So what we have here is yet another journalist casting grave doubt on the claims made by Kelley et al.
Paal provided the link to a 2008 radio documentary on Syria he had produced with the focus on the crop failures that the Middle Eastern country had been experiencing and their causes. The radio documentary was featured at SWF South German Broadcasting. Throughout the documentary the emphasis on the reasons for the crop problems in Syria was squarely on land-use and poor agricultural practices, with climate change not playing any real role.
The documentary begins by explaining how Syria is divided into 5 different climate zones. In Zone 5, the largest and most arid, groundwater has been pumped out to such an extent that vegetation can no longer thrive. At the 10-minute mark:
More than half the country belongs to Zone 5, the steppes and desert region. Here it rains less than 200 mm per year. Zone 5 is government property. There are no privets lots. Agriculture would be possible here only with irrigation, but the water table has dropped so much that the steppes have become so barren that the government has forbidden all use. The blame for this is not climate change, but rather the way the land is managed.”
The documentary explains how 75% of all farmers raise sheep to earn a living, and that millions of sheep are living where less than 150 mm of rain falls yearly. Vegetation has no chance. “15 – 20% of the steppes are lost and maybe we cannot recover them.” The documentary adds that there are 15 million sheep in Syria and that the figure is 4 times more than 10 years ago.
“Media fixated on climate”
Another problem the region faced, Paal said, was the threat of the UG 99 fungus that threatened the region’s grain crop.
At the very end of the SWR report Paal stated:
In the public media reporting, agricultural research has not made any progress. The media are fixated on climate and the focus on the ground beneath their feet has been lost. And now in the wake of the food crisis, international agricultural reseach has the chance to benefit once again.”
Today, some 7 years later, Kelley et al tells us that this has not come to pass – tragically. The focus still remains on the bogus problem of climate change and people are suffering more unimaginable misery than ever because of it.
Someone needs to go to jail.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterTwo days ago I wrote about the first part of an analysis (on Germany winter temperatures) by Kowatsch and Kämpfe appearing here at EIKE. Winter temperatures in Germany have been falling for a quarter of a century now. Much to my satisfaction, that post has been widely shared among social media.
Today I’m writing about the second part: What is the primary driver behind Europe’s variability, i.e. what causes periods of cold winters and periods of milder winters? The main drivers, Kowatsch and Kämpfe conclude, are oceanic cycles.
Figure 1 below shows a plot of German winters since 1881. Shown is the temperature lower curve and the number of days with westerly winds (upper curve) – along with their corresponding smoothed curves.

Figure 1: Germany’s mean winter temperature (lower blue curve) follows the course of the frequency of days with mild westerly winds (W, SW and NW, violet upper curve). Both are accompanied by a smoothed curve).
It’s no surprise that the more days a winter has with winds coming from the west (Atlantic), the milder the winters turn out to be. A correlation here does not surprise us. Here the mechanism that drives Europe’s winters is the North Atlantic Oscillation (NAO), which is the pressure difference between southwest Europe (Portugal to the Azores) and northwestern Europe (Iceland).
When the NAO is very positive it means there is a powerful Azores high and a powerful Icelandic low which serve to pump Atlantic air eastwards into Central Europe (Figure 2, right). If the Azores high and the Iceland low are both weak, then cold air from Eastern Europe or Siberia can make its way over across Europe and the winters tend to be much colder (Figure 2, left).

Figure 2: Prevailing weak NAO pattern shown left leads to cold Europe winters. Strong positive NAO pattern shown right leads to mild winters (Source: UKMO).
Next Figure 3 shows the NAO chart for the past winter, which was most of the time was highly positive, meaning many mild westerly winds swept in from the Atlantic and over Europe.

Figure 3: Winter 2014/15 saw an overwhelmingly positive NAO, thus producing a mild winter for Western and Central Europe. 
So what drives the NAO air pressure difference? Kowatsch and Kämpfe have analyzed this and found there is a strong correlation between NAO and the Atlantic Multidecadal Osciallation (AMO). Figure 4 below shows the inverse relationship between the AMO and the winter-time westerly wind frequency over Europe:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 4: The higher the AMO value, the less westerly weather that occurs.
Not only does the AMO drive the NAO, but it is also is a major factor driving Arctic sea ice extent. Arctic sea ice extent does not drive the winters over Europe, as some scientists have been hypothesizing over the recent years. Rather it is the AMO that is driving the Arctic sea ice and the European winters as well.
Although good satellite sea ice data records for the Arctic go back only 35 years, one sees a distinct relationship between the AMO and wintertime Arctic sea ice, see Figure 5 below:

Figure 5: As AMO values rise (green curve), sea ice area (blue) reduces significantly.
EIKE adds:

And there are clear indications that this relationship applies over the long-term as well. During the 1930s, i.e. during the last AMO positive phase, large melting of the sea ice and strong melting of the Greenland glaciers were observed.”

And when the severe winters of 2009/10 and 2012/13 caused the proponents of the global warming theory to scramble for an explanation, they concocted and put out the tale that “melting Arctic sea ice was disturbing the large scale circulation and thus favored winter cold at the middle latitudes“.
The scientists claimed that especially the low levels of Arctic sea ice in September were suddenly responsible for causing cold winters. Yet, the following chart shows no relationship at all:

Figure 14: The extent of September Arctic sea ice has no impact whatsoever on winter temperatures over Central Europe (Germany). Arctic sea ice cover in blue; Germany winter temperatures in red. The same is true for other times of the year (autumn ice cover or winter ice cover to winter temperatures show no relationship).
EIKE warns that the climate system is much more complicated than meets the eye: “Still the complicated and yet to be researched relationship between ocean currents, AMO, sea ice and large weather patterns have with a high probability an impact on Europe’s climate and weather, and there exists no easy explanations”. Studies have shown that solar activity also play a role in Europe’s winters.
At the end, Kowatsch and Kämpfe look at the (lack of) success that institute’s and experts have had in forecasting the winter of 2014/15. It shows that the science of forecasting is lacking terribly. Of the 7 forecasts examined, 2 were completely faulty, 3 were poor, and 2 were only about half correct and would not earn a grade any higher than a C -.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterAt EIKE distinguished German physicist and climate expert Prof. Dr. Horst-Joachim Lüdecke writes how we are witnessing a notable paradigm shift in climate research today: the resurrection of medieval scholasticism. In plain language: the science of the Dark Ages.

German climate physicist Prof. Dr. Horst-Joachim Lüdecke says today’s climate science paradigm has shifted to a “medieval scholasticism” and is a real threat to science and society as a whole. Photo: EIKE. 
Scholasticism dominated medieval western Europe and was based on the writings of the Church Fathers, with strict adherence to traditional doctrines. To say the least, it was effective in stifling enlightenment.
The breakthrough from this crusty, dogmatic approach, Lüdecke writes, came with Galileo, who gave highest priority to systematic and numerical measurement, which today remains the standard method of science. With Galileo’s approach hypotheses or theories that are not confirmed by measurements get discarded and are no longer pursued. The method led to giant leaps and bounds in technology, medicine and science, from which today humanity is benefitting immensely.
Richard Richard Feynman summarized Galileo’s approach beautifully, saying that if a hypothesis disagrees with observations, then it’s wrong.
This fundamental approach, the Lüdecke writes, is no longer in use in climate science and, what is worse, the old medieval scholastic method is even now dangerously invading other fields of science.
According to Lüdecke, the key question today: Is the climate change witnessed since 1850 unusual, and thus due to man, or is it well within the range of natural variability the planet has seen throughout its history? The German physicist says a hypothesis’s burden of proof is clearly not on its skeptics, but on the one proposing the hypothesis. He writes:
It is senseless to favor a certain hypothesis – senseless according to our still valid scientific paradigm – when no confirming measured data can be shown to support it. One can occupy himself with a hypothesis, put it at the center of his research, and even have complete faith in it. However one cannot use it as a basis for taking rational action without first having confirmed measurements. In summary: If we cannot observe any unusual climate activity since 1850 compared to the times before that, then we have no choice but to assume natural climate change.”
In order to assume there has been “unusual activity”, Lüdecke says, it would be necessary to have comprehensive data about the oceans before 1850. This doesn’t exist, and so a comparison is not possible. Lüdecke reminds: “It is mandatory to prove that the climate data since 1850 are indeed unusual when compared to the period before that.” A comparison is already very difficult to do with atmospheric temperatures. With ocean data: “Who today can tell us what temperature distributions the oceans had back during the Medieval Warm Period?” Lüdecke writes Assuming that today is unusual without being able to compare it to anything from the past is not science at all, he tells us.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




When it comes to extreme weather events, there are plenty of paintings and recorded accounts showing that they too existed earlier on, and that today’s events are nothing new, Lüdecke writes. Even the IPCC has reached that conclusion. The German climatologist puts the assumptions of more future extreme weather events in the category of “crystal balls” and not modern science.
Prof. Lüdecke also blasts the over-emphasis on climate models, writing that “the models fail already for the past” and that they cannot even predict the next El Nino correctly or the missing tropospheric hot spot. He writes:
Using the R. Feynman yardstick these climate models are not only inaccurate or a bit false; they are totally false. […] Anyone selling climate forecasts from climate models as scientific is using a medieval paradigm. He is conducting moral sciences instead of physics.” 
Ouch. Lüdecke also then calls the alliance between the IPCC and policymaking “dubious” and one that was set up with the target of reaching an already predetermined result. He calls the manner in which policymaking is moving ahead “embellished nonsense”.
In his conclusion the German professor advises those engaged in a discussion with alarmists, or listening to a presenation by an alarmist, to not go easy on them. There are three points, he advises:
1. The modern science paradigm of priority on measurement over theoretical model remains valid. The climate alarmist must prove that his hypothsies is confirmed by observations and measurements. It is not up to you to prove his hypothesis is false.
2. When the climate alarmists “starts beating around the bush” insists he name a peer-reviewed paper that proves, based on measurements, that the climate change since 1850 is unprecedented compared to earlier times (there isn’t any).
3. Don’t let yourself be drawn into the discussion over climate models. That the models are unable to describe the climate development means they are false, as to point no. 1.”
The distinguished professor ends by blasting climate policymakers, warning they are bordering on “criminal activity” in their conscious misuse of science to formulate policy:
We are allowing hundreds of thousands of people in the poorest developing countries to starve in order to be able to finance climate protection and energy transformation that are not based on today’s valid science paradigm. That is not only idiotic, but also borders on criminal activity by the politically responsible persons.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOne thing we can be predicted with very high certainty: On March, 20, 2015 most of Germany will see a partial yet substantial eclipse of the sun.
40 gigawatts of rated power blocked in just minutes!
Normally that would be no big deal. But for the first time in history, due to Germany’s massive installed solar capacity of 40 gigawatts, an eclipse of the sun could mean a collapse of Germany’s intense power grid, with possible ramifications for the European power network.

Animation: A. T. Sinclair/NASA (http://eclipse.gsfc.nasa.gov/.html)
Today’s print edition of Spiegel features an entire story on the coming event, should skies be clear. At it’s online site here it gives a preview of the upcoming event, writing:
The German power grid operators are dreading March 20, 2015. On this day Germany will see a partial solar eclipse during the morning. Should there be no clouds in the sky at this time, all solar power generating systems all over the country would be feeding in drastically less power into the grid in just a matter of minutes – and the grids would become dangerously destabilized.”
Already grid operators are scrambling to avoid such a scenario, and are considering refusing the feed in the power of large solar power plants on that day. Even though the eclipse will sweep across Europe around mid morning, a time well below peak solar power production, no large enough conventional back up system is on hand to react that quickly and that massively on such short notice. Another possibility would be to request large energy consumers in industry to scale back their consumption for the period the eclipse will have an impact.
German T-Online writes:
The shadow of the solar eclipse on March 20, 2015 will sweep across the North Atlantic. Thus in North Germany almost 83% of the sun will be blocked, so reports the website sonnenfinsternis.org. In South Germany it will still be at least 67%. Starting at 50 percent coverage, a solar eclipse is easy to notice.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterReader Ed Hoskins sent me the following temperature graphic for Central England by e-mail. I’d say the chart says it all…linear trend of more than 6°C COOLING per century. It’s worse than we thought!

Bare ground in the winter will soon be a thing of the past!
Clearly temperatures have been sinking for the last 10 years. The “missing heat” is also nowhere to be found in England. The Central European trend is similar.
In fact, many places globally are showing a cooling trend over the last decade.
So when it comes to disproving warming, what more could they want!
References:
http://www.metoffice.gov.uk/.dpuf
http://woodfortrees.org/plot:12 
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSome scientists devote their lives painstakingly assembling fragments of evidence to piece together a picture of the past. They deserve tremendous credit. Unfortunately today we appear to have inept or sleazy scientists who take collected data and destroy it – thus permanently blinding our view of the past. These people deserve to be loathed.
Ed Caryl presents an essay of such an example.
==============================
What Is The Temperature Trend At Barrow Alaska?
By Ed Caryl
If you ask this question of Wolfram-Alpha, the online Guru that Siri depends on for answers, you get this plot.

Figure 1 from Wolfram-Alpha.
If you look at all the available temperature data bases for Barrow, you get multiple answers, none that agree, and none agree with Wolfram-Alpha, or even come close.

Figure 2 is a plot of Barrow temperatures from five different sources. The BEST data nearly coincides with the Barrow Airport NWS Average (the blue line us under the red line) until the last decade. The Russian data ends at 2000.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




During the search for this data, I came to the conclusion that RAW data simply does not exist for any stations except for the filled-out sheets from COOP stations or the electronic reports from the automated stations. All the on-line data, whether from BEST, NOAA, USHCN, GHCN, GISS, or wherever, has been manipulated in some way. USHCN, NOAA and GHCN seem to be the prime manipulators, filling in missing records with estimates, inventing data for “zombie”stations that won’t die, and “homogenizing”data to supposedly correct for UHI. GISS then takes the GHCN data and adds their own special sauce where they think it is necessary.
Of the 19 stations examined in my previous article, only Barrow received the “special sauce”. For all the others GISS simply passed along the GHCN data with no changes. All the changes in the last three years and nine months in those GISS files were GHCN changes. But Barrow is special. Here is what GISS did to Barrow

Figure 3 illustrates the GISS “homogenization” change to Barrow temperatures (the green stair-steps), adding more than one degree per century to the warming trend by cooling the past.
Without the change illustrated in figure 3, 1940 would be the warmest year by 0.04°C. This change obviously has nothing to do with Urban Heat Island, it is in the wrong direction. Changes like this give a whole new meaning to the term “hutzpah”.
So from where did Wolfram-Alpha get their data? I have no idea. The source they cite has no connection to climate. It’s appearance suggests it was made up from whole cloth.
So who do we trust with the temperature records? We certainly cannot trust GHCN and GISS, nor any of the other agencies because they get their data from GHCN. GISS simply further corrupts that data. They are also continuously changing the data on a monthly basis, not just the previous month, but months in the distant past. For an excellent review of the “dancing data” see this recent article, and the associated comments.
Who can we trust? No one.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter “CO2 Has Never Been This High In 600,000 Years!”… FALSE!
By Ed Caryl
One item on the list of catastrophes that the CAGW climatists claim is that at nearly 400 ppm, the CO2 concentration has never been as high in hundreds of thousands of years. The number quoted is flexible, sometimes 600,000, sometimes 800,000.
It is true that in the ice core figures, CO2 measures from 180 to 200 ppm during the coldest periods and peaks at around 300 ppm during the interglacial periods. But it is well known that the ice core measurement resolution is a few hundred years for recent times and spreads to a few thousand years for the most ancient measurements. Thus the ice core measurements can’t show short periods of high atmospheric CO2.
This was demonstrated in my last article on the brief spike of CO2 in the Younger Dryas period 12,800 years ago from the paper by Steinthorsdottir et al.

Figure 1
Figure 1 above is a plot of CO2 and Greenland temperature during the Younger Dryas. The purple diamond marks the time of the nano-diamond (ND) event as seen in the Greenland ice cores. The horizontal time error bars on the peak CO2 data bring the ND-event within the time  period of the CO2 peak. The stomata index is carbon 14 dated, which has a time error of ±150 years.

Figure 2 is a plot of temperature versus CO2 concentration from the Figure 1 data. The trend line shows that the relationship is negative; a temperature rise of 1°C occurs when CO2 falls by 2.5 ppm during the 2000 year period covered by the stomata proxy data. The R2 value is very low, indicating that this trend is very likely zero. It is apparent that the brief high CO2 concentration did not cause any warming, as it occurred when the temperature was approaching the lowest recorded by the ice core data.

Figure 3 is a plot of the Dome Concordia CO2 measurement over the last 22,000 years. The ND event time is marked by the red dot.
The ice core data can be seen to get smoother as it gets older. Only the stomata data shows the 400+ ppm peak at the ND event. The ice core data cannot show a brief spike in CO2, because at Dome C, the snow (firn) to ice transition takes 100 years or more to close the tiny bubbles that sample the atmosphere.
The ND event was probably caused by a kilometer-size comet that came into the atmosphere over what is now Canada. It likely came in at a shallow angle, like the Chelyabinsk object in February 2013. It is thought to have exploded over the Laurentide ice sheet, with some pieces impacting in what is now Quebec, New Brunswick and Nova Scotia, and others continuing on to impact as far away as the Pacific Ocean. The intense thermal flash ignited all the forests of North America, leaving a soot layer laced with impact-generated particles and raising the CO2 level to more than 400 ppm as seen in southern Sweden in the leaves of the following year.
There is another stomata study, covering eastern Canada. The trees in eastern Canada were burned away, so the stomata data from one location, Pine Ridge Pond, shows a lower peak, and another, Splann Pond, no peak at all. The trees furnishing the leaf stomata needed to re-grow, which took 20 to 40 years or longer, depending on the number of viable seeds in the ground and local conditions. During that time, CO2 was falling back to normal levels.

 Figure 4 is from Mcelwain, J. C., Mayle, F. E. and Beerling, D. J. 2002. Stomatal evidence for a decline in atmospheric CO2 concentration during the Younger Dryas stadial: a comparison with Antarctic ice core records. J. Quaternary Sci., Vol. 17 pp. 21–29. ISSN 0267-8179.
This data is from Pine Ridge Pond in New Brunswick. The top line is a summer temperature proxy from sub-fossil chironomid remains (Midges). The numbers 1 and 2 marks the peaks of the Bölling and Allerød warm oscillations. The lower traces are the stomata proxies with upper and lower 95% bounds. The number 2 here marks the ND event CO2 peak. The CO2 data point at 1 does not appear in the Figure 1 data from Sweden. The total time for the CO2 level to fall back from 400 ppm to 200 ppm appears to be 100 years or less.
Both Figures 1 and 4 show temperature slowly rising during the Younger Dryas as CO2 concentration is slowly falling.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 1 has a ±150-year error in the carbon 14 age data. The spike in CO2 does not line up with the ND event. In Figure 5, a 150-year correction is applied to line up these dates.

Figure 5 is a plot of the southern Sweden stomata data shifted 150 years to the right to align with the ND event.
Figure 6 below is the corresponding XY plot of Figure 5. In the Swedish data there is no stomata data on the temperature rise out of the YD period between 11,500 and 11,750 years ago. There appears to be no relationship between CO2 and temperature. The trend is very close to zero with extremely low R and R2 values.

There should be a CO2 increase as temperature rises and the oceans begin to out-gas dissolved CO2. We see this increase in the longer Canadian stomata data in Figure 4.

Figure 7 is an XY plot from the Figure 4 data. Here we see that CO2 rises at about 4 to 8 ppm for each degree of summer temperature rise at the Canadian latitudes. There appears to be a small delay of up to 150 years between temperature rise and CO2 rise as CO2 peaks always appear after temperature peaks by about this amount in both stomata data sets.
From these two papers we learn the following:
– A large sudden rise in CO2 decays away in 100 years or less.
– A large sudden rise in CO2 does not cause a rise in temperature.
– A large rise in temperature causes CO2 to rise, not the other way around. All the rises in CO2, including in modern times, came after temperature increases.
– The delay between temperature rise and CO2 rise is somewhere between zero and 150 years.
We can see that delay in modern times. The rise in temperature after the little ice age began in the late 19th century, accelerating after 1910. The rise in CO2 began about the time Keeling started measuring it in 1959, accelerating after that, a delay of about 50 years.
Is the rise in CO2 all due to temperature rise? No. It is a combination of temperature change and increased fossil carbon emissions. Will those emissions cause temperature to rise further? No. The large rise at the ND event caused NO temperature rise in either of the data sets above.
For further information on the Nano-Diamond event see:
– www.jstor.org/stable/10.1086/677046 Nanodiamond-Rich Layer across Three Continents Consistent with Major Cosmic Impact at 12,800 Cal BP. Charles R. Kinzie, et al. 2014
– http://www.news.ucsb.edu/2014/014368/nanodiamonds-are-forever#sthash.Jz8DHJU3.dpuf
– http://cosmictusk.com/university-of-chicago-nanodiamonds-prove-cosmic-impact-responsible-for-ancient-climate-change/
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter unduh Game Qiu qiu 99 Online Android
website judi yg sediakan link unduh game qiu qiu 99 online android saat ini sanggup kamu mainkan dgn nominal deposit se besar 0,5�gi kamu pendaftar mula-mula dalam wujud cashback & mampu kamu jadikan juga sebagai salah satu aset pemasangan taruhan. Bonus yang lain pun dapat kamu temukan bersama gampang, baik bonus refferal atau bonus mingguan. seluruhnya info tentang promo, & bonus ini dapat kamu temukan di kolom promo web judi game online duit ori. tidak cuma itu, disana kamu pula dapat menonton live berunjuk rasa berkaitan permainan yg kamu inginkan, dgn adanya faktor ini maka kamu mampu menentukan bahwa pedoman trik bermain judi online duit ori yg kamu pahami mampu kamu terima & kamu aplikasikan kembali. Salah satu kelebihan yg terdapat di agen judi game online ini yakni kamu tak bakal merasa adanya kebohongan publik yg dilakukan agen sebab belum pun meraih jackpot yg diberikan. faktor ini dikatakan begitu, sebab terhadap website judi online tersebut disediakan kolom siapa yg jalankan deposit terakhir kali, siapa yg jalankan withdraw terakhir kali & siapa yg mendapati hadiah jackpot mampu kamu ketahui dgn rincian. 
Sebelum kamu mengetahui pedoman trik unduh game qiu qiu 99 online dgn cuma-cuma ini, kamu dapat lewat proses pendaftaran atau pelaksanaan akun di website judi game online Indonesia, kamu dapat menikmati beraneka kemudahan yang lain. Salah satunya merupakan kamu dapat serentak lakukan pengisian formulir yg disediakan bersama serta-merta, sesudah selesai kamu dapat segera menekan tombol setuju & tunggulah beberapa diwaktu sampai notifikasi atau pemberitahuan masuk kedalam email yg kamu punya. janganlah lupa utk menyiapkan koneksi yg nomor wahid segera, factor ini kamu melaksanakan buat mempercepat proses pendaftaran & mencegah adanya pengulangan pengisian formulir yg di mana mampu pass menyita saat kamu. 
sesudah itu, sebaiknya kamu klik kolom trick main apalagi dulu, faktor ini kamu melakukan guna menentukan apa yg sudah kamu pelajari di website tersebut telah kamu pahami. Usahakan buat senantiasa melaksanakan logout sesudah kamu selesai jalankan pemasangan taruhan atau kalau kamu sudah selesai melaksanakan permainan judi online tersebut. jangan sampai hingga data yg sudah kamu masukan mampu di hacker oleh para pihak yg tak bertanggung jawab nantinya. sebab kepada kala pengisian data diri di kolom pendaftaran, kamu dapat diperingatkan buat lebih berhati – hati, & dikala berjalan kecerobohan, maka website judi game online ini tak dapat bertanggung jawab dapat factor tersebut.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThey’re back.
Hans-Joachim Schellnhuber and his WBGU have just released their latest Special Report: Climate Protection as a World Citizen Movement. The 126-page report is the 9th of its kind since the first one was published in 1995.

Professor Schellnhuber telling German Parliamentarians to act as he and his WBGU recommend, or else sea levels will rise 230 feet. Photo cropped from bundestag.de.
Totalitarian designs
The latest Special Report is shrill and the underlying message is: Time is running out and unless policymakers do as us German scientists say, the world will end in catastrophe. The Special Report suggests that the normal democratic processes are failing and that governments must start heeding the instructions of the elite German group of Potsdam scientists. Schellnhuber, a person who openly admits having no background in sociology, insists that he and his fellow WBGU scientists be given the helm in all decision matters concerning climate policy.
Schellnhuber, the WBGU Chairman and Director of the alarmist Potsdam Institute for Climate Impact Research (PIK), once recommended a watering down of democracy and more policy-making power being placed in the hands of far-sighted “experts”.
4 recommendations
The alarmist, climate doomsday obsessed site Klimaretter here writes that Hans Joachim Schellnhuber not long ago appeared before German Parliamentarians to present the “impending climate catastrophe” up close and “to explain the four recommendations of the Council”.
The climate alarmist Klimaretter gives their four recommendations:
First recommendation, Klimaretter writes:
First the expertise of climate science must be securely anchored in the political process of climate action. Also when, as Schellnhuber emphasizes, policy making and science are of two different realms, science is essential for keeping the world climate policy on course: ‘Without a compass, you cannot steer a ship.'”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Here we see Schellnhuber & Co. are not content with simply supplying governments with data, but they also insist on being the ones guiding future policy for global society. But how can we know that their science is not being tainted by their political convictions? We can’t. This is why it is so dangerous to put so much into the hands of such a tiny group…who happen to be the most alarmist at that.
The second recommendation, Klimaretter writes:
Secondly there should be the right for countries to file climate protection lawsuits in constitutional courts in order to increase the societal pressure on the governments. A strong involvement by the civil society is decisive in pushing climate protection forward. The ‘global societal contract for climate protection’ does not only manifest itself in demonstrations such as the recent one in New York, but also in the strengthening of the Divestment Movement.
Not only do the WBGU scientists want to be the ones running planetary policymaking, but they want it institutionalized.
Third recommendation:
Thirdly the two-degrees Celsius target has to be established as international law because only by limiting global warming to two degrees Celsius can the consequences for the societies in many countries be managed. A continued business-as-usual CO2 emission would not only lead to a melting of the Greenland and Antarctic ice sheets, but also of the East Antarctic. That would bring about a sea level rise of 70 meters.”
Here the scientists, who to many readers, by now are surely beginning to appear as the quintessential mad scientists, are claiming that sea levels will rise and drown large parts of the planet if their requests do not become binding international law. Hard to be believe they’ve made it this far.
Fourth recommendation
Schellnhuber warns that time is running out and is calling for “flat zero” global carbon emissions already by the year 2070 in order to reach the 2°C target. “At the latest by 2030 Co2 emissions must reach their peak and start downward.”
That demand, and their seemingly complete unawareness of the 18-year pause and growing scientific literature showing only moderate CO2 sensitivity, suggests that the WBGU are very remote from reality.
Since the WBGU was established in the early 1990s, they’ve published 9 lengthy special reports and 14 even lengthier flagship reports…all pushing for radical societal transformation. Seems the Potsdam scientists are more preoccupied with being the architects of social adventurism than serious scientists objectively looking at the recent data and findings.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe German media are giving time and space to skeptical voices.
The latest is a report appearing in Germany’s print high-profile national daily the Frankfurter Allgemeine Zeitung (FAZ) which features climate economist Richard Tol titled: “The apocalypse won’t take place“.
Image above, right: FAZ
The subheading reads: “Climate economist Richard Tol sees the consequences of global warming as manageable – he has become a “figure of hate for green activists”
The FAZ describes the controversial 44-year old Dutch scientist and outspoken IPCC critic as someone who in the early days was “quite green”, comes from a modest background, but who developed to become one of the world’s leading authorities in his field. The FAZ:
Tol is one of the most productive and most respected researchers in his field. He is (co)author of more than 250 papers in renowned journals and according to the Ideas-Repec databank, among the top 100 scientists worldwide.”
The FAZ reports on how Tol believes the IPCC has gone overboard with hysterical scenarios for the future and as a result had his name removed from the IPCC’s final report.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On claims that 97% of climate scientists are in agreement, the FAZ writes:
Such a consensus does not exist, he explains. ‘Climate science is very bitter and politicized.’ He sees the unpleasant tendency of scientists getting more attention by issuing ever more drastic warnings.”
According to the FAZ, Tol is confident that humans can overcome the challenges posed by climate change through their uncanny ability to adapt by applying their ingenuity. His come country of Holland is cited as an example with the construction of dikes to hold back the seas. Another example he cites is the huge gain in agricultural yields over the past decades that will provide ample supplies of food in a warmer world.
Overall Tol believes “the European Union is on the wrong path” with its climate policy of costly subsidies for the feed-in of green energies, which has scarcely has an impact on climate.
It should all be discarded and the ten thousand climate bureaucrats should look for new jobs. We need a policy change”
In the FAZ article, Tol is in favour of a carbon tax because in his view it is “the only effective measure.”
========================
Richard Tol is Professor of the Economics of Climate Change at the Institute for Environmental Studies & Department of Spatial Economics, Vrije Universiteit, Amsterdam; Research Fellow at the Tinbergen Institute, Amsterdam; Research Network Fellow at the CESifo, Munich, Germany; and Co-Editor of Energy Economics
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman skeptic site Klimanotizen brings us what I view as very good news on the trend of climate science skepticism in Germany.
Readers need to keep in mind the very harsh environment skeptics face in Germany, where they are targeted and marginalized by powerful forces such as major arms of the government, leading politicians, massively funded alarmist institutes and the mainstream media as dangerous disinformers who should not be listened to, and under no circumstances ever be given a bullhorn.
But fortunately, thanks to Germany’s democratic society, that effort is failing. The latest example Klimanotizen presents is a recent annual meeting of the German Home and Property Owners Association in Hanover last week.
What was different about this annual meeting was that one of the invited speakers was Prof. Fritz Vahrenholt, co-author of the skeptic book The Neglected Sun – How the Sun Precludes Climate Catastrophe – a best-seller in the German version Die kalte Sonne. The gathering was in large part a climate-skeptical event – all taking place in the Kuppelsaal at the Congress Centrum before an audience of 1200.

1200 listened attentively to Prof. Vahrenholt’s speech on why there’s no man-made climate catastrophe – followed by “sustained and thunderous applause”. Courtesy: Klimanotizen. 
In his opening remarks Chairman Rainer Beckmann pointed out that there was a time when warmer weather was welcome, and cold was dreaded. Moreover most of the last 11,000 years were warmer than today. Warm periods, even those that were warmer than today’s, were always good for human development. Beckmann also poured cold water on the notion of a consensus among the experts. “There are many scientists who would not believe in man-made climate catastrophe.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Professor Fritz Vahrenholt: “Man-made climate catastrophe no longer the issue”. Courtesy: Klimanotizen.
Next at the podium was Prof. Vahrenholt, one of the founders of Germany’s modern-day environmental movement. Klmanotizen writes:
Prof. Vahrenholt impressively described many developments and facts about Germany’s Energiewende, which to many in the audience were entirely new. For example he described the large economic burdens and the environmentally detrimental impacts of renewable energies and Germany’s image loss abroad. He showed how gradually the talk is going around that the Energiewende is not working out. He then detailed how the sun’s role has been under-estimated by the IPCC. During the time of increasing warming in the 20th century, the sun showed the greatest activity in over 1000 years. But since then its activity has been waning and also global temperatures have not risen in 17 years. The IPCC scientists have no explanation for it. However with the sun and the ocean phenomenon it is easily explained. Therefore a man-made climate catastrophe is no longer the issue.”
How did the German audience react to Vahrenholt’s speech? Klimanotizen were present and they write of a “sustained and thunderous applause“. Hanover’s leading daily the Hannoversche Allgemeine Zeitung (HAZ), also present at the annual meeting, confirms while paraphrasing Vahrenholt:
Sure an energy transformation is necessary in order to be independent of other countries, but we do not need any fear-driven energy policy stemming from falsely interpreted climate data. Vahrenholt received long applause from the visitors of the annual meeting.”
The result is that 1200 people, who likely had inklings of doubt about the allegedly approaching climate catastrophe, were shown data confirming that indeed it’s mostly all bogus. The good thing here is that once someone sees the Truth, they’ll never go back to believing the lie.
How many people have gone back to believing in Santa Claus or the Tooth Fairy?
Special thanks to Klimanotizen for covering this event and reporting.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterI’m Catholic and this Sunday I’m announcing that I’m disassociating myself from the Vatican and its pope. I urge other skeptic Catholics to consider doing the same. This is not a step I’ve taken lightly.
I’ll be opting out of Germany’s Kirchensteuer (Church Tax) and will not attend any services in the future. With their latest planned encyclical they are indicating that they have shifted back to the Dark Ages of bad-weather witches, superstitions and Medieval indulgences. Worse, they are openly subscribing to nutty end-of-times theories.
This comes on the heels of a recent announcement that Pope Francis intends to issue an encyclical on climate change. I am not renouncing Catholicism Christianity, rather I am solely renouncing my recognition that the Vatican and Pope are the faith’s administrator and moral compass. It’s the last straw in an unending string of corruption, child sexual abuse and scandals that have raged within the Catholic Church in recent times.
False prophecies based on junk models
The Vatican announces that it accepts a science (but it is one that is built on the false prophecies of faulty climate models made by unscrupulous scientists who claim they can now see decades and even hundreds of years into the future) and that bad weather is now due to the sins of man. It’s back to the dark days of Church-sanctioned witchhunts of the sort that once punished, tortured and burned people for brewing bad weather. Stunningly, once again, this is where today’s Catholic Church is heading today.
We can only speculate on why the Vatican has decided to take this extreme, divisive, and hugely misguided step, especially at a time when climate science is hotly debated and more tenuous then ever. It has elected to ignore the long-term data, the role of the sun and oceans, the complete lack of correlation between CO2 and global temperature, and seems to have declared the debate over among Catholics. It has entered a bargain founded on a monumental lie and bought into the silly end-of-world scenario. Such a Church is no longer worthy of being followed.
Vatican aligning with population control ideology
Even more disturbing is that the Vatican has opted to align itself with those who possess ideologies that are openly hostile to and spiteful of humanity. In May 2014 the Vatican held a workshop where the invited delegates included Naomi Oreskes, Arctic sea-ice crackpot Peter Wadhams, and Professor Hans-Joachim Schellnhuber of the ultra-alarmist Potsdam Institute for Climate Impact Pesearch. Strangely it doesn’t seem to bother the Vatican that Professor Schellnhuber once openly stated that the ideal human population for the planet was less than 1 billion people, implying an excess of more than 6 billion inhabitants. He also once said that the planet would “explode” if the population reached 9 billion.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This kind of environmental stewardship is one that advocates the pre-emptive abortion of future generations – a denial of life for future generations – i.e population control. This is hostile to the human race and it is appalling to any practicing Catholic. Either Pope Francis is stunningly naïve, or just diabolically evil.
And don’t expect the Vatican to backtrack anytime soon and to admit that it may have acted too hastily. Recall that It did not apologize to Galileo until 1992 – some three hundred and fifty years after the great philospher’s death. Galileo’s crime: he dared to challenge the consensus of the time.
Poorest urgently need affordable fossil fuels
I can no longer stomach this giant step back to the witch-hunting Dark Ages the Catholic Church is contemplating. The Vatican appears to have unwittingly elected to abandon the poorest among us, and their urgent need for affordable and reliable energy that only fossil fuels and nuclear power are able to deliver. The move by the Vatican risks putting the lives of tens of millions of the world’s most impoverished at risk. This Pope needs to remember that the road to Hell is often paved with good intentions. Though his intentions may be good, they are in this case based on horribly false prophesies peddled by charlatans who arrogantly refuse to debate.
What’s going to be next? An encyclical on the virtues of veganism – based on junk science nutrition?
Defying a corrupt Vatican is the Catholic thing to do
It’s important to keep in mind that rejecting a corrupt, incompetent or misguided Vatican is in fact the most Catholic thing to do. The collection money you give every week will do a lot more good if you give it directly to the needy. The Vatican or the regional Bishop need not send over a minion priest with the errand of saving my soul. Instead the Vatican should worry about its own.
Little wonder that Pope Benedict XVI resigned. The Vatican appears to be well on the way to becoming a cesspool of corruption and self-deceit. I can no longer bear it. The witch-hunting, end-of-world climate encyclical will be the last straw.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA few years ago it seemed as if there were lots of opportunities everywhere to make money with climate change. But as time goes on, it is increasingly becoming apparent that the heydays for many in Europe are just about over.
======================================
Zurich Insurance Group shuts down climate office that was opened in 2008

By Sebastian Lüning, Fritz Vahrenholt
The Zurich Insurance Group is closing the climate office it had opened in 2008, a Zurich spokeswoman confirmed to E&E Publishing. Over the past several weeks and months Zurich Office Director Lindene Patton had been actively promoting the idea of the climate catastrophe to the US Senate. Patton had also co-wrote the US National Climate Assessment, which flopped completely thanks to the alarmist tendencies of her colleagues.
Apparently the Zurich has slammed on the brakes because the lobbying efforts closely tied to the IPCC are no longer getting acceptance from the public and parts of US politics. In general the insurance business is suspected of using extreme weather warnings to peddle their products to customers and to justify high premiums.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The following is an excerpt of an article by Evan Lehmann of the E&E News Platform dated 27 June 2014 on the closure of the Zurich climate change office:
Leading insurer to close its climate change office, leaving the industry ‘mute’
Zurich Insurance Group is closing its U.S. climate change office six years after opening it to help persuade companies to press public officials for solutions to climbing disaster losses, according to several sources. The move seems likely to end a high-profile advocacy effort that exposed federal lawmakers to the financial concerns of a major insurer regarding rising temperatures. Some observers also say the closure stands to lessen an industry voice that might resonate with Republicans in a debate that’s often characterized as driven by Democratic ideology. Zurich’s decision comes amid a flush of visibility for the office and its director, Lindene Patton, who in recent months helped write the National Climate Assessment, testified before a Senate panel and spoke at the White House. In some circles, that has distinguished Patton as an unusually credible advocate for climate action who speaks from the suit-and-trouser world of the financial sector, where crunching numbers outpaces environmental ideology. One observer described her as a “dynamo.” […] 
When Zurich announced its ‘climate initiative’ six years ago, it was an effort, in part, to rally other members of the massive industry to get involved in shaping public policy. It warned of worsening climate risks that foretold of more than just sharpening damage from floods and storms: The industry also faces increased pressure from regulators and, in the eyes of customers, reputational risk if it doesn’t act, the company said. […] ‘The internal meaning could be that they don’t want to stick their neck out, that they want to be less visible with regard to climate change in general,’ said Walter Stahel, director of risk management research at the Geneva Association, a Swiss think tank funded by the insurance industry. ‘And they want to break it down into much more concrete [efforts] to impose adaptation measures.’ […] A Zurich spokeswoman confirmed yesterday that the climate office is being closed.”
Continue reading at E&E News.
Already in autumn 2012 the Deutsche Bank closed its analysis department for the impacts of global warming.
 

Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe main media often avoid reporting catastrophes involving bitter cold winter conditions, as it may cause the public to doubt global warming. So it’s little wonder that they have opted not to report on an ongoing massive blizzard pounding the Russian Orient, northern parts of China and extending to northern Japan.
However, the smaller media outlets are picking up where the mainstream media is slacking off.
The French language www.catnet.net reports here on “a very powerful snowstorm” that has hit the Russian Orient and Northern China and pumped very cold Arctic air into the region. It writes:
The storm in particular hit the Khabarovsk and dell’Amnur regions with heavy snowfalls and icy winds in the sector of North-North East that have reached speeds of 120-130 km/hr over the Okhotsk Sea.”
catnet.net writes of widespread power outages and winds of 105 km/hr and 72 cm of snow in the region of Khabarovsk. The region of d’ell’Amnur also saw 50 cm of snow with winds of over 105 km/hr. The catnet.net reports that the city of Komsomolsk has been “completely paralyzed“.
The English-language news.xinhuanet.com writes of an “ongoing blizzard” that continues “pelting the region with snow” and temperatures falling to -17°C.
China’s CCTV News presents a video of the conditions here and reports, “Strong winds with heavy snow reduced visibility in Fuyuan to less than 50 meters, affecting local traffic.”
CCTV News here also reports of a 60-hour blizzard pounding China’s Heilongjiang province and continuing even today: “Outdoor temperatures reached as low as minus 20 degree Celsius and the accumulated snow is up to 90 cm deep, leaving residents struggling to open doors.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterVery recently the Australian Meteorological Institute issued a bulletin advising that the chance of an El Niño in 2014 had “clearly eased“. And if one were to occur, it was “increasingly unlikely to be a strong event“.

Like this year’s El Niño itself, reliable prediction method remains elusive as ever. Graphic: NOAA. 
This of course all flies in the face of multiple recent warnings of a “super El Niño ” being in the works and set to push global temperatures to a new all-time record highs – all coming from leading institutes and experts. Once again these forecasts are turning out to be completely wrong.
“Efficient 12 month forecasting scheme”
That the experts are all wrong should be quite surprising because not long ago a team of scientists led by Josef Ludescher, which included climate pope Prof. Hans-Joachim Schellnhuber of the renowned Potsdam Institute, published a paper titled: Improved El Niño forecasting by cooperativity detection“, which purported the ability of predicting El Niño events up to one year in advance with high certainty.
The authors announced that they had “developed an approach based on network analysis, which allows projection of an El Niño event about 1 y ahead“, and claiming they can “develop an efficient 12-mo forecasting scheme” and “achieve some doubling of the early-warning period”.  Moreover they added:
Our method is based on high-quality observational data available since 1950 and yields hit rates above 0.5, whereas false-alarm rates are below 0.1.”
Today we know that the probability of the heavily ballyhooed super El Niño occurring this fall has been evaporating rapidly. What happened? In climate science it often seems that the “0.1 chance” of something not happening in reality occurs 90 percent of the time.
The very same authors followed with another paper earlier this year appearing in the Proceedings of the National Academy of Sciences titled: “Very early warning of next El Niño“. The abstract this time stated that already in September 2013 they had been forecasting “the return of El Niño in late 2014 with a 3-in-4 likelihood”.
At the online Austrian news agency pressetext.at here, lead author Ludescher is even quoted saying:
Compared to the previous approaches, our methods offer very clear advantages: Firstly we reach a very high rate of accuracy and secondly prognoses can be made for a time period of up to one complete year.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Note how the author had been quite convinced by the new “unique avenue” for predicting El Niño events well in advance.
But now that this year’s projected El Nino is failing to show up, maybe the scientists had indeed been a little too optimistic with their one-year forecast.
Even the 2-month forecasts are failing!
Maybe a forecast a whole year in advance is asking for too much. But surely the new Ludescher method at least should yield much better results for the much shorter 2-month forecast. After all, if it’s 76% accurate one year in advance, it really ought to be 90% or better for a measly 2 months ahead. Here as well it’s turning out that climate scientists are unable to get the El Niño forecast correct for just 2 months in advance, never mind an entire year! At his KlimaLounge blog, for example, Stefan Rahmstorf wrote here in May warning that a powerful El Niño was on the march, and used a graphical animation to “impressively show” the development. Today that “powerful El Niño” also is no longer in any discussion.
So even the 2-month forecasts are unreliable. Scientists are baffled once again.
Also a look back at Real Climate here is worth a read: They wrote that this year’s El Niño had only a “2 in 10 chance” of fizzling.
El Niño to send “world climate off the rails”
Back in May, citing experts at NOAA, the Climate Prediction Center (CDC) and the International Research Institute (IRI) for Climate and Society, German online Die Welt here wrote: “The world climate could go off the rails over the coming months” and that the probability of an El Niño occurring in fall and winter were 80%.
To his credit, Die Welt journalist Joachim Müller-Jung added that we’ve heard such predictions before:
Also in 2012 they calculated that there was a more than 70 percent chance an El Niño would occur. The anomaly fizzled with hardly a murmur or fanfare.”
Again, in climate science the improbable has a way of occurring far more more often than not. Many scientists are merely shooting in the dark. Clearly there is still a lot they still do not understand at all about the climate.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAs global warming is being used as justification for profound policy shifts, one has to wonder if the one-sided fudging of data that produces the appearance of more warming is a deliberate attempt to deceive and defraud the public.
=============================
Is GISS Also Cheating in the Arctic?
By Ed Caryl
Almost four years ago, I wrote A Light In Siberia, where I examined 24 Arctic weather stations. The annual temperature data for those stations was downloaded from GISStemp. In light of all the recent controversy about weather station data corruption by “adjustments”, I decided to reacquire the GISS data for 19 of those stations for which I had kept the annual figures, and check for changes. There is also the matter of divergence, especially in the Arctic latitudes, between GISS LOTI and the satellite temperature readings. I examined this issue in this article back in November.
Is all that Arctic warming real?

Figure 1 is the annual temperature anomaly plots for land and ocean north of 60°.
I won’t bore you with individual 19 plots of the changes (see Figure 3), but here is one sample that my be illustrative, from Barrow Alaska. The station is at the airport, across the runway from the terminal and hangar areas, but close to the asphalt paved runway. There may have been a move in 1989, giving an excuse for the large discontinuity at that time, but there is no excuse for the constant positive correction, in the same direction as the well-documented urban heat island temperature increase at Barrow.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 2 is a plot of GISS annual temperature for Barrow, Alaska, downloaded in August of 2010 and June of 2014, and the difference between these two sets of data. This is just the adjustment that has been applied in the last 3 years and 9 months.

Figure 3 is a plot of all the adjustments for all 19 stations. 
The difference plots for most of the other stations look like noise, with occasional large steps, but the adjustments are nearly always warmer for the last half of the 20th century. The next plot is the average.

Figure 4 is a plot of all the adjustments that have been applied by GISS in the last three years and nine months for 19 Arctic stations averaged together.
Again, these are just the “adjustments”or “corrections” that GISS has applied in the last three years and nine months to the 19 Arctic stations. I have no way of knowing what they did before August of 2010.
Note the trend line in Figure 4. These recent changes to the data have resulted in more than half of all the warming that has supposedly taken place since the bottom of the Little Ice Age and a third of the difference between GISS LOTI and RSS seen in Figure 1.
We may never know what the real temperature change has been.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s leading daily in terms of circulation Bild recently featured an op-ed piece that harshly criticizes Germany’s Energiewende (transisition to renewable energies).
Clearly the Energiewende is not even coming close to living up to what is was originally billed to deliver. Despite adding more than 70 gigawatts of wind and solar capacity that will cost consumers some $200 billion, German CO2 emissions have not decreased to speak of. Coal-fired power has actually risen.
In summary German electricity prices have skyrocketed and poor consumers are being hit hard. Energy-intensive industries are off-shoring operations – and jobs!
A number of experts are calling the Energiewende the greatest wealth redistribution from poor to rich scheme in Germany’s history as wealthy property owners cash in with subsidized zero-risk wind and solar installations. The poor consumers are forced to cough up the money.
“Enough with green power!”
So it’s little wonder that major German media outlets are beginning to express doubts. Bild features an opinion piece titled: “Enough with green power!”
The popular German daily calls the promises of cheap power from wind and sun “a fairy tale”. It writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Indeed the truth is: The price of power continues to climb. Just in the past five years the power price exploded 29 percent.
The reason is simple: In the energy market, central planning rules and not the free market.”
Disfigured market
Today there is so much installed capacity, Bild writes, that “on days with lots of sunshine and wind, the green power has to be sold to foreign countries” – even if they don’t need it. When that happens the highly subsidized power gets sold at negative prices. The result? Huge losses for power companies. This is how disfigured the electric power market has become.
In summary Bild concludes that the price of power is much more expensive than it needs to be and that it is a product that needs to remain affordable. Germany’s energy policy is on the wrong path.
Unfortunately there are no signs things will change anytime soon in Germany, which now has the world’s second highest electricity prices in the world after Denmark.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s ambitious offshore wind energy project is increasingly threatening to become an expensive green energy folly.
Originally the flagship North Sea wind energy project was scheduled to be delivering clean energy by August 2013. However technical failures beleaguered the project and delayed the opening 7 months: until March 2014. 
BARD I offshore windpark shut-down extends 9 months. Builders have been unable to resolve technical faults plaguing the project from the start. Text added to photo by NTZ. Original photo: BARD.
But March came and passed, and again the technical problems persisisted and engineers were forced to delay the opening until August 2014, background here.
But that deadline too has now passed and the Austrian Der Standard here reports that the 400 MW BARD I offshore wind park shut-down will be extended at least another month as engineers struggle to get the park online by the end of September.
Engineers remain baffled
According to Der Standard: “Problems with over-voltages in the cable network plagued and ultimately led to a switch-off. The troubleshooting was supposed to be completed in August, however no exact analysis has yet to be produced.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Hope to repair problems this month
A consortium of companies have been feverishly searching for the root cause of the network problems, but Der Standard writes that the reas0n for the faults is still unclear and that fluctuations in the grid “overloaded a filter” at the Tennet-operated Borwin 1 transformer station. “The repairs should be finished by the end of September.”
Here we are assuming they mean the year 2014. BARD 1 has not issued any press releases or provided comment on the new delays.
Delay costs up to 2 million euros a day!
The Bard 1 North Sea wind park consists of 80 units 5 MW turbines and is located offshore 100 km from the north German coast. The extended shut down will mean a further financial blow to the project, with cost overruns reported to be already well in the double digit millions of euros. Alarmist site klimaretter here writes of the shutdown.

The estimated costs run between one and two million euros per day.”

But in the end, everyone knows who is going to end up footing the bill. Germany already has among the highest electricity costs in the world. Germans will have to prepare to pay even more, and soon!
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHere’s some double-barrel hypocrisy, again straight out of Hollywood.

Photo by: Nicolas Genin, licensed under the Creative Commons Attribution-Share Alike 2.0 Generic license.
Last week big Obamacare booster and anti-CO2 activist George Clooney took his private jet all the way from Las Angeles across the US, Canada, and the Atlantic, before finally landing in Germany…to seek medical help for his chronic back problems. Apparently Obamacare and America’s best physicians are unable to take care of it.
Much of the German media have been reporting on Mr. Clooney’s visit to a clinic in Solingen last Friday, see video here.
Spiegel writes:
The actor had himself examined last Friday by the Neurosurgery Department of the Städtischen Klinikums Solingen, so confirmed clinic director Hermann-Josef Bökmann, according to the DPA news agency.”
I guess Obamacare and the US medical system aren’t good enough for the ailing actor.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And how does the environmentally conscious Clooney justify burning tonnes of jet fuel and spewing greenhouse gases directly into upper troposphere (where it supposedly really hurts the climate)? Well damn it, my back hurts! And Obamacare is for the simple folks, anyway. 
The media also report that this month Clooney will be taking his jet to Italy to get married. For that event Hollywood stars Ben Affleck, Brad Pitt and Matt Damon will also be flying in on private jet(s), also spewing more tonnes of greenhouse gas into the upper troposphere on the carbon account of Mr. Clooney.
Spiegel writes here that last Friday’s examination took “several hours” and looked into his chronic back problems/pain stemming from an accident he suffered while filming “Syriana“. Spiegel also adds Clooney had admitted to alcohol problems, and taking pain-killers to keep the back pain bearable.
Searching for that 1 non-consensus doctor? 
So why did he really fly by private jet all the way to Europe for private care? I’d guess he’s decided not to take the advice of 99% of the doctors at home, who have likely advised him that the needed treatment is (risky) back surgery involving who knows what.
This is not really the kind of medicine anyone likes to swallow, especially when you know the treatment could seriously alter lifestyle. Yet, let’s recall how Clooney once spoke to the public on following doctors’ advice and that of activist climate scientists:
If you have 99 percent of doctors who tell you ‘you are sick’ and 1 percent that says ‘you’re fine,’ you probably want to hang out with, check it up for the 99. You know what I mean?”
Obviously George is searching the corners of the globe, in his private jet, for that 1 doctor who doesn’t agree with the other 99, climate protection and medical consensus be damned. Do as I say, not as I do. Skepticism for me, but not for you.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Germany-based European Institute for Climate and Energy (EIKE) presents a detailed analysis on the IPCC’s recently published final 40-page Synthesis Report released earlier this month.

Image source: IPCC
EIKE, however, concludes that the IPCC report is fraught with error and distortion. Author Klaus-Eckart Puls writes:
Not only does it contain major contradictions, simplifications and even falsehoods with respect to the earlier comprehensive partial reports, it is a stark contraction to almost every measurement and trend in nature. This is being noticed by event the alarmist tending media [3] : ‘Indeed while the previous climate reports [The 3 comprehensive reports of 2013/14] for the most part provided the science and the contradictions, the new Synthesis report suppresses most of the scientific findings.'”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Puls then provides a list contradictions, falsehoods and distortions stemming from the new Synthesis Report, all of which are refuted by measurements and facts which Puls provides:
1. air temperature
2. sea level rise
3. ocean temperature
4. storms
5. polar ice
6. extreme weather
7. crop yields
8. species extinctions
9. man is responsible
Puls summarizes (reiterating some of what he wrote in his introduction:
In the 40-page Summary for Policymakers [1] published in early November, the IPCC in large part contradicts the depictions and data in its own(!) comprehensive reports (several thousand pages) it released at the end of 2013 and early 2014. The summery-statements stand also in crass contradiction to almost every trend-measurement found in nature over the past 150 years.
For example the online SPIEGEL [3] writes: ‘Final IPCC Report: At the Intergovernmental Panel on climate Change, Alarmism Comes before Accuracy’ … ‘The document is supposed to rationally inform on the science – instead it suppresses the central contradictions.’ … ‘Indeed while the previous climate reports [The 3 comprehensive reports of 2013/14] for the most part provided the science and the contradictions, the new Synthesis Report suppresses most of the scientific findings’.”
Thanks – that suffices!”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterTwo German scientists describe what many western governments have been basing their energy and environmental policies on. It’s not pretty. What follows is an excellent review of climate modeling so far. 
=======================================
Fun with Climate Models: Flops, Failures and Fumbles
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(Translated, edited by P Gosselin)
What’s great about science is that one can think up really neat models and see creativity come alive. And because there are many scientists, and not only just one, there are lots of alternative models. And things only get bad when the day of reckoning arrives, i.e. when the work gets graded. This is when the prognoses are compared to the real, observed measurements. So who was on the right path, and who needs go back to the drawing board?
When models turn out to be completely off, then they are said to have been falsified and thus are considered to have no value. The validation of models is one of the fundamental principles of science, Richard Feynman once said in a legendary lecture:

Failed hypotheses have been seen very often in science. A nice collection of the largest scientific flops is presented at WUWT. Unfortunately the climate sciences also belong to this category. Roy Spencer once compared an entire assortment of 73 climate models to the real observed temperature development, and they all ended up overshooting the target by far:

And already yet another model failure has appeared: In August 2009 Judith Lean and David Rind made a daring mid-term climate prognosis in the Geophysical Research Letters. They predicted a warming of 0.15° for the five-year period of 2009 to 2014. In truth it did not warm at all during the period. A bitter setback.
Over the last years it has started to dawn on scientists that perhaps something was missing in their models. The false prognoses stand out like a sore thumb. Not a single one of the once highly praised models saw the current 16-year stop in warming as possible. In September 2011 in an article in the Journal of Geophysical Research Crook & Forster admitted that the superficial reproduction of the real temperature development in a climate model hardly meant the mechanisms were completely understood. The freely adjustable parameters are just too multifaceted, and as a rule they are selected in a way to fabricate agreement. And just because there is an agreement, it does not mean predictive power can be automatically derived. What follows is an excerpt from the abstract by Crook & Foster (2011):
In this paper, we breakdown the temperature response of coupled ocean‐atmosphere climate models into components due to radiative forcing, climate feedback, and heat storage and transport to understand how well climate models reproduce the observed 20th century temperature record. Despite large differences between models’ feedback strength, they generally reproduce the temperature response well but for different reasons in each model.”
In a member journal of the American Geophysical Union (AGU), Eos, Colin Schultz took a look at the article and did not mince any words:
Climate model’s historical accuracy no guarantee of future success
To validate and rank the abilities of complex general circulation models (GCMs), emphasis has been placed on ensuring that they accurately reproduce the global climate of the past century. But because multiple paths can be taken to produce a given result, a model may get the right result but for the wrong reasons.”
Sobriety in the meantime has also spread over to IPCC-friendly blogs. On April 15, 2013, in a guest post at Real Climate Geert Jan van Oldenborgh, Francisco Doblas-Reyes, Sybren Drijfhout and Ed Hawkins made it clear that the models used in the 5th IPCC report were completely inadequate for regional climate prognoses:
To conclude, climate models can and have been verified against observations in a property that is most important for many users: the regional trends. This verification shows that many large-scale features of climate change are being simulated correctly, but smaller-scale observed trends are in the tails of the ensemble more often than predicted by chance fluctuations. The CMIP5 multi-model ensemble can therefore not be used as a probability forecast for future climate. We have to present the useful climate information in climate model ensembles in other ways until these problems have been resolved.”
Also Christensen and Boberg (2012) were critical about the AR5 models in a paper appearing in the Geophysical Research Letters. The scientists presented their main results:
– GCMs suffer from temperature-dependent biases
– This leads to an overestimation of projections of regional temperatures
– We estimate that 10-20% of projected warming is due to model deficiencies”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In January 2013 in the Journal of Climate Matthew Newman reported in an article “An Empirical Benchmark for Decadal Forecasts of Global Surface Temperature Anomalies” on the notable limitations of the models:
These results suggest that current coupled model decadal forecasts may not yet have much skill beyond that captured by multivariate red noise.”
In the prognosis time-frame of multiple decades, they do not perform better than noise. An embarrassment.
Also Frankignoul et al. 2013 expressed serious concerns in the Journal of Climate because of the unimpressive performance of the climate models. They graded the models plainly as “unrealistic” because they did not implement the role of ocean cycles correctly.
In July 2013 Ault et al. looked at a paper in the Geophysical Research Letters and at the models for the tropical Pacific region. They made an awful discovery: Not one of the current models is able to reproduce the climate history of the region during the past 850 years. Excerpts from the abstract:
[…] time series of the model and the reconstruction do not agree with each other. […] These findings imply that the response of the tropical Pacific to future forcings may be even more uncertain than portrayed by state-of-the-art models because there are potentially important sources of century-scale variability that these models do not simulate.”
Also Lienert et al. (2011) found problems with the North Pacific. And in July 2014 in an article in Environmetrics, McKitrick & Vogelsang documented a significant overestimation of the warming in the climate models for the tropical region over the past 60 years.
In March 2014 Steinhaeuser & Tsonis reported in Climate Dynamics on a comparison of 23 different climate models and the extent to which they were able to reproduce temperature, air pressure and precipitation over the 19th and 20th centuries. The surprise was great when the scientists found that the model results deviated widely from each other and were unable to give a correct account of reality. A more detailed discussion is available at The Hockey Schtick.
In a press release from September 17, 2012, scientists of the University of Arizona complained that as a rule climate models failed when looking at periods of three decades and less. Also attempts at prognoses for regional levels were unsuccessful:
UA Climate Scientists put predictions to the test
A new study has found that climate-prediction models are good at predicting long-term climate patterns on a global scale but lose their edge when applied to time frames shorter than three decades and on sub-continental scales.”
In October 2012 Klaus-Eckart Puls at EIKE warned that up to now the temperature prognoses of the climate models have been false for every atmospheric layer:
For some decades now climate models have been projecting trends (“scenarios”) for temperature for different layers of the atmosphere: near surface layer, troposphere, and stratosphere. From the near surface layer all the way to the upper troposphere it was supposed to get warmer according to the AGW hypothesis, and colder in the stratosphere. However meteorological measurements taken from all atmospheric layers show the exact opposite!”
So what is wrong with the models?
For one they still have not found a way to implement the empricially confirmed systematic impact of the ocean cycles into the models. Another problem of course is that the sun is missing in the models as its important impact on climate development continues to be denied. It’s still going to take some time before the sun finally gets a role in the models. But there are growing calls for the taking the sun into account and recognition that something is awry. In August 2014 in the Journal of Atmospheric Sciences a paper by Timothy Cronin appeared. It criticized the treatment of solar irradiance in the models. See more on this at The Hockey Schtick.
The poor prognosis-capability of climate models is giving more and more political leaders cause for concern. Maybe they should not have relied on the model results and developed far-reaching plans to change society. To some extent they have already began to implement these plans. Suddenly the very credibility of the climate protection measures finds itself at stake.
The best would be a moratorium on models. Something needs to be done. It is becoming increasingly clear that the present wild modeling simply cannot continue. It’s time to re-evaluate. The climate models so far are hardly distinguishable from computer games on climate change where one sits comfortably on the couch and shoots as many CO2 molecules out of the atmosphere as he can and then reaps the reward of a free private jet flight with climate activist Leonardo di Caprio.
===================================
Fritz Vahrenholt and Sebasian Lüning authored the climate science book The Forgotten Sun. In this book they examined the poor quality of climate models and why they will always fail.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThere’s no doubt Europe’s 2014/15 winter was a mild one, which was welcome as the continent had reeled from a string of 5 consecutive colder than normal winters in a row, from 2008 to 2013.
Unfortunately we cannot say the same for spring this year, at least so far. A blast of cold air is now gripping much of the continent and people in many areas this morning are waking up to snow (see here).
This is no April Fool’s prank
Worse, the cold snap is expected to continue through Easter. This morning the online Pforzheimer Zeitung (Pforzheim Newspaper) writes that Good Friday will see “snowfall down to the flatlands” as cold polar air refrigerates Europe. “At 5 kilometers elevation in the atmosphere, -40°C will prevail…”. (Obviously the extra CO2 won’t be trapping a whole lot of heat up there.)
At Twitter Swiss meteorologist Jörg Kachelmann this morning reminded followers and mocked how just two weeks ago a number of weather experts had predicted a warm spring for March, April, May”. Kachelmann is a noted harsh skeptic on long-term seasonal forecasts, claiming they are hardly worth the paper they are printed on.
On the other hand Joe Bastardi in an earlier Saturday Summary predicted weeks ago that cold would grip Europe at the end of March, early April. Dead on!
German WDR public broadcasting this morning reported “numerous car accidents” due to “snow and ice” on streets and motorways in the state of North Rhine Westphalia. The Schwäbische.de here reports of snowfall causing problems in Bavaria, southern Germany. The online Stuttgarter Nachrichten writes that the month of April has started with snow for Germany’s southwestern state of Baden Wurttemberg.
Wetter.de has posted an animation of the air flow across Europe over the next five days. A large high off the coast in the Atlantic in combination with a powerful low over eastern Scandinavia will be pumping masses of polar air through Europe. By Sunday, one sees that a white Easter is a real possibility – an event that rarely occurs in Central Europe. German DWD Weather Service forecasts snow at higher elevations over Easter, with nighttime temperatures falling to as low as -4°C, reports web.de.
The snow and cold fly in the face of global warming alarmists predictions of springtime arriving earlier and earlier. Climate alarmist Potsdam Institute scientist Friedrich-Wilhelm Gerstengarbe told German ZDF television two years ago that spring would be arriving earlier and earlier – because of global warming.
Of course the cold is due to the prevailing weather patterns, just as was the case for the mild winter. It has nothing to do with climate change, as global warming alarmists often would have us believe.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAn Empirical Review of Recent Trends in the Greenhouse Effect
By Robin Pittwood, Kiwi Thinker
Abstract
The core of the human caused global warming proposition is that an increasing level of greenhouse gases acts to reduce heat loss from the planet making the atmosphere here warmer. The amount of warming anticipated by the IPCC models is from about one to several degrees C for a doubling of CO2 concentration.
But a conundrum has arisen lately:  While CO2 has continued rise significantly the temperature has not.  There has been no global warming since about 1997. Scientists on both sides of the debate have noticed this and have offered something like 55 explanations as to why this could be so. Some of those explanations lock into the dogma built into the IPCC models, taking for certain that the greenhouse effect is increasing, but because there is no atmospheric temperature rise, they then have to explain the retained heat is somewhere else.
Is the greenhouse effect occurring as the IPCC models propose?
This study analysed two important factors directly associated with the greenhouse effect, atmospheric temperature and outgoing radiation and finds that outgoing radiation has not declined. The missing heat has gone back to space as usual.  But more importantly the (lack of a) trend observed in an empirical derivation of the Stefan Boltzmann relative emissivity factor directly contradicts the greenhouse theory built into the IPCC models.
Article
Regular readers at any of the main climate change blogs will be aware that since about 1997 there has been nearly no global temperature rise. And they will know too, that this is despite atmospheric CO2 concentration continuing to rise. To date there are some 55 ideas to explain this slowdown in global warming. Some of the ‘explanations’ presume the so-called ‘greenhouse effect’ must still be increasing as the IPCC models calculate; it’s just that the heat has been hidden elsewhere, maybe deep in the ocean.
This study, based on 34 years of satellite data; outgoing long-wave infrared radiation (OLWIR) and temperature, demonstrates otherwise.
I used three data sets, OLWIR from NOAA, and the average of both UAH and RSS for global temperature.
I obtained monthly average OLWIR (W/m2) for each 2.5 degree latitude by 2.5 degree longitude area of the globe. After converting the netCDF files to Excel, I scaled each 2.5*2.5 area’s OLWIR to account for the varying size of its area, resulting in a global average OLWIR.  (There was some missing data mid 1994 to early 1995. I populated this by a linear interpolation).  The resulting annual average OLWIR is shown in the graph below for the years 1979 to 2012. A linear regression fit shows a generally increasing trend in OLWIR over this period.

The temperature data is also plotted on the graph below. A linear regression fit shows a generally increasing trend for the years 1979 to 2012.
The relationship between temperature and emitted radiation follows a universal law of physics, Stefan Boltzmann’s law states the emitted radiation is the product of the fourth power of absolute temperature and an emissivity factor. A reduction in the emissivity factor means less outgoing radiation for a given temperature.  That would indicate a stronger greenhouse effect.  An increase in the emissivity factor means more outgoing radiation for a given temperature.  That would indicate a more transparent atmosphere.  The study derived earth’s emissivity factor for each of the 34 years and the results displayed.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Using an average global temperature of 287 Kelvin added to the temperature anomaly, the relative emissivity has been derived for each year using the formula:
j / (k*T^4)
where j is OLWIR, k is the Stefan Boltzmann constant, and T is the temperature.
If the greenhouse effect was increasing, relative emissivity should be declining. A quick look at the graphs shows clearly this is not the case.

Our planet’s relative emissivity has been flat-lining, despite increasing CO2 concentration over the study period. The derived emissivity factor, being basically constant, directly contradicts all of the IPCC models. No increased greenhouse effect is observed.
Findings:
The two primary findings of this empirical study are:


Outgoing radiation has not declined over this period as expected by IPCC models. The missing heat has gone back to space – as usual and as per Stefan Boltzmann’s law, via OLWIR, and,
The increasing greenhouse effect expected by IPCC models, has not exposed itself. There has been no increased greenhouse effect over this period. [A closer inspection of the relative emissivity trend shows the atmosphere is even becoming a little more transparent – though little should be made of this given the variability of the data].


Conclusion:
The core of the human caused global warming proposition is that an increasing level of greenhouse gases acts to reduce heat loss from the planet making the atmosphere here warmer. But is the greenhouse effect occurring as the IPCC models propose? This study analysed two important factors directly associated with the greenhouse effect, atmospheric temperature and outgoing radiation and finds that outgoing radiation has not declined. The missing heat has gone back to space as usual.
But more importantly the (lack of a) trend observed in an empirical derivation of the Stefan Boltzmann relative emissivity factor directly contradicts the greenhouse theory built into the IPCC models.
The original post on this study may be found here.
Data Table:

 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterCanadian philosophical researcher Shawn Alli has posted a highly critical series titled: The CO2 Climate Change Cult Series.

Philosophy researcher, book author, Shawn Alli thinks global warming science has “cult-like status”. Photo source here.
Though he does not appear to be some famous academic professor, his series does poignantly bring up a number of inconvenient points that have leading climate scientists confounded.
Ideologies underpinning IPCC science
Alli sent me an e-mail asking if I’d look over Chapter 7 and 8, which I did. Today’s post focusses on Chapter 7, which starts off powerfully:
Many objective and impartial scientists believe that they have no ideologies and never work to prove what they want to prove. This is a nonsensical belief. Under the ideologies of racism and eugenics, Western-European scientists in the past intentionally prove what they want to prove. The same concept is true in the present. The ideologies of man-made CO2 climate change are underpinning the science behind the Intergovernmental Panel on Climate Change (IPCC). One example of this ideological science is the IPCC’s claim of the Himalayan glaciers disappearing in 2035. [1] It’s only because of climate skeptics and deniers that the IPCC retracts their nonsensical claim three years later. [2] But despite the admission of error the Chair of the IPCC Dr. Rajendra Pachauri refuses to apologize. [3] The fact that the public outrage surprises him and damages the IPCC’s credibility, [4] demonstrates that the IPCC is 100% out of touch with the global general public about climate change.
The reason why the error is such a large problem is because of two reasons: science and socio-economic-political implications. The CO2 cult holds the IPCC to the level of god-like status, forever defending their cause. This pushes CO2 cult believers to claim that the IPCC reports are the highest form of climate knowledge on the planet.”
If you don’t believe that leading climate journalists have been taken over by the cult, Alli presents a number of quotes from the Guardian’s George Monbiot, and from the Newsweek staff, who maintain that the science is rigorous like no other, and thus beyond dispute.
Hockey stick: Distortion of reality…”junk environmental ideological science at its best”
Alli also thinks Michael Mann’s hockey stick chart, in its attempt to remove the Medieval Warm Period, was “intentionally manipulating the global general public and distorting reality.” He adds:
But even if you dismiss the hockey stick graph argument and the fraudulent data from climate scientists, you have to face the reality that global warming ends in 1998. After years of voracious denials […] the IPCC finally admits the stall of global temperatures in kind terms in Working Group 1 of their fifth assessment.”
“junk…ideological science at its best”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On the claim by the IPCC that man caused the warming from 1800 to 1998 and that the recent pause is due to natural variability, Alli calls this selective logic: “junk environmental ideological science at its best.”
Alli then writes how he posed three questions to leading (alarmist) climate scientists, such as Kevin Trenberth, Richard Somerville, Tom Wigley, on whether they are surprised by the recent pause. In general they answer that they are not, and that the models continue to be right for the most part. Alli responds, focusing on Wigley’s response:
Professor Wigley points out that there’s nothing surprising about the temperature lag. I would correct him and claim that there’s nothing surprising about the temperature lag now, due to the passage of time; but in 1998 it would be very surprising.”
Indeed one only needs to look at the course of the 100+ models to see that the pause had never been expected.
Models “all guesswork”…”no way” they can be accurate
Alli also comments on the tweeking of models so that they better match the reality, i.e. “scientists are starting with a result and creating a model that proves it.” Alli gives this practice the deserved grade of “F”.
This is ideological science at its best. And this is what a lot of Western-European science is about, explaining past events through particular ideologies. “
Even more shocking is that Alli feels that the scientists “don’t understand chaos theory at all“, and sums up the models: “…there is absolutely no way that any current climate model can be accurate. It’s all guesswork based on past trends“.
Cult science
So why are scientists and activists so convinced by the science when it is so faulty? Alli thinks it gets down to the human need for a religion and purpose: “The issue of man-made CO2 climate change gives individuals an opportunity to justify their existence fighting a ‘righteous cause’ in the face of corrupt and greedy private interest energy groups.”
In the end, reacting to the fact that only 3 of 31 leading scientists and activists were willing to dismiss the claim that climate change leads to more violence, Alli sees this as evidence of a “cult-like status” in climate science.
Shawn Alli was educated at York University of Toronto and is the author of two books: Oil, the 4th Renewable Resource and Whistleblowers: True Patriots of Humanity.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Frank Bosse and Fritz Vahrenholt
In February the sun was very quiet in activity. The observed sunspot number (SSN) was only 44.8, which is only 53% of the mean value for this month into the solar cycles – calculated from the previous systematic observations of the earlier cycles.

Figure 1: Solar activity of the current Cycle No. 24 in red, the mean value for all previously observed cycles is shown in blue, and the up to now similar Cycle No. 1 in black.
It has now been 75 months since cycle No. 24 began in December, 2008. Overall this cycle has been only 53% of the mean value in activity. About 22 years ago (in November 1992) Solar Cycle No. 22 was also in its 75th month, and back then solar activity was 139% of normal value. The current drop in solar activity is certainly quite impressive. This is clear when one compares all the previous cycles:

Figure 2: Comparison of all solar cycles. The plotted values are the differences of the accumulated monthly values from mean (blue in Figure 1).
The solar polar magnetic fields have become somewhat more pronounced compared to the month earlier (see our Figure 2 “Die Sonne im Januar 2015 und atlantische Prognosen“) and thus the sunspot maximum for the current cycle is definitely history. It’s highly probable that over the next years we will see a slow tapering off in sunspot activity. Weak cycles such as the current one often follow. Thus the next minimum, which is defined by the appearance of the first sunspots in the new cycle 25, may first occur after the year 2020. The magnetic field of its sunspots will then be opposite of what we are currently observing in cycle 24.
The radiative forcing of CMIP5 models cannot be validated?
A recent paper by Marotzke/ Forster (M/F) is in strong discussion here at climateaudit.org with more than 800 comments. Nicolas Lewis pointed out the question: Is the method of M/F for evaluating the trends infected by circularity?
There is not only a discussion about the methods, but also about the main conclusion: “The claim that climate models systematically overestimate the response to radiative forcing from increasing greenhouse gas concentrations therefore seems to be unfounded.”
Is the natural variability really suppressing our efforts to separate the better models of the CMIP5 ensemble from not so good ones?
Here I present a method to find an approach.
Step 1
I investigated the ability of the 42 “series” runs of “Willis model sheet” (Thanks to Willis Eschenbach for the work to bring 42 anonymous CMIP5 models in “series”!) to replicate the least square linear trends from 1900 to 2014 (annual global data, 2014 is the constant end-date of these running trends). I calculated for each year from 1900 to 1995 the differences between the HadCRUT4 (observed) trends ending in 2014 and the trends of every “series” also ending in 2014. The sum of the squared residuals for 1900 to 1995 the differences between the HadCRUT4 (observed) trends ending in 2014 and the trends of every “series” also ending in 2014.
The sum of the squared residuals for 1900 to 1995 for every “series”:

Figure 3: The sum of the squared residuals for the running trends with constant end in 2014 from 1900,1901 and so on up to 1995 for every “Series” in “Willis sheet”. On the x-axis: the series 1…42.
Step 2
We describe the same procedure described in Step 1, but this time with the trends up to 2004, only 10 years before the end of the trend series:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 4: The sum of the squared residuals for the running trends with constant end in 2014 from 1900, 1901 and so on up to 1995 for every “series” in the “Willis sheet”. On the x-axis: the series 1…42. The ordinate scale is the same as in Figure 3.
Here one sees that the errors for the trends until 2004 on average are much smaller (Figure 4) than they are for the trends up to 2014 (Figure 3). That is no wonder as the parameters of most models for the time period up to 2005 were “set“. Thus the depiction of the trends of the models up to 2014 are also well in agreement with observations:

Figure 5: The trends of the model mean (Mod. Mean, red) in °C/ year since 1900, 1901 etc. up to 1985 with the constant end-year 2004 compared to observations (black).
Obviously the setting of the model parameters no longer “hold” as the errors up to the year 2014 rise rapidly.
Step 3
We calculate the quotients of the errors for the 2014 trends divided by the errors for the 2004 trends (See Figure 4) for every single series and make a 2-dimensional check:

Figure 6: The single series as plotted points. The coordinates are determined by the trend error der until 2014 (X axis) and the ratio of the error up to 2014/2004 (Y axis). The red rectangle marks the “boundaries”, the “good“ series are inside, the “bad“ are outside.
The borders are represented by the standard deviations of both series.
The y-axis in Figure 6 above is the quotient of failures in trend estimations to 2014 (see Figure 5) divided by the trend estimations to 2004 (see Figure 4) with a standard deviation of 3.08; the x-axis is the accuracy of the series in trend estimation for the running trends with the constant end year 2014 (see Figure 5) with a standard deviation of 0.0038. The big differences of many series (up to a factor of 11) between the trend errors compared of 2004 and the trend errors to 2014 is impressive, isn’t it? The stability of the series with great differences seems to be in question, that’s why they are “bad”.
Step 4
Now comes the most interesting part: From the 42 runs of different series, I selected the “good” ones which are within the borders of the red rectangle in Figure 4 and calculated their average. The same procedure was done with all the “bad” ones.

Figure 7: The selected “good” series (see step 1-3), the series mean of all 42 series, the “bad” ones and the observations for rolling trends with constant end-year 2014 in K per annum.
The “good” (blue) series produce a remarkably better approach to the observations than the model mean (red) and the “bad”( green) show the worst performance.
Up to this point we didn’t know what model was behind what “series” in the “Willis sheet”. Thanks to the help from Willis Eschenbach and Nic Lewis we just learned the assignment and the properties of the models behind the “series”, also their corresponding sensitivity with respect to forcing by GHG. The mean value of the transient climate response (TCR), which is the expression for the calculated greenhouse gas effect, is approximately 1.6 for the “good“ models, the model mean (all models) is 1.8 and the “bad” model mean is 1.96.
As one observes is Figure 7, the selection of the “good” models “improves” the convergence towards the observations. For this a TCR of approximately 1.3 is assumed, compare to our blog post “Wie empfindlich ist unser Klima gegenüber der Erwärmung durch Treibhausgase? (How sensitive is our climate with respect to warming from greenhouse gases)“.
Conclusion
The mean of the models overestimates the radiative forcings in the global temperature to 2014. The objectively better models have a lower mean of TCR. The “bad” models have a higher mean of TCR. Many models are perhaps “over tuned” for the trends to 2005. The result is a dramatic loss in forecasting quality beyond the tuning period. Are Marotzke and Forster wrong? Will we ever hear them admit it? There are reasons for doubt.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMy last post featured a commentary by renewable energy expert Prof. Fritz Vahrenholt, who forcefully conveyed the folly of Germany’s mad rush into renewable energy, and the country’s hysterical obsession with its suicidal fast-track shutdown of its stable base-electric-power generation.
What follows are German electrical power supply charts that clearly illustrate in no uncertain terms Prof. Vahrenholt’s points. To show just how unreliable wind and sun really are, the first chart shows Germany’s power production, broken down according to the respective sources, over the last 3 and half days:

Power generation Germany vs date/time. Source: www.agora-energiewende.de/Graph.
 Dark blue – conventional power (fossil and nuclear)
 Medium blue – wind
 Yellow – solar
 Green – biomass
Note how there has been a virtual blackout by sun and wind since December 3 as Germany’s weather has been dismally gray and windless over the period. Such conditions are not uncommon in Europe and can persist for 2 weeks or more.
Note how there are times when sun and wind combined were less tha 2% of the needed supply. Unfortunately, power utilities simply cannot call Mother Nature up and place orders for power days in advance. They have to just take what Mother Nature sends, whether they want it or not, and German law says they have to pay for it even when they do not feed it in.
Supply havoc for no benefit
What follows next is a chart depicting Germany’s power supply from each energy source over an entire year (sorry about the suboptimal quality of the graphics).



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Here we see that especially in the summertime both wind and sun can make a major contribution. But once again their wildly fluctuating supply creates havoc and problems that far outweigh any “benefit” the theoretical, imperceptible 0.02 or so degrees of less warming the planet might see over the next 30 years.
Large-scale exodus of Germany-based industry looms
And when the sun does shine and the wind blows many conventional power plants have to be throttled down to near idle, but can never be shut down because they have to be ready to fire up again as soon as the sun and wind diminish. This means these conventional power plants often run very inefficiently and highly uneconomically. So it’s little wonder E.ON is ditching the loss-making business of forced part-time power plant operation and going to renewable energies where profit is guaranteed by government mandated subsidies.
And with a power supply that is becoming exceedingly unstable and exorbitantly expensive, energy intensive industries are gearing to move operations, and the thousands of jobs they provide, out of Germany and over to foreign locations where electricity is affordable and reliable.
Large-scale storage technology still pie-in-the-sky
And does one see the pump storage (Pumpenspeicher) contribution in the above chart whenever the sun and wind go AWOL?
Of course we don’t. That’s because there is none to speak of in Germany. Yet, this is one of the main solutions that the government energy masterminds propose in order to compensate for windless and sunless periods. It still has not sunk into their heads that this amount of pump storage capacity is a technical impossibility in Germany, even with massive terra-altering. Never mind the economic unfeasibility of the idea.
The question remains: After Germany shuts down its remaining nuclear power and coal-fire plants, what will the country do when the sun doesn’t shine and the wind doesn’t blow?
That question has yet to be answered.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIndependent German meteorologists have been increasingly criticizing the Deutsche Wetterdienst (DWD) – German Weather Service – for its climate activism and alarmism. The once staid yet highly professional and competent organization used to be among the most respected in the world.
But that appears to be no longer the case today as meteorologists ramp up their harsh criticism of the DWD’s forays into climate alarmism. They are clearly losing respect for and confidence in the organization.
Brandishing the “climate change bludgeon”
The latest wave of criticism was unleashed by statements made by the DWD spokesman Gerhard Lux in response to a spate of thunderstorms and deluges that have hit Central Europe in recent weeks. Lux claims that it is “another indication of climate change“. Moreover, one leading German meteorologist claims that the DWD has been overdoing it in issuing weather warnings for every perceived anomaly. According to Dominik Jung at Yahoo News:
Since the beginning of June the DWD has issued storm warnings on 36 of 66 calendar days.”
Although high profile meteorologist Jung says a number of these were of course legitimate, he feels overall the DWD has been overdoing it with the warnings:
Just how many of these storm warnings were actually justified, however, is not listed. I could list some examples of false storm warnings. It is as if nothing else could be expected that after the severe thunderstorms of the last weeks, immediately again the ‘climate change bludgeon’ is being brandished.”
Jung doesn’t understand what all the fuss over the recent “unusually rainy” weather is all about, noting that 6 of the last 8 months were drier than normal, and that overall “it all evens out”.
The opposite of what models predicted!
The UK’s Met Office was not the one proclaiming visions of barbeque summers. Leading experts in Germany in the early and mid 2000s warned of a future of “Sahara-summers” for Central Europe, claiming that we had to prepare for “hotter and drier” summers. Here Jung quotes an article by German Bild daily that featured IPCC climate scientist Professor Mojib Latif. Bild wrote:
‘The probability of an extremely hot summer is increasing.’ The heat and missing rain for Professor Latif are ‘indices that global warming in Germany has arrived’.“


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




But Jung reminds us that precisely the opposite has actually happened since: “11 summers later, we have yet to see one that has been drier than normal.” Jung adds that “Germany is still miles away from Sahara summers” and summarizes:
In 2003 the heat and drought were signs of climate change, 2014 is now a month of July that is too wet? Who is supposed to understand that?”
The term climate change “overstretched”
Jung also uses Latif’s prediction of warm winters with little snow and frost ahead for Germany as another example of a bad forecast (a prediction he made on April 1, just after David Viner’s made his now much ridiculed prediction). Today we see that here too the exact opposite took place. What followed was a series of brutal winters, to which Latif responded by claiming a cold winter does not refute a warming climate. But this is a reaction that baffles meteorologist Jung, who in turn points out:
Now we are being told that ONE overly wet month of July supports the climate change? The term climate change is being stretched.”
Science groping in the dark
Jung criticizes the constant flip-flopping that regularly goes on in climate science and asks: “Who takes this back and forth seriously?“…”The thought that the science is groping in the dark is becoming more pronounced than ever.”
Jung even goes so far as to question their competence and notes that “many people are no longer really taking it all seriously.” Jung speculates that the alarmism, no matter what the weather does, is in part motivated by the desire for more funding.
Retired meteorologist on DWD: “Makes me sad”
Retired meteorologist Klaus-Eckart Puls is even harsher with his criticism of the DWD and their recent climate alarmism shenanigans. Puls himself worked 30 years for the DWD. In an e-mail he communicated his reaction:
The DWD is developing more and more into a ‘political climate-alarmist’ institution – that makes me sad because I was actively in service 30 years.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterScientific scepticism within the policy-driving field of climate science has taken another significant step in growth and reach in Europe and internationally.
Photo: Benny Peiser, Lord Lawson (GWPF)
Five years after its inauguration in 2009, the London-based Global Warming Policy Foundation has announced the launch of its new campaigning arm, the Global Warming Policy Forum.
The new organisation will be able to conduct campaigns and activities which do not fall squarely within the Foundation’s remit as an educational charity. This arrangement reflects those used by other organisations with dual structures, such as Amnesty International UK and Greenpeace UK.
The Global Warming Policy Foundation’s news and opinion pieces will henceforth be covered by the new website of the Global Warming Policy Forum, as will the CCNet newsletter, founded and edited by Dr Benny Peiser since 1997.
Trust and credibility in the eyes of the public
The Global Warming Policy Foundation calls itself an all-party and non-party think tank which is open-minded on the contested science of global warming and says it is deeply concerned about the costs and other implications of many of the policies currently being advocated. Its key to success is the trust and credibility that we have earned in the eyes of a growing number of policy makers, journalists and the interested public.
Members include renowned climate scientists
Its academic advisory council includes renowned scientists from all over the world, including Richard Lindzen, Ross McKitrick, Nir Shaviv, Robert Carter and Henrik Svensmark.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Public has lost trust in climate science
The GWPF site states that this is of great relevance today in light of scientific scandals and the public’s loss of trust in climate activists and politicians. “For us, public trust is our most important asset. It has been accumulated as a result of the reasoned and moderate positions we have taken, the integrity of our foundation and the credibility of our actions.”
Along with the newly founded campaigning forum, the Foundation will continue to advance its charitable objects by commissioning and publishing reports and papers and by organising lectures and debates on key matters relating to climate science and policy. “While the Foundation will continue to publish our reports and videos, the Forum will campaign in a way that will make our work even more effective,” said Dr Peiser, the Director of both arms of the GWPF.
To shape future evolution of climate science
Lord Lawson, the chairman of both GWPF arms said: “This reorganisation will enable us to build on the progress of the past five years and make substantial further progress over the next five – years which may well be decisive in the evolution of climate change policy.”
The new campaigning organisation is a wholly-owned subsidiary of the Global Warming Policy Foundation. In recent years, the GWPF’s influence has grown rapidly, among both UK and international policy makers and the news media and is widely regarded as one of the world’s leading think tanks on global warming policy issues.
Independent, no funding from energy companies
The GWPF writes that it is funded overwhelmingly by voluntary donations from a number of private individuals and charitable trusts. In order to make clear its complete independence, it does not accept gifts from either energy companies or anyone with a significant interest in an energy company.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe dispute over windpark development on some of Germany’s most idyllic landscapes is heating up rapidly and massively. And should the dispute continue on its current trajectory, it won’t be long before the ugly contraptions get stopped for good.
The dispute reached a boiling point recently with windpark opponents suspecting green energy activists of poisoning birdlife in order clear the way for an unobstructed windpark permitting.
According to south Germany’s online Stuttgarter Nachrichten, a number protected red kites have been found poisoned by the E 605 herbicide – in rural areas that just happen to be sited for the installation of large-scale industrial windparks.
Under Germany’s wildlife protection laws, wherever the predatory red kites are found to be nesting, green energy developers are promptly denied permits to install their turbines. But if red kites are nowhere to be seen, then wind-park developers stand a far better chance of getting the go-ahead. Angry windpark opponents are now pointing the finger at the windpark proponents for the poisoning. The Stuttgarter Nachrichten writes, however, that there’s no proof.
The Stuttgarter Nachrichten writes that a number of poisoned red kites were found at several locations in southwest Germany.
‘Systematically’ rare predatory birds are being killed wherever they find themselves in the way of large windparks, some wind-power critics are now surmising. That in the recent days in Pfalzgrafenweiler in the district of Freudenstadt also a dead peregrine falcon has been found, which according to police died from chloralose, just makes the situation more explosive.”
But windpark proponents are calling the accusations unfounded, and claim that poisoning the birds would even have the opposite effect: The bird would be put higher up on the endangered list, and thus make permitting of wind turbines even more unlikely. Other “green” activists call the accusations “speculation”.
The Stuttgarter Nachrichten ends its article writing that one fact is certainly beyond speculation: “The gloves have come off when it comes to the dispute over the transition to green energies.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe online India Today here reports that India’s Prime Minister Narendra Modi said on Friday:
Climate has not changed. We have changed. Our habits have changed. Our habits have got spoiled. Due to that, we have destroyed our entire environment,” he said while addressing students and replying to their questions through video conferencing in the first-ever initiative.”
Hat-Tip Tom Nelson at Twitter.
Alarmist climatologist Stefan Rahmstorf of the end-of-world-obsessed Potsdam Institute for Climate Impact Research (PIK) responded angrily at Twitter, as the German-government-funded scientist called the statement “very depressing” and accused the Prime Minister of “denial about reality”:

When considering climate on larger timescales, Prime Minister Modi is actually very correct in claiming that climate has not really changed when viewed on a millennial or centennial scale, as the Earth’s temperature is well within the Holocene temperature range. Over the short term climate is always changing, and many scientists attribute much of the change over the last 100 years to natural factors. There are hundreds of peer-reviewed papers supporting this. Unfortunately, these papers were mostly ignored by the UN IPCC.
The big climate change that Rahmstorf is talking about is what one finds in the climate model projections. Rahmstorf seems to be confusing the model world with reality and observations.
The models have come under increasingly massive criticism as 97% have over-projected global temperature increase for the last 15 years.
Concerning whether the planet is warming, the online India Today adds that it is an “issue that is being debated at various multilateral fora”.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterChief Executive Johannes Teyssen of German power giant Eon announced yesterday the spin off of its fossil fuel and nuclear generation operations, saying it will focus instead on renewables like wind power, energy efficiency technology, and smart grids. The announcement yesterday sent shock waves through Germany’s power generation market and the political landscape.
The moves produces a host of important questions? Who will take over the massive conventional power generation operations Eon is spinning off? In a nutshell, what is going to happen to a large part of Germany’s steady base-power supply in a power grid that is becoming increasingly dangerously precarious?
Daniel Wetzel at Die Welt writes of the “hidden dangers of the power revolution” and that Eon’s move is of “importance for the future of the German energy market, for the electricity supply security and the competiveness of the entire nation.”
Another blow was delivered on Monday as Vladimir Putin announced that Russia was cancelling the construction of the South Stream pipeline as a result of political conflict over the Ukraine crisis. The pipeline was planned to deliver huge amounts of natural gas to stabilize the European energy grid.
Over the past years, government intervention has made fossil energies unattractive and is forcing a shutdown of its 9 remaining nuclear reactors by 2022.
Where will the power come from when the wind doesn’t blow?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Today Holger Steltzner at Germany’s flagship Frankfurter Allgemeine Zeitung writes that the Eon move presents the German government with 2 major problems: “It has to make sure that the decommissioning of the nuclear power plants succeeds, and it must explain where the power will come from when the wind doesn’t blow.”
23 billion euros to subsidize 2 billion euros of renewable power
Steltzner describes a hostile German power market that has been grotesquely distorted by massive government subsidies in wildly fluctuating renewable energy sources. Stelzner writes:
With 23 billion euros annually, the government subsidizes renewable energy that is worth only 2 billion on the market.”
An irresponsible and reckless experiment?
In summary Germany’s wildly executed Energiewende experiment has just gotten a whole lot more interesting: a major gas supply pipeline from Russia has been cancelled, and the future of a large part of Germany’s electric power supply backbone is now in the dark. And if the trend continues, a whole lot more risks ending up in the dark.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterUPDATE: Read Carbon Brief here for implications of GOP victory
===============================
When it comes to climate change policymaking, the proposed so-called global treaty designed to protect climate (i.e. the global temperature, precipitation amounts, pressures, relative humidities, wind speeds, etc.) now faces a formidable obstacle: a US Congress now in the hands of the GOP Party.
DRUDGE writes:
Republicans Take Congress
+7 +8? +9? Senate
The Dem Disaster
Germany’s Spiegel writes:
Debacle for Democrats in US Congress Elections
Goodbye, Mr. President
My understanding is the USA needs the consent of the US Senate before it can ratify any international treaty.
Of course President Obama could attempt circumventing Congress to enact a treaty, but that would merely confirm why voters punished his party in the first place: abuse of power.
Why Obama did not pass a climate treaty back in 2009 when he had the chance remains a mystery to me. Worse, in my view, President Obama squandered the chance to work together with the opposition and accept compromise on every issue, which is the way democracies are designed to work. Instead he obstinately stuck to ideological lines and, using Chocago style political tactics, tried to muscle his policy onto the entire country.
Backfired!
Let’s hope lessons are learned here.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOuch!
According to Science Daily, NASA/Jet Propulsion Laboratory has rediscovered the aerosol factor in climate (yet again). Those familiar with climate science know that aerosols are the preferred wild card used by embarrassed climate scientists whenever their models fail to properly account for unexpected cooling periods…which incidentally is more than 97% of the time.
The cooling clouds
Today Science Daily here reports that NASA’s jet Propulsion Laboratory in California has a paper out that examines the major role aerosols play on climate, especially cooling-effect cloud formation: Well, maybe we got it all wrong after all…and forget what the IPCC has said up to now.
The not-so-surprising statement:
…they found that the total impact from the influence of aerosols on this type of cloud is almost double that estimated in the latest report of the United Nations’ Intergovernmental Panel on Climate Change.”
Doubling! I thought this was all settled. How could they have been off by 100%?
What other factors were they 99% sure about, but now will soon revise 100% in one direction or the other? I think it’s safe to say that as observations continue diverging glaringly from the models, many climate factors will have to undergo similar profound adjustments, and some even introduced for the first time.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Rather than narrowing it down in the models, scientists clearly appear to really have meandered way off into the woods and swamps with their models. The big repair work still lies ahead.
Clouds have the biggest impact on the albedo, cool our planet
According to Science Daily, a “new, comprehensive global analysis of satellite data” led by Yi-Chun Chen of NASA’s Jet Propulsion Laboratory and a joint team of researchers from JPL and the California Institute of Technology in Pasadena “have quantified how changes in aerosol levels affect low-level clouds over the ocean, ‘which cover about one-third of the ocean’s surface, have the biggest impact on the albedo, or reflectivity, of Earth’s surface, reflecting solar energy back to space and cooling our planet’.”
To me this is a back door that opens the way to admitting that water vapor has a negative feedback after all. Never mind the aerosols, which are always in ample supply. More water vapor from higher global temps means more cloud formation, which cool the earth. Now if they’ve underestimated this so much that they now have to double it, then the models can be scrapped – and policymakers should be fuming. Taxpayers too!
According to John Seinfeld, professor of chemical engineering at Caltech:
These results offer unique guidance on how warm cloud processes should be incorporated in climate models with changing aerosol levels.”
That would be just a start. How about incorporating other major well-known factors into the models: like cosmic radiation regulated by the sun’s magnetic field, ocean cycles, and expanding global sea ice?
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe polar-vortex-inducing “warming Arctic” seems to be doing strange things to the Arctic itself – defying the very laws of physics: The “warmth” there is causing the sea ice extent to explode. Compare 2012 versus 2014:

Arctic images for September 3. Source: www.ijis.iarc.uaf.edu/htm. 
Depending on which dataset you use, the Arctic sea ice extent this year is about 1.8 million sq km more than it was at the same time in 2012. That’s equivalent to over 20,000 Manhattans.
Applying in reverse the theory that a warm ice-less Arctic produces bitter cold northern hemispheric winters though Rossby wave perturbations, we should expect that the recently added Arctic sea ice will now lead to warmer winters.
Of course that would be in stark contradiction to what was observed in the late 1970s. Back then we saw extensive Arctic sea ice cover, yet bitter northern hemispheric winters were generally the rule. Predictions of an impending ice age were issued. Today the global warming alarmist scientists wish we would just forget all that.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The notion that a warm Arctic causes frigid winters in Florida is a half-baked Hail-Mary hypothesis at best. It’s designed to buy a little bit of time.
Read more on Arctic sea ice here.
Switzerland sees bitter-cold, overcast August
A few days ago I wrote here how some Western European countries had seen a cold August, with mountain areas even getting the first licks of winter. Now Switzerland has just released its August data. The online 20min.ch site here writes that the Alpine country’s August was 1.5°C below the long-term mean. The 20min.ch writes:
‘In August a clear deviation with respect to the temperature value was observed,’ says meteorologist Sarina Scheidegger of Meteonews. ‘Only in Sitten did the deviation stay below 1°C. In the rest of Switzerland it was at least 1.5°C too cold.'”
August was also 50% less sunny than normal, the 20min.ch site reports.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe online Salzburg Austria ORF site here writes: “Despite climate change, winters in the Salzburg mountains over the past 30 years have not gotten warmer, rather they have gotten colder.”
0.9°C drop since 1984
The ORF site writes that this is based on a study commissioned by the Schmittenhöhe Bahnen. The ORF site adds: “Independent meteorologists confirmed the trend“. The study elaborates further:
The mean temperature over the winter months at Schmittenhöhe has fallen  0.9°C since 1984. That is from minus 3.8 to minus 4,7 percent.”
Obviously the ORF writer was sloppy here and likely meant “degrees Celsius”, and not “percent”.
“Surprising result”
The ORF also writes that the Schmittenhöhe Bahnen – who commissioned the study – reacted by saying it is “a surprising result”. Board Chairman Erich Egger says he is relieved that winters have not gotten warmer and that the future of the ski industry is intact.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




However the ORF quotes meteorologist Bernd Niedermoser of the Salzburg Weather Service, who reminds that there has been “a significant warming” over the last 130 years and that it occurs in cycles, and that there will always be “periods where it will be colder for a short time.”
Tell it to the modelers.
More snow thanks to “global warming” 
Meanwhile Austrian site www.nachrichte.at writes that precipitation at the Pyhrn-Priel and Dachstein regions during the winter season has increased – in the form of snow. On the precipitation, it writes:
And because it is transported over to us by cold air masses from the North Sea, it comes down 90% as snow already at 1100 meters elevation.”
Yet, the Austrian alarmists refuse to let go of their climate change horror scenarios, insisting that by 2050 the “skiing fun will end” because of runaway global warming”.  The site sought out the opinion of Jürgen Schmude, Economics Geographer at the University of Munich:

Austria’s ski resorts could lose up to 30 days per year by then, should the average temperature indeed increase by 2°C.

 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterUPDATE: DUE TO ELEVATED INTEREST, THIS ARTICLE WILL BE A STICKY POST FOR ANOTHER DAY OR TWO. 
Fellow New Englander, engineering physicist and energy expert, Mike Brakey has sent a summary analysis of NOAA past temperature “adjustments” for Maine.
=====================================
Black Swan Climate Theory
By Mike Brakey
Here in the U.S. I have documented manipulations similar to those in Switzerland and other locations worldwide that NTZ wrote about yesterday.
Over the last months I have discovered that between 2013 and 2015 some government bureaucrats have rewritten Maine climate history between 2013 and 2015 (and New England’s and of the U.S.). This statement is not based on my opinion, but on facts drawn from NOAA 2013 climate data vs NOAA 2015 climate data after when they re-wrote it.
We need only compare the data. They cooked their own books (see numbers below).

Figure 1: NOAA cooled the years of Maine’s past by an accumulated 151°F! (55,188 heating degree day units).
The last four months have been some of the coldest you might ever recall in our lifetime. So far 2015 is the fourth coldest in Maine’s history over the last 120 years. Data from 2013 confirm that so far – from January 1 to April 29 – 2015 has required 4249 heating degree days.
That rivals 1904, 1918 and 1923 over the last 120 years.
But when I recently looked at NOAA’s revised 2015 data, these last four months now would not even put us in the top twenty of coldest months. The federal government went into the historical data and lowered those earlier years – and other years in the earlier decades – so that they can keep spending $27 billion a year on pushing global warming.
They assumed no one would archive temperature data. But I did. My research indicated they used the same algorithm across the United States at the same time. Fortunately I had archived their data from 2013 for Maine and recently compared it to their 2015 data (see above table).
As an engineering physicist and heat transfer specialist, I have worked with heating and cooling degree days for forty years. It is alarming when one discovers multi-million dollar websites have been corrupted with bogus data because the facts do not match up with agendas.
It tremendously harms the industry you and I both work in. Worse, it harms the public. If the public knew the climate data facts indicated it was not getting warmer locally, and that it might actually be getting cooler, it would have all the more reason to insulate and become more energy-efficient in their homes.
I have put together a Maine history of climate temperatures in a narrated PowerPoint Presentation placed on YouTube titled, Black Swan Climate Theory.
Below is a brief sampling of my findings:

Table 1: Sampling of findings.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So far 2015 Maine temperatures, as of April, are running neck-and-neck with the coldest years in Maine’s history: 1904 (40.6°F), 1918 (42.1°F) and 1925 (42.3°F). These temperatures cited come right from the federal government’s own NOAA climate data (from 2013). I archived them on my computer for future reference.
2015 so far among coldest on record
A BLACK SWAN event is forming in 2015 (following chart):

Figure 2: Plot comparing the new, altered dataset to the 2013 dataset. Black curve is the plot of the 2013 dataset. The blue curve is the plot of the 2015 new, altered data. 
Based on the first four months of 2015, there is an excellent chance 2015 Maine temperature might average, on an annual basis, well under 43.0°F. Not only have Maine temperatures been on a decline since 1998, we are now seeing temperatures reminiscent of the bitter turn of the early 1900s.
“Massive rewrite”
It appears NOAA panicked and did a massive rewrite of Maine temperature history (they used the same algorithm for U.S. in general). The new official temperatures from Maine between 1895 and present were LOWERED by an accumulated 151.2°F between 1895 and 2012.
“Out-and-out fraud”
In my opinion, this is out-and-out fraud. Why did they corrupt national climate data? Global warming is a $27 billion business on an annual basis in the U.S alone.

Now NOAA data revised in 2015 indicate that 1904, 1919 and 1925 in Maine were much colder than anything we experience today. (See the scorecard above comparing the NOAA data that are 18 months apart). Note how for 1913 the NOAA lowered the annual temperature a whole 4°F!
For the balance of the years, as they get closer to the present, the NOAA tweaks less and less. They have corrupted Maine climate data between 1895 and present by a whopping accumulated 151.2°F.
Unfortunately NOAA is remaining true to that old saying, “Figures don’t lie but liars figure.”
A multi-million dollar website has been corrupted. I can no longer rely on the tax-payer funded NOAA for clean, unfiltered, climate data for my ongoing research.
Conclusion
I can no longer trust the climate data and energy information ultimately drawn from the U.S. government. Locally, I now have to determine if they got their data from NOAA.
This makes research a lot tougher.
Mike Brakey
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMany readers will recall the climate bet for charity this site and its readers (the coolists) entered into against the climate alarmists, principally climate loudmouth Dana Nuccitelli and Rob Honeycutt, back in January 2011.
The coolists maintain that the 2011 – 2020 decade will be the same or cooler than the 2001 – 2010 decade. The alarmists of course are absolutely convinced that the current decade will be warmer.
Listening to the media lately, one might think that the coolists are getting trounced. Nothing could be further from the truth. The bet is based on the RSS and UAH satellite data, and they tell us a different story. Nuccitelli and his buddies can cite NOAA, GISS or NCDC all they want, but those datasets are not going to matter come 12/31/2020.
Robin Pittwood of the Kiwithinker has been so kind to tabulate the race so far as it develops. The first four years of the decade are now behind us, and Robin tells the coolists are maintaining a slight lead. Yes, this decade so far is running COOLER than the previous one! Hardly a good development for the Nuccitelli & Co. The dang oceans must have eaten up all the heat.

Chart shows this decade continues to be cooler than the previous one. Source: Robin Pittwood of the Kiwthinker. 
With the current CO2 emissions trajectory running at the IPCC’s worst case scenario, this decade so far theoretically should have been at least a good 0.2°C warmer, and certainly not cooler. Something must have gone terribly wrong for the cocky climate boy-wonder in California.
Robin writes:
We are now 40% through the race … and clearly it is still close with the coolists in the lead by half a nose.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Now back to the hype we’re hearing about the ‘hot’ 2014. Notice that during 2014 (months 37 to 48) the green line just keeps trucking along at the same basic slope as it has for the past few years and much of the previous decade too. There was even a small El Nino in 2014, whose effect is conspicuous by its absence. Maybe the heat that is missing in the observed atmospheric temperature trend is hiding in the ocean?  ;-)”
So we’ve got another 6 years to go and now is a good time to speculate how those might go. Personally I expect 2015 to be a warm one as well, because of the current Tiny Tim El Nino. But then we all know what happens after an El Nino. Right, global temperatures tend to drop due to La Nina that follows.
Also boding ill for Nuccitelli and Co. is the projection that the current solar cycle will soon be winding down and so it is quite possible we will be seeing a cool period around 2018, similar to what we saw back around 2008. Indeed it’s too early to call it for the coolists, but I must say I’m quite comfortable with our current position.
Let’s assume that the coolists do win the bet and thus deliver the major upset. How will the warmists react? Are they going to cry foul? Or are they going to be relieved and a bit happy because the planet is not warming like they thought. That would be the rational reaction.
I doubt very much Dana is sweating about this at all. He’s a master rationalizer and will creatively concoct a way to deny it.
Awhile back at this site William “Winston” Connelly demanded that the terms of the bet be modified. Sorry, it is a bit late for that, and it’s not his bet anyway.
Should the coolists win, the warmists are going to have a lot explaining to do. But they are well prepared, as already there is a huge supply of excuses out there for them to choose from.
And even if the warmists should somehow eke out a victory, it’ll be quite a hollow one because they all claimed it would be min. 0.2° warmer. A few hundredths warmer would also take the air out of the alarmism.
Fun blogging lies ahead.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman scientists Fritz Vahrenholt and Sebastian Lüning ridicule the New York climate conference nobody is going to. Enjoy!
====================================
Imagine there’s a climate conference, but no one goes
By Sebastian Lüning and Fritz Vahrenholt
(Translated, edited by P Gosselin)
Imagine there’s a climate conference, but no one goes. Already months ago South Korean UN General Secretary Ban Ki-moon busily sent out invitations to world leaders, kindly requesting them to appear at the Climate Change Special Conference in New York on 23 September 2014. The aim of the conference is to agree on concrete actions for a CO2 reduced world in order to curb a menacing climate catastrophe. At the German Huffington Post Ban Ki-moon set forth his underlying motivation for September 2014 conference(translated from the German):

I have travelled the world in order to see the impacts with my own eyes. From the Arctic to the Antarctic, from low-lying islands of the Pacuífic, which are threatened by rising sea levels, to the melting glaciers of Greenland, the Andes and the Alps. I have seen expanding deserts in Mongolia and in the Sahel Zone, and threatened rainforests in Brazil. Everywhere I have spoken with the affected people who are deeply worried about the threat to their way of life and their future because of climate change.”
Dear Mr General Secretary: If you really wish to cut back on CO2 emissions, then you should NOT jet around the globe in your UN jet to supposedly see climate change with your own eyes. Perhaps you have heard that the Pacific Atolls are living corals that are growing along with sea level rise. The glaciers already melted before, 1000 years ago during the Medieval Warm Period when it was as warm as today. Currently the Sahel desert regions are not expanding as you claim, rather they are becoming greener. Moreover the rainforests of Brazil are threatened foremost by deforestation thanks to palm oil and biofuels. That is something to be really worried about, and not about climate change.
As opposed to the UN General Secretary, many world leaders have obviously realized that the science is overheated. An increasing number of scientists are distancing themselves explicitly from the catastrophe mindset. After 16 years of no global warming, the basis for trust between policymaking and the IPCC scientists is sustainably disturbed. We believed you and you’ve disappointed us, the scathed politicians bemoan behind closed doors.
So it is little surprise that hardly anyone has the desire to attend the Climate Summit Circus. Already in May, 2014, German Chancellor Angela Merkel respectfully declined -she had other more important appointments. What could they possibly be about? Even today there is still no entry in Merkel’s Online  appointment book for the 23rd of September. Perhaps an appointment with the hairdresser that can no longer be put off? Crochet evening with good friends? Let’s keep it a surprise for now.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the middle of August 2014 India Prime Minister Narendra Modi also declined the invitation to attend. India today is the world’s third largest CO2 emitter. Perhaps someone in New Delhi got cold feet over the requested “concrete measures”. Or perhaps they simply looked at the latest global temperature charts.
Also in Peking they were not amused. Suddenly the world’s largest CO2 emitter, China, no longer has much desire to show up in New York. Chinese Prrsident Xi Jinping wasted little time in canceling his flight ticket. Nothing will result from all the negotiations anyway, the UN needs to know.
No German Chancellor, no Indian Prime Minister and no Chinese President. Consequently the UN General Secretary became visibly nervous and had to make late nominations. He was able to find a person -in the political little leagues: Bonn’s Lord Mayor Jürgen Nimptsch cordially expressed his willingness to travel to the Conference. Ban Ki-moon was most pleased, and the conference was saved. Now if all citizens of Bonn made massive efforts, then they would be able to offset the Indian and Chinese CO2 surpluses of the next few years in about an estimated 2 billion years.
And things don’t look all that rosy when it comes to a climate agreement. The famous Kyoto-Protocol expired at the end of 2012. At that climate conference in Doha, 144 countries promised to vote to extend the treaty by 2020. So far today 11 countries have signed the extension document. In the meantime, have the other 133 countries reconsidered? So far not a single one of the 28 EU countries have signed on, also not Germany. But already Mauritius and Micronesia are on board (they would be beneficiaries of climate protection payments).
The climate alarmism-driven US-President Barack Obama also has realized that it no longer makes sense to strive for a large, new international climate treaty. Realistically it would never work anyway. In Paris at the end of 2015 there preferably will be a non-binding treaty. World leaders would more likely sign that. After all, they would not have to fulfill it…especially when they lose desire to do so…
==============================
Prof. Fritz Vahrenholt and Dr. Sebastian Lüning are the authors of CO2-skeptical book The Neglected Sun, which correcty downgraded CO2 climate sensitivity and forecast the the modest cooling that is now taking place.
 

Share this...FacebookTwitter "
"
Share this...FacebookTwitterSpiegel science journalist Axel Bojanowski, a geologist, writes about Europe’s largest natural catastrophe, which occurred in 1540.
No, it wasn’t a mega-volcanic eruption, a super earthquake, or a monster meteor hit. It was a severe “unprecedented” drought that fried and scorched the continent to an extent that dwarfs anything we have experienced over the past 100 years, scientists have uncovered. In the introduction Bojanowski writes:
Hardly any rain and extreme heat eleven months long. More than 300 chronicles reveal the gruesome details of a gigantic catastrophe in the year 1540. And they show: The disaster can happen again.”
I hope Spiegel publishes this article in English later on because it succinctly reminds us that there is a lot more to climate and extreme weather than a trace gas and that weather and climate have always been brutal. Voodoo science, rain-dancing and bicycle riding aren’t going to tame the weather.
Bojanowski writes that there was no warning that a catastrophe was about to grip the continent. Europe had enjoyed a spell of rainy mild weather accompanied by bumper harvests. Culture and society flourished. In December 1539 heavy rains led to flooding and people had to flee their homes. “They had no idea how precious the rain would soon be.”
In his article Bojanowski describes how suddenly in January 1540 a drought ensued and would last 11 months. Scientists say it was “far worse” than the European heat wave of 2003 according to a new paper authored by Oliver Wetter et al appearing in the journal Climate Change. The study’s abstract reminds us that extreme extremes are all too familiar in the past when CO2 were at a critically low level of 270 ppm (my emphasis).
The heat waves of 2003 in Western Europe and 2010 in Russia, commonly labelled as rare climatic anomalies outside of previous experience, are often taken as harbingers of more frequent extremes in the global warming-influenced future. However, a recent reconstruction of spring–summer temperatures for WE resulted in the likelihood of significantly higher temperatures in 1540. In order to check the plausibility of this result we investigated the severity of the 1540 drought by putting forward the argument of the known soil desiccation-temperature feedback. Based on more than 300 first-hand documentary weather report sources originating from an area of 2 to 3 million km2, we show that Europe was affected by an unprecedented 11-month-long Megadrought. The estimated number of precipitation days and precipitation amount for Central and Western Europe in 1540 is significantly lower than the 100-year minima of the instrumental measurement period for spring, summer and autumn. This result is supported by independent documentary evidence about extremely low river flows and Europe-wide wild-, forest- and settlement fires. We found that an event of this severity cannot be simulated by state-of-the-art climate models.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Spiegel writes that according to one wine grower, “It rained only 3 days in March.” Bojanowski writes that as the year progressed, the soil dried out and the air above it became oven hot as the summer sun relentlessly scorched the continent day after day. The result? Bojanowski describes a scene of multiple days over 30°C, rivers drying out, animals dying of dehydration, large-scale crop failures, forest infernos, and people collapsing like flies from heat stroke. The social fabric came apart at the seams: “Tensions erupted into persecution and executions. people barricaded themselves in homes in fear of the violence.”
The Spiegel journalist also writes that the mega-drought of 1540 shows that the hypothesis drawn up by climate scienists claiming the 2003 heat wave was exascerbated by man-made global warming is overly simplistic. He quotes Rüdiger Glaser of the University of Freiburg:
Indeed it just isn’t that simple: The fact that 1540 saw an even worse heat wave without the artificially enhanced greenhouse effect relativizes the assessment of a man-made impact on the weather of 2003.”
Near the end of the article Bojanowski writes that experts say that the same catastrophe could happen again today and that Europe is ill-prepared. Moreover, it is doubtful that droughts of such magnitude can be predicted early nowadays and the reasons for the 1540 extreme event are subject to pure speculation only.
See Spiegel photo gallery of Germany’s 2003 summer scorcher.
So, should it surprise us that the extreme heat of 1540 precluded the Little Ice Age? What evidence of solar activity do we have for the year 1540? There are lots of factors that need to be pieced together in the hopes of finding out what may have caused the catastrophic 1540 heat wave. One factor can be excluded: trace gas CO2.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAnthony Watts has posted a story “written by” Larry Bell, who according to NewsMax is “a professor and endowed professor at the University of Houston, where he directs the Sasakawa International Center for Space Architecture and heads the graduate program in space architecture.”
Honestly speaking I don’t care how distinguished Prof. Larry Bell may be, or how distinguished others might think he is. In my book, I don’t think much of the character at all. In my view his piece automatically gets an “F” as a grade.
The reason is that he evidently thinks it is not necessary to cite sources and to give credit where credit is due. He appears to think it’s perfectly okay to copy and paste other people’s work and give readers the impression it’s all his very own.
On June 9th I posted a piece titled: Giant Of Geology/Glaciology Christian Schlüchter Refutes CO2…Feature Interview Throws Climate Science Into Disarray, which got a fair amount of attention, including Larry’s.
Eight days later, on June 17, he posted his “own” version at NewsMax. At the end of the story NewsMax even had the temerity to write: “© 2014 Newsmax. All rights reserved.”
Of course much of the story is Larry’s own. But the quotes of Prof. Schlüchter were translated from the original German to English by myself. Unlike Larry, I cited at least a half dozen times the German source. Larry on the other hand simply helped himself to my hard translation work, without citing it.
Maybe steps can be taken to change his thinking, and that of NewsMax’s.
In the future I’d appreciate if the good professor practiced proper academic behavior and cited his sources.
All he had to do was cite and add a link or two.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAs wind turbines increase in size and scale, so do their deadliness to wildlife and hazards to human health.
Today’s modern wind turbines now soar to heights of up to over 200 meters, can have outputs of well over 5 MW, and blade tip speeds of over 300 kilometers per hour, thus making them especially lethal to avian wildlife, and hazardous for human health through infrasound.

Source: academia.eu, Erin F. Baerwald et al.
21,000 square meters of “swept area” of annihilation 
To give an idea of their scale, Danish company Vestas, for example, offers an 8-MW offshore turbine with a total height of 220 meters that is equipped with a monster rotor diameter of 164 meters. The result: horrendous blade speeds and pressure gradients. Flying wildlife stand no chance. Worse is the growing size of the hazardous swept area.
Vestas boasts that its V164-8.0 MW® turbine has a swept area of more than 21,000 square meters, which is “equivalent to almost three football pitches“. Vestas bellows: “When it comes to profitability, the bigger the swept area the bigger the revenue.”
Unfortunately for birds and other wildlife it is also: The bigger the swept area, also the bigger the wildlife annihilation area. But wildlife be damned.
Huge number of fatalities
Wildlife fatalities from wind turbines are poorly documented and mostly unknown. Estimates are on the low side and thought to be much higher, as the industry attempts to play down their real danger.
Birds, bats and other animals can be killed by turbines in any one of three ways: 1) through loss of their habitat due to the disruption of a vast installation area, 2) direct impact with high speed moving blades (birds) and 3) from barotrauma, where bats are the primary victims.
The most sinister of the three is barotrauma, which is a common way bats are killed by wind turbines.
Study shows mayhem


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




An article published at academia.edu by Erin F. Baerwald et al of the University of Calgary confirms the violent deaths that bats suffer from wind turbines. Bats do not even need to come into contact with the moving blades. It is enough for them to be close to the end of a moving blade to become victims of barotrauma. As the turbine’s blade slices by at 300 km/hr, the negative pressure in the blade’s wake causes the air in the bats’ lungs to expand and incur lethal injury.
Barotrauma typically occurs when an organism is exposed to a significant change in ambient pressure, such as when a scuba diver, a free-diver or an airplane passenger ascends or descends, or during uncontrolled decompression of a pressure vessel.
The academia.edu article writes:
The decompression hypothesis proposes bats are killed by barotrauma caused by rapid pressure reduction near moving turbine blades [1,4,5]. Barotrauma involves tissue damage to air-containing structures caused by rapid or excessive pressure change; pulmonary barotrauma is lung damage due to expansion of air in the lungs that is not accommodated by exhalation.”
Moving turbine blades create zones of low pressure as the air ﬂows over them. Animals entering these sudden low pressure zones may suffer barotrauma; academia.edu article writes:
Pressure differences as small as 4.4 kPa are lethal to Norway rats Rattus norvegicus) [6]. The greatest pressure differential at wind turbines occurs in the blade tip vortices which, as with airplane wings, are shed downwind from the tips of the moving blades [7]. The pressure drop in the vortex increases with tip speed, which in modern turbines turning at top speed varies from 55 to 80 m/s. This results in pressure drops in the range of 5–10 kPa (P. Moriarty, personal communication), levels sufﬁcient to cause serious damage to various mammals [6].” […] 
Even if echolocation allows bats to detect and avoid turbine blades, they may be incapacitated or killed by internal injuries caused by rapid pressure reductions they cannot detect.”
188 dead bats examined
Baerwald and her team examined 188 dead bats killed by a wind turbine facility in southwestern Alberta:
Of 188 bats killed at turbines the previous night, 87 had no external injury that would have been fatal, for example broken wings or lacerations (Table 1). Of 75 fresh bats we necropsied in the ﬁeld, 32 had obvious external injuries, but 69 had haemorrhaging in the thoracic and/or abdominal cavities (Table 1). Twenty-six (34%) individuals had internal haemorrhaging and external injuries, whereas 43 (57%) had internal haemorrhaging but no external injuries. Only six (8%) bats had an external injury but no internal haemorrhaging.
Among 18 carcasses examined with a dissecting microscope, ten had traumatic injuries. Eleven bats had a haemothorax, seven of which could not be explained by a traumatic event. Ten bats had small bullae — air-ﬁlled bubbles caused by rupture of alveolar walls — visible on the lung surface (Figure 1A). All 17 bats examined histologically had lesions in the lungs consistent with barotrauma (Table 1), with pulmonary haemorrhage, congestion, edema, lung collapse and bullae being present in various proportions (Figure 1). In 15 (88%), the main lesion was pulmonary haemorrhage, which in most cases was most severe around the bronchi and large vessels.”
In summary, the wind turbines are extremely lethal to wildlife on a scale so horrendous and embarrassing that it is being kept out of the public’s eye. What’s worse is that these turbines, and the growing swept areas of annihilation they bring with them, have been installed by the thousands and plans are being made to install many thousands more – many in natural areas. Wildlife will have no chance.
This is all endorsed by Greenpeace and the WWF.
 
Share this...FacebookTwitter "
