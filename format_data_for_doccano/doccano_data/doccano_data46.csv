"The home secretary wants us to believe the substantial increase in child poverty is somehow not the result of policies pursued by the government since 2010 (Report, 22 November). And if the Tories were to be re-elected and child poverty jumps to over 5 million by 2022, as predicted by the Institute for Fiscal Studies two years ago, then presumably, again, we should not attach any blame to her party.David WinnickLabour MP for Walsall North 1979-2017 • Ten-year and eight-year sentences for the detectorists jailed for the theft of a Viking’s treasure; seven and a half years each for two men who raped a woman in a Soho nightclub (Reports, 23 November). Can I suggest that the respective judges attend a training course on the meaning of social justice.Steven BowditchCarlisle, Cumbria  • I wonder how many Guardian readers like myself missed BBC One’s Question Time leaders’ special on Friday night as it failed to make the TV schedule in your Friday paper. Wake up at the back!Phil LeeElslack, North Yorkshire • Anyone tuning in to see Would I Lie To You? on Friday night would have seen Boris Johnson instead and would probably have concluded they hadn’t missed it after all.Brian AllenBirdham, West Sussex • While appreciating the publicity given Mildura’s plight in Australia’s heatwave (Suffocating dust storm adds to town’s woes, 22 November) as a former resident I must point out that Mildura is not a town, having been proclaimed a regional city in 1934.Murray HedgcockLondon • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitterThe Iceland Monitor website here writes the North Alantic island is having its coldest summer in more than 20 years. According to the site:
The first thirteen weeks of summer this year have been the coldest in Reykjavik in over twenty years, reveals Icelandic meteorologist Trausti Jónsson.
The northern city of Akureyri fares even worse – one has to go back around thirty years to find a colder summer.”
Experts now say their are growing signs that this may be much more than a mere weather anomaly, and have more to do with an overall developing cooling trend. The Iceland Review site here writes that Met Office meteorologist Páll Bergþórsson warns how “Iceland may be entering a cold period“:
Iceland has enjoyed 25 years of above-average temperatures, Páll told Morgunblaðið, but those years may be over with a cold period taking over in the coming years.
‘The ocean here off Southwest Iceland is colder than usual and the cold is persistent after it first arrives,’ Páll stated.”
The cold is not isolated to Iceland, but appears to be spreading across the greater North Atlantic. Paul Homewood writes at his site on how the United Kingdom recently “saw one of the coldest July nights for many years“, with southern England setting a new record low of just 1°C on August 1st.
The cold gripping the North Atlantic likely is likely in large part due to cooling sea surface temperatures. The following chart from Climate4You shows how SST in June was at its lowest point in 14 years.

Share this...FacebookTwitter "
"Here’s a little story about hubris: an Australian prime minister wins a federal election no one gave him a chance in after running a relentlessly negative campaign against an opposition that bit off way more policy than the public was prepared to chew. The victory gave the leader enormous political authority within his caucus, the sense of invincibility in the public’s eyes and the enduring love of his base, emboldening him to let loose with his plan to remake Australia. He treats the vanquished with contempt, which seems their due given their implosion, all the while ignoring the fact that it was they, not he, who had determined the result. And three years later it’s all over, a defeat so crushing that it set the tone for the next decade. Scott Morrison’s no Paul Keating, but he risks falling into the same trap after an unexpected miracle victory. Because when the deafening, delirious cheers from a win you don’t expect subside, is it any surprise you wake up with a case of tin ear? Of course the difference is that Keating’s mistake was to make Australia bigger than it was ready to be: willing to be engaged in its region, ready to make peace with its history, prepared to sever the constitutional ties with the motherland. For Morrison it’s all about making Australia smaller: denying both its history and its present, cutting itself off from the world and, as I’ve argued previously, stifling any form of organised dissent. But as figures in this week’s Essential Report show, although Morrison may be willing his “quiet Australians” to remake themselves in his image, they really haven’t changed at all. When it comes to climate change – despite all the self-serving assertions that Labor’s ambition cost it power – people still believe the government is asleep at the wheel. In fact the number of people thinking the government isn’t doing enough is at an all-time high of 60%, significantly up from pre-election polling. As for all that “climate manners” baloney that as the east coast burns “now is not the time” to talk about climate change, Australians are stronger than ever here too: call a spade a flaming shovel, PM! The last leader to try this line on, Tony Abbott, generated way more purchase. Back then half the population rejected the link. Now 60% see the connection, and most of these reckon now’s a reasonable time to have the discussion. While the party breakdowns show Morrison is clearly playing to his base and the outliers to its right, the bulk of voters – including one-third of Coalition voters – see the dissembling as the smokescreen it has always been. Yet he blusters away, believing he has a mandate to refuse to confront the science that places more and more Australians at risk every year. Meanwhile he’s is desperate to airbrush the final days of the previous parliament from the record, particularly its historic failure to end cruelty on Manus and Nauru. The legislation sponsored by the interim member for Wentworth, Kerryn Phelps, that pushed forward the novel idea that doctors should determine whether a soul under Australia care should receive medical attention is a line in the sand for the PM. Again it appears he has mistaken his election win with a change in mood for the Australian public because the support for these measures, or something even more humane, remains above 60%. For all the talk on risks to sovereignty and the steady leaks of disclosures about the nature of the ailments of some of those seeking care, the debate has pushed up two points for each of the extremes, at the expense of the status quo. But really, nothing has changed. Here’s the truth behind these figures: the election result did not fundamentally change Australia or how Australians see themselves. They may have balked at Labor’s expansive agenda but they do want action on climate change and they are more than ever ready to think the government is not doing enough. And they want to see some basic humanity when it comes to asylum seekers. And that’s not all. The Australia that wondered why the government held out against a banking royal commission while laying into the unions before the election is the same Australia wondering why deregistering unions is now the government’s top legislative priority. The Australia that demanded that the government take meaningful action on family violence before the election will not now cheer on as the PM hands a review into the family law system to Pauline Hanson. The Australia that demanded the NDIS be funded adequately before the election is the same Australia that will see any attempt to prop up the budget with unspent funds as fiscal abuse of the needy. The government won the election by promising to do nothing. End of story. Like Keating before him, Morrison will believe his victory has changed Australia at his own political peril. • Peter Lewis is an executive director of Essential"
"Ikea’s parent company is to invest an additional €200m (£171m) in green energy and forest planting as part of a plan by the world’s largest furniture retailer to become carbon neutral by 2030. The investment is being made by Inter Ikea Group, the owner of the Ikea brand which is operated by a string of franchise businesses, the largest of which is Ingka Group. Inter Ikea Group said its €200m investment would be released in two phases. The first phase of €100m would be directed towards new renewable energy projects including heating, cooling and electricity generation. The group said investment would be in partnership with suppliers and directed towards parts of its supply chain where converting to renewable energy was more difficult – such as the textile industry, ceramics and glass production. The second tranche will be aimed at removing and storing carbon through reforestation and responsible forest management. Ikea said it was considering a variety of global regions for reforestation projects. The group statement said: “It is most likely that we will put an emphasis on projects in tropical and subtropical regions. This is because there is a vast amount of degraded land in need of reforestation, and forests in these regions grow faster making it possible to remove more carbon from the atmosphere.” Ingka Group, which has previously laid out plans to spend at least €3bn on sustainability investments, said this week that since 2009, it had pumped close to €2.5bn into renewable energy. The group now owns 534 wind turbines and 715,000 solar panels in 14 countries as well as a further 920,000 solar panels on store rooftops. The company, which operates 374 Ikea stores in 30 countries, has also invested in over 26,000 hectares of forest land, mostly in the US and Lithuania, taking its total ownership of responsibly managed forests to 208,700 hectares (about 2,000sq km) in five countries. The group has also invested in a plastics recycling plant, textile and mattress recycling and is trialling the sale of used, patched-up furniture in the UK as part of efforts to become more environmentally friendly. The investments have put Ingka Group on track to produce as much energy from renewable sources as consumed in its operations by next year. “We believe that the best way to minimise our climate impact and to contribute to limiting climate change to 1.5°C is mainly by reducing our greenhouse gas emissions – but we also need to remove existing carbon from the atmosphere. We can make a positive difference through our integrated supply chain, our global presence and our forest and climate expertise,” said Lena Pripp-Kovac, chief sustainability officer of Inter Ikea Group."
"
Share this...FacebookTwitterJust a quick post today, German site wobleibtdieglobaleererwaermung here writes that whenever one observes a number of datasets, they have one thing in common: There’s no detectable CO2 warming, and there”s verzylittle out there suggesting the warming will continue.
Most temperature datasets don’t show warming, sea ice doesn”t show it, lower troposphere temperature data do not show it, snow cover data don’t show it, historical climate cycles do not show it, and on goes the list.
wobleibtdieglobaleererwaermung now tells us that “the global satellite measurements by UAHv6 now show a warming ‘pause’ of 221 months spanning from March 1997 to July 2015, which is over half of the satellite record, which began in January 1979: (36×12+7 = 439 months/2 = 219.5 months).” See their first figure.
Even the current El Niño has not been able to stop the pause up to now. And once again the “Super El Niño” is struggling. True the current ElNiño is expected to end the warming pause, but only temporarilly as the expected subsequent La Niña 2016/2017 will compensate and once again continue extending the warming pause, possibly well beyond 20 years.
The gaping divergence continues
Even a slight trend warming would not be enough to salvage the global warming theory wreckage. The wobleibtdieglobaleererwaermung site reminds us: “The unfalsified measured global reality since 1990 continued to diverge again from the IPCC model projections again in July 2015“, see their second figure.
Moreover realistic estimations of global temperature development tell us to expect the opposite in the future (cooling), says wobleibtdieglobaleerderwaermung:
‘…Because of the thermal inertia in the climate system, formost the heat capacity of the ocean, the current temperature stagnation will turn into a cooling phase in the near future.’ Source: 2015 SO xxx Cf-Klima – Berliner Wetterkarte.”
Share this...FacebookTwitter "
"Poo comes in many different sizes, from the microscopic poo of the smallest invertebrates, to the largest poo of the African elephants who can each produce over 50kg per day. It also comes in many shapes, such as tubes (dogs), pellets (rabbits) or splats (cows), but the wombat is unique in the animal kingdom in that it produces cubic poo, and lots of it – around 80 to 100 cubes per night. The wombat is a large relative of the koala, native to Australia. It is solitary and nocturnal, living in underground burrows during the day but coming out at night to forage on grasses and other vegetation. It also sleeps a lot; an average of 16 hours per day. As it is nocturnal, the wombat has very poor eyesight, so it relies on its sense of smell to navigate and find food.  Poo is produced by all organisms – and species have adapted to utilise it in many different ways, such as a mechanism for seed dispersal, or a food source for animals including dung beetles. Poo can also provide information about the individual who produced it and their diet. The different textures, size, shape and smell can all help to identify the species that produced the poo – this information can be used to survey elusive animals such as the otter (which produces a distinctly fishy-smelling “spraint”“, and can also give an estimation of how long ago the poo was produced. Even dinosaurs have left fossilised poo behind, called coprolites.  However, poo is also very smelly, so it can be used by individuals to communicate their presence to others. Why is this needed? Although contests are frequent in the animal kingdom, they can be fatal – so are avoided if possible. One way of avoiding conflict is to mark your territory with a scent such as poo – this provides information on who you are and where you live. The wombat is highly territorial so uses its cube-shaped poo to mark its territory, preventing conflict. Wombats have been found to differentiate between various poos and show avoidance behaviour when presented with poo produced by predators and other male wombats. The hormonal content of poo can also be examined, for example so that males can tell when females are most fertile.  Wombats deposit poo outside their burrows and on the tops of rocks and logs, where they are more easily found by other wombats. The distinctive shape is an advantage as the flat sides of the cubes ensure they do not roll off their precarious locations. Wombat poo is cubic, not because the wombat has a square-shaped anus, but because it has a very long and slow digestive process, typically 14 to 18 days, which allows the digestive matter to become extremely dry and compacted. The wombat also has a very long digestive tract, allowing it to absorb the most nutrients and water from its food. The first part of their large intestine contains horizontal ridges that probably mould the poo into cubes, whereas the last part of the large intestine is relatively smooth, allowing the cubic shape to be maintained. The highly compacted nature of the poo means that the rectum is unable to contour the poo into the more usual tubular shape. So, the wombat, with is nocturnal way of life, poor eyesight but excellent sense of smell, uses poo as its main way of telling who lives where and if there are any strangers in the area (thus avoiding conflict), and as a way of increasing its reproductive success. It produces cubic poo as a result of its diet and long digestion. And, the cubic poo is the perfect shape for sitting on top of rocks and logs as it doesn’t roll away. Poo can be clever, too."
"
Share this...FacebookTwitterHamburg-Based Max-Planck-Institute for Meteorology: Aerosols Cool Less Than Previously Thought
By Sebastian Lüning, Fritz Vahrenholt
[Translated, edited by P Gosselin]

In our book “The Neglected Sun” we wondered a lot about the cooling effect of aerosols that was assigned in the climate models. Aerosols are tiny dust particles and droplets that act to diffuse sunlight and thus as a rule act to cool the earth. But by how much? In Chapter 5 of our book we wrote:
According to the IPCC, the cooling effect of aerosols offsets about two thirds of the power of CO2. In the IPCC’s view, aerosols reduce the warming generated by all greenhouse gases by 45 percent. But the uncertainty is large – it could be 15 percent, or even 85%, because we have only modest to low level of scientific “understanding of the relationships.”
Today very few are aware that the climate models generate far more warming than what we really produced over the last 100 years. The IPCC strategy: All the surplus heat is cancelled by aerosols until the models “fit”. The cooling joker is thus badly needed in order to maintain CO2’s high climate sensitivity.
In March 2015 we saw some progress in the aerosol discussion. One of the authors of the latest IPCC report claimed that the range of uncertainty concerning the effect of aerosols on climate had been greatly reduced thanks to new research findings, and in the meantime there’s been a lot of talk that the cooling potential of aerosols indeed had been significantly exaggerated in the past. The real cooling value is actually at the lower limits of the range assumed up to now by the IPCC.
The most important and boldest claims come from Bjorn Stevens, one of the three directors at the Hamburg-based Max Planck Institute for Meteorology (MPIM). That paper appeared in the Journal of Climate. What follows is the paper’s abstract:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Rethinking the lower bound on aerosol radiative forcing
Based on research showing that in the case of a strong aerosol forcing, this forcing establishes itself early in the historical record, a simple model is constructed to explore the implications of a strongly negative aerosol forcing on the early (pre 1950) part of the instrumental record. This model, which contains terms representing both aerosol-radiation and aerosol-cloud interactions well represents the known time history of aerosol radiative forcing, as well as the effect of the natural state on the strength of aerosol forcing. Model parameters, randomly drawn to represent uncertainty in understanding, demonstrates that a forcing more negative than −1.0 W m−2 is implausible, as it implies that none of the approximately 0.3 K temperature rise between 1850 and 1950 can be attributed to northern-hemispheric forcing. The individual terms of the model are interpreted in light of comprehensive modeling, constraints from observations, and physical understanding, to provide further support for the less negative ( −1.0 W m−2 ) lower bound. These findings suggest that aerosol radiative forcing is less negative and more certain than is commonly believed.
In general one should be careful not to overuse the word “sensational”. But here the word is most suitable. Surprisingly the German media has been deadly quiet on this. A Google news search reveals that there has not been a single article written about the paper. Undesirable news that the media prefer not to make public?
The implications of the paper were immediately recognized within the scientific community. On March 19, 2015, Nic Lewis explained the paper’s far-reaching implications at Steve McIntyre’s Climate Audit and Judith Curry’s Climate Etc.: Also the climate sensitivity gets further limited, and most likely is near the lower limit of the IPCC’s given range. Lewis’s calculations using the new Stevens value yield a most probable mean value for CO2 climate sensitivity (and indeed for the long-term “ECS”) of 1.45°C of warming for each doubling of CO2. The new total range suggested by Lewis ranges from 0.9 to 1.65°C per doubling of CO2. This is far below the IPCC’s latest range of 1.5 to 4.5°C per doubling of CO2.

Figure 1: Range of CO2 climate sensitivity according to calculations by Nic Lewis using the latest Stevens 2015 values. Source.
Bjorn Stevens was fully aware of the avalanche of reactions this would unleash. It is going to take awhile before his IPCC colleagues get over their indigestion and allow the new findings to flow into their modeling work. Until that happens, it is best to avoid any media storm. The MPIM intentionally did not issue a press release to announce the paper. As the English-language media busily discussed the logical consequences of the paper, the MPIM in Hamburg eventually found it necessary to put out a statement. On April 2, 2015, Stevens put out a statement saying that his paper only addressed aerosols and would not be appropriate for speculation on CO2 sensitivity. With it he buys himself a little public peace – for the time being. However the scientific community will not be able dodge the consequences of the paper over the mid to long-term.
 

Share this...FacebookTwitter "
"The bog at Forsinard stretches to the horizon, a vast mosaic of greens and browns. The tallest plants here grow only ankle high, but even so, walking requires careful attention. Hummocks covered in heather (Calluna vulgaris) or cotton grass (Eriophorum spp.) offer lumpy but secure footing. Soggy patches of sphagnum moss are less predictable. These bogs, in northern Scotland’s Flow Country, are deceptive in more ways than one. Beneath the moss and the heather and the sedge lies one of the planet’s largest surviving expanses of peat – a nutrient-poor, carbon-dense mass of partly decayed organic matter. But here lies the peatland’s hidden strength: a prodigious ability to lock away carbon, making it an important resource in the fight against climate change. The bogs are also home to a diverse assemblage of species, many uniquely adapted to its unusual conditions, and provide a critical breeding habitat for migratory birds. In Britain and beyond, people have drained large swaths of peatland and converted it to pasture or crop land for centuries. An estimated 80% of Britain’s peat bogs have been damaged or destroyed. Today, however, the country is on the leading edge of a global peatland restoration movement, and the programme at Forsinard is among the largest of these efforts. Peat is made up of partly decayed plant parts, pickled in acid released by living sphagnum moss. Plants in the vast bog at Forsinard are both rooted in peat and laying down new peat as time passes – a process that began about 10,000 years ago at the end of the last ice age. A mass of healthy peat is about 90% water, which it filters and purifies, and houses a small group of specialised plants that have adapted to the extreme conditions of a nutrient-poor, waterlogged, acidic habitat. Scientists now know that peat ecosystems are the most powerful carbon sinks on Earth. They are capable of holding twice as much carbon per hectare as a pristine redwood forest, the planet’s second-most carbon-rich ecosystem, says Hans Joosten of the Greifswald Mire Centre in Germany. Scotland’s peat bogs, which comprise more than 20% of the country’s land area, hold about 75% of the carbon locked away in all British soils and vegetation – which is why their restoration has become such a priority. In the 1980s, the British government subsidised a blitz of bog drainage in order to plant exotic trees for marketable timber. (Since the first world war, when a lack of available timber hindered Britain’s war effort, the country has viewed creating forests as a national good.) The resulting plantations of lodgepole pine (Pinus contorta) and Sitka spruce (Picea sitchensis), species native to North America, failed to thrive. The Flow Country had been treeless for thousands of years for good reason. Peat soil is often too acidic and nutrient-poor to support healthy trees, and the Flow Country endures howling winter winds of up to 90mph, which can stunt their growth or yank them out by the roots. During the forestry boom, the government offered grants to those interested in ploughing up natural bogs to plant trees, and provided tax relief to wealthy forestry investors. Overall, 67,000 hectares (165,560 acres) – 17% of the ancient peatland of Flow Country – was drained. Some of Britain’s richest citizens reaped impressive profits, but usable timber was rarely produced. In most cases, the plantations have grown only spindly trees that are unsuitable for lumber, so are used as biofuel or simply abandoned. While these ill-conceived forests haven’t produced much wood, they did trigger one of the fiercest environmental battles in British history. Richard Lindsay had just begun to survey the life of the Flow Country when the government’s timber incentive programme began. He and his colleagues at the UK’s now-disbanded Nature Conservancy Council hurried to record the beauty and biodiversity of wild Flow Country bogs moments before ploughs began ripping them apart to create tree plantations. “We were literally running along right in front of the ploughs,” he remembers. “We would go and survey an area one day, and go back the next day to see the ploughs [pass] right through the area that we’d just surveyed.” Living in pop-up tents, walking long distances across the formidable bog, Lindsay’s crew explored an intricate world where water equalled life. They found a community of different sphagnum and sedge species – some adapted to live on the raised hummocks and ridges, others thriving in the lower, soggier spots. They discovered that the rolling terrain hid mazes of pools, where diving beetles moved busily between the surface and the bottom, caddisfly larvae trundled along inside protective shells they’d built from bits of clay and pebbles, and newts and frogs fed on the insects. This aquatic abundance also supported droves of migratory birds. Ornithologists who rushed to study the Flow Country found a spectacular array of breeding species. In April, when the migratory waders arrive, the bogs come alive with graceful birds flying, calling, and soon after, incubating their eggs. Throughout the spring and summer, wading birds stalk the edges of bog pools, picking off prey to feed their chicks. In addition to offering rich hunting grounds, the bog provides ideal camouflage. The grey, white, and black plumage of common greenshanks (Tringa nebularia), large sandpipers named for the light-green hue of their legs, disappears against the sedge and heather. Golden plover (Pluvialis apricaria) hatchlings look like little more than a heap of sphagnum moss when hunkered down atop the bog. The region is an essential habitat for breeding birds. The researchers found that the Flow Country hosted a startling 66% of Europe’s breeding greenshanks, 35% of the dunlin (Calidris alpina), and 17% of all European golden plovers. Divers – elegant, sharp-billed birds known as loons in the US – also raise families here: black-throated (Gavia arctica) and red-throated (Gavia stellata) divers nest among the small lakes of the blanket bog, often crossing the bog pools with young chicks on their backs. But as plantations grew up, the conifers formed dense, impassable thickets. Predators began to move in – hooded crows (Corvus cornix), red foxes (Vulpes vulpes), pine martens (Martes martes), and others that birds of the bog had never encountered before. The danger zone stretched hundreds of metres around each plantation, eliminating potential nesting habitat for unknown numbers of dunlin, golden plover, and willow ptarmigan (Lagopus lagopus). The new plantations brought other threats to the region’s native species. To prepare their land for timber, plantation owners ploughed up the bog, killing off the blanket of native plants that build peat and hold water on the landscape. Water drained away, eroding gullies and drying out the peat. Lindsay, now head of environmental and conservation research at the University of East London, sees bogs as superorganisms in which the plants work together to manage the flow of water and keep the system healthy. “If you cut an artery in your leg, it’s a small wound but can have profound effects on you,” he says. “In the same way, cutting a small part of a bog can have profound impacts because its entire hydrology is connected.” Armed with data from these scientific surveys, a group of advocates led by the Royal Society for the Protection of Birds (RSPB) and the Nature Conservancy Council launched a full-fledged battle to protect the Flow Country bogs. Finally, in 1988, after about 190,000 hectares (470,000 acres) of UK bogs had been drained and planted with trees, the government ended its financial incentives. By then, the Flow Country had been severely impacted. The RSPB acquired part of it – the 21,000-hectare (51,900-acre) Forsinard Flows reserve – in 1995. Within four years, an additional 146,000 hectares (360,800 acres) of Flow Country bog had been designated as a special protection area under the EU birds directive. At that point, the anti-plantation movement was driven solely by conservation concerns – Lindsay and others were working to protect the peatlands’ native species. It would still be a few years before ecologists came to appreciate another trait of the bog: its ability to store tremendous amounts of carbon (although only if it’s healthy – and wet). When bogs are drained, air exposure speeds up peat decomposition, causing the bogs to haemorrhage carbon into the atmosphere. “Peatland switches from a carbon sink in natural conditions to a carbon source in drained conditions,” says Roxane Andersen, a peatlands scientist at the University of Highlands and Islands in Thurso, Scotland. “Carbon that has taken thousands of years to accumulate could be released in much less time.” Major farming regions in Europe and North America – including the midwestern corn belt and California’s Central Valley – lie on drained peatlands that have been spewing carbon for centuries. “You cannot see these emissions,” Joosten says. “A meadow with cows looks like a rich agricultural landscape. [But] this area emits the same amount of CO2per hectare as driving 135,000 km (83,885 miles) in a mid-size car.” He calculates that drained peatlands produce about 6% of all human-generated greenhouse-gas emissions. “That’s an enormous amount for a source that had not been recognised before,” he says. Today, Scotland is pouring cash into eliminating the very forests that people were paid so generously to plant just decades earlier. The country has spent millions so far, including more than £10m for restoration work at the Forsinard Flows reserve. The Scottish government’s climate change plan aims to restore 250,000 hectares (617,800 acres) of peatland by 2030. Because drained peatlands give off carbon 20 times faster than intact peatlands can sock it away, the priority during restoration efforts is to re-wet the ground. At remote forestry sites, the trees are often so small that it would cost more than the timber is worth to truck it away. In these cases, the felled trees are left to rot in the plough furrows. Bog restoration takes time but today, 16 years after the restoration began, Andersen has found that a location within the Forsinard reserve known as Talaheel – one of the first sites to be forested and one of the first targeted for restoration in 1998 – has switched from carbon source to carbon sink, capturing about 60% as much carbon per hectare as the pristine control site. “Even though some of the plants growing there are not typical of undisturbed bog,” Andersen says, “on balance, they’re taking up more carbon than they release.” Now, with what she’s learned from Talaheel and other restoration sites, she believes that peatlands damaged by plantations can be transformed from carbon source to sink in fewer than 10 years. As she nimbly picks her way across the recovering landscape, Andersen gazes at the mottled emerald and olive of the open bog. She sees hope for the ecosystem’s ability to adapt. “Peatlands have been around for such a long time, slowly but surely forming peat,” she says. “That suggests they’re intrinsically very resilient.” If they can be restored to health, Andersen and other scientists believe that the peatlands will endure, even in a time of unprecedented change. Holding its secrets close, the bog hides a paradise for birds and beetles – and, deeper down, a vast stockpile of carbon we can’t afford to set free. A longer version of this story was originally published on bioGraphic, an online magazine powered by the California Academy of Sciences."
"We’re used to stories of towns and cities waking up to floodwaters invading their homes. In complete contrast, the Australian city of Wangaratta, 230km north of Melbourne, is dealing with a hairy weed invasion that looks like a scene from the horror edit of an American Western film classic. This “hairy panic”, known to scientists as Panicum effusum, is native to the area and is regularly found in pasture fields. It’s known to be weedy, meaning it grows fast and under the right conditions is able to form dense patches. In this instance hairy panic found the ideal conditions to exploit its weedy nature: an extremely dry summer and a nearby farmer said to have left his fields unmanaged.  With little moisture in the air the stems and seed of the plant dry out and are easily picked up and carried along by the wind, moving faster and further under high wind conditions. Houses are perfect barriers to the spread of this plant, entrapping an ever-increasing wall of tumbleweed. Unlike the native hairy panic, the classic tumbleweed from Hollywood westerns is actually a non-native invasive species. This Russian thistle (Salsola tragus) arrived in the US after being shipped as as flax seed to South Dakota in the 1800s. Native species can also be classed as invasive however, as the term generally applies to weedy species which bully out their neighbouring plants. Both plants produce lots of seeds and are blown around, so many of the same rules apply. Russian thistle is also tough to control in dry windy weather conditions.   However, unlike hairy panic, Russian thistle’s economic impact has been measured – it costs millions of dollars to keep highways free from pesky tumbleweeds, and the plant is know to harbour crop pests such as say’s stinkbug or the beet leafhopper which carries a virus that attacks vegetables. There are no known human health risks associated with hairy panic grass, although residents in Wangaratta are definitely not welcoming the disruption to daily routines with open arms. There is concern over sheep and other livestock eating too much of the grass which may lead to a condition called “yellow big head”, causing blistering of the skin. Luckily by the time the plant dries up it is no longer toxic. As hairy panic isn’t considered a fire risk, authorities are unable to assist in this instance – however annoyed locals may be. Perhaps legislation could be put in place for landowners to ensure efficient management of their pastures, particularly if their fields are near residential areas. The plant isn’t very tolerant of heavy grazing, but left to seed it grows rapidly. Grazing control may be considered as a management tool, although perhaps a contentious issue due to possible livestock disease.  Landowners are advised to wet pastures for times when dry conditions allow the weed to roll rampant through the streets. However in inland Australia during summer – hot and dry at the best times – “wetting pastures” is easier said than done. Both hairy panic grass and Russian thistle thrive in inhospitable conditions, such as low soil fertility, and quickly produce enough biomass to drive locals mad."
"
Share this...FacebookTwitter“O, what a tangled web we weave,
When we first practice to deceive.”
– Walter Scott
============================
By Michael Brakey, New Gloucester, Maine
Part 2/2
As an energy consultant, I have been implementing energy efficiency improvements over the past six years to help transform our very inefficient log cabin home in New Gloucester, Maine into one of the most energy efficient homes in the United States.
In order to measure the results, I wanted to compare apples-to-apples on heating and cooling demands. Therefore, I have been closely tracking and archiving local heating and cooling degree-day statistics over the last decade.
To do this I have local, unfiltered heating degree-day (HDD) history going back to 1893 from nearby Lewiston/Auburn. Seeing people are more familiar with degrees Fahrenheit (0F), I have converted the HDD to temperatures, and averaged them over running 11-year solar cycles. Those results are shown in the following chart:

While I was continually updating my local data, I also had cause to visit the National Oceanic and Atmospheric Administration’s (NOAA) website in January 2013 for data on the entire state of Maine. Here I noticed that NOAA’s data indicated that the state of Maine was a total of 1030F colder over the last 117 years compared to local Lewiston data. That worked out to 0.880F per year for “statewide” Maine compared to Lewiston in a southern interior climate.

That seemed reasonable because of the inclusion of northern Maine. I archived NOAA data for Maine, Ohio, Tennessee and the 48 contiguous states, as one entity.
Adjusted dataset twice in 18 months, adjustments totaling of 254°F
In early 2015, I revisited the NOAA website and updated my HDD and cooling degree-day (CDD) data for a local television presentation. Here I was shocked to discover that NOAA had not only rewritten Maine climate history for a second time in the last 18 months, but with all the tinkering they also screwed up southern interior Maine averages. Southern Maine temperatures were now colder than all of Maine as a whole! NOAA had inflated HDD figures so high that they had lowered Fahrenheit temperatures an additional 1510F summed over the years! Southern Maine interior was now 2540F colder over the last 119 years versus original Lewiston data. This means the NOAA rewrote Maine climate history to the extreme of lowering each year the equivalent of 2.120F per year colder. In order to counter Mother Nature’s recent cyclic cooling, the earlier historic years were lowered as much as five degrees while recent temperatures remained almost untouched.

Black line before adjustments. Green line after adjustments.
Past adjusted downward also throughout the USA
Upon comparing NOAA data from other states that I had archived in 2013 to current NOAA data, I found similar discrepancies:

Ohio’s historical temps were lowered total of 83.80F.
Tennessee’s record had been lowered total of 51.50
The U. S. temps for 48 contiguous lowered total of 73.40

Why all the alterations?
Why would NOAA be dramatically lowering temperature records for Maine as well as for other states? A picture is said to be worth a thousand words. In the following illustration I charted the different phases of change by NOAA in 2011 and then in 2014.


The black line shows the local data that I collected and archived from local Lewiston, Maine websites (see reference 1).
The blue line is data I downloaded in 2013 from NOAA’s website for the entire state of the Maine.
The green line is data I downloaded recently from the same NOAA website for the southern interior region of Maine, which includes Lewiston.

There was little if any difference between NOAA and local data in 1998 – until a few years ago. It was only after Mother Nature started cooling local temperatures that NOAA began altering the climate history record. The chart above shows three versions of a rolling 11-year average of historical temperature data since the early 1900’s for the Lewiston/Auburn area.
NOAA confirmed in writing that it’s altering climate data


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




NOAA was contacted and asked for an explanation. On May 6, 2015, NOAA confirmed in writing the massive changes to Maine’s data. NOAA stated the changes were intentional and justified! NOAA’s written statement included these words:
“…improvements in the dataset, and brings our value much more in line with what was observed at the time.  The new method used stations in neighboring Canada to inform estimates for data-sparse areas within Maine (a great improvement).”
NOAA’s statement about the need to recently introduce colder Canadian data into Maine’s past temperature history seemed fishy to me. How do they explain similar adjustments to the data for Maine’s southern interior region? 
Worse, they made southern Maine colder than the entire state of Maine! They also revised downward historic temperatures for Tennessee, Ohio, and the United States as a whole. Every U.S. state for which I kept archived NOAA data from 2013 had been adjusted in an almost identical manner.
On June 4, NOAA responded through a general Associated Press statement that they continually readjust thousands of weather data points to account for different measuring techniques through the decades (see part of article to right).
Public deserves facts, not fantasy
My question to NOAA is: Why?
Why does NOAA feel compelled to apply different measuring techniques to climate data? Why not give access to the raw collected data? Why must NOAA apply a master algorithm to the data that not only has been proven to be corrupted, but also whitewash major climate cooling events in recent years. The American public should be given facts not fantasy.
Could NOAA explain the recent climate measuring techniques implemented in the spring of 2014 that have resulted in the CD2 southern interior of Maine (seen in blue area of chart to right) being a third of a degree 0F colder per year when compared to the entire state of Maine?
Again this is fantasy over both fact and common sense. The information below is drawn from NOAA’s most current website. Below is NOAA’s most recent “adjusted data’ for Maine on their website.

NOAA simply ignoring reality
The charts above indicate that southern Maine has on average been 1/30F colder than all of Maine for the last 120 years! NOAA’s recent response to all these questions and observations can be found in their June 4th press release. They reiterated the same mantra; ignore satellite data, ignore facts given by non-scientist (and scientists alike) that disagree with NOAA’s climate data enhancements! We should just trust what NOAA tells us.
Trust is lost
Little wonder recent surveys indicated 76% of the American population does not trust the government to do what is right.
NOAA data cannot be relied on
As stated in yesterday’s post, decision makers in the state of Maine, and across America, cannot and should not rely on NOAA data for setting energy policy. If we are indeed experiencing regional cooling, then we should be encouraging insulation and less expensive sources of heating, such as natural gas, heat pumps, geothermal and future technologies associate with thorium and hydrogen.
However, based on NOAA’s data, which indicates a warming trend, lobbyists are focused on electric generation by means of wind and solar. It is important to gather data from other non-governmental sources to make sound decisions. It appears that we presently live in a nation where an agency of the Federal government has rewritten our climate history. Decisions worth trillions of dollars are being made based on fraudulent climate data.
Resources:

Black Swan Climate Theory, April, 2015, Mike Brakey, 1st series of five (5) short YouTube videos on NOAA climate adjustments https://www.youtube.com/playlist?list=PLDXMwo2SyaRse3GWujVHJGTLl9nvGAD59


151 Degrees of Fudging, May 2, 2015, Mike Brakey, Link: https://notrickszone.com/2015/05/02/151-degrees-of-fudging-energy-physicist-unveils-noaas-massive-rewrite-of-maine-climate-history/#sthash.9QtBzze0.SF5o7vzD.dpbs


NOAA E-Mail Confirms Large Scale Rewrite of U.S. Temperature Data, May 6, 2015, Mr. Derek Arndt, NOAA, Link: https://notrickszone.com/2015/05/07/noaa-e-mail-confirms-large-scale-rewrite-of-u-s-temperature-data-in-2014-improvements-in-the-dataset/#sthash.T6Bpcr1O.4fwNcmBn.dpbs


Black Swan Climate Theory II, Michael Brakey, June, 2015.  The six part PowerPoint YouTube series is also found at the following link: https://www.youtube.com/playlist?list=PLDXMwo2SyaRse3GWujVHJGTLl9nvGAD59 . The presentation takes you step-by-step through how it appears that leadership in NOAA unashamedly created a new master algorithm that was applied to the Maine data to rewrite climate history.The “Trick” to Controlling the Climate Agenda, Will be released in June, 2015. See link: https://notrickszone.com/2015/06/01/bombshell-comprehensive-analysis-reveals-noaa-wrongfully-applying-master-algorithm-to-whitewash-temperature-history/comment-page-1/#comment-1028832
Data-Set Changes Makes it Hard to Tell Real Story. See link: https://redneckusa.files.wordpress.com/2014/07/data-set-changes-makes-it-hard-to-tell-real-story.pdf

 
Share this...FacebookTwitter "
"Cities across the world are increasingly at risk from climate change. People living in extreme poverty are especially vulnerable, both because global warming will tend to hit developing countries the hardest, and because they have less money to throw at the problem. We used newly-available data to investigate how cities are responding to climate change and whether resources are being allocated efficiently or fairly. We expected there to be differences in spending between rich and poor. But we did not expect them to be so vast, with New York for instance spending more than £190 (US$260) per person to protect its people and infrastructure from the impact of climate change, while Ethiopia’s capital Addis Ababa spends less than £5 ($7). It seems the amount spent on climate adaptation is driven more by the amount of wealth at risk rather than the number of vulnerable people. Adaptation simply means any actions that anticipate the negative consequences of climate change – to human health, the economy or ecosystems – and attempt to minimise the damage. In big cities this might mean raising sea walls to tackle sea level rise or expanding drains to cope with bigger storm surges. We need a comprehensive picture of how much is being spent on these adaptation measures across the world. The Millennium Development Goals, despite their shortcomings, have demonstrated that measuring a problem provides an invaluable baseline from which improvements can occur. For this study, published in Nature Climate Change, we focused on spending in ten megacities. New adaptation spending figures were gathered and analysed using data triangulation, which draws on many different sources and types of data to arrive at more accurate estimates. Our work on this is part of a wider project on measuring the size of the green economy. Where ever you look, this “adaptation economy” remains a small part of the overall economy – a maximum of 0.33% of a city’s gross domestic product. Yet there are real disparities between cities. As you might expect, developed cities spend significantly more per capita. After all, most things cost a lot more in the US than in Ethiopia, and new drainage systems, air conditioning and so on are no different.  But this same disparity also applies as a percentage of city GDP. The three rich cities we looked at spend nearly half as much again as the developing cities (around 0.22% of city GDP, compared to 0.15%), even though climate change is a far scarier prospect for low-lying, flood-prone Jakarta or already-hot Addis Ababa than it is for London or Paris. Of course, cities in poorer countries have greater competing needs for their finances. Things Londoners or Parisians can take for granted such as clean water or basic healthcare are still pressing issues in Lagos or Mumbai.  Yet such disparity still has to end, particularly as between now and 2050 the major growth in urban populations will be in China, India, Indonesia and Nigeria. In these countries we need to think about how to boost cities’ resilience through far more adaptation funding. It can be done. Just look at Beijing, which stands out because the proportion of its economy devoted to climate adaptation was significantly higher than any other city in the study. Almost half of this was spent on changes to the built environment such as water efficiency retrofitting – a much higher ratio than any other city – with less going towards health or agriculture. The fact the Chinese capital is taking adaptation seriously is linked to strong central government policies, which encourage cities to face up to climate change. In China, all provinces have a comprehensive adaptation plan and a taskforce to deliver it. When governments offer leadership and policy certainty, things will happen. Most cities at least show solid growth in adaptation spending over the past five years, beyond their average GDP growth for the period. But adaptation spending was more volatile in Addis Ababa and Lagos, the cities in the study that spent the least in real, proportional and per capita terms, and heavily-dependent on a few specific projects. This should be a cause for concern. It is clear that insufficient funds are being spent to protect major population centres in developing and emerging economies. Our study is an early warning sign: we must remain focused on protecting people at risk, and not just the “capital”. Read this next: British power stations are burning wood from US forests – to meet renewables targets"
"
Share this...FacebookTwitterBy Ed Caryl
On 1 July 2014, NASA launched OCO-2, the second attempt at orbiting a global carbon dioxide observatory. In December, the first global map was released.

Compare this map with a frame from a previously released video showing a model of what the CO2 distribution was thought to be for roughly the same time period in 2006, the 1st of November.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Note the differences. There is much more CO2 coming from the tropical rainforests than the model predicts, and there is a sink, where CO2 is taken up, over Russia that the model does not have.
Since January, there has been no public disclosure of any further maps from OCO-2 on the OCO-2 website, except for a slide (their figure 5, shown below) from a webinar presentation that took place in February. This covers the period from late November to late December.

Compare this with a corresponding frame from the model video.

The reality measured by OCO-2 hardly resembles the model. The map released by NASA also seems to cut off CO2 sinks in the North Atlantic and Pacific. This may be excused by the sun angle in the Northern Hemisphere in December. NASA is surely learning a lot from OCO-2, but the findings may not be “politically correct”. We must await further data releases.
Share this...FacebookTwitter "
"Energy suppliers often refer to their industry as being caught in a “trilemma”, as people demand electricity that is both secure and cheap, while also being clean. But maybe it’s time to add a fourth consideration to the list – beauty. Just as we marvel at Roman aqueducts or Victorian railways, so we could design power plants, solar panels, turbines and other infrastructure to be beautiful additions to the landscape. As we move away from ugly coal and gas, we have a great chance to celebrate low carbon energy with imaginative new designs. UK energy minister Amber Rudd seems to agree. Speaking last year about nuclear energy, she stated: “I think it is a reasonable ambition to make sure that these big projects have aesthetic appeal as well [as being functional] to help win the public over.” Yet there are two problems to look out for. First, it is unreasonable to merely mask controversial or potentially environmentally damaging developments with a veneer of “attractiveness”. Managing public opinion with pretty designs does not supplant other valid concerns such as the choice of location or huge construction costs.  Second, even where “beautiful” design is sought as part of an environmentally responsible scheme, how individuals define and perceive “beauty” will certainly be a highly variable affair. One person’s majestic wind turbine is another person’s imposing eyesore. Like any type of architecture, judgements about beauty will depend on highly personal preferences, and how the new design relates to its existing context. The quest to find an appropriate aesthetic when designing novel infrastructure is not new. When the Victorians built the UK’s railway system a century and a half ago, the scale of this new technology and the visual and environmental changes it brought to urban and rural landscapes alike were immense – and hotly debated.  Engineers and architects designed large viaducts and impressive stations to be beautiful as well as functional. Though their alien structures were decried by some as ugly impositions, with time those same buildings have come to be part of the cherished character of British landscapes.  In the 1950s, nuclear power once again called for unprecedentedly large and unusual buildings. At Trawsfynydd in Wales, the leading designers of their time took up the challenge. Architect Sir Basil Spence and landscape architect Dame Sylvia Crowe designed a nuclear power station in a bold modernist style.  Although decades have passed and the plant has been decommissioned, opinions about its aesthetic value continue to be divided; some praise the architecture as “optimistic, triumphant [and] pioneering” while others would be happy to see the building completely disappear. We need innovative and sensitive design ideas for new energy systems, not just to “win over” the public but to actually improve the environment. Recent examples of well considered and multifunctional energy landscapes do exist.  At Georgswerder Energy Hill in the German city of Hamburg,  large wind turbines stand proudly atop an artificial mountain of landfill in a post-industrial area. Purified groundwater onsite is captured and used for energy, and the sunny side of the mountain is graced by solar panels. Visitors learn about renewable energy at a visitor centre before walking up to an elegant public “horizon line” walkway that encircles the mountain and gives expansive views of the city beyond.  In Norway, the Øvre Forsland hydroelectric power station similarly aims to be educative, to reflect the local context, and to unapologetically attract attention. One interesting example on the drawing board is the proposed Tidal Lagoon Swansea Bay. The power station consists of a large artificial lagoon formed by a sea wall, with water allowed in and out through underwater electricity turbines. Electricity is harvested from the difference between low and high tides. The plans include space for walkers and cyclists along the top of the sea walls, and an iconic, ark-shaped offshore visitor centre (pictured above, by Juice Architects) on the far side of the lagoon. Landscape architects LDA have already received the highest accolade in their field – the Presidents’ Medal – for creatively developing a scheme which “puts place-making at its heart and seeks to integrate a major renewable energy project into the lives of local people”.  Given the grim consequences of climate change and the political stakes associated with generating energy, the question of aesthetics may seem trivial. Investments in renewables obviously need to be based on more than just appearances. However, as society quickly transitions to better sources of energy, designers are embracing the opportunity to reflect and celebrate the change. Seeing how big power plants, as well as hugely important small-scale community initiatives, can fit within the landscapes that people use and enjoy is a real challenge.  There will probably never be a power plant or solar panel that everyone deems beautiful. But debating beauty and design alongside function is vital to achieve better renewable energy developments."
"Germany’s automobile industry is its most important industrial sector. But it is in crisis, and not only because it is experiencing the effects of a recession brought on by Volkswagen’s cheating on emissions standards, which sent consumers elsewhere. The sector is also facing the existential threat of exceedingly strict European Union emissions requirements, which are only seemingly grounded in environmental policy. The EU clearly overstepped the mark with the carbon dioxide regulation that went into effect on 17 April 2019. From 2030 onwards, European carmakers must have achieved average vehicle emissions of just 59 grams of CO2 per km, which corresponds to fuel consumption of 2.2 litres of diesel equivalent per 100 km (107 miles per gallon). This simply will not be possible. As late as 2006, average emissions for new passenger vehicles registered in the EU were around 161 g/km. As cars became smaller and lighter, that figure fell to 118 g/km in 2016. But this average crept back up, owing to an increase in the market share of gasoline engines, which emit more CO2 than diesel engines do. By 2018, the average emissions of newly registered cars had once again climbed to slightly above 120 g/km, which is twice what will be permitted in the long term. Even the most gifted engineers will not be able to build internal combustion engines (ICEs) that meet the EU’s prescribed standards (unless they force their customers into soapbox cars). But, apparently, that is precisely the point. The EU wants to reduce fleet emissions by forcing a shift to electric vehicles. After all, in its legally binding formula for calculating fleet emissions, it simply assumes EVs do not emit any CO2 whatsoever. The implication is that if an auto company’s production is split evenly between electric vehicles and ICE vehicles that conform to the present average, the 59 g/km target will be just within reach. If a company cannot produce electric vehicles and remains at the current average emissions level, it will have to pay a fine of about €6,000 (£5,150) per car, or otherwise merge with a competitor that can build electric vehicles. But the EU’s formula is nothing but a huge scam. Electric vehicles also emit substantial amounts of CO2, the only difference being that the exhaust is released at a remove – that is, at the power plant. As long as coal- or gas-fired power plants are needed to ensure energy supply during the “dark doldrums” when the wind is not blowing and the sun is not shining, EVs, like ICE vehicles, run partly on hydrocarbons. And even when they are charged with solar- or wind-generated energy, enormous amounts of fossil fuels are used to produce EV batteries in China and elsewhere, offsetting the supposed emissions reduction. As such, the EU’s intervention is not much better than a cutoff device for an emissions control system. Earlier this year, the physicist Christoph Buchal and I published a research paper showing that, in the context of Germany’s energy mix, an EV emits a bit more CO2 than a modern diesel car, even though its battery offers drivers barely more than half the range of a tank of diesel. And shortly thereafter, data published by VW confirmed that its e-Rabbit vehicle emits slightly more CO2 than its Rabbit Diesel within the German energy mix. (When based on the overall European energy mix, which includes a huge share of nuclear energy from France, the e-Rabbit fares slightly better than the Rabbit Diesel.) Adding further evidence, the Austrian thinktank Joanneum Research has just published a large-scale study commissioned by the Austrian automobile association, ÖAMTC, and its German counterpart, ADAC, that also confirms those findings. According to this study, a mid-sized electric passenger car in Germany must drive 219,000 km before it starts outperforming the corresponding diesel car in terms of CO2 emissions. The problem, of course, is that passenger cars in Europe last for only 180,000km, on average. Worse, according to Joanneum, EV batteries don’t last long enough to achieve that distance in the first place. Unfortunately, drivers’ anxiety about the cars’ range prompts them to recharge their batteries too often, at every opportunity, and at a high speed, which is bad for durability. As for EU lawmakers, there are now only two explanations for what is going on: either they didn’t know what they were doing, or they deliberately took Europeans for a ride. Both scenarios suggest that the EU should reverse its interventionist industrial policy, and instead rely on market-based instruments such as a comprehensive emissions trading system. With Germany’s energy mix, the EU’s regulation on fleet fuel consumption will not do anything to protect the climate. It will, however, destroy jobs, sap growth, and increase the public’s distrust in the EU’s increasingly opaque bureaucracy. • Hans-Werner Sinn, is professor of economics at the University of Munich. He was president of the Ifo Institute for Economic Research, and serves on the German economy ministry’s Advisory Council.  © Project Syndicate "
"
Share this...FacebookTwitterOn the folly scale, the following story is right up there with the Antarctic Ship of Fools.
Unfortunately this one ended in a terrible tragedy.

Global warming researchers Marc Cornelissen and Philip de Roo believed to have perished in the Arctic. Photo Twitter.
The online Spiegel here reports that two Dutch researchers, Marc Cornelissen, 46, and Philip de Roo, 30, are assumed to have died in the Arctic. “They wanted to collect data about the melting ice cover.”
According to Cornelissen’s Twitter site, the pair began their expedition in late March. By early April they has set off on skis across Arctic sea ice accompanied by a husky. They had been posting daily reports at Twitter.
At times Cornelissen tweeted of unusually warm temperatures and even posted audios claiming to be skiing in shorts.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On April 29 things took a turn for the worse and the pair sent out an SOS while traveling near Bathurst Island, approximately 200 kilometers north of Resolute Bay.
On April 30 Cornelissen’s Twitter site posted that the two were missing.
Spiegel writes that it is suspected that one of the pair fell through “thin ice” and that their situation went unknown for a week. A Canadian search party found one body but the other member of the party remains missing. It is assumed that he has perished. Only the husky dog survived.
The site Cold Facts here posted a report stating that the ice conditions there were “very poor”. The two researchers are said to have been experts in their fields. Question: Why were the two trekking on ice conditions described as “very poor”? Shouldn’t experts know better?
Also it needs to be asked if the decision to send out two researchers on foot in dangerous and highly unpredictable conditions was a grossly negligent one. Who approved this? Today modern satellite altimetry and aerial instrumentation can measure ice conditions more far accurately, safely, and efficiently. Why send out two men on foot on thin ice when the Arctic melt season is well under way?
Personally I think the expedition smacks more of a piss-poorly judged publicity stunt by activists, and much less a scientific expedition to explore the unknown. This looks to be highly dim-witted and reckless adventurism in servitude of sensationalist science. There needs to be an independent inquiry into this accident.
Negligence in harsh conditions often carries a lethal price. Unfortunately some of us still have to learn the hard way.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHow many times must a hockey stick be broken, before alarmists stop wetting their beds? … The answer my friend, is blowing in the wind.
======================================
Second climate status report on the Baltic Sea Region: Medieval Warm Period was Half A Degree Warmer Than Today
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
[Translated, edited by P Gosselin]
In mid-May 2015 the second Climate Status Report on the Baltic Sea region was released. It was coordinated by the Helmholtz Center in Geesthacht, Germany. In a press release the institute explained:
The Second Assessment of Climate Change for the Baltic Sea Basin (BACC II), a recently published report, serves as a revision and expansion of the 2008 edition of the BACC book. ‘The current publication for the Baltic Sea area is a regional variant on the global report published by the Intergovernmental Panel on Climate Change (IPCC),’ says Prof. Hans von Storch, Director of the Institute of Coastal Research at the Helmholtz-Zentrum Geesthacht and initiator of the report. The comprehensive scientific survey includes work from 141 scientists from twelve countries. The project team was coordinated by the International Baltic Earth Secretariat at the Helmholtz-Zentrum Geesthacht and consists of meteorologists, hydrologists, oceanographers and biologists.
Warming continues
The current study takes into consideration observed climate changes for approximately the last two hundred years as well as possible changes that might occur by the year 2100. These projections are obtained from computer models. Warming air temperature in the Baltic Sea region has already been verified based on measurements, but the increase is seasonally and regionally different. The most drastic recorded increase in warming to have occurred in the northern Baltic Sea region was 1.5 degrees Celsius between 1871 and 2011 during the spring seasons. This number is well above the global warming estimates of up to one degree Celsius documented in the last IPCC report.”
The folks in Geestacht indeed forgot to mention a small detail in the press release, as you will soon see. The first two chapters of the report deal mainly with the climate development of the last 12,000 years and the last 1000 years:
Pages 25-49: Climate Change During the Holocene (Past 12,000 Years)
Irena Borzenkova, Eduardo Zorita, Olga Borisova, Laimdota Kalniņa, Dalia Kisielienė… Download PDF (1004KB)
Pages 51-65: The Historical Time Frame (Past 1000 Years)
Tadeusz Niedźwiedź, Rüdiger Glaser, Daniel Hansson, Samuli Helama, Vladimir Klimenko… Download PDF (912KB)“


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Obviously the Baltic Sea study goes far beyond the claimed 200 years. So out of curiosity, we examined the first two chapters. In the abstract of the 12,000-year chapter we discovered something interesting (emphasis added):
The Holocene climate history showed three stages of natural climate oscillations in the Baltic Sea region: short-term cold episodes related to deglaciation during a stable positive temperature trend (11,000–8000 cal year BP); a warm and stable climate with air temperature 1.0–3.5 °C above modern levels (8000–4500 cal year BP), a decreasing temperature trend; and increased climatic instability (last 5000–4500 years). The climatic variation during the Late-glacial and Holocene is reflected in the changing lake levels and vegetation, and in the formation of a complex hydrographical network that set the stage for the Medieval Warm Period and the Little Ice Age of the past millennium.”
The pre-industrial climate of the Baltic Sea region was everything but stable. According to the study during the period of 8000-4500 years before today, it was about 1 to 3.5 degrees Celsius warmer than it is today. This corresponds to the so-called “mid-Holocene climate optimum”. This is a warm period that is practically unknown to the public and not very well-liked by the media outlets. Suddenly we find a completely new meaning in the press release’s subheading “Warming continues”. It is getting warmer – but nowhere near as warm as it was during the 8000-4500 year before present period.
At the end of the abstract the attention shifts to the Medieval Warm Period, which is a part of the subsequent chapter by Tadeusz Niedźwiedź and colleagues. In the text describing the last 1000 years we find the well-known climate cycle that the IPCC tried to discard: the Medieval Warm Period, Little Ice Age, Modern Warm Period. The chapter writes:
According to the scientific literature, there are four climatic periods of the past millennium: the Medieval Warm Period (MWP 900-1350), the Transitional Period (TP 1350-1550), the Little Ice Age (LIA 1550-1850), and the Contemporary Warm Period (CW after 1850).”
Just how warm was it during the Medieval Warm period in the Baltic Sea region? Also here with this inconvenient question the authors do not shy away (emphasis added):
Recent investigations of Fennoscandia by Ljungqvist (2010) showed that the MWP [Medieval Warm Period] occurred between 800 and 1300. At that time, warm-season (May-September) temperatures exceeded the contemporary warming of the end of twentieth century by about +0.5°C. The start of the warming was noted between the ninth and tenth centuries, and the peak temperature appeared at the beginning of the second half of the twelfth century. In a winter temperature simulation over the Baltic Sea region (Schimanke et al. 2012) during that time anomalies reached their highest value of+0.8°C for the MWP.”
The text above is a clear statement. The Baltic Sea region was 0.5°C warmer 1000 years ago.
No one wanted in any way that this important condition get mentioned in the press release. How could it have been warmer 1000 years ago than it is today at a time when atmospheric CO2 concentration was extraordinarily low?
Share this...FacebookTwitter "
"
Share this...FacebookTwitterResponse to NOAA’s claim adjustments are improvements
By Mike Brakey
The email from NOAA’s Derek Arndt confirms that they conducted a massive rewrite of U.S. data in 2014. He also confirmed that the 1913 Maine climate data was indeed lowered a whopping 40F as noted in my article, Black Swan Climate Theory.
My response is based on actual unadjusted temperature data from the Lewiston-Auburn area of Maine, which I secured from a local source and provided in prior emails. (I have attached that data and links to the websites the data was extracted from).  As shown in Chart 1, between 1895 and 1937, the Lewiston-Auburn region (Zone 19 in Chart 2) was typically ¾0F warmer than Maine’s overall state average, based on NOAA data I downloaded in 2013.

Chart No. 1 & 2.
This data is the black line on Chart 1. I would expect the Lewiston-Auburn area to be slightly warmer than Maine as a whole because it is in southern Maine. Based on the 2013 data, Maine’s average temperatures were about ¾0F colder or less than those for Lewiston-Auburn during the period from 1904 to 1939, and again from 2008 through the present.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The green shaded area shows what the NOAA data would have looked like if that ¾0F difference had remained constant through 2015.  Looking at the year 1913, I might agree with Mr. Arndt that they had an error and I would understand a temperature correction of approximately  ¾0F, but not 40F.
Contradictory data
I am suspicious of the NOAA data, both the original from 2013 and the revised, between 1940 and 2008 because the Maine average temperatures are so significantly less than those for the Lewiston-Auburn region. The other oddity is that there was a downward trend in temperatures for Lewiston-Auburn starting in 1998. However, both sets of NOAA data show temperatures rising for the state of Maine during that same time period.
As well-intended as I believe most NOAA associates likely are, I implore NOAA to please make available the plain, unexciting, unfiltered temperature data (as typified by the green line in Chart 1 above).  If the RAW temperature data is always made available, I would be happy to entertain any theories and projections NOAA or IPCC wishes to make…as long as we all know the true base line (similar to what we have for the green line in Chart 1 with Lewiston-Auburn historical temperature data).
In conclusion, I implore NOAA to return credibility to its website, by getting out of the statistical smoothing and adjusting business and by just providing the scientific community with the basic unfiltered temperature data at all of its site locales. Let’s stay away from all the havoc created between Charts 3 and 4.

Chart no. 3 & 4.
Watch the entire series of YouTube videos on how I found the NOAA adjustments.
Share this...FacebookTwitter "
"Outdoor air pollution is responsible for around 40,000 deaths in the UK each year, according to a new report by the Royal College of Physicians. It’s a scary headline number. However just as significantly this is also one of the first reports to recognise how important indoor air quality is to our health. After all, we spend around 90% of our time inside, whether at home, at work, or commuting. Indoor air pollution is not a new phenomenon. Since the dawn of history, humans have burnt wood, peat or coal to produce heat. The walls of caves, inhabited millennia ago, are covered with layers of soot and mummified bodies from the stone ages often have blackened lungs.  A passage in Leviticus indicates that Biblical people were aware that damp buildings were a health risk. In the 18th century it was recognised that “want of ventilation” resulted in increased rates of infectious disease. By the mid-19th century it was being reported that “deficient ventilation … (is) more fatal than all other causes put together”. Around the 1960s research into indoor air quality really began to take hold. Initially it highlighted the dangers of radon and tobacco smoke before extending to formaldehyde (a common household chemical that can cause cancers and respiratory problems) in the early 1970s, house dust mites and sick building syndrome later that decade, and eventually focused on allergies during the 1990s.   Since the millennium interest has moved towards developing countries where around 3 billion people cook and heat their homes using open fires and simple stoves burning wood and coal. The subsequent indoor air pollution results in 4.3m people a year dying prematurely.  The World Health Organisation estimates around 99,000 deaths a year in Europe from indoor pollution. Assuming these deaths are equally distributed across Europe one would expect around 9,000 deaths in the UK. While there is legislation to reduce exposure to pollutants in the workplace, as well as tobacco smoking legislation that now prohibit smoking in public spaces, it is extremely unlikely that any government would try and impose air quality standards in private homes. A typical home has lots of different sources of pollution: heating, cooking, cleaning, smoking, perfumes and furnishings. Even the simple act of moving about stirs up particles. Demands to improve the energy efficiency of buildings comes with the concern that more airtight homes could have an adverse effect on indoor air quality. The air inside your home may already contain all sorts of unwanted stuff such as particulate (microscopic bits of solid or liquid matter), carbon monoxide, oxides of nitrogen, formaldehyde, radon, and volatile chemicals from fragrances used in conventional cleaners. Then there are the “bioaerosols” – bacteria, fungi, viruses, house dust mites and bits of skin shed by furry or feathered animals. Even peeling an orange has been shown to increase the number of particles by several orders of magnitude. Although some indoor pollutants are unavoidable, there are various ways to reduce your exposure: Do as your grandparents did and open the windows to increase the ventilation. If you’re cooking it is important to use the extraction fan otherwise levels of nitrogen dioxide can exceed those on the most polluted roads. Don’t smoke indoors or use candles. If you have a wood-burning fireplace ensure it is fitted and used correctly.  Install a carbon monoxide detector as this “silent killer” leads to around 40 deaths each year in the UK. Chose hard-surface floors. They’re easy to clean, and carpets can let dirt and pet hair escape back into the air. Try to keep the humidity level in your home between 30% to 50% and always ensure proper ventilation in damp areas, such as bathrooms. This helps prevent mould which has been linked with upper respiratory tract symptoms. Some people are more sensitive than others including babies and children, elderly people, and those with respiratory problems such as allergies and asthma. Use a doormat to prevent dirt from entering into your home and/or ask people to take off their shoes when they visit you. Reduce your use of cleaning products or air fresheners,  especially those containing limonene (which gives the lemon citrus smell). Get some houseplants. Studies by NASA and the University of York for the BBC both found that plants could reduce levels of formaldehyde in the home."
"
Share this...FacebookTwitterThe Sun in May 2015, and Atlantic Waves
By Frank Bosse and Fritz Vahrenholt
[Translated, edited by P Gosselin]
Our primary “fusion reactor” remains in a weak phase in its current solar cycle, number 24 since systematic observations began in the year 1749. In May sunspot activity was below normal. The observed sunspot number (SSN) was 58.8. The mean of all previous cycles for the current 78th month into the cycle is SSN=79. Thus May saw 75% of the usual activity.

Figure 1: The current cycle 24 (started in December 2008) is shown in red and is compared to the mean cycle (blue) and to cycle no. 5 (black).
A pronounced lull
Figure 1 shows that current solar cycle 24 has never exceeded the mean (blue) at any time since it began. In the 78 months since the it began, SC 24 has always been below normal. This has never been observed for any previous cycle.  The low solar activity since December 2008 is unique when it comes to its consistency when compared to the other cycles since observations began!
Even when activity reached a maximum in October 2011 in the sun’s northern hemisphere, and in February 2014 for the southern hemisphere, it remained just below the mean value. Together with the delayed start of the cycle we now have a record 10 years of quiet solar activity.

Figure 2: The accumulated sunspot anomaly of all cycle up to the 78th solar cycle month.
Figure 2 depicts a comparison of all the cycles with respect to solar activity. So far the current cycle is in 4th place in terms of low activity. But 3rd place is very reachable because SC 7 saw high sunspot values in its last third of the cycle, and so the chances are good that the total activity of SC 24 will be quieter than the last cycles of the Dalton Minimum.
Atlantic waves…
…are really high when it’s stormy. In early May off the coast of Portugal one of the co-authors of this article came to realize this in a 14-meter long sail boat. But the Atlantic also created other types of waves in the past month. A team of scientists led by Gerard D. McCarthy of the University of Southampton went on the search for internal North Atlantic variability, see www.nature.com/nature/journal.html. They determined that the Atlantic Multidecadal Oscillation (AMO) not only has ups and downs in sea surface temperature (SST) in the extratropic Atlantic region, but that these temperature variations lead to changes in sea level (SSH) along the east coast of the USA. The pattern appears as follows:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Figure 3: The “circulation series” shown in blue. In the paper the SSH variation is determined by comparing the sea level south of and north of Cape Hatteras. The AMO is black. Source: Figure 3 of the cited McCarthy publication.
The relatively long time series of tide measurements at the East Coast is thus a proxy for the ocean heat content (OHC) of the North Atlantic. Its direct measurement since the 1950 entails large uncertainty. But beginning in 2004 it has been much more precise thanks to the submerged ARGO measurement buoys and the RAPID network.
What implications does this study have? First of all, the existence of natural Atlantic Multidecadal Oscillations is confirmed, and not only as a variation in sea surface temperature (SST) as it was previously defined. It is now sure that the AMO is a large-scale North Atlantic water mass circulation pattern. It is an independent internal natural variability of our climate system, and not just one involving global temperature.
Already in January 2013 we pointed to falling North Atlantic ocean heat content (OHC) since 2007. What follows is the data plot:

 Figure 4: The ocean heat content (OHC) of the extratropical North Atlantic since 1979. Source: Climate4you. 
In the paper and its accompanying press release it is explained that the current decline in the OHC means it is announcing that the probability of the North Atlantic cooling more than 10 years is very high. The AMO’s impact on temperatures in the northern hemisphere was major in the past, as the following plot shows:

Figure 5: The AMO (green) compared to temperature changes of the Northern Hemisphere (red). 
If the AMO exists as an internal variability, as the McCarthy paper tells us, then that could imply that 0.5°C warming seen in the northern hemisphere since 1975 was due to the AMO and that the remaining 0.5°C of warming was due to impacts from greenhouse gases and other factors, such as varying solar activity.
For estimating climate sensitivity from greenhouse gases, this has far-reaching implications: Up to now we were not able to completely exclude the impact of aerosols on the cooling of temperatures between 1945-1975, but now it is appearing as increasingly improbable. Indeed it is becoming more evident that the cooling was due to the weakening AMO during that time period (see Figure 3).
If indeed aerosols have a lesser cooling effect than previously assumed, then the climate sensitivity with respect to greenhouse gases must be less.  Since 1975 for the northern hemisphere it was not 0.26 °C / decade increase, but rather only 0.13. This is close to being identical to the southern hemisphere. We’ve often discussed this 50:50 order here …and once again we are confirmed.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMy father used to say that medical doctors were really gangsters in white coats. I used to think he was just being cynical, and so I pretty much dismissed it. Well it turns out his attitude allowed him to live beyond 90, and today I realize he was right all along.
What follows below is a reader comment by MJSnyder that really made my day. A couple of days ago I posted here on the consensus-led disaster of the lipid hypothesis. One reader got all upset about it and attempted to discredit the doctor whom I was citing with the aim of discrediting the science.
Of course one doctor doesn’t make science. But over the past years an entire chorus of doctors have emerged, and they are sharply criticizing the at times fraudulent science underpinning the lipid hypothesis. Even the government, having seen tens of millions of diabetics over the recent decades, has finally begun accepting the new results that fat and cholesterol are not killers after all and that they are actually healthy. Longstanding dietary guidelines are being amended.
I’ve switched to a high-fat, low-carb diet with vegetables and have seen amazing results when it comes to weight and examination test results. No more medicines for me. Of course this really bothers evil Big Pharma. But I’m not the only one who has seen success…
Here’s what one reader sent:
Pierre – Last year you had a posting on your life-style changes that intrigued me, so I followed the links, that lead to more links, that lead…..
I became convinced that the low carb diet was the way to go. So I switched to high fat, low carb. I’m now down 43 lbs, my blood pressure has normalized (now 5 pills less per day), my type II diabetes is controlled (7 pills less). I’ve also dropped Lipitor (cholesterol statin) and no longer have excruciating leg cramps.
My original goal was a loss of 80 lbs, but this has been so easy to attain that I’m thinking of extending it to 100 lbs.
I’m feeling so good about myself again that I’m seriously planning another cross-continent bicycle tour. That would the 3rd. I’m 71 years now.
Thank you Pierre – I’m very grateful for you sharing your personal experiences.
I’m convinced that the Climate Science industry and the Pharmacological industry are fraternal twins.
What’s incredible is that the cure is so simple and only involves nutrition adjustments – nothing more. Tens of millions have the opportunity to get better soon, in less than a year!
I’ve posted a couple of times on nutrition, and I think the reader means this post: https://notrickszone.com/2014/05/10/the-greatest-nutritional-and-pharmaceutical-swindle-of-all-time…
Or perhaps here: https://notrickszone.com/-how-consensus-science-may-have-almost-killed-andrew-revkin/
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn 2009 Al Gore predicted an ice-free Arctic by 2014. It never materialized – not even close.
Not to be outdone, John Kerry upped the ante and boldly proclaimed an ice-free Arctic by 2013. That too was utter nonsense.
In 2010 oceanography researcher Wieslaw Maslowski claimed: “Near ice-free summer Arctic might become a reality much sooner than GCMs predict“. This was reported in the press as “US Navy predicts summer ice free Arctic by 2016“.
Louis Fortier, scientific director of ArcticNet, a Canadian research network, said the sea ice was melting faster than predicted by the Intergovernmental Panel on Climate Change (IPCC).
An earlier National Climate Assessment report wrote that models that best match historical trends project a nearly ice-free Arctic in the summer by the 2030s.

Other real experts were less dramatic with their predictions. For example in 2009 Overland & Wang predicted that there would be an ice-free Arctic in the summer by 2037. A 2006 paper by Marika Holland et al. predicted “near ice-free September conditions by 2040”. Tony Heller, a.k.a. Steve Goddard, has an entire list of ice-free Arctic predictions.
Postponed again to 2050
Now polar conditions have stopped cooperating, and sea ice looks poised to defy the projections. A couple of days ago I wrote here about how natural cycles are now aligning to lead to more sea ice cover over the next one or two decades, and that global sea ice levels are back to normal levels – a fact that the end-of-world obsessors are finding difficult to come to terms with.
The recent sea ice developments even have the government-funded alarmist institutes now in a state of anyxiety. Already we are beginning to see them push back the predicted date of an ice-free Arctic. The latest example come from Germany’s prestigious, yet alarmist, Alfred Wegener Institute (AWI) for polar and ocean research – so reports Germany’s Deutschland Funk national public radio here in an interview with Christiane Habermalz, Arctic Ny Alesund station engineer of the AWI.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the interview Habermalz insists that the Arctic is the “hot-spot” of global warming, and that sea ice is melting faster than expected (Fact: it isn’t at all). She claims that the Arctic is warming 1.3°C per decade, basing that on only two decades of data: from 1993 to present. She also did not hold back from giving the impression that the trend would continue unabated, but then adding:
…in any case during the Arctic summer more and more of the sea ice is melting further and there are increasingly greater ice-free zones. That is something that also the scientists here at Ny Alesund have said, and that when the melting of the sea ice continues the scenario of an ice-free pole by 2040/2050 is very likely.”
2050? That’s a far cry from what we’ve been hearing from other experts over the last years.
There are some interesting statements here. First Habermalz is implying that it will take a sustained 1.3°C per decade of Arctic warming for this to happen. But as most people who have read about the Arctic know, temperatures there go in cycles. The warm cycle has already reached its peak and so the temperature level there needed to melt the ice by 2030 will not be reached. Thus the 2040/50 ice-free scenario won’t happen as calculated by the AWI. (By ice-free, we mean over a number of years, and not a single outlier year, which cannot be excluded). The AWI knows it, and so now we are seeing a conscious postponement of an ice-free Arctic.
Of course expect the AWI and similar institutes to keep ringing the alarm bells, but at the same time quietly move the goalposts back as reality dawns.
Finally, what do the experts project this summer’s Arctic sea ice minimum to be this year? Joe Bastardi tells us at his Saturday Summary here at the 13:15 min mark:

US government NCEP forecast for Arctic sea ice anomaly this year. Source: Weatherbell.
Obviously the AWI has gotten the message, and so now the Arctic horror predictions have been pushed back to a future time, one far enough into the future that by then everyone will have forgotten all the silly, hysterical predictions made during the 2000s.
 
Share this...FacebookTwitter "
"Australia’s long spell of hot and dry weather that has increased the risk of bushfires is set to continue into summer, with the Bureau of Meteorology warning communities should prepare for more severe fire danger. The BoM’s summer outlook shows a higher than usual chance of above-average day and nighttime temperatures for most of the country, and an above-average chance of drier than average conditions for large parts of eastern Australia.  The bureau said spring, which brought catastrophic fire danger to the east coast, was likely to have been one of the driest on record. Andrew Watkins, the BoM’s head of long-range forecasts, said there was an 80% chance of warmer than usual days and nights for much of the country through summer. The outlook is similar for rainfall, with coastal areas of Western Australia from the midwest to the Kimberley the only locations showing increased odds of wetter-than-average conditions. “Summer’s looking particularly dry with high odds of drier-than-average conditions right down the east coast, including Tasmania,” Watkins said. A positive Indian Ocean dipole, which moves weather systems that would typically bring rain away from Australia, and a negative southern annular mode, are driving the continued hot and dry conditions. The onset of the northern monsoon is expected in mid-summer, which Watkins said could increase the odds of closer to average rainfall from January and February. But he said communities should be preparing for severe weather risks and a continuation of severe fire danger over the coming months. “We’ve already seen significant bushfire activity during spring, and the outlook for drier and warmer-than-average conditions will maintain that heightened risk over the coming months,” Watkins said. The outlook for heatwaves is also heightened. Australia recorded its hottest summer on record in 2018-19. The recent spring bushfires caused six deaths and destroyed more than 600 homes. The BoM said this spring is likely to have been the fifth driest for NSW and one of its 10th warmest overall. The trend was the same in almost all other states and territories, with the exception of western Tasmania, where weather conditions were cooler and wetter than usual. Victoria recorded record-breaking heat in November in many locations but its mean minimum temperatures for spring are on track to be the lowest since 2003. Meanwhile, firefighters in New South Wales on Thursday were battling more than 150 blazes and issued a warning for residents to prepare for fires to worsen over the weekend. While there were no total fire bans in place for Thursday, the greater Hunter, greater Sydney, Illawarra-Shoalhaven, southern ranges, central ranges and northern slopes were under “very high” fire danger rating, as was the ACT. “With more than 150 fires burning across #NSW and the forecast of more hot and windy weather for the weekend please use this time to prepare. Review your bush fire plan, prepare your properties and discuss as a household what you will do if threatened by fire,” the NSW Rural Fire Service tweeted. On Thursday morning, 64 of the 157 fires across NSW were uncontained. The Bureau of Meteorology said lightning strikes from thunderstorms which hit Sydney and the state’s north-east on Tuesday had sparked fresh blazes, with an estimated 100 new fires igniting in a 24-hour period."
"How do we stop the “arms race” in Easter egg packaging? Every year, supermarket shelves fill with garish, unnecessarily big boxes to exploit our shallow desires for the fanciest-looking chocolate eggs. The bigger the front face of the packaging, the more attractive it is, the more shelf appeal it has, and the more likely it is you’ll buy it. But more packaging also means more plastic, cardboard, energy – and waste afterwards. It’s big business. Every year, more than 80m boxed chocolate eggs are sold in the UK alone, leading to around £250m in sales. Meanwhile, food and drink packaging continues to cause environmental problems. Packaging uses resources and generates waste. The weight of food and drink packaging per person has not declined in the UK since figures were first generated in 1998 and 3% of the total environmental footprint of British households, measured by energy, still comes from packaging.  Faced with public concern in 2008, confectionery manufacturers made some progress in 2009 towards reducing Easter egg packaging but progress since then has not been tracked and manufacturers still seem to be locked into unnecessarily large, eye catching packaging. Sweets are usually an impulse or gift purchase, and sales are still largely driven by what they look like. Two identically-sized chocolate eggs will vary in how well they sell: the one with a larger shelf “facing” will tend to generate more sales simply because of its increased eye appeal.  The result is that Easter egg manufacturers and retailers are in an “arms race”, a race that demands eggs take up more and more space on the shelf. Each larger package means fewer individual units can be displayed in the same shelf space, leading to lower sales, which then requires higher profit margins to create the same revenue … and so on.  Meanwhile, confectionery manufacturers fear that discussing the problem between themselves and agreeing standards will be seen as restricting competition and they don’t want to fall foul of competition law. Buyers at the big supermarkets are in the same situation; they can’t talk to their confectionery suppliers unilaterally because they’d lose sales, but they can’t talk to suppliers collectively because they fear the wrath of competition law. Of course, Easter eggs need protecting. They’re only fragile shells of chocolate, after all, and poor packaging would arguably mean greater waste from damaged goods that have to be thrown away.  The challenge is to design gift packaging that uses as little material as possible – without limiting the egg’s “standout” on the shelf. Resizing primary packaging (the part that shoppers see) would reduce the cost of cartons and transport costs for the manufacturers; no one wants to pay for a lot of empty space surrounded by an attractive box. Retailers don’t really want to use precious shelf space on cartons containing lots of fresh air either. And smaller packs would also reduce the amount of waste we have to throw away or try to recycle from our homes.  Manufacturers of detergents, deodorants and food and drink have all seen the environmental benefits of cutting back on unnecessary packaging. But Easter eggs are bought almost entirely as gifts – looks are all-important, and size matters. Big British-based manufacturers have drawn up a Code of Practice for responsible packaging. It requires honesty. Manufacturers adopting this code no longer use packages with “double walls”, for instance, since any hollow space between the walls can mislead customers. However, this same code sets out the gifting dilemma, too:  When a product is conceived as a gift or luxury item, it is recognised that the packaging will reflect the presentational nature of the product and may be more elaborate than functionally necessary, but this does not mean that it should be excessive. A simple rule on the ratio of packaging to product could change the way the system works without any one supplier or retailer disadvantaging themselves against their competition. This sort of rule would mean less packaging, lower transport costs, less waste and retailers would be able to sell more per unit of shelf space. Consumers would also be more confident that they won’t be disappointed when they open up their Easter egg. It’s an example of how government regulations can be good both for businesses and consumers. What we suggest for Easter eggs has echoes elsewhere, from the changes in supermarket refrigeration displays to reduce energy consumption, to the call from businesses for a carbon price and clear consistent regulation from the recent climate change COP in Paris. Sensible regulation has worked elsewhere – and not all regulation is bad."
"
Share this...FacebookTwitterThe poles, we are told, are supposed to be the tell-tale barometer of global warming. No place is supposed to warm up as quickly as the poles.
And because there are practically no thermometers to speak of at both the North and South poles, we need a better way of getting an idea of how temperature is behaving at these remote yet “sensitive” regions of our planet.
Because ice melts when it’s warmer and freezes when it’s colder, polar sea ice cover could act as a good measurement tool in place of the mercury thermometer. Not only does it indicate air temperatures, but also water temperatures beneath the ice. It can be argued that sea ice extent is indeed a better way of measuring overall temperature than mercury thermometers. Fortunately NASA has been taking satellite excellent photos of both poles since 1979 and thus we have an accurate record of sea ice spanning 35 years.
As CO2 rises, global warming is claimed to be enhanced, and thus the poles should be warming, disproportionately many scientists claim, compared to other regions like those located near the equator. We should see it in the global sea ice record.
The following is a plot of CO2 vs global sea ice extent since 1979:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




 Graphic formed by combining WoodForTrees CO2 plot and the U. of Illinois sea ice anomaly plot.
The above chart shows that today’s global sea ice is basically at the same level as it was 35 years ago, back when CO2 was below 350 ppm. Moreover the overall trend is flat. There’s no correlation. CO2 has not caused sea ice to melt like it has been claimed to do. Not even close! The melting that did occur was very short in duration, less than 5 years, from 2005 to 2008.
The whole scare of a polar meltdown has been nothing but a huge load of bovine manure. The whole thing has been nothing but widespread hysteria in the collective paranoid mind of a society fanned by high tech, highly funded swindlers and a complicit media class.
The whole global warming scare arguably has been a power grab by an elitist cabal of lying bureaucrats who have deluded themselves into thinking they have all the answers and solutions.
It’s high time that the new generation of politicians start calling it out.
 
Share this...FacebookTwitter "
"Malcolm Turnbull says Australia will struggle to meet its Paris emissions target without rapid decarbonisation of the energy sector, and he says the Liberal party’s continuing failure to develop a coherent climate and energy policy is costing the country much-needed new investment in power generation. In a wide-ranging interview with Guardian Australia’s politics live podcast ahead of the publication of his memoir next year, the former prime minister said the Liberal party had struggled with climate change denialism since 2007 because climate change had morphed into an issue of “identity” rather than fact.  Other highlights of the interview included: Turnbull predicting Scott Morrison would have great difficulty curbing climate activism by adjusting the existing secondary boycott regime, saying: “I think it’s very likely not in line with the constitution.” He also argued the proposal floated by Morrison was fundamentally inconsistent with the principle of free expression. Turnbull saying the Murdoch media – “the dominant, the leading media group in Australia” – was a long-time promoter of climate denialism, making it harder to land a sensible policy. He laughed off this week’s statement from Rupert Murdoch that there was no denialism at News Corporation, declaring the proprietor was “not reading his own papers or watching his own cable news channels”. A flat rejection of the idea ventilated widely during the bushfire crisis that Australia had no material impact on climate change because it makes up only 1.3% of global emissions. “The reality is Australia has to take action to reduce emissions,” Turnbull said. “We have a commitment under the Paris agreement to do so. People also look to Australia as a developed country, a wealthy country, to take the lead, to take a leading role.” He said Australia’s current failure to act seriously to reduce pollution hampered its ability to persuade other countries to do their part. A declaration that it would be a major mistake if the Morrison government ended up subsidising coal, because “subsidising coal is about as crazy as it gets. The bottom line is renewables have won, that’s why no one in the energy sector is building new coal.” A swipe at the National party, noting some politicians claiming to represent farmers and people in the bush “were not speaking for farmers”, because farmers were battling on the frontline of a climate crisis. “The reality is people on the land are dealing with the consequences of a hotter and drier climate.” While Morrison and the minister for emissions reduction, Angus Taylor, declare regularly that Australia will meet its Paris targets in a “canter”, Turnbull – the prime minister who ratified the Paris agreement – expressed scepticism on the basis the government lacked a coherent set of policies to drive the necessary abatement. “I think in the absence of a rapid decarbonisation of the energy sector, we will struggle to get to the 26-to-28%, that’s why the national energy guarantee was very important,” he said. Turnbull said Australia might be able to land the 2030 target with help from Kyoto era carryover credits, but their use was controversial. He said it would be better for Australia to use carryover credits to meet the 2030 target as an insurance principle, invoking that accounting to get there if necessary, rather than have the Kyoto credits carry half the abatement task, which is Morrison’s current policy. He said the credits should not be a substitute for practical emissions reduction, because that only created problems down the track, as the 2030 target was just the first of a series of actions leading ultimately to net zero emissions by 2050. Turnbull said he’d met recently one of the largest renewable energy investors in the world, who told him companies were avoiding Australia because of the lack of policy and because of political risk. The former prime minister declared the energy sector was now “crying out” for settled policy, because the policy he attempted to implement, the national energy guarantee (Neg), had been blown up by “insurgents” and as a consequence of that “we have higher emissions and higher electricity prices”. He said Morrison and the now treasurer Josh Frydenberg had been fully on board with the Neg. The Neg was “a joint project” with Morrison and Frydenberg, he said, and it had enjoyed consistent support in the cabinet. But while Morrison and Frydenberg had been two of the government’s “keenest supporters” of the proposal, they would not bring it back because that would provoke the right wing of the Liberal party. Turnbull said they were aware there’s a group within the party “prepared to blow the show up if they persist with it”. Turnbull said Peter Dutton, who led the coup against his leadership, “never criticised [the Neg] to my recollection”. He said Taylor, the current energy minister, was “an internal critic but it was never entirely clear why”. He said the rump of sceptics inside the Liberal and National parties remained a barrier to sensible climate action. Turnbull said he continued to struggle to comprehend why climate change denialism persisted in the face of concrete evidence of warming. “There are plenty of odd beliefs out there and conspiracy theories but what I have always struggled to understand is why climate denialism still has the currency that it has, particularly given the evidence of the impact of climate change is now so apparent, and it is particularly apparent to people living in regional and rural Australia. “Precisely what has been forecast is happening.”"
"
Share this...FacebookTwitterMax Planck Society: “Temperatures stagnant approximately since 1998, but at high level”
By Sebastian Lüning and Fritz Vahrenholt
[Translated/edited by P. Gosselin]
Attempting midterm predictions
The Max-Planck Society publishes the magazine “Max Planck Forschung” on a regular basis. In its 1/2015 issue beginning on page 68 one finds the article: “…and now on the climate of tomorrow”. The German language article is also available (pdf here). The article starts:

How will the climate appear in 10 or 15 years? Scientists have been unable to provide a satisfactory answer to this question – mainly because random changes play a large role in such mid-term time-frames. A natural fluctuation is likely also the cause of temperatures barely increasing over the past 15 years. Jochem Marotzke of the Max Planck Institute for Meteorology in Hamburg and his colleagues all over Germany are working intensively on a system that will deliver reliable prognoses for the coming years.”

Hiatus confirmed
In other words this is about the pause in warming since 1998 and the question of why none of the expensive climate models had correctly forecast the hiatus. Indeed this is a big problem, especially for the fraternity of the climate modellers, who in Germany are led by chief modeler Jochem Marotzke. His favorite excuse: “random changes”, which in his opinion are completely unpredictable. But that’s fatally wrong. His colleagues have long known better and have identified the 60-year ocean cycles as systematic climate drivers. See for example  here, here, here, here.
Scrambling to explain faulty models
First of all the Max Planck Magazine thankfully does confirm what all temperature curves now clearly show, but what a few climate activists clearly refuse to believe:
Another resaon was a phenomenon that at the end of the past decade it was visible that there was a temperature plateau, and this continues to occupy climate scientists today. The global warming that was in high gear during the 1980s and 1990s now appears to have been making a pause since the start of the new millennium. The temperatures have been stagnating since about 1998, but at a high level.”
Jochem Marotzke has recognized that this cannot continue on. Awhile back he launched the Project MiKlip with the aim of making more reliable prognoses. In the Max Planck Forschung (MPF) magazine it is stated:

Today, almost 10 years later, the science regarding decadal climate prognoses has come a long way. From 2011 to mid 2015 the German Federal Ministry for Science has financed the project MiKlip (Midterm Climate Prognoses), that Jochem Marotzke initiated and now coordinates as its director. In the meantime the application for the second phase has been made.”

Cooling Atlantic


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




We’ve reported on the MiKlip project before. The main result from the initiative so far is hardly known to the media because it is just too inconvenient. See our article “Over the midterm the climate prognoses of the BMBF MiKlip Projects: North Atlantic will cool down by several tenths of a degree by 2020″. Using a Google search, the environmentally activist Süddeutsche Zeitung has yet to report on this amazing prognosis. Activist climate website “Klimaretter.info” naturally has not done so either. Thus we are very curious on whether the Max Planck Magazine is now perhaps able to talk openly about this. In the article’s  title and introduction we see that this important information is absent. In England however, the University of Southampton recently came up with the same result but was much more transparent and proactive with the cooling finding. See our blog article “University of Southampton: Cooling ocean cycle will cause Atlantic to cool by half a degree Celsius over the coming decades, global warming hiatus continues and hurricanes will become less frequent“.
Max Planck Institute refuses to see ocean cycles
But instead of following the example from England, Marotzke continues to stick to his worn out chaos meme. MPF magazine writes:

Such forecasts however are still in the early stages. ‘There is still a lot of work that remains ahead of us,’ says the Hamburg-based scientist. Over the mid-term climate prognoses are burdened by a fundamental difficulty: the chaos of the climate system. As it is so with the weather, also the climate (the mean of weather) is also subject to natural fluctuations that more or less occur randomly. […] Climate scientists refer to these more or less random fluctuations as spontaneous or as internal variability. Due to such variations the global mean temperature can vary by 0.2 or 0.3°C from one year to the next. For scientists these variations are known as so-called ‘noise’ that superimpose the actual signal of global warming.”

Models’ hopelessly faulty assumptions
Here we would like to advise Marotzke: Try just once to apply the ocean cycles, like your colleagues in England are doing. Natural variability not only contains ‘noise’, but also quasi cyclic behavior that today are empirically well-known. However the sad truth is that climate models are unable to properly represent these known cycles. The problem is not with nature, rather it is in fact in the models. Also the weighting of the individual climate drivers is poorly understood. The IPCC table of radiative forcings for solar fluctuations has assigned a much too low value, one in fact that has absolutely nothing to do with the geological-empirically determined systematic impacts of the sun.
We suspect that Marotzke has painted himself into a corner and so has to continuously find excuses and ignore the ocean cycles that have been at play over the last 20 years, though many have long been aware of them (see our article: IPCC–cofounder Bert Bolin had all along been aware of the climatic role of ocean cycles).
Marotzke refuses to acknowledge low climate sensitivity
In the second part of the article the Max-Planck scientists discussed various possibilities as to why a warming pause happened. It was considered that the CO2 climate sensitivity may have been set much too high:
One possibility would be that the climate change drive in the models has been falsely assigned – i.e. the amount of radiative energy connected with a rise in atmospheric CO2 that gets trapped in the climate system or that gets reflected back out into space from aerosols. The values that the various models calculate for this magnitude vary widely. Another possibility is that the models over-estimate how sensitive the climate reacts to a rise in CO2. Some models assume that the global mean temperature will rise only 2°C from a doubling of CO2. Others assume that it will be more than 4.5°C warmer.”
But then a few lines later Marotzke and Co. abandon the possibility and return to their wild chaos theory. The MiKlip recognition of a cooling North Atlantic gets no mention at all. Instead the article concludes with a prognosis that anyone could have conjured up without millions in research money. Eventually someday the stupid temperature plateau will end. But as to when, no one really knows. An embarrassing conclusion. In the MPF magazine we read:

The temperature plateau is going to end sometime in the years ahead, as most scientists are convinced of this. It is likely that the warming of the earth’s surface will then progress even more quickly. At the latest when the trade winds blow over the Pacific more weakly the pause will be over.”

Other research groups here are clearer and more solid on this because they have a better grip on the unpopular ocean cycles than than the scientists in Hamburg do:

BBC: Global warming slowdown ‘could last another decade’
New paper in the Geophysical Research Letters: Ocean cycles will lead to a light cooling for the northern hemisphere over the coming 15 years.
Judith Curry projects warming pause to continue until the 2030s: Hans von Storch requests a vote of no confidence in such a case for C02
Japanese scientist postulates cooling beginning in 2015 and aging weather stations showing warm readings

Share this...FacebookTwitter "
"Five years ago, a magnitude 9.0 earthquake occurred 200km off the east coast of Japan, causing a devastating tsunami. The resulting waves affected 2,000km of coastline, killed some 18,000 people, destroyed nearly 110,000 buildings and damaged twice that number. It also triggered the meltdown at the Fukushima Daiichi nuclear power plant, which released toxic levels of radiation into the environment and remained the focus of worldwide concern for a long time afterwards. As we reflect on the terrible destruction of lives and livelihoods wrought by this natural disaster, one question springs to mind: how can we better protect ourselves from the next one?  After all, this was not the first such disaster to hit Japan. For example, the 1896 and 1933 Sanriku earthquakes – which reached magnitudes of 8.5 and 8.4 respectively – also caused deadly tsunamis. For that reason, Japan had already introduced a number of defences prior to 2011. Tsunami barriers were constructed both on and offshore, trees were planted along the coastline, vertical evacuation buildings were built to the highest standards and regular evacuation training was introduced.  But the sheer force of the 2011 tsunami took many by surprise. Most of the protective measures were designed to cope with magnitude 7.4 to 8.0 earthquakes, which occur every few decades in the region. This planning failure was partly due to the limited amount of recorded data, which only spans back 40 to 50 years and contains uncertainties about the location and magnitude of previous mega-earthquakes.  To improve warning systems and build effective defences, we need a detailed understanding of how the tsunami gathers height as it nears the shoreline, and how this affects the damage caused. As soon as the major search and rescue operation was completed, the Tohoku Earthquake Tsunami Joint Survey Group – made up of natural scientists and engineers from 63 universities – set out to gather this information.  The group’s measurements confirmed that when the first wave hit the coast, it was largest at the point nearest to the earthquake’s epicentre, as expected. But the shape and height of the coastline and seabed affected how far the tsunami spread inland, and to what depth. For instance, the low-lying southern part of the Tohoku coast experienced the worst flooding, with sea water reaching more than 5km inland.  By contrast, on the more northerly Sanriku coast the tsunami’s energy was concentrated into deep bays where water levels rose as high as 40m, damaging human settlements on mountain sides rather than ranging far inland. The effectiveness of defences varied along the coastline too. Tsunami barriers worked in some places but not in others. Breakwaters and seawalls, which were built to protect from storm surges and ocean waves, were completely or partially destroyed depending on where they were. The tsunami also overran coastal dikes and river embankments.  Many structures could not withstand the force of the tsunamis, or the damage caused by drifting vessels and wood debris. The ground liquefied and scour holes developed near foundations, causing the collapse of many buildings. Roughly two-thirds of the protective coastal forests were lost.  The post-tsunami survey and later research gathered detailed data about the causes and extent of the damage. This information can be used to reduce uncertainties when it comes to forecasting future events of this size. Thanks to this research, we now know more about the probability of similar earthquakes, have improved numerical models and can make better predictions about building failures. All of this will enhance the design and construction standards in Japan, and other countries that are prone to tsunamis. Before the end of 2011, the Japanese parliament had passed laws to establish “tsunami-safe cities”. This involved enhancing research and education, evacuation training and measures to prevent or mitigate the effect of tsunamis in the long term. The government also committed 25.5 trillion yen (£158bn) toward an intense, five-year period of rebuilding.   Next, the Reconstruction Design Council presented a plan to rebuild along Tohoku’s coast, based on new tsunami risk simulations and studies. The proposed protection was divided into two levels, which correspond to two classes of tsunamis, based on their magnitude and frequency. Level one (L1) are “smaller”, low-impact tsunamis that occur once every 10 to 100 years. Level two (L2) are rare, high-impact tsunamis which only happen once in several hundred to 1,000 years.  Structural measures such as seawalls, embankments and tree plantations will be designed and built to defend people and properties against L1 tsunamis. Soft measures such as land use zoning and evacuation plans will be implemented to protect human lives against L2 tsunamis.  Putting these improvements into practice has taken longer than expected. The main focus is still on rehousing those whose homes were destroyed. At last count, almost 59,000 of the 470,000 people originally displaced are still living in temporary accommodation.  In many locations, the ground level of sites for new houses must be raised before construction can begin. For example, in the port town of Rikuzentakata, the ground level was raised by about 10m, and two protective seawalls of 3m and 12.5m high are being built. Elsewhere, private houses will be relocated to higher ground, areas behind protective structures will be elevated and forests planted. The Miyagi prefecture proposes to refortify the coast with a tall seawall several kilometres long for tsunami protection.  All of these measures take time, and many have divided opinion: some inhabitants do not want to move from the coastal strip, but neither do they want their view infringed by a tall wall.  Although the scientific research carried out after the 2011 tsunami will help to protect Japan from future disasters, there will always be shades of uncertainty. After all, it is unlikely that every possible combination of events has been predicted and accounted for. That’s why it is crucial to continue monitoring for early warning signs, evaluating predictive models and building physical defences. Perhaps most importantly, we need to raise awareness of the risks of coastal living, and ensure that people are prepared to move quickly when the need arises."
"
Share this...FacebookTwitterUpdate: To the sheep of David Appell: https://notrickszone.com/2015/06/09/disastrous-scientific-consensus-finally-crumbles-after-60-years-of-deadly-failure/comment-page-1/#comment-1029797
====================================
Science has a way of calling itself the art of enlightenment, yet historically it has a nasty habit of taking us deep into dark dead-ends. Human history is filled with examples.
Whenever new theories get prematurely accepted as hard fact, policies usually follow and mislead society into new and ultimately disastrous directions. Dissidents are cast into academic exile. Eventually society gets led deep into a dark dead-end, light-years from the truth. Society wakes up and mends its ways only when real science is allowed to function once again.
So it was with the lipid theory, where cholesterol from high fat diets was claimed to be a major killer. Today, after 6 decades, it is turning out to be strikingly false.
That lipid theory was propelled in the 1950s by Dr. Ancel Keyes and his infamous, phony 7-country chart, which purported to show a direct link between heart disease and fat intake. Six decades long western societies were led to adopting the low-fat high carb diet for healthy living as a result. Today, after tens of millions having died horrible deaths from diabetes, heart disease and cancer, the science is only now finally beginning to admit it had gravely erred. The consensus science had been wrong.
Must read
Disclose.tv here has an article by Dr. Dwight Lundell, a veteran heart surgeon, who tells why it was wrong, and the horrendous consequences.
… we opinion makers insisted heart disease resulted from the simple fact of elevated blood cholesterol.
The only accepted therapy was prescribing medications to lower cholesterol and a diet that severely restricted fat intake. The latter of course we insisted would lower cholesterol and heart disease. Deviations from these recommendations were considered heresy and could quite possibly result in malpractice.”
The result he writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Despite the fact that 25% of the population takes expensive statin medications and despite the fact we have reduced the fat content of our diets, more Americans will die this year of heart disease than ever before.” […]
The long-established dietary recommendations have created epidemics of obesity and diabetes, the consequences of which dwarf any historical plague in terms of mortality, human suffering and dire economic consequences.”
Imagine that it took 6 decades to figure that out.
The same will be true when it comes to the CO2 and climate theory. The parallels are stunning. Like the lipid theory, the climate-CO2 theory is also based on an absurd hockey stick chart fabricated by a less-than-honest activist scientist. It’s going to take a few more decades, and probably here too tens of millions of premature deaths as well.
Consensus is the brake failure of science
It wasn’t until early last year that I rejected the old consensus on cholesterol and health and switched to a high-fat, low carb diet that includes lots of meats, eggs, Kerrygold butter and vegetables. Since then I’ve lost 20 lbs, my blood pressure has returned to normal, and my blood values are normal. I haven’t felt better in at least 20 years. This is what results from rejecting “consensus” science.
The lesson here? Consensus is the brake failure of science. When it happens we can only hope it doesn’t take us over a cliff. This is precisely what is happening today in climate science.
The 97% should have been ignored
Concerning heart disease, if earlier patients had ignored 97% of the doctors and followed the advice of the other 3%, many would still be alive and even healthy today.
Reading Dr. Lundell’s admission at the above link may change your life and make it immensely better.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s online business news magazine WirtschaftsWoche (business week) here has an interview with Professor Gonde Dittmer (right), who claims Germany’s transition to renewable energies so far has been a grand failure. The title of the WirtschftsWoche piece:
“Doubts over the government’s climate policy. The true aim of the Energiewende is not environmental protection.”
An illusion…not a single kilogram CO2 saved
Dittmer, a professor of mathematics and electrical engineering, tells WirtschaftsWoche that all the solar and wind energy installed so far has not saved a single kilogram of CO2 and that these renewable energies are not green at all.
He also calls the claim that 25% of Germany’s electricity is renewable “an illusion”. He tells WirtschaftsWoche that a wind turbine first needs to run 4 years before it compensates the energy that was needed to produce the system in first place. Dittmer says that instead of saving energy, solar and wind power have had the opposite effect: “To the contrary the result is increased CO2 emissions.”
Huge tab for the public
Dittmer also thinks that replacing older wind turbines with more efficient new turbines (repowering) is a gimmick that will make little difference. He blasts the renewable energy industry as a money-maker for a select few at the expense of the general public:
The true aim of the Energiewende is not the reduction of CO2 emissions – rather economic profit. […] It’s all about a redistribution from the bottom to the top.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Naivety, ignorance, ideology, illusions…”
Dittmer reminds us that when the subsidies run out and the costs mount, the consumers will be forced to pick up a massive tab, and that they have actually been duped to gladly do so.
The losers are, in addition to the climate, as you have correctly said, are private households who finance this system with compulsory levies. […] The Energiewende policy so far is based on naivety, ignorance, ideology, illusions and false incentives.”
Absurd
Dittmer, a retired professor, also calls the notion of setting up some windmills and solar panels and thinking that this will do the trick “absurd”. He tells WirtschaftWoche: “We don’t have the space for this, we don’t have the money and we don’t have the technology.”
In his view the solution to the “problem” is to drastically reduce energy consumption. He asks if it’s really necessary to heat every room in the house and to fly on holidays.
He also believes that the electric cars will be a folly because much of the energy gets wasted and that they would only further burden the current supply system.
Photo credit: www.gonde-dittmer.de/
Share this...FacebookTwitter "
"The world may already have crossed a series of climate tipping points, according to a stark warning from scientists. This risk is “an existential threat to civilisation”, they say, meaning “we are in a state of planetary emergency”. Tipping points are reached when particular impacts of global heating become unstoppable, such as the runaway loss of ice sheets or forests. In the past, extreme heating of 5C was thought necessary to pass tipping points, but the latest evidence suggests this could happen between 1C and 2C. The planet has already heated by 1C and the temperature is certain to rise further, due to past emissions and because greenhouse gas levels are still rising. The scientists further warn that one tipping point, such as the release of methane from thawing permafrost, may fuel others, leading to a cascade. The researchers, writing in a commentary article in the journal Nature, acknowledge that the complex science of tipping points means great uncertainty remains. But they say the potential damage from the tipping points is so big and the time to act so short, that “to err on the side of danger is not a responsible option”. They call for urgent international action. “A saving grace is that the rate at which damage accumulates from tipping could still be under our control to some extent,” they write. “The stability and resilience of our planet is in peril. International action – not just words – must reflect this.” Prof Tim Lenton at the University of Exeter, the lead author of the article, said: “We might already have crossed the threshold for a cascade of interrelated tipping points. The simple version is the schoolkids [striking for climate action] are right: we are seeing potentially irreversible changes in the climate system under way, or very close.” “As a scientist, I just want to tell it how it is,” he said. “It is not trying to be alarmist, but trying to treat the whole climate change problem as a risk management problem. It is what I consider the common sense way.” Phil Williamson at the University of East Anglia, who did not contribute to the article, said: “The prognosis by Tim Lenton and colleagues is, unfortunately, fully plausible: that we might have already lost control of the Earth’s climate.” The new article comes as the UN warns action is very far from stopping global temperature rise, with the world currently on track for 3C-4C. The commentary lists nine tipping points that may have been activated. “We have this alarming evidence that part of the west Antarctic ice sheet may be in irreversible retreat,” said Lenton. “All the signals are that it is.” A similar situation appears to be occurring at the Wilkes basin in east Antarctica. The collapse of these ice sheets would eventually raise sea level by many metres. The massive Greenland ice sheet was melting at an accelerating rate, the scientists said, while Arctic sea ice is shrinking fast. “Permafrost across the Arctic is beginning to irreversibly thaw and release carbon dioxide and methane,” they said. The Gulf Stream current in the Atlantic, which warms Europe, has also slowed by 15% since the mid-20th century. “That is just about in the range of natural variability, but it is also hard to rule out that it is part of a longer downturn,” Lenton said. The scientists report that 17% of the Amazon rainforest has been lost since 1970. The tipping point, where loss of forest leads to it drying out, could lie in the range 20%-40%, they said. In temperate forests, especially in North America, heating has triggered more fires and pest outbreaks, potentially turning some regions from a sink for carbon to a source. In the tropics, corals are predicted to be wiped out by 2C of heating. A cascade of tipping points could occur because, for example, the melting of Arctic sea ice amplifies heating by exposing dark ocean that absorbs more sunlight. That may increase the melting of Greenland ice and permafrost areas. “Multiple risks can interact, with one change reinforcing another, and with warming of just a degree or two sufficient to result in dramatic cascading effects,” said Williamson. Prof Martin Siegert, at Imperial College London, said: “The new work is valuable. They are being a little speculative, but maybe you need to be.” He pointed out that the extremely rapid rate at which CO2 was being pumped into the atmosphere was unlikely to have ever occurred on Earth before. “It may mean that tipping points can occur in unexpected ways as there is no geological precedent for this rate of CO2 change.” The article reports that preliminary results from the latest climate models suggest global heating will be greater than expected, increasing the risk of tipping points. Prof Piers Forster, at the University of Leeds, disagreed on that point. However, he added: “I completely endorse their call for action. Although possibly low probability, the risks they identify are real.” Lenton said action would still have real benefits, by slowing the impacts and giving more time for people to adapt. He said: “This article is not meant to be a counsel of despair. If we want to avoid the worst of these bad climate tipping points, we need to activate some positive social and economic tipping points [such as renewable energy] towards what should ultimately be a happier, flourishing, sustainable future for the generations to come.”"
"Eighty this year, Judy Chicago’s hair is white and violet, and she’s wearing lipstick so plum-dark it registers as black. It’s a strident image that suggests she’s a fighter, which she is: funny and forthright, she has dedicated a career to courageous exploration of difficult subjects, from catastrophic injury to mental illness. Some things, though, can’t be fought: extreme weather has left her grounded in New Mexico, thousands of miles from Gateshead where a survey of half a century of her work opened earlier this month. I end up talking to her on a video call. This intervention of natural forces is grimly apposite. Chicago’s show at the Baltic focuses on extinction narratives and human responsibilities to the planet. She has spent the past three years contemplating mortality. The series The End: A Meditation on Death and Extinction turns from Chicago’s feelings about her own death to grief over what we are doing to our environment. “There’s not a lot we can do about the fact that we’re going to die, is there?” she says. “We can’t do anything about our own mortality, but we can definitely do something about what we’re doing to the other creatures on the planet, and [to] the Earth.” She really takes us through the fury, grief and terror surrounding ageing and death. From the tragicomic experience of seeing your mother’s body reflected back at you in the mirror, to the horror of dying hooked up to banks of machines in a hospital. She comes at death from many angles: philosophical, psychological and emotional. “Far more difficult than the mortality images were the extinction images,” she says. “That was really gruelling.” Paintings in the series show tropical frogs and arctic fauna facing habitat loss; elephants and sharks mutilated by hunters; scenes of deforestation and animal illness. “Intensive research about it really brought me face-to-face with a level of horror that I had not previously comprehended.” Death has long made its presence felt in Chicago’s life. Born Judith Cohen in Chicago in 1939, she married in 1961, while still a student in Los Angeles. Two years later her husband Jerry Gerowitz died in a car accident, making her a widow at 23. She started her career as an artist by injecting rainbow colour into the sombre arena of minimalist art. She learnt to wield a spray gun and painted crisply graphic symbols suggesting sex, fertility and birth on to the hoods of cars. The art world of LA at the time was so macho that Ken Price, Billy Al Bengston and Larry Bell – the surfing, biking, cigar-chomping stars of the scene – were known as “the studs”. “The most prominent curator in southern California refused to look at my work because, as he said, he couldn’t deal with ‘the fact that I was a woman and an artist, too,’” says Chicago. “I mean, it was just terrible.” In order to get seen in LA she “absolutely had to disguise my gender in my work”. Yet, instead of hiding, she decided to be true to herself. “That meant confronting the fact that even though art has no gender, the art world seemed unable to accept me because of my gender.” In 1970, an advert appeared in the pages of Artforum showing the artist leaning nonchalantly against the ropes of a boxing ring with the name “Judy Chicago” emblazoned on her sweatshirt like a prizefighter. The text read: “Judy Gerowitz hereby divests herself of all names imposed upon her through male social dominance and freely chooses her own name: Judy Chicago.” And thus she was reborn: Judy from Chicago, like Leonardo, the guy from Vinci. She moved to Fresno and founded a feminist art programme at California State University. Instead of concealing her gender, she was going to change the status quo, one battle at a time. And it was a battle. In 1975, Anaïs Nin encouraged her to write about her experience in Through the Flower: My Struggle As a Woman Artist. Rereading it today, she says, is painful: “There are very vivid descriptions of the difference between how I felt in my studio as an empowered individual, and how I would feel when I left my studio, and was viewed entirely through the lens of gender.” The fight was not simply for women artists to be seen, but to lay foundations for a new kind of art making that stepped away from ideas of the lone male genius and his proprietorial dominance over the natural world. “I remember having a huge fight with Richard Serra in the mid 1960s when he did a show at the Pasadena Museum,” she says. “He had a bunch of redwood trees chopped down, and piled them up in the museum. I was horrified and I told him. The next day he pounded on my studio door, waving Artforum, and said, ‘You may hate what I do, but they like it.’ I didn’t care. I was horrified by that imposition on the landscape, that arrogance.” At the time, Chicago was also making art out in the landscape, but she worked only with coloured smoke and bodies: materials that had minimal impact on the environment and left little trace. She always wants materials to sit lightly. That’s why she prefers spray painting: “I never liked oil paint, I never liked imposing paint on the surface.” In the mid 70s Chicago started the work with which her name is now synonymous. The Dinner Party is a vast triangular table with place settings in lushly glazed ceramics and embroidered cloth for 39 eminent historic figures, all of them women. The triangular base of the installation carries 999 further names glazed into ceramic floor tiles, the entryway is lined in tapestries, and historic information is displayed around the space on panels. More than just a historic rebalancing, it is an unabashedly erotic work: labial, drippy, carnal. Five thousand people attended the opening of The Dinner Party in San Francisco in 1979. It caused a sensation, but also uproar. The show was closed, and its exhibition tour collapsed. Yet the popular momentum accompanying the work was strong enough that a grassroots movement grew to tour it around the US and beyond. The Dinner Party is now permanently installed at the Brooklyn Museum. It has become a canonical work, not just of feminist, but of 20th-century, art. At the time it nearly destroyed Chicago’s career. She says she lost everything: her studio, her marriage, and her financial security. It is grotesque that The Dinner Party still feels so relevant 40 years later: that the same debates are raging about birth control, abortion and representation. “I think it’s incredibly sad that, at this point in America, young women are going to have to fight the same goddamn fight we fought in the 1970s all over again,” says Chicago. She quotes the historian Gerda Lerner – “Women live in a state of trained ignorance” – and says there’s a lack of awareness of the battles women have fought or the lessons they’ve taught. “As a result, we are still in the same cycle of repetition that I thought, in the naivety of youth, I was going to overcome by doing The Dinner Party with my own paintbrush.” Chicago pulled back from showing much of it at Baltic: “Much as I appreciate all the attention The Dinner Party brought me, for many decades it blocked out the rest of my production.” But there is plenty of other work to look at, for Chicago is prolific: about 8,000 works are logged in her studio database, everything from bronze sculpture to paintings on glass. There are grand series exploring big themes such as childbirth and the Holocaust. And there are more intimate works, such as Autobiography of a Year (1993-94), charting her day-to-day mental state, or Kitty City, an “investigation of inter-species relationships”, set in her home and starring herself, her husband Donald and their cats. She’s started to think about the art market and the value of her work, something she claims never crossed her mind until she got her first mortgage aged 60. “Now I’m 80, and, you know, in America it’s no fun to be old and poor,” she says. “So now I think I’d like to make some money, but other than that I never thought about it.” • Judy Chicago is at Baltic, Gateshead, until 19 April."
"What would you like to study next year? The Bengal tiger, or the African water rat? It is an important question, for rarely, it seems, is there an impetus to study species that are highly successful, numerous or considered “ordinary”. This continued momentum towards the weird, wonderful and endangered can frequently be driven by the fact that endangered and exotic species attract funding, high journal impact and equally importantly, publicity. “Ordinary”, “less cute” species do not. From the perspective of species conservation and biodiversity, there has been much discussion about the prevalence of prioritising large, highly-visible and aesthetically pleasing species over smaller, more everyday animals. Habitat conservation typically does benefit all species which live within a preserved area, and so flagship animals, which are often used to front campaigns and high-profile research projects, do help support other species by attracting public support – and money – to the cause. But scientists must be careful not to overlook our planet’s other, less “glamorous” creatures. They are vital to our understanding of biology. With finite time, money and resources, preference currently is given to those species in critical danger of persecution or immediate need of protection: pandas, tigers, rhinos. But the impact of this on our knowledge of animal biology – their physiology, energetics, ecology and behaviour – is not yet fully understood. A scientific study on the physiology of the African elephant (Loxodonta Africana), for example, is unlikely to inform greatly on that of the African water rat (Dasymys incomtus) despite the fact that they frequently share the same habitat.  Indeed, there is a chance that our focus on these exotic and endangered species is biasing our knowledge of animal biology. A recent review revealed that 42% of studies published in the selected journals focused on species listed as threatened. Conversely, only 4% involved research into those categorised as non-threatened.  This means that we tend to study those animals that are struggling to adapt and modify under the pressures of human activity worldwide. And as a consequence, we spend less time discovering how more common and “successful” species are seemingly able to adapt and change to these pressures, and the mechanisms, characteristics and traits that enable them to do so.  Phenotypic plasticity, the ability of an organism to change its observable traits in response to changes in the environment, has received much deserved attention in recent years, particularly in birds. It has been suggested that these species may well cope better with climate and habitat change. Early studies on phenotypic plasticity have, as perhaps a logical starting point, focused on nature’s extremists and athletes, in line with the fascination for studying exotic and endangered species.  Examples include long distance migratory shore birds, such as godwits, groups of which can migrate up to 11,000km over the open ocean without stopping. That these species are able to undertake such extensive and impressive migrations suggests a natural predisposition for plasticity of the body’s organs throughout the annual cycle, enabling them to cope with such energetically challenging and demanding events. Indeed, these species show much propensity for change in their digestive organs, muscles and fat stores.  Other species have shown very rapid changes in their migratory habits and routes. Classic examples, which have attracted considerable attention, are blackcaps  (Sylvia atricapilla) and chiffchaffs (Phylloscopus collybita) – both passerine birds which have, over the last 50 years, gradually begun moving from central Europe to overwinter in the UK, halting their migration post-breeding to sub-Saharan Africa, some 7,000km away. Why these unusual species would show this trait while other similarly-sized, closely-related birds with similar diets don’t is not fully understood. More work is needed on less “extraordinary” birds. Currently, the extent of this flexibility and what initiates such changes is unclear. Of course plasticity can only go so far in response to change. For example, metabolic rate cannot increase or decrease indefinitely, and at some juncture, anatomical factors will impose a limit on what degree of change is possible. This plasticity, however, has not been tested extensively in what one might consider a more “typical” or “ordinary” species, and particularly not in their natural environment. It is possible that these “normal” species are capable of demonstrating equally admirable plasticity in their characteristics, but the environmental scenario which requires its exhibition has not yet arisen. Evolutionary ecologist Massimo Pigliucci has suggested a potential reason why there are few studies on this: “This field often relies on studies that are low-tech and tedious to carry out, and yet demanding high personnel costs and long periods of time, a combination that is sometimes difficult to justify to funding agencies when compared with more ‘high-tech’ science.” Understanding the potential and capacity for change in particular species is vital for predicting the responses of different species to anticipated changes in the climate and general landscape.  A firm basis for understanding the capacity of a species to change can only come from a sound platform of good general knowledge of animal biology, in particular from those species which are numerous, prosperous, and operate successfully within a changing environment. Of course, important and vital research must continue into endangered species, but a longer and larger-scale outlook is critical if we are to recognise fully the extent of change that may take place in response to shifts in the climate. “Ordinary” should no longer be a dirty word when it comes to what is recognised and endorsed by funders and researchers."
"When you think about things that are quintessentially British, you probably would not immediately put “flying” into that category – but you should. We Brits don’t just like flying, we love it. Data from the International Air Transport Association (IATA) shows that more Britons flew abroad last year than any other nationality. Roughly one in every dozen air passengers was British. Britons took to the skies 126.2m times in 2018, beating Americans and Chinese people into second and third place. Needless to say, this comes at an environmental price.  The UK aviation industry pumped 37m tonnes of carbon dioxide (CO2) into the atmosphere last year alone. That’s about 4% of the 918m tonnes that the global aviation industry emitted in 2018. And it’s an upward trend. The aviation industry is currently growing at between 4% and 5% a year, at which rate passenger numbers will double every 15-20 years. “UK CO2 emissions from aviation have doubled over the last 20-25 years and are predicted to grow into the future,” says Tim Johnson, the director of the Aviation Environment Federation, an environmental campaigning organisation that represents communities who are affected by noise and emissions, primarily around UK airports. The problem this creates for the aviation industry is acute, especially since in June 2019, the UK government signed into law a commitment to make the UK a “net zero” greenhouse gas emitter by 2050. By “net zero” this means that any greenhouse gases that are still used will have to be offset in some way. Schemes include buying and preserving parts of the world’s rainforests or planting new trees somewhere in the world, or more radical technology to literally pull the CO2 out of the air. Currently, aviation is responsible for about 2.5% of the world’s CO2 emissions. That may seem a small percentage, but this share of the total could increase significantly with the expected growth of air travel and the drive to greener operations in other industries. Accordingly the industry is looking to technology and engineering to help make aircraft more environmentally friendly. At the forefront of this is the electric engine. Electric engines for aircraft come in two forms. Rather like their motor car equivalents, there are hybrid electric engines, which would still burn fuel but can switch to battery power when appropriate, and there are fully electric engines that derive all their power from batteries. To Rob Watson, director of Rolls-Royce Electrical, the move to electric engines is a revolution that will usher in not just a more sustainable industry but a whole new era of flight. “A third era in aerospace is emerging around us now, and it is enabled by electrification,” he says. “From our perspective, it’s a really exciting opportunity for us to help pioneer this third era.” According to Watson, these eras of flight are driven by the available engine technology. First, it was piston engines to drive propellers, then it was jet engines, and now the electric engine promises to bring savings in both operating costs and environmental impact. “We are determined to play the part that you would expect from a company with Rolls-Royce’s engineering pedigree,” says Watson. To that end, Rolls-Royce has partnered with Airbus and Siemens to develop the E-Fan X, the latest in a series of hybrid electric demonstration aircraft. Following the successful flight of the E-Fan, a two-seater fully electric aeroplane that flew across the English Channel in 2015, the E-Fan X project received a large share of the £255m that the government committed to investment in the field last year, and is on course to begin test flights in 2021. This time instead of a fully electric personal plane, the company is adapting a small commuter aircraft based on the BAE 146 design into a hybrid electric. One of the aircraft’s four engines will be replaced with an electric engine running off batteries. “It is going to be the highest power hybrid electric aircraft that we have flown,” says Glenn Llewellyn, VP of zero emissions technology at Airbus. Following this, Llewellyn imagines one more test plane to demonstrate full electrification of all the engines, and then the plane can enter service. “Our target for the early 2030s is to have zero CO2 emission aircraft. This means completely eliminating CO2 per passenger,” says Llewellyn. To do this, he explains that the electricity stored in the batteries will come from renewable means such as solar panels and wind turbines. If all goes to plan, the first all-electric flights are likely to be small, island-hopping journeys, progressing to domestic and then short-haul flights. But unless there is a major breakthrough in the amount of charge a battery can hold, the batteries will simply be too heavy and take up too much space to be practical for long-haul flight. The bottom line is clear: however you approach the problem, long-haul flights will have to use traditional fuel-burning engines. But that doesn’t mean they will need to use the traditional fossil fuel, kerosine. Airlines are developing and testing Safs – sustainable aviation fuels. When the industry began investigating these a number of years ago, it was first thought that they would be biofuels, extracted from crops or plants, such as palm oil. However, the temptation of local farmers to cut down tropical rainforest to plant palm trees to sell to the fuel companies has seen airlines withdraw pretty quickly from that route. Instead British Airways and a number of others are turning to something that we make far too much of every day: rubbish. The fuel produced by chemically processing this rubbish is an artificial kerosine. Present rules allow it to be mixed in a 50/50 ratio with fossil kerosine. This is unlikely to change because the fossil kerosine contains naturally occurring chemicals that cause the rubber seals on a jet engine to swell, making them tight. Engine manufacturers rely on this process to make the engines Safe. Artificial kerosine does not contain these special molecules in anything like the same quantity and so cannot be used exclusively in current engines. Even if they could, Tim Johnson is sceptical that Safs would make a real difference. Last year, 7m litres were used on flights. “That sounds like a reasonable amount by volume but it’s enough to power the global aviation industry for 10 minutes,” he says, “so in terms of scaling up Safs, we’re a long way from making that a reality.” Added to this, they are twice the price of ordinary kerosine – a cost airlines may have to pass on to their passengers. There are other things that airlines and aircraft designers may be able to do to increase carbon efficiency. More effective air traffic control could prevent aircraft having to take detours to avoid congested skyways. Better wing design could reduce the drag of aircraft. Better carbon fibre manufacturing techniques could result in lighter airframes. And airlines could always squeeze more seats in. All of these together can offer small percentage-level improvements that will contribute towards reaching the 2050 target. It remains a big challenge, however, with a lot of risk. A delay in any one of the proposed technologies coming online, such as the electric engines or the sustainable aviation fuels, could torpedo any hope of hitting the net zero carbon emissions the law requires by 2050. If it becomes clear during the next decade that the target is unreachable on the current trajectory, some real pain may have to be endured by the industry and the people who use it. At the heart of the predicament is the fact that the airlines operate on very small profit margins, making their money through volume. This means that the growth of the industry is essential, yet this very growth is the chief obstacle in halting the environmental impact. At present, technological innovation is delivering a 1% per annum saving in carbon efficiency, but this is completely outstripped by the industry growing at 4-5% a year. Unfortunately, says Johnson, carbon offsetting schemes are little more than a temporary fix. Those schemes rely on some form of preserving or planting trees, but as the 2050 deadline approaches, all the countries we traditionally use for carbon offsetting, such as India, China and others in South America, are going to need those hectares to offset their own rising carbon emissions. “This is the fundamental obstacle to us reaching our environmental objective,” says Johnson. “If this industry were static in terms of people flying, all the improvements we’ve discussed would be improving the industry on an annual basis.” But they’re not. And that means only one thing according to Johnson: restricting the demand for air travel. It’s a conversation that an increasing number of people may already be having with themselves. The Swedish concept of flygskam or “flight shame” entered the lexicon this year. The Swiss bank UBS surveyed 6,000 people in the US, Germany, France and the UK and found that 21% of respondents said they had cut the number of flights they took during the last 12 months. A 2014 survey of 1,000 UK residents revealed that just 15% of Britons were responsible for 70% of flights and this led to calls for a frequent flyer tax. Some sort of carbon pricing scheme has also been suggested by the Energy Transitions Commission (ETC), an international organisation dedicated to roadmapping ways to a low carbon future. Under such schemes, carbon could be priced at up to £200 per tonne, and a proportionate contribution added to each plane ticket. Even if passengers in the west do think more carefully about flying, and the price of tickets goes up to deter them further, the decrease in passenger numbers will probably be outstripped by rising demand in developing economies such as India and China. That means globally the number of us flying will still rise, and that means to achieve net zero by 2050, airlines may have to expand into the carbon capture market, developing commercial technology to pull CO2 out of the atmosphere. Such technologies do exist but they are small-scale devices used to keep the air breathable on submarines and spacecraft. To scale these up to something capable of making a global impact will require serious investment in green startup companies and probably government incentives. To delay the investment in this technology almost certainly means having to abandon net zero carbon emissions by 2050, or the introduction of draconian measures to limit air travel in the coming decade, no matter what economic damage that does to the aviation industry. When it comes to aviation and the environment, one thing is certain, says Johnson. “We are going to have to have difficult conversations about how we hit our net zero targets.” "
"
Share this...FacebookTwitterThe year started out on the mild side in Central Europe, but since early May temperatures have been stubbornly on the low side.
“Rarity”: 5 consecutive June days of surface frost
Over northern Germany, for example, the last 10 or so days have been gripped by cold weather. The online Sudkürier here cites meteorologist Dominik Jung, writing how last week there was “a very unusual phenomenon: five days in a row in North Germany there was surface frost. That according to Jung is a rarity for June.”
Ground surface frost is already rare enough over the northern German lowlands in May, let alone June!
In Germany farmers and weather hobbyists often talk of these annual June cold spells, calling them Schafskälte – or “sheep cold”. They often occur in mid June when cold polar air grips the country.
“Record suspect low”
But this year the phenomenon appears to be especially pronounced.

German meteorologist Dominik Jung explains what’s behind this year’s “very unusual” June cold spell. Image cropped from: https://www.youtube.com/


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Not only last week was cold, but so is this week. In today’s wetter.net  forecast video, Jung tells viewers how this morning: “…around Hamburg ground-surface temperatures fell to -3°C. Yes, for this time of the year this is a record-suspect low.”
In the video the commercial meteorologist also says that after today’s milder temperatures the “grizzly summer weather” shows no signs of letting up. Daytime temperatures are forecast to stubbornly remain stuck in the 50s and 60s (14 – 20°C) over the rest of the week.
“Numerous days with ground level frost”
The online sachsen-fernsehen (Saxony television) writes that not only was the Hamburg region hit, but the cold was widespread across northern Germany:
“In Lübeck and Hannover, just above the ground readings of down to -2°C were taken. Even in Berlin early this morning the thermometer showed ground level frost with readings around 0°C. 
Precisely at Germany’s number 1 beaches, the North and Baltic seas, June has been quite fresh so far. The month’s half in the north has been about 1°C colder than the longterm mean. And with the numerous days with ground level frost that June has seen so far, it’s hardly a wonder.”
Drought also taking hold…
Moreover, large parts of northern Germany are being gripped by a deepening drought. Here as well no significant amounts of rainfall are in sight.
The latest buzz is that Germans should not be expecting any type of “barbecue summer” this year.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhat follows is something that should make anyone who makes dramatic predictions that ends up being totally wrong blush with embarrassment, and feel like a real fool.
===============================
By Sebastian Lüning and Fritz Vahrenholt, Die kalte Sonne
[Translated by P Gosselin]
In 2008 US broadcaster ABC News had a show on the climate danger. The most important news at the time: Already in just seven years, 2015, the climate will have gone crazy and climate catastrophes would be piling up.
All wrong, as we now know today.
This debacle aside, also today such clips continue to be produced. And when the predicted year arrives, everyone will have forgotten the crazy stories and predictions.

=============================
Milk $13 a gallon?
 Gas $9 a gallon?
 How much longer are we going to listen to these nuts?
Also watch the following:

And yet another spectacular fail here.
Share this...FacebookTwitter "
"Australia has suffered a devastating early bushfire season with fires across several states burning through hundreds of thousands of hectares and destroying hundreds of properties with the loss of six lives. New South Wales has been the most severely hit, with more than 1.65m hectares razed, an area significantly larger than suburban Sydney. All six deaths occurred in there and more than 600 homes were destroyed. At one point firefighters were battling a fire front about 6,000km long, equivalent to a return trip between Sydney and Perth. In Queensland, 20 homes have been lost and about 180,000ha burned. In Victoria, where the bushfire season usually starts later, 100km/h winds fanned more than 60 blazes during an unprecedented heatwave on Thursday. The most extreme warning, a code red, was issued for the north-western and central regions. The state’s emergency services minister, Lisa Neville, compared it to “the worst conditions you’d see in February or March”. Seven districts in South Australia were rated as being at catastrophic risk of fire on Wednesday as temperatures soared into the 40s. A blaze on the Yorke peninsula burned through about 5,000ha, damaging at least 11 properties and injuring 33 people. Western Australia has also experienced early bushfires in several regions, with fears of much worse to come over summer, and there were minor bushfires this week in Tasmania. Australia has always had devastating bushfires, a point emphasised by some columnists and newspaper editorials, but scientists say the fire conditions this year are without parallel on several fronts. Let’s start with the situation in NSW. Over the past 50 years, there have been just two calendar years in which more of the state has burned than this year: 1974 and 1984. With this year, those two were much larger than any other year, as this graph shows, based on data from the University of Wollongong’s centre for environmental risk management of bushfires: This year, which still has six weeks to run, sits fractionally behind 1984. Both are a long way behind 1974, when more than 3.5m hectares burned. But scientists says fire conditions today are fundamentally different, and fundamentally worse in many ways, when compared with some of the fires experienced in the past. The centre’s director, Ross Bradstock, says the 1974 fires burned through largely remote country mostly in the state’s far west, devouring green, non-woody herbaceous plants. The conditions were created by above average rainfall which produced ample fuel in outback grasslands. By contrast, the fires in the east of the state this year have been fuelled by a lack of rain. The extent of the fires is in significant part driven by the amount of dry fuel available, some of it in highly unlikely places, and the amount of dry fuel is linked to the record-breaking drought. Rainfall between January and August 2019 was the lowest on record in some areas, including the northern tablelands of NSW and Queensland’s southern downs. Parts of both states experienced record low soil moisture. As temperatures and wind speeds increased but humidity remained low, conditions were primed for small fires to become major conflagrations. Bradstock says it has put NSW in uncharted territory: “For the forests and woodlands in the eastern half of the state, this is unprecedented. “Natural features in the landscape which often impede fires, like these wetter forest communities, are just burning. There is likely to be long-term ecological and other environmental consequences.” The director of the fire centre at the University of Tasmania, David Bowman, says the unprecedented nature of the fires this spring can be seen through their intensity and geographical spread across the country, noting at time of writing there were fires in five states. The extent of the bushfire risk is illustrated through Bureau of Meteorology data of the cumulative forest fire danger index across winter. The map shows the overwhelming majority of the country, with a few exceptions in Victoria, central Queensland and western Tasmania, experienced between “above average” and “highest on record” fire conditions in winter when compared with the average since 1950. Bowman says the extraordinary nature of the fire season is clear on several measures: the extent of area burned, and the underlying dryness and poor air quality affecting people across the country. Smoke in NSW and Queensland has prompted a rise in people seeking emergency treatment for respiratory problems. But as illustrative evidence he emphasises the areas affected in which fire has never or rarely burned in the past, including rainforests, wet eucalypt forests, dried-out swamps and organic matter in the soil where the water table has dropped. He says one of the most striking images of the extreme fire conditions in recent weeks were those of a devastated banana plantation at Taylors Arm, west of Macksville, in northern NSW. He lists it alongside the loss of other landscapes – including Gondwana-era vegetation in the Tasmanian world heritage wilderness area that in some cases had not burned for more than 1,000 years – as evidence of change. “There’s just layer upon layer upon layer of differences,” Bowman says. “If you narrow your frame you can say ‘nothing to see’. But if you broaden your aperture, it’s clear. “I wrote a book on Australian rainforests. I’ve seen every Australian rainforest biome, and the fact that multiple versions of these ecosystems right around the country are burning all within the same couple of years … This is a really confronting warning light.” They largely back the scientists. As has been widely reported, 23 former fire and emergency services chiefs from across the country have jointly warned climate crisis is making bushfires deadlier and the season longer, and called on the government to act. Neil Bibby, former chief executive of Victoria’s Country Fire Authority and one of the 23, says: “It has been the last couple of years where we have been realising things have started to change and this is the new future … It will only get worse.” The chief executive of the Australasian Fire and Emergency Service Authorities Council, Stuart Ellis, says this bushfire season already has an “enduring nature”. “[It’s] just relentless,” he says. Andrew Gissing, an emergency management expert at the Bushfire and Natural Hazards CRC and a consultant with Risk Frontiers, says an analysis of building losses from bushfire seasons back to 1925 suggests this season is already the third worst in NSW. In Queensland, about a third of all financial losses from burned buildings since 1925 have occurred this year. No fire can be blamed on climate change alone, but Bowman says the rise in higher temperatures, extreme dryness, worsening fire seasons, extreme bursts of fire weather and behaviour and the spread of fire across the country all align with scenarios painted by climate change projections. Greenhouse gas emissions have a clear impact on rising temperatures and, through that, an indirect link on increased dryness in eastern Australia. A recent study found the extreme temperatures that drove historic 2018 bushfires in northern Queensland were four times more likely to have happened because of human-caused climate change In short, climate change can and does makes bushfires worse. Bradstock says a range of published research has found escalating atmospheric concentrations of greenhouse gases are increasing the risk of the type of fires affecting NSW’s eastern forests, but reducing the likelihood of a similar fire to that experienced in 1974. The elevated scores on the forest fire danger index in winter this year meant not only that the risk of bushfires was significantly heightened as the warmer seasons began, but opportunities for hazard reduction burning had been limited in some parts of the country – although NSW authorities still managed to meet its annual target of 135,000ha of prescribed burning. Sarah Perkins-Kirkpatrick, from the University of New South Wales’ climate change research centre, says studies by the CSIRO and others have found the fire season has got longer, particularly in eastern Australia, where it is starting earlier. This is expected to continue until 2050 at least. “We know that catastrophic conditions are now more likely to occur, and into spring as well,” she says. On this year, Bradstock says: “I guess the most concerning thing to emphasise is it’s not over. We’re not even into summer yet.”"
"One thing I remember vividly from my childhood is The Day of the Triffids. In John Wyndham’s apocalyptic novel, the triffids were carnivorous plants that didn’t need roots and had developed three legs to allow them to find prey (whose nitrogen they fed on instead). They were originally bred by humans to provide high-quality vegetable oil, since the growing population’s demand for food was outstripping supply. Initially contained on farms, the triffids escaped following an “extreme celestial event” and began to terrorise the human population.  Replace “breeding” with “genetic modification” and you have the contemporary cautionary tale about the threat of “Frankenfoods” to human health and the environment. But this raises another question – if we ignore their potential, what does it mean for human food requirements in the future? The Day of the Triffids was first published in 1951, right at the start of the “green revolution”. The latest thing was breeding new varieties of cereal which were high-yielding. Together with other newly developed technologies including machinery – tractors and irrigation pumps – and synthetic inputs like pesticides and fertilisers, this helped double major commodity crop production between 1960 and 2000 to 2 billion tonnes worldwide, rebutting Malthusian fears about the world failing to feed its growing population.  In the last decade, the rosy glow has worn off a little. Growth in world crop yields has declined and is even stagnating, perhaps due to climate change – especially stress from heat and drought. Yields are no longer increasing fast enough to keep pace with projected demand. If current trends continue, we’ll need to expand our crop land by 42% by 2050. As a consequence, forests will be lost. Along with associated costs from requiring more water, plus the effects on biodiversity, this will increase agriculture’s greenhouse-gas emissions significantly. In total, agri-food is set to emit enough greenhouse gases to surpass the entirety of the 1.5℃ temperature-rise target called for in Paris for 2050.  There are basically two options: we can increase yields to meet demand without expanding area, and/or we can reduce demand enough to allow supply to catch up. Increasing supply in a sustainable way is perfectly possible. Some of this is about increasing efficiency through better farming, such as using precision agriculture to target the right amounts of fertilisers and pesticides to the right places.  Some of it is about changing land management to get the most out of agricultural land while maintaining ecosystem services, for example by managing the edges of fields as buffer strips to prevent chemicals being washed away by heavy rains; and as places with lots of wild flowers where bees can thrive to improve crop pollination. And some of it is about developing new animal and plant varieties that are more efficient, more productive or better able to cope with the changing environment. New varieties can come about from various means. Conventional breeding continues to be important. But modern laboratories have given us more strings to our bow. Not all biotechnological approaches are genetic modification in the legal sense. Using chemicals or X-rays to create genetic variation has long been a mainstay of “conventional breeding”, for example. Other techniques – such as CRISPR – are arguably post-GM, in that they can involve the clinical editing of single genes without leaving a signature of foreign DNA. CRISPR can produce identical plants to those produced conventionally, but much faster. Yet for some people, biotechnological crop or livestock modification conjures up “triffidophobia”.  Just how wary should we be about new technologies? Conventional breeding has served us well, but can’t keep up with demand or the speed with which the weather is changing. Any change in farming practice has associated risks that need to be assessed and managed, but these also need to be weighed against the risks of doing nothing. To increase food supply to meet projected demand, farming in the same way as we do now, the emissions from deforestation and other changes will lock us into a world of 4-5℃ of climate change. Together with other significant costs to the environment and human health and well-being, that’s probably a greater risk than the alternative.  It is difficult to guess how much biotechnological approaches will contribute to the solution, though. We still need to develop precision agriculture and smarter land use. And even if the gaps between current and required yields are halved – a big ask across the world – we’ll still need more land to meet demand. This would still impact on the likes of our water supply and create enough warming to challenge the Paris targets.   This is where the second option comes in – decreasing demand. Globally, we feed livestock about a third of all the calories we grow – enough to feed all the people in Asia. About a third of the food we grow is also lost or wasted. And across the world, many people overeat enough to make themselves ill through obesity, diabetes and so on. If we made wiser purchasing and consumption decisions, potentially we could halve current global demand for food. That would create space for sustainably feeding the growing population as well as growing biofuels and carbon storage in new forests. For me, the message is clear. We are unsustainably using the planet’s resources to produce the food we demand, and there will be very negative results if we continue  on the same trajectory. New technology can help, but needs assessed as it is developed. Old technology still has a role; as does reducing waste, over-consumption and meat-heavy diets. There is no simple answer but there is a toolbox, and we’ll need every tool at our disposal to address the challenge we created. Our technology won’t produce The Day of the Triffids, but without it, we may create a future Apocalypse Now. For more coverage of the debate around GM crops, click here."
"The New South Wales government was advised six months ago that Sydney’s water storage levels could be at “emergency levels” by May next year unless it started planning immediately. A cabinet-in-confidence document prepared by state-owned agency WaterNSW warns that storage levels could fall to 40% by Christmas and were likely to reach what are considered emergency levels – about 35% and declining – by mid-next year if the coming summer is hot and dry. Sydney’s storages have slumped from 96% full in April 2017 to less than 46%. Ian Wright, a University of Western Sydney scientist, likened the trajectory to “a ski-slope”. The WaterNSW document says inflows since early 2018 had been the lowest on record and water use across the city had been higher than expected. It had increased the risk that some critical supply areas, such as the Illawarra, may run out of water in about two years. Titled “drought supply options study”, the document says storages will become increasingly difficult to manage if they fall below 30%. Storages have depleted at a faster rate during this drought than during the millennium drought, when they fell to 33%. It does not explicitly mention climate change, but warns of the need to plan for “a scenario where climate doesn’t follow history and we get a follow-up drought before recovery”. Sign up to receive the top stories from Guardian Australia every morning “The only options left to us at this point are large-scale desalination plants,” it says. The NSW Greens’ water spokeswoman, Cate Faehrmann, said the document showed the government’s 2017 metropolitan water plan was based on data from the 1939 drought, and ignored years of expert warnings of lower water availability due to climate change and population growth. “It’s grossly negligent for the government to be planning for water security based on historical trends. Unless they factor in reduced water availability under a hotter climate we don’t stand a chance,” she said. A spokeswoman for the water minister, Melinda Pavey, said the government was investigating measures to support Sydney’s water supply and was already taking steps. People in Sydney use more water per person than Melburnians, but the spokeswoman said water use in Sydney fell last financial year, both in total and per capita terms, after investment in water efficiency programs. The government had also preemptively introduced level one water restrictions when dam levels reached 53.5%, before the 50% trigger was reached, and last week announced that level two restrictions would start on December 10, ahead of the 40% trigger point. Average per person water use had fallen from 211 litres to 183 litres a day, the spokeswoman said. She said the government was considering expanding the city’s desalination plant, which is operating at full capacity and supplies 15% of daily water demand, and work had commenced on a strategy to be released next year that would integrate water and sewerage planning. It could increase the use of recycled sewage water, a step long called for by experts. “This will be an adaptive plan for Sydney’s water and sewerage needs out to the year 2080,” the spokeswoman said. Faehrmann said experts had urged the government to invest in large-scale water recycling and stormwater harvesting during the millennium drought but consecutive administrations had failed to act. She said Pavey needed to explain why she did not introduce more water saving measures after receiving the WaterNSW advice in May. “She knew all of this while Sydney had no enforced water restrictions whatsoever,” she said. Wright, a senior lecturer in environmental science, said the government should adopt a water pricing mechanism similar to other states that charged consumers higher rates when they used large amounts. “It is the only jurisdiction that doesn’t have blocked pricing,” he said. He said bringing in level two restrictions earlier than planned and considering an expansion of desalination was welcome, but said the desal plant should have been operating at full capacity much earlier. He urged the government to do more. “Where are the big recycling projects?” he said."
"
Share this...FacebookTwitterUPDATE: http://www.thelocal.de/20150612/reagan-to-gorbachev-tear-down-this-wall
========================================
Sorry for the interruption in blogging and comment moderation over the past 24 or so hours – I was a bit swamped by other things. But now things are back on track. I’ll be posting back at normal speed tomorrow.
Though I missed the anniversary date by two days, The following video is a nice flashback … to 28 years ago:

I don’t know about you, but I get goose bumps every time I hear that last sentence.
I’m glad to say that during a recent visit to Berlin, President Reagan was prominently featured at the Checkpoint Charlie Museum, a must-see if you’re visiting the German capital. If you go, I suggest starting the visit at the top of the museum and working backwards.
Reagan’s (spineless) advisors actually crossed out the “Tear down this wall” sentence, deeming it too provocative. But Reagan ignored it. Less two and a half years later the wall came crashing down.
 
Share this...FacebookTwitter "
"The European parliament is split over whether to declare a global climate emergency before next week’s crucial UN summit. If passed, the climate emergency resolution – to be voted on on Thursday – would throw down the gauntlet to incoming European Union leaders. The European commission’s president-elect, Ursula von der Leyen, is expected to take office on 1 December, having promised “a European green deal” in her first 100 days.  The draft resolution states there is “an environment and climate emergency in Europe and globally” and declares the EU will “take action accordingly”. “It is a message to European citizens, to young people, to say that Europe is the very first continent to declare a climate emergency and to act accordingly,” said Pascal Canfin, a French MEP who chairs the European parliament’s environment committee and co-authored the resolution. The text also references the US president Donald Trump’s decision to begin formal withdrawal from the Paris climate agreement earlier this month. “We need to send a signal that after Trump’s decision, Europe is more than ever committed to deliver,” said Canfin, an ally of the French president, Emmanuel Macron. While the climate emergency resolution is supported by many Liberals, Socialists, Greens and the radical left, the centre-right European People’s party (EPP) – the European parliament’s largest group – is uneasy about the word “emergency”. A source said the German word der Notstand was associated with the name of an infamous law of the Nazi era. The EPP has tabled an amendment stating that the parliament “declares a climate and environmental urgency” [sic] and calling on the EU to take “urgent action”. “I fully underline that we see the urgency of the issue. We need to prioritise this,” said the EPP leader, Manfred Weber, when asked whether his group would back the climate emergency text. The parliament’s political forces are also divided over how quickly Europe should cut emissions to reach a target of net zero emissions by 2050. In a separate vote on Thursday, the European parliament is expected to approve a resolution stating that current EU climate targets are “not in line” with the 2015 Paris climate agreement, which calls for keeping global heating “well below” 2C above pre-industrial levels while aiming for only a 1.5C rise. The EPP supports an emissions reduction of “at least 50%” by 2030 (compared with 1990 levels), while Liberals and Socialists would go to 55%. The Greens argue that anything less than 65% is inadequate. “We have to realise that to meet the Paris agreement there are … very, very strict limits of carbon dioxide and other greenhouse gases that we can release into the atmosphere from now for the next hundreds of years. And if we choose to release that much during this next decade then we can’t keep the temperature below 2C,” said the Swedish Green MEP Pär Holmgren. Holmgren, a meteorologist and well-known TV weatherman until elected to the European parliament this year, advised the Thunberg family on climate science long before Greta began her school strike. Holmgren told the Guardian that he was frustrated with political leaders using Greta’s name, but not taking sufficient action: “There are so many quoting Greta, or saying we have to listen to Greta, or saying we have to keep global warming below 1.5C … and to hear someone say that, and then still not deliver? “Yes, there is a climate emergency and it has been for many decades, but if you want to say that then you have to do something about it as well.” Others say a 55% emissions reduction goal for 2030 is in line with scientific advice. “We are politicians, so we need to bring society on board. We are not drafting an IPCC report,” Canfin said. “We are drafting something that will apply to business, SMEs, agriculture, farmers and citizens.” The Greens’ preferred goal of at least 65% is based on a recommendation by the Climate Action Network (CAN) Europe, a coalition of 1,700 NGOs that bases its analysis on an an IPCC report on how to keep global heating below 1.5C. That report shows other pathways to cut emissions, but some increase the risk of overshooting the 1.5C ceiling on temperature rises, which scientists say is essential to avoid the most dangerous consequences. The scale of the task was outlined by the UN environmental agency on Tuesday, when it reported that global emissions must fall by more than 7% each year from now until 2030 to stay within the 1.5C limit. Most EU member states have signed up to a goal of net zero emissions by 2050, although Poland, the Czech Republic and Hungary continue to hold out, as they await promised EU funds to help their economies go green. The EU has focused its attention on the more distant 2050 target, fearful of damaging splits over the imminent 2030 deadline. “We have been campaigning on the increase of the 2030 target for years and it was disgracefully ignored,” said Klaus Röhrig, EU climate and energy policy coordinator at CAN Europe. The EU’s current objective is to cut emissions by 40% by 2030, which was “shockingly insufficient” Röhrig said."
"The world’s use of coal-fired electricity is on track for its biggest annual fall on record this year after more than four decades of near-uninterrupted growth that has stoked the global climate crisis. Data shows that coal-fired electricity is expected to fall by 3% in 2019, or more than the combined coal generation in Germany, Spain and the UK last year and could help stall the world’s rising carbon emissions this year. The steepest global slump on record is likely to emerge in 2019 as India’s reliance on coal power falls for the first time in at least three decades this year, and China’s coal power demand plateaus. Both developing nations are using less coal-fired electricity due to slowing economic growth in Asia as well as the rise of cleaner energy alternatives. There is also expected to be unprecedented coal declines across the EU and the US as developed economies turn to clean forms of energy. In almost 40 years the world’s annual coal generation has fallen only twice before: in 2009, in the wake of the global financial crisis, and in 2015, following a slowdown in China’s coal plants amid rising levels of deadly air pollution. The Guardian has updated its style guide to introduce terms that more accurately describe the environmental crises facing the world. Instead of “climate change”, the preferred terms are “climate emergency, crisis or breakdown” and “global heating” is favoured over “global warming”. The scale of the climate and wildlife crises has been laid bare by two landmark reports from the world’s scientists. In October 2018, they said carbon emissions must halve by 2030 to avoid even greater risks of drought, floods, extreme heat and poverty for hundreds of millions of people. In May 2019, global scientists said human society was in jeopardy from the accelerating annihilation of wildlife and destruction of the ecosystems that support all life on Earth. The editor-in-chief, Katharine Viner, says: “We want to ensure that we are being scientifically precise, while also communicating clearly with readers on this very important issue. The phrase ‘climate change’, for example, sounds rather passive and gentle when what scientists are talking about is a catastrophe for humanity.” Other terms that have been updated include the use of “wildlife” rather than “biodiversity”, “fish populations” instead of “fish stocks” and “climate science denier” rather than “climate sceptic”. Damian Carrington Environment editor The research was undertaken by the Centre for Research on Energy and Clean Air , the Institute for Energy Economics and Financial Analysis and the UK climate thinktank Sandbag. The researchers found that China’s coal-fired power generation was flatlining, despite an increase in the number of coal plants being built, because they were running at record low rates. China builds the equivalent of one large new coal plant every two weeks, according to the report, but its coal plants run for only 48.6% of the time, compared with a global utilisation rate of 54% on average. The findings come after a report from Global Energy Monitor found that the number of coal-fired power plants in the world is growing, because China is building new coal plants five times faster than the rest of the world is reducing their coal-fired power capacity. The report found that in other countries coal-fired power capacity fell by 8GW in the 18 months to June but over the same period China increased its capacity by 42.9GW. In a paper for the industry journal Carbon Brief, the researchers said: “A 3% reduction in power sector coal use could imply zero growth in global CO2 output, if emissions changes in other sectors mirror those during 2018.” However, the authors of the report have warned that despite the record coal power slump the world’s use of coal remained far too high to meet the climate goals of the Paris agreement. The US – which is backing out of the Paris agreement – has made the deepest cuts to coal power of any developed country this year by shutting coal plants down in favour of gas power and renewable energy. By the end of August the US had reduced coal by almost 14% over the year compared with the same months in 2018. The EU reported a record slump in coal-fired electricity use in the first half of the year of almost a fifth compared with the same months last year. This trend is expected to accelerate over the second half of the year to average a 23% fall over 2019 as a whole. The EU is using less coal power in favour of gas-fired electricity – which can have roughly half the carbon footprint of coal – and renewable energy."
"Demolition work is the most dangerous job in construction, which itself is one of the industries with the highest injury rates. The tragic building collapse and loss of life at the disused Didcot A power plant in Oxfordshire is a stark reminder of just how dangerous demolition can be.  One person is dead and three are still missing after a large part of the main boiler house collapsed on February 23. While it’s far too early to know what actually caused the accident, there are a number of reasons why buildings can collapse unexpectedly during – or just prior to – demolition.  Firstly, and most significantly, contractors may not fully appreciate the structural principles of the building they are dealing with. For example, if a key component – which could be an obvious large girder or something as small as a nut on a particular threaded steel rod – is removed the remaining building could become less stable and must be checked by a competent structural engineer.   Failing to understand the consequences of altering or removing key parts of a structure was tragically demonstrated when a building in Stanley Road, Liverpool collapsed in 2000, killing one person. A steel beam had been bent back to allow access for a skip lorry and steel wall ties had been removed. Workers on the site weren’t aware that alterations over time meant these walls had become more structurally important. Problems of structural stability are further compounded by recent trends in environmental sustainability and the emergence of the “circular economy”, where components and contents of buildings are recovered for resale, reuse or recycling. For example, when a power plant is decommissioned recovery of machinery and equipment is to be expected. Precious metals can be sold on, brick and timber can be reused, and even the concrete can be crushed and recycled.  This presents significant hazards as workers are required to work in the building to “deconstruct” the various elements, rather than use a long-reach demolition rig from a safe distance. It is not unusual to essentially cut a hole or doorway in the wall to allow large machinery to be easily moved in and out. An additional consequence of this method is it allows wind to flow through the building, which can “load” the walls beyond their tolerance levels.   If the cumulative effects of removing fixed machinery that could very well be attached to structural elements of the building, removing parts of walls, and other parts of the building are not considered, then the consequences could be catastrophic. Explosions are the other main risk. In Didcot’s case, one avenue for investigation might be accidental detonation. After all, three of Didcot’s disused cooling towers were demolished with explosives in July 2014. However, cooling towers are relatively simple structures which lend themselves to explosive demolition rather than excavators or dismantling piece-by-piece. The building that collapsed was probably planned to be demolished by one of these more conventional means. However, such specialist explosive work is invariably undertaken under the control of an experienced explosives engineer, so the more obvious source of an explosion might come from what fuelled the building – gas or coal. Gas may build up in the plant itself, leak from pipes over time, or could be present in a “live” pipe that was thought to be “dead” or isolated. In these cases, a spark or source of ignition could easily set off an explosion. Such explosions tend to kill indirectly, as the force causes walls to explode and the roof to fall down, crushing the workers below. This is what happened when corroded 35-year-old gas pipes caused the 2004 Stockline Plastics factory explosion in Glasgow which killed nine people. Coal dust can also cause these sorts of explosions. In fact, most types of dust can cause an explosion if airborne and sufficiently agitated. With the right dust/air ratio, a substantial dust cloud can easily be ignited and cause an explosion equally as devastating as gas. Early reports indicate an explosion just prior to the collapse at Didcot, though this was later denied. However, any causes identified here can only be considered as potential avenues for investigation. The UK’s Health and Safety Executive’s investigation will undoubtedly uncover the actual cause (or causes) of the collapse in due course.  Hopefully lessons can be learned for the future. But, of course, this will be of little consequence to the families of the dead and missing workers."
"The ocean is deep. In fact, most of it is deep. Officially anything deeper than just 200 metres is considered the “deep sea”, but the average depth of the entire ocean is about 3.5km and the deepest point – the Challenger Deep in the Mariana Trench, in the western Pacific – is a little short of 11km down. That means that most of the living space on Earth is in the deep sea. We scientists like to categorise things and the ocean depths are no exception. Depths from the surface to 0.2km is known as the “littoral zone”, from 0.2km to 3km, the “bathyal zone”, and from 3km to 6km, the “abyssal zone”. Anything deeper than that is the “hadal zone”.   The hadal zone is largely comprised of deep trenches caused by tectonic plate subduction that drive the vast abyssal plains steeply down to depths of 11,000 metres in places. But even here, animals thrive, blissfully unaware of how little attention they receive. Here’s an insight into their incredible world. The term “hadal” comes from “Hades,” which refers both to the Greek kingdom of the Underworld and the god of the Underworld himself, Hades (brother of Zeus and Poseidon). The term can also mean the “abode of the dead”. In modern times, Hades is seen as evil, but in mythology he was often portrayed as unreasonably “stringent” rather than actively malicious. Interestingly, he strictly prohibited the inhabitants of his dominion to leave, which is a rather apt analogy for hadal fauna, as these species are often confined to trenches and are rarely capable of going elsewhere.  The extreme depths of the hadal trenches were discovered using “bomb sounding”, whereby someone threw a half-pound block of TNT off a ship and the echo was recorded on board the ship. This method was used to sound the depths of many trenches, but the exact depth of the deepest point, currently in the Mariana Trench, is still difficult to compute. Four other trenches, all in the Western Pacific, also exceed 10km: the Tonga, Kuril-Kamchatka, Philippine, and Kermadec trenches.  The HMS Challenger expedition (1873 to 1876) was the first to sample hadal depths – having collected sediment from about 8km – although it could not confirm whether or not the sediment was merely the remnants of shallower animals. The 1901 Princess Alice expedition successfully trawled specimens from over 6km. However, it was a 1948 Swedish expedition, which successfully trawled a variety of species from 7km to 8km in the Puerto Rico Trench, that finally proved that life existed at depths greater than 6km. In 1956, the first photographs of the hadal zone were taken by none other than Jacques Cousteau in the Romanche Trough in the Atlantic. The hadal zone comprises a series of disjointed trenches and other deep spots. There are 33 trenches and 13 troughs around the world – 46 individual hadal habitats in total. The mean depth of the trenches is 8.216km. The total area of the hadal zone is less than 0.2% of the entire seafloor but accounts for 45% of the total depth range. It is therefore surprising that the deepest 45% of the sea is rarely mentioned in deep sea literature. Of the 33 hadal trenches, 26 (84%) are located in the Pacific, three are found in the Atlantic (8%), two (4%) in the Indian Ocean, and two (4%) in the Southern Ocean. The majority run up the western Pacific. Most of the hadal trenches in their modern form are believed to have formed 65.5m years ago during the Cenozoic period. Earth appears to be the only terrestrial planet with subduction zones and plate tectonics. Both Mercury and the Earth’s moon are tectonically dead. Mars appears to have tectonically ceased, and Venus is dominated by thick lithosphere with mantle plumes. On Earth, subduction zones produce continental crust, which can protrude from the ocean (the continents). It has been speculated that without subduction, the land would still be underwater and terrestrial life, including humans, would never have evolved. Bottom water temperatures are cold and vary between 1°C and 4°C. However, hydrostatic pressure increases linearly by 1 atmosphere (atm) for every ten metres of depth. The pressure at hadal depths therefore ranges from 600 to 1,100 atmospheres. The pressure at the deepest point is, therefore, equal to a one tonne weight being placed on the end of your finger. Many marine organisms are found at hadal depths and the most common groups are the polychaetes, bivalves, gastropods, amphipods and holothurians. All of these groups are found at full-ocean depth and often in large aggregations. Contrary to popular media, the hadal zone is not a mysterious realm inhabited by aliens or “monsters of the deep”. Instead, it is a poorly understood region largely inhabited by hoppers, snails, worms, and sea cucumbers. In fact, the upper trenches are inhabited by little pink fish and bright red prawns. In the 1970s, the Puerto Rico Trench was a pharmaceutical waste disposal site. The figures are astonishing: in just five years, more than 387,000 tons of waste material was discarded in the trench, an amount equivalent to 880 Boeing 747s. In addition, the ill-fated Apollo 13 mission to the moon in 1970 carried a radioisotope thermoelectric generator (RTG) that was supposed to remain on the moon with the lunar lander. The RTG contained 3.9kg of plutonium-238, and in the end was jettisoned over the south-west Pacific, where it reportedly survived re-entry and settled in the Tonga Trench at a depth of 6km to 9km where it should now remain radioactive for several thousand years. The 2011 magnitude 9.0 Tōhoku-Oki earthquake off Japan was caused by a fault rupture in the Japan Trench. The event and subsequent tsunami left about 20,000 dead or missing and affected more than 35 coastal cities. The quake was followed by 666 aftershocks that exceeded magnitude 5.0. The energy involved in high-magnitude earthquakes originating in trenches is immense. The 2004 Sumatra-Andaman earthquake in the Java Trench caused a sufficiently massive release of energy to alter the Earth’s rotation, shortening the day by 2.68 microseconds. Similarly, the Tōhoku-Oki earthquake shifted the Earth’s axis by between 10cm and 25cm, shortening the day by another 1.8 microseconds. One of the most common analogies used in trench science is “Mount Everest would fit into the Mariana Trench with a mile or so to spare”. This is true, and from an evolution and physiology perspective it is immense. Likewise, exploring these extreme depths is highly problematic. But how far is 11km really? The Mississippi River is 11km at its widest point, Manhattan Island is twice as long as the Mariana Trench is deep, and assuming the average running speed of Mo Farah at the 2012 Olympics, he could run 11km in 30 minutes. Given how easily we can affect our planet over far larger distances, our effective proximity to these “extreme” locations means even the deepest places on Earth are no longer pristine – and remain hugely vulnerable."
"Most Europeans take pride in recycling. A good citizen separates glass from plastics, biowaste from metal cans and brags about it to their friends. Recycling helps soothe some of the anxiety driven by endless consumption.  However in Russia, recycling comes with a sense of shame. This is reflected by the fact that more than 80% of Russian domestic waste ends up in landfill, and most of the rest is incinerated. For comparison, Europe’s best recyclers – Austria and Germany – reuse well over 60% of their municipal waste while the UK manages 39%. A 2012 report by the International Financial Corporation, part of the World Bank Group, found that Russia’s waste recovery rate was “nearly zero”. I first became aware of negative social attitudes to recycling in Russia during research in Samara (formerly Kuybyshev), the country’s sixth largest city and which lies in a twist of the river Volga 1,000km from Moscow. Until the collapse of the Soviet Union it was a closed city hosting aviation and automobile industries. Along with a team of Russian and Finnish researchers, we wanted to immerse ourselves in the local culture and learn about the potential for developing eco-innovations in an economy undergoing rapid transition. The results of which were published late last year.  We focused on how people dealt with their waste. At first the task didn’t seem too gratifying as the people whose lives we followed told us they threw all their waste in the bin and that there was neither waste separation nor recycling.  But as we observed their daily lives, we noticed some people leaving beer bottles under the staircases of their apartment building. We also saw bottle collection points outdoors under trees or in shabby basement premises. The outdoor collection points were tended by women who told us their salary was some 200-300 roubles (about £2) a day, but they refused to tell who collected the bottles and paid their salary. We were usually thrown out of the basement recycling places as soon as it turned out we wanted information. When we asked people whether they ever took bottles to these recycling points, most regarded the question as ridiculous. The question made a lot of sense to us as the families we asked were from the low-income tiers of society and could certainly have used the extra money. Probing the issue further we were told that “only alcoholics, drug addicts or poor babushkas [elderly women] who clean corridors” take bottles to recycling points. In addition to the bottles, we also saw used cardboard neatly packed as if it was going somewhere. But nobody seemed to know who it belonged to and where it was heading for. Once, when taking a photo of one such cardboard pile, a bulky man came shouting loudly and chased us away. It’s not easy to get access to companies in Russia, but we were lucky to find one waste management firm willing to talk to us. One morning we met the CEO in his office. After some champanskoye (sparkling wine) and chocolate he took us to visit his company’s landfill site. The company focused primarily on landfill, he told us, because to get involved in recycling or reused items was too risky a business; and waste fragments of any value, such as bottles and metals, were already in the hands of the mafia. Integrating this informal, underground recycling with official efforts to deal with waste is tough.  To give one example, we recently worked with Baltika brewery in St Petersburg, which wanted to start bottle collections because of the environmental policy of its parent company, Carlsberg Group. As part of an intensive course on corporate sustainability, an enthusiastic group of international and Russian students were asked to design bottle collection and recycling methods that would encourage Russians to recycle. Baltika wanted to set up an independent, stand-alone system.  Knowing about the informal bottled recycling, which seemed to be as well-organised in St Petersburg as it was in Samara, I suggested a collaboration with independent recyclers, given there was a system already up and running. The question was met with a cold response: such informal bottle collectors were regarded as criminals. In Russia, informal recycling identifies you as some kind of undesirable. It is a heavily stigmatised activity and ordinary Russians make an effort not to be seen doing it. People also view many recycling companies as either having links to organised crime, or risking conflict with such groups. So at both an individual level and more organised corporate level there are major barriers to setting up the types of systems taken for granted in other parts of Europe. And despite the best efforts of citizens and companies, don’t expect to hear about major advances in systematic large-scale recycling in Russia any time soon."
"We live in a world where large numbers of people are connected by just a few degrees of separation. But while having friends of friends all over the globe can be great for holidays, trade and networking, travel also allows viruses to move like never before. Zika is the latest “explosive pandemic” to be declared a global emergency by the World Health Organisation. But viruses don’t just target humans – they can infect all forms of life from bacteria to bananas, horses to honeybees.  A lethal combination of the Varroa mite and the deformed wing virus has resulted in the death of billions of bees over the past half century. In a study published in the journal Science, colleagues from the Universities of Exeter, Sheffield and I report how the virus has spread across the globe.  Honeybees are geographically separated into two distinct groups, a single species from Africa, confusingly known as the European honeybee, and six other species, all from Asia. The European honeybee is the main species managed by humans, purely because of its ability to make the most honey per colony. In the 1950s these European bees were taken to Asia to improve honey production, and at some point the Varroa mite jumped the species barrier from its native Asian honeybee across to the Western one. Over the next 50 years, the mites spread around the world with the global trade in European honeybees.  Within three to five years of the mites’ arrival, bee colonies started to collapse on a massive scale. Natural wild populations were soon wiped out, as were millions of managed colonies. For decades it was thought that bees were being sucked to death by the mites, as the mites feed exclusively on the bees’ blood. This idea was supported by the appearance of bees in heavily-infested colonies with dry, crippled wings. But more recent research showed that the Varroa mite was, in fact, a carrier rather than a killer, transmitting deformed wing virus directly into the bloodstream. Though bees suffer from various viruses, these are usually found at very low levels and move between bees via food or during mating. The Varroa mite’s totally new transmission route changed the game. Some infected honeybees had crippled wings so could not fly and died quickly, but although most infected bees had normal wings their lifespan was shortened by up to 50% by the virus – causing inevitable colony collapse.    Over time, the virus evolved into a single killer form, now known as the A-type, and it is this which has since spread to bee colonies globally. By analysing data from bees and mites collected around the world, the evolutionary history of this pathogen was reconstructed to reflect how it was spreading. We learned that the deformed wing virus originated within European honeybees themselves, and not their Asian relatives or the mites. The Varroa mite just happened to be particularly effective at spreading the virus. The current pandemic started in the mid-20th century and its spread mirrors that of the Varroa mite. European and North American honeybee colonies were found to be the main transmission hubs, which is to be expected since they are key areas in the global bee trade.  Honeybees and other pollinators are all interconnected via trade, which creates an ideal situation for the rapid spread of pathogens and parasites worldwide and between species – including bumblebees. There are many parallels between the global spread of deformed wing virus and other insect-borne human pathogens such as the Zika virus. And as international trade and travel continues to increase we can expect to see many more emerging viruses impacting both human and animal health. But our genetic history indicates we are well adapted to survive these emerging pathogens, and there are a number of Varroa infested honeybee populations around the world that can now survive without any form of mite control. Natural selection wins again it would seem."
"
Share this...FacebookTwitterTornadoes are normally associated with the famous Tornado Alley of the US Midwest. But they also occur from time to time in Germany.
Nowadays the drama-seeking media are quick to report on any tornado event that gets recorded, and so often there’s the mistaken perception that their frequency is rising (of course due to man-made weather brewing). Moreover the media have no qualms about their readers and viewers making that erroneous leap in thought.
Earlier this month Germany was hit by some relatively severe tornado activity. In Augsburg earlier this week 150 homes were damaged by a twister. The media naturally put the topic on center-media stage.
Flagship daily Süddeutsche Zeitung [South German News], SZ, even conducted an interview with the DWD German National Weather Service on the subject of tornadoes and what might be their cause. Over the recent years the DWD has become a rather avid activist and promoter of the man-made global warming theory. But in the SZ interview, the DWD was refreshingly fully honest, and resisted blaming German tornado activity on climate change.
First the SZ asked DWD meteorologist Lars Kirchhübel about how tornadoes are formed and why they are so dangerous. Then about halfway through the interview the topic switches to the impacts of climate change on tornadoes: The SZ asks, “Are they becoming more frequent in Germany – and are they a consequence of climate change?”
The SZ gives us the DWD’s reply:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Tornadoes are not forming more frequently than earlier, we are simply made more aware of them says DWD expert Kirchhübel. Between 20 and 60 tornadoes are know each year in Germany. It has been only over the last few years that those involved have recorded them with their mobile devices, and so thus enhance the people’s perception.”
And on whether there is a discernible trend linkíng tornado activity to global warming, Kirchhübel tells the SZ that the dataset is too short and that there has been no discernible trend so far. He adds:
Also a clear relationship with climate change is not verifiable.”
About a week ago NoTricksZone posted another report on German tornado activity here, and it found that the trend is actually downward for the past 15 years, and not “no trend”:

Number of confirmed tornadoes in Germany since 2000. Trend has been significantly downward over the past 10 years. Source: DWD.
Share this...FacebookTwitter "
"Dog owners might disagree, but as far as evolutionary biologists are concerned, all dogs are just dogs. It may seem odd that Canis (lupus) familiaris extends from rabbit-sized Chihuahuas to Great Danes which can be almost the size of a small pony, whereas seemingly much smaller differences place many animals into separate species or sub-species. One has to dig a bit into evolutionary theory for this to make sense. The dog is a direct descendant of the grey wolf (Canis lupus), with evidence that lots of different wolves fed into the dog gene pool over the years. In the course of dog domestication, their behaviour, morphology and physique has changed, and differences among dog breeds are indeed astonishing. Imagine if future palaeontologists were to find Chihuahua remains in the fossil record: this animal would appear to have little in common with wolves.  But these differences among dog breeds – and between dogs and wolves – aren’t enough to warrant recognition as distinct species. Dogs are simply too young, from an evolutionary perspective. It usually takes hundreds of thousands of years or more for mammals to evolve into distinct new species, requiring the slow accumulation of mutations that cause inheritable changes to its physical characteristics – or “phenotype”. Archaeological data and analysis of DNA from today’s dogs and wolves, as well as ancient remains, suggest that domestication started about 16,000-40,000 years ago, with most current dog breeds originating in the past 200 years. Charles Darwin pointed out that humans have accelerated the process of selection by choosing particular individuals for breeding, based on certain desired characteristics – what we call artificial selection. Natural selection generally requires much more time, because it acts on novel variants introduced into the gene pool through the slow process of chance DNA mutation. Nevertheless, the power of artificial selection in generating extreme phenotypes does not change the fundamental fact that dog breeds have been separated for only a short evolutionary time. This means that dog breeds differ drastically in their appearance and other characteristics, while most of their genomes are still very much alike. Comparing different breeds, most of their genomes indeed show only little differentiation. In other words, Chihuahuas and Great Danes are overall very similar to one another. The vast physical differences are largely driven by relatively few loci (regions) in the genome. These loci have a large phenotypic effect, leading to strong differentiation among breeds.  This is particularly interesting for evolutionary biologists, and pinpointing such regions in the genome has for example recovered the genetic basis of size variation among dog breeds. We now also have an understanding of the mutations that control traits such as coat characteristics and ear floppiness. So if breeds are that similar to one another in their genomes, how are the vast differences maintained? The obvious answer is the mating pattern we impose on our dogs – we keep breeds separate by preventing interbreeding between them.  The fact humans keep them apart is crucial here. Species are commonly defined as “groups of interbreeding natural populations that are reproductively isolated from other such groups”. This requires hybrids between distinct species to either be non-viable (such as the proposed “humanzee”), or for their offspring to be infertile like most mules, or the more exotic “ligers”. In both these cases there would be complete reproductive isolation between the two groups, whether they be humans and chimps, lions and tigers, or Labradors and poodles. Yet two entirely different dogs will produce perfectly fertile offspring, and many modern breeds in fact originated in this way. Of course in some cases other factors might make mating very tricky. A female Chihuahua would have trouble naturally delivering a male Great Dane’s offspring, for instance. But though some breeds would never mate with each other without human intervention, middle-sized breeds could provide the link between extremely large and small dogs.  Street dogs are a vivid illustration of this point – they show how the distinct gene pools of dog breeds can rapidly mix once the restrictions of artificial breeding are removed. Moscow’s famous feral dogs have existed separate from purebred pets for at least 150 years now. In this time they have largely lost features like the spotty colouration that distinguish one breed from another, or the wagging tails and friendly behaviour towards humans that distinguish dogs from wolves. So genetic exchange would still be common among dog breeds, were they allowed to reproduce freely. In that sense, dog breeds would not be classified as separate species under most definitions. If those Chihuahuas and Great Danes don’t look like the same species right now, it’s only because humans are constantly maintaining a barrier between them."
"
Share this...FacebookTwitterFred F. Mueller at the European Institute for Climate and Energy (EIKE) here writes about how the storm that swept across Europe in late March exposed the lies of the German Energiewende (transition to renewable energies).
With the current rate of growth in renewable energy installations, Mueller writes that it’s just a question of time before the grid gets overloaded just by the renewable energies under certain weather conditions and that it will no longer be possible to dump the surplus  uncontrollably fed in power into neighboring power markets.
Mueller writes how at the end of March Germany saw a combination of high winds and lots of sunshine. During the recent storm there was lots of wind energy production accompanied by lots of solar power production due to large gaps in cloud cover.
According to German flagship national daily Frankfurter Allgemeine Zeitung (FAZ) the surplus energy led to massive costs to power consumers and double digit million costs for the power grid operators, who naturally will simply pass these costs along to the consumers. The situation in late March was so precarious that hundreds of wind turbines were ordered switched off.
The FAZ reports that a record amount of power was fed into the grid due to the strong winds and abundant sunshine: At 2:15 pm a total of 44 gigawatts of sun and wind energy were fed in, which equals the power output of 31 nuclear power plants.
EIKE author Rolf Schuster has compiled the data on installed solar/wind capacity in Germany as of the end of February 2015: a total of 78 gigawatts of capacity that comprises 40 gigawatts of wind and 38 gigwatts of solar. Had the storm hit later in the spring, the situation would have been even worse because more solar power would have been produced, probably another 10 gigawatts.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Rolf Schuster compiled the results of the storm in Table 1: Datum = date; Stunde = hour; Preis = exchange price; Menge = amount; Summe1 = sum 1; Summe2 = sum 2.

Table 1: The nominal exchange losses stemming from the negative prices on 29 – 30 March. Note: Every figure under 50 €/ MWh in reality means that most conventional power plants had to incur losses (Figures from EEX: Table Rolf Schuster)
According to the data in the hours leading up to the storm, power with a market value of almost 3 million euros had to be “given away for free” to foreign markets at negative prices. However, Mueller writes, that was only a small part of the costs. Grid operators wound up losing anywhere from 10 million to 60 million euros during a three day period. According to the FAZ, a total of 20.3 gigawatts of reserve capacity had to be used in order to stabilize the power supply in south Germany. Moreover hundreds of wind turbines had to be taken offline. Yet the affected windpark operators still got paid for the power they did not produce – as is required by Germany’s renewable energy feed-in act. These costs eventually get paid by the consumer.
This time the power grid withstood the overloading from the storm. But Mueller writes that whoever believes the worse is now behind and we all can sit back and relax with the knowledge the power grid can withstand anything, they are being terribly naïve. In Germany within the scope of the Energiewende, it is planned to install approximately 330 gigawatts of wind capacity and possibly 100 gigawatts of solar capacity by 2050.
The result, Mueller writes, is that already on moderately windy and sunny days the grids will become overloaded with “green power” because there is still no storage technology available. The physics is clear: this will inevitably lead to a “collapse in the power supply”. Here so-called “power autobahns” (major cross-country transmission lines), which certain profiteers of the Energiewende are trying to sell us as the wonder cure against the consequences of their own politics, aren’t going to help.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s DWD National Weather Service has developed a nasty habit of putting out warmed up press releases for announcing monthly mean data, and then later very quietly revising the data downwards.
Result: the public believes that warming is happening when in fact there really isn’t any.
German skeptic site wobleibtdieglobaleerwaermung (whereistheglobalwarming) writes a post titled: “What’s wrong with the DWD? Once again a downward correction. June 2015 was 0.2° Celsius colder than reported in the press releases“.
It describes how the June 2015 mean temperature for Germany was overstated by 0.2°C in its press release. It adds:
Also in the two earlier months of May and April, and the entire spring of 2015, the press releases reported a mean temperature that was elevated 0.2°C. DWD correction: May and spring 2015 were 0.2°C less ‘warm’ than announced in the press releases – spring 2015 now 1.4°C colder than a year earlier.
The overly hasty DWD press release announcing the June 2015 data states:
” …The first month of the summer with a nationwide mean temperature of 16.0 °C was 0.6°C above the international valid reference period of 1961 to 1990. Using the 1981 to 2010 reference period the deviation was still 0.3°C…”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Here the wobleibtdieerderwaermung site also points out yet another sloppy error made by the DWD: the difference between the two reference periods for June is in fact 0.4°C, and not 0.3°C, citing a 2014 DWD press release here.
So, did the DWD issue a correction to inform the public of the true June 2015 result, that it was in fact cooler then they had claimed earlier? The wobleibtdieerderwaermung writes:
At the DWD homepage http://www.dwd.de/ one finds at a well hidden location, after a total of seven (7) clicks, the value of 15.8 °C for June in Germany – all the way down, to the right.”
In other words, the DWD made sure to bury the real results, to keep them as much out of sight from the public as they could.
wobleibtdieerderwaermung suggests that the DWD ought to issue a new press release with the following content so that the public can be properly informed:
…The first month of the summer with a nationwide mean temperature of 15.8 °C was 0.4°C above the international vaild reference period of 1961 to 1990. Using the 1981 to 2010 reference period the deviation was only 0.0°C, and thus was exactly the mean for the WMO reference period…a climate warming in Germany’s June 2015 is thus not detectable over the last 35 years.”

So what’s compelling the DWD to engage in the habitual deceptive behavior? wobleibtdieerderwaermung speculates that all this probably has nothing to do with error and has more to do with “political intentions”.
Yet another government institution that we can no longer believe. Little wonder trust in government is near an all-time low.
Share this...FacebookTwitter "
"After the flood, the terrible reckoning: this week it emerged that one of the most ancient churches of Venice, containing the city’s earliest remaining mosaics, had been hit by the tides that overwhelmed the city during the past week. The Byzantine Santa Maria Assunta Basilica, dating to 639, was inundated three times. Half of Venice’s 120 or so churches are thought to have suffered damage. The flood waters affected 85% of the city, causing devastation to the shops, businesses and homes of Venetians who struggle to preserve one of humanity’s most beautiful achievements as a living city. Those residents have been grievously let down. Some disasters are unforseeable. This one was all too predictable. Tides high enough to flood Venice were once exceptional events, but, of the 10 highest tides in its history, half have occurred during the course of the last 20 years. The world’s seas are rising, due to the climate crisis, and Venice has anyway been sinking, by around 1mm a year, into the soft terrain on which its foundations were built. Given this ominous context, the failure to complete a flood barrier project launched in 2003, which is now running 10 years behind schedule, shames the successive Italian governments that have overseen the plan. A corruption scandal, cost overruns and muddled management mean it will not be in place until 2022 at the earliest. The inadequacy of the regional Veneto council, controlled by Matteo Salvini’s League, was vividly captured by its rejection of measures to tackle the climate crisis last week – a decision taken minutes before its chambers on Venice’s Grand Canal were filled with saltwater. But the inquest into this disaster should have a remit that goes beyond flood prevention. The world has loved Venice without caring for it. The Piazza San Marco Association has observed that the city had become so depopulated that it would be difficult to find the electricians, plumbers and carpenters needed to repair the damage. Venice, it said in a statement, “was moving ever closer to a real and irrevocable end”. The local population now stands at around 55,000, down from 175,000 in the postwar period and around half of those residents are 65 or older. More than 1,000 Venetians leave for good each year. The intrusive nature of mass tourism, fuelled by the constant flow of cruise ships which damage and pollute the environment, has led to protests that the city is becoming a theme park. Numerous properties are rented out to visitors through Airbnb, further hollowing out the centre and rendering its labyrinthine streets all but impassable for much of the year. There has been much talk about solutions, but little meaningful action. On 1 December a consultative referendum will be held on whether to separate the administration of Venice from the mainland town of Mestre. The desirability of such a separation is moot, given the level of economic interdependency; that it is being contemplated at all indicates the current level of despair. A mission from the Unesco World Heritage Centre is due to make an advisory visit to Venice early next year. In the wake of last week’s events, that trip should now become a catalyst for action, with international assistance, to save the city for generations to come. This is a debt owed by the present to the past as well as the future. • This article was amended on 26 November 2019 because an earlier version said that the 10 highest tides in the history of Venice occurred during the course of the last 20 years. In fact, of the 10 highest tides in its history, half have occurred in the past two decades."
"
Share this...FacebookTwitterWhat else can be said about all the doom and gloom nonsense from UN scientists surrounding the atolls and sea level? A new paper that is just out should make them red with embarrassment.
This new paper tells us that the atolls are doing just fine and are gaining in area! Read the paper’s abstract that now follows.

Coral islands defy sea-level rise over the past century: Records from a central Pacific atoll

Abstract
The geological stability and existence of low-lying atoll nations is threatened by sea-level rise and climate change. Funafuti Atoll, in the tropical Pacific Ocean, has experienced some of the highest rates of sea-level rise (∼5.1 ± 0.7 mm/yr), totaling ∼0.30 ± 0.04 m over the past 60 yr. We analyzed six time slices of shoreline position over the past 118 yr at 29 islands of Funafuti Atoll to determine their physical response to recent sea-level rise. Despite the magnitude of this rise, no islands have been lost, the majority have enlarged, and there has been a 7.3% increase in net island area over the past century (A.D. 1897–2013). There is no evidence of heightened erosion over the past half-century as sea-level rise accelerated. Reef islands in Funafuti continually adjust their size, shape, and position in response to variations in boundary conditions, including storms, sediment supply, as well as sea level. Results suggest a more optimistic prognosis for the habitability of atoll nations and demonstrate the importance of resolving recent rates and styles of island change to inform adaptation strategies.”


Don’t you just love it when observational data clash with hysterical crystal ball model projections?
Share this...FacebookTwitter "
"Last year, 6m tonnes of “wood pellets” harvested from forests in Louisiana, Georgia, Florida, Alabama and Virginia were shipped across the Atlantic, to be burnt in renewable “biomass” power plants. This was almost double the 2013 figure – the US “wood pellet” industry is booming.  Demand is largely driven by European countries wanting to meet targets set out in the EU’s Renewable Energy Directive. Half of the pellets exported from the US were used to generate electricity in Britain’s massive Drax power station, which is slowly converting from coal to biomass in order to reduce carbon emissions and claim valuable “Renewable Obligation certificates” for green electricity. So can it really be sustainable to transport wood halfway round the world to burn in a power station? Many environmentalists don’t think so. A consortium of NGOs recently argued that the EU should exclude wood from its renewable energy targets. They claim the industry is felling large areas of hardwood wetland forests across the south-eastern US, causing a loss of biodiversity and a net increase in carbon emissions. Even when the forest regrows it does not store as much carbon in biomass and soils as the original – and it’s certainly not as good for wildlife. A UK government study found that electricity generated from regenerated forests could have a carbon intensity five times higher than coal. Burning wood also releases nitrogen oxides and carcinogenic compounds. So why burn wood to meet renewable electricity targets when cleaner options such as wind, solar, hydro or tidal power have a much lower environmental impact? Wind and solar power are already expanding rapidly and will be key in future, especially as we get better at storing energy. But in the meantime, these clean but intermittent power sources can’t yet replace coal.  Coal produces 39% the world’s electricity, alongside a third of all carbon dioxide emissions and a wide range of other toxic emissions. Yet for all its faults coal has two big advantages: it’s cheap, and it can operate continuously to provide a minimum “baseload” level of electricity.  It’s relatively easy to modify a coal plant to burn wood instead – fuel handling and injection systems need to be adapted to handle the wood pellets instead of pulverised coal, but the combustion process is otherwise similar. It’s a quick and comparatively cheap way to shift towards renewables. For this to be worthwhile however, the amount of carbon emitted by extracting, processing, transporting and burning wood pellets must be significantly less per unit of power (MWh) generated than the equivalent for coal. This can be ascertained through carbon accounting, or “life cycle assessment”. Perhaps surprisingly, trucking wood pellets 200km to a port and transporting them 7200km by ship isn’t a deal-breaker in terms of carbon emissions. Since large ships carry massive cargoes efficiently at low speed, transport contributes around 40kg CO2 per MWh electricity generated. Significantly more carbon (more than 100kg per MWh) is emitted by the drying, grinding down and shaping required to transform harvested wood into small, easy-to-handle pellets.  Even this still has a far lower carbon intensity than UK coal though, so transport and processing clearly doesn’t stop wood power being a sustainable option. But here’s where it gets complicated. Whereas burning coal releases carbon that had been stored in the ground for millions of years, CO2 emissions from burning wood are part of a continuous biological cycle. Carbon in wood was only recently taken out of the atmosphere through photosynthesis, and replacement tree growth will suck it back out again.  However the time taken to replace that carbon varies hugely depending on whether you’re harvesting large trees from ancient forests, or small branches from new plantations. We also have to consider how these American forests would have been managed without any wood pellet demand. The government study notes that wood from intensively-managed plantations could mean more carbon taken up by growing trees than emitted by the transport and processing of the pellets, leading to a net reduction in emissions even before avoided coal emissions are accounted for. Conversely, as referred to earlier, the study found that if wood pellets are sourced from regenerated natural forests, carbon emissions could be five times higher than from burning coal. So the type of wood that is burned is crucial. What’s the most likely effect?  Fortunately America has lots of spare wood lying around that would otherwise be burned or wasted. Drax and other big players claim their pellets are sourced from such “forest residue” – saw-mill scraps, trees that died naturally, or were too misshapen to be used as lumber, small twigs, and so on – though environmental groups dispute this.  Whatever the truth right now, there’s certainly lots of potential in wasted wood. Between 14% and 63% of the currently spare forest residue in the US would be sufficient to meet the UK’s entire biomass demand in 2020. A recent academic paper suggested that even after accounting for possible forest carbon loss, electricity generated from US wood pellets is still far cleaner than coal.  There are some regulatory safeguards in place too. Power station operators need to prove that electricity generated from wood is clean enough to count as “renewable” in terms of UK and EU policy. The worry here is that increasing demand from the well-regulated European energy sector could displace existing wood demand from unregulated sectors towards unsustainable sources such as pristine forests. Ultimately, the environment would benefit more if American wood was used at home to reduce the huge quantities of coal burned there, and European rural economies would benefit more if renewable energy targets were met using local wood. But in the meantime, US forests provide a cheap source of wood pellets for European power generators to meet renewable energy and carbon reduction targets.  It’s not the long-term goal of 100% clean, renewable energy that humankind is capable of achieving but, from where we are right now, it’s a step in the right direction."
nan
"
Share this...FacebookTwitterGerman online finanztreff.de here reports on the opinion recently expressed by Prof. Hans-Werner Sinn, Director of the renowned Munich-based ifo-Institute for Economic Research, regarding Germany’s attempted move into renewable energies, primarily solar and wind power.
Currently about 25% of Germany’s energy supply is “green”.
At a conference of experts in Berlin Sinn is quoted by Dow Jones as saying that the installation of “renewable energies in Germany has already reached its limits” because there is just nowhere near enough storage capacity available to balance out the sharp and volatile supply spikes of wind and solar power.
Sinn also ridiculed the idea of using electric cars as a means to store the green energy, calling the notion a “PR gag”. He added that 159 million BMW i3 vehicle would have to be put on the streets, i.e. thus nearly tripling the number of cars currently on the streets. A preposterous solution.
On using green energy to produce gas, Sinn calls it a horribly expensive alternative that would cost about 24 cents per kilowatt-hour; Russian natural gas by comparison is only 3 cents per kilowatt-hour, he says.
“It would get expensive very rapidly,” Sinn warned.
Currently Germany’s Ministry of Environment is proposing the investment of 1 trillion euros for a new energy supply system. Sinn calls that idea “a monstrous gamble with an uncertain outcome“, and one that harbors “a real risk” of Germany “gambling away its prosperity“.
So how will German policymakers react to Professor Sinn’s assessment? Well, if they don’t heed his warnings, then there’s really no one left out there who may still be able to talk sense and reason back into the policymakers’ heads.
Should the policymakers ignore the warnings of the renowned Ifo Institute, then the only thing left is to learn it the hard, painful way. Knowing today’s German intellectual obstinacy of the elite class, the odds of that are better than even.
Share this...FacebookTwitter "
"The so-called “Heathrow 13” Plane Stupid climate activists have been given suspended prison sentences for trespassing on the airport’s runway. The case – and the decision of the judge to hand down custodial sentences at all, even if they were suspended – illustrates the way judicial attitudes to unlawful climate activism have seesawed over the years, and the harsh treatment meted out to the activists may yet backfire.  In 2008, six Greenpeace activists who had admitted causing criminal damage at Kingsnorth power plant were found not guilty by a jury, following a week of expert testimony on coal and climate change. It seemed a significant moment for the UK climate movement. Their “lawful excuse” defence justified their actions to fight global warming, and appeared to offer campaigners a way to make governments take both notice and action. But subsequent acts of mass disobedience faltered: in April 2009, 114 activists planning to shut down Ratcliffe-on-Soar power station were pre-emptively arrested in a case which ultimately brought to light the extent of police infiltration of the environmental protest movement. Later that year 29 activists were found guilty of “obstructing the railway” by a jury in Leeds after the judge refused to allow them to present a necessity defence and call expert witnesses to justify their “hijacking” of a coal train at Drax power station. And in June 2010, nine Plane Stupid activists were found guilty by a jury and fined for breach of the peace after they had broken into Aberdeen airport and played golf on the runway, dressed as Donald Trump. Taking non-violent direct action in order to “put climate change on trial” seemed at a dead end. The trial of the Heathrow 13 may have changed all that. In fact, the activists probably owe a vote of thanks to district judge Deborah Wright. History tells us that social movements not only mobilise when conditions are favourable; they also mobilise in response to threat, especially where that threat is widely seen as an injustice. The court’s guilty verdict was to be expected, but the judge’s threat to impose the maximum sentence of three months imprisonment succeeded in producing a wave of sympathetic media coverage, internet petitions and an impressive and sustained show of solidarity from 300 or so supporters outside the court. Criminal trials are social theatre: Wright’s promise of a punitive sentence turned this one into a political event. In so doing, the trial reminds us that the courts, especially the criminal courts, are a site of battles over legal and political legitimacy. Trials like that of the Heathrow 13 are, in the strict sense, about the causes that motivate action, the weighing of harms and the acceptability of specific conducts – but they are also about the scope that democratic societies afford for small groups of citizens to challenge what they perceive to be injustice in the name of the collective good. Though the Heathrow 13 were spared jail time, a suspended prison sentence for a non-violent minor crime, committed by (largely) first-time offenders, arguably remains extraordinary and excessive. In 2006, sitting in a High Court appeals case of anti-war activists who had committed aggravated trespass and criminal damage at RAF Fairford on the eve of the invasion of Iraq, Lord Justice Hoffmann formalised a basic bargain: where activists act in a publicly accountable way – with restraint, sincerity, and a sense of proportion – then police, prosecutors, and magistrates should show sensitivity and equal restraint, taking the conscientious motives of protesters into account. Activists are aware of the bargain: the Heathrow defendants certainly were, and it is a staple of advice for would-be environmental disobedients. But this sentence throws the bargain into confusion. By acting with less restraint – and causing more damage – activists can potentially secure a jury trial. Though the potential penalties are more severe, this move typically works in favour of the activists as juries, in general, are less likely than magistrates to convict in these sorts of cases (despite the Leeds and Aberdeen verdicts). But if magistrates are now imposing jail time, actual or suspended, for minor offences, then acting with restraint starts to appear less attractive. If you’re going to be dealt with harshly for aggravated trespass, you may as well cause criminal damage too, because that might get you a more favourable trial. This year will see a concerted wave of climate disobedience across Europe, as activists react, post-Paris, both to the lack of a concrete action plan by Western governments and to the apparent necessity of citizen action in order to force governments do anything meaningful at all. In the UK, we should expect more climate disobedience, not less: the Heathrow 13 trial raises the stakes."
"The replacement for the EU-US Safe Harbour agreement that was ruled unlawful by a European court last year may well fail the same legal tests as its predecessor. The new agreement, called Privacy Shield, seems to be little more than a new name strapped onto what are largely the same data sharing protections, or lack of them, contained in Safe Harbour. Safe Harbour dated from 2000 and allowed US and European companies to exchange data without officially conforming to the relatively strict requirements of European data protection legislation. The European Court of Justice has ruled it to be unlawful following a challenge brought against Facebook – but also in the light of Edward Snowden’s revelations about US government mass surveillance programmes. Safe Harbour provided firms with considerable leeway – considered a box-ticking exercise – with little if any real protection for individuals.  While mass surveillance is a concern, it is difficult to police due to the nature of national security as a secretive business with very little transparency or public accountability. But the terms under which firms do business is certainly within the realms of oversight. Now the European Commission has announced an “agreement in principle” on the new EU-US Privacy Shield. The full text of the proposed agreement has not yet been made available, but the wording of the European Commission and US Federal Trade Commission announcements reveals a number of problems. FTC Chairwoman Edith Ramirez said:  Under the agreement … the Federal Trade Commission will continue to prioritise enforcement of the framework… We will continue to work closely with our European partners to ensure consumer privacy is protected on both sides of the Atlantic.   But the FTC’s own assessment makes it clear that enforcement was not a major priority under Safe Harbour. Only latterly were some of the most high-profile data controllers such as Google, Facebook and MySpace fined for their breaches. Several studies have suggested that enforcement had been very lax indeed. From the European side, EU commissioner Vĕra Jourová used careful wording to imply stronger protections for EU citizens’ privacy without any concrete provisions: The new arrangement will provide stronger obligations on companies in the US to protect the personal data of Europeans. Of course, without any clear statement of what those obligations are or how they will be enforced, these words have an empty ring to them. Talk of “stronger monitoring and enforcement” is meaningless unless there are penalties associated with any breaches.  Three provisions are outlined. Where, under US law, public authorities can access personal data transferred under the new arrangement they will be subject to clear conditions, limitations and oversight. There will be the “possibility” of raising any complaint in this context with an ombudsman. And there will be an annual joint review of the implementation of the new arrangements. But while this will involve representation from national security agencies, there is no mention of any role for consumer representatives. Similarly, there is little reassurance to be found in the proposed safeguards and remedies.  While companies will be given deadlines to respond to complaints, there is no suggestion that these will be enforceable, nor which country’s law would apply. Would European citizens have the right to take a case to the US courts? European data protection authorities can refer complaints to the FTC, but there’s no indication that they would be taken any further, nor are there any provisions for Europeans to gain redress there. An alternative dispute resolution procedure is mentioned, but without any indication of who the mediator would be and whether judgements would be enforceable. Finally, the prospect of a US ombudsman is mentioned – but again without any detail that might explain their powers, independence and what sort of oversight would be in place. It seems clear that the main aim of the EU-US Privacy Shield is, as critics have stated, to give US-based companies an easy way of handling personal data from European citizens without having to provide the full protections afforded by the EU’s Data Protection Directive.  Seen this way, Safe Harbour could be viewed primarily as a way of preventing data protection legislation from jeopardising transatlantic trade. Why the urgency to rush to replace such a leaky arrangement, demonstrated to be full of holes? The headlong rush to agree and implement this badly thought-out follow-up agreement is perplexing when there are already other means in place. For example, model clauses for consumer contracts, or the technology to obtain informed consent directly from customers to process personal data outside the EU. With that in mind, it’s difficult to see how the proposed new arrangement is any different in intent to the one it replaces."
"As night closes in across Kentucky a small chubby spider makes a silk line between two plants. She then moves along her “trapeze wire” and waits. After a while a moth approaches within range, and the spider unleashes a swinging sticky ball, ensnaring the moth and pulling him in to be eaten. The attacker is a bolas spider, and she hunts by releasing an odour that precisely matches the chemical composition of female moth mating pheromones. The male moth is lured in, but instead of getting a mate, he gets eaten. Bolas spiders are just one of a plethora of animals and plants which are highly skilled at thriving through trickery and deception. Charles Darwin and his contemporary Alfred Wallace both appreciated the functions of deception in their theory of evolution. However, modern science has started to uncover just how devious many species can be. One of the main uses of deception in nature is to secure food. The fork-tailed drongo is a bird found in Southern Africa that lurks around group-living species, including meerkats, and might at first appear helpful because it sounds alarm calls when a predator approaches. However, much of the time the drongo’s calls are made when no predator is around. The drongo watches as a meerkat digs up a juicy beetle and then makes a false alarm call, which causes the meerkat to flee, allowing the bird to swoop down and claim the prey for itself. The alarm calls drongos use even mimic those made by the animals they exploit.  But stealing food seems benign compared to the deception of predators, which use mimicry and enticement to lure victims directly into the jaws of death. Many web-building spiders use bright colours to attract prey, and carnivorous plants also use overt signals and mimicry to attract victims. The Venus flytrap produces smells that mimic food, luring in flies, and some pitcher plants have been shown to use attractive fluorescent glowing blue colours. These colourful signals work by exploiting “preferences” that many animals have in their sensory systems to be drawn to conspicuous stimuli.   The second use of deception is in survival, with the most common method being camouflage. This can involve matching the general colour and pattern of the environment, or can be much more specialist. On his eight-year voyage around the Malay archipelago, Wallace encountered the butterfly Kallima in Sumatra and was astounded at how closely its wings matched the colour, shape, and structure of dead leaves. Many specimens even had markings mimicking patches of mould.  Resembling other objects for protection is common in nature. Some excellent early evidence for evolution and natural selection was provided by Henry Bates, an entomologist who travelled to the Amazon with Wallace. Bates noted that many  edible butterflies mimicked the colour and behaviour of toxic species, and were avoided by attackers. 
Another striking example is jumping spiders, some of which mimic the appearance of ants, which predators often avoid owing to their strong defences. Organisms also cheat for reproductive reasons. Orchids have an astounding range of approaches which they use to get insects to pollinate their flowers, while offering no reward. One method is to lure male insects with smells and colours resembling a potential mate, like bee orchids that attract male bees. Other species create the false promise of food. One flower from Hainan Island, China, mimics the alarm pheromones and appearance of bees, thus attracting a ferocious predatory hornet. And once mating has been achieved there are young to be cared for. The common cuckoo, a notorious cheat, lays its eggs in the nests of other species, so the foster parents rear the cuckoo chick instead. The cuckoo often even lays eggs that mimic the colour and pattern of those of their host, so the host can’t tell the difference.  Insects can be equally devious, seen in the behaviour of cuckoo bees, and the audacious  slave-maker ants. The workers of these remarkable animals often have one function alone – to raid the nests of other ant species and steal the brood. The captured ants then integrate with the host colony, dutifully carrying out all the main tasks of the nest, from cleaning and rearing young to defence.  The struggle to survive and reproduce is intense for all organisms, and we should not be surprised that cheats are everywhere. What’s remarkable is the extent to which animals and plants exploit one another and the level of sophistication involved. Nature is a brutal place, so it’s a good idea to cheat and deceive if you want to be successful."
"
Share this...FacebookTwitterThe latest 17 June 2015 edition of Weltwoche from Switzerland has a commentary on the Vatican and its encyclical on climate titled: “A Matter of Faith“.
The commentary believes the Vatican is out of place with Its recent encyclical on climate science, reminding readers that the Vatican hardly has a stellar record when it comes telling Catholics what true science really is, and that today It is wrong with Its claim there is a consensus on the issue.
“Galileo is chuckling”
The Weltwoche article writes in its introduction:
With an encyclical the Pope is attempting to teach correct climate policy. The Catholic Church has long since always proven its sense for true science. Somewhere Galileo is chuckling.”
Weltwoche recounts the Church’s debacle surrounding Galileo, writing that it took the Catholic Church over 300 years to apologize for having falsely accused the 17th century physicist, who claimed the Church had been wrong in thinking the earth was the center of the universe.
“The Amen to the reporters of the IPCC”
Yet under Pope Francis the Church appears to have learned nothing from its long history of intellectual blunders, and Its Little Ice Age and bad-weather witch-hunts. Weltwoche writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Pope Francis is now sending the encyclical “Laudato Si” to his bishops, which reads as the Amen to the reporters of the IPCC and the capitalism critics, such as Naomi Klein.”
Weltwoche describes how Pope Francis claims there is a “scientific consensus” and that as a result “mankind has to change its lifestyle“.
A Hail Mary to reverse crumbling consensus?
Weltwoche also writes how major media outlets such as The Guardian and Reuters have cheered the Pope’s word on the issue, hoping it will finally tip the scales in favor of radical environmental change. But this reaction was expected, writes Weltwoche:
The jubilation can be explained because the consensus in the science has been crumbling: The temperature has not been rising in what will soon be 20 years and it remains below all prognoses as a result. With increasing desperation, instead of abandoning their refuted models and theories, the climate scientists offered more than 50 explanations.”
Stiff opposition
Weltwoche then describes a growing atmosphere of shrillness pervading among climate scientists and activists, but on the other hand emerging countries have been unimpressed by the ever more shrill alarms being sounded. A climate treaty faces stiff opposition from the US Congress, and for this reason Pope Francis plans to visit Washington in September, Weltwoche writes, adding that His Holiness plans to have a talk with Catholic and House Speaker John Boehner:

However the Holy Father will barely be able to teach him much, and not at all the Chinese, and certainly not the Indians, who will first bring their citizens out of poverty, just as the encyclical demands. And to do that they need affordable energy, foremost coal.”

 
Share this...FacebookTwitter "
"The future role of gas in the UK is the subject of significant debate. There is controversy about how much gas we could use and for how long, and whether this will be compatible with statutory climate change targets. As North Sea supplies decline, there are also starkly differing views about whether some of the gas we will need in future should come from domestic shale gas resources. Despite the number of headlines about shale gas, there has been very little development activity so far. Fracking for shale gas has only been carried out at one site near Blackpool, where operations by Cuadrilla caused minor earthquakes in 2011. This means that it is almost impossible to determine whether significant UK shale gas production would make economic sense. The recent falls in oil and gas prices have added to this uncertainty, but are likely to make commercial viability more challenging. During the recent 14th licensing round for onshore oil and gas, 159 areas were awarded licenses for development – 75% of these were for unconventional oil and gas extraction, which has sparked local debates in many of the affected areas. Two planning applications submitted by Cuadrilla for exploration at sites in Lancashire were recently turned down by the local council on the grounds of noise and traffic. One of these was refused against the advice of council officers. An appeal by Cuadrillia is currently underway. Whether or not it goes in favour of the council or the developer, it raises broader questions about the role of local democracy and decision-making.  Last August the government announced the introduction of fast-track planning regulations designed to limit the length of local planning processes for unconventional oil and gas operations. Greg Clark, the secretary of state for communities and local government, also said he expects to have the final say over the Lancashire applications.   This intention to constrain local planning processes has understandably led to concerns about local democracy. It is not the first time national government has tried to intervene in local decision-making, especially when it comes to the development of new large-scale infrastructures or natural resources. While national government may emphasise a particular course of action, like the development of shale gas, there is no guarantee that local decision-makers will simply agree. Furthermore, selective limits on local planning risk exacerbating public mistrust. A Sciencewise project on public engagement with shale gas and oil, commissioned by the government, revealed significant unease among participants about decision-making processes.  Given that large-scale changes to energy infrastructures are very likely to be required across the UK as the energy system decarbonises, this issue goes well beyond shale gas. Local opposition has also been significant for other energy developments such as wind farms, solar farms, gas storage sites and electricity transmission lines. The government’s approach to different energy sources appears to be inconsistent – most notably between onshore wind and shale gas. In contrast with the approach for shale, local planners will determine whether new onshore wind projects go ahead or not. Ministers have defended this situation on the grounds that a lot of wind farms are already being deployed, while shale gas is at a very early stage.  Although the government’s regular energy opinion poll no longer asks specific questions about onshore wind, other polls suggest it still has significant public support - as well as being the cheapest low carbon electricity generation technology. The focus on shale and wind could also be a missed opportunity for a broader conversation about the UK’s sustainable energy transition. This conversation should not be restricted to which technologies or resources should be used, and what they might cost. Previous research from the UK Energy Research Centre suggests that people are also interested in how energy systems can reflect values such as fairness, sustainability and efficiency. A focus on individual sources like shale gas in isolation leaves little space for this broader conversation to be held."
"Everyone used to call Helen Tandy “the Grinch” at Christmas. She would get odd looks and long sighs from friends and family when she tried to explain that she didn’t want gifts and wouldn’t be buying any either. Christmas crackers – “a horrible waste: a bang, some tat and then it’s all chucked away” – were banned at her home. Shiny wrapping paper (which can’t be recycled) made way years ago for plain brown or newspaper, then, last December, she tried furoshiki – the Japanese art of fabric wrapping. Tandy’s artificial tree will next month be wheeled out for its 31st Christmas, and will be decorated from a carefully stored box of decorations handmade or collected, one by one, over the years. “I didn’t want to get to the end of Christmas Day and look around and feel like we’d made a week’s worth of waste in just a few hours,” says Tandy. “I couldn’t stomach it.”  Tandy, 50, works as an ethical financial adviser in Chester and lives with her husband and 22-year-old son. Eight years ago, she quit her job in mainstream banking and audited her life against her impact on the planet; she now runs sustainability workshops as a climate ambassador for the Women’s Institute and a Friends of the Earth co-ordinator, “Back then, people thought I was weird, but now they’ve started to engage and talk differently. More people understand why it’s not right for Christmas to become a consumerist nightmare. I’m not religious at all but the pandemonium of sales and buying things for the sake of buying something goes against what the festive season is all about.” It’s safe to say that her husband and son weren’t fully on board when Tandy first started scaling back on what she considered unnecessary waste. “I’ve dragged everyone along with me and in some ways they were kicking and screaming to start with, but they’ve come to realise that we need less stuff and more time together. When I buy presents now, they’re experiences, not objects”. A Tandy-style family Christmas – more sustainable, less wasteful and better for the environment – might have seemed anachronistic or simply mean a few years ago but there are signs that many more families will be opting for an eco-friendly Christmas this year. Activists behind Buy Nothing Day and Green Friday, which both encourage supporters to spend nothing and celebrate sharing and mending instead, are mounting a direct challenge to the rampant commercial frenzy of this week’s Black Friday. But can a growing backlash against buying really make a difference? “It’s more about a personal sense of relief,” says Léon Pearce, a 28-year-old sound engineer who lives with his musician wife, Rebecca Hawley, in Liverpool. Opting out and “not buying stuff I don’t really need” puts him more at ease with his conscience, he says. “It’s as if something quite negative has just gone from my life.” The couple are embarking on their first Buy Nothing Christmas this year. “I haven’t always been anti-consumerist,” he says. “Until six months ago I was quite a clothes addict. I justified it to myself by never buying fast fashion and choosing more expensive stuff that would last a few years. But now I don’t care so much about the latest clothing or trends, and I have much more money. I do miss browsing around shops looking at nice things, but just not enough.” For their first Christmas together, four years ago, Pearce says he bought his wife lots of gifts. “All the presents were of a certain type. They probably weren’t things that would get thrown away as that’s never been my vibe, but it’s definitely going to be different this year. It sounds really cheesy but the main gift is being together and committing to not working, because we both work a hell of a lot. Ours are the sorts of jobs that take up your life rather than nine to five, so it’ll be phones off and laptops off for a couple of days, That’s more than enough.” Pearce has been inspired in part by his involvement with Extinction Rebellion and a growing distaste for unsustainable consumption of “stuff”. “We both stopped buying from Amazon a few months ago, which was a new challenge, and I consciously began boycotting Black Friday three years ago. We always used to take advantage of Black Friday for work – buying audio and musical equipment, microphones and gadgets and that sort of thing.” The couple have urged friends and family not to buy them anything or, “if they really must, it has to be something edible or a bottle of wine we can all share rather than something wrapped in plastic wrapped in wrapping paper”. Not having children, Pearce admits, makes having a green Christmas much easier. “The youngest person we would normally buy a gift for is 12, and in some ways he’s the most supportive of what we’re doing. He understands it.” According to a study by waste management company Biffa, the UK creates 30% more waste than usual over Christmas. This includes an estimated 227,000 miles of wrapping paper and 114,000 tonnes of plastic packaging. Retailers may well not welcome this shift. November and December traditionally account for over 20% of total annual sales, and as a British Retail Consortium spokesperson says, 2019 has been “an incredibly challenging year” on and offline. Sales growth in the past 12 months has fallen to its lowest ever level – just 0.1%, compared with 2.8% a decade ago. The BRC put the blame on “weak consumer demand” reportedly propelled by “Brexit uncertainty” rather than the anecdotal view that Brits have simply reached “peak stuff”. Maud Barrett, 36, a textile artist originally from Paris who now runs a social enterprise in south London teaching DIY and crafting skills, says it is becoming clear that “wasteful accumulation of things” can’t be considered the norm for much longer. “It’s a pressure,” she says. “It has an impact on your wellbeing. We’re so much happier since we stopped just buying things: it really helps not having the worry.” This year she, her husband and their three-year-old daughter and 10-year-old son will be trying to minimise the family’s carbon footprint by celebrating their second secondhand Christmas. It hasn’t always been easy. “Both my kids want stuff,” she admits. “But both of them are very aware of my ideals of life and how I want us to be as a family so they do understand. They’re not always happy but, well, they understand and my husband is also more on board.” Barrett’s growing unease with mass consumerism was sparked by a period of living in the Middle East. “We were there for four years for my husband’s job,” she says, “and had no real contact with nice independent shops or places that could make a difference with sustainability. I was so annoyed about the amount of waste we created – like buying bottles of water every day – and the lack of choice we had, that I promised we would change our habits hard and fast when we moved back to London.” This year, she says there will be “one or two” presents for the children – her daughter wants Barbies and her son wants an XBox – but none of them will be box fresh from the shops. “My partner won’t necessarily get anything until I address an actual need that he has – it could be something boring like work shirts – and he will now apply the same rules for me. I don’t want something for the sake of it: that doesn’t make me happy.” Instead, Barrett says, they have built family traditions that “aren’t about things: things don’t make people happy”. Their traditions, she says, make the most of the most luxurious commodity of all: time together. “We arrange a few weekends where we do crafts as a family – we make decorations like baubles and collages, or the children make toilet roll decorations. I look for ideas on Pinterest, but it’s about creating memories, doing things together that they look forward to.” Despite this, market researcher Mintel predicts that Britons will still spend £48.7bn this December, an increase of 3.8% on the same period last year. Matthew Sparkes, a sociology lecturer at Cambridge University, says that though qualitative evidence may be scant, his hunch is that “environmentally aware consumers are going to be a middle-class phenomenon at this stage. People who have the capacity to engage in countercultural consumerism by making their own presents and so on will have a different outlook and social network.” Sparkes points out that consumer credit in the UK is higher than at any time in history, which suggests that it will be some time before ethical consumption makes a significant dent in the UK’s Christmas economy. “Class undercuts all aspects of consumption, he adds. “Someone with very limited social resources will feel very different social pressures: they will want their kids to fit in. Having the option to opt out [of shopping] is a luxury in itself. If you’re on a zero-hours contract, you’re not necessarily thinking about sustainable consumption. The pressures are so different and are underpinned by the structural issues that drive consumption.” That the health of the nation is considered to be shaped by its economy and how much its people spend is one factor, says Sparkes. That consumption – be it mindlessly acquisitive or mindfully guilty – shapes individual identity is another. In this sense, buying lots or deliberately buying very little at Christmas can both become ostentatious signifiers of class. It’s easier to forgo presents when one already has a considerable level of comfort and disposable income. Tandy agrees. In her opinion, a change at government level is needed for there to be a significant swerve in public opinion. “I feel quite sad going through the town centre [in the run-up to Christmas]. I think about the people who go into debt at Christmas for the sake of two or three days because they feel this overwhelming need to be like everyone else. And all this stuff is pushed on you so much. For instance, I used to be very aware of the car I drove: it was a status symbol. I thought it was stuff that made a person – the car you drove, the house you had – and over time I realised it isn’t. It’s the people you’re with – your friends and family – that counts.” Shiny wrapping paper that doesn’t hold its shape when scrunched into a ball isn’t recyclable. Switching to plain brown paper or newspaper fastened with ribbon and string rather than sticky tape and plastic bows is one way to reduce waste. Wrapping presents in lengths of fabric, following furoshiki (the traditional Japanese art of wrapping items in decorative cloth), is another option that is growing in popularity. Research shows that experiences provide more lasting happiness than objects – and so a gift of tickets to a show, paying for a course or activity, a Netflix subscription or membership of the National Trust might be another option. An estimated 6 million real Christmas trees end up in landfill each year. Many local authorities run recycling schemes, where they collect the trees and turn them into woodchip or compost for parks. This is an improvement, but it’s worth looking out for tree recycling and tree rental schemes, where trees are hired out for Christmas then replanted. "
"In 1707, a Jesuit missionary from what is now the Czech Republic named Samuel Fritz published one of the first detailed maps of the Amazon River. Fritz spent much of his life in the region and his map names and locates (often incorrectly) many of the Amazonian forest peoples he encountered. In this sense, his map helped tie them to certain places, and to particular colonially-defined identities.  While Fritz was mapping out the Amazon, other Europeans were hard at work in tropical forested countries across the globe, drawing up boundaries that ignored and criminalised forest peoples’ customary rights to live in their ancestral territories.  Maps have always been part of the imposition of power over colonised peoples. While map-making might be thought of as “objective”, it is fundamentally political, a necessary part of controlling a territory. Maps inscribe borders, which are then used to include some and exclude others. During a late 19th-century rubber boom, Amazonia became increasingly well mapped out as the young nations of Peru, Bolivia, Brazil and Colombia vied for territorial control. The rights and interests of Amazonian peoples were never included in this process and they would be continually denied rights, recognition and citizenship from these nations until the 1980s and 1990s. Even following legal recognition, their territorial rights – critical for their continued existence – are still often ignored in practice. These marginalised people are now working together to reclaim the process of mapping itself. In the central Brazilian Amazon there has been a recent flurry of “counter-mapping”, used by forest peoples to contest the very state maps that initially failed to recognise their ancestral territorial rights. Counter-mapping first came to prominence in the 1990s, when it was particularly influential in Indonesia. Back then, it was rudimentary and new maps were produced by hand. Today, communities have access to GPS and smartphones and are able to walk along trails marking out their territorial claims.  In Brazil counter-mapping falls under the wider term of “auto-demarcation”, which also includes various other forms of territorial monitoring that would normally be carried out by the state. The goal is to safeguard the integrity of territory, defined as much more than just land (schools, for example, are one stated objective).  In Brazil, recognition of forest peoples’ territorial rights can take decades. The government, acting in the interest of rural elites, is currently attempting to roll back these rights.  The Munduruku people of the middle Tapajós river, a southern tributary of the Amazon, provide the most iconic example of counter-mapping. The auto-demarcation of their ancestral Sawre Muybu territory is part of a wider Munduruku political movement Ipereğ Ayũ against dam construction and industrial mining on their land. Neighbouring riverine peasants who self-identify as “the Beiradeiros,” are counter-mapping their community of Montanha-Mangabal to resist land grabbing, illegal mining and logging. The Beiradeiros and the Munduruku have passed from being enemies to allies through joint political action against major proposed hydroelectric projects and now work together to auto-demarcate their respective territories. But can counter-mapping really liberate these communities? Research on counter-mapping in Nicaragua and Belize in the 1990s and 2000s shows it did result in the recognition of indigenous land rights. But land can’t fix everything. Even reclaiming their land couldn’t free indigenous peoples from colonial social relations. State-indigenous relationships continued to be oriented around property rights, the basis of modern politics.  Counter-mapping can also be ineffective. In the Chaco region of Bolivia, years of stalled land titling led some Guaraní indigenous people to give up on state recognition of their territory. Instead, they signed an agreement with Repsol, a Spanish oil company, which acknowledged their property rights. Despite this having no legal standing in Bolivian law, the Guaraní saw an agreement with an oil company as better than a state land title. In central Brazilian Amazonia, however, auto-demarcation has in some cases forced the government to act. For instance, the Munduruku have gained official recognition of their territory, Sawre Muybu. Auto-demarcation then can be understood as a combative form of dialogue with the state, of struggle for access to territorial rights, much more than just the materialisation of these rights.  The indigenous peoples of the middle and lower Tapajós are now considering the links between their struggles and those of the Zapatista movement in southern Mexico, where auto-demarcation was used as part of reclaiming their sovereignty.  The degree of political agency and empowerment that Amazonian forest peoples acquire through the process of auto-demarcation is striking. Independent of whether it leads to state action and guarantees of territory, this is an important achievement."
"
Share this...FacebookTwitterOnline weather site www.wetter24.de here today writes about the devastating Heinrichflut (Heinrich Flood) of 1965, back when CO2 was only 320 ppm, well below the often claimed “safe” level of 350 ppm that some alarmists like to have us think would bring us much less extreme weather.
Worst flood in the region’s collective memory
In 1965 the spring and early summer had been cool and wet. In the early afternoon on Friday July 16, 1965, in the central German region between Paderborn, Kassel and Gottingen, the skies darkened quickly and torrential rains fell. Within a matter of hours large areas became submerged under water. Rivers and streams swelled and swept houses, livestock and property away. 16 people were killed. It was the worst flood in the region’s centuries-long collective memory. Had the storm hit during the night, the loss of life would have been far worse, experts say.
The following aerial photos were taken the next day and show the aftermath of the July 16 flood:

Bad Karlshafen. Source: here.

Eberschutz. Source: here.

Imarshausen. Source: here.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





 Karlshafen. Source: here.
Cold air trough formed between two air masses
What caused the freak weather of 1965?
According to Wikipedia in mid July 1965 a mass of warm air flowed northwards from the subtropics and collided with cold Arctic air flowing down from Scandinavia. On the backside of the warm air mass over northern France a so-called cold air trough formed and led to the warm becoming completely surrounded by the cold air. The warm air lifted above the cold air mass, leading to severe thunderstorms and torrential precipitation. The region’s hilly terrain and river valleys served to exacerbate the situation.
200 mm in 24 hours
In an area between Paderborn and Kassel and Fritzlar precipitation amounts of 100 mm fell in just 2 hours. In other areas between July 14 and July 17 up to 200 mm of rain fell in 72 hours. In Dalheim alone over 200 mm fell in 24 hours.
What does all this mean? It means that freak weather events are also common in times of low atmospheric CO2 concentrations and “global cooling”. It all gets down to weather and not climate. Weather catastrophes are not going to be prevented by practicing “green” rituals and CO2 voodoo.
Despite alarmist claims that weather extremes are becoming more frequent, objective observers see no trend change in extreme weather events in Germany or world wide.
Sources:
https://de.wikipedia.org/wiki/Heinrichsflut
http://www.wasserverband-diemel.de/historisch.php
https://www.youtube.com/watch?v=8b9Y8YyOd1E 
Share this...FacebookTwitter "
"You will not be surprised to learn that the climate crisis is a big and complicated problem. But when I started Not Cool, a Climate Podcast, I honestly hoped that if I could just talk with a few climate experts, we could clarify the facts and outline straightforward solutions. Thirty-one experts and 26 interviews later, I realize how mistaken I was, with more questions now than when I started. But I’ve also learned some amazing facts about how nature works, how humans work, and how to start addressing this crisis.  Zoning laws might seem inconsequential, but they can also save lives. The deadly fire in Paradise, California, and the flooding from Hurricane Harvey were as much about lax zoning laws as they were about extreme events caused by climate breakdown. Regardless of how quickly we bring down our emissions, we have some warming already locked in, which means there will be more fires, hurricanes and rising sea levels. Zoning laws help people stay safe in more extreme and frequent disasters. Integral to our zoning laws are the building materials we use. Cement, for example, accounts for approximately 8-10% of all global carbon emissions. Roughly half of those emissions come from the carbon removed during the process of making cement, while the other half result from the energy required to make cement. Steel poses similar problems. Ironically, these carbon-emitting materials are often used in climate change adaptation solutions like sea walls. Fortunately, nature provides incredible tools for addressing and adapting to climate change. Mangroves – essentially forests that grow along coastlines – are near magical solutions that came up in multiple interviews. They help prevent erosion and protect coastal regions from waves and rising sea levels. The trees are a haven for biodiversity, which could be partly why coral reefs seem to thrive in their presence. And mangroves also sequester a lot of carbon, which can help address both global heating and ocean acidification – an effect of the increased carbon in the oceans. Our oceans take in a shocking amount of carbon – about 25% to 30% of all emissions. We can thank our oceans for ensuring that climate breakdown isn’t worse, but that also means that ocean acidification is a huge problem, especially in polar regions where the colder water absorbs more gas. Though some people hope technical solutions like geoengineering could help address global heating, these won’t help ocean acidification. There are two types of geoengineering, more accurately known as climate engineering. One highly contentious method involves injecting particulates, such as sulfur aerosols, into the sky to minimize solar radiation and decrease temperatures. The problem with this approach is that if countries disagree about optimal global temperatures, we can’t just suddenly stop the geoengineering systems, as this would cause global temperatures to rise quickly and dramatically. But if left unaddressed, serious international disagreement could lead to war. The other – far less contentious – geoengineering option involves pulling carbon out of the atmosphere. Though technologies for this exist, they’re not yet affordable or scaleable. But nature could again help here, as more forests could absorb more carbon, cooling the Earth. The Amazon rainforest is not the world’s lungs; it’s our sweat glands. Most of the oxygen we breathe actually comes from marine organisms like phytoplankton (another reason to be grateful for oceans). Instead, forests are useful because they pull moisture from the soil and expel it through their leaves, cooling the Earth just as sweat cools our bodies. So not only are forests vitally important for reabsorbing the carbon we emit, they also decrease temperatures. Unfortunately, many forests – especially the Amazon – face deforestation. Some researchers fear that if even 25% to 30% of the Amazon rainforest is cut down, the loss of moisture could change its basic makeup, transforming it from a rainforest to a savanna. This threat remains speculative, but is it possible we’ve already passed other critical tipping points? Climate systems like to be in equilibrium. If we push them out of equilibrium, past their tipping points, we could trigger feedback loops and exacerbate global warming. For the most part, these are considered future threats, so it was disconcerting to learn that we may have already tipped the West Antarctic Ice Sheet into a state of irreversible melting. If that’s the case, we can expect ocean levels to rise even more than predicted with current warming levels. On the other hand, many of the experts I spoke with also hope we may be on the verge of a human tipping point. As many pointed out, past cultural shifts happened slowly, then suddenly. If climate crisis awareness and concern increase at their current pace, we may yet be able to make the changes necessary to ward off the worst climate threats. Perhaps one sign that we’re nearing a human tipping point is the incredible scientific consensus surrounding climate change. I didn’t formerly care that 97% of climate scientists agree about climate change. I cared about the actual scientific studies that clearly show the Earth is warming. But consensus is more relevant than I realized. First, this level of scientific consensus doesn’t occur unless the science is really robust. Second, most people don’t have time to read all of the science. They have to put their trust in experts, and when 97% of experts say something is true, the public typically listens. The problem is that many people don’t realize how strong climate consensus is. Talking about the climate crisis can have a powerful impact. Just talking more can help address confusion about climate facts and help us all realize that public consensus regarding climate change is quite broad. This doesn’t mean quoting climate science to your conservative uncle at a holiday dinner. You could have a conversation about the money you saved by getting an electric car or bike, or that you want solar panels because they make you more self-sufficient and will save you money in the long run. Looking for another easy way to address the climate emergency? Talk to your bank. Many banks help fund the fossil fuel industry, and if yours is doing so, you can switch to a bank or credit union that doesn’t. As an individual, you can and should vote – but while we wait for better climate policies, moving your money could be one of the most impactful actions you can take to de-fund the fossil fuel industry. Fun statistic: people are more likely to leave their spouse than their banks. Perhaps the most important thing to know about the climate crisis is that solutions exist. It is political will we lack. Many people worry about convincing climate deniers that climate breakdown is real, but deniers make up a very small percentage of the population. Our real focus should be on convincing those in power that the majority of us want to see strong political action. That happens when we talk to each other, when we talk to our representatives, and when we talk to our financial institutions. Individual climate action is critical, but this is ultimately a societal problem, and the solution must be societal as well. Ariel Conn is the host of Not Cool, a Climate Podcast, the former director of communications and outreach for the Future of Life Institute, and the founder of Mag10 Media, an organization dedicated to improving science communication"
"As four reactors at the Fukushima Daiichi Nuclear Power plant suffered catastrophic cooling failures and exploded in March 2011, the world watched in disbelief. For Japan, this was not just the greatest nuclear disaster since Chernobyl. It was “the most severe crisis … since World War II.”  Five years on, the nation continues to struggle with the effects. Towns up to 40km from the plant remain a dead-zone: desolate and uninhabited. As many as 100,000 people still remain displaced, unable to return to their homes. Workers at the Tokyo Electric Power Company (TEPCO) still don claustrophobic masks and rubber suits to venture into the Fukushima facility. Their job is to decommission the plant safely, a task that plant manager Akira Ono recently said was “about 10% complete”. The task is beset with setbacks and spiralling costs. In December 2011 the government estimated that managing Fukushima would cost US$50 billion. By 2014 this had nearly doubled to include US$19 billion to decommission the Fukushima plant; US$22 billion to decontaminate the surrounding area; US$9 billion to build temporary storage facilities for nuclear waste; and US$43 billion to compensate the victims. Today even this looks hopelessly optimistic.  Fukushima is now the biggest civil liability case in history. More than two million people have sued TEPCO and US$50 billion has already been paid out. This is already equivalent to 49 Exxon Valdez oil spill settlements, and experts predict the total cost of compensation could rise to US$120 billion.  One notable subplot has been compensation for cases of suicide. A court’s landmark decision that TEPCO pay US$470,000 to the heirs of a 58-year-old farmer’s wife named Hamako Watanabe could prove much more costly. The Watanabe family were evacuated from the village of Yamakiya in April 2011, losing their farm and leaving them with a US$140,000 mortgage on their now uninhabitable home. Watanabe became severely depressed and during an authorised one-night visit to their home in June the same year, she burned herself to death.  Other bereaved families have also come forward. Two similar cases are now underway, and the Japanese government anticipates that as many as 56 suicides could be tied to the disaster. And this looks conservative: the NHK broadcasting service has put the number at 130. What is certain is that the number is rising. A further 19 evacuees took their lives in 2015 and there is no reason to believe 2016 will be any different.  Officially the buck for everything stops with TEPCO. Under Japanese nuclear-liability law, the nuclear operator is responsible for the full cost of an accident, even if it is not proven to be negligent. In practice, the Japanese taxpayer is bearing most of the burden. TEPCO’s liability may be unlimited, but its assets are not. Despite the country’s seismic history, TEPCO’s private insurance policy did not cover earthquakes or tsunamis. And in accordance with regulations introduced in 2009, TEPCO was insured through private policies and state indemnities for up to only US$1.1 billion: about a fiftieth of the damages paid out so far.  The government has been forced to prevent TEPCO’s bankruptcy – over and above all of its other Fukushima-related outgoings. It has bought a majority share and has continued to finance compensation payments through a series of indemnity agreements and loans in the form of government compensation bonds. The state has also enacted retroactive legal guidelines that obligate other power companies and financial institutions to contribute to the compensation effort.  One has to ask whether the concept of unlimited liability has any real meaning when the operator’s capacity to pay is so limited. It also raises questions for other parts of the world. In the UK, for example, nuclear liability is capped at a mere US$220m, less than two hundredths of what TEPCO has already paid in compensation claims. Japan is evidently not the only country that should be taking lessons from Fukushima. The article originally said that the TEPCO payouts to date are 400 times that of Exxon Valdez, as opposed to 49. It also said that the dead zone around the plant was 10km, but now says 40km."
"As urbanisation and modernisation reach unprecedented levels, road congestion has become a modern day menace. Heavy traffic is associated with air pollution, safety risks, and losses in terms of accessibility, economic competitiveness, sustainable growth and social cohesion. If we are determined to make our cities attractive and sustainable, we must respond to these challenges.  There are a number of measures available to address this problem; either by restricting conventional car use, or providing viable alternatives. None of these solutions is more up-and-coming and marketable right now than the shared use of mobility resources – for example, car sharing. And none of them more environmentally friendly than cycling, which more and more people see as a realistic way of making shorter trips.  Put these two together, and you get bike sharing: an innovation that combines the best qualities of both solutions, while extending the reach and scope of public transport. To be clear, bike sharing refers to rental schemes, whereby civilians can pick up, ride and drop off bicycles at numerous points across the city – usually at automated stations.  The benefits of bike sharing schemes include transport flexibility, reductions to vehicle emissions, health benefits, reduced congestion and fuel consumption, and financial savings for individuals.  But the most special quality of public bicycles is the idea of sharing. By sharing with others through a publicly available scheme, individuals can use bicycles on an “as-needed” basis, without the costs and responsibilities associated with ownership. In doing so, these schemes allow people who may not otherwise use bicycles, to enjoy the benefits of cycling; whether they’re tourists or locals.  Bike sharing schemes can also act as a door opener for increased bicycle use, by making a strong visual statement that bicycles do belong to a city’s streets. According to my research, commuters using on-road transport can see bike sharing as a powerful on-street “cycling promotion campaign”.  What’s more, other studies report that cycling increased in cities which implemented bike sharing schemes, noting that these results reflect the combined impact of improvements to cycling facilities, as well as the provision of bike sharing schemes. Some go even further by suggesting that the introduction of bike sharing systems can cause cycling to be seen as a safe and normal mode of transport, in contexts where it’s not common. Bike sharing is a concept originating back to the 1960s. However, it was slow to catch on until better technology was developed, which could provide real-time information about the scheme, track the bikes and help safeguard against theft.  Now, bike sharing is booming at an unprecedented rate, largely due to the reasonably low cost of the schemes, and how easy they are to implement compared with other transport infrastructure. And it’s an easy win for governments and urban societies, which can boost their green credentials by embracing such an environmentally friendly design.  In 2004, only 11 cities had adopted bike sharing. Today, more than 1,000 public bicycle schemes of varying sizes and specifications run in more than 50 countries, across five continents.  Europe’s biggest scheme is the Paris Vélib’, with 1,800 stations and more than 20,000 bikes. Hangzhou, China hosts the world’s largest system – three times bigger than Vélib’ – which is set to expand to 175,000 bikes by 2020. Perhaps the most sophisticated scheme is Copenhagen’s Bycyklen, which has a fleet of electric bicycles featuring weather resistant tablets with GPS. According to recent research into Gothenburg’s Styr & Ställ scheme, if bike sharing is properly promoted, the general population of the city feels that such schemes offer a pro-environmental, inexpensive and healthy mode of transport. In particular, they were seen to complement the city’s public transport services, and give the city a more human-friendly feel. But research and experience tell us that there can be problems with bike sharing. For example, although the usage rate of these schemes tends to vary globally between three and eight trips per bicycle per day, some facilitate as few as 0.3 trips per bicycle per day.  Apart from under use, schemes can also prove slow to expand, or come up against sluggish and complicated planning procedures. They can create political friction, too, if local authorities are unwilling to forsake street parking spaces for bike stations. Strict cycling regulations can also be a roadblock: in both Melbourne and Brisbane, Australia, compulsory helmets were found to deter many potential riders. Safety concerns and a lack of cycling infrastructure – such as bike lanes – were also found to affect uptake. Despite these difficulties, bike sharing schemes are, on the whole, a win for everyone. Rebranding something as conventional as urban cycling in a way that embraces the philosophy of shared resource economies and is well accepted by the public, is a timely investment for actively promoting sustainable transportation. Cities that come up with strong and coherent plans will find that recognisable bike sharing schemes can form a powerful and positive part of their image. Meanwhile, civilians of all stripes stand to benefit from clearer roads and cleaner air – whether they cycle or not."
"There is an invidious strain of centrism in Australian media and politics that is one of the most powerful forces against effective action on climate change. It is a strain that has become more virulent in response to protests by Extinction Rebellion and the raised voices of those who care not to genuflect to the systems that have led us to the current crisis.  It is a strain that conservatives use to their advantage. Two weeks ago, as New South Wales and parts of Queensland burned, the prime minister was at pains to argue that now was not the time to talk about climate change. And the centrists agreed. This week Scott Morrison was ready to talk about climate change and he had the script all prepared. Morrison told the ABC’s Sabra Lane that “the suggestion that any way, shape or form with Australia accountable for 1.3% of the world’s emissions, that the individual actions of Australia are impacting directly on specific fire events, whether it’s here or anywhere else in the world, that doesn’t bear up to credible scientific evidence either”. It’s a line straight out of the climate-change denial playbook. No one is suggesting if we had a price on carbon there would be fewer bushfires, or it alone would significantly reduce global temperatures, but that does not mean Australia cannot make a difference. Only on climate change do you ever hear conservatives argue we are powerless. Our economy is only around 1.5% of the world’s total GDP and yet we have no qualms in going to the G20 every year and pushing our agenda. But on climate change? Sorry, we are impotent. Except we’re not. We are the 15th biggest emitter in the world, the biggest on a per capita basis among advanced economies. We have massive power, because we are wealthy enough to show what can be done. If we do nothing, it becomes a strong reason for anyone who emits less than us either in total or per capita to do the same. And the problem is we are using what power we have to obstruct action on climate change. Morrison argued that “if anything, Australia is an overachiever on our commitments, on global commitments, and for 2030, we will meet those as well with the mechanisms that we’ve put in place and we’ll ensure we do achieve that”. What utter tosh. Our Kyoto commitment is based on the dodgy counting of land use; and our commitment to Paris targets doubles down on that dodginess by using carry-over credits from the Kyoto target – something nations such as the UK are now fighting hard to have removed. Our target is also well below what scientists say is needed to keep temperature rises below 1.5C. Thirteen months ago the UN issued a report that concluded we have 12 years to do something to limit climate change, after which it will be too late to keep the rise in temperatures below 1.5C. The science has not changed in that time; all that has is we now have only 11 years. But this week it was reported that fossil fuel production by 2030 is set to be double that which is needed to keep temperature rises below 1.5C. We are failing, and Australia’s own policy is ensuring that failure will continue. But heck, pointing that out will seem biased, and so the centrist looks for a chance to appear balanced. It is why they have grabbed onto the disruption of Extinction Rebellion and loud claims by the Greens – because the centrist loves nothing more than being able to tell both sides to calm down. A clear example of this came this week from former ALP cabinet minister Craig Emerson, who wrote an opinion piece in the AFR denouncing tribalism that he argues is killing civil discourse. In it he suggested that “national socialism is resurgent. But so is international green socialism – a variant of white supremacism”. Yes, nothing like suggesting sections of the environmental movement are racists to get that civil discourse going. Emerson suggested this white supremacism occurred when “well-off greens demand the races of Asia and Africa forgo economic development using fossil fuels to rectify the sins we white, affluent humans have inflicted on the planet”. Yes “the races” of Asia and Africa. Emerson didn’t help his case against tribalism by spending most of the week on Twitter berating Greens supporters and suggesting the ALP was the only major party doing anything good on climate change (if the ALP isn’t the biggest force of tribalism in Australian politics, I clearly need to invest in a new dictionary). He further weakened his cause by suggesting that people were arguing that poorer nations needed to shift immediately to 100% renewable energy. No organisation or person of any note is arguing this (although Emerson did find a random person on Twitter). But worse, this argument that fossil fuels help poorer nations is a retread of the old argument that “coal is good for humanity” that Tony Abbott was pushing in 2014, and which was easily debunked at the time. It was the same argument that saw coal mining companies argue to leaders of the G20 that coal was needed because the WHO had reported that 4 million people die prematurely from household air pollution because “nearly 3 billion people use primitive stoves to burn wood or biomass to cook and heat homes”. Except what the WHO actually noted was that “around 3 billion people cook using polluting open fires or simple stoves fuelled by kerosene, biomass and coal”. And yet Emerson’s article, which pushed specious arguments about demands for immediate change to renewables, which likened sections of the environmentalist movement to white supremacists, and which echoed lines from mining companies was met with gushing praise from some very senior journalists. That’s because the column called for calm and reason, and centrists love calm and reason and love even more to praise anyone calling for it. And so in the space of five years we went from an argument pushed by Tony Abbott and mining companies to encourage more coal mines being shown to be clearly fallacious to it now being praised as part of a reasonable approach. This is because centrists care more about being seen to be neutral than whether that neutrality is worthy, or worrying if the centre has moved. It is the force that has journalists and politicians arguing that we should not make the perfect the enemy of the good, and yet spending little time examining how good something has to be before the perfect becomes its enemy. Not all extremism is equal and no force of social or economic change happened due to people refusing to make waves. It happened because people were prepared to go to prison, be attacked, and seek to disrupt those who would go about their lives ignoring the issue. Centrists love the final vote that sees change occur – where politicians from both sides sit together and agree; they care only in retrospect for the work, suffering and effort over decades that leads to that change. And they ignore that throughout those decades, the powerful in the media and politics actively prevented change occurring by spending more time calling for calm and reason than noting reality. And so long as powerful journalists believe that arguments are worthy purely because they call for a middle ground, then ever will they be a force that prevents effective action on climate change. Greg Jericho is a columnist for Guardian Australia"
"Bluetongue disease, a virus which attacks sheep and cattle, has broken out in France, leading to fears that some time this year infected midges are likely to be blown across the channel and bring the disease to the UK, according to a recent government report.  By mid-February 184 farms had been infected throughout France. A 150km restriction zone has been thrown up around them in an attempt to control the disease. It’s easy to see why – northern Europe’s most recent outbreak between 2006 and 2010 caused an economic loss of hundreds of millions of pounds while more than 2m sheep across Europe have died since 1998 as a direct or indirect consequence of bluetongue.  Just as malaria is carried from human to human by infected mosquitoes, bluetongue is transmitted from animal to animal by female biting midges. The virus mainly affects sheep, goats, cattle and deer – it doesn’t do anything to humans.  The name bluetongue was given for the characteristic swollen and blue-purple coloured tongue in infected animals, especially sheep. However, this is a rare feature and most don’t actually get a blue tongue at all. More common symptoms include fever, low milk production, haemorrhages, mouth and nasal ulcers and problems with reproduction. In previous European outbreaks nearly half of the infected sheep died from the disease, while mortality rates in some sheep breeds can be up to 70%. Meanwhile cattle often carry the virus without actually suffering from any of the symptoms. Cows can be the perfect invisible source of a bluetongue outbreak within a farm. Bluetongue virus is widespread in the Americas, southern Asia, northern Australia, Africa and Europe. As with all other viruses, bluetongue is constantly mutating. Of the 27 different genetic forms (called serotypes) only one has caused large outbreaks in northern Europe: bluetongue serotype 8.   Serotype 8 emerged across northern Europe from France to Germany in 2006, 550km from previous outbreaks in Italy and Spain, and reached the UK the following year. A large vaccination programme eventually got things under control and by 2012 northern Europe was once again declared free of bluetongue. It remained that way until August 2015. The latest outbreak was first reported around Louroux-de-Bouble, a village in one of the major cattle areas in the centre of France. In total 27 cattle and 6 sheep were found to be infected. French authorities deployed a 150km control zone around the infected farm and started localised vaccinations.   It’s thought unlikely that this will stop the spread of bluetongue. While the majority of today’s infected farms are concentrated to the south of the first infection, the latest – reported on February 10 – was found 200km to the north. If bluetongue keeps spreading northwards, aided by the mild midge-friendly winter, and arrives in the farms along France’s north coast later this year then there is a very good chance it will jump across the English channel and British livestock will become infected. A UK government report says there’s a 60-80% likelihood this will happen by the end of summer. Midges can be carried downwind for long distances – comfortably far enough to cross the channel, which narrows to just 30km (20 miles) at the strait of Dover. Infected midge-blowing is probably what caused the UK’s 2007 bluetongue outbreak and the 2012 outbreak of Schmallenbertg, another livestock disease transmitted in the same way.   Bluetongue can also be introduced through the movement of live animals  or through infected semen and embryos, but these are legally restricted and therefore the risk is very low. Wild boar, deer and other wildlife act as “reservoirs” for the disease, periodically passing it on to midges, and thus back into livestock. The most dangerous and unpredictable way for the disease to spread uncontrollably remains the combination of midges and infected wildlife.  The control zones we currently have aren’t enough. They’re supposed to contain bluetongue outbreaks through restricting animal movements, vaccination and surveillance – yet the effectiveness of these zones has never been evaluated, so each country responds in different ways. The exact source of this latest infection is unknown – often the case with bluetongue outbreaks – which makes it more difficult to predict the development of the disease. In the UK, vaccine production was stopped after northern Europe was declared bluetongue-free in 2012, so supplies are very limited.  Yet vaccination is the only way to stop the spread of the disease. Models show that to prevent an outbreak, at least two-thirds of the farms at risk must be vaccinated in a relatively short time. At the moment negotiations are in place to produce enough vaccine for Britain’s sheep and cows. This is going to be expensive. Farmers need more support and EU or national governments should subsidise part of the cost where necessary. Environmental and animal agencies should also look out for infected midges and infected wild animals along the south coast – catching a British bluetongue outbreak as soon as possible will determine how quickly and successfully it can be controlled."
"Imagine you are the government’s Minister for Transport: the economy is prospering, global oil prices are falling, and airlines are ordering hundreds of new airliners and investing in infrastructure in order to expand their flight networks. Tourism and the service industry are booming, and the public appetite for cheap air travel appears insatiable. But your government also is committed to radically reducing the greenhouse gas emissions, such as carbon dioxide, that cause climate change.  It’s an obligation that has huge implications for all sectors of the economy – none more so than the energy-intense transport sector, and particularly aviation. Can technological advances and engineering offer a means to have your cake and eat it? To cut emissions while not interfering with the economic and employment boom generated by the industry – not to mention how popular cheap air travel is with voters. While the airline industry is quick to reassure that technical solutions, such as improved materials, engines and biofuels, and market-based measures can provide a fix, our research has found these to be examples of “technology myths”.  Most Ministers for Transport would take the low-risk option of the promise of technocratic and market approaches to the problem tomorrow rather than take more direct action today. Industry promises and reassurances offer time to address the attractive opportunities provided by greater mobility and economic growth. Both are key government objectives. The reality of the effects of rising aviation industry emissions on climate change has been known for decades, yet the industry and its emissions has continued to grow without constraint. Aviation emissions proved too contentious to be dealt with under the Kyoto Protocol, and the European Union’s efforts to bring international, non-European aviation emissions into the EU Emissions Trading Scheme were blocked by the industry. Published in the journal Transportation Research Part D, our study sheds some light on the “promise” of technical solutions through a 20-year examination of how they were reported in the media and the extent to which they were subsequently implemented. We found that new airline industry technology, including airframe, engine and alternative fuel breakthroughs, have been consistently presented by the industry as essential to building an ecologically sustainable aviation industry.  But the discussion of them continues to give credence to the myth of zero-emission flight – shielding the industry from closer scrutiny of its efforts to meet emission targets and improve sustainability practices. The clearest examples of such myths are solar and electric flight. Last summer, the Solar Impulse 2 solar-powered aircraft attempted to fly around the world. This single-seat aircraft required enough solar cells to cover a wingspan the size of a 500-seater Boeing 747 airliner to generate enough power even to carry its single pilot aloft. Even those involved in the project admit it will never replace current air transportation. Electric flight is equally problematic, as it requires a 15-fold increase in the energy density of lithium batteries (power supplied by weight of battery) in order for commercial flight to become possible. While some industry experts claim that this is not beyond the realm of possibility, it’s unlikely to arrive before 2035, and even then a very long aircraft development and fleet replacement process would follow. All this is far too late to avoid dangerous climate change. The more viable option of replacing aviation kerosene with biofuels also comes with caveats. The most efficient biofuels reduce CO2 emissions by up to 90%, but are inefficient to store and create land use competition with agriculture for crops. Others are more space efficient, but unable to deliver net energy (the energy content of the produced kerosene is lower then the energy required to turn the feedstock into kerosene).  The cost of biofuels is also underestimated. For example, a recent Independent Transport Commission (ITC) report to the UK government recommended that carbon emissions need not be a show-stopper for further development of Heathrow and Gatwick airports. The report’s claim that biofuels will be commercially viable is reached by comparing the cost of ready-to-use aviation kerosene with the cost of existing biofuel feed stocks such as wood pulp and palm oil. But this is not a useful comparison because no aircraft will ever be able to leave the runway on pure palm oil alone, but must run a blend of fuels. At the same time, the report states that CO2 emissions are likely to be mitigated by a 1.6% annual improvement in fuel efficiency and operations – conveniently ignoring the fact that the volume of air traffic continues to grow at 5% each year. The fact remains that aviation, a steadily growing and polluting industry, remains outside major climate agreements such as those agreed at the Paris COP21 conference last year. The myth of sustainable aviation remains intact, and the industry ducks regulation once more."
"Tree planting is suddenly the zeitgeist. Tabloid newspapers, utility companies and oil corporations are pledging to plant trees by the million, in some cases before Christmas. Even the Brexit party is on to it. The Woodland Trust has launched its “big climate fightback”. This Thursday, on Channel 5, Chris Packham and John Humphrys host Plant a Tree to Save the World. It’s not as catchy as Plant a Tree in ’73, the last time tree planting genuinely caught the public imagination. Then, the government launched a national tree planting campaign as a response to Dutch elm disease. Today, NGOs and businesses are leading the way while successive, recent governments have made unambitious pledges, which they have failed to keep. There is no national tree planting strategy in England. It is shameful. Meanwhile, we are losing ash trees by the million to ash dieback.  In July, Ethiopia began a huge nationwide strategy in which 350m trees were planted in one day (at current rates in England and Wales, this would take us 140 years). In 2017, 1.5 million Indian volunteers planted 66m trees in 12 hours in Madhya Pradesh. The government in New Zealand launched a plan to plant a billion trees by 2027 (including 83m this year). In Pakistan, the programme to plant a billion trees to combat the effects of climate change was completed ahead of schedule in 2017. Their new target is 10bn trees. I will plant trees on the edge of my small woodland in the Black Mountains this week – birch, aspen, field maple and a dozen tiny oaks that I grew from acorns – as I have done every year for a decade and a half. In the community woodland I help manage, we’ll continue to plant diverse species under the ash we expect to lose. My neighbour, Keith Powell, is finalising plans to plant 175,000 broadleaf trees on the upland common behind our homes. Trees give life. It’s hard to overstate their benefit. They are fundamental to our rural and urban landscapes, our lives and the future of this planet. Trees reduce soil degradation on farms, provide vital habitat for wildlife, supply us with food, heat and medicine, safeguard water quality, give shade, build biodiversity and create spaces to walk lightly and breathe deeply in our cities. Trees diminish flood risk, improve air quality by absorbing pollution and yield a renewable resource in the form of timber. Most importantly, in the climate emergency, trees sequester carbon. They absorb carbon dioxide from the atmosphere, storing it in their trunks, branches and roots, before releasing oxygen back into the air. Trees mitigate climate change and tree planting is now recognised as one of the best ways to tackle this global crisis. Some of the trees I planted 15 years ago are nearly 10 metres tall. Watching them grow and turn with the seasons reminds me that time passes, which encourages me to live as well as I can. I won’t be around to see most of these trees reach maturity, but that is the point: if you take the trouble to plant trees now, someone may walk through your woodland or down your street a century or more into the future and think well of you, even though they don’t know your name. Planting a tree is also, for me, a simple act of faith. As the American poet W S Merwin wrote: “On the last day of the world I would want to plant a tree.” We have to engage, as families and schools, as communities and as a nation, on fixing the future. We cannot wait for the government to lead on tree planting. We have to do it ourselves. And the time is now. Rob Penn is the author of The Man Who Made Things Out of Trees"
"Bedbugs have a lousy reputation at the best of times, but these unfortunate insects have taken a particularly firm kicking recently. An announcement that their genome had been sequenced was framed not as a remarkable scientific accomplishment but as useful information to help us humans destroy our enemies. It’s not hard to see where the animosity comes from. Though bedbugs – known to scientists as Cimex lectularius – will feed on bats, chickens and domesticated animals, it is their taste for human blood that causes problems. After widespread DDT usage largely wiped them out in the mid-20th century they have made a strong return in recent years, with many becoming resistant to modern pesticides.  The bedbug problem is getting worse. Infestation horror stories have popped up in most major cities and a pest control team was even asked recently to exterminate bedbugs on an offshore oil rig. We tend to associate bedbugs with dirty living conditions, but this is a myth – they don’t actually choose dirty homes over clean ones. Unusually for many blood-sucking insects, bed bugs haven’t (yet) been implicated in spreading disease to the humans they bite, so that’s one small thing in their favour, though they are suspected of carrying organisms that cause leprosy, oriental sore and the bacterial brucellosis, and may be able to transmit Chagas disease. So can we defend these bugs, or is insecticide the only solution? Bedbugs suck blood, which contains the DNA of people they fed on. Human DNA extracted from live, frozen and dried bedbugs has proven suitable for DNA profiling. Some scientists say we could therefore use the bugs as a source of evidence to prove a particular person had been in a bedroom. Cimex are also wingless and don’t stay on their hosts after feeding. They tend to remain near the source of food though, so unlike other blood-feeders such as mosquitoes or black flies they can be present at a crime scene long after the perpetrator has fled. Bedbugs are highly specialised for what they do. Like other Hemiptera (true bugs) their mouthparts are specially adapted to suck liquids, using needle like mandibles and maxillae to form hollow tubes, complete with pumps for saliva and suction. The saliva they inject prevents blood from clotting as they feed and in their gut, and their abdomens expand to allow them to feast on larger meals. All these features are a product of natural selection – and bedbugs are still changing, fast.  Then there is winglessness, which often evolves in species where flight is either too expensive in terms of energy, unnecessary in the absence of predators, or too risky in terms of living on a windy island. Many insects have short winged or wingless forms, but most of them have winged relatives, suggesting that once wings were present and functional. In fact, a close look at Cimex shows that it still has tiny front wings. Add to this host-seeking ability and rapid evolution of resistance to insecticides, and the bedbug becomes a useful model organism for scientific investigation. Our need to understand a rapidly evolving species drove the complete bedbug genome sequencing. Among other things, scientists discovered the common bedbug split from those that feed on bats about a quarter of a million years ago, which means bedbugs predate modern humans by about 45,000 years. This may be an example of speciation in progress.  Our ancestors likely first associated with these nocturnal feeders while seeking shelter in caves. So bed bugs can tell us something about human history. They were certainly biting ancient Egyptians, and Roman scholar Pliny mentioned them in 77AD. It was the Romans who called them “Cimex”, which means bug, and they were recommended to treat ear infections and snake bites. The genome research also shows how bedbugs have adapted to rely on a bacterial parasite called Wolbachia, that lives inside the bug’s guts and helps them conjure vital vitamins out of their blood only diet.  Thanks to bedbug research we now know a lot more about the genes that confer pesticide resistance, which may lead to new insecticides useful for the control of this and other species. Pests and pesticide resistance are in constant battle and a reminder of the resilience of species to survive. Bedbugs and other household pests could even be regarded as advantageous to the economy in that they keep people in work. More than 1,000 pest control companies provide employment in the UK alone, part of an annual market worth about £330m. Then there are the chemical firms manufacturing pesticides, companies that make vacuum cleaners, washing powders and (as a last resort) new mattresses. So sleep tight, and if the bedbugs do bite, think about their contribution to forensic entomology, evolution and the economy."
"As the world grapples with climate change, we urgently need to find ways of reducing our CO₂ emissions. Sectors which rely heavily on fossil fuels, such as energy and aviation, are commonly held to be the worst offenders. But what most people don’t realise is that there’s another culprit, hiding in plain sight; on the streets of our cities, and in the buildings where we live and work.  In 2007 alone, steel and concrete were each responsible for more CO₂ emissions than the entire global aviation industry. Before reaching the construction site, both steel and cement must be processed at very high temperatures – and this takes a lot of energy. So how can we reduce our dependence on these “dirty” materials, when they play such a crucial role in construction? One option is to use natural materials, such as wood. Humans have been building with wood for thousands of years, and wooden structures are currently experiencing a minor resurgence – partly because it’s a cheap and sustainable material.  But there are some disadvantages to building with wood; the material can warp in humid conditions, and is susceptible to attack by pests such as termites. And while natural materials, such as wood, are appealing from an environmental perspective, they can be unsatisfying for engineers who might wish to make components in a specific shape or size. So what if, instead of using natural materials as we find them, we make new materials that are inspired by nature? This idea started to gain traction in the research community in the 1970s and really exploded in the 1990s, with the development of nanotechnology and nanofabrication methods. Today, it forms the basis of a new field of scientific research: namely, “biomimetics” – literally “copying life”.  Biological cells are often referred to as “the building blocks of life”, because they are the smallest units of living matter. But to create a multi-cellular organism like you or me, cells must clump together with a support structure to form the biological materials we’re made of, tissues such as bone, cartilage, and muscle. It’s materials like these, which scientists interested in biomimetics have turned to for inspiration.  In order to make biomimetic materials, we need to have a deep understanding of how natural materials work. We know that natural materials are also “composites”: they are made of multiple different base materials, each with different properties. Composite materials are often lighter than single component materials, such as metals, while still having desirable properties such as stiffness, strength and toughness.  Materials engineers have spent decades measuring the composition, structure and properties of natural materials such as bone and eggshell, so we now have a good understanding of their characteristics.  For instance, we know that bone is composed of hydrated protein and mineral, in almost equal proportions. The mineral confers stiffness and hardness, while the protein confers toughness and resistance to fracture. Although bones can break, it is relatively rare, and they have the benefit of being self-healing – another feature that engineers are trying to bring to biomimetic materials.  Like bone, eggshell is a composite material, but it is around 95% mineral and only 5% hydrated protein. Yet even that small amount of protein is enough to make eggshell very tough, considering its thinness – as most breakfast cooks will have noticed. The next challenge is to turn this knowledge into something solid. There are two ways to mimic natural materials. Either you can mimic the composition of the material itself, or you can copy the process by which the material was made.  Since natural materials are made by living creatures, there are no high temperatures involved in either of these methods. As such, biomimetic materials – let’s call them “neo-bone” and “neo-eggshell” – take much less energy to produce than steel or concrete.  In the laboratory, we have succeeded in making centimetre-scale samples of neo-bone. We do this by preparing different solutions of protein with the components that make bone mineral. A composite neo-bone material is then deposited from these solutions in a biomimetic manner at body temperature. There is no reason that this process – or an improved, faster version of it – couldn’t be scaled up to an industrial level.  Of course, steel and concrete are everywhere, so the way we design and construct buildings is optimised for these materials. To begin using biomimetic materials on a large scale, we’d need to completely rethink our building codes and standards for construction materials. But then, if we want to build future cities in a sustainable way, perhaps a major rethink is exactly what’s needed. The science is still in its infancy, but that doesn’t mean we can’t dream big about the future.  “Biomimetic materials: re-thinking how we build stuff”, a talk by the author, is part of the Cambridge Science Festival."
"The concentration of climate-heating greenhouse gases has hit a record high, according to a report from the UN’s World Meteorological Organization. The jumps in the key gases measured in 2018 were all above the average for the last decade, showing action on the climate emergency to date is having no effect in the atmosphere. The WMO said the gap between targets and reality were both “glaring and growing”. The rise in concentration of greenhouses gases follows inevitably from the continued surge in global emissions, which was described as “brutal news” for 2018. The world’s scientists calculate that emissions must fall by half by 2030 to give a good chance of limiting global heating to 1.5C, beyond which hundreds of millions of people will suffer more heatwaves, droughts, floods and poverty. But Petteri Taalas, the WMO secretary-general, said: “There is no sign of a slowdown, let alone a decline, despite all the commitments under the Paris agreement on climate change. We need to increase the level of ambition for the sake of the future welfare of mankind. “It is worth recalling that the last time the Earth experienced a comparable concentration of carbon dioxide was 3-5m years ago. Back then, the temperature was 2-3C warmer and sea level was 10-20 metres higher than now.” Three-quarters of the emissions cuts pledged by countries under the Paris agreement of 2015 are “totally inadequate”, according to a comprehensive expert analysis published earlier in November, putting the world on a path to climate disaster. Another report has found that nations are on track to produce more than double the fossil fuels in 2030 than could be burned while keeping heating under 1.5C. “The [CO2 concentration] number is the closest thing to a real-world Doomsday Clock, and it’s pushing us ever closer to midnight,” said John Sauven, head of Greenpeace UK. “Our ability to preserve civilisation as we know it, avert the mass extinction of species, and leave a healthy planet to our children depend on us urgently stopping the clock.” The WMO report, published on Monday, found the global average concentration of CO2 reached 407.8 parts per million in 2018, up from 405.5ppm in 2017. It is now 50% higher than in 1750, before the industrial revolution sparked the widespread burning of coal, oil and gas. Since 1990, the increase in greenhouse gas levels has made the heating effect of the atmosphere 43% stronger. Most of that – four-fifths – is caused by CO2. But the concentrations of methane and nitrous oxide, the two other key greenhouse gases, also surged in 2018 by a higher amount than the annual average over the past decade. Methane, which is produced by cattle, rice paddies and fossil fuel exploitation, is responsible for 17% of the heating effect. Its concentration is now more than double pre-industrial levels. Nitrous oxide, which comes from heavy fertiliser use and forest burning, is now 23% higher than in 1750. The observations are made by the Global Atmosphere Watch network, which includes stations in the Arctic, high mountains and tropical islands. “The record rise in greenhouse gas concentrations is a cruel reminder that for all the real progress in clean technology, we have yet to even stop global emissions increases,” said Nick Mabey, chief executive of think tank E3G. “The climate system cannot be negotiated with. Until we stop new investment in fossil fuels and massively scale up green power the risks from catastrophic climate change will continue to rise.” When the world’s nations agreed the Paris deal in 2015, they pledged to ramp up their promised emissions cuts by the annual UN climate summit in 2020, which will be hosted by the UK in Glasgow. This year’s summit needs to do vital preparatory work and begins on 2 December in Madrid, Spain. Chile had been due to host but cancelled because of civil unrest. Richard Black, director of the Energy and Climate Intelligence Unit in the UK, said: “This record level of greenhouse gases should act as a sobering reminder to governments that so far they are collectively reneging on the pledge they made at the Paris summit, of attempting to keep global warming to 1.5C. That window is closing, and Chile, Italy and the UK [must] use all the diplomatic tools they have to put emissions on a trajectory closer to what science recommends and the public want.”"
nan
"
Share this...FacebookTwitterDespite the trillion-dollar campaign aimed at curbing fossil fuels, the use of coal continues to rapidly expand and is acting to finally pull undeveloped countries out of extreme grinding poverty.
Investors Business Daily (IBD) here reports “coal use is surging across the globe“, citing the National Academy of Sciences, which says there’s an “unmistakable coal renaissance under way” and that coal “has again become ‘the most important source of energy-related emissions on the global scale.'”
Hat-tip: AndyG55
The NAS study shows coal use is expanding strongly in poor Asian countries like India and China, mainly because of its high affordability. IBD writes: “In sum, using coal is a stepping stone to prosperity.”
The IBD site adds that 1,200 coal plants are planned across 59 countries, that coal use around the world has grown about four times faster than renewables, and that China’s reliance upon coal will keep growing:
And according to U.S. government projections, China will add yet another U.S. worth of coal plants over the next 10 years, or the equivalent of a new 600-megawatt plant every 10 days for 10 years.”
The IBD blasts the Obama Adminstration’s plan to cut back on coal use in the USA, writing that the President is living in a “dreamland” and that “the rest of the world has no intention of following Mr. Obama’s act of economic masochism” and that the plan “will cost America hundreds of thousands of jobs” and “the poor will be hurt most“.
Strangely despite surging coal consumption, global temperatures have not risen in close to two decades. Consequently the once highly ballyhooed global warming theory is crumbling,
Read more at Investor’s Business Daily.
Share this...FacebookTwitter "
"A year ago, a black scar appeared on the far north Queensland landscape. Satellite images and photographs show the aftermath of a bushfire that burned in world heritage tropical rainforest for 10 days. Almost no one noticed when the Japoon national park caught fire – mature rainforest trees destroyed across about 250 hectares. A single story in a local newspaper, focusing on how the fire started, appears to be the only time it has been reported. Experts and rainforest authorities say the remarkable extent of the damage, across an environment supposed to naturally suppress fires, is among the clearest evidence that climate change has shifted the paradigm in the tropics. “When the rainforest was burning, the first thing we learned was that it can burn,” says Leslie Shirreffs, the chair of the Wet Tropics Management Authority. “The fire came outside from adjacent land, but ordinarily when it came to rainforest it would stop.” Last week the authority released a climate adaptation plan that acknowledged the impacts of climate change on 900,000 hectares of north Queensland tropical rainforest and its ecosystems. The authority has previously said climate change damage to the forest is as bad as coral bleaching on the reef. Shirreffs says the plan takes into account observations made by Indigenous traditional owners, including things such as changing seasonal indicators and rainfall patterns, and changing bird behaviour. The adaptation plan focuses on strategies to help build resilience, such as land restoration to strengthen wildlife corridors, pest control and protective habitat elements that might provide species shelter during climate extremes. Climate threats to the rainforest come in many forms. There is a threat from tropical cyclones, which experts say will increase in intensity and impact due to climate change. Recent extreme heat events are also worrying. Centuries-old heat records were broken in north Queensland last year, including at forest mountain peaks which recorded a six-day run of temperatures above 36C. Some creatures, like the rare lemuroid ringtail possum, are unable to survive when temperatures rise above 29C. “The data now shows that lemuroid ringtail possums and potentially other mountaintop species could become locally extinct, at what was previously their most abundant site, within the coming decade,” Shirreffs says. “When you have a 900,000-hectare world heritage area you assume there’s an inbuilt resilience. But that’s without anticipating some of the extremes that are now happening.” The fire broke out after the forest canopy had already been damaged by two other natural disasters. During the past 15 years the area had been hit by two severe tropical cyclones – Larry and Yasi. Vines that had grown into the cyclone-damaged canopy would carry the fire from the forest floor and into the tops of the trees. The dry season had been unusually long and temperatures were at extreme highs for almost a week. At the same time Queensland experienced its first ever “catastrophic” fire conditions, sparking threats to lives and property that diverted most of the attention elsewhere, while the Japoon national park burned. Shirreffs said it was unclear how the rainforest would respond to the fire damage but there were already some worrying signs, including Siam weed, an invasive plant that has begun growing in the burnt area. “We do see [responding to climate change] as a test and it can be sobering what happens around the place, but the wet tropics is a remarkable place, it’s one of the best managed world heritage areas in the world,” she said. “We have to look at the practices we know make forests stronger and we need to step things up. We need to do some out-of-the-box stuff. We don’t have a lot of power while the world gets its carbon budgets in order, but we need to do things that we can.”"
"The Coalition is too closely linked to the fossil fuel industry to be able to contemplate a future without coal, oil or gas. As climate change-induced crises continue through Australia, they must distance themselves from the industry associations and their lobbyists, and face up to a future which is different from the past, one that can be both exciting and beneficial to all Australians. While unprecedented bushfires burn across the country – first in New South Wales and Queensland, then in Western Australia and now in South Australia and Victoria – it is worth pausing for a moment on the word “unprecedented” to let it sink in. Unprecedented does not mean unexpected. At BP, over 20 years ago, we acknowledged climate change and what it would bring and that we needed to reduce emissions. Our acknowledgment brought cries of foul from industry associations and many peer companies. Here in Australia, I argued long and hard inside the Business Council of Australia for a similar acknowledgement of climate change. I failed. Global greenhouse gas emissions each year are not reducing, they are accelerating. The scientific community has been issuing increasingly urgent calls for rapid reductions in emissions with the foresight that global warming trends will bring these kinds of “unprecedented” conditions. The federal government chooses to ignore them. Three decades on from the first report of the Intergovernmental Panel on Climate Change, Australia’s emissions are growing again, as are our fossil fuel developments. Sign up to receive the top stories from Guardian Australia every morning Australia is now the second-largest gas exporter, the second-largest thermal coal exporter and the largest metallurgical coal exporter on the planet. We push our products with the zeal of a drug lord – we do not care about the future misery we are creating. A dangerous game of brinksmanship is on display across the country, as major corporations collaborate with governments to open up more and more basins for exploitation at a time when they know full well the consequences. At the same time, we are the sunniest and windiest inhabited continent on the planet, capable of reducing not only our own emissions through rapid deployment of renewable energy but also creating export industries of a clean future. And yet the government is invested in the past and protecting the status quo. It dares not to rock the boat in which it sails. And Australia is seeing the consequences of this failure as we speak. And so the question – still – is: Why? Australia’s fossil fuel industry has an uncomfortably close relationship with governments, particularly through their industry associations and lobby groups. Many will recall the time that Scott Morrison, thentreasurer, brought a lump of coal into parliament back in 2017. But how many of us have wondered how he came by this prop? It was a gift. A neatly shellacked lump of coal, of course, so Morrison didn’t get any dirt on his hands, was gifted to him by the then CEO of the Minerals Council of Australia, Brendan Pearson, a man who earlier this year moved across into an advisory role in the office of now prime minister Morrison. I have seen how industry associations, in Australia and overseas, are simply the mouthpiece of those who are invested in the status quo. The nature of these groups causes them to move at the pace of the slowest, and the standard of the lowest – bankrolled by those who are most heavily invested in the past. The problem, as we are now seeing, is that the industry associations are also heavily invested in our political processes, to the detriment of us all. Our politicians are afraid of the future. They are afraid of foresight. They too are invested in the past and walk backwards into a warmer future. The Coalition must turn its back on the industry associations and their lobbyists, face the future and act in the interests of future generations. Because current generations are turning their backs on them. • Greg Bourne is a climate councillor and former head of BP Australasia"
"
Share this...FacebookTwitterProfessor Fritz Vahrenholt and Dr. Sebastian Lüning recently took a look at the odd behavior of former IPCC author Peter Wadhams, who now suspects the oil industy of being behind the accidental deaths of three climate colleagues.
Three British scientists have lost their lives since 2013 – all three had been involved in Arctic research. One was killed by lightning, another fell down some stairs, and the other killed in a bicycle accident. This series of unfortunate, yet totally unrelated, incidents is enough to have Wadhams thinking it may well be a sinisterly crafted campaign orchestrated by Big Oil.
The Telegraph reported:
Three scientists investigating melting Arctic ice may have been assassinated, professor claims
Cambridge Professor Peter Wadhams suspects the deaths of the three scientists were more than just an ‘extraordinary’ coincidence […] The three scientists he identified – Seymour Laxon and Katherine Giles, both climate change scientists at University College London, and Tim Boyd of the Scottish Association for marine Science – all died within the space of a few months in early 2013. Professor laxon fell down a flight of stairs at a New year’s Eve party at a house in Essex while Dr Giles died when she was in collision with a lorry when cycling to work in London. Dr Boyd is thought to have been struck by lightning while walking in Scotland. […] Asked who might have wanted them out the way, [Wadhams] replied: “I can only think of the oil lobby but I don’t think the oil lobby goes around killing people.”

Read the entire aricle at The Telegraph.
Vahrenholt and Lüning write that Wadhams’s behavior appears to be part of a larger pattern of behavioral eccentricity. They write:”Already in the climate discussion he’s been turning off his colleagues totally with his hysterical climate catastrophe scenarios.” For example Wadhams is among those who promote the Arctic sea ice death spiral, telling the world in 2012 that the Arctic would be toast by the year 2016. Even the most hardcore alarmists think that particular scenario is preposterous. Last September Gavin Schmidt wrote at Twitter:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Some anticipation for Peter Wadhams. Audience members already crying, ‘Wadhams still using graphs with ridiculous projections with no basis in physics,’ ‘Wadhams now onto methane pulse of 50 GT. But no better justified than his previous statements,’ and ‘Wadhams clearly states that there is no physics behind his extrapolations.’”
The Arctic sea ice Armageddon is not the only nutty fantasy Wadhams is obsessed with. He is also hysterical about the methane bombe. Spiegel Online reported in 2013 that a group of leading scientists declared an imminent climate catastrophe.
Scientist Gail Whiteman of Ersmus University in Rotterdam calculated together with Chris Hope and Peter Wadhams of the University of Cambridge how expensive climate change at the poles could be for the entire world. The researchers arrived at a figure of 60 trillion dollars– that is about equivalent to the entire global output for 2012. […] In 2010 Natalia Schachowa of the University of Fairbanks in Alaska for the first time reported on the unsettling phenomenon of methane release in Siberia, and that it could be a sort of Arctic time bomb.
It turns out that this time bomb is pure fantasy from hysterical minds. There is no scientific basis for it. The estimates of damage are also of no value.
Renowned climate scientist Judith Curry made it clear in an article at her blog titled “Arctic time bomb (?)” that a large number of colleagues do not share the Arctic methane catastrophe. Even Gavin Schmidt of NASA sees only a minimal chance of a rash release of methane in the Arctic. Tipping point specialist Tim Lenton of Exeter University also sees no urgent danger and sees a process happening only on a scale of tens of thousands of years. A report by Carolyn D. Ruppel in 2011 also shows the same. Curry also mentions other critical opinions, like those of David Archer of the University of Chicago who calls the methane climate bomb scenario “completely baseless”.
Lüning and Vahrenholt conclude that when one considers the recent conspiraicy theories made by Wadhams along with his wild climate claims, “A picture is created of a man who has manoevered himsefl into a  extremely far fringe corner in the climate dicussion. Wadhms has squandered is credibilty. There should be no place for an activist. on a referee panel like the IPCC.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterU. of Southampton: We won’t know whether or not sea level is accelerating until 2020-2030. Mojib Latif: models must first take natural variability much more into account
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(Translated and edited by P Gosselin)
Forecasts have long since fascinated man. There’s something mystical about looking into the future. The oracle of Delphi, a look into the crystal ball, reading tea leaves: indeed the error rate is high, yet that does not deter people from paying more money for more far-fetched predictions.
The ClimateChangePredictions.org website has taken on the task of putting climate change predictions on the test stand to see whether or not they have anything to do with reality. One nice example is sea level rise. Currently sea level is rising 2 – 3 mm per year, and if the trend remains stable, a sea level rise of 25 cm is expected by the end of the century. However this does not keep some attention-seekers from announcing much higher rises to the public. At the ClimateChangePredictions.org website here you will find a highly interesting list of prognoses.
Australian climate scientist John Church predicted 3 m by 2100. For others that figure is much too low, and we are threatened instead with 7 m – or even 100 m! We almost get the impression that the higher the bid, the better the chances of winning – at least that’s the impression we get from the media.
Serious studies show just how absurd the sea level rise bidding has become. Within the framework of a European research program supported by a total of 10 million euros, a consortium of 24 institutes investigated scenarios for future sea level rise. Participating among them was the Bremerhaven-based Alfred Wegener Institute (AWI). The main aim of the 2009 to 2013 ice2sea program was to quantify the melting of land-based ice masses. In May 2013 the researchers presented their Final Report (pdf here). The consortium of scientists concluded that the most probable scenario for sea level by the end of the century is a rise of only between 16.5 cm and 69 cm. That was a bitter disappointment for the alarmists in the field.
So what purpose do the alarmist prognoses serve? Some originate from government organizations, who use them to prop up their aggressive climate policy aims. In the USA the Obama Administration warned of a rise of a rise of 2.10 m by the end of the century – far remote of the mainstream science.
The most recent IPCC report also appears to have lost all contact to reality, which despite all the careful prognoses found in the scientific literature, claims there is a rising danger from sea level rise. Here people like to look 2000 years into the future, absolute nonsense when one considers the numerous poorly known sea level trends.
Who is finally going to blow the whistle on the shrill alarmists and their predictions of a coming flood? When prognoses are far beyond the fringes of the accepted range, it should cause us to stop, think and cast doubt on apocalypse forecasters. For the press they couldn’t care less and gladly view it as a convenient source of attention-grabbing spectacular climate stories.
Within the scientific community, however, scientists see the predictability of sea level far more critically. In March 2015 a group of scientists lead by Mohammad Bordbar – which also included Mojb Latif – published a study that took the natural variability of sea level into greater account. The abstract of the paper stated that we can no longer continue to ignore these processes. The paper appeared in Nature Climate Change. The abstract reads:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Effects of long-term variability on projections of twenty-first century dynamic sea level
Sea-level rise1 is one of the most pressing aspects of anthropogenic global warming with far-reaching consequences for coastal societies. However, sea-level rise did2, 3, 4, 5, 6, 7 and will strongly vary from coast to coast8, 9, 10. Here we investigate the long-term internal variability effects on centennial projections of dynamic sea level (DSL), the local departure from the globally averaged sea level. A large ensemble of global warming integrations has been conducted with a climate model, where each realization was forced by identical CO2 increase but started from different atmospheric and oceanic initial conditions. In large parts of the mid- and high latitudes, the ensemble spread of the projected centennial DSL trends is of the same order of magnitude as the globally averaged steric sea-level rise, suggesting that internal variability cannot be ignored when assessing twenty-first-century DSL trends. The ensemble spread is considerably reduced in the mid- to high latitudes when only the atmospheric initial conditions differ while keeping the oceanic initial state identical; indicating that centennial DSL projections are strongly dependent on ocean initial conditions.”
Natural variability currently makes it impossible to determine if the speed of sea level rise is beyond the range of natural variability. The University of Southampton also explicitly reports this in a press release dated 9 May 2014. It is necessary to first understand the natural processes and to account for them in the development of sea level rise before an anthropogenic signal can be identified and quantified. It’s indeed going to take another 5 to 15 years before scientists are able to decide whether or not sea level rise has accelerated in an unusual manner. What follows is the press release in its entirety:
“Back to the future to determine if sea level rise is accelerating
Scientists have developed a new method for revealing how sea levels might rise around the world throughout the 21st century to address the controversial topic of whether the rate of sea level rise is currently increasing.
The international team of researchers, led by the University of Southampton and including scientists from the National Oceanography Centre, the University of Western Australia, the University of South Florida, the Australian National University and the University of Siegen in Germany, analysed data from 10 long-term sea level monitoring stations located around the world. They looked into the future to identify the timing at which sea level accelerations might first be recognised in a significant manner.
Lead author Dr Ivan Haigh, Lecturer in Coastal Oceanography at the University of Southampton, says: “Our results show that by 2020 to 2030, we could have some statistical certainty of what the sea level rise situation will look like for the end of the century. That means we’ll know what to expect and have 70 years to plan. In a subject that has so much uncertainty, this gives us the gift of long-term planning.
“As cities, including London, continue to plan for long-term solutions to sea level rise, we will be in a position to better predict the long-term situation for the UK capital and other coastal areas across the planet. Scientists should continue to update the analysis every 5 to 10 years, creating more certainty in long-term planning — and helping develop solutions for a changing planet.”
The study found that the most important approach to the earliest possible detection of a significant sea level acceleration lies in improved understanding (and subsequent removal) of interannual (occurring between years, or from one year to the next) to multidecadal (involving multiple decades) variability in sea level records.
“The measured sea levels reflect a variety of processes operating at different time scales,” says co-author Dr Francisco Calafat, from the National Oceanography Centre. He adds, “One of the main difficulties in detecting sea level accelerations is the presence of decadal and multi-decadal variations. For example, processes associated with the North Atlantic Oscillation have a strong influence on the sea levels around the UK over multi-decadal periods. Such processes introduce a large amount of ‘noise’ into the record, masking any underlying acceleration in the rate of rise. Our study shows, that by adequately understanding these processes and removing their influence, we can detect accelerations much earlier.”
Co-author Professor Eelco Rohling, from the Australian National University and formerly of the University of Southampton, adds: “By developing a novel method that realistically approximates future sea level rise, we have been able to add new insight to the debate and show that there is substantial evidence for a significant recent acceleration in the sea level rise on a global and regional level. However, due to the large ‘noise’ signals at some local coastal sites, it won’t be until later this decade or early next decade before the accelerations in sea level are detection at these individual tide gauge sites.”
The findings of the study, funded by the Natural Environmental Research Council (iGlass consortium), are published in this months issue of the journal Nature Communications.”
 
Share this...FacebookTwitter "
"Is Britain really using far less food, fuel, metals and materials now than at the turn of the century? Have we reached “peak stuff”? Certainly the UK Office of National Statistics figures for 2000-2013 seem to suggest this is the case. The problem is that these figures don’t take into account the full range of materials that went into the products we import. The ONS calculates the effects of trade on the UK’s materials use in a way that takes into account everything required to produce any goods consumed in Britain, whether they originated in the UK or abroad. This is called the total raw material consumption, and is effectively the country’s “material footprint”. To reach this figure, ONS takes the materials extracted from within the UK’s territory, subtracts those materials involved in the production of exported goods, and adds materials that are involved in the production of imported goods.  Removing the impact of exported goods is straightforward because we know the total materials that are required to make UK products. But in order to estimate the materials involved in imports, we need to know how much of each different type of product we import, from where, and how efficiently industries are in the country that produces that product. The problem is that the ONS assumes that UK imports have the same profile as the European average when in reality the UK’s trade partners will be different. This is important because production practices vary worldwide and knowing exactly where the UK imports from will give a more accurate number for the material footprint. So our research group tried to calculate the UK’s material footprint taking this production variation between countries into account. To do this we used a model of global trade that understands how industries trade with other industries all over the world. What we found was that while domestic material consumption has fallen (the blue portion of the figure below), this has been overshadowed by rising imports – particularly from China and the rest of the world where material efficiency is, on average, worse than Europe. We found an estimated material footprint for the UK for 2011 that was 18.5 tonnes of material per person, with 57% of this originating from China and the rest of the world. In 2001 this proportion was 47%, and in 1970 it was just 15%. This is considerably higher than the figures reported by the ONS for 2011 where the material footprint is 10.3 tonnes per person. Our figures also reveal a sharp increase of consumption until the economic crisis in 2008, and a study by Thomas Wiedmann and colleagues published recently concluded something similar: that Britain’s material footprint has risen over the last 20 years, peaking at around 25 tonnes per person in 2008. The ONS report on the other hand points to a general decline in UK material consumption, and particularly that this decline comes despite a growth of GDP at the same time. Could this be, as has been suggested, due to UK households purchasing fewer resource-intensive goods – for example, by replacing physical items such as CDs and books with digital media? In fact our research shows that both the increase prior to the economic crisis in 2008, and the fall that followed it, are mainly driven by the use of construction materials. ONS data for the construction industry shows that the value (in 2013 prices) of construction industry work increased from £44 billion in 2000 to £81 billion in 2007, before dropping to £66 billion in 2009. House building rose from 176,850 completions in 2000 to 226,420 in 2007, plunging to 137,280 in 2010. This is matched by a reduction in the portion of the material footprint between 2008 and 2009 made up by construction materials, which fell by 7.3%, ores by 1.0%, and fossil fuels by 3.9%. So have Western economies like Britain really hit “peak stuff”? We’d argue that the materials required by the UK follow the patterns of economic growth more closely than the data reported by the ONS. Speculation that this has peaked seems premature while we are still in a period of economic recovery. Only time will tell if we can successfully decouple the link between GDP and material use – buying less even as we grow richer."
"When you think of China, animal welfare probably isn’t the first phrase that springs to mind. In a country known for its fur farms, bile bears and live animal eating, you could be forgiven for assuming everyone is in on the act.  Given China’s track record when it comes to animal exploitation – much of which was sanctioned by government – it’s not surprising the Middle Kingdom still has a bad reputation. A year ago, I too would have said it was accurate. But, after making two research trips to the country in the past year, I can firmly say my head has been turned. Never would I have imagined China would become one of my top countries in the world for conservation and animal welfare.  My first impression upon arriving back in Beijing after 20 years in May 2015, was not good – for a start the smog was much worse than I remembered it.   I was in the country to participate in an international zoo animal welfare conference, a workshop at Beijing Normal University, and to visit some wildlife sites in Sichuan Province. At the conference, scientists from all over China and from many Chinese zoos presented their work showing how they were creating highly-stimulating enclosures for zoo animals. It was excellent quality research. This is all the more impressive when we realise that there is not the massive public pressure found in Europe or North America to improve the well-being of captive animals. I knew I’d see some amazing species while in China, though I expected them to be largely confined to small islands of green in the midst of a highly modified and human-impacted landscaped. But entering the mountains of Sichuan reminded me that China still has vast areas of relatively pristine land. I visited one such area, Tangjiahe Nature Reserve, in search of large goat-like antelopes called takins and the golden snub nose monkey. Sadly, we didn’t encounter any monkeys, but I did however find the park was full of Chinese tourists. This may not sound that unusual, but – rather ironically – national parks in many less developed countries are rarely visited by the nationals of that country. Tour operators in such countries often think of ecotourism as the sole preserve of foreign tourists. Despite what many people might think, all the national parks I visited in China were extremely well organised with great infrastructure. For example, there were CCTV cameras on trails and even on mountaintops, which permitted the observation and control of tourist behaviour in ecologically sensitive areas. In fact, tourists were only permitted entry to the best wildlife areas when accompanied by a trained guide – and special authorisation was required to enter the most sensitive areas of all. In Chengdu I visited Animals Asia’s bear sanctuary, where bears previously kept for bile farming are rehabilitated. The sanctuary is compromised of many large and highly enriched bear enclosures, a bear hospital and a poignant bear graveyard. Currently it is home to more than 150 bears who will live out their days there in some comfort, before becoming residents of the aforementioned graveyard. This centre had been set up by Europeans, but it was largely staffed by locals doing amazing work while training other Chinese institutions.   In September 2015, I returned to China with six of my PhD students to see those elusive golden snub nose monkeys. We went to participate in a postgraduate workshop about animal conservation – and again what struck me was the passion the young Chinese scientists had for wildlife and conservation.   Yes, China still has many serious problems when it comes to animal welfare, with much of its wildlife forced to retreat into the mountain fortresses of the Tibetan Plateau. But there is hope. China is now producing many young scientists and biologists who do not simply see their work as a job, but more as a vocation. The access these scientists have to funding and technology, and their increasing contact with foreign institutions, mean things are looking up."
"
Share this...FacebookTwitterAlthough over the last 2 years the current solar cycle saw some activity, it recently has quieted down considerably and it continues on the path to being one of the quietest since observations began over 350 years ago. -PG
===============================
The Sun In March 2015
By Frank Bosse and Fritz Vahrenholt
Translated, edited by P Gosselin
Last month our sun gave a really sluggish impression. The sunspot number (SSN) was only 38.4: only 46% of what is normal at this time into a cycle for all the cycles observed since 1750.

Fig. 1: The current solar cycle 24 compared to the mean of all previous cycles (blue) and to solar cycle no. 1, 1755-1766, (black).
Comparing the individual cycles to each other further confirms that the current cycle is a quiet one compared to those we saw in the second half of the last century:

Fig. 2: Comparison of all the solar cycles. The figures represent the summed SSN deviation from the mean for first 76 months into the cycle, for all cycles. The current cycle so far is the 4th most inactive since observations began in 1750.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The current cycle is the quietest since solar cycle no. 7, which occurred around 1830. When it comes to the question of why, the polar magnetic fields of the sun are decisive. We reported on this in detail (see “The sun in Jaunary 2014 and news about the polar solar field“). Its been a few months since the last data recording and today we are 2 years past the suspected smoothed maximum. The polar fields went through the zero-point already in March 2013, as can be seen from the data from the Wilcox Solar Observatory (WSO). There it can be seen that especially the north polar field is still barely established.
How does that compare historically?
Recording of data for the polar fields first began in the early 1970s, which means the time period is still too short to allow real comparisons to be made. But in a paper from 2012 the authors led by Andrés Muñoz-Jaramillo used the observations of solar flares made since 1900 as a proxy for the sun’s polar fields. The lead author of the paper kindly agreed to share the data with the authors of this article and so it is possible to compare the current relationships with the long-term series:

Fig. 3: The relative strength of polar solar fields since 1900.
Here it is clear to see that in the second year past the cycle peak, the polar fields have never been so weak. Consider that the strength of the sun’s polar fields during the solar sunspot minimum is a decisive indicator for the activity of the next solar cycle. A very recent paper by Robert Cameron and Manfred Schüssler confirms this.
We only need to be patient a little longer and to pay further attention to the ongoing development of the sun’s polar fields in order to attempt a forecast. The preliminary indications do point to a low level of activity and thus perhaps an even weaker solar cycle 25 beginning around 2022.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNow that it’s spring, it’s as good a time as any to look at polar sea ice. Climate scientists have told us time and again that global warming would first be been at the Earth’s poles.
Well, if that is true, then we need to start worrying about cooling.
In the Arctic the following chart shows a clear stabilization taking place over the past 8 years with an upward trend over the last five years:

Source: Cryosphere Today, Arctic Climate Research, University of Illinois
It needs to be pointed out that there are many factors impacting sea ice. Among them are ocean currents and cycles, and prevailing weather patterns. In summary, however, the once feared “death spiral” remains totally absent.
Had the past five years been centered about the -1.75 million sq km anomaly in the Arctic, then the warmists may have had a point. But that is not the case as the Arctic sea ice is close to 1 million square kilometers above the alarm level.
A number of high-profile scientists and meteorologists also are now projecting growth in Arctic sea ice over the next 10-20 years as major oceanic oscillations shift to their cooler phases.
Record-smashing Antarctica, warming totally AWOL
If you are a global warming alarmist, then the situation is even more confounding at the south end of the Earth. Especially at the Earth’s southern pole is warming totally AWOL.

Source: arctic.atmos.uiuc.edu/cryosphere


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Because Antarctica is surrounded by water, trends there do behave differently then what goes on in the land-surrounded Arctic.
Consider the following stunning points about Antarctica:
1. Antarctic sea ice has been above normal for almost 3 years uninterrupted.
2. Three years uninterrupted above normal sea ice is unprecedented over the satellite record.
3. Record after record sea ice highs have been set during that period.
4. The trend for the last 10 years has been stunningly strong.
5. The long-term 30-year trend is strongly upwards.
From Antarctic sea ice trends, there’s absolutely no indication that there’s any warming going on down there. If scientists had been warning of cooling, they’d be having a much easier time today convincing the public.
Indeed Antarctica is the very place that AGW alarmist scientists don’t want anyone to look at. In fact today there’s almost no climate data they want you to see – only the “adjusted” surface temperatures that they themselves cook, manipulate and alter.
Global sea ice trend positive since 2006!
Finally charts and data on total global sea ice show absolutely no alarm. Global sea ice has been at a normal level for almost 3 years now. Overall the recent trend is upward, thus indicating cooling – and not warming:

Source: arctic.atmos.uiuc.edu/cryosphere
The above global sea ice anomaly chart shows that there was a brief downward trend from 2004 to 2012, but that loss has since been completely wiped out. The overall trend since 2006 is upwards. In fact the mean of the last 2 years is as high as it was 35 years ago.
Don’t listen to the doom and gloom of the government bought climate scientists. You can look at the data yourself. A good place to do this is over at Anthony Watts’s sea ice page here.
 
Share this...FacebookTwitter "
"Italy plans to cut back on the number of visitors allowed into Cinque Terre, a particularly picturesque section of its north-western coast. Around 2.5m tourists visited the area in 2015; this year, numbers will be limited to 1.5m. Such a drastic move raises questions about the impacts and benefits of mass tourism – and particularly cruise ships. This region of the Italian Riviera, characterised by its charming seaside villages set against rugged terrain, was once difficult to access and off the beaten path of mass tourism. Cruises helped change all that.  These ships began docking in the nearby port of La Spezia just a couple of decades ago, and several now arrive every week. This brought immediate economic benefits to the region. However, as the numbers of tourists have grown each year, the strain on local infrastructures has become too much to bear. Last year, nearly 650,000 of those Cinque Terre tourists came from cruise ships. These are small villages in precarious locations and therefore lack the necessary water, sewerage, electrical, and transportation services to accommodate such a rise in demand. While there are a few public toilets in Cinque Terre, these are not enough – and residents now report tourists using footpaths and even private gardens to relieve themselves. None of this is new. Venice should already have provided a warning of the damage wrought by too many cruise ships. More than half of the historic city’s population has left since 1980, when its popularity as tourist destination skyrocketed, and fewer than 58,000 people live in the city today. Their numbers are dwarfed by the 100,000 or more tourists per day during the peak summer season, up to 30,000 of whom are on a cruise. Most major ocean liners hold 3,000 or more passengers. These large ships allow the number of visitors to the city to exceed its physical capacity, as determined by hotel rooms. This makes everyday life cumbersome. Strolling tourists clutter the footpaths, pausing to take photographs. There are lengthy queues for water taxis, the rates of which have risen because of demand. This is reflective of prices throughout the city. Within the city, tourism is prioritised because of the money it brings in. Property prices continue to rise and residents find it difficult to afford housing in the city. Market stands are steadily closing down as they cannot compete for space in the campi with cafés and pubs, let alone the souvenir shops bursting with Venetian masks. Basic services for life in the city are diminishing. Each year cruise ships dump about 1 billion gallons of waste into the sea. They’re supposed to eject it into the deep ocean, however sometimes they dump closer to shore, presenting serious health risks. When the Costa Concordia struck ground off of Italy’s coast in January 2012, the disaster once again shed light on the ecological damage cruise ships can cause. After human-rescue efforts were exhausted, marine biologists, fearing toxins (such as petrolchemicals and human waste) would enter the water, worked quickly to move coral and sponge species to safer areas nearby. In particular, about 200 giant fan mussels were manually relocated. The waters and fragile coral reefs around Caribbean islands can be particularly affected by big cruise ships. Coral reefs are a crucial tourism attraction, and an essential part of their marine ecosystem, but two-thirds of the region’s coral is threatened by human activity. In one incident last December, the Zenith, a 12-deck vessel carrying more than 1,800 passengers dropped anchor near the Grand Cayman’s coral reef and destroyed large chunks of it as the anchor and its chain dragged across the ocean floor. While there are regulations against damaging the Cayman’s coral reef, the ship was inside the anchorage area. Thus, there remains no compensation for the damage, just a public statement of grievance about the incident. Some places have even deliberately demolished their coral reefs. Falmouth, on Jamaica’s north coast, has dredged its port to clear the way for the very largest ships, such as Royal Caribbean’s 6,000-passenger Allure of the Seas and the Oasis of the Seas. While trade journal Port Technology assures that care was taken and modules installed to help rebuild coral elsewhere, environmentalists say the project destroyed 35m cubic feet of coral reef and two square miles of mangroves. Cruise ships aren’t all bad, of course. They are a part of the mass tourism trend that has democratised travel and opened up activities which were once reserved for the wealthy. Cruises provide a way for millions of people to go abroad and experience different cultures. This is not without merit.  But the industry’s tremendous growth is rapidly degrading its destinations – the very products it promises. Its continued financial success is based on the sustainability of these destinations. If the cruise industry does not see this as enough reason to impose regulations, then the international community has a responsibility to step in, both for the people who live in destinations that depend on tourism and for ourselves as tourists who want there to be a world to see well into the future."
"Over the last 30 years, floods have killed more than 500,000 people globally, and displaced about 650m more. In a recent paper published by the Centre for Economic Performance, we examined why so many people are hit by devastating floods. We looked at 53 large floods, which affected more than 1,800 cities in 40 countries, from 2003 to 2008. Each of these floods displaced at least 100,000 people from their homes.  Of course, part of the problem is that many cities were originally built near rivers and coastlines. For a long time, these cities’ residents benefited from lower transport costs, because they were close to ports and the trade which occurred there. But these days, modern land transport often makes these historical advantages obsolete, as more cities rely on highways and railways than on ports. Yet history is not the only reason why flood-prone locations are overpopulated. For one thing, rising sea levels and a changing climate are putting more cities’ residents at risk. And what’s more, new homes are still being built in flood-prone areas around the world.  This is largely because private developers do not bear the full social cost of building on cheap land on flood plains. Instead, governments typically foot much of the bill for building and maintaining flood defences. As a result, developers do not take on the full risk of constructing homes in areas that are prone to flooding, and many people looking for new homes for their families move into these buildings. And so, the global population at risk of flooding keeps growing. To contain this large and growing social problem we should, at the very least, tighten the control over construction in flood-prone areas. Or, even better, home builders who insist on constructing new houses in flood plains should be required to bear the full costs that they impose on society in the long run. Another part of the problem is that people continue to live in flood-prone locations, even in the aftermath of large floods. There is no widespread movement towards safer areas.  Low-lying urban areas are hit by large floods about three to four times more often than other urban areas. This is partly because some low elevation areas are close to coastlines and rivers. But in fact, our study found that the risk of large-scale flooding is still higher in low elevation areas, even after we adjust for their proximity to these amenities.  Despite this higher risk of flooding, low-lying urban areas concentrate more economic activity than safer urban areas. This is true even in the parts of the world that are prone to extreme rainfall, such as the basins of major South Asian rivers, where the risk of large-scale flooding is particularly high. It is true that farmers in these areas sometimes benefit from the flood soils, but city dwellers generally do not. When cities are devastated by large floods, low-lying areas sustain more damage than other areas. But, like other parts of flooded cities, the low elevation areas recover rapidly. You may think that this recovery is good news. But unfortunately, it means that economic activity does not move to safer areas, so it remains at risk from the next big flood.  And sure enough, the odds of being hit again by a large flood are higher for cities that have already been flooded before – so the cycle of flooding repeats itself. We are not saying that the rising risk of floods should make people abandon thriving cities. But the pattern of repeated large floods is common even in economically marginal areas, where the case for living on flood plains is not always convincing. In our study we found that even cities that are prone to large-scale flooding often contain higher elevation areas that are safer, and that’s where new construction should take place. Flooding is a devastating and recurrent problem that afflicts many of the world’s cities. We need better policies to ensure that we do not mistakenly subsidise new construction on the flood plains, so that the problem of flooding does not get any worse – especially as sea levels rise."
"Antarctica and Greenland may be two of the most remote places on Earth but what happens in both these vast landscapes can significantly impact on human activity further afield. Recent changes seen in vast ice sheets could have serious implications for millions of people around the world who live in coastal areas. These ice sheets store enough water to raise sea levels by over 60 metres, and there are some very worrying signs about their stability, especially in West Antarctica.  The real problem lies in the fact that ice sheets are reacting to increases in air and ocean temperatures and contributing to rising sea levels, currently estimated to be around three millimetres a year. While it is clear that ice sheet contributions to sea level rise have accelerated in the last decade or so, there is much more uncertainty about how ice sheets might respond in the future. With one recent study giving estimates which ranged from 60 centimetres to three metres by 2300. And that’s just from Antarctica. This uncertainty stems from the way ice sheets lose mass and transfer water to the oceans. In Greenland warmer air temperatures melt the ice sheet surface, which then causes water to drain off into the ocean. But in Antarctica, temperatures are so cold that very little of the ice sheet ever melts.  So how does Antarctic ice make its way to the ocean? The answer lies in ice streams, which are zones of the ice sheet that flow much faster than the surrounding ice at hundreds of metres per year. The ice streams then discharge ice into the ocean in the form of icebergs that eventually melt.  Ice streams can be unpredictable as they can turn on and off and change their position. Measurements show that there are about 50 major ice streams in Antarctica, which account for around 90% of the ice that is lost each year.  Ice streams make predicting future changes in ice sheets very difficult. While it’s relatively easy to estimate how much more melting might occur if air temperatures increase by say 2°C, nobody really knows what will happen to the ice streams.  A different approach to predicting the future is to look to the past and see how ice streams responded to previous periods of climate warming. In our paper, we reconstructed past ice stream activity, when an ice sheet the size of Antarctica disappeared over North America at the end of the last ice age between around 20,000 and 7,000 years ago.  This “North American Ice Sheet” covered most of Canada and by using satellite imagery to view land forms it left behind, we were able to map the location of all of the major ice streams that were once active in this ice sheet. We then used an existing database to track the retreat of the ice sheet over time – and estimated when the ice streams switched on and off. We also worked out how much ice the streams might have discharged from the ice sheet. We found ice streams switched off as the ice sheet retreated, having much less influence on the dynamics of the ice sheet. This means that the larger ice sheets simply have more ice streams and vice versa. This shows that the collapse of the North American ice sheet was mostly caused by increased melting of the ice sheet’s surface and not necessarily by ice streaming.  Ice streams in Greenland and West Antarctica are contributing to sea level rise which is likely to continue for at least the next century or so. Our reconstruction clearly showed ice streaming is much more likely to take place when the ice sheet is in contact with the ocean and slides over a bed of soft, slippery sediments. This confirms that some parts of West Antarctica may be especially vulnerable. While not everyone agrees the North American ice sheet is a useful comparison for the present day ice sheets, it is the only comparison we have of an ice sheet as big as Antarctica experiencing a rapid warming, and eventually complete disappearance. So when it comes to the millions of people around the world who live in coastal areas, only time will tell if what we have learnt from the past has relevance for the future."
"I desperately want to eat, but I would rather have a future. It’s day 10 of Extinction Rebellion’s global climate hunger strike and more than 500 people have ended their fasts. I am not ready to end mine. I am willing to starve to death, if that would help initiate real climate action, because I refuse to stand by and allow my nieces and nephews to live through a dark age of starvation, disease, and war. For the past week I’ve felt exhausted, dizzy, angry, and desperate. Now I mostly wake up sad that it has come to this. My parents tearfully urged me to stop, but how can I, when Intergovernmental Panel on Climate Change (IPCC) models estimate temperatures that would make the planet unlivable? The Paris agreement pledged to prevent 2C of warming, a rise in temperature that will bring disasters all around the world, including the United States. Such disasters are already killing and displacing people, mostly in poor countries, who did little to create the crisis. Central America is experiencing its sixth straight year of drought. At 3-5C, global civilization would devolve into wars over precious resources. This must be prevented at all costs.  I have no money and no power over our government. I have only my body, so I will fast until Nancy Pelosi agrees to a one-hour on-camera meeting with Extinction Rebellion. She presents herself as an ally of climate justice. I hope she will show compassion for my suffering and the suffering of millions of others before my body, our society, and the planet pass the point of no return. My sacrifice is meant to communicate the gravity of our situation and propel others into action. While I fantasize about scarfing down my famous cheesecake, there are too many lives on the line to give up now. A recent US army report says our military and national power grid could collapse by 2040. We will run out of food and our society would break down. At just 2C of warming, the tropics will have to be evacuated. Where will 40 million Central Americans go? Dr Hans Joachim Schellnhuber, a coordinating lead author of a key IPCC report, estimates the carrying capacity of a 5C planet at below 1 billion people. That means eight billion deaths. It’s impossible to capture that horror in words. Activists have tried to protect us for decades – the Sierra Club, Greenpeace, indigenous peoples – but the influence of money in our government has easily overpowered them. In essence, they failed. In 2015, US fossil fuel subsidies totaled $649bn, more than the defense budget and nearly 10 times what Congress spent on education that year. My hope rests with the young people who know they’ve been betrayed and are refusing to accept their fate. To prevent catastrophe, the solutions are simple: we need to reach net-zero emissions by 2025 and reduce atmospheric CO2 levels thereafter. Achieving this requires ambitious legislation. We need a massive movement of nonviolent civil disobedience to force our government into action. From the Suffragettes to the Freedom Riders to Gandhi’s Salt Marchers, non-violent civil disobedience has proved itself to be the most effective tactic for bringing about rapid social change. Extinction Rebellion has adopted this principle, and some of us have escalated the action to a hunger strike because of our desperation. If governments refuse to act now, crop failure could plunge the world into hunger. “Climate emergency” is the Oxford Dictionary’s word of the year for 2019. We need to change our behavior, our society, and our laws, and make it the act of the year. I desperately want to eat. I want to live a long life and have kids and a dog and grow old with my partner. I certainly don’t want to die at the age of 27, but I am willing to do what is necessary to advance action against this climate emergency. Speaker Pelosi, we are asking for one hour. Please meet with us. I would rather we all have a future. Eric Tien is an Extinction Rebellion protester"
"Technological improvements mean that the phones, tablets, computers and other electric devices we find so essential are cheaper and more powerful than ever. But this means we upgrade them sooner and they quickly become unwanted or obsolete, and are thrown away. The huge amounts of waste electrical and electronic equipment – WEEE, or e-waste – that results is quickly becoming a major worldwide environmental, economic and health problem. A recent report by the European Union-funded Countering WEEE Illegal Trade project found that only just over a third of Europe’s e-waste ended up in official collection and recycling programs. The rest, amounting to over 6m tonnes a year, was either exported (1.5m tonnes), recycled in ways that fell outside the law (3.15m tonnes), scavenged (750,000 tonnes), or simply thrown in the bin (750,000 tonnes). Considering the vast quantities of e-waste produced worldwide, where this waste ends up is a serious concern. Considering the energy and materials-intensive process of manufacturing it in the first place, so is the impact on the world’s natural resources and environment. But not all e-waste is the same. Different equipment can contain hundreds or even thousands of different substances, some of which are potentially highly toxic, while others are extremely valuable. This has led to theft: in 2012 the EU estimated that theft of valuable components and materials from e-waste was worth between €800m and €1.7 billion. Much of electronic waste is made of metals: gold, lead, nickel, silver, tin and zinc, alongside valuable reusable plastics. Hazardous elements include materials such as asbestos, batteries, printed circuit boards, and printer toner cartridges. Throwing away high-value materials represents a huge waste. However, the economics of extracting them don’t always work in the West. Instead, e-waste exported to developing countries ends up in informal recycling schemes run by individuals, and sometimes criminal gangs. In some countries this has dominated the e-waste recycling chain, with equipment burnt in open fires or processed with hazardous acids in order to recover valuable metals.  Properly organised recycling schemes have emerged in developed countries, with the EU leading the way in adopting the “producer pays principle”, which requires manufacturers and sometimes importers and distributors to fund the collection and recycling of their products – and to ensure they’re disposed of using environmentally sound methods.  In the European Union, this first appeared as the 2006 WEEE Directive, which included rising national e-waste recycling targets, and a further directive in 2012 that broadened what counted as e-waste and introduced tougher restrictions on illegal waste export. Each year around 9.5m tonnes of e-waste are disposed of in the EU. It is also estimated that of the 1.3m tonnes of undocumented electronic waste exported, 70% was functioning equipment – which could potentially have continued to be used. Electronic waste was at first just dumped in landfill sites. But the danger of the highly-toxic elements in e-waste escaping landfill sites – into the water table, for example – meant that tighter controls were needed. Problems related to e-waste disposal in developing countries are worse, and already cause significant environmental and health problems. The open burning of plastics, widespread general dumping, malpractices associated with improper dismantling and treatment of e-waste as observed in countries such as China, India and Nigeria can result in serious health consequences.  Places such as Guiyu in China and Agbogbloshie in Ghana have become notorious for their unregulated, heavily polluted, sweatshop-dominated, digital dumps. Metals do not degrade in the environment and so can accumulate, contaminating the soil and groundwater, bioaccumulating in the creatures living in them. Beyond the cost to the environment and health is the economic cost. The loss of precious, useful and often rare materials from unprocessed e-waste is very significant. Materials found in modern electrical and electronic products include metals classified as critical raw materials which are in short supply. Ethical concerns linked with e-waste include reports of child labour in its treatment and handling, especially in some parts of Asia and Africa. Illegal shipment of e-waste from affluent countries to poorer developing countries that lack the facilities to properly treat such wastes is widespread. The evidence points to a close link between ethical malpractice in e-waste handling and environmental damage and health problems. Preventing illegal e-waste shipments could alleviate – if not necessarily eradicate – these effects. With the world’s population expected to grow to nine billion by 2050, and a corresponding leap in the amount of waste electronics that we consume and discard, we urgently need to get a grip on this problem and introduce proper laws, regulations and procedures that will ensure that electronic waste is safely dealt with."
"
Share this...FacebookTwitterOver the last couple of days at their Die kalte Sonne blog Geologist Dr. Sebastian Lüning and professor of chemistry Fritz Vahrenholt have focused their attention on sea level rise.
On Monday they wrote a piece titled: “Sea level rise lagging behind expectations: Now only ‘data massaging’ helps“.
In their post the two authors present a number of charts and cite many papers. In the end they conclude that sea level rise has not accelerated at all, despite what the media and a few alarmist scientists may otherwise claim.
Lüning and Vahrenholt write that sea level acceleration is the result only when one dubiously fudges the data:
What would you think if a soccer game ended with a score of 3:1, but the result later changed to 3:3?”
Today Lüning and Vahrenholt followed with another post on sea level rise, which shows that the methodology used at times by scientists to compute and project sea level rise leaves little to be desired.
========================================
What climate models have not taken into consideration up to now: Up to one third of the sea level rise traced back to ocean salinity


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
[Translated/ edited by P Gosselin]
For over one hundred years there has been a network of coastal tide gauges around the world that serve to measure the sea level. The hard data that is recorded play a decisive role in determining sea level rise. Because some coastal locations are rising and some are sinking, the corresponding vertical movement has to subtracted from or added to the tide gauge readings respectively. Using satellite measurements, today this can be corrected with reasonable accuracy. In March 2014 in a paper in the Geophysical Research Letters a team of scientists led by Guy Wöppelmann conducted a global revision of all GPS corrected coatal tide gauge measurements for the 20th century. The result is interesting: While sea level rose an average of 2.0 mm per year in the northern hemisphere, it was only about half as much in the southern hemisphere: 1.1 mm/year. What follows is the paper’s abstract:
Evidence for a differential sea level rise between hemispheres over the 20th century
Tide gauge records are the primary source of sea level information over multi-decadal to century timescales. A critical issue in using this type of data to determine global climate-related contributions to sea level change concerns the vertical motion of the land upon which the gauges are grounded. Here we use observations from the Global Positioning System for the correction of this vertical land motion. As a result, the spatial coherence in the rates of sea level change during the 20th century is highlighted at the local and the regional scales, ultimately revealing a clearly distinct behavior between the northern and the southern hemispheres with values of 2.0 mm/year and 1.1 mm/year, respectively. Our findings challenge the widely accepted value of global sea level rise for the 20th century.
The rise in sea level over the past 150 years is foremost attributed to the thermal expansion of the warmed water and the melt water from glaciers and the ice caps. But in November 2014 in the Environmental Research Letters Paul Durack showed that also ocean water salinity also contributed to sea level rise to a non-negligible extent. The Lawrence Livermore National Laboratory reported in a press release:
The team found that there was a long-term (1950-2008) pattern in halosteric (salinity-driven) sea level changes in the global ocean, with sea level increases occurring in the Pacific Ocean and sea level decreases in the Atlantic. These salinity-driven sea level changes have not been thoroughly investigated in previous long-term estimates of sea level change. When the scientists contrasted these results with models, the team found that models also simulated these basin-scale patterns, and that the magnitude of these changes was surprisingly large, making up about 25 percent of the total sea level change. ‘By contrasting two long-term estimates of sea level change to simulations provided from a large suite of climate model simulations, our results suggest that salinity has a profound effect on regional sea level change,’ Durack said. ‘This conclusion suggests that future sea level change assessments must consider the regional impacts of salinity-driven changes; this effect is too large to continue to ignore.‘
Attribution for the causes of observed sea level rise obviously is struggling with serious problems. No one has properly taken the changes in salinity into account.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Ed Caryl
Recently, Roy Spencer posted a graph that appeared to be a data record of some kind for the last 100 years. Then he revealed that it was generated in Excel with a simple random number function. The graph showed details that resembled things like El Niño’s and La Niña’s, pauses, and sudden warming and cooling.
I decided to repeat his graph introducing cycles into the mix. We know that the climate follows ~60 (AMO ocean cycle), ~210 (de Vries or Suess solar cycle), and ~1000 year (un-named) cycles (approximately). The following is a graphic of what happens if these cycles are introduced into the random number generator. The graph extends to 1014 simulated years by month. The random number generator is constrained to + and – 0.5, and each month adds 0.9 of the value of the previous month. The cycles use the sine function (SIN()) with input from the fractional year value, multiplied by 0.1 to produce a 62 year cycle, 0.029 to produce a 215 year cycle, and 0.006 to produce a cycle just over 1000 years. For this last cycle the COS function was used to shift the cycle phase by 90 degrees. Each month, 1/40th of each cycle value is added along with the 0.9 of the previous month. This produces a graph that roughly resembles earth’s climate over the last 1014 years with extension to the next 200.

Figure 1 is a simulation of the last 1014 years, with the applied climate cycles shown.

Figure 2 is a magnification of the last 214 years from Figure 1. Blue is monthly data, black is the annual average, the red trace is the simulated AMO 62-year cycle.
Each re-calculation will completely change the data, but similar features always appear. In this iteration, an El Niño appears at 1999, that looks just like the real El Niño of 1998. We see a warming trend in the early twentieth century, and another in the late twentieth century, just like the real warming trends.
In figure 1, we see a Medieval Warming period and two periods of Little Ice Age. A minimum is seen that resembles the Dalton Minimum of the early 1800s, and the cool 1910s and 1970s appear. Even the cool Maunder Minimum appears in the correct place. Most of this result is not coincidence because the 62-year cycle is timed to match the real AMO, and the 204-year and 1000-year cycles roughly match real solar activity.
In this simulation, two successive warming periods very like the actual twentieth century warming periods, can occur from natural cycles alone, no extra “forcing” from CO2 is required.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So, what will the future bring? Now that we have this model, that reflects the past, as we know it, with general accuracy, can we project that into the future? Sure…this is just an Excel spreadsheet after all. I pasted on 200 more years. As I did so, Excel of course recalculated the whole table. So here is a second example of the last 214 years that it came up with, in case someone accuses me of “cherry-picking”. Note that we get much the same pattern of warming and cooling, with a couple of El Niño’s in approximately the right place in the last 20 years.

Figure 3 is another calculation of the same period as in figure 2. The black trace is an annual average of the monthly data. All three cycles are shown.
Note the resemblance between figures 2 and 3. Each is a different calculation using different random numbers, yet the small addition of non-random sine wave cycles pushes the output into shapes that resemble the climate that happened in this period.

Figure 4 is the future, as projected by our model. The black trace is an annual average of the blue monthly data. All three cycles are shown.
As you can see, the future holds nothing to fear. There will be a few El Niño’s in the next ten years, then a moderate cooling as we come off the peak of the 62 and 204 year cycles. There will be more of those in mid-century, as the AMO rises again, then more cooling for a period at the end of the century as both of those cycles bottom out. No extensive warm periods will appear until late in the twenty-second century, as both peak again.
This model is not new. On the side-bar of this blog, an illustration from Nicola Scafetta’s model is similar, with the addition of some shorter cycles. An earlier post on this blog from a paper by Prof. H. Luedecke and C.O. Weiss (cited above) also used a similar model. The chief addition is random “weather”.
No CO2 molecules were harmed in the generation of these graphs. Nor, for that matter, were they considered.
For those with Excel expertise, I have posted the file to Dropbox here.
Share this...FacebookTwitter "
"At the start of each year, Norway hands out new licences for offshore oil and gas development. Typically, these “Awards in Predefined Areas” (APA) receive little coverage outside of the specialist media. But this year was more controversial, after the country’s energy minister argued that the environmentally-sensitive Lofoten islands “must at some point come into play”. Lofoten is a unique and stunning archipelago in Norway’s far north, where huge unspoilt mountains rise out of the ocean. Located at the end of the gulf stream, it’s unusually mild for somewhere beyond the Arctic circle. Large coral reefs found to the west of the islands mean that the region’s cod-filled waters are protected by domestic laws and international conventions. Despite the energy minister’s comments, no licences were actually offered immediately next to Lofoten – this time. And those that were offered in the region were all further from Lofoten than the closest existing one, which is around 70km from the south-west edge of the islands and is operated by state-owned Statoil, who are yet to start drilling. Nonetheless even the prospect of future development was enough to worry environmental groups, and has led some to question the country’s commitment to addressing climate change despite the 2015 Paris agreement. The collapse in oil prices over the past two years has delayed or cancelled many expensive new projects around the world. Lofoten has emerged as a cheap alternative as the islands are close to the mainland and the surrounding waters are relatively shallow.  Drilling in the area was prohibited under Norway’s 2006 management plan for sustainable use of the Barents and Norwegian seas. But the resources are hard to ignore – there are an estimated 1.3 billion barrels of oil in Lofoten and neighbouring Vesteralen and Senja. (By comparison, the UK’s entire resources are estimated to be up to 21 billion barrels.) In 2013, Norway’s Labour prime minister Jens Stoletenberg supported an impact assessment study on development in the area, but following the election that year the new Conservative-led coalition agreed not to drill in these areas, around the protected island of Jan Mayen, or in the so-called High Arctic region.  With the Conservatives still in power, opening up Lofoten would represent a backtrack. Yet it’s not just Lofoten. This year’s round of exploration licenses was also notable for the number offered in the Norwegian Sea, 24 out of a total 56 – with 27 in the North Sea and five in the Barents Sea. This is the highest number since the current system was introduced. It highlights the financial difficulties facing oil and gas companies, but also suggests a change in the geography of Norwegian oil and gas development. The next wave of exploration work was long expected to take place in the Barents Sea, off Norway’s northern coast. However the lack of previous infrastructure to build on and some disappointing reports of smaller than expected oil discoveries means the economics there are challenging. This was an issue back when oil prices were riding high, and the drop since then has further dimmed the prospects of developing the Barents. Norway is also concerned about the future of gas demand in Europe. What’s the point of setting up drilling rigs and pipelines in the Arctic if no one wants to buy it? Gas has been caught up in the EU’s drive to reduce its dependence on Russian energy, and difficulties with the EU emissions trading scheme have so far stymied hopes that it could be the bridging fuel to a predominantly renewable future.    In May 2015 Norway’s parliament asked the country’s US$857 billion sovereign wealth fund, Norges Banke, to divest from coal power – a move applauded by climate activists. But less than a year later this latest round of new oil and gas developments has drawn criticism from those who claim opening up new fields will undermine Norway’s commitment to tackling climate change, just weeks after the Paris deal.  Even though development at Lofoten is unlikely in the near future, the minister’s comments on opening the area up at some point could be reflective of a wider trend across the world. For all the big talk about fighting climate change, the basic truth remains: future production of oil and gas is central to the Norwegian economy, while the EU will still want a secure supply of these fossil fuels – especially gas."
nan
"English children are apparently “not engaging with nature”, according to a major two-year study. We’ve previously heard that they don’t know a calf is a baby cow, and that names of trees and flowers have gone from junior dictionaries to make way for words like “broadband” or “analogue”. Fears about the lack of time spent outdoors have prompted high-profile campaigns to encourage a “free-range, nature rich, outdoor childhood”. Now I spent a huge proportion of my youth doing exactly the kind of tree-climbing and roaming this movement advocates. I’ve worked for conservation organisations involved in these campaigns, and I’ve researched how people benefit from gardens. So why do pleas to get children back into nature leave me a little uneasy? The research featured in the latest news reports was led by Natural England, a government advisory body. The headlines are that 88% of English children have visited the natural environment in the last year, and that 70% go at least once a week. The media of course focused on the negative side of these figures – the 12% not visiting the natural environment. We might accept that, as this is the first reporting of this survey, we don’t know what the trend is across recent years, because there are two bigger questions to consider.  The first is with the very idea of engaging with the “natural environment”. In 1976 the Welsh author and academic Raymond Williams suggested that nature may be the most complex word in the English language. Some ecologists deny humans can ever be disengaged from it as we are part of it. Human geographers have long argued that cities are natural phenomena, made through the combined effort of humans and ecological processes. This might seem semantic, but there are practical implications to the difficulty of agreeing what nature is and where you can find it. Natural England’s survey counts a range of places including urban parks, mountain or moorland, children’s playgrounds and allotments, although not – perhaps perversely given evidence of how they benefit people and wildlife – private back gardens. Regarding all these places as “natural” emphasises their similarity. But they’re hugely varied and engaged with in different ways so can have distinct benefits. What a child does in a small city playground is likely very different from how he or she experiences the open landscape of a national park. Rather than thinking of all places with a good amount of greenery as natural and therefore beneficial, we need to distinguish which features and characteristics can have positive affects. By understanding this it becomes possible to plan environments which support positive, healthy engagement. The second issue is the risk of conflating place and activity. My research on community gardeners, for instance, showed that what one does when outdoors is as significant in terms of well-being as the very fact of getting out and among the plants. To know what activities to encourage, we need to be more specific about what we actually want to achieve. If increased physical activity is a priority then time spent cycling to school or playing in a safe street may be better than a trip to see the countryside largely from the back of a car – and more readily accessible.  The other reason for a more detailed picture of children’s outdoor activities is to avoid the risk of presenting a homogenising picture which holds up a certain type of engagement with nature as the ideal. Think of hikers in cagoules forging on through all weathers, or peering through binoculars at a barely visible bird. But these pursuits are off-putting for many, and can squeeze out other outdoor activities which might have broad appeal.  The notion of the “great outdoors”, invigorating countryside and bracing fresh air is also highly culturally specific, closely tied to a “white British” identity. These associations can lead non-white ethnic groups to feel excluded from the countryside, and visit less often. The Natural England survey found that children from black and minority ethnic households are less likely than those from white families to regularly visit natural environments. It is not clear how much this is associated with income or living in cities. But the survey shows that even visits to urban greenspaces vary with ethnicity, suggesting it’s not just down to location. For some people the outdoors simply doesn’t seem that great. Natural England and others have been working to address this by deliberately engaging with minorities to understand why they may be unlikely to visit natural environments. Research available so far suggests that different cultural groups have varied motivations for spending leisure time outdoors, with people of Asian heritage more likely to seek a sociable experience of eating and gathering, for example. So there is more to learn here. Williams concluded that the word nature has powerful effects on any argument, so we should be “especially aware of its difficulty”. With this in mind I suggest we are wary of all the good that can be masked when we talk about “engaging with nature”. Children can enjoy the outdoors in many different ways and this can start right on their doorstep."
nan
"Do the same rules that govern human attraction also apply to our choices of fruit and vegetables? Plenty of evidence suggests we do look for similar traits in both people and produce, and our perceptions of food are clearly affected by what it looks like. Each year we waste 1.3 billion tonnes of food worldwide, a third of the total produced. This unbelievable figure is partly made up of “ugly” fruit and vegetables – those that are perfectly edible but rejected by supermarkets due to their blemished skin or unusual shape.  In March 2015 I opened a pop-up Ugly Food Shop in a mission to change perceptions of ugly food. I became interested in why it was ever rejected in the first place, and whether supermarkets either dictated or answered to a desire for perfect veg.   Since then, ugly foods seem to be making a comeback. A flurry of excitement accompanied the launch of British supermarket Asda’s “wonky veg box” which, for just £3.50 (US$5), promises to feed a family of four for a week. So have we always cared about the shapeliness of our bananas, or are we only now becoming more receptive to the idea of bendy vegetables? Theories of human attraction suggest beautiful people are generally considered to be more honest, more social and more successful. Ultimately, we seem to be programmed to find attractive people more likeable – even newborn babies spend more time gazing at the prettiest among us. Symmetry is critical here, as symmetrical faces are easier to visually process and signify genetic health. From an evolutionary perspective, selecting a mate with even features is a safer bet, as asymmetries can be caused by disease and infections during physical development. Although it makes sense that we would naturally select produce that is the most likely to be free from disease, in reality imperfections in the shape of fruit and veg have no real bearing on their nutritional content or taste, and no evolutionary advantage. An alternative explanation is that we “eat with our eyes”. Colour has a huge impact on how we perceive taste, with multiple studies demonstrating how a variety of learned and natural responses can influence the communication between our eyes and brain to determine taste. For example, professional wine tasters admitted to being a little suspicious while drinking white wine visually disguised as a full-bodied red, however they ultimately trusted their retinas over their taste-buds, until the trickery was revealed. Equally, altering the colour of vanilla ice cream can determine it’s reported taste, with brown vanilla ice cream described as chocolate, pink as strawberry, and green as mint. Given these findings, it is understandable that it will always be the disfigured potatoes that are left on the shelf. However throwing away a few lonely spuds has nothing on the millions of tonnes of fruit and vegetables which are denied even the chance to make it through the supermarket doors.  Thanks to global abundance and international trade, supermarkets can now be more selective. Much of the food deemed ugly is damaged on long boat trips – literally a fruitless journey – while ugly produce grown closer to home is also rejected, imposing harsh conditions on farmers. The needless waste of both imported and homegrown fruit and veg seems senseless; however if consumers are unaware of it, they can do nothing to change it. Attitudes seem to be shifting though, thanks largely to high-profile coverage of massive food waste. Ugly food is becoming more popular, and social influence has a huge impact on our behaviour. Wonky veg can be rebranded to enhance that social influence, for instance our shop marketing campaign focused on “humanising” a team of unfortunate fruit and veg, giving consumers something to root for. More than just fashion, the multiple benefits of “ugly” foods are admired as it is both cheap and helps to cut waste. The ugly comeback shows awareness and social influence can override a natural instinct to select symmetrical and unblemished fruit and veg. Whether this is a trend capable of withstanding the rise and fall of passing fancy, only time will tell. However in the meantime if we can cut waste and spend less, that definitely sounds appealing to me."
"Of all the horrors that might befall the burnt-out, the flooded, the cyclone-ravaged and the drought-stricken Australian this summer, perhaps none could be viewed with more dread than turning from their devastated home to see advancing on them a bubble of media in which enwombed is our prime minister, Scott Morrison, arriving, as ever, too late with a cuddle. It’s fair to say that Morrison has pulled off other roles with more conviction – the shouty Commandant of the Pacific camps perhaps his most heartfelt to date, the Gaslighter-in-Chief his most audacious, his Mini-Me to Donald Trump’s Dr Evil not without tragicomic charge – but sorrowful Father of the Nation has begun to feel a firebreak too far.  In Australia we are all now being treated as children, quietened Australians, most especially on the climate crisis. While the climate crisis has become Australians’ number one concern, both major parties play determinedly deaf and dumb on the issue while action and protest about the climate crisis is increasingly subject to prosecution and heavy sentencing. In Tasmania, the Liberal government intends to legislate sentences of up to 21 years – more than many get for murder – for environmental protest, legislation typical of the new climate of authoritarianism that has flourished under Morrison. As Australia burns, what we are witnessing nationally is no more or less than the criminalisation of democracy in defence of the coal and gas industries. In this regard, the climate crisis is a war between the voice of coal and the voice of the people. And that war is in Australia being won hands down by the fossil fuel industry. Which brings us back to that industry’s number one salesman, the prime minister, standing there in the ash in the manner of Humphrey B Bear on MDMA, as, mollied up, he pulls another victim in the early stages of PTSD into his shirt, his odour, his aura – such as it is – and holds them there perhaps just a little too long. Sometimes, at his most perplexing, he lets that overly large head loll on the victim’s shoulder and leaves it there. Prayers and thoughts naturally follow. Perhaps it is just his way. Certainly, the prime minister is an unusual issue of two stock types frequently derided in broader Australian culture: the marketing man and the happy-clappy. But in fairness to both tribes, he seems to draw on the worst in both traditions and make of them something at once insincere, sinister and vaguely threatening. Perhaps it’s the slightly up and down smile, the uneven mouth and crooked teeth, a lack of symmetry that can be attractive in some here seems to suggest nothing more than an untrustworthy menace. After all Elvis made of his sneer an alluring smile. Scott, with his reverse magic, makes of his every smile a sneer. Still, his wisdom would seem to be that if he is seen to be very good at feeling our pain we won’t ask him what caused the wound. And therein the problem. The prime minister must accept that public men are judged by public acts. Real empathy would mean speaking honestly to our nation about what the climate catastrophe means for our economy, our environment, our society, and each of us and for each of us personally. All this theatre hides a deeply cynical calculation: that Australians will keep on buying the big lie, a lie given historic expression last Thursday morning when on national radio the prime minister declared that Australia’s unprecedented bushfires were unconnected to climate change. The same day the New South Wales government announced that Sydney dams had in the last 12 months received just 10% of the normal water inflows and declared level two water restrictions as numerous country towns face the prospect of no water. And on this day, when Sydney was blanketed in bushfire smoke, when much of Victoria was declared code red, fires were burning out of control in South Australia, and “climate emergency” was declared word of the year by Oxford Dictionaries, Morrison said that “to suggest that at just 1.3% of emissions, that Australia doing something more or less would change the fire outcome this season – I don’t think that stands up to any credible scientific evidence at all”. This is an argument entirely in bad faith. Two days before saw the release of a major UN report that forecast Australia to be the sixth-largest producer of fossil fuels by 2030. Between 2005 and 2030 Australia’s extraction-based emissions from fossil fuel production will have increased by 95%. By 2040, according to the report, on current projections the world’s annual carbon emissions will be 41 gigatonnes, four times more than the maximum amount of 10 gigatonnes required to keep global heating below 1.5C. According to the Economist: “The report lays much blame on governments’ generosity to fossil-fuel industries.” The report details at length how Australia supports its fossil fuel industries. Actively working through legislation, subsidy and criminalisation of opposition to enable Australia to become one of the world’s seven major producers of fossil fuels makes Australia’s actions directly and heavily responsible for the growing climate catastrophe we are now witnessing in Australia. It gives the lie to the nonsense that we will make our Paris commitments “in a canter”. It cannot be explained away. It cannot be excused. Australia is actively working hard to become a major driver of the global climate crisis. That is what we have become. The same day Morrison went to the Gabba, got photographed with cricketers and tweeted: “Going to be a great summer of cricket, and for our firefighters and fire-impacted communities, I’m sure our boys will give them something to cheer for.” To the question does he think we are that stupid, the answer was implicit in an interview the same day when the prime minister justified not meeting with 23 former fire chiefs and emergency services leaders calling for a climate emergency declaration in April, claiming the government had the advice it needed. He went on to say that: “We’re getting on with the job, preparing for what has already been a very devastating fire season.” Only he’s not. Getting on with the job would be calling a moratorium on new thermal coalmines and gas fracking. Getting on with the job would be announcing a subsidised transition to electric vehicles by 2030. Getting on with the job would be working to close down all coal-fired powered stations as a matter of urgency. Getting on with the job would be calling a summit of the renewable energy industry and asking how the government can help make the transition one that happens now and one that creates jobs in the old fossil fuel energy communities. And getting on with the job would be going to the world with these initiatives and arguing powerfully, strongly, courageously for other countries to follow as we once led the way on the secret ballot, women’s suffrage, Antarctic protection, the charter of human rights. We are not a superpower, but nor are we a micronation. We have an economy the size of Russia’s. Our stand on issues whether good or bad is noted and quoted and used as an example. And one only has to look at the global standing of New Zealand to see the power of setting a moral and practical example, and the good that flows from it for a nation and its people. Australians everywhere are ready to get on with the job of dealing with climate change. We just need a prime minister to lead us. In the meantime though we are left with a mollied-up Humphrey B Bear. That same day, news broke of a panicked attempt by the federal government to administer some desperate triage over the growing costs to ordinary Australians of climate change in the form of perhaps the most ill-considered piece of policy in recent political history: to underwrite insurance premiums in north Queensland where premiums on homes in cyclone-affected areas are becoming unaffordable. Major insurers have been warning for years that many homes will no longer be insurable as the consequences of climate change are felt and have been demanding action on climate change. The government has done nothing and now wishes to use taxpayers’ money to hide the growing costs to individual Australians of climate change. If the government does go ahead with this panicked response the precedent established is pregnant with catastrophe for the public purse. According to a detailed report by SGS Economics and Planning released at the beginning of this year more than 1.6 million Sydneysiders are at high risk of flooding or bushfires, about 2 million Brisbane residents face extreme risks from cyclones, and more than 4.4 million people in NSW and Queensland live in areas with extreme or high risk of cyclones. It will be impossible for any government to subsidise the premiums of Townsville residents with cyclone risk and not offer it to those in Huonville whose fire risk also increases yearly. And yet the government will not act on the fundamental problem that leads to those risks, choosing instead to use the public purse to hide the growing evidence of its failure. The man who brandished a lump of coal and told us not to be scared, the man who last October told farmers to pray for rain, the man who says there is no link between the climate emergency and bushfires, the man whose party has for 30 years consistently and effectively sought to prevent any action on carbon emissions nationally and internationally will finally have to answer for the growing gap between his party’s ideological rhetoric and the reality of a dried-out, heating, burning Australia. And as the climate heats up ever quicker, and as the immense costs to us all become daily more apparent, that day draws ever closer. Many political commentators tend to view Morrison as some political genius, the winner of the unwinnable election. But history may judge him differently: a Brezhnevian figure; the last of the dinosaurs, presiding over an era of stagnation at the head of a dying political class imprisoned within and believing its own vast raft of lies as the world lived a fundamentally different reality of economic decay, environmental pillage and social breakdown. A corrupted, sclerotic system incapable of the change needed, surviving only by and through a dull repression of dissent and dissenters can, nevertheless, seem eternal – until the hour it crumbles. At some point something gives. Something always gives. The longer the impasse, the more denied the common voice, the greater and more terrible that future moment. We still have other, better choices. We need leaders who will enable us to make them. Morrison’s Pentecostal religion places great emphasis on the idea of the Rapture. When the Rapture arrives, the Chosen – that is, those Pentecostalists with whom the prime minister worships and their controversial pastor – will ascend to Heaven while the rest of us are condemned to the Tribulation – a world of fires, famine and floods in which we all are to suffer and the majority of us to die wretchedly, while waiting for the Second Coming and Scott and co wait it out in the Chairman’s Lounge above. Could it be that the prime minister in his heart is – unlike the overwhelming majority of Australians – not concerned with the prospect of a coming catastrophe when his own salvation is assured? In any case, as a Christian whose faith is built on a direct reading of the gospels, the prime minister would know the most compelling and convincing form of betrayal has always been the embrace and kiss."
nan
"Samanth Subramanian argues that “the great trick of online retail has been to get us to do more shopping while thinking less about it – thinking less, in particular, about how our purchases reach our homes” (Deliver us, 21 November). But consumers have never taken much interest in where stuff comes from or how it is delivered. In a survey of UK adults back in 2009, only 14% claimed to have “some knowledge” of the “role of logistics in the economy”. When logistics works, which is most of the time, it is taken for granted and ignored. As a result, few people have any sense of the complexity, transport-intensity, environmental impact and social costs of modern supply chains, not just on the “last mile” but all the way back to the raw material source. Greater public awareness of distribution systems upstream of the home and shop could help to promote more sustainable patterns of consumption and more informed debate on subjects such as Brexit, climate change and the gig economy, all of which have an important logistical dimension.Prof Alan McKinnonKühne Logistics University, Hamburg, Germany • Join the debate – email guardian.letters@theguardian.com  • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitterDepending on which global temperature data one looks at, temperatures have not increased in the last 18 or so years. The reasons proposed have been various, ranging from natural cycles to increased aerosols, to heat escaping to space or the deep ocean.
Perhaps there are some other reasons that have not been considered. The following is a simple list, with illustrations. The list is divided into two sub-lists. Things that are natural and things that are anthropogenic or man made.
SOME NATURAL REASONS
 1. It’s The Atlantic Multidecadal Oscillation (AMO)

The AMO has been at the top of it’s warm phase since 1998. The index doesn’t get much higher than it is now. It can only go down from here. It was at a similar peak during the warm 1930s through the 1960s. It was negative during the cool 1970s. The peaks of the AMO tend to be flat for a couple of decades before flipping cool. We don’t know what drives the AMO. Data here.
2. It’s The Pacific Decadal Oscillation (PDO)

The PDO has been trending down since the early 1980s. It also was up during the 1930s and negative during the 1970s. The AMO and the PDO are the natural ocean cycles that climate scientists talk about. The PDO reached a peak in the 1980s and has been declining since. This index is volatile. The PDO has a huge effect on weather on the Pacific Coast of North America. Data here.
 3. It’s The AMO and PDO together

They are sometimes roughly added together. (Even though they are not measuring the same thing.) If one adds them together, it can be seen why the late 1930s were warm and the 1970s cool. The sum (green trace) reached a peak in 2000 and is now declining because of the declining PDO. (Computed by author.)
4. It’s the sun

The sunspot number (SSN) average has declined since the mid-1990s. One can see a cause for the 1970s cooling in the SSN, but not for the 1930s warming. The early 20th century cooling may have been caused by the low SSN around the turn of the century. The sun is excused for the recent pause because the total solar index (TSI) changes only by a fraction of a Watt/m2 over large changes in SSN. But other factors may be in play. (Source: WDC-SILSO, Royal Observatory of Belgium, Brussels.)

5. It’s cosmic rays
The neutron count is an indicator of the cosmic ray flux at the top of the atmosphere. Here is the neutron count at Oulu, Finland since 1965. It is thought that cosmic rays seed cloud formation. Therefore high recent count is providing cooling clouds. Graphic downloaded from here, the Sodankyla Geophysical Observatory, University of Oulu, Finland.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




6. It’s clouds and earth’s albedo
Albedo and cloud cover reached a peak in the 1998-2000 era, at the beginning of the pause. Clouds, especially high clouds, reflect solar energy. Each 1% of albedo change translates to 1 W/m2. There is another graphic of albedo from the EarthShine project, here. All the albedo data show a significant rise in albedo after 1998. The cosmic ray/neutron count may not match the albedo/cloud cover, but cloud cover really did increase. Graphic used by permission of Dr. J. Floor Anthoni, and seen here.
PAUSE IS ANTHROPOGENIC
I mean by anthropogenic that man may have caused the pause by manipulating the temperature data. These manipulations seem to enhance the warming trend in support of politics, though the stated intent for many was to enhance accuracy. Here are some examples:

7. It’s the time of observation (TOBs) adjustment
Observing times have been gradually changed from afternoon to morning hours. The bias from this adjustment was about 0.2°C for TMax and 0.25°C for TMin. This impacts the historic data, but also, this adjustment is now finished. Most measurement sites now use morning observing times and no more changes will be made, hence the pause. No more warming will come from this source. The TOBs adjustment is clearly visible in the DIFFERENCE BETWEEN RAW AND FINAL USHCN DATA SETS graphic below, though it is only half of the total. Figure from here.

8. It’s all adjustments including TOBs
This graphic shows the result of all adjustments: homogenization, sensor changes (CRS vs MMTS), and TOBs. Note also that the warming due to all these changes is about 0.5°C, much of the warming that is supposed to have taken place since 1950. Note that these changes went flat during the 1990s decade.  Note the similar shaped curve to the TOBs adjustment with a flat shape in recent times. There should be no more warming from this source. Figure from NOAA/NCDC here.
9. It’s the number of stations

Since 1980, the number of stations reporting temperature data has declined by half. Some of the decline was due to the collapse of the Soviet Union. This resulted in loss of data from the Russian high arctic and Siberia, among the coldest land stations in the Northern Hemisphere. Some of these stations have resumed reporting in recent years, but most have not.
Other stations in Africa and Asia were closed by newly independent former colonies. World-wide, many stations closed instead of being upgraded. On average the remaining stations are at lower elevations and in warmer, populated areas. This situation has now stabilized. Figure from NASAGISS here. A discussion of this problem is here.
These are nine possible reasons for the pause. One or two are sufficient. Nine is overkill.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWe already have Climate Audit, but now it looks like we may be getting “Climate Scientists on Trial”. Here’s a site you’ll want to subscribe to, bookmark – or at least visit on a regular basis:
climatechangepredictions.org
As the name says, it focusses on earlier climate predictions made by the global warming alarmists (and there have been many) and compares them to what really happened. The climatechangepredictions.org site is run by Ian Hipwell, a retired lawyer from Sydney, Australia.
I think Ian will be a real asset because in his profession one is often trained to hold people’s feet to fire. Many like to say or write things, but are they able to back it all up later on. After all people who listen to these experts often act and make decisions based on the things said, and thus may incur either benefit or major damage as a result.
Alarmist scientists have said lots of things in the past, and it’s time to go back and look at them. The approach could be something like: Mr. Scientist, 15 years ago you said snow and ice would be things of the past, yet we are now seeing record snowfalls and harsh winters. Which is the lie?
In an e-mail to me Ian has written that although he is not scientifically trained, he has “followed the climate change issue as a hobby for some years. It was the name calling by AGW supporters that first made me suspect that the case wasn’t as strong as we had been led to believe.”
He writes that his intention is “to invite people to consider that perhaps the science isn’t settled after all“. Yes, the jury is still out.
And because so many of the earlier predictions made over the past 40 years have been within the realms of absurdity, Ian writes that the blog will surely provide a fair amount of humor. Indeed. For us skeptics the earlier claims of snow being “a thing of the past” and the Arctic being ice free by 2014 still continue to be the source of much laughter.
I think having this kind of blog, which devotes effort on examining past predictions, is a great idea because this is what science really gets down to. After all if the observations contradict the hypothesis and predictions, then the hypothesis is simply wrong.
 
Share this...FacebookTwitter "
"Student activists at Cambridge have accused the university of attempting to greenwash its relationship with oil and gas firms by stealing their group’s name for a university project. Cambridge University is to launch its Cambridge Zero initiative at an event in London next week. The project’s website, which is already live, touts it as a “bold response to the world’s greatest challenge”.  It says that, along with developing greener technology, it will “harness the full power of the university’s research and policy expertise, developing solutions that work for our lives, our society and our economy.” The project is to be led by Dr Emily Shuckburgh, a climate scientist and mathematician who previously spent 13 years as a researcher with the British Antarctic Survey. Cambridge Zero’s portfolio of research will include work on zero-carbon energy alternatives, policies, industries, financial processes, transport and climate repair. The university says its 2018 carbon reduction strategy makes it the first university taking science-based steps to achieve “absolute zero” net carbon by 2048. Cambridge has come under criticism for its links to the oil and gas industry, most recently over a £6m donation from Shell to a laboratory studying methods of hydrocarbon extraction. The university has begun to lobby journalists for positive coverage of the launch. Critics from the student-led Cambridge Zero Carbon society, who have been campaigning for the university to divest from fossil fuels, say it is a public relations stunt designed to divert attention from continuing links to oil and gas giants. “Taking our society’s name, which has stood for climate and reparative justice, for the university’s fossil fuel-partnered PR stunt spin initiative in order to give social legitimacy to climate criminals is exceptionally unhinged and morally bankrupt,” a spokesperson for the group said. Campaigners expressed concern about Shuckburgh’s work on a 2013 project with oil exploration company Schlumberger, and said that Shuckburgh had shared stages at events with oil executives. Activists also raised concerns over Cambridge Zero’s planned partnership with the BP Institute – a university institute endowed and part-funded by the oil giant BP – to research geo-engineering techniques, including carbon capture. In a letter to the Guardian after the initial publication of this article, Shuckburgh said she had never given a talk at an event organised by BP. “As a prominent climate scientist, I have been on many panels talking about climate science and there have been occasions on which oil executives have been on the panels too.” This in no way implied a connection with the fossil fuel industry, Shuckburgh’s letter said. She said that as principal researcher on a 2013 grant provided by the National Environment Research Council she had used data from Schlumberger ship surveys to contribute to work on fuel efficiency and to academic writings. The project was not for Schlumberger, the letter said. In 2012, 2015 and 2018 she had given climate science talks to masters students at the BP institute, a research institute at Cambridge university. A joint letter by the EcoNexus and Biofuelwatch advocacy groups accused Cambridge Zero of “Orwellian spin” by describing the work as “climate repair”. They said: “Geoengineering is a fantasy technology that at best legitimises the ongoing ecocide and genocide perpetuated by fossil fuel companies, and if implemented would have a devastating and unpredictable impacts on ecosystems and human communities around the world.” A university spokesman said: “Cambridge Zero is the University of Cambridge’s response to calls for action on climate change. It harnesses the research, innovation and policy ideas from more than a thousand academics across the university with a singular focus on decarbonising the modern economy. Dr Emily Shuckburgh is one of the UK’s leading climate scientists with a 25-year academic career dedicated to scientific discovery exclusively related to climate science at Oxford, MIT, Cambridge and the British Antarctic Survey.” • This article was updated on 24 and 26 November 2019: to include a response provided by Dr Emily Shuckburgh; and to remove unfair implications about her interactions with the fossil fuel industry, for which the Guardian apologises."
nan
"Jeremy Clarkson has made what could be the biggest reversal of his 30-year career. The anti-environmental columnist has, for the first time, accepted the existence of global heating after seeing the impact for himself. Clarkson’s epiphany came as he and his Grand Tour co-stars ran into difficulty while filming a 500-mile boat race from Siem Reap in Cambodia to Vung Tau in Vietnam.  The group’s jet boats slowed to a crawl and they were forced to wade through Tonlé Sap lake in the usually vast Mekong river system, which has been affected by water shortages. “The irony is not lost on me,” he told the Sunday Times. “A man who hosted a car programme for 30 years, limited to 7mph by global warming.” He described enduring “two days of absolute frustration” as the group had to be towed through the river, which had been reduced to a “puddle”. The former Top Gear host confessed he found the “graphic demonstration” of global warming “genuinely alarming”. However, Clarkson does not appear to have yet embraced the green movement he once dismissed as “eco-mentalists”. “But we don’t blame mankind for it,” he said. “We’ll let Greta [Thunberg] do that.” He took yet another dig at the 16-year-old Swedish campaigner in his interview, accusing Thunberg of having no answers to the climate crisis. “‘Ooh, we’re all going to die.’ Right, tremendous. Now go back to school,” he said. “But I genuinely hope people people are working on what on earth to do about it.” Clarkson had previously used his column in the Sun to label Thunberg a “spoilt brat”, following her speech at the United Nation’s climate action summit in September. “How dare you,” Thunberg scolded world leaders at the New York summit. “‘You have stolen my dreams and my childhood with your empty words.” In 2009, environmental campaigners dumped manure on Clarkson’s lawn in response to his attitude to global heating. Grand Tour, the lavishly funded series that Clarkson started after his acrimonious departure from the BBC’s Top Gear, returns to Amazon Prime on 13 December. The BBC revealed on Saturday that Thunberg will guest-edit a Christmas special of Radio 4’s Today programme. The campaigner is set to speak to leading figures in the fight against global heating and has commissioned reports from the Antarctic and Zambia."
"
Share this...FacebookTwitterStefan Rahmstorf: No pause, anywhere!
By Michael Krueger
[Translated by P. Gosselin)
“No pause, anywhere!” announced Stefan Rahmstorf in his latest article at KlimaLounge. And he added: “As our long-term readers know, there’s been a steady global warming since the 1970s, though it has been superimposed by the usual short-term fluctuations, it has not slowed down or accelerated by any significant means. […] As there has not been any slowdown, there has not been any pause or hiatus of any kind in warming.”
But this is easy to check over. To do this I’ve gotten the data on global temperature from the NOAA, plotted them and added the linear trends for the periods of 1970-2015, 1980-2015, 1990-2015, 2000-2015 and 2005-2015. (By the way, NOAA also uses the NASA GISS dataset for global temperature).

What is seen above is that the trend since 1970 has been in decline. The rise in the trend lines is becoming less and less., i.e. flatter and flatter. Meanwhile the global warming scientists have been telling us for year/decades that global warming would accelerate more and more as greenhouse gases increased.
In fact just the opposite has been true.
Here once again is the NOAA data in its original form from the NOAA site for the period of 1998-2015.

There are actually people who see in it an unabated global warming (in the range of 1/100 of a degree). Hard to believe. Yes, you only have to believe in it, and suddenly you’ll see it. It’s like the blotch images in psychology.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Germany-based European Institute for Climate and Energy (EIKE) held another conference on climate and renewable energy last March. One of the speakers was Prof. Dr. Dieter Ameling, an expert in heavy industry. EIKE has posted his presentation. 

In the presentation Ameling calls Germany’s Energiewende (transition to renewable energies) a real threat to industry, warning that the country faces a de-industrialization.
Already, Ameling reminds us, every day the Energiewende in Germany is progressing and that the damage already done is getting even worse and that “foremost it will soon be irreparable“.
Subsidies’ vast divergence from earlier projections
At the 5:15 mark he calls the German government’s 2022 targets for renewables “economic nonsense” and will result in “electricity getting continuously more expensive“.
His following chart shows a comparison of the German government’s projected green energy subsidies compared to that of reality:

The gray bars show the government’s projected annual subsidies in billions of euros. The blue bars depict the real skyrocketing subsidies. In 2014 the subsidies rose even further, to 23.6 billion euros. Chart: Dr. Dieter Ameling.
“Unaffordable” and “absolute imbecility”
The big problem, Ameling emphasizes, is the huge supply-volatility in wind and sun, which are totally weather-dependent. At the 9:35 mark the retired professor calls the German state of Bavaria’s energy-mix plan for 2022 as something that “cannot function“…”is unaffordable“, and “is absolute imbecility“. 
The chart at the 11:20 mark shows how Germany has one of the highest electricity prices worldwide, more than double the rate found in USA, Canada, or Russia. 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




At the 13-minute mark another chart shows the huge gap in natural gas prices between Germany (10.7 cents per gas unit) and the USA (only 3.7 cents per gas unit). Thanks to fracking, gas prices in USA have tumbled while in Germany poor households barely can afford to heat their homes.
Germany’s skyrocketing electricity prices
At the 13:34 mark Ameling displays a chart showing Germany’s electricity price development:

Since 2000 the price of electricity in euro-cents/kwh in Germany has more than doubled! Currently a 4-person household is paying over 366 euros a year just for the green energy feed-in tariffs alone. Ameling warns that figure will continue to rise rapidly.
Exodus of industry leaving Germany, Europe
Later in the presentation Ameling shows how the energy-intensive industries such as cement, glass, steel, chemicals etc. are being hit hard by the skyrocketing energy costs. In Germany alone 3.5 million jobs depend on the steel industry. At the 19:03 mark Ameling warns that the exodus of industry “has already begun” with heavyweight companies such as ThyssenKrupp, Norsk Hydro, BASF, SGL Carbon and Voest moving operations abroad.
1 trillion euros!
How much is Germany’s Energiewende projected to cost? In 2013 former Environment Minister Peter Altmaier told the Frankfurter Allgemeine Zeitung it would cost Germans 1 trillion euros!

At the end Ameling summarizes, announcing that the “Energiewende has failed” because it is simply too expensive and too volatile. The infrastructure that is needed to handle it is not even in place. Unless Germany radically alters the current direction of its Energiewende, Ameling says it will be “bye bye Germany“.
He ends the presentation with the following Friends of Science image, reminding us that CO2 is not even the driver of climate.

Share this...FacebookTwitter "
"Every year, the NEC in Birmingham, England, becomes a magnet for dog lovers, as more than 22,000 canines assemble for Crufts. Founded by travelling dog-food salesman Charles Cruft in 1891, Crufts has become one of the world’s largest and most prestigious dog events. Here, you can meet dogs of every shape and size, see inspiring human-dog partnerships and shop for all things dog-related. There’s always a fascinating mix of people in attendance – and this year, I get to be among them.  So what is it about Crufts I find so enthralling? Well, far from being a beauty pageant for pampered pooches, these days Crufts is a celebration of all things canine – and for a self-confessed “dog person” like me, that’s an exciting prospect. But more importantly, Crufts challenges me to reflect on the bond between humans and dogs from a scientific perspective.  There is no doubt that humans and dogs have a prolonged evolutionary relationship. Since dogs were first domesticated, humans have selectively bred them to bring out particular physical and behavioural characteristics. Selective breeding has resulted in the wide diversity of about 400 pedigree dog breeds recognised today, from the diminutive Chihuahua to the Great Dane. But sadly, many pedigree dog breeds suffer from defects and diseases, which affect their welfare and longevity – these are often a consequence of inbreeding.  Yet it seems that science is coming to the rescue of our doggy companions. Recent research has shown that rates of inbreeding in many pedigree dogs are actually declining from a high in the 1980s and 1990s. This suggests that dog breeders are becoming better informed, and improving their practices. For example, genetic tests are now used by many dog breeders, to ensure that breeding animals are genetically healthy.  Crufts provides an ideal place to educate and inform dog owners, breeders and puppy hunters about the value of such health tests.  Increasing our awareness of issues associated with all dog breeds – including “designer” cross-breeds such as cockapoos and labradoodles – can only improve quality of life for both dog and owner.    The deep bond between people and their dogs is also demonstrated in a wide range of canine activities at Crufts: from the frenetic relay races of flyball, to the precise movements of dog and handler in obedience. These activities offer a physical and mental challenge for dogs and owners alike. And with rising levels of canine obesity mirroring that of the human population, strategies to improve physical activity levels for both species will be of significant mutual benefit.  Crufts offers a great platform to promote schemes such as “Get Fit with Fido” – a weight loss competition run by the Kennel Club. Research suggests that many pet dogs aren’t walked daily, so showcasing mutually enjoyable physical activities, such as agility training, might just encourage some dog owners to get a little more active with their pets. The activities at Crufts can help us to understand the science behind what makes a good canine athlete: from gundogs, to “dancing” dogs in the canine freestyle event, to world-class agility dogs. In fact, canine performance science is a rapidly growing area of interest, encompassing genetic selection, puppy rearing, training, housing, handling and health for working dogs. Crufts visitors will see many dogs trained using methods which have been improved by new insights into canine learning – a simple way that science has contributed to canine welfare.   Yet this relationship goes both ways: in fact, dogs can be credited with providing many human health benefits, beyond the customary “walkies”.  Dog owners report higher levels of perceived health than non-dog owners, and were found to have more vitality, and better social lives and mental health. One famous study even suggested that dog owners lived longer after a heart attack than non-dog owners. Whether this is a genuine effect of pet ownership, or a sign that people who own pets tend to have a particular personality type, has not been established – but it remains an area of fascination for those interested in the human-dog relationship.  Of course, assistance dogs such as guide dogs, hearing dogs and mobility dogs are essential companions and lifesavers. What’s more, anecdotal reports of dogs signalling to their owners the onset of diabetic hypoglycaemic attacks or epileptic fits have been confirmed by scientific study. So-called “therapy pets” play a valuable role in homes, hospices and hospitals, making patients happier and acting as non-judgemental confidants. Some dogs have even been trained to detect prostate cancer, putting a whole new spin on the “lab test”.  Many organisations involved in the training of these dogs are represented at Crufts, and the “Friends for Life” award recognises their exceptional bravery, support and companionship. There is no doubt about it: we humans share a special connection with our canine companions. And Crufts is the perfect place to celebrate it."
"Walking the galleries of a natural history museum, you might be left with the impression that not all animals were created equally. (Of course, if you study the displays about evolution, they’ll tell you that they weren’t created at all.) There is a noticeable bias in what kinds of animals museums choose to display: on the whole, the huge, exotic, rare and extraordinary get more than their fair share of shelf-space. As a result, natural history museum galleries are not accurate reflections of the nature they might be thought to represent. Around 80% of described species are arthropods – the group that contains insects, crustaceans and arachnids; and around 80% of living individual animals are nematode worms. As is commonly argued by specialists in these fields, these ecologically and numerically dominant groups are not given the attention they statistically deserve. But there is another group that is also regularly banished from most museums: those more mundane animals that feature heavily in our everyday lives, as pets, livestock and scientific subjects. They are not deemed special enough. Do people want to go to a museum to see animals that we can find on our plates, on our laps and on our streets? It is thought that we would rather see dinosaurs, dodos and giant whales. So these animals are rarely represented in natural history museum displays. That is why we at UCL’s Grant Museum of Zoology have dedicated an exhibition to these somewhat sidelined creatures – to give them a chance to tell their stories. By staging this exhibition, which we have called The Museum of Ordinary Animals, we want to highlight the boring beasts that have changed the world, including dogs, rats, cats, cows, chickens and mice.  Ordinary animals are everywhere, and the ways they interact with our lives are endless and varied. We have invited them into our homes as pets; their role in our diets has changed us biologically; they are critical to modern medicine and they hold huge symbolic value in many cultures. These animals have had profound impacts on humanity and the natural world, and we have learned extraordinary things from them. While (most) natural history museums are dedicated to communicating that the species on display are a product of evolution, many of these ordinary animals were in fact created: they have come into existence through unnatural means. Humans have been domesticating animals ever since dogs were formed from wolves, though the process was often not deliberate. Other domestic species were deliberately brought into being, at least to some extent. The breeding of livestock such as cattle, goats and sheep would ease the growing human population’s problem of the over-hunting of wild animals. Others still, such as domestic hamsters, were only created in recent decades, to fill human scientific and aesthetic desires (they were intended as lab animals before they became pets). So is their “unnaturalness” the reason why ordinary animals have largely been removed from natural history museums? The concept of some animals being outside the boundaries of “nature” is an interesting one (it’s worth saying that some people argue that humans are a natural species, and therefore everything we do is “natural”, but I think that’s a dead end, as it renders the already abstract concept of nature meaningless). The natural history of these species is not the same as the rest of the animal kingdom’s. We can think of them more in the context of social history, as their stories are so utterly intertwined with our own. Studying chickens, for example, allows the worlds of evolution, archaeology, genetics and theology to interweave. UCL geneticist Mark Thomas, who contributed to the exhibition, tells us that around 1,000 years ago, there was massive evolutionary pressure for domestic chickens to be able to lay eggs all year round and to be less aggressive (allowing for the confinement of many individuals in a small space). At the same time, chicken bones become significantly more common in the archaeological record, showing that people were eating more of them. Remarkably, this coincides with a decree from Benedictine monks to avoid eating four-legged animals on fast days. Birds and eggs were exempt. Although chickens were first domesticated around 6,000 years ago, the features that essentially led to the chickens we know today (including battery hens), were arguably brought about by a religious diktat. Among the most ubiquitous of ordinary animals is the house mouse, originally from India. We have a collection of around 9,000 house mouse skeletons in the Grant Museum, collected from islands around the world: humans have given them near global distribution. The skeletons are the result of a study into the effects of island living on evolution. Museum storerooms are full of such objects: but they are intended for research, not display. When we visit museums we have the chance to see that evolution has produced some extraordinary species and mind-blowing diversity: it is these exotic and glamorous animals that we tend to find on display. But it’s important to remember that the more ordinary species - which are often the product of human intervention as much as evolution – also have incredible stories to tell us. The Museum of Ordinary Animals runs until December 22 at the Grant Museum of Zoology, UCL, London."
"We live in a world drowning in objects: households with a television in each room; kitchen cupboards stuffed with waffle makers, blenders and cappuccino whisks; drawers filled to bursting with pocket-sized devices powered by batteries – batteries which themselves take a thousand times more energy to make than they will ever provide.  Just over a century ago, “disposability” referred to small, low-cost products such as disposable razors and paper napkins. Today, practically everything is disposable – it is culturally permissible to throw away anything from a barely-used smartphone, television, or vacuum cleaner, to an entire three-piece suite or fitted bathroom. This has led to the serious problem of electronic waste. In the European Union, mountains of scrapped circuit boards and other computer junk are growing three times faster thank any other type of waste in the EU. We generate 40 tonnes of waste in the process of manufacturing just one tonne of electronic products – yet 98% of these products are discarded within just six months of purchase. Given the huge quantities of precious resources (including gold and other rare metals) that find their way into our gadgets, it would surely be worth us taking more care of them, repairing them when broken, and keeping them for longer. In fact, the opposite is happening: product lifespans are shortening as material culture becomes increasingly disposable.  The notion of a “throwaway society” is nothing new. American economist Bernard London first introduced the term “planned obsolescence” in 1932 as a means to stimulate spending among the few consumers who had disposable income during the depression. The concept was popularised by Vance Packard in his The Waste Makers in 1964. In fact, the concept of disposability was a necessary condition for America’s cultural rejection of tradition and acceptance of change. There is a different approach, however – one of emotionally durable design, which can help us to reduce the consumption and waste of resources by building a more lasting relationship between us and the products we buy. Simply put, it helps us design products that are built to last longer, and provide a longer-term experience.  The term “emotional” is used here because wasteful patterns of consumption and waste are driven, in large part, by emotional and experiential factors. We tire of things, novelty wears off all too quickly and we fall out of love with them, so to speak. Considering emotional durability at the design stage helps us to wean people off their desire for the new, and can shape new and sustainable business models. Here, longer-lasting products have the potential to build economic models around creating robust products, upgrade and repair services, and brand-loyal customers – all without excessive waste.  In design terms, we can support greater levels of emotional longevity when we specify materials that age gracefully, and that develop quality over time. We can design products that are easier to repair, upgrade and maintain throughout their lifespan. These are effective product life extension strategies, and while they can come at an increased cost at point of purchase, they generate revenue downstream, through the introduction of service and upgrade packages. Extending the life of a product has significant ecological benefits. For example, take a toaster that lasts about 12 months. Even if the toaster’s life is extended to just 18 months through more durable design, the extra longevity would lead to a 50% reduction in the waste consumption associated with manufacturing and distributing it. Scale this up to a national or international population of toaster-buyers, and it’s clear how significant an impact this could be. There is a growing sense that the consumer electronics industry must transition from a linear economy to a circular one. A circular economy is one in which resources are kept in use for as long as possible. The maximum value is extracted from them, while materials and energy are recovered or recycled as much as possible at the end of any product’s life. This is a seismic shift in thinking, affecting everything from the design and delivery of short-life products, to that of longer-lasting material experiences.  Simply having more stuff stopped making people in Britain happier decades ago. The New Economics Foundation (NEF) argues for an economy of better, not more. One in which things age gracefully, where they last and can be repaired many times before being recycled, allowing us to share better the surplus of stuff we already have. Designing products that can be kept for longer nurtures a deeper relationship with both the product and the brand, which increases the likelihood of brand loyalty maturing.  Such emotionally durable design doesn’t just make sense from an environmental and resources perspective, but can be seen as a commercially viable business strategy in an increasingly competitive globalised world."
"Ursula von der Leyen has said the EU as the world’s “trading superpower” will lead the fight against the “existential threat” from the climate crisis, and offered a waspish farewell to the Brexit party, as MEPs backed her new European commission to start work on 1 December. The European parliament, sitting in Strasbourg, approved the new college of commissioners, headed by the EU executive’s first female president, by 461 votes to 157 with 89 abstentions on Wednesday, giving her a larger majority than her predecessor, Jean-Claude Juncker.  Von der Leyen said the level of support she had secured, while less than that for José Manuel Barroso in 2004 and 2010, was a vote of confidence in what she described as an “agenda for change”. The Green party, which has been unconvinced by the radicalism of Von der Leyen’s approach, abstained in the vote and anti-EU parties including Italy’s far-right League and France’s National Rally rejected the proposed commission. The commission, which will be formally approved by leaders on the European council on Thursday through a written procedure, is forming a month later than intended as a result of MEPs rejecting the original nominees from Hungary, France and Romania. Von der Leyen’s hour-long speech to MEPs lacked the ad-libbing of Juncker, who was never shy of causing controversy, and offered few eye-grabbing policy initiatives. But when Brexit party MEPs clapped and cheered at the mention of Brexit, the incoming commission president strayed from her notes. “A vast majority of this house seems to be happy about the fact a very, very, very small group in this house would not be able to clap as loud any more,” Von der Leyen said. “And I have never, ever made any secret about that fact that I will always be a remainer.” She added: “We will respect the decision taken by the British people. We will work closely together on solutions to common challenges, especially security matters. But one thing has to be absolutely clear: whatever the future holds, the bond and the friendship between our people are unbreakable.” Von der Leyen repeatedly emphasised that her top priority upon taking office this Sunday was dealing with the climate emergency and ensuring the end of carbon emissions by the middle of the century. The commission is set to unveil its “green deal” on 11 December. She said: “This is an existential issue for Europe – and for the world. How can it not be existential when 85% of people in extreme poverty live in the 20 countries most vulnerable to climate change? How can it not be existential when we see Venice under water, Portugal’s forests on fire or Lithuania’s harvests cut by half because of droughts? This has happened before but never with the same frequency or intensity.” Von der Leyen said the commission would look to robotics to move people out of occupations that she suggested should no longer be carried out by people. She said: “We will automate work that is wearisome for us humans: carrying heavy loads, performing repetitive tasks in factories or in offices. And this will give us time. Time for what distinguishes human beings. Time for what computers can’t do: empathy and creativity.” Von der Leyen said she wanted the commission to be “geopolitical”. “We can be the shapers of a better global order”, she said. She made a thinly veiled reference to the policies of Donald Trump in a section of the speech criticising those who sought confrontation and unilateralism. Of the transatlantic relationship, she said: “Yes, we have issues – without any doubt. But our ties have lasted the test of time. While we are speaking, thousands of students, researchers, entrepreneurs, artists continue to build zillions of friendships, business contacts and science projects. These myriad of fine threads woven together make a bond that is stronger than any individual point of discord.” On a personal note, Von der Leyen – who was born in Germany and spent much of her childhood in Brussels where her father was an official – said her commission would seek to lead in the fight against cancer across the EU. “When I was a girl, living in Brussels, my little sister died of cancer at the age of 11,” she said. “I remember the utter sense of helplessness of my parents, but also of the medical staff who looked after her with such care. Every one of us has a similar story or knows someone who has. The number of cancer cases is rising but we are getting better at diagnosis and treatment. Europe will take the lead in the fight against cancer.” Phil Hogan – trade Known in Ireland as Big Phil, Hogan will oversee the post-Brexit trade talks. This is his second term in the commission. As agriculture commissioner he was given the nickname Farmer Phil by the European commission president, Jean-Claude Juncker. Hogan has not shied away from intervening in the Brexit debate: at one point he warned people to ignore the views of the “three stooges” – Boris Johnson, Nigel Farage and Jacob Rees-Mogg. Věra Jourová – values and transparency In 2006, Jourová spent a month in a Czech jail on false corruption charges. Now she will oversee the sensitive issue of democratic backsliding. Hungary and Poland have been accused of undermining the independence of their judiciaries in recent years. Ursula von der Leyen has suggested she will look to link member states’ record on the rule of law with EU funding. Virginijus Sinkevičius – environment and the oceans At 29, Lithuanian Sinkevičius is the youngest ever EU commissioner and the first to be born after the fall of the Berlin wall. He graduated in 2012 with a degree in economics and international relations from Aberystwyth University and has studied courses at the universities of Maastricht and Oxford. He became an economics minister in the Lithuanian government at the age of 27. Thierry Breton – internal market A former chairman and chief executive of the IT firm Atos and one-time finance minister under Jacques Chirac, Breton was chosen for this big portfolio by the French president, Emmanuel Macron, after MEPs rejected France’s first choice, Sylvie Goulard. She had been accused of using a European parliament assistant for domestic political work when she was an MEP. Breton doubled Atos’s revenues between 2008 and 2019 to around €12.3bn by moving into cloud computing and big data. Ylva Johansson – migration, asylum and internal security Migration remains one of the biggest challenges for the EU, with criticism growing about the bloc’s funding of the Libyan coastguard and the deplorable conditions in which migrants are detained by the authorities in Libya. Johansson, a former minister in the Swedish government, has said she wants a new pact among the member states on migration and an overhaul of asylum rules. But she admitted to MEPs during hearings that there would not be any new proposals during her first 100 days in office."
"
Share this...FacebookTwitterAfter the European heat wave of last week, the pendulum has swung to the other extreme.
Currently the weather pattern dominating Central Europe is bringing unusually cold air over the continent, and early this morning regions in a number of countries were hit by ground surface frost.
Parts of Belgium, Luxemburg, Germany, Switzerland, Austria and the Czech Republic saw surface frost – even down to the lower elevations (Belgium is hardly a mountainous region).
German site Wetter24 twittered here a map depicting the frosty areas gripping this 10th of July, 2015. Also see map here.
Swiss meteorologist Jörg Kachelmann here writes and supplies a link showing a German video reporting conditions that the German Eifel region woke up to early this morning. At the 1:50 mark the video reports:
We saw fields that were snow-white. That on the tenth of July I have never seen before. My colleague Fabian had also never seen this before. It just looked wonderful. We just thought that indeed we are not in autumn or spring; we are actually in July. These pictures impressed us, and that we found this frost.”
Apparently the “greenhouse effect” of atmospheric CO2 was unable to trap the heat and prevent frost from forming at ground level.
Yesterday Aonach Mor and Strathallan in Scotland saw frost. So did Blackpool and Exeter in England!
Central Europe and Great Britain were not the only places at the middle latitudes of the northern hemisphere that saw frosty conditions. ABC News here reports that “Tioga Pass was closed from 4 miles west of Jct 395 to the Yosemite National Park entrance gate, due to snow.”
Also the southern hemisphere has seen cold weather as well. The forecast for Australia is calling for below normal temperatures.
Share this...FacebookTwitter "
"I trampled clumsily through the dense undergrowth, attempting in vain to go a full five minutes without getting snarled in the thorns that threatened my every move. It was my first field mission in the savannahs of the Republic of Guinea. The aim was to record and understand a group of wild chimpanzees who had never been studied before. These chimps are not lucky enough to enjoy the comforts of a protected area, but instead carve out their existence in the patches of forests between farms and villages. We paused at a clearing in the bush. I let out a sigh of relief that no thorns appeared to be within reach, but why had we stopped? I made my way to the front of the group to ask the chief of the village and our legendary guide, Mamadou Alioh Bah. He told me he had found something interesting – some innocuous markings on a tree trunk. Something that most of us wouldn’t have even noticed in the complex and messy environment of a savannah had stopped him in his tracks. Some in our group of six suggested that wild pigs had made these marks, while scratching up against the tree trunk, others suggested it was teenagers messing around.  But Alioh had a hunch – and when a man that can find a single fallen chimp hair on the forest floor and can spot chimps kilometres away with his naked eye better than you can (with expensive binoculars) as a hunch, you listen to that hunch. We set up a camera trap in the hope that whatever made these marks would come back and do it again, but this time we would catch it all on film. Camera traps automatically start recording when any movement occurs in front of them. For this reason they are an ideal tool for recording wildlife doing its own thing without any disturbance. I made notes to return to the same spot in two weeks (as that’s roughly how long the batteries last) and we moved on, back into the wilderness. Whenever you return to a camera trap there is always a sense of excitement in the air of the mysteries that it could hold – despite the fact that most of our videos consisted of branches swaying in strong winds or wandering farmers’ cows enthusiastically licking the camera lens, there is an uncontrollable anticipation that maybe something amazing has been captured. What we saw on this camera was exhilarating – a large male chimp approaches our mystery tree and pauses for a second. He then quickly glances around, grabs a huge rock and flings it full force at the tree trunk. Nothing like this had been seen before and it gave me goose bumps. Jane Goodall first discovered wild chimps using tools in the 1960s. Chimps use twigs, leaves, sticks and some groups even use spears in order to get food. Stones have also been used by chimps to crack open nuts and cut open large fruit. Occasionally, chimps throw rocks in displays of strength to establish their position in a community.  But what we discovered during our now-published study wasn’t a random, one-off event, it was a repeated activity with no clear link to gaining food or status – it could be a ritual. We searched the area and found many more sites where trees had similar markings and in many places piles of rocks had accumulated inside hollow tree trunks – reminiscent of the piles of rocks archaeologists have uncovered in human history.  Videos poured in. Other groups working in our project began searching for trees with tell-tale markings. We found the same mysterious behaviour in small pockets of Guinea Bissau, Liberia and Côte d’Ivoire but nothing east of this, despite searching across the entire chimp range from the western coasts of Guinea all the way to Tanzania. I spent many months in the field, along with many other researchers, trying to figure out what these chimps are up to. So far we have two main theories.
The behaviour could be part of a male display, where the loud bang made when a rock hits a hollow tree adds to the impressive nature of a display. This could be especially likely in areas where there are not many trees with large roots that chimps would normally drum on with their powerful hands and feet. If some trees produce an impressive bang, this could accompany or replace feet drumming in a display and trees with particularly good acoustics could become popular spots for revisits. On the other hand, it could be more symbolic than that – and more reminiscent of our own past. Marking pathways and territories with signposts such as piles of rocks is an important step in human history. Figuring out where chimps’ territories are in relation to rock throwing sites could give us insights into whether this is the case here.  Even more intriguing than this, maybe we found the first evidence of chimpanzees creating a kind of shrine that could indicate sacred trees. Indigenous West African people have stone collections at “sacred” trees and such man-made stone collections are commonly observed across the world and look eerily similar to what we have discovered here. To unravel the mysteries of our closest living relatives, we must make space for them in the wild. In the Ivory Coast alone, chimpanzee populations have decreased by more than 90% in the past 17 years.  A devastating combination of increasing human numbers, habitat destruction, poaching and infectious disease severely endangers chimpanzees. Leading scientists warn us that, if nothing changes, chimps and other great apes will have only 30 years left in the wild. In the unprotected forests of Guinea, where we first discovered this enigmatic behaviour, rapid deforestation is rendering the area close to uninhabitable for the chimps that once lived and thrived there. Allowing chimpanzees in the wild to continue spiralling towards extinction will not only be a critical loss to biodiversity, but a tragic loss to our own heritage, too. You can support chimps with your time, by instantly becoming a citizen scientist and spying on them at www.chimpandsee.org, and with your wallet by donating to the Wild Chimpanzee Foundation. Who knows what we might find next that could forever change our understanding of our closest relatives."
"A blood-sucking, disease-spreading, whining creature is always going to be a hard sell, even to nature lovers. And the dreaded mosquito is now the prime suspect behind the sudden arrival and explosive spread of Zika virus in Central and South America. Zika is transmitted by a mosquito vector Aedes aegypti, a pan-global tropical species already well known for spreading diseases such as yellow and dengue fever.  There are only around 3,500 species of mosquito, which is modest for a family of insects – but their impact on human health and welfare is catastrophic. Female Anopheles mosquitoes carry the parasite that causes up to 500m cases of malaria a year while the Asian Tiger Mosquito, Ades albopictus, spreads dengue fever and the chikugunya virus. Mosquitoes have been ready vectors for emergent diseases such as West Nile virus and now Zika.  Mosquitoes are credited with causing more misery and loss to humanity than any other organism (with the obvious exception of ourselves). Mosquitoes are unlovely creatures, all twitchy legged and whining, their larvae infesting miasmas and dismal swamps. And under the right conditions they are mobile and expansionist pioneers, perfectly at home in the disrupted habitats we create. Which begs the question: what good do they do – and if we could wipe them from the face of the Earth should we? As pointed out by ecologist Sarah Fang, the consensus is that mosquitoes do not do any unique or particular good that would be missed. If you judge them according to ecologist Charles Elton’s gentle but evocative idea of each creature having a niche – much as every English village has a cast of characters who have their place such as butcher, baker and policeman – then mosquitoes seem to have no special purpose on the face of it. So one wouldn’t miss them, surely? Arguments in favour of mosquitoes fall into two broad categories. First that their sheer numbers are an essential link in some food webs, notably the Arctic tundras where, for a few brief weeks in summer they hatch in extraordinary numbers, creating visible clouds of adults and a very rich food supply to migratory birds that have come north to exploit this bounty.  Fang also suggests that the mosquitoes’ assaults may be ferocious enough to divert the migration lines of caribou with possible consequences at a landscape scale as the herds’ grazing and trampling shift location. In an unusually exact link between mosquitoes and their predators, a study of foraging Little Forest Bats, Vespadelus vultuernus, in eastern Australia revealed a very heavy reliance on adults of the mosquito Aedes vigilax. So, that Little Forest Bats need mossies may be as good a case as mosquitoes can muster. Juvenile mosquitoes are also important in some freshwater foodwebs, including as prey to specialists such as the mosquito fish, Gambusia affinis or in the tiny pools of water held in the leaf bases of pitcher plants and bromeliads high in the rainforest canopy. In among the canopy trees a miniature fauna of vividly coloured poison dart frogs and crabs thrive in the bromeliad pools, called phytotelmata, feeding off the bodies of drowned juvenile mosquitoes. But despite poison dart frogs and bats having their own fan club among ecologists and nature enthusiasts, they are unlikely to sway the majority of people in favour of mosquitoes. The second argument is that mosquitoes have a more general role providing ecosystem services such as pollination by adults or driving the release of nutrients as their young feed on organic detritus. But although mosquitoes can act as pollinators for orchids and golden rods, among other plants, they don’t have a monopoly – they are not especially suited to this role and there are plenty of other pollinators to take their place.  While the decline of the honey bee is a prominent example of an ecosystem service at peril, mosquitoes are just another one of the many pollination bit-part players, an unloved understudy that can be written out of the part. Their significance has always been to menace.  As the Portuguese explorer João de Barras said of the tropics: God has placed a striking angel with a flaming sword of deadly fevers, who prevents us from penetrating into the interior to the springs of this garden. So there seems no great reason to defend mosquitoes. Their destruction would lift a terrible curse from humanity. Except for one nagging doubt … All that warm, nutritious blood suddenly available. There are plenty of other midges and mites, black flies and fleas out there just waiting for the opportunity to step in. Be careful what you wish for."
"Beavers have recently made a tentative return to Britain. Scotland has led the way, with an official trial population in Knapdale, a remote area of lochs and forest in the west of the country; and another in Tayside to the east, suspected to come from private-collection escapees and unlicensed releases. Further south, a small feral population in Devon in south-west England is currently being tolerated by officialdom and admired locally, while there are also plans for a trial in mid-Wales. Should we let these beavers take up permanent residence? The Scottish government has first refusal. It is overdue to make a decision on the back of five years of scientific monitoring and other evidence. While conservationists wait with bated breath, we think there’s only one sensible choice – beavers should be allowed back. The EU’s Habitats and Species Directive has been the cornerstone of conservation policy in Britain for the last 30 years. It actively encourages member states to consider reintroducing formerly native animals. The Eurasian beaver is a good candidate, having dwindled in mainland Europe to a handful of small isolated populations by the late 19th century. Thanks to the directive, it is now re-established across most of its former range, making Britain something of a laggard. The beaver became extinct here 400 years ago. In fact, Knapdale represents the first legal attempt to reintroduce an extinct native mammal to the country.  None of this is about nostalgia. Beavers are often referred to as “ecosystem engineers” and herein lies much of the reasoning and controversy behind their reintroduction. There is extensive evidence from Europe and North America that wetlands created by beaver dams benefit everything from water plants, dragonflies and amphibians to fish and ducks to song birds and bats. In Knapdale, damming by beavers transformed a small pond into a wetland of a type and complexity probably unseen in Britain for centuries.  Beavers can also restore habitats without the need for a bulldozer or planning permission. On the Bamff estate on Tayside, we found that grazing by beavers trebled the number of wetland plants over a nine-year period. Where raised water levels saturated a meadow thanks to damming of ditches, the number of plant species increased by 49% and the multitude of habitats created increased the total diversity of aquatic invertebrates by almost 30%. Indeed the benefits were even further reaching. We found that the beaver dams also acted as a sink for agricultural pollutants, and may also help to reduce the risk of flooding. Individually these findings are not that surprising, though it is unusual to demonstrate them all in parallel. So it’s a no-brainer? While the Scottish public are broadly supportive of reintroducing these dog-sized, rather retiring herbivores, farmers, foresters and some anglers are less keen. Beavers get accused of damaging farm crops and commercial plantations through feeding, tree-felling, blocking streams, causing floods, undermining flood embankments and clogging up fish-spawning gravels.  These concerns are often legitimate and locally significant, and need to be addressed. Yet there are tried and tested ways of mitigating beaver impacts borrowed from the US and Germany that have already been trialled in Scotland, including live-trapping, electric fencing and so-called “beaver deceivers” for managing pond levels. At the same time, beavers have been wrongly held responsible for some high-profile flooding incidents and there remains a widely held but entirely mistaken belief among some anglers that they eat fish. In fact, the most recent analysis in Scotland suggests that beavers generally have a positive impact on the likes of trout.  The reality is that beavers, people and fish have co-existed for thousands of years. There is no reason why in principle this should not continue, even if beavers change the landscape and the landscape itself has changed in their absence. The successful reintroduction and effective management of beavers in central Europe testifies to their adaptability. Beavers bring multiple environmental benefits and the risk of local but manageable disruption shouldn’t eclipse these. In some senses the “beaver question” is a metaphor for the much bigger question of what sort of environment we want in Britain in future. Beavers are potentially at the vanguard of a wider movement called rewilding – transforming landscapes through everything from less intensive farming to reintroducing keystone species. Saying yes to beavers doesn’t mean opening the floodgates to all supposedly desirable species from bison to lynx, but it recognises that we can cope with changing how we run our land, and that the alternatives might be better. On the other hand, saying no to beavers would shut the door on any bigger ambitions, perhaps for decades.  This is also not about going back to the Stone Age – indeed taking land out of production might require more intensive farming elsewhere to address concerns about food security. Instead of imposing rewilding, we must seek the cooperation of landowners. We might incentivise this with subsidies to recognise the ecosystem services that species like beavers provide, while compensating inconvenienced landowners. And as well as mitigating against the impacts that reintroduced creatures can cause, we’ll need to think more about the wider risk of further divorcing people from nature by creating wilderness areas.  But be all that as it may, the positives greatly outweigh the negatives. When it comes to conservation, we have lacked ambition for too long. Saying yes to reintroducing beavers is the sort of bold and forward-looking move that would resurrect the UK’s conservation credentials."
"
Share this...FacebookTwitterI can hear it already. Like the climate activists who now deny there was a global cooling scare 40 years ago, in 10 years time or so we’ll be hearing the media and all the proponents of the low-fat/high carb diet claiming that this too was never a consensus.
Remember how eating saturated fats was supposed to cause artery-clogging, dangerous cholesterol and hence had to be avoided at all times? Day after day we were indoctrinated to follow the government’s and doctors’ guidelines of eating high carb, low fat foods. The science was fully endorsed for decades by the AMA, AHA, etc.
The food industry responded by filling store shelves with Twinkie and Cocoa Puffs-quality “foods”. Today tens of millions are afflicted with horrendous ailments like diabetes, heart disease and malnutrition.
Fortunately a few people ignored the totally bogus consensus nutritional recommendations and continued consuming high fat diets that included real butter, chicken, beef, cheese, eggs, fat-dripping bacon …and more eggs, along with their vegetables. The Telegraph here writes about how one person ate bacon and eggs every day almost her entire life and has just turned 116! In her kitchen she has a sign with a what I’d call a really sensible nutritional guideline:
“Bacon makes everything better!”
On the other hand we could continue corroding and oxidizing our bodies with carbs, or even follow the example of tech guru Steve Jobs, who had top chefs cooking a strict vegan diet for him daily. Jobs wound up dead at only 56. His “healthy” diet may have been deemed responsible, and friendly to the environment. But it certainly was not healthy or friendly to him.
Share this...FacebookTwitter "
"Global agreements to aim for “well below” 2℃ warming are nice enough, but now it’s time to develop some detailed policies to help us get there. Ships and planes are significant sources of greenhouse gases, and their emissions are projected to rise. Currently, both sectors exist outside national level frameworks and are not explicitly referred to in the international Paris deal. So what changes can we expect? A recent IMF paper on the global economic implications of the Paris agreement suggested that international shipping and aviation fuels should have a levy applied to them to create both revenue and encourage reduced emissions. The IMF proposes US$30 per tonne of CO2 emitted. A scheme already exists in Europe, where every flight from one EU country to another is included in the Emissions Trading Scheme and CO2 emissions must be accounted for and “paid for” using permits – in essence applying a price to the flight’s emissions.  The primary difference between the IMF’s proposed levy and a global ETS is over how the carbon price is set. In a levy, the price is chosen by policymakers and reviewed periodically, in an ETS a carbon market and an emissions target (or cap) is used to set the price. The IMF suggests putting a little over half of the revenue aside for developing countries as compensation for trade losses. The remainder (around US$25 billion) would contribute to the US$100 billion Green Climate Fund, which helps poorer nations cope with the effects of global warming. This is unpopular with many in shipping and aviation who understandably question why their sectors should provide such a large share. After all, they still only represent a combined 4% of global greenhouse gas emissions, so why contribute to 25% of the fund? The money could be used in other ways, of course, such as to purchase offsets from other industries or to fund investment in research and development on cleaner ships and planes. But it’s not clear whether offsetting would genuinely help reduce emissions, whereas the latter would be hard to administer and ensure that all countries benefited equally. What would a carbon tax mean for the price of international air travel or the cost of the food, fuel and goods that arrive by sea?  Burning a tonne of either ship or jet fuel creates about three tonnes of CO2, so the IMF’s proposed levy would create a surcharge of about US$90 per tonne of fuel consumed. Fuel costs around US$300 per tonne at today’s low oil prices, so a levy would increase a company’s fuel costs by about 10-30%. But fuel is just one component of a ship or plane’s total costs and therefore the prices that customers pay for flights and goods. In practice, markets that determine overall prices can and do vary by more than the probable effects of a levy (at least at the level IMF propose). Oil prices have fallen dramatically in recent years, for instance, but that hasn’t produced substantially cheaper transatlantic flights or consumer goods from China. The focus on levies and revenues like that proposed by the IMF risks missing the point. Keeping warming at well below 2℃ needs absolute emission reductions – fast.  Unfortunately, current evidence is that US$30 a tonne for CO2 would not deliver the absolute emission reductions required over coming decades. This is partly because demand for shipping and aviation doesn’t closely match price fluctuations – there are often few alternatives, and both industries are key to keeping the modern world up and running. So if higher costs passed on to consumers still don’t reduce demand then we must reduce the emissions per ship. However eco-friendly vessels won’t pop up overnight. Making progress requires new technologies, either those that improve the efficiency of existing ships’ hulls and propulsion machinery, or those that create entirely new ships powered by renewable or alternative fuels.  Developing these technologies will take some time. But to create these technologies there also needs to be a clear signal that this is the direction shipping is going. Otherwise investors won’t have confidence in the R&D, infrastructure and start-ups necessary to help shipping transition.  None of this rules out carbon pricing – this in itself can be part of a “clear signal”. But the extent emissions are actually reduced really needs to be considered, as without this we just end up moving money around the world while remaining on a course for climate catastrophe.  The global agencies responsible for regulating shipping and aviation both meet later this year, with greenhouse gases and climate-change issues high on the agenda. These meetings will be crucial because transforming both into low-carbon industries will only become harder the later we start."
"The world is facing three existential crises: a climate crisis, an inequality crisis and a crisis in democracy. Will we be able to prosper within our planetary boundaries? Can a modern economy deliver shared prosperity? And can democracies thrive if our economies fail to deliver shared prosperity? These are critical questions, yet the accepted ways by which we measure economic performance give absolutely no hint that we might be facing a problem. Each of these crises has reinforced the fact that we need better tools to assess economic performance and social progress. The standard measure of economic performance is gross domestic product (GDP), which is the sum of the value of goods and services produced within a country over a given period. GDP was humming along nicely, rising year after year, until the 2008 global financial crisis hit. The global financial crisis was the ultimate illustration of the deficiencies in commonly used metrics. None of those metrics gave policymakers or markets adequate warning that something was amiss. Though a few astute economists had sounded the alarm, the standard measures seemed to suggest everything was fine.  Since then, according to the GDP metric, the US has been growing slightly more slowly than in earlier years, but it’s nothing to worry about. Politicians, looking at these metrics, suggest slight reforms to the economic system and, they promise, all will be well. In Europe, the impact of 2008 was more severe, especially in countries most affected by the euro crisis. But even there, apart from high unemployment numbers, standard metrics do not fully reflect the adverse impacts of the austerity measures, either the magnitude of people’s suffering or the impacts on long-term standards of living. Nor do our standard GDP measures provide us with the guidance we need to address the inequality crisis. So what if GDP goes up, if most citizens are worse off? In the first three years of the so-called recovery from the financial crisis, about 91% of the gains went to the top 1%. No wonder that many people doubted the claims of politicians who were then saying the economy was well on the way to a robust recovery. For a long time I have been concerned with this problem – the gap between what our metrics show and what they need to show. During the Clinton administration, when I served as a member and then chairman of the Council of Economic Advisers, I grew increasingly worried about how our main economic measures failed to take into account environmental degradation and resource depletion. If our economy seems to be growing but that growth is not sustainable because we are destroying the environment and using up scarce natural resources, our statistics should warn us. But because GDP didn’t include resource depletion and environmental degradation, we typically get an excessively rosy picture. These concerns have now been brought to the fore with the climate crisis. It has been three decades since the threat of climate change was first widely recognized, and matters have grown worse faster than initially expected. There have been more extreme events, greater melting of glaciers and greater natural habitat destruction. It is clear that something is fundamentally wrong with the way we assess economic performance and social progress. Even worse, our metrics frequently give the misleading impression that there is a trade-off between the two; that, for instance, changes that enhance people’s economic security, whether through improved pensions or a better welfare state, come at the expense of national economic performance. Getting the measure right – or at least a lot better – is crucially important, especially in our metrics- and performance-oriented society. If we measure the wrong thing, we will do the wrong thing. If our measures tell us everything is fine when it really isn’t, we will be complacent. And it should be clear that, in spite of the increases in GDP, in spite of the 2008 crisis being well behind us, everything is not fine. We see this in the political discontent rippling through so many advanced countries; we see it in the widespread support of demagogues, whose successes depend on exploiting economic discontent; and we see it in the environment around us, where fires rage and floods and droughts occur at ever-increasing intervals. Fortunately, a variety of advances in methodology and technology have provided us with better measurement tools, and the international community has begun to embrace them. What we have accomplished so far has convinced me and many other economists of two things: first, that it is possible to construct much better measures of an economy’s health. Governments can and should go well beyond GDP. Second, that there is far more work to be done. As Angel Gurría, secretary general of the Organisation for Economic Cooperation and Development, has written: “It is only by having better metrics that truly reflect people’s lives and aspirations that we will be able to design and implement ‘better policies for better lives’.” Joseph E Stiglitz is a Nobel laureate in economics and the co-author of Measuring What Counts: The Global Movement for Well-Being"
"We are often told that curtailing the freedom of business is coercive and undemocratic. But by what democratic principle should corporations and billionaires decide the fate of current and future generations? When a government releases them from regulation, it allows them to determine whether other people live or die. No one elected them to do so. Even businesses with apparently strong credentials cannot be trusted with this extraordinary power. Take Marks & Spencer, famous for its “Plan A” environmental standards. Its goal, it says, is “to be a zero waste business across all that we do … we already send zero waste to landfill.” But a few days ago, it commissioned a wraparound ad in a limited number of Metro newspapers, in which a video screen was embedded promoting Christmas jumpers. The screen, battery, electronics and casing were designed for a single use. For the first time ever, environmental policies are now central, almost everywhere. But they have scarcely been mentioned in most of the media coverage It’s hard to think of a more profligate form of disposability. Marks & Spencer’s defence of this disgusting waste is that “the video screens can be recycled via electrical appliance collection points”. In other words, it’s up to the people who were handed the free paper to clear up the mess the company made (not that these complex materials can be fully recycled, anyway). I expect 99% of the screens went straight to landfill. This week we discovered that greenhouse gases in the atmosphere have reached record levels, just as they need to be plummeting in order to avoid climate catastrophe. The first task of all governments is now to stop powerful interests, like M&S, from trashing the habitable planet. This is the main criterion by which we should judge political parties. With this in mind, I read all the manifestos for the UK general election published so far. I was immediately struck by a remarkable gulf: between their emphasis, and the media’s emphasis in reporting them. For the first time ever, environmental policies are now central, almost everywhere. But they have scarcely been mentioned in most of the coverage, which is all about Brexit, spending pledges, immigration and the usual 20th-century themes. It’s a reminder that the most environmentally dangerous industry we face, largely controlled by billionaires, is the media. This is not to say that the manifestos have got it right. The Brexit party’s content-free “contract” is a total joke. The Democratic Unionist party writes as if it has been leafing through the dictionary, trying to discover what “environmental” means. Some of the Tory party’s pledges are promising, but they’re so vague that it could wriggle out of most of them. Labour’s transformation is genuinely exciting, but is beset by some important contradictions. Plaid Cymru’s proposals are pretty good, but it has a blind spot on farming (it wants to maintain the EU’s disastrous common agricultural policy, apparently without modification). The Liberal Democrats, mostly, get it. But only the Greens have really grasped what it means to democratise our relationship with the living world. One extraordinary feature of this election is that growth, for some parties, has become almost a dirty word. It is mentioned only twice in the Labour manifesto, both times with qualifications. The Lib Dems have made a crucial breakthrough, arguing that GDP should no longer be a government’s central objective; it should focus instead on wellbeing. This is a policy the Greens have been urging for years. By contrast, for all its talk about a “green industrial revolution”, the Conservative party is still bloviating about “unleashing” businesses and igniting growth through such disastrous projects as the Oxford-Cambridge expressway. It really hasn’t thought this through. Almost all the parties, even the DUP, now talk about green transitions and a circular economy, but with radically different levels of detail. Labour’s threat to delist any company that fails to tackle our environmental emergencies directly addresses the issue I raised at the beginning of this column. Its green new deal, sustainable investment board and green transformation fund are all crucial steps – though it is profoundly disappointing to see Labour fudge the 2030 target for a net-zero economy that was agreed at the party conference. There are some major contradictions, such as its conditional support for new airports, and its adoption of the National Farmers Union target for carbon-neutral food production by 2040. Net-zero in the rest of the economy means that farmland must be used as a massive carbon sink, so farming needs to achieve not zero but a big negative figure, and by 2030 not 2040. Labour’s rural policies are generally weak, and there are gaps in its rail and roadand energy plans. If it forms a government – minority or majority – it should invite the Greens’ Caroline Lucas to be environment secretary, importing the deep engagement it lacks. While I disagree on a couple of minor issues with the Greens, their manifesto sets the standard against which the others can be judged. The scope of the Lib Dems’ new thinking is one of the biggest surprises in this election. The new duty of environmental care it proposes for private and public bodies, its proposed zero-waste and nature acts, its suggestion of new taxes on frequent flyers, legal protection for public space and support for rewilding are all new and welcome. But there is still too much voluntarism: it urges but does not compel banks and corporations to reform their environmental standards. We cannot rely on market forces and corporate goodwill to defend us from catastrophe. We should vote for parties – in this case Green or Labour – that allow us to make collective decisions about our common interests, leading to democratic intervention. No one has the right to choose whether or not to destroy our lives. • George Monbiot is a Guardian columnist"
"The banded mongoose, a small social mammal of the African savannah, is known to be one of the most cooperative and helpful of all animals. They live across central and southern Africa in family groups of up to 28. Individuals routinely feed and protect the offspring of other group members, and when one of their own is threatened they gang up together to defend against attack from predators or a rival team of mongooses. But life is not all friendly cuddles between team-mates. Recent research shows these animals have a dark side. In the latest study of these mongooses, published recently in the Proceedings of the Royal Society B, researchers from the University of Exeter, Liverpool John Moores University and I show how competition between relatives can lead to mass evictions.  The drama ensues when the presence of greater numbers of offspring and younger siblings compromise the productivity – breeding success – of senior group members. Over a period of days, the happy family’s territory then becomes a chaotic battleground between relatives. The conflict is ultimately resolved by the older, dominant individuals evicting their younger team-mates en-masse. Shrieking battle cries accompany the civil war, with mothers and fathers chasing and wrestling their own daughters and sons, and elder brothers and sisters attacking their younger siblings. The tension is palpable, and the wounds can be bloody as well as psychological. The evictees do not want to leave and try to hang on in there, before surrendering and fleeing after days of sustained persecution. Eviction is not the only behaviour used to alleviate reproductive competition within groups of banded mongoose. Infanticide has been recorded, with adults killing the pups of fellow group-members, and there is also evidence that a female may abort gestating young during periods of stress, and that to do so increases the chance that she is not herself evicted. We must take care not to judge such behaviour within a human context, however. Eviction, infanticide and abortion may appear callous, but ultimately those mongooses that are evicted will usually go on to disperse successfully and found new groups with a refreshed gene pool (thanks to reduced inbreeding). This latest study shows the value of long-term research and collaboration. When I first arrived in Uganda’s Queen Elizabeth National Park back in 1996, to investigate these mongooses as part of a partnership between the University of Cambridge and the Uganda Wildlife Authority, I never imagined that these same mongooses would continue to be monitored by researchers over the subsequent two decades. We are now at a stage where today’s field researchers are following the great, great, great, great, great … offspring of the original group members. Such studies, monitoring the life history of multiple generations of individuals within populations, provide a remarkable insight into the evolutionary ecology of species, and tell us a great deal about how and why animals behave the way that they do.  I have spent much of my life as a behavioural ecologist studying cooperative animals, including banded mongooses but also chimpanzees, grey mouse lemurs, and even social spiders. Perhaps the most fascinating aspect of these societies is that while we observe cooperation on the outside, closer inspection often reveals that such apparent friendly helpfulness is underpinned by conflict and the threat of aggression. Sometimes your best friend can turn out to be your worst enemy."
"
Share this...FacebookTwitterWater shortages at Lake Baikal: climate activists ignore important climate cycles
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
[Translated, edited by P. Gosselin]
Not long ago we corresponded with the Helmholtz Asscoiation over a somewhat botched article about Lake Baikal. They simply assumed that the climate at the lake had been constant before industrialization – a fatal flaw.
On May 6, 2015 the activist groups of 350.org and Global Voices followed and committed similar flaws when they misinterpreted the current climate changes as “unique” and as “something that had never occurred before“. At Global Voices we read [translated from the German]:
According to experts, climate change is the cause of Russia’s shrinking Lake Baikal.
[…] The Russian Minister had clear words for the drop in the water level: ‘The climate’. So what on earth has happened with the climate? Experts assume that precipitation amounts in the Baikal region fluctuate in cycles of several decades. What is now happening, however, is clearly out of the pattern of normal variation. At the end of March the water level for example fell 9 cm below the critical value. Such a water shortage has not been observed in over 100 years. According to the Ministry for Catastrophe Protection, the water amount finding its way into the lake in the summer and fall of 2014 was only 65% of the climatic normal. The drying of Lake Baikal is taking place within the backdrop of a dramatic climate change in Russia: According to the Rosgidromet Meteorological Center, the rise in the mean temperature occurred here 2.5 times faster than it has globally. Climate change is leading to a rapid rise in the frequency of natural catastrophes, including drought.”
It’s nice to see that activists are at least recognizing precipitation cycles on a decadal scale. However they fail to take the longer term hundred-year or millennial cycles into account. The lowest lake water level in the last 100 years? That is only a tenth of a 1000-year cycle that is clearly described in the literature. See: “Study by the University of Alberta: 1000-year climate cycles triggered by solar activity fluctuations“ or “Climate at Lake Baikal pulsed in sync with the sun over the past 5000 years“.
In January, 2015, Sputnik News discussed the reasons for the water shortage. In addition to a pronounced drought in the previous year, also the hydropower plant removed too much water from the lake:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Over the past twelve months the lake water has dropped a record 40 cm to a sixty-year low — just shy of the critical mark of 456m. Some experts blame this on the local energy companies, but officials and biologists attribute the drop to last year’s drought.”
No word on this at 350.org/Global Voices. Instead they prefer to dramatize the warming of the past 70 years:
Lake Baikal is indeed warming. According to a study published already in 2008, the temperature of the surface water of Lake Baikal has risen already 1.21°C since 1946.”
Why do the activists cite a study from 2008 when there is more up-to-date data available that extends to today? Why the seven-year omission? We want to know more about this and so we look at the Lake Baikal GISS temperature record for the past 130 years at New Scientist:

The answer: In 2007 there was an extreme warm peak that obviously some people wanted to fully use in the statistic. In truth the temperatures have been falling again at Lake Baikal since 2004, measured with the 5-year running mean. In principle temperatures at Lake Baikal already have stagnated since 1988. Moreover the activists failed to mention that 1000 years ago, during the Medieval Warm Period, Lake Baikal was once similarly warm as it is today, perhaps with similar warming spells during the transition phase.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
The online North German NWZ daily here has an article on a speech given by University of Konstanz physics professor Dr. Gerd Ganteför on the subject of Germany’s transition to renewable energies, the so-called Energiewende, and on the general irrationalities pervading German climate science.
He says that the country appears to have “a desire for demise“.
In a presentation called “The Energiewende – Vision and Reality“, he reminded the audience of earlier end-of-world scenarios that never materialized, such as “the end of oil, forest die-off from acid rain, ozone hole”. He thinks that the German population “can be convinced of anything, ‘as long as it’s bad!‘” the NWZ reports.
Ice age approaching
Ganteför told the audience that the climate is going to change anyway even without the influence of man. And on a millennial scale: “The current warm phase will end at that we are approaching a new ice age.” He also told the audience that eliminating light bulbs and using smaller vacuum cleaners are not going to rescue any climate whatsoever.
Energiewende will fail


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So far in Ganteför’s view the Energiewende has been limited only to a transition in the electricity supply and that this will fail due to the lack of storage technology.
Removed from scientific fact
The NWZ also writes that Ganteför “criticizes the ‘false fear’ in the public discussion: Germany has become far too removed from the scientific facts and is too caught up in the current zeitgeist: ‘Indeed we are all going to die, but not because of the climate catastrophe,’ was his prediction at the end.”
Photo credit: http://www.faszinationphysik.ch/.
Gerd Ganteför is also the author of the German language books: Climate, the demise of the world is not taking place and Is everything NANO or what?: Nanotechnology for the curious.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSpiegel science journalist Axel Bojanowski interviews Oliver Geden, climate expert at the Berlin-based German Institute for International and Security Affairs – SWP. He is also an advisor to the German government. 
2°C target “an illusion”
In the interview Geden calls the 2°C limit target “an illusion that has been fed by politicians and scientists“.
Geden tells Spiegel that scientists and politicians have calculated how much CO2 is allowed to be added to the earth’s atmosphere before the temperature climbs 2°C, but that they have dithered and dallied so much that theoretically no more CO2 emssions will be allowed globally by the year 2044. Thus the 2°C target is already a grand pipe dream.
“Very dubious” CO2 accounting tricks
In the interview Geden believes Paris will fall far short of what is necessary to reach the theoretical 2°C target, and
As a result the climate negotiators will use many calculation tricks which I think are very dubious.”
He expects policymakers to use tricks like “negative” future emissions from CCS technology, or growing trees. However Geden, a warmist and promoter of ending fossil fuels, calls negative emissions in the interview “political science fiction“.
Geden tells Spiegel that 500 million hectares of forests would have to added to the globe, an area equivalent to one and half times India!
Many developing countries would go into resistance if we demanded they stop using the land for food and to grow trees for stroring CO2 instead.”
The negative emissions calculations being put forth are in fact now so out of touch that Geden sarcastically tells Spiegel:
Scientists might as well just assume in 2070 green martians will land on earth as rescuers and suck the CO2 out of the atmosphere.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Climate science reputation damaged
Bojanowski then asks Geden if all the carbon accounting tricks are hurting the reputation of climate science. Geden confirms that it is, reminding us that:
Five or six years ago it was consensus that greenhouse gas reductions of three percent annually were not realistic. But then emissions rose like never before – and suddenly the IPCC claims that six percent is doable. Precisely in a phase when CO2 emissions are rising liker never before the optimism is suddenly growing that drastic savings are possible. All this just to keep the 2°C story alive.”
Geden adds that scientists are forced to play along with the nonsense because they see the risk of getting less research funding.
The tendency is that those who supply the policymakers with the desired studies and models are better off.”
Science hubris
Geden also points out that “many climate scientists are idealists who wish to rescue the planet;..”
He believes that many scientists are suffering from “hubris” and actually “believe that the earth’s system is controllable“. He slams Hans-Joachim Schellnhuber’s WBGU which in 2011 “proposed a Great Transformation of Global Society to combat global warming”.
It was the first work since the fall of communism that called for the restructuring of the entire world according to a plan.”
Science being “led around “by the nose”
Joachim Müller-Jung at Germany’s flagship Frankfurter Allgemeine Zeitung (FAZ) writes a commentary on the “political fever” that has swept through the science community as the Paris Conference approaches. 
Müller-Jung writes that “science is allowing itself to be led around by the nose by politicians and economists.”
Müller-Jung describes the 2°C limit as “utopian”.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Dennis Ambler and Pierre Gosselin
Few institutes have been as adamant and dogmatic about man-made global warming as the Potsdam Institute for Climate Impact Research (PIK), headed by German climate doomsday professor, Herr Professor-Doktor Hans-Joachim Schellnhuber.

German climate doomsday professor Hans Schellnhuber forced to postpone climate doomsday scenarios due to natural factors, but insists warming is still happening, and it will be worse – at a later time in the future. Photo: PIK
The institute has long maintained that the science was settled, and was instrumental in formulating a master-plan for re-organizing global society and watering down democracy in order to avert the modeled disaster. Their master-plan calls for allotting more power to an elite group of “visionary” scientists – like to Herr Doktor Schellnhuber himself.
So today it’s all the more surprising that they are announcing a paper that concedes natural factors indeed are more powerful than the 0.01% CO2 atmospheric concentration added in part by humans over the last 150 years. This is a milestone for the PIK, which earlier claimed they could not find any real evidence of other factors driving the climate.
Their press release writes (emphasis added):
So far it seemed there were hardly any major natural temperature fluctuations in Antarctica, so almost every rise in temperature was attributed to human influence,” says Armin Bunde of Justus-Liebig-Universität Gießen (JLU). ‘Global warming as a result of our greenhouse gas emissions from burning fossil fuels is a fact. However, the human influence on the warming of West Antarctica is much smaller than previously thought. The warming of East Antarctica up to now can even be explained by natural variability alone.’ The results of their study are now published in the journal Climate Dynamics.”
They had us going there for a minute, but no, it isn’t a real admission they were wrong: global warming has been merely hiding behind natural variability as well as in the oceans, they insist.
The press release continues:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The scientists did not only analyze data from individual measuring stations but also generated regional averages. The results show a human influence on the warming of West Antarctica, while this influence is weaker than previously thought.
However, the warming of Antarctica altogether will likely increase more strongly soon.
Soon? How long are we to wait? Many are losing patience in their long wait for the promised catastrophe. Suddenly things look as if they are losing their urgency.
For several years temperatures in Antarctica, but also globally, have been increasing less rapidly than in the 1990s. There are a number of reasons for this, e.g. the oceans buffering warmth.
The study now published by the German team of scientists shows that man-made global warming has not been pausing – it was temporarily superimposed and therefore hidden by long-term natural climate fluctuations like in Antarctica.2
How do they know it’s temporary? From their models? Well, they have been wrong since day 1. Obviously there’s much more to the climate system than just trace gas CO2.
‘Our estimates show that we are currently facing a natural cooling period – while temperatures nonetheless rise slowly but inexorably, due to our heating up the atmosphere by emitting greenhouse gas emissions,’ explains Hans Joachim Schellnhuber.
‘At the end of this natural cold spell temperatures will rise even more fiercely. Globally, but also in Antarctica which therefore is in danger of tipping.”
The good Herr Dr. Schellnhuber never lets you down. Just be patient longer than we thought. The catastrophe that we promised is just taking longer to get here – but when it does, by golly, it’ll be a lot worse – you’ll all be sorry for not doing what we told you.
This is taking on comical dimensions.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAs Germany piles on more sporadic energy from wind and solar into its power grid, stability concerns are growing.
Increasingly volatile energies like wind and sun are turning out to be more of an expensive nuisance rather than a benefit.
Researchers at the Germany-based Fraunhofer-Instituts für Optronik, Systemtechnik und Bildauswertung, Institutsteil Angewandte Systemtechnik (IOSB-AST) have studied the risk of grid overloads caused by renewable energies at the community level, the online Ostthüringer Zeitung (OTZ) writes here.
The result, reports the OTZ:
Already in just a few years power will have to be stored locally as well. […] And the answers in their study are, depending on the perspective, thoroughly alarming or spurring for policymaking and economy.”
According to the OTZ, a team of researchers led by Peter Bretschneider at the Fraunhofer’s IOSB-AST conducted a 3-year study, where they literally built a statistical mock-up city of 30,000 that included a downtown, residential areas, commercial district, solar installations and wind parks. “A total of 1847 residential and business buildings that included everything from grandma’s little house to office complex for public officials.”
And so that the mock-up city simulates what is typical today in Germany, it also had everything a town would expect to have with the current German feed-in act:
4456 ‘grid elements’, i.e. power lines, transformers, large points of consumption and feed-in systems, foremost photovoltaics on the roofs.”
Even the homes were provided with the thermal insulation that they are expected to have later on.
The OTZ continues:
Next the Fraunhofer scientists electrified their simulated city. Then using meteorological data they allowed the sun to rise and set, the wind to blow, the temperatures to change – just like in real life.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Next they extrapolated outwards to the expected conditions of the year 2018 and 2023, leaving the local power grid unchanged and allowing more wind and solar energy to come online as expected from the provisions of the feed-in act. How did the city’s power grid fare? The OTZ tells us the shocking results, and they aren’t pretty:
Already today in the simulated city one of the 14 network nodes gets sporadically overloaded. In 2018 the impacted transformer comes under serious stress 22 days a year, and so does another transformer. Five years later three nodes are impacted by long-term frequent back-feeding of surplus solar energy in the medium-voltage grid. At least one cable in the area exceeds ‘the limits of thermal loading’. […]  ‘Yes, a transformer would be glowing – and the cable would go up in smoke,’ system engineer Sebastian Flemming explains the results in layman’s terms.”
The OTZ asks what this all means for the citizens? Flemming responds: “Blackout, for the entire city.”
In the wintertime this would be most inconvenient, and for some possibly even fatal.
Flemming adds that even if a blackout were averted, the wild frequency fluctuations in the grid would have “grave consequences” for many electrical appliances and systems. The OTZ writes:
None of today’s productions systems in the economy could function under such fluctuations, especially everything that is computer-controlled.”
In other words, it would not even take a blackout to cripple a city.
The OTZ then asks what can be done with the surplus electrical energy that will surely result from the wind and sun. Here once again the financially and technically unfeasible storage systems get brought up. Another solution mentioned is the conversion of the electricity into heat for supplying warmth to homes.
But the online OTZ daily writes that solutions appear to be a ways off, and so it warns:
Time is running out: According to the study, beginning in 2018, the first transformers are threatened with prolonged overloading.”
Do these findings of the Fraunhofer Institute surprise us? Not at all. It’s been known for a long time that the feed-in of solar and wind power leads to crazy, uncontrolled power surges in the grid. Supply stability remains the glaring problem that too many among us continue to deny.
Prepare for blackouts!
Share this...FacebookTwitter "
"Students and alumni from Harvard and Yale disrupted the annual football game between the two elite universities on Saturday, occupying the field in New Haven, Connecticut, at half-time and demanding the colleges divest from investment in fossil fuels. More than 200 protesters stalled the high-profile game for around an hour, many chanting: “Hey Hey! Ho Ho! Fossil fuels have got to go!” The protest was briefly booed by some in a crowd of 44,989 and discussed widely on social media. After the protest had delayed the TV broadcast of the game and pushed it toward sunset in a venue without floodlights, most of the protesters left the field voluntarily, escorted by police officers. A handful who remained were told they would be arrested. The number of arrests made was not immediately available. Students began campaigning in 2012 for both schools to stop investing in oil and gas and coal companies that contribute to the climate crisis. Both universities refused, arguing that they would be in a better position to encourage corporate climate action if they remained shareholders. “They believe that they can engage with these companies and get them to change their fundamentally extractive business models, which we think comes from a place of naivety amounting to gross negligence,” Nora Heaphy, an undergraduate at Yale, said. “It’s absurd to make those kinds of claims. So since then our campaign has moved away from administrative engagement, recognizing that it is often a stalling tactic.” A few months ago, hundreds of students at both universities walked out of class for a global climate strike. Last year at Yale about 50 students, community members and professors occupied the investment office until they were arrested. Heaphy has been arrested twice. Both schools have massive endowments invested across the economy, including in fossil fuels. Harvard’s is worth $39bn, Yale’s $29bn. Activists believe that if the universities divest, hundreds of institutions will follow them. Students at other prestigious schools are locked in similar battles. At the Massachusetts Institute of Technology (MIT), one group is opposing the decision to accept $3m and name an auditorium after the oil company Shell, which some experts call an example of the “colonization of academia” by fossil fuel corporations. A recent Guardian investigation revealed that 20 companies are responsible for a third of all carbon emissions since 1965. Internal documents from Exxon show the company knew the oil and gas industry would drastically alter the Earth’s climate decades ago and launched sophisticated campaigns to convince the public otherwise. Caleb Schwartz, a Harvard undergraduate, said no shareholder resolution could “sufficiently address the impact that Exxon has had on the climate crisis and on our politics” and added: “Ultimately, these companies need to go out of business in order for us to have a safe and livable future.” MIT has accepted funding from Shell to renovate a lecture hall in the Department of Earth, Atmospheric and Planetary Sciences, a highly visible space used for large classes for first-year students. “The significance of this is not the $3m in and of itself, which is pennies both to Shell and, frankly to MIT,” said Geoffrey Supran, an MIT alum who studies the history of global warming politics with Naomi Oreskes at Harvard. “The significance of this is this is part of a systemic trend – the invisible colonization of academia by the fossil fuel industry.” Supran said MIT received more industry funding than any other non-medical university in America. Students at MIT say they are offended by the message the naming of the auditorium will send to the academic community. The department is home to both climate scientists and researchers exploring more efficient ways for drillers to extract oil and gas. Advocates at MIT have pushed for the university to divest from fossil fuels. “Many of the things that MIT has said they would do, they haven’t done,” said Catherine Wilka, a graduate student in climate physics and chemistry. Wilka said she was “frustrated with the lack of evidence we’ve seen that this strategy of constructive engagement has changed anything about the fossil fuel companies’ intended business plans for oil and gas extraction – even as the science has painted an incredibly direct picture of the consequences if we don’t transition away from fossil fuels soon”."
nan
"Coldplay fans are bereft at the prospect of being unable to see the band’s new double album Everyday Life performed out in the wild, after Chris Martin told the BBC that they would not be touring it. Instead, the band will spend the next year or two figuring out how best to put on a “sustainable” and “actively beneficial” live experience that places environmental concerns above scale and convenience, addressing the climate-ravaging issues of flying and single-use plastic, for example, in the live music industry. The future they imagine is a para-, para-, paradi... oh, never mind.  In an era that sees celebrities criticised for speaking out about the climate emergency, then strung up again for flying to do so, of course it is Coldplay who are putting their money where their mouths are. I will not hear a word said against Coldplay. When actors use tear sticks to help them cry during emotional scenes, I wonder why they don’t just pipe in Fix You on a loop instead. Coldplay’s later career has pulled off the impressive feat of bringing the aesthetic of a decades-old semi-illegal world music festival in the Midlands to a global audience. Chris Martin is a superstar, a stadium frontman who clearly loves being on stage in front of thousands, even though he carries the vibe of a GCSE drama teacher who can’t stop talking about his Monday night reiki course. I love Coldplay. I don’t see how anyone can fail to love Coldplay. Coldplay’s vast money mountain should make the prospect of not touring an album a little easier on the financial front, even though playing shows is one of the only ways left for most musicians to make a living from music. As a result, it will be tougher for performers at a lower level to follow their example. However, Martin has already thought of that. “I think it is a question of just accepting that you have to do your best, not to be over-zealous in criticising others because everyone will catch up if you prove it is easy to do the right way,” he said. He’s the Elon Musk of carbon-neutral touring. Basically, trust him, he’s got this. One of the biggest issues, when it comes to live concerts, is the audience. We are a huge part of the problem, comprising a significant proportion of a tour’s carbon footprint by simply making our way to the show. I like watching live music and so I want Coldplay to fix this. Here’s an idea to get them started. If Chris Martin stopped making guest appearances during literally everyone’s sets at Glastonbury, it might just be enough of a cut to save us all. Christmas has come early for Dolly Parton fans. Thanks to Netflix’s exuberant policy of commissioning absolutely loads of stuff, it has served up Dolly Parton’s Heartstrings, eight really long episodes of drama, each adapted from a Parton song, with the source material of course including Down From Dover and Jolene (but sadly not Baby, I’m Burning – maybe season two?). Parton introduces each one ,casing the entire endeavour in a retro jacket, and while it is predictably schmaltzy and spectacularly drawn out – these are stories taken from minutes-long songs, after all –it does offer the TV movie comfort of a Sunday afternoon under a blanket. Better, though, is Dolly Parton’s America, the podcast hosted by Radiolab’s Jad Abumrad, which has been exploring how Parton unites a divided country. Abumrad has spent time with Parton, a notoriously charming but ungiving interviewee, and has spun it into gold as bright as her smile by speaking to family, friends, colleagues and, crucially, those most affected by her music. The episode on her “Dollitics” expertly pulled apart the union anthem 9 to 5, while Jolene got an instalment of its own, and it is brilliant, informative and just about as entertaining as the legend herself. Congratulations to The Vivienne, the deserving winner of the inaugural RuPaul’s Drag Race UK, who walked away with the kind of underwhelming prizes that only the BBC could offer with a straight face: three badges and the promise of a “digital series” with the show’s producers. Given the budgetary restraints, you’d be forgiven for thinking that might end up being an Instagram story, perhaps, at a push, a YouTube video. But no. The production company has already announced two follow-up series: The Vivienne Takes Hollywood and Morning T&T, which pairs the winner with her fellow finalist Baga Chipz, and has them reprising their Trump and Thatcher impersonations for a spoof talkshow. The Vivienne was the perfect reality TV contestant and the inevitable winner. She started strong, coasted at the top, dipped to the bottom, learned her lesson, then got her game back right when it counted. She had a serious, sympathetic backstory and she went on that crucial journey. The only disappointment was the lack of surprise, because she’d been the clear frontrunner since episode one. As a longtime Drag Race viewer, the format had been flagging. It started to feel like there were more series than RuPaul has had birthdays and, as a result, it was in danger of becoming too meta, more about the show than the people on it, with contestants constantly referring to previous contestants, the cultural touchstones eating themselves. Drag Race UK has been a crude, smutty, utterly British defibrillator that has given it all a new lease of life. Its contestants were mucky, its drag more disruptive than one might have predicted and it provided one of the sweetest TV moments of the year, when Cheryl (formerly) Cole met her namesake Cheryl Hole. Now that’s the kind of wholesome family entertainment I want my licence fee to fund. • Rebecca Nicholson is an Observer columnist"
"
Share this...FacebookTwitter[Sticky post…new articles follow after this one.]
=====================================
By Ed Caryl
This is a follow-up to the article AWI’s Sloppy Antarctic Peninsula Science…Overlooked GISS Temperature Data, Snowfall Amounts. The reality is that the situation at the South Pole is worrisome.
Ocean around Antarctica markedly colder since 2006…
It is difficult to believe that global warming/climate change is doing anything to the glaciers of the Antarctic Peninsula and the Western Antarctic. Here is why: The ocean around Antarctica has been getting markedly colder since 2006; sea ice is increasing, especially since 2012; and land temperatures have been cooling since the El Niño of 1998.
0 – 100m ocean temperature plummeting:

Figure 1 is the upper 100 meters of ocean south of 60°S. There’s been a rapid cooling since about 2007. Negative numbers are used to select latitudes in the Southern Hemisphere. The source is KNMI, link.
Sea ice skyrockets…

Figure 2 is the Southern Hemisphere sea ice area anomaly. The source is KNMI, link.

Figure 3 is a plot of the annualized ocean temperature and Southern Hemisphere ice extent using the KNMI data from figures 1 and 2. Ocean temperature is inverted to show that the ice extent matches the cooling ocean. Note the correlation between the two curves. 
Antarctic Peninsula sees dramatic cooling…



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 4 is a plot of the temperature anomalies at 13 Antarctic stations on or near the Antarctic Peninsula. The baseline is the 1998 to 2014 average for each. Antarctic peninsula has been cooling since 2000. Data source: GISTemp, link.
There is a lot a variation in the annual average temperatures for these stations, especially in the years where there were only two stations reporting, Esperanz and Faraday. For that reason, the average in figure 5 begins in 1963 when O’Higgins began reporting.

Figure 5 is the average anomaly for the stations in figure 4.
There were two peaks in temperature, one in 1989 and a second during the El Niño year of 1998 which caused a steep upward in temperature world-wide, and especially in Antarctica. But since then there has been a dramatic cooling. There is no “hiatus” on the Antarctic Peninsula, there is marked cooling.
Larsen Ice Shelf station cooling at a rate of 18°C per century
Cooling is especially true of the very location everyone is concerned about, the Larsen Ice Shelf. There is an automated weather station (AWS) there that has been reporting continuously since 1995.

Figure 6 is the annual average temperature at the Larsen Ice Shelf. The source is GISTemp.
Figure 6 shows the step in temperature in 1998 at the Larsen Ice Shelf. The trend in cooling after 1998 is 1.8°C/decade, the second fastest cooling on the Peninsula. Butler Island is cooling faster, at 1.9°C/decade. (Of course 18°C/century cooling is meant as sarcasm, and is only a trick that warmists like to use.)
Result: exploding sea ice
It is easy to see why the sea ice around Antarctica is increasing. The average ocean temperature from the surface to 100 meters dropped below the freezing point in 2008 and has stayed there. It is hard to melt ice when the water it is floating on is below the freezing point of fresh water, and seldom rises above that temperature.
The Southern Ocean around Antarctica has similar warming and cooling cycles as the North Atlantic, just not as strong. The cycle is now going negative, and temperatures on land and in the ocean are going sharply cooler, with ice increasing. There is no warm ocean water melting ice shelves from below. The ocean is getting colder and is below freezing most of the time. Any increase in ice calving off the glaciers must be from increased snow feeding those glaciers or geothermal heating from volcanism under the ice.
Welcome to reality.
Share this...FacebookTwitter "
"Something happened in 2017. Australia is second only to Canada in welcoming immigration on a large scale. Our faith in the benefits of accepting newcomers of all faiths and races is rock solid. But a couple of years ago we began to grow impatient about the government’s management of the immigration program, impatient in particular about overcrowding in our cities. This is the verdict of the Scanlon Foundation’s 2019 Mapping Social Cohesion report, published on Tuesday. The mission of the foundation for the past decade or so has been to measure how this migrant nation hangs together. In that time an extraordinary 50,000 of us have been polled to track the hopes and fears that sweep Australia – and not just about immigration. The author of the reports, Prof Andrew Markus of Monash University, finds most Australians now share “an underlying concern about the government not properly managing the situation – the impact on overcrowding, house prices, environment”. Markus is one of this country’s leading authorities on the politics of race and this is the 12th report he has written for the Scanlon Foundation. His findings are a civilised rejoinder to those who skew politics to the far right in this country that their racist constituency does not speak for the nation. But in 2019 Markus fears impatience with government management might imperil majority support for Australia’s immigration program. “This has not yet occurred, but the potential is evident.” We are not Europe. Asked every year to name the most important problem facing their countries, Europeans have lately nominated immigration. “It’s sort of cooled down a bit now,” says Markus, “but even to the present day when people are asked what’s the main issue for the EU, they still nominate controlling population movement and immigration.” Not in Australia. We always put the economy at the top of the list. Immigration came in fourth in 2019, nominated by 6% of us. In second place on the list, after an abrupt rise, is the environment and climate change. Markus has never seen such a sudden surge. The last was after the the Lindt cafe siege, when for a few years about 10% nominated national security and terrorism as the great problem facing the nation. “But this year climate change went not to 10, it went to 19,” says Markus. “And that’s so far ahead of the third issue. There’s a lot of daylight there.” The importance of the shift is underlined by the discovery that climate sceptics have all but lost traction. In 2011, when 11% of us said climate change was our biggest worry, another 6% nominated overreaction to those fears as the great problem facing Australia. The following year, the sceptics outnumbered the climate worriers almost two to one. Not any more. Against the 19% nomination for climate change in 2019, the sceptics could muster, at best, a contrary 1%. Markus sees this shift as an acute challenge to Canberra. “Morrison has got an opportunity to actually rebuild some capital in effective government,” he says. “But he’s got this issue of climate change. If he doesn’t deal with that, which is emerging as a major issue, that could very seriously damage this government.” Markus began his work at the end of the Howard era and the arrival of Kevin Rudd. In those years of hope and renewal, the Scanlon survey showed nearly half of us believed government did the right thing for the Australian people almost always or most of the time. But with Rudd’s collapse in 2010 went a good measure of trust in government. It has never recovered. In the weeks before Malcolm Turnbull’s downfall, the Scanlon survey of 2018 revealed only 29% believed in the good intentions of Canberra. After the re-election of the Morrison government this year, the figure is essentially unchanged at 30%. It’s a long slide, but Marcus disputes claims in other surveys that Australia is experiencing a catastrophic loss of faith in democracy. “There are some people out there who do surveys with small samples,” he says. “And with small samples from one year to the next you will get variability. And that produces headlines. “But we’ve got I think the most rigorous way of surveying. We actually do it in two different modes – by telephone and by self-administration – and what that is showing is much more a picture of ‘steady as she goes’ rather than dramatic decline.” The education line cuts across the immigration debate like a mighty trench They shift a little, and the shifts have lately been gloomy, but year in and year out the steady findings of the Scanlon surveys define Australia: 90% of us have a sense of belonging to this place. 87% are proud of the Australian way of life. 85% agree multiculturalism has been good for Australia. 84% report having a happy 2019. 80% welcome resettlement in Australia of refugees assessed abroad. 79% oppose selecting immigrants by race. 73% believe Australia is a land of economic opportunity where, in the long run, hard work brings a better life. 71% believe globalisation is good for the country. 68% believe accepting immigrants from many different countries makes Australia stronger. 62% are optimistic about Australia’s future. Then there’s the darker side: 61% of Australians disapprove of asylum seekers making their way here by boat. 47% of us have little or no concern about the treatment we mete out to asylum seekers in PNG and Nauru. 40% in 2019 admit negative or very negative feelings towards Muslims. The level of hostility to Muslims was masked until a couple of years ago, when the Scanlon Foundation began parallel tracking its research. Telephone interviews over the years showed 21% to 25% of us hostile to Islam. But these figures essentially double when surveys are completed in private and online. The gap between the two sets of results shows us to be a polite people. We hesitate to admit personal unhappiness or gloom for the future of the country. We clearly don’t enjoy confessing to strangers that we’re in financial trouble. A little of our optimism about the impact of mass immigration evaporates online. We’re even shy of confessing to strangers that we don’t much like Christians – only 4% would own up to that on the telephone in 2019, but 14% said so clearly online. Markus argues that while our sunny picture of the country darkens a little when we answer in private, those Australians most hostile to race speak loud and clear however they are surveyed. “The views of the hardcore negative types are pretty constant irrespective of the surveys,” says Markus. “And often it’s around 10% of the population. Now it would be a worry if self-completion surveys then showed it wasn’t 10% but it was 20% to 25%. But it’s actually pretty constant.” So who are the most hostile to immigration? Easy answer: One Nation voters. The 2019 report shows One Nation voters are profoundly pessimistic about Australia’s future; loath globalisation; don’t give a rats about the environment; are scathing about the motives of government; dismiss multiculturalism; are fiercely hostile to Muslims; couldn’t care less how harshly we treat asylum seekers; and are the only group in the survey – young and old, rich and poor, city and country – where most still hanker for the old White Australia policy of selecting migrants by race and religion. How important here is the city/country divide? Not at all on the importance of climate change. Wherever we live in cities or the bush, we agree that after the economy, the climate is the single biggest problem facing Australia today. But on immigration, the gap between city and country widens significantly. The 2019 survey found that outside the capital cities there was an 8% drop in support for multiculturalism; a 4% rise in those wanting immigrants selected by race and religion; a 6% fall in those concerned about the treatment of refugees; and, though the bush is where migrants don’t settle and governments are desperate to send them, a nine-point jump to 49% of those who believe Australia’s immigration intake is too large. The fundamentals are sound, even as about one in 10 of us continue to rage against this new Australia of many faiths and many cultures But this is not the most dramatic divide revealed in the Scanlon surveys over the years. The education line cuts across the immigration debate like a mighty trench: Only 27% of university graduates say Australia takes too many immigrants, but for those who never finished high school the figure is 70%. Nearly 90% of graduates applaud multiculturalism but only 61% of those who never finished school. Among graduates, 58% worry we treat refugees too harshly, but their fears are shared by only 32% of who never finished school. While a rump of 14% of graduates still wish immigrants could be chosen by race, support for the old White Australia position more than doubles to 35% who never finished school. Western Australia emerges from the survey as a fascinating puzzle: wildly optimistic about the future of the nation, peculiarly trusting in government, little perturbed by climate change and not particularly worried about the size of the immigration intake. But of all mainlanders, West Australians are most keen to select immigrants by race and are, by a long shot, the most hard-hearted about Australia’s treatment of refugees. Nothing Canberra has done to its prisoners in PNG and Nauru in the past couple of years has budged the national 50:50 split between the indifferent and the sympathisers. Markus says: “It’s pretty rock solid.” But when these figures are broken down by political alignment, Markus sees signs of movement. Thirty per cent of the Liberal constituency say Australia is being too harsh, compared with 87% of Greens. The 2019 figure for refugee sympathisers in Labor ranks is 61%. “It is a huge problem for Labor,” says Markus “because the government with its constituency can keep doing what it’s been doing, but it really wedges Labor.” Are Christians notably more compassionate? Certainly not Anglicans. In 2019 only 39% of them could muster some sympathy for the asylum seekers Australia is putting through the mill out in the Pacific. Markus doesn’t blame their God. He says gently: “Conservative old Australia.” Though not quite so bleak, the figures for the other faiths put paid to the notion that the churches are mighty reservoirs of sympathy for refugees. On the subject of the Pacific solution, Catholics come in slightly under the national split, with only 46% of them reporting some or a great deal of concern for what Australia is doing to refugees. That’s typical. On issues such as the size of the immigration intake, support for multiculturalism, a hankering for the right to pick migrants by race and confidence that immigrants improve our society by introducing new ideas and cultures, the churches don’t put the attitudes of the rest of the community to shame. At best they merely mirror them. Markus ran some figures for Guardian Australia which show that on nearly all questions asked in the survey – including concern for climate change – the progressive horse to back is those who nominate No Religion. Overall, Markus is a grim optimist. Reports of discrimination are too high, but not for the moment growing higher. The fundamentals are sound, even as about one in 10 of us continue to rage against this new Australia of many faiths and many cultures. It’s in the government’s hands whether we continue to support what is in world terms very high support for large scale immigration. Markus is at pains to emphasise that multiculturalism backed by almost all of us is a two-way street. “They’re saying we recognise that diversity is good, that diversity has made us a better country. You get very high levels endorsing the notion that immigration improves society by bringing new ideas and cultures. “But on the other hand, it’s two-way because the expectation is that immigrants will, over time, be more like us. It’s not an endorsement of pluralism. It’s an endorsement of a two-way change and obviously in that change the immigrants are changing more than the host society.” But we’re all changing? “Yes. We’re moving. But they’re moving more.” "
"Australia’s peak scientific institution has told an inquiry into the reliability of Great Barrier Reef science that it is “greatly concerned” over a trend to cherrypick and misrepresent scientific evidence. In a submission to a Senate inquiry, the Australian Academy of Science’s president, Prof John Shine, wrote that selective use of science and misrepresentations were “dangerous” and would lead to “poor outcomes”. The inquiry, introduced by the Nationals senator Susan McDonald and the Liberal senator James McGrath, is looking at the evidence linking pollution from farm runoff to degradation of the reef. In the months leading up to the inquiry, industry groups including Canegrowers and AgForce had sponsored a speaking tour by the controversial scientist Dr Peter Ridd, who claims that the reef is not being damaged by farm pollution. He also disputes evidence for human-caused climate change, and claims that mass coral bleaching events on the reef are natural. The campaign had aimed to pressure the Queensland government to withdraw proposed legislation, which later passed, that set limits on nutrients, sediments and chemicals running into the reef’s catchments. Australia’s former chief scientist Ian Chubb, who chairs an expert panel of reef scientists, likened the campaign to the tactics used by the tobacco industry when it attacked the science linking its products to cancer. In his submission, Shine wrote: “The Australian Academy of Science is greatly concerned about a recent tendency to ‘cherrypick’, dismiss, misrepresent, or obscure scientific evidence or smear individual scientists.” Later in the submission, he added: “A commonly used tactic in opposing or advocating for policy positions is to ‘cherrypick’ scientific findings rather than consulting and analysing the body of literature systematically. “Cherrypicking evidence to support a decision or position is dangerous and leads to poor judgment and outcomes.” The academy said it backed the methods and findings of a 2017 Scientific Consensus Statement on the impacts of poor water quality of the reef. The Australian Environment Foundation – a group that promotes climate science denial and supported Ridd’s tour – has also written to the inquiry, repeating Ridd’s claims that science linking farm pollution to the reef was “demonstrably wrong or unreliable”. • Sign up to receive the top stories from Guardian Australia every morning Dr Jennifer Marohasy, a former long-serving director at the AEF who now works at the Institute of Public Affairs, claims in a submission that water quality is improving along the reef, and that governments were conspiring to “maintain the perception of declining water quality”. Last week one reef scientist explained to Guardian Australia that Marohasy had misrepresented her work in an IPA video. The submissions also reveal a split among Queensland’s canegrower industry groups. The Proserpine and Bundaberg districts continued to question the science in their submissions, while groups in Cairns and the Herbert River said farm runoff was damaging to the reef but challenged the need for regulation. The Queensland Farmer’ Federation also said it had “no reason to question that land-based runoff continues to impact water quality in the GBR, and that agricultural activities contribute to this”. As reported by Guardian Australia, the federation’s newly elected president, Allan Dingle, the chairman of Bundaberg Canegrowers, has been an enthusiastic backer of Ridd’s claims. He has characterised the science underpinning the Queensland government’s laws as “unsubstantiated scaremongering”. The farmers’ federation manages more than $4m of taxpayer-funded water quality improvement grants from the federal government’s controversial grant to the Great Barrier Reef Foundation. A submission from the Department of the Environment and Energy highlights how the world heritage committee had expressed concern in 2017 that water quality on the reef was not improving. The committee will review the reef again next year. In August the Great Barrier Reef Marine Park Authority downgraded the reef’s long-term outlook from “poor” to “very poor” for the first time, citing impacts from climate change as a key driver. The Senate inquiry is due to issue its report in October 2020."
"
Share this...FacebookTwitterThe Sun in April
By Frank Bosse and Prof. Fritz Vahrenholt
[Translated, edited by P Gosselin]
The sole real source of energy for our planet also was also below normal in April: The sunspot number (SSN) was 54.4. Taking the average of the previous 23 cycles, that is only 70% of what is average for this month into the cycle.
Compared to March activity rose some 46%. These short-term changes however are usual noise in the overall signal, which says the entire activity since the current cycle began has been only 53% of the mean value since 1750.

Figure 1: Current solar cycle 24 (red), the mean solar cycle (blue) and the similar solar cycle  no. 7, which took place from 1823 to 1833 and was the last in the Dalton Minimum.
The comparison with solar cycle no. 7 could see increasingly large deviations in the months ahead, as solar activity increased markedly, as depicted by sharp peaks of the black line in Figure 1. Such a development appears highly improbable for solar cycle no. 24. What follows is a comparison of all cycles:

Figure 2: The accumulated solar cycle sunspot anomaly for all cycles 77 months into the cycle. The current cycle began in December 2008.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Figure 3: The speed of the solar wind, which impacts the Earth’s upper atmospheric layers, has fallen off since the early 1990s. It is expressed as the geomagnetic Ap Index. It is a measure of the sun’s impact on the Earth’s magnetic field. Source of the image: Climate4you.
Not only the Earth is impacted by the solar winds, but also the entire sun’s surroundings far out in space. The heliosphere reacts to the stream of particles from the sun. When it is weaker – as is the case during times of solar minima – more cosmic radiation from the Milky Way can penetrate into the Earth’s atmosphere. This is measured here on Earth, e.g. in Moscow since 1958:

Figure 4: Changes in cosmic radiation
During the solar sunspot number maxima (compared to 2000) the solar wind is stronger and thus reduces cosmic radiation by up to 20% when compared to the minima in activity. The current cycle (maximum is already over) is bringing only about an 8% reduction. Over the entire period since 2006 there has been significantly more cosmic radiation than any such period since 1958.
Another factor involved with solar activity is UV radiation. It strongly depends on the sunspot number because the ultraviolet radiation is produced in the areas near sunspots. Unlike the other visible ranges of the spectrum, sunspots in UV images appear brighter than the surrounding areas. Although UV radiation mainly has an impact in the stratosphere, there are top-down effects that lead to impacts to the troposphere.
The signals for solar activity all continue to point to “very low“. We can all wait with suspense to see what impacts the low solar activity will have.
Original German version here.
Share this...FacebookTwitter "
"Greta Thunberg is to swap leading the global fight against the climate crisis for the more stressful experience of directing a group of high-profile BBC presenters, after being announced as one of this year’s guest editors for Radio 4’s Today programme. The environmental activist will take control of an episode of the BBC’s flagship radio news programme at the end of this year, speaking to leading figures in the fight against global heating and hearing from indigenous, frontline activists. Thunberg, who led school strikes around the world, has also commissioned reports from the Antarctic and Zambia, as well as a Mishal Husain interview with the governor of the Bank of England, Mark Carney.  The 16-year-old, currently sailing across the Atlantic ocean to attend the UN Climate Action Summit in Madrid, had only just been born when the Today programme began the tradition of appointing public figures to guest edit programmes in the quiet news days between Boxing Day and New Year’s Eve. This year’s line-up also includes Lady Hale, the president of the supreme court, who is due to retire as the UK’s top judge when she turns 75 in January. She will give listeners a tour of her North Yorkshire hometown and the supreme court, while challenging the audience to “explore the issue of coercive control”. Hale, a former law lecturer who has campaigned for greater diversity in the judiciary, hit the headlines in September when she delivered the supreme court ruling that Boris Johnson’s government had illegally suspended parliament. She has since been immortalised in a children’s book charting her journey from Richmond to the top levels of the legal profession. The Turner prize-winning artist Grayson Perry will work with the Today team to examine “stereotypes and conventional thinking” during his episode, while another guest editor spot will go to the rapper and spoken word artist George the Poet, who will report from Uganda and explore issues around identity. The final guest editor slot will go to Charles Moore, the former editor of the Daily Telegraph, who will focus on freedom of expression in modern society. Moore, who wrote the authorised biography of Margaret Thatcher and founded The Rectory Society for fans of clergy dwellings, has previously criticised the BBC over its perceived anti-Brexit bias."
"Catastrophe is looming for the banana industry. A new strain has emerged of a soil-borne fungus known as “Panama disease” which can wipe out entire plantations – and it is rapidly spreading around the world. Farmers in Australia, Latin America and across Asia and Africa all fear the worst. The fungus is almost impossible to stop or eradicate. It moves through soil, so contamination can be as simple as infected dirt travelling from one farm to another on the sole of a shoe, or as complex as soil particles blowing on the wind across long distances – even across oceans, in theory.  Faced with huge losses to a global industry, many have called for a new strain of disease-resistant “superbanana”. However, this would be just another temporary fix. After all, the world’s most popular banana, the Cavendish, was itself the wonder fruit of its day, being introduced in the 1950s after an earlier strain of Panama disease destroyed its predecessor.  The fungi simply adapted and fought back, though, until the Cavendish also became susceptible. Panama and other diseases will continue to do so until we seriously reform how we grow and market bananas.  The banana industry is its own worst enemy. The huge farms where most exported bananas are grown are ideal for pests. These plantations are monocultures, which means they grow only bananas and nothing else. With very few shifts between crops over the years, and lots of tropical sunshine, there is an abundant and year-round supply of food for pests without any breaks, in time or space, to disrupt the supply and lower the disease pressure. Banana producers spend a third of their income on controlling these pests, according to a study I published in 2013. Chemicals to control microscopic but deadly worms are applied several times a year. Herbicides that control weeds are applied up to eight times a year, while bananas may be sprayed with fungicides from a plane more than 50 times per year in order to control Black Sigatoka, an airborne fungus.  And those bags that are wrapped around each individual banana bunch? They’re lined with insecticides to serve as both a physical and chemical barrier to insects feeding on and damaging the skins. All of this amounts to approximately one litre of active ingredients for every 18.6 kg box of bananas that is exported to consumers in the global north. It’s a huge, long-running problem for the industry and the new strain of Panama disease may just be the nail in its coffin. Or maybe this is the wake-up call the export banana industry so desperately needs. Given the way the fungus spreads, containment and quarantine are hardly long-term solutions. Some experts, especially those entrenched in the business of growing export bananas, argue that we need to breed or genetically modify a new type of banana that is resistant to the latest strain of Panama disease. But this is harder than it sounds. Modern bananas – the tasty yellow ones – don’t exist in nature; they were bred into existence around 10,000 years ago. They reproduce asexually, which means they don’t have seeds and every banana is a genetic clone of the previous generation.  This lack of genetic variation makes breeding a new banana particularly challenging. If one Cavendish is susceptible to a disease, all others will be too. When all bananas are clones, how do you create the genetic variation from which traits for better disease resistance can be identified and nurtured? A new banana would also have to be tasty, durable enough to withstand long voyages without bruising, and bright yellow. Looks really do trump pest-resistance. A new type of banana introduced during a previous Panama disease panic back in the 1920s was rejected by consumers for going black on the outside, even when it was ripe and sweet inside. Today, banana growers are in a fight for survival, continuously applying newly-formulated fungicides in an effort to keep ahead of the diseases. But they are acutely aware that they are losing ground. While breeding a new banana staves off the current problem, history has already shown that this doesn’t get to the root of the problem, which is the design of the production system. We need to ditch the massive farms. Around the world, millions of small-scale farmers already grow bananas in a more organic and sustainable way. Alongside bananas are cacao, avocado, mango, corn, orange, lemon and more. A mix of crops creates more stable production systems which rely on fewer, if any, pesticides and generates diverse income sources, handing local people greater food sovereignty. Farms where bananas are mixed in with other crops are also more resilient to climate change which is likely to hit banana-producing regions – developing countries – harder than most. Yes, this would mean fewer bananas are grown. Sustainable agriculture simply can’t keep up with the megafarms. But if we learned to ignore the odd blemished or undersized banana, then the actual amount sent to market need not drop at all.  The farmers themselves should be okay as they’ll make up their income by producing different crops. Breaking the dominance of the banana multinationals should also distribute wealth among more farmers and empower the regions where they’re grown. As a consumer, ask yourself this: isn’t that a far better way to spend your money?"
"
Share this...FacebookTwitterDr. Sebastian Lüning’s and Professor Fritz Vahrenholt’s “Die kalte Sonne” site here bring us a perfect example illustrating how debate losers like to handle debate: simply declare it over and walk away. (Translated and edited by P Gosselin)
===========================
The Heinrich Böll Foundation runs a climate blog called “Klima der Gerechtigkeit (Climate of Justice). Author Lili Fuhr writes regularly there on topics like “James Hansen predicts much higher sea level rise over the coming decades: 2°C more is much too much!” or “Pope opposes emissions trading in climate protection”. In the reader comments there really isn’t much going on. Perhaps there’s a very strict moderation in place? Indeed at the site it is stated:
We are beyond whether climate change is taking place and whether it is caused by man. It is aseptic to continue this debate. Now it gets down to having a discussion on what is the best way to combat it [climate change].“
Following the Boll Foundation’s logic we’d also lead an aseptic debate. This saddens us naturally because we are convinced that climate is changing, and that this always happened in pre-industrial times. Perhaps readers would like to inject a little life to Lili Fuhr’s blog and leave a few comments? Here you can go to her blog. Kalte Sonne chief Editor Sebastian Lüning tried, and within 50 milliseconds a reply page appeared bearing the message: “Spam deleted”. That’s what we call an especially rash and consequential comment oderation..
 
 
Share this...FacebookTwitter "
"On the flat, marshy stretches of Maryland’s eastern shore, not a huge amount has changed since Harriet Tubman escaped from slavery here 170 years ago. Rivers and streams lace a wedge of land dotted with wood-board churches and small towns. Crabs and oysters are plucked from the adjacent Chesapeake Bay. The climate crisis is set, however, to completely transform low-lying Dorchester county, threatening to submerge some of the key heritage associated with Tubman, the celebrated abolitionist whose daring missions helped free scores of slaves from bondage in her homeland. If planet-warming emissions aren’t radically scaled back then swaths of the Harriet Tubman Underground Railroad national historical park, only established in 2013, will be inundated at high tide by 2050, according to projections by University of Maryland scientists. A $22m (£17m) Tubman visitor centre, completed in 2017, is set to be severely menaced by the rising waters, the analysis finds, along with several churches connected to Tubman and Joseph Stewart’s canal, where timber was transported from a business that had enslaved her father. “Dorchester county is a poster child as to what the rest of the world can expect with flooding,” said Peter Goodwin, president of the University of Maryland Center for Environmental Science. The county doesn’t rise more than 1.5 metres (5ft) above sea level and is exposed on three sides to the bay, which can act as a funnel to push storms on to the land. The seas could swell by as much as 60cm by 2050, a situation compounded by the fact the land is sinking, a hangover caused by the retreat of ice sheets from the last ice age. “It’s worrying,” Goodwin said. “The county is beautiful but it’s going to look very different. If we can get ahead of things and plan for the future then you can help define what the shoreline will look like. The problem is if you don’t do that then people are going to drift away and the culture will be eroded.” The situation is causing alarm among those who have highlighted Tubman’s legacy. “These landscapes are rapidly vanishing because of climate change,” said Kasi Lemmons, director of Harriet, a new film based on Tubman’s life. “Losing landmarks such as these underscores the need to protect and preserve the land and our national history for the generations to come.” Proximity to water for communication, transportation and food has long been intrinsic to Dorchester county but flooding is increasingly chipping away at the routines of day-to-day life. High-tide water lapped in residents’ front yards and is now reaching porches. Carelessly parked cars can end up sodden. School buses struggle to get down roads that are in constant repair. The storms are getting fiercer, as the water and atmosphere warms. The encroaching tides now also imperil the cultural touchstones of Tubman’s life. The former slave was born in Dorchester county in 1822 and despite suffering a severe head injury managed to escape to Philadelphia as a young woman. She then helped guide more than 70 enslaved people north to freedom via a network of safe houses and routes known as the Underground Railroad. Several locations on the Harriet Tubman Underground Railroad Byway, a driving loop of important Tubman sites, are already being eroded, according to Tubman’s biographer Kate Clifford Larson. “We’re not going to have those landscapes to tell those amazing stories if something doesn’t happen quickly,” Larson said. “In the 20 years I’ve been to these sites I’ve seen them start to disappear because of the water seeping in. “Some of the roads become impassable and you have to wait out until the water recedes. And some of the precious, really precious, African-American historical and cultural sites are at the most danger right now because they are in the lowest-lying areas.” Larson frets about where the resources will come to protect places such as the New Revived Methodist church in Smithville, in the heart of Tubman’s former community that often has a waterlogged graveyard. “They are going to need to move the graves and that costs a lot of money,” she said. “It’s frightening how quickly these sites are becoming threatened.” The Rev Darlene Dixon has only been the pastor of the New Revived for five months but has already experienced being temporarily cut off from her church by a storm that pushed 15cm of water on to the roads and on to the cemetery. “People are concerned, and naturally I am, too,” Dixon said. “The biggest part of their angst the unknown – which storm, which high tide will cause major damage.”  Dixon said a seawall may have to be erected to protect the church but that may not stop the surrounding community, already one of the poorest in Maryland, crumbling away as the flooding intensifies. “People here have big hearts but there are not many people left in the community because they want to make a living. There’s the fear of the water too,” she said. “We are seeing change occur before our eyes.” The National Park Service, which oversees the Tubman park, is putting together an assessment of the threats it faces. Deanna Mitchell, the park superintendent, said she reassures tourists that the visitor centre has been built on a relatively elevated piece of land with sea-level rise in mind. “It’s a beautiful facility and the landscape is beautiful, too,” she said. “Every time I go to work I’m immediately in a mode of reflection. I see that with visitors, too. “I’m optimistic that we can address whatever comes our way if people can come together on this. We are nine miles away from Chesapeake Bay, which gives us a sort of buffer. But that’s not a cure-all. There’s no way to deny that there’s sea-level rise.”"
"Unlike us, plants have ample self-control when it comes to choosing how much they eat. Ironically, as humanity struggles with an obesity epidemic, plant breeders are trying to make crops eat more. When you see a field of wheat in summer, the spikes of grain rippling gracefully in the breeze, you probably won’t have guessed that the plants are fat. Yet, compared to the wild grasses they are bred from, the ears of modern cereal plants are grotesquely obese. They have larger and more numerous grain, laden with vast reserves of starch, way in excess of what they actually need. This excess weight is our food. With year-on-year gains from conventional breeding beginning to peter out and an ever-expanding human population to feed, the race is on to find new ways to persuade plants to put on even more weight. And it turns out that an effective way to do this is to interfere with the signalling systems that control the rate at which plants synthesise their food. For plants, “food” means carbon dioxide from the atmosphere which they turn into sugars by photosynthesis, and nitrates in the soil which are metabolised to form amino acids. Plants then monitor the concentration of sugars and amino acids in their tissues and grow more rapidly when they “sense” that food is available. This is a “feed-forward” control system. But that’s not the whole story. Plants also have genetically programmed limits on growth. These limits ensure they produce the right tissues, of the right size, at the right time. They also stop the plant trying to grow when it is damaging to do so, for example when the weather turns bad.  When a plant comes up against its growth limits, food begins to accumulate and this generates a “feedback” signal causing the plant to turn down the food production systems. Effectively the plant realises it is full and stops eating. But what if we could tweak the controls? Could we then make crops even more obese? Experiments with the sugar control system suggests that the answer is a resounding yes.  A team of researchers from agrochemists Syngenta and Rothamsted Research made a single genetic modification to maize plants to prevent the accumulation of trehalose-6-phosphate, a key sugar monitored by the plant. Essentially, the plants were tricked into “thinking” that they were not producing enough sugar and as a result they increased production. This, in turn, seems to have triggered the feed-forward system because the genetically-modified plants produced up to 50% more grain in well-watered conditions and outperformed unmodified plants by 123% in drought conditions. If the same changes could be engineered for the nitrogen control system, then not only might we achieve even higher yields, but we could also address the agricultural run-off problem at the same time. Millions of tonnes of nitrate fertiliser are applied to fields every year but much of it remains unconsumed by crops. And when it rains, the excess runs off the fields, polluting nearby rivers and lakes. The difficulty is that, despite decades of research, the signalling system that underpins nitrogen appetite control has remained something of a mystery. Until now. In a study recently published in Plant Cell, a Swiss-German team describe how they uncovered part of the system lurking in a surprising place.  Quite by accident, they found out that a specific form of vitamin B6 (known as a vitamer) tells the plant when it is full of nitrogen. The first clue was that the vitamer accumulates in plants in parallel with ammonium, one of the immediate products of nitrate metabolism. The second was that plants with unusually high amounts of the vitamer had impaired growth that could be overcome by supplying ammonium.  Although not all the details are yet clear, the most telling observation was that the accumulation of the specific B6 vitamer led to the nitrate metabolism system being turned down – it works as an appetite control system. Perhaps the main reason we are having to retune the settings on the appetite systems of crop plants is that they are held back by their evolutionary history. The grass species that were domesticated to form cereal crops such as maize, rice and wheat are likely to have grown in poor soils – and plants that have adapted to such soils generally have conservative food strategies. This means they take up only as much as they need to grow and produce seed for the next generation. So it’s not surprising that when we throw nitrogen fertiliser at their cultivated descendants, they don’t gorge themselves on the unexpected feast. A mismatch between evolutionary history and modern conditions is also behind the human obesity epidemic. Just as with crops, the solution could lie in tweaking appetite systems; we just need to work out how to go in the opposite direction."
"
Share this...FacebookTwitterO/T
I’ve been waiting patiently for the German media to react to the explosive undercover video of a Planned Parenthood (PP) director, Deborah Nucatola, rolled by the Center for Medical Progress.
Warning – not easy to watch for people who even have just an inkling of compassion or any sense of humanity:

Sadly all this evil is happening now, and within the borders of the global “beacon of liberty and democracy”, of which I am a citizen, the United States of America.
It’s now been three days since the shocking video has been released and the reaction from the German media has been almost totally muted – just as I expected. Why? Here the predominantly center-left German media need time to carefully craft and spin the shocking story in a way that will not cause too much public disgust. They’ll get to it, though – dryly and curtly, and then rapidly move on to other things.
One major media outlet has gotten around and done a report on the PP video: the center-left Süddeutsche Zeitung (SZ) here – penned by Claus Hulverscheidt. How did he spin it?
As expected Hulverschidt presents the video as something that is part of an orchestrated attack campaign on a reputable “health and family planning provider”, of course one led by right-wing “Republikaner” (a harsh derogative in Germany) such as Jeb Bush, Ted Cruz, Carly Fiorina.
Hulverschidt bends over backwards to depict the PP franchise abortion organization as “not just some organization” but as a respective one “that has made a name for itself” in services like “family planning“, “cancer prevention” and “the search for health insurance for low income earners“. He writes of PP:
“Especially in large cities it enjoys great respect among women, is supported by celebrities such as actress Scarlett Johansson, and gets funding from the federal government in Washington.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Hulversheidt claims that the damage done by the video is not so much because of what Deborah Nucatola says at the dinner table, but because of the matter-of-fact way she says it: one professional speaking to another in her field. Never mind Nucatola openly admits in the video that PP centers are harvesting baby parts, organs and tissue for profit (maybe not PP’s profit, but certainly that of its scrupulous buyers).
Hulverscheidt concludes his piece:
In any case she indeed does say that they are operating in an ethical-moral gray zone. But with the help of the tissue samples, there is the opportunity to achieve progress in the fight against incurable diseases like Alzheimer and Parkinson, which otherwise would not be possible.”
Sorry, but the generational cannibalization of the unborn to the tune of millions of lives is not the way to cure diseases. Only a hopelessly, morally bankrupt and twisted mind could think so. Also disturbing is that Hulverscheidt fails to even bring up a single point or argument on behalf of the defenseless unborn.
Also no surprise, given the leanings of the SZ: Hulverscheidt does not bother to provide a link to the video itself to his readers, probably in the hopes they will just believe his every spin and not bother watching and deciding for themselves.
He also fails to mention that even Planned Parenthood Director Gloria Feldt is disturbed by the video and denounced (through clenched teeth, no doubt) “what seems to be totally inappropriate.”
This circling of wagons around a pet issue and defining it as black vs. white is typical of the German media, especially also when it comes to climate change, for example.
The media providing cover for an organization as loathsome as PP tells me that there are still many dark undercurrents at work in modern Germany.
Shame on Germany’s media.
Full version here.
Share this...FacebookTwitter "
"Announcements by airlines that they will offset their carbon emissions (Can carbon offsets tackle airlines’ emissions problem?, 19 November) misleads passengers into thinking that they are doing something to stop the atmosphere overheating. They are not. All that is accomplished is no net increase in atmospheric CO2. The message that needs to be conveyed is that far more offsetting is required to help reduce the upward trend in temperature. To double the calculation would be a good start. In the absence of carbon taxes or a frequent flyer levy, airlines (and cruise companies) should be required to inform passengers of this fact. It doesn’t matter too much whether the airline or the passengers pay, or if the cost is shared, as long as it happens.Patrick CosgroveChapel Lawn, Shropshire  • EasyJet is now reported as having jumped on the carbon offsetting bandwagon, claiming that all its flights will become “carbon neutral”. It might be wise for this scheme now to be recognised as little more than a comfortable delusion. Projected into the future, all airlines and indeed petrol companies could claim they were carbon neutral by adding typically a few percent to either ticket or pump prices. Indeed, Shell is already offering such a scheme. While the price of “offsetting” will inevitably increase, the Earth could warm irreversibly beyond a dangerous 1.5 or 2C threshold. Yet we could all still be driving and flying whenever we wished, having been told we were having no net impact. Carbon offsetting is basically dishonest in that it purports to offer a way of saving the world that is commensurate with a business-as-usual scenario. It is not a substitute for rapid reductions in fossil fuel energy use.Dr Stephen WozniakSidmouth, Devon • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitterIt appears leading German politicians have no interest in dealing with facts.
Last March geologist Dr. Sebastian Lüning, co-author of the climate science skeptic book “The Neglected Sun“, wrote a letter to German Chancellor Angela Merkel. Sadly he never got a reply.
Therefore he has posted the following letter at the Chancellor’s “Direct to the Chancellor” website here.
You can support Dr. Lüning’s request for answers and democratic participation by clicking “dafür stimmen” (in favor), circled in yellow in image below, at the end of the letter at the above link. You’ll have to enter the code in the box.

Here is Dr. Lüning’s letter in English:
The Fight against global warming





<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Dear Chancellor Merkel
I am referring to the article “The fight against global warming: Climate protection has priority” at: http://www.bundesregierung.de/Content/DE/Artikel/2015/02/….
1) You wrote (with reference to Germany):
‘Extreme weather events are becoming more frequent’
On which scientific publications and time periods are you basing this on? According to my knowledge most studies have found Central Europe has had no increase in weather extremes over the past 100 years.
2) You presented ‘heavy rains and storm flooding are on the increase’ and ‘the five largest natural catastrophes of 2014’ as examples of extreme weather events. Such a list can be drawn up for any desired year. Climatically relevant, however, in this relationship are foremost long-term trends of the last 100-300 years. How does these look? What is the intent of your list?
3) You wrote:
‘Climate change is leading to high costs. The total costs arising from natural disasters in 2014 worldwide was 110 billion dollars. One cyclone in India for example caused damage of seven billion dollars.’
However, scientific papers show that the observed rise in global extreme weather insurance damage is almost completely based on socio-economic reasons.
4) You quote Peter Höppe of reinsurer Munich Re: ‘Damages from thunderstorms and bad weather have been shown to be on the increase in various regions such as the USA and Central Europe.’
And what about other regions on Earth? How do things look when it comes to the global mean? And can it be excluded that natural fluctuations/shifts are at play here?
Thank you in advance for your reply.
Kindest regards
Sebastian Lüning


Share this...FacebookTwitter "
"Stop! Don’t send that email. Don’t offer thanks or send a jokey message. If you do, you will add to your carbon footprint. Be rude, say nothing – and save the planet. A new study commissioned by energy company OVO reckons Brits send more than 64m unnecessary emails every day, and that if every adult in the UK sent one fewer “thank you” email a day we would save more than 16,433 tonnes of carbon a year – equivalent to 81,152 flights to Madrid or taking 3,334 diesel cars off the road.  These are the sorts of stats beloved of green energy companies trying to get a bit of free publicity. But it’s all true, according to Mike Berners-Lee, a professor in the environment centre at Lancaster University, author of How Bad are Bananas: The Carbon Footprint of Everything, and brother of Tim Berners-Lee, inventor of the web. True in very general terms anyway: he probably won’t vouch for all those flights. How can one little email destroy the planet, I ask Mike Berners-Lee, who advised OVO on the research. “When you are typing, your computer is using electricity,” he says. “When you press send it goes through the network, and it takes electricity to run the network. And it’s going to end up being stored on the cloud somewhere, and those data centres use a lot of electricity. We don’t think about it because we can’t see the smoke coming out of our computers, but the carbon footprint of IT is huge and growing.” The electricity I grasp; the cloud is a bit beyond me. “It’s made up of enormous data centres all over the world,” Berners-Lee explains. “They are burning through huge amounts of electricity.” Super-efficient communication and storage is killing us. Every silver lining has a cloud. Berners-Lee admits the numbers are “crude estimates”, but says they are a useful way of making a general point. “When we take a small action to cut carbon,” he says, “it’s a message to yourself that you care about the climate emergency.” Does he blame his brother for all this? He laughs. “Many good things have come out of the web,” ... but only if we use it selectively. Now, how on earth do I file this piece? "
nan
"
Share this...FacebookTwitterNo warming in Antarctica. Southern Ocean Cooling Down
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
[Translated by P Gosselin]
In Antarctica if a single piece of ice breaks off, the media worldwide go into a frenzy: How could it happen? That’s got to be climate change. Yes, global warming is striking Antarctica with full force and is rearing its ugly head. Every iceberg that breaks off at the edge of the ice sheet is a sign of climate catastrophe. Amen.
But also during pre-industrial times chunks of ice broke off regularly. This is how ice sheets work: Snow builds up on the continent and then gradually moves towards the coast. What’s new?
So just how much has Antarctica warmed over the last years and decades? One reads or hears very little about this in the media. Therefore we’d like to take this knowledge deficit as an occasion to look more carefully at the temperature history of the great white continent.
Paul Homewood once posted on the temperature development of the past 35 years, using the satellite measurements:

There’s been no detectable warming. It was cold earlier and it is cold today! No Trend.
Perhaps the thermometer at the Amundsen Scott Base at the South Pole has found warming? Based on GISS data, Paul Homewood generated the following curve:

Also in the region of the South Pole station there has been no detectable warming, and that over the past 50 years.
In the next step we leave the mainland and examine the ocean to see if it may have warmed around Antarctica. Bob Tisdale put together the temperature curve based on the KNMI Climate Explorer data:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Again we find no warming here as well. To the contrary the Southern Ocean has even cooled over the past 35 years.
In June 2014 Marshall et al. confirmed the cooling trend in a Paper in the Philosphical Transactions A. The abstract states:
In recent decades, the Arctic has been warming and sea ice disappearing. By contrast, the Southern Ocean around Antarctica has been (mainly) cooling and sea-ice extent growing. 
In the paper’s main section the authors add:
Over the last few decades, the two polar regions of our planet have exhibited strikingly different behaviours, as is evident in observed decadal trends in surface air temperature shown in figure 1. The Arctic has warmed, much more than in the global average, primarily in winter, while Arctic sea-ice extent has decreased dramatically. By contrast, the eastern Antarctic and Antarctic plateau have cooled, primarily in summer, with warming over the Antarctic Peninsula and Patagonia . Moreover, sea-ice extent around Antarctica has modestly increased.
Appearing in the same year in the Annals of Glaciology was a paper by Ekaykin et al., where the temperature development of Central Antarctica was reconstructed over the past 350 years. The researchers found characteristic 30-50 years cycles. Interestingly it was warmer than today back in the 1940s than today. The following is the paper’s abstract:
Multiple climate shifts in the Southern Hemisphere over the past three centuries based on central Antarctic snow pits and core studies
Based on the results of geochemical and glaciological investigations in snow pits and shallow cores, regional stack series of air temperature in central Antarctica (in the southern part of Vostok Subglacial Lake) were obtained, covering the last 350 years. It is shown that this parameter varied quasi-periodically with a wavelength of 30–50 years. The correlation of the newly obtained record with the circulation indices of the Southern Hemisphere (SH) shows that the central Antarctic climate is mainly governed by the type of circulation in the SH: under conditions of zonal circulation, negative anomalies of temperature and precipitation rate are observed, whereas the sign of the anomalies is positive during meridional circulation. In the 1970s the sign of the relationship between many climatic parameters changed, which is likely related to the rearrangement of the climatic system of the SH. The data suggest that during the past 350 years such events have taken place at least five times. The stable water isotope content of the central Antarctic snow is governed by the summer temperature rather than the mean annual temperature, which is interpreted as the influence of ‘post-depositional’ effects.
And when we look even further back in the past, we find more surprises. During the last interglacial, the Eem Warm Period of 130,000 years ago, it was 3.5 to 4.0°C warmer than today. This was reported by Parennin et al. in a publication appearing in February 2015 in the Climate of the Past Discussions.
On this matter a paper by Conway et al. appearing in 1999 in Science is interesting. Back then the authors recognized that the West Antarctic ice sheet shrank foremost during the mid Holocene, i.e. some 5000 years ago. The scientists suspect that the melting process started already during the early Holocene some 10,000 years ago and has continued on without any external influences until today:
Past and Future Grounding-Line Retreat of the West Antarctic Ice Sheet
The history of deglaciation of the West Antarctic Ice Sheet (WAIS) gives clues about its future. Southward grounding-line migration was dated past three locations in the Ross Sea Embayment. Results indicate that most recession occurred during the middle to late Holocene in the absence of substantial sea level or climate forcing. Current grounding-line retreat may reflect ongoing ice recession that has been under way since the early Holocene. If so, the WAIS could continue to retreat even in the absence of further external forcing.
Today we would like to conclude with a curious “discovery” On May 23, 2014. Spiegel Online brought us a frightening climate alarm story:
Ice melt: Irreversible chain reaction feared in Antarctica
[…] “A large piece of the ice cap in West Antarctica finds itself at a stage or irreversible retreat,” NASA scientist Eric Rignot of the University of California, Irvine. In the previous calculations by the IPCC concerning sea level rise the phenomenon was not adequately taken into account. In a study that was recently published in the “Geophysical Research Letters” the scientists lead by Rignot studied the retreat of all six large glaciers.”
Just awful…so, who brings us this terrible news? Does Eric Rignot really know what he’s doing? Hold on to your seat: Rignot is in fact not a climate scientist. He’s an electrical engineer…just in case someone complains later on that a non-Phd does not qualify anyone to participate in the climate discussion…
Share this...FacebookTwitter "
"For most of us, commuting is a task to be endured. Busy, noisy and often cramped, the world’s underground transport systems are places that we humans tolerate as a matter of necessity. But not so for Moscow’s “metro dogs”. A number of strays have taken to riding the city’s underground railway – and remarkably, they seem to know where they’re going. Of Moscow’s 35,000 odd stray dogs, about 20 are thought to travel regularly on the city’s underground rail system. These dogs seem to be able to identify which trains to board, and where to alight. It appears that they can recognise humans who will give them a treat or a pat – and avoid those who won’t. They also show an impressive ability to deal with the noise and activity of the busy metro system, which many pet dogs would find distracting and stressful – indeed, they can often be found relaxing and sleeping in the crowded carriages.  So how did Moscow’s stray dogs learn this behaviour? Well, dogs have co-evolved alongside humans for several thousand years. During that time, they have developed the capability to recognise and respond to our physical and emotional signals. While most animals have trouble interpreting the social cues of other species, dogs are unusually adept at responding to human behaviour. This evidence goes some way to explaining how Moscow’s metro dogs know who to approach and who to steer clear of.  These social skills strongly suggest a degree of convergent evolution between dogs and humans. This occurs when different species evolve similar traits while adapting to a shared environment. So, the abilities of the metro dogs might even suggest that they have developed coping mechanisms similar to those of their fellow human commuters.   But Moscow’s stray dogs have an even stronger motivation to venture into the metro system. Dogs learn through positive associations – this forms the basis for the modern reward-based methods we use to train both working and pet dogs. For example, we can teach a dog to “sit” on command by rewarding that behaviour with treats. These positive reinforcement strategies generate reliable and consistent responses from our canine companions, as well as safeguarding their welfare.  It seems likely that the metro dogs have learned to associate the subways with warmth and food. So the strays return, time and time again, much like the pet dog that repeatedly “acquires” dinner from the kitchen counter. For the metro dogs, the rewards of food and shelter are probably worth the risk of negative experiences, such as being shooed away, hurt or worse: one poor pooch, called Malchik, was stabbed to death in the subway, to the dismay of many Muscovites.  In this way, the metro mutts might serve as an interesting model for training pet dogs, since they show us that particularly powerful rewards will overcome incidental negative experiences. Explaining how the metro dogs navigate the underground transport system is a bit more complicated. Given that the canine nose is substantially more sensitive than our own, it’s distinctly possible that they choose which stations to disembark at, based on scent. But studies suggest that dogs often use many sensory cues to find their way, and do not rely on smell alone.   So, the metro dogs probably use many indications including smell, lighting, passenger movement and perhaps even specific people to get their bearings in the subway. It has even been suggested that the dogs come to know the stations by name, by listening to the announcements over the tannoy. We know that dogs can learn words, so this is a possibility. But in this case, we can’t be sure whether the dogs genuinely know the names of specific stations, or simply associate some of them with food.  The final puzzle is how the dogs are able to time their journeys. This is a tough one, because it’s difficult to prove that dogs can even grasp the concept of time: many pet owners will receive identical welcome responses from their dogs, whether they have been absent for one minute or one hour. These observations suggest that dogs may perceive the passage of time very differently to humans.  Even so, many animals thrive on routine, and dogs are no exception. The regular goings on in Moscow’s metro – the opening and closing of stores, the peak hour rush and the system’s nightly shutdown – could be encouraging the dogs in their travels. The dogs are likely to associate these routine happenings with positive experiences, much like the excitement of a pet dog on hearing their owner’s car pull into the driveway after a day at work.   Moscow’s metro dogs represent an extremely interesting example of the domestic dog’s ability to adapt to a world built for humans, by humans. They show us that dogs have developed the capability to read human behaviours and respond accordingly, and to integrate themselves into our daily customs and practices. Understanding how dogs respond to the changing human world can help us understand both them, and ourselves, much better."
"Labour has announced plans to plant 2bn trees over the next 20 years and create 10 new national parks, as part of a rewilding policy intended to tackle the climate emergency and help natural habitats. The proposals also include an investment of £1.2bn to restore habitats such as woodlands and peat bogs in England, and extra funding for national park authorities. An extra £2.5bn would be used for a tree-planting programme covering national parks, other publicly owned land, farmland and “natural corridors” along parks, cycle routes and canals. Labour said it would increase funding for national parks by 50%. None of the 10 proposed new national parks have been decided on, but ideas suggested by Labour include the Malverns, Chilterns, Lincolnshire Wolds and north Pennines. Part of the decision would rest on the state of environmental degradation in the areas being considered as well as the potential for capturing carbon emissions and improving biodiversity. The entire programme, once completed, could store up to 47m tonnes of carbon emissions each year by 2050, Labour said, while new wild habitats would benefit endangered birds, animals and insects. The party said an estimated 20,000 jobs would be created in areas such as forestry management, and a total of 1m jobs under a wider plan to reshape the economy on a sustainable basis. On Wednesday night, Jeremy Corbyn told supporters in Falmouth at a rally to promote the party’s “green industrial revolution”, that the 2016 Paris climate agreement did not go far enough. He said: “I want to lead a Labour government that next year will host the next climate change conference, and which will be much stronger than Paris. “Our government will be one that will be very environmentally conscious, it will bring about a net zero emissions. Our government will work on the world stage to achieve that as well.” Part of Labour’s 1m green jobs plan will also include nationwide home refurbishments,creating jobs through insulation upgrades, as well as in offshore wind and carbon capture. The jobs will also come from hydrogen and tidal energy expansion, port infrastructure, flood defences and plastics recycling. With just two weeks until the election, Corbyn warned supporters: “Everything is going to be thrown at us in the next two weeks. Every bit of abuse that the right wing press can find. Every bit of abuse that the wealthiest in our society can throw at people that want to bring about real change.” Friends of the Earth welcomed the plan but said parties should remember that “trees will only help fix the climate crisis if emissions cuts happen at the same time”. Guy Shrubsole from the environmental group, said: “This is by far the most ambitious tree-planting pledge we’ve seen from a political party. Tree cover in the UK needs to double as part of the fight against climate breakdown and this means adding 3bn new trees, and fast. If sustained, Labour’s promised tree-planting rates would achieve this by 2050.”"
"I started learning driving only three years ago, and – inevitably – failed my first test. Naturally, I was disappointed: but then it occurred to me that I could avoid the whole issue, if only I could get my hands on a driverless car. And this triggered the research question: what would the overall impact on travel demand, energy use and carbon emissions be if driverless cars were readily available to the likes of you and me?  I joined a few like-minded academics in the US – Don MacKenzie and Paul Leiby – to research how the automation of road transport might affect energy use, and to quantify the potential range of these impacts. We found that a widespread adoption of self-driving vehicles could indeed help to reduce energy consumption in a number of ways. For example, on motorways, automated vehicles can interact with each other and drive very closely as a “platoon”. This can reduce the total energy consumption of road transport by 4% to 25%, because vehicles which follow closely behind each other face less air resistance.  What’s more, when vehicles can interact with each other and road infrastructure – such as traffic control systems – this will smooth out the traffic flow. The result will be less congestion and a reduction in energy use of up to 4%. On top of this, automated “ecodriving” – a driving style which controls speed and acceleration for more efficient fuel use – can reduce energy use by up to 20%. When you are riding in your self-driving car, obviously you won’t be at the controls, so you will no longer be able to enjoy the rapid acceleration of your driving days – so perhaps the desire for more powerful engines could diminish. And given that vehicle safety is expected to improve dramatically in self-driving cars, some of the heavy safety features could be removed, making cars lighter. Each of these changes could reduce energy use by up to 23%.  So far, so good – all of these mechanisms improve the efficiency with which a car travels. But, as a society, our interest lies in reducing total energy use, or total carbon emissions – and energy efficiency forms only one half of this picture. Our total carbon emissions also depend on the demand for travel. So, while improving the energy efficiency of cars by automating the driving process will reduce the carbon emissions of individual vehicles, the overall impact of this change will depend on how many people use them. For instance, consider what would happen if large numbers of people switched to self-driving cars from travelling by train. We generally prefer the privacy and convenience of travelling by car, but using public transport means we can concentrate on other stuff – such as reading a book or getting some work done. A self-driving car offers all of these benefits. As a result, we found that driverless cars could prove so attractive that they increase car travel by up to 60% in the US.  As you can see below, the features of driverless cars may have a range of impacts on energy consumption – both positive, and negative.  Self-driving cars could also encourage a completely new group of people to own vehicles – for example, the elderly, the disabled and possibly those too young to drive themselves. This would increase the welfare of that demographic by giving them greater mobility. Yet travel demand, energy use and carbon emissions would all rise: our estimate for the US is an increase between 2% and 10%. But it’s not all bad news: self-driving cars could encourage a move away from current car-owning culture to a car-sharing or on-demand culture. This opens up a few different possibilities. For one thing, by making the per-mile costs more visible to the user, car sharing or automated taxis could reduce travel demand from individuals. Yet these shared automated cars may still travel empty for some parts of their trips, so this option could lead a reduction of energy use between 0% to 20%.  But even greater energy savings are possible if the size of the self-driven shared car is matched to the trip type: for example, if a one-person commute trip is undertaken by a compact car, while for a family leisure trip a medium-sized sedan is used. This approach could reduce energy demand by 21% to 45%. One thing we haven’t touched in great detail is the potential for self-driving cars to encourage a switch to alternate fuels such as electricity and reduce carbon emissions. Imagine the car dropping you off at your destination and finding a charging point to recharge itself.  So, automation does have the potential to reduce energy use for road transport. But this is not a direct result of automation per se; rather, it is due to how automation changes vehicle design, operations and ownership culture. It’s also interesting that some of the energy-saving benefits of self-driving cars are possible at a lower level of automation, through increased interaction between vehicles and infrastructure.  It is clear that the benefits of self-driving cars will depend on how we use them. The widespread adoption of automated vehicles could well have some unexpected effects, so it’s vital that we find and implement ways to realise the full energy-saving and carbon-reducing potential of self-driving cars. Until then, we’d better keep practising our driving."
"It’s mid-February and along Britain’s south coast gilt-head bream are drifting from the open sea into the estuaries. Meanwhile, thousands of little egrets are preparing to fly to continental Europe for breeding season, though a few hundred will remain in the UK.  Across northern Europe, young wasp spiders will soon scamper out of their silky egg sacs. And this summer, countryside visitors throughout the south of England will catch sight of iridescent blue flashes as small red-eyed damselflies flit across ponds.  These events all have one thing in common: they’re happening much further north than they would have as recently as 20 years ago. It’s not just a European thing. Polar bears are on the move, umbrella trees are creeping northwards through the US, and tropical birds in New Guinean mountains are retreating uphill. Southern Africa’s iconic quiver tree, which provides refridgeration in its hollowed out trunks, is itself escaping the heat and heading away from the equator. Across the world species are moving from their natural habitats. Fingers point at climate change. As areas become too hot or dry, many wildlife populations are declining. But on the flip side, some species are showing up in places that were historically too cold or wet.  The story we usually hear is of terrible declines in plants and animals. The Pyrenean Frog is languishing on mountaintops on the Spanish-French border, for instance, unable to move to cooler climes. Magellanic penguin chicks are dying in storms brought on by climate change. Costa Rica’s golden toads, which are actually a rather amazing bright orange, are thought to have been driven to extinction by warmer, drier weather, among other factors.  So why are so many species threatened by climate change, while others, like the gilt-head bream, little egret and wasp spider, are able to thrive? Colleagues and I have just published a paper that tries to answer this question. Our team, led by Alba Estrada, wanted to understand why some species decline in the face of climate change while others colonise distant habitats. Colonisation might avoid extinctions and may even make some species more successful than they were before climate change. If we could predict which species can and can’t colonise new locations, we could decide which are most in need of conservation.  How far individual animals or plant seeds can move was long thought to be the most important factor. For example, the wasp spider has probably spread so quickly by using an extraordinary technique called ballooning: releasing fine threads of silk into the air and floating for many kilometres on them.  But other characteristics also turned out to be highly important. For example, how quickly plants and animals can breed, how well they can compete with other species for resources, and what kinds of food they can eat or habitat they can live in. The upshot of this is that we might be able to predict which animals will thrive under climate change. The wood mouse is found throughout continental Europe, up to the southern tip of Norway and Sweden. As climate changes, we think the mouse will move north into Norway, Sweden, and Finland because it can breed quickly, live in lots of habitats, has a broad diet, and individuals can travel a long way.  On the other hand, consider the European ground squirrel. This small rodent currently lives in southeast Europe, though large parts of the rest of the continent will become suitable as the weather warms. However, we think it might stay just where it is because it can only live in grasslands – and climate change won’t suddenly turn farms and forests into meadows. It’s encouraging to know that some species are doing well under climate change, and that northern European wildlife lovers can look forward to seeing some exotic plants and animals in their countryside. There are some headaches, however. Those gilt-head bream are munching away on the local shellfish, which might be taking food away from the native fish. Small red-eyed damselflies look great, but they could become all too common around British ponds and outcompete native species. Several birds that have colonised the UK from warmer climes seem to be have been helped along by wetland conservation areas. Could the very methods we use to protect wildlife be helping some dangerous species to spread? There are good reasons to both welcome these newcomers with open arms, and worry about the damage they might do. Climate change is once again posing us some tricky conservation questions."
"Gene-modifying techniques could reduce the greenhouse gas emissions from livestock, helping to feed the world while combating the climate emergency, scientists have said. “Conventional [genetic] selection is extremely powerful,” said Mike Coffey, a professor of livestock informatics at Scotland’s Rural College. “At this point in time, GM [genetic modification] is not allowed in Europe, but some of these technologies could have great potential promise.”  Eileen Wall, the head of research at the college, said work was under way, without using GM, to formulate better diets for ruminants to reduce the methane they produce, but using GM could give a greater range of options. “You could have novel genes in plants to make less methane.” Methane associated with livestock production is an increasing contributor to the climate emergency, as the world’s appetite for meat shows no sign of slowing down. The amount of land required to be cultivated to feed livestock adds to the problem, with its associated fertiliser use and deforestation. Many studies have suggested that moving to a diet based largely on plants and containing much less meat than is currently consumed in rich countries will be vital to combatting the climate crisis. It would also be healthier, as consumers in the rich world are eating more meat than is recommended, though poorer people struggle to get enough protein. Using GM technology in plants for human consumption and in animals is banned in Europe. However, the UK could loosen restrictions after Brexit. Any such move would be highly controversial among some farming campaigners, in part because it could open up rifts with the EU over trade. Rob Percival, the head of policy at the Soil Association, cast doubt on the potential climate benefits. “GM is a distraction – we already have the solutions to the climate crisis at our fingertips. The focus should be on empowering farmers to adopt more nature-friendly agroecological farming systems and shifting diets to create demand for more sustainable food,” he said.  “Instead of looking to risky and unproven technologies and chemicals as a sticking plaster, we should be tackling the root causes of these crises, putting farmers in the driving seat of sustainable innovation.” Geoff Simm, the director of the global academy of agriculture and food security at the University of Edinburgh, said farmers were feeling “demonised” by campaigns encouraging people to adopt vegan diets to protect the climate.  Calculations of the harm done by eating meat are usually based on US production techniques, which are highly intensive and involve grain-feeding. In the UK, by contrast, cows and sheep are more likely to graze outdoors, often using land that would not be viable for crop production, which means their associated emissions are far less. In the UK there is also far more overlap between the beef and dairy industries, with more than half of beef production coming from the dairy herd, which also makes for lower emissions. Conventional breeding techniques have also played a role in cutting livestock emissions, with the UK now producing more milk from fewer cattle than it did 25 years ago."
"The imprinting of climate emergency into the public consciousness, achieved by the school strikes and mass activist arrests, seems to have generated more introspection than positive action. The debate around personal sacrifice, hypocrisy and lifestyle change is playing at high volume and, as recently highlighted by the climate expert Michael Mann, this presents a danger that popular demand for catastrophe-avoiding systemic change could get lost in the mix.  This debate is just as alive (and equally confused) within the music industry. Headline emphasis is often placed on issues such as single-use plastics or band travel by air. Important as those things are, evidence shows that factors such as audience transportation and venue power account for as much as 93% of all the CO2 emissions generated by major music events. As a band that has toured globally for several years, we’ve had cause to reflect on this. Concerns over our own carbon impact and those of our wider industry aren’t new to us, but the urgency is. Last year, the UN Intergovernmental Panel on Climate Change called for “rapid, far-reaching and unprecedented changes in all aspects of society” and said carbon emissions were harmful, regardless of the fun had in their generation. In other words, what goes on tour doesn’t stay on tour. We’ve taken unilateral steps for nearly two decades – like many bands, we’ve paid to have trees planted, prohibited the use of single-use plastics and travelled by train wherever feasible. We have explored advanced carbon offset models, but in researching these programmes serious issues arose. First, the concept of offsetting creates an illusion that high-carbon activities enjoyed by wealthier individuals can continue, by transferring the burden of action and sacrifice to others – generally those in the poorer nations in the southern hemisphere. Evidence suggests that offset programmes can wreak serious havoc for the often voiceless indigenous and rural communities who have done the least to create the problem. Ultimately, carbon offsetting transfers emissions from one place to another rather than reducing them. The European commission has warned that 85% of projects were unlikely to deliver “real” or “measurable” reductions, while the UN environment programme recently stated that offsetting cannot be used by polluters “as a free pass for inaction”.  We’ve also discussed ending touring altogether – an important option that deserves consideration. In reality, however, an entire international roster of acts would need to stop touring to achieve the required impact. In a major employment industry with hundreds of acts, this isn’t about to happen. Any unilateral actions we take now would prove futile unless our industry moves together, and to create systemic change there is no real alternative to collective action. So today we’re announcing the commissioning of the renowned Tyndall Centre for Climate Change Research to map the full carbon footprint of typical tour cycles, and to look specifically at the three key areas where CO2 emissions in our sector are generated: band travel and production, audience transport and venue. The resulting roadmap to decarbonisation will be shared with other touring acts, promoters and festival/venue owners to assist swift and significant emissions reductions. The stark reality is that failure to do so could mean matters are taken out of our hands. In recent months, (thanks in no small part to those strikes and those arrests) 245 local authorities across the UK have declared a climate emergency, with 149 setting targets of zero emissions by 2030 or earlier. In the festival sector alone, this number includes the licensing authorities for each of the five best-attended UK outdoor events: Glastonbury, Download, Reading/Leeds, V Festivals and Creamfields. Their event plans will now inevitably include mandatory rules on carbon emissions, and so the likelihood of licences being granted without emissions being dramatically and continually reduced is slim. Given the current polarised social atmosphere, uplifting and unifying cultural events are arguably more important now than ever, and no one would want to see them postponed or even cancelled. The challenge therefore is to avoid more pledges, promises and greenwashing headlines and instead embrace seismic change. The report produced by the Tyndall Centre will not provide a panacea, and we know implementation of its findings will require significant change for us and our colleagues across the industry who are as keen as we are to create change. But in an emergency context, business as usual – regardless of its nature, high profile or popularity – is unacceptable. • This article was written by musician Robert Del Naja on behalf of Massive Attack"
"You know that greenhouse gases are changing the climate. You probably know drinking water is becoming increasingly scarce, and that we’re living through a mass extinction. But when did you last worry about phosphorus?  It’s not as well-known as the other issues, but phosphorus depletion is no less significant. After all, we could live without cars or unusual species, but if phosphorus ran out we’d have to live without food. Phosphorus is an essential nutrient for all forms of life. It is a key element in our DNA and all living organisms require daily phosphorus intake to produce energy. It cannot be replaced and there is no synthetic substitute: without phosphorus, there is no life. Our dependence began in the mid-19th century, after farmers noticed spreading phosphorus-rich guano (bird excrement) on their fields led to impressive improvements in crop yields. Soon after, mines opened up in the US and China to extract phosphate ore – rocks which contain the useful mineral. This triggered the current use of mineral fertilisers and, without this industrial breakthrough, humanity could only produce half the food that it does today.  Fertiliser use has quadrupled over the past half century and will continue rising as the population expands. The growing wealth of developing countries allows people to afford more meat which has a “phosphorus footprint” 50 times higher than most vegetables. This, together with the increasing usage of biofuels, is estimated to double the demand for phosphorus fertilisers by 2050. Today phosphorus is also used in pharmaceuticals, personal care products, flame retardants, catalysts for chemical industries, building materials, cleaners, detergents and food preservatives. Reserves are limited and not equally spread over the planet. The only large mines are located in Morocco, Russia, China and the US. Depending on which scientists you ask, the world’s phosphate rock reserves will last for another 35 to 400 years – though the more optimistic assessments rely on the discovery of new deposits. It’s a big concern for the EU and other countries without their own reserves, and phosphorus depletion could lead to geopolitical tensions. Back in 2008, when fertiliser prices sharply increased by 600% and directly influenced food prices, there were violent riots in 40 different developing countries. Phosphorus also harms the environment. Excessive fertiliser use means it leaches from agricultural lands into rivers and eventually the sea, leading to so-called dead zones where most fish can’t survive. Uninhibited algae growth caused by high levels of phosphorus in water has already created more than 400 coastal death zones worldwide. Related human poisoning costs US$2.2 billion dollars annually in the US alone. With the increasing demand for phosphorus leading to massive social and environmental issues, it’s time we looked towards more sustainable and responsible use. In the past, the phosphorus cycle was closed: crops were eaten by humans and livestock while their faeces were used as natural fertilisers to grow crops again.  These days, the cycle is broken. Each year 220m tonnes of phosphate rocks are mined, but only a negligible amount makes it back into the soil. Crops are transported to cities and the waste is not returned to the fields but to the sewage system, which mainly ends up in the sea. A cycle has become a linear process. We could reinvent a modern phosphorus cycle simply by dramatically reducing our consumption. After all, less than a third of the phosphorus in fertilisers is actually taken up by plants; the rest accumulates in the soil or is washed away. To take one example, in the Netherlands there is enough phosphorus in the soil today to supply the country with fertiliser for the next 40 years. Food wastage is also directly linked to phosphorus overuse. In the most developed countries, 60% of discarded food is edible. We could also make agriculture smarter, optimising the amount of phosphorus used by specially selecting low-fertiliser crops or by giving chickens and pigs a special enzyme that helps them digest phosphorus more efficiently and therefore avoid extensive use of phosphorus-heavy growth supplements. It takes vast amounts of energy to transform phosphate ore into “elemental phosphorus”, the more reactive and pure form used in other, non-agricultural sectors. Inventing a quicker route from raw rocks to industrially-useful compounds is one of the big challenges facing the future generation. The EU, which only has minimal reserves, is investing in research aimed at saving energy – and phosphorus. We could also close the phosphorus cycle by recycling it. Sewage, for instance, contains phosphorus yet it is considered waste and is mainly incinerated or released into the sea. The technology to extract this phosphorus and reuse it as fertiliser does exist, but it’s still at an early stage of development. When considering acute future challenges, people do not often think about phosphorus. However, securing enough food for the world’s population is at least as important as the development of renewable energy and the reduction of greenhouse gases. To guarantee long-term food security, changes in the way we use phosphorus today are vital."
"
Share this...FacebookTwitterScience-ethically dubious: Stefan Rahmstorf silent on large body of dissenting Gulf Stream results in newspaper interview
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
[Translated, edited by P Gosselin]
There was an interview with Stefan Rahmstorf in the German daily Märkischen Allgemeine Zeitung (MAZ) on March 23, 2015:
A tipping element on which the globe’s future hinges
Climate scientist Stefan Rahmstorf and his colleagues at the Potsdam Institute for Climate Impact Research have evidence of a further weakening of the Gulf Stream.”
That’s old hat. As we have already reported here, other teams of scientists unfortunately have been unable to find any such weakening of the Gulf Stream, and so Rahmtorf is pretty much standing all by his lonesome in the middle of nowhere. And that did not did not remain unnoticed by the MAZ, which persisted courageously:
MAZ: Climate skeptics such as former Environment Hamburg Senator of Fritz Vahrenholt characterized the weakening of the Gulf Stream as part of the natural cycles.
Rahmstorf: I’d be curious to see evidence of that – unfortunately Herr Vahrenholt has published practically nothing in the scientific literature. We also looked for natural cycles and have determined that there have not been any significant fluctuations over the past 1000 years.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




True, Fritz Vahrenholt did not publish anything on that topic. But others have to a great extent and Vahrenholt quoted them. This is how science works: You do not need to research everything yourself, rather you turn to the large research networks and peer-reviewed literature. Notable here are for example studies from the University of Rhode Island, NASA, University of Heidelberg, University of Hamburg. The scientists in Hamburg have just recently shown natural cycles. It is quite amazing that suddenly Rahmstorf is unable to recall any of these studies and prefers to indulge in some Vahrenholt-bashing. Apparently the MAZ also found his excuse hardly helpful and continued to persist:
MAZ: Climate scientist Mojib Latif also does not believe in the currently diminishing speed of the Gulf Stream.
Rahmstorf: The current weakening has also been confirmed by other studies. We simply track the stream with the help of proxy data further back in time. In a 2004 study fellow scientist Latif used temperature differences from the North and South Atlantic in order to determine the speed of the stream. Here it was not taken into account that we had an aerosol blocking of the sunlight because of air pollution in the northern hemisphere. This effect cannot be so clearly separated from that of a change in the stream; thus we have refined his methods.
Who believes? Rahmstorf here is peddling to a newspaper his very one-sided view as the supposed consensus within the science field. Embarrassing and science-ethically very unclean. That’s a shame.
===============
It seems Rahmstorf may have a growing habit of not playing cleanly. -PG
Share this...FacebookTwitter "
"One of the big problems with the world’s heavy carbon emissions is that they are driving up the levels of carbon dioxide in our oceans, which is making them more acidic. The surface pH of the oceans has already dropped from 8.1 to 8.0 over the past couple of decades, and is projected to reach 7.7 by 2100 – a huge change in biological terms.  This is reducing the carbonate in the water that marine organisms including shellfish, corals and sea urchins depend on to make their shells and exoskeletons. I co-published a study two years ago into how this would affect mussels. By simulating the ocean conditions of 2100, we found that their shells did not grow as large and were harder and more brittle. Now, in a new study, we have seen fascinating signs of them adapting to these changes.   When we looked at the mussel shells of the future in our first study, we found they fractured considerably more easily. This made them more vulnerable to predators such as birds and crabs – and also to stormy conditions, since the stronger waves can bang them against rocks and other mussels. As an economically important food source across the world, it has worrying implications for those who depend on them to make their living – indeed, mussel farmers tell me they are noticing these changes even now. It also raises the prospect of similar problems for other shellfish such as oysters and cockles, not to mention sea urchins and corals. Our new study took the work further by using a combination of X-ray techniques to understand how ocean acidification causes these changes and how the organisms continue to make their shells in spite of it.  Marine organisms such as mussels create shells in several stages. They take up the carbonates and calcium in sea water through their tissue and convert them into a substance known as amorphous calcium carbonate (ACC). They essentially move this substance to the correct location in their body and convert it into a harder substance called crystalline calcium carbonate (CCC), which comprises the bulk of the shell. But they also keep some carbonate in ACC form, which they use for repair purposes – not unlike the way humans grow bones.   Our “future mussels” had to cope with the uptake of fewer carbonates overall, but what they did was to convert a lower proportion into CCC than usual – hence they grew less shell. Instead they kept more as ACC, which seemed to be a repair mechanism to combat the increased risk of shell damage from having more brittle shells.  So is this a sign that nature will find a way to cope as the oceans get more acidic? Not necessarily. The mussels might have been retaining more of the repairing ACC, but they are vulnerable while the shell is fractured, and might not live long enough to fix it.  We also don’t yet know whether they would have enough ACC to keep their more brittle shells in a good enough state of repair. To find out, you would have to look at what happens to them over a number of generations. This is what we intend to look into next. This research will have huge implications for other marine organisms producing calcium carbonate shells and exoskeletons including shellfish, corals and sea urchins. In the meantime, ocean acidification undoubtedly means huge changes for the creatures that live there, with consequences that are extremely difficult to predict."
"An increasing proportion of voters worry Australia is not doing enough to reduce the risks of climate change, and more people see a direct link between warming and bushfires, according to the latest Guardian Essential poll. Ominously for the Morrison government, which bristles at regular public criticism it is not doing enough to reduce the risks of the climate crisis, 60% of the sample of 1,083 voters believes Australia should be doing more. This is up from 51% in March. Just under half the sample, 43%, believes it is likely bushfires are linked to climate change, and argues it is entirely appropriate to discuss that link during an emergency of the scale we’ve seen around Australia over the past fortnight. When this question was last put to survey respondents in 2013, only 27% of the sample had this view. While Scott Morrison has accepted the link between climate change and natural disasters, the prime minister has argued – including in parliament on Monday during a statement on the bushfires – that it is not appropriate to get into that debate while a disaster is in progress. The Labor leader, Anthony Albanese, responded to Morrison’s comments on Monday by arguing Australia does not have the luxury of time to defer important discussions. But Albanese said it was important that public discussion of the issues be “sober” and not rancorous. Voters most likely to think Australia is not doing enough to deal with the risk of climate change are under 34, and support Labor or the Greens – although the latest Guardian Essential survey indicates that 46% of Coalition voters in the sample share this view. The poll indicates that 61% of the sample believes that climate change is happening and is caused by human activity. That level of support is consistent with readings taken in March this year and October of last year. While that view is supported by 74% of Labor voters in the sample and 89% of Greens voters, it is supported by just under half of Coalition voters, 47%. Just over a quarter of the sample (28%) says people aren’t witnessing climate change, they are witnessing a normal fluctuation in the Earth’s climate. Perceptions are different depending on the age of voters. People aged 18-34 are most likely to accept anthropogenic climate change (74%) and voters over 55 are least likely to (50%). A separate poll of 25,000 Australians aged 15 to 19, released on Tuesday, shows a sharp rise in concern for the environment and climate change in both cities and regional areas. As part of the 18th annual Mission Australia youth survey, people were asked to name the three most important issues for Australia. Behind mental health, the environment was ranked the second most important issue, chosen by 34% of young people, with more than half of those citing climate change. In 2018, the environment was ranked eighth, nominated by just 9% of young people. The chief executive of Mission Australia, James Toomey, said young people were feeling disenfranchised and this was driving them to find other ways to be heard “such as climate strikes.” He said: “The growing public dialogue and experience of issues, such as extreme weather events and drought, are clearly affecting young people’s view of the world.” Essential said the proportion of people who think it is likely that the bushfires are linked to climate change, but that it is inappropriate to publicly raise this issue during disasters, has remained fairly constant over time. In this fortnight’s poll, 17% of the sample express that view while 14% had that opinion in 2013. Morrison defended the Coalition’s record on climate action during question time on Monday. He contended that Australia was in that group of countries which is “beating, the commitments that we have made to the world, and we will continue to do that”. “Australia is doing its bit when it comes to dealing with climate change,” the prime minister said. But he said the government had no intention of adopting “reckless targets supported by the Greens and the Labor party”. The prime minister said it was an “outright lie” to argue that if the Coalition had adopted higher emissions reduction targets then the bushfires would not have happened. While Australia has committed under the Paris agreement to reduce emissions, pollution has risen consistently since the Coalition repealed the carbon price shortly after winning government in 2013. In an interview with Guardian Australia’s politics podcast last week, the former prime minister Malcolm Turnbull cut across Morrison’s regular protestations that enough is being done by noting that Australia would struggle to meet its Paris emissions target without rapid decarbonisation of the energy sector. • Sign up to receive the top stories from Guardian Australia every morning Turnbull also said the Liberal party’s continuing failure to develop a coherent climate and energy policy was costing the country much-needed new investment in power generation. There has been controversy post-election about the reliability of opinion polling, as none of the major surveys – Newspoll, Ipsos, Galaxy or Essential – correctly predicted a Coalition victory on 18 May. The polls instead projected Labor in front on a two-party-preferred vote of 51-49 and 52-48. The lack of precision in the polling has prompted public reflection at Essential, as has been flagged by its executive director, Peter Lewis. Guardian Australia is not now publishing measurements of primary votes or a two-party-preferred calculation, but is continuing to publish survey results of responses to questions about the leaders and a range of policy issues. The poll’s margin of error is plus or minus 3%."
