"
Share this...FacebookTwitterExperts are finding out wind turbines are not only an inefficient way to produce electricity, but that they are also wrecking the environment, natural habitats and even the climate.

German meteorologist Dr. Karsten Brandt warns wind turbines are altering local climates. Image: Donnerwetter.de.
So far we know wind parks:

Are an erratic source of power
Have high maintenance costs
Involve recycling problems
Blight the natural landscape
Are a hazard to birds and wildlife
Result in deforestation and wrecked biotopes
Make people seriously sick (infrasound), and
Interfere with weather radars.

And according to one German prominent meteorologist, Dr. Karsten Brandt of Donnerwetter.de,  wind turbines are now even putting the brakes on wind speeds and even altering local climates.
How an environmentalist could support this form of energy is becoming increasingly mind-boggling. Hat-tip Die kalte Sonne here. The Donnerwetter.de press release follows:
Less and less wind due to more and more wind turbines?
An ever weaker wind is blowing across Germany. For example in the 1960s annual wind speeds of 3.7 meters per second were measured in Osnabrück, but now it’s only 3.2 m/s. That’s a drop of over 13 percent. Almost all weather stations in the country which were analyzed by the Bonn-based meteorologists at donnerwetter.de found that the trend looks similar. 
Wind speed has decreased “very significantly”
“In most places, the mean wind speed has decreased very significantly,” says Dr. Karsten Brandt. And he has a suspicion: “We believe that in the last 15 years more and more massive wind turbines have influenced the wind speed.”
The trend of ever decreasing winds was not observed out on the open sea, however. To the contrary: On the islands of Norderney or Helgoland the wind has in fact increased slightly over the past 20-30 years. Yet in northern Germany, just inland from the coast, i.e. just after the first wind rotors, the donnerwetter.de meteorologists found a decline in the average annual wind speed: from 3.8 – 3.9 m/s to less than 3.5 m/s.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Of course, the increase in building construction and especially high-rise buildings in Germany has had a slight braking effect,” admits Brandt. “The braking effect of wind turbines should, however, exceed this.”
Confirmed by other studies

A variety of studies support the meteorologists’ assumption. “Danish research has shown that air flow is weaker than before the turbines even 14 kilometers downstream from a wind farm,” says Dr. Brandt. 
This is an effect that the operators of such parks are concerned about. If a new turbine park is built in front of an existing park in the main wind direction, the losses could be over 50 percent, American studies have shown.
In northern Germany, there is now one wind turbine every 10 square kilometers. According to the donnerwetter.de meteorologists, the North German air flow is generating so much energy that a weaker north wind is now arriving at the north German interior. The situation is similar with westerlies, which are weakened by wind turbines in the Netherlands and Belgium. 
Wind park warming…”more heat inland”!
According to Dr. Brandt: “The weaker wind ensures less air exchange. This in turn drives up pollutant concentration in our air. Especially in the summer months, the lack of wind means more heat inland and less land-sea-wind circulation. In addition, the air is heated by the generators, as further studies have shown.” 
“Think again before further developing wind energy”

So far the wind has been considered as an almost inexhaustible source of energy – albeit being incalculable and poorly predictable. The fact that you can extract some of your energy from the wind turbines was seen as a pioneering achievement. 
“But the fact that man takes so much energy from the wind”, the climatologist concludes, “and considering the consequences, we should probably think again before further developing wind energy.”

Share this...FacebookTwitter "
"
Share this...FacebookTwitter

Within the last few years, over 30 papers have been added to our compilation of scientific papers that find the climate’s sensitivity to CO2 concentration changes is low to negligible.
Link: 85 Scientific Papers – Low CO2 Climate Sensitivity
A few of the papers published in 2018 that were added to the list are provided below.

Fleming, 2018


“The results of this review point to the extreme value of  CO2 to all life forms, but no role of  CO2 in any significant change of the Earth’s climate. … Many believe and/or support the notion that the Earth’s atmosphere is a ‘greenhouse’ with CO2 as the primary “greenhouse” gas warming Earth. That this concept seems acceptable is understandable—the modern heating of the Earth’s atmosphere began at the end of the Little Ice Age in 1850. The industrial revolution took hold about the same time. It would be natural to believe that these two events could be the reason for the rise in temperature. There is now a much clearer picture of an alternative reason for why the Earth’s surface temperature has risen since 1850.”


“There is no correlation of CO2 with temperature in any historical data set that was reviewed. The climate-change cooling over the 1940–1975 time period of the Modern Warming period was shown to be influenced by a combination of solar factors. The cause of the Medieval Warm Period and the Little Ice Age climate changes was the solar magnetic field and cosmic ray connection. When the solar magnetic field is strong, it acts as a barrier to cosmic rays entering the Earth’s atmosphere, clouds decrease and the Earth warms. Conversely when the solar magnetic field is weak, there is no barrier to cosmic rays—they greatly increase large areas of low-level clouds, increasing the Earth’s albedo and the planet cools. The factors that affect these climate changes were reviewed in “Solar magnetic field/cosmic ray factors affecting climate change” section. The calculations of “H2O and CO2 in the radiation package” section revealed that there is no net impact of CO2 on the net heating of the atmosphere. The received heat is simply redistributed within the atmospheric column. This result is consistent and explains the lack of CO2 correlations with observations in the past. The current Modern Warming will continue until the solar magnetic field decreases in strength. If one adds the 350-year cycle from the McCracken result to the center of the Maunder Minimum which was centered in 1680, one would have a Grand Minimum centered in the year 2030.”



Smirnov, 2018  


“From this, it follows for the change of the global temperature as a result at doubling of the concentration of atmospheric CO2 molecules [is] ∆T = (0.4 ± 0.1) K, where the error accounts for the accuracy of used values, whereas the result depends on processes included in the above scheme. Indeed, we assume the atmospheric and Earth’s albedo, as well as another interaction of solar radiation with the atmosphere and Earth, to be unvaried in the course of the change of the concentration of CO2 molecules, and also the content of atmospheric water is conserved. Because anthropogenic fluxes of carbon dioxide in the atmosphere resulted from combustion of fossil fuels is about 5% [Kaufman, 2007], the contribution of the human activity to ECS (the temperature change as a result of doubling of the atmospheric carbon dioxide amount) is ∆T = 0.02 K, i.e. injections of carbon dioxide in the atmosphere as a result of combustion of fossil fuels is not important for the greenhouse effect.”



Davis et al., 2018


“[T]he contemporary global warming increase of ~0.8 °C recorded since 1850 has been attributed widely to anthropogenic emissions of carbon dioxide (CO2) into the atmosphere. Recent research has shown, however, that the concentration of CO2 in the atmosphere has been decoupled from global temperature for the last 425 million years [Davis, 2017] owing to well-established diminishing returns in marginal radiative forcing (ΔRF) as atmospheric CO2 concentration increases. Marginal forcing of temperature from increasing CO2 emissions declined by half from 1850 to 1980, and by nearly two-thirds from 1850 to 1999 [Davis, 2017]. Changes in atmospheric CO2 therefore affect global temperature weakly at most.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Holmes, 2018 


“Calculate for a doubling of CO2 from the pre-industrial level of 0.03% [300 ppm]: [formula found in text] Calculated temperature after doubling of CO2 to 0.06% [600 ppm] ≈ 288.11 K. Climate sensitivity to CO2 is ≈ 288.14 – 288.11 ≈ – 0.03 K.”


“The change would in fact be extremely small and difficult to estimate exactly, but would be of the order -0.03°C. That is, a hundred times smaller than the ‘likely’ climate sensitivity of 3°C cited in the IPCC’s reports, and also probably of the opposite sign [cooling]. Even that small number would likely be a maximum change, since if fossil fuels are burned to create the emitted CO2, then atmospheric O2 will also be consumed, reducing that gas in the atmosphere – and offsetting any temperature change generated by the extra CO2. This climate sensitivity is already so low that it would be impossible to detect or measure in the real atmosphere, even before any allowance is made for the consumption of atmospheric O2.”



Allmendinger, 2018


“Knowledge about thermal radiation of the atmosphere is rich in hypotheses and theories but poor in empiric evidence. Thereby, the Stefan-Boltzmann relation is of central importance in atmosphere physics, and holds the status of a natural law. However, its empirical foundation is little, tracing back to experiments made by Dulong and Petit two hundred years ago. … For studying the pressure dependency, the experiments were carried out at locations with different altitudes. For the so-called atmospheric emission constant A an approximate value of 22 Wm−2 bar−1 K−0.5 was found. In the non-steady-state, the total thermal emission power of the soil is given by the difference between its blackbody radiation and the counter-radiation of the atmosphere. This relation explains to a considerable part the fact that on mountains the atmospheric temperature is lower than on lowlands, in spite of the enhanced sunlight intensity. Thereto, the so-called greenhouse gases such as carbon-dioxide do not have any influence.”


“While a theoretical calculation of such an absorption coefficient was not feasible, at least a principal explanation may be given: There is no good reason to assume that absorbed IR-radiation will be entirely transformed into heat. Instead, it is conceivable that a part of it is re-emitted, i.e. to say in all directions, before having induced a temperature enhancement.”


“This approach contradicts in many ways the conventional greenhouse theory: Firstly, the boundary processes at the Earth surface and at the lowest layer of the atmosphere are predominant, while the conventional greenhouse theory regards the whole atmosphere; and secondly—even more crucial—the radiation budget is solely determined by the air conditions of the atmosphere such as pressure and temperature while so-called ‘greenhouse gases’ such as carbon-dioxide do not have the slightest influence on the climate. Besides, the atmosphere cannot really be compared to a greenhouse, not least due to the absence of a glass-roof which absorbs IR-radiation, and which inhibits considerable air convection.”



Laubereau and Iglev, 2018


“Using a simple 1-dimensional model the global warming of the surface is computed that is generated by the increase of GHG and the albedo change. A modest effect by the GHG of 0.08 K is calculated for the period 1880 to 1955 with a further increase by 0.18 K for 1955 to 2015. A larger contribution of 0.55 ± 0.05 K is estimated for the melting of polar sea ice (MSI) in the latter period, i.e. it notably exceeds that of the GHG and may be compared with the observed global temperature rise of 1.0 ± 0.1 K during the past 60 years.”


“In conclusion we wish to say that we have performed a study of the infrared properties of carbon dioxide, methane, dinitrogen-oxide and water to estimate their contribution to the global warming in 1880 – 2015. Our results suggest that the IR properties of the CO2 are responsible for ~ 20% of the mean temperature increase of the surface [during 1880-2015] and notably less for CH4 and N2O.”



Liu and Chen, 2018


“CO2 and temperature records at Mauna Loa, Hawaii, and other observation stations show that the correlation between CO2 and temperature is not significant. These stations are located away from big cities, and in various latitudes and hemispheres. But the correlation is significant in global mean data. Over the last five decades, CO2 has grown at an accelerating rate with no corresponding rise in temperature in the stations. This discrepancy indicates that CO2 probably is not the driving force of temperature change globally but only locally(mainly in big cities). We suggest that the Earth’s atmospheric concentration of CO2 is too low to drive global temperature change.”


“Our empirical perception of the global warming record is due to the urban heat island effect: temperature rises in areas with rising population density and rising industrial activity. This effect mainly occurs in the areas with high population and intense human activities, and is not representative of global warming. Regions far from cities, such as the Mauna Loa highland, show no evident warming trend. The global monthly mean temperature calculated by record data, widely used by academic researchers, shows R~2=0.765, a high degree of correlation with CO2. However, the R~2 shows much less significance (mean R~2=0.024) if calculated by each record for 188 selected stations over the world. This test suggests that the inflated high correlation between CO2 and temperature (mean R~2=0.765-0.024=0.741) used in reports from the Intergovernmental Panel on Climate Change (IPCC) was very likely produced during data correction and processing. This untrue global monthly mean temperature has created a picture: human emission drives global warming.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitter5300 years ago sea level near Surinam and Guyana was about 1m higher than today
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P. Gosselin)
A paper authored by Khan et al. 2017 looked at the Caribbean over the past 10,000 years.
After the end of the last ice age some 11,000 years ago, sea level rose around Surinam and Guyana at a rate of 11 mm per year. That’s about 5 times faster than today.
During the middle and late Holocene, i.e. over the past 5000 years, sea level rise was only 2.4 mm per year. By the way: 5300 years ago sea level at both countries was about 1 meter higher than today’s level. Surprised? Abstract:
Drivers of Holocene sea-level change in the Caribbean
We present a Holocene relative sea-level (RSL) database for the Caribbean region (5°N to 25°N and 55°W to 90°W) that consists of 499 sea-level index points and 238 limiting dates. The database was compiled from multiple sea-level indicators (mangrove peat, microbial mats, beach rock and acroporid and massive corals). We subdivided the database into 20 regions to investigate the influence of tectonics and glacial isostatic adjustment on RSL. We account for the local-scale processes of sediment compaction and tidal range change using the stratigraphic position (overburden thickness) of index points and paleotidal modeling, respectively. We use a spatio-temporal empirical hierarchical model to estimate RSL position and its rates of change in the Caribbean over 1-ka time slices. Because of meltwater input, the rates of RSL change were highest during the early Holocene, with a maximum of 10.9 ± 0.6 m/ka in Suriname and Guyana and minimum of 7.4 ± 0.7 m/ka in south Florida from 12 to 8 ka. Following complete deglaciation of the Laurentide Ice Sheet (LIS) by ∼7 ka, mid-to late-Holocene rates slowed to < 2.4 ± 0.4 m/ka. The hierarchical model constrains the spatial extent of the mid-Holocene highstand. RSL did not exceed the present height during the Holocene, except on the northern coast of South America, where in Suriname and Guyana, RSL attained a height higher than present by 6.6 ka (82% probability).The highstand reached a maximum elevation of +1.0 ± 1.1 m between 5.3 and 5.2 ka. Regions with a highstand were located furthest away from the former LIS, where the effects from ocean syphoning and hydro-isostasy outweigh the influence of subsidence from forebulge collapse.”
Share this...FacebookTwitter "
"It’s not surprising that the government’s recent white paper was controversial. “Taking back control” of UK regulation was one of the main objectives of the Leave campaign. But the white paper suggests that the UK will maintain the EU’s approach to a huge range of environmental, consumer protection and food safety regulation, by maintaining a “common rule book” with the EU for trade in goods. Or does it? According to the government, this “common rule book” only applies to rules that must be checked at the border. It isn’t obvious which rules apply. Speaking to the Environmental Audit Committee, the environment secretary, Michael Gove, recently concluded that while the UK will share food and animal and plant health regulation, it will go its own way on many issues, including “the way in which our food is grown”.  His comment seems to deny that much of EU agrifood regulation deals precisely with the process by which food is grown. This includes what pesticides can be used, and in what quantities, prohibitions on the use of hormones in farm animals, and so on. The white paper suggests some areas where the UK and EU could recognise that their regulation is “equivalent”, including organic labels. While this may seem like a technical distinction, in fact it is quite a central debate between the EU (which says the UK must follow its approach exactly) and the UK (which has argued that as long as its outcomes are equivalent, it should be able to go its own way).  So what on first glance seems like broad regulatory harmonisation is, upon further inspection, unclear in terms of its scope and coverage. The UK is clearly trying to maintain some wiggle room. In terms of non-goods related environmental legislation, such as rules for air pollution, species protection and habitat preservation, the white paper does not call for a common rulebook. Instead the UK government states that it won’t lower standards, and also commits to uphold international standards and agreements. This may sound inspiring, but in fact such commitments, known as “non-regression” clauses, are included in most EU free trade agreements – and have been widely criticised for doing precisely nothing. The government’s white paper states that its EU trade relationship will most closely approximate an “association agreement”. These vary widely – but by means of contrast, the EU-Ukraine DCFTA agreement, sometimes held up as a potential model for the UK-EU relationship, also contains commitments to harmonise with a broad range of environmental regulation. These don’t just include those that are related to trade in goods, but also air quality, climate change, public participation in environmental decision making, and environmental impact assessment. Of course, it’s fine for the UK to go its own way on environmental legislation, as long as it is able to maintain – or even improve, as Gove has suggested – EU levels of protection. And the UK government, at least initially, will adopt EU environmental laws, in the process of “transposing” them into domestic law. But this process is far from automatic, as the UK must replace the many monitoring and enforcement functions that the EU currently undertakes. There are ongoing consultations about how to replace these functions with a UK “environmental watchdog”. But fines for noncompliance, something that the EU employs, seem to be off the table in the discussion of options for the UK’s environmental watchdog. This raises concerns about whether the UK will have an equivalent ability to uphold environmental rules. Also, EU environmental principles, unlike the legislation, will not be “transposed” through the Withdrawal Bill. Upcoming environmental legislation is meant to address this deficit with a general statement of environmental principles and their interpretation and application. But it’s possible that these commitments may be “lighter” than those provided in the EU – simply requiring that the UK government consider them rather than requiring all legislation to be based on them. The precautionary principle is a good example to consider. It justifies a conservative approach to assessing risk on the basis that there may not yet be enough conclusive scientific evidence to establish environmental harm. The precautionary principle forms the basis of a number of EU bans or restrictions on US products. Donald Trump’s disparaging comments about the prospects for a UK-US trade deal under the white paper model reflect the US administration’s position that the UK should move toward its approach to regulatory approvals in areas such as GMOs, food additives, chemical washes for meats (including the infamous “chlorinated chicken”), which it describes as “science-based”.  Furthering this concern, the white paper confirms that the UK will pursue membership of the CPTPP trade agreement, a signed, but not-yet ratified, trade agreement between Australia, Brunei, Canada, Chile, Japan, Malaysia, Mexico, New Zealand, Peru, Singapore and Vietnam. However, the CPTPP’s “regulatory coherence” chapter arguably goes against the EU’s “precautionary” approach in this area. So what can we expect of the UK’s sustainability in the future? A lot seems to hang on trusting Gove’s assertion that the UK would only ever want to raise its standards. The UK is facing external pressures from the US, India and other countries to relax consumer protection standards. On top of this, there is a strong domestic lobby, led now by David Davis, the former Brexit secretary, arguing that the UK should not dampen its international competitiveness with pesky EU environmental standards.  The recent rebellion on the Customs Bill does not undermine the UK’s commitment to a “common rule book” with the EU. But in light of international pressures, as well as the prospect of weakening UK environmental monitoring and enforcement, Gove’s promises form a pretty shaky foundation for UK environmental standards."
"
Share this...FacebookTwitterUnmasking Marcott’s “Uptick”

20th century “uptick” from Marcott et al., 2013, RealClimate.org  
Almost immediately after it was introduced to the public, the lead author of Marcott et al. (2013) squelched the narrative that said the hockey-stick-shaped reconstruction he and his colleagues produced is a robust representation of modern global-scale temperature changes.
In an interview with Marcott published by RealClimate.org, it was acknowledged that the “uptick” does not represent a global-scale reconstruction, as it is based on only a few proxy records and lacks statistical significance. 

Despite this admitted lack of supporting evidence for the 20th century’s “uptick”, the Marcott et al. (2013) “hockey stick”-shaped graph has nonetheless been unskeptically cited by other authors nearly 700 times. 
Marcott’s compilation of 73 reconstructions
The same “73 globally distributed” proxy temperature records used to manufacture the Marcott et al. (2013) “hockey stick”-shaped graph above were featured two years earlier in Shaun Marcott’s Oregon State University doctoral dissertation.  
Marcott, 2011  “Late Pleistocene and Holocene Glacier and Climate Change”
One may view the graphical representations of all 73 proxy temperature records used for the 2013 “uptick” on pages 200-203 of Marcott’s 2011 paper (above link, about three-fourths of the way down). 
Interestingly, a majority of the graphs do not have temperatures extending to the right Y axis, indicating that most of the 73 proxy records do not encompass the modern era and preclude analysis of the relative temperature differences between the past and present.
In fact, just 32 of the 73 graphs have overall trend lines that extend to “0 yrs BP” in the Marcott dissertation paper.  The rest end somewhere in the Late Holocene (or earlier).  The 32 reconstructions that do extend all the way to the right Y axis are shown below.


Same data, contradictory results 
As even a cursory glance at the 32 reconstructions illustrates, Marcott’s 2011 paper showed no 20th century temperature “uptick” after a modest overall Holocene cooling trend.
A compilation of all 73 Holocene temperature trends for the past 11,300 years is presented in one compressed graph on page 204.  Notice that the large amplitude of variations involving temperature changes of several degrees Celsius shown in the proxy reconstructions has been replaced by much smaller variable ranges (tenths of a degree). 

In contrast, the 2013 paper — utilizing the very same 73 temperature reconstructions — depicts the explosive temperature rise during modern times popularized by climate activists. 

This glaring contradiction between Marcott’s 2011 and 2013 papers was pointed out by Professor Paul Matthews in a comment published by the journal Science.

Image Source: Science
Marcott’s selected reconstructions indicate 2°C warmer temps during the Early- to Mid-Holocene
Interestingly, the temperature reconstructions Marcott used to produce both his 2011 Ph.D thesis and his 2013 Science paper show that (a) Early- to Mid-Holocene temperatures were, on average, more than 2°C warmer than today, and (b) they varied throughout the Holocene by multiple degrees Celsius instead of by just the tenths-of-a-degree shown in both the 2011 and 2013 papers. 
Of the 32 reconstructions extending to the Y axis in Marcott’s papers, 25 clearly define the modern or present temperature relative to the past.  The other 7 did not have modern or present temperature values that were clearly defined in the body of the paper.   In the 25 reconstructions that did allow comparison, the compiled peak Holocene temperatures were determined to be 2.3°C warmer than today on average. 
This result wholly contradicts the claims of Marcott’s 2013 paper.
Examples of the warmer-than-today records
Perhaps Marcott did not look closely enough at the content of each paper he referenced.  Had he done so, he may have noticed that Rodrigues et al., 2009 indicate the “at present” temperature in the Iberian region is 15°C, which is about 1°C colder than it was during the Little Ice Age (16°C) and 4°C colder than the peak Holocene temperature. 

Isono et al. (2009) report that the “present” temperature is 16.7°C, but the peak Holocene temperature was 21.4°C, meaning that North Pacific temperatures were approaching 5°C warmer about 7,000 or 8,000 years ago.

Even a graph that initially appears to support a sharp rise in temperature during modern times (an “uptick”) like Nielsen et al. (2010) actually asserts the Holocene peak was  4°C warmer than the modern average in the body of the paper itself.

As mentioned, some graphs are identified as not clearly defining the modern temperature values.  However, as Bendle and Rosell-Mele, 2007 point out, the amplitude of past temperature changes could reach as high as 10°C within a matter of centuries.  This would appear to contradict the contention that Holocene temperature variability was much less pronounced (a few tenths of a degree spanning millennia).

Of note, none of the reconstructions analyzed support the contention that modern temperatures are unusually high or unprecedented.  
If the paleoclimate evidence doesn’t support a recent pronounced “uptick”, where does it come from?
To summarize, the proxy evidence from the peer-reviewed scientific papers that Marcott derived his global temperature data set compilation wholly contradicts Marcott’s apparent attempt to construct a Mann-like Holocene-length “hockey stick” temperature record.  
Marcott himself has acknowledged that the 20th century “uptick” is based on only “a few” reconstructions that are neither globally representative or statistically robust.  This begs the questions:
1. What data set is used to justify the depiction of a pronounced temperature “uptick”? 
2. Has the “uptick” been fabricated?
3. On what basis did the journal Science publish the 2013 version of a paper that is contradicted by an earlier work by the same author? 
The list of Marcott’s graphs
Below is the table of contents for the 32 referenced reconstructions extending to the right Y axis.  The warmer-than-now temperature value is emboldened on the right.  This list is followed by the pictorial representations of the Marcott-selected reconstructions and excerpts from the papers.  
Sachs, 2007 – Northwest Atlantic SSTs: +4.5°C, +9.5°C, +7.0°C = +7.0°C Rodrigues et al., 2009 – Iberian Shelf: +4.0°CBarrows et al., 2009 – New Zealand: +2.1°CBendle and Rosell-Mele, 2007 – North Icelandic Shelf: not clearly definedBarron et al., 2003 – Northern California: +1.3°C   Isono et al., 2009 – North Pacific: +4.7°CLarocque and Hall, 2004 – Northern Sweden: +2.1°C, +3.0°CEmeis et al., 2003 – NW Europe: +4.0°CKim et al., 2002 – Eastern Atlantic: +2.6°CKurek et al., 2009 – Yukon Territory: +2.0°CPelejero et al., 1999 – South China Sea: +0.25°CMcGlone et al., 2010 – Southern Ocean: +2.0°C, not clearly definedThornalley et al., 2009 – Subpolar North Atlantic: not clearly definedDeMenocal et al., 2000 – NW Africa: MWP “marginally warmer than present”Linsley et al., 2010 – Western Pacific: +0.5°C, +0.5°C Stott et al., 2004 – Western Tropical Pacific: +0.5°C, +0.5°CClegg et al., 2010 – Alaska: +1.0°CNielsen et al., 2010 – South Atlantic/Southern Ocean: +4.0°CFarmer et al., 2005 – South Africa: +1.5°CWeijers et al., 2007 – Tropical Africa: +1.3°CCastañeda et al., 2010 – Eastern Mediterranean: +1.5°CWeldeab et al., 2006 – Western Tropical Atlantic: +1.2°CBenway et al., 2006 – Eastern Pacific Warm Pool: not clearly definedHuguet et al., 2006 – Arabian Sea: +5.3°C , not clearly definedSchefuß et al., 2005 – Central Africa: not clearly definedSeppä and Birks, 2001 – Fennoscandia: +1.7°CSeppä et al., 2005 – Sweden: +2.5°C 

Holocene peak (+4.5°C, +9.5°C, +7°C) +7.0°C warmer than present
Sachs, 2007   Sachs, J. P. (2007). Cooling of Northwest Atlantic slope waters during the Holocene. Geophysical Research Letters 34, L03609, doi:10.1029/2006GL028495.


Holocene peak +4.0°C warmer than present 
Rodrigues et al., 2009   Rodrigues, T., Grimalt, J. O., Abrantes, F. G., Flores, J. A., and Lebreiro, S. M. (2009). Holocene interdependences of changes in sea surface temperature, productivity, and fluvial inputs in the Iberian continental shelf (Tagus mud patch). Geochemistry, Geophysics, and Geosystems 10, Q07U06, doi:10.1029/2008GC002367.


Holocene peak +2.1°C warmer than present
Barrows et al., 2007   Barrows, T. T., Lehman, S. J., Fifield, L. K., and De Deckker, P. (2007). Absence of Cooling in New Zealand and the Adjacent Ocean During the Younger Dryas Chronozone. Science 318, 86-89.



Holocene peak vs. present not clearly defined, warm/cool amplitudes of 10°C
Bendle and Rosell-Mele, 2007   Bendle, J. A. P., and Rosell-Mele, A. (2007). High-resolution alkenone sea surface temperature variability on the North Icelandic Shelf: implications for Nordic Seas palaeoclimatic development during the Holocene. The Holocene 17, 9-24.


Holocene peak +1.3°C warmer than present
Barron et al., 2003   Barron,  J. A., Heusser, L., Herbert, T., and Lyle, M. (2003). High resolution climatic evolution of coastal northern California during the past 16,000 years. Paleoceanography 18, 20-1 to 20-14



Holocene peak +4.7°C warmer than present
Isono et al., 2009   Isono, G., Yamamoto, M., Irino, T., Oba, T., Murayama, M., Nakamura, T., and Kawahata, H. (2010). The 1500-year climate oscillation in the midlatitude North Pacific during the Holocene. Geology 37, 591-594


Holocene peak +2.1°C and +3.0°C warmer than present
Larocque and Hall, 2004   Larocque, I., and Hall, R. I. (2004). Holocene temperature estimates and chironomid community composition in the Abisko Valley, northern Sweden. Quaternary Science Review 23, 2453-2465.


Holocene peak +4.0°C warmer than present


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Emeis et al., 2003   Emeis, K. C., Struck, U., Blanz, T., Kohly, A., and Woß, M. (2003). Salinity changes in the central Baltic Sea (NW Europe) over the last 10 000 years. The Holocene 13, 411-421.


Holocene peak +2.6°C warmer than present
Kim et al., 2002   Kim, J.-H., Schneider, R. R., Muller, P. J., and Wefer, G. (2002). Interhemispheric comparison of deglacial sea-surface temperature patterns in Atlantic eastern boundary currents. Earth and Planetary Science Letters 194, 383-393.


Holocene peak +2.0°C warmer than present
Kurek et al., 2009   Kurek, J., Cwynar, L., and Vermaire, J. C. (2009). A late Quaternary paleotemperature record from Hanging Lake, northern Yukon Territory, eastern Beringia. Quaternary Research 72, 246-257.


Holocene peak +0.25°C warmer than present
Pelejero et al., 1999   Pelejero, C., Grimalt, J., Heilig, S., Kienast, M., and Wang, L. (1999). High resolution UK37 temperature reconstructions in the South China Sea over the past 220 kyr. Paleoceanography 14, 224-231.


Holocene peak +2.0°C warmer than present (bottom), not clearly defined (top)
McGlone et al., 2010   McGlone, M. S., Turney, C. S. M., Wilmshurst, J. M., Renwick, J., and Pahnke, K. (2010). Divergent trends in land and ocean temperature in the Southern Ocean over the past 18,000 years. Nature Geoscience 3, 622-626.


Holocene peak not clearly defined
Thornalley et al., 2009   Thornalley, D. J. R., Elderfield, H., and McCave, I. N. (2009). Holocene oscillations in temperature and salinity of the surface subpolar North Atlantic. Nature 457.


Holocene peak not clearly defined, MWP “marginally warmer than present”
deMenocal et al., 2000   deMenocal, P., Ortiz, J., Guilderson, T., and Sarnthein, M. (2000). Coherent Highand Low-Latitude climate variability during the Holocene warm period. Science 288, 2198-2202. [Northwest Africa]


Holocene peak +0.5°C warmer than present (2 reconstructions)
Linsley et al., 2010   Linsley, B. K., Rosenthal, Y., and Oppo, D. W. (2010). Holocene evolution of the Indonesian throughflow and the western Pacific warm pool. Nature Geoscience 3, 578-583.                                        


Holocene peak +0.5°C warmer than present (2 reconstructions)
Stott et al., 2004   Stott, L., Cannariato, K., Thunell, R., Haug, G.H., Koutavas, A. and Lund, S. (2004)  Decline of surface temperature and salinity in the western tropical Pacific Ocean in the Holocene epoch.  Nature 431.


Holocene peak +1.0°C warmer than present
Clegg et al., 2010   Clegg, B. F., Clarke, G. H., Chipman, M. L., Chou, M., I.R., W., Tinner, W., and Hu, F. S. (2010). Six millennia of summer temperature variation based on midge analysis of lake sediments from Alaska. Quaternary Science Review, doi:10.1016/j.quascirev.2010.08.001.


Holocene peak +4.0°C warmer than present
Nielsen et al., 2010   Nielsen, S. H. H., Koç, N., and Crosta, X. (2010). Holocene climate in the Atlantic sector of the Southern Ocean: Controlled by insolation or oceanic circulation? Geology 32, 317-320.


Holocene peak +1.5°C warmer than present
Farmer et al., 2005   Farmer, E. C., deMendocal, P. B., and Marchitto, T. M. (2005). Holocene and deglacial ocean temperature variability in the Benguela upwelling region: Implications for low-latitude atmospheric circulation. Paleoceanography 20, doi:10.1029/2004PA001049.


Holocene peak +1.3°C warmer than present
Weijers et al., 2007   Weijers, J. W. H., Schefuß, E., Schouten, S., and Damste, J. S. D. (2007). Coupled Thermal and Hydrological Evolution of Tropical Africa over the Last Deglaciation. Science 315, 1701-1704.


Holocene peak +1.5°C warmer than present
Castañeda et al., 2010   Castañeda, I. S., Schefuß, E., Pätzold, J., Damste, J. S. D., Weldeab, S., and Schouten, S. (2010). Millennial‐scale sea surface temperature changes in the eastern Mediterranean (Nile River Delta region) over the last 27,000 years. Paleoceanography 25, PA1208, doi:10.1029/2009PA001740.


Holocene peak +1.2°C warmer than present
Weldeab et al., 2006   Weldeab, S., Schneider, R. R., and Kölling, M. (2006). Deglacial sea surface temperature and salinity increase in the western tropical Atlantic in synchrony with high latitude climate instabilities. Earth and Planetary Science Letters 241, 699-706.


Holocene peak not clearly defined
Benway et al., 2006   Benway, H. M., Mix, A. C., Haley, B. A., and Klinkhammer, G. P. (2006). Eastern Pacific Warm Pool paleosalinity and climate variability: 0 – 30 kyr. Paleoceanography 21, PA3008, doi:10.1029/2005PA001208


Holocene peak +5.3°C warmer than present (top), not clearly defined (bottom)
Huguet et al., 2006   Huguet, C., Kim, J.-H., Damsté, J. S. S., and Schouten, S. (2006). Reconstruction of sea surface temperature variations in the Arabian Sea over the last 23 kyr using organic proxies (TEX86 and UK37). Paleoceanography 21, doi:10.1029/2005PA001215.


Holocene peak not clearly defined
Schefuß et al., 2005    Schefuß, E., Schouten, S., and Schneider, R. R. (2005). Climatic controls on central African hydrology during the past 20,000 years. Nature 437, 1003-1006.


Holocene peak +1.7°C warmer than present
Seppä and Birks, 2001   Seppä, H., and Birks, H. J. B. (2001). July mean temperature and annual precipitation trends during the Holocene in the Fennoscandian tree-line area: pollen-based climate reconstructions. The Holocene 11, 527-539.


Holocene peak +2.5ºC warmer than present
Seppä et al. 2005      Seppä, H., Hammarlund, D., and Antonsson, K. (2005). Low-frequency and high-frequency changes in temperature and effective humidity during the Holocene in south-central Sweden: implications for atmospheric and oceanic forcings of climate. Climate Dynamics 25, 285-297.

Share this...FacebookTwitter "
"Sign up for updates on America’s public lands. Under this administration, nothing is sacred as we watch the nation’s crown jewels being recut for the rings of robber barons. For more than 100 years, professional management of our national parks has been respected under both Democratic and Republican administrations. Yes, they have different priorities, the Democrats often expanding the system and the Republicans historically focused on building facilities in the parks for expanding visitation. But the career public servants of the National Park Service (NPS), charged with stewarding America’s most important places, such as the Grand Canyon, Yellowstone and the Statue of Liberty, were left to do their jobs. Even in the dark days of interior secretaries James Watt and Gail Norton, both former attorneys with the anti-environmental Mountain States Legal Foundation, the National Park Service (NPS) was generally left untouched, perhaps because they recognized that some institutions have too much public support or their mission too patriotic to be tossed under the proverbial bus. This time is different and we should know, as Jon, one of this story’s authors, worked for the last 10 interior secretaries as a career NPS manager, and ultimately led the agency under Barack Obama, and Destry, Jon’s brother and co-author, has worked with the past 12 NPS directors as a conservation advocate. The change began within 24 hours of the inauguration when Donald Trump complained that the NPS was reporting smaller crowds on the National Mall than Obama had drawn. Perhaps this is when the NPS wound up on the list of transgressors. Soon the interior secretary, Ryan Zinke, attempted to double the entrance fees, rescinded climate policies and moved seasoned senior national park superintendents around to force their retirements. After Zinke’s abrupt resignation, secretary David Bernhardt populated too much of the department’s political leadership with unconfirmed, anti-public land sycophants, and announced a reorganization to install his own lieutenants to oversee super regions, realigning NPS from seven regions to twelve in the name of greater efficiency. Next came the proclamation that career staff in Washington would be sent to the field to be closer to the people they serve, but in reality, to be out of the way and no longer an impediment to his agenda. Then came the decisions to leave the parks open to impacts during the unfortunate government shutdown, illegally misuse entrance fees, open park trails to e-bikes, suppress climate science, kill wolf pups and bear cubs in their dens to enhance “sport hunting”, privatize campgrounds, and issue muzzle memos to park managers. With a waiver of environmental laws, bulldozers are plowing ancient cacti in national parks along the southern border in order to build a wall. Senior career park managers are likely to be replaced with unqualified political hacks. These are not random actions. This is a systematic dismantling of a beloved institution, like pulling blocks from a Jenga tower, until it collapses. You ask, why on earth would someone want to do that to the popular National Park Service, the subject of one of Ken Burns’ acclaimed documentaries and often called “America’s best idea”? Because if you want to drill, mine and exploit the public estate for the benefit of the industry, the last thing you want is a popular and respected agency’s voice raising alarms on behalf of conservation and historic preservation. Because if you want the public to ignore the science of climate change, the last thing you want are trusted park rangers speaking the truth to park visitors. Because if you want to get the federal government small enough (in the words of Grover Norquist) to “drown it in a bathtub”, the last thing you want is a government agency with high popular appeal that needs to grow rather than shrink. It is clear that this administration cannot be trusted with the keys to the vault of our most precious places that define us as a nation, such as Mount Rushmore or Yosemite national park. When this nightmare ends, and we begin to rebuild, we suggest it is time for Congress to consider making the National Park Service an independent institution, more akin to the Smithsonian, and no longer subject to the vicissitudes of a hostile political agenda in a Department of the Interior dominated by extractive industries and anti-public land crusaders. Brothers Jonathan and Destry Jarvis have spent a combined 87 years in the conservation of parks and public lands. Jonathan was the 18th director of the NPS and served in the agency for 40 years. Destry has spent 47 years as an advocate for national parks working for several non-governmental organizations and in the private sector. The opinions expressed here are those of the authors. For more information about how this project is supported, click here."
"
Share this...FacebookTwitterTop Swiss meteorologist Jörg Kachelmann blasts the quality of modern weather information in Germany, warning that 80-90% of weather stories found in the online media are “false information” or even “made-up nonsense”, and feels his field has become “a hoard of anarchy.”

Swiss meteorologist Jörg Kachelmann. Photo source: https://weather.us/
Yesterday here I reported how veteran Swiss meteorologist Jörg Kachelmann, 59, called the blaming of single weather events on climate change “complete idiocy”.
The quality of weather reporting and information, and the overall knowledge of natural sciences, have gotten so bad in Germany, according to Kachelmann, that he felt compelled to comment at the online Hannoversche Allgemeine Zeitung (HAZ). He wrote (link added by author):
 In matters concerning natural sciences, a collective educational precariat rules.”
Meaning: when it comes to knowledge of natural sciences, and especially meteorology, Germany is in trouble, and the citizens are being terribly disinformed.
Excessive, click-baiting media hype
One of the major reasons behind the destructive development, according to Kachelmann, is all the “nonsense” that gets reported by the media concerning the weather.
One example is the often-made claim today that severe thunderstorms or heavy downpours are linked to “climate change”. What in the past used to be just called a storm or bad weather, now gets recorded by countless mobile devices and sent to some studio, where it is hyped and sold as a 100-year event of Biblical proportions.
“Anarchy” ruling day-to-day weather reports
Kachelmann comments how today one often finds weather tips in the German media, e.g. for golfers and mountaineers, but which are in fact “complete idiocy”. Much of the nonsense, the Swiss meteorologist believes, is driven by the media’s insatiable appetite for clicks. “There’s anarchy in the weather report,” Kachelmann writes.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Today every north wind in the wintertime gets dubbed the “Siberian whip!” or every warm summer breeze from the south now gets labelled as a “Saharan heat wave!”, he describes.
Meteorology has become a hoard of anarchy
Kachelmann’s observations are spot on. But we could add that the rush to crank out sensational headlines is not limited to tabloids, but also flagship media outlets and once renowned weather and climatological institutes, who are now getting into the click-baiting, attention-seeking extreme weather frenzy.
For example “renowned” institutes are increasingly linking foul weather to climate change, and warn things are only going to get worse! “We’re toast!” the AP once warned, citing serious scientists.
“80 to 90% false information” …”or made up”
In Kachelmann’s view the field of meteorology has deteriorated so much that he comments at HAZ:
It’s truly a drama: Today 80 to 90 percent of the weather stories in the German online media are false information or often freely made-up nonsense. My science has become a hoard of anarchy.”
He adds:
The absence of knowledge about nature allows every nonsense to be printed — in order to generate clicks — yet not be recognized as such.”
So why has the German citizenry become so weather-disinformed?
Kachmann points to the educational system, where children are allowed to bypass natural science classes at schools. He comments at HAZ:
It is breathtaking what only a few decades and the allowance to skip school subjects can do to a country that, at least in folksongs, was long familiar with storms.”
============================================
Jörg Kachelmann runs Kachelmannwetter.com and, in cooperation with Dr. Ryan Maue, weather.us. He was formerly the meteorologist for flagship ARD German television.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThere’s capital to be derived from climate change, and now spiritual leaders and organized religion are getting in the act. And they offer a real Hell you can believe in – even certified by science!
Religion comes up with an all new, improved Hell
As enlightenment over the past decades and centuries have led the masses to doubt the once colorful concept of Hell — that fire-filled place reserved for the incorrigibly unvirtuous and run by reptilian demons — spiritual leaders have seen their clout in modern society erode. No longer is it so easy for them to control people’s behavior with feelings of guilt and threats of eternal damnation.
Recently, however, spiritual leaders have uncovered a new instrument to gain back some control over the masses: climate change – the new, and this time real Hell – yes, that’s been confirmed by 97% of the climate prophets – so disbelieve at your own risk!
Holy Words
This was demonstrated not long ago by Pope Francis’s Laudato si, His second encyclical. According to Wikipedia: “In it, the Pope critiques consumerism and irresponsible development, laments environmental degradation and global warming, and calls all people of the world to take ‘swift and unified global action’.”
The new Hell certified by “leading scientists”!
In a nutshell, do as they say or perish in climate hell. Laudato si was authored in large part by the Pope of Climate Doom himself, Prof. Hans-Joachim Schellnhuber of the ultra-alarmist Potsdam Institute for Climate Impact Research (PIK).
And just earlier this week, according to the online thecourier.com here  now the orthodox Christians are getting in on the act too. Once again Orthodox leaders too can let themselves stand morally above all others and preach to us on our sinful ways. And should we, the masses, not heed their Holy Science-Certified Words, then the new Hell (climate change) will ferociously engulf us as never seen before.
Hat-tip: a reader


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Frustrated scientists: message “not reaching people”
According to The Courier, leading climate change experts and campaigners gathered in Greece so that they could “work with the leaders of the Orthodox Church and other religions to fight global warming”.
Apparently activists and scientists are frustrated that their message is not reaching people fast enough. The two-day conference was inaugurated by “Green Patriarch” Bartholomew.
If science fails – then move on to faith!
Of course in attendance was the former PIK director and now accepted prophet Hans-Joachim (John) Schellnhuber. He told those in attendance:
Faith can help us because we scientists have tried everything. We can’t say what’s happening in a more compelling way when we warn about the end of civilization.”
According to the Courier, “hundreds of islanders” greeted Bartholomew “upon his arrival by boat”. The conference also included “long-breaded Orthodox priests” who got around in “golf carts and horse-drawn carriages”.
Climate visionaries and dignitaries
Also in attendance was a climate adviser to the Pope: Bill McKibben of 350.org; Jane Lubchenco, former NOAA head under Obama; Patricia Espinosa, UNFCC replacement for Christiana Figueres; Christiana Figueres herself, now Mission 2020; WAPO journalist Juliet Eilperin; and Jeffrey Sachs, economist, Columbia Earth Institute and climate adviser to the Pope.
No word if they came in on row boats, or horse-drawn carriages.
Share this...FacebookTwitter "
"While the G7 leaders have been pledging to stop using fossil fuels by 2100, we’re still waiting to hear the details of the Conservative government’s plans for renewable energy. The party’s manifesto commitment to “end any new public subsidy” for onshore wind farms does not bode well, however.  And virtually the first smoke signal issued by Amber Rudd, the new UK energy secretary, was that there could be an early end to the onshore wind subsidies paid to wind farms that have been built in previous years. This pleased many Conservative MPs and Scottish Conservatives, who were even more viscerally opposed to onshore windfarms in their election manifesto than their counterparts in other parts of the UK.  Industry, especially the electricity industry, does not want subsidies scrapped for existing or future onshore wind farms. Neither do NGOs involved in tackling climate change. Onshore wind is clearly the cheapest low-carbon form of electricity generation. With existing wind-farm owners threatening to sue and Scottish energy minister Fergus Ewing insisting that the Scottish government be consulted as a big contributor to UK wind overall, the latest reports are that the UK government has postponed an imminent announcement to consult first.  Conservative policy certainly puts the Scottish government in a bind. On one hand it needs to pursue its green-energy targets both to protect its left flank and to appease large sections of the Scottish energy industry. On the other hand the problem exposes the Scottish government’s reliance on English money to fund renewables in Scotland.  Yet at the same time, Scottish policy is central to UK-wide EU targets for 15% of energy to be renewable by 2020 (requiring about 30% renewable electricity). Almost two-thirds of the consented (but not yet commissioned) UK windfarm capacity is sited north of the border. The Scottish government’s own target is to source the equivalent of 100% of its electricity from renewable sources by 2020. By 2014 almost 50% of Scottish electricity generation came from renewables, predominantly wind and hydroelectricity (compared to 19% for the UK).  There is now sufficient capacity either installed, under construction, or given firm premium-price contracts to reach about two-thirds of the Scottish 2020 target. But even if all of the consented Scottish onshore wind farms that are still looking for funding are also implemented, the target would still only be 90% met – meaning that the two consented offshore wind projects in the Moray Firth need to go ahead too.  Yet during and since the independence debate, the Scottish government has carefully avoided the proposition that it should be given a portion of the UK renewable funding pot to spend on low-carbon energy. The pot was capped last autumn at £200m a year, and is funded by income from the electricity bills of UK consumers.  Behind this Scottish-government reticence lurks a fear that in future, Scotland would have to fund its renewable subsidies from the pockets of Scottish electricity consumers. Given that fewer than 10% of UK consumers are in Scotland, and that more than 25% of UK renewable energy incentives have been spent on Scottish renewables, such a change could end up severely limiting future Scottish renewables deployment. 
This helps to explain why the Scottish government has merely demanded that it be made a statutory consultee when changes to renewable policies are being made at Westminster.  Cynics might argue that Amber Rudd’s kite-flying about seeking an early end to subsidies for onshore wind under the old renewables-obligation scheme (which ends in 2017) is to show her wind-turbine-hating Tory colleagues that, in practice, being anti-onshore-wind is not so popular. She can then disavow the kite and, ultimately, be congratulated for her munificence by announcing the continuation of a policy of funding onshore wind until 2020.  She would say that the manifesto policy of ending subsidies was only for wind farms that had not yet been given planning consent, and could roll out extra funding for new projects under the new contracts-for-difference scheme to be implemented by early 2021.  But this loses sight of the bigger challenges. These revolve around greenhouse gas reduction, where the Scottish government is already being berated for not keeping up with its targets. We need to make substantial progress towards decarbonising heat and transport, which means supplying a lot more of it through electricity. This requires green power well beyond the current 100% target.  That is because we need to encourage electric cars and also supply low-carbon heat through heat pumps and district heating, not to mention having more green power to export south of the border. It would take longer and be more expensive to do this solely through offshore wind farms. Really Scotland needs to continue to embrace onshore wind and (also in the future) ground-mounted solar photovoltaics if its targets are to be achieved speedily and economically. In order to finesse away Tory opposition to future onshore wind farms in the UK, some authority over renewables financing could to be given back to the Scottish government – it has such power under the old renewables-obligation scheme, but not under contracts for difference. A compromise could emerge whereby the Scottish government took decisions over how to spend a part of the low-carbon incentives, and developers of renewables projects in Scotland could have a choice whether to fund projects out of that pot of money or the (bigger) Westminster fund.  Of course Scottish Renewables, the industry association, would be worried about how such legislation is drafted, fearing that here may be a drift towards stopping Scottish schemes being funded at all by Westminster. But provided it is drafted correctly, the Scottish government’s new statutory rights of consultation would most likely be a barrier to any slippage. This would mean that the UK’s policy of reducing carbon emissions could be defended at least in Scotland, if not in England and Wales."
"Fifty years ago, I concluded that the best thing for the planet would be a peaceful phase-out of human existence. We’re causing the extinction of hundreds of thousands of other species. With us gone, I believe ecosystems will be restored and there will be enough of everything. No more fighting over resources. The idea wasn’t as well received as I had hoped. My journey to advocating for voluntary human extinction began at school. I was born in the post-war baby boom in a small desert town in Oregon, in the US. There were more new students than the elementary school could cope with, so classes overflowed into churches. In my fourth year, we were taught in the county library; people checked out books as we learned. High school was the same: the cafeteria had to be converted into classrooms. There just weren’t enough resources – a situation that remains the same as we boomers enter our final decades.  After an involuntary stint in the army, I read Paul Ehrlich’s book Population Bomb, which argued that overpopulation would lead to food shortages and famine, and soon joined a movement called Zero Population Growth. Their slogan was Stop at Two, but it didn’t take much maths to work out that this would take too long. We were already overpopulated at 3.7 billion: instead of stopping at two children, we needed to stop at once.  At 25, I wanted to show I was serious. A medical school gave me a discounted vasectomy in exchange for being a student doctor’s first try at the procedure, which was successful. I became a supply teacher, which gave me plenty of free time to study population issues. In the summers, I hitchhiked around the US, as many thousands did in the 1970s. Everywhere, people told me that their locale used to be so nice before all these people moved in, and it became too crowded. In the late 1980s, I settled in Portland, Oregon, and began to call this concept the Voluntary Human Extinction Movement. Our message is simple: we encourage people to stop procreating so the biosphere might return to its former glory, and everyone already here will be able to live life more abundantly. In 1996, when we got a website, things took off. People from all over the world emailed me, saying they had thought they were alone. I got hate mail, too. “You first,” is a common taunt. OK, I got snipped; you next. My favourite encounters are with people who thoroughly question the concept: I’ll take thoughtful disagreement over mindless agreement any day. I don’t know how many share my beliefs, but I speak to hundreds of advocates each year. We have active volunteers across the world, from India to Mexico. In my own relationships, I’ve always explained that pregnancy is impossible. Marriage never made sense to me anyway: I would have missed getting to know many wonderful women had I stuck with one. Today, Extinction Rebellion and the climate strike movement haven’t quite embraced the population’s contribution to the crisis. Other high-profile population awareness organisations are working hard to be acceptable, so suggest zero or one offspring, and still say stop at two. Two is too many: computer models suggest even one-child families would result in 5-10 billion people by 2100. Although the basic concept of the movement is the same, my motivations have evolved. I was a deep ecologist at first, caring more about our impact on the ecosphere than human needs. I’ve become more concerned about any new humans being brought into existence. Procreation today is the moral equivalent of selling berths on a sinking ship. It’s true that society would be greatly diminished without children, but it isn’t right to create them just because we like having them around. People worry that we won’t have enough workers to support pensioners, but economic systems are artificial and can be adjusted. We don’t need to breed more wage slaves to prop up an obsolete system. If we go extinct, other species will have a chance to recover. I’ll never see the day when there are no humans on the planet, but I can imagine what a magnificent world it would be – provided we go soon enough. ● As told to Freya Pratty If you would like your comment on this piece to be considered for Weekend magazine’s letters page, please email weekend@theguardian.com, including your name and address (not for publication). Do you have an experience to share? Email experience@theguardian.com"
"
Share this...FacebookTwitterGerman ZDF public television recently broadcast a report showing how electric cars are a far cry from being what they are all cracked up to be by green activists.

Northern Chilean desert being ruined by widespread lithium mining. Image cropped from ZDF documentary: Die Schattenseiten der E-Mobilität
The report titled: “Batteries in twilight – The dark side of e-mobility” shows how the mining of raw materials needed for producing the massive automobile batteries is highly destructive to the environment. For example, two thirds of the cobalt currently comes from the Congo, where the mining rights have been acquired by China. Other materials needed include manganese, lithium and graphite.
Every electric car battery needs about 20 – 30 kg of lithium.
The mining of the raw materials often takes place in third world countries where workers are forced to work under horrendous conditions and no regard is given to protecting the environment. When it comes to “going green”, it seems everything flies out the window.
Immense water consumption
The report shows that one source of the lithium is the desert of northern Chile. Everyday at the mine shown some 21 million liters of ground water get pumped to the surface, where it evaporates and a sludge with 6% lithium content gets shipped to processing plants. The operations are transforming the Chilean desert landscape into a vast industrial wasteland.
Precious vegetation shriveling up
The Chilean lithium mining operations are pumping out what little precious groundwater that remains and ruining the living basis of the local population. What little vegetation there was to begin with is now dying due to falling water tables. Overall, mining operations are expected to expand four-fold within the next decade and the mining companies profit while the local citizens lose their livelihoods.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Car companies turning a blind eye
The automotive companies, the buyers of the lithium batteries insist that they have strict requirements in the sourcing of their products and make sure it is done in a sustainable way. Obviously they are having little effect.
Congolese slave labor for China
Today’s batteries for e-cars also require approx. 10 – 15 kg of cobalt, where two thirds of which comes from authoritarian Republic of the Congo. The mining rights are owned by Chinese companies. Here as well the benefits of the mining operations do not find their way to the local residents, who are forced live under horrendous conditions.
Privately operated local companies are not allowed, unless the authorities are paid bribes to look the other way. In these rogue operations, work conditions are primitive and extremely dangerous. The ZDF reports that some 20% of Congolese cobalt is extracted in this manner. Profits do not find their way down to the miners.
Child labor
Meanwhile the ground around the mining villages are now perforated with vertical shafts that pose a constant danger to children who risk falling into them. Work conditions for the miners themselves is extremely dangerous. The money they earn is not enough to provide for their families. Children are forced to work and do not go to school.
Chinese companies control most of the lithium supply chain, ZDF reports, and miners are cheated by them. The valuable raw material makes its way to China, where it gets processed for the manufacture electric batteries, according to Dr. Mathias John of Amnesty International. Congolese cobalt likely is contained in the car batteries of German electric cars.
German automakers such as Mercedes insist that they make effort to ensure that their supply chains “exclusively process cobalt from industrial mines that have the proper sustainability standards.”
As electric cars begin to flood global markets, the environmental and social destruction of third world countries where the precious minerals are mined will reach ghastly proportions. The promised green utopia will remain a an illusion.
Share this...FacebookTwitter "
"The cold, remote Arctic Ocean and its surrounding marginal seas have experienced climate change at a rate not seen at lower latitudes. Warming air, land and sea temperatures, and large declines in seasonal Arctic sea ice cover are all symptoms of the changing Arctic climate. Although these changes are occurring in relatively remote locations, there is growing evidence to link Arctic sea ice retreat to increasingly erratic weather patterns over the northern hemisphere. As sea ice declines, areas of open water increase, allowing the ocean to lose more heat to the atmosphere. Heat lost from the ocean to the atmosphere reduces the atmospheric pressure which provides more energy to storms and increases their cloud content through evaporation.  Water flowing north from the Atlantic Ocean provides a major source of heat to the Arctic Ocean and surrounding continental shelf seas. While the Atlantic Water (the particular water mass in the Arctic ocean) carries enough heat to melt all the floating Arctic sea ice in less than five years, it is currently insulated from the surface by a lighter, fresher layer of water over most of the central Arctic Ocean.  However, this paradigm appears to be changing. North of Svalbard, Atlantic Water heat has been mixed up towards the surface, resulting in increased surface heat lost to the atmosphere over the ever greater area of open ocean. This change has recently been shown to enhance the rate of sea ice loss eastwards.  A key Arctic region for Atlantic Water heat exchange with the atmosphere is the Barents Sea. Atlantic Water flowing east through the Barents Sea Opening – between Bear Island, and northern Norway – remains exposed to the atmosphere as it circulates through the central Barents Sea. It gradually cools and becomes fresher (due to sea ice melting) as it moves eastwards to the Kara Sea.  In the Barents Sea, sea ice forms every autumn and melts in late spring/summer. In the northern part of the sea, a north-south change from cold to warm sea surface temperatures signals the presence of the Polar Front, which separates cold Arctic water from the warm Atlantic water. The meeting of the two water masses, its location and the temperature difference across it reflects changes in Barents Sea circulation. During years with low seasonal sea ice concentrations (when there’s more heat loss from more exposed open water), the north-south differences in atmospheric temperatures across the Barents Sea are reduced. These conditions have been linked to wintertime cyclones travelling further south into western Europe, instead of their tendency to move eastwards towards Siberia, as well as more frequent cold winter extremes at middle latitudes. For our recent study, we looked at satellite measurements of sea ice and sea surface temperature, to determine how ocean and ice conditions have evolved between 1985 and the end of 2016. We found that prior to 2005, sea ice extended south of the Polar Front every winter, but that since 2005 this has not been the case.  At the same time, the sea surface temperature difference across the Polar Front has increased, with southern temperatures increasing at a faster rate than those to the north. The average between 1985 and 2004 was -1.2°C in the north and 1.5°C in the south, while between 2005 and 2016 it was -0.6°C in the north and 2.6°C in the south. Clearly, from 2005 the Barents Sea has become too warm for sea ice to exist south of the Polar Front. The question then is why is the Barents Sea getting warmer? Long-term oceanographic measurements of water temperature and salinity near the Barents Sea Opening have shown that inflowing Atlantic Water temperatures have increased over the last 30 years, with what appears to be a small but persistent rise around 2005 – likely to be due to upstream changes in the North Atlantic sources (though it must be noted that our study did not explore this question). An impact of the warmer water entering the Barents Sea is a warmer atmosphere, which in turn insulates the warmer surface water allowing the Atlantic Water heat to penetrate further to the north, preventing winter sea ice formation and import (that is sea ice that has formed farther north that has drifted southwards) to the region south of the Polar Front.     We believe that this represents a long-term shift in the climate of the Barents Sea, a region already identified as influential on lower-latitude European weather. Furthermore, we believe that the 2005 regime shift we observed over the Barents Sea may have contributed to the increasingly frequent extreme weather events experienced over Europe in the past decade or so."
nan
"
Share this...FacebookTwitterCNN and the Guardian just reported on a new study suggesting meat is bad for human health (even though humans and their ancestors have been eating and thriving on it for some 3 million years).
The authors also suggest that the healthy alternative is the vegan diet!
Meat tax “could save 220,000 lives per year”?
The team of scientists led by Dr. Marco Springmann who authored the new study published in the journal Public Library of Science ONE claim that a global meat tax “could save 220,000 lives and cut health care bills by $41 billion” a year.
The study’s authors assert that meat consumption increases risk of heart disease, cancer, stroke and diabetes, and is even “carcinogenic when eaten in processed forms, including sausages, bacon and beef jerky” and thus comparable to “cigarettes and alcohol”.


Dr. Marco Springmann is from the Nuffield Department of Population Health at Oxford University.
Springmann also claims: “Consuming red and processed meat not only affects your health but also the economy at large” due to “illness and care for family members who suffer with chronic disease.”
“Based on weak epidemiology”…”literally fake science”
However, since the paper was published, there’s been a hailstorm of criticism.
For example science journalist and the author of Big Fat Surprise, Nina Teicholz, tweeted that the results and recommendations made by Springmann are based on lousy science and “should never be used as a foundation for policy.”. At Twitter she wrote:


This is all based on weak epidemiology, the kind of science meant to generate hypotheses, not test them. This is, literally, fake science that should never be used as a foundation for policy. @cnn reporter should know better https://t.co/GATSRaluOk
— Nina Teicholz (@bigfatsurprise) November 8, 2018



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Lead author a vegan and climate activist!
Not only is the science dubious, but it turns out that the lead author of the paper itself is a vegan, and has also fallen for the junk science behind climate change!
Reader Simon Dwinder discovered the link:

""In his own case, it seemed a no-brainer to become a vegan ten years ago, when he realised that it is demonstrably healthier and better for the planet""https://t.co/9jpWWS4Lzd
— Simon Dwinder #StandUp4Brexit (@Sidwinder75) November 8, 2018

And (leftist) reader tlcoles November 8, 2018 added:


So the CNN article should have read “Ateam of researchers led by Dr. Marco Springmann, a vegan at the Nuffield Department of Population Health at Oxford University, produces science to declare meat bad…again.” 😂

The meaty, high-(good)fat diet worked fantastically for me
Personally 5 years ago I made the switch to the high fat, low junk-carb diet, eating plenty of butter, eggs, meat, nuts, cheese etc. and wound up losing 20 pounds and seeing my health return with full power. I no longer have to take any prescription medicines at all.
Vegan diet harbors huge health risks
Moreover, anyone doing the least amount of research will quickly discover that the vegan diet in many cases is a slow and tortuous suicide. Just ask KasumiKriss, who stopped being a vegan after four years and saw her health improve dramatically.
Other reading:
– Vegans and vegetarians more mentally unstable
– Meat scare “intimidation of the public”
– The sick kids of vegans 


Share this...FacebookTwitter "
"Egyptian billionaire Naguib Sawiris recently announced plans to buy a Greek island to give refugees from the Middle East and Africa a country of their own. Though Sawiris referred to his proposal as a “crazy idea” on Twitter, it pales in comparison to an earlier scheme for the Mediterranean from the first half of the 20th century, which was seriously considered by heads of state and, at one point, even the United Nations. It was called Atlantropa, and would have involved the partial draining of the Mediterranean Sea and the creation of a Eurafrican supercontinent.   Atlantropa was the brainchild of the German architect Herman Sörgel, who tirelessly promoted his project from 1928 until his death in 1952. His experience of World War I, the economic and political turmoil of the 1920s and the rise of Nazism in Germany convinced Sörgel that a new world war could only be avoided if a radical solution was found to European problems of unemployment, overpopulation and, with Saudi oil still a decade away, an impending energy crisis. With little faith in politics, Sörgel turned to technology. Dams across the Strait of Gibraltar, the Dardanelles, and eventually between Sicily and Tunisia, each containing gigantic hydroelectric power plants, would form the basis for the new supercontinent. In its final state the Mediterranean would be converted into two basins, with the western part lowered by 100 meters and the eastern part by 200 meters and a total of 660,200 km2 of new land reclaimed from the sea – an area larger than France. Later plans for Atlantropa also included two dams across the Congo River and the creation of a Chad and Congo Sea, which Sörgel hoped would have a moderating influence on the African climate making it more pleasant for European settlers. In line with the colonial and racist attitudes of the times, Sörgel envisaged Africa with its resources and its land to be entirely at the disposal of Europe, a continent with plenty of space to accommodate Europe’s huddled masses. While Sörgel’s proposal may sound absurd to our ears, it was taken seriously by architects, engineers, politicians and journalists at the time. The extensive Atlantropa archive in the Deutsche Museum in Munich abounds with architectural drawings for new cities, the dams and bridges of the future continent as well as letters of support and hundreds of articles about the project, which appeared in the German and international popular press as well as in specialised engineering and geographical magazines. What made Atlantropa so attractive was its vision of world peace achieved not through politics and diplomacy, but with a simple technological solution. Atlantropa would be held together by a vast energy net, which would extend from the gigantic hydroelectric plant in the Gibraltar dam and provide the entirety of Europe and Africa with electricity. The power plant would be overseen by an independent body who would have the power to switch off the energy supply to any individual country that posed a threat to peace. Moreover Sörgel calculated that the construction of the supercontinent would require each country to invest so much money and people power that none would have sufficient resources to finance a war. Putting his faith in the people of Europe and their desire for peace, Sörgel dedicated a large part of his work to the promotion and dissemination of the project through the popular press, radio programmes, films, talks, exhibitions and even poetry and an Atlantropa symphony. He hoped popular support would help him get the backing of politicians.  Unsurprisingly, in the eyes of his contemporaries the required collaboration between nation states always appeared even more utopian than the vast technological dimensions of Atlantropa. As the New York-based magazine UN World observed in 1948:  Harnessing Gibraltar for mankind’s good does sound like a dream, but in this 20th century no dream – not even that of cooperation among nations – is quite impossible. By 2012, when the European Union was awarded the Nobel Peace Prize in acknowledgement of its contribution to lasting peace in Europe, the hope expressed by the UN World appeared to finally have come true. However, in 2015, cooperation among nations sadly looks like a distant dream once again. Where once Herman Sörgel had used the image of a Europe bursting at the seams that is saved by a peaceful merger with the African continent, we are now confronted with the mirror image as people from across Africa and the Middle East seek refuge in Europe.  Now would be the time to prove that the Peace Prize was indeed deserved. Now would be the time to show solidarity and unity. Instead, the EU appears on the brink of being torn apart over its inability to find a communal solution to accommodate a group of refugees, whose number ultimately comes to no more than a meagre 0.11% of the overall population of the Union. Sadly European unity, and with it a solution for the refugee crisis, once again appears more utopian than Sörgel’s plans for draining the sea."
"
Share this...FacebookTwitterSerious Climate Doping Suspicion Against RSS: Satellite Temperatures Raised One And Half Tenths Of A Degree
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(Translated/edited by P Gosselin)
Temperatures can be measured from the ground and from satellites. Satellite data have two versions, UAH and RSS. The version of UAH (University of Alabama, Huntsville) makes a solid impression. The RSS version shows larger deviations and suggests a stronger warming. 
How come? 
Doping the data
Both datasets surely get their data from similar satellites. The explanation lies in a “post-processing” of the measured values ​​by the RSS group. In the chart below you can see the old version in red. 

Global temperature based on RSS satellite measurements. From Climate4You Newsletter June 2018.
At some point from mid 2015, the RSS people pushed the temperatures starting at  the year 2000 manually upwards. Therefore today you can find the values ​​of the blue curve in the database. As a result of this subsequent data change, additional warming was generated at a speed of one and a half tenths of a degree. It does not sound very much, but it is much if you consider that the 20th century warming was only eight-tenths of a degree.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Data on statistical steroids
It’s a little bit as like a year 2010 high jump world record of 2.40 meter later being changed to 2.45 meter by the International Athletics Federation. We could call this desktop doping, which would certainly not be a bad description for the RSS intervention. 
RSS statisticians massively massaged their data under the radar, without any interest from the media. A few years later new heat records get surprisingly reported, but in many cases likely solely through the heat-promoting measures of desktop doping. 
Change the data to fit the broken models
The changes happen to affect the hiatus phase, as it apparently had to do with the fear that the warming would not continue. The values ​​were simply raised. It’s a classic case where the readings did not confirm the models. But instead of improving the models, the measurement data were changed. There are hardly any other disciplines out there where things work this way.
Once again, it’s clear that we urgently need climate-related checks. The damage to the trust is already done. Now only stricter checks can help, and restricting employees in cases of suspicion – lifelong in the case of repeat-offenders. 
Criminal fraud
Proposal: Anyone who fabricates or falsifies climate data, or brings these willfully into the public, should be punished with 2 years in prison.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Kirye

 
 
 
 
 
Since the global warming scare started some 30 years ago, Japan’s winters in fact have have not been warming – but rather many areas show the opposite is happening: cooling.
January in Japan no warming in over 30 years
For Japan as a whole, the entire country has not seen any rise in January mean temperature over the past 30 years, according to data from the Japan Meteorological Agency (JMA):

As the chart above shows, if anything, Japan mean January temperature has been falling a bit, thus contrdicting the warming claims of climate alarmists.
Cooling Kyoto
January in Kyoto has been cooling over the past 30 years, as the following chart shows, even as atmospheric CO2 concentrations have risen from about 350 ppm back in 1985 to over 410 ppm today:

No trend at Naze in 33 years
The same is true for the south Japan station of Naze:

Naze has seen slight January cooling over the 33 years – not warming!
Wintry Hokkaido stays that way
In northern Japan, the month of January has also gotten slightly colder over the past 30 years, as shown by measurements taken at the Suttsu station in Hokkaido:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





 
Overall, January today in Suttsu is at about the same level as it was more than 100 years ago.
Same is true at Okinawa
Moving far south to the Nago station in Okinawa, here as well we see that January mean tenmperatures have been cooling, and not warming like climate activists insisted it would.
Japan refuses to cooperate with the global warming “science”:

By now many people should be awaiting an explanation as to why the trend has behaved the opposite of what has been predicted for decades by CO2 global warming scientists.
Cooling near Nagasaki
The trend for January at the Sasebo station near Nagasaki over the past 32 years has also seen a steady linear decline:

How can anyone in the Japanese media be speaking about rapid warming over the recent years? Much of the climate news in Japan are of poor quality, unfortunately, as they continue to make people believe it’s warming when it is in fact not.
Japan’s winters have seen no trend 
Okay, the charts show trends for the month of January, the dead of winter. So what about the complete winter in Japan from December through February? Here as well we see no warming at all across Japan:

The untampered data from the Japan Meteorological Agency (JMA) shows the Japan’s winters have not warmed at all in over three decades.
Typhoons have also become less frequent
In general many other factors have not cooperated with the many predictions made by global warming scientists. One important example is typhoons, which we were told would become more frequent and intense. But here’s the typhoon data from the JMA:

Also there’s been no real trend in the number of typhoon landfalls hitting Japan.
In summary, lots of hype about warming in Japan, yet the data haven’t shown it in over 3 decades.
Share this...FacebookTwitter "
"The government is fighting to keep secret draft versions of its strategy for helping the Pacific deal with climate change, prompting concerns it may be hiding changes that weakened the final report. The Department of Foreign Affairs and Trade released its climate change action strategy in November, detailing how the foreign aid program would be used to help developing nations – particularly those in the Pacific – deal with global heating. The department’s draft report had languished in the office of the foreign minister, Marise Payne, for nine months, and the delays had frustrated foreign aid groups, particularly given Pacific nations have identified climate change as the region’s single biggest threat. Seeking to understand whether the minister’s office influenced the final version, the Greens senator Mehreen Faruqi lodged a freedom of information request for the draft copy, which the department gave to the minister’s office in February last year. But the government is now refusing to release the draft, arguing it is not in the public interest and would “undermine the value and authority of the final climate change strategy”. The department is relying on exemptions in the FOI act that block the release of “deliberative matter” – material that has been used in the making of decisions. “I consider that there is no identifiable benefit or public interest to release this type of draft information,” the department’s decision-maker said. “Release of the deliberations that form part of the drafting process would undermine the value and authority of the final Climate Change Action Strategy. I therefore consider that it would not be in the public interest to release the draft Climate Change Action Strategy.” Payne was previously questioned about delays to the release of the final report during Senate estimates, following reports her office had sat on it for months. She said the release of the final report was delayed because changes were required to “better reflect our international climate change engagement prior to the Paris Agreement coming into effect in 2020, particularly noting – for those who are oblivious – that we have just had a federal election”. “The government wants to take the opportunity to make sure that strategies such as this and other relevant documentation are contemporary and are relevant to the changes in our commitments, which will be seen under the Paris Agreement,” Payne said in July. But Faruqi said the refusal to release the draft version “absolutely smacks of a cover-up”. She said the argument that there was no public interest in its release “makes no sense” and raised suspicion about efforts to keep it secret. “This strategy appears to have sat on the foreign minister’s desk for almost nine months and we simply don’t know how it was altered in that time,” she said. “The public has a right to know whether the government politically interfered to water down the strategy.” A department spokeswoman said the draft strategy was updated during the nine months to better reflect new government initiatives, including the announcement of $500m for climate and disaster resilience in the Pacific and $140m for a fund to mobilise the private sector on climate change. “An early draft of the Strategy was sent to the Foreign Minister’s Office in February 2019,” she said. “After the Government went into caretaker mode and the election was held, the Morrison Government made a number of decisions to build climate resilience and mitigation through the Pacific Step-up. The Strategy therefore needed to take these new initiatives into account.” Other changes between the draft and the final version included a stronger focus on social inclusion, updates to climate finance data, updated source references, and the addition of “more current case studies”, the spokeswoman said. Pacific nations have previously expressed frustration at Australia’s intransigence on climate change. During last year’s Pacific Islands Forum, Australia attempted to distance itself from language calling for urgent action on climate change, putting it at odds with other nations. It was successful in removing almost all references to coal and had worked hard to soften the language on climate change. The foreign affairs department has been approached for a response."
"
Share this...FacebookTwitterIt is often claimed that modern day sea ice changes are “unprecedented”, alarming, and well outside the range of natural variability.  Yet scientists are increasingly finding that biomarker proxies used to reconstruct both Arctic and Antarctic sea ice conditions since the Early Holocene reveal that today’s sea ice changes are not only not unusual, there is more extensive Arctic and Antarctic sea ice during recent decades than there has been for nearly all of the last 10,000 years.

Antarctic Sea Ice Extent
In the Southern Ocean surrounding Antarctica, the sea surface temperatures have been cooling since 1979.

Image Source: Jones et al., 2016

Image Source: Fan et al., 2014
Purich et al., 2018     “Observed Southern Ocean changes over recent decades include a surface freshening (Durack and Wijffels 2010; Durack et al. 2012; de Lavergne et al. 2014), surface cooling (Fan et al. 2014; Marshall et al. 2014; Armour et al. 2016; Purich et al. 2016a) and circumpolar increase in Antarctic sea ice (Cavalieri and Parkinson 2008; Comiso and Nishio 2008; Parkinson and Cavalieri 2012).”

Image Source: Purich et al., 2018
The decline in Southern Ocean temperatures has coincided with an increase in Antarctic sea extent since 1979.

Image Source: Jones et al., 2016
Comiso et al., 2017     “The Antarctic sea ice extent has been slowly increasing contrary to expected trends due to global warming and results from coupled climate models. After a record high extent in 2012 the extent was even higher in 2014 when the magnitude exceeded 20 × 106 km2 for the first time during the satellite era. … [T]he trend in sea ice cover is strongly influenced by the trend in surface temperature [cooling].”

Image Source: Comiso et al., 2017
In contrast to the post-1970s cooling and sea ice advance, Antarctica warmed and sea ice declined during the 1950s to 1980s.
Antarctica warming rapidly, 1950s-1980s
IPCC (2001):    “Another analysis of a 21-station data set from Antarctica by Comiso (1999) found a warming trend equivalent to 1.25°C per century for a 45-year record beginning in the 1950s but a slight cooling trend from 1979 to 1998. The slight cooling trend for this later 20-year period also was confirmed via analysis of surface temperatures over the whole continent, as inferred from satellite data.”
Fan et al., 2014:  “[S]ea surface temperatures and surface air temperatures decreased during 1979–2011, consistent with the expansion of Antarctic sea ice. In contrast, the Southern Ocean and coastal Antarctica warmed during 1950–1978.”
Declining Antarctic sea ice concentrations, 1950s-1980s
Sinclair et al., 2014     “We present the first proxy record of sea-ice area (SIA) in the Ross Sea, Antarctica, from a 130 year coastal ice-core record. High-resolution deuterium excess data show prevailing stable SIA [sea ice area] from the 1880s until the 1950s, a 2–5% reduction from the mid-1950s to the early-1990s, and a 5% increase after 1993.”
Miles et al., 2013     “Despite large fluctuations between glaciers—linked to their size—three epochal patterns emerged: 63 per cent of glaciers retreated from 1974 to 1990, 72 per cent advanced from 1990 to 2000, and 58 per cent advanced from 2000 to 2010.  … Indeed, several studies report increasing sea-ice concentrations in the study region from approximately 1980 to 2010, which is consistent with the predominance of glacier advance since 1990, when above-average sea-ice and fast-ice concentrations could have suppressed calving by increasing back-pressure on glacier termini. In contrast, reduced sea ice concentrations from the 1950s to the mid 1970s are consistent with glacier retreat during the 1960s and 1970s, when air temperatures were also increasing along the Pacific coast.”
Antarctic sea ice conditions were similar to today’s during 1897-1917.
Edinburgh and Day, 2016     “In stark contrast to the sharp decline in Arctic sea ice, there has been a steady increase in ice extent around Antarctica during the last three decades, especially in the Weddell and Ross seas. In general, climate models do not to capture this trend … This comparison shows that the summer sea ice edge was between 1.0 and 1.7° further north in the Weddell Sea during this period but that ice conditions were surprisingly comparable to the present day [during 1897-1917] in other sectors.”
(press release)     “We know that sea ice in the Antarctic has increased slightly over the past 30 years, since satellite observations began. Scientists have been grappling to understand this trend in the context of global warming, but these new findings suggest it may not be anything new. … The new study published in The Cryosphere is the first to shed light on sea ice extent in the period prior to the 1930s, and suggests the [sea ice] levels in the early 1900s were in fact similar to today“
New paper finds Antarctic (Peninsula) sea ice more extensive today than possibly any time in the last 10,000 years.
Belt, 2018     “Exceptionally, Massé et al. (2011) observed a general decline in sedimentary IPSO25 concentration in a short offshore transect from East Antarctica; a trend shown subsequently to be quite general for various other Antarctic regions (Belt et al., 2016). In the latter study, it was suggested that the origin of this trend might be found in the preferred habitat of the known source of IPSO25 (B. adeliensis), which has a tendency to proliferate in platelet ice, found most commonly in near-shore locations covered by fast ice (Medlin, 1990). As such, it was hypothesised that higher concentrations of IPSO25 might be found in locations proximal to ice shelves, since their basal melt acts as the major driver for platelet ice formation (Jefferies et al., 1993). Re-examination of some palaeo sea ice records based on IPSO25 added further credibility to this suggestion (Fig. 6), and Smik et al. (2016a) also identified highest concentrations of IPSO25 in near-shore surface waters soon after spring sea ice melt.”


Arctic Sea Ice Extent
“Extensive modern sea ice conditions” during spring (80% concentrations), but “consistently low” and “marginal” (<10%) sea ice conditions from 10,500 to 1,500 years before present.
Köseoğlu et al., 2018     “The core 70 site is characterised by extensive modern sea ice conditions (≈80% SpSIC [Spring Sea Ice Concentration]) and the downcore record represents a gradual evolution of sea ice cover in the northern Barents Sea from ice-free conditions during the early Holocene to prolonged seasonal sea ice presence prevalent in the region today. The primarily insolation-controlled southward expansion of sea ice cover previously inferred for the core site throughout the Holocene (Belt et al., 2015; Berben et al., 2017) is reflected in the CT model assessment. Consistent with the onset of the Holocene Thermal Maximum and the resulting proximity of the annual maximum sea ice edge to the core site between ca. 9.5–8.5 cal kyr BP evident from low PIIIIP25-derived SpSIC (ca. 5–15%), the CT model predicts mostly marginal sea ice conditions during this interval. … From ca. 10.0–1.5 cal kyr BP, ice-free conditions characterised the core 11 site, as evidenced by consistently low SpSIC (ca. <10%) and marginal sea ice conditions predicted by the CT model, and further supported by an enhancement of AW [Arctic Water] inflow to the core site from ca. 9.8 cal kyr BP (Groot et al., 2014).”

“Lower than modern” sea ice conditions between 2,200 and 1,200 years before present.  Little Ice Age sea ice conditions “possible similar to conditions as observed today”.
Kolling et al., 2018     “Our biomarker record indicates that Disko Bugt [West Greenland] experienced a gradual expansion of seasonal sea ice during the last 2.2 kyr. Maximum sea ice extent was reached during the Little Ice Age around 0.2 kyr BP. Superimposed on this longer term trend, we find short-term oscillations in open water primary production and terrigenous input, which may be related to the Atlantic Multidecadal Oscillation and solar activity changes as potential climatic trigger mechanisms.  The period between 2.2 and 1.2 kyr BP, with lower than modern sea ice conditions in Disko Bugt (Fig. 6b), coincides with generally warm conditions over the Greenland Ice Sheet.”
“During the last 0.1 kyr, all biomarker concentrations showed an increase, brassicasterol and HBI III reach maximum values in the uppermost sample (80 µg/gTOC and 1.8 µg/gTOC, respectively; Fig. 3b, d).
“[During the Little Ice Age (0.7–0.2 kyr BP)] our biomarker record supports harsher sea ice conditions, possibly similar to conditions as observed today (Fig. 6b), indicated by strong increased in IP25 concentration and the PDIP25 index (Fig. 4c, d). …  A self-amplifying system may have caused the environmental changes observed in Disko Bugt area as follows: solar triggered Arctic sea ice melt [Ruzmaikin et al., 2004] increases freshwater supply towards the North Atlantic causing a reduction in sub-polar gyre activity and AMO [Holland et al., 2001, Schmith et al., 2003] as described by Sha et al. [2016]. This may in turn cause distinct changes in WGC composition and meltwater supply from the Greenland Ice Sheet that affects phytoplankton blooms in West Greenland.
“We find that the Disko Bugt area was influenced by seasonal sea ice over the last 2.2 kyr BP. The overall sea ice trend indicates a development from a reduced sea ice cover during early spring, with sea ice algae productivity hampered by light availability to a gradual extend of the sea ice season from 1.2 kyr BP onwards. This change in sea ice extend is parallel to decreasing Northern Hemisphere atmospheric temperatures and culminates in the Little Ice Age around 0.2 kyr. We assume that modern conditions, with sea ice present until late spring and the presence of a stable ice edge at Disko Bugt, established around that time [~200 years ago].”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->







Other Arctic reconstructions indicate more extensive sea ice conditions exist today than most of the Holocene.

Image Source:  Yamamoto et al., 2017

Image Source: Perner et al., 2018
Nothing unusual or unprecedented: ‘Internal variability’ or natural cycles responsible for half of the Arctic sea ice loss since 1979.
Yu and Zhong, 2018    “The underlying physical mechanisms for the Arctic warming and accelerated sea ice retreat are not fully understood. In this study, we apply a relatively novel statistical method called Self-Organizing Maps (SOM) to examine the trend and variability of autumn Arctic sea ice in the past three decades and their relationships to large-scale atmospheric circulation changes. Our results show that the anomalous autumn the Arctic Dipole (AD) (Node 1) and the Arctic Oscillation (AO) (Node 9) could explain in a statistical sense as much as 50% of autumn sea ice decline between 1979 and 2016. The Arctic atmospheric circulation anomalies associated with anomalous sea surface temperature patterns over the North Pacific and North Atlantic influence Arctic sea ice primarily through anomalous temperature and water vapour advection and associated radiative feedback. … We investigate the potential mechanisms for the autumn arctic sea ice decline for the period 1979-2016 using the SOM method. Our results show that more than half of the autumn Arctic sea ice loss may be associated with the changes in the temperature and water vapour transport and the associated water vapour radiation feedback resulting from anomalous atmospheric circulations linked to SST anomalies over the North Pacific and North Atlantic. …  [T]he results here help advance the knowledge about the relatively large contributions from the decadal-scale natural climate variability to Arctic climate change…”

Image: https://www.nature.com/articles/s41598-018-22854-0

Image: http://www.nature.com/nature/journal/v509/n7499/full/nature13260.htm

Image: https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2011GL048008

Image: https://www.nature.com/articles/nclimate3241

Image: http://www.pnas.org/content/112/15/4570.full

Image: https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2005GL023429
Graph
Share this...FacebookTwitter "
"Rupert Murdoch’s son has strongly criticised his family’s news outlets for downplaying the impact of the climate crisis, as bushfires continue to burn in Australia. James Murdoch and his wife, Kathryn, issued a rare joint statement directly criticising his father’s businesses for their “ongoing denial” on the issue, which has been reflected in the family’s newspapers repeatedly casting doubt on the link between the climate emergency and the bushfires.  “Kathryn and James’s views on climate are well-established and their frustration with some of the News Corp and Fox coverage of the topic is also well-known,” a spokesperson for the couple said, confirming a report in the Daily Beast. “They are particularly disappointed with the ongoing denial among the news outlets in Australia given obvious evidence to the contrary.” James Murdoch was most recently the chief executive of the family’s 21st Century Fox entertainment business, leaving when it merged with Disney. He is making media investments through his own Lupa Systems company but continues to sit on the board of the family’s newspaper business, News Corp, which also owns the Times and the Sun. The bushfires have focused attention on the likes of Andrew Bolt, a political commentator for News Corp’s Australian newspapers who is known for promoting the views of climate science deniers, and for his own attacks on “alarmists” and his derision of climate change science. He also has a programme on the Murdoch-owned Sky News Australia, where he has criticised the “constant stream of propaganda” on the public broadcaster ABC about the role of the climate crisis in the bushfires. “Politicians who should do better are out there feeding the fear and misinformation,” he said in a recent broadcast criticising politicians who said carbon emissions needed to be cut to avoid future fires. “As if that would stop a fire. You’d have to be a child like Greta Thunberg to believe that fairytale.” US viewers have also heard commentary from Fox News presenters such as Laura Ingraham, who has said that “celebrities in the media have been pressing the narrative that the wildfires in Australia are caused by climate change”, before introducing guests who cast doubt on this interpretation. James Murdoch’s criticism sheds light on the family’s internal rifts, amid speculation over his 88-year-old father’s succession plans. James’s older brother Lachlan is still actively involved in the family businesses as the US-based chairman and chief executive of the slimmed-down Fox Corporation, which owns Fox News. Last year, Rupert Murdoch told shareholders “there are no climate change deniers” around his company and said his business was early to commit to “science-based targets to limit climate change” and was working to reduce its climate emissions. However, he has been publicly critical about the “alarmist” approach to the issue. In 2015, he used his Twitter account to describe himself as a “climate change sceptic not a denier”. A climate change skeptic not a denier. Sept UN meets in NY with endless alarmist nonsense from u know whom! Pessimists always seen as sages Lachlan Murdoch, Rupert Murdoch and News Corp have all separately donated millions of dollars to bushfire recovery efforts in recent days, although the Daily Beast claimed the donations were made after it requested comment about James Murdoch’s statement. James Murdoch has a long history of advocacy on environmental issues, inviting the former US vice-president Al Gore to present a version of his An Inconvenient Truth slideshow to Fox executives in 2006. At the time he was the heir apparent to the media empire and had been trusted with running BSkyB in London, where he would push environmental issues to the fore, working on ways to reduce the power used by Sky’s set-top boxes and insisting on using hybrid taxis long before such things were standard corporate behaviour. Since stepping back from day-to-day roles with the family business at the end of 2018, the multibillionaire has made clear he feels uncomfortable about much of Fox News’ output and was unsuccessful in an attempt to cash-in his stock completely and make a clean break with the company – an effort that failed after Lachlan declined to buy him out. Kathryn Murdoch has already set out the couple’s vision, telling the New York Times last year that she was increasingly focused on the issue of global heating: “There hasn’t been a Republican answer on climate change. There’s just been denial and walking away from the problem. There needs to be one.” She said she was particularly moved to act after seeing Al Gore’s speech at the Fox event in 2006: “I decided to switch everything I was doing. I wanted to be able to look my children in the eye and say ‘I did everything I could.’”"
"
Share this...FacebookTwitterRapid sea level rise was supposed
to shrink Earth’s coasts. It hasn’t.

Image Source: Mörner, 2018
“Over the past decades, atoll islands exhibited no widespread sign of physical destabilization in the face of sea-level rise. 88.6% of islands were either stable or increased in area, while only 11.4% contracted. It is noteworthy that no island larger than 10 ha decreased in size. These results show that atoll and island areal stability is a global trend, whatever the rate of sea-level rise.”- Duvat, 2019

Image Sources: Donchyts et al., 2016 and BBC (press release)
I. Despite sea level rise, “the coasts are growing all over the world”
Sea levels aren’t rising fast enough to deleteriously affect coastal areas on a net global scale.
Satellite observations indicate there has been 13,565 km2 of net growth in land area across the globe’s coasts between 1985-2015.
In other words, the Earth’s coasts gained more land area than were lost to rising sea levels.
“Earth’s surface gained 115,000 km2 of water and 173,000 km2 of land over the past 30 years, including 20,135 km2 of water and 33,700 km2 of land in coastal areas.” (Donchyts et al., 2016)
As a visual example, Ahmed et al. (2018) find that Bangladesh’s coastal land area grew by 7.9 km2 per year during 1985-2015.
“This paper draws upon the application of GIS and remote sensing techniques to investigate the dynamic nature and management aspects of land in the coastal areas of Bangladesh. … This research reveals that the rate of accretion [coastal land growth] in the study area is slightly higher than the rate of erosion. Overall land dynamics indicate a net gain of 237 km2 (7.9 km2annual average) of land in the area for the whole period from 1985 to 2015.”  (Ahmed et al., 2018)

Image Source: Ahmed et al., 2018
II. Even with ~4 mm yr−1 local sea level rise, Pacific islands grew in size during 1971-2014
Between 1958-2014, the globe’s sea levels rose at a rate of about 1.4 mm yr−1 , or 14 centimeters (5.5 inches) per century (Frederikse et al., 2018).
Ice melt from Greenland and Antarctica contributed a grand total of 1.5 cm of the 7.9 cm (3.1 inches) of sea level rise during those 56 years.
“The global-mean sea level reconstruction shows a trend of 1.5 ± 0.2 mm yr−1 over 1958–2014 (1σ), compared to 1.3 ± 0.1 mm yr−1 for the sum of contributors.” (Frederikse et al., 2018)
However, there are regions of the world where sea levels are rising at rates two or three times the global average.  Tuvalu, representing over 100 islands located in the central west Pacific, has  undergone “twice the global average” rate of sea level rise (~3.90 ± 0.4 mm yr−1) since the 1970s.
It would be expected that such high rates of local sea level change would result in shrinking island coasts and overall land area during this period.
But the opposite has occurred.  There has been a net increase in the coastal land area of Tuvalu between 1971-2014 in 8 of 9 atolls.
“We specifically examine spatial differences in island behaviour, of all 101 islands in Tuvalu, over the past four decades (1971–2014), a period in which local sea level has risen at twice the global average. Surprisingly, we show that all islands have changed and that the dominant mode of change has been island expansion, which has increased the land area of the nation.”
“Using remotely sensed data, change is analysed over the past four decades, a period when local sea level has risen at twice the global average (~3.90 ± 0.4 mm yr−1). Results highlight a net increase in land area in Tuvalu of 73.5 ha (2.9%), despite sea-level rise, and land area increase in eight of nine atolls.” (Kench et al., 2018)
III. The stability or coastal net growth of islands in recent decades to century “is a global trend”
Coastal stability and expansion for atoll and island land area is not just a regional trend, but a global one.
A comprehensive (709 islands) review of coastal changes that have been observed in the last decades to century (Duvat, 2019) reveals that no atoll island destabilization has occurred due to the effects of rising sea levels.
In fact, 88.6% of the globe’s islands have coasts that are either stable or expanding in size.
Further, not a single island larger than 10 hectares [1 ha = 10,000 square m, or 2.5 acres] has decreased in size in recent decades.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




None of these observed trends affirm the popularized claim that modern sea level rise is currently threatening the globe’s coasts.

Duvat, 2019
A global assessment of atoll island
planform changes over the past decades

Image Source: Duvat, 2019
“This review first confirms that over the past decades to century, atoll islands exhibited no widespread sign of physical destabilization by sea level rise. The global sample considered in this paper, which includes 30 atolls and 709 islands, reveals that atolls did not lose land area, and that 73.1% of islands were stable in land area, including most settled islands, while 15.5% of islands increased and 11.4% decreased in size. Atoll and island areal stability can therefore be considered as a global trend.”
“Importantly, islands located in ocean regions affected by rapid sea-level rise showed neither contraction nor marked shoreline retreat, which indicates that they may not be affected yet by the presumably negative, that is, erosive, impact of sea-level rise.”
“It is noteworthy that no island larger than 10 ha decreased in size, making this value a relevant threshold to define atoll island areal stability.”
“[A]mong the 27 islands having a land area lying between 100 and 200 ha (9 in French Polynesia, 6 in the Marshall Islands, 6 in Kiribati, 5 in Tuvalu and 1 in the Federated States of Micronesia), only 3 increased in area, while 24 were stable.”
“The great majority of Pacific islands showed positional stability, as illustrated by the Tuamotu atolls, where 85–100% of islands were stable, depending on atolls (Duvat & Pillet, 2017; Duvat, Salvat, et al., 2017).”
“Importantly, the reanalysis of available data on atoll island planform change indicates that over the past decades to century, no island larger than 10 ha and only 4 out of the 334 islands larger than 5 ha (i.e., 1.2%) underwent a reduction in size.”

IV. Sea level rise is not the coastal threat that natural geological processes are
Rapid sea level rise rates due to global warming are not the threat to coastal communities and wildlife that they have often been claimed to be.  What is?  Natural geological/crustal changes, or vertical land movement.
Tied to the Earth’s gravitational attraction and shifting plates, geologic subsidence (land sinking) or uplift (land rising) processes are far more of a determinant of coastal structure and positioning than the rather small (by comparison) seawater volume changes in the world’s ocean basins.  This is why sea level rise (or fall) rates are local, not global, as they vary quite dramatically across the world.
Along the coast of Juneau, Alaska, for example, the land surface has been rapidly rising due to gravitational uplift for many decades.  Consequently, relative sea levels are plummeting in this region at a rate of over -13 mm yr−1 (minus-5 inches per decade) according to NOAA.

The opposite is occurring along the U.S. Gulf coast (Grand Isle, Louisiana), where the land area is sinking and thus sea levels are rising at a rate of over +9 mm yr−1.

Scientists have concluded that “sea level rise is not the primary factor controlling the shoreline changes” in regions where sea levels are rapidly rising (Testut et al., 2016).   Even localized rates of sea level rise as high as 5 mm yr−1 are not rapid enough to overcome the much more pronounced geologic changes (accretion and uplift).
“We show that Grande Glorieuse Island has increased in area by 7.5 ha between 1989 and 2003, predominantly as a result of shoreline accretion [growth]: accretion occurred over 47% of shoreline length, whereas 26% was stable and 28% was eroded. Topographic transects and field observations show that the accretion is due to sediment transfer from the reef outer slopes to the reef flat and then to the beach. This accretion occurred in a context of sea level rise: sea level has risen by about 6 cm in the last twenty years and the island height is probably stable or very slowly subsiding. This island expansion during a period of rising sea level demonstrates that sea level rise is not the primary factor controlling the shoreline changes. This paper highlights the key role of non-climate factors in changes in island area, especially sediment availability and transport.”  (Testut et al., 2016)
V. Vertical motions of the Earth’s crust exert “dominant control” over relative sea level
Along the eastern coast of the U.S., Piecuch and colleagues (2018) find that the “dominant control” over the disparate rates of sea level rise during the modern era has been exerted by “vertical motions of the Earth’s crust”, not climate.
“Here we analyse instrumental data and proxy reconstructions using probabilistic methods to show that vertical motions of Earth’s crust exerted the dominant control on regional spatial differences in relative sea-level trends along the US East Coast during 1900–2017, explaining most of the large-scale spatial variance. … Rates of coastal subsidence caused by ongoing relaxation of the peripheral forebulge associated with the last deglaciation are strongest near North Carolina, Maryland and Virginia [locations where the sea level rise rates are highest]. Our results indicate that the majority of large-scale spatial variation in long-term rates of relative sea-level rise on the US East Coast is due to geological processes that will persist at similar rates for centuries. … We note that negative VLM [vertical land motion] reflects subsidence and hence contributes to sea-level rise. Correspondingly, the most negative VLM [vertical land motion] rate (−2.5 ± 0.6 mm yr−1) is likely (P = 0.75) to occur in the states that host the maximum sea-level rise, North Carolina or Virginia, whereas the most positive rate of VLM (0.7 ± 0.8 mm yr−1) is very likely (P = 0.90) to occur in Maine.” (Piecuch et al., 2018)
Pfeffer and colleagues (2017) assessed 849 coastal sites and determined that geophysical processes, or vertical land motion (VLM) trends (ranging from −13 to +16 mm yr−1 ), “have been recognized as a dominant component of the total relative sea-level variations observed at coasts” at locations throughout the globe.
“VLMs contribute actively to the sea-level changes felt by coastal populations, as they can amplify, diminish or counteract the effects of climate-induced signals (e.g. Pfeffer & Allemand 2016). In many cases, for example, Torres Islands (Ballu et al. 2011), western Tropical Pacific (Becker et al. 2012), southern Europe (Woppelmann & Marcos ¨ 2012) or Indian Ocean (Palanisamy et al. 2014), VLMs [vertical land motions] have been recognized as a dominant component of the total relative sea-level variations observed at coasts. … VLMs are estimated at 258 GPS stations and 591 tide gauges, for a total of 849 coastal sites. Trend values range from −13 to +16 mm yr−1 (Fig. 3a). A strong spatial variability in VLM is observed at all scales, including locally, which is evidenced for example by the dense instrumental network in Japan. High rates of crustal uplift are observed at high latitudes, while subsidence of coastal areas is more often observed at medium latitudes (e.g. the East American coast).” (Pfeffer et al., 2017)

VI. Meter-scale sea level rise is “related to geologic events only”, not climate change
In a 2018 paper published in the journal Geoscience Frontiers, geophysicist and tectonics expert Dr. Aftab Khan asserts that “both regional and local sea-level rise and fall in meter-scale is related to the geologic events only and not related to global warming and/or polar ice melt.”
Very high rates of land subsidence and uplift persist today.  Vertical land motions as profound as ±10 to 30 mm yr−1 have been observed by geologists – easily overwhelming even the highest measured relative sea level changes.
The conclusion that rapid and high-amplitude (i.e., meters-per-century) sea level changes occur primarily as a consequence of natural geologic processes effectively leaves no room for global warming and/or polar ice melt to significantly contribute to the alarming meters-per-century sea level rise projected to engulf the Earth’s coasts by the end of the century.
Modeled predictions of multiple meters of sea level rise by 2100 (for example, 2.6 meters of global sea level rise by 2100 according to authors like Dr. Michael Mann and Dr. Richard Alley in Garner et al. 2017) are dismissed as “highly erroneous” by Dr. Khan.
Suggestions of a controlling anthropogenic influence on coastal and shoreline changes — the scariest aspect of climate modeling predictions — may therefore be significantly undermined by real-world scientific observations.

Khan, 2018
Why would sea-level rise for global
warming and polar ice-melt?
“Geophysical shape of the earth is the fundamental component of the global sea level distribution. Global warming and ice-melt, although a reality, would not contribute to sea-level rise. Gravitational attraction of the earth plays a dominant role against sea level rise.”
“Geological processes are responsible of two types of major movements of the crustal block viz., uplift and subsidence. Hence, the relation of sea level and crustal motion is attributed to sea level drops when there is an uplift while it rises when there is subsidence.”
“Snay et al. (2016) have found large residual vertical velocities [land uplift], some with values exceeding 30 mm/yr, in southeastern Alaska. The uplift occurring here is due to present-day melting of glaciers and ice fields formed during the Little Ice Age glacial advance that occurred between 1550 A.D. and 1850 A.D.”
“Johansson et al. (2002) conducted research on a project BIFROST (Baseline Inferences for Fennoscandian Rebound Observations, Sea-level, and Tectonics) that combines networks of continuously operating GPS receivers in Sweden and Finland to measure ongoing crustal deformation due to glacial isostatic adjustment (GIA). They have found the maximum observed uplift rate 10 mm/yr for Fennoscandian region analyzing data between August 1993 and May 2000. Sella et al. (2007) and Lidberg et al. (2010) suggested that postglacial rebound continues today albeit very slowly wherein the land beneath the former ice sheets around Hudson Bay and central Scandinavia, is still rising by over a centimeter a year, while those regions which had bulged upwards around the ice sheet are subsiding such as the Baltic states and much of the eastern seaboard of North America.”
“Transgression commences when continental block undergoes subsidence with respect to continental shelf and abyssal plain, while regression occurs when this process is reverse i.e., when continental block is uplifted with respect to continental shelf and abyssal plain. Prograding delta system in low lying areas and other geologic events may cause local/relative sea-level fall as new sedimentary deposition advances as accretion pushing sea further down the coast irrespective of global warming and polar ice-melt.”
“Hence, both regional and local sea-level rise and fall in meter-scale is related to the geologic events only and not related to global warming and/or polar ice melt.”
“Prediction of 4–6.6 ft sea level rise in the next 91 years between 2009 and 2100 is highly erroneous.”
Share this...FacebookTwitter "
"Pope Francis’s encyclical on the environment has quickly made him one of the world’s most significant figures in the climate debate. His message was notable not just for its acceptance of mainstream climate science but also for its outright rejection of market logic.  Nowhere is this more clear than when he addresses the various emissions trading and carbon offsetting schemes that leave decisions such as whether to phase out coal power in the hands of the market. These “carbon markets”, he said, are a “ploy which permits maintaining the excessive consumption of some countries and sectors”. If only our politicians were able to see this as clearly as Pope Francis. As we approach the 2015 UN climate conference in Paris, carbon markets just won’t go away – even despite the fact market solutions actively hinder our ability to make serious emissions cuts. The first round of pre-Paris negotiations in Geneva in February produced a draft negotiating text that is littered with references to new and expanded market mechanisms. The market-based agenda was pushed by negotiators from the EU, US, Japan and Brazil and provoked an optimistic response from financial, fossil fuel and other industry interests at the recent Carbon Expo in Barcelona. Ahead of Paris, many will ask whether we are in for a repeat of the disastrous Copenhagen climate change conference in 2009. But given the current focus on market-based approaches, it is necessary to look at the record of the carbon markets that formed the basis of the agreement that a Paris deal will replace: the 1997 Kyoto Protocol. Kyoto was a landmark agreement that bound developed countries to reduce their greenhouse gas emissions by an average of 5% between 2008 and 2012 from 1990 levels. It also included a number of novel market instruments for meeting that goal – one of the most important of which was the Clean Development Mechanism. The CDM allows developed countries to substitute domestic efforts to combat climate change for emissions reductions generated by projects in developing countries. The operators of these projects, which can be anything from wind farms to rubbish dumps, are awarded “carbon credits” for each tonne of carbon they reduce compared to what would otherwise have occurred. The credits are then traded, bought and surrendered by governments that ratified Kyoto, or corporations covered by the EU’s Emissions Trading System, as an alternative to reducing their own emissions. We have carried out research, recently published in a special carbon offsetting edition of the journal Environment and Planning A, which explores some of the problems with the CDM. We used the Gujarat Fluorochemicals Limited industrial gas destruction facility in Gujarat, India, as a case study – it was the first of more than 7,000 registered CDM projects. Our findings demonstrate why governments should exclude carbon markets from international climate negotiations. Between 2005 and 2013, the GFL project was awarded more than 55m carbon offset credits for destroying a potent greenhouse gas known as HFC-23, a by-product of the refrigerant gases produced by the factory. Sales of the credits proved to be extremely lucrative for the company, bringing in more than half a billion US dollars and generating business for associated carbon trading industries. However, local communities surrounding the project weren’t so happy. They claim to have suffered from pollution from the GFL plant for many years and have had to put up resistance. Local villagers, GFL workers and activists from NGOs told us the air, soil and water pollution generated by the plant had harmed their health and agricultural output.  The CDM entrenched and exacerbated these problems as it encouraged the company to maximise the production of refrigerant gases that were causing the pollution in order to destroy HFC-23 and receive as many carbon credits as possible. The company was effectively profiting from local pollution in order to let richer nations of the hook for their own emissions. While working on this article we put these accusations to GFL but the company did not respond. This perversity benefited the European corporations that purchased the credits but was bad news for the climate. For example, EDF Energy, which made a pro-carbon market submission to the UK’s Energy and Climate Change Committee, surrendered more than 200,000 GFL offset credits. The purchases allowed the company’s fossil fuel power stations in the UK to pollute over their level of allocated by the EU, while at the same time EDF could justify its attempts to cultivate a “green” marketing image, such as sponsoring the 2012 London Olympics as “official sustainability partner”. Campaigns from NGOs such as Carbon Market Watch and Paryavaran Mitra resulted in the EU banning the use of HFC-23 offsets and the United Nations making some changes to rules governing carbon credits. However, the poor social and ecological impacts of the GFL project were the product of the economic imperatives that underpin carbon markets in general. Carbon markets are in fact designed to seek out cheap emissions reductions such as HFC-23 destruction over fundamental structural changes to energy systems away from fossil fuels and towards renewables. Researchers and activists have linked this profit-driven logic to the creative accounting, financial fraud, phantom emissions reductions and polluter subsidies that have riddled carbon markets, arguing they cannot be reformed and should be scrapped. Further, the negative impacts of CDM offset projects have not been restricted to large industrial projects like HFC-23 destruction, with projects from forestry to biogas and coal to wind, repeatedly being exposed as fuelling local conflicts in developing countries. Expanding protections for local communities and environments beyond the “boutique” schemes currently in place face strong structural barriers because they interfere with the profits of project developers or fossil fuel industries. As a result, the continuation, expansion or creation of new market mechanisms in the Paris agreement is likely to generate further damaging outcomes at offset projects, mostly in the Global South. At the same time, relying on carbon markets will work against the capacity of governments around the world to end the era of coal, oil and gas. Policies that benefit the already powerful and harm those most affected by climate change? Nothing could be further from Pope Francis’s message linking climate issues with development and global justice. Perhaps he’ll be the man to finally make inroads with the people that matter, as governments will be faced with a stark choice in Paris: continue with the failed market-based approach or plan a serious transition away from fossil fuels."
"
Share this...FacebookTwitterNo matter how hard climate-catastrophe obsessed alarmists attempt to beat out a little doom from the data, their results still fall far way short of their projections. Moreover, the modest warming the planet has seen over the recent decades is tied more to natural cycles.
One alarmist tweeted in response to one of my recent posts with a WoodForTrees chart showing a temperature rise over the past 40 years. His aim was to say: The temperatures are rising fast and are right on course with the models:

At first glance we see that the satellite data do show a warming trend over the past 40 years, and so the alarmists must be right – some might think.
But look at the chart more closely.
If you do, you’ll see that the global temperature over the past 40 years has risen from an anomaly of -0.2°C to +0.3°C, meaning a whopping 0.5°C over 40 years, which is 1.2°C per century.
When we put this in perspective, this is far lower than the than 4 to 6°C per century that the alarmists often like to have the public believe.
Putting this on a chart (I had to do a little rescaling):


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Chart: P Gosselin, using WoodForTrees data.
Of course the recent pause was interrupted by an El Nino event and the latest satellite data show that the global surface temperature is down to a mere anomaly of only 0.12°C:

Chart snipped from Weatherbell Saturday Summary, July 14, 2018.
Temperature is not the only magnitude that global warming alarmists have totally exaggerated. Another example mentioned earlier is Arctic sea ice, which has been expanding over the past decade, i.e. doing the opposite of what was forecast:

Al Gore’s hysterical projections of ice-free Arctic late summers are exposed as an absolute sham. 2018 uses a conservative projected value.
Today the doomsday scenarios and projections made 10 years ago have yet to show any signs of coming true. In fact, many scientists are projecting a cooling tendency ahead.
Share this...FacebookTwitter "
"Orangutans are often more popular on the internet than in their native forests. Online, their attractive faces, fluffy bodies and swinging abilities make them perhaps the most shareable of all the great apes. But back in Borneo and Sumatra, where local populations are more ambivalent about orangutans, the situation is less straightforward. The third annual International Orangutan Day was held in August: a celebration of all things orangutan which aimed to highlight their crisis and encourage public action. For 24 hours, orangutan conservation organisations filled Facebook and Twitter with images, trivia and calls to save the rainforests of Borneo and Sumatra – their only home. People donated to charities, signed petitions, liked, tagged, shared and retweeted content, posted supportive selfies and even organised local gatherings to mark the day.  This was just one of many digital entry-points that has made orangutan conservation an increasingly accessible, everyday affair. Today, one doesn’t need to gain a PhD, spend months in the jungle or stage Greenpeace-style confrontations to help save orangutans. Thanks to digital technology and social networking, ordinary members of the public can do their bit.  The dominant narrative portrays orangutans as being pushed to the brink of extinction by deforestation and the expansion of oil palm plantations. This is often illustrated by a colourful cast of both stereotypical characters – the majestic, handsome male, the loving mother and the cute baby – and individual personalities such as Budi and Jemmi, two orphans in Sumatra whose adventures have been avidly followed across Facebook, Twitter and their rescue centre’s website.  These charismatic creatures bring a powerful immediacy and reality to the dominant narrative. Through them, an account of environmental destruction and species loss is turned into a series of gripping stories and personal tragedies: the innocent babies who have lost their mothers, the formidable male left helpless by chainsaws, the “saved” victims in need of help.  Not simply animals or scientific specimens, these orangutans are the very faces of the rainforest – threatened by appropriately large, faceless villains. As such, they’re immensely powerful magnets of public affection, support and funding.  In the midst of all this, however, some other faces and voices remain hidden. Among them are the people who live alongside orangutans in Borneo and Sumatra.  Many orangutan conservation bodies work closely with local partners and communities. But these collaborations tend to receive far less attention in online conversations and popular perceptions of the orangutan “crisis”. And when local communities do appear in conservation material, they’re often cast as either victims of deforestation or as “ecologically noble” allies who simply need to be educated about conservation. But as any anthropologist would point out, real life is far more complicated than that. Even the most exotic groups have internal divisions, ambitions, political leanings and ethical dilemmas. Not everybody is an instinctive defender of the forest or subscriber to Western conservation values.  Indeed, many rural Borneans are understandably more concerned about obtaining development and guarding their livelihoods – from crop-raiding orangutans, for instance – than the rather vague idea of saving the environment. And as recent research has shown, humans and orangutans are not always natural bedfellows. Hunting and conflict-related killing have also contributed to the decline of orangutan populations in recent decades.  Such findings don’t make for easy reading, not least because they reveal the complex humanity of Bornean and Sumatran populations. Like orangutans, these rainforest dwellers also have a vital stake in the fate of their environment – but in ways that can challenge the black-and-white morality of the dominant conservation narrative.  Only a small minority of these voices are currently part of digital conversations about orangutan conservation. But if orangutan conservation goals are to be realised, these local faces and voices can’t be glossed over. Rather, they need to be more carefully integrated into the dominant narrative – while ideally helping to transform it."
"The next four years are going to be anomalously warm – even on top of regular climate change. That’s according to new research my colleague Sybren Drijfhout and I have just published.  We developed a new prediction system we call PROCAST (PROabilistic foreCAST), and used it to predict the natural variability of the climate system. This refers to how the climate varies naturally from warm to cool phases that last a few years at a time, and is separate from the long-term trend of anthropogenic global warming. PROCAST predicts a warm phase for the next few years. Our work, published in Nature Communications, is important as such forecasts help predict the chances of events like heatwaves or cold snaps months in advance, and it is now well established that anomalous climatic events have a direct human impact. For example, heatwaves lead to excess deaths in only a few weeks. During the 2003 European heatwave, a long drought caused UK wheat production to drop by 12%.  Tougher winters, meanwhile, can worsen respiratory infections, increasing pressure on health services and the supply of drugs. Indeed, consumption of flu vaccines can vary significantly depending on the weather conditions. In the UK, snowy conditions in winter 2010 were estimated to have cost the economy £690m a day, while natural gas consumption increased massively. Predicting these extreme climatic events up to a season in advance is therefore a priority, in order to allow early adaptation and cost-effective mitigation. Scientists have made some important breakthroughs in understanding and modelling the climate system, yet these have not yet been transferred into an ability to predict the climate from year to year. This inability has its roots in the deterministic chaos of the climate system, which has been popularised by the idea of the “butterfly effect” where the tiniest error in the estimation of the current weather might have significant consequences later. Despite these difficulties, major research centres and national meteorological services have embraced this challenge and a significant effort is currently going toward developing accurate predictions of year to year climate variations. At the core of this development each group and centre relies on its individual state-of-the-art climate model used to propagate into the future the current climate state. Unfortunately, because climate models are not perfect, we are still not able to efficiently predict the climate a few years in advance. This is where PROCAST comes in. Instead of relying on a single climate model, we combined a range of different climate models used in the context of the Coupled Model Intercomparison Project phase 5 (CMIP5). PROCAST can be quickly trained to build on the work already done by these models, which are already completed and freely available.  This has two obvious advantages. First, it removes any dependence on a single, possibly biased, model. But it also dramatically improves the speed of the predictions – a forecast that previously took a supercomputer an entire week now can be done on a laptop in a few hundredths of a second. To check if our predictions are accurate and reliable, we conducted a series of a posteriori predictions, or “hindcasts”. We found our system was both accurate (able to predict what actually happened in the future) and reliable (on average, it did not predict events that did not occur). Our study shows that, on top of the forced warming from climate change, natural variability will induce an anomalously warm phase of more than 0.02℃ for 2018, more than 0.03℃ for 2018-2019, and more than 0.01℃ for 2018-2022. These numbers, which can look unfamiliarly small, are in fact comparable in intensity to the typical rate of global warming experienced each year if averaged it over the past century (around 1℃ over 100 years roughly equals 0.01℃ every year). However it is important to acknowledge that the method does not only predict one given value, but a probability. This means that warm years are more likely than cold years for the period 2018-2022. Indeed our research showed that over the next two years it is 64% likely to be anomalously warm. In addition, over the course of the next five years PROCAST predicts a relative decrease in the likelihood of extreme cold years."
"
Share this...FacebookTwitterStefan Rahmstorf caught redhanded manipulating temperature charts
By Michael Krueger
(Text translated/edited by P. Gosselin)

Three days ago, climate researcher Stefan Rahmstorf published an article at his KlimaLounge blog on the hearing of Jewish climate scientist Nir Shaviv in the German Bundestag concerning the Climate Change Conference in Katowice.
Accuses Shaviv of presenting “outlandish theories”
 There he describes Shaviv as a “climate skeptic” with outlandish theories and who is courted by the fossil lobby and AfD Party. During the hearing, the German Left party even accused Shaviv of obviously being paid to publish climate-denialism. Stefan Rahmstorf went even further, claiming, “This is a targeted misleading of the layperson audience”. 
Just who is misleading whom, I would like to pursue here. 
The conflict between Jewish climate scientist Nir Shaviv and Stefan Rahmstorf dates back to 2003, when Stefan Rahmstorf wrote the following e-mail to his colleagues:
I feel another recent paper may require a similar scientific response, the one by Shaviv & Veizer (attached). …This paper got big media coverage here in Germany and I guess it is set to become a climate skeptics classic: …”
Since then, Shaviv has fallen out of favor with Stefan Rahmstorf.
Dissenters get labelled as right wingers
In the comment area of Mr. Rahmstorf’s article, some commentators — who were immediately labelled by other commenters as right wing spectrum — criticized that NASA’s temperature curve in Figure 5 was truncated in 2016, exactly when the last El-Nino pushed up the global temperature. Mr. Rahmstorf vehemently rejected the criticism.
In the article Mr. Rahmstorf refers to a link on how to create your own widget according to Figure 5, here the link. There the year 2017 is included and the curve is not cut off at 2016. Between 2016 and 2017 the global temperature dropped by 0.1°C, and in 2018 by a further 0.1°C.
Hide the decline
In the year 2016 we were at +1°C temperature anomaly according to NASA (a new record!), but today in the year 2018 only at 0.8°C. Mr. Rahmstorf obviously wanted to hide this by cleverly truncating at 2016, probably with the hope his lay public would not notice it?
Mr. Rahmstorf first showed the following Figure 5 in the article, which was truncated at 2016:

When the “deception” was discovered, he quickly changed Figure 5, without comment, and recorded the year 2017. Now the chart looks like this:

The year 2018 is still missing, which is currently only 0.8°C above the mean just before the end of the year, i.e. 0.1°C lower than 2017.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Poor correlation
With the chart he also tries to give the impression that there is a close relationship between CO2 rise and temperature rise. If one looks at the correlation coefficients, i.e. whether there is a linear relationship between CO2 and temperature rise, one can immediately see that between 1880-1970/80 there is only a moderate correlation between CO2 and temperature. It is around 0.6. A value of zero means no correlation, 1 means a perfect correlation. Only between 1980 and today does the correlation increase to around 0.9.
Thus one can say that actually only since 1980 does a good correlation exist.
To be correct, it has to be taken into account that other climatic factors also contribute to the rise in temperature and not just CO2 alone. In addition, in the recent geological past (around the last 1 million years), as evidenced by ice cores in the Antarctic and Arctic, it is always the temperature that has risen and then followed by CO2. 
So it may well be that even today the temperature increase precedes the CO2 increase and the CO2 increase is partly due to temperature, e.g. because less CO2 can be stored in warm seas. (Half of the CO2 remains in the air, the other half goes into the ocean). 
Natural factors kept hidden
Of course, Mr. Rahmstorf does not mention this in his article, in the belief nobody would notice. Or in other words, it’s about “deliberately misleading the lay audience”, and here not by Mr. Shaviv.
Mr. Rahmstorf’s supporters in the comments section obviously do not care whether Mr. Rahmstorf uses the methods which he accuses others of using. It is about deliberately discrediting others who have a different opinion and not of having a debate at factual level. The climate activists consider themselves scientifically and politically legitimized to force their policy on the opponents of opinion, and to do so by using smearing and violence if necessary. Sometimes a Jewish scientist gets placed in the “right-wing corner” and persons with a different opinion placed with the right wing AfD. The ends justify the means.
More misleading claims by Rahmstorf
In the following I would like to briefly go into further “deceptions” in Mr. Rahmstorf’s article. He writes:
30 years ago, in 1988, the American climate researcher James Hansen famously declared in the US Senate that the long predicted warming was now there and recognizable in the data.”
But Hansen was completely wrong with his 1988 scenarios, as we know today. See the following figure:

Furthermore ,Stefan Rahmstorf defends the hockey stick curve of his friend Michael Mann from 1998/99.
Busted hockey stick chart
Recent reconstructions would still show the same result. It should be noted that Mann’s 1998/99 hockey stick was truncated in 1980 because the proxy data showed no increase at the end of the time series. His colleague Briffa even truncated the chart in 1960. Used in place of the proxy data were weather data/temperatures from weather stations showing much larger rises than the proxy data averaged.
What follows is the the Briffa version where the proxy data are cut off at 1960 and replaced by data from weather stations and with the proxy data (green) up until the present.

The same was done with the more recent “reconstructions” mentioned by Mr. Rahmstorf.
When Mr. Rahmstorf was asked, he replied, claiming “these are well-known ‘talking points’ of the ‘climate sceptics’, and almost everything is wrong or misleading.”
Original article in German at Science Skeptical here.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe advocacy for widespread growth in renewable energy (especially wind, solar, and biomass) usage has increasingly become the clarion call of the anthropogenic global warming (AGW) movement.  And yet more and more published research documents the adverse effects of relying on renewables.

Image: Wasili Karbe, cropped from video here.
Over the course of the last year, at least 30 papers have been published in the peer-reviewed scientific literature detailing the fatuity of promoting renewable energy as a long-term “fix” for climate change mitigation.  A categorized list of these papers is provided below.
1. “More Renewables Mean Less Stable Grids” 
Schäfer et al., 2018    “Multiple types of fluctuations impact the collective dynamics of power grids and thus challenge their robust operation.”
(press release)   “More renewables mean less stable grids, researchers find …  [I]ntegrating growing numbers of renewable power installations and microgrids onto the grid can result in larger-than-expected fluctuations in grid frequency.”
2. Increasing Fossil Fuel Use (Natural Gas) Reduces Emissions More Than Increasing Wind/Solar Energy
Anderson et al., 2018     “Before considering the future, it is worth examining just how far we’ve already come without any federal CO2 regulation (for existing power plants) in the U.S. Figure 1 illustrates historical CO2 emissions and natural gas prices from 2005 through 2017 (estimated). During that period, emissions have declined from nearly 2.7 billion tons to approximately 1.9 billion tons (∼30%), while revealing a strong link to natural gas prices. To be sure, while other factors (such as renewable energy incentives) also had an impact, the clearest means by which to reduce CO2 emissions has been to reduce the cost of generating electricity with less CO2-emitting fuels (i.e., substituting natural gas for coal). So successful have market forces been under the existing regulatory framework to date that estimated 2017 CO2 emission levels are already at the CPP’s 2025 target(albeit without accounting for electricity demand growth between 2017 and 2025), well exceeding the AEO’s own Reference Case projections for 2025.”
Jewell et al., 2018     “Hopes are high that removing fossil fuel subsidies could help to mitigate climate change by discouraging inefficient energy consumption and leveling the playing field for renewable energy.Here we show that removing fossil fuel subsidies would have an unexpectedly small impact on global energy demand and carbon dioxide emissions and would not increase renewable energy use by 2030. Removing [fossil fuel] subsidies in most regions would deliver smaller emission reductions than the Paris Agreement (2015) climate pledges and in some regions global [fossil fuel] subsidy removal may actually lead to an increase in emissions, owing to either coal replacing subsidized oil and natural gas or natural-gas use shifting from subsidizing, energy-exporting regions to non-subsidizing, importing regions.”
3. Renewables Fail To Deliver: When Demand Is High, Generation Capacity Is Low
Cradden and McDermott, 2018     “Prolonged cold spells were experienced in Ireland in the winters of 2009–10 and 2010–11, and electricity demand was relatively high at these times, whilst wind generation capacity factors were low. Such situations can cause difficulties for an electricity system with a high dependence on wind energy.”
4. Renewable Energy Becomes More Costly The More It Is Deployed … Renewable Energy Expansion Ensures More Fossil Fuel Installation Is Necessary As Backup
Blazquez et al., 2018     “However, promoting renewables –in liberalized power markets– creates a paradox in that successful penetration of renewables could fall victim to its own success. With the current market architecture, future deployment of renewable energy will necessarily be more costly and less scalable. Moreover, transition towards a full 100% renewable electricity sector is unattainable. Paradoxically, in order for renewable technologies to continue growing their market share, they need to co-exist with fossil fuel technologies. … The paradox is that the same market design and renewables policies that led to current success become increasingly less successful in the future as the share of renewables in the energy mix grows. … Full decarbonization of a power sector that relies on renewable technologies alone, given the current design of these markets, is not possible as conventional technologies provide important price signals. Markets would collapse if the last unit of fossil fuel technologies was phased out. In the extreme (theoretical) case of 100 percent renewables, prices would be at the renewables marginal cost, equal to zero or even negative for long periods. These prices would not be capturing the system’s costs nor would they be useful to signal operation and investment decisions. The result would be a purely administered subsidy, i.e., a non-market outcome. This is already occurring in Germany as Praktiknjo and Erdmann [31] point out and is clearly an unstable outcome. Thus, non-dispatchable technologies need to coexist with fossil fuel technologies. This outcome makes it impossible for renewables policy to reach success, defined as achieving a specified level of deployment at the lowest possible cost. With volatile, low and even negative electricity prices, investors would be discouraged from entering the market and they would require more incentives to continue to operate.”
Marques et al., 2018     “The installed capacity of wind power preserves fossil fuel dependency. … Electricity consumption intensity and its peaks have been satisfied by burning fossil fuels. … [A]s RES [renewable energy sources] increases, the expected decreasing tendency in the installed capacity of electricity generation from fossil fuels, has not been found. Despite the high share of RES in the electricity mix, RES, namely wind power and solar PV, are characterised by intermittent electricity generation.  … The inability of RES-I [intermittent renewable energy sources like wind and solar] to satisfy high fluctuations in electricity consumption on its own constitutes one of the main obstacles to the deployment of renewables. This incapacity is due to both the intermittency of natural resource availability, and the difficulty or even impossibility of storing electricity on a large scale, to defer generation.  As a consequence, RES [renewable energy sources] might not fully replace fossil sources …  In fact, the characteristics of electricity consumption reinforce the need to burn fossil fuels to satisfy the demand for electricity. Specifically, the ECA results confirm the substitution effect between the installed capacity of solar PV and fossil fuels. In contrast, installed wind power capacity has required all fossil fuels and hydropower to back up its intermittency in the long-run equilibrium. The EGA outcomes show that hydropower has been substituting electricity generation through NRES [non-renewable energy sources], but that other RES have needed the flexibility of natural gas plants, to back them up. … [D]ue to the intermittency phenomenon, the growth of installed capacity of RES-I [intermittent renewable energy sources – wind power] could maintain or increase electricity generation from fossil fuels.  … In short, the results indicate that the EU’s domestic electricity production systems have preserved fossil fuel generation, and include several economic inefficiencies and inefficiencies in resource allocation. … [A]n increase of 1% in the installed capacity of wind power provokes an increase of 0.26%, and 0.22% in electricity generation from oil and natural gas, respectively in the long-run.”
5. Biofuels – Declared Carbon-Neutral Renewables By The EU – Increase Emissions More Than Coal 
Sterman et al., 2018     “[G]overnments around the world are promoting biomass to reduce their greenhouse gas (GHG) emissions. The European Union declared biofuels to be carbon-neutral to help meet its goal of 20% renewable energy by 2020, triggering a surge in use of wood for heat and electricity (European Commission 2003, Leturcq 2014, Stupak et al 2007). … But do biofuels actually reduce GHG emissions? … [A]lthough wood has approximately the same carbon intensity as coal (0.027 vs. 0.025 tC GJ−1 of primary energy […]), combustion efficiency of wood and wood pellets is lower (Netherlands Enterprise Agency; IEA 2016). Estimates also suggest higher processing losses in the wood supply chain (Roder et al 2015). Consequently, wood-fired power plants generate more CO2 per kWh than coal. Burning wood instead of coal therefore creates a carbon debt—an immediate increase in atmospheric CO2 compared to fossil energy—that can be repaid over time only as—and if— NPP [net primary production] rises above the flux of carbon from biomass and soils to the atmosphere on the harvested lands. … Growth in wood supply causes steady growth in atmospheric CO2 because more CO2 is added to the atmosphere every year in initial carbon debt than is paid back by regrowth, worsening global warming and climate change. The qualitative result that growth in bioenergy raises atmospheric CO2 does not depend on the parameters: as long as bioenergy generates an initial carbon debt, increasing harvests mean more is ‘borrowed’ every year than is paid back. More precisely, atmospheric CO2 rises as long as NPP [net primary production] remains below the initial carbon debt incurred each year plus the fluxes of carbon from biomass and soils to the atmosphere. … [C]ontrary to the policies of the EU and other nations, biomass used to displace fossil fuels injects CO2 into the atmosphere at the point of combustion and during harvest, processing and transport. Reductions in atmospheric CO2 come only later, and only if the harvested land is allowed to regrow.”
Fanous and Moomaw, 2018     “These nations fail to recognize the intensity of CO2 emissions linked to the burning of biomass. The chemical energy stored in wood is converted into heat or electricity by way of combustion and is sometimes used for combined heat and power cogeneration. At the point of combustion, biomass emits more carbon per unit of heat than most fossil fuels. Due to the inefficiencies of biomass energy, bioenergy power plants emit approximately 65 percent more CO2, per MWH than modern coal plants, and approximately 285 percent more than natural gas combined cycle plants. Furthermore, the Intergovernmental Panel on Climate Change (IPCC) states that combustion of biomass generates gross greenhouse gas (GHG) emissions roughly equivalent to the combustion of fossil fuels. In the case of forest timber turned into wood pellets for bioenergy use, the IPCC further indicates that the process produces higher CO2 emissions than fossil fuels for decades to centuries.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




6. Biofuels “Use More Energy At A Higher Cost” And Produce More Air Pollution Than Fossil Fuels
Richardson and Kumar, 2017     “A growing human population creates a larger demand for food products and makes conservation of resources and increased efficiency of agricultural production more vital. … These results conclude that feed production systems are more energy efficient and less environmentally costly than corn-based ethanol. … [A]ccording to the findings of this study, biofuels, derived for the purpose of producing energy with little environmental impacts, actually use more energy at a higher environmental cost than the alternative crop use. As technology stands now, in terms of energy and environmental sustainability, the benefits of switching land uses to the production of corn-based transportation biofuels are not as favorable as continuing to produce corn for feed/food consumption.”
Emery et al., 2017     “Although climate change mitigation and energy security policies are generally expected to be compatible with air pollution and health cost reductions (McCollum et al., 2013), there is evidence that first-generation alternative fuels such as corn ethanol lead to higher health costs due to air pollution than conventional fuels [gasoline]  (Hill et al., 2009). … We find that life-cycle non-GHG air pollutant emissions, particularly NOX [nitrous oxides] and PM [particulates], are higher for corn ethanol and other biofuel blends than conventional petroleum fuels. Emissions of volatile organic compounds (VOCs) and carbon monoxide (CO) increase by 9–50% per 100 km traveled for high-ethanol blends from corn grain and combined grain and stover feedstocks. NOX, PM [particulates], and SOX [sulfur dioxides] increase by 71–124% from corn grain and 56–110% from combined grain and stover, relative to conventional gasoline. Biodiesel blends show an increase of 1–11% (B20) and 4–55% (B100) in air pollution, with the largest increases in VOC [volatile organic compounds] and SOX [sulfur dioxides] emissions. … The total social costs of ethanol blends are higher than that of gasoline, due in part to higher life-cycle emissions of non-GHG pollutants and higher health and mortality costs per unit.”
7. Proximity To Wind Turbines Significantly Reduces Quality Of Life, Well-Being For Nearby Residents
Barry et al., 2018     “The findings indicate that residential proximity to wind turbines is correlated with annoyance and health-related quality of life measures. These associations differ in some respects from associations with noise measurements. Results can be used to support discussions between communities and wind-turbine developers regarding potential health effects of wind turbines.”
Krekel and Zerrahn, 2017     “We show that the construction of wind turbines close to households exerts significant negative external effects on residential well-being … In fact, beyond unpleasant noise emissions (Bakker et al., 2012; McCunney et al., 2014) and impacts on wildlife (Pearce-Higgins et al., 2012; Schuster et al., 2015), most importantly, wind turbines have been found to have negative impacts on landscape aesthetics (Devine-Wright, 2005; Jobert et al., 2007; Wolsink, 2007). … We show that the construction of a wind turbine within a radius of 4,000 metres has a significant negative and sizeable effect on life satisfaction. For larger radii, no negative externalities can be detected.”
Gortsas et al., 2017     “Infrasound, low frequency noise and soil vibrations produced by large wind turbines might disturb the comfort of nearby structures and residents. In addition repowering close to urban areas produces some fears to the nearby residents that the level of disturbance may increase. Due to wind loading, the foundation of a wind turbine interacts with the soil and creates micro-seismic surface waves that propagate for long distances and they are able to influence adversely sensitive measurements conducted by laboratories located far from the excitation point.”
8. “Renewable Energy Consumption Has A Negative Effect On Economic Growth”
Lee and Jung, 2018     “The results of the autoregressive distributed lag bounds test show that renewable energy consumption has a negative effect on economic growth, and the results of a vector error correction mechanism causality tests indicate a unidirectional relationship from economic growth to renewable energy consumption. The empirical results imply that economic growth is a direct driver expanding renewable energy use. In terms of policy implications, it is best for policy makers to focus on overall economic growth rather than expanding renewable energy to drive economic growth. … [O]ur result suggests that renewable energy policy should be implemented when the real GDP is enough large to overcome the negative impact from renewable energy, because the causality from economic growth to renewable energy consumption in the long run as one of our result is caused by both low productivity of renewable energy production and expansion of government-led renewable energy.”
9. Research: 100% Renewable Energy Is “Unattainable” In Reality – Decarbonization Is “Arguably Reckless”
Clack et al., 2017   “The scenarios of [Jacobson et al., 2015, “Low-cost solution to the grid reliability problem with 100% penetration of intermittent wind, water, and solar for all purposes”] can, at best, be described as a poorly executed exploration of an interesting hypothesis. The study’s numerous shortcomings and errors render it unreliable as a guide about the likely cost, technical reliability, or feasibility of a 100% wind, solar, and hydroelectric power system. It is one thing to explore the potential use of technologies in a clearly caveated hypothetical analysis; it is quite another to claim that a model using these technologies at an unprecedented scale conclusively shows the feasibility and reliability of the modeled energy system implemented by midcentury. From the information given by [Jacobson et al., 2015], it is clear that both hydroelectric power and flexible load have been modeled in erroneous ways and that these errors alone invalidate the study and its results.”
Heard et al., 2017     “While many modelled scenarios have been published claiming to show that a 100% renewable electricity system is achievable, there is no empirical or historical evidence that demonstrates that such systems are in fact feasible. Of the studies published to date, 24 have forecast regional, national or global energy requirements at sufficient detail to be considered potentially credible. We critically review these studies using four novel feasibility criteria for reliable electricity systems needed to meet electricity demand this century. [N]one of the 24 studies provides convincing evidence that these basic feasibility criteria can be met. Of a maximum possible unweighted feasibility score of seven, the highest score for any one study was four. … On the basis of this review, efforts to date seem to have substantially underestimated the challenge and delayed the identification and implementation of effective and comprehensive decarbonization pathways. … To date, efforts to assess the viability of 100% renewable systems, taking into account aspects such as financial cost, social acceptance, pace of roll-out, land use, and materials consumption, have substantially underestimated the challenge of excising fossil fuels from our energy supplies. This desire to push the 100%-renewable ideal without critical evaluation has ironically delayed the identification and implementation of effective and comprehensive decarbonization pathways. We argue that the early exclusion of other forms of technology from plans to decarbonize the global electricity supply is unsupportable, and arguably reckless. … The realization of 100% renewable electricity (and energy more broadly) appears diametrically opposed to other critical sustainability issues such as eradication of poverty, land conservation and reduced ecological footprints, reduction in air pollution, preservation of biodiversity, and social justice for indigenous people.”
10. Wealthy Countries Foist Social-Environmental Disruption From Wind, Solar Onto Poorer Countries 
Shakespear, 2018     “A trend was found, whereby developing countries tend to suffer the most socio-environmental disruption from material extraction for solar-panels and wind-turbines while exhibiting lower implementation of these technologies, and developed countries show opposite effects. This indicates that EUE [ecologically unequal exchange] effects constitute global solar-panel and wind-turbine systems, and that developed countries displace socio-environmental disruption from energy innovation onto developing countries. … [I]mplementation of solarpanels and wind-turbines tended to be the most prevalent within countries that suffer the least environmental and socio-economic consequences from the extraction of materials for these technologies. This effectively means that efforts to increase sustainability in relatively powerful countries via renewable energy implementation exacerbates unsustainable practices in the relatively less powerful countries that extract the minerals for these technologies.”
11. Wind Power Harming The Environment, Biosphere – Destroying Habitats, Endangering Rare Species 
Millon et al., 2018  (full paper)   “Wind turbines impact bat activity, leading to high losses of habitat use … Island bats represent 60% of bat species worldwide and the highest proportion of terrestrial mammals on isolated islands, including numerous endemic and threatened species (Fleming and Racey, 2009). … We present one of the first studies to quantify the indirect impact of wind farms on insectivorous bats in tropical hotspots of biodiversity. Bat activity [New Caledonia, Pacific Islands, which hosts nine species of bat] was compared between wind farm sites and control sites, via ultrasound recordings at stationary points [A bat pass is defined as a single or several echolocation calls during a five second interval.] The activity of bent winged bats (Miniopterus sp.) and wattled bats (Chalinolobus sp.) were both significantly lower at wind turbine sites. The result of the study demonstrates a large effect on bat habitat use at wind turbines sites compared to control sites. Bat activity was 20 times higher at control sites compared to wind turbine sites, which suggests that habitat loss is an important impact to consider in wind farm planning. …  Here, we provide evidence showing that two genera of insectivorous bat species are also threatened by wind farms.  … To our knowledge, this is one of the first studies quantifying the indirect negative impact of wind turbines on bat activity in the tropics. … The lower attractiveness of the foraging habitat under wind turbines, both in a tropical and in a temperate climate, indicates that the indirect impact of wind turbine is a worldwide phenomenon.”

Lopucki et al., 2018      “Living in habitats affected by wind turbines may result in an increase in corticosterone levels in ground dwelling animals… Environmental changes and disturbance factors caused by wind turbines may act as potential stressors for natural populations of both flying and ground dwelling animal species. The physiological stress response results in release of glucocorticoid hormones. … The common vole showed a distinct physiological response − the individuals living near the wind turbines had a higher level of corticosterone [physiological stress affecting regulation of energy, immune reactions]. … This is the first study suggesting impact of wind farms on physiological stress reactions in wild rodent populations. Such knowledge may be helpful in making environmental decisions when planning the development of wind energy and may contribute to optimization of conservation actions for wildlife.”
Ferrão da Costa et al., 2018     “According to a review by Lovich and Ennen (2013), the construction and operation of wind farms have both potential and known impacts on terrestrial vertebrates, such as: (i) increase in direct mortality due to traffic collisions; (ii) destruction and modification of the habitat, including road development, habitat fragmentation and barriers to gene flow; (iii) noise effects, visual impacts, vibration and shadow flicker effects from turbines; (iv) electromagnetic field generation; (v) macro and microclimate change; (vi) predator attraction; and (vii) increase in fire risks. … Helldin et al. (2012) also highlighted that the development of road networks associated with wind farms could promote increased access for traffic related to recreation, forestry, agriculture and hunting. The consequence, particularly on remote places, is the increase in human presence, affecting large mammals via significant disturbance, habitat loss and habitat fragmentation. These negative effects are expected to be particularly relevant for species that are more sensitive to human presence and activities, such as large carnivores. Large carnivores, such as the wolf, bear, lynx or wolverine, tend to avoid areas that are regularly used by humans and—especially for breeding—show a preference for rugged and undisturbed areas (Theuerkauf et al. 2003; George and Crooks 2006; May et al. 2006; Elfstrom et al. 2008; Sazatornil et al. 2016), which are often chosen for wind power development (Passoni et al. 2017). … Results have shown that the main impact of wind farms on wolves is the induced reduction on breeding site fidelity and reproductive rates. These effects, particularly when breeding sites shift to more unsuitable areas, may imply decreasing survival and pack viability in the short term.”
Watson et al., 2018     “The global potential for wind power generation is vast, and the number of installations is increasing rapidly. We review case studies from around the world of the effects on raptors of wind-energy development. Collision mortality, displacement, and habitat loss have the potential to cause population-level effects, especially for species that are rare or endangered.”
Aschwanden et al., 2018    “The extrapolated number of collisions was 20.7 birds/wind turbine (CI-95%: 14.3–29.6) for 8.5 months. Nocturnally migrating passerines, especially kinglets (Regulus sp.), represented 55% of the fatalities. 2.1% of the birds theoretically exposed to a collision (measured by radar at the height of the wind turbines) were effectively colliding.”
Naylor, 2018     “While wind energy provides a viable solution for emission reductions, it comes at an environmental cost, particularly for birds. As wind energy grows in popularity, its environmental impacts are becoming more apparent. Recent studies indicate that wind power has negative effects on proximate wildlife. These impacts can be direct—collision fatalities—and indirect—habitat loss (Fargione et al. 2012; Glen et al. 2013). Negative impacts associated with operational wind farms include collision mortalities from towers or transmission lines and barotrauma for bats. Habitat loss and fragmentation, as well as avoidance behavior, are also consequences resulting from wind farm construction and related infrastructure. The potential harm towards protected and migratory bird species are an urgent concern, especially for wind farms located along migratory flyways. In terms of mortality, wind turbines kill an estimated 300,000 to 500,000 birds, annually (Smallwood 2013). The high speed at which the fan wings move and the concentration of turbines create a gauntlet of hazards for birds to fly through. … [T]he height of most wind turbines aligns with the altitude many bird species fly at (Bowden 2015). Birds of prey— raptors—are of particular concern because of their slow reproductive cycles and long lifespans relative to other bird species (Kuvlesky 2007).”
Lange et al., 2018     “Results from our surface water extractions and aerial surveys suggest that the wind farm has negatively affected redheads through altered hydrology and disturbance displacement. Our surface water extraction analysis provides compelling evidence that the local hydrology has been greatly affected by the construction of the wind farm. … Our results suggest the occurrence of direct habitat loss and disturbance displacement of redheads from the wind farm along the lower Texas coast. Although our study was directed solely toward redheads, it is likely that this wind farm has affected other species that use these wetlands or migrate along the lower Texas coast (Contreras et al. 2017). Studies in Europe investigating the effects on waterfowl by wind turbines have reported similar results, showing that turbines have likely compromised foraging opportunities for waterfowl through disturbance displacement (Larsen and Madsen 2000).”
Chiebáo, 2018     “I studied the large-scale movements of white-tailed eagles during the dispersal period, assessing their space use in relation to the distribution of existing and proposed wind farms across Finland. I found that a breeding pair holding a territory closer to an installation has a lower probability to breed successfully when compared to a pair from a territory lying farther away. Such lower probability may in part reflect a harmful interaction between the eagles and wind turbines in the form of collision mortality, to which the adults appear to be particularly vulnerable during the breeding season. Regarding the post-fledging period, I found that the probability of a young eagle approaching a wind turbine decreases sharply as the turbine is installed at increasing distances from the nest.”
Frick et al., 2017     “Large numbers of migratory bats are killed every year at wind energy facilities. However, population-level impacts are unknown as we lack basic demographic information about these species. We investigated whether fatalities at wind turbines could impact population viability of migratory bats, focusing on the hoary bat (Lasiurus cinereus), the species most frequently killed by turbines in North America. Using expert elicitation and population projection models, we show that mortality from wind turbines may drastically reduce population size and increase the risk of extinction. For example, the hoary bat population could decline by as much as 90% in the next 50 years if the initial population size is near 2.5 million bats and annual population growth rate is similar to rates estimated for other bat species (λ = 1.01). Our results suggest that wind energy development may pose a substantial threat to migratory bats in North America. If viable populations are to be sustained, conservation measures to reduce mortality from turbine collisions likely need to be initiated soon. Our findings inform policy decisions regarding preventing or mitigating impacts of energy infrastructure development on wildlife.”
Hammerson et al, 2017      “Conservationists are increasingly concerned about North American bats due to the arrival and spread of the White-nose Syndrome (WNS) disease and mortality associated with wind turbine strikes. To place these novel threats in context for a group of mammals that provides important ecosystem services, we performed the first comprehensive conservation status assessment focusing exclusively on the 45 species occurring in North America north of Mexico. Although most North American bats have large range sizes and large populations, as of 2015, 18–31% of the species were at risk (categorized as having vulnerable, imperiled, or critically imperiled NatureServe conservation statuses) and therefore among the most imperiled terrestrial vertebrates on the continent.”
Vasilakis et al., 2017     “Numerous wind farms are planned in a region hosting the only cinereous vulture population in south-eastern Europe. We combined range use modelling and a Collision Risk Model (CRM) to predict the cumulative collision mortality for cinereous vulture under all operating and proposed wind farms. Four different vulture avoidance rates were considered in the CRM.  Cumulative collision mortality was expected to be eight to ten times greater in the future (proposed and operating wind farms) than currently (operating wind farms), equivalent to 44% of the current population (103 individuals) if all proposals are authorized (2744 MW). Even under the most optimistic scenario whereby authorized proposals will not collectively exceed the national target for wind harnessing in the study area (960 MW), cumulative collision mortality would still be high (17% of current population) and likely lead to population extinction.”
12. Wind Turbine Blade Waste Disposal A Growing Ecological Nightmare
Liu and Barlow, 2017     “Wind energy has developed rapidly over the last two decades to become one of the most promising and economically viable sources of renewable energy. Although wind energy is claimed to provide clean renewable energy without any emissions during operation, but it is only one side of the coin. The blades, one of the most important components in the wind turbines, made with composite, are currently regarded as unrecyclable.  With the first wave of early commercial wind turbine installations now approaching their end of life, the problem of blade disposal is just beginning to emerge as a significant factor for the future. … The research indicates that there will be 43 million tonnes of blade waste worldwide by 2050 with China possessing 40% of the waste, Europe 25%, the United States 16% and the rest of the world 19%.”
Ramirez-Tejeda et al., 2017     “Globally, more than seventy thousand wind turbine blades were deployed in 2012 and there were 433 gigawatts (GW) of wind installed capacity worldwide at the end of 2015. Moreover, the United States’ installed wind power capacity will need to increase from 74 GW to 300 GW3 to achieve its 20% wind production goal by 2030.  … The wind turbine blades are designed to have a lifespan of about twenty years, after which they would have to be dismantled due to physical degradation or damage beyond repair. … Estimations have suggested that between 330,000 tons/year by 2028 and 418,000 tons/year by 2040 of composite material from blades will need to be disposed worldwide. That would be equivalent to the amount of plastics waste generated by four million people in the United States in 2013. This anticipated increase in blade manufacturing and disposal will likely lead to adverse environmental consequences. … Despite its negative consequences, landfilling has so far been the most commonly utilized wind turbine blade disposal method. …  Landfilling is especially problematic because its high resistance to heat, sunlight, and moisture means that it will take hundreds of years to degrade in a landfill environment. The wood and other organic material present in the blades would also end up in landfills, potentially releasing methane, a potent greenhouse gas, and other volatile organic compounds to the environment.”
Share this...FacebookTwitter "
"Road traffic accidents are the number one cause of death among 15 to 29-year-olds. If no action is taken, it is predicted that road traffic will kill as many as 1.9m people worldwide per year by 2030. Add to this the negative impacts of greenhouse gas emissions, air and noise pollution, chronic diseases such as heart disease or diabetes and rising levels of obesity, and a future full of cars looks bleak indeed.  These are the concerns underpinning European Mobility Week – an annual campaign, which began in 2002 – to promote sustainable forms of urban transport. This year, more than 1,700 local authorities from 42 different countries play host to a range of public events such as bicycle masses, talks and seminars about green mobility patterns, walk-to-school initiatives and many other public activities to support the uptake of sustainable and active travel. Over the past few decades, most cities around the globe have been shaped by the car. The majority of our public spaces have been transformed into endless flows of traffic, to better accommodate our dependence on this form of transport. As the number of people living in urban areas continues to grow, so too will the number of cars on the roads. There is a serious risk that this type of car-centred urbanisation will become unsustainable, and damage living standards for all. As a result, governments are becoming increasingly committed to controlling the number of conventionally-fuelled cars on the roads. To complete the transition from a heavily car-dominated society to a resource-efficient one, cities will need to achieve a more equal “modal share” – that is, city-dwellers need to be encouraged to take up alternative modes of transport in greater numbers. As a part of this effort, hundreds of cities in Europe and around the world – from Barcelona, to Brussels, to Istanbul – will encourage motorists to give up their automobiles for 24 hours, typically by closing their central streets to cars, as part of World Car-Free Day. About half of all car trips in countries like the UK, the Netherlands, and the US are fewer than five miles long. Replacing cars with other modes of transport for these short journeys would be a colossal step in the right direction. To this end, policy-makers, transport planners and traffic engineers have a variety of stick and carrot measures to make car use undesirable or unnecessary.  The stick measures are often regulatory; designed to force people to reduce car usage. These mechanisms range from congestion charges, toll roads, parking levies, traffic calming and road restrictions to fuel taxes, vehicle excise duty and even expensive car ownership permits.  The carrots are often soft measures, which give car users the options they need to be able to change their travel behaviour on a voluntary basis. One example is to make additions and improvements to alternative infrastructure, such as bus and rail services. But they can also include things such as the provision of cycle routes, pedestrianisation, priority bus lanes and other special rights-of-way.  Hybrid public transport modes and cheaper fares also help, as do initiatives for buying alternatively-fuelled cars and tools or information to help people practice smarter and more fuel-efficient driving, which makes the most of advanced vehicle technologies, when car use cannot be avoided. The sharing economy has stepped in, too, with ride sharing apps and websites like BlaBlaCar and iThumb and more than 900 dedicated public bicycle programmes worldwide.  Events like car-free days are important reminders of the steps that need to be taken to ensure safe and sustainable urban development. We need to use all these tools, and more, to meet the travel needs of the present without compromising the ability of future generations to enjoy liveable cities."
"The National Trust is planning to plant 20 million trees over the next decade as part of efforts to achieve net zero emissions by 2030. The organisation made the announcement, which it says will cost £90m-100m, on Thursday to mark its 125th anniversary.  By the end of the decade, it says the new trees and natural regeneration of woods will cover more than 18,000 hectares (44,000 acres), an area one and a half times the size of Manchester. It will mean that 17% of the land the National Trust looks after will be wooded, up from 10%. The focus will be on planting on farmland – including in upland areas – that the trust owns, rather than in country estates, but the director general, Hilary McGrady, said the National Trust would be working with farmers to deliver the targets. The charity says a similar level of tree cover is needed nationwide to meet government targets to cut greenhouse gas emissions. Other initiatives announced by the trust include maintaining peat bogs, investing in more renewable energy and cutting its carbon footprint. Efforts will focus on the National Trust’s own pollution, but McGrady acknowledged the impact of visitors, many of whom travel by car to the organisation’s properties. She said the trust was measuring the impact of visitor emissions and suggesting ways to encourage more sustainable transport. The charity, which was founded in the 19th century to protect and care for natural and historic places, plans to work with other organisations to create “green corridors” that connect people in urban areas to nature. “As Europe’s biggest conservation charity, we have a responsibility to do everything we can to fight climate change, which poses the biggest threat to the places, nature and collections we care for,” McGrady said. “People need nature now more than ever. If they connect with it then they look after it. And working together is the only way we can reverse the decline in wildlife and the challenges we face due to climate change.” "
"I can quite happily go to a zoo just to watch the chimpanzees. It is not that the other animals are boring, but that chimps are so fascinating. In recent days the media has reported their drinking of alcohol, their ability to vary smiles and a US move to designate them as endangered. So, what makes chimps so attractive to scientists and the general public alike? From a scientific point of view they are our closest
genetic relative. We share more than 98% of the same DNA and had a common evolutionary ancestor only 5-7m years ago. So chimpanzee biology and behaviour can tell us much about ourselves. And of course chimps look like us (as do most primate species). Due to these similarities, chimps are one of the most studied primate species of all time. Chimps were first described approximately 300 years ago and ever since they have appeared in books, films, TV adverts and have even flown in space ships. Their importance in understanding human evolution cannot be denied and this further adds to their high profile within human societies. But during my childhood, chimps were portrayed on the TV as loveable clowns: just think of the Tarzan films or adverts for PG Tips. However, in my opinion there is something else in the human condition that leads us to be infatuated with chimps. And it is not that they are the most cute and cuddly looking animal. That title goes to the giant panda. Instead it is to do with our human propensity to be voyeurs: we love to watch other people. Interesting people are those who put on public display their loves, hates and passions. The problem is there is only so much staring and gawping that interesting people (celebrities aside) will tolerate. Chimps provide an alternative outlet for our fascination with others. Chimps are passionate, scheming, aggressive animals. In many ways they seem to represent the human condition in its most elemental state. When we observe them we are looking at ourselves. But they act without the restrictions that polite society puts on us. And in zoos on wildlife documentaries, groups that are used to being watched by humans are not shy about expressing their desires, be they sexual or otherwise. In other words they are a voyeur’s dream. To watch a group of chimpanzees is to watch a soap opera unfold before your eyes, but without the pretence of time passing quickly. They live life in the fast lane. Just as one example, chimpanzees are 100 to 1,000 times more aggressive than humans. Even TV soap operas do not show this much action happening in short spaces of time. If a male chimp is angry with someone or something then he lets them know in no uncertain terms. This happens not just in terms of bashing things, but also through pronounced facial expressions such as bearing teeth. I think we humans are jealous of chimps because they can vent their aggressive feelings without societal disapproval. A friend of mine use to work on a project observing captive giant pandas, the world’s most marketed animal. But despite their cuteness they were boring to watch, just eating bamboo, sleeping, defecating every half hour and mating once a year. I challenge anyone to spend a whole day observing them. They just have too little behavioural diversity, expressing interesting behaviours such as aggression or sex at very low frequencies. Chimps also have a caring side. Once they have attacked and beaten another individual, they will soon go over and give them a hug to prevent this negative interaction spiralling out of control. They show empathy towards sick members of their group. Older individuals are tolerant of the capers of the younger individuals.  They live in a loving society where individuals hold hands, hug and kiss in the manner of people from Latin countries. And their partiality to a spot of alcohol has now generated much excitement. Even when chimps are sitting around doing nothing, as a human observer you sense that something interesting could happen at any second. They never seem to have vacant expressions even when they are resting. They appear to be scheming away, working out how to manipulate other members of their group for food, friendship or sex. Chimps give the impression of being intelligent without the need to be making and using tools to procure food – just sitting down will do. Finally, chimps display remarkably strong personalities. Just one day of watching a group in a zoo is enough for you to determine their characters. Some are bold, others timid. Some are very agitated, whereas others seem serene. It is this blend of personalities that creates interesting group dynamics and the script for their soap operatic lives. We are addicted to chimps because they let us spy on their lives, lives that are so rich and amazing that one, whose name was Flo, even had her obituary published in the Sunday Times newspaper."
"In 2019, millions of Californians experienced a wildfire safety blackout, some for nearly a week at a time, as the troubled utility company Pacific Gas & Electric and other investor-owned utilities grappled with replacing one devastating disaster with another, comparatively manageable one. 2019 was not an anomaly, but the beginning of a new way of life for many California residents. While “de-energization” for fire safety has been state policy for more than a decade, it had never before been used on such a mass scale. According to utility experts, politicians and PG&E, customers can expect many more years of blackouts to come, as fire risk in California’s hills only increases.  “Wildfire blackouts could be California’s new normal for the next 10 to 30 years, or even longer,” the Senate energy committee chair, Lisa Murkowski, told a hearing on utility and fire safety in December. In stark contrast to recent years past, California’s 2019 wildfire season was relatively mild: just 732 structures destroyed, compared with the tens of thousands and dozens killed in 2017 and 2018. The crisis of 2019’s fire season was less the fires themselves, and more the actions taken that were meant to prevent fires from igniting in the first place. Intended as a measure of last resort, California power utilities conducted nine public safety power shutoffs in the fall of 2019 in an effort to reduce wildfire risk in hot, windy weather conditions – and to reduce liability costs to utilities. Those costs following deadly wildfires in 2017 and 2018 fires linked to equipment belonging to PG&E, drove the company to file for bankruptcy in 2019, and to reconsider how to manage the grid during future fire weather events. Bill Johnson, PG&E’s CEO, has at different times claimed his utility – the largest in the state – would resort to blackouts for the next three, five or 10 years. The southern California investor-owned utility San Diego Gas and Electric “is the poster child for safety”, said Michael Wara, the director of the climate and energy policy program at Stanford’s Woods Institute for the Environment. SDG&E has been de-energizing its lines during fire weather events for more than a decade. “Why is it that PG&E thinks it’s going to be able to replicate what San Diego’s done and do even better over a larger area in less time? It’s not impossible, but it’s an enormously challenging task,” said Wara. PG&E’s post-de-energization reports to the state utilities commission showed a number of hazards after each event, from damaged lines and conductors to fallen trees. After its largest shutoff at the end of October, the utility noted more than 100 individual hazards. “Would every piece of system damage that they noted have caused a fire? Probably not. But some of them probably would have,” said Wara. “[Public safety power shutoff policy] is so unpopular, and it impacts so many people, I worry we will be pushed to be overly optimistic about other potential avenues for creating safety.”  Despite the widespread shutoffs, PG&E equipment was still tied to igniting several fires in the fall of 2019, including the Kincade fire in Sonoma county, which destroyed 352 structures and burned more than 77,000 acres. “It’s not clear to me that the system is that much safer than 2017,” Wara said. “The safety that we had this season and the absence of fires during these dangerous wind events was due to the fact that the wires weren’t hot.” Fire risk in the California hills will rise precipitously through the middle of the century, according to a 2018 report for California’s Fourth Climate Change Assessment, with big new hazards in areas where high voltage transmission lines run through the mountains and connect California to clean energy out of state. In the face of that rising danger, the public safety power shutoff is a utility’s fastest and cheapest means of reducing fire risk. “I want to assure you that we do not expect an annual repeat of what we went through this fall. We are working hard now to narrow the scope and duration of future safety shutoffs and minimize their customer impact as much as possible,” Johnson told the Senate hearing. But he also took credit for the less destructive 2019 fire season: “PG&E’s [public safety power shutoff] program achieved its singular goal: there was no loss of life during wildfires in 2019.” Not everyone in California is convinced that success is PG&E’s to claim. Will Abrams and his family lost their home in the 2017 Tubbs fire that destroyed more than 5,600 structures and killed 22 people. They were forced to evacuate again from the 2019 Kincade fire. “The fact that our firefighters went in and did an amazing job, learned from prior fires and got these more under control shouldn’t be a PG&E victory lap,” said Abrams. “I would argue that the shutoffs provide a disincentive for other mitigation. Because if you can just pull the power, you don’t have to do the vegetation management and the microgrids and all the other stuff you need to do.” All of that “other stuff” is enormously expensive and labor-intensive and will take years to complete. And the costs of installing stronger poles and trimming trees will not just be borne by the company’s profits. CEO Johnson has said ratepayers will not be on the hook for the costs associated with the company’s bankruptcy, but they will have to foot some of the bill for grid upgrades and maintenance. Customers saw their rates increase again on 1 January, though not as much as the utility would have liked. PG&E customers already pay some of the highest prices in the country for power, and those prices will only increase.  PG&E expects to reinforce 7,100 miles of line in fire risky areas in the next 12 to 14 years. To date, the utility has completed just 129 miles. To some, PG&E’s bankruptcy initially seemed like an opportunity to restructure the troubled utility in favor of creating a more reliable and resilient grid to weather future climate change – one that wouldn’t necessitate extensive annual blackouts. “This bankruptcy represents a closing window of opportunity to change course so that not only is PG&E a proven safe and reliable provider of energy but so the state has a way forward to address wildfires and climate change,” said Abrams, who has filed motions in the case advocating for more significant restructuring and transparency in the process. But the California governor, Gavin Newsom, rejected PG&E’s plan to leave bankruptcy, calling it “woefully short” of reorganizing the company “to provide safe, reliable, and affordable service to its customers”. In 2018, the state legislature passed a bill aimed at heading off that bankruptcy but providing new funding sources for fire-burdened utilities and requiring new wildfire safety plans – which ultimately included de-energization. In 2019, at Newsom’s urging, the legislature passed new legislation that created a wildfire liabilities fund, and placed a June deadline for PG&E to leave bankruptcy. Critics argued that both bills were essentially bailouts for investor-owned utilities. “I voted no on both of them – I thought that they shifted financial responsibility on to Californians and neglected to raise public safety to the paramount priority,” said assembly member Marc Levine. “De-energization was a massive failure.” While California’s fires have been orders of magnitude more destructive than the blackouts, they touch just a fraction of the millions who had their lights turned off in 2019 – making de-energization a hotter problem for politicians and PG&E to solve.They have just a few months before the next fire season begins. Three new pieces of legislation introduced in the state legislature’s first week back in 2020 aimed at addressing a troubled PG&E, regardless of the bankruptcy’s resolution. A new proposal from Levine would install a public administrator from the state regulatory commission for a period of six months to oversee all the functions of a floundering investor-owned utility. “We need to stop treating PG&E like a business to keep solvent and more like a convicted felon that needs to be held accountable,” said Levine.  Assembly member Kansen Chu authored two bills directly aimed at de-energization which would authorize state regulators to determine if utilities should compensate customers after each power shutoff, and require utilities to support customers who rely on power for medical needs. “There’s so much ageing infrastructure, but that’s not going to be fixed very soon,” Chu said. “In the meantime I want them to be more responsible and more careful with their shutoffs because the first shut off was a disaster.” But leaving the power on in the meantime, said Chu, “is probably more devastating”."
"Thousands of climate protesters flooded the streets of Australian state capitals on Friday night as fire authorities warned of another dangerous night ahead in four states. Firefighters in New South Wales, Victoria, South Australia and Western Australia continued to battle fires, with gusty winds expected to create hazardous firefighting conditions late into the night.  A male firefighter in his 20s suffered burns to his face, ears and hands in the Snowy Valley region where fierce winds were pushing the fires in different direction. Temperatures reached above 40C in some parts of NSW during the day, and strong south-westerly winds with gusts of up to 90km/h were expected to move up the coast later in the night, the Bureau of Meteorology said. “The change is critical,” the BoM’s Graham Reader said. “The winds really peak around the change and the directions shift is very sharp and particularly gusty.” The change was not expected to reach Sydney until early on Saturday morning. By 8pm on Friday, fire authorities in NSW and Victoria had started to issue emergency warnings as southerly winds fanned the fires. In Victoria, 21 fires were burning out of control by late afternoon, with more than 1.3m hectares burned so far this bushfire season. On Friday afternoon the state’s premier, Daniel Andrews, said 286 residential properties had been damaged or destroyed in the state. Andrews praised the response of Victorians to evacuation orders and other warnings. “People have, by and large, followed the advice given, and that is one of the reasons why I’m able to say to you tonight, despite this unprecedented fire activity, we have nobody who is unaccounted for, we have no further people that have died, and we have no further communities that have been cut off.” But he warned that “all of those things can change” and urged the public to remain vigilant. People living in the state’s alpine region were told they had until 7.50pm on Friday to safely evacuate. “Evacuation after this time is considered life threatening,” an emergency warning said. Relief centres were set up in Bonegilla, Myrtleford and Wangaratta for evacuees. In the alpine towns of Bright and Harrietville, authorities had placed satellite phones, baby formula, food, nappies and torches in containers in case the two areas were cut off. State authorities were concerned fires in the north of Victoria could merge with others burning near the NSW border. In NSW, where 66 of the 137 fires burning were not contained, the Rural Fire Service warned the forecast wind change “could cause erratic fire behaviour over many firegrounds”. Conditions in several areas of the Snowy Mountains, and in the southern highlands around Bundanoon, were particularly challenging. Conditions in the state were expected to ease on Saturday. In Western Australia, a fire jumped one of the the main freeways south of Perth, threatening lives and homes just 30km south of the city centre. Residents were told to immediately head south if they could. Fires in South Australia had burned through more than a third of Kangaroo Island, killing two people and injuring 22 fire personnel. The town of Parndana in the centre of the island was again spared on Friday after being threatened twice by flames. In the evening more than 10,000 climate change protesters filled the streets in Sydney, Melbourne, Brisbane, Adelaide and Canberra, with anger directed towards the Australian prime minister, Scott Morrison. Sydney protester Ambrose Hayes, 14, said people were “fed up” with Morrison, who she said was not acting on the climate crisis. Morrison rejected criticism of his government’s climate record in a series of interviews on Thursday and Friday. Conceding climate change had played a role in the fires, he told one radio station his government did not want “job-destroying, economy-destroying, economy-wrecking targets and goals” on climate change. Can barely capture the whole crowd.Huge climate/bushfires/dump ScoMo protest outside Sydney town hall.Has shut down George and Park Street intersection. #SackScoMo #AustraliaFires pic.twitter.com/KYK12k7e94 He said any such efforts to cut emissions “won’t change the fact that there have been bushfires or anything like that in Australia”. In a conference call with MPs, Morrison banned backbench MPs from doing international media, after Liberal MP Craig Kelly caused an outcry by denying the link between climate change and bushfires on the UK’s Good Morning Britain show. On Friday it emerged a senior News Corp employee had accused the company of “misinformation” and diverting attention from climate change during the bushfire crisis in an all-staff email addressed to the company’s executive chairman. The email accused News Corp papers, including the Australian, the Daily Telegraph and the Herald Sun, of misrepresenting facts and spreading misinformation to focus on arson as the cause of the bushfires, rather than climate change. The company defended its coverage and said the employee, Emily Townsend, had submitted her resignation in December. The Bureau of Meteorology confirmed on Thursday that 2019 was the country’s hottest since records began in 1910. The year was also been the country’s driest since rainfall records began in 1900. The bureau said 2019 had also been the worst year for the Forest Fire Danger Index – a metric used to assess the risk of dangerous bushfire weather. That record goes back to 1950."
"We will likely never know how life on Earth started. Perhaps in a shallow sunlit pool. Or in the crushing ocean depths miles beneath the surface near fissures in the Earth’s crust that spewed out hot mineral-rich soup. While there is good evidence for life at least 3.7 billion years ago, we don’t know precisely when it started.  But these passing aeons have produced something perhaps even more remarkable: life has persisted. Despite massive asteroid impacts, cataclysmic volcano activity and extreme climate change, life has managed to not just cling on to our rocky world but to thrive.  How did this happen? Research we recently published with colleagues in Trends in Ecology and Evolution offers an important part of the answer, providing a new explanation for the Gaia hypothesis. Developed by scientist and inventor James Lovelock, and microbiologist Lynn Margulis, the Gaia hypothesis originally proposed that life, through its interactions with the Earth’s crust, oceans, and atmosphere, produced a stabilising effect on conditions on the surface of the planet – in particular the composition of the atmosphere and the climate. With such a self-regulating process in place, life has been able to survive under conditions which would have wiped it out on non-regulating planets. Lovelock formulated the Gaia hypothesis while working for NASA in the 1960s. He recognised that life has not been a passive passenger on Earth. Rather it has profoundly remodelled the planet, creating new rocks such as limestone, affecting the atmosphere by producing oxygen, and driving the cycles of elements such as nitrogen, phosphorus and carbon. Human-produced climate change, which is largely a consequence of us burning fossil fuels and so releasing carbon dioxide, is just the latest way life affects the Earth system.  While it is now accepted that life is a powerful force on the planet, the Gaia hypothesis remains controversial. Despite evidence that surface temperatures have, bar a few notable exceptions, remained within the range required for widespread liquid water, many scientists attribute this simply to good luck. If the Earth had descended completely into an ice house or hot house (think Mars or Venus) then life would have become extinct and we would not be here to wonder about how it had persisted for so long. This is a form of anthropic selection argument that says there is nothing to explain. Clearly, life on Earth has been lucky. In the first instance, the Earth is within the habitable zone – it orbits the sun at a distance that produces surface temperatures required for liquid water. There are alternative and perhaps more exotic forms of life in the universe, but life as we know it requires water. Life has also been lucky to avoid very large asteroid impacts. A lump of rock significantly larger than the one that lead to the demise of the dinosaurs some 66m years ago could have completely sterilised the Earth. But what if life had been able to push down on one side of the scales of fortune? What if life in some sense made its own luck by reducing the impacts of planetary-scale disturbances? This leads to the central outstanding issue in the Gaia hypothesis: how is planetary self-regulation meant to work?  While natural selection is a powerful explanatory mechanism that can account for much of the change we observe in species over time, we have been lacking a theory that could explain how the living and non-living elements of a planet produce self-regulation. Consequently the Gaia hypothesis has typically been considered as interesting but speculative – and not grounded in any testable theory. We think there is finally an explanation for the Gaia hypothesis. The mechanism is based on “sequential selection”, a concept first suggested by climate scientist Richard Betts in the early 2000s. In principle it’s very simple. As life emerges on a planet it begins to affect environmental conditions, and this can organise into stabilising states which act like a thermostat and tend to persist, or destabilising runaway states such as the snowball Earth events that nearly extinguished the beginnings of complex life more than 600m years ago.  If it stabilises then the scene is set for further biological evolution that will in time reconfigure the set of interactions between life and planet. A famous example is the origin of oxygen-producing photosynthesis around 3 billion years ago, in a world previously devoid of oxygen. If these newer interactions are stabilising, then the planetary-system continues to self-regulate. But new interactions can also produce disruptions and runaway feedbacks. In the case of photosynthesis it led to an abrupt rise in atmospheric oxygen levels in the “Great Oxidation Event” around 2.3 billion years ago. This was one of the rare periods in Earth’s history where the change was so pronounced it probably wiped out much of the incumbent biosphere, effectively rebooting the system. The chances of life and environment spontaneously organising into self-regulating states may be much higher than you would expect. If fact, given sufficient biodiversity, it may be extremely likely. But there is a limit to this stability. Push the system too far and it may go beyond a tipping point and rapidly collapse to a new and potentially very different state. This isn’t a purely theoretical exercise, as we think we may able to test the theory in a number of different ways. At the smallest scale that would involve experiments with diverse bacterial colonies. On a much larger scale it would involve searching for other biospheres around other stars which we could use to estimate the total number of biospheres in the universe – and so not only how likely it is for life to emerge, but also to persist. The relevance of our findings to current concerns over climate change has not escaped us. Whatever humans do life will carry on in one way or another. But if we continue to emit greenhouse gasses and so change the atmosphere, then we risk producing dangerous and potentially runaway climate change. This could eventually stop human civilisation affecting the atmosphere, if only because there will not be any human civilisation left. Gaian self-regulation may be very effective. But there is no evidence that it prefers one form of life over another. Countless species have emerged and then disappeared from the Earth over the past 3.7 billion years. We have no reason to think that Homo sapiens are any different in that respect. This article was updated on July 10 to add the reference to Richard Betts."
"
Share this...FacebookTwitterThe time in running out for the purveyors of the “rapidly accelerating sea level rise” scare story.
Especially IPCC alarmist scientists like spreading scare stories about sea level rise, and how it’s accelerating.
So far global CO2 emissions have in fact continued to climb at a rate that is defined as the “business as usual” emissions scenario RCP8.5, which means a sea level rise of up to 97 cm by 2100, according to the most recent IPCC projections:

IPCC AR5 sea level rise for 4 different emissions scenarios. So far CO2 emissions have been on the worst case path.
Could even be 90 by 2060!
And some experts even suggest that sea level rise may occur even far more quickly. For example the Pacific Islands Ocean Observing System (PACIOOS) here wrote. “Recent observations and projections suggest that 3 feet (90 cm) or more of sea level rise could occur earlier than 2100 and even as early as year 2060.”
Meanwhile some time ago alarmist climate site Skeptical Science here wrote: “Overall, the range of projected sea level rise by 2100 is 75 to 190 cm.”
Of course, hysterical sites like Skeptical Science don’t publish anything without first injecting a good dose of hyperbole. So we will put them down for 1200 mm of sea level rise by 2100.
Gap between reality and IPCC about to become glaring
The following chart depicts the IPCC alarmists, like Skeptical Science, projection (1200 mm), the conservative IPCC AR5 business as usual estimate (800 mm), the projected linear trend of the satellite measurements trend (320 mm), and the projected trend of what the tide gauges –  i.e. where people actually live – have been observing (160 mm):


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Observed data show no signs that sea levels are rising as quickly as IPCC models have been suggesting. IPCC alarmist scenarios are about 7 times higher than what is observed by tide gauges. Chart: notrickszone.com.
Acceleration not showing up in the observations
Naturally the alarmists always claim that the sea level rise rate will be modest at first, but that it will really begin to take off in a decade or two once the oceans warm and expand, and Greenland and Antarctica start to melt in earnest.
But there’s only one problem: So far there hasn’t been any noteworthy acceleration seen in neither the satellite data or tide gauge data.
Moreover, Greenland and Arctic ice volume have been increasing. And so has Antarctica. Of course we do see a paper from time to time with alarmist scientists statistically waterboarding some rate increase out of the sea level data, but almost always the increase gets traced back to natural variation.
Time is running out – for the alarmists
What’s clear is that we will certainly know what sea level rise is doing in 15 years, ca. 2033. by then the IPCC claimed acceleration should making its debut in earnest.
However, if the tide gauges don’t show some real, major acceleration by then, from 1.6 mm/year to say 4 mm/year, then it will be safe to say that any IPCC of over 70 cm was nothing but wolf-crying.
We’re watching carefully. The days of the sea level scare story are numbered.
Share this...FacebookTwitter "
"A new scientific paper proposing a scenario of unstoppable climate change has gone viral, thanks to its evocative description of a “Hothouse Earth”. Much of the media coverage suggests that we face an imminent and unavoidable extreme climate catastrophe. But as a climate scientist who has carried out similar research myself, I am aware that this latest work is a lot more nuanced than the headlines imply. So what does the hothouse paper actually say, and how did the authors draw their conclusions? First, it’s important to note that the paper is a “perspective” piece – an essay based on knowledge of the scientific literature, rather than new modelling or data analysis. Leading Earth System scientist Will Steffen and his 15 co-authors draw on a diverse set of literature to paint a picture of how a chain of self-reinforcing changes might potentially be initiated, eventually leading to very large climate warming and sea level rise.  One example would be the thawing of Arctic permafrost, which releases methane into the atmosphere. As methane is a greenhouse gas, this means the Earth retains more heat, causing more permafrost to thaw, and so on. Other possible self-reinforcing processes include the large-scale die-back of forests, the melting of sea ice, or the loss of ice sheets on land. Steffen and colleagues introduce the term “Hothouse Earth” to emphasise that these extreme conditions would be outside those that have occurred over the past few hundred thousand years, which have been cycles of ice ages with milder periods in between. They also present an alternative scenario of a “Stabilised Earth” where these changes are not triggered, and the climate remains similar to now. The authors make the case that there is a level of global warming which is a critical threshold between these two scenarios. Beyond this point, the Earth System might conceivably become set on a pathway that makes the extreme “hothouse” conditions inevitable in the long term. They argue – or perhaps speculate – that the process of irreversible self-reinforcing changes could in theory start at levels of global warming as low as 2°C above pre-industrial levels, which could be reached around the middle of this century (we are already at around 1°C). They also acknowledge large uncertainty in this estimate, and say that it represents a “risk averse approach”. A key point is that, even if the self-perpetuating changes do begin within a few decades, the process would take a long time to fully kick in – centuries or millennia. Steffen and colleagues support their suggestion of a threshold at 2°C through reference to previously-published scientific work. These include other review papers which themselves drew on wider literature, and an “expert elicitation” study in which scientists were asked to estimate the levels of global warming at which “tipping points” for these key climate processes might be passed (I was one of those consulted). The authors argue that 2°C can still be avoided if humanity takes concerted action to reduce its warming effect on the climate. In a similar way that the “Hothouse Earth” scenario involves huge changes in the climate system with multiple effects of one process leading to another, the concerted global action to avoid 2°C would, they suggest, also involve huge changes in the human system, again with several fundamental steps leading from one change to another. Personally, I found this an interesting and important think piece that was well worth reading. But since this is not actually new research, why is it getting so much coverage? I suspect that one reason is the use of the vivid “Hothouse Earth” term at a time when everyone’s talking about heatwaves. Another is that it’s clearly a dramatic narrative, and not surprisingly this has led to some sensationalist articles. With some exceptions, much of the highest-profile coverage of the essay presents the scenario as definite and imminent. The impression is given that 2°C is a definite “point of no return”, and that beyond that the “hothouse” scenario will rapidly arrive. Many articles ignore the caveats that the 2°C threshold is extremely uncertain, and that even if it were correct, the extreme conditions would not occur for centuries or millennia. Some articles do however emphasise the more tentative nature of the work, and some push back against this overselling of the doomsday scenario, arguing that provoking fear or despair is counterproductive.  One thing that strikes me about the scientific literature on “tipping points” is that there are a lot of review papers like this that end up citing the same studies and each other – indeed, my colleagues and I wrote one a while ago. There is a great deal of interesting, insightful research going on using theoretical methods and calculations with large approximations. However, we have yet to see an equivalent level of research in the highly-complex Earth System Models which generate the kind of detailed climate projections used for addressing policy-relevant questions by the Intergovernmental Panel on Climate Change (IPCC). Steffen and colleagues have made a good start at addressing such questions, going as far as they can on the basis of the existing literature, but their essay should motivate new research to help narrow down the huge uncertainties. This will help us see better whether “Hothouse Earth” is our destiny, or mere speculation. In the meantime, awareness of the risks – however tentative – can still help us decide how to manage our impact on the global climate."
"
Share this...FacebookTwitter406 Guinea Delegates Make Junket To Katowice Climate Conference
By Die kalte Sonne(German text translated/edited by P. Gosselin)
The climate conference in Katowice is in full swing and a variety of carbon-saving initiatives are being discussed: eating less meat, less heating and less air travel. In the latter case, of course, the conference itself is taking on great proportions of absurdity.
It would have been easy to turn the conference into an internet meeting with live streaming and online commenting. But then the long wonderful “business trip”  with all its receptions, daily allowances and pre-Christmas meetings with fellow climate rescuers would have been missed. This time more than 22,000 participants have made their way to Poland, most comfortably by plane. The largest delegations to the Climate Conference came from Africa.
Guinea is sending 406 delegates this year, the Democratic Republic of Congo is there with 237 participants, and the Ivory Coast is sending 191 compatriots to Poland. The list of participants is available on the homepage of the conference as a pdf and is 1084 pages long.
The list of delegates from Guinea starts on page 239 and goes to page 273. There are 406 names on it. In the previous year in Bonn the group from Guinea was even larger, 86 participants more, with a delegation size of close to 500 people.
The Ivory Coast has also “severely restricted” participation this year. At the COP23 in Bonn, the country was present with 492 participants. Maybe Bonn was a more attractive destination than Katowice? Eco-business.com has compiled the numbers of climate conferences in recent years in an Excel spreadsheet, which is available here.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The obvious question: what is supposed to be the task of all these delegates? And who will pay for the travel costs? Let’s start with the first question, the role of the delegates. Here we can really only speculate, since we do not know the individual daily program of the participants. A look at the affiliation of the participants gives a first idea. Among other things, there are several employees of the Friedrich Ebert Foundation from Guinea.
There are also journalists, a large number of NGO employees, representatives of the water authority, etc. It remains unclear who really provides added value here, and who is only traveling as a tourist or on a daily travel allowance. Incidentally, this does not only apply to Guinea, but to all delegates.
Is Question 2 maybe easier to answer? Who pays the travel expenses and daily allowances? On the website of the Bonn COP23 we get some information on this:

Daily subsistence allowance disbursement and travelDelegates from Parties eligible for funding are kindly requested to contact the daily subsistence allowance (DSA) office located in the temporary structure in the foyer of the main building of the World Conference Center Bonn as of Monday, 30 April 2018. Delegates attending the pre-sessional meetings of the regional groups are invited to come to the DSA office in room H-030 in the Altes Abgeordnetenhochhaus building on the United Nations Campus from Tuesday, 24 April to Friday, 27 April. Please bring your passport, electronic flight ticket confirmation and boarding pass(es). After receiving clearance from the DSA office, delegates can proceed to the bank to collect their DSA.”

So there is a group of participants who are eligible for flight, accommodation and daily allowance. All you have to do is go to a booth at the conference with your passport and plane tickets, and then there’s cash from the bank. It can be assumed that the participants of most African countries are fully financed by the UN.
In view of the good daily allowances and travel opportunity, the incentive to participate in the climate conferences is great. The COP24 has its own website for ‘Funded Delegates Accommodation’. The minimum stay in Katowice is 12 days. What is the usual UN daily allowance? According to the ICSC website, Poland receives $194 per day outside Warsaw. For a stay of 12 days, that’s $2,328 per person. In Bonn, it was $272 per day in the previous year. This may explain the slight decline in the number of interested parties this year.
Is COP24 really only about climate?
Share this...FacebookTwitter "
"Australia’s unforgiving, unrelenting and unprecedented fires have demonstrated so clearly that the climate doesn’t recognise tricky “Kyoto carryover” accounting and doesn’t care for juvenile finger pointing at other countries. With a warming climate, this brutal summer is a preview of what will become a regular occurrence in our lifetimes. More and more Australians realise that climate change is a clear and present threat. Our only chance to maintain our standard of living, and our economy, is if all countries rapidly decarbonise. Many are committed to this, Australia is not. We cannot expect global progress if we ourselves aren’t prepared to at least pull our weight, let alone show any leadership. Yet, we have a prime minister who looks into the camera and speaks to a people in survival mode and deep trauma and waves away our responsibility. He claims that we are responsible for just 1.3% of global carbon dioxide emissions, as if we are irrelevant. Australia has never been irrelevant and we certainly aren’t now. Even though Scott Morrison’s logic for climate inaction has been debunked many times, let’s do it again, for the sake of letting the PM, his climate denier cronies and fossil fuel lobby puppet masters know they will be held accountable for their lies and negligent inaction. Australia is the 14th largest emitter out of 208 countries. If all countries with emissions under a “measly” 2% were lumped together we’d together be responsible for almost as much annual emissions as China and India put together. The physics of the climate system doesn’t care about political boundaries. Does Germany not matter because it’s responsible for (slightly) less than 2%, or does it matter because it’s part of the EU, responsible for 9.4% of emissions? How about if we divide China into 56 countries of 25 million people, each with emissions half of Australia’s – would that let them off the hook? Australia has the highest emissions per capita of all major nations. The average Australian has four times the carbon footprint of the average global citizen, significantly due to our unusually high reliance on coal for electricity, the poor energy efficiency of our vehicles and buildings and the high domestic emissions from coal and gas extraction and processing. China and India haven’t yet peaked their emissions – unsurprising given their stage of development – but both are decoupling emissions from development such that their average citizen will never have the carbon footprint the average Australian has now. The “too small to matter” argument is logically absurd, but it is also morally bankrupt and economically reckless. We all know that throwing one piece of litter out the window wouldn’t ruin the environment, but if all did we’d soon be surrounded by rubbish. How about voting? It is a foundation of our democracy that nobody’s voice is so small as to be meaningless. Likewise, if any one taxpayer stopped paying tax we all know it wouldn’t make a measurable difference to the government’s bottom line, but if everyone stopped paying tax it would smash consolidated revenue. So when did we become a nation of shirkers? We’ve always punched above our weight. A young Australia was immensely proud of the troops committed to the first world war, even though the Diggers comprised less than 1% of the Allied Powers. We are only 0.3% of the global population but are gutted whenever we’re not near the top of the Olympic medal tally. Carbon accounting standards push responsibility for the coal and gas we export onto the final customers, but now that we understand the negative consequences of the associated emissions, the argument “if they didn’t buy from us, they’d buy from someone else” feels shamefully like the drug dealer’s defence. Including these emissions more than triples our carbon footprint. Our prime minister claims we are doing our bit, however a close reading of the government’s most recent projections shows that the Department of the Environment expects us to make no progress on reducing emissions through this decade – and that’s assuming the LNG sector doesn’t grow and that we reach 51% renewables in the National Electricity Market, which will be unwelcome news to at least a couple of ministers. The projections also heroically assume that there are no methane leaks from the entire LNG sector, and while they give us credit for planting trees, preventing bushfires and protecting land from clearing, there’s no accounting for the massive emissions of the bushfires burning right now. The UN Environment Program recently announced that global emissions need to reduce by 7.6% every year for a decade to keep warming below 1.5C. With no emissions reductions projected, it’s no wonder that Australia’s climate policies were recently ranked dead last among 57 nations. Meanwhile, other countries are embracing the challenge. In November I visited a cement factory in Belgium that is trialling a low-cost technology – originally developed in Australia – for decarbonising cement manufacture. Globally, the cement sector is responsible for around 8% of emissions, as growing developing countries urbanise. In Essen, in Germany’s Ruhr Valley, I saw a technology that allows power-hungry aluminium smelters to operate well (and increase profits) in renewable-dominated grids. The technology was first developed in Gladstone and partly Australian-owned before being sold offshore. In nearby Duisburg, I visited ThyssenKrupp, a major German industrial company with a commitment to net-zero carbon emissions by 2050. The company has embarked on an ambitious plan to decarbonise steel production, also responsible for around 8% of global emissions, with the ultimate goal of replacing coal with hydrogen. ThyssenKrupp is also developing technology to combine “waste” gases with “green” hydrogen – hydrogen produced with renewable energy – to synthesise chemicals such as methanol and ammonia, providing a pathway to lowering emissions from aviation and agriculture. As these economies wean themselves off coal the demand for hydrogen will skyrocket. With the potential to harness vast quantities of low-cost renewable energy, Australia is well placed to become an energy superpower in a decarbonised global economy. None of the major industrial companies I visited in Europe sees decarbonisation through a sacrifice lens. There’s no talk of “economy wrecking targets”. Rather, having accepted that the economy must be decarbonised, they are rushing to seize a competitive advantage. Meanwhile, Australia is a world away, in every sense. A rich, talented, capable nation is being held back by a lack of honesty and a lack of imagination – a nation held back by the vested interests of those who profit from the extraction and sale of gas and coal. Our prime minister is paralysed, unable to acknowledge that fossil fuel emissions are changing the climate, and that the changing climate is hurting Australians. Until his government stands up to the vested interests and starts telling the truth, Morrison’s authority will shrink ever smaller – as will Australia’s position in the world and our nation’s future prospects. • Simon Holmes à Court is senior adviser to the Climate and Energy College at Melbourne University"
"
Share this...FacebookTwitter• CO2 emissions from termites are more than double human emissions from fossil fuels.


Image sources:  New York Times, 1982,   Zimmerman et al., 1982

• Termite populations have been observed expanding rapidly in recent decades.


Image Source: Grace, 2006

Image Source: Buczkowski and Bertelsmeier, 2017

• CO2 emissions from soil is 9 times greater than human CO2 emissions.


Image: press release for Carey et al., 2017

• Deserts are shrinking as the Earth greens and soil area expands.

Venter et al., 2018      “Over the past three decades, 7.5 million km2 (55%) of non-forest biomes in sub-Saharan Africa underwent significant net gains in woody plant cover. This is more than triple the 2.2 million km2 (16%) significant decrease in woody plant cover, confirming local-scale studies indicating increases in WPE [woody plant encroachment] over the last century. … These results confirm global greening trends, thereby bringing into question widely held theories about declining terrestrial carbon balances and desert expansion.”
Munier et al., 2018     “On average, all vegetation types have experienced greening over the last two decades at rates ranging from 0.026 m2m−2yr−1 for winter crops to 0.042 m2m−2yr−1 for coniferous forests. Coniferous forests are mainly greening in temperate regions and show the largest area affected by high positive trends. By contrast, grasslands are greening at a moderate average rate, but since they cover almost half of the total vegetated area, the grassland area affected by high trend values is greater than for any other vegetation type but coniferous forests. … In the tropical zone, evergreen forests and grasslands are rapidly greening (see Table 4), which seems to be related to rising CO2 in the atmosphere [Zhu et al., 2016]. On the contrary, in high latitudes of the Northern Hemisphere where coniferous forests are dominating, Zhu, Z. et al. [2016] suggested that changes in the vegetation dynamics are mainly driven by climate change.”
Brandt et al., 2017     “Here we used a passive microwave Earth observation data set to document two different trends in land area with woody cover for 1992–2011: 36% of the land area (6,870,000 km2) had an increase in woody cover largely in drylands, and 11% had a decrease (2,150,000 km2), mostly in humid zones. Increases in woody cover were associated with low population growth, and were driven by increases in CO2 in the humid zones and by increases in precipitation in drylands, whereas decreases in woody cover were associated with high population growth.”
Bastin et al., 2017     “We show that in 2015, 1327 million hectares of drylands had more than 10% tree-cover, and 1079 million hectares comprised forest. Our estimate is 40 to 47% higher than previous estimates, corresponding to 467 million hectares of forest that have never been reported before. This increases current estimates of global forest cover by at least 9%.”

Question
If termite populations and soil-terrain area have been rapidly
growing in recent decades, and these sources emit 2 and 9 times
more CO2 into the atmosphere than humans do via fossil fuel
combustion respectively, why is it assumed that an increase in
human CO2 emission is 100% responsible for the increase in
atmospheric CO2 concentration?
Share this...FacebookTwitter "
"China recently announced plans to build a 5,300 km railway  linking the Atlantic with the Pacific, cutting through the heart of the Amazon jungle in Brazil and Peru. Environmental groups are concerned that the railway will threaten sensitive ecosystems, wildlife and indigenous peoples. Indeed on the face of it, this would be a disaster for conservation in the most biologically rich place on Earth. But is a train line in fact the lesser of two evils? If the alternative is more roads, then yes it is. Roads bring access to previously remote areas – and consequently bring down a cascade of problems on tropical forests. Logging, mining, and hunting result in the destruction of forests, all paving the way for their complete conversion to agriculture. Indeed, in the Amazon 95% of deforestation occurs within 5km of a road. Train lines on the other hand are usually state-controlled and more easily regulated. Therefore land speculation is much more difficult around railways than roads. The proposed line will cost an estimated US$10 billion to build and will reduce the cost of shipping oil, iron ore, soya, beef and other commodities from Brazil and Peru to Asian markets. With the promise of investment from China the venture has gained considerable traction, with the leaders of each country signing a memorandum on the project. So it seems there is a good chance the railway will go ahead. China recently lifted a ban  on beef from Brazil, and China’s beef imports are likely to increase by 50% (770,000 tonnes) over the next five years. Opposition to the rail proposal is therefore relatively futile, as it is reasonable to assume that supply links between China and Latin America will continue to increase in one way or another, transporting goods by rail or by road.  The problem of the ever-expanding beef industry is thus not the proposed railway, but the policies that fail to prevent deforestation across the Amazon basin. Therefore, environmental groups should be advocating the best possible route for the railway, rather than blocking the plans – and subsequently paving the way for more road building. So what are the potential problems of a railway and how can they be avoided? Reports suggest that the proposed route could increase access to remote tribes living in voluntary isolation throughout the forests of Peru’s Madre de Dios region. This area is also among the most species-rich places on Earth: home to more than 10,000 species of plants, 600 species of birds and 200 mammal species. In addition, the railway is likely to pass through Brazil’s Cerrado, a unique area of tropical woodland and grassland which provides key habitat for iconic and threatened species including the maned wolf, giant anteater and Spix’s macaw. Unfortunately, previous mega-infrastructure developments in the Amazon such as the Trans-Amazonian Highway, and the Belo Monte dam were implemented with little consideration for the impact on nature and local people, so these areas could be threatened by the construction of a railway. But the railway is still just a line on a map. In fact the approximate route can be achieved by following existing roads and passing through land that has already been cultivated for the majority of the way. And this can easily be seen from Google Earth. There is almost no need for the train line to pass through any virgin forest. Even in the critical part of Peru, the Inter-Oceanic Highway already passes along the eastern portion of the Madre de Dios, and this area has already suffered from land speculation, mining and small-scale agriculture throughout its length. To meet the demand of export channels west of Brazil without the train line, this road would need expansion, increasing the likelihood of the area falling foul to the complete deforestation as seen around nearly all other major highways across the Amazon basin. If Latin American governments want this railway to have negligible impact on their precious forest resources, they can achieve that – with advice from environmental voices and proper investment in best practices from the planning stage all the way through to the management of the railway. The precise route of the railway is yet to be determined, so there is still time for the environmental community to help to minimise the impact of an inter-continental railway across South America."
"The scientists responsible for the “doomsday clock” moved it 30 seconds closer to midnight – the symbolic point of total catastrophe for humanity and the planet – at the beginning of 2018. The minute hand now hovers ominously at two minutes to 12, the closest point it has ever been (matching the previous peak of 1953 – the height of the Cold War).  This judgement is a reflection of the multiple threats we face as a species, the most urgent being nuclear war and climate change. The former has loomed over humanity for decades. But the latter emergency has only become apparent relatively recently (to the extent that some people and powers even deny that it is a problem). Yet the scientific consensus is clear and alarming. Unless we manage to limit global warming this century to 2°C, then we are in devastating, civilisation threatening trouble.  We’ll need many things to help combat this emergency: technological innovation and scientific and engineering advances which allow us to harness renewable energies. It will also require new patterns of working and living in more sustainable ways. And I think we will also need something that is both subtler and yet perhaps more profound than these revolutions: a new vision of nature itself. Over the past few centuries, various perspectives on nature have dominated public discourse – generally to the detriment of the environment. The first is the view that humankind has “dominion” over the Earth – that we rule over the planet in some consequential sense. This in itself is not necessarily problematic. It is conceivable that this could be aligned with an ethos of responsible and careful stewardship. But this “dominion” perspective has been widely allied with a mechanistic view of nature that views it as devoid of any intrinsic worth, identity, and purpose beyond its instrumental value to human beings.  The result is a dominant ideology which regards the natural world primarily as a resource that humans are free to plunder at will. This perspective has surely played a pivotal role in our planetary emergency.  But although much damage has already been done, I still believe we could redeem ourselves and set our relationship on a better path if we could develop an alternative vision – of which many can be found across human history and culture.  I’ve recently encountered a wealth of these through my research, which focuses on “untranslatable” words which relate to well-being. Such words are significant, as they represent ideas and practices which have been overlooked or under-appreciated in one’s own culture or time period, but have been recognised by another culture or era. These include visions of nature which have long been neglected in favour of the dominant ideology outlined above. A case in point is the idea of “natura naturans”. Albert Einstein was once asked whether he believed in God, and replied: “I believe in Spinoza’s God, who reveals himself in the orderly harmony of what exists – not in a God who concerns himself with the fates and actions of human beings.”  Baruch Spinoza, born in Amsterdam in 1632, was a pioneer of rationalism and helped lay the foundations for the Enlightenment. He was a controversial figure in his day – with his works placed on the Catholic Church’s List of Prohibited Books – mainly because he was accused by critics of promulgating atheism.  But his philosophy was more nuanced than simply being a direct rejection of the sacred. Rather, he is now seen as one of the first modern advocates of a perspective known as pantheism. This is the idea that God and the cosmos are indivisible – one and the same. To explain this idea, he deployed the Latin phrase “natura naturans” – nature naturing. God is the dynamic process and manifestation of creation itself, nature unfurling in all its glory. Since then, many thinkers have aligned themselves with a pantheistic perspective, even if many have dispensed with the notion of a theistic deity. In this modern sense of the term, the cosmos itself is regarded as sacred or precious in some way, as per Einstein’s reference to “the orderly harmony of what exists”.  Many contemporary scientists and philosophers share this view. They may not believe in God, per se, but the awe the universe inspires in them does appear to come close to religious devotion. For instance, the prominent atheist Richard Dawkins has spoken approvingly of “Einstein’s God”, which he describes as “the laws of nature which are so deeply mysterious that they inspire a feeling of reverence”.  This vision of nature as sacred – which seems to have the potential to appeal to all people, religious and nonreligious alike – may be just what is needed if we are to preserve this planet, our one and only home in the cosmos."
"Heavy flooding has affected more than a million people in the north-eastern Indian state of Assam, with 45 dead and more than 200,000 in relief camps. And yet there is still very little coverage of the disaster in the international media – perhaps not surprising when you consider even most Indians aren’t paying attention. But they should – and so should you. The fact a region that is flooded regularly should be so unprepared for the latest downpour is scandalous, as is the shortsighted or uncaring government response.  The floods have also affected local wildlife, with the Kaziranga National Park – home to two thirds of the world’s Indian rhinos – reporting the electrocution of elephants fleeing from the water, as well as the death of at least three rhinos.  The floods come amid reports of increasing illegal immigration from Bangladesh and poor working conditions on local tea plantations, while armed conflicts between separatist groups and state security forces make the situation in the region even more unstable.  Assam is best known for its black tea, which grows well in the hot, steamy Brahmaputra valley. But while the monsoon may create perfect conditions for tea, it also means the region is highly susceptible to flooding.   More than 40% of the region is at risk and severe floods occur every few years, eroding riverbanks and dumping large amounts of sand on farmland, often rendering lands infertile. For local communities, these floods have been disastrous and many are not receiving sufficient aid. For example my own research on recovery after major floods in 2012 found affected families who hadn’t received the promised compensation from the government, even two years on.  Government initiatives to build new embankments have led to further distress. For example, new barriers constructed in 2012 displaced hundreds of families who found their resettled homes were now on the wrong side of the embankments. Compensation was poor, lower than market rates, while others received no support for resettlement due to identity and land ownership issues for illegal immigrants from Bangladesh. Some embankments built along the Brahmaputra in central Assam as an ad hoc response to the 2012 floods were so poorly constructed over natural drainage they actually failed to keep the river movements in check and increased erosion. The embankments simply breached in the following year’s monsoon. The subsequent relocations and distress were entirely preventable. The Brahmaputra has caused serious erosion for decades now, and yet the government response has been inefficient. Plans to tackle the problem remain confined only to paper. The floods in Assam have taken a heavy toll on water, sanitation, health and education systems. Affected people flee their homes and create makeshift camps, where access to essential facilities is inadequate for the hundreds of thousands displaced. The quality and accessibility of drinking water in particular is severely affected, and people are depending on contaminated sources – even when they know it isn’t clean. Defecation in the open becomes dangerous, especially for women and adolescent girls, all the more so during floods and regular displacement.  During floods the government turned some public schools into relief camps for a week or two. This of course affects the school term. Once the water recedes people start leaving the camps and are forced to fend for themselves. When they return to their villages they’ll be faced with destroyed homes, lost food grains and fields ruined by silt or sometimes even entirely lost to erosion. The road to recovery is hard to see, particularly as no long-term support is guaranteed by government, civil groups or NGOs. The floods also have an adverse affect on marginalised people, such as women, who bear the responsibilities of running households, childcare and rebuilding homes after floods. A 2013 study involving 900 households around Assam found that soil erosion, as a consequence of flooding, heavily affected the standard of living for farmers. This in turn forced women to leave the home and earn an income which resulted in girls dropping out of school to look after younger siblings and do the chores. India’s 2005 Disaster Management Act doesn’t recognise the chronic challenges of erosion as a natural disaster. The present development plans are shortsighted. They do not feature a long-term recovery, or take into consideration environmental factors. In the case of Assam, disaster resilience will only be possible through education and the participation of local communities and institutions. Something that needs to be done if the area is prone to flooding."
"
Share this...FacebookTwitterJochem Marotzke, Director of Germany’s Max Planck Institute for Meteorology (MPIM), says we would have to wait 20 years before seeing any impact on climate from CO2 reductions, based on model simulations. Climate variability prevails… 
=====================================================
Reduction of CO2 emissions possibly would have no effect on climate over the coming 20 years


By Die kalte Sonne
(German text translated/edited by P Gosselin)
Jochem Marotzke, director of Germany’s Max Planck Institute for Meteorology (MPIM), wondered whether CO2 savings could really have a direct influence on the temperature in the near future. In a new paper (Marotzke 2018), the Hamburg-based climate researcher simulates the temperature profile of the 2030s predicted by climate models and uses once again a conventional emission profile (Scenario RCP 4.5), and once a politically reduced emission scenario. 
Conclusion: Most likely, there would probably be no difference as natural climate variability prevails over these time scales. The paper was published in WIRE’s Climate Change and can be downloaded free of charge as a pdf:

Quantifying the irreducible uncertainty in near‐term climate projections
If the Paris agreement at the Conference of Parties 21 is implemented very effectively, greenhouse‐gas emissions might decrease after year 2020. Whether this would lead to identifiable near‐term responses in “iconic” climate quantities of wide scientific and public interest is unclear, because the climate response would be obscured by quasi‐random internal variability. I define the climate response as an increase or decrease in a linear climate trend over the period 2021–2035, compared to 2006–2020, and establish the probability of such a trend change being caused by an assumed policy shift toward emissions reductions after 2020. I quantify the irreducible uncertainty in projecting such a trend change through very large (100‐member) ensembles of the state‐of‐the‐art climate model MPI‐ESM‐LR. Trends in global‐mean surface temperature (GMST) are higher over the period 2021–2035 than over 2006–2020 in one‐third of all realizations in the mitigation scenario RCP2.6, interpreted as implementing the Paris agreement, compared to around one‐half in the no‐mitigation scenario RCP4.5. Mitigation is sufficient to cause a GMST trend reduction with a probability of 0.40 and necessary with a probability of 0.33. Trend increases in Arctic September sea‐ice area and the Atlantic meridional overturning circulation are caused by the emissions reductions with a probability of only around 0.1. By contrast, emissions reductions are necessary for a trend decrease in upper‐ocean heat content with a probability of over one‐half. Some iconic climate quantities might thus by year 2035 exhibit an identifiable response to a successful Paris agreement but sometimes with low probability, creating a substantial communication challenge.”

In the conclusion, there are some even clearer statements. Marotzke warns that even painful efforts to reduce CO2 in the next two decades could have little impact on the climate:
My thought experiment demonstrates that it is crucial to have realistic expectations of the efficacy of climate policy in the near‐term: Even if greenhouse‐gas emissions begin to decline after year 2020, the probability is substantial that the response of iconic climate quantities to this decline will not have emerged by year 2035.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Science communication challenge
With 90% probability, the Arctic Sea Ice (SIA) and the Gulf Stream (AMOC) will not respond to changes in CO2 emissions in the 2030s. Marotzke already sees a great communication challenge for the scientists, similar to the unexpected hiatus of recent years.

The major advance brought about by my analysis lies in the ability to quantify the degree of irreducible uncertainty about whether the assumed emissions reduction will cause the desired climate response over a given timescale. The probability of this response occurring depends on the quantity in question but also on the type of causation; for the time horizon out to 2035 the probability lies here in the range between a bit under 0.1 for causation both sufficient and necessary for SIA and AMOC and a bit above one‐half for necessary causation for ocean heat content.
Communicating these probabilities will be nontrivial but will be aided by the precise definitions and meanings underlying them (Hannart et al., 2016; Pearl, 2000). The communication challenge (Deser et al., 2012) furthermore supports the notion that the recent hiatus was not a distraction to the scientific community (Lewandowsky, Risbey, & Oreskes, 2016) but instead provided an opportunity to communicate the role of internal variability (Fyfe et al., 2016) to an audience that might otherwise be disinclined to engage in this discourse.”


The climate sciences continue to navigate in difficult waters. The natural variability causes them huge problems because it has been neglected in the models.
Alarmist dreams
Marotzke still dreams that nature only produces noise (“quasi-random internal variability”). However, the day will surely come when he will also acknowledge the systematic effect of natural climate factors such as ocean cycles and solar activity fluctuations. Perhaps he should start to take an interest in paleoclimatology, which is leaving him in the dust…


Share this...FacebookTwitter "
nan
"There are few dams in the world that capture the imagination as much as Belo Monte, built on the “Big Bend” of the Xingu river in the Brazilian Amazon. Its construction has involved an army of 25,000 workers working round the clock since 2011 to excavate over 240m cubic metres of soil and rock, pour three million cubic metres of concrete, and divert 80% of the river’s flow through 24 turbines. Costing R$30 billion (£5.8 billion), Belo Monte is important not only for the scale of its construction but also the scope of opposition to it. The project was first proposed in the 1970s, and ever since then, local indigenous communities, civil society and even global celebrities have engaged in numerous acts of direct and indirect action against it.  While previous incarnations had been cancelled, Belo Monte is now in the final stages of construction and already provides 11,233 megawatts of energy to 60m Brazilians across the country. When complete, it will be the largest hydroelectric power plant in the Amazon and the fourth largest in the world.  The dam is to be operated by the Norte Energia consortium (formed of a number of state electrical utilities) and is heavily funded by the Brazilian state development bank, BNDES. The project’s supporters, including the governments of the Partido dos Trabalhadores (Workers’ Party) that held office between 2003 and 2011, have justified its construction on environmental grounds. They describe Belo Monte as a “sustainable” project, linking it to wider policies of climate change mitigation and a transition away from fossil fuels. The assertions of the sustainability of hydropower are not only seen in Brazil but can be found across the globe – with large dams presented as part of wider sustainable development agendas. With hydropower representing 16.4% of total global installed energy capacity, hydroelectric dams are a significant part of efforts to reduce carbon emissions. More than 2,000 such projects are currently funded via the Clean Development Mechanism of the 1997 Kyoto Protocol – second only to wind power by number of individual projects.  While this provides mega-dams with an environmental seal of approval, it overlooks their numerous impacts. As a result, dams funded by the CDM are contested across the globe, with popular opposition movements highlighting the impacts of these projects and challenging their asserted sustainability. Those standing against Belo Monte have highlighted its social and environmental impacts. An influx of 100,000 construction and service workers has transformed the nearby city of Altamira, for instance. Hundreds of workers – unable to find employment – took to sleeping on the streets. Drug traffickers also moved in and crime and violence soared in the city. The murder rate in Altamira increased by 147% during the years of Belo Monte construction, with it becoming the deadliest city on earth in 2015.  In 2013, police raided a building near the construction site to find 15 women, held against their will and forced into sex work. Researchers later found that the peak hours of visits to their building – and others – coincided with the payday of those working on Belo Monte. In light of this social trauma, opposition actors gave the project a new moniker: Belo Monstro, meaning “Beautiful Monster”. The construction of Belo Monte is further linked to increasing patterns of deforestation in the region. In 2011, deforestation in Brazil was highest in the area around Belo Monte, with the dam not only deforesting the immediate area but stimulating further encroachment.  In building roads to carry both people and equipment, the project has opened up the wider area of rainforest to encroachment and illegal deforestation. Greenpeace has linked illegal deforestation in indigenous reserves – more than 200km away – to the construction of the project, with the wood later sold to those building the dam.  Brazil’s past success in reversing deforestation rates became a key part of the country’s environmental movement. Yet recently deforestation has increased once again, leading to widespread international criticism. With increasing awareness of the problem, the links between hydropower and the loss of the Amazon rainforest challenge the continued viability of Belo Monte and similar projects. While the Clean Development Mechanism focuses on the reduction of carbon emissions, it overlooks other greenhouse gases emitted by hydropower. Large dams effectively emit significant quantities of methane for instance, released by the decomposition of plants and trees below the reservoir’s surface. While methane does not stay in the atmosphere for as long as carbon dioxide (only persisting for up to 12 years), its warming potential is far higher. Belo Monte has been linked to these methane emissions by numerous opposition actors. Further research has found that the vegetation rotting in the reservoirs of dams across the globe may emit a million tonnes of greenhouse gases per year. As a result, it is claimed that these projects are – in fact – making a net contribution to climate change.  Far from providing a sustainable, renewable energy solution in a climate-changed world, Belo Monte is instead cast as exacerbating the problem that it is meant to solve. Belo Monte is just one of many dams across the globe that have been justified – and funded – as sustainable pursuits. Yet, this conflates the ends with the means. Hydroelectricity may appear relatively “clean” but the process in which a mega-dam is built is far from it. The environmental credentials of these projects remain contested, with Belo Monte providing just one example of how the sustainability label may finally be slipping."
"
Share this...FacebookTwitterScientists have determined that today’s Arctic sea ice concentrations are still much higher than they have been for most of the last several thousand years, undermining claims that modern era Arctic sea ice changes are remarkable, unusual, or unprecedented. 

Source: Kolling et al., 2018
In the graphical illustration of Late Holocene West Greenland sea ice changes shown above, Kolling and colleagues (2018) indicate that both present-day and Little Ice Age era (~1300s to 1800s AD) sea ice does not melt until May.(Fig. 6a).
During most of the last 2,200 years — especially during the Medieval Warm Period (MWP) and Roman Warm Period (RWP) — spring sea ice melted in March, two months earlier than today (Fig. 6b).
The authors attribute the lower-than-today sea ice concentrations and warmer temperatures during the MWP and RWP to a “self-amplifiying system” involving variations in solar activity and the AMO.  Atmospheric CO2 concentrations are not mentioned in the paper as a factor influencing sea ice changes.
“The period between 2.2 and 1.2 kyr BP, with lower than modern sea ice conditions in Disko Bugt (Fig. 6b), coincides with generally warm conditions over the Greenland Ice Sheet.”
“A self-amplifying system may have caused the environmental changes observed in Disko Bugt area as follows: solar triggered Arctic sea ice melt [Ruzmaikin et al., 2004] increases freshwater supply towards the North Atlantic causing a reduction in sub-polar gyre activity and AMO [Holland et al., 2001, Schmith et al., 2003] as described by Sha et al. [2016].”
Consistent with other reconstructions for the region (Kryk et al., 2017; Durantou et al., 2012; Yamamoto et al., 2017; Perner et al., 2018), proxy evidence shows that current sea ice conditions are only modestly different than the indicated conditions during the past few centuries.


Source: Kryk et al., 2017; Durantou et al., 2012; Yamamoto et al., 2017; Perner et al., 2018
The lack of any unusual or remarkable change in sea ice conditions during the modern era relative to the past suggests there is a lack of conspicuous connection between rising anthropogenic CO2 emissions and the Arctic climate.

Kolling et al., 2018
New insights into sea ice changes over the
past 2.2 kyr in Disko Bugt, West Greenland
“Our biomarker record indicates that Disko Bugt [West Greenland] experienced a gradual expansion of seasonal sea ice during the last 2.2 kyr. Maximum sea ice extent was reached during the Little Ice Age around 0.2 kyr BP. Superimposed on this longer term trend, we find short-term oscillations in open water primary production and terrigenous input, which may be related to the Atlantic Multidecadal Oscillation and solar activity changes as potential climatic trigger mechanisms.
“The period between 2.2 and 1.2 kyr BP, with lower than modern sea ice conditions in Disko Bugt (Fig. 6b), coincides with generally warm conditions over the Greenland Ice Sheet.”
“Overall, IP25 concentrations remained relatively low and constant until 1.2 kyr BP, followed by a gradual increase (Fig. 3e). The lowest [sea ice] concentrations, around 0.06 µg/gTOC, are observed in the lowermost core section from 2.2 to 1.5 kyr BP (Fig. 3e).”
“During the last 0.1 kyr, all biomarker concentrations showed an increase, brassicasterol and HBI III reach maximum values in the uppermost sample (80 µg/gTOC and 1.8 µg/gTOC, respectively; Fig. 3b, d).”

Source: Kolling et al., 2018
“[During the Little Ice Age (0.7–0.2 kyr BP)] our biomarker record supports harsher sea ice conditions, possibly similar to conditions as observed today (Fig. 6b), indicated by strong increased in IP25 concentration and the PDIP25 index (Fig. 4c, d).”

Source: Kolling et al., 2018
“AMO variability has been linked to solar activity changes [Knudsen et al., 2011]. Changes in incoming radiation may influence sea ice extent and the Greenland Ice Sheet behaviour [Ruzmaikin et al., 2004] and consequently affect the freshwater discharge/inflow [Schmith et al., 2003] and nutrient availability to the area. A self-amplifying system may have caused the environmental changes observed in Disko Bugt area as follows: solar triggered Arctic sea ice melt [Ruzmaikin et al., 2004] increases freshwater supply towards the North Atlantic causing a reduction in sub-polar gyre activity and AMO [Holland et al., 2001, Schmith et al., 2003] as described by Sha et al. [2016]. This may in turn cause distinct changes in WGC composition and meltwater supply from the Greenland Ice Sheet that affects phytoplankton blooms in West Greenland.”
“We find that the Disko Bugt area was influenced by seasonal sea ice over the last 2.2 kyr BP. The overall sea ice trend indicates a development from a reduced sea ice cover during early spring, with sea ice algae productivity hampered by light availability to a gradual extend of the sea ice season from 1.2 kyr BP onwards. This change in sea ice extend is parallel to decreasing Northern Hemisphere atmospheric temperatures and culminates in the Little Ice Age around 0.2 kyr. We assume that modern conditions, with sea ice present until late spring and the presence of a stable ice edge at Disko Bugt, established around that time [~200 years ago].”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterImpressive Cold Grips As Planet Continues Its Warming Pause
By SnowFan
(Translated/summarized by P Gosselin)
The continuing global cooling and the start of the grand minimum require new targets in climate policy and a complete withdrawal from the previous warming madness.
After a complete failure by the IPCC climate models and the crazy assignment of CO2 as a pollutant, scientific reason must once again return to the climate discussion.
Neither did the sea ice in the Arctic disappear in the summer of 2016 as it was often predicted by nutty scientists (even by NASA, who wrote that Arctic summers would be ice-free by 2013), nor have global temperatures risen by an significance over the past 20 years, thus contradicting the projections of IPCC models.

The chart above depicts in orange the range of the IPCC projections for the deviation of global mean temperature since 1990. The mean IPCC projection was +0.75°C of warming. Satellite measurements by UAH and RSS (blue line) show only an increase of 0.34°C. The models have been completely wrong. Source: When will “The Pause” in global temperature return? 
Moreover, the ice mass at both poles and Greenland have grown over the past years. Also the facts surrounding the increasingly cooler Antarctic are presented by a recent study.
An extreme record value of almost -100°C was measured in 2004, but kept quiet in order not to dísturb the quasi religious fairy tale of manmade “global warming”.
1988 Maldives predictions an epic blunder


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This is also one reason why sea level rise has increased less than originally projected and why the 1988 prophesy that all 1196 Maldives islands would sink underwater within 30 years have turned out to be preposterous. Not a single island has gone under!
“Missed It By That Much”
On September 26, 1988, “experts” announced all of the 1196 Maldives islands would be underwater. In 2018 – 30 years later – we see this has ended up being an epic blunder.

Source: Real Climate
In fact, one recent paper found, for example, that the South Sea Tuvalu islands have grown, the shaming climate scientists!
Time for competent and honest institutions
The time has arrived where government offices, authorities, weather services, media headquarters and educational institutes become staffed by educated and independent persons who are able to see the reality in the interrelationships of weather and climate and report them in an unfalsified manner.
It’s the sun, water, clouds, vapor, ice, snow that determined the weather of our planet, and not life-sustaining trace gas CO2, which makes up only 0.04%of our atmosphere.
Anyone who vilifies trace gas CO2 as a pollutant conducts him/herself in a manner that is hostile to life and is thus not suited to be a scientist, teacher, professor, journalist or politician!
Share this...FacebookTwitter "
"
Share this...FacebookTwitterClimate modeler Jochem Marotzke: more time to decarbonize, earlier climate models were too sensitive 
=========================================================
Correction (12 November 2018): Dr. Lüning writes that he had to modify his post on Marotzke a bit. “Marotzke did not mean CO2 climate sensitivity but that more CO2 is buffered, adding less to the atmosphere.” However, the goalposts still have been moved back and we still get 10 more years. 
==========================================================
Hat-tip: Sebastian Lüning and Fritz Vahrenholt
On October 5, 2018, German national weekly Spiegel here presented a noteworthy interview with Germany’s top climate modeler, Jochem Marotzke, director of the Max Planck Institute for Meteorology in Hamburg.

Top German climate modeler, Jochem Marotzke, Director of the Hamburg-based Max Planck Institute for Meteorology. Image: Max Planck Institute for Meteorology.
Spiegel wrote in its sub headline:

Unexpected extra time in the climate scenario: ‘Our reprieve has been extended by about ten years’ Physicist and climate researcher Jochem Marotzke explains why humanity has more time to stop global warming than previously thought.”

Or in other words, German skeptics Dr. Sebastian Lüning and Prof. Fritz Vahrenholt write at their Die kalte Sonne blog, “the sensitivity of CO2 was obviously overestimated.”
Yes, the climate goalposts just got moved back once again.
Earlier skeptic claims of overly sensitive models now spot on
More than 6 years ago in 2012, Lüning and Vahrenholt had already pointed out the problem of over-sensitive models in their book “Die kalte Sonne” – a claim that Marotzke back then said was “completely outlandish”.
Naturally today Lüning and Vahrenholt find themselves somewhat vindicated, and are confident more vindication is on the way as the reality of climate change becomes increasingly known.
We can emit “at least twice as much”
In the Spiegel interview, conducted editor Olaf Stamp, Marotzke was asked about how much CO2 we could still add to the atmosphere:
MAROTZKE: […] According to the latest climate scenarios, the amount of CO2 that we may emit is far greater than previously assumed – a fundamental point.
SPIEGEL: So we’ve been given amore time to reduce CO2 emissions?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




MAROTZKE: Exactly. That’s what today’s improved models show. Our remaining CO2 budget for the 1.5°C target is in fact at least twice as much as previously thought: almost 1 trillion tonnes. Thus our reprieve has been extended about 10 years. Of course, it makes a huge difference if we have to bring the emissions of greenhouse gases down to zero in 15 years or 25 years. I assume that this will be the key message in the special report.”
And, according to Marotzke:
Our earlier models are too sensitive in one crucial place […]”
Here the Hamburg-based Max Planck Institute for Meteorology director is talking about CO2 climate sensitivity. And Lüning and Vahrenholt write: ” And when Marotzke says this, then it has real weight.”
IPCC Report politicized, “long deviated from the scientific basis”
In the Spiegel interview, which took place three days before the IPCC report was released, Marotzke suspected that the 1.5-degree report of the IPCC was to play down the danger of climate change. But when the report came out, it conveyed the opposite, namely worsened climate warnings. 
This, according to Lüning and Vahrenholt, “is an indication that it is more a political report than a scientific account. Apparently the IPCC report authors, handpicked by politics, have already long deviated from the scientific basis.” 
1.5°C target ” came as a surprise to us climatologists”
When asked by Spiegel why the 1.5°C target was used instead of 2°C:
SPIEGEL: Why was the limit lowered from 2 degrees to 1.5 degrees? 
MAROTZKE: That came as a surprise to us climatologists as well. Especially the West Pacific island states insisted on 1.5 degrees at the Paris negotiations because they would be threatened by the rise of the sea level already at 2 degrees. However in most parts of the world, especially in Europe, we do not expect much difference between a 1.5-degree world and a 2-degree world.”
Politics overruling science
“Once again, political motives were more important than science,” Lüning and Vahrenholt write in response to Marotzke’s comments. 
“Curiously enough, the Pacific Islanders also ignore the fact that they live on growing coral islands, which have already withstood much stronger sea-level rise rates in the transition from the last ice age to today’s interglacial. One has to assume that, above all, this should accelerate the path to the international coffers for climate compensation payments,” say skeptics Lüning and Vahrenholt. 
The whole Spiegel interview is behind a paywall at spiegel.de.
Rejects claims of tipping points taking place
Marotzke also explained that signs of the alleged tipping points coming from the Potsdam Institute were rather weak. He also flat out rejected the tipping points of a stalling Gulf Stream and melting West Antarctic.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterYesterday we wrote about a study that told us the data do not support that weather blockings are occurring more often than they used to. Some alarmist media and scientists have claimed that the heavy snowfalls in the Alps are happening due to manmade global warming.
Swiss meteorologist: Such snowfalls “nothing unique” for Alps
Yesterday one of Europe’s most high profile meteorologists, Jörg Kachelmann, penned an opinion piece at t-online.de reminding the public that heavy snow events in the Alps, such as the one we are now experiencing, are in fact nothing unique and that it is not a catastrophe.
In the days ahead, many parts of the Alps are expecting up to another meter of new snow, yet, according to Kachelmann, this should not pose any problems to buildings and structures – if their construction indeed adhered to the applicable building codes.
“Nothing to do with climate change”
Kachelmann adds later in his t-online piece: “1. The snowfalls are nothing unique so far for the Alps. 2. They have nothing to do with climate change.”
The veteran Swiss meteorologist adds that the heavy snow in the Alps “are making people happy because they ensure the ski season will extend until Easter.”
Snow is in fact welcome
Moreover, they are good for the glaciers, and will help relieve the drought conditions seen in Europe last year. The Swiss meteorologist adds:
They [the snowfalls] are making the media happy as well because weather catastrophes get many clicks. However, the current weather situation is not a catastrophe. Human lives (except in the mentioned 0.1 percent problem) are only in danger if people behave inappropriately.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Kachelmann also thinks the media overhype now taking place may be unnecessarily scaring people away from booking ski trips to the Alps, a region where massive amounts of snow are common.
Models suggest severe winter conditions
Meanwhile, German meteorologist Dominik Jung of wetter.net reported that a Russian “Beast from the East” looks to be in the works for Europe for the weeks ahead:

According to Jung, who cites US and European weather models, beginning January 20 much greater cold will be invading large parts of Europe. And by January 25, the cold conditions could deepen and become extreme.
Northern hemisphere “under the gun”
Also at Weatherbell, 40-year meteorologist Joe Bastardi backs Jung’s projected development, presenting a frigid chart at yesterday’s Daily Summary that shows the forecast 11-16 days out:

Cold to grip Europe, North America and Asia in the weeks ahead, models suggest.
Joe says:
Once this gets here, until March, these areas and these areas, are under the gun. Repetitive snow threats and bitter cold relative to averages, and it’s coming at the coldest time of the year.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterLeft-leaning filmmaker German-Dutch filmmaker Martin Poels has produced some 50 films over the past 15 years. 

German-Dutch film maker Martin Poels has come under attack for questioning climate dogma. Image cropped here.
His most recent film is titled Paradogma – a personal journey why true liberty needs heretics, It focusses on current controversial debates such as climate change, and how dissenters are being silenced.
Martin Poels recently wrote: “People who dare to question important themes today, are often silenced or labeled as suspicious and dangerous and that we now find ourselves “in a new era where world views clash and free speech crumbles under pressure to conform.”
German liberty under threat
And because Poels has been critical concerning the state of the climate debate, he has been threatened and marginalized. 
German mainstream media has silenced the film, and anonymous threats have been launched against Poels, which show that the topic of climate and energy has become type of religion.
And anyone who questions this religion gets shut out of the public discussion forum.
Nevertheless journalist Jörg Rehmann spoke with Poels after the screening of his film in Brussels at the end of last year:

According to the interview:
Since Martin Poels has become critical about the contradictions of climate science, he has been blocked out by the German media and threatened by green lobbyists and at times called a Nazi.”
In the interview he begins by stating that because the film looks at climate and energy, it is a difficult topic because of the deep political dogma that it involves. “But the biggest problem,” Poels said, “Is that the media refuses to report on it.”
Climate: “forged” consensus that must not be disturbed
Poels mentions that they were successful, however, getting the film shown in 100 cinemas. Overall he calls the subject of climate in Germany a dogma that it is very difficult to criticize. He calls climate consensus something that was forged, and not something that is to be disturbed.
Hostile Greenpeace?
The filmmaker speaks of having received threats from organizations, such as Greenpeace, so much so that he became afraid. He said: “I got a call warning that I should better stop the film, before you really get problems.” He says the call was anonymous, but his understanding was that it came from Greenpeace.
Next Poels describes how some people reacted when the film was shown. He said: “Sometimes there were people who got really aggressive in their talk against me”.
“Shameful” media


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




He then calls the German publicly funded media’s role in the climate topic “shameful”, as it is clear that the green energy issue is not a topic that is to be questioned nor discussed.
Either you’re with us, or against us
Poels also notes that the topic of green energies can be discussed and criticizesd in Holland, but that it Germany the issue of green energies has become very sensitive and criticism is not welcome “because rescuing the climate is good, and when you criticize it, it means you no longer want to save the planet.” It’s: either you’re with us, or against us. Poels calls this radical mindset “nonsense”.
Corrupted by business interests
Poels sees green energies as desirable, but currently he believes they are a social injustice, as the rich benefit and the poor have to bear the costs. Moreover, they are harming the environment more than they are helping.
The flim also shows that the science is long from being settled, thus contradicting claims often made by alarmist scientists and the media. Poels believes that the science has been corrupted in part by lobbyists “where the target is no longer the target, and that business has become the target itself.” He adds:
For me, that’s one explanation why we are not allowed to discuss it. Because it criticizes not only climate change, but the business behind it.”
Biased media has abandoned its job
For Poels, this corruption by self interest is simply being neglected by the German public media: “There are simply rules within the media that say to talk about climate change uncritically – only positively. That’s a law within the media business.”
In total, Poels believes German journalism has long abandoned it’s neutrality on the topic of climate change and green energies. “It’s only politics.” He comments further:
Not only the science is politicized, but so are the media.”
German media “really frightening”
Poels then says the media are more open in the Netherlands, but finds the situation in Berlin “really frightening”. He agrees that in Germany it’s enough to express skepticism on climate science in order to be labelled a fringe right winger.
He finds it ironic that the media often accuse climate skeptics of conspiracy theories, but at the same time subscribe to the conspiracy theory that oil companies helped fund his film.
Academic arrogance
In the area of academia, Poels says overall the film has been received positively and openly by most students, but that professors have composed themselves arrogantly and simply dismiss the film’s content offhand after viewing it. One example, Poels cites, is how one professor simply dismissed a critical student – who had challenged the professor – as “a student who still had a lot to learn”.
Energiewende at a dead-end
In summary Poels agrees that the German Energiewende has reached a dead-end and that the establishment is no longer capable of learning lessons.
Historically, that all sounds familiar.
Share this...FacebookTwitter "
nan
"The unusually hot summer of 2018 has proved challenging for farmers across the UK. Among other things, the scorching weather and lack of rain has damaged crops, and the grass used to feed farm animals too. Unfortunately the unusual may become more usual as the effects of climate change are felt more frequently across the world. The high ambient temperatures and humidity seen this year, as well as extreme weather conditions such as flooding, are a significant challenge to the future of farming.  Pasture-based systems of dairy production, which are very common in the UK, are particularly sensitive to environmental factors. In fact, dairy cows are more likely to be vulnerable to the effects of climate change than cows that are housed, because housing provides shelter and technological options to mitigate the extremes of weather.   For our recent study, our team looked at how climate change might impact UK milk production, given what we already knew about how it affects dairy cows. In particular, we wanted to quantify the effects of heat stress on milk production.  Heat stress in cows occurs when ambient temperature and humidity go above animal specific thresholds. These thresholds are estimated by the temperature humidity index (THI). At present, the current British temperature and humidity is considered moderate on this scale, but is expected to get worse. It is open to debate, and depends on the cattle themselves, but generally a THI of more than 70 is regarded to be the point when heat stress becomes a problem and less milk is produced. Using 11 different climate projection models, and 18 different milk production models, we estimated potential milk loss from UK dairy cows as climate conditions change during the 21st century. Given this information, our final climate projection analysis suggests that average ambient temperatures in the UK will increase by up to about 3.5℃ by the end of the century. This means that THIs during the summer, in some parts of the country, will lead to significant heat stress for cows if nothing is done to alleviate the hot weather’s effects.  Lactating cows initially respond to mild heat stress by sweating, panting, drinking more, and seeking shade when possible. At higher temperatures cows eat less feed, which leads to a fall in milk production. In south-east England – the region with the highest incidence of heat stress – the average annual milk losses due to heat stress is projected to exceed 170kg/cow. Cows in the UK currently produce an average of about 7,500kg of milk each year so these future losses would be about 2.4% of their production.  However, climate change projections also suggest the UK would experience more heatwaves, and these would lead to even greater losses of milk. For example, the hottest area (south-east England) in the hottest year in the 2090s is predicted to result in an annual milk loss exceeding 1,300kg/cow, which is about 18.6% of annual milk yield.  In economic terms, south-west England is expected to be the region most vulnerable to climate change because it is characterised by a high dairy herd density, and so potentially a high level of heat stress-related milk loss. In the absence of mitigation measures, the estimated heat stress-related annual income loss for this region by the end of this century may reach £13.4m in average years, and £33.8m in extreme years. However, by the end of the century we predict dairy cattle in large portions of Scotland and Northern Ireland could experience the same level of heat stress as cattle in southern England today.  These predictions assume that nothing is done to mitigate the problems of heat stress. But there are many parts of the world that are already much hotter than the UK where milk is produced, and much is known about what can be done to protect the welfare of the animals and minimise economic losses from heat stress. These range from simple adaptations, such as the providing shade, to installing fans and water misting systems.  Cattle breeding for increased heat tolerance is another potential, which could be beneficial for maintaining pasture-based systems. In addition, changing the location of farming operations is another practice used to address economic challenges worldwide. Even though there is little indication that movement of dairy farming operations is a feasible strategy to decrease the risks of environmental challenges in the UK, regions with little or no prediction of conditions leading to heat stress (for example some parts of Scotland) may become increasingly important for UK dairy farms that depend on the availability of pasture. In any case, we estimate that by 2100, heat stress-related annual income losses of average size dairy farms in the most affected regions may vary between £2,000-£6,000 and £6,000-£14,000 (in today’s value), in average and extreme years respectively. Armed with these figures, farmers need to begin planning for a hotter UK using cheaper, longer-term options such as planting trees or installing shaded areas."
"
Share this...FacebookTwitterEven though CO2 concentrations hovered well below 300 ppm throughout most of the Holocene, newly published paleoclimate reconstructions affirm that today’s surface temperatures are only slightly warmer (if at all) than the coldest periods of the last 10,000 years.  This contradicts the perspective that temperatures rise in concert with CO2 concentrations.

 Bottom Graph Source: Rosenthal et al. (2013)
1. Even Past Cold Periods Were 0.5–1.5 °С Warmer Than Today
Nosova et al., 2018
“According to the present climate reconstruction, mid Holocene warming started only at 7,700 cal bp, with temperatures higher than now during the mid Holocene period. This warming was due to an increase in winter temperatures (1–5 °С higher than current), while summer temperatures remained relatively stable, with a July temperature<1 °С higher than now. … During the mid Holocene, two cold periods at 6,900–6,500 and at 5,300–5,000 cal bp were observed. Interestingly, during the cold periods, the temperatures exceeded the current ones by 0.5–1.5 °С.”
“The transition from the mid Holocene thermal maximum to the following period occurred without considerable climatic changes. The mean annual temperatures remained much higher than the current ones by 0.5–2.5 °С until 2,500 cal bp. Local maximum temperatures were observed at 4,800, 4,300, 3,500 and 2,900–2,700 cal bp. The present climatic reconstruction demonstrates a gradual cooling down to current levels at ca. 2,500 cal bp, and then followed by a new warming phase with up to 1–2 °С increase at approximately 1,500 cal bp.”

2. Only 3 Of 116 Holocene Temperature Anomaly Records Were Colder Than Today
Bajolle et al., 2018
“The mean annual temperature recorded at the closest meteorological station [La Sarre: 1961–1990] is 0.8 °C, with August temperature averages of 15.0 °C (1961–1990) and 15.4 °C (1981–2010). … During zone Lch1 (8500–5800 cal year BP), the average reconstructed temperature was 16.9 °C, with a decrease from 19 °C (maximum) to 17 °C at the end of the zone. In zone Lch-2 (ca. 5700–3500 cal year BP), temperatures had an average of 16.8 °C, with a decrease from 17.8 °C around 5200 cal year BP to 16.2 °C at 3400 cal year BP. Zone Lch-3 (ca. 3500–1200 cal year BP) started with inferences for high temperatures (19.3–18.5 °C), followed by a decrease to 16.8 °C between ca. 3000 and 2500 cal year BP. An increase (18.3 and 19.6 °C) was inferred for the period between 1800 and 1500 cal year BP. The average chironomid inferred temperature during Zone 3 was 17.9 °C. In the last zone (Lch-4), the temperatures decreased from ca. 17.5 °C at the beginning of the zone to 14.8 °C at the end of the zone. The average during this zone was 16.5 °C. The temperature anomalies show that throughout the whole record, only six of the inferences were colder than the climate normal of 15.4 °C and three were colder than today, with the climate normal of 15 °C (Fig. 4b). The average anomaly from 15 °C (2.10 °C) and from 15.4 °C (1.70 °C) for the whole record showed that the temperature inferences were generally, and significantly, warmer than today.”

3. New England (USA) Colder Now Than Nearly All Of The Last 11,000 Years
Oswald et al., 2018

4. Today’s Temperatures Still Just As Cold As The Global Little Ice Age
Coffinet et al., 2018
“This study represents the first detailed late Holocene quantitative air temperature reconstruction from the RVP [Rungwe Volcanic Province, southwestern Tanzania/East Africa] region. We identified a succession of cold/warm/cold events, largely in phase with the other regional East African climate records and with the cold periods identified worldwide by Wanner et al. (2011). This further supports that global scale processes may be the main drivers of the Holocene climatic variability. Moreover, warm conditions during the MCA [Medieval Climate Anomaly] followed by abrupt cooling during the LIA were observed at Kyambangunguru and elsewhere in East Africa suggesting that these two recent events occurred globally.”

5. Modern Temperatures -2.9°C Colder Than 7,000 Years Ago
Zhao et al., 2018
“According to the interpolation of meteorological data of the two nearest weather stations at Linxia (ca. 46 km away; MAT [mean annual temperature] = 7.3 °C) and Minhe (ca. 54 km away; MAT [mean annual temperature] = 8.3 °C)… In this study, we reconstructed mid-late Holocene climatic changes using GDGT distributions in a loess-paleosol sequence in the Lajia Ruins of the Neolithic Qijia Culture, Guanting Basin, in the southwestern end of the Chinese Loess Plateau. … MAT [mean annual temperature] decreased from 11.9 °C to 8.0 °C [today], during the past ca. 7000 yr, and a drastic decline in MAP [mean annual precipitation] (70 mm), accompanied by a 0.8 °C decline in MAT [mean annual temperature], occurred at 3800–3400 yr BP.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




6. Temperatures “7–9°C Higher Than Modern during The Early Holocene”
Zheng et al., 2018
“In this study we present a detailed GDGT data set covering the last 13,000 years from a peat sequence in the Changbai Mountain in NE China. The brGDGT-based temperature reconstruction from Gushantun peat indicates that mean annual air temperatures in NE China during the early Holocene were 5–7°C higher than today.  Furthermore, MAAT records from the Chinese Loess Plateau also suggested temperature maxima 7–9°C higher than modern during the early Holocene (Peterse et al., 2014; Gao et al., 2012; Jia et al., 2013). Consequently, we consider the temperatures obtained using the global peat calibration to be representative of climate in (NE) China. … The highest temperatures occurred between ca. 8 and 6.8 kyr BP, with occasional annual mean temperatures >8.0 ± 4.7°C, compared to the modern-day MAAT of ∼3°C.”

7. 1950-2015 Just 0.7°C Warmer Than Coldest Temps Of The Last 9,000 Years
Harning et al., 2018
“Iceland’s terrestrial HTM [Holocene Thermal Maximum] has previously been constrained to ~7.9 to 5.5 ka based on qualitative lake sediment proxies (Larsen et al., 2012; Geirsdottir et al., 2013), likely in association with progressive strengthening and warming of the Irminger Current (Castaneda et al., 2004; Smith et al., 2005; Olafsdottir et al., 2010). Numerical modeling experiments for Drangajokull suggest that peak air temperatures were 2.5 – 3°C warmer at this time relative to the 1961-1990 CE average (Anderson et al., 2018). … During the Little Ice Age (LIA, 1250-1850 CE), the Vestfirðir region entered the lowest multi centennial spring/summer temperature anomalies of the last 9 ka.  Based on recent numerical  modeling simulations, this anomaly is estimated to be 0.6-0.8°C below the 1950-2015 average on Vestfirðir (Anderson et al., 2018).”


8. 2004-2007 Temps Colder Than All But 3 Other Holocene Periods
Wang et al., 2018   
“The average RAN15-MAAT of 18.4°C over the most recent part of the record (<0.8 ka BP) [the last 800 years BP] overlaps with the range of MAATs, ca. 16.2°C to 18.7°C (av. 17.5°C) measured since 1952 at the nearest meteorological station (Yichang, located ca. 100 km away) and is very close to the av. MAAT of 18°C measured directly outside the cave by a temperature logger between 2004 and 2007 (Hu et al., 2008a). This agreement between reconstructed temperatures and instrumental measurements increases our confidence in the potential of the RAN15 proxy. RAN15-MAATs in HS4 vary from 16.5°C to 20.6°C (av. 19°C), during the last 9 ka BP, and broadly follow a long-term trend of declining temperatures in line with declining solar insolation at 30°N in July (Laskar et al., 2004). … Interestingly, the most recent 0.9 ka BP [900 years BP] is distinguished by greater variability with the highest (20.5°C) and lowest (16.5°C) RAN15-MAATs occurring consecutively at 0.6 ka BP [600 years BP] and 0.5 ka BP [500 years BP].” [Surface temperatures dropped by -4.0°C within ~100 years.]

9. 1952-2014 Temps 4.0 to 7.0 °C Colder Than 8,000 – 10,000 Years Ago
McFarlin et al., 2018
“(Greenland)  Early Holocene peak warmth has been quantified at only a few sites, and terrestrial sedimentary records of prior interglacials are exceptionally rare due to glacial erosion during the last glacial period. Here, we discuss findings from a lacustrine archive that records both the Holocene and the Last Interglacial (LIG) from Greenland, allowing for direct comparison between two interglacials. Sedimentary chironomid assemblages indicate peak July temperatures [Greenland] 4.0 to 7.0 °C warmer than modern during the Early Holocene maximum [10,000 to 8,000 years ago] in summer insolation. Chaoborus and chironomids in LIG sediments indicate July temperatures at least 5.5 to 8.5 °C warmer than modern.”

Modern Derived Temps 0.2°C Above Coldest Of Last 14,000 Years
Wu et al., 2018
“Summer temperatures (MJT) at Xingyun Lake in the late glacial were low, increased during the early Holocene, were highest during the middle Holocene, and then decreased during the late Holocene.The range of inferred values [for the Holocene] was 21.0°- 26.5°C. The pollen inferred temperature derived from surface samples (21.2°C), is close to the modern instrumental July temperature in Kunming (22°C), supporting the reliability of reconstructions from down-core pollen assemblages.”

Share this...FacebookTwitter "
"
Share this...FacebookTwitterArctic sea ice volume data show earlier projections of ice-free Arctic summers were a sham. Sea ice now steady 10 years.
Lately Arctic sea ice volume has been a topic which climate skeptics have been looking at quite closely.
According to Al Gore and a number of climate ambulance chasers, Arctic sea ice in late summer should have long disappeared by now, see here..
But then just a few years after, the Arctic sea ice area began to recover from its lows of 2007 and 2012. So immediately alarmists shouted that area was not really what mattered, but rather sea ice volume is what really counted. Okay, that made perfect sense. Mass is in fact what’s important, and not area, when worrying about polar ice disappearing.
So naturally skeptics have since then been watching volume, which we were told by alarmists would shrink, and shrink, and shrink – until totally gone in late summer. In 2007 one US climate official declared the Arctic sea ice was in a “death spiral”.
Those alarmist projections have since turned up totally false
First, looking at peak ice, which occurs around April 1st, using the data from the Danish meteorological Institute (DMI) here, we find that Arctic sea ice VOLUME has totally defied the downward death spiral trend projected by experts and their models.

The chart above depicts Arctic sea ice volume on April 1st for the years 2003 to 2018, using the data from the DMI. Note the growing chasm between alarmist projections and reality. 
Humiliation of the alarmists


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The most closely watched measure of Arctic sea ice magnitude is the minimum that is typically reached in very late summer, i.e. around September 20.
Here as well using the DMI data, I’ve plotted the September 20 Arctic sea ice going back to 2003.
Here’s the result of the plot:

Al Gore’s hysterical projections of ice-free Arctic late summers are exposed as an absolute sham. 2018 uses a conservative projected value.
Today the doomsday scenarios and projections made 10 years ago have yet to show any signs of materializing. Late summer Arctic sea ice has been surprisingly stable over the past decade.  Gore and alarmists fell into the trap of applying an idiotic polynomial curve extrapolation into the future.
In fact there are indications that Arctic sea ice may be starting an upward trend as oceanic and solar cycles enter their cooler phases.
Low sea ice also occurred in the past
There’s no doubt that Arctic sea ice has dwindled considerably since it peaked back at around 1980, a time when climate scientists had warned the globe risked cooling into an ice age.
Also, today’s Arctic sea ice amount is in the same neighborhood as it was back in the 1930s. Moreover, today’s levels are considerbly higher than they were over a large part of the Holocene, which saw periods that were far warmer than today.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe purveyors of climate alarm posit that rising CO2 emissions cause up to 600% increases in burned area due to global warming. Newly published science thoroughly undermines these claims. Observational evidence affirms global-scale fire frequencies and burned area have actually been declining for decades (especially since the early 1900s), with overall biomass burning lower today than during the much colder Little Ice Age.

Bottom Graph Source: Ward et al., 2018
On a global scale, fire emissions/burned area peaked in the 1910s, but then plummeted to “about 5% below year 1700 levels by 2010” (Ward et al., 2018).
The decreasing trend in wildfires has continued unabated in the 21st century, as there has been “a strong statistically significant decline in 2001–2016 active fires globally” (Earl and Simmonds, 2018).
On a long-term scale, “global biomass burning during the past century has been lower than at any time in the past 2000 years” (Doerr and Santín, 2016).
Even in the Western United States, where wildfires are currently ravaging the landscape, there has been a “decline in burning over the past 3,000 y[ears], with the lowest levels attained during the 20th century and during the Little Ice Age (LIA, ca. 1400–1700 CE)” (Marlon et al., 2012).
The perception of increasing fire occurrence vs. the observations of decreasing trends
Doerr and Santín (2016) characterize the association between global warming and increases in wildfires as a “perception” spawned by using selective regional data and short timescales (in other words, by excluding contradictory evidence).  The alarming conclusions that wildfires are worsening due to rising anthropogenic CO2 emissions are then promulgated by mainstream media.
“Numerous reports, ranging from popular media through to peer-reviewed scientific literature, have led to a common perception
that fires have increased or worsened in recent years around the world. Where these reports are accompanied by quantitative observations, they are often based on short timescales and regional data for fire incidence or area burned, which do not necessarily reflect broader temporal or spatial realities.”
To summarize, there are “widely held perceptions both in the media and scientific papers of increasing fire occurrence, severity and resulting losses“, and yet “the quantitative evidence available does not support these perceived overall trends” (Doerr and Santín, 2016).

Ward et al., 2018
Trends and Variability of Global Fire Emissions
Due To Historical Anthropogenic Activities
“Globally, fires are a major source of carbon from the terrestrial biosphere to the atmosphere, occurring on a seasonal cycle and with substantial interannual variability. To understand past trends and variability in sources and sinks of terrestrial carbon, we need quantitative estimates of global fire distributions. … Global fire emissions of carbon increase by about 10% between 1700 and 1900, reaching a maximum of 3.4 Pg C yr−1 in the 1910s, followed by a decrease to about 5% below year 1700 levels by 2010. The decrease in emissions from the 1910s to the present day is driven mainly by land use change, with a smaller contribution from increased fire suppression due to increased human population and is largest in Sub‐Saharan Africa and South Asia. Interannual variability of global fire emissions is similar in the present day as in the early historical period, but present‐day wildfires would be more variable in the absence of land use change.”





























Earl and Simmonds, 2018
Spatial and Temporal Variability and
Trends in 2001–2016 Global Fire Activity


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“We find that there is a strong statistically significant decline in 2001–2016 active fires globally linked to an increase in net primary productivity observed in northern Africa, along with global agricultural expansion and intensification, which generally reduces fire activity.”


Doerr and Santín, 2016
Global trends in wildfire and its impacts:
perceptions versus realities in a changing world
“Wildfire has been an important process affecting the Earth’s surface and atmosphere for over 350 million years and human societies have coexisted with fire since their emergence. Yet many consider wildfire as an accelerating problem, with widely held perceptions both in the media and scientific papers of increasing fire occurrence, severity and resulting losses.”
“However, important exceptions aside, the quantitative evidence available does not support these perceived overall trends. Instead, global area burned appears to have overall declined over past decades, and there is increasing evidence that there is less fire in the global landscape today than centuries ago.”
“Analysis of charcoal records in sediments [Marlon et al., 2008] and isotope-ratio records in ice cores [Wang et al., 2010] suggest that global biomass burning during the past century has been lower than at any time in the past 2000 years.”
“Regarding fire severity, limited data are available. For the western USA, they indicate little change overall, and also that area burned at high severity has overall declined compared to pre-European settlement. Direct fatalities from fire and economic losses also show no clear trends over the past three decades. Trends in indirect impacts, such as health problems from smoke or disruption to social functioning, remain insufficiently quantified to be examined. Global predictions for increased fire under a warming climate highlight the already urgent need for a more sustainable coexistence with fire. The data evaluation presented here aims to contribute to this by reducing misconceptions and facilitating a more informed understanding of the realities of global fire.”

Marlon et al., 2012
Long-term perspective on
wildfires in the western USA
“Understanding the causes and consequences of wildfires in forests of the western United States requires integrated information about fire, climate changes, and human activity on multiple temporal scales. We use sedimentary charcoal accumulation rates to construct long-term variations in fire during the past 3,000 y in the American West and compare this record to independent fire-history data from historical records and fire scars. There has been a slight decline in burning over the past 3,000 y, with the lowest levels attained during the 20th century and during the Little Ice Age (LIA, ca. 1400–1700 CE). Prominent peaks in forest fires occurred during the Medieval Climate Anomaly (ca. 950–1250 CE) and during the 1800s.”
“Analysis of climate reconstructions beginning from 500 CE and population data show that temperature and drought predict changes in biomass burning up to the late 1800s CE. Since the late 1800s , human activities and the ecological effects of recent high fire activity caused a large, abrupt decline in burning similar to the LIA fire decline. Consequently, there is now a forest “fire deficit” in the western United States attributable to the combined effects of human activities, ecological, and climate changes. Large fires in the late 20th and 21st century fires have begun to address the fire deficit, but it is continuing to grow.”

 

Share this...FacebookTwitter "
"
Share this...FacebookTwitterIt has long been established in the scientific literature (and affirmed by the IPCC) that CO2 concentration changes followed Antarctic temperature changes by about 600 to 1000 years during glacial-interglacial transitions throughout the last ~800,000 years (Fischer et al., 1999; Monnin et al., 2001; Caillon et al., 2003; Stott et al., 2007; Kawamura et al., 2007).
In contrast, two new papers cite evidence that the timing of the lagged CO2 response to temperature changes may have ranged between 1300 and 6500 years in some cases.  It would appear that a millennial-scale lagged response to temperature undermines the claim that CO2 concentration changes were a driver of climate in the ancient past.  

Koutavas et al., 2018
Temperature correlations between the eastern equatorial 
Pacific and Antarctica over the past 230,000 years
“The EEP [eastern equatorial Pacific] stack shows persistent covariation with Antarctic temperature on orbital and millennial timescales indicating tight coupling between the two regions. This coupling however cannot be explained solely by CO2 forcing because in at least one important case, the Marine Isotope Stage (MIS) 5e–5d glacial inception, both regions cooled ∼5–6.5 thousand years before CO2 decreased. More likely, their covariation was due to advection of Antarctic climate signals to the EEP by the ocean.”
“The discovery that atmospheric CO2 covaries with Antarctic temperature and global ice volume (Lorius et al., 1990; Lüthi et al., 2008; Petit et al., 1999) has propelled CO2 to the forefront as climatic “globalizer”.  However, the processes governing CO2 variability are themselves poorly understood, and likely require an oceanic/climatic trigger in the first place (Adkins, 2013; Ferrari et al., 2014; Sigman et al., 2010).”
“Antarctic ice core records are furthermore ambiguous with regard to the causal relationship between CO2 and temperature. Phase relationships show CO2 lagging behind temperature in the obliquity band (Jouzel et al., 2007) and across some major transitions (Caillon et al., 2003; Fischer et al., 1999; Kawamura et al., 2007; WAIS Divide Project Members, 2013), most prominently during the Marine Isotope Stage (MIS) 5e–5d boundary, i.e. the last glacial inception. Antarctic cooling at this time was associated with a major Milankovitch signal, and appears to have transpired almost entirely before the change in CO2 concentration. It remains unclear whether the temperature lead was restricted to Antarctica or was broader.”

Uemura et al., 2018
Asynchrony between Antarctic temperature and CO2
associated with obliquity over the past 720,000 years

“Precise knowledge of the relationship between changes in temperature, atmospheric CO2 and solar insolation is essential to understanding Earth’s climate system. The values of a temperature proxy, the hydrogen isotopic composition (δD), in the Antarctic EDC ice core have varied in parallel with CO2 concentrations over the past 800 thousand years (kyr; r2 = 0.82). However, δD [temperature] apparently leads CO2 variations.”
“The lead is ca. 2000 years at a West Antarctic site.”
“Over the past 420 kyr, the Vostok ice core shows that the Antarctic δD temperatures lead the CO2 variations by 1.3 ± 1.0 kyr.”
“During the lukewarm interglacials (430–650 kyr BP), Antarctic δD [temperature] leads CO2 by 1900 years, and the correlation between CO2 and δD is weaker (r2 = 0.57), as determined from the EDC core.”
“Although the mechanisms underlying the coupling and the phase lags remain unclear, the Southern Ocean region, rather than Antarctica, is thought to play the central role in regulating CO2 variations. A box model, for example, estimated a ca. 60% increase in CO2 during TI that is attributable to direct and indirect temperature effects, such as changes in sea ice cover and vertical mixing in the Southern Ocean. On millennial time scales, a multi-proxy study suggests that an antiphased hemispheric temperature response to ocean circulation changes resulted in Antarctic temperatures leading global temperatures and CO2 during TI [the last glacial termination].  … [O]ur data suggest that the lead in Antarctic δD temperatures (i.e. temperature without correcting for source effects) over CO2 is partly attributable to the effects of the moisture source on δD temperatures over the past 720 kyr in the obliquity band. These results suggest that the importance of moisture source effects for the obliquity signal in δD. Thus, the source effect must be considered in future research about the relationship between Antarctic temperatures and CO2.”
“Within the obliquity frequency band, our analyses suggest that temperature variations in Antarctica have led ocean temperatures throughout the past 720 kyr. This phenomenon is most likely explained by the strong influence of local AMI on ΔT. … During TI [the last glacial termination], CO2 rose at ~18 kyr BP, which is related to the melting of the Northern Hemisphere ice sheet and the subsequent weakening of the Atlantic meridional overturning circulation (AMOC). Thus, the timing at which CO2 begins to rise during a termination would be determined by when the Northern Hemisphere ice sheet begins to melt. When eccentricity is small, the summer insolation maxima are small. Thus, if obliquity rises beyond the threshold of melting, a moderate climate forcing could cause warming enough that the southern margin of the North American ice sheet begin to retreat.”

Studies Indicating Temperature-CO2 Lag Was 600-1000 Years

IPCC (2007)
“Atmospheric CO2 follows temperature changes in Antarctica with a lag of some hundreds of years.”

Stott et al., 2007
Southern Hemisphere and Deep-Sea Warming Led Deglacial Atmospheric CO2 Rise and Tropical Warming
“Deep sea temperatures warmed by ~2C between 19 and 17 ka B.P. (thousand years before present), leading the rise in atmospheric CO2 and tropical surface ocean warming by ~1000 years.”

Caillon et al., 2003
“The sequence of events during Termination III suggests that the CO2 increase lagged Antarctic deglacial warming by 800 ± 200 years and preceded the Northern Hemisphere deglaciation.”

Fischer et al., 1999
“High-resolution records from Antarctic ice cores show that carbon dioxide concentrations increased by 80 to 100 parts per million by volume 600 ± 400 years after the warming of the last three deglaciations.”

Monnin et al., 2001
“The start of the CO2 increase thus lagged the start of the [temperature] increase by 800 ± 600 years.”

Indermuhle  et al., 2000
“The lag was calculated for which the correlation coefficient of the CO2 record and the corresponding temperatures values reached a maximum. The simulation yields a [CO2] lag of (1200 ± 700) yr.”

Kawamura et al., 2007    
“Our chronology also indirectly gives the timing of the CO2 rise at [glacial] terminations, which occurs within 1 kyr of the increase in Antarctic temperature.”
Share this...FacebookTwitter "
"The Volkswagen emissions investigation looks set to be of one of the biggest corporate scandals in recent history – and we’ve seen quite a few. While most of the focus will be on VW in the coming days and weeks, the real scandal lies elsewhere: with European governments and regulators who turned a blind eye to rule-bending. In some cases they’ve actually helped carmakers avoid environmental restrictions.  Documents leaked to the Guardian reveal just four months ago the UK, France and Germany all lobbied to maintain loopholes from outdated car emissions tests. Such behaviour isn’t unusual. For decades European car industry regulation has been weak and inconsistent, while car traffic and the resulting air pollution levels have been allowed to increase manifold. The UK government quietly launched its consultation on air quality earlier this month. This was in response to a supreme court ruling stating the government must take immediate action to cut nitrogen dioxide pollution, which has reached dangerous levels in many of the UK’s big cities. The only national measure in the proposed plans are for clean air zones, similar to the one already run in London, but responsibility for their implementation has been passed onto local authorities for which no additional money is available. The document notes that approximately 80% of the NOx (nitrogen dioxide and nitric oxide) emissions are due to transport, with the largest source being diesel vehicles. Air pollution has been linked to coronary artery disease, heart attacks and strokes. In the consultation it is estimated that the impact of nitrogen dioxide on mortality is equivalent to 23,500 deaths every year in the UK. This figure has been taken, along with earlier estimates of mortality due to particulate matter (29,000), to give 52,500 premature deaths each year due to air pollution.  We can’t simply add up the mortality statistics from the two pollutants due to double counting, but this huge number should nevertheless be taken very seriously. In fact, it should be treated as a national emergency. Despite tightened emission standards for diesel vehicles, air pollution measurements in the UK have failed to show improvements. As such the gap between on-road and test measurements of emissions is not itself new. A number of studies have indicated that new diesel vehicles breach EU standards when tested under real world conditions. The recent report from campaign group Transport & Environment found that nine out of every ten new diesel vehicles broke EU limits. On average real world NOx emissions were about seven times higher than permitted levels. Cars from all the major motor manufacturers were in breach of the limits with the worst car producing 22 times than that permitted. It is evident that the current practice of allowing motor manufacturers to select the bodies to test and check their compliance with emission limits is not fit for purpose and an independent testing authority should be established. Yet for many years the European car industry has lobbied against tighter environmental regulation, despite the mounting evidence of car transports’ rising negative impact on the climate (carbon emissions) and urban air pollution (NOx emissions). In the UK, for example, successive governments have been very eager to support car manufacturers with operations in the country. Just earlier this year the industry celebrated record sales of cars and vans in the UK. Yet the dark shadows of this one-sided policy now become visible. While the overwhelming focus of the UK’s transport strategy has been on expanding individual car journeys, public transport has become more expensive and worse in terms of quality and reach. Hopefully something good will come out of the VW scandal. Perhaps the UK and European public will become more aware of the threats of air pollution, not only by diesel engines, but by all car traffic. We need a sustainable transport strategy and have a real go at tackling air pollution in our biggest cities. With urban centres getting ever bigger and car ownership steadily rising, the problem is not going to go away."
"Scientists have for the first time created hybrid embryos with DNA from the nearly-extinct northern white rhinoceros, an advance that could ultimately lead to the first resurrection of a mega-mammal. But while this scientific achievement could provide a new way to produce future generations of endangered or extinct animals, applying this approach to the white rhino does not meet with universal approval among conservationists. The international team of researchers, led by Professor Thomas Hildebrandt from the Leibniz Institute for Zoo and Wildlife Research, have used an existing assisted reproduction technology developed for horses, and applied it to the white rhino. Eggs and sperm from northern white rhino are in short supply, due to the rarity of the subspecies. So the team also used material from southern white rhino, successfully fertilising southern eggs with sperm from both northern and southern subspecies, proving that the process works. Only seven out of 314 fertilised eggs developed into embryos – a roughly 2% success rate – but the research demonstrated three important steps. First, that rhino eggs can be captured from live females. Second, that they can be fertilised using IVF and developed to the “blastocyst” early embryonic stage (ready for transfer to a surrogate female) – and that this can be done as a hybrid of southern and northern rhino. And third, that the resulting embryos can be frozen without damage. This process is technically very challenging. A special device was developed to enable the operators to extract oocytes (unfertilised eggs) from the ovaries of anaesthetised female southern white rhino from a number of European zoos. This is a three-person job requiring a steady hand that can guide a needle of just over 1 millimetre in diameter and almost 1 metre in length into the reproductive system via the rectum to capture the eggs. The next step will be to transfer three of the embryos that have been frozen to the uterus of surrogate southern white rhino for gestation and birth. This final step toward the birth of a calf containing northern white rhino DNA is no small step, as artificial insemination in rhino has rarely been attempted. San Diego Zoo is currently evaluating six surrogacy candidates, and has already successfully artificially inseminated one with southern white rhino sperm. The four other embryos produced were used to evaluate the potential for creating sperm and eggs from the genetic material of northern white rhino whose sex cells are not already available. While this only worked for southern white rhino embryos and not the hybrids, it did demonstrate the method could be successful. As the first demonstration of this process working for rhino, the research is significant, impressive and exciting. It offers a possibility to rescue the genes of a subspecies that, following the death of the last male northern white rhino earlier this year, is now represented by just two elderly females. And if the method works for the rhino, it should be possible to extend it to other endangered large mammals. The key question of whether scientists can produce pure northern white rhino embryos using this technique remains unanswered. But, even if it is possible, what would be the point? Ultimately, to be useful, these manipulative techniques need to increase the chance of survival of endangered (wild) animal populations. Otherwise, artificially engineered fertilisation and the management of genes has little value for nature conservation. To my mind, the time to save the northern white rhino has passed. If we could not save it when it was here (the last wild northern white rhino is thought to have disappeared around 2006) it seems unlikely we could conserve a resurrected wild population now or in the foreseeable future. The purpose of simply preserving the subspecies’ genes in a new hybrid rhino (in captivity), and whether it would be worth all the effort, is unclear. Recent research by Dr Tate Tunstall of the San Diego Zoo Institute for Conservation Research and colleagues indicates that there may be enough genetic diversity in the frozen northern white rhino material (from only 12 individuals) to provide a suitably diverse founder population for resurrection. They also showed that the genetic differences between the northern and southern subspecies may be the result of evolutionary adaptations to different habitats. An alternative strategy to resurrection would be to secure a safe habitat in the former northern white rhino’s range of central East Africa, populate it with southern white rhino and let natural selection run its course. The introduced rhino population would be expected to evolve over generations to adapt to their new environment and fill the ecological role left vacant by the northern white rhino. There are already southern white rhino currently living and breeding in Uganda at the Ziwa Sanctuary. Restoration ecologists have similarly replaced extinct giant tortoises with related species in a process called taxon substitution. Taxon substitution using the southern white rhino would be simpler and more cost-effective than manipulating genes and introducing manufactured hybrids, and would likely have a higher probability of success. I am concerned that new technologies, such as the creation of these hybrid rhino embryos, are distracting us from on-the-ground conservation and dealing with the root causes of endangerment. There is a growing pervasive psychology that we need to preserve genes for some utopian future. The desperate logic of mixing subspecies and applying assisted reproduction technology is also being discussed regarding the Sumatran rhino. Saving bits of dead animal now to bring back species (or subspecies) in the future perpetuates the delusion that everything will be okay at some point. We need action now. Jurassic Park-esque scientific advances will only work if we save habitats, stop pollution, constrain invasive species, reverse climate change and halt poaching. Otherwise, I fear that we will still be loading samples onto the frozen ark as the lights go off on an otherwise empty Planet Earth."
"Thwaites glacier, a vast river of ice the size of Great Britain, holds enough frozen water that were it to collapse, the world’s oceans would rise by more than 60cm. Part of the West Antarctic ice sheet, it is one of the most unstable glaciers on the continent. Since the 1980s, Thwaites has lost 540bn tonnes of ice into the dark waters of the Amundsen Sea. This single glacier is responsible for 4% of global sea level rise. The rate of Thwaites’s disintegration has alarmed scientists for good reason. In a handful of decades it could retreat to the point that collapse becomes inevitable and irreversible. That would lock us into a future sea level rise of far more than half a metre or so. The reason is simple: today, Thwaites is a brake on large inland glaciers. Lose Thwaites, and those it holds back will follow. Over centuries perhaps, they would add fully 2m to sea level rise.  Nearly 100 scientists and support staff recently arrived at Thwaites, a place as inhospitable as Earth can muster, for an urgent and ambitious field expedition. Among the British and American teams are scientists, engineers and technicians who have set up tents on Thwaites ice shelf, the slab of glacier that has slipped off the Antarctic bedrock on to the sea. They have now set up a hot water drill to bore through the 600m shelf into the frigid waters beneath. It is a process that takes days, with small teams working nonstop around the clock. Why drill down? With the borehole open, the researchers will winch down a torpedo-shaped robotic submarine called Icefin. It will slip into the depths and make for the grounding line, where the base of the glacier lifts off the land. There it will inspect a grim discovery that Nasa scientists made some months back. Flying over the glacier on a plane fitted with ice-penetrating radar, they spotted a gigantic hole at the base of Thwaites. At 4km wide and 10km long, it is two-thirds the area of Manhattan. The 350m-tall cavern formed over three years when 13bn tonnes of ice melted away. Water had found its way between the glacier’s rough base and the bedrock to melt it, unnoticed, from below. Thwaites will surely now deteriorate faster. It is a stark reminder that for all the observations and sophisticated climate models that scientists produce, nature can still serve up unwelcome surprises. The fact is that we are ill-equipped to model precisely a global system as devilishly complex as the climate. If we don’t know every detail – every process, every threshold, and the direction and strength of every feedback loop – we must always expect surprises. This might be the lesson of Thwaites glacier. In both the US and the UK – the countries behind the expedition – science is in peril. The Royal Society warns that Britain is losing top scientists amid ongoing Brexit uncertainty. In the US, the administration has set itself against science, particularly in environmental disciplines, and scores of researchers have quit their posts. If Thwaites tells us anything, it is that we need more science, not less, to survive the climate crisis. Without it, we will not understand the full threat we face, nor be well placed to mitigate its most dangerous consequences. If we want to avoid more unwelcome surprises, we must not let our guard down. "
"
Share this...FacebookTwitterPeople familiar with the chaos that is weather will agree that seasonal forecasts based merely on computer simulations are highly speculative and involve much guesswork. The quality of their output leaves little to be desired.
As much as some of these forecasts may be presented with authoritative tones, in the end they all come with a fine print disclaimer concerning certainty, and so they are nothing one can take to the bank.
The average of a series of WAGs
Even the most powerful super-computers using conventional simulations struggle to predict the weather 10 days out, let alone what an entire a winter will be like in terms of temperature and precipitation. The simulations used by the US weather agencies, for example, simply perform a number of data crunching runs — each using different start conditions — to generate  a set of scenarios (i.e. wild-ass guesses) and then average them out to create an “ensemble”. Under the bottom line, the ensemble is based on a set of wild ass guesses, and so is correspondingly unreliable.
Woefully uncertain
Not surprisingly, Germany’s flagship daily Frankfurter Allgemeine Zeitung (FAZ) also finds that the ensembles leave very little to be desired and point out that the seasonal forecasts issued by weather agencies such as the NOAA are hugely uncertain, and that clearly the computer simulation methodology is in dire need of improvement.
Even farmers seem to have greater success.
So what can be done to improve forecasting performance?
The FAZ writes that a whole new methodology has been developed by German scientists and that this new methodology promises to vastly improve seasonal forecasts. The FAZ writes that earlier this year a study by the University of Hamburg was published in the Geophysical Research Letters. The press release announced: “Possible for the first time: reliable three-month forecasts for European winters“.
80% winter season accuracy


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to the FAZ, oceanographer Dr. Mikhail Dobrynin of the Hamburg University Institute of Oceanography, Center for Earth System Research and Sustainability and his colleagues have developed a method that works with 80% success rate. Instead of solely relying on a super computer crunching data using a variety of start conditions and then averaging them out, Dobrynin says their method relies also on “teleconnections”, i.e. finding “signals amid the chaos“.
The FAZ reports that for winter forecasts, Dr. Dobrynin has identified four factors: “the snow depth in Siberia, Arctic polar vortex, extent of Arctic sea ice and the Atlantic ocean temperature”, which allow “the path of certain air masses going to Europe to be predicted”. The most critical of these is the snow cover over Siberia in fall.

The NAO index is one key factor in seasonal winter forecasts for Europe. Source: Geophysical Research Letters.
The scientists say that conditions in different geographical regions over the Atlantic “can act as a switch that steers winter weather in Europe” and that focusing on how these interact and behave can allow greatly improved forecasting.
According to the conclusion of the study, the method shows vastly improved performance:

For the real forecast test from 2001 to 2017 the prediction skill of the winter NAO is increased from 0.42 for the full ensemble mean to 0.86 for the subsampled ensemble mean. As a result of a better representation of the winter NAO, the prediction skill for the winter surface temperature, total precipitation, and SLP is improved for considerable parts of the NH.”

NOAA forecasts “hardly better” than guessing
The FAZ writes that “without considering teleconnections, winter in Europe has been virtually unpredictable”. 
Dr. Mikhail Dobrynin added that results of forecasts made by the NOAA “were hardly better” than if they had guessed. The new method should thus improve the winter season forecasts considerably. However, he warns that the uncertainty will always exist and we must remain wary of any predictions dealing with seasonal weather.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Kirye
Increasing CO2 in the atmosphere is supposed to be trapping heat and thus warming the global temperature.
But when we look at the Japan Meteorological Agency (JMA) statistics from my home country of Japan, one does not find any such warming over the recent decades.
I looked at the number of so-called cold days in Tokyo, i.e. days on which the thermometer dropped to 0°C and colder. Surprisingly over the past 30 years the trend has been more cold days, and not less:

Data source: JMA
Next I looked at the rural station of Miyama near Kyoto. This station shows a decreasing number of cold days trend since the data there began:

Data source: JMA
However, when we look at the past 34 years, a period when experts said in the late 1980s we’d see great warming, the opposite has in fact occurred:

Data source: JMA
The number of cold days at Miyama has since been on the rise. And if I started the chart at 1989 (30 years), the upward trend would be even more impressive.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Now moving far north to Hokkaido to the station of Suttsu, we also find the trend is the same over the past 30 years: we are seeing more cold days, and not less as we’d expect from a warming planet:

Data source: JMA
Moving to Kochu Prefecture to Murotomisaki station, here as well we find no downward trend for cold days. Cold days are on the rise:

Data source: JMA
Also the station of Tottori has been seeing an upward trend in the number of cold days over the past 30 years:

Data source: JMA.
90% no warming!
Of course over the past 200 years there has been a long term warming as the planet climbed out of the Little Ice Age. But overall over the past 3 decades, Japan has been seeing an increase in cold days. This should not come as a surprise because recently we found out that 90% of all rural sited stations in Japan have shown no warming trend, or even cooling, over the past 20 years.
The data show here has been no warming in Japan, and leaders need to finally acknowledge this.
Obviously natural factors are overwhelming CO2’s (modest) greenhouse effect.
Share this...FacebookTwitter "
"Ever thought how the ingredients for that bacon sandwich got to your plate? By that, I mean the amazing historical journey that has transformed the animal and plant species we farm today into the huge global biomass that now feeds billions of us. The shift from hunting and foraging to farming began some 12,000 years ago and was one of the most fundamental shifts in our own species’ evolutionary and cultural history. It set up exponential population growth and health consequences we still live with today. The animals and plants that underpin all this are those we changed forever through a phenomenon called “domestication”. It’s an enigmatic process we still know little about. For decades, scientists (including Charles Darwin) have argued about how domestication works, with much ink being spilt contrasting the deliberate human role versus that of a natural biological process. Back to that bacon sandwich. The pig was one of the first farmyard animals to be domesticated, and today pork is the most widely eaten meat across the globe. Pigs are also important for the pharmaceutical industry – they’re the source of more than 20 key drugs – while “transgenic” pigs can provide humans with heart-valve transplants and maybe in future entire organs. So where did this illustrious farmyard animal’s domestic relationship with humans begin? Its ancestor the wild boar (Sus scrofa) is distributed across the vast majority of Europe and Asia, meaning it could have been domesticated almost anywhere. However, zooarchaeological evidence (the bones and teeth of animals) indicate pig domestication probably began in Eastern Turkey some 9-10,000 years ago and then, independently, several thousand years later in central China. Recent research matching DNA from wild boar populations to domestic pigs suggests pig domestication occurred in additional places across the Old World – including Europe. Archaeologists traditionally thought humans directly intervened early in the process, isolating a few individuals from the local wild population. Once these “proto-domestic” animals were separated from their wild counterparts, the theory goes, there was no further significant breeding between the two. This should be especially true for pigs, since the re-introduction of “wild” traits back into domestic stock would be particularly undesirable – no farmer wants hairy pigs with attitude and dangerous tusks who keep wanting to escape. This form of domestication should result in a genetic “bottleneck” – an evolutionary process not unlike that involved in the natural (or human-mediated) dispersal by mammals to remote islands. Then, over the next several generations of breeding and selection in this small group, the looks and behaviour that differentiate domestic from wild forms would appear. Others, however, argue domestication was much more dynamic and fluid, occurring over a longer timescale and involving more-or less continuous gene flow between wild and domestic populations. They challenge claims of additional instances of pig domestication beyond the Near East and China, stating that genetic data could equally be explained by ongoing breeding with wild boar as domestic swineherds moved across Eurasia with early farmers. In a new paper published in Nature Genetics, researchers from Oxford and Wageningen University (Netherlands) have applied advanced modelling approaches to genomic data from pigs and wild boar in order to resolve these longstanding contradictory viewpoints. Their results are compelling and throw new light on the process of domestication. First, the data shows modern-day domestic pigs to be a mosaic of different wild boar populations, supporting previous conclusions drawn from studies of modern and ancient DNA. Their results, however, don’t support previous claims for the existence of numerous other centres of pig domestication outside Western Asia and China. Their modelling of genomic data from Western Asia and Europe instead implies continuous and significant gene flow between wild boar and domestic pigs across these regions and, crucially, no evidence for a genetic bottleneck in European domestic pigs. But how were the distinctive traits that differentiate wild and domestic forms of Sus scrofa maintained in the face of continued gene flow back and forth? The highly plausible explanation is that recurrent intentional or unintentional selection for similar traits somehow counteracted its effects, creating what the researchers calls “genomic islands of domestication” – that is, pigs in some regions were less affected by gene flow from wild boar.  These so-called genetic sweeps seem to have had the same affect on pig genomes in the two geographically isolated regions of the world where pigs were independently domesticated, hinting at a more fundamental underlying genetic and developmental basis for the process – perhaps involving a number of so called “domestication genes”. This new genetic data is finally allowing us to move beyond questions about when, where and how many times pigs were domesticated, to how the process actually worked. Something to think about, next time you tuck into your bacon sandwich."
"As Australia’s unprecedented bushfire season continues to unfold, competing arguments have been made about the principal causes of the human and environmental tragedy – particularly around the role of climate change. The prime minister, Scott Morrison, has acknowledged that climate change has had an influence on the fires and has defended his government’s climate record. But Morrison has also said that “job-destroying, economy-destroying, economy-wrecking targets and goals” on climate change “won’t change the fact that there have been bushfires or anything like that in Australia”. Backbench MP Craig Kelly denied any link between climate change and bushfires in a combative interview on British TV. Conservative media have concentrated on other factors, such as the amount of hazard reduction burning carried out, or the activities of arsonists – a claim shown to have been inflated and misrepresented. Bushfire experts say that in normal years hazard reduction is a way to control the behaviour of fires, but the changing climate is making it harder to carry out prescribed burns and, according to fire chiefs, it is not a “panacea” for extreme bushfires. Here is what we know about the long-term influences on the bushfire catastrophe. Extreme heat and dryness are two important influencers of fire and, on both measures, 2019 was remarkable for Australia. Australia experienced its hottest year on record in 2019, with average temperatures 1.52C above the 1961-1990 average. Our second hottest year was 2013, followed by 2005, 2018 and 2017. New South Wales – one state hard hit by the bushfires – broke its record by a greater margin, with temperatures 1.95C above average, beating the previous record year, 2018, by 0.27C. At a very basic level, rising levels of greenhouse gases in the atmosphere change the Earth’s radiation balance, allowing less heat to escape. Australia also had its driest ever year in 2019, with rainfall 40% lower than average, based on records going back to 1900. NSW also had its driest year. A visualisation from Prof Nerilie Abram, a climate scientist at the Australian National University, examines hot and dry years in Australia since 1910 and how they correlate with major bushfires. Fire authorities and the Bureau of Meteorology look at the risk of bushfires using the forest fire danger index, a combined measure of temperature, humidity, wind speed and the dryness, but not the amount, of fuel on the ground. Australia’s 2019 spring months of September, October and November were the worst  on a record going back to 1950 for bushfire risk. There have been two other meteorological patterns that helped generate the extreme conditions Australia has been experiencing, and both these “modes of variability” were in “phases” that made conditions worse. The Indian Ocean dipole was in a “positive phase”, meaning the Indian Ocean off Australia’s north-west was cooler than normal and the west of the ocean was warmer. Positive dipole events draw moisture away from Australia and tend to deliver less rainfall. But there is evidence that the extra greenhouse gases in the atmosphere are also impacting the dipole and another phenomenon, known as the southern annular mode (SAM). A 2009 study found that positive dipole events “precondition” the south of the country for dangerous bushfire seasons and that these events were becoming more common. A 2018 study in the journal Nature Communications found the number of extreme positive dipole events goes up as climate heating continues. At 1.5C of global warming, the frequency of extreme positive dipole events doubles compared with the pre-industrial period. The southern annular mode was in a “negative phase” as the bushfires took hold in November and December. This phase was generated by a sudden warming event in the stratosphere above Antarctica. This caused westerly winds to track further north, blowing hot air across the continent into fire-prone areas, further fanning flames. Abram’s own research has found that the SAM is being pushed towards more positive phases which, when they occur in Australia’s winter, tend to dry the continent. Prof Matt England, of the University of New South Wales Climate Change Research Centre, said: “These modes of variability are not changing in a way that’s good for south-east Australia. “We know with certainty that we are stacking the dice for the chances of these extreme drought years because of the changes in the modes.” Scientists have already detected a trend towards more dangerous fire weather in Australia. A 2017 study of 67 years of FFDI data found a “clear trend toward more dangerous conditions during spring and summer in southern Australia, including increased frequency and magnitude of extremes, as well as indicating an earlier start to the fire season”. That trend continued in 2019, which was the riskiest year for bushfires on a record going back to 1950. A study of Queensland’s historic 2018 bushfire season found the extreme temperatures that coincided with the fires were four times more likely because of human-caused climate change. In advice issued in November 2019, Australia’s National Environmental Science Program was unambiguous. “Human-caused climate change has resulted in more dangerous weather conditions for bushfires in recent decades for many regions of Australia. “Observations show a trend towards more dangerous conditions during summer and an earlier start to the fire season, particularly in parts of southern and eastern Australia. “These trends are very likely to increase into the future, with climate models showing more dangerous weather conditions for bushfires throughout Australia due to increasing greenhouse gas emissions.” Despite such unequivocal statements, Scott Morrison has been irritated that interviewers have asked about his government’s record on climate change, saying it was “just ridiculous” to link “any one emissions reduction policy to any of these fires”. Morrison’s argument that no emissions reduction policy can be tied to individual events is spurious, as the same argument could be put for any and all efforts to reduce emissions anywhere in the world, at any time. Scientists also believe that 2019 was a “standout” year in Australia for the formation of extreme bushfires that became “coupled” with the atmosphere, generating their own lightning and gusty, violent and unpredictable winds. Rainfall is replaced with blackened hail and embers that can be shot out over distances of 30km. Another study has found that global heating will create more favourable conditions for these “pyroCB” storms to form in Australia. Climate studies show that conditions in Australia for extreme bushfires will only get worse as more greenhouse gases are added to the atmosphere. On Friday afternoon the president of the Australian Academy of Science, Prof John Shine, said Australia would need to further improve its climate modelling ability and understanding of fire behaviour to mitigate against the extreme events that would become more frequent and intense because of climate change. “Australia must take stronger action as part of the worldwide commitment to limit global warming to 1.5° C above the long-term average to reduce the worst impacts of climate change,” he said. England said: “We are loading the dice for more and more of these summers. But we have had knowledge of this for some time. “What we have seen in Australia this year will just be a normal summer if we warmed the planet by 3C. And an extreme summer would be even worse than we’ve seen now.” Abram said: “Even from my perspective, I am surprised by just how bad 1C of warming is looking. “It’s worrying that we are talking about this as a new normal, because we are actually on an upward trajectory. Currently the pledges in the Paris agreement are not enough to limit us to 1.5C – we are looking more like 3C.”"
nan
"Barclays is being urged to stop offering loans to fossil fuel companies as part of the first ever shareholder climate resolution aimed at a UK bank. A group of 11 pension and investment funds managing more than £130bn worth of assets have filed a resolution calling for Barclays to set clear targets to phase out services to energy companies that fail to align with Paris climate goals. That includes lending to specific fossil fuel projects or for companies themselves, which include electricity and gas providers which fall foul of climate targets. The Paris agreement requires emissions to peak then fall rapidly to reach net-zero by 2050. The resolution, spearheaded by the campaign group ShareAction and signed by more than 100 additional individual shareholders, will be voted on at Barclays annual general meeting in May 2020. The Brunel Pension Partnership (BPP) – which manages £30bn for local government pension schemes across counties such as Devon, Dorset, Oxfordshire, Somerset and Cornwall – was among the institutional investors backing the resolution. The 11-strong group owns about 0.2% of Barclays shares. BPP’s chief executive, Laura Chappell, said the climate crisis was putting its own client’s retirement benefits at risk. “Climate change poses significant risks to global financial stability and could thereby create climate-related financial risks to our own business operations, portfolios and client partner funds, unless action is taken to mitigate these risks.” She added: “We hope the Barclays Board formally supports this resolution.” A recent study commissioned by groups including the Rainforest Action Network singled Barclays out as the largest financier of fossil fuels in Europe and the sixth largest in the world. It showed that total lending and underwriting to carbon-intensive companies and projects totalled $85bn (£64bn) between 2015 and 2018. Barclays has also been criticised by groups including ShareAction and Greenpeace over its climate policy, which they say does not go far enough to address the crisis. While the bank said in January last year it would stop financing greenfield mining and construction or expansion of coal-fired power stations in all countries, it still allows Barclays to bankroll companies that are highly dependent on coal. It also stops short of ruling out backing controversial tar sands projects and allows the bank to support Arctic oil and gas projects. The resolution comes ahead of the Bank of England’s first ever climate stress tests, which will force the UK’s largest banks to report how exposed they are to the climate crisis and how they would respond to temperatures rising by up to 4C. The bank has warned that drastic environmental damage could hit financial institutions by reducing asset values, lowering profitability and raising the cost of underwriting insurance losses. Barclays is among the eight lenders expected to go through the exercise. While the central bank will only release aggregate results to the public, it plans to use the first batch of reports to inform how it supervises each company. Barclays said: “We are working to help tackle climate change, and we meet with Share Action and other shareholders regularly to update them on our progress.” Arcus Foundation As You Sow Brunel Pension Partnership Central Board of the Methodist Church Falkirk Council Pension Fund Folksam Jesuits in Britain Lankelly Chase LGPS Central Merseyside Pension Fund Sarasin & Partners"
"Today the student movement made history by announcing that more than half of UK universities have committed to divest from fossil fuel companies. Since 2012, students have campaigned to marginalise companies like Shell and BP which profit from climate breakdown. The campaign, supported by the National Union of Students,People & Planet and Students Organising for Sustainability UK, has shown the power of students taking collective action. The University of Glasgow was the first UK university to divest in October 2014, and was soon followed by major divestments after sustained campaigns at institutions including Warwick, Sheffield, King’s College London, Edinburgh and Durham. The 50% mark was reached when the University of York became the 77th UK university to divest.  As we celebrate this moment, we should also reflect on how it has taken us so long to get here. We should ask why globally important universities including Oxford and Cambridge still refuse to move their money out of all fossil fuels. Despite growing declarations of climate emergency, 50% of UK universities remain invested in the principle profiteers of the climate crisis. At a time when Australia burns in the bushfire crisis and climate deniers remain in positions of power across the globe, this lack of action is unforgivable. The social licence of the fossil fuel industry has already been significantly damaged. We’ll now use this moment as a springboard to continue campaigning until the whole university sector has divested and the fossil fuel industry can no longer operate. The need to keep up the pressure on these companies couldn’t be clearer. Indigenous and frontline communities are still fighting for their rights in response to the way these transnational corporations operate in their communities. The First Nations continue their decades-long resistance against tar sands expansion in Canada, while the Movement for the Survival of the Ogoni People in the Niger Delta are still fighting Shell’s business model which, we believe, causes dispossession and destruction across the region. Our solidarity with impacted communities is crucial. The support for fossil fuel imperialism by the UK government underlines our imperative to act here too. In Argentina, bilateral trade agreements with the UK support the business ventures of companies like BP. Here, BP operates through its part-ownership of Pan American Energy (PAE) and is involved with the exploitation of Vaca Muerta, one of the world’s largest shale oil and gas reserves. Multinational oil companies are acting in violation of the rights of the Mapuche indigenous people, who have not given consent for the extraction that destroys their ancestral home to take place. The government remains an active participant in the exploitative business models of oil companies overseas. This is particularly concerning at a time when new fossil fuel infrastructure needed to stop being built by 2017 to remain within the 1.5 degree parameter the Paris Agreement identified as a limit. As students and universities we can keep the pressure on by ensuring civil society is fully divested from the fossil fuel industry. Universities are meant for the public good and so must lead the way in displaying how the UK takes responsibility for our actions in the world. They should be at the forefront of making the links between the struggles for climate justice and other social justice issues. The universities that have divested should use that commitment as a platform to intervene in the fight against land dispossession by fossil fuel companies and struggles against racist, forced deportations. At their roots are a system built on exploitation, dispossession, empire, imperialism and colonialism. The fossil fuel industry and its partners in corporate crime will continue to increase their resistance to all those fighting it. In light of that, so must we. Zamzam Ibrahim is the president of the National Union of Students"
nan
"The summer heatwaves of 2019 resulted in almost 900 extra deaths, according to statistical analysis from Public Health England. Over the past four years more than 3,400 people have died early during periods of extreme temperature in England. Global heating is increasing the frequency of heatwaves and a cross-party committee of MPs warned in July that the UK was “woefully unprepared” for this impact of the climate emergency.  All regions of England were affected except the south-west, and almost all the premature deaths were among people aged 65 or over. The frail elderly with heart or kidney problems are most at risk in a heatwave and dehydration can also lead to dizziness and falls. The physicist Edward Teller tells the American Petroleum Institute (API) a 10% increase in CO2 will be sufficient to melt the icecap and submerge New York. “I think that this chemical contamination is more serious than most people tend to believe.” Lyndon Johnson’s President’s Science Advisory Committee states that “pollutants have altered on a global scale the carbon dioxide content of the air”, with effects that “could be deleterious from the point of view of human beings”. Summarising the findings, the head of the API warned the industry: “Time is running out.” Shell and BP begin funding scientific research in Britain this decade to examine climate impacts from greenhouse gases. A recently filed lawsuit claims Exxon scientists told management in 1977 there was an “overwhelming” consensus that fossil fuels were responsible for atmospheric carbon dioxide increases. An internal Exxon memo warns “it is distinctly possible” that CO2 emissions from the company’s 50-year plan “will later produce effects which will indeed be catastrophic (at least for a substantial fraction of the Earth’s population)”. The Nasa scientist James Hansen testifies to the US Senate that “the greenhouse effect has been detected, and it is changing our climate now”. In the US presidential campaign, George Bush Sr says: “Those who think we are powerless to do anything about the greenhouse effect forget about the White House effect … As president, I intend to do something about it.” A confidential report prepared for Shell’s environmental conservation committee finds CO2 could raise temperatures by 1C to 2C over the next 40 years with changes that may be “the greatest in recorded history”. It urges rapid action by the energy industry. “By the time the global warming becomes detectable it could be too late to take effective countermeasures to reduce the effects or even stabilise the situation,” it states. Exxon, Shell, BP and other fossil fuel companies establish the Global Climate Coalition (GCC), a lobbying group that challenges the science on global warming and delays action to reduce emissions. Exxon funds two researchers, Dr Fred Seitz and Dr Fred Singer, who dispute the mainstream consensus on climate science. Seitz and Singer were previously paid by the tobacco industry and questioned the hazards of smoking. Singer, who has denied being on the payroll of the tobacco or energy industry, has said his financial relationships do not influence his research. Shell’s public information film Climate of Concern acknowledges there is a “possibility of change faster than at any time since the end of the ice age, change too fast, perhaps, for life to adapt without severe dislocation”. At the Rio Earth summit, countries sign up to the world’s first international agreement to stabilise greenhouse gases and prevent dangerous manmade interference with the climate system. This establishes the UN framework convention on climate change. Bush Sr says: “The US fully intends to be the pre-eminent world leader in protecting the global environment.” Two month’s before the Kyoto climate conference, Mobil (later merged with Exxon) takes out an ad in The New York Times titled Reset the Alarm, which says: “Let’s face it: the science of climate change is too uncertain to mandate a plan of action that could plunge economies into turmoil.” The US refuses to ratify the Kyoto protocol after intense opposition from oil companies and the GCC. The US senator Jim Inhofe, whose main donors are in the oil and gas industry, leads the “Climategate” misinformation attack on scientists on the opening day of the crucial UN climate conference in Copenhagen, which ends in disarray. A study by Richard Heede, published in the journal Climatic Change, reveals 90 companies are responsible for producing two-thirds of the carbon that has entered the atmosphere since the start of the industrial age in the mid-18th century. The API removes a claim on its website that the human contribution to climate change is “uncertain”, after an outcry. Exxon, Chevron and BP each donate at least $500,000 for the inauguration of Donald Trump as president. Mohammed Barkindo, secretary general of Opec, which represents Saudi Arabia, Kuwait, Algeria, Iran and several other oil states, says climate campaigners are the biggest threat to the industry and claims they are misleading the public with unscientific warnings about global warming. Jonathan Watts “Heatwaves continue to result in significant health impact,” said the PHE report. It reported the “excess deaths” during the heatwaves, ie the additional mortalities compared with the long-term average for those dates. Two heatwaves accounted for the 892 deaths. The first, from 21 to 28 July, included the highest temperature ever recorded in the UK: 38.7C in Cambridge. The second occurred between 23 and 29 August. The climate crisis made 2019 a year of record temperatures in the UK, according to the Met Office. The only region that recorded a statistically significant number of deaths in those under 65 was London, with 41 early deaths reported during the August heatwave. “Tragically, many of these deaths are likely to have been preventable,” said Bob Ward, at the Grantham Research Institute on Climate Change at the London School of Economics. “Many of the people who are killed by heatwave conditions die in their own homes or in care homes. The Committee on Climate Change (CCC) pointed out in July 2019 that the government has failed to set out a coherent plan for implementing the adaptations required.” The CCC said it had been recommending new building regulations to ensure homes, hospitals and schools do not overheat since 2015, but that this advice had been rejected by ministers, who cited a commitment to “reduce net regulation on homebuilders”. Without action, the number of people dying as a result of heat is expected to reach 7,000 a year by 2040, the CCC said. “The CCC also noted that although there has been a heatwave plan for England since 2004, there is no evidence that it has reduced the number of deaths that occur during hot weather,” said Ward. The report from the House of Commons environmental audit committee said hospitals and care homes in particular must be prepared for heatwaves, given that sick and elderly people are most vulnerable. But they say currently the NHS is only required to prepare plans for severe cold weather. “The government needs to take much more seriously the dangers of hot weather. The threat of deadly heatwaves is growing due to climate change and the death toll is likely to rise unless there is strong action,” said Ward. The Department of Health has been contacted for comment."
"The Australian actor Yael Stone has vowed to give up her green card, which allows her to work in the United States, as a “personal sacrifice” aimed at reducing carbon emissions in what she called the “climate war”. In a video posted to Twitter on Tuesday and Instagram on Sunday, the actor and star of Netflix’s Orange is the New Black said she came to the decision to give up her green card “after a long, considered process”.  “We’ve come to understand that it’s unethical for us to set up a life in two countries, knowing what we know,” Stone said in the video, calling such frequent travelling “environmentally unjust”. “The carbon emissions alone from that flying – it’s unethical. It’s not right. So I will be going through the process of giving up my green card, and saying goodbye to a life in America. I’m going to be here in Australia doing the the work I can to make a difference here. Because the time is now.” Not environmentally ethical to build a life across two continents. Time to make a sacrifice. pic.twitter.com/4gFVImMeMg In an earlier video posted to Instagram on Sunday, Stone expressed horror at the political response to Australia’s ongoing and months-long bushfire crisis. “I’m sitting in a dark room wondering what the hell is happening. Our country is on fire … and our prime minister has done absolutely nothing. Cold, calculated nothing. We don’t have leaders, we have cowards,” she said.  Death and destruction here in Australia. It’s time to act. This is war. A post shared by  Yael Stone (@yaelstone) on Jan 3, 2020 at 7:29pm PST The actor, who recently starred in Sydney Theatre Company’s production of The Beauty Queen of Leenane, also implored others to act. “The leaders we have are the people around us. And that’s what we have to become. “We have to step up because this is war. This is a climate war. And for the first time our enemy is not wearing a uniform that we’ll be able to recognise. Our enemy is our own behaviour.” Stone said giving up her green card was a way that she could put “skin in the game”. “This is war, and we’ve only got 10 years. So let’s make these sacrifices. Let’s make these changes. Let’s put some skin in the game and say yeah, I care, and this is what I’m going to do about it. This is just the beginning from me,” she said. “It’s corporate wide, it’s government wide, it’s systematic changes that must happen, and they must happen yesterday. It’s time to act.”"
nan
"As fires rage across Australia, floods wash away villages and temperatures break records, scientists are wheeled out and asked by journalists is this climate change? The answer is always fudged, along the lines of “individual events cannot be put down to climate change, this is just an extreme of weather, only further research can tell if there is a connection.” This proper and natural scientific caution has been reinforced by decades of attacks by the fossil fuel lobby, plus threats to remove grants and university tenure. The same cautious approach has also infected science journalists who repeat the same formula.  But this mantra “It’s weather not climate” can now be discarded because Swiss scientists have shown that windstorms, floods, droughts and heat waves – events as short as a single day – can be placed firmly at the door of global heating. The weather will go on varying wildly from day to day but the Swiss have been able to prove that these swings are made worse by extra temperature and moisture in the atmosphere. In other words every extreme has been made greater by man-made climate change. Let us hope that every climate scientist and journalist reads the Swiss paper and when asked the question “Is this global heating?” now just says “yes.” "
"Humans are notorious for cheating and deceiving. But we also like to see cheaters get punished. Surprisingly, our research has revealed that the same holds true in the animal kingdom – at least among birds.  We found that African cuckoo finches – brood parasites that rely on a different kind of bird to raise their young – have evolved to look like harmless weaver birds in an attempt to deceive their hosts. But we also discovered that their tawny-flanked prinia hosts have caught onto this and responded by being aggressive to anyone resembling their enemy – a form of collective punishment.  Brood parasites never build their own nests or raise their own offspring. Instead, they lay their eggs in the nests of other birds and abandon the care of their young to the hosts. The first act of most brood parasite species’ chicks after hatching is to do away with the host’s own brood. Different species do this by ejecting their nest mates from the nest, by using their sharp beaks to fatally injure them, or by physically dominating them.  While hosts obviously do all they can to defend their nests, brood parasites evolve responses to this behaviour. This in turn drives the evolution of better defences in the host, and so on – a process known as an “evolutionary arms race”.  One of the most common strategies for brood parasites to manipulate their hosts into raising their offspring is known as “aggressive mimicry”. This is a way for the birds to dupe a host by looking harmless, for example by resembling a species that is not parasitic. The strategy is already well-documented in a variety of brood parasite species: some lay eggs that resemble those of their hosts, while the chicks and fledglings of others look (and sound) like the host’s own chicks and fledglings. This is necessary, as hosts will reject parasitic eggs, chicks and fledglings, if they can detect them. The first challenge for brood parasites is for a female to get her egg into a host nest. Because of this hosts are often very aggressive towards adult brood parasites near their nests. Our research focused on whether natural selection has shaped aggressive mimicry in female brood parasites to help them slip past host defences.  We specifically looked at cuckoo finches, as there is already good evidence of an evolutionary arms race between it and its primary host in southern Zambia, the tawny-flanked prinia. We were suspicious that adult female cuckoo finches might be employing aggressive mimicry to get into their host’s nest because they look remarkably similar to another group of species that shares their grassy habitats: females of the several common species of weavers, known as bishopbirds or widowbirds. Is this coincidence, or a deceptive strategy shaped by natural selection? To answer this question, first we measured and compared the colour and pattern of cuckoo finches’ plumage to those of Vidua finches (the cuckoo finch’s closest relatives) and weavers at the Natural History Museum at Tring, UK.  If female cuckoo finches looked more similar to Vidua finches than to weavers, then it would suggest that the cuckoo finch plumage is a product of their shared ancestry. If they looked equally similar to Vidua finches and weavers, it would suggest that their plumage has been shaped through shared selection pressures from a shared environment (for example, having to avoid shared predators). However, if they looked more similar to the weavers than the Vidua finches, it would suggest that natural selection for mimicry has driven their resemblance. We found the latter, which suggested that female cuckoo finches have evolved to mimic weavers. We then conducted two field experiments in southern Zambia to test whether we could verify this apparent case of mimicry. This meant months of long days watching these birds from the inside of a hide, which was absolutely brilliant! Using model cuckoo finches and model southern red bishops (a common weaver species at the study site), we tested whether the prinias reacted differently towards female cuckoo finches and female southern red bishops, compared to male cuckoo finches and male southern red bishops. Unlike females, males of these two species look very different: male cuckoo finches are bright yellow and male southern red bishops are black and red. Surprisingly, we found that the prinias were extremely aggressive to both the harmful female cuckoo finches and harmless southern red bishops – treating both as threats. They were not, however, aggressive to males of either species.  So were the prinia really deceived by the cuckoo finches’ mimetic plumage? To answer this, we carried out one last experiment. We presented a female cuckoo finch, a female southern red bishop or a male southern red bishop model near a prinia nest. After that, we replaced a prinia egg with an experimental egg to simulate egg laying by a real cuckoo finch. Just as expected, we found that the prinias were much more likely to reject the foreign egg after seeing one of the two female species than when they saw a male bird. This showed that they were unable distinguish between the two female species and that the cuckoo’s mimicry is successful, but does not give the cuckoo finch the advantage in the arms race at this site.  The analogy of the “wolf in sheep’s clothing” could be helpful here. The prinias recognise the wolf as a threat, but as they are unable to tell wolves from sheep, they respond by punishing all the sheep, just to be safe.  This is unfortunate for the cuckoo finch – and we suspect this is because the rate of parasitism is consistently high at this site, making this strategy worthwhile for the crafty prinias. Similar to cheating in human society, it seems like the real loser in this situation is the innocent bystander: the unassuming female southern red bishop."
"The world’s tides contain enough energy to power the entire UK’s electricity consumption. And, since it effectively harnesses the moon’s constant and predictable gravitational pull, tidal power overcomes one of renewable energy’s classic problems – the fact you never know quite how much sun, wind or rain to expect. Now, underwater windmills positioned just below the ocean surface could be a major breakthrough for tidal power. Costly technology and inaccessible locations have thus far held things back. Large, heavy and expensive turbines mounted on the seabed have been developed, but these are aimed at commercial scale developments. Tidal power needs its equivalent of the rooftop solar panel. Imagine then a wind turbine, but underwater, and not fixed to the seabed – these so-called “mobile floating turbines” are a cheaper and more adaptable alternative to big, fixed developments. Most floating turbines look something like this: They’re placed whereever tidal flows will be strongest, and are then loosely tethered to (but not built on) the seabed. Cables take power generated by the turbines down to the seabed and along to the shore. Floating turbines are able to capture energy from the fastest-flowing water, which tends to be just below surface. At the bottom, where the water bumps against the seabed, things slow down and the flow is less smooth. Turbines floating in the right place could generate significantly more energy than those stuck to the sea bed. Tidal currents also shift direction roughly every six hours, therefore an optimal turbine would take advantage of these two-way flows. Floating turbines can freely rotate in the changing tide, eliminating the need for costly and complex mechanical yawing systems used by bed-mounted turbines.  Deploying large, heavy turbines on the bed requires expensive specialised vessels and docks. Even routine maintenance is costly.  In contrast, floating turbines can be towed to a site and installed very quickly at a fraction of the cost. Internal machinery can be positioned above the waterline allowing instant access for routine maintenance and minimal waterproofing costs.  Since they’re relatively cheap to set up and operate, floating turbines are suited for a wider market, not just utility companies. Industries close to the coast could invest in a floating turbine to reduce their electricity bill, in much the same way as they are currently doing with solar or wind technologies. You can even “plug in” multiple turbines by sharing mooring points.   While bed-mounted turbines aren’t visible from the surface, most floating turbine designs would be visible and could interfere with shipping lanes or be exposed to floating debris.  Floating turbines could be best suited to sheltered tidal environments such as estuaries, since storm waves could interfere with their power output and operation. Numerous floating turbine designs exist, utilising a variety of interesting innovations. Some have a hull which floats on the surface while the turbines operate underwater, as in the case of Scotrenewable’s SR2000 which claims to be the “largest and most powerful tidal turbine in the world”. Its 64m long hull and 16m diameter turbine blades are designed to last for 20 years.  Other floating designs include a modular design for easy transportation and assembly anywhere in the world, or a specially-streamlined turbine moored to a swivelled connector, for use in rough seas. Some “floating” tidal turbines actually bob somewhere just below the surface. In one design a “hinge” on the sea bed is attached to a semi-submerged platform that can fit up to 36 turbines, which can freely rotate into the flow. Developer Black Rock considers lots of independent and inexpensive turbines positioned to catch the optimum tidal flow a better configuration than a single larger turbine. Floating turbines demonstrate the continued effort towards exploiting the vast tidal energy resource. The sector is growing ever closer to commercial scale arrays using bed-mounted turbines, but floating turbines could increase development opportunities further."
"This is an article from Curious Kids, a series for children of all ages. The Conversation is asking young people to send in questions they’d like an expert to answer. All questions are welcome. Skip to the bottom to see how to enter.  How do the clouds stay up in the sky? – Samson, age four, London, UK. Thanks for the question, Samson. Believe it or not, I once weighed a cloud and not many people can say they have done that! My scientist friends and I flew up into the sky in a giant airship, and went all the way through a fluffy, white cloud. Actually, it was very wet up there, because clouds are made up of billions of tiny water droplets.  As we flew through the cloud, we used lasers and other special scientific devices to measure how big the cloud was, and count how many tiny droplets of water were in it. Then, we did some maths and found that this cloud – which was actually pretty small, for a cloud – weighed four tonnes. That’s the same as two elephants! So, you’re right to wonder how such a heavy thing can stay up in the sky.  There are three pieces to this puzzle, and the first one is gravity. Like everything on this planet, the tiny droplets that make up a cloud are drawn towards the Earth by gravity. But these droplets are so small that it’s hard for them to push past all the air beneath them. This means that they don’t fall very fast at all – in fact, only about one centimetre per second. And any wind blowing upwards can carry the droplets back up.  To fit the second piece of the puzzle, we’ll need to learn some proper chemistry; not too much, though, just enough for our story. Let me introduce the periodic table: a map of all the elements that we humans know about. Elements are the building blocks of all things – just like the smallest pieces of Lego, which you use to build bigger and more complex objects.  The periodic table is organised so that the lightest element of each row is always on the left. Hydrogen is the lightest of all elements, so you’ll find it at the top left. As you move along each row from left to right, the elements get heavier and heavier.  Click here for a larger, interactive version. Dry air is mostly made up of two gases, nitrogen and oxygen, plus a little bit of argon and tiny amounts of other gases. For now, we can just focus on nitrogen and oxygen. As you can see on the periodic table, the weight of a single nitrogen atom is 14, while oxygen weighs almost 16.  But neither nitrogen nor oxygen atoms like to be alone, so they almost always go in pairs – two atoms in a molecule, like two peas in a pod. Because of this, a nitrogen molecule usually weighs 28, and an oxygen molecule weighs 32.  As soon as we add water (H₂O) to the air, things get interesting. A water molecule is made up of two hydrogen atoms and one oxygen atom. Remember how hydrogen is the lightest element? Well, a single water molecule weighs just 18. So it’s actually lighter than a molecule of nitrogen or oxygen. That’s why moist air is lighter than dry air.  The next piece of the puzzle is temperature. As a rule, warm air rises up, while cold air sinks down. When water in the air is warmer, it’s more likely to be a gas. When it’s cooler, it prefers to take a liquid form, such as cloud droplets, rain, hail or snow.  As warm, moist air rises, it gets cooler and cooler. And as it cools, more tiny water droplets form. You might expect the water droplets just to fall down as rain, but instead, something fun happens. You know how sweat cools our skin when it dries and changes from liquid into gas? Well, when gas turns into liquid, the exact opposite happens: it actually gives off heat.  This means that the cloud droplets are now surrounded by a tiny blanket of warm air. And what does warm air do? It rises! Not very far, though, because the air will cool again as it goes up. Now our puzzle is complete: clouds are made up of tiny droplets of water, which are hardly affected by gravity, embedded in moist air, which is lighter than dry air. And they’re surrounded by tiny warm blankets of air, which lift them up towards the sky. That’s how clouds weighing billions of tonnes can stay afloat up in the sky.  


      Read more:
      Curious Kids: Why do you have to wear a helmet in space?


 Hello, curious kids! Have you got a question you’d like an expert to answer? Ask an adult to send your question to us. You can: * Email your question to curiouskids@theconversation.com 

* Tell us on Twitter by tagging @ConversationUK with the hashtag #curiouskids, or

* Message us on Facebook. Please tell us your name, age and which town or city you live in. You can send an audio recording of your question too, if you want. Send as many questions as you like! We won’t be able to answer every question, but we will do our best. This article has been updated to reflect the effects of air resistance and gravity on cloud droplets more accurately."
"Two senior Victorian ministers have endorsed a police call for climate activists to abandon a planned protest on the state’s next high fire danger day. The demonstration has been set down for Friday night in Melbourne’s CBD in response to the bushfires, which have blackened more than 1.2m hectares of Victoria. Authorities on Wednesday urged Uni Students for Climate Justice organisers to call off the action, change the date or at least confine it to one spot. The emergency services minister, Lisa Neville, said she was stunned to hear the protests were going ahead when fire conditions were expected to worsen and urged organisers to reconsider. “This is a really reckless and selfish thing people are doing,” she said. “I don’t want to see police having to pull people out of [fire-affected] communities to come in and manage a protest. “There is a time for protests. It’s not this Friday.” The link between rising greenhouse gas emissions and increased bushfire risk is complex but, according to major science agencies, clear. Climate change does not create bushfires, but it can and does make them worse. A number of factors contribute to bushfire risk, including temperature, fuel load, dryness, wind speed and humidity.  The Bureau of Meteorology and the CSIRO say Australia has warmed by 1C since 1910 and temperatures will increase in the future. The Intergovernmental Panel on Climate Change says it is extremely likely increased atmospheric concentrations of greenhouse gases since the mid-20th century is the main reason it is getting hotter. The Bushfire and Natural Hazards research centre says the variability of normal events sits on top of that. Warmer weather increases the number of days each year on which there is high or extreme bushfire risk. Dry fuel load - the amount of forest and scrub available to burn - has been linked to rising emissions. Under the right conditions, carbon dioxide acts as a kind of fertiliser that increases plant growth.  Dryness is more complicated. Complex computer models have not found a consistent climate change signal linked to rising CO2 in the decline in rain that has produced the current eastern Australian drought. But higher temperatures accelerate evaporation. They also extend the growing season for vegetation in many regions, leading to greater transpiration (the process by which water is drawn from the soil and evaporated from plant leaves and flowers). The result is that soils, vegetation and the air may be drier than they would have been with the same amount of rainfall in the past. The year coming into the 2019-20 summer has been unusually warm and dry for large parts of Australia. Above average temperatures now occur most years and 2019 has been the fifth driest start to the year on record, and the driest since 1970. Not a significant one. Two pieces of disinformation, that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush have spread across social media. They have found their way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. The environment minister, Lily D’Ambrosio, said the last thing emergency services needed was people “deviated or distracted” by a well-meaning but poorly-timed protest. “People are entitled to protest, absolutely, but the timing is wrong,” she told reporters while at the airport to greet North American firefighters coming to help. “People are recovering, trying to recover, at the same time they’re preparing for another spike event.” The acting assistant police commissioner, Tim Hansen, also said Friday was not a good time. “This is a distraction for us. We see frontline staff returning from the fire ground ... fatigued that do need a break and this is now another operation we need to resource,” he told reporters. “We are frustrated by this protest timing and we are also frustrated by the lack of flexibility by the protest organisers to work with us in trying to find a more suitable time. “These are unprecedented times for emergency services.” The protest is expected to draw thousands of people who believe the fires are the result of decades of climate change. The protest organiser Anneke Demanuele has been contacted for comment."
"Antarctica’s ice sheets could totally collapse if the world’s fossil fuels are burnt off, according to a recent climate change simulation. While we are unlikely to see such a dramatic event any time soon, we are already observing big changes and it’s worth considering what the worst case scenario might look like for the continent’s ecosystems. How long before Antarctica turns into grassy tundra? For now, life thrives mostly at the very edge of the continent – it’s driven by the plankton-rich Southern Ocean and clustered around seasonally ice-free areas of coastal land. The interior might be sparsely inhabited, but the continent is not as barren as many think. There are around 110 native species of moss and two flowering plants, the Antarctic hairgrass and pearlwort. These plants have flourished along the relatively mild Antarctic Peninsula in recent decades. However they can’t go much further – they already occur at almost the most southern suitable ice-free ground. With ice-caps and glaciers receding already in the Peninsula region, native land plants and animals are benefiting from more easily available liquid water. Already we are starting to see increased populations, greater areas occupied and faster growth rates, consequences only expected to increase – everything is currently limited by the extreme physical environment.  It may eventually prove too warm for some native species, but the bigger issue in upcoming decades and centuries will be whether new and currently “non-native” species will arrive that are stronger competitors than the native organisms. Native polar species are inherently weak competitors, as they have evolved in an environment where surviving the cold, dry conditions is the overriding selective pressure rather than competition from other biological sources. If humans (or other wildlife expanding their range southwards) bring new competitors and diseases to Antarctica, that may pose a very grave risk to the existing biodiversity. Some native species would likely be pushed into the remaining more extreme regions where they can avoid competition and continue to rely on their inherent stress tolerance abilities. We usually split the process of natural colonisation – which applies even today in Antarctica – and that of movement of “alien” species by human agency. The best available data for the Antarctic region come from some sub-Antarctic islands, where it appears humans have been responsible for many more successful colonisations than nature. In fact, over the recent centuries of human contact with the region we have introduced 200-300 species compared to just two or three known natural colonisations.  Penguins, seals and flying seabirds move between islands and the Antarctic Peninsula, so there is potential for some natural colonisation. Vagrant birds are regularly observed across the sub-Antarctic and even along the Peninsula, some of which have colonised successfully (such as the starlings, redpolls and mallard ducks on Macquarie Island).  Migrants such as skuas and gulls, which spend time on land at both ends of their migration, could be important natural vectors of transfer for invertebrates, plant seeds and spores, and microbes into an ice-free Antarctica. Importantly, bird colonies also fertilise surrounding rock and soil with faeces, eggshells and carcasses. Plant and animal life flourishes near seabird colonies, encouraged by this enrichment. However it can be tough to predict what Antarctic melt would mean for individual species, never mind entire ecosystems. Take penguins, for instance – they have already survived previous inter-glacial retreats, but at reduced population sizes. This time round it is likely that Adélie and emperor penguins who are more dependent upon sea ice would decline, while less ice-dependent species such as gentoos and chinstraps might benefit. Indeed, there is already some evidence that emperors are struggling (although also that they may be adapting and learning to emigrate). However the fact fish-eating gentoo penguins are increasing on the Peninsula while Adélies and chinstraps (both krill eaters) aren’t doing so well suggests prey availability can be more to blame than ice cover. Figuring out the impact of large-scale environmental change at ecosystem or food-web level is hard – it’s a complex process that will no doubt throw up some unexpected results. The sub-Antarctic islands are full of examples of such unexpected impacts. Pigs, dogs, cats, sheep, reindeer and rabbits have all been intentionally introduced in the past, with often devastating effects. Rats and mice were introduced to South Georgia and other islands accidentally by sealers and whalers, for instance, and have decimated seabird populations. A recent eradication campaign appears to have been successful and pipits, ducks and small seabirds are showing some immediate signs of recovery.  The removal of non-native cats from Macquarie and Marion Islands has similarly helped native burrowing seabirds, although responses in such ecosystems can be far more complex and unpredictable – the removal of cats from Macquarie also led to increase in the introduced rabbit population, and considerably increased damage to sensitive native vegetation. Antarctic biodiversity is far more complex than widely assumed, with up to 15 distinct biogeographic regions that have been evolutionarily isolated for many millions of years. Humans present the greatest threat, not only of introducing new species, but also of moving “native” species between regions within Antarctica. This could be even more damaging, as these native species would already be pre-adapted to polar life. Visitors to Antarctica are subject to increasingly strict biosecurity measures but accidental introductions continue to occur, often through food shipments for scientists. Changes in sea and land ice affect access to new areas, so we can only expect plant and invertebrate invasions to increase unless biosecurity becomes more effective.  While cost issues may be raised, it is worth remembering that prevention will always be better – and cheaper – than subsequent control and eradication, even if such action is possible."
"Air pollution is rarely a major concern for most people in Western Europe. You seldom notice it except when sitting in heavy traffic or when it obscures the far horizon at a scenic spot.  However until the middle of last century it was a different story, with heavy industry and domestic heating filling city air with smoke, noxious gases and ozone. These air pollutants contribute to smog: the unpleasant combination of gases and particles that irritates the lungs and can do lasting damage to health. Many parts of the developing world still suffer from the high levels of air pollution that accompany unbridled industrial expansion and rapid economic development. New research on the health impacts of outdoor air pollution suggests that it is responsible for more than 3m premature deaths around the world each year and that this number could double by 2050. The study, published in Nature, looks at how the major sources of air pollutants, including traffic, industry, agriculture and domestic sources contribute to pollution levels in different parts of the world and estimates their associated impacts on mortality through heart and lung diseases. Unsurprisingly, the greatest effects were found in rapidly developing, heavily populated countries such as China and India. Despite large increases in industrial production, energy generation and vehicle traffic, the study identifies domestic and commercial energy use associated with heating and cooking as the biggest contributor to the high toll from outdoor air pollution in these regions. China suffers the most, accounting for more than 40% of air pollution-related deaths worldwide – more than 1.3m each year. The country’s large population, intensive agriculture and heavy industrialisation mean that economic development has come at a high environmental cost.  Major cities such as Beijing have experienced rapid deterioration in air quality associated with economic growth and the changing lifestyles of an expanding urban middle class. Traditional paper fans have long since been replaced by air conditioning as the preferred means of keeping cool in summer. At the turn of the century Beijing had one million vehicles; now, it has more than five times as many, bringing exhaust fumes and gridlocked streets. Towering new high-rise apartments are hidden from view behind a pollutant haze that turns the sky white and forces citizens to don protective face masks. Ordinary Chinese citizens are well aware of the problem. Environmental issues top the list of major public concerns and are a popular topic for online discussion. Air quality is monitored on a continuous basis at more than 1,000 sites nationwide, and a host of popular mobile phone apps stream live data on air pollution levels on an hourly basis. Acknowledging the problem has been a big step forward, but addressing it without damaging economic growth presents a major headache. Beijing’s geography means that its air quality can be particularly bad. Pollution from factories, farms and homes right across the vast and fertile North China Plain – the country’s traditional economic heart – is trapped by southerly winds against the mountains that surround the city to the north and west. Pollutants pool over the region, combining to form a haze that extends over hundreds of kilometres, appearing in satellite images as a murky blanket hiding the ground.  The Chinese government, keen to present the city’s best face to the world, imposed strict air pollution controls during the summer Olympics in 2008, for the APEC forum last autumn, and most recently for a military parade to mark the end of World War II. On each occasion the haze vanished – a clear demonstration of what can be achieved.  But the long-term changes needed to make this blue sky an everyday occurrence require greater effort. Plans are underway to relocate polluting industries, move to cleaner energy generation and tighten enforcement of environmental regulations.  Beijing steelworks was moved out of the city into neighbouring Hebei province before the Olympics; now other manufacturing industries are following suit. New, cleaner and more efficient facilities will reduce the sources of pollution and shift them downwind of the city. However, with a population of more than 100m and producing a quarter of China’s steel, Hebei already has major air pollution challenges of its own – and its pollution controls are less strict than in the capital. A shift in power generation from coal to gas is also underway, bringing benefits for climate as well as air quality. China currently leads the world in renewable energy production, with its huge investments in solar, wind and hydropower. These make up only 10% of the country’s energy needs, but are expected to rise to 16% by 2020. These large infrastructure changes are the key to controlling and reducing air pollution, but residential and agricultural sources must now be addressed, too, to bring the blue sky back.  However, the balance between economic development and environmental protection is starting to shift, much as it did in the West half a century ago. The new policies now being put in place will put China on a cleaner trajectory than the one assumed in the new Nature study.  The authors of the study are right to highlight the human costs of air pollution, and to warn of the future dangers of “business as usual” development. But in China now there is a new desire for clearer air that will put the nation on a different path – and reduce the heavy toll of air pollution-related deaths."
"Vanguard, the world’s second largest asset manager, has refused to sign up to a group of major investors demanding that polluters respond to the climate crisis, despite its rival BlackRock relenting to pressure to do so. The US investment manager’s decision leaves it increasingly isolated after BlackRock last week joined Climate Action 100+ (CA100+), a group of asset managers that pushes the largest fossil fuel producers to show how they will meet carbon dioxide reduction targets.  CA100+ counts among its members asset managers controlling more than $40tn, giving it clout to push large oil companies and other fossil fuel extractors to address climate issues. Last year, it forced British oil multinational BP to describe how its strategy aligned with goals laid out at the 2015 Paris climate summit. Vanguard on Monday revealed that its assets under management surpassed $6tn during 2019, after a net gain of $230bn in new investments, much of it in passive investments that track stock market indices, giving it large stakes in many fossil fuel companies. It has also gained regulatory approval to launch a new UK investment advice service, adding to the funds service that it started offering in the UK in 2017. Vanguard chief executive Tim Buckley has repeatedly insisted that it will focus on engaging with companies rather than voting for action. “We have to make sure we’re talking to companies on how they are dealing with and addressing these issues, but not crossing the line and telling them what to do,” he said in an interview with the Financial Times published on Sunday. Jeanne Martin, campaign manager at ShareAction, highlighted the voting records of both BlackRock and Vanguard. Both investors opposed more than 80% of climate-related shareholder motions at fossil fuel companies between 2015 and 2019, according to Guardian analysis of data provided by Proxy Insight – far higher than many counterparts. Martin said: “Following BlackRock’s move to join CA100+, the spotlight is now firmly on Vanguard. The fact they aren’t already a member is telling of their approach to climate engagement.”  A Vanguard spokeswoman said the company had no plans to join Climate Action 100+. Another spokeswoman later said the company continued “to evaluate how our alignment with this organisation could benefit Vanguard’s investors”. The second spokeswoman said that Vanguard was taking action to address climate change, including taking part in emissions disclosure initiatives. The spokeswoman said: “While voting at shareholder meetings is important, it is only one part of the larger corporate governance process. Vanguard is pursuing an active engagement strategy that focuses on boards’ climate governance and oversight of climate risk or climate strategies, and on comparable and investor-relevant disclosures.”"
nan
"
Share this...FacebookTwitterThe peer-reviewed scientific literature robustly affirms that land-falling hurricane frequencies and intensities have remained steady or declined in recent decades.  So have droughts, floods, and other extreme weather events.  But the editorial board of The Washington Post spurns this scientific evidence and inexplicably blames politicians and “those who deny” climate change for landfalling hurricanes and the associated damage. 
Image Source: The Washington Post 11/09/2018
It is well documented in the scientific literature that a cooler climate is associated with more weather extremes and hurricane activity, whereas a warmer climate leads to a reduction in weather extremes and hurricane activity.

“Recent review papers reported that many high-resolution global climate models consistently projected a reduction of global tropical cyclone (TC) frequency in a future warmer climate.“ (Sugi et al., 2015)
“Our work illustrates a major constraint on the large-scale global atmospheric engine: As the climate warms, the system may be unable to increase its total entropy production enough to offset the moistening inefficiencies associated with phase transitions. This suggests thatin a future climate, the global atmospheric circulation might comprise highly energetic storms due to explosive latent heat release, but in such a case, the constraint on work output identified here will result in fewer numbers of such [highly energetic storm] events. … On a warming Earth, the increase in perceptible water has been identified as a reason for the tropical overturning to slow down,  and studies over a wide range of climates suggest that global atmospheric motions are reduced in extremely warm climates.“  (Laliberté et al., 2015)
“Extratropical cyclones cause much of the high impact weather over the mid-latitudes. With increasing greenhouse gases, enhanced high-latitude warming will lead to weaker cyclone activity. Here we show that between 1979 and 2014, the number of strong cyclones in Northern Hemisphere in summer has decreased at a rate of 4% per decade, with even larger decrease found near northeastern North America.” (Chang et al., 2016)
“The impact of climate change is seen in slightly decreased intensities in landfalling cyclones.” (Perrie et al., 2010)

The Washington Post editorial board has apparently decided that contrarian scientific evidence is subservient to their political aims.
This way they can justify blaming out-of-favor politicians and those who “deny” climate change for the devastating consequences of an impending landfalling hurricane.
Below are several scientific papers published within the last year that do not seem to support the Post’s angle that says we can reduce hurricane landfall frequencies if only we can agree to believe, rather than deny, that humans are responsible.

“Downward Trend Since 1950” In Landfalling Hurricane Frequency/Intensity

Truchelut and Staeling, 2018 
“The extremely active 2017 Atlantic hurricane season concluded an extended period of quiescent continental United States tropical cyclone landfall activity that began in 2006, commonly referred to as the landfall drought. We introduce an extended climatology of U.S. tropical cyclone activity based on accumulated cyclone energy (ACE) and use this data set to investigate variability and trends in landfall activity. The [hurricane landfall] drought years between 2006 and 2016 recorded an average value of total annual ACE [accumulated cyclone energy] over the U.S. that was less than 60% of the 1900–2017 average.”
“Scaling this landfall activity metric by basin-wide activity reveals a statistically significant downward trend since 1950, with the percentage of total Atlantic ACE expended over the continental U.S. at a series minimum during the recent drought period.”

Klotzbach et al., 2018
“Continental United States (CONUS) hurricane-related inflation-adjusted damage has increased significantly since 1900. However, since 1900 neither observed CONUS [Continental United States] landfalling hurricane frequency nor intensity show significant trends, including the devastating 2017 season.”


Zhang et al., 2018     
“Over the 1997–2014 period, the mean frequency of western North Pacific (WNP) tropical cyclones (TCs) was markedly lower (~18%) than the period 1980–1996. Here we show that these changes were driven by an intensification of the vertical wind shear in the southeastern/eastern WNP tied to the changes in the Walker circulation, which arose primarily in response to the enhanced sea surface temperature (SST) warming in the North Atlantic, while the SST anomalies associated with the negative phase of the Pacific Decadal Oscillation in the tropical Pacific and the anthropogenic forcing play only secondary roles.”

Zhao et al., 2018
“A vigorous debate has currently focused on the relationship between increasing TC [tropical cyclone] activity and increasing SST [sea surface temperatures] (Knutson et al. 2010). … [O]ver the WNP [Western North Pacific] basin,a significant decrease of TCF [tropical cyclone frequency] has been observed since 1998 (Liu and Chan 2013; Lin and Chan 2015; Zhao and Wang 2016). Global TCF [tropical cyclone frequency] has showed a similar reduction since the late 1990s (Maue 2011). Change of TCF over the past few decades does not appear to be consistent with changes in local SST. Observational analyses further pointed out that there is no significant correlation between the TCF [tropical cyclone frequency] and local SST [sea surface temperatures] over the WNP  [Western North Pacific] basin (Chan 2006; Yeh et al. 2010).”


Heller, 2017
“The hurricane analysis conducted by Burn and Palmer (2015) determined that hurricane activity was subdued during the [warm] Medieval Climate Anomaly (MCA) (~900-1350 CE) and became more produced during the [cold] Little Ice Age (LIA) (~1450-1850 CE), followed by a period of variability occurred between ~1850 and ~1900 before entering another subdued state during the industrial period (~1950-2000 CE). In general, the results of this study corroborate these findings.”
“[W]hile hurricane activity was greater during the LIA, it also had more frequent periods of drought compared to the MCA (Burn and Palmer 2014), suggesting that climate fluctuations were more pronounced in the LIA compared to the MCA. The changes in the diatom distribution and fluctuations in chl-a recorded in this study starting around 1350 also indicate that variations in climate have become more distinct during the LIA and from ~1850-1900. … [C]limate variability has increased following the onset of the Little Ice Age (~1450-1850 CE), however it is difficult to distinguish the impacts of recent anthropogenic climate warming on hurricane activity from those of natural Atlantic climate regimes, such as ENSO.”

Wellford et al., 2017
“Since the late 1800s, in contrast to much of the Southeastern USA, the Georgia coast has experienced infrequent hurricane landfalls, particularly in recent decades. As a result, coastal storm preparedness complacency appears to be rampant along the Georgia coastline. Both local and state governments were unprepared for shadow evacuation during Hurricane Floyd in 1999. The study described here includes an examination of temporal and spatial trends in hurricane landfall along the Georgia coast from 1750 to 2012. Since 1750, 18 of the 24 recorded hurricanes that made landfall along the Georgia coast occurred between 1801 and 1900, yet the hurricane intensities have declined since 1851.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




No Increasing Trend In Drought/Flood Frequency, Severity

Guo et al., 2018
“In drought-prone regions like Central Asia, drought monitoring studies are paramount to provide valuable information for drought risk mitigation. In this paper, the spatiotemporal drought characteristics in Central Asia are analyzed from 1966 to 2015 using the Climatic Research Unit (CRU) dataset. Central Asia showed an overall wetting trend with a switch to drying trend since 2003.”

Mangini et al., 2018
“The main objective of this paper is to detect the evidence of statistically significant flood trends across Europe using a high spatial resolution dataset. … Anticipated changes in flood frequency and magnitude due to enhanced greenhouse forcing are not generally evident at this time over large portions of the United States for several different measures of flood flows. … Thus, similarly to the main findings of Archfield et al. (2016) for the US, the picture of flood change in Europe is strongly heterogeneous and no general statements about uniform trends across the entire continent can be made.”

Zheng et al., 2018     
“For the extreme drought and flood events in total, more frequent of them occurred in the 1770s and 1790s, 1870s–1880s, 1900s–1920s and 1960s, among which the 1790s witnessed the highest frequency of extreme drought and flood events totally.”


Schedel, Jr. and Schedel, 2018    
“Flood events on the U.S. East Coast are not more severe or frequent than in the past. However, because of sea-level rise, these events are starting from a higher baseline height. Thus, the same severity of a flood event today reaches a greater absolute height than an identical flood would have reached 50 or 100 years ago.Based on current data, the good news is that the apparent worsening of flood events is due to a single, primary cause: sea level rise. Flood events are not getting stronger or occurring more frequently than in the past. They are instead starting from a higher point, allowing them to reach higher levels more often. The bad news is that sea-level rise will be a fact of life for many years into the future. Communities need to start now to make informed plans and decisions about how best to adapt.”


Valdés-Manzanilla, 2018
“This study presents a chronology of historical and measured flood events in the Papaloapan River basin of Mexico during 450 years. Twenty-eight historical floods were recorded during the period 1550–1948 [7 per century] on this river and one flood event (1969) in the instrumental era (1949–2000) [2 per century], of which 14 were extraordinary floods and only 15 were catastrophic ones. There were several flood-rich decades during 1860–1870, 1880–1890, 1920–1930 and 1940–1950. Wavelet analysis found a significant flooding periodicity of 58 years. The wavelet coherence analysis found that flooding had an in-phase relationship with the Atlantic Multidecadal Oscillation and also with the Pacific Decadal Oscillation.”

Dobrovolný et al., 2018
“The new MJJ precipitation reconstruction is restricted to inter-annual and inter-decadal variability, which is in line with our understanding of natural precipitation variability. Reconstruction reveals two long periods of low precipitation variability, in the 13th–14th centuries and 1630s–1850s. It also demonstrates that precipitation anomalies of larger amplitude and longer duration occurred in the earlier part of the last millennium than those found in the instrumental period. Negative trends in soil moisture content and gradual changes in annual precipitation distribution leading to higher extremity of precipitation regime may be responsible for the lower sensitivity of oaks to precipitation after the 1980s. The new reconstruction does not indicate any exceptional recent decline in MJJ precipitation.”


Extreme, Unstable Weather Decreases With Warming

Zou et al., 2018
“The Tibetan Plateau (TP), one of the world’s most sensitive areas to climate change, became significantly warmer during recent decades. Since 1960 (1980), storm (hail) days have been decreasing by 6.2%/decade (18.3%/decade) in the region.”
“Based on 53‐year continuous weather records at 48 TP stations and reanalysis data, we show here for the first time that the consistent decline of storm days is strongly related to a drier midtroposphere since 1960. Further analysis demonstrated that fewer hail days are driven by an elevation of the melting level (thermodynamically) and a weaker wind shear (dynamically) in a warming climate. These results imply that less storm and hail may occur over TP when climate warms.”

Zhang et al., 2017
“Based on continuous and coherent severe weather reports from over 500 manned stations, for the first time, this study shows a significant decreasing trend in severe weather occurrence across China during the past five decades. The total number of severe weather days that have either thunderstorm, hail and/or damaging wind decrease about 50% from 1961 to 2010. It is further shown that the reduction in severe weather occurrences correlates strongly with the weakening of East Asian summer monsoon which is the primary source of moisture and dynamic forcing conducive for warm-season severe weather over China.”

Chen et al., 2017
“Results indicate that the midlatitude summer cyclone activity over East Asia exhibits decadal changes in the period of 1979–2013 and is significantly weakened after early 1990s. …  Moreover, there is a close linkage between the weakening of cyclonic activity after the early 1990s and the nonuniform surface warming of the Eurasian continent.”
“Significant warming to the west of Mongolia tends to weaken the north–south temperature gradient and the atmospheric baroclinicity to its south and eventually can lead to weakening of the midlatitude cyclone activity over East Asia.”
Share this...FacebookTwitter "
"Every August, London Zoo weighs and measures every one of its 19,000 animals. It’s a great PR move for the zoo, guaranteeing lots of friendly coverage of photogenic animals on scales or next to tape measures, at a time when many politicians and journalists have clocked off for the summer. But, as a wildlife conservation researcher and a former zookeeper, I have seen exactly how these sorts of annual “weigh-ins” also helped the animals themselves. Recording the weights and size of animals in a zoo directly benefits their welfare, and could potentially help in the global conservation of their wild counterparts. Monitoring the health of the animals in your charge is a large part of what being a keeper is all about. You do this by getting to know the individuals and noting any changes in their behaviour each day as you would your own pet. You even assess their droppings, looking at colour and solidity – which made for interesting conversation on morning coffee breaks.  Although these observations are useful, they can be a bit subjective. By taking measurements such as weight you immediately have something a bit more concrete that can be used to evaluate well-being and review the effectiveness of husbandry methods. Also, giving the correct dosage of food supplements or medicines often requires you to know the weight of an animal. Small creatures like snakes or lizards can be put into a pillow case and weighed using hanging scales. A trained handler can even hold venomous snake species such as a black mamba against a tape measure.  However larger mammals are a bit trickier. Whether it is a lemur or rhino, it often involves time, effort and patience to train one to walk onto a set of scales. Usually there is some form of food reward to help entice them onto the scales in the first place and then to keep them stationary long enough for a reading. For the most dangerous mammals of all, like the African leopards I worked with, zookeepers have to either target train them with food (using a stick with meat on the end) or wait until there is a reason to sedate them then weigh them. If you think this sounds difficult, it is nothing compared to the challenges faced out in the wild. There, this kind of information is usually only gathered when the species is specifically being studied and only then typically when the animal is under sedation for research purposes (for instance to fit a GPS tracking collar).  Often the species that are being studied have been officially assessed as threatened with extinction, based on population numbers and trends, types of threat and conservation effort. Although populations need to be monitored directly over time to check for increases or decreases, they can also be modelled based on basic information such as weight, life expectancy and breeding rates to give an idea of what the population is likely to do under different circumstances. In the region of 25% of known animalshave been classified, however for all taxa (mammals, reptiles, birds and so on) there are species that have not been classified due to insufficient data. Many of these fall into the less “charismatic” categories such as amphibians, crustaceans or fish. For example it is thought 23% of assessed amphibians have not been classified while up to half of amphibian species are potentially threatened with extinction. There are even gaps in our knowledge of mammals, 14% of which have not been classified.  How can scientists fill in those gaps? I attended a conference recently where a speaker was discussing the potential for utilising the data gathered by zoos to produce models for the species with missing data and assess how vulnerable they might be to climate change, habitat loss and other threats.  And zoos have a lot of data: of all the thousands of threatened land vertebrate species – everything from tigers or lemurs to colourful snakes or tiny frogs – around one in seven have some individuals held in captivity somewhere. Zoos really can fill an important role and have an impact. This knowledge in turn could then be used to highlight where conservation efforts and often limited funding should be focused, to increase the survival chances of more threatened species out in the wild."
"This is an article from Curious Kids, a series for children of all ages. The Conversation is asking young people to send in questions they’d like an expert to answer. All questions are welcome: find details on how to enter at the bottom.  We live in Deal, Kent and can see the coast of France from here. The waves lap towards us onto the shore on our side of the Channel, but they also lap towards the people on the opposite shore in Calais. Is there a place in the middle where the waves change direction? – Sebastian, age 12, Kent, UK Well done for noticing this, Sebastian. This is very true, the waves lap towards England on one shore, and also lap towards France across the Channel. This happens for a few reasons. First, waves are created by the wind. When the wind blows across the surface of the water, it pushes the tiny particles of water on top of the ocean away from it. Over time, the energy from the wind moving along these particles causes waves to form. The blowing wind keeps pushing the energy along the water, driving the waves away from the place where they began.  The same thing happens when you blow really hard across a basin full of water: the waves you have created travel away from the source (your breath) – not just forwards, but in all directions. Now, if the planet had no land and we lived in a waterworld, the waves would carry on travelling around the globe without anything to stop them. But in reality, we have land such as England and France getting in the way of the waves.  So, as the wind blows through the English Channel – in whichever direction – it pushes the waves away from it, towards both England and France. There’s another force which causes the waves to lap against both shores. The ground at the bottom of the sea – also known as the “sea bed” – rises from the middle of the channel, like a valley, all the way up to give us the lovely beaches we have on both the coasts.  As the waves get closer to the land, the sea bed also rises towards the shore, causing the waves to slow down. And when they slow down, they get closer together. Think of it like this: when the traffic slows down on the motorway, the distance between the cars gets smaller and smaller as drivers all press on the brakes. In exactly the same way, the distance between one wave and the next – what scientists call the “wavelength” – gets squashed as the waves slow down.  But even when the waves slow down, they still contain all that energy they got from the wind. So, as the wavelength becomes shorter, and the waves have to go slower, they put that energy into growing taller instead.  You will be able to see this when you look out to sea: the waves coming towards the shore get taller and taller, until they’re so tall and close together that they start “breaking”. White foam forms on the top of each wave, and splash! They crash on the shore, transferring all the energy they’ve been carrying onto the land.  This breaking happens at the coastline, both here in England and also in France. If the wind is strong enough, the westward moving waves produced in the English Channel may one day even make it all the way to America. Waves break along every coastline in the world.  Hello, curious kids! Have you got a question you’d like an expert to answer? Ask an adult to send your question to us. You can: * Email your question to curiouskids@theconversation.com 

* Tell us on Twitter by tagging @ConversationUK with the hashtag #curiouskids, or

* Message us on Facebook. Please tell us your name, age and which town or city you live in. You can send an audio recording of your question too, if you want. Send as many questions as you like! We won’t be able to answer every question, but we will do our best. More Curious Kids articles, written by academic experts: What is fire? – Lyra, age seven, Oxford, UK
*_  How do SIM cards make a phone work? – Leo, age five, Sydney, Australia What’s it like to be a fighter pilot? – Torben, age eight, Sussex, UK"
"The whale shark is the largest fish in the world, but much of its lifecycle remains shrouded in mystery. These gentle giants gather in just a handful of places around the globe – something which has long baffled scientists – but our new research has started to explain why. Better understanding of whale shark movements could help prevent further population loss in a species that has already experienced a 63% population decline over the past 75 years. When swimming solo, the whale shark, which can grow up to 18.8 metres in length and 34 tons in weight, travels all over the world. Recently, a group of scientists tracked the remarkable journey of one whale shark across the Pacific from Panama to the Philippines. At more than 12,000 miles it proved to be one of the longest migrations ever recorded. Yet whale sharks are known to come together at just a few specific locations around the world. Anything from ten to 500 whale sharks may gather at any one time in areas off the coasts of Australia, Belize, the Maldives, Mexico and more. Approximately 20 hotspots have been identified – mere pinpricks in the vastness of the world’s oceans – but we don’t know what exactly attracts the whale sharks to them. In some cases the sites are linked to a specific biological phenomenon – such as the spawning of land crabs at Christmas Island in the Indian Ocean, which provides whale sharks with the seasonal equivalent of a Christmas feast. Our new research aimed to discover whether there was something else that united the places where these giants of the ocean hang out. The physical features of these spots – known as their bathymetry – have been shown to influence gathering points in other marine species. So in collaboration with the Maldives Whale Shark Research Programme, we decided to investigate whether it drives whale shark gatherings in the same way. Our new global study shows that whale sharks congregate in specific areas of shallow water, next to steep slopes that quickly give way to areas much deeper water (usually between 200 metres and 1,000 metres). We identified three main reasons. First, the deep water is used by whale sharks for feeding. Studies have shown the sharks diving to depths of almost 2 kilometres (1,928 metres to be precise) to feed on zooplankton and squid. Second, the steep slopes are known to bring nutrients up to the surface from the deep, which in turn increases the abundance of plankton and attracts large numbers of filter feeding species. And finally, in shallow water, as well as feeding on coral and fish spawn, the sharks are able to thermoregulate, warming themselves back up after their dives into deep water which gets as cold as 4℃. If you’ve ever seen or swum with a whale shark, it was most likely in one of these relatively shallow aggregation areas. Knowing where these hotspots are has provided local communities with a windfall from ecotourism. In the Maldives alone, economic benefits from whale shark-related activities were estimated at US$9.4m per year. Whale sharks are worth a lot more alive than dead – and with many of these meeting points in developing countries, the income is invaluable.  But with the increasing pressures of tourism comes new dangers for the sharks. Crowds of snorkelers and tourist vessels are increasingly disturbing the whale shark’s waters, and – more worryingly – risk potentially fatal strikes by boats. To protect these beautiful creatures and continue to reap the rewards of ecotourism, we recommend that marine protected areas should be set up around whale shark gatherings and codes of practice be followed when interacting with them. These discoveries have narrowed down some of the key reasons why whale sharks congregate where they do, but many mysteries remain. Do individuals travel between these hotspots? Coastal gatherings are predominately made up of immature male sharks, usually still just four or five metres long. So where are all the girls? And where do whale sharks mate and give birth? Mating and pupping have never been seen in the wild – but, intriguingly, up to 90% of the whale sharks passing through the Galapagos marine reserve are female and thought to be pregnant. Could this be a key labour ward for the world’s whale sharks? Last year a BBC film crew at the Galapagos attempted to follow a pregnant female in a submersible to watch it give birth, but to no avail. That’s one secret that the depths are keeping for now."
"
Share this...FacebookTwitterMy daughter will be visiting Wilmington next week, and so Hurricane Florence has been very much on my mind.
Days ago, almost all weather models showed the cyclone curving out into the North Atlantic and going nowhere, but they’ve turned out to be wrong.
Bastardi saw it a week ago
Already a week ago veteran meteorologist Joe Bastardi got into the act, and his hunch did not quite agree with the models. On September 1st he brought up the real possibility of Florence missing the turn to the north, and instead heading out to the US east coast. What follows is the chart Joe used on his September 2 Daily Update:

On September 2nd, Joe Bastardi warned Florence could head to the US east coast. Chart: Weatherbell.
Today we already know that Joe’s forecast of Gordon was accurate, and now we are seeing that his hunch of Florence missing the turn to the north was right on.
On his Daily Update of Wednesday, September 5, it was becoming clear Florence had little intention of turning northward as Joe’s chart tells us:

By September 5 Joe had already sniffed out the likely general track. – more than a week before Florence is forecast to strike the east coast. Chart: Weatherbell. 
A day later at his Daily Update, on Thursday (September 6), ahead of everyone else, Joe showed Florence generating into a monster Category 4 storm and on a possible path to the Carolinas:

Chart: Weatherbell
Models can’t handle longer term forecasting – analogs needed
How does he do it? The veteran meteorologist not only uses models to make his forecasts, but relies heavily on analogs, i.e. similar recorded patterns having frequently occurred in the past. It’s happened before, and similar events can happen again.
His method often allows him to be days ahead of the purely mathematical models used by leading weather agencies, who find themselves constantly correcting them with every run. So today we wait with suspense to see Joe’s latest news on Florence’s projected track.
Models not in agreement
Though the latest forecasts from the different models are just about unanimous on Florence plowing into US coast (with still a small chance of curving out northward before reaching land) they are still in disagreement where the hurricane will strike the coast.
GFS model
Dr. Ryan Maue at Twitter informs the US GFS model has Florence landfalling on the coast of NORTH CAROLINA:

No change from the GFS model for #Florence … still a major hurricane landfall somewhere in the Carolinas by Thursday next week.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Since the track is curved, a small deviation or change in forward speed could yield a different landfall point or even a miss offshore. pic.twitter.com/1ImFP9UUuW
— Ryan Maue | weathermodels.com (@RyanMaue) September 8, 2018

UKMET model
Ben Noll at Twitter reports that the latest UKMet model run shows Florence going much further south, making landfall near the Florida-Georgia border!
European model
Meanwhile this morning Swiss meteorologist Jörg Kachelmann points out that the European model has Florence aiming between the GFS and UKMet models. Again the models are purely mathematical computations and do not directly take analogues into consideration like Joe Bastardi does.
Also see Ben Noll’s recent tweet here.
So follow Joe Bastardi’s daily updates at Weatherbell for the latest refined projections. Joe often sides with the European model.
Keep in mind, as every meteorologist knows, weather is highly unpredictable, and so surprises can never be excluded.
Here come the climate ambulance chasers!
One thing is certain: the global warming ambulance chasers and fake CNN-type media will be making all sorts of hysterical claims once Florence hits the coast. Naturally, despite all their climate “expertise”, none of these climate doomsday prophesiers ever had a clue about what track Florence would follow days ago.
Yet they’ll be the first (after the fact) to claim they predicted this sort of thing all along, and blame it on manmade climate change. The reality is that hurricanes have been trending downward over the past 50 years.
Media will blare Florence’s unusual track “unprecedented!”
What’s interesting about Florence is its relatively high latitude start position. As Dr. Philip Klotzback mentioned at Twitter, in the past no hurricane at Florence’s position ever managed to make it to the US east coast. All of them have turned away and disappeared somewhere in the Atlantic:

33 named storms (since 1851) have been within 100 miles of #Florence's current position.  None of these storms made US landfall.  The closest approach was #Hurricane George (1950) – the highlighted track.  However, Florence does not appear to be taking a climatological track. pic.twitter.com/4x02pasgPg
— Philip Klotzbach (@philklotzbach) September 7, 2018

Get ready for insane climate headlines
But Florence has managed to find its own track to the US east coast. So expect the global warming ambulance chasing scientists to call it “UNPRECEDENTED!” and say it must be because of human emissions of CO2! The media will accept it as Gospel Truth and go crazy with hysterical headlines. The USA Today here has already begun using the “unprecedented” label.
So what would Joe Bastardi, the person who was first to forecast the event, say about it? Joe will tell you it’s all natural, and not because of humans emitting some CO2 into the air.
Share this...FacebookTwitter "
"This is an article from Curious Kids, a series for children of all ages. The Conversation is asking young people to send in questions they’d like an expert to answer. All questions are welcome: find details on how to enter at the bottom.  What is fire? – Lyra, age seven, Oxford, UK Thanks for the question, Lyra. Basically, fire is light and heat that comes from a special kind of chemical reaction, which humans figured out how to make hundreds of thousands of years ago.  To understand how that reaction works, there are a few things that we need to learn about the world around us. Everything that you see and touch is made up of tiny things called atoms. You can think of atoms as really, really small bits of Lego – so small you can’t even see them.  Atoms join together to form molecules, and molecules join together to form the objects we can see and feel in everyday life. For example, wood is mainly made of a type of molecule called cellulose  and each molecule of cellulose is made of atoms called carbon, oxygen and hydrogen. Now, to see how the chemical reaction works, let’s imagine that you’re living in a cave 400,000 years ago, and that you’re one of the very first people to use fire.  You’re hungry and you want to cook an animal that you caught earlier in the day. On your way back to the cave, you collected some twigs and sticks for your fire. But there’s two other things you need before you can light the fire. You need oxygen – but luckily there’s plenty of that in the air (though you wouldn’t have known about it at the time). And you’ll need some heat to start things burning. Of course, matches haven’t been invented yet, so instead you quickly rub two sticks together. The rubbing causes friction, which heats up the sticks – like when you rub your hands together fast to warm them up. This heat causes all the molecules in the wood to jiggle around.  When a part of a stick gets hot enough, the molecules are moving about so much they start to break apart. This is when you start to see smoke. The smoke is all those broken up molecules escaping from the wood as gases. But you haven’t made fire yet – you need things to get even hotter! So you keep rubbing the sticks together really hard. Eventually, the gas molecules from the wood get so hot they bash into oxygen in the air and join together. When they do that, they make new molecules called water and carbon dioxide. At the same time, they also make heat and light. Well done, you’ve made a flame! You can stop rubbing the sticks together now.  As you put more twigs on your small fire, the heat carries on breaking down the molecules in the wood, and making more gases. These gases catch fire as well. But something else needs to happen before your fire can really grow. When the gases leave the wood you get left with charcoal. Then, as your fire gets even hotter, the charcoal also starts to combine with more oxygen, making even more heat and light. Now things are hot enough to start cooking. You make your meal, and after a while you run out of fuel for your fire. All the wood and charcoal burns away leaving ash. This is the stuff in the wood that doesn’t burn. Without the light and heat from the fire, there’s nothing to do but go to sleep – but at least you’re not hungry anymore.  Hello, curious kids! Have you got a question you’d like an expert to answer? Ask an adult to send your question to us. You can: * Email your question to curiouskids@theconversation.com 

* Tell us on Twitter by tagging @ConversationUK with the hashtag #curiouskids, or

* Message us on Facebook. Please tell us your name, age and which town or city you live in. You can send an audio recording of your question too, if you want. Send as many questions as you like! We won’t be able to answer every question, but we will do our best. More Curious Kids articles, written by academic experts: How do SIM cards make a phone work? – Leo, age 5, Sydney What’s it like to be a fighter pilot? – Torben, age eight, Sussex, UK If an insect is flying in a car while it is moving, does the insect have to move at the same speed? – Sarah, age 12, Strathfield, Australia"
"The climate is changing – and so are our seas. Warming sea temperatures have resulted in British cod moving north, benefiting Iceland. The English Channel has warmed during the last half century and the grey Atlantic triggerfish is now a year-round, rather than just a summer, resident in the waters off Cornwall and Dorset. Along the south coast of England there has also been an eastward shift in the distribution of “warm” Atlantic barnacles, which are now displacing the “cold” North Sea species. But bigger fish, including sharks, are changing their range, too. An excellent recent paper revealed how temperature changes the occurrence and activity of roaming apex predators. It said that the redistribution of species is one of the most pervasive impacts of anthropogenic climate warming.  This detailed study of Australian tiger sharks suggested that an increase in water temperature of 1-2°C will lead to them being seen off New South Wales all year round (at the moment, they tend only to visit the region in summer). And as this species is responsible for a large proportion of the shark bites on humans this raises the issue of whether control measures, such as shark nets, should be deployed to protect Australian bathers. Some sharks will follow the warmer water and their prey into UK waters, too. I have examined the known ranges of sharks and if water temperatures rise the following large species found off the coasts of Spain and Portugal may join the 40 species that are already in UK waters: great hammerhead, blacktip shark, sand tiger, bigeye thresher, longfin mako, bronze whaler, oceanic whitetip shark, silky shark, dusky shark, and goblin shark.  Indeed, one of these species has already visited British waters. The first bigeye thresher was caught off the UK near Newlyn, Cornwall in 1995. But while the potential number of shark species around the UK may increase in the next few decades, the overall number of sharks (especially the larger ones) will fall thanks to global overfishing. In fact, one report estimated that 100m sharks are killed each year, many for shark fin soup. Most of the larger sharks are recorded on the IUCN Red List – which monitors endangered species – as “vulnerable” to or “near threatened” with extinction. Basically, we are killing sharks faster than they can reproduce. A typical female shark reaches maturity at ten-years-old and will produce less than ten young. Contrast this with a cod, which can reach maturity at a year old and produce over a million eggs each year. As well as overfishing, sharks are also vulnerable to pollution. Most people are aware of the problems of waste plastics in the ocean. As the plastics break down into smaller and smaller particles, their ability to absorb pollutants increases and their incorporation into the ocean food chain becomes more likely. Sharks as top predators will take on the pollutants from everything that they have eaten, putting their health in peril. Of course, if more large shark species are likely to come to British waters, many will wonder whether great whites will be among them. There is considerable debate over whether they have already visited – and I see no reason why not. They can live in large numbers in colder waters than the UK off South Africa and there’s a plentiful supply of one of their favourite foods – seals – along the Cornish coast, as well as around Scotland and other parts of the country. The only argument against there being great whites in British waters is that their numbers worldwide are declining (they are now protected in several countries) so the chances of seeing one in this region fall every year. In March 2015, the conservation research organisation OCEARCH tagged a 14ft (4.4 metre) great white shark off Jacksonville, Florida and nicknamed her Lydia. She swam over 30,000km, including meanderings along the east coast of the US – before striking out for Europe. A year later, when she crossed the mid-Atlantic Ridge and came within a few hundred miles of Ireland, the media became very excited. The Mirror announced Great White shark ‘just days away from Cornwall’ after scientists track it swimming across Atlantic. Sadly, satellite contact was lost soon after that so we don’t know whether she made it. But this, and my recent suggestion that there may soon be more shark species around the UK, attracted a flurry of media attention – much of it overblown. While I was careful not to predict an influx of great white sharks, the type of headline used by The Daily Mail was almost inevitable: Eleven terrifying shark species, including great whites and hammerheads, are ditching warmer waters and heading to British shores. Thankfully, a more measured response was made subsequently by The Guardian: “Warmer seas will not lure great white sharks to UK, experts say.” There seems to be an almost inevitable need to use the cliche “killer sharks” in press stories about sharks. But the number of human fatalities resulting from shark attacks is tiny compared to other causes – even vending machines are deadlier.  Britain’s largest shark is the basking shark, which can grow up to eight metres in length but eats nothing bigger than plankton. Nevertheless, it is a summer, silly season necessity to print a photo of a basking shark fin and claim it’s a “killer” great white. Perhaps the best overview of the popular press view of sharks is expressed by Private Eye. While we continue to demonise sharks as mindless killers their wholesale slaughter goes unchallenged, until one day soon they will become extinct and shark natural history films will be reclassified as just history. So when we hear that more new species may start visiting the UK, it should trigger efforts to protect them, not just another wave of hysteria."
"
Share this...FacebookTwitterDespite the warm year seen in Central Europe so far this year, and all the claims that it’s due to climate warming, the globe in fact has shown it’s been cooling off, or at least not warming at all.
Hat-tip: Schneefan
UAH satellite measurements of temperature at 1500 m altitude in October 2018 came in at an anomaly of + 0.22°C with respect to the WMO climate mean from 1981-2010. That’s four tenths of a degree less than October, 2017.
So far 2018 is the third year in a row that the globe has cooled off from it’s El Nino peak set in 2015. Especially large parts of North America have seen a cold October, as an NCEP/NCAR reanalysis shows:
Arctic stable over past decade
And despite earlier predictions of an ice-free late summer Arctic made by alarmist climate scientists years ago, Arctic sea ice has in fact stabilized over the past 10 years. This year the  Northwest passage was closed the entire year.
Arctic sea ice extent has exploded since early November, gaining over 200,000 km² daily on average, as depicted by the following Alfred Wegener Institute (AWI) chart:

Hudson Bay freeze-up earlier than average for 2nd year
The surprising ice burst contradicts claims that polar bears have been in trouble. Polar bear biologist and expert Dr. Susan Crockford reports here:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This is the second year in a row that freeze-up of Western Hudson Bay ice has come earlier than average” and that “it’s unlikely that a strong wind will again blow the newly-formed ice offshore (as happened earlier this year) because the ice is more extensive.”
According to Dr. Crockford: “Ice has been developing rapidly over the last couple of days.”
The Canadian Ice Service chart for 10 November shows the ice very clearly:

Winter hitting northern hemisphere earlier
In October, snow cover over North America stood at 9.7 million square kilometers, which is some 1.7 million square kilometers over the mean of the past 50 years.

Source: Rutgers University Global Snow Lab
The October snow cover trend is also the same story for the entire northern Hemisphere, hat-tip: Kirye:

Source: Rutgers University Global Snow Lab
Share this...FacebookTwitter "
"Have you heard the one about Jeremy Corbyn’s plans to renationalise the energy system? In an interview with Greenpeace, the Labour MP and leadership candidate said: “I would personally wish that the Big Six were under public ownership, or public control in some form.”  It would be easy to take this quote out of context, add up the market value of the Big Six and suggest the Corbyn campaign wants to spend £124 billion renationalising the utilities. Yet, in the next breath however Corbyn added: “But I don’t want to take into public ownership every last local facility because it’s just not efficient and it wouldn’t be a very good way of running things.” So what does the Corbyn camp suggest instead? The only clear evidence is in his Protecting Our Planet manifesto, which sets out ten energy pledges and details some key policies.  It’s no aggressive nationalisation plan. What it is, is a manifesto for a more decentralised and democratically accountable system, inspired more by present-day Germany than 1980s Britain.  So does Corbyn’s energy policy look like a throwback or a revolution? There are four reasons to suspect the latter. “Competition” in the UK energy market has left consumers bamboozled and overcharged. Our choices are like a shopping mall food court: you can have anything you like, as long as it’s fast food. The energy market is similar, most suppliers are operating the same big utility model with the same options; you can have anything you like, so long as it’s a national tariff from a large private utility.  Corbyn’s manifesto cites Germany, which allows consumers the option to buy energy from municipal utilities or co-operatives. Some new consumer options are being seen in the UK. Smarter ways of buying green energy are appearing, and Nottingham City Council has set up its own energy company with a name that sends a clear message: Robin Hood Energy.  But while it’s easy enough to build a wind turbine these days – or even a whole wind farm – it’s significantly harder for innovative new businesses to actually join the market. Corbyn’s manifesto commitment to growing municipal and co-operative models would mean consumers face more meaningful choices. The manifesto pledges to create a “route-map into tomorrow’s ‘smart energy’ systems” to “use smart technologies to run localised storage, balancing and distribution mechanisms” and allow customers the “right to have first use of the energy they generate themselves”. But why isn’t this happening already?  It’s useful to think of our electricity system as being like a big swimming pool. Everyone’s electricity has to go into this big pool and a vast amount of market regulation is needed to make sure the pool stays “balanced” at the right level, with all the buying and trading and using of power going on underneath the surface. This means small-scale solutions to generating and using power locally are extremely difficult to set up, as they all incur the costs of trading in the big pool. To stretch the metaphor, this means little fish have to swim in a big pond.  Such a setup creates barriers to innovation and is holding back new technologies. There is no technical reason why you shouldn’t be able to choose to buy energy from local sources these days – what stands in the way is the requirement that everyone has to swim in the big pool first. By creating local energy markets, smaller but still viable businesses can flourish. The manifesto commits to pursue energy investment through a National Investment Bank. While this model has seen success in Germany, what is less well understood is how important citizen banks have been in deploying this investment.  The UK doesn’t have a citizen banking sector like Germany. This means you can only invest in renewables by either buying shares in a green energy company or investing in a co-operative. However, new models are emerging. Abundance Generation, an online crowdsourcing platform, allows investors to participate in renewable energy schemes for as little as £5, and a German-style local bank is being developed in Hampshire.  While Corbyn’s manifesto sees the benefit of establishing a state investment bank to invest in the energy transition, it will be important to deliver this investment through the right institutions at the right level so citizen investment can complement state finance. Throughout, the manifesto argues for more citizen influence over the energy system – and not just through supposed consumer “choice”.  It is not only the German system that can be drawn on to change this. Energy decision-making can be brought closer to citizens by, for instance, looking at public value energy governance which draws on Danish and North American examples, direct action to take back ownership of key infrastructure, or reframing energy as a public good.  It is clear from the manifesto that the energy policies of the Corbyn camp are anything but a throwback to monolithic state utilities. There is potential for more competition through more diverse energy business models, a clear willingness to make space for smart energy innovation, a call for different approaches to energy system finance, and a platform for more plural approaches to energy governance. Whether or not people agree with these proposals, it should be clear that they are not “old solutions to old problems”, but provocative responses to increasingly urgent challenges."
"Images of distressed, caged puppies on their way to be slaughtered at Yulin dog meat festival in China have caused outrage around the world. Angry Facebook posts, tweets and online petitions supported by the likes of Ricky Gervais and Simon Cowell direct us to gruesome photos of dead dogs, skinned and boiled and hung up on butchers hooks. I too find myself heartbroken by these images. But as a vegan I find myself wondering why isn’t there more outrage in the world over the slaughter of other animals. For instance, each year in the US roughly 110m pigs are killed for meat. Where is the same public outcry over bacon? The simple answer is emotional prejudice. We just don’t care enough about pigs for their needless suffering to pull at our heartstrings. As Melanie Joy, social psychologist and expert on “carnism” points out, we love dogs, yet we eat pigs, and there are simply no good moral reasons for such hypocrisy. One popular argument is that we should care more about dogs because of their superior social intelligence. This twitter user is typical: However this belief really just reflects the fact that people spend more time getting to know dogs than pigs. Many people have dogs as pets and through this relationship with dogs we’ve come to learn about them and care deeply for them. But are dogs really that different from other animals we eat? Though obviously not identical, dogs and pigs are quite similar in all the features that seem to count morally to most people. They have similar social intelligence with rich emotional lives, both can use human-given cues to locate objects, both might be able to use a mirror to locate objects (though research suggests pigs might have an advantage here) and, of course, both animals have a deep capacity to suffer and a desire to avoid pain. So whether you believe, like the philosopher Peter Singer, that sentience should be the basis of our assigning moral value to an agent, or you believe, like Peter Carruthers, that higher intelligence or the capacity to act according to moral principles should be the basis, then dogs and pigs seem to be on equal footing. Yet where are the global protests on behalf of pigs? As a psychologist who studies the way people think morally, I am sobered (and saddened) by the cold truth that people are often blind to the inconsistencies in their thinking, particularly when animals are involved. Andrew Rowan, director of the Center for Animals and Public Policy at Tufts University, once observed that: “the only consistency in the way humans think about animals is inconsistency”. His statement is increasingly being backed up by new psychology research.  For one, people allow the wrong factors to influence their judgements of an animal’s moral standing. People often think with their heart rather than their head. For example, in one recent study conducted by my lab (not yet published) we presented people with images of farm animals and had them decide how wrong it would be to harm them. Unknown to participants, however, they were either presented baby animals (baby chicks, for example) or adult animals (fully-grown chickens).  By a large margin people said it would be more wrong to harm the baby animals than the adult animals. And why? Additional measures showed it was because baby animals are cute and evoke feelings of warmth and tenderness in people, while adult animals do not. The intelligence of the animal had nothing to do with the moral value that was assigned. While these results may not be terribly surprising, they do highlight a problem with our moral hardware. Our morals seem to be guided in this case by involuntary emotions rather than careful reasoning. Second, we are inconsistent in our use of “facts”. We tend to think the evidence is always on our side – what psychologists call myside bias. In one study I simply had people rate their level of agreement or disagreement about a number of potential benefits of going vegetarian. The benefits ranged from environmental benefits to animal welfare, health, and financial benefits. I thought people would be divided about the benefits of going vegetarian, endorsing some of the arguments but not all of them. This is not at all what I found. People did not simply endorse one or two benefits; they either endorsed all or none of them. In other words, people recruited all of the arguments that supported their foregone conclusions about eating meat or going vegetarian. Thirdly, we are quite flexible in our use of information about animals. Rather than thinking carefully about the issues or the facts, we tend to endorse evidence that supports our desired views. In another recent study not yet published, carried out with Steve Loughnan from the University of Edinburgh, we had people tell us how wrong it was to eat one of three different animals. One animal was a fictitious, alien animal they had never encountered before; a second was a tapir, a strange animal that is not used for food in their culture; finally, there was a pig. All participants received the same information about the animal’s intelligence and cognitive capacities, but people only thought it was wrong to kill the alien and the tapir for food. For the pig, participants ignored the intelligence information when making their moral judgement. It is normal that we eat pigs – and this seemed to be sufficient to lower pigs’ moral value, despite their equal intelligence. Thus, while the vegan inside me is puzzled to see people get upset about the use of dogs as food yet not think twice about chowing down on a pork chop, my inner psychologist is not at all surprised. Our moral psychologies are good at finding fault, but not when the spotlight is turned toward our own practices and preferences."
"Three decades from now, several crucial elements of the Antarctic Treaty will come up for possible renewal, plunging the future of the continent into uncertainty. For six decades, the treaty has been the cornerstone of governance for our most southerly, harshest and most pristine continent. It has fostered scientific research, promoted international cooperation, ensured non-militarisation, suspended territorial claims and strengthened environmental protections. Its guardians are the Antarctic Treaty Consultative Parties (ATCPs) – chief among them the US, UK, Australia, New Zealand, Russia, Norway, Germany, Chile and Argentina. Out in the field, a new generation of robots and drones are peering under ice shelves, probing the ocean depths and monitoring glaciers, ushering in the age of the “Smart Antarctic”. The ice sheets aren’t exactly flourishing – the Antarctic continent has lost three trillion tonnes of the stuff since 1992 – but scientific research is thriving. For many polar researcher this is a reason for optimism – but in the political arena, the horizon is darkening. As it stands, the Antarctic Treaty acts as a safeguard for Antarctic science: an international bulwark against commercial or political interference. But as the years tick by, the treaty – and the cooperation that accompanies it – could begin to quietly fracture or even disintegrate completely. In 1998, seven years after it was first signed into the treaty, the Protocol on Environmental Protection came into effect. Its purpose was to “enhance protection of the Antarctic environment and dependent and associated ecosytems” – a noble if poorly defined pledge that has proven difficult to uphold. But, tucked away among the acronyms and technical terminology, Article Seven of the Protocol consisted of a single important sentence, easily missed by the careless reader: “any activity relating to mineral resources, other than scientific research, shall be prohibited”. Simple and to the point. Antarctica’s natural resources, whatever they may be, are to remain pristine and untouched. At least for now.  Article 25 carries a caveat: “If, after the expiration of 50 years”, it reads “any of the Antarctic Treaty Consultative Parties so requests, a conference shall be held as soon as practicable to review the operation of this Protocol”. In other words, 30 years from now in 2048, the ATCPs could reject anti-mining regulation and start stripping Antarctica of its mineral resources, diverting the continent towards a radically different future. Many consider this undesirable, unworkable and unthinkable, but long-time observers know that the uncharted waters of polar politics can constantly surprise. In fact, the “unthinkable” has already been thought – and half-acted upon. In the 1980s, the ATCPs drew up an international mining framework called the Convention on the Regulation of Antarctic Resource Activities, which sought to regulate any possible future resource extraction. It established property rights and gave special privileges to seven claimant states – including the UK. The framework would not function today – China and India would certainly demand far-reaching revisions – but in the 1980s it was only when France and Australia pulled out and started championing the current protocols that the convention was shelved. Indeed, a number of states might now have issues with the treaty. Much of the governance set down by the Antarctic Treaty still dates from when it was first negotiated in the late 1950s, in a very different political, technological, legal and environmental climate. It only involved 12 states and was concluded long before China became a polar superpower. The Antarctic ice sheets were considered stable – and there was still a great deal of mystery surrounding what lay beneath them. There was little to no tourism – now it’s the biggest industry operating in Antarctica.  Fast forward to 2048: the Antarctic is melting, plastics are found in the ice, and foreign species (including yet more humans) dot the continent. Drones and other automated vehicles are routinely used and the polar summer is a hive of activity, with thousands of tourists mobbing every penguin colony. Commercial fishing thrives in the Southern Ocean and permanent settlements spring up on the Antarctic peninsula and surrounding islands. The profits available from biological harvesting have made the extremes of Antarctic living a reality. Indeed, major polar operators such as China and the US only continue to support the mining ban because their energy needs can be satisfied elsewhere. At present ACTPs are focusing on improving cold weather technology and gaining confidence in Antarctic conditions, but it might not be long until they have the capability and incentive to do more. China is already using underwater vehicles to search for gas hydrates and metallic nodules in the South China Sea. Ominously, underwater mining and deep-sea energy prospecting seem set to be growth industries over the coming decades. So what could change between now and 2048? Possibly little: the ATCPs might decide to keep the Protocol and continue to prohibit mining. Or they might not.  The recent announcement of a marine protected area in the Ross Sea was a good sign for conservationists, but it required a great deal of tough negotiation. This “general protection zone” forbids fishing completely, and joins an existing “special research zone”, which permits limited fishing of for toothfish and krill. These will come up for review in 2047 and 2052, adding another dimension to what could become a period of unparalled change for polar governance. If the ATCPs decide to question the provisions of the Protocol, automated mining could begin soon after. Those in favour might argue that the Antarctic environment is continuing to degrade in a way that no amount of regional management can halt. Or they might put forward the view that the need for new sources of protein outweighs the “restrictive” conservation measures. Either way, the “special” qualities of Antarctica might not carry quite the same emotive weight in the future.   After 2048, Antarctica could be carved up between nations like every other land mass and surrounding ocean, and slowly relieved of its resources. Those who care about the future of Antarctica must keep a close eye on the continent and its surrounding seas, or risk losing them to drones, drills and desperate politicians."
"
Share this...FacebookTwitterIn two new papers, scientists affirm a strong connection between solar activity and the Earth’s climate, as temperatures are said to be 3 times more sensitive to solar forcing than CO2 forcing.  
With the advent of  a grand minimum in the coming decades, a consequent “dampening” of temperatures (and slowing of sea level rise) is expected.  
Between 2000 and 2100, surface temperatures are only expected to warm by a total of about 1.1°C, a climate change that may ultimately be beneficial.  

McCrann et al., 2018
“The effect of the Sun’s activity on Earth’s climate has been identified since the 1800s.  However, there are still many unknowns regarding the mechanisms connecting the Earth’s climate to the variation in solar irradiance. Climate modelling that implements the solar sciences is a novel approach that accounts for the considerable effect that natural factors have on the climate, especially at regional level. This paper discusses the noticeable effect that planet oscillations have on the Sun’s activity, which gives a very good correlation with the observed patterns in global surface temperatures, rainfall records and sea levels.”
“A clear 60-year cycle has been identified in many studies, and in accordance with this, it is expected that temperatures will reach a trough of the cycle around 2030-2040. This is in agreement with the forecasted low sunspot activity that is usually linked to lower temperatures.”
“Furthermore, considering the influence of the Solar Inertial Motion, a solar slowdown is predicted for Solar Cycles 24 and 25, which will create a weak grand minimum. It is anticipated that this weak grand minimum will be reflected in a dampening effect of global temperatures, and a subsequent moderation in the rate of sea level rise.”

Booth, 2018
“The TCR [transient climate response] to doubled CO2 is less than 2K (1.93 ± 0.26K).  Only 1.1 K of HadCRUT4 warming is expected between 2000 and 2100AD.  ∼35% of the warming during 1980–2001 was from solar variability, by 2 different analyses.”
“Temperature is nearly 3 times as sensitive to solar radiation as to CO2 radiation.  A model for ocean warming estimates equilibrium sensitivity as 15% greater than TCR [transient climate sensitivity].”
Share this...FacebookTwitter "
"For years, scientists and environmentalists have debated the best ways to conserve and protect natural resources from pollution and over-exploitation.  In the late 19th century, conservation advocates with the help of President Roosevelt succeeded in making Yellowstone the first US national park. Yellowstone’s status sent a strong message against unregulated commercial extraction and the model has since been replicated worldwide. However, the strict exclusionary nature of national parks was extremely burdensome for local and indigenous peoples who remained reliant on natural resources within protected areas.  The policy of “fortress conservation” was intended to give way in the late 20th century to a host of more sustainable alternatives, announced at the first Earth Summit in Rio in 1992. Conservation and development would be better integrated, and rural poverty addressed by bringing the poor into a global marketplace, while simultaneously delivering the market deep into the rainforests. Since Rio, market-based conservation has gained a lot of traction, and almost all forms of nature have been commodified. Packaged into sleek financialised terminology such as carbon credits, ecosystem services or species banking, the market has become such a supposed panacea for conservation that selling nature has become, for many, the only method of conserving it. Yet a cautionary tale of bioprospecting challenges the dominant and countervailing logic that if conservation were somehow made profitable, nature could begin to pay for its own survival.  Bioprospecting is the process of turning indigenous medicinal knowledge and nature into commercial drugs. Its advocates say it would provide the motivation and more importantly financing for conservation in the world’s biodiversity hotspots. Why chop down the Amazon if the forest might contain all kinds of useful and valuable drugs? The drug discovery example planted in the public’s imagination the iconic image of the “‘barefoot doctor’ seeking to find the medicinal cure to humanity’s ills under the canopy of the rainforests”. But with little to show in terms of any new blockbuster drugs or significant biodiversity saved, we are left to ask why the market has thus far been so underwhelming at achieving its conservation goals? Capitalism has never really been compatible with conservation. It encourages concentration of resources in already wealthier areas, while the urgent need to protect certain species or habitats is rarely reflected in market prices which are driven by desires to turn a quick buck. For example, drug discovery takes place in large high-tech research laboratories far removed from biodiversity-rich source countries targeted for conservation.  It takes more than 15 years and hundreds of millions in research and development costs to bring drugs to market – investment costs too big for low-income counties and local communities to even conceive of, never mind getting involved in, in any meaningful way.  For conservation to be effective, there needs to be an understanding of the benefits and the burdens of bioprospecting participation for all parties involved.  Burdens include the displacement and loss of access for locals due to new conservation enclosures – sometimes involving violence – and the potential misappropriation of nature and knowledge, what critics refer to as “biopiracy”. Many of these issues have a serious effect on any local “buy-in” to conservation programmes, and indigenous people rarely see the value of nature in terms of individual market exchange. Bioprospecting has come a long way in addressing some of these issues. The 2010 Nagoya Protocol, signed by 63 countries and the EU, set up access and benefit sharing mechanisms for the world’s genetic resources.  But right as bioprospecting seemed to be working out many of its problems, large pharmaceutical companies started closing their natural products divisions and moved on to the next big thing: chemically-derived computer generated molecules, known as combichem – a portmanteau of combinatorial chemistry. As with many market conservation initiatives, this was a fix; the fluidity of the market left the rural poor with little hope of a potential windfall of conservation benefits in their hands. For conservation thinking to move forward it needs to take into account some very important and complex issues concerning markets.  As much as we would like to believe that we have moved beyond the Malthusian belief that overpopulation and local level mismanagement leads to environmental degradation and scarcity, the spectre of too many people in the world continues to cast a “dark shadow” across our current conservation policy. This naturalisation of environmental problems fails to take into account many of the real drivers of global environmental change, such as the marginalisation of rural resource users due to poorly planned conservation policies, complicit elites, consumption by the global north and large scale extraction by multinationals. Paradoxically, many of these same industries have now become the saviours for today’s market conservation. No one has all the answers to conservation’s complex challenges, and rarely if ever are we going to find a perfect solution. But we can find the optimal solution. It is astonishing that so many critical social and natural scientists, many of whom have devoted their lives to challenging the dominant narratives of conventional thinking, have become champions for market conservation. We can do better."
"
Share this...FacebookTwitterNinety-nine percent of the Earth’s atmosphere is made up of two gases: (78%) nitrogen (N2) and (21%) oxygen (O2). Neither is considered an IR-absorbing/re-emitting greenhouse gas (GHG) like (0.041%) carbon dioxide (CO2) or (0.00018%) methane (CH4). 
Utilizing real-world Raman spectrometer data, an independent researcher from Sweden has found both N2 and O2 do indeed absorb radiation, or function as GHGs. If true, the CO2-is-a-special-heat-trapping-gas conceptualization effectively collapses.

Image Source: ResearchGate
A new paper entitled “Quantum Mechanics and Raman Spectroscopy Refute Greenhouse Theory” has recently been made available online.
Written by Blair D Macdonald, an independent researcher specializing in fractral geometry and quantum mechanics, the analysis utilizes real-world IR spectral measurements from a Raman spectrometer (laser).
Concisely, Macdonald has determined that CO2 is no more “special” a gas absorber and re-emmitter of radiation than nitrogen or oxygen, even though the latter are not considered greenhouse gases.
What follows is but a tiny snapshot of some key points from this comprehensively-sourced paper.
Note: It would be advisable that interested readers – especially those who are rightly skeptical of iconoclastic analyses like these – should read the text in some detail before commenting.  Turning the spotlight on papers that question conventional wisdom is primarily intended to elicit open-minded discussion.  It is not intended to convey we have arrived at a definitive conclusion about the authenticities of the CO2 greenhouse effect.

Macdonald, 2018
Quantum Mechanics and Raman Spectroscopy 
Refute Greenhouse Theory
Abstract:  “Greenhouse theory’s premise, nitrogen and oxygen are not greenhouse gases as they do not emit and absorb infrared radiation, presents a paradox; it contradicts both quantum mechanics and thermodynamics – where all matter above absolute 0° Kelvin radiates IR photons.  It was hypothesized these gases do radiate at quantum mechanics predicted spectra, and these spectra are observed by IR spectroscopy’s complement instrument, Raman spectroscopy; and N2 spectra can be demonstrated to absorb IR radiation by experiment, and application o the N2-CO2 laser.  It was found the gases do possess quantum predicted emission spectra at 2338 cm−¹ and 1156 cm−¹ respectively, both well within the IR range of the EMS, and are only observed – and their temperatures accurately measured – by Raman spectrometers.  Raman spectrometers measure, more accurately, the Keeling curve, and have application with meteorological Lidars and planetary atmospheric analysis.  The N2-CO2 Laser showed – contrary to current greenhouse theory – N2 absorbs electrons or (IR) photons at its – metastable ‘long-lasting’ – spectra mode.  It was argued atmospheric CO2, as a law, is heated by the same mechanism as the N2-CO2 laser: nitrogen (first) and the entire atmosphere absorbs IR radiation directly from the Sun, just as it heats water on the ocean surface.  With these findings, greenhouse theory is wrong – all gases are GHGs [greenhouse gases] – and needs review.”

 

 

Image(s) Source: Macdonald, 2018
Share this...FacebookTwitter "
"The BuzzFeed video, “Bacon lovers meet baby pigs” is amusing to watch. With 14,493,383 views, you may have seen it. It depicts several young men and women waiting blissfully to be delivered a plate of mouthwatering bacon, only to be handed instead a cute baby pig. Gasp! The participants react with high-pitched squeals of glee as they embrace a piglet, before looks of bemusement emerge in the realisation that their love for bacon and affection for the piglet [don’t mix]. One woman exclaims, “I’m never going to have bacon ever again.” A male respondent jokes, “I mean, he does look delicious, let’s be honest.”  The video is entertaining. But it also reflects a subtle truth about the relationship men and women have to meat: the two sexes often differently resolve the tension caused when thinking about the slaughter of animals. 


      Read more:
      Why don't we feel more guilty about eating animals?


 Many studies show that men tend to enjoy meat more than women, and consume it more. For example, a 2014 Faunalytics study found that females disproportionately outnumbered men among both current (74%) and former (69%) vegetarians and vegans in the US. Women are more likely than men to reject meat for reasons related to its appearance, taste, health, weight loss, environmental concerns, and animal welfare. Men, by contrast, identify a lot with meat, perhaps because of historical associations between meat and masculinity.  Women who do eat meat often use somewhat different strategies than men to avoid guilt over eating animals. The psychologist Hank Rothgerber has shown for example that men, as a group, tend to endorse human domination beliefs and pro-meat justifications for the slaughter of farmed animals. That is, they’re more likely to agree with statements like, “humans are at the top of the food chain and meant to eat animals”, or “meat tastes too good to worry about what all the critics say”. In one study based on a 1-9 scale of agreement, where nine meant “strongly agree,” men averaged almost six compared to around 4.5 for women on measures of pro-meat and hierarchical justifications. These pro-meat beliefs help neutralise any notion that eating meat is problematic.  Rothgerber found that women on the other hand are more likely to engage in less overt strategies to reduce the cognitive dissonance, such as avoiding thoughts about the suffering of animals when eating meat (on the same scale of agreement, where nine meant they strongly try to avoid such thoughts, women average around nine while men register 5.5). These indirect strategies are useful, but they are more fragile. When confronted with the reality of animal slaughter (perhaps through sympathetic movies such as Earthlings or Okja) it may be more difficult for women to avoid sympathising with the animals they find on their plates.   Women’s sympathies towards animals are on sharp display when contrasting men and women’s responses to baby animals. Baby animals, like human babies, are particularly vulnerable and dependent on the care of their parents for survival. They also display stereotypically “cute” features – large head, round face, large eyes and chubby cheeks – that we associate with human infants, what ethologist Konrad Lorenz termed Kindchenschema, or “baby schema”.  Research shows that both men and women can detect cute features in baby faces. But women, especially women high in maternal tendencies, find images of cute babies particularly emotionally rewarding.  Because of their mixed opinions about meat, and women’s emotional attunement to baby features, my colleagues Neil McLatchie, Cecilie Olesen and I wondered whether women might find meat particularly distasteful when it comes from a baby animal. Might women show greater tenderness towards a piglet than their adult counterpart, an adult pig? And might this lead women to reject meat, even when the end product looks the same for both animals? We wondered the same about men, but we did not expect them to show much movement in their appetite towards meat on account of their more positive relationship with meat. Across three studies, we presented 781 American men and women with either images of baby animals – from baby cows and kangaroos to baby pigs and lambs – or their adult counterparts. We paired the animal images with a meat dish (the precise dish varied between studies). In each study, the meat product was always the same image regardless of whether the animal was an adult or baby. Participants rated their appetite for the dish on a 0-100 scale (from Not at all to Extremely appetising) and made ratings of how cute the animal was or how tender it made them feel.  Women consistently found the meat dish less appetising when it came from a baby animal than when from an adult. Looking across the three studies, they tended to rate the meat dish on average 14 points less appetising on the 0-100 scale. This was partly explained by their greater feelings of tenderness towards the baby animal. Results for men were less conclusive. Their appetite for the dish was largely unaffected by the “babyness” of the animal (across the studies, on average, about four points less appetising when it was a baby). Interestingly, we observed these gender differences despite establishing beforehand that both men and women rated baby farm animals (chicks, piglets, calves, lambs) as highly worthy of their moral concern. Men seemed better able to separate their appraisals of baby animals from their appetite for meat.  Of course, our studies did not investigate whether men and women went on to reduce their meat consumption, as we did not follow them into their homes or kitchens. What our research does suggest is that appeals to care-taking emotions, which are so important for how we treat members of our own species, might be beneficial for getting people to rethink their relationship to meat. This seems especially true for women. Indeed, vegetarian strategists and animal advocacy groups identified this baby-tenderness effect long ago. The next time you pick up a leaflet from an animal welfare group like Viva! or PETA, pay attention to the animal images you see. More than likely most of them will be of baby animals."
nan
"Pollutants in rivers and other water bodies are a serious problem for marine life as well as human health. However, removing them from the water can be a costly process, often requiring energy from fossil fuels, which adds to both operating costs and environmental damage. Consequently, using plants to remove pollutants – a process known as phytoremediation – has become increasingly attractive around the world.  Not only is phytoremediation more environmentally friendly than conventional methods, it is cheaper too. It involves using photosynthesising organisms to remove pollutants – for example, heavy metals like lead – from water. It is thought that the mechanism of removal involves a combination of adsorption (whereby pollutants stick to the surface of roots) and absorption (whereby they’re taken up by the plants’ transport system) of metals via the plant roots.  Our research team has recently been investigating how phytoremediation could help clean up rivers in Britain. Though phytoremediation has been used in the country previously, this time we have been specifically using water hyacinth. This tropical plant is not native to the UK, and is actually classed as an invasive species. It has been used for phytoremediation before, but we were the first to use it in a temperate Northern hemisphere river, far removed from its native habitat, originally in South America. What we found was remarkable. The water hyacinth was able to remove highly toxic elements from river water. We introduced the plant to the Nant-Y-Fendrod stream, a tributary of the River Tawe, in Swansea. This waterway is located in an area which was the heart of global copper production during the 19th and 20th centuries. As a consequence, it has been heavily polluted by millions of tonnes of copper and zinc smelting waste. Despite previous efforts to remediate the land using conventional approaches, such as the removal of contaminated soil, considerable contamination of heavy metals remains, affecting the stream’s water quality. In fact, pollution is so bad that it fails to meet EU water quality standards. 


      Read more:
      Four simple ways you can reduce pollution in your local river


 We constructed two purpose-built treatment pods to contain the plants in the river, preventing them from escaping but allowing the water to move in and out of them. We used 25 plants in each pod, covering around one square metre. This equated to approximately 10% of the width of the channel. The content of heavy metals in the river water was determined – using inductively coupled plasma mass spectrometry – prior to plant introduction, within the treatment pods, and downstream on an hourly basis for a period of seven hours. We found that the water hyacinth was able to remove many different heavy metals – including cadmium, zinc, arsenic, lead, chromium, aluminium, copper, manganese and nickel – from the stream’s water. The speed of this metal removal was fast. Our tests demonstrated more than 60% of the aluminium and zinc polluting the water which went into the the pods was removed within just seven hours. Such a high speed of removal is consistent with the reputation of water hyacinth as the fastest growing aquatic plant in the world.  To date, most research work on the water hyacinth plant has originated from developing countries. But given the effects of climate change on the distribution of all kinds of species, researchers from developed countries urgently need to play a greater role in exploring its control, management and effective utilisation.  One particular area of research that still needs to be explored is dealing with the water hyacinth after it has adsorbed/absorbed pollutants. There are several possible solutions, such as recovery of the metals it has adsorped/absorbed for industrial use, and using the plant biomass for bioenergy production or fertilisers. Another option is to find a way to live with what is the world’s most prolific aquatic plant, instead of eradicating it – which has so far been unsuccessful.    The plant has a prolific growth rate and, as climate change affects the range of all kinds of species, it will likely spread into new regions. This means that it may no longer be a problem solely linked with poorer countries in Africa, Asia and South America, where it clogs up rivers, lakes and canals causing huge economic burdens.  Though there are disadvantages to phytoremediation – including that it takes time for the plant to trap the pollutant, and that it must carefully be managed to stop it blocking waterways entirely – our research has shown how nature can help heal the damage caused by industry."
"The mahseers are an iconic group of fish found throughout the fast-flowing rivers of South and South-East Asia. Characterised by their large scales, attractive appearance and potentially vast size, the mahseers have long been afforded saintly status as “God’s fishes”. They are also known to anglers as some of the world’s hardest fighting freshwater game fish, earning them the reputation of “tigers of the water”. But despite lots of interest in mahseers, their future is under serious threat as their rivers become polluted and blocked by hydropower dams in order to support a rapidly growing human population. Those fish that do survive are vulnerable to illegal “dynamite fishing” in which a blast kills or injures all aquatic life, allowing poachers to harvest anything that floats to the surface.  Of the 18 currently valid species of mahseer, the official IUCN Red List of Threatened Species currently lists four as endangered, one as vulnerable, and one as near threatened. The rest either lack enough data to reach a conclusion or haven’t been evaluated. Recent research published by colleagues and I in PLOS ONE focused on the hump-backed mahseer, the largest and most endangered of all mahseers. The fish was once common throughout the Cauvery river and its various tributaries in southern India, but it is now limited to just a handful of small isolated populations. Weighing as much as a small adult human (55kg), this freshwater giant qualifies as megafauna, yet bizarrely it has remained a taxonomic enigma without a valid scientific name. Until now. Colleagues and I discovered that the hump-backed mahseer is actually the same species as Tor remadevii: a mahseer that previously lacked a common name. Scientists first described Tor remadevii as a new species in 2007, based on a small sample of juvenile fish from the most southerly tributary of the Cauvery catchment in the state of Kerala. Little did they realise that the small fish they had discovered from this remote sub-catchment was the same as the monster mahseer found in the upper and middle reaches of the main river Cauvery.   The hump-backed mahseer was first brought to the attention of the world’s anglers in Henry Sullivan Thomas’s 1873 classic, The Rod in India. During British rule, several huge specimens were recorded, including the still-standing world rod-caught record, a 120lb (54kg) monster captured in 1946 by a taxidermist from Mysore known as de Wet Van Ingen. Indian independence followed soon after, and the mahseer was largely forgotten by the outside world, with many believing the fish had been dynamited to extinction. That was until 1977, when the Trans World Fishing Team – comprised of three Englishmen –travelled to India and spent several months exploring the country’s rivers before reaching the Cauvery. There they found the hump-backed mahseer very much alive, and realised their sporting dreams by recording individual catches up to 92lbs (42kg). This reignited global interest, and catch-and-release anglers from around the world flocked to the River Cauvery in search of the legendary fish. Local villagers found employment as angling guides, cooks or drivers, some of them rehabilitated poachers who realised that a live mahseer had renewable value, unlike the single value of a dead one at market. Patrols were set up to protect the species 24/7, allowing the ecology of the river to flourish.  But all was not what it seemed. Since their establishment in the 1970s, the angling camps had been collecting invaluable data which shed new light on the situation. When colleagues and I analysed these detailed catch records, we realised the hump-backed mahseer had almost disappeared. Although overall mahseer stocks were rising, the humpback itself was being rapidly replaced by a non-native and highly invasive species of mahseer, which had been deliberately introduced to the River Cauvery to boost stocks in the late 1970s. This led us to publish a paper in 2015, outlining the threat of imminent extinction facing the hump-backed mahseer. The hump-backed mahseer has been known around the world by its common name, but confusion over its scientific name has prevented its inclusion in the IUCN Red List of threatened species. Given the fish is on the edge of extinction, it proved a significant challenge finding wild specimens from which to collect the DNA and associated evidence required to support a formal taxonomic clarification. Only after three years of expeditions was our team finally successful in finding a small population of humpbacks in a remote jungle section of the River Moyar, a tributary of the Cauvery. The paper we recently published fixes the scientific name as Tor remadevii and should see the iconic species assessed as “critically endangered” in the next update of the Red List. The significance of the research published will afford this iconic fish the recognition and legislative protection it so urgently requires to develop robust conservation planning.  However, in the long term, the fish’s future rests in the hands of the three Indian states with stakes in the highly-contested Cauvery river system – Tamil Nadu, Kerala, and Karnataka. One hope is that the humpback mahseer will become a unifying force and bring these states together to protect the rich biodiversity and natural function of the Cauvery from further decay, allowing the river to continue to support the many millions of people who depend on it."
"The devastating floods in the Indian state of Kerala are a stark reminder of the vulnerability of the world’s most densely populated regions to weather and climate phenomena. In addition to the tragic loss of several hundred lives, widespread floods driven by unusually high and persistent monsoon rains have severely impacted the region’s fragile infrastructure and displaced more than a million people. Only in recent days has the Indian government been able to understand the full extent of an estimated US$3 billion worth of damage. It is now typical that the aftermath of severe weather events is marked by questions about the role played by human-induced climate change. More precisely, scientists aim to provide a timely statement about the extent to which global warming has changed the likelihood of a certain weather-related hazard. The practice of attributing an event to climate change has become a regular activity and is being tackled with a growing number of methodologies. Improvements in the computer models used to make climate predictions means that attribution information can often be made available immediately after, and sometimes even during, the event. For instance, reports declaring this summer’s heatwave across Northern Europe to be at least twice as likely as a result of climate change were circulated while many citizens continued to experience the scorching temperatures. Being able to communicate this information while the event is still firmly in the consciousness of the general public is potentially very powerful in changing the opinions of those resistant to climate action News of the worsening situation in Kerala is an opportunity to consider why understanding the effect of climate change is more difficult for some events than for others. For example, the links between global warming and temperature extremes are reasonably well understood. It should come as little surprise that a warmer world will bring more severe summer heatwaves and more frequent mild winters. When it comes to rainfall, however, things are a bit more complicated.  Unlike temperature, rainfall varies hugely in space and time. Even the most sophisticated climate models struggle to simulate physical processes such as convection and evaporation that drive rainfall activity. On top of that, global warming is not expected to change the frequency and intensity of rainfall extremes in the same way in all parts of the world. On a global scale, an increase in the most severe rainfall events is anticipated given the atmosphere’s capacity to hold around 7% more water per °C rise in temperature, as described by the Clausius–Clapeyron relation. But when we get to the regional scale, this relationship becomes somewhat distorted by the response of rainfall to meteorological phenomena such as tropical cyclones, thunderstorms and, in the case of the Kerala event, monsoons. So, how should an extreme rainfall event be defined? By the amount of rain that fell or by the weather patterns that caused it? The choice to focus solely on the rainfall itself is particularly relevant for flooding events. Though accusations of poor decision-making and mismanagement of water resources are beginning to appear in the Kerala aftermath, the floods simply would not have occurred without a significant amount of rain. Few of those suffering lost homes and livelihoods are likely to care much about where the rain came from or the intricacies of the weather conditions that led to it. But to understand as much as possible we must consider the individual responses of weather phenomena to a changing climate. Different approaches tackle the problem in different ways – and may produce conflicting results. Even in the absence of a significant trend in the highest rainfall totals, a climate change signature may still exist in the form of rising temperatures in the oceans where the moisture that fed the rainfall originated. Disentangling these contributory factors takes time. In comparison to droughts and heatwaves, short-term hazards such as floods do not usually give us much chance to report concrete findings while the media and general public are still engaged in the event. In-depth studies may not publish their results for many months, sometimes even years after the event in question. Many of these issues are not exclusive to extreme rainfall. The excellent US National Academies report on Attribution of Extreme Weather Events in the Context of Climate Change describes the shortcomings in our efforts to attribute a variety of extremes. But for rainfall in particular there is a discrepancy between what we understand about the general effect of global warming and our rather lesser ability to quantify the climate change fingerprint on specific events.  While this is a cause for concern, the opportunity for improvement should be the focus of our attempts to make attribution a more effective vehicle for communicating climate risk."
"Life on Earth is entering the greatest mass extinction since the death of the dinosaurs, according to a major new study – and humans may be among the casualties. Such a catastrophic loss of species would leave a huge hole in the world’s ecosystems, and all sorts of weird and wonderful life would evolve into the vacancies left behind. To consider what life after a mass extinction might involve, we can look to the past. There have been five major mass extinctions in Earth’s history – though colleagues and I recently proposed a sixth – and comparing current rates of change to the geological record of the “Big Five” extinctions suggests that this time the warning signs are real.  So let’s be pessimistic, and assume the apocalypse is going to happen. What does Earth look like afterwards? The Permian-Triassic boundary (251m years ago) saw the greatest crisis in Earth’s history, when at least 90% of species died off. Even insects suffered huge losses – the only mass extinction in their long history. The event is widely attributed to the effects of the Siberian Traps – huge volcanic outpourings of lava and associated greenhouse gases, in what is now northern Russia. This lead to global warming, ocean acidification and acid rain, marine oxygen depletion and poisoning by toxic metals such as mercury. Imagine today’s gloomiest climate predictions, but cranked up a few notches. The few species that survived gave rise to all life thereafter and there has not been such a profound restructuring of ecosystems since, perhaps because this “survival of the fittest” rendered their descendants more tolerant to global change.  What did the planet look like in the Early Triassic? It was hot – hot as hell – and seemingly lifeless over vast areas. Sea-surface temperatures reached up to 45°C in the tropics. In the vast Pangaean desert it was probably even hotter. The heat caused land animals, marine reptiles and fish to disappear from the fossil record in all but the high latitudes, which were presumably a little cooler, for millions of years. In fact, there are several “gaps” in the Early Triassic.  The bulk of the world’s coal today derives from vast swathes of the Permian seed fern Glossopteris – a prominent casualty, whose loss led to a “coal gap” of at least 12m years.  A series of Early Triassic “fungal spikes”, where rocks contain greatly enhanced numbers of spores, has been attributed to huge amounts of dead plant and animal matter available for fungi to feed upon. The heat, and acid rain-induced destruction of soils (which would have smelled of vanilla), must have rendered the planet largely uninhabitable.  Without plants there are no plant-eaters. Without herbivores there were no carnivores. One of the few “big” survivors on land was the “shovel lizard” Lystrosaurus, an odd-looking vegetarian which, in the absence of predators and competitors, diversified with some success during the Triassic.  The carnage was worse in the oceans, where up to 96% of species went extinct. The loss of all reef-building corals led to a 10m year Early Triassic “reef gap”. Think of it: a world without reefs – and without all the diverse and abundant life they support.  But Earth wasn’t quite lifeless – and as well as Lystrosaurus there were marine success stories amid the horror. Claraia was an opportunistic genus of scallop-like bivalve that survived the end-Permian, and then quickly diversified to fill the vacant niches left by the almost total annihilation of the dominant Permian sea-floor dwellers, the brachiopods. Claraia was tough and could withstand very low oxygen levels – a trait that came in very handy when most sea-bed life was being starved of oxygen.  Perhaps the most famous and eye-catching extinction saw the death of the (non-avian) dinosaurs around 66m years ago at the Cretaceous-Tertiary boundary. As well as picture-postcard victims such as T. rex, the turnover in tiny plankton at the other end of the food chain saw an end to the formation of the famous Cretaceous chalk cliffs that are so widespread across Europe (the period’s name comes from the German “kreide”, meaning chalk).  Whether it was a meteorite, more massive volcanic eruptions, or a bit of both that did the damage, in comparison to the Permian-Triassic scenario, the death of the dinosaurs was more modest (around 75% of global species lost) and the recovery was more rapid. Either Earth sorted itself out more quickly, or, following the “Great Dying” 185m years previously, life had become better at adapting to, and evolving with, stress.  Of course, dinosaurs are not exactly extinct. Birds are highly evolved dinosaurs that derive from the few dinosaurian survivors of the Cretaceous-Tertiary (K-T) event and nobody can deny their evolutionary success in the 66m years since the demise of the chicken-like T. rex. Crocodiles and alligators – the closest living relatives of birds – are among the other prominent survivors. While it’s clear that birds’ ability to fly to oases of calm and plenty allowed them to flourish amid the upheaval of the K-T boundary, it is not obvious why crocodilians survived. Theories suggest their cold-blooded bodies (vs. the supposed warm-blooded theropod dinosaurs), their fresh or brackish water habitat or even their high IQ enabled them to flourish. The good news amid all this death and destruction is that life on Earth always recovers, even when it has been really badly damaged. Without extinction, there is no evolution – the two are intrinsically linked.  The earliest dinosaurs evolved 20m years after the Permian-Triassic losses. Their evolution was almost certainly driven by a freshening of climate during the “Carnian Pluvial Event” (when it rained, a lot), new-found lush vegetation and the swathes of ecospace available to colonise.  Dinosaurs lived for 165m years before their demise, but without their death, humans probably wouldn’t be here today to do their damage. Mammals, of course, were the great beneficiaries of the dinosaurs’ downfall.  If humans are indeed doomed then we won’t be around to see what evolves to replace us. But rest assured, we geologists don’t take ourselves too seriously – we know that Earth is bigger than us, and it will bounce back."
"The G7 leaders have pledged to wean their economies off fossil fuels by the end of the century, as part of a series of commitments in the joint post-summit communique. It’s the first significant climate pledge since the new Conservative government came to power – and it might prove an important indicator of things to come.  After energy and climate change were barely mentioned in the recent election campaign, the G7 represents the first of a series of events which will force the government to reveal its hand. Climate policy may even define UK Prime Minister David Cameron’s legacy on the international stage. The Conservative manifesto provides some indication of the party’s likely policies: competition to keep energy bills low, securing energy supplies, limiting onshore wind farms, a commitment to meeting the UK’s climate change targets and support for the Climate Change Act. But as yet we know very few details. This risks leaving a vacuum which could be filled by untruth or misrepresentation. Scientists are having trouble convincing the public about climate science – polling released in early 2015 showed most people in the UK believed the climate was changing but just 18% were “very concerned”. This raises the important question of which camp our political leaders belong to. Cameron and his new energy and climate change secretary, Amber Rudd, must listen to scientists.  The science is clear on this – climate change is a real phenomenon caused principally by the increasing level of the greenhouse gas, CO2, in the atmosphere. The IPCC states human influence is the “dominant cause” of recent warming.  But the science doesn’t automatically filter through to politicians. The most recent IPCC report is a good example of this. The report included a 30-page “Summary for Policymakers”, which was the subject of intense debate in Copenhagen, with scientists and politicians editing and redrafting the main points. Somewhere in the edit, the scientific findings about the failure of the 1997 Kyoto protocol were chopped down to a pithy bullet point stating that it “offers lessons”. Perhaps our politicians would wish to believe they had achieved more than the scientific data suggested. Now the G7 is out of the way, the UK won’t have to wait long to show further international leadership and make a substantive and lasting impact on climate change. In December 2015 the world’s leaders will meet in Paris to negotiate an agreement to replace the Kyoto protocol on greenhouse gas emissions. Paris can correct some of Kyoto’s omissions. The US never ratified Kyoto, and China was exempted in 1997 as it was then classified as a developing country. How things have changed – China is now the largest emitter of greenhouse gases. There are promising signs. Rudd has in the past spoken out in support of the IPCC’s work – and Greenpeace described her appointment as a “hopeful sign” that the government remains committed to addressing climate change. Closer to home, Rudd will also have to respond to any recommendations from the Competition and Markets’ Authority antitrust probe into the power market and the “Big Six” energy companies. This is likely to occupy a lot of her time. But while it is essential that the UK energy market is fair, transparent and affords all people equitable access to energy, there are bigger concerns on a world stage which need addressing if we are to achieve the 2°C temperature rise target that for many scientists is a “red line”. I hope we might see the UK leading the debate in this area and making a real difference.  Cameron has said this will be his last term as prime minister – and if he wants a truly global legacy there’s always Paris. The UK’s scientists wish him and Rudd every success in this area. All our futures depend on it."
"
Share this...FacebookTwitterSchneefan (Snow Fan) at German skeptic site wobleibtdieerderwaermung.de here recently posted an overview of Arctic sea ice. This summer as well has Arctic sea ice refused to obey all the claims of melting.

Source: DMI plot sea ice cover.
Sea ice increase accelerating
The above chart shows August mean Arctic sea ice area in million square meters from 1979 to 2018 (red curve). There’s been a positive linear trend since 2007.
Moreover, the upward linear trend has even sharpened since 2012 (green lines) since Al Gore and Peter Wadhams made their absurd projections there would be an ice-free Arctic by now.
Kirye at KiryeNet here shows that current Arctic sea ice volume for mid September remains at the center of the pack, and thus no sign of short-term dwindling Arctic sea ice:

Chart: KiryeNet
The Northwest Passage this year as well was continuously blocked by ice and thus impassable for the entire year.
Yacht ignored warnings, got crushed
But some refused to believe the ice was not melting. For example German Yacht Online here reported how a crew on the yacht “Anahita” had ignored warnings of the Canadian Coast Guard and tried to cross the Passage. By late August the yacht ended up getting crushed by sea ice and sank within minutes. The 2-man crew was forced to escape on the ice by foot and were later airlifted to safety by helicopter.
According to Yacht online: “The ‘Anahita’ was one of a dozen other yachts on the way from the east to the west through the Northwest Passage. However this summer the sea ice in the Arctic remained tenacious.”
Ship of Fools II


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Also a group of publicity seeking climate activists on Russian ice breaker/expedition ship ‘Akademik Ioffe’ were forced to move their starting point about 1000 km to the south to Kugaaruk. Just hours after starting on August 24, 2018, the vessel “ran aground on an uncharted shoal” and all passengers had to be rescued.
The trip was supposed to focus the world’s attention on global warming and “disappearing” Arctic sea ice. However, the expedition ended up being an embarrassment and ironically showed the opposite: the Arctic still had quite some ways to go before becoming ice-free.

The conditions the Northwest Passage Project crew were hoping for, but never became the case. Ice breaker/expedition ship Akademik Ioffe. Photo: The Northwest Passage Project
All passengers on the Akademik Ioffe were safely transferred to shore and returned home, the site informs.
“Uncharted geologic feature”
According to the website, the expedition was abandoned because the Akademik Ioffe needed repair after it had run aground and been refloated.
The expedition itself insisted the mission was not curtailed due to ice conditions and instead blamed “an uncharted geologic feature”. But why would a ship need to enter an uncharted area? Maybe because ice was blocking the usual route?
Today “Akademik Ioffe“ is back on the way to Les Mechins, Quebec from Kugaaruk and the expedition is postponed to summer 2019.

Chart: Marine Tracker.
Share this...FacebookTwitter "
"If only Scott Morrison was as willing to spend money preventing climate change as he is to spend it on disaster repair. The idea that a “stitch in time saves nine” and “an ounce of prevention is worth a pound of cure” was once central to the conservative approach to politics and economics. But while deterrence still lies at the heart of Australia’s $38.7bn defence budget, when it comes to climate change, Australian conservatives opt for suck it and see. Of course, this radical approach to ignoring risk is neither “conservative” nor widely practised around the world. As the climate science denier and Liberal party MP Craig Kelly found out when interviewed by a British conservative, Piers Morgan, the bizarre arguments that rightwing commentators spew out in Australia just don’t cut the mustard in the old country. It seems that while every rightwing commentator knows that the best way to fight a bushfire is to prevent it, when it comes to the climate crisis the same idea appals them. Hazard reduction burning before the bushfire season costs money. It causes smoke, inconvenience and it sometimes gets out of control – causing the very bushfires it seeks to prevent. Those costs don’t make hazard reduction burning a bad idea, they just prove that conservatives are more than happy to spend money upfront to avoid bigger costs down the track. Except when it comes to investing in renewable energy. How depressing it must be for Australian conservatives to hear statements from the royal family warning that Australia is contributing to a global “ecocide”. But, if the right to be monarch (and Australia’s head of state) is so-called God-given, does that mean God isn’t talking to our future kings and queens any more? Doesn’t Scott Morrison talk to God too? And doesn’t the Pope think we should take urgent action to burn fewer fossil fuels? It’s confusions like these that, back in the 1700s, gave science a good name. Just as a fish can’t tell you how the water is, most Australians seem unaware just how detached from reality our debate about the climate emergency is. As the graph below shows, most of the richest economies in the world have managed to significantly reduce their greenhouse gas emissions. Many grow their economies at the same time. Yet in Australia we have been told that reducing emissions and reducing jobs are one and the same thing. The bushfires that have ravaged Australia for the last month, and are likely to burn for at least a month more, haven’t just burned up our forests. They have burned up the last shreds of the curtain that Australia’s climate deniers hide their wilful ignorance behind. Scott Morrison’s claim that Australia is “meeting and beating” our emissions reduction targets is as misleading as it is meaningless. Leaving aside the fact that Australia is relying on accounting tricks to meet our Paris targets and to cover up our rising emissions, even if Australia was “on track”, that track still leads us to a world that is at least 3C warmer than it was 100 years ago. Australia is now experiencing the early symptoms of what climate change looks like. While conservatives have trolled the public debate, saying “there is no climate emergency” and that “CO2 is plant food”, Australians have now had their first clear look at what an “extreme weather event” is. This summer’s fires were so fierce they made their own lightning, which started new fires. This summer’s fires were so intense they created a wind storm that flipped over ten-tonne firetrucks and killed a firefighter. This summer’s fires were so vast that we have no chance of extinguishing them all. They will burn for at least another month unless heavy rains show. Those commentators who, for years, have obsessed about the “costs” of avoiding climate change while telling their audiences about the benefits of a heating planet, will probably never hang their heads in shame. But perhaps the news outlets that provide a platform for their dangerous denialism will. Or, perhaps not. There is nothing in our constitution that says for-profit companies must act responsibly or in the interests of their readers. And most Australians with an instinctive support for free speech and freedom of the press are willing to accept that it’s hard to regulate against fake news. But it is no coincidence that the same voices who once denied climate change, and then denied that climate change is caused by fossil fuels, are now the ones declaring that climate change doesn’t make bushfires more frequent or more ferocious. And it is no coincidence that the prime minister is far happier to fund disaster repair than he is to invest in disaster avoidance. Just as the climate-denying commentators burned up their credibility when they focused on the “upside” of climate change, the Coalition burned up its policy credibility when they ripped up the carbon price. There was a brief moment after the last election when the prime minister and some in the press gallery thought climate policy could be put on the backburner. But reality bites. Hard. The people who told us that the quiet Australians weren’t that worried about climate change, and that December’s fires were a “state issue”, are now in charge of developing a national plan to repair this disaster and prevent the next ones. What could go wrong? Richard Denniss is chief economist at independent thinktank the Australia Institute, @RDNS_TAI"
"I have always wondered why our species Homo sapiens, that evolved in Africa about 200,000 years ago, seemed to do nothing special for the first 150,000 years.  Because it is not until about 50,000 years ago that the first sign of creative thinking emerged with beautiful cave paintings found in Spain, France and Indonesia.    Around the same time a new sub-species referred to as anatomically modern humans or Homo sapiens sapiens appears. Anatomically modern humans were more slender than their earlier ancestors; they had less hair, smaller skulls. They looked basically like us. But these changes weren’t just cosmetic. Two recent papers throw some light on how the revolutionary development of smaller and more fine-boned humans influenced the growth of cooperative culture, the birth of agriculture and human dominance of the planet.  The first is an analysis of the fossilised skulls of our ancestors during this transitional period, carried out by a team led by Robert Cieri at the University of Utah and published in the journal Current Anthropology.  Cieri and colleagues found the brow ridge (the bony bit above the eye sockets) became significantly less prominent and male facial shape became more similar to that of females. They referred to this as craniofacial feminisation, meaning that as Homo sapiens slimmed down their skulls became flatter and more “feminine” in shape. They think this must have been due to lower levels of testosterone, as there is a strong relationship between levels of this hormone and long faces with extended brow ridges, which we may perceive today as very “masculine” features.  People with lower levels of testosterone are less likely to be reactively or spontaneously violent, and therefore this enhanced social tolerance. This has a huge knock-on effect. As seen among humans today, we live in populations with extremely high densities with an incredible amount of social tolerance. So a reduction in reactive violence must have been an essential prerequisite for us to be able to live in larger groups and develop cooperative culture.  The idea that humans became more feminine, less aggressive and thus could cooperate in large groups is certainly very intriguing as it would have allowed individuals with different skills to be valued and be reproductively successful due to the reduction of particularly male-male violence. In most primates the physically strongest male tends to dominate, but in early humans the smartest or the most creative males may have come to the forefront. The question remains, how did we become more feminine, less violent and more creative? A second paper in the journal Animal Behaviour led by Brian Hare at Duke University may throw some light on to this.  He and colleagues compared chimpanzees (Pan troglodytes) and bonobos (Pan paniscus) in West Africa, two closely related species living in very similar environmental conditions either side of the Congo River.  One key distinction between the two species is the size difference between males and females, their “dimorphism”. Male chimps are significant larger than females, whereas the difference in bonobos is much smaller. This difference is driven by different levels of testosterone. The size is just one manifestation of deeper differences that also show up in how the animals interact with one another. Chimpanzees, particularly males are very aggressive, but violence within or between groups is almost non-existent among bonobos.  As both these species have a common ancestor there must have been strong selection going on to feminise the bonobos.   Hare and colleagues suggest a process of self-domestication whereby violent individuals are punished and prevented from reproducing.  The traits exhibited by bonobos are very similar to the changes observed in species that humans have domesticated such as dogs, cows, guinea pigs and foxes. They postulate the reason why bonobos were able to feminise and chimpanzees did not, is because on the Eastern side of the Congo where the chimps live they are in direct competition with gorillas, whereas the bonobos on the western side have no competition.  Harvard professor Richard Wrangham, a co-author of the Hare paper, suggested in a recent talk that the same process may have happened to early humans. This feminisation through self-domestication may not only have made humans more peaceful and evenly sized, but may have also produced a more sexually equal society.  A recent study in the journal Science by colleagues of mine at UCL showed that in hunter-gatherer groups in the Congo and the Philippines decisions about where to live and with whom were made equally by both genders.  Despite living in small communities, this resulted in hunter-gatherers living with a large number of individuals with whom they had no kinship ties. The authors argue this may have proved an evolutionary advantage for early human societies, as it would have fostered wider-ranging social networks, closer cooperation between unrelated individuals, a wider choice of mates, and reduced chances of inbreeding.   The frequent movement and interaction between groups also fostered the sharing of innovations, which may have helped the spread of culture. As Andrea Migliano, the leader of the study points out, “sex equality suggests a scenario where unique human traits, such as cooperation with unrelated individuals, could have emerged in our evolutionary past.” It may have only been with the rise of agriculture that an imbalance between the sexes reemerged, as individual men were suddenly able to concentrate enough resources to maintain several wives and many children.  Indeed the Robert Cieri led study does show slightly more masculine facial shapes emerging in recent agriculturalists relative to early humans and recent human foragers. So at the moment we have some tentative hints of what may have happened between 50,000 and 10,000 years ago.  Humans may have undergone self-domestication and over many generations weeded out those individuals that were unable to control their reactive violence.   This is not as far-fetched as it sounds – studies of the Gebusi tribe in Papua New Guinea by Bruce Knauft showed significant levels of male mortality due to the tribe deciding that an individual’s behaviour is so intolerable that for the good of the tribe they must be killed.   So human proactive violence – that is, thought out, discussed and planned violence – is used to curb, control and cull reactively violent individuals. This process combined with female mating choices over thousands of years could have selected for males with lower testosterone and more feminine features, which leads to a much more gender-equal society and the start of our cumulative culture."
"Whether commanding the attention of rock star Neil Young or apparently being supported by the former head of Greenpeace, genetically modified food is almost always in the news – and often in a negative light. GM divides opinion, and even individual people can find themselves pulled in two different ways. On the one hand it is a largely new technology and new tech often brings prosperity, solves problems and offers hope for the future. But this also makes it a step into the unknown and people are frightened of what they do not know, or what cannot be known.  In a study recently published in the journal Appetite, colleagues and I examined why some people reject GM technology. We were neither arguing for nor against GM, but rather we wanted to look at the characteristics which determine people’s views.  Specifically, we examined attitudes in the EU to two different types of genetic modifications made to apples. Both involve the introduction of genes to make them resistant to mildew and scab. The first is a gene that exists naturally in wild/crab apples. This is an example of what is called “cisgenesis”. In the second one the gene is from another species such as a bacterium or animal, and is an example of “transgenesis”. As an idea of the gains available from this process, the production of a new apple cultivar may take 50 years or more. Gene transfer technologies can substantially shorten this. At the same time they may introduce characteristics from totally alien species which is virtually impossible to do naturally. This may then introduce many desirable qualities into the apple – for instance, in the hypothetical case we are analysing, the apples were made more resistant to disease. We found people’s attitudes tend to be driven by their fears of risk, and their hopes of gain, with hopes being more important for cisgenesis (introduced genes from other apples) and the former for transgenesis (genes from other species).  But quite separate to risk and gain are perceptions that the technologies are “not natural”. Evidently people are disturbed when science takes us away from what they see as the laws of nature. People are also concerned about environmental impact. Our data is based on a Eurobarometer survey carried out in 2010 of 15,650 people from around the EU. In general people seem to be more hesitant about transgenesis, than cisgenesis (apple to apple gene transfer). Thus 57.1% of respondents wished to see cisgenesis encouraged compared to just 31.4% for transgenesis. Clearly people are more worried about having animal genes in their apples, compared to genes from wild apples. Attitudes are not spread randomly across the population. Rather there are systematically different views dependent on gender, level of education, home background, whether in a village or a large town and across different countries.  Men are significantly more likely to support cisgenesis, for example, as are better educated and more prosperous people. Religion is also important and Muslims, Catholics and Orthodox Christians are significantly less approving than the general population.  People are more united in their disapproval of transgenesis (adding genes from other species). But, again, more educated people tend to be more approving as do men and the more prosperous, while older people tend to be more wary. Finally, for both technologies studying science, or having a father who studied science, impacted favourably on attitudes. Some figures show the impact of religion: compared to the 31.4% who approved of transgenesis overall, just 23.3% of Orthodox Christians did so. The situation is reversed for cisgenesis with 57.1% approving overall, but Greek Orthodox Christians now more supportive with 60.9% approving. It is now Muslims who are substantially less supportive with only 40.6% approving.  This is an example of how religious diversity leads to differing opinions on new technologies. Thus if a government wishes to encourage GM technology, it might give some thought to opening up dialogue with religious leaders. The EU is one of the world’s toughest places to gain approval for GM crops, in part because of these concerns expressed by its citizens. This has resulted in the EU falling behind other countries.  The more positive attitudes of scientists and better educated people may suggest wariness of GM foods is simply driven by ignorance. Increasing knowledge and understanding would help reduce this, but there may be limits – in reality few of us are fully able to evaluate the relevant technical arguments. Hence we tend to rely on the opinions of those we trust, religious leaders in some cases, experts, scientists and governments in others. The evidence is that people are more supportive and less concerned with cisgenesis than transgenesis. This perhaps makes sense as many in the sample perceived apples crossed with genes from other apples as more “natural” than apples crossed with something else. If from the outset these had been separately labelled, then it is possible the EU would have been quicker to give the green light to cisgenesis.  On the other hand treating them all as one and the same increases the possibility that the green light will eventually be given to all GM products, cisgenesis and transgenesis alike. It is an example of the dangers of placing disparate technologies in a single basket and saying: take it or leave it."
"
Share this...FacebookTwitterThe European Institute for Climate and Energy (EIKE) here posted a video of excerpts of a German Parliamentary hearing on climate change in the German Federal Parliament featuring Potsdam Institute for Climate Impact Research (PIK) scientist Anders Levermann and atmospheric physicist Prof. Nir Shaviv of Hebrew University in Jerusalem.
The hearing was to look into the controversy of climate change, with the AfD opposition party casting doubt on the German government’s long-held alarmist position.
In total the hearing lasted some 2 hours, but EIKE has fortunately provided a condensed 16-minute version featuring the main points.

As expected Levermann of the alarmist and activist PIK claimed that the physics of global warming were “rock solid” and that a doubling of CO2 would undoubtedly lead to 3°C of warming. He tried to claim the science was settled.
No proof…dubious hockey stick
At the 1:40 mark, Shaviv responded by saying there was “no scientific proof that showed CO2 has a large impact on climate” and that the arguments used by the IPCC to claim otherwise “are faulty”.
He says we know today that the hockey stick chart was “dubious science”.
IPCC ignores the sun
Shaviv also told the members of the German Parliament that the IPCC refuses to acknowledge the sun’s powerful role on driving climate and sea level rise rate. “The sun has contributed to more than half the warming.”
At the 3:40 mark Shaviv states that CO2 climate sensitivity is in fact only 1 – 1.5°C for a doubling of CO2, far less than the figure suggested by the PIK’s Levermann.
Models are faulty
Levermann then bluntly responded (5:05) with an insult, calling Shaviv’s non-alarmist claims “nonsense”.
But Shaviv fired back (6:10), reminding that there’s much scientific literature supporting the sun is a major driver and that the IPCC climate models are faulty and lopsided.
At the 7-minute mark Levermann claims the global temperature rose 0.2°C over the past 2 decades “in just a short” time, but not mentioning the natural oceanic El Nino event being at play. He then claimed they had already refuted all the points made by skeptics.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




From 15.0°C in 1850 to 14.8 today?
An interesting moment came at the 8-minute mark when one Parliamentarian asked Levermann which pre-industrial reference temperature the IPCC was working with. Parliamentarian Dr. Kraft asked Levermann what exactly was the global temperature before industrialization some 150 years ago. According to Levermann, it was “in the area of 15°C”, thus implying today’s global temperature is over 16°C. At this point Parliamentarian Hilse (8:40) noted that “the WMO, NASA and the NOAA gave 14.8°C as the global mean temperature in 2016”. According to Parliamentarian Hilse:
So, Herr Levermann, if what you say is right, then it means the temperature has fallen 0.2°C.”
Levermann then told the Parliamentarians that the fact that CO2 causes warming was as sure as gravity making objects fall, and called everything said by Shaviv “all shit” (9:30).
CO2 sensitivity rapidly declining
At the 9:50 mark Levermann clarifies that a doubling of CO2 itself leads to only 1.1°C of warming, but that the added warming will result from the water vapor feedback. He insists there is little uncertainty here. Yet EIKE points out at the 10:35 mark that the IPCC range in fact contains a high degree of uncertainty: 1.5° C to 4.5°C and that there is nothing certain about the science at all.
Recently scientists have been walking back CO2’s warming effect, EIKE shows:

EIKE presents the above chart to show how leading scientists have been ratcheting down their estimates of CO2 climate sensitivity over the years, which today is well below Levermann’s claims of 3.0°C for a doubling. Image cropped at 13:12.
Strangely at the 11:15 mark, the PIK scientist claims that the CO2 molecule is V-shaped. Yet, it is known that it is a straight molecule (11:50).
Shaviv: “No proof that large CO2 changes lead to large temperature changes”
In the end Shaviv disputes Levermann’s claim that the science is “rock solid”, noting that the models neglect factors such as clouds and that there are a number of studies showing that CO2’s impact on temperature is far more modest.
Shaviv summarizes:
There’s no proof that large changes in CO2 would lead to large temperature changes.”
Overall, EIKE called the debate before the Parliamentary Committee a “debacle for the climate alarmists”.
Share this...FacebookTwitter "
"What makes Pope Francis and his 183-page encyclical so radical isn’t just his call to urgently tackle climate change. It’s the fact he openly and unashamedly goes against the grain of dominant social, economic and environment policies. While the Argentina-born pope is a very humble person whose vision is of a “poor church for the poor”, he seems increasingly determined to play a central role on the world stage. Untainted by the realities of government and the greed of big business, he is perhaps the only major figure who can legitimately confront the world’s economic and political elites in the way he has. However his radical message potentially puts him on a confrontation course with global powerbrokers and leaders of national governments, international institutions and multinational corporations. The backlash has begun even before the encyclical has been officially published. US presidential candidate Jeb Bush, a Catholic, feels the pope should stay out of the climate debate, joining other Republicans, fossil fuel lobbyists and climate denier think-tanks in seeking to discredit Pope Francis’s intervention. There are several meanings of the word “radical” that can be applied to the Pope and in particular his forthcoming encyclical. First, radical can be understood as going back to the roots (from Latin radix, root). The majority of Catholics live in the Global South; in Latin America and sub-Saharan Africa. Francis is the first pope from the Global South, and naming himself in honour of Saint Francis of Assisi, “a man of poverty and peace who loved nature and animals”, signalled to the world a commitment to going back to the roots of human existence. The pope knows the plight of the majority world. Before he became Archbishop of Buenos Aires, he was a priest in the vast, poor neighbourhoods, the villas miserias or slums, of Argentina’s capital. Improving the lives of slum dwellers and addressing climate change is, for Pope Francis, one and the same thing. Both require tackling the structural, root causes of inequality, injustice, poverty and environmental degradation. For example, his encyclical says:  Even as the quality of available water is constantly diminishing, in some places there is a growing tendency, despite its scarcity, to privatize this resource, turning it into a commodity subject to the laws of the market. Yet access to safe drink- able water is a basic and universal human right, since it is essential to human survival and, as such, is a condition for the exercise of other human rights. (p. 23) This stands in stark contrast to, for example, Peter Brabeck-Letmathe, the chairman of Nestlé, the world’s largest food and bottled water company, who thinks water is a normal commodity with a market value, and not a human right. Nestlé is far from unusual. Its stance is backed up by the official water privatisation policies  of the World Bank, IMF and other international institutions. In fact, the encyclical is a radical – for a pope and international leader, unprecedented – attack on the logic of the market and consumerism, which has been expanded into all spheres of life. The document states: Since the market tends to promote extreme consumerism in an effort to sell its products, people can easily get caught up in a whirlwind of needless buying and spending. Compulsive consumerism … leads people to believe that they are free as long as they have the supposed freedom to consume. But those really free are the minority who wield economic and financial power. (p. 149-150) The pope rejects market fundamentalism, instead arguing that “the market alone does not ensure human development and social inclusion.” In the same way, he warns us of the brave new world of carbon markets such as the EU Emissions Trading System  and the UN’s Clean Development Mechanism, which have been created to reduce the world’s carbon emissions. The encyclical states:  The strategy of buying and selling “carbon credits” can lead to a new form of speculation which would not help reduce the emission of polluting gases worldwide. This system seems to provide a quick and easy solution under the guise of a certain commitment to the environment, but in no way does it allow for the radical change which present circumstances require. Rather, it may simply become a ploy which permits maintaining the excessive consumption of some countries and sectors. (p. 126) The pope’s right. The same criticisms of carbon markets have been made by myself and others. Pope Francis has already angered conservative Catholics in the US by clearly stating that: Climate change is a global problem with grave implications: environmental, social, economic, political and for the distribution of goods. It represents one of the principal challenges facing humanity in our day. (p. 20) While the pope is not a politician – or maybe precisely because he is not one – he commands high moral and ethical authority that goes beyond traditional partisan lines. His encyclical speaks truth to power, and he might be the only person with both the clout and the desire to meaningfully deliver a message like this: Many of those who possess more resources and economic or political power seem mostly to be concerned with masking the problems or concealing their symptoms, simply making efforts to reduce some of the negative impacts of climate change. However, many of these symptoms indicate that such effects will continue to worsen if we continue with current models of production and consumption. There is an urgent need to develop policies so that, in the next few years, the emission of carbon dioxide and other highly polluting gases can be drastically reduced, for example, substituting for fossil fuels and developing sources of renewable energy. (p. 21) The bosses of Shell, ExxonMobil and other fossil fuel companies will not like this message, as it threatens their fundamental business model, and it also stands in contrast to the underwhelming ambitions of the G7 leaders who recently pledged to phase out fossil fuels only by 2100. The time for bold, radical action on the environment as well as poverty eradication has come. This seems to be Pope Francis’ message: “The same mindset which stands in the way of making radical decisions to reverse the trend of global warming also stands in the way of achieving the goal of eliminating poverty.” (p. 128) We need to think beyond the current, taken-for-granted logic that believes only markets and consumerism can solve the world’s social and environmental problems. The pope himself believes the situation is so grave that only a new, “true world political authority” will be able to address these problems.  This article was updated on 18 June to include quotes from the final encyclical rather than the earlier draft leaked to L'Espresso magazine."
"
Share this...FacebookTwitter
Russian Arctic in 1920-1940 was warmer than today
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P. Gosselin)
The topic today is the temperature trend in the Arctic. Of special interest are the hard facts. At Climate4You we find the satellite measured temperature development (UAH) of the Arctic:

 Figure 1: Temperature chart of the Arctic over the past 40 years (satellite measurement). Data: UAH. Chart: Climate4You
Arctic temperatures today “similar” to 1980
We do see a warming over the past 4 decades. Since the El Nino-induced peak of 2016, the temperature has fallen gradually. The coldest temperatures were recorded at the end of the 1980s and early 1990s.
At around 1980 similar temperatures as those of today were measured. Unfortunately there is no satellite data for the time before 1979, and so not even a full 60-year ocean cycle is covered, and thus this makes it really difficult to assign warming to man or to natural causes over the recent decades.
Russian Arctic just as warm in the 1930s as today!
But of course there were weather stations before 1979, and these showed a warming phase in the Arctic already in the 1930s and 1940s, a time when it was just as warm as it is today. Example: Opel et al. 2009 reconstructed the temperature history in the Russian Arctic for the last 100 years using ice cores. The warm maximum occurred in the 1930s and not today:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




115 year ice-core data from Akademii Nauk ice cap, Severnaya Zemlya: high-resolution record of Eurasian Arctic climate change
From 1999 to 2001 a 724 m deep ice core was drilled on Akademii Nauk ice cap, Severnaya Zemlya, to gain high-resolution proxy data from the central Russian Arctic. Despite strong summertime meltwater percolation, this ice core provides valuable information on the regional climate and environmental history. We present data of stable water isotopes, melt-layer content and major ions from the uppermost 57 m of this core, covering the period 1883–1998. Dating was achieved by counting seasonal isotopic cycles and using reference horizons. Multi-annual δ18O values reflect Eurasian sub-Arctic and Arctic surface air-temperature variations. We found strong correlations to instrumental temperature data from some stations (e.g. r = 0.62 for Vardø, northern Norway). The δ18O values show pronounced 20th-century temperature changes, with a strong rise about 1920 and the absolute temperature maximum in the 1930s. A recent decrease in the deuterium-excess time series indicates an increasing role of the Kara Sea as a regional moisture source. From the multi-annual ion variations we deduced decreasing sea-salt aerosol trends in the 20th century, as reflected by sodium and chloride, whereas sulphate and nitrate are strongly affected by anthropogenic pollution.”

Figure 2: Temperature chart Severnaya Zemlya (Russian Arctic) over the past 130 years. Upper peaks = warm. Source: Opel et al. 2009
A part of the warming by the way, has to do with measures that keep the air clean in Europe. The anthropogenic sulfate particle kept the Arctic cool for many years, so reports that University of Stockholm (via Science Daily). Should we get back to being dirty for reasons of climate change?

European clean air policies unmask Arctic warming by greenhouse gases
[…] The drastic cut in sulfate particle emissions in Europe partly explains the amplified Arctic warming since the 1980s, shows a new study published in Nature Geoscience. The team, which consists of scientists from Stockholm University and the Norwegian Meteorological Institute, say that their surprising finding highlights an even more urgent need for reducing greenhouse gas emissions to mitigate Arctic climate change. Human activities, such as industrial production, transport, power generation, and wood burning emit large amounts of tiny pollutant particles containing, for example, soot and sulfate, into the atmosphere. High airborne amounts of these particles, also known as aerosol particles, cause about 400,000 premature deaths every year in Europe and can be transported over long distances. Aerosol particles have different sizes, as well as chemical and physical properties, all of which determine their climate effects.

“Soot particles absorb solar radiation and warm the climate, in a similar way as greenhouse gases, such as carbon dioxide, do. Sulfate particles, on the other hand, reflect solar radiation and act as seeds for cloud droplet formation, cooling the climate as a result,” says Juan Acosta Navarro, PhD student at the Department of Environmental Science and Analytical Chemistry (ACES) and the Bolin Center for Climate Research, Stockholm University, and co-author of the study. He continues: “The overall effect of aerosol particles of human origin on climate has been a cooling one during the last century, which has partially masked the warming caused by the increase in greenhouse gas emissions.” […]
J. C. Acosta Navarro, V. Varma, I. Riipinen, Ø. Seland, A. Kirkevåg, H. Struthers, T. Iversen, H.-C. Hansson, A. M. L. Ekman. Amplification of Arctic warming by past air pollution reductions in Europe. Nature Geoscience, 2016; DOI: 10.1038/ngeo2673“

But also later alterations to the measurement data make the Arctic look warmer today than it actually is (see here and here). A nice summary of climate change in the Arctic can be found at Judith Curry’s site.

Share this...FacebookTwitter "
"The Victorian government has announced a two-year inquiry into the bushfire crisis, ahead of the mooted federal royal commission which has met resistance from some states. On Tuesday the Victorian premier, Daniel Andrews, announced the inspector-general of emergency management, Tony Pearce, will receive $2.55m for extra staff to review recent bushfires in the state, including in the Gippsland region and the dramatic evacuation of Mallacoota. The inquiry will report by mid 2020 on preparedness and firefighting efforts – ahead of the next fire season – with a second report on relief and recovery due in 2021. The intervention comes as Melbourne suffers from very poor to hazardous smoke conditions – at one point overnight reaching the worst air quality in the world. On Sunday Scott Morrison said that a national inquiry – most likely a royal commission – would be “necessary” to examine the bushfires and he intended to take a proposal to cabinet for endorsement in coming weeks after agreement with the states. The Western Australian government has dissented from the call for a royal commission. On Monday the WA emergency services minister Francis Logan said: “I would prefer – given the royal commissions that are under way at the moment and it takes a huge amount of time in doing royal commissions … I’d prefer personally to see a thorough investigation, not necessarily a royal commission into it.” The New South Wales premier, Gladys Berejiklian, has already announced that state will hold a separate inquiry. Andrews told reporters in Melbourne that Morrison was “still working through the type of inquiry he prefers” and a proposal was yet to go to cabinet. “It is unclear to me – and that’s not a criticism it just isn’t settled yet – whether this would be an inquiry into how the national effort can be as best coordinated as possible or whether it is an inquiry into the event more broadly,” he said. Andrews said he had told Morrison about Victoria’s plans and Morrison had given a commitment to consult on the terms and scope of a national inquiry. Andrews praised Pearce, who he said had the “experience, the understanding and the status in our emergency services system” to conduct the Victorian state inquiry. Later on Tuesday Morrison told reporters in Canberra that a national inquiry had never been intended to replace state inquiries and any suggestion they were in conflict was “false”. Morrison clarified that a national inquiry would examine the preparation and response to bushfires, the scope of federal power including when it can initiate defence force action rather than simply respond to state requests, and “resilience and adaptation” to climate change. Bernard Teague, a retired Victorian supreme court judge who conducted the Black Saturday royal commission, said a national royal commission would be ideal if the federal and state governments could agree about the terms of reference and who would conduct it. “If that’s not possible … then it may be scaled down to have appropriate inquiries in the relevant jurisdictions,” he told Radio National. Teague said the hurdles to setting up a royal commission in the right way were “substantial” and it was therefore “not particularly likely”. Teague said it is clear climate change has a major impact on bushfires but an inquiry could consider “taking more appropriate action into the future” to combat it. The business community will meet in Canberra on Tuesday and is expected to push for the extension of recovery grants to those directly affected by bushfires in Victoria as well as government support for “exceptional circumstances” faced by businesses indirectly affected by the national crisis, to be paid for from a $2bn federal recovery fund. The Victorian emergency services minister, Lisa Neville, announced further measures to assist in the cleanup in the state, where 353 residential properties have been damaged by the fires, including the suspension of the landfill levy."
"
Share this...FacebookTwitterDaniel Wetzel at German national daily Die Welt here recently commented that limiting the warming to 1.5°C warming is utopian. That’s of course, assuming the man-made global warming theory is correct to begin with.
According Wetzel, time theoretically ran out long ago.
Wetzel wrote that despite all the controversy surrounding the IPCC report, one thing is clear: “It’s going to take trillions for the 1.5°C target . And without many veggie days, it’s not going to happen.”
The green urgency for a state of emergency
Even before the report was released to the public, environmentalists and climate activists had already made up their minds that humanity had one last chance to avert calamity. Profound wide-scale action would need to be taken. Green politicians and environmental activists are now demanding a declaration of a state of emergency, it seems. Theoretically however, the window in fact closed weeks ago.
Misrepresenting the report

For Germany, green-colored or shaded politicians and activists said the report confirms that Germany must exit coal power by 2025 at the latest. But Wetzel comments that many special interests are framing the report as something that it really isn’t:


Every lobbyist is taking out of the UN climate report what what appeals to them, and leave everything else aside.”
Clock stuck at 5 to 12, in fact ran out weeks ago


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Wetzel comments that the urgent claims made by the Greens that there is still a small window of opportunity is “surprising” because according to the Mercator Research Institute’s (MCC) “CO2 countdown clock“, time already ran out 30 days ago even for the mid range scenarios, meaning there wasn’t supposed to any more CO2 emissions at all. But Wetzel writes:
In the latest climate report, suddenly there’s 300 gigatonnes more. […] Indeed on in this manner does the world gain 7.5 years time for CO2 reductions, says Oliver Geden, a lead author for the next UN report.”
He cites Chapter C1.4, footnote no. 14 of the report.
A TRILLION dollars a year
According to Wetzel, the UN report also notes that between 900 billion and 1.8 trillion dollars would need to be invested every year from 2015 – 2050 to revamp the global energy system. This is a figure that even the richest nations are going run from.
Currently Germany’s Energiewende alone is costing Germany 34 billion euros annually. Worse, there’s been no CO2 reduction in Germany in close to a decade. That’s some 300 billion euros for zero result. Wetzel adds that Germany has already reached its threshold of financial pain as electricity prices have soared to among the highest worldwide.
Wetzel points out severe “limitations in nutrition are needed”
The Die Welt economics journalist also writes that the German Greens forget to tell the public that it would be necessary to “commit some 8 million square kilometers of agricultural area to growing energy plants in order to reach the 1.5°C warming target.”
Moreover reaching the target would also require going much more without meat, whose production is energy and CO2 intensive. Overall, Wetzel writes, reaching the 1.5°C target “collides with the fight against poverty and hunger” and , if the theory is true, there’s no chance of reaching the 1.5°C target.
 



Share this...FacebookTwitter "
nan
"A large dog romps across a blue and white canvas, leaving a trail of brown paw prints. “Oh well,” shrugs Vivian Suter. “They’re part of the work now. I don’t think anyone will mind.” I realise Bonzo – one of three Alsatian crossbreeds that shadow the artist wherever she goes in her Guatemalan home – has just put the finishing touches to an artwork that will shortly be on public display thousands of miles away. The painting lies on the floor of her “laager” – a storage barn open to the elements, apart from a metre-high stone wall, which you have to clamber over with the help of a rickety chair. The wall is to guard against mudslides, she explains, gesturing at a ghostly tideline that rings the interior. Most of her works hang from a rack; the piles on the floor are for three upcoming exhibitions in Berlin, London and Madrid. Having just opened a 53-piece installation at Tate Liverpool, Suter is halfway through choosing the 200 works that will feature in her Camden Arts Centre exhibition, which opens next week.  It is the latest stage in an extraordinary renaissance for a 70-year-old Swiss-Argentinian artist who all but disappeared in her 30s. Suter was close to having to sell off part of her home when a curator tracked her down for an update of a group show in which she had featured in 1981. What he found was an artist perfectly attuned to an era of looming ecological crisis, with three decades of work in her backyard. Strapped for cash and far from specialist suppliers, she had learned to work with house paint and fish glue on cheap local fabric, which she would then leave outside for the weather to finish off. She stoops to stir a twig that has fallen into a tin brimming with scummy green water and says: “This is a good colour. I’ll definitely find a use for it.” The title of her Camden show, Tintin’s Sofa, pays tribute to another of the dogs with which she and her 97-year-old artist mother Elisabeth Wild share their hideaway on the slopes of a volcano, a bone-rattling three-hour drive from Guatemala City. Though Suter seldom ventures out, leaving shopping to her two assistants, she is well-known in the small lakeside town of Panajachel. “Just get a tuk-tuk and ask for the black door,” I am told. Walking through that black door, set into a high wall on the town’s outskirts, is like stepping through CS Lewis’s wardrobe into a timeless world that is both beautiful and menacing. Her hideaway, covering several acres of an old coffee plantation, is a tumble of rock and vegetation. Close to the small bungalow in which Suter has lived for more than three decades, lies a boulder that was washed down the mountain in the last rainstorm, and has yet to be colonised by the strangler figs whose roots lattice the ground. It was one such tree that drew her to this site back in the early 1980s when – recovering from a divorce and wearied by life in her home city of Basel – she took a road trip across Central America. On reaching Lake Atitlán in Guatemala, she decided to stay, entranced by its fierce beauty and remoteness. “Nobody told me there was a war going on,” she says. She fell in love, remarried (again briefly) and gave birth to a son, Pancho, now 34, who lives on the other side of the lake but has recently turned one of the sheds on the slopes of his mother’s garden into a recording studio. Suter is not sure if he will join us for lunch because a Nicaraguan rapper is about to turn up. Pancho has adopted his grandmother’s surname, and she in turn snaps up his cast-off clothes, greeting us for lunch in a badass graffiti T-shirt. Wild, too, has been enjoying a renaissance. A solo show in Dubai in 2019 will next year be followed by a retrospective at Vienna’s Museum of Modern Art. The reason for coming all this way to meet them is that, while Wild is confined to a wheelchair and no longer well enough to travel, the life and work of the two artists is so intertwined it would be hard to understand one without the other. It’s a pilgrimage that has already been made by the artist Rosalind Nashashibi, whose film Vivian’s Garden was part of her shortlisted 2017 Turner prize entry. Wild was born in Vienna in 1922 to a Jewish father and a Catholic mother, who fled Nazism, ending up in Argentina. While working there as textile designer, she met and married Suter’s factory owner father, before fleeing back to Europe to escape the dictatorship of Juan Perón. Settling in Basel with their 12-year-old daughter, they set up a furniture shop where Wild turned her skills to cabinet painting. “I would go to flea markets and find old furniture and restore it,” she says, leafing through an album of exquisitely painted work.  Suter recovered from all this uprooting to secure a place at art school in Basel at just 17. Within three years, she had landed her first group show. She made her solo debut a year later. When did Wild first know her daughter was an artist? “Always,” she says. The closeness between the two women is evident as they chat, gently challenging each other’s versions of history in a mixture of German, English and Spanish. They live yards apart in separate bungalows, with their shared artistic heritage covering the walls of both, from a couple of intricate botanical watercolours by Wild’s grandmother to a scattering of large abstracts painted by Pancho as a child. Mother and daughter have exhibited several times together, most recently in Los Angeles, where a critic’s remark that their work was “compositionally diametric yet chromatically in sync” captured the creative tension between them. While Suter works in a bold freestyle, often very quickly, in collaboration with whatever the weather throws at her, Wild sits at a desk snipping and glueing, composing a small geometric collage every day from architecture and lifestyle magazines. While Suter leaves all her work undated and unsigned, Wild painstakingly signs and logs every piece for storage in a painted chest which is the only piece of her furniture that made the journey to Guatemala. When I ask Wild how she would describe her daughter’s work, there is a long silence. “Sometimes,” cuts in Suter, “I showed my mother my things and I couldn’t stand her comments so I stopped showing her.” She admits that she too can be judgmental: “I look at my mother’s collages and sometimes, when she’s not there, I quickly move something. But she always notices. We have a relationship, and sometimes individually, without speaking about it, we make similar things. The spirit is the same.” Suter’s response to a question about the impact of her mother’s criticism is to lead me up a perilous flight of stone steps laid into the hillside to a studio that is most definitely not wheelchair-friendly. She does most of her work outside it, squeezed into a narrow gap between its side wall and the encroaching forest, “because I really like painting while squished”. Bare white canvases lean against the bright red wall waiting for her to start work on her next big project, a commission from Art on the Underground for London’s Stratford station. For such big works this seems less than ideal, and the peril of her perch is greatly increased by the mess of old paint cans that litter the ground. For all the nimbleness with which she flits around – a slight, otherworldly figure with a drift of auburn hair – there is an anxiety in her relationship with her surroundings. She has fortressed her garden with towering spears of bamboo. One wall of her studio has a built-in cupboard, the door of which stands ajar. “There’s probably some good paint in there but I haven’t looked for years.” Why? “Because it’s probably got scary things in it.” Like what? “Like snakes maybe.” She knows from bitter experience how dangerous this environment can be, and her respect for it has become the keystone of her work. In 2005, a hurricane sent a mudslide hurtling over everything she had created. “At the time I saw it as just a catastrophe,” she says, “but as they started drying, the colours began to come out, and I realised that I had to start working with nature and not against it. “Then I started leaving them outside in the rain so that they could get splashed. It was a turning-point which transformed everything. It made all I do into one work – and that’s how I see it now, not as single pieces but as a whole.” One of the ruined paintings hangs above her bed. It’s a rich burgundy that looks simultaneously cosy and sacramental. In a gesture, perhaps, to her truce with nature, she has hung it upside down so that its top 18 inches, rather than its bottom, is caked with mud. Does she ever tire of the isolation? “Why would I?” she says. “My best friend is here. The question is what will happen when she goes.” Towards the end of lunch, when Suter is out of earshot, I ask Wild again what she makes of her daughter’s work. This time there’s no hesitation. She leans back in her chair with a smile and says: “It’s free – in a good way.” Vivian Suter’s Nisyros (Vivian’s Bed) is at Tate Liverpool until 15 March; Tintin’s Sofa is Camden Arts Centre, London, 16 January-5 April. She is part of En Plein Air at the High Line, New York, until March. "
"The birth of industrial civilisation in the 18th century meant humans could extract, transport, and process ever more of nature’s bounty, permanently affecting natural cycles. As we navigate the Anthropocene, the much-debated geological epoch that recognises the geological and ecological impact of the industrial age, there are several environmental disasters and crimes that should be taught in schools to educate young people about the human impact on our shared planet. In choosing a list of five, I have confined my choices to the 1960s and beyond as popular environmental alarmism was born in the decade of cultural revolution that questioned the conventional wisdom of Western civilisation.  This was the first major oil spill of the post-Second World War era. When the SS Torrey Canyon was shipwrecked on a reef off the coast of Cornwall, England, spilling 875,000 barrels of crude oil into the sea, a national event sparked an international debate about the impact of transporting oil, the size of tankers (which had grown dramatically since 1945), and the use of untested chemicals to break down the spilled oil.  Millions of litres of the detergent BP 1002 were sprayed into the sea, but it failed to break down the oil and caused more long term damage to birds and the marine environment.  Torrey Canyon was one of the first televised environmental disasters. Images broadcast around the world helped fuel the fledgling environmental movement and highlighted the vulnerability of marine ecosystems, the role of chemicals, and the dangers of a new global economy based on consumerism and fossil fuels. One of the most significant environmental disasters in American history happened in the city of Niagara Falls, upstate New York. Between 1942 and 1953 the Hooker Chemical Company used the city’s “Love Canal” to dump 21,000 tonnes of toxic chemicals, including 12 carcinogens. It then sold the land to the Niagara Falls School Board for US$1. By 1978, the chemical pollution had caused residents surrounding Love Canal to suffer from birth defects, miscarriages and cancer rates far in excess of national averages.  A popular resident’s protest, driven by local mother-turned-activist Lois Gibbs, forced the American government to act and prompted a national debate about chemical waste disposal sites. President Jimmy Carter declared a state of emergency, 700 families were eventually moved away from the site, and the Environment Protection Agency’s Superfund was established in 1980 to clear up chemical waste sites, oil spills, and natural disasters.  One community’s suffering and protest provided the legal framework to challenge polluters and command the American state to fund the clean up of environmental disasters. Operation Ranch Hand was part of an American herbicidal warfare programme during the Vietnam War, which sought to remove the strategic cover the forest canopy provided for the Viet Cong. Three US administrations – the governments of Lyndon Johnson, John F. Kennedy, and Richard Nixon – sprayed 72m litres of defoliants and herbicides, primarily “Agent Orange” to kill Vietnam’s forests and poison its rice paddies.  The US was condemned internationally and accused of breaking the Geneva Convention which banned the uses of chemical weapons on humans. Though it defended itself by stating that humans were not directly targeted, America’s actions were described as “ecocide” by Swedish prime minister Olof Palme at the UN’s first environment summit in 1972. Operation Ranch Hand should be taught in schools as it initiated discussions about the targeting of the natural environment in warfare, ecocide as the fifth “crime against the peace”, and whether nature should be bestowed with its own legal rights. In March 2011, a strong earthquake off the coast of Japan resulted in the largest nuclear disaster since Chernobyl in 1986. A tsunami unleashed by the quake overwhelmed the Fukushima nuclear plant’s safety systems, disabling the emergency generators and preventing the reactors from being cooled. As a result, reactors one, two, and three suffered meltdowns.  Despite no deaths being directly attributed to the nuclear meltdown, unlike at Chernobyl, it is estimated that the radiation from the many dump sites will last for 300 years. Teaching about the Fukushima disaster in schools encourages children to consider the fuels of the future as we come to legislate for the roles of solar, tidal, wind, and non-renewable energies. With a growing global population and energy demands, how we produce energy and maintain the health of the natural world is a central question for the 21st century. Palm oil is derived from the palm fruit which originates in West Africa but is now largely cultivated in Malaysia and Indonesia. It is found in cosmetics, cleaning products, shampoos and all kinds of food from frozen pizzas to peanut butter.  Yet palm oil is also a leading cause of deforestation and biodiversity loss. The World Wildlife Fund estimates that 300 football pitches are deforested every hour to make way for plantations, while species such as the orangutan are being driven towards extinction as their habitats disappear.  It is important to teach about the impact of palm oil production because it forces us to confront the very foundations of our relationship with nature. It is a case study of an unsustainable economic system that elevates short term economic gain at an ecological cost. A discussion about palm oil is a discussion about the future of life on this planet."
"
Share this...FacebookTwitterAccording to a new paper (Oliver and Terry, 2019) published in Palaeogeography, Palaeoclimatology, Palaeoecology, oyster remains have been found encrusted in rock 2.5 to 3.8 meters above the present mean sea level.  This fossilized evidence dates to ~6000 to years ago, a period when the Earth’s surface temperatures were 4-6°C warmer than they are today.

Image(s) Source: Oliver and Terry, 2019
The evidence provided by Oliver and Terry (2019) will be added the to growing list of more than 80 scientific papers indicating sea levels from locations throughout the world were meters higher than they are today just a few thousand years ago.
80+ Papers: Mid-Holocene Sea Levels
Were Multiple Meters Higher Than Today

Oliver and Terry, 2019
Relative sea-level highstands in Thailand since the
Mid-Holocene based on 14C rock oyster chronology
• “~6000 cal yr B.P. old oysters can be found from between 3.8 ± 0.1 m to 2.5 ± 0.1 m above present day mean sea level. … Dead (fossil) oysters were collected from between 1 and 3 m above the centre of the live oyster band in a more sheltered cleft inside the notch. The oldest sample with an age of 5270–4950 cal yr B.P. was collected at an elevation of 3.01 ± 0.1 m above the apex of the notch. The ages decrease with elevation down to 920–710 cal yr B.P. at 1.03 m.”
• “In all the sites, the 14C age of the dead oysters inside the notches increases with increasing elevation above present day MSL. Clearly, relative sea level was 2 to 3 m higher than present between 6000 and 3000 B.P. and has steadily fallen since.” 
• “There was a progressive warming from ~13,500 years ago to a peak at 6500 ± 200 years ago followed by a cooling of −2.6 °C to the present day.” 
• “Generally, there is a ~1 m wide live oyster band (with modern 14C ages) in the apex of the sea notch that corresponds to the present day MSL. 14C ages of dead oysters are systematically older higher up the sea notch and reach a maximum 14C cal yr B.P. age of 6513–6390 cal yr B.P. at an elevation of 2.5 ± 0.1 m above present day MSL in an exposed site at West Railay Beach. Consequently, relative sea levels must have been higher in the mid Holocene than they are now.”
• “[A]t a more sheltered site inside a bay on Ko Pha Nak, the highest preserved oyster shell is at 3.2 ± 0.1 m above MSL and has a younger 14C calibrated age of 5845–5605 cal yr B.P. Furthermore, oysters from 3.8 ± 0.1 m above present day MSL, encrusted on a stalactite in a cave at West Railay Beach has a 14C calibrated age of 6176–6041 cal yr B.P.”


Image(s) Source: Oliver and Terry, 2019
Share this...FacebookTwitter "
"The UK and Ireland have been experiencing a prolonged hot and dry spell since June, with the first half of summer being the UK’s driest on record. The lack of rainfall has led to hosepipe bans in Northern Ireland and the north-west of England, while the weather is also playing havoc with farming. A shortage of lettuce and broccoli is expected in the next few months, and grass isn’t growing fast enough to feed Ireland’s sheep and cattle through the winter. The hot and dry weather is associated with a high pressure weather system situated over the UK. The high pressure means that the storms the UK occasionally gets at this time of year are being steered much further northwards towards Iceland. While the UK and Ireland have been wilting in the sunshine, Reykjavík has recorded its wettest (May) and cloudiest (June) months on record.  This high pressure system is unusually persistent and has been building up over Europe throughout spring and early summer. In April it was over Central Europe and in May shifted northwards towards Scandinavia. Subsequently it was the hottest April and May in Germany and the hottest May in Denmark since observations began in the 1880s. But why has it been so dry and warm? Here is a shortlist of candidates that could be playing a role – or not – in this unusual summer: Let’s start with the obvious: temperatures are increasing globally due to the burning of fossil fuels, which is increasing concentrations of atmospheric carbon dioxide. The global rise in temperatures means that heatwaves are occurring against a warmer background and so are more likely to become extreme. The past few years have seen some record-breaking temperatures in Europe, for example the 2015 heatwave and the 2017 “Lucifer” heatwave in Central Europe. Unusually warm summer temperatures have also been recorded elsewhere, for example in Canada and Japan, and climate change is very likely to have played a role in the UK and Ireland as well. Temperatures over the North Atlantic Ocean can play a role in setting the position of a narrow band of strong wind in the upper atmosphere known as the jet stream. The position of the jet stream in turn has a profound impact on the weather experienced in the UK and Ireland.  The jet stream can affect weather in Europe. This summer, ocean temperatures have been relatively warm between the Gulf of Mexico and North Africa while temperatures south of Greenland have been unusually cold. This is thought to have pushed the jet stream further northwards, sending bad weather towards Iceland while allowing areas of high pressure to linger over Europe. Every few years, ocean temperatures in the tropical Pacific swing between being relatively warm (known as El Niño) and cool (La Niña). Since October 2017 the area has been in a La Niña phase. This is sometimes associated with cold winters in north-western Europe (for example the winter of 2010-11 and the recent “Beast from the East” cold spell in March 2018). However, La Niña cannot really be blamed here – this year’s event had started to weaken around April and had almost gone by June when the UK’s current dry spell began.  The above factors influence the type of weather the UK and Ireland will get but, within these broad possibilities, good or bad luck also plays a role. This is especially the case for very unusual weather such as the current hot and dry spell. This summer is no different and the hot and dry weather is partly due a combination of Atlantic temperatures, climate change and annual weather patters. Should weather patterns continue as they are then 2018 may turn out to be as hot and dry as the extreme summer of 1976. This raises the question of how predictable it is. The science of forecasting the weather a few months ahead is still in its infancy, and such “seasonal forecasts” are subject to lots of uncertainty. However, the UK Met Office did predict back in early June that there was an increased probability of a drier and warmer summer. While meteorologists are not yet able to predict prolonged hot and dry spells months in advance there were useful indicators of an increased chance of extreme weather. Advancing the science of seasonal forecasting requires a deeper understanding of the different factors than can influence the weather, from ocean temperatures and jet streams through to changes in Arctic sea ice. As part of the UK Drought and Water Scarcity programme research institutions in the UK are being funded to further our knowledge of these influences and to better understand how the UK can respond to and mitigate the impacts of prolonged dry weather."
"The most powerful leaders in the West used the G7 summit in Germany to make a big statement on the environment. Their stated goal is to cut carbon emissions by 40% to 70% by 2050 and then end all fossil-fuel use by 2100. They announced a US$100bn (£65bn) fund by 2020 comprising public and private money to help smooth the transition. My response to David Cameron, Angela Merkel and the rest is pretty simple: good luck with that.  When people talk about decarbonisation, they tend to make the mistake of thinking about energy only in terms of electricity. If you ask how to wean us from fossil fuels, they will say build more solar power, more wind farms and so forth. There are several problems with this. We are already struggling with capacity on the grid and have a huge task to add as much renewable energy as it can cope with. To cover the extra requirements to make heat and domestic transport electric, we would need five times more. I don’t know anyone who thinks this is remotely realistic.  Because most forms of renewable energy only work when the power source is available, be it wind, sun or whatever, we will need large amounts of storage capability to allow them to replace electricity powered by fossil fuels. And while it’s easy to see how you can store kilowatts and megawatts of green power in the batteries of the future, getting up to gigawatts is another matter. The huge engineering requirement makes it almost impossible to get the costs to a point where this is viable.  Electricity is also the least of the big drains on energy. The big challenges are transport fuels, especially for long-distance haulage and trans-ocean shipping. We really don’t have any smart ideas for replacing diesel for these yet, and it’s difficult to see where they will come from. The Royal Academy of Engineering did a study in 2013 looking at the options for low-carbon fuelling of shipping. The best it could come up with was LNG (liquefied natural gas).  You can conceive of running large numbers of domestic cars on green electricity by charging them on the grid. But the idea that anybody is going to be able to produce a battery big enough to store the electricity to power a passenger aircraft or a major container ship is laughable.  Energy consumption by sector Energy consumption that is renewable Then there is hydrogen. It’s got fantastic potential. It has a few cost issues at the moment, but they can probably be sorted out over the next few decades. It may well emerge as a viable option for domestic transport, but it has nothing to offer heavy haulage either. To have enough hydrogen to power a trans-ocean ship or plane would require massive amounts of compression that would use so much energy that it would not be worthwhile. It appears beyond the limits of physics to overcome this.  So far I have only talked about energy – yet we have built our societies around many other uses of fossil fuel that rarely get mentioned. Fertilisers is a good example. Most of the world’s food supply is based on fertilisers, and I don’t know of anybody who is suggesting that the largely urban population we will have by 2050 can be fed without using the amount of fertilisers we use at the minute, or that they can be produced without using fossil fuels.  Then there is steel. We are recycling more and more steel, but 50% of it is still primary production from virgin materials (and this is expected to continue). Steel is actually an alloy of iron and carbon, so it’s not just a question of the energy that we need to produce it. You can reduce the fossil fuels on the energy side by switching to an arc furnace powered by hydroelectricity, for instance, but where are you going to get the carbon for primary production? Your only alternative to fossil fuels is charcoal, which would entail mass deforestation across the world to get enough – and massive carbon emissions to make it from wood.  Society also depends on plastics. Where are you going to get plastics in sufficient quantities to meet demand without fossil fuels? The same applies to materials we need for renewable-energy essentials like lightweight carbon-fibre wind-turbine blades, and thin-film photovoltaics. Nobody has a serious alternative to this. Equally we could talk about pharmaceuticals, cement – the list goes on.  That’s not to say I don’t welcome the $100bn fund. It means more funding for research into renewable energy, which is definitely needed. But even on an 85-year timescale, it’s difficult to see what we can do about the barriers of physics. I wish I could simply endorse the climate change protesters and say it can all be done, but that would require a suspension of disbelief at the expense of scientific honesty.  That’s not to say we can’t make a difference in many ways. Geothermal energy is not on most people’s radars, but it has vast potential that’s not even close to being exploited. We can change the game in short-haul transport by switching to electric and hydrogen-powered cars.  There are various ways in which nuclear power can potentially be improved, for example by using thorium instead of uranium as the feedstock, or by getting more energy from nuclear waste. There is nuclear fusion too, if it ever succeeds. But nuclear is no good at responding to fluctuations in power demand – and neither are renewables – and it’s difficult to conceive of this changing.  I have no sentimental attachment to fossil fuels. I have had relatives who died in coal mines. But as an engineer, I have to admit when I am beaten. I can see a Gandhian future where everyone uses many fewer fossil fuels and lives in a much more spiritual way, and I would welcome it. But I don’t see any signs of that coming out of the G7. Realistically the only solution to our fossil-fuel dependency is an end to mass consumer culture, but that’s just not what the politicians are proposing. Instead we are just encouraging the developing countries to get addicted to the same consumer lifestyle as those in the West.  Probably where we are more realistically heading is towards a world in 2100 where we depend more heavily on coal. Unlike oil, it will still be available in large quantities. We will remove the majority of the carbon emissions by coupling carbon capture and storage technology to underground coal gasification.  The fact that the politicians are not telling us this is a sign of the triumph of the protesters. They have managed to change the argument from reducing carbon emissions to getting rid of fossil fuels, since nuclear is low-carbon and not something they approve of. So instead we get platitudes that are empty and unachievable. Until we can have an honest conversation about the future of our relationship with energy, there is no point in taking our leaders seriously."
"There’s a famous British nursery rhyme about how many magpies one sees in a day. It begins: “One for sorrow, two for joy …”  The whole verse is strangely ambiguous, the lines alternating between good and evil as if we cannot make up our minds about this familiar bird. The rhyme ends with 13 magpies: “… beware it’s the devil himself.”  However I’ve got a soft spot for them. Perhaps I’m influenced by my local football team, Newcastle United, being nicknamed the magpies on account of their black and white stripes. Although the team seems wholly unable to acquire anything silver or glittery, unlike its feathered namesakes.  Magpies are commonplace in my city. Adults fuss and clatter as they tweak their twig nests, gangs of “teenage” birds loiter on park benches, inquisitive individuals tug at TV aerials or pry through the backyards tracking the fate of smaller birds. They have flourished in the UK in the past few decades, and their population trebled between 1970 to 1990 and has stabilised since then. But such a gaudy and notorious species was bound to attract public ire, especially as their reputation has been fed by centuries of superstition. Magpies, wherever they live, haunt folklore. Sometimes they appear as a sinister omen, but equally often as a friend. In the UK, a lone magpie is considered especially ominous and it is commonplace to voice a respectful enquiry as to the health of its wife and children. Conversely in China and Korea magpies are seen as bringing good luck.  The magpies of Europe seem to have been caught up with the dark reputation of their blacker feathered relatives, the crows and ravens. Shakespeare flings them into the supernatural mix of Macbeth as “maggot-pies”, a grim name, but likely to be a corruption of older words, “mag” for chatter and “pie” for black and white.  Except that they are not black, but an iridescent deep green with flashes of slick petrol blue and purple. Their stubby wings and long tail fan into art deco-like rays, and the whole colour scheme has a 1920s and 30s style and glittery appeal. They stroll and swagger, peer and prod. Compare one in flight to artists’ impressions of proto-bird Archaeopteryx and there is a striking similarity. Many palaeontologists refer to the T. rex and Velociraptor as “non-avian dinosaurs”. However, if you watch a magpie at its most confident, on the hunt, you’ll see the link between these modern aviators and those ancient carnivores.  Their malevolent reputation is also associated with an eye for a glittery trinket, thieves who will steal to decorate their nests. Note the fecklessness of this: they aren’t even stealing to make a living, but purely for vanity. “Thieving magpie” is a common insult. But a study published last year in the journal Animal Cognition seems to discredit this behaviour. Researchers found no evidence magpies were attracted to shiny objects offered to them, indeed the birds shunned the gifts. Instead they had “neophobia”, the researchers claimed; the birds were afraid of the unfamiliar, wary of the baubles. However, once you discover that the items on offer were metal screws and aluminium foil you could understand why any self-respecting jewel thief would turn up their beak at tawdry items of DIY hardware.  It is the magpie’s misfortune to have been swept up in the culture wars around birds of prey. The decline of sparrows, starlings and other smaller garden birds in recent decades and the simultaneous rise of the magpie and other predators such as sparrowhawks have been linked by campaign groups such as Song Bird Survival, with calls for culls of raptors and crows to help maintain a natural balance.  Conservation groups such as the RSPB have repeatedly pointed out the lack of evidence of impacts and asked why such campaign groups are so closely allied to hunting and shooting organisations. A recent review of 42 studies showed magpies and crows have very little impact and were unlikely to limit bird populations.  The effort and expense of controlling their numbers was disproportionate to the limited gains, done more because crows and magpies are conspicuous, the easy scapegoats of legend."
nan
"If you know who Sean Hannity is, you probably know that he is no fan of the Green New Deal. The proposal has blanketed Fox News since it debuted in November 2018, with Hannity and fellow hosts on the network narrowing in a particular line of attack, summarized during a radio spot he did last year: “What they are proposing is so outrageously expensive and cost prohibitive even they acknowledge that if we confiscated all the billionaires’ wealth, it still wouldn’t be able to pay for this mess of theirs.” Along similar lines, Republicans circulated a bogus study from the industry-funded American Action Forum claiming a Green New Deal would cost $93tn, elevating the number into something of a meme among rightwing talking heads and politicians. Senate majority leader Mitch McConnell told his colleagues it would be more than enough to “buy every American a Ferrari”. Hannity and McConnell, along with most of the rest of the Republican party, have more recently been heaping praise onto Trump for assassinating Iranian Gen Qassem Suleimani. “This is a huge victory for American intelligence, a huge victory for our military, a huge victory for the state department, and a huge victory and total leadership by the president,” Hannity boasted after the killing. Without consulting Congress, the president kicked long-simmering US-Iran tensions up to a boil that now threatens to spill over into another full-blown war in the Middle East. His threats to bomb cultural sites throughout the country – in violation of international law – make that even more likely. So why aren’t Republicans asking how the government would pay for it?  A recent study from Brown University’s Watson Institute found that, since 2001, wars in Afghanistan, Syria and Pakistan have cost the US $6.4tn – $2tn more than all federal spending in 2018. The trouble with a prospective new war in Iran, of course, isn’t that it would cost too much money. It’s that it would put potentially millions of lives at risk, mostly to appease Donald Trump’s fragile ego, a coterie of neocons who’ve been edging toward it for years and a slew of defense contractors eager to cash in. Neither a Green New Deal nor another war would plummet the US into bankruptcy, a virtual impossibility barring earth-shattering changes to the make-up global economy. They probably wouldn’t even raise inflation. The disconnect between Republicans’ fiscal conservatism on climate and spendthrift war drums illustrates a basic fact about American politics: that our budgets are more than anything expressions of what it is the country chooses to value – not how much money we have in the bank. The only time costs become an issue is when it comes to programs that run counter to Republican policy priorities, whether by making sure that everyone has healthcare or taking on the urgent threat of the climate crisis, the potential real costs of which are virtually exponential. In office, Republicans have been prolific deficit spenders, from supposed small-government ideologue Ronald Reagan to George W Bush to Trump, who pushed through $2tn worth of tax cuts for the wealthy. Democrats all too often fall into the trap of worrying about the deficit, from the Clinton administration’s war on public programs to Nancy Pelosi’s seemingly religious commitment to enforcing so-called pay-as-you-go (“Paygo”) rules that would kneecap any progressive agenda. At the same time, the establishment Democrats urging fiscal prudence and (rightfully) calling Trump an illegitimate president have reliably voted to expand his military budget, arming him with $738bn for this year alone. At this point, nobody is expecting intellectual honesty from the Republican party. Democrats, though, shouldn’t play into their hands. It’s time to be as hawkish about taking on real threats as Republicans are about taking on fake ones, whatever the cost. Kate Aronoff is a writer based in New York"
nan
"The heat in the world’s oceans reached a new record level in 2019, showing “irrefutable and accelerating” heating of the planet. The world’s oceans are the clearest measure of the climate emergency because they absorb more than 90% of the heat trapped by the greenhouse gases emitted by fossil fuel burning, forest destruction and other human activities. The new analysis shows the past five years are the top five warmest years recorded in the ocean and the past 10 years are also the top 10 years on record. The amount of heat being added to the oceans is equivalent to every person on the planet running 100 microwave ovens all day and all night. Hotter oceans lead to more severe storms and disrupt the water cycle, meaning more floods, droughts and wildfires, as well as an inexorable rise in sea level. Higher temperatures are also harming life in the seas, with the number of marine heatwaves increasing sharply. The most common measure of global heating is the average surface air temperature, as this is where people live. But natural climate phenomena such as El Niño events mean this can be quite variable from year to year. “The oceans are really what tells you how fast the Earth is warming,” said Prof John Abraham at the University of St Thomas, in Minnesota, US, and one of the team behind the new analysis. “Using the oceans, we see a continued, uninterrupted and accelerating warming rate of planet Earth. This is dire news.” “We found that 2019 was not only the warmest year on record, it displayed the largest single-year increase of the entire decade, a sobering reminder that human-caused heating of our planet continues unabated,” said Prof Michael Mann, at Penn State University, US, and another team member. The analysis, published in the journal Advances In Atmospheric Sciences, uses ocean data from every available source. Most data is from the 3,800 free-drifting Argo floats dispersed across the oceans, but also from torpedo-like bathythermographs dropped from ships in the past. The results show heat increasing at an accelerating rate as greenhouse gases accumulate in the atmosphere. The rate from 1987 to 2019 is four and a half times faster than that from 1955 to 1986. The vast majority of oceans regions are showing an increase in thermal energy. This energy drives bigger storms and more extreme weather, said Abraham: “When the world and the oceans heat up, it changes the way rain falls and evaporates. There’s a general rule of thumb that drier areas are going to become drier and wetter areas are going to become wetter, and rainfall will happen in bigger downbursts.” Hotter oceans also expand and melt ice, causing sea levels to rise. The past 10 years also show the highest sea level measured in records dating back to 1900. Scientists expect about one metre of sea level rise by the end of the century, enough to displace 150 million people worldwide. Dan Smale, at the Marine Biological Association in the UK, and not part of the analysis team, said the methods used are state of the art and the data is the best available. “For me, the take-home message is that the heat content of the upper layers of the global ocean, particularly to 300 metre depth, is rapidly increasing, and will continue to increase as the oceans suck up more heat from the atmosphere,” he said. “The upper layers of the ocean are vital for marine biodiversity, as they support some of the most productive and rich ecosystems on Earth, and warming of this magnitude will dramatically impact on marine life,” Smale said. The new analysis assesses the heat in the top 2,000m of the ocean, as that is where most of the data is collected. It is also where the vast majority of the heat accumulates and where most marine life lives. The analysis method was developed by researchers at the Chinese Academy of Sciences in Beijing and uses statistical methods to interpolate heat levels in the few places where there was no data, such as under the Arctic ice cap. An independent analysis of the same data by the US National Oceanographic and Atmospheric Administration shows that same increasing heat trend. Reliable ocean heat measurements stretch back to the middle of the 20th century. But Abraham said: “Even before that, we know the oceans were not hotter.” “The data we have is irrefutable, but we still have hope because humans can still take action,” he said. “We just haven’t taken meaningful action yet.”"
"
Share this...FacebookTwitterIn direct contrast with CO2-centric climate modeling, extensive paleoclimate evidence affirms that the Holocene climate has been far more variable in the past 12,000 years than during the relatively quiescent period we’ve enjoyed since the mid-19th century. In the absence of CO2 concentration changes or human interference, abrupt global cooling episodes led to agricultural collapse, famines, and the extirpation of ancient civilizations.  These naturally-occurring climate events are likely to recur…and we will be powerless to intervene.

Between 1860 and 2014, CO2 concentrations rose dramatically (from 285 parts per million to 400 ppm), and yet global temperatures have fortunately remained relatively stable, with an overall per-decade change rate of just 0.05°C.

Image Source: Zhu et al., 2017
In contrast to the last 150 years of modest climate change, there was an instance 14,500 years ago in which “Northern Hemisphere temperatures increased by 4–5°C in just a few decades” and a concomitant “12–22 m sea level rise in less than 340 years” (Ivanovic et al., 2017), which is a warming of multiple degrees per decade and a sea level rise amounting to 3.5 to 6.5 meters per century.   This well-documented climate event occurred without CO2 levels fluctuating, indicating that CO2 was not causally involved in this explosive warming or sea level rise.
The 8.2 ka Abrupt Cooling/Warming Event
About 8,200 years ago, there was an abrupt, multiple-degree C cooling and warming episode (the “8.2 ka event”) that was global in scope, and lasted a total of about 150 years, with the amplitude of the cooling and warming phases lasting only decades.  The event was “associated with a total eustatic sea level rise of 0.8–2.2 m [Li et al., 2012; Törnqvist and Hijma, 2012]” (Ahn et al., 2013), indicating that there was far more pronounced climatic changes and sea level rise rates — ~1 meter per century — during this period than the mere 0.05°C per decade change and <0.2 meter of sea level rise that has occurred in the last 150 years.
Kobashi et al., 2007     “A large number of paleoclimatic records over a hemispheric area show a large and abrupt climate change around 8200 years BP. However, the duration and general character of the event have been ambiguous. Here, we provide a precise characterization and timing of the event using methane and nitrogen isotopes in trapped air in an ice core. Climate change in Greenland and at a hemispheric scale was simultaneous (within ~4 years) as supported by climate model results (LeGrande et al., 2006).  The event started around ~8175 years BP, and it took less than 20 years to reach the coldest period, with a magnitude of cooling of ~3.3°C [per decade] in central Greenland.   After 60 years of maximum cold, climate gradually recovered for 70 years to a similar state as before the event [+3.3°C within 70 years]. The total duration of the event was roughly 150 years. … The fall in temperatures that accompanied the 8.2 ka event also corresponded with abrupt migrations of human populations and abandonment of sites ranging from Spain to Greece and in the Middle East (Gonzalez-Samperiz et al., 2009)  ….  Ice cores from Greenland (Alley et al., 1997) and Africa (Thompson et al., 2002) suggest that the 8.2 ka event was global in extent.”
During this period, atmospheric CO2 concentrations effectively stayed the same, with “a small, about 1–2 ppm, increase of atmospheric CO2 during the 8.2 ka event” (Ahn et al., 2013), once again supporting a lack of causal connection between large-scale global warming and cooling and CO2 concentration changes.
Atwood et al., 2017     “The relatively stable climate of the Holocene epoch (11,700 yr BP-present) was punctuated by a period of large and abrupt climate change ca. 8,200 yr BP, when an outburst of glacial meltwater into the Labrador Sea drove large and abrupt climate changes across the globe.  Polar ice and marine records indicate that annual average surface temperatures dropped by 2-6 °C in central Greenland and by 1-3 °C in the North Atlantic Ocean and Europe [within decades]. The associated climate perturbations are generally thought to have persisted for 100-150 years [before temperatures returned to the previous baseline]. … These events stretch our understanding of the dynamical principles that govern the climate system, given the lack of these events in the modern record and the inability of climate models to reproduce such variability.”

Griffiths and Robinson, 2018     “The 8.2 ka BP (8200 cal. BP) event is regarded as the largest abrupt climate change event of the Holocene period (Alley et al., 1997; Alley and Agústsd ottir, 2005 ). It was first identified in the Greenland ice cores (Alley et al., 1997; Rasmussen et al., 2006; Thomas et al., 2007), but has subsequently been reported in multiple proxies across Europe (Magny et al., 2003; Seppa et al., 2007; Prasad et al., 2009; Zillen and Snowball, 2009; Daley et al., 2011; Giesecke et al., 2011), and throughout the Northern (Morrill and Jacobsen, 2005; Shuman, 2012; Liu et al., 2013; Dixit et al., 2014) and Southern Hemispheres (Morrill and Jacobsen, 2005; Cheng et al., 2009; Bustamante et al., 2016). In the Northern Hemisphere the event has been cited as precipitating a cold period, with a drop in temperature for example of 6 ± 2°C at Summit, Greenland (Alley et al., 1997) and of c. 1.6°C at Hawes Water, northwest England (Lang et al., 2010) that, according to counts of Greenland ice core layers, lasted a total of just over 160 years (Thomas et al., 2007). The event was reportedly caused by a glacier meltwater outburst from Laurentide lakes Agassiz and Ojibway around 8470 cal BP, which reduced deep water formation and caused an abrupt slowdown of the Atlantic meridional overturning circulation (Barber et al., 1999). This hypothesis has been supported by work showing two sea-level jumps between 8.5 and 8.25 ka BP (Tornqvist and Hijma, 2012).”
The 4.2 ka Abrupt Cooling/Warming Event
About 4,200 years ago, another abrupt global-scale cooling event occurred that was associated with severe Northern Hemisphere-wide drying period that lasted for centuries.  The accompanying megadroughts and famines wiped out human civilizations that had existed in the same locations  for centuries to millennia.  After about 300 years of enduring cold and drought-stricken climates, “unified Neolithic farming culture completely collapsed” (Fenggui et al., 2010 ).
Like the 8.2 ka event, the 4.2 ka event featured a sudden, decadal-scale drop in surface ocean temperatures of 1-2°C (Guo et al., 2018).  Also like the 8.2 ka event, the 4.2 ka event was not accompanied by changes in CO2 concentrations, again emphasizing the lack of a strong linkage between CO2 fluctuations and large-scale climate changes in the paleoclimate record.
Guo et al., 2018   “The mid-Holocene environmental transition was characterised by global cooling and the abrupt weakening of the Northern Hemisphere monsoon systems. It is generally considered the key driver of the collapse of several mid-Holocene agricultural societies, on a global scale. … The mid-Holocene environmental transition has attracted much attention from climate scientists and archaeologists, especially Holocene event 3 (HE3, ~4.2 ka) [4,2000 years ago],as termed by Bond et al. (1997), because it marks the termination of the Holocene climatic optimum (Perry and Hsu, 2000) and the initiation of the Neoglacial (Solomina et al., 2015). Existing records reveal that ocean surface temperatures decreased by ~1-2°C during HE3 [4.200 years ago] (Bond et al., 1997; deMenocal et al., 2000b), which persisted for ~300-600 years (Cullen et al., 2000; Perry and Hsu, 2000); while a total duration of up to ~1500 years was recorded in the North Atlantic (Bond et al., 1997, 2001). In addition, HE3 was punctuated by a series of geologically-rapid global cooling and/or dry events (Morrill et al., 2003; Marchant and Hooghiemstra, 2004; Booth et al., 2005; Shanahan et al., 2015) which were superimposed on the gradual drying trend of the mid-Holocene (Morrill et al., 2003; Mayewski et al., 2004; Wanner et al., 2008, 2011; Roberts et al., 2011). Associated with HE3 were the collapse of cultures in Pakistan (Staubwasser et al., 2003; Madella and Fuller, 2006; Macdonald, 2011; Giosan et al., 2012; Ponton et al., 2012; Leipe et al., 2014; Menzel et al., 2014; Prasad et al., 2014a), Mesopotamia (Weiss et al., 1993; Cullen et al., 2000; deMenocal, 2001), China (Jin and Liu, 2002; Wu and Liu, 2004; An et al., 2005; Innes et al., 2014; Zeng et al., 2016; Zhu et al., 2017) and Egypt (Thompson et al., 2002; Marshall et al., 2011; Phillipps et al., 2012). In high latitudes of the Northern Hemisphere, a peak in detrital carbonate flux on the East Greenland Shelf at 4.7 ka signaled both the beginning of the Neoglacial and a southward expansion of the Arctic sea ice (Jennings et al., 2002). In Europe, a 4.2 ka drought event is recorded by multi-proxy data from a cave flowstone in Italy (Drysdale et al., 2006); diatom assemblages from Montcortes Lake in the Iberian Peninsula indicate that lake levels were lower during a pronounced dry interval from 2360 to 1850 BCE (Scussolini et al., 2011); a decrease in deciduous Quercus and Pinus pinea-type percentages in Southwest Iberia at ~4.2 ka suggests an abrupt shift to dry conditions (Lillios et al., 2016); and a synthesis of records from the Mediterranean reveals an unusually dry interval from 4.5 to 3.9 ka (Mercuri et al., 2011; Roberts et al., 2011). Evidence from eastern tropical Africa indicates a shift to drier conditions at ~4.0 ka (Marchant and Hooghiemstra, 2004), although at this time wetter conditions were maintained in West Africa (Russell et al., 2003) and in parts of South America (Marchant and Hooghiemstra, 2004); and magnetic and geochemical data from the Holocene sediments of Lake Tana in northwest Ethiopia confirm that the driest interval occurred at ~4.2 ka (Marshall et al., 2011), which is also identified in the Mount Kilimanjaro ice core (Thompson et al., 2002) and in the Mauritian lowlands (de Boer et al., 2014). In eastern Russia, evidence of a cold spell between 4.5 ka and 3.5 ka is provided by a multi-proxy record from Two-Yurts Lake (Hoff et al., 2015). A severe centennial-scale megadrought in mid-continental North America occurred between 4.1 and 4.3 ka (Booth et al., 2005).”
Xiao et al., 2018     “Researches on the 4.2 ka event and its impact on cultural evolution in China have been encouraged by Hsü’s view (1998) that famines and mass migrations have occurred in the past. In ancient China, these could have resulted from regional droughts related to global cooling. Wu and Liu (2004) synthesized data from paleoclimatic records in eastern China and suggested that the climatic anomaly that occurred ~4.2 ka ago produced a drought in the northand flooding in the south, which was responsible for the collapse of neolithic cultures in the central plain of China during the late third millennium BC. … Fang and Sun (1998) first attributed the interruption of the Laohushan Culture to climatic cooling based on the impacts of ≥10°C cumulative temperature decreases on frost-free period in the lake region and of a temperature drop to agricultural production in areas along the Great Wall during the historical period. This interpretation has been followed by Tian (2000) and Tian and Guo (2004). As stated above, our multi-proxy data imply a decrease in regional precipitation rather than temperature.”
Klus et al., 2017     “Abrupt cold events have been detected in numerous North Atlantic climate records from the Holocene. … Here, we describe two cold events that occurred during an orbitally forced transient Holocene simulation using the Community Climate System Model version 3. Both events occurred during the late Holocene (event 1 referring to 4305-4267 BP [38 years] and event 2 referring to 3046-3018 BP [28 years]) and were characterized by substantial surface cooling (-2.7 and -2.2 °C, respectively [-0.71 °C/per decade and -0.78 °C/decade]) …  …  Northeast of Iceland, however, shows an increase in both SST and SSS, but a decline in sea ice concentration (event 1: warming of 1.6 °C [+0.42 °C/decade], rise of 0.7 PSU, decline of -5 % in sea ice concentration; event 2: warming of 1.9 °C [+0.68 °C/decade], rise of 0.9 PSU, decline of -11 % in sea ice concentration). … The events were triggered by prolonged phases of a positive North Atlantic Oscillation which, through changes in surface winds, caused substantial changes in the sub-polar ocean circulation and associated freshwater transports, resulting in a weakening of the sub-polar gyre. Our results suggest a possible mechanism by which abrupt cold events in the North Atlantic region may be triggered by internal climate variability without the need of an external (e.g. solar or volcanic) forcing.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





1-3°C Decadal-Scale Holocene Surface Cooling/Warming In the North Atlantic
In the subpolar North Atlantic, Holocene sea surface temperatures routinely rose and fell by 1°C to 3°C within a span of decades.
Berner et al., 2008  “Superimposed on general Holocene climate change is high-frequency [North Atlantic] SST [sea surface temperature] variability on the order of 1-3°C [during a ’10- to 50-year time resolution’].”

Modern Ocean Heat Content Changes So Minimal They Are “Below Detection”, While Holocene Ocean Temperature Changes Reached “>2 °C Within 200 Years”
According to Levitus et al. (2012), the global ocean heat content (0-2000 m layer) rose by a total of just 0.09°C during the 55 years between 1955 and 2010.   During the Holocene, temperatures in the 0-1000 m layer rose and/or fell by more than 2°C within 200 years, or 1°C per century.
Bova et al., 2016     “Rapid variations in deep ocean temperature detected in the Holocene … The observational record of deep-ocean variability is short, which makes it difficult to attribute the recent rise in deep ocean temperatures to anthropogenic forcing. Here, we test a new proxy – the oxygen isotopic signature of individual benthic foraminifera – to detect rapid (i.e. monthly to decadal) variations in deep ocean temperature and salinity in the sedimentary record. We apply this technique at 1000 m water depth in the Eastern Equatorial Pacific during seven 200-year Holocene intervals. Variability in foraminifer δ18O [water temperature proxy] over the past 200 years is below the detection limit [a change or variability in ocean heat cannot be detected in the past 200 years], but δ18O signatures from two mid-Holocene intervals indicate [natural, unforced] temperature swings >2 °C within 200 years.”
Between 80,000 and 20,000 Years Ago, Temperatures Rose By 10°C And More Within Decades Dozens Of Times
Referred to as Dansgaard-Oeschger (DO) events occurring during the last glacial (~80,000 to 20,000 years ago), global temperatures would rise by multiple degrees within decades about every 1,500 years, each time nearly reaching the modern interglacial’s warmth before gradually cooling back down over the course of centuries.  The amplitude of these explosive warming events reached 10 to 15°C in Greenland.   As usual, CO2 concentrations did not change during these abrupt warming/cooling episodes, as they remained flat and dangerously low at 180 to 190 ppm throughout the last glacial.  Scientists have concluded that  “DO events are part of the natural variability and not externally triggered” (Shao and Ditlevsen, 2016).
Sánchez et al., 2017      “The estimated increases in Greenland atmospheric temperature were 5–16°C [Capron et al., 2010] and the duration of the warming events between 10 to 200 years [Steffensen et al., 2008].”

Lohmann and Ditlevsen, 2018    “During the last glacial period, lasting from approximately 120 to 12 kya BP (thousands of years before present), a large number of abrupt large-scale climate changes have been recorded in Greenland ice cores and other Northern Hemisphere climate proxies. These so-called Dansgaard–Oeschger (DO) events (Dansgaard et al., 1993) are characterized by an abrupt warming of 10–15 K from cold conditions (stadials) to warmer conditions (interstadials) within a few decades. This is typically followed by gradual cooling, lasting centuries to thousands of years, until a more abrupt jump back to cold conditions is observed. … In conclusion, we show that the long-term variations in DO warming event frequency, often described as millennial climate activity, are consistent with a memory-less stationary random process. From the data at hand we cannot exclude the possibility that the long-term variations occurred by chance. If we however divide a DO cycle into two independent processes governing warming and cooling, this is not true anymore and significant time-varying structure is detected. We thus propose a model that incorporates long-term variations through forcing of the parameters with external climate factors. We find good agreement with the data in a model where the mean duration of interstadial phases of the DO cycle is controlled by global ice volume and the stadial phases by boreal summer insolation.”
Jensen et al., 2017     “The Dansgaard-Oeschger (DO) events of the last glacial are some of the most prominent climate variations known from the past. Ice cores from Greenland show multiple temperature excursions during the last glacial period as the climate over Greenland alternated between cold stadial (Greenland Stadial, GS), and warmer interstadial (Greenland Interstadial, GI) conditions with a period of roughly 1500 years (Grootes and Stuiver, 1997). Each DO-event is characterised by an initial temperature rise of 10±5 °C toward GI [Greenland Interstadial] conditions in a few decades, a more gradual cooling over the following several hundreds of years, and a relatively rapid temperature drop back to GS at the end of most of the events (Johnsen et al., 1992; Dansgaard et al., 1993; North-Greenland-Ice-Core-project members, 2004; Kindler et al., 2014).DO-events are manifested not only in Greenland, but around the world.”
Hewitt et al., 2016     “Many northern hemisphere climate records, particularly those from around the North Atlantic, show a series of rapid climate changes that recurred on centennial to millennial timescales throughout most of the last glacial period. These Dansgaard-Oeschger (D-O) sequences are observed most prominently in Greenland ice cores, although they havea global signature, including an out of phase Antarctic signal. They consist of warming jumps of order 10°C, occurring in typically 40 years, followed generally by a slow cooling (Greenland Interstadial, GI) lasting between a few centuries and a few millennia, and then a final rapid temperature drop into a cold Greenland Stadial (GS) that lasts for a similar period. … [S]teady changes in ice-sheet runoff, driven by the AMOC, lead to a naturally arising oscillator, in which the rapid warmings come about because the Arctic Ocean is starved of freshwater. The changing size of the ice sheets would have affected the magnitude and extent of runoff, and we suggest that this could provide a simple explanation for the absence of the events during interglacials and around the time of glacial maxima.”
Rasmussen et al., 2016  (press release)      “Extreme climate changes in the past Ice core records show that Greenland went through 25 extreme and abrupt climate changes during the last ice age some 20,000 to 70,000 years ago. In less than 50 years the air temperatures over Greenland could increase by 10 to 15 °C. However the warm periods were short; within a few centuries the frigid temperatures of the ice age returned. That kind of climate change would have been catastrophic for us today.  Ice core records from Antarctica also show climate changes in the same period, but they are more gradual, with less severe temperature swings.”
Jensen et al., 2016      “Proxy data suggests a large variability in the North Atlantic sea surface temperature (SST) and sea ice cover during the Dansgaard Oeschger (DO) events of the last glacial. However, the mechanisms behind these changes are still debated. … Based on our analysis, we suggest that the variability of the subpolar gyre during the analyzed DO event can be explained by internal variability of the climate system alone. Further research is needed to explain whether the lacking amplitude in the Nordic Seas is due to the model deficiencies or if external forcing or some feedback mechanisms could give rise to larger SST variability.”
Agosta and Compagnucci, 2016        “The climate in the North Atlantic Ocean during the Marine Isotope Stage 3 (MIS 3) —roughly between 80,000 years before present (B.P.) and 20,000 years B.P., within the last glacial period—is characterized by great instability, with opposing climate transitions including at least six colder Heinrich (H) events and fourteen warmer Dansgaard–Oeschger (D-O) events. …  During the D-O events, the high-latitude warming occurred abruptly (probably in decades to centuries), reaching temperatures close to interglacial conditions. Even though H and D-O events seemed to have been initiated in the North Atlantic Ocean, they had a global footprint. Global climate anomalies were consistent with a slowdown of AMOC and reduced ocean heat transport into the northern high latitudes.”
Olsen, 2016     “The most frequent abrupt stadial/interstadial changes retained from the marine sediments are known as Dansgaard-Oeschger (D-O) cycles, and appear every 1-2 kyr. These cycles are characterized by abrupt short-lived increase in temperatures (10 ± 5°C) followed by gradual cooling preceding the next rapid event. A second millennial scale feature detected in the sediments record is cooling events culminating significant iceberg discharges analogous to Heinrich events. Mechanisms triggering abrupt changes display uncertainties, but leading hypothesis is attributed to modifications in the Atlantic Meridional Overturning Circulation (AMOC) and deep-water formation initiated by freshwater input.”
Mayewski, 2016       “The demonstration using Greenland ice cores that abrupt shifts in climate, Dansgaard-Oeschger (D-O) events, existed during the last glacial period has had a transformational impact on our understanding of climate change in the naturally forced world. The demonstration that D-O events are globally distributed and that they operated during previous glacial periods has led to extensive research into the relative hemispheric timing and causes of these events. The emergence of civilization during our current interglacial, the Holocene, has been attributed to the “relative climate quiescence” of this period relative to the massive, abrupt shifts in climate that characterized glacial periods in the form of D-O events.”
Bogotá-A et al., 2016       “We reconstructed upper forest line (UFL) positions between ~2000 and ~3400 m elevation and the most abrupt temperature shifts ranged up to 10 °C/100 yr at Terminations II and III. Regional vegetation change is mainly driven by eccentricity (100 kyr) and obliquity (41 kyr) cycles, while changes in local aquatic vegetation show variability in the obliquity and precession (21 kyr) bands. Millennial-scale climate variability reflecting Dansgaard–Oeschger (DO) climate cycles in the upper part of the record, continues in this penultimate intergalcial–glacial cycle strongly suggesting that this variability has a persistent character in Pleistocene vegetation and climate dynamics.”
Shao and Ditlevsen, 2016       “The glacial climate is dominated by the strong multi-millennial Dansgaard–Oeschger (DO) events influencing the long-time correlation. However, by separately analysing the last glacial maximum lacking DO events, here we find the same scaling for that period as for the full glacial period. The unbroken scaling thus indicates that the DO events are part of the natural variability and not externally triggered.”
Lynch-Stieglitz, 2017     “Abrupt changes in climate have occurred in many locations around the globe over the last glacial cycle, with pronounced temperature swings on timescales of decades or less in the North Atlantic. The global pattern of these changes suggests that they reflect variability in the Atlantic meridional overturning circulation (AMOC). … In many locations in the Northern Hemisphere, abrupt changes in climate have occurred that span almost the full range of glacial to interglacial conditions, with the transition between climate states occurring in decades or less (Alley & Clark 1999, Voelker 2002). These abrupt climate changes are most clearly recorded in the climate records from glacial ice on Greenland (Andersen et al. 2004) and are referred to as DansgaardOeschger (D-O) events. The warm intervals are referred to as interstadials, and the cold intervals are referred to as stadials. … [T]he prevailing paradigm is that the abrupt climate changes are a result of changes in the northward transport of heat by the Atlantic meridional overturning circulation (AMOC) (Broecker et al. 1985, Clark et al. 2002, Rahmstorf 2002).”
Climate Modeling Rooted In CO2-Driven Temperature Change Cannot Reproduce This Variability 
In writing about the abrupt, global-scale climate changes during the 8.2 ka event that do not follow modeled expectations of an anthropogenically-driven modern climate, (Atwood et al., 2017) wrote:
“These events stretch our understanding of the dynamical principles that govern the climate system, given the lack of these events in the modern record and the inability of climate models to reproduce such variability.”   
Indeed, considering how profound past climate changes have been in the absence of CO2 fluctuations relative to the modest (0.05°C per decade) temperature changes of the last 150 years with pronounced CO2 rise, there does not appear to be a non-political justification for focusing our attention on CO2 as a driver of climate change.
Another abrupt global cooling event in line with the 8.2 ka or 4.2 ka may be in store for us in the coming decades.  And if it does happen, we will be powerless to stop it.
Share this...FacebookTwitter "
"Should we give up having children to save the planet? Recent news articles and scientific papers have once again raised concerns about “overpopulation” and the environmental implications of having too many humans on Earth. Many people consider bringing fewer children into the world to be the logical solution. If you read the comments section of these articles, you’ll find out what anyone who’s been in a conversation about overpopulation knows: such exchanges are polarised, emotionally loaded and conflict ridden.  Regardless of whether you think that overpopulation is the defining issue of our time, don’t think it is a real problem, or lie somewhere in between, it’s absolutely crucial we can have these conversations without further polarising the debate. In a recent comment in Environmental Research Letters, we offer three tips for having conversations about overpopulation in a more ethical, thoughtful and sensitive way. An individual person (or a couple) acting by themselves can only do so much. It can seem like the most impactful action one can take is to have fewer children, but our capacity to act collectively can have far greater impacts than any one (or two) people can alone. Environmental problems are so large that they are hard for us to wrap our minds around. When people are encouraged to think about these problems as individuals, it can cause them to go into denial about how much impact they can genuinely have. But research has shown that highlighting a collective responsibility for addressing environmental issues actually leads to a greater desire to act. Often recommendations for how to be more environmentally friendly are targeted at things you do in your personal life: recycle more, eat less meat, fly less, and so on. However, businesses, universities, hospitals, churches and charities all have big environmental footprints, too. In fact, these are usually much larger than any one individual’s footprint. Therefore, individuals acting professionally within these organisations can substantially reduce their environmental impact. For example, the head of purchasing of a large organisation may be able to make bigger reductions in their organisation’s carbon emissions through changing purchasing guidelines than they could ever make by having fewer children. So organisations, or people working on behalf of organisations with big environmental footprints, are often much more strategic actors to target when striving towards larger-scale pro-environmental changes. When we’re talking about population as an environmental issue, it’s important to remember that it’s not the number of people per se but rather the consumption habits that lead to environmental degradation. Seven billion Americans using as much water, plastic, petrol and meat as they do now, would be a global disaster. In many countries, however, individuals use a fraction of the average American, and Eritrea has the smallest per capita ecological footprint of all. So few children are being born in most developed countries that without immigration, populations would be declining. For example, in Canada, the fertility rate was 1.6 children per woman in 2011 (well below the replacement rate of 2.1). So if you think about it, the real environmental impact here has to do with how much people are consuming – and this varies widely both between and within countries. Suggestions to have fewer children are very closely linked to the idea of birth control. Birth control has an ugly history and its knock-on effects can still be seen in China and South Korea today. In these countries, birth control led to the abortion of many female embryos as families preferred to have boys for several cultural reasons. However, today these countries face the problem of having more men than women of childbearing age which is one reason behind the trafficking of young women from other countries, such as Vietnam. Against this backdrop, in 2012, the United Nations Population Fund declared family planning a human right. But still about 12% of women aged 15–49 globally don’t have access to family planning. This is a modern-day human rights violation happening right now. This is why, when the suggestion of addressing environmental issues by having fewer children comes up, the conversation often switches to overpopulation and becomes fraught. Overpopulation is usually seen as a problem that puts future generations at risk. Therefore when it is raised in conversations about family planning, it’s read as a value statement: my children’s rights being violated in future are more important than the rights of those being violated now. This may not be your intended message, so be clear: should women have the right to choose when and how many children they have? An expanding human population is a collective challenge which incorporates values, emotions, different worldviews, and the alignment of different interests. So next time you find yourself wading into an exchange about overpopulation, be clear about your underlying assumptions. This is a conversation with many layers and we need to approach it with open minds, sensitivity, tact and compassion."
"When Scott Morrison thanked governments of the world for their assistance with Australia’s bushfire crisis, he particularly singled out “the loving response from our Pacific family”. Across the Pacific region – a collection of developing and least developed nations that are themselves almost uniquely at risk from climate-induced catastrophes – the response to the Australian bushfires has been immediate and generous, but it also reveals something of the problematic fraternity that Australia has with the rest of the region.  Governments from all over the Pacific have offered support. A hundred Papua New Guinean defence personnel, mostly engineers, will fly to Australia to help with firefighting efforts, and Fijian defence personnel will also be coming to assist. Vanuatu’s government has pledged $250,000. A PNG politician urged people to donate to relief efforts, pledging 50,000 kina (A$20,000) himself. And then there are the small gestures: a coffee shop in Fiji donated all of its sales on Monday – F$3,000 (A$2,000) – to bushfire relief; a group of Red Cross volunteers in Vanuatu walked down the street collecting donations, carrying a sign reading: “Give hope to Australian bush fire survivors”. Giro Imbu, 35, organised a similar donation drive in Lae, Papua New Guinea’s second-largest city, after seeing images of the bushfires on television. Imbu led a group of young people who walked through the city’s settlements on Thursday and Friday collecting donations. On their first day they received 1,000 kina. “We see the environment was really devastated, we see the plants being destroyed, we see a lot of the countrymen losing their lives in the fire,” Imbu said. “We’re not very educated, but it has given us a drive … we want to help.” Vanuatu Choir, who were displaced from Batlow while working to pick fruit, perform hymns at the Wagga multi-faith service for those affected by bushfires. #nswfires pic.twitter.com/F99RplyT5y To put all of this in context, in 2017 Vanuatu’s GDP per capita was just under US$3,000, Papua New Guinea’s was about US$2,500, Australia’s was close to US$55,000. The minimum wage in PNG is 3.50 kina (A$1.50) an hour. As Morrison noted at his press conference – speaking about Vanuatu’s pledge of $250,000 – “it might not sound like a lot in terms of the tremendous assistance provided by many other countries, but from them, that was a gift from the heart”. The heartfelt response of Pacific nations to Australia during this time is in part a reciprocation of the assistance Pacific countries receive from Australia when crises befall them. As James Marape, the prime minister of Papua New Guinea, noted in his statement about the fires: “Australia is the closest friend of PNG and is always the first in PNG in our times of adversities.” After Cyclone Pam devastated Vanuatu in 2015, Australia committed $50m in support for early and long-term recovery. After Cyclone Winston caused damage in Fiji amounting to about 30% of its GDP in 2016, Australia stepped in with $35m for recovery efforts. Morrison also reminded the world of Australia’s generosity as he was thanking Pacific countries for theirs, saying: “[Pacific leaders] know how Australia has been faithful to them in their hours of need, and they just in their own way are trying to extend that in the best way they possibly can.” But Australia’s generosity also puts Pacific countries in a tight spot. Pacific leaders have to walk a difficult line: keeping Australia and its financial support on side, particularly as they face the prospect of increased climate-related natural disasters in their countries, while wanting to challenge Australia on its climate policies. Pacific leaders are among the most outspoken and effective climate leaders the world has. We know they are angry at Australia’s refusal to transition away from coal, as well as Australia’s use of carryover credits to meet Paris targets. We know, in the words of the former prime minister of Tuvalu, , Enele Sopoaga, that they see Australia as trying to save its economy, while they are working to save their people. We know that they knowAustralia is not doing enough to tackle the climate crisis – the same climate crisis that is seeing their islands suffer rising sea levels, increasingly frequent devastating cyclones, salinity of the water table, erosion of their islands; that same climate crisis that threatens to make Australia’s current devastating fire season the norm for our future. And yet, still, they are there to offer us help. When asked whether he thought it was odd for people in a much poorer country like Papua New Guinea to be raising money for people in a wealthier one, Imbu, who organised the Lae fundraiser, said: “We live in an environment where the richest are getting richer and the poorest getting poorer, but as human beings we have this hardware, we try to help.” Pacific nations deserve all the thanks Morrison has given them, but to survive, they need much more from him."
"
Share this...FacebookTwitterAnother new false-alarm paper reveals that coastal wetlands may not only persist well into the 21st century despite present rates of sea level rise, but the coasts may expand and even prosper due to the natural ability for soil to “build up vertically by sediment accretion”.  

Headline/image source: Sciencenews.org
“Coasts are growing all over the world”
Two years ago, a ground-breaking paper was published in the journal Nature Climate Change indicating that the Earth’s shorelines have been growing overall since the mid-1980s (Donchyts et al., 2016).
In other words, because “coasts are growing all over the world”, there is more land area above sea level today than there was 30 years ago.
This conclusion has again been confirmed by a new paper (Luijendijk et al., 2018) that indicates only 24% of the world’s beach shorelines are eroding, whereas 76% of the world’s beach shorelines are either growing (28%) or stable (48%).
Supposedly “vulnerable” Pacific islands are expanding 
Hisabayashi et al., 2018 found that 15 of 28 studied atoll islands in the southwest Pacific grew in shoreline area during 2005 to 2015.
Kench et al., 2018 examined “101 islands in Tuvalu over the past four decades (1971–2014)”, a period in which local sea level has risen at twice the global average.  They found a “land area increase in eight of nine atolls.”
“Surprisingly, we show that all islands have changed and that the dominant mode of change has been island expansion, which has increased the land area of the nation. … Using remotely sensed data, change is analysed over the past four decades, a period when local sea level has risen at twice the global average [<2 mm/yr-1] (~3.90 ± 0.4 mm.yr−1). Results highlight a net increase in land area in Tuvalu of 73.5 ha (2.9%), despite sea-level rise, and land area increase in eight of nine atolls.” (Kench et al., 2018)
Coastal marsh area has been stable or expanding


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Kirwan et al., 2016 reported that coastal marshes and their “vulnerable” ecosystems are not only persisting despite present-day sea level rise, coastal marsh area has generally been stable or expanding.
In fact, it was claimed that sea level rise rates of 10-50 mm/yr (1 to 5 meters per century) during the 21st century would not be substantial enough to submerge the globe’s coastal marshes.
“Coastal marshes are considered to be among the most valuable and vulnerable ecosystems on Earth, where the imminent loss of ecosystem services is a feared consequence of sea level rise. However, we show with a meta-analysis that global measurements of marsh elevation change indicate that marshes are generally building at rates similar to or exceeding historical sea level rise, and that process-based models predict survival under a wide range of future sea level scenarios. We argue that marsh vulnerability tends to be overstated because assessment methods often fail to consider biophysical feedback processes known to accelerate soil building with sea level rise, and the potential for marshes to migrate inland. … In summary, dynamic models of marsh vertical accretion indicate that marshes will generally survive relative SLR rates of 10–50 mm yr−1 during the twenty-first century, depending on tidal range and suspended sediment availability.” (Kirwan et al., 2016)
Coastal wetlands may not be threatened by sea level rise
Adding yet another layer to the strengthening conclusion that global sea levels aren’t rising fast enough to “spell doom” to “vulnerable” coastal ecosystems and communities, Schuerch et al. (2018) find that the natural ability of coastal wetlands to “build up vertically by sediment accretion” could potentially lead to “wetland gains of up to 60 per cent of the current area“.
More and more, scientists are undercutting alarmist proclamations of catastrophic 21st century sea level rise brought on by anthropogenic global warming.

“Rising sea levels don’t have to spell doom for the world’s coastal wetlands. A new study suggests salt marshes and other wetlands could accumulate soil quickly enough to avoid becoming fully submerged — if humans are willing to give them a little elbow room. … The new study builds on previous work that suggests rising seas will increase sediment buildup in some parts of coastal wetlands. This increased sediment, as well as human adaptations to allow wetlands to move inland as the seas rise, could allow the coastal fringes to not only survive but to increase their global area by as much as 60 percent.” (Sciencenews press release for Schuerch et al., 2018)

“On the basis of our simulations, we find that, globally, rather than losses, wetland gains of up to 60 per cent of the current area are possible, if more than 37 per cent (our upper estimate for current accommodation space) of coastal wetlands have sufficient accommodation space, and sediment supply remains at present levels.”
“[M]ost large-scale assessments have overestimated the vulnerability of coastal wetlands to SLR [present-day sea level rise]. These differences highlight a major knowledge gap in our understanding of the responses of coastal wetland areas to global environmental change. It has been argued that the reason for the observed discrepancy is that large-scale assessments have so far failed to consider the well understood biophysical feedback mechanisms that are typically included in local-scale models. These mechanisms include the ability of coastal wetlands to build up vertically by sediment accretion, which is enhanced with increasing inundation heights and frequencies, triggered, for example, by accelerating SLR [present-day sea level rise], and which enables coastal wetlands to persist or even prosper with SLR [present-day sea level rise].”
“[W]e project that until 2100, the loss of global coastal wetland area will range between 0 and 30 per cent, assuming no further accommodation space in addition to current levels. Our simulations suggest that the resilience of global wetlands is primarily driven by the availability of accommodation space, which is strongly influenced by the building of anthropogenic infrastructure in the coastal zone and such infrastructure is expected to change over the twenty-first century. Rather than being an inevitable consequence of global sea-level rise, our findings indicate that large-scale loss of coastal wetlands might be avoidable, if sufficient additional accommodation space can be created through careful nature-based adaptation solutions to coastal management.”
“[O]ur calibrated model, which includes mangroves as well as tidal salt and freshwater marshes, correctly predicts observations of present-day vertical wetland change, obtained from large meta-datasets from all over the world (Crosby et al., 2016; Kirwan et al., 2016; Lovelock et al., 2015), for 78% of all coastal areas where data are currently available (N=46).”
Share this...FacebookTwitter "
"Large numbers of species are at risk of global extinction from climate change. As a result, some governments are trying include wildlife in their plans for how to adapt the management of natural landscapes to a warming world. The problem is we still know very little about the sorts of environments that could help wildlife survive adverse climate shifts. But we do know that, during the Ice Age, pockets of warmer conditions protected species such as red squirrels and even red deer from the extreme cold. So, could modern versions of these “refugia”: locally cool habitats such as bogs, alpine environments or shaded valleys give species what they need to survive today’s warming? Using 5m records of plants and insects collected by citizen scientists in England, my colleagues and I looked for signs that refugia are protecting species today. We found that quite a number of sites around the country are already beginning to act as refugia. This was particularly the case in areas where the landscape is hilly or steep, where the local climate conditions (microclimate) vary more often. We estimate that these areas of variable microclimate have reduced the risk of extinction for insects and plants that are particularly sensitive to warming by an average of 9% and 22% respectively. Incorporating these key wildlife areas into our plans for climate change could help save more species and local populations from extinction. Our research indicates that inside these refugia the microclimate can vary over very short distances. This can be as little as few hundred metres across a shaded valley. But a variable microclimate can also develop in hummocky terrain, which has lots of slopes facing different ways – both towards and away from the sun. These local differences can be as much as 7°C during the hottest parts of the day. For some species, that can be the difference between extinction or survival. A surprising aspect to the work was that the refugia we found weren’t necessarily forming in the coolest parts of the landscape. Instead, they formed in those areas that had the most variable microclimate. It is therefore quite possible that there are lots of alternative habitats for threatened species close to where they already live. This would mean that the species that live in these refugia wouldn’t have to move far to make use of them. This could be particularly important for plants and, as we already know, they can’t shift their geographical range as quickly as animals in response to warming. But we found that animals also benefit from refugia and, in most cases, animal species will be able to make use of numerous alternative thermal habitats within the lifetime of an individual. So how can we protect refugia from climate change, to make sure they are available for wildlife to use in the future? In some ways, the areas we’ve identified are quite different to the expansive, continuous areas of habitat that we currently prioritise for wildlife conservation, such as large areas of moorland or bog. But there is certainly some overlap with areas we have already protected for wildlife. This is particularly the case within the UK’s network of Sites of Specific Scientific Interest (SSSIs), the highest category of legal protection we can give to parts of the landscape.  So at least we won’t be starting from scratch when we adapt our conservation plans to the huge challenge of climate change. But some important sites for refugia lie outside these networks, and we should aim to protect as many of these as we can. In regions with fewer, naturally occurring refugia – flatter, often low-lying areas such as the east of England – we might even want to be more radical and consider using mechanical diggers to create hummocky terrain from scratch. This might sound expensive, but becomes far more attractive if it can be done where there is building or engineering work already going on, as the equipment and expertise will already be available and on site. For example, we could add the creation of refugia to plans for new housing developments. There are particular wildlife benefits to be had where digging exposes more alkali minerals such as as chalk to the air. This allows rarer, specialist plants and animals to move in and make use of the unusual soil conditions that arise. As the world warms up, much of our wildlife is facing a future of warming temperatures in landscapes which, thanks to human activity, are already hostile to many species. Refugia won’t “save” species from climate change, but finding and protecting the sorts of areas that give our flora and fauna the best chance of survival seems like a first and perhaps obvious step towards a more integrated approach to managing our environment. This would help us to safeguard its value as the provider of the food we eat, the water we drink and the natural landscapes we enjoy."
"Fields of sunflowers are now a common – and beautiful – sight all over the world. They have inspired artists from Van Gogh to Klimt, and continue to do so in the age of Instagram, if the recent selfie craze is anything to go by and as one Canadian sunflower farm discovered. It was forced to shut after thousands of tourists seeking the perfect selfie caused chaos. An astonishing 7,000 vehicles caused a traffic jam stretching over four kilometers. But when sunflowers were introduced to Europe from the Americas in the early 16th century they were little more than garden novelties. The 16th-century English herbalist, John Gerard, was disappointed that the sunflowers in his Holborn garden in London were only 4.3 metres tall (those of his European competitors reached 7.3 metres). Today, sunflowers, with their massive, yellow flower heads are among the most recognisable plants on the planet. The growth in their prevalence – and that of sunflower selfie snaps – is largely due to their ballooning use for oil. Over the last 60 years, changes to our diets and industrial needs mean the area of global oil crop production has more than doubled. Four oil crops consume most of this land: oil palm, soya, rape and sunflower. Sunflowers have two main commercial uses, oil and confectionery (for direct seed consumption). Oil varieties of the flower have small, black, oil-rich seeds with thin hulls, which are pressed to produce an edible, almost tasteless, pale oil, rich in unsaturated fatty acids (especially oleic acid and linoleic acid). The oil is popular for cooking, margarine manufacture and even bio-diesel production. Leftovers from oil extraction are used to make high-protein animal feed. Confectionery types, on the other hand, have large, striped, oil-poor seeds with thick hulls. Both oil and confectionery types are the results of centuries of careful selection and breeding from wild plants. In North America, the sunflower’s native continent, the harvest contributes little to global production; peak production happened in the late 1970s only to fall dramatically in the 1980s. Today, most sunflowers are grown in the former Soviet Union.   The annual sunflower, a member of a genus of about 50 species from the Americas, was domesticated in North America about 5,000 years ago. Native North American uses of sunflower ranged from food and medicine, through a fibre and dye plant to a source of musical instruments and bird snares.  Commercial interest in sunflowers as an oil crop was slow to develop across most of Europe and North America. In contrast, Russians were using sunflowers as an oil crop by the late 18th century, perhaps because the Russian Orthodox Church did not prohibit the oil’s use during Lent. By the end of the 19th century, Russians had selected highly productive oil and confectionery varieties, which were re-imported to North America in the baggage of Russian immigrants. During the early 20th century, the Soviet plant breeder Vasilii Stephanovich Pustovoit began selecting sunflowers for oil content. In 1913 seeds contained approximately 30% oil, by the late 1950s seeds contained approximately 50% oil. Much of the change was achieved by breeding for thin hulls surrounding the kernels. By the 1960s, Western commercial sunflower oil production was based on the Soviet sunflower variety “Peredovik”. 


      Read more:
      The flower breeders who sold X-ray lilies and atomic marigolds


 Soviet sunflower seeds even got mixed up with the Cold War – high-quality seeds surreptitiously moved among Soviet and American plant breeders. Soviet sunflower breeders used naturally occurring variation within the annual sunflower to make commercial progress. But by the mid 20th century, North American breeders were taking a different approach, crossing wild and cultivated sunflower species to exploit the yield advantages associated with hybrid vigour. Today, most commercial sunflower farmers grow hybrid sunflower seed. Hybrid sunflower seed can be made by slowly, meticulously and expensively emasculating individual flowers to create females, which are then pollinated by hand. Alternatively, mutant sunflowers, incapable of producing fertile pollen, are used as female parents in hybrid crosses. Insects are essential for producing the vast quantities of the hybrid sunflower seed planted each year, since pollen must be transferred from male-fertile to male-sterile plants. Without insects, hybrid sunflower seed production would be uneconomic. But once in the farmer’s field, the sunflower crop does not rely on insects: crop seeds are produced by flowers that are fertilised with their own pollen. But new seeds will have to be purchased for the next season. Sunflower breeding continues in earnest today. New demands are placed on breeders by the environments in which farmers want to grow sunflowers and by consumers in the ways they want to use the harvest. Height, for example, is something every child wants their sunflower to achieve. But to the farmer, tall sunflowers must be avoided. Energy used to push up stems cannot be used to make seeds. And heavy rains and strong winds will knock over tall, top-heavy plants.  The dramatic changes of form and use of sunflowers over the last century show what can be achieved by breeders if suitable genetic resources are available. If we continue to adapt sunflowers to our needs as climates change, we must ensure diverse genes are conserved for future generations – ensuring those sunflower fields remain on offer as the perfect place to take a picture.  


      Read more:
      After Svalbard: why safety of world seed vaults is crucial to future food security


"
"
Share this...FacebookTwitterBy  Kirye 

The media, alarmist scientists and many leading policymakers often tell the public “the Arctic is rapidly melting”. And if a poll were done today, a vast majority of the people in Japan and elsewhere would say this is true. Unfortunately they have become the victims of “fake news”.


Luckily we have some hard data from the Arctic. And if one looks at them, it is true that sea ice has seen a declining trend – if we go back 40 years.
Yet, if we look at the past 12 years, we see that the trend for minimum has stopped, and one could argue even reversed:




Chart: By Kirye


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The above Arctic sea ice volume chart, which relies on data from the Danish Meteorological Institute (DMI), shows that there has even been a modest increase in the minimum sea ice volume recorded every late summer.  
Overall, Arctic volume has been stable, slightly on the rise over the past 12 years, as the full year data from the DMI show:
Yet, the media constantly falsely report that the Arctic sea ice is still melting away rapidly (it isn’t), and many have even made the alarms louder.
Sloppy, misleading media
Unfortunately the media have been sloppy, lazy and misleading in their reporting of what is really happening at the poles of the Earth. If they did their homework, they’d realize their shrill headlines are inappropriate and outdated.
In early September NoTricksZone’s author Kenneth Richard presented a number of papers, where he wrote:

An accumulating collection of “headlines” taken from the 2018 scientific literature is indicating the Arctic region is no longer experiencing accelerated mass ice sheet/glacier loss, warming, or sea ice declines.”

Disservice to the public
Why the media, IPCC and many policymakers ignore this remains a mystery. It’s a disservice to the public and taxpayers who have entrusted them to conduct policymaking responsibly and honestly.
P. Gosselin contributed to this article.Share this...FacebookTwitter "
"Big news from Lancashire in north England: the county council has rejected two planning applications to develop shale gas sites in recent days, the first in four years. Lancashire councillors’ decisions to reject planning applications by Cuadrilla at Roseacre Wood (June 25) and Little Plumpton (June 29) against the conditional approval of planning officers is a major blow for the industry. For reasons I will outline, though, it may not yet to lead to a national defeat.  The decision is unlikely to resolve any of the bigger and still outstanding public health issues surrounding unconventional gas extraction (as well as fracked shale gas, this also includes coal-bed methane and underground coal gasification). When it comes to the possible hazards, the scientific, regulatory and legal knowledge and opinion are both conflicting and conflicted. Such fears have led many communities, including a number of those in the relevant parts of Lancashire, to oppose fracking applications in their area. There is a growing scientific consensus that unconventional gas extraction in all its forms will contribute significantly to global climate change, which obviously has long-term public health effects. It might also cause water and air pollution, though industry voices disagree.  There are also fears about subsidence in coal-mining areas with a history of abandoned seams, and earthquakes, both of which have been played down by the government. Another concern is around mental health and well-being.  It doesn’t help that research on unconventional gas extraction has been heavily conflicted and fraught with evidence of substantial conflicts of interest in the US. Environmental groups and journalists have even coined the term “frackademia” to refer to universities winning contracts to undertake research for the companies involved.  The UK government has meanwhile insisted that the industry will be well regulated and that industry practice will be good. This is contrary to some research voices, while other governments have taken a very different view, with bans in Germany and France.  For their part, developers argue that unconventional gas extraction will be vital to meet our energy needs, at least in the medium term, as well as supplying feedstocks for the chemical industry and creating many jobs and prosperity for communities.  When it comes to developing policy for the industry, communities and activists argue that public-health considerations have been marginalised. The 2012 Royal Society report on unconventional gas extraction prepared by engineers and geologists contained no public-health experts in its working group and made minimal in-depth mention of public-health issues either.  A Scottish-government expert report published last year drew on this 2012 report and neither contained any experts on public health nor any independent experts on regulation or industry practice. Neither report learned from US failures to include public-health professionals either.  When agencies like Public Health England have reported on the prospects for unconventional gas extraction, they have tended to reflect the favourable assessments of these other bodies – as well as those of the UK government itself. The Public Health England report contained nothing on the wider public-health impacts via global climate change; nothing on socio-economic impacts, which have important health consequences; and nothing on work environments. These are serious gaps that need to be filled in.  American public-health professionals with practical experience of fracking said that claims in the report that the public-health problems related to the industry in the US such as poor regulation and bad industry practice would not apply in the UK were a “leap of faith unsubstantiated by scientific evidence”. They pointed out that the conclusions ignored the “inherent industry risks whatever regulation applies (casing failures, cement failures, waste and water spillage)” and argued the report overlooked the evidence about extra risks in heavily populated areas.  In this climate, decision-makers are being encouraged to turn a blind eye to the potential public-health issues. In Lancashire, for instance, newspaper reports suggest that the councillors were coming under pressure linked to the legal ramifications of approving and not approving the applications.  The impending Transatlantic Trade and Investment Partnership could make such considerations even more significant, if companies get the right to challenge local authorities or even governments over fracking bans. In this arena, public health risks being subordinated to company profits. Some planners have also suggested to me that local councils may in future not be able to consider any health factors in these decisions because they will be dealt with separately by regulatory agencies.  One other issue is also worth mentioning. The environmental statements that have to be included in all planning applications can contain narrow assessments of the potential health impacts of unconventional gas extraction. They ought to fully inform the planners about all the risks and benefits of the proposal.  They are not required to consider global climate-change issues, for instance, and have often focused just on noise and traffic. The quality and scope of the health-impact assessments in the US has varied a great deal – from the detailed and rigorous to the superficial. The assessments are also conducted by consultants who are mostly paid for by either interested companies or local authorities, which rarely if ever reach conclusions that conflict with the interests of who is paying. Community groups can rarely afford to pay for such reports.  Notwithstanding the Lancashire decisions, the challenge now facing the UK remains to ensure an independent, thorough, transparent and rigorous public-health impact assessment of unconventional gas extraction. This has to be conducted at national level, free of industry and commercial influences and capable of convincing the public of its lack of bias.  It should not rely on “theoretical solutions” but should draw on the best empirical evidence available, while acknowledging the potential shortcomings of the UK’s regulatory system. For many, it should rely on the precautionary principle against going ahead while there are uncertainties. That is arguably the only way to protect public health."
"
Share this...FacebookTwitterRecent research has emphasized that “critical mysteries remain” in our ability to quantify or even understand carbon cycle processes as they relate to Earth’s water bodies.  Observational constraints prevent the detection of an anthropogenic signal in ocean carbon uptake trends on decadal timescales (McKinley et al., 2017).  Many new papers even contradict the IPCC-endorsed conclusion that the oceans are a net sink for CO2 emission rather than a net natural source.  
The “We Had No Idea” Terrestrial Carbon Cycle
Since the mid-1980s, the Earth’s coasts and land area have been expanding (Donchyts et al., 2016), meaning there is more land mass above sea level today than there was three decades ago.  Sea level rise has not been rapid enough to keep pace with the natural shifts in Earth’s geological processes.
Net growth in global land and soil area could significantly affect the Earth’s carbon budget, especially since “Earth’s soil is releasing roughly nine times more carbon dioxide to the atmosphere than all human activities combined” (Carey et al., 2017).
Scientists frequently “discover” terrestrial locations that are new, unaccounted for sources of natural CO2 emission that “we had no idea” about.  They also routinely “discover” terrestrial surfaces that are deemed new CO2 net sinks that they never knew existed (Bastin et al., 2017).
Furthermore, scientists acknowledge that “the heterogeneous and sparsely measured terrestrial biosphere cannot be directly measured” (McKinley et al., 2017).
With new carbon sources and sinks “discovered” on a routine basis, as well as the very limited availability of direct measurements, why should there be any confidence that our land area carbon budget estimates are reliable?
Earth’s Water Bodies: “A Mechanistic Understanding of Carbon Sink Variability Requires Substantial Additional Elucidation”
Scientists have recently acknowledged that “critical mysteries remain” in ocean carbon uptake processes such that we lack a “detailed, quantitative, and mechanistic understanding of how the ocean carbon sink works” (McKinley et al., 2017).
Observational constraints do not even allow us to confirm that the alleged ocean carbon sink has been growing in recent decades due to anthropogenic emissions.

McKinley et al., 2017
“That the growth of the partial pressure of CO2 gas in the atmosphere ( pCO2 atm) drives a growing oceanic sink is consistent with our basic understanding that, as the globally averaged atmosphere-to-ocean pCO2 gradient increases, carbon accumulation in the ocean will occur at an increasing rate. This behavior has been illustrated clearly with models forced with only historically observed increases in pCO2 atm and no climate variability or change (Graven et al. 2012, Ciais et al. 2013). Nonetheless, critical mysteries remain and weigh heavily on our ability to quantify relationships between the perturbed global carbon cycle and climate change.”
“The current inability to accurately quantify the mean CO2 sink regionally or locally also suggests that present-day observational constraints are inadequate to support a detailed, quantitative, and mechanistic understanding of how the ocean carbon sink works and how it is responding to intensifying climate change. This lack of mechanistic understanding implies that our ability to model (Roy et al. 2011, Ciais et al. 2013, Frolicher et al. 2015, Randerson et al. 2015), and thus to project the future ocean carbon sink, including feedbacks caused by warming and other climate change, is seriously limited.”
“First, substantial uncertainty remains on the mean sink (∼30% of the total flux). Formally, the quantitative estimate of the 1980–1989 sink (−2.0 ± 0.7 Pg C y−1) is not statistically distinguishable from that for 2000–2009 (−2.3 ± 0.7 Pg C y−1). Reducing this uncertainty is absolutely critical to global partitioning of anthropogenic carbon sources and sinks. Each year, the Global Carbon Project (http://www.globalcarbonproject.org) estimates global sources and sinks of carbon, but because the heterogeneous and sparsely measured terrestrial biosphere cannot be directly measured, its flux is estimated by difference from estimated anthropogenic sources and the ocean sink (Le Quer´ e et al. 2015). In these budgets, land use change uncertainty is at least 50% of the mean flux, and uncertainty is growing for emissions from fossil fuel burning and cement manufacture (Ciais et al. 2013). Reduction in ocean sink uncertainty could therefore help to compensate from a global budgeting perspective.”
“The sum of the available evidence indicates that variability in the ocean carbon sink is significant and is driven primarily by physical processes of upwelling, convection, and advection. Despite evidence for a growing sink when globally integrated (Khatiwala et al. 2009, 2013; Ciais et al. 2013; DeVries 2014), this variability, combined with sparse sampling, means that it is not yet possible to directly confirm from surface observations that long-term growth in the oceanic sink is occurring.”
“Globally integrated variability fluctuates with ENSO. Yet, at regional scales outside the equatorial Pacific, these modes tend to explain less than 20% of the large-scale variance in pCO2 ocean and CO2 flux (McKinley et al. 2004, 2006; Breeden & McKinley 2016), indicating that much variance remains undescribed. Consistent with the limited amount of variance explained, the mechanistic connections of these modes are not well understood, except in the equatorial Pacific with ENSO. In the North Atlantic, a variety of studies have suggested a connection of the NAO and AMO to pCO2 ocean and CO2 fluxes, but whether these changes occur through convection or advection remains an open question. In the Southern Ocean, the SAM has been linked to pCO2 ocean and CO2 fluxes through impacts on wind-driven ventilation and subduction; however, since the mid-2000s, the clear relationship to SAM has substantially weakened (Fay & McKinley 2013, Landschutzer et al. 2015). In the North Pacific, the relative influence of the PDO ¨ as opposed to ENSO requires further study. Particularly as observations in the high latitudes have become more abundant, evidence has grown that climate modes do not adequately explain carbon cycle variability and that mechanistic understanding of carbon sink variability requires substantial additional elucidation.”
“[T]his CESM-LE analysis further illustrates that variability in CO2 flux is large and sufficient to prevent detection of anthropogenic trends in ocean carbon uptake on decadal timescales.”

The Earth’s Water Bodies: Net CO2 Source Or Sink?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Observational analysis has indicated that water bodies release more of their stored CO2 as they warm and retain more of their stored CO2 as they cool.
This has been borne out in Mauna Loa CO2 records as they relate to a “warm water year” versus a “cold water year”.

Flohn (1982).
“The recent increase of the CO2-content of air varies distinctly from year to year, rather independent from the irregular annual increase of global CO2-production from fossil fuel and cement, which has since 1973 decreased from about 4.5 percent to 2.25 percent per year (Rotty 1981). … Indeed the cool upwelling water is not only rich in (anorganic) CO2 but also in nutrients and organisms. (algae) which consume much atmospheric CO2 in organic form, thus reducing the increase in atmospehreic CO2. Conversely the warm water of tropical oceans, with SST near 27°C, is barren, thus leading to a reduction of CO2 uptake by the ocean and greater increase of the CO2. … A crude estimate of these differences is demonstrated by the fact that during the period 1958-1974, the average CO2-increase within five selective years with prevailing cool water only 0.57 ppm/a, while during five years with prevailing warm water it was 1.11 ppm/a.  Thus in a a warm water year, more than one Gt (1015 g) carbon is additionally injected into the atmosphere, in comparison to a cold water year.”

The Intergovernmental Panel on Climate Change (IPCC) has nonetheless claimed the oceans are a net carbon sink  rather than a net source.
Recent research analysis has challenged this conclusion, including several new (2018) published papers.
Astor et al. (2013), for example, found that 72% of the attribution for the increase in CO2 emission for the studied region arose from warming sea temperatures, and thus they concluded “the ocean is primarily a source of CO2 to the atmosphere”.
A Partial List Of Papers Indicating Earth’s Water Bodies Are A Net Source Of CO2
Below is a very non-comprehensive compilation of 12 recently-published papers that challenge the IPCC conclusion that the oceans function as a net sink for CO2.
This list would appear to support the conclusion that “critical mysteries remain” in our ability to quantify or even understand carbon cycle processes as they relate to Earth’s water bodies.

Astor et al., 2013
“Based on these observations, 72% of the increase in fCO2 sea in Cariaco Basin between 1996 and 2008 can be attributed to an increasing temperature trend of surface waters, making this the primary factor controlling fugacity at this location. … An increase/decrease of 1°C is usually followed by an increase/decrease of 16–20 matm of fCO2sea. Thus, the SST increase of 1.3°C between 1996 and 2008 accounted for 16 matm increase in fCO2sea explaining around 72% of the fCO2sea observed variation. This suggests that the changes measured in fCO2 sea were primarily the result of surface-ocean warming in Cariaco Basin. … These observations confirm that this area is a consistent source of CO2 to the atmosphere. The main process controlling the long-term changes in surface fCO2sea at CARIACO was temperature, with net community production playing a secondary role. … At the CARIACO site, the ocean is primarily a source of CO2 to the atmosphere, except during strong upwelling events.”

Ikawa et al., 2013
“We estimated that the coastal area off Bodega Bay was likely an overall source of CO2 to the atmosphere based on the following conclusions: (1) the overall CO2 flux estimated from both eddy covariance and pCO2 measurements showed a source of CO2; (2) although the relaxation period during the 2008 measurements were favorable to CO2 uptake, CO2 flux during this period was still a slight source; (3) salinity and SST were found to be good predictors of the CO2 flux for both eddy covariance and pCO2 measurements, and 99% of the historical SST and salinity data available between 1988 and 2011 fell within the range of our observations in May–June 2007, August–September 2008 and November 2010–July~2011, which indicates that our data set was representative of the annual variations in the sea state. Based on the developed relationship between pCO2, SST and salinity, the study area between 1988 and 2011 was estimated to be an annual source of CO2 of ~ 35 mol C m−2 yr−1. The peak monthly CO2 flux of ~ 7 mol C m−2 month−1 accounted for almost 30% of the dissolved inorganic carbon in the surface mixed layer.”

Levy et al., 2013
“Although they are key components of the surface ocean carbon budget, physical processes inducing carbon fluxes across the mixed-layer base, i.e. subduction and obduction, have received much less attention than biological processes. Using a global model analysis of the pre-industrial ocean, physical carbon fluxes are quantified and compared to the other carbon fluxes through the surface mixed-layer, i.e. air-sea CO2 gas exchange and sedimentation of biogenic material. Model-based carbon obduction and subduction are evaluated against independent data-based estimates to the extent that was possible. We find that physical fluxes of DIC [Dissolved Inorganic Carbon] are two orders of magnitude larger than the other carbon fluxes and vary over the globe at smaller spatial scale. At temperate latitudes, the subduction of DIC and to a much lesser extent (<10%) the sinking of particles maintain CO2 undersaturation, whereas DIC is obducted back to the surface in the tropical band (75%) and Southern Ocean (25%). At the global scale, these two large counterbalancing fluxes of DIC [Dissolved Inorganic Carbon] amount to +275.5 PgC y−1 for the supply by obduction and -264.5 PgC y−1 for the removal by subduction [net +11.0 PgC y−1] which is ∼ 3 to 5 times larger than previous estimates.”

Reimer et al., 2013
“The study of air-sea CO2 fluxes (FCO2) in the coastal region is needed to better understand the processes which influence the direction and magnitude of FCO2 and to constrain the global carbon budget. The near-shore region was a weak annual net source of CO2 to the atmosphere (0.043 mol CO2 m-2 y-1); where 91% of the outgassed FCO2 was contributed during the upwelling season.”

Rutherford et al., 2016
“Continental shelves account for a large proportion of global primary production, and potentially a disproportionate fraction of the carbon dioxide (CO2) flux between atmosphere and ocean. The continental shelf pump hypothesis proposes that continental shelves at high latitudes act as net sinks of atmospheric CO2. However, direct measurements on the Scotian Shelf, off eastern Canada, indicate that this shelf region acts as a net source of CO2 to the atmosphere.”

Brown et al., 2015
“Complex oceanic circulation and air–sea interaction make the eastern tropical Pacific Ocean (ETPO) a highly variable source of CO2 to the atmosphere. … Inter-annual variability was observed within the region, with the location of the western extent of the freshpool moving westwards considerably between 2010 and 2014. Previous work within this region suggest that changes in thermocline depth related to ENSO are likely to influence pCO2 within this region. The region is a net contributor to atmospheric CO2, with average sea to air fluxes (over the four years of observations) of 1.6 mmolm−2d−1, with all regions of the ETPO outgassing year-round, except the rainfall diluted Gulf of Panama/Freshpool region.”

Xue et al., 2012
“Air–sea CO2 flux computations indicated that the NYS acted as a net CO2 source with respect to the atmosphere in each season, annually releasing 0.63 ± 0.10 mol C m− 2 to the atmosphere. In combination with the CO2 efflux rate (1.68 ± 0.33 mol C m− 2 yr− 1) reported in the southern Yellow Sea (SYS), we estimate that the entire Yellow Sea, including both the NYS and the SYS, was a net CO2 source at a rate of ~ 1.49 mol C m− 2 yr− 1, annually releasing ~ 6.78 Tg C to the atmosphere (1 Tg = 1012 g).”

Sisma-Ventura et al., 2017
“Seasonal pCO2 variability was studied in the Southeast Levantine (SE-Levantine) during 2009–2015 with the aim of quantifying air–sea CO2 fluxes in this ultra-oligotrophic, warm and highly evaporative marginal sea. Mixed layer pCO2 varied significantly between 560 ± 9.0 μatm in August (summer) and 350 ± 8.7 μatm in March (winter). Comparison of pCO2 to Sea Surface Temperature (SST) yielded a strong positive correlation (n = 135, r 2 = 0.94), suggesting that the seasonal variations are the result of a thermodynamic effect on the carbonate system in seawater. Using the coupling between pCO2 and SST, we calculated the mean monthly values and the air-sea fluxes in this region. These calculations indicated that this region is a net source of CO2 to the atmosphere over an annual cycle, with an average flux of 845 ± 270 mmol C m2 y−1 (~0.98 Tg C y−1 ).”

Biswas et al., 2018
“The era of global warming and increased emission of greenhouse gases can be marked by the beginning of the industrial age. It is also true that under several conditions, natural ecosystems can be equally responsible for CO2 emission like any other anthropogenic activities which continuously release heat-trapping gases in the process of development. … East Kolkata Wetland (EKW) is an urban or peri-urban wetland located on the outskirts of the Kolkata City which performs multi-facet activities, carbon sink being one of them. The raw waste from the city is naturally treated in this wetland system, however, the aquaculture ponds situated in these wetlands which make use of this waste water for fishery is rarely studied. The present study aims to see whether the aquaculture ponds of EKW complex are acting as a source or a sink. Airwater carbon dioxide (CO2) flux was estimated for three consecutive seasons in a year and it was found that the system is acting as a CO2 source in all the three seasons.”

Wang et al., 2018
“We conducted a free‐water mass balance‐based study to address the rate of metabolism and net carbon exchange for the tidal wetland and estuarine portion of the coastal ocean and the uncertainties associated with this approach were assessed. We measured open water diurnal O2 and dissolved inorganic carbon (DIC) dynamics seasonally in a salt marsh‐estuary in Georgia, U.S.A. with a focus on the marsh‐estuary linkage associated with tidal flooding. We observed that the overall estuarine system was a net source of CO2 to the atmosphere and coastal ocean and a net sink for oceanic and atmospheric O2.”

Li et al., 2018
“Our calculated CO2 areal fluxes were in the upper-level magnitude of published data, demonstrating the importance of mountainous rivers and streams as a global greenhouse gas source, and urgency for more detailed studies on CO2 degassing, to address a global data gap for these environments. …  Rivers have been widely reported to be supersaturated in carbon dioxide (CO2) with respect to the atmosphere, and are a net source of atmospheric CO2 (Butman and Raymond, 2011; Raymond et al., 2013).”

Rosentreter et al., 2018
“Although the overall status of mangroves [creeks] is net autotrophic (Alongi, 2002), mangrove sediments and waters have been shown to be a large source of CO2 to the atmosphere due to large organic matter inputs from diverse sources such as the mangrove biomass itself, other terrestrial detritus, nutrients from land, microphytobenthos, phytoplankton and the exchange of organic matter with the open ocean (Lekphet et al., 2005; Borges et al., 2005; Bouillon and Boschker, 2006; Kristensen et al., 2008). … The vast majority of mangrove CO2 gas exchange studies found surrounding waters were supersaturated in CO2 with respect to the atmosphere, hence, a net source of CO2.”
Share this...FacebookTwitter "
"In the middle of the last century, mass-produced, disposable plastic waste started washing up on shorelines, and to be found in the middle of the oceans. This has since become an increasingly serious problem, spreading globally to even the most remote places on Earth. Just a few decades later, in the 1970s, scientists found the same problem was occurring at a much less visible, microscopic level, with microplastics.  These particles of plastic are between 0.05mm and 5mm in size. Larger pieces of plastic can be broken down into microplastics but these tiny bits of plastic also come from deliberate additions to all sorts of products, from toothpaste to washing power.  Now, with major global sampling efforts, it has become clear that microplastics are dispersing all over the world – in the water column, sediments, and marine animal diets – even reaching as far south as the pristine environments of Antarctica. While this plastic problem has become more prevalent, one of the most pristine ecosystems on Earth, the fjords of the Western Antarctic Peninsula, have been revealed by retreating glaciers. Tucked between islands and the mainland, the coast along the Western Antarctic Peninsula has long, narrow inlets created by glaciers. During the last 50 years, these fjords have physically changed, due to reduced sea ice cover and because nearly 90% of glaciers have retreated in this region. These processes have exposed the ocean floor of many of the fjords for the first time.  The potential for microplastics to impact this environment and its marine life is huge – and we’re now working to figure out the depth of the effect that microplastic pollution is having on the newly colonised habitats. Any microplastics recovered in the Southern Ocean, particularly in newly formed ecosystems, raise alarm. They not only indicate that the area has been affected, but that plastic pollution is increasingly ubiquitous too. In November 2017, our multidisciplinary UK-Chile-US-Canada research team – known as ICEBERGS – joined the RRS James Clark Ross (an ice strengthened research ship) and headed to Antarctica’s northernmost fjords. Our goal was, and still is, to gain a better understanding of how the environment and organisms evolve in newly emerging and colonising habitats in Antarctica. We are particularly interested in the marine ecosystems on the ocean floor, so have been looking at areas such as Marian Cove and Börgen Bay on the Western Antarctic Peninsula, where communities have only developed in the last few decades – due to the retreating glaciers. Thriving marine ecosystems can act as climate regulators. When ice retreats, new, pristine fjordic habitats are revealed and phytoplankton blooms occur. These help to counteract climate change because they take carbon dioxide gas out of the atmosphere. New productive seabed habitat also becomes available for the diverse shallow water fauna that eat this algae, and store the carbon long term. Not counteracting climate change, however, is the fact that new open water absorbs heat faster, in contrast to ice that would have reflected it.  The animals colonising the exposed fjords face challenging conditions. The sediment and fresh water flowing in the glacier melt runoff make it very difficult for many organisms to survive. And, if exposed to them, microplastics can be a serious concern for many marine animals, especially filter-feeding organisms (for example krill, and other zooplankton). As these creatures filter water to obtain food, they may ingest microplastics which can clog and block their feeding appendages, limiting food intake. Ingested microplastics may be transferred to the circulatory system too, which can cause an increased immune response.  Microplastics may also bring in new bacteria and chemical pollutants attached to them too. So, because many filter-feeding organisms support the entire food web, any impact on them should be expected to have cascading effects on the ecosystem. In newly revealed habitats, creatures are less likely to have been impacted by marine pollutants previously so they can help us learn about more recent changes in an environment. To our knowledge, microplastics have not been found in the Antarctic fjords before now, but our preliminary results have already found an alarmingly high presence – similar to those found in the open water of the Atlantic and Pacific Oceans, near big civilisations. These results came from samples taken directly from the fjords, and we are now looking further at the evidence of how micro-organisms are being affected by microplastics. During the next two Antarctic summers, we will be collecting more geophysical, physical oceanographic, sedimentological and biological data from these pristine sites in the same locations, so we can compare the changes over time in the habitats that colonise new ocean floor in Antarctic fjords.  Only after such rigorous data collection and analysis will we be able to tell the true impact of microplastics on pristine environments. Until then, we can all do our bit to cut down on potential pollution and protect what may very well be the last pristine environments on Earth."
"Elegant science can arise from ugly facts. This is the thought that springs first to mind as we read a new study in Nature about how a single invasive species – the black rat Rattus rattus – can deeply impact not just the landscape it overruns, but fundamentally alter the wider marine realm that surrounds it. The elegance springs from the exploitation of chance patterns of invasion. The researchers behind the study, led by marine biologist Nick Graham of Lancaster University, looked at the Chagos Archipelago, a remote group of coral atolls in the Indian Ocean. Some of the small islands that make up the archipelago are rat-infested and some are rat-free, a result of different patterns of human habitation in the 18th and 19th centuries.  Graham and colleagues found that the difference between the islands is now startling and has no need to be teased apart by sophisticated statistical techniques. Those islands with rats have something like one or two seabirds per hectare, while those without rats have 1,000 or more in the same area.  On rat-free islands, the seabirds range far and wide across the oceans to feed, and then deposit much of the resulting nitrogen and phosphorus-rich excrement on their home island. These nutrients are then washed into the shallow waters of the surrounding coral reef lagoons, where they support a complex food web that ultimately maintains large fish stocks. The fish in turn then graze the reefs and keep a healthy balance between seaweed and the island-building corals.  Next to the rat-infested islands, however, the researchers showed the fish populations are smaller, grow more slowly and eat less than half as much seaweed. These reefs, therefore, are more prone to be smothered by seaweed, and to have less healthy corals. This general phenomenon is not new. On the Chagos Islands it is a few centuries old, but elsewhere it can range back thousands of years – humans have long been migrating, taking rats and other fellow invaders such as pigs, rabbits and cats with them to cause comparable ecological havoc.  The trick here, as the authors underlined, has not been in finding evidence of human impact, for that is now nigh-well pervasive, but in finding some examples of something approaching a natural baseline – those islands that are still rat-free – which can allow the scale of that impact to be assessed. Given this history, the Chagos Archipelago story is not, technically, part of the Anthropocene – for the current best estimate for a beginning of this putative, still informal, geological epoch is somewhere in the mid-20th century. But it does illuminate the extent of – and the likely fallout from – the yet greater changes associated with more recent human impacts, when the scale and speed of biological invasions continued and indeed accelerated. Since the mid-20th century, most of the lakes and waterways of North America, for instance, have been the scene of a blitzkrieg by the zebra mussel, a native shellfish of Asia. The invasive zebra mussels of the River Thames of London, meanwhile, have seen their short-lived grip on the river prised from them by the yet more prolific Asian clam which, in the space of little more than a decade, has become a dominant species in the river.  San Francisco was once known for hippies with flowers in their hair, but its surrounding bay is also home to some less benign visitors, including vast numbers of the Amur River clam from across the Pacific, and the shipworm (actually a burrowing mollusc), which on its arrival managed to bore its way through numerous wooden piers and wharfs. Meanwhile, on the other side of the world in the East African savannah, there are a plethora of invading plants including the aptly named “devil weed” and “famine weed”, which spreads rapidly and can wipe out entire harvests. Teasing out the ecological ripple effects of these newer and more numerous examples of the Anthropocene will be harder than in the finely-worked Chagos Islands study of Nick Graham and co. The natural ecological baseline is now yet more distant, while other effects – from pollution, urbanisation, agriculture, and climate change – are also intensifying. Amid a thickening tangle of environmental forcing factors, it is becoming harder to precisely link cause and effect. It is clear, though, that the Earth system is now on a new trajectory, of the Anthropocene, following the relative stability of the Holocene. This new story of rats and reefs underlines how far-reaching these changes are likely to be. 


      Read more:
      Dawn of the Anthropocene: five ways we know humans have triggered a new geological epoch


"
"Chirp, chirp! To make this familiar summer sound, the male cricket holds his nerve and “stridulates” – rubbing his back legs together in order to entice a female. He knows this makes him vulnerable. What a female cricket can find, so too can the predators and parasites that wish to consume or infect him.  Hiding in the vegetation, he is also surrounded by a silent audience of other males. Those “sneakier” males do not sing themselves, but will try to intercept females as they approach a singing rival. It is this dramatic scene that plays out as we hear the crickets and grasshoppers calling on warm evenings. Or at least it did. Because the crooning of the crickets has quietened in recent years and may be becoming a thing of the past. There is strong evidence that large numbers of crickets and grasshoppers (known, along with mantises, earwigs and cockroaches as the “Orthoptera”) are declining across Europe. A 2017 review of European species showed that over 30% of the 1,000 European species were in decline while only 3% were increasing. As with many insects, we simply don’t know what is happening to most of the rest.  The problem is that recent work has suggested that all insect species, including Orthoptera, are declining – the so-called “insect Armageddon”. A 2017 study found that the abundance of flying insects has plunged by 75% over the past 25 years. One member of the study team, Professor Dave Goulson of Sussex University, said at the time: “Insects make up about two-thirds of all life on Earth [but] there has been some kind of horrific decline.”  He added: “We appear to be making vast tracts of land inhospitable to most forms of life, and are currently on course for ecological Armageddon. If we lose the insects then everything is going to collapse.” Among the species threatened is the delightfully-named “wart-biter” – so-called because of an 18th century Swedish practice of using the strong jaws of the cricket to remove warts from the skin. The wart-biter is now the focus of conservation efforts, including reintroductions into sites from which it has been lost. But this kind of intensive conservation simply is not possible for all species. The reasons behind the decline in crickets and grasshoppers are the standard fare. The loss, damage and fragmentation of habitats, largely as a result of increasing farming and urbanisation, as well as increasing rates of fires such as those that the world is experiencing in 2018. Crickets are often held to be indicators of good quality natural habitat, so their decline mirrors the ongoing decline in the wider natural world.  Anybody who has spent any time in the world’s most natural places will know that natural “soundscapes” are neither peaceful nor serene – they are as noisy and busy as any urban high street. The crickets are just one part of the larger soundscape that provides the musical accompaniment to nature’s play. Depending on where you live, you might hear bird song, flowing water, the buzzing of bees, the roar of tigers, the rustle of leaves, or the calling of frogs.  In 1962, Rachel Carson famously wrote about the “Silent Spring” caused by the effects of agricultural pesticides on songbirds. Now we are beginning to appreciate that other components of the natural world are falling silent. This is why some scientists are turning to “soundscape ecology” or “ecoacoustics” as a tool to understand the changing natural world.  This new scientific field gives conservation biologists another tool – an ecological stethoscope with which to listen for subtle changes in the environment. But in order to protect the soundscape we need to protect the landscape. At a time when land is at a premium for food production, housing and industry, we need to make space for nature."
"
Share this...FacebookTwitterTo keep informed on how the Atlantic hurricane season is developing, I find that hurricane expert Philip Klotzbach of the Colorado State University does a good job at that at Twitter.
A warmer planet does not mean more hurricanes
As the peak of the hurricane season approaches (September) he recently tweeted below average activity was forecast for the next two weeks:

Below-average Atlantic #hurricane activity predicted for the next two weeks (August 16-29) by @ColoradoStateU forecast team:https://t.co/xXojKUE6xE pic.twitter.com/DorPmJkoXC
— Philip Klotzbach (@philklotzbach) August 16, 2018

That’s good news, especially in light of the fact that global warming experts, who seem not to understand how hurricanes develop, warned that these Atlantic cyclones would keep getting more frequent and stronger. Data suggest this has been hardly the case.
Detrimental wind shear, cool sea surface temperatures
So what’s been keeping the lid on hurricanes in the tropical Atlantic development zone this year?
Klotzbach mainly points to two 2 factors: sea surface temperatures (SSTs) and vertical wind shear. A couple of days ago he tweeted that wind shear in the region has been “above average” and that this tends to “reduce hurricane activity”:

Latest output from the Climate Forecast System model calls for above-average vertical wind shear in the Caribbean and tropical Atlantic in September – the climatological peak of the Atlantic #hurricane season.  Strong shear reduces hurricane activity. @TropicalTidbits pic.twitter.com/sBt9mAmGIh
— Philip Klotzbach (@philklotzbach) August 14, 2018

Here Klotzbach even tweeted that vertical wind shear was “detrimental for hurricane formation.”
Shear 5th strongest since 1980


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On August 10, the Colorado State University hurricane expert tweeted that wind shear had been at the 5th strongest in close to 40 years:

30-day-averaged shear in the Caribbean (10-20°N, 90-60°W) is the 5th strongest on record (since 1980).  Since 1980, the only years with stronger shear from July 10 – August 8 were: 1986, 1987, 1997 and 2015.  All of these were below-average Atlantic #hurricane seasons. pic.twitter.com/hm4bIdgVWK
— Philip Klotzbach (@philklotzbach) August 10, 2018

Mid August Tropical Atlantic surface temps cool
Although the tropical Atlantic surface has warmed up a bit, sea surface temperatures still remain cool there, which, according to Klotzbach, “for mid August are the coldest since 1994” and thus tend to suppress hurricane formation:

While there has been some recent anomalous warming, tropical Atlantic (10-20°N, 60-20°W) sea surface temperatures (SSTs) are still the coldest for mid August since 1994.  Cooler tropical Atlantic SSTs tend to suppress #hurricane formation. pic.twitter.com/6KJJgDtfjG
— Philip Klotzbach (@philklotzbach) August 13, 2018

Unfavorable peak season hurricane formation conditions 
Klotzbach sums up the forecast for the upcoming peak season in his tweet accompanying the first diagram above.
Latest output from the Climate Forecast System model calls for above-average vertical wind shear in the Caribbean and tropical Atlantic in September – the climatological peak of the Atlantic hurricane season. Strong shear reduces hurricane activity.”
Good news. But when it comes to weather, things can turn on a dime.
PS: Another great place for hurricane information is Tropical Tidbits.
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterAlmost daily the CO2 Science site brings reports on the impact of climate change on the living world. Hat-tip: Die kalte Sonne here

Recently, CO2 Science brought up a paper in Nature Communications.
Using satellite images, Venter et al. 2018 found an eight percent increase in woody vegetation in sub-Saharan Africa over the last three decades, underscoring the global “greening trend”.

Recent study by Venter et al finds that the Sahara has shrunk by 8% over the past three decades. NASA image, public domain.
According to Wikipedia, the Sahara covers a vast area of some 9.2 million square kilometers. Eight percent of that translates into more than 700,000 square kilometers. That’s an area that’s almost as big as Germany and France combined! This is profound.
In other words, it’s well over 10,000 Manhattans!
If the added green area were effectively used for agriculture, it could produce enough food to feed the African continent. Unfortunately, this is a fact that the doomsday-obsessed media, activists and ruling politicians fear will become publicly known. They instead would prefer that the globe returns to a climate of the 1980s, when drought and famine ravaged the vast North African region.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to the recent study, the cause was a decline in vegetation fires in a warmer and more humid climate. Abstract:
Drivers of woody plant encroachment over Africa
While global deforestation induced by human land use has been quantified, the drivers and extent of simultaneous woody plant encroachment (WPE) into open areas are only regionally known. WPE has important consequences for ecosystem functioning, global carbon balances and human economies. Here we report, using high-resolution satellite imagery, that woody vegetation cover over sub-Saharan Africa increased by 8% over the past three decades and that a diversity of drivers, other than CO2, were able to explain 78% of the spatial variation in this trend. A decline in burned area along with warmer, wetter climates drove WPE, although this has been mitigated in areas with high population growth rates, and high and low extremes of herbivory, specifically browsers. These results confirm global greening trends, thereby bringing into question widely held theories about declining terrestrial carbon balances and desert expansion. Importantly, while global drivers such as climate and CO2 may enhance the risk of WPE, managing fire and herbivory at the local scale provides tools to mitigate continental WPE.
Read more at CO2 Science.
Another element that is unmentioned is the fertilization effect of the added CO2 into the atmosphere surely provides.
Relotian media
This is positive news that no one will find in the Relotian mainstream media, which are fixated on purveying propaganda, falsehoods, half truths and censorship with the aim of distorting public opinion and vigorously marginalizing dissenting views.
Also (thanks to readers:
– https://journals.ametsoc.org/doi/abs/10.1175/JCLI-D-17-0236.1
– https://www.nasa.gov/feature/goddard/2016/carbon-dioxide-fertilization-greening-earth
– http://journals.ametsoc.org/D-17-0236.1
– http://www.mdpi.com/htm
– http://www.mdpi.com/2072-4292/10/3/424/htm

Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn a new paper, scientists document another long-term cooling trend, this time in the North Atlantic’s sea surface temperatures.  Characterized as yet another stubborn “warming hole” in the anthropogenic “global” warming (AGW) narrative, the cooling trend amounts to “0.8 K century-1” and does not follow expectations outlined in models of  global-scale warming.

The portrayal of a globally-synchronous warming of the Earth with only small pockets of “warming hole” anomalies  is not supported by local and regional data reported in scientific papers.
In the Northern Hemisphere, for example, scientists (Kretschmer et al., 2018) have identified other “warming holes” in the temperature data for the 1990-2015 period.  About 80% of the contiguous U.S., Europe and much of Asia, including parts of the Arctic (Eastern Siberia), cooled during the 1990-2015 period, as shown here.
In the Southern Hemisphere, Antarctica has not warmed in the last 38 years.   And according to Purich et al., 2018, most of the Southern Ocean has been cooling since the late 1970s as well (as shown here).
There are not tiny, isolated holes of cooling in an otherwise uniformly-warming world.  These are gaping expanses of cooling…or non-warming.
Yes, some regions of the globe have been warming.  Some regions have been cooling.  And some regions remain trendless.
But in recent decades, the warming has not been global in scope.

Gervais et al., 2018
Mechanisms Governing the Development of the North Atlantic
Warming Hole in the CESM-LE Future Climate Simulations
“Recent studies have documented the development of a warming deficit in North Atlantic sea surface temperatures (SST) both in observations of the current climate (Rahmstorf et al. 2015; Drijfhout et al. 2012) and in future climate simulations (Drijfhout et al. 2012; Marshall et al. 2015; Woollings et al. 2012). This ‘North Atlantic warming hole’ (NAWH) is characterized in the observed record as a region south of Greenland with negative trends in SSTs of 0.8 K century-1 (Rahmstorf et al. 2015). In fully coupled global climate model (GCM) future simulations, the NAWH is seen as a significant deficit in warming within the North Atlantic subpolar gyre (Marshall et al. 2015; Winton et al. 2013; Gervais et al. 2016).  This local reduction in future warming is communicated to the overlying atmosphere and may impact atmospheric circulation (Gervais et al. 2016), including the North Atlantic storm track (Woollings et al. 2012).”

5 Other New Papers Also Document A Warming “Hole” In the North Atlantic

Grieman et al., 2018



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





2. Nicolle et al., 2018

3.  Thornalley et al., 2018

4. Smeed et al., 2018

5. Piecuch et al., 2017
 
Share this...FacebookTwitter "
"Watching animals in their natural habitat may seem harmless, but it can have serious consequences for the conservation status of wildlife. More than 1,400 species listed as Endangered and Critically Endangered by the International Union for the Conservation of Nature are threatened by tourism. This can be a consequence of habitat destruction caused by tourism development or disturbance caused by tourists.  The golden-capped fruit bat, for example, is an endangered species that is endemic to the Philippines. One of the major threats it faces is disturbance at the roost site caused by tourists. Not only can this disturbance stress the animals, it can also lead to the abandonment of pups. Together with other threats, such as deforestation, this disturbance contributes to pushing this and other species towards extinction. Nature tourism can be a primary source of income for entire communities or even countries. For example, in 2010 nature tourism in Scotland was worth £1.4 billion and generated 39,000 jobs. £127m of that is attributable to wildlife watching alone.  Consequently, we need to find ways to manage these activities so that the targeted wildlife can continue to thrive and the businesses that depend on it can remain economically viable. This is not an easy task.  The first obstacle is a lack of data. It is difficult and expensive to “track” people during their recreational activities, especially over large areas and long periods of time. Surveys allow experts to ask people about their recreational activities, but they are expensive to run and the response rate can be poor.  Here’s where social media can come to the rescue. Platforms such as Facebook and Twitter have billions of users, who share large amounts of information about their activities.  Flickr is a photo-sharing website that has been active since 2004. Most of the photographs uploaded onto Flickr have a time stamp indicating when the photo was taken. Some of them have geographical coordinates indicating where the photo was taken, too. Users can also add text to their photos, which gives an indication of their content.  Wildlife watching, and nature recreation in general, is closely associated with photography, making Flickr an ideal source of information to quantify these activities on a large scale and in fine detail.  As ideal as this may sound, however, Flickr data would be useless for conservation purposes if it didn’t reflect patterns of actual visitation. To address this, my co-authors and I compared the distribution in space and time of Flickr photographs to spatial and temporal trends from visitor statistics obtained from surveys.  We found that the monthly numbers of visitors to the Cairngorms National Park in Scotland obtained through surveys corresponded to the monthly numbers of people taking photographs in the Cairngorms National Park and sharing them on Flickr. Since not all tourists are social media users, there are fewer Flickr users than visitors, but the trends showed by the two datasets are very similar.  We found the same correspondence between the spatial distribution of geotagged Flickr photographs of wildlife taken in Scotland and the spatial patterns of wildlife watching activities according to an online Scotland-wide survey. Moreover, this relationship was true down to an area as small as 10km. All the data used in this study are publicly available and were downloaded following the terms and conditions of the data provider (in this case Flickr). We did not use the actual photographs but only the data associated with them, which was completely anonymised so as to avoid any privacy issues. By mapping where the most Flickr nature photographs were taken, we could then identify some of the most popular wildlife watching destinations in Scotland – and thus where certain species might face added pressure from tourism. Chanonry Point in the Moray Firth, for example, was identified as a hotspot for Flickr photographs of dolphins – and the beach is indeed one of the best locations in the UK to watch bottlenose dolphins from land, as is Aberdeen, which was also a hotspot for Flickr images of the mammals.  Meanwhile, a map of Flickr photographs of seals showed, among other locations, Forvie Nature Reserve in Aberdeenshire as a hotspot. This is an official seal haul-out site (a site on land where seals come ashore for resting, moulting or breeding) that now holds more than 1,000 grey seals.  Now we know that these areas are home to large numbers of animals and attract significant numbers of people eager to view them – so it is important to monitor these sites to avoid impacts on the wildlife. The first obstacle on the path to managing nature tourism sustainably can be overcome by harnessing the power of the internet and social media. We can use this data to identify areas where wildlife is under strong pressure from recreational activities and intervene, perhaps preventing any significant impacts on the wildlife. We can also investigate whether nature recreation is helping countries to achieve biodiversity and sustainability targets, such as the United Nations Sustainable Development Goals. For example, we can look for associations between nature tourism growth and progress towards biodiversity and sustainability goals in different countries. Wildlife watching is always an exciting experience and I want the next generations to be able to enjoy it. In order to preserve the wildlife and the industry that relies on it, we need to put more effort into designing effective management strategies that will lead to sustainable nature tourism. Social media could be an effective way to do this."
"The saying goes that the Taj Mahal is pinkish in the morning, milky white in the evening, and golden when the moon shines. Though this may once have been true for the famously pristine marble monument, a mixture of pollution and poor management has now burdened the Taj with a 24-hour layer of yellowy-brown. Condemning the “lethargy” of restoration efforts, India’s Supreme Court recently told the government to restore the Taj  or demolish it. Located in Agra, in the northern Indian state of Uttar Pradesh, the Taj Mahal is one of the most iconically beautiful buildings in the world. Built by Mughal Emperor Shah Jahan as a testament to his grief, following the death of his first wife Mumtaz Mahal, Rabindranath Tagore called it “a tear running down the cheek of time”. The Taj was constructed of translucent white marble, brought to Agra from the north-west Indian region of Rajasthan. It was then inlaid with semiprecious stones, including jasper, jade, turquoise, lapis lazuli, sapphire and carnelian. The whole riverside complex, including the gardens and surrounding sandstone walls, was finished in 1653. Over the last four centuries the Taj has aged and darkened as a result of natural oxidation processes – the marble equivalent of rust – but it has been given no help by its hostile surroundings. It has been drenched in acid rain, coated in soot from industrial and domestic chimneys, and eroded by atmospheric pollutants. Air pollution in Indian cities is legendary, and Agra is no exception. As in many Asian cities, increasing car ownership has caused traffic to surge, while dirty air seeps from Agra’s oil refinery and tannery chimneys. These pollutants – sulphur dioxide, Nox gases, and mainly carbon-based particulates – have steadily weathered and eroded the Taj’s brilliant white façade, giving it a yellow sheen. Despite the establishment of a 4,000 square mile protective area around the site, (the Taj Trapezium Zone), within which emissions are supposedly strictly controlled, photographs show a marked deterioration in the Taj’s condition over the last few years.  Legal emission limits have been long contested by developers, and are widely ignored. Smoky funeral pyres are lit, and piles of rubbish are regularly burned very close to the buildings. Pollution from the Yamuna River presents a further challenge. Untreated sewage and industrial waste pours in from the city, creating nutrient-rich waters. These nutrients are then picked up by the wind and deposited in the Taj’s increasingly porous stonework, allowing river-derived microorganisms to thrive on its surfaces, colouring them green.  Allegedly, excrement from the many insects that thrive in the contaminated river water has hastened the damage, but the effect is surely negligible compared to that of fossil fuel-derived sulphur dioxide and nitrogen dioxide. Since 1998, a range of Indian research institutes have explored restoration methods, and millions have been spent trying to reverse the discolouration. One attempt involved smothering the Taj with damp clay poultices similar to face packs. It was hoped they would draw the damaging acids out of the surface layers of marble, but, if anything, they seem to have made the situation worse. In London, some 50 years after the completion of the Taj Mahal, Sir Christopher Wren designed a structure of comparable ambition. St Paul’s Cathedral was finished around 1711, a resting place for the nation’s great and good, and was built from the light-coloured, calcerous rock, Portland Stone. St Paul’s has suffered many of the same problems as the Taj Mahal – acid rain, soot, atmospheric pollutants, darkening with age. But after 40 years of monitoring by teams of university geographers, employing scientific techniques such as repeated observation with microerosion meters, the extent of the weathering is far better understood Older British readers may recall the infamous smogs that engulfed Britain’s cities in the 1940s and 50s. Four hundred years of coal-powered domestic heating, and latterly the fumes emanating from vehicles and coal-fired power stations, allowed sulphur dioxide and fine particles of carbon to reach toxic levels in London’s air. On cold, still autumn evenings, dense chemical smog can do as much damage to calcerous or chalky stone as it can to people’s lungs. Combined with rainfall it creates weak sulphuric or nitric acid, which over centuries can erode calcareous stone. When St. Paul’s was closely examined in the 1980s, some of the parapets and carvings had crumbled away completely leaving stone surfaces held together by black sooty crusts, hiding the voids beneath.  The worst excesses of soot and sulphur dioxide have been curbed by environmental legislation, though the atmospheric nitrogen produced by traffic, particularly diesel vehicles, still causes problems. Like Agra, London regularly breaks the World Health Organisation limits on air pollution.  However, the rate of weathering on St Paul’s seems to have halved with the fall in atmospheric sulphur dioxide. Concerns remain over microflora growing on stone surfaces, but sensitive cleaning and the odd replacement stone have largely protected Wren’s legacy. It remains to be seen whether the Taj can be similarly restored. The Taj Mahal is a wonder of the modern world, but this national and international treasure needs swift and decisive action if it is not to lose its legendary lustre."
"Senior government ministers have sought to distance themselves from conservative Liberal MP Craig Kelly who sparked controversy by telling UK television there was no link between climate change and Australia’s bushfire crisis. Kelly, a longstanding critic of climate change action, was lambasted as a “denier” and “disgraceful” by the conservative British commentator Piers Morgan and the meteorologist Laura Tobin in a combative interview on ITV overnight. He had earlier spoken to the BBC to claim that there was “no link” between climate change and Australia’s crippling drought, pegging blame for the bushfire crisis that has so far claimed 25 lives and destroyed almost 2,000 homes on a lack of hazard reduction. Asked about Kelly’s remarks, Treasurer Josh Frydenberg said the government’s view was that climate change was causing hotter, drier summers, while agreeing that fuel load was a contributing factor to the bushfires. “Our view of climate change is that it’s real. We accept the science,” Frydenberg said. Minister for the drought, David Littleproud, who has previously questioned whether climate change is being caused by human activity, also criticised Kelly’s remarks as a “sideshow”.“He doesn’t represent the views of the government,” Littleproud said. “I couldn’t give a rats what he said, it’s irrelevant, let’s just focus on those people that are out there that need our help.” Opposition leader Anthony Albanese said his reaction to Kelly’s comments was one of “despair”. “Despair not just that Craig Kelly has those views and continues to advocate them, not just here in Australia, but globally, and be seen to be representing the Australian government’s position, but the knowledge that he’s one of the people who has held back action,” Albanese said. “He’s one of the people who has stopped action on climate change domestically, which has led us to be in a position whereby we’re actually, as well, arguing for less action internationally, rather than more.” “The tragedy is that he’s imposed those views along with a few others to ensure that Australia isn’t taking action.” Labor’s shadow infrastructure minister Catherine King suggested Kelly had been put up for the interview by the government, saying it was “beyond embarrassing”. “I did @BBCRadio4 against him Sunday. The producer said they had asked for a senior government rep and this is who @ScottMorrisonMP thought was the best person to represent his government,” King said on Twitter. But a spokesman for the Coalition said “the suggestion was fanciful” that Kelly had been put forward to represent the views of the government, and Kelly told Guardian Australia he had not spoken to the prime minister’s office before agreeing to the interview request. Kelly had told ITV that the cause of the fire crisis was high fuel loads and the drought, and there was no evidence that climate change was causing Australia’s climate to warm. “This is a terrible disaster, this is one of our nation’s worst natural disasters, and in the past when we have these in our nation we all sat back and did what we could to fix it up, rather than people getting out there and scoring political points and that is what’s happening now,” he told ITV’s Good Morning Britain. “To try to make out as some politicians have to hijack this debate, exploit this tragedy and push their ideological barrow, that somehow or another the Australian government could have done something by reducing its carbon emissions that would have reduced these bushfires is just complete nonsense,” Kelly said. Morgan savaged Kelly for his remarks, saying he was taking a “nothing to see here, nothing to worry about” approach as “your entire country is eviscerated by fires”. “You are facing now one of the greatest crises you have ever faced, and there is you Mr Kelly, with respect, a senior politician who still doesn’t think this has anything to do with a heating-up planet,” Morgan said. Tobin accused Kelly of denying the science which showed that 2019 was Australia’s hottest and driest year on record. “At the moment we want everyone to commit in the world to be one and a half degrees to lower our global temperature rise,” Tobin said. “You can’t even commit to two degrees. “You have the second highest carbon emissions per person on Earth and you are burying your head in the sand. You aren’t a climate sceptic, you are a climate denier,” she said. Cutting off the interview, Morgan said: “I’ve got to say: wake up. Wake up. Climate change and global warming are real and Australia right now is showing the entire world just how devastating it is. “And for senior politicians in Australia to still pretend there’s no connection is absolutely disgraceful.” Kelly also used the interview to defend Scott Morrison for taking a holiday to Hawaii during the bushfire crisis, saying the management of fires was primarily the states’ responsibility. The remarks came after the conservative backbencher appeared on the BBC on Saturday, claiming that there was no link between climate change and Australia’s drought. “There is no link, the facts that cause the fires are the drought and the drying of the environment,” Kelly said. “On this, climate scientists down here have been very clear and they have said there is no link between drought and climate change.” “People here in Australia understand – if they look at the evidence and look at the signs – there is nothing that we can do here in Australia by sending billions more off to China to buy solar panels to replace our coal-fired electricity generators,” he said. “That is not going to change the weather here in Australia one iota and is not going to stop one bushfire.” Speaking on ABC’s Radio National on Tuesday morning, Kelly doubled down on the remarks, saying Morgan did “not want to hear the facts” and arguing that hazard reduction was more important than taking action on climate change. He said people were exploiting the bushfire tragedy “for ideology”, and the cause of the fires was “the dryness of the atmosphere and the landscape”, while rejecting suggestions that the Coalition was home to a group of denialist MPs. “There is no denialist cult,” Kelly said. He also referred to Tobin as a “weather girl” who “had no idea what she was talking about”. “She says the Australia continent is drying out and that is just not true.” Tobin responded to the criticism on Twitter on Tuesday morning, pointing to her degree in physics and meteorology, and her four years’ experience as an aviation forecaster at the Royal Air Force. Yes I’m a Meteorologist-A degree in Physics & Meteorology-4 yrs as an aviation forecaster at the RAF-12 yrs as a broadcast meteorologist-Attended a @WMO Climate course last year & upto date with all the science #NotAWeatherGirl #IKnowWhatImTalkingAbout#DoYou?#ClimateChange https://t.co/fvwTpzftTI The remarks come as Morrison defends the government’s climate change policy, while stressing there is “no dispute” in Australia about the impact of global warming on Australia’s climate. “I have seen a number of people suggest that somehow the government does not make this connection,” the prime minister said. “The government I lead has always made that connection and that has never been in dispute.” Kelly, who established the Parliamentary Friends of Coal Exports for likeminded MPs, has been a longstanding internal critic of government attempts to reduce carbon emissions, and was a vocal critic of the former prime minister Malcolm Turnbull’s attempt to introduce a national energy policy. He has also argued against any government investment into renewable energy, calling for subsidies for households and businesses to be scrapped. After Morrison became leader, Kelly was told to rein in media appearances, particularly on Sky News, where he had become a frequent guest of conservative commentators. Kelly has twice had his preselection threatened but in 2016 Turnbull intervened to prevent a moderate challenging him for the seat of Hughes, and before the 2019 election Morrison also moved to ensure his incumbency was protected."
"It is week nine of the current bushfire crisis; almost 20 people are dead, over 1,000 homes have been lost, half a billion animals have been killed and a land area twice the size of Belgium has been burned. Countless lives have been affected and we know there is more to come. The most important thing right now is to protect as much life and property as possible.  But looking beyond the immediate crisis, we need to start an honest discussion about something none of us want to admit – that these unprecedented, catastrophic fires may indeed mark the beginning of Australia’s new normal. As the world and Australia fail to make meaningful reductions in greenhouse gas emissions, it is clear that we are entering the next phase of climate change – that is, increasingly frequent and severe weather events, occurring in places that have never been affected before. It’s a scary and confronting reality to reckon with; perhaps that’s why some of us find it easier to write off scientists and bushfire survivors speaking hard truths as part of a “climate cult”. Thankfully, our emergency services have chosen not to shy away from the truth, preparing themselves for a horror summer while knowing that they did not have enough personnel, volunteers, equipment or funding to deal with the scale of the crisis. Influential figures in our financial system have also confronted the issue head-on. With worsening extreme weather events sending premiums soaring to the point that some regions are effectively uninsurable, the insurance industry is reviewing whether traditional insurance models can remain tenable. Meanwhile, banks such as NAB are developing “resilience investment” products to assist local governments to build infrastructure such as emergency centres and seawalls. This is encouraging, given the scale of the work needed to ensure local food, energy, water, transportation and communications systems can withstand extreme and prolonged weather events and recover quickly with minimal external assistance. But while some are facing the crisis, there has been a glaring lack of leadership from the federal government on a coordinated plan to support the growing numbers of families, business owners and communities affected by extreme weather. The announcement by the prime minister of a new National Bushfire Recovery Agency and a $2bn package to assist those affected by the bushfire crisis is a step in the right direction. But focusing on relief for this crisis alone misses the bigger picture – this is not a one-off event. We can no longer afford to react to each emergency by drawing on national and state budgets in an ad hoc way. What will happen when the next cyclone hits? Or the next major flood event? And what about the worsening drought? As increasing numbers of people become displaced from regions that are no longer inhabitable, there is an inescapable need for a systematic approach to not only disaster preparation and recovery, but also to building more climate-resilient regions. And to do this, we need much more than reactive measures from government that are propped up by generous donations from the public. Without a doubt, adaptation will be expensive. But not as expensive as the cost of inaction. Of course the billion-dollar question remains: where will the money come from? An obvious place to start the search is at the doorstep of the industry that is the most responsible for climate change: the fossil fuel industry. It is unconscionable that as Australia burns, the taxpayer subsidises this industry to the tune of $1,728 per person per year. What if instead we channelled the $41.8bn worth of fossil fuel subsidies into a transitions fund, to support not only disaster preparedness and relief, but also workers and communities to transition to new jobs and industries? A second option is found in the Australia Institute’s calls for a national climate disaster fund to be established. The Australia Institute’s modelling shows that a levy of $1 per tonne of embodied emissions from all coal, oil and gas mined in Australia would raise approximately $1.5bn per year. Both approaches would go a long way towards addressing the needs of the victims of this climate crisis, while also stopping it from getting worse in the future. What is notable about both approaches is that they place the primary responsibility for funding recovery and adaptation efforts on our elected leaders and the public purse. This crucial process, which will determine our future safety and wellbeing, should not be left to private, debt-driven investment or market forces. To be sure, there is a debate to be had about how much of the cost of climate resilience should be public versus privately funded. Getting the balance right is critical, but we already have existing models such as the Clean Energy Finance Corporation to turn to for inspiration. But however we fund it, the one truth that cuts through the (literal) smoke and mirrors is the fact that we need careful, long-term planning and coordination to ensure that we invest in the systems we need to keep our people, planet and economies safe even as Australia is battered by worsening climate impacts. If our government can show some leadership by listening to the experts and working with different industries to find a way forward, maybe we will come to see climate adaptation as less of a cost and more of an investment in a liveable future. Dr Amanda Cahill is the chief executive of the Next Economy and is an associate at the University of Queensland and the Sydney Policy Lab"
"
Share this...FacebookTwitterCharlatans exposed…when sham predictions clash with reality
Yesterday Japanese blogger Kirye prepared a chart (below) depicting Arctic sea ice volume since 2006, the year Al Gore’s Inconvenient Truth (AIT) was released, and just a year or two before a spate of ice-free-Arctic-by-2013 (or earlier) predictions were issued by a number of “experts”, which of course the fake news media lapped up.

Source: Japanese skeptic blogger Kirye.
Arctic did the opposite of what the experts forecast
As Kirye’s chart above shows, Arctic sea ice volume in reality has since increased since all the doomsday predictions of 10 years ago. The very opposite of what was confidently predicted has in fact taken place.
Same level as in the 1930s, when CO2 was far lower
Naturally the alarmists like using the sea ice extent chart that goes back to 1979, which shows a clear downward trend because 1979 was at a peak for Arctic sea ice.
However, when we look at charts depicting Arctic sea ice since 1900, we see that today’s Arctic sea ice situation is in fact similar to what we experienced some 80-90 years ago:

Chart: Alekseev et al, 2016. 
A false prediction is a false prediction


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




That Arctic sea ice has declined significantly since about 1970 is not the point here. The real story is all the bold predictions of an ice-free Arctic that were made at the time just after AIT was released, and how they all failed resoundingly.
To illustrate the point very clearly, I used Kirye’s plot and added those expert’s predictions so we can see how they all fare compared to reality:

Total failure of the ten-year forecasts made by “experts”. 
Even 10-year forecasts are total failures – can we trust 50-year forecasts?
These “experts” couldn’t even get the forecast for the next 10 years correct. So how are we supposed to take them seriously with their “robust” climate forecasts for the next 20, 50 or 100 years?
The latest idiotic, charlatan quality prediction comes from hockey-stick maker and climate-alarm hustler Dr. Michael Mann, who recently said that Trump’s legacy, beginning in 2024, will be “a charred planet”.
Glaring failure needs to be followed by swift firings
In private industries, where forecasts really count, persons with such a track record of undisputed glaring failure would have been given the boot long ago, and in many cases even sued for outright fraud.
The death spirals and ice-free Arctic predicted for 2013 to 2018 never came to pass. And by ice-free, they implied this would be the case in the later summer year after year.
It’s time for NASA and other climate institutes to clean house and re-staff with serious, competent scientists. As a taxpayer I’m fed up with all the garbage, nonsense and local climate ambulance chasing they’ve been giving us year after year. We the people have the right to get something of value for our money.
And it’s high time we start thinking about suing for fraud.
Share this...FacebookTwitter "
"Moderate Liberals have seized on Scott Morrison’s apparent shift on climate change policy to argue the government will do more to cut emissions, as some conservatives push back against any “symbolism” that could damage the economy. In a sign of the challenge facing the prime minister as he seeks to “evolve” climate change policy, government MPs have split over the prime minister’s comments on the weekend that the Coalition wanted to reduce emissions “even further” than current commitments.  While saying Australia’s 2030 emission reduction targets remain government policy, Morrison said he wanted to do “better” and would only rely on the use of carryover credits from the Kyoto protocol if needed. Australia is the only country relying on carryover credits to meet its Paris 2030 target of 26% to 28% of 2005 levels by 2030, which critics say do not represent the cuts required to limit global warming to as close to 1.5C as possible. Katie Allen, the Liberal MP for the Victorian seat of Higgins, welcomed Morrison’s remarks, telling her constituents that she would be a “strong voice” in the party room for stronger action on climate change. “I’m excited we are starting to move in the right direction – but we have a lot more to do,” Allen told her supporters on Facebook. “I have been and will continue to be a strong voice for Climate Action inside the tents.” When asked if she supported the aim of net zero emissions by 2050 and lifting “clean energy ambitions” in line with the global efforts to keep the world below 1.5C warming, Allen said she agreed more needed to be done. “I’m working on influencing that agenda. We need to have higher ambitions to lead the world in renewables – not just to drive down our own emissions but help other countries with theirs,” Allen said. “We have a diplomatic strength that should be used to help strengthen the global agenda on climate action.” The self-styled modern Liberal MP Tim Wilson also endorsed Morrison’s comments, saying the commitment at the last election to “cut emissions, but not jobs” was a baseline for action. “The prime minister has rightly identified there’ll be more evolution of policy to cut emissions, but not jobs, and I look forward to contributing to that important evolution,” Wilson told Guardian Australia. Dave Sharma, the MP for Malcolm Turnbull’s former seat of Wentworth, said he was “pleased to hear” Morrison’s comments on the importance of responding to climate change and promoted the government’s plan to “continue to evolve our policies with a view to reducing our emissions further”. Does climate change cause bushfires? The link between rising greenhouse gas emissions and increased bushfire risk is complex but, according to major science agencies, clear. Climate change does not create bushfires, but it can and does make them worse. A number of factors contribute to bushfire risk, including temperature, fuel load, dryness, wind speed and humidity.  What is the evidence on rising temperatures?  The Bureau of Meteorology and the CSIRO say Australia has warmed by 1C since 1910 and temperatures will increase in the future. The Intergovernmental Panel on Climate Change says it is extremely likely increased atmospheric concentrations of greenhouse gases since the mid-20th century is the main reason it is getting hotter. The Bushfire and Natural Hazards research centre says the variability of normal events sits on top of that. Warmer weather increases the number of days each year on which there is high or extreme bushfire risk. What other effects do carbon emissions have? Dry fuel load - the amount of forest and scrub available to burn - has been linked to rising emissions. Under the right conditions, carbon dioxide acts as a kind of fertiliser that increases plant growth.  So is climate change making everything dryer?  Dryness is more complicated. Complex computer models have not found a consistent climate change signal linked to rising CO2 in the decline in rain that has produced the current eastern Australian drought. But higher temperatures accelerate evaporation. They also extend the growing season for vegetation in many regions, leading to greater transpiration (the process by which water is drawn from the soil and evaporated from plant leaves and flowers). The result is that soils, vegetation and the air may be drier than they would have been with the same amount of rainfall in the past. What do recent weather patterns show? The year coming into the 2019-20 summer has been unusually warm and dry for large parts of Australia. Above average temperatures now occur most years and 2019 has been the fifth driest start to the year on record, and the driest since 1970. Is arson a factor in this year's extreme bushfires? Not a significant one. Two pieces of disinformation, that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush have spread across social media. They have found their way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. Another moderate Liberal, Jason Falinski, said the party would continue to “drive responsible policy on climate change”. “We need practical and sensible policy here and seek ambitious action globally,” he said. But as moderates welcomed the shift, conservative MPs were warning against a change in policy. The Queensland Nationals MP Llew O’Brien told the Courier Mail that if Australia went beyond its current commitments, it would be “pure symbolism at the expense of the economy”. The former Nationals leader Barnaby Joyce also issued a thinly veiled warning that the government risked a backlash in the bush if it moved to ramp up emission reduction targets. “To the person in the weatherboard and iron, the solution is not: you’ll lose your job and we’ll put up your power prices, because that is not a solution, that is another problem,” Joyce told Guardian Australia. Joyce said the royal commission into the bushfires needed to be “absolutely pragmatic” in its focus, looking at how to prevent a repeat of the crisis without straying to “global” issues. “If it goes off on a path of a macro global view, it will not ultimately bring people together, it will tear people apart,” he said. “Global outcomes must be managed globally.” The divide comes as Morrison insists the role of climate change is “not in dispute” within his ranks, despite several MPs denying the role of a warmer planet as an underlying cause of the severe bushfire season. The Nationals MP George Christensen was the latest to promote his view that climate change was not a factor, telling his supporters on Facebook that climate change is not “a bogey man who can go around lighting bushfires”. “I post this because those who are politicising this tragedy by pushing their extreme green political agenda while the fires still burn absolutely disgust me,” he said. The Liberal MP Craig Kelly last week caused a storm of controversy after appearing on UK television to argue that there was “no link” between climate change and Australia’s drought. Following the appearance, Morrison told his MPs that backbenchers should not do any international media interviews."
"
Share this...FacebookTwitterA new paper documents “remarkably different” land temperatures from one instrumental data set to another. In some regions there is as much as an 0.8°C conflict in recorded temperature anomalies for CRU, NASA, BEST, and NOAA. The relative temperature trend differences can reach 90% when comparing instrumental records. Consequently, the uncertainty in instrumental temperature trends — “0.097–0.305°C per decade for recent decades (i.e., 1981–2017)” —  is as large or larger than the alleged overall warming trend itself for this period.

In a just-published audit of the IPCC-preferred HadCRUT temperature data set, Dr. John McClean identified 70 problems that seriously compromise the reliability and accuracy of this IPCC-preferred instrumental record dating back to 1850.
Joanne Nova provides a summary of the main points from the paper, McLean’s Ph.D thesis.



McLean found freakishly improbable data, and systematic adjustment errors , large gaps where there is no data, location errors, Fahrenheit temperatures reported as Celsius, and spelling errors.


Almost no quality control checks have been done: outliers that are obvious mistakes have not been corrected – one town in Columbia spent three months in 1978 at an average daily temperature of over 80 degrees C.  One town in Romania stepped out from summer in 1953 straight into a month of Spring at minus 46°C. These are supposedly “average” temperatures for a full month at a time. St Kitts, a Caribbean island, was recorded at 0°C for a whole month, and twice!


Temperatures for the entire Southern Hemisphere in 1850 and for the next three years are calculated from just one site in Indonesia and some random ships.


Sea surface temperatures represent 70% of the Earth’s surface, but some measurements come from ships which are logged at locations 100km inland. Others are in harbors which are hardly representative of the open ocean.



Are Any Of The Temperature Data Sets Reliable? 
A new paper published in the Journal of Geophysical Research reveals that the recorded land temperature data from the four most commonly-referenced instrumental data sets — CRU, NASA, BEST, and NOAA — are “remarkably different” from one another.
In fact, the authors find that “for some areas, different data sets produce conflicting results of whether warming exists” due especially to variations in the use of “infilling techniques” — adding artificial temperatures to areas where there are no real-world measurements.
One data set trend can be “nearly 90%” different than another data set trend, which ratchets up the uncertainty to levels that undermine confidence in the overall reliability of the instrumental record.
Excerpts from the paper’s abstract and discussion/conclusion are provided below.


Rao et al., 2018
Land Surface Air Temperature Data Are Considerably Different
Among BEST‐LAND, CRU‐TEM4v, NASA‐GISS, and NOAA‐NCEI
“Several groups routinely produce gridded land surface air temperature (LSAT) data sets using station measurements to assess the status and impact of climate change. The Intergovernmental Panel on Climate Change Fifth Assessment Report suggests that estimated global and hemispheric mean LSAT trends of different data sets are consistent. However, less attention has been paid to the intercomparison at local/regional scales, which is important for local/regional studies. In this study we comprehensively compare four data sets at different spatial and temporal scales, including Berkley Earth Surface Temperature land surface air temperature data set (BEST‐LAND), Climate Research Unit Temperature Data Set version 4 (CRU‐TEM4v), National Aeronautics and Space Administration Goddard Institute for Space Studies data (NASA‐GISS), and data provided by National Oceanic and Atmospheric Administration National Center for Environmental Information (NOAA‐NCEI). The mean LSAT [land surface air temperature] anomalies are remarkably different because of the data coverage differences, with the magnitude nearly 0.4°C for the global and Northern Hemisphere and 0.6°C for the Southern Hemisphere.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“This study additionally finds that on the regional scale, northern high latitudes, southern middle‐to‐high latitudes, and the equator show the largest differences nearly 0.8°C.”
“These differences cause notable differences for the trend calculation at regional scales. At the local scale, four data sets show significant variations over South America, Africa, Maritime Continent, central Australia, and Antarctica, which leads to remarkable differences in the local trend analysis. For some areas, different data sets produce conflicting results of whether warming exists.”
“Our analysis shows that the differences across scales are associated with the availability of stations and the use of infilling techniques. Our results suggest that conventional LSAT data sets using only station observations have large uncertainties across scales, especially over station‐sparse areas.”
“The relative difference of trends estimated from different data sets can reach nearly 90% for different regions and time periods. CRU-TEM4v generally appears to have the largest grid box scale differences, while NASA-GISS has the smallest differences compared to BEST-LAND.”
“The uncertainty of the LSAT [land surface air temperature] trend estimation caused by the data set differences (i.e., RMSD) ranges from 0.035 to 0.086°C per decade for the long-term trend (i.e., 1901–2017) to 0.097–0.305°C per decade for recent decades (i.e., 1981–2017).”
“In developing future LSAT data sets, the data uncertainty caused by limited and unevenly distributed station observations must be reduced.”

Image Source: Rao et al., 2018
Share this...FacebookTwitter "
"Ordinary citizens have become increasingly important to scientific research over the past decade. Today, mobile phone technologies, relatively cheap cameras and almost ubiquitous internet connectivity have opened up new opportunities for conservation organisations to engage with ordinary citizens and encourage citizen science.  A citizen scientist is a volunteer who collects and/or processes data as part of a scientific enquiry. This could mean noting the plants found on a day trip or more systematically recording wildlife in a special area. While citizen science projects can be in any branch of science, my focus is on wildlife research. The list of citizen science projects is long. This year’s BBC Springwatch, which concludes this week, has highlighted a number of mass participation projects in which people can become involved, such as recording the first signs of spring. All such schemes are predicated on the idea that people will go out and report what they see. But technological advances are also changing the way that professional scientists collect and record data on animals. These changes often require specialised equipment and resources beyond the scope of most amateurs. Now that new technologies are changing the working practices of professional ecologists, what does this mean for citizen science? Until recently, the way to ascertain the presence of great crested newts in a pond was to go and look. Because the newt is a protected species, disturbing it is illegal. But just looking for the adults or their eggs is not. Today, however, finding great crested newts and other aquatic animals can be done using environmental DNA (eDNA). DNA is released into the water by plants and animals in a host of ways: from their skin, faeces, mucous, hair, eggs and sperm, or when they die. By simply collecting and analysing a water sample from the pond or stream, we can find traces of eDNA and identify the animals living there, even if they are hard to recognise.  DNA barcoding allows species to be identified using short genetic markers in an organism’s DNA.  And actually, these barcodes can be obtained from tiny amounts of tissue even by non-specialists. All that is required is the correct DNA processing and sequencing technology.   Genetic identification is not the only way in which technological advancement is changing the way that we record the species around us. Noting the birds in a woodland is more often than not a case of listening and identifying the songs rather than seeing the birds themselves. Eco-acoustics or soundscape ecology studies the relationships between animals and their environment based on sound. There are now technologies available that allow birds and amphibian communities to be identified from sound recordings. This means that it will soon be possible to place an audio recorder in the field and walk away while it records birdsong and other sounds over an extended period of time. The aim is that the recordings can be analysed automatically using software to draw up a species list for that area. But if the collection of wildlife data is to reveal useful information, it needs to be done systematically. Recording the presence of a wildlife species only tells you that it was there at the time that it was recorded. To spot trends, the recording needs to be repeated in the same way over a number of years. This can be difficult when relying on volunteers, but it is not impossible and there are many good examples of systematic surveys, but these are mainly carried out by people with a little more than basic knowledge. In fact, technology is now progressing to the point that it can do the work of a specialist on behalf of any citizen, helping to standardise measurements and carry out complex analysis instead of just simple observations. For example, a new app enables visitors to the New Forest to search for cicadas - last sighted in the forest in 2000 - by analysing sound recordings of background noise captured with a mobile phone. It’s not hard to imagine similar projects asking people to collect and study samples of eDNA or make regular recordings of the dawn chorus using easily available tools. Mass recording of wildlife sightings such as those requested by the BBC and the Mammal Society are not simply about recording wildlife for scientific enquiry. They are about individuals, couples and families going outside, exploring and connecting with their environment. Discovering what is there and being part of a larger group of people. It is about making new discoveries together.  But with new technologies, the details of citizen science will change. Future technological advances will present new ways to continue our long established heritage of amateur natural history."
"Global engineering company Siemens will not pull out of a contract at the new Adani coalmine in Australia, rejecting calls from climate campaigners including Greta Thunberg. President and CEO of Siemens, Joe Kaeser, announced Monday that after reviewing the rail signalling contract the company had “a legally binding and enforceable fiduciary responsibility.”  He said: “While I do have a lot of empathy for environmental matters, I do need to balance different interests of different stakeholders, as long as they have lawful legitimation for what they do.” He said the company, based in Germany, “should have been wiser about this project beforehand” and claimed had it been his own company, he may have “acted differently”. He added that the company “fundamentally shares the goal of making fossil fuels redundant to our economies over time”. Campaigners said the decision was “shameful” and would damage its reputation and undermine its own climate policies. Siemens says it is one of the first companies to have pledged to be carbon neutral by 2030. The decision on the contract, reportedly worth $30m, comes as Australia is in the grip of an unprecedented bushfire crisis that has claimed at least 27 lives, destroyed more than 2,000 homes and likely pushed several species towards extinction, scorching millions of hectares of unique habitat and killing more than a billion animals. Explaining his decision, Kaeser said he was assured by a December 2019 letter from Resources Minister Matt Canavan that the mine, in Queensland’s Galilee Basin, had passed all legal obstacles. Just finished our extraordinary Managing Board Meeting. We evaluated all options and concluded: We need to fulfil our contractual obligations. Also, we will establish an effective Sustainability Board to better manage environmental care in the future. https://t.co/uPgjPgwFrr Canavan wrote to Kaeser in December with a plea “not to be intimidated by the noisy anti-coal minority targeting the Adani Carmichael mine project and companies providing services to it.” He wrote: “If the protestors achieve their goals of ending coalmining by bullying companies into submission, the result would be millions more people without a home, without access to electricity and without as much hope as they otherwise could have.” In the statement, he said the project was also “approved” by the indigenous Wangan and Jagalingou people which was “very important to us”. That approval is strongly disputed by a group of Wangan and Jagalingou people. Adani took court action to prevent that group, led by Adrian Burragubba, from setting up camp on the land. The Queensland Government in 2019 extinguished native title over Wangan and Jagalingou to enable the mining project to proceed. Kaeser said he was personally “moved” by messages from Australians who had “described that their homes and their country is burning and suffering from these terrible fires”. The Adani coalmine will extract an initial 10m tonnes of thermal coal per year from a site 300km inland and transport it along a railway line to Adani’s Abbot Point Port for export. Kaeser said there were competitors to the railway signalling contract the company signed on 10 December 2019, which meant “whether or not Siemens provides the signaling, the project will still go ahead”. Last week Swedish climate activist Greta Thunberg said Siemens had “the power to stop, delay or at least interrupt the building of the huge Adani coalmine in Australia” and people should push the company “to make the only right decision”. It seems that @SiemensDE have the power to stop, delay or at least interrupt the building of the huge Adani coal mine in Australia. On Monday they will announce their decision. Please help pushing them to make the only right decision. #StopAdani Greens leader Richard Di Natale had also written to Siemens, and warned the company risked “reputational damage” over the deal. Galilee Blockade spokesperson Ben Pennings said: “Siemens has just trashed their billion dollar reputation for a $30m contract. Their reckless indifference to the suffering of Australians will be judged harshly, now and in the history books.” “Siemens’ expertise is vital to the Adani coal railway and there is too much at stake to give up. Citizens will escalate their protests until Siemens listens to the science and choose the right side of history. “Adani will never have social licence to build a new thermal coalmine in Australia. Our challenge is to turn this discontent into civil disobedience powerful enough to overcome any government repression.” Australian Conservation Foundation senior campaigner Christian Slattery said the Siemens announcement, “while bushfires rage in Australia, is nothing short of shameful”. He said: “The company has shown its true colours with this decision. It has a climate change policy, but it is hollow and empty. Sadly, Siemens has shown it is no better than the fossil fuel companies it works with.” The Galilee Basin has been identified as one of the largest untapped sources of coal in the world, and campaigners and scientists have warned the Adani mine will open the way to several other coal mining projects in the region. Slattery added: “If constructed, the infrastructure for Adani’s mine will open the Galilee Basin to one of the largest expansions of thermal coal mining on the planet. “Siemens claims to support the Paris Agreement, but now it is committed to work on one of the world’s biggest carbon bombs.” “The unfolding bushfire crisis in Australia, which has killed at least 28 people and more than one billion native animals is a terrifying foretaste of the climate change future if more coal mines are dug.” An Adani spokesperson said: “We are pleased to be working with Siemens as the company is known for its exceptional experience in building rail signalling infrastructure around the world. “With construction of the Carmichael Project well and truly under way we have repeatedly demonstrated that we will not be intimidated or deterred from delivering on our promises to regional Queenslanders, Australians and people in developing nations who desperately need affordable energy to help lift them out of poverty.”"
"The average carbon dioxide emissions of cars sold in the UK rose for the third year in a row during 2019 as falling diesel sales and the rising popularity of SUVs dealt a blow to Britain’s hopes of reaching climate targets. Average CO2 emissions rose for the third year in a row, up 2.7% year on year to 127.9g of CO2 per kilometre, according to data from the car industry body. This is far above the newly introduced EU target of 95g per kilometre carmakers need to achieve over this year and next for all new cars. Cars account for just over 18% of UK emissions, according to government figures. Transport emissions as a whole account for a third of the UK total, with the sector viewed as vital contributor if the country is to achieve goals of cutting emissions to 51% of 1990 levels by 2025 and to reach net zero by 2050. All manufacturers selling in the EU are rushing to meet emissions regulations that came into force on 1 January. The regulations were introduced in response to the climate crisis, with road transport a major contributor to global CO2 emissions. Overall UK car sales fell by 2.4% year on year to about 2.3m, according to the Society of Motor Manufacturers and Traders, with the industry body blaming Brexit uncertainty and the slump in diesel sales as the main factors. This indicates the worst year for the UK market since 2013, when sales were 2.26m. They reached a peak of 2.7m in 2016 but have declined steadily since. A quarter of the CO2 increase was caused by the 21.8% drop in diesel sales over the year. Newer diesels on average have lower CO2 emissions than petrol cars, despite a backlash prompted by air quality concerns. Another quarter was caused by increased sales of SUVs, which are often heavier and have much worse aerodynamic profiles than smaller cars. Increased fuel use by SUVs was the second largest contributor to the increase in global CO2 emissions from 2010 to 2018, according to the International Energy Agency. The other half of the headline CO2 increase was caused by a change to testing standards. Mike Hawes, the SMMT chief executive, acknowledged the CO2 figures showed the challenge facing the industry. He said: “The step change that is required is significant.” Under the EU regulations, carmakers face fines potentially running into billions of euros across the UK and the rest of Europe if they surpass individual limits designed to ensure that average fleet emissions hit the 95g target.  One bright spot in an otherwise declining market was the rapid increase in sales of battery electric vehicles, which have zero CO2 tailpipe emissions, and hybrid vehicles, which combine an internal combustion engine with a battery-powered motor. Annual sales of alternatively fuelled vehicles rose by 20.6% to a record market share of 7.4%. That was driven by the surge in battery electric sales, which were up by 144%. However, sales of battery electric vehicles would need to rise from the 1.6% market share for 2019 to 27% to hit the 95g target alone, according to the SMMT’s calculations. Hawes repeated his industry’s plea for a post-Brexit trade deal that preserves frictionless trade between the EU and the UK, and that prevents the imposition of tariffs. He added that Brexit uncertainty remained his number one fear for the industry. “Undoubtedly consumer confidence around our big-ticket items is weak,” said Hawes, speaking at a briefing in London before the publication of the final figures."
"
Share this...FacebookTwitterAs Germany moves to phase out coal power, more focus is being placed on relying on wind energy to fill in the gap.
Recently German business daily Handelsblatt here reported that despite the country adding more wind energy capacity, “the latest figures show that only a little wind power is available at any time.”
According to the German BWE wind energy group, 29,900 wind turbines are currently operating in the country with a total capcity of 56,000 megawatts. Wind energy makes up 18.8% of the country’s power supply.
Glaring weaknesses
But the Handelsblatt reports there are “glaring weaknesses” and that wind turbines cannot be relied on to deliver steady power when it’s needed.
According to Oliver Then, Managing Director of the VGB PowerTech Association, citing recent research results which the Handelsblatt has obtained: “The actual production figures show that the readily available wind power capacity in Germany is less than one percent of installed capacity.”
Back up absolutely necessary
According to the Handelsblatt, VGB PowerTech evaluated 2016 data from a number of European countries, and reports that the message is clear:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Even if the expansion of wind power progresses rapidly, there will always have to be back-up capacity, for example in the form of fossil power plants.” 
VGB Director Oliver Then says that as more and more green energies get fed in, the less gas and fossil fuels plants operate, and thus making them no longer profitable. Yet they remain absolutely essential to keep the grid stable.
Can rely on neighboring countries?
Proponents of green energies who support a rapid fossil fuel phaseout insist that it can be done, and that Germany would only need to rely increasingly on a power supply from neighboring countries. When the wind is not blowing in Germany, power could be imported from another country where the wind is blowing.
But VGB Director Oliver Then says the data do not support this claim in any way, adding, “Power production is strongly synchronous over great distances.”
This means that if wind lacks in Germany, it often lacks in Poland as well and so neighbors cannot be relied on to provide electricity.
Pump storage not feasible
Pump storage as a way to store energy is also not feasible says Then, saying it would need to be increased 1000 fold, which would entail enormous costs. Then notes that periods of no wind extending two weeks are not uncommon in Germany.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterEarlier this year in Ljubljana, Slovenia, acoustics and health expert Dr. Mariana Alves Pereira explained the impacts low frequency infrasound can have on health. It’s far from pretty.
Infrasound is very low frequency (<20 Hz) and is below the threshold of human hearing. It is sensed by the human ear only as pressure waves.
Hat tip: Reader Jim Feasel
Dr. Alves Pereira has a Masters in Biomedical Engineering and a PhD in Environmental Sciences.

“It’s a problem to human health”
In her presentation she explains to the audience that because infrasound is of very low frequency, the wavelengths are very long and thus can easily penetrate thick barriers and into buildings. “This is why it’s a problem to human health.” The waves travel kilometers and are difficult to shield against.
Governments rely on inadequate measurements
The acoustic expert also describes why the dBA scale is inadequate for measuring infrasound and thus are irrelevant for their evaluation.
At the 12:30 mark she uses the example of a mink farm in Denmark located near a wind park and so is thus subjected to “acoustic pollution” from the wind turbines. Here she demonstrates how woefully inadequate the methods and measurements often used by permitting authorities for assessing acoustic pollution really are.
Neurological and cardiovascular damage


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Later she illustrates how damaging infrasound can be to human health. For example aviation workers have a risk of epilepsy (a neurological problem) that is some 50 times higher than average (22:00) for the occupation and how workers had tumors, and cardiovascular disease from abnormal tissue growth caused by infrasound exposure.
At 33:09 mark, Dr. Alves Pereira presents the clinical stages of vibroacoustic disease for occupational exposures. Workers exposed to infrasound more than 10 years developed severe health damage, e.g. psychiatric disturbances, severe joint and muscle pain, blood in the urine or decreased vision, among others.
Horses near wind turbines developed “boxy foot”
At the 43:00 mark, Dr. Alves Pereira explains how at first they were skeptical of claims made by patients that infrasound had made them sick while at home. In 2000 her team began to look at the claims and found that non-occupational residents who were subjected long-term to infrasound indeed got sick.
At the 48:08 mark, Dr. Alves Pereira turns her attention to wind turbines.
In one example, in Portugal 4 wind turbines were installed within 800 meters of a home and began operation in November, 2006. Five months later in March 2007 the family members in the home were suffering serious health issues and the boy’s performance at school crashed. His energy had been sapped. The horses the family owned developed “boxy foot”.
Moreover, the previously mentioned mink farm in Denamrk suddenly saw hundreds of aborted fetuses (53:30), all caused by infrasound from the nearby wind turbines, experts suspect.
Post traumatic stress syndrome
At the 56:00 mark, Dr. Alves Pereira shows a home in Germany surrounded on two sides by wind turbines located less than 2000 meters away. When the family moved into the home, there had been only two turbines, but then came dozens of new turbines. The family was forced to convert into a bunker in a desparate attempt to shield themselves.
In Ireland a 9-year old child developed epilepsy and the 19-year old brother wound up with post-traumatic stress syndrome (PTSD) – as did the worker at the mink farm in Denmark. The house in Ireland had to be abandoned.
Dr. Alves Pereira sums up: “I know it’s kind of depressing, but these are the scientific facts what we have over 30 years of research.”
Share this...FacebookTwitter "
"If global temperatures are allowed to rise by 2℃, we face creating a “Hothouse Earth” that would shift the planet to an irreversible state, a recent research paper warns. This has provoked a global frenzy in social, news and print media reminiscent of the planetary emergency professed by Al Gore a decade ago. Only this time climate scientists, and not politicians, are the ones causing the storm.  The research is compelling, but the arguments are hardly new. We’ve long known that Earth systems require extensive human intervention, that nature will not redress the balance itself. We already know of the planetary boundaries and, thanks to our unsustainable practices, how crossing certain thresholds of natural resources (fresh water, land use, and biodiversity loss) and environmental variables (atmospheric aerosols, biochemical flows and ozone depletion) could lead to tipping the Earth’s systems out of balance. Nonetheless, the idea of Hothouse Earth has taken off. This is a good thing in terms of raising awareness and triggering global concerns and subsequent actions for integrated climate governance. But such accounts often fail to consider the political climate of the day. 


      Read more:
      Hothouse Earth: here's what the science actually does – and doesn't – say


 Ongoing austerity measures in the aftermath of the 2007-08 financial meltdown mean that states are divesting from their responsibilities on welfare, making way for supposedly “caring” forms of market-based mechanisms. Short-term policies of “doing more with less” have also affected civil society as many organisations that rely on government funding are either disappearing or struggling to sustain their causes.  Meanwhile, this research could not have come at any better (or worse) time with the prolonged spells of heatwaves around the world. And studies suggest that public perceptions of environmental hazards fluctuate with the proximities and experiences of climatic events.  But if not carefully interpreted, claims of doom and gloom scenarios can polarise public and political opinions. Much scientific research of this ilk, and certainly the vast majority of the media coverage about it, fails to appreciate the potential of individual people in tackling environmental issues. The same is true of many politicians, who consider environmental sustainability too serious a task to be trusted to people.  As a result, communities - although recognised as vulnerable to the effects of disappearing forests, warming oceans and melting ice sheets - remain absent from the decision-making processes and the proposed solutions. But community-based actions can be incredibly powerful, when harnessed.  There are various meaningful actions and initiatives that can be spearheaded by people in their communities. And in this time of political disengagement from the issue, it’s more important than ever that we do so. While 1% of us may be able to consider their options for relocating to more hospitable places on Earth (Silicon valley billionaires are buying up property in New Zealand), or relatively less hospitable locations on the moon and Mars, the others will have to do something, now.  Among the steps that can be taken immediately, you could consider: Not just attitudes and behaviours, we need to reconsider how we live our everyday lives. As we become more knowledgeable about the state of nature in our surroundings with deteriorating air, soil and water conditions, we need to think about changing the way we our families and our friends are contributing to the environment. Opt for an organic or vegetarian diet, support Fairtrade, and purchase locally sourced goods where you can. Growing fruit or vegetables in your front or back gardens, or in pots indoors, will not only liven up your living space and provide you with fresh, local produce. The increased photosynthesis increases carbon sink and contributes to reducing greenhouse gases. Even more so, do it as a community. Many local authorities are now encourage the greening of the abandoned lands and derelict areas.  Or better still, start one. Transition Network is a good example of actions based on voluntary individual and collective participation. It began as a permaculture movement to reduce fossil fuels dependence, growing own food, sourcing locally, and promoting social inclusion. Today it is one of the largest community-based networks, with presence all over the world. Many towns and cities are now promoting different kinds of bike ride or sharing schemes. Sustainable transport solutions can help decrease car dependence besides reducing carbon footprint. Citizen science is increasingly becoming a valuable way of community-sourced and voluntary participation and research in all scientific disciplines. Contributions from everyday lives of citizens help scientists get out of their silos and find better solutions to complex and wicked problems. Most of the political parties on a broad range of spectrum now understand and support the need for sustainable and healthy lifestyles to make our places better in social, economic and environmental terms. But political agendas are a reflection of what people demand. And what better way to empower ourselves than to use our voting rights responsibly? Local and national governments are committed to improving the environment. Many towns and cities have signed up for the Covenant of Mayors, voluntarily agreeing to reduce emissions and using sustainable energy sources. Surprisingly, not many countries have sufficient legal structures in place for climate action. Among national strategies, the Well-being of Future Generations Act in Wales is often quoted as an exemplar of good policy and practice."
"
Share this...FacebookTwitterA wave of media hysteria has been unleashed by the recent hot and dry “Sahara” weather Europe has seen over the past few weeks. Cries to shut down the coal power plants and to adopt vegan diets have reached peak volume!
ARD Fake News: “CO2 causing lung disease”
The neurosis has gotten so bad, that flagship German media have been reporting new breath-taking claims.
For example Germany’s version of the BBC ARD German public television, here claimed that CO2 is not only “killing the climate”, but is also even “causes lung disease”!
NBC’s Al Roker: Warming now causing less hurricanes!
In the US, NBC meteorologist Al Roker here did have some good news: Global warming is now causing less hurricanes (and not more): The melting Arctic ice is cooling the Atlantic, which works against the formation of hurricanes, he claimed.
Unfortunately that “information” from Mr. Roker has turned out to be really fake. Expert meteorologist Dr. Ryan Maue even called Roker’s outlandish claim “cringeworthy”.
“Not heat problem, rather hysteria problem”
But among the cacophony of hysteria emanating from the global fake news construct, there have been a few remaining voices of sanity – fortunately.
For example journalist/lead commentator Torsten Krauel of Germany’s flag ship national daily Die Welt here wrote an opinion piece titled: “Germany doesn’t have a heat problem, rather it has a hysteria problem.
In the opinion piece Krauel writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




There have been many hot summers, as well as rainy cool ones. Germany does not have a heat problem, and a look at the past shows this.”
Krauel then reminds the amnesia-prone German readers of the hot spells of the 1990s, or 2006, 1983, 1975, 1963 and 1958 as examples, where periods of heat and/or extreme drought also occurred.
Indeed according to Swiss meteorologist Jörg Kachelmann, July 2006 was much warmer than July 2018, by 2°C.
Going vegan our only hope
Die Welt’s Krauel adds with sarcasm:
But over 2018 in some places they complain like end-of world preachers. It is the largest anomaly since records have been kept. Water will be in short supply, Sea level is rising. Become a vegan, otherwise it will continue like this.”
Cold front erases the hysteria
In the meantime, a cold front has passed through the continent, thus dislodging the blocking high behind the unusually summerlike weather which many had been enjoying.
Central European temperatures today as of 1 p.m. ranged only from the low sixties to low seventies Fahrenheit.

Chart: Kachelmannwetter.de
It won’t be long before we start hearing complaints about all the cool and damp weather and longings for summer.
Share this...FacebookTwitter "
"Lemurs are cute – there is no denying it. Their big eyes and fluffy faces mean they really are the poster animals of Madagascar, an island known internationally for its unique flora and fauna. But the plight of Madagascar’s lemurs has made international headlines once again after experts warned the animals may be entirely extinct in the wild within 25 years.  The BBC showed gorgeous images of lemurs juxtaposed with the sad fact that nearly all of the 106 identified species of lemur are threatened. These stories appear in the international media with depressing frequency. Those not closely involved might wonder why, if lemurs are so special, they have not been properly protected yet. Surely Madagascar can’t afford to lose its lemurs and the world can’t just stand by and watch it happen?  Unfortunately, conservation is far from easy to achieve. The problems facing lemurs in Madagascar are a microcosm of the challenges of tropical forest conservation throughout the world. Madagascar’s forests and their lemurs are primarily threatened by agriculture. We are often told that Madagascar has lost 90% of its forest, and that rural people clearing land for agriculture are the problem.  Unfortunately, like many things, the truth is rather more complex. This narrative underplays the role of colonial era and commercial land conversion, and overplays the destructive nature of the traditional land use system.  Malagasy farmers traditionally cut then burn patches of forest and farm them for a few years, before leaving the land fallow to regain fertility. This isn’t a story of terrible people destroying their lovely pristine forest – such “shifting agriculture” (known locally as tavy) can be perfectly sustainable at low population densities. Pressure comes from Madagascar’s booming population. As the numbers living in rural areas increase, people clear the same land more frequently, soil fertility drops and the land becomes degraded and of little use for either agriculture or lemurs.  Deforestation also releases carbon dioxide into the atmosphere, contributing to climate change (in fact many would be surprised to know that land use change is the source of between 7% and 14% of the world’s emissions of greenhouse gases). With this in mind, it seems that forest conservation really should be a no brainer: it is good for the planet, good for biodiversity (remember those lovely lemurs) and, since shifting cultivation can be unsustainable anyway, people would be better off doing something else.   This is the thinking that underpins the proposed international climate mechanism REDD+ (Reducing Emissions from Deforestation and Degradation), in which poor tropical countries such as Madagascar get financial incentives to reduce their deforestation and so contribute to global efforts to slow climate change. So would REDD+ finally solve the problems of tropical forest conservation (and save those lemurs)? Unfortunately many challenges remain. A significant one is how the funds will be used to actually slow deforestation? In Madagascar the funds from REDD+ pilot projects have been used in part to fund community forest management: where legal management responsibility for forests is transferred to communities. Recent research from Madagascar provides some evidence that this can indeed slow deforestation but it is far from a panacea. A review of community forest management interventions around the world found there is limited evidence that the approach can deliver the hoped-for environmental, or local welfare, benefits.  To be successful, any project aiming to reduce deforestation will need to ensure that farmers at the edge of the forest do not lose out. This is vital both from a pragmatic perspective (if people don’t have alternatives they will have no option but to continue with existing land-use practices, however damaging) and from the perspective of environmental justice and human rights.  Key questions remain about how benefits from REDD+ payments will be distributed locally – the question of whether resources will be sufficient to compensate for lost livelihoods – and how the rights of those affected will be protected. There has been recent criticism that international commitments to these social safeguards in the REDD+ mechanism are too weak. Bruno Ramamonjisoa, a professor of forestry at the University of Antananarivo in Madagascar told me that: “Madagascar’s lemurs, and their forests, are a vital part of our natural heritage. However, forest conservation in Madagascar will only be successful if the people dependent on forests, and their needs, are fully incorporated into conservation plans. Those developing the REDD+ policies must understand the real challenges facing forest-edge communities in Madagascar”.  It is expected that REDD+ will be approved at the major climate summit in Paris later this year and this may well unlock funds for forest conservation in Madagascar in future. However the threats to lemurs will not be easily solved – and the real threats to people sharing habitat with lemurs, must not be ignored."
"
Share this...FacebookTwitterThe weather models are all now pointing to wintry weather pushing into Europe next week, after a year of near record warm temperatures. Is a cold winter in store?
German skeptic weather and climate blogger Schneefan (Snow Fan) here writes that the winter most likely will be starting early this year, but it remains a question if the colder, more wintery conditions will persist throughout the winter.
The current low solar activity favors it will, as studies show Europe’s winters turn harsher when solar activity is quiet. Over the past few days, the models have been in agreement in showing that cold wintry weather is approaching in the days ahead.
Schneefan writes that the big 3 weather models ECMWF (Europe), GFS (USA) and GEM (Canada) have all been projecting the same development:

Shown above are the prognoses dated 10 November, 2018, from ECMWF (Europe), GFS (USA) and GEM (Canada) for the 20th of November. Source: Wetterzentrale
Yesterday the three models forecast the following for November 19:

Source: Wetterzentrale
The stratospheric models from ECMWF und GFS also point to an early wintery weather pattern change, with a large trough extending over the entire Mediterranean and an extensive high over Scandinavia and Northern Russia:

Comparison of the ECMWF (150 hPa, 14 km altitude) and GFS (100 hPa, about 16 km altitude) prognoses November 20. This unusual large weather pattern signifies a change in the wind patterns and favor cold Russian air moving over Europe . If the models are right, it would mean an early start for winter in Europe. Source: ECMWF and GFS.
WO/GFS already foresees frost for Eastern Europe this weekend:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





 

Snow is also forecast to spread across large regions of eastern Europe early next week:



Large parts of Germany and Europe could see snow cover at the end of November:

Schneefan writes that the conditions could be similar to those seen in the winters of 2005/06 and 2010/11. One reason, Schneefan writes:
We now find ourselves in a multiple-year solar minimum of weak solar cycles that is the weakest in the last  200 years.
Just recently the GFS06 showing a northern position (Greenland/Atlantic blocking) and further massive winter invasions from the north on November 29, 2018.

So while Europe may be enjoying agreeable mild weather for now, models show that it may very well end abruptly. Preparations for winter should be done over the coming days.
Global warming eliminating snow and ice remains a myth. Soon expect to hear warmist scientists claim the cold is due to the warming causing polar vortices. Don’t buy the nonsense. It’s BS science.
The truth is that this is just winter as usual, and the climate has not really changed that much.
Share this...FacebookTwitter "
"There is still time to donate to the Observer and Guardian climate emergency charity appeal, which has raised more than £875,000 for projects designed to plant, protect and renew trees, woodlands and forests. More than 11,000 readers have so far given to the appeal, which promotes environmental and social justice through natural climate solutions, from safeguarding rainforests in the Amazon basin to rewilding the Scottish Highlands and greening Britain’s towns, cities and countryside. The appeal closes at midnight on Sunday 12 January.  The four charities supported through the appeal are: Woodland Trust, Trees for Life, Trees for Cities and Global Greengrants Fund UK. David Elliott, chief executive of Trees for Cities, said: “We are inspired and humbled by the amazing level of engagement that readers have shown for this appeal. Their support will significantly help our organisations create a landscape shift – in more than one sense – that is so urgently and vitally needed. Restoring and protecting our natural environment is one of the most effective actions we can take to push back against the escalating impacts of the climate crisis.” Cristina Orpheo, of Global Greengrants Fund’s local partner in Brazil, CASA Socio-Environmental Fund, said: “Many thanks to all who responded to the Guardian and Observer charity appeal. The funds designated for Global Greengrants Fund and its partners will be used to support traditional communities and improve their living conditions so that they have a better chance of promoting the preservation and protection of this great biome for future generations.” Scores of donors have left online messages explaining why they gave to the appeal. Many said it was to signal their frustration with governments’ failure to take the climate crisis seriously, and the slow institutional political response to what they considered to be the most important issue facing the planet. One reader said: “At a time that feels very bleak, these projects not only offer some comfort, but powerful examples of how we can overcome our individual despair and seek to build a better future together.” • The appeal ends at midnight on Sunday 12 January. Readers can donate online here or send a cheque (payable to the Guardian and Observer charity appeal 2019) to: The Guardian and Observer charity appeal 2019, Charities Trust, Suite 20-22, Century Building, Tower Street, Liverpool L3 4BJ."
"We’ve all seen reports on TV: queues round the block, makeshift camps, furtive checking of watches, and the rapturous applause on the opening of the doors. Such is the clamour for new “must-have” technology. While I admire the leaps forward in mobile technology we’ve witnessed in the last decade, this rush for new devices is having a devastating effect on the environment. We must acknowledge this and deal with the problem if we are to continue to enjoy our planet as much as we do our new mobile lifestyles. Although individual phones are small, containing relatively little material, collectively the numbers are substantial. There are at least an estimated 85 million unused phones in the UK alone, each manufactured using gold, copper, silver and other precious metals which, if not recycled, must be extracted from the ground.  This adds up. These unused phones contain approximately four tonnes of gold, lost resource that would cost £110m and an equivalent of 84,000 tonnes of CO2 released into the atmosphere to replace. It is even estimated that phones contain more gold per tonne than ore mined from South Africa’s famous mines. My colleague Jacquetta Lee and I recently published research in the International Journal of Life Cycle Assessment, focused on the environmental impact throughout the lifecycle of mobile devices, from manufacture, use and disposal. We concluded that the current mobile phone business model, driven by volume of sales and frequent upgrade cycles, is costing the environment. The problem occurs when the upgrade cycle is shorter than the phone’s useful lifetime. Although mooted to be three years or more, phones are often replaced much sooner. Many are replaced through “free” contract upgrades. That itself would not be such an issue if they were returned for reuse or recycling. But consumers are wedded to the ability to communicate, so they often keep the replaced phone as a spare in case the new one breaks or is lost. It hibernates and languishes there until it is truly obsolete, when it has no value for communication or monetary worth for resale. Recycling metals from phones is currently not a profitable business, so there is little incentive to return the phone. All too often it can end up in landfill; the metals are lost and must be replaced by mining virgin ore. Given that the majority of a phone’s environmental impact occurs during manufacturing there is strong incentive to reduce the number of phones made each year, extend their working lifetime and if possible make them less complex. It needs a new business model, and there may be an alternative. We are now looking in to the possible benefits of a “cloud-based product service system”. Here, the heavy processing and memory storage of mobile devices are moved to a remote server, over the internet. With less need for powerful components, mobile devices could be less complex, designed to last longer and require less valuable resources to make.  The consumer buys the ability to communicate and access to the powerful processing of the server. This is accessed by a handset leased to them by the service provider. That provider then has incentive to ensure the device is used for an appropriate length of time before being returned for a new one. The valuable metals are recovered and components could be reused. This cloud model has been used already in the PC world, where replacing power-hungry desktops with thin client computers that run off the cloud, with less hardware, has reduced power consumption by up to 55%. But there are of course other challenges to overcome.  We need to work out how to implement such business models whilst convincing consumers that cloud services can be trusted to deliver high performance, and hold data privately and securely. Are you ready to move your phone’s entire photo collection into the cloud? In the meantime more work needs to be done to encourage recycling. From discussions with companies involved in phone returns, it is apparent that often even sending a prepaid envelope to the consumer for the old phone, to be dropped into the nearest letter box, is not incentive enough.  Recycling may be encouraged by something as intangible as benefit to the environment, but that is a low incentive at present. It will become large enough when the environmental value of recycling the phone translates into the price of the metals in them becoming high. It’s a big question and one that will not be answered easily. What is encouraging however is that manufacturers are acutely aware of the issues and open to ideas for change. In the meantime consumers need to face reality; that our lifestyles do not exist in a bubble. The choices we make now will affect our planet sooner than we realise and at some point the bubble will burst."
"Comparisons have been made between summer 2018 and Britain’s record breaking heatwave of 1976, which is often hailed as being unprecedented for how hot and dry it was. June 2018 has not only been the hottest since 1976, it is one of the driest on record. For those that love the summer sunshine and see rain as the source of a washed out BBQ, this is welcome news. But 1976 was also famous for the drought that left fields brown and made life extremely difficult for farmers, ultimately affecting the country’s food supply. A closer look at the conditions in 1976 shows why farmers (and shoppers) today are likely to be better off in the face of a prolonged, extremely hot and dry summer. Certainly, widespread reports of crops wilting in the heat has raised concerns that there could be widespread food shortages. For example, vegetables like broccoli, cauliflowers and notably salad crops like lettuces have already been affected. There are also fears that there may be a shortage of potatoes (and in turn crisps) due to a combination of the cold weather that affected Britain earlier in the year and the current heatwave.  June 1976 brought vegetable shortages and astronomically high prices for some items, particularly for potatoes. The year is also remembered because the Labour government at the time was forced to introduce food subsidies in a desperate attempt to keep down the cost of living. Official files held at The National Archives, contemporary reports and the farming press reveal the devastating impact the drought had on agricultural production, as well as the extent to which shortages led to a rapid increase in prices.  Potatoes are shallow-rooted plants which are sensitive to even small deficiencies of water in the root zone. When moisture stress occurs, as evidenced by the wilting of the leaves, the growth rate is significantly reduced, which in turn affects both their quality and yield. In the 1970s, unlike today, irrigation was limited to a small number of farmers. Potato crops were therefore subject to severe water shortages, which led to very slow growth, particularly for those crops being grown on more drought-prone lighter soils. So, while the dry winter of 1975-76 had enabled potatoes and horticultural crops to be planted early, the ground was already suffering from a moisture deficit. In 1976 although many food prices rose significantly, the increases were dwarfed by the exponential rise in the price of potatoes, with production down by approximately 40%. Given the relatively constant demand for potatoes by mid to late winter, prices were six times higher than what they were in a normal season. But price hikes of this magnitude are less likely to occur today. British consumers are not as dependent on potatoes as a staple item of their diet as they were in the 1970s due to the availability of alternative starchy foods like pasta and rice. Today farmers are better able to irrigate their crops, enabling them to mitigate some of the worst effects of the present exceptionally dry conditions. There are still issues of concern, though. Notably that in 2018 many main crop potatoes were planted late because of the cold, wet spring. Nonetheless, it is highly likely that the unprecedented price rises experienced following the 1976 drought will not be repeated. When the drought finally ended at the end of August 1976, September turned out to be abnormally wet, with high rainfall continuing throughout the autumn. This was significant in how it affected the crops when the rain finally came. The onset of rain led to a secondary growth of potatoes. The existing potatoes, instead of being able to use the moisture to grow, produced small new potatoes of their own.  The wet autumn of 1976 not only delayed the harvesting of the potato crops, but meant much of the crop went into store wet and ill-suited for long term keeping. It was the combination of factors taking place in the autumn which led to the later high prices for potatoes. In spite of the present drought, it is highly unlikely that the shortages will be as bad as those that occurred in the 1976. It is probable that even if the present dry hot weather continues it will not produce a repeat quite of the magnitude of the food price hikes which occurred in 1976. These reflected not only the impact of the west European drought but also international factors, in particular an El Niño induced reduction in world food production. This is not to say that food prices, particularly for potatoes, will not be affected. But the significance of the price rises will likely be considerably less than in 1976. Nevertheless, based on the experiences of 1976, the price rises may not be confined to a single year – it all depends on how the weather changes in the months to come."
"
Share this...FacebookTwitterAerial photos show that the 15 temperature observation stations the JMA is using to determine mean temperature anomalies are likely impacted far more by urbanization than the agency claims.
By Kirye
and P. Gosselin
According to the Japanese Meteorological Agency (JMA) here, as of 2018, 15 observation stations are used to gather data to calculate surface temperature anomalies.
The 15 sites are Abashiri, Nemuro, Suttsu, Yamagata, Ishinomaki, Fushiki, Iida, Choshi, Sakai, Hamada, Hikone, Miyazaki, Tadotsu, Naze and Ishigakijima. Here’s a table of these stations from NASA:

NASA is using only 7 of these stations (marked). Many of these 15 stations used by the JMA have a high BI value, meaning they are heavily impacted by urbanization. 
An earlier document issued by the JMA stated that the agency had used 17 stations, see Table 1.2.3. Today they are using 15.
JMA selection criteria: “relatively small” urbanization influence 
The JMA says the criteria for selecting the 15 weather observation sites are: they have a long observation period and the influence of urbanization is “relatively small” and “not biased by a particular region”.
What follows is a location plot of the 15 JMA observation stations scattered across Japan:

How “relatively small” is the urbanization really?
To find out more about the siting quality of the stations, Kirye used Google Earth to locate the stations.
What follows are Google Earth photos of their location. You will see that the JMA’s description “relative small” influence of urbanization is quite an understatement.
It’s urban warming, and not global warming!
Many stations are in fact dubiously surrounded by massively heat-absorbing structures. Keep in mind the pinpoint location shown could be off by some meters.

Abashiri is in the middle of buildings and streets.
 

Choshi is also found in a densely built up area, which would tend to really heat up in the summer.
 

Fushiki observation station is somewhat better sited, with more green vegetation in the area, yet much temperature distorting paved surfaces are nearby.
 

Hamada station is also becoming increasingly choked off by urbanization.
 

Hikone is right in the middle asphalt and buildings. We can only wonder how much all the air conditioners around are heating up temperature readings in the summertime? This is urban warming, and not global warming!
 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Iida station. Wow! Hardly any green vegetation in sight, so the area must really heat up in the summertime sun, and keep things warm late into the evenings.
 

Miyazaki station. Japan loves concrete and asphalt. So little room for vegetation. Expect the green fields to go in the years ahead.
 

Ishinomaki station. Everywhere heat-absorbing buildings and asphalt streets that boost the readings.
 

Naze. NASA assigns it a BI of 0, meaning as rural as could be. Maybe the reason for this is because Naze is on an island in the middle of the ocean. But here we see the station is in the middle of a city.
 

Nemuro station is also surrounded by buildings, concrete, steel and asphalt. Perhaps the Google Earth marker is not so exact and so the station is in the field to the right. Still, lots buildings and hot asphalt around.
 

Sakai station has some green areas around it, but still great urban influences at work.
 

Suttsu, only the second station considered by NASA to be “rural” is so only on one side! If the wind blows from the forest to the west, then the readings will be more accurate.
 

Tadotsu is a terribly sited stations, due to obvious reasons. The whole place is a giant heat sink!
 

Yamagata, the last of the 15 stations JMA uses, is also completely surrounded by heat absorbing asphalt, concrete, steel and buildings.
What can we conclude?
Little wonder that global temps shot up just after 1990 when NASA stopped using so many stations worldwide, and seemed to focus more on those sited in urban environments.
Arguably the JMA’s claim of a “relatively small” influence from urbanization is an understatement of multiple degrees.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany has seriously overestimated how much its neighboring countries are able to help out in the event wind and solar energy fail to deliver, thus putting it’s power supply at risk.
One of Germany’s strategies for making its energy supply renewable is to rely on its neighbors to step up when green energies fail to deliver.
As the country adds more volatile wind and solar energy to the grid, Germany hopes that neighboring countries will cooperate in helping to stabilize the power grid in the event the wind doesn’t blow and the sun doesn’t shine — especially after the country shuts down its remaining nuclear power plants and starts to shut down old coal plants. Nuclear and coal power make up the lion’s share of Germany’s stable baseload power supply.
“A dangerous miscalculation”
However, it appears German officials have made a major miscalculation: citing a recent study, journalist Daniel Wetzel at Die Welt writes: “Europe cannot bail out the German power supply. This is so because “hardly a neighboring country has any remaining extra power plant capacity.” The Die Welt economics journalist then calls the German strategy “a dangerous miscalculation.”
In 2014 the German Ministry of Economics assumed the country could rely on 60 gigawatts of over-capacity in related adjacent markets in Europe, but it turns out that the figure was overstated by a factor of 3 to 4. Consequently on windless and sunless days, Germany could end up missing considerable amounts of power.
Wetzel writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




As a result, soon all over Europe power stations with ‘secured power’ that can produce independently of current wind and sun conditions will be missing.”
He also adds that as every European country strives to add more wind and solar capacity, more of their baseload capacity plants are being shut down as well, which only makes the situation increasingly worse when sun and wind do not show up. The point is rapidly coming where there will not be sufficient baseload capacity to keep the grid stable.
One solution, Wetzel suggests, would be to install gas-fired power generators so that they could be fired up in times of low wind and solar output: “However, new gas-fired plants are being built nowhere because refinancing under the conditions of the Energiewende appears as being too risky,” Wetzel reports.
In a nutshell, as Europe expands its wind and solar capacity, more baseload capacity will be needed. But instead of adding it, Europe is reducing it, and thus making the supply and grid stability worse.
As for Germany, it is increasingly dawning on politicians that designing energy infrastructure is best left technical and electrical engineering experts, and not to climate -catastrophe obsessed politicians and green activists who seem to think such complex systems can be built up ad hoc as you go.
The price of this slipshod politicized approach could wind up being very painful in the midterm future.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Guest post by Kirye in Tokyo
An analysis of the rural-sited Japanese weather stations used by the Japanese Meteorological Agency (JMA) shows there’s been no warming at all over the the past 2 decades or more.
Strangely many of these stations, which are practically unimpacted by data-corruptive urban sprawl, are no longer used by NASA.
For example, NASA quit using the rural Fukaura station back in 1990. Up to that point Fukaura was cooling notably. What follows is the NASA chart for Fukaura:

Fukaura showed cooling before NASA dropped the station in 1990. Image: NASA
The same, for example, is true for Nikko.
NASA dropped rural Japanese stations
What follows below is a list of the rural stations I examined, which have a Brightness Index (BI) of 10 or less. The far right column shows the period they were used by NASA.

Source: NASA.
My earlier enquiries about stations sent to NASA via the Internet went without any answer. Perhaps they don’t reply to foreign requests. I don’t know.
The next chart below is the geographical plot of these rural sited stations. As you see they are all well scattered across the country:

Google Earth map showing location of the rural stations.
JMA data in fact show no warming
What follows below are temperature charts for each station, using the data from the JMA, arranged in more or less alphabetical order. On some charts I plotted more than one station.
Over 90% of rural stations show cooling or no trend
Of the 24 stations plotted, 22 show no change or some modest cooling over the past two or more decades – that’s more than 90%. Only two stations show some warming, but only a very modest amount.

Aburatsu data, Ushibuka data
 

Data Aikawa here. Oshima here. Katsuura here. Miyakejima here.
 

Akune data, Makurazaki data
 

 Fukaura here.
 

Fukue data, Yakushima data
 

Hachijojima data.
 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Data Irozaki
 

Miyama data. Note: NASA has never used Miyama’s temperature data, but the rural area in Kyoto Pref is also a slight cooling trend.
 

Murotomisaki data
 

Naze data
 

Nikko data here.
 

Shionomisaki data,

Sukumo data
 

Suttsu data
 

Tanegashima data
 

Okinoerabu data, Minamidatojima data, Kumejima data, Yonagunijima data
 
Japan shows no warming over past 2 decades
What follows next is the chart for all of Japan for the last 20 years, using data from the JMA:

As the chart above shows, using JMA data, the whole country of Japan shows no warming over the past two decades.
Urban environment
Tony Heller at Real Science here shows the environment that many Japanese weather stations – like the ones NASA use – find themselves having to deal with. 
But as the temperature chart for all of Japan mentioned above shows, even the urban heat island effect still is unable to produce warming over the past 20 years. Without the cities one could rightfully argue there would be a cooling trend.
=====================================================
Follow Kirye at Twitter.
Share this...FacebookTwitter "
"The G7 leaders’ pledge to eliminate the use of fossil fuels as an energy source by century’s end could be the most significant outcome of the most recent meeting. It also reinforces German host Angela Merkel’s claim to be the “climate chancellor”. As is customary with such pledges, however, the announcement was short on specifics and it’s really not clear how reductions in fossil fuel usage can be achieved.  After all, disasters at Chernobyl in 1986 and Fukushima in 2011 have made key G7 members considerably less enthusiastic about nuclear power, one obvious alternative. Both Germany and Japan have crucial roles to play over the coming decades in facing up to these challenges. It was Merkel’s Germany that decided in the wake of Fukushima to abandon nuclear power by 2020. Under an aggressive 50% expansion in renewables since then, in 2014 German fossil fuel consumption had fallen to an historic 35 year low. But what about Japan? After Fukushima the country initially shut down all its nuclear plants. However, since then successive pro-nuclear governments have tried to restart its reactors, in part to reduce the spiralling financial and environmental costs of the resulting sharp increase in oil, gas and coal imports. Japan is now the world’s second biggest importer of fossil fuels after China and the world’s fifth largest emitter of CO2. Despite efforts to restart the nuclear programme, all 43 operable reactors remain in shut-down mode due to public unease. Even the scheduled restart for Sendai No. 1 plant in Kyushu has been delayed until August due to technical difficulties. Hence the question the country faces is not whether it should restart its nuclear plants, but whether it can do so in the face of public fears of another earthquake or tsunami. Those fears are real. Evidence suggests that Japan may have experienced at least 22 tsunamis higher than 10m. Moreover, Japan has experienced the highest density of 8+ magnitude earthquakes in the world since modern records began in 1900. Within the coming decades seismologists expect powerful undersea earthquakes of the type that occurred off northeastern Japan in 2011 along the Nankai trough to the south of Honshu, Shikoku, and Kyushu. This would threaten the huge Hamaoka nuclear power plant, located roughly equidistant between the population centres of Nagoya and Tokyo-Yokohama. As recently as the 1970s just 3% of Japan’s electricity came from nuclear power. Since then, however, governments have nurtured nuclear under the assumption that the country lacks domestic energy resources and is vulnerable to overseas political volatility. In the intervening period Japan, like many other countries, has become addicted to oil.  While Japan might not sit on huge oilfields, the idea it lacks domestic energy potential is false. It has abundant geothermal energy, for instance, as the local macaque monkeys know well. Japan mostly receives 1,800 – 2,100 hours of sunshine per year, more than solar-friendly Germany, and at a similar latitude to sunny Spain. The country also has some of the most plentiful wind, tidal, and wave energy resources in Asia due to its mountainous island and marine geography. Despite this the state has invested huge sums in developing nuclear power while, according to former prime minister Naoto Kan, the electric power companies have treated renewables as a “nuisance”. This treatment appears to be continuing, even as local small-scale, or distributed, solar energy is catching on thanks to new feed-in tariffs which reward renewable generation. At first regional energy companies integrated this energy into the main grid but this has slowed; one provider, Kyushu Electric Power, has stopped accepting applications from renewable suppliers, stating that the company can’t cope with the destabilisation to their systems. Japan had intended to reduce fossil fuel dependence by building 14 new nuclear reactors, under the then-government’s 2010 Basic Energy Plan. These new reactors would have raised the nuclear share of electricity from 29% in 2011 to 50% by 2030, and its share of Japan’s primary energy mix from 10% to 24%.  But Fukushima consigned that plan to the dustbin, and the country has yet to develop a credible alternative that will satisfy the country’s energy demand while simultaneously matching pledges to reduce and, now, eliminate fossil fuel usage. In the near-term Japan faces huge obstacles in meeting its G7 targets for reducing fossil fuel usage. Over the longer term, the situation looks less bleak. Fertility levels far below the replacement rate means the country’s population is shrinking and some local authorities are developing smart compact cities in response, which should accelerate as depopulation deepens. Japan also possesses deep technological and economic resources to draw on in delivering solutions to the big questions of the 21st century. Once regional energy providers are able to absorb local solar and geothermal energy, the potential for renewables will rapidly expand. Japan faces perhaps the toughest 21st century energy challenges of the G7 states. Can it simultaneously address safety and environmental concerns by replacing nuclear and fossil fuel energy usage with renewables? It is in the resolution of this problem that Germany may be able to lend a hand."
"
Share this...FacebookTwitterRecently we’ve been hearing about how cold it’s been over much of North America, for example how Houston saw its earliest snowfall on record!
Well, it appears that the early wintry conditions are getting set to take even stronger hold over the Northern Hemisphere.
Yesterday at Weatherbell’s Daily Update, veteran meteorologist Joe Bastardi showed how some 90% of North America has been well below normal temperature-wise so far this month:

Source: Weatherbell Daily Update.
In Europe, the continent has experienced a very warm summer and fall so far, but that is about to change rather dramatically — should the latest computer model generated weather forecasts pan out, and which they are expected to do.
Snow is forecast to cover much of the US and all of Canada by early next month:

Source: Weatherbell Daily Update.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Russian beast from the east
Joe says at the Daily Summary that Europe should expect “brutal cold” at the end of the current month. At the end of the video he says:
“Boy, we’ve got some interesting things going on in Europe. […] Wicked cold coming into Europe.”

Source: Weatherbell Daily Update.
Also Japanese skeptic blogger Kirye at Twitter sent me chart showing Arctic sea ice volume is back up to normal after having been a bit below normal over the past couple of months.

Source: Kirye.
Once again expect another rollout of the scientifically bogus explanation of a Arctic-warming-induced perturbed jet stream causing all the cold. Just keep in mind this is barely a hypothesis that has no data to back it up and that it mostly relies on phony models created by climate activists.
Although the globe may have warmed about half a degree, much of the Northern Hemisphere land mass will continue to see cold snows winters like it did 50 years ago. The earlier idiotic alarmist predictions are proving to be merely fantasy visions of hysterical minds.
Share this...FacebookTwitter "
"In 1997-98, extremely dry El Niño conditions in Indonesia kicked off a wave of large–scale uncontrolled burning, destroying about five million hectares of tropical forest (equivalent to seven million football fields).  Much of the burning occurred in carbon-rich peatland forests and continued in two phases from July 1997 until March 1998, releasing vast amounts of carbon dioxide into the atmosphere, and huge clouds of smoke and haze across the region.  Present conditions in the Pacific Ocean are similar to what they were in mid-1997.  El Niño is set to strengthen, and seasonal weather prediction models point towards this being an exceptionally dry season. Indonesia and its neighbours should be worried. In order to predict, and hopefully prevent, such fires in the future, we’ve looked at how far in advance they can be anticipated using a seasonal weather prediction model. During the dry season, numerous fires occur in Indonesia’s peatland forests, particularly in the southern region of Kalimantan and eastern Sumatra.  Although some rain falls during a normal dry season, it is sporadic, leaving many windows of opportunity for burning.   Most of these fires are deliberately lit to clear rainforest to establish oil palm and Acacia pulp and paper plantations. Fire spread is enhanced by the increased availability  of combustible material, notably, woody debris as a result of wasteful logging practices, and the widespread practice of draining peatlands. When El Niño strikes, however, the situation changes drastically.  During strong El Niño episodes, almost no rain falls during the dry season and the monsoon is delayed.  So in areas where peatlands have been degraded by logging and draining, fires ignite easily and once started, the peat is so dry that fires escape underground, and cannot be put out until after the monsoon reappears.   At their worst, the fires have enormous impacts on carbon emissions, regional haze production, biodiversity, and the economy, and are recognised as a serious health risk in Indonesia as well as neighbouring Singapore and Malaysia. The fires are a major threat to the remaining orangutans who live in the forests – the Bornean orangutan is rated endangered, and the Sumatran orangutan is critically endangered. During past El Niño years, around one gigatonne of carbon was emitted from peatland forest fires, equivalent to about 10% of annual global fossil fuel emissions, and regional haze from such fires has caused major disruptions to air traffic in nearby Singapore and Kuala Lumpur.  Sea surface temperatures from the vast array of sea buoys established across the Pacific Ocean plus other important meteorological data are now telling us that El Niño conditions are already in place.  Furthermore, most seasonal weather prediction models, which are driven by observed SSTs, predict El Niño will strengthen over the coming months.  This means the upcoming dry season in Indonesia will probably be much drier than usual, and the fires worse. 


Probability rainfall forecasts for Asia for the periods: June-July-August 2015 (top) and September-October-November 2015 (bottom).
Author providedInternational Research Institute (IRI)

 The regional haze problem has become so serious in recent years that the Singapore government passed the Trans-boundary Haze Pollution Act in 2014.  This act financially penalises companies listed on the Singapore stock exchange deemed responsible for smoke-haze affecting the city-state but originating elsewhere.  The governments of the ten ASEAN member states signed the ASEAN Agreement on Trans-boundary Haze Pollution on 10 June 2002, which Indonesia finally ratified in September 2014.  The agreement requires all states to implement measures to prevent, monitor and mitigate trans-boundary haze pollution by controlling peat land and forest fires.  It makes explicit mention of the development of an early fire warning system to help prevent and mitigate major haze events.  Since burning is opportunistic, it can happen as soon as conditions will allow it.  Research since the 1997 haze disaster has given us a fairly reliable understanding of how dry conditions must be in order for severe fires to happen. But by the time these conditions occur, burning has already started, fires have escaped, and it is too late for prevention.  Dry conditions instead need to be forecast weeks to months in advance for any prevention to be effective.  Up until now, the forecasting component has been missing. We wanted to see if past fires, especially severe El Niño-influenced fires, could have been predicted using seasonal weather forecasts.  Using satellite observations of fire activity and the case study region of southern-central Kalimantan, which is characterised by a June-November dry season, we demonstrated that most of the severe fires (and associated haze) since 1997 could have been anticipated using rainfall predictions from the European Centre for Medium-Range Weather Forecasts seasonal weather prediction model.  A second part of our work confirmed a clear link between severe fires and massive forest loss (also estimated from satellite data). Our findings were recently published in the journal Natural Hazards and Earth System Science. The implication of our work is that regional weather services, fire-fighting and resource management agencies are potentially able to identify areas that are likely to be dangerously dry ahead of time.  Preventing severe uncontrolled burning in Indonesia and associated impacts will ultimately depend on how well fire is managed.  This is a complex problem involving governments, multinational companies and indigenous people. Nonetheless, knowing ahead of time about a potentially bad fire situation will no doubt form part of the final answer.   While seasonal predictions are not perfect, and occasionally a year may turn out differently to what was expected, seasonal forecasts are anticipated to continue to show improved skill in future. The challenge remains to build on these advances to create an Indonesia-wide early fire warning system for operational use."
nan
"When Sudan the white rhino was put down by his carers earlier this year, it confirmed the extinction of one of the savannah’s most iconic subspecies. Despite decades of effort from conservationists, including a fake Tinder profile for the animal dubbed “the most eligible bachelor in the world”, Sudan proved an unwilling mate and died – the last male of his kind. His daughter and granddaughter remain – but, barring some miraculously successful IVF, it is only a matter of time. The northern white rhino will surely be mourned, as would other stalwarts of picture books, documentaries and soft toy collections. But what about species of which of which we are less fond – or perhaps even entirely unaware? Would we grieve for obscure frogs, bothersome beetles or unsightly fungi? Extinction is, after all, inevitable in the natural world - some have even called it the “engine of evolution”. So should extinction matter to us? First of all, there are strong practical arguments against biodiversity loss. Variation, from individual genes to species, gives ecosystems resilience in the face of change. Ecosystems, in turn, hold the planet steady and provide services essential to human welfare. Forests and wetlands prevent pollutants entering our water supplies, mangroves provide coastal defence by reducing storm surges, and green spaces in urban areas lower city-dwellers’ rates of mental illness. A continued loss of biodiversity will disrupt these services even further. Seen in this light, the environmental damage caused by resource extraction and the vast changes that humans have wrought on the landscape seem extremely high risk. The world has never before experienced these disturbances all at the same time, and it is quite a gamble to assume that we can so damage our planet while at the same time maintaining the seven billion humans that live on it. Although the unregulated plundering of the Earth’s natural resources should certainly worry those brave enough to examine the evidence, it is worth specifying that extinction is an issue in its own right. Some environmental damage can be reversed, some failing ecosystems can be revived. Extinction is irrevocably final.  Studies of threatened species indicate that, by looking at their characteristics, we can predict how likely a species is to become extinct. Animals with larger bodies, for example, are more extinction-prone than those of smaller stature – and the same holds true for species at the top of the food chain. For plants, growing epiphytically (on another plant but not as a parasite) leaves them at greater risk, as does being late blooming. This means that extinction does not occur randomly across an ecosystem, but disproportionately effects similar species that perform similar functions. Given that ecosystems rely on particular groups of organisms for particular roles, such as pollination or seed dispersal, the loss of one such group could cause considerable disruption. Imagine a disease that only killed medical professionals – it would be far more devastating for society than one which killed similar numbers of people at random. This non-random pattern extends to the evolutionary “tree-of-life”. Some closely related groups of species are restricted to the same threatened locations (such as lemurs in Madagscar) or share vulnerable characteristics (such as carnivores), meaning that the evolutionary tree could lose entire branches rather than an even scattering of leaves. Some species with few close relatives, such as the aye-aye or tuatara, are also at higher risk. Their loss would disproportionately affect the shape of the tree, not to mention erasing their weird and wonderful natural history stories. The most regular counter argument contends that we should not worry about extinction, because it is a “natural process”. First of all, so is death, but it does not follow that we meekly surrender to it (especially not prematurely or at the hands of another). But secondly, fossil records show that current extinction levels are around 1,000 times the natural background rate. They are exacerbated by habitat loss, hunting, climate change and the introduction of invasive species and diseases. Amphibians seem particularly sensitive to environmental change, with estimated extinction rates up to 45,000 times their natural speed. Most of these extinctions are unrecorded, so we do not even know what species we are losing. But does it really matter that the world contains fewer types of frog? Let’s take a hypothetical small, brown African frog that becomes extinct because toxic waste pollutes its stream. The frog has never been described by science, so no one is the wiser about its loss. Putting aside disaster movie-level ecosystem collapse as a result of ongoing mass extinction, the frog’s intrinsic value is a matter of opinion. It evolved over millions of years to be adapted for its particular niche – to us, the authors, the loss of that perfectly balanced individuality makes the world a lesser place.  But it is easy to moralise about biodiversity when you don’t have to live alongside it. One person’s marvel of nature might be another person’s torment – an orangutan raiding a poor farmer’s crops, or a leopard snatching a shepherd’s livestock. Pathogens are also part of life’s rich tapestry, but how many of us mourn the eradication of smallpox? So how far should our aversion to extinction extend? We cannot answer this question – but like all good philosophical conundrums it belongs to everyone, to be debated in schools, cafes, bars and market places across the world. We may not all agree, but extinction is broadening its reach, so consensus and urgent action are needed if we hope to control it."
nan
"
Share this...FacebookTwitterAccelerating sea level rise due to global warming is supposed to eat away at the shorelines across the globe. However a recent paper published in the journal Nature here authored by a team scientists led by Arjen Luijendijk found that some 75% of the world’s sandy shorelines are stable or growing!
An analysis of satellite-derived shoreline data indicates that 24% of the world’s sandy beaches are eroding at rates exceeding 0.5 m/yr, but 28% are accreting and 48% are stable.
Also erosion rates exceed 5 m/yr along 4% of the sandy shoreline and are greater than 10 m/yr for 2% of the global sandy shoreline.
Image source: Luijendijk et al., 2018
According to the paper, the application of an automated shoreline detection method to the sandy shorelines resulted in a global dataset of shoreline change rates for the 33 year period 1984–2016.
The scientists also found that Australia and Africa are the only continents for which net erosion (−0.20 m/yr and −0.07 m/yr respectively) is found, with all other continents showing net accretion.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




What’s surprising is that another researcher has determined that melting ice caps from global warming induced ice melt does not contribute to sea level rise, and that sea level rise is mostly caused by the Earth’s shape.
 3 mm/yr sea level rise “definitely a conjecture”
In a scientific paper published by the journal Geoscience Frontiers, Aftab Alam Khan at the Department of Geology, University of Dhaka in Bangladesh found: “thermal expansion only explains part (about 0.4 mm/yr) of the 1.8 mm/yr observed sea level rise of the past few decades.” and that the claim and prediction of 3 mm/yr rise of sea-level due to global warming and polar ice-melt “is definitely a conjecture”
He added that the prediction of 4–6.6 ft sea level rise in the next 91 years between 2009 and 2100 is “highly erroneous”!
Khan then concludes that though global warming, both polar and terrestrial ice melts, and climate change might be a reality, all these phenomena are not related to sea level rise and fall.
Ice melt would not contribute to sea level rise
According to Khan, “Geophysical shape of the earth is the fundamental component of the global sea level distribution. Global warming and ice-melt, although a reality, would not contribute to sea-level rise.”
If Kahn’s assertion turns out to be correct, then IPCC scientists will have some major scientific revamping to do.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMojib Latif: three statements, three times totally off the mark
By Die kalte Sonne
(German text translated by P Gosselin)
At the end of the year, it’s usual to take a look back. That’s what we wish to do at this blog.
Leading German climate scientist Mojib Latif made three historical statements in 2012 that are worth remembering. How much truth was there in his statements of that time?
STATEMENT 1:
Mojib Latif on December 4, 2012 in the talkshow “Pelzig hält sich”:
I want to say one thing again. I would be glad if it were the sun. Then we really could do nothing. Yes. But it is not that. If you look at the sun’s radiation, the sun has been weaker for 50 years. And how is a weakening sun supposed to cause massive warming?”
False. The sun has actually become stronger in the last 50 years when one considers the total solar irradiance (TSI – white curve in the diagram), which also includes cosmic rays and the solar magnetic field.

Figure: Development of solar activity over the past 400 years. White curve shows total solar irradiance (TSI), yellow peaks mark sunspots. Source:    PAGES2K website, downloaded in 2016.
———–
STATEMENT 2:
Mojib Latif on December 4, 2012, in the talkshow “Pelzig hält sich“:
Yes, you can quantify everything. That is, of course, a plain lie if it is claimed that we do not take the sun into account. There is no climate model that does not take the sun into account. I do not think we are fools. This somehow gives the impression that we are the biggest idiots of all time. It’s not like that.”
False, Mr. Latif. A look at the radiation drive in the 5th IPCC Climate Report is enough to see that the sun plays almost no role in the models. CO2: 1.68 W/m2, sun: 0.05 W/m2. The sun is made practically as a non-factor in this.

Figure: Radiation as a driver among the individual climate factors according to the 5th IPCC report. The sun plays practically no role in the IPCC.
———–


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




STATEMENT 3:
Mojib Latif in an interview with the Neuen Osnabrücker Zeitung (NOZ) on September 12, 2012:
NOZ: Mr. Latif, does the sun more likely to contribute to global warming or the greenhouse gas carbon dioxide, CO2?
LATIF: It’s a mix of both. It is clear that man has been responsible for more than half of the rise in temperature since the beginning of industrialization.”
Just before that in the Austrian daily Austrian daily ‘Die Presse‘ (DP) on February 9, 2012, he said the following:
DIE PRESSE: Back to the previous warming, 0.8 degrees for 100 years. For [Fritz] Vahrenholt, half comes from the sun. And at the IPCC everything comes from CO2?
LATIF: No, the IPCC never said that. It is very careful and says that about half of the warming is anthropogenic.
DIE PRESSE: Then it says the same as Vahrenholt?
LATIF: Yes, that’s what drives me crazy: An exaggerated threat is built up and then torn up with great relish.”
Again Latif is wrong. Here it’s enough to just look at the Special report of the IPCC concerning the 1.5°C target:
Reflecting the long-term warming trend since pre-industrial times, the observed mean global surface temperature in the decade 2006-2015 was 0.87 °C (probably between 0.75 °C and 0.99 °C) higher than the average for the period 1850-1900 (very high confidence).
Estimated anthropogenic global warming is consistent with the extent of observed warming within ±20% (likely range).”
In other words: According to the IPCC, the total warming observed over the last 150 years is anthropogenic.
———–
Three Latif statements, three times over the line.
Is Latif’s criticism of the Die kalte Sonne book still valid under these circumstances? We would like to talk to Mojib Latif about it personally. After his earlier refusal, is he now perhaps ready for discussion? We hope for good climatic developments in 2019.
We wish all Die kalte Sonne blog readers – and of course Mr. Latif – a Happy New Year!
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn the first 9½ months of 2018,  368 scientific papers have been published that cast doubt on the position that anthropogenic CO2 emissions function as the climate’s fundamental control knob…or that otherwise serve to question the efficacy of climate models or the related “consensus” positions commonly endorsed by policymakers and mainstream media sources.

These 368 new papers affirm the position that there are significant limitations and uncertainties inherent in our understanding of climate and climate changes, emphasizing that climate science is not settled.
More specifically, the papers in this compilation support these four main skeptical positions — categorized here as N(1) – N(4) — which question climate alarm.
N(1) Natural mechanisms play well more than a negligible role (as claimed by the IPCC) in the net changes in the climate system, which includes temperature variations, precipitation patterns, weather events, etc., and the influence of increased CO2 concentrations on climatic changes are less pronounced than currently imagined.
N(2) The warming/sea levels/glacier and sea ice retreat/hurricane and drought intensities…experienced during the modern era are neither unprecedented or remarkable, nor do they fall outside the range of natural variability.
N(3) The computer climate models are neither reliable or consistently accurate, and projections of future climate states are little more than speculation as the uncertainty and error ranges are enormous in a non-linear climate system.
N(4) Current emissions-mitigation policies, especially related to the advocacy for renewables, are often ineffective and even harmful to the environment, whereas elevated CO2 and a warmer climate provide unheralded benefits to the biosphere (i.e., a greener planet and enhanced crop yields).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In sharp contrast to the above, the corresponding “consensus” positions that these papers do not support are:
A(1) Close to or over 100% (110%) of the warming since 1950 has been caused by increases in anthropogenic CO2 emissions, leaving natural attribution at something close to 0%.
RealClimate.org: “The best estimate of the warming due to anthropogenic forcings (ANT) is the orange bar (noting the 1𝛔 uncertainties). Reading off the graph, it is 0.7±0.2ºC (5-95%) with the observed warming 0.65±0.06 (5-95%). The attribution then follows as having a mean of ~110%, with a 5-95% range of 80–130%. This easily justifies the IPCC claims of having a mean near 100%, and a very low likelihood of the attribution being less than 50% (p < 0.0001!).”
A(2) Modern warming, glacier and sea ice recession, sea level rise, drought and hurricane intensities…are all occurring at unprecedentedly high and rapid rates, and the effects are globally synchronous (not just regional)…and thus dangerous consequences to the global biosphere and human civilizations loom in the near future as a consequence of anthropogenic influences.
A(3) The climate models are reliable and accurate, and the scientific understanding of the effects of both natural forcing factors (solar activity, clouds, water vapor, etc.) and CO2 concentration changes on climate is “settled enough“, which means that “the time for debate has ended“.
A(4) The proposed solutions to mitigate the dangerous consequences described in N(4) – namely, wind and solar expansion – are safe, effective, and environmentally-friendly.
To reiterate, the 368 papers compiled in 2018 thus far support the N(1)-N(4) positions, and they undermine or at least do not support the “consensus” A(1)-A(4) positions.  The papers do not do more than that.   In other words, it is not accurate to claim these papers prove that anthropogenic global warming (AGW) positions are invalid, or that AGW claims have now been “debunked”.
Below are the three links to the list of  2018 papers amassed as of the 15th of October, 2018, as well as the guideline for the lists’ categorization.
Finally, a sampling of some of the new papers is also included below.
Skeptic Papers 2018 (1)
Skeptic Papers 2018 (2)
Skeptic Papers 2018 (3)

Part 1. Natural Climate Change Observation, Reconstruction
Warming Since Mid/Late 20th Century? (30)
A Warmer Past: Non-Hockey Stick Reconstructions (58)
Lack Of Anthropogenic/CO2 Signal In Sea Level Rise (12)
Sea Levels Multiple Meters Higher 4,000-7,000 Years Ago (12)
A Model-Defying Cryosphere, Polar Ice (25)
Mass Extinction Events Caused By Glaciation, Sea Level Fall (3)
Antarctic Ice Melting In High Geothermal Heat Flux Areas (2)
Abrupt, Degrees-Per-Decade Natural Global Warming (5)
Part 2. Natural Mechanisms Of Weather, Climate Change  
Solar Influence On Climate (78)
ENSO, NAO, AMO, PDO Climate Influence (19)
Modern Climate In Phase With Natural Variability (8)
Cloud/Aerosol Climate Influence (4)
Volcanic/Tectonic Climate Influence (2)
The CO2 Greenhouse Effect – Climate Driver? (9)
Part 3. Unsettled Science, Failed Climate Modeling

Climate Model Unreliability/Biases/Errors and the Pause (19)
Urban Heat Island: Raising Surface Temperatures Artificially (3)
Failing Renewable Energy, Climate Policies (11)
Wind Power Harming The Environment, Biosphere (10)
Elevated CO2: Greens Planet, Higher Crop Yields (7)
Warming Beneficial, Does Not Harm Humans, Wildlife (7)
Warming, Acidification Not Harming Oceanic Biosphere (7)
Coral Bleaching A Natural, Non-Anthropogenic Phenomenon (2)
No Increasing Trends In Intense Hurricanes (6)
No Increasing Trend In Drought/Flood Frequency, Severity (6)
Natural CO2 Emissions A Net Source, Not A Net Sink (5)
Global Fire Frequency Declining As CO2 Rises (2)
CO2 Change Lags Temperature Change By 1000+ Years (3)
Miscellaneous (12)
Scientists: We Don’t Understand (1)

Non-Hockey Sticks: A Few Thousand Years Ago It Was 1-3°C Warmer Than Today
Papadomanolaki et al., 2018  (Baltic Sea)  A large fraction of the Baltic Proper became hypoxic again between 1.4 and 0.7 ka BP, during the Medieval Climate Anomaly (MCA), when mean air temperatures were 0.9–1.4 °C higher than temperatures recorded in the period 1961–1990 (e.g. Mann et al., 2009; Jilbert and Slomp, 2013).
Leonard et al., 2018  (Great Barrier Reef, Australia)  Coral derived sea surface temperature (SST-Sr/Ca) reconstructions demonstrate conditions ∼1 ◦C warmer than present at ∼6200 (recalibrated 14C) and 4700 yr BP, with a suggested increase in salinity range (δ18O) associated with amplified seasonal flood events, suggestive of La Niña (Gagan et al., 1998; Roche et al., 2014).
Suvorov and Kitov, 2018  (Eastern Sayan, Siberia)  The authors examined the variability of activity of modern glaciation and variation of natural conditions of the periglacial zone on climate and on dendrochronological data. Results of larch and Siberian stone pine growth data were revealed at the higher border of forest communities. …  It is believed that the temperature could be 3.5 °C warmer at the Holocene optimum than at the present time (Vaganov and Shiyatov 2005). … Since 2000, there has been growth of trees instability associated with a decrease in average monthly summer temperatures. …  Since the beginning of 2000, decrease in summer temperatures was marked.
Lozhkin et al., 2018  (East Siberia)  The postglacial occurrence of relatively warm/dry and warm/wet intervals is consistent with results of a regional climate‐model simulation that indicates warmer than present temperatures and decreased effective moisture at 11 000 cal. a BP and persistence of warm conditions but with greater moisture and longer growing season at 6000 cal. a BP.
Smith, 2018  (Greenland Ice Sheet)     To project how much sea level will rise in response to ongoing climate warming, one of the things we need to know is how sensitive the rate of Greenland Ice Sheet melting is to rising temperatures. McFarlin et al. present results from a set of sediment cores from a small nonglacial lake in the highlands of northwest Greenland, which contain deposits from the Holocene and the Last Interglacial (LIG). They found midge assemblages indicating peak July temperatures that were 4.0° to 7.0°C warmer than modern temperatures during the early Holocene and at least 5.5° to 8.5°C warmer during the LIG. This perspective of extreme warming suggests that even larger changes than predicted for this region over the —–coming century may be in store.
Kullman, 2018  (Scandes, Northern Sweden)     The present paper reports results from an extensive project aiming at improved understanding of postglacial subalpine/alpine vegetation, treeline, glacier and climate history in the Scandes of northern Sweden. The main methodology is analyses of mega fossil tree remnants, i.e. trunks, roots and cones, recently exposed at the fringe of receding glaciers and snow/ice patches. This approach has a spatial resolution and accuracy, which exceeds any other option for tree cover reconstruction in high-altitude mountain landscapes. …  All recovered tree specimens originate from exceptionally high elevations, about 600-700 m atop of modern treeline positions. … Conservatively drawing on the latter figure and a summer temperature lapse rate of 0.6 °C per 100 m elevation (Laaksonen 1976), could a priori mean that, summer temperatures were at least 4.2 °C warmer than present around 9500 year before present. However, glacio-isostatic land uplift by at least 100 m since that time (Möller 1987; Påsse & Anderson 2005) implies that this figure has to be reduced to 3.6 °C higher than present-day levels, i.e. first decades of the 21st century. Evidently, this was the warmth peak of the Holocene, hitherto. This inference concurs with paleoclimatic reconstructions from Europe and Greenland (Korhola et al. 2002; Bigler et al. 2003; Paus 2013; Luoto et al. 2014; Väliranta et al. 2015).
Borisova, 2018  (central East European Plain)     Paleobotanical assemblages from peat, lake, and archaeological deposits reveal that during the Middle Holocene (MH; ca. 9.0 to 4.7 kyr BP), the central East European Plain was occupied by highly productive and diverse mixed-oak forests, along with mire, meadow, and riverine communities. Climatic reconstructions based on modern analogues of fossil pollen and plant macrofossil assemblages indicate that throughout the MH [Middle Holocene] mean annual precipitation was at near present levels (~600 mm) and July temperatures were similar to those of today (~17°C). However, differences in the Fossil Floras (FFs) suggest changes in winter conditions though the MH [Middle Holocene, 9.0 to 4.7 kyr BP], with January temperatures higher than the present-day value of -10°C by 2°C in the Early Atlantic, 6°C in the Middle Atlantic, and 3°C in the Late Atlantic-Early Subboreal. The annual frost-free period was 15 days longer than today in the Early Atlantic, about one month longer in the Late Atlantic, and became close to present by the beginning of the Subboreal. The combination of warm winters with diverse and productive vegetation communities provided an environment that was more hospitable than that of today for Late Mesolithic and Neolithic societies.
McFarlin et al., 2018    (Greenland)  Early Holocene peak warmth has been quantified at only a few sites, and terrestrial sedimentary records of prior interglacials are exceptionally rare due to glacial erosion during the last glacial period. Here, we discuss findings from a lacustrine archive that records both the Holocene and the Last Interglacial (LIG) from Greenland, allowing for direct comparison between two interglacials. Sedimentary chironomid assemblages indicate peak July temperatures [Greenland] 4.0 to 7.0 °C warmer than modern during the Early Holocene maximum [10,000 to 8,000 years ago] in summer insolation. Chaoborus and chironomids in LIG sediments indicate July temperatures at least 5.5 to 8.5 °C warmer than modern.
Bartels et al., 2018  (North Atlantic Region)     During summer, AW [Atlantic Water] rises up to waterdepths as shallow as ~55 m. … Summer surface temperatures [1955-2012] range between up to 3°C at the northern mouth and <-1.5 °C at the southern mouth of the Hinlopen Strait, while winter surface temperatures vary between 0.5 and <~1.5°C (averaged, 1955–2012; Locarnini et al. 2013). … Increased summer insolation probably amplified the surface melting of the glaciers resulting in enhanced meltwater production and in a very high accumulation of finegrained sediments within the fjord […].  In addition, during the mild early Holocene conditions, summer sea-surface temperatures probably reaching 8–10°C [~5 – 9.5°C warmer than 1955-2012] (indicated by M. edulis findings as discussed in Hansen et al. 2011) may have contributed to reducing the number of glaciers that entered the fjord directly as tidewater glaciers and thus causing a diminished IRD input. These comparably warm surface temperatures most likely resulted in a reduced sea ice cover during summer, which is also reflected in the sea-ice biomarker data exhibiting lowest IP25 values during the early Holocene. … [G]lacier advances are most likely caused by atmospheric cooling as indicated, e.g. by d18O values from the Greenland NGRIP ice-core (Rasmussen et al.  2014a), by data from peats and permafrost soils on Spitsbergen (e.g. Humlum et al. 2003; Humlum 2005; Jaworski 2016), and by evidence that solar activity reduced around 2.7 ka, contributing to a cooling in both hemispheres (van Geel et al. 1999, 2000). … In lake sediments from northwestern Spitsbergen a temperature drop of ~6°C is recorded between c. 7.8 and c. 7 ka [-0.8°C per century], which has been connected to a stronger influence of Arctic Water and expanding sea ice (van der Bilt et al. 2018).
Street-Perrot et al., 2018  (Estonia)     Estimates of summer temperatures in Estonia based on rapidly responding proxies such as aquatic macrofossils (Valiranta et al., 2015) and chironomids (Heiri et al., 2014) suggest conditions 2 °C warmer than today during the early Holocene.
Pozachenuk, 2018 (Western Russia)  Mass peat accumulation in the territory of Vyatka region began only in the first half of the Atlantic Holocene period. The maximum warming corresponds to the second half of at (climatic optimum Holocene), when the average temperatures of January and July exceeded modern 2-3˚C. at this time in the region formed coniferous-broad-leaved forests of complex composition, with a slight presence of broad-leaved species (Qercus, Tilia, Ulmus) and Corulus. Siberian element of flora-fir on the territory of Vyatka region appeared only in the Subatlantic period of Holocene, most likely due to climatic conditions.
Kolaczek et al., 2018 (Southeastern Poland)    The reconstruction of the mean July temperature based on Chironomidae revealed the exceptionally high rate of warming during the period of ca. 11,490–11,460 cal. BP (at least 1 °C per decade) up to values > 2 °C than modern ones. … Between ca. 11,490 and 11,460 cal. BP, the strongest warming trend in the Early Holocene MJT was registered, that is from 15 to 20.7°C (0.19°C yr1, 1.9°C/decade). Then, ca. 11,450 cal. BP, the temperature decreased to 18.3°C and up to ca. 10,560 cal. BP MJT fluctuated between 17  and 19°C. The climate of the area [today] is classified as cold temperate with mean annual air temperature of 8.2°C  and mean annual precipitation 620 mm. A mean temperature of the warmest month, i.e. July, is +18.2°C [today], whereas a mean temperature of the coldest month, i.e. January, is -3.6°C.
Ruskeeniemi et al., 2018  (Greenland Ice Sheet)     Towards the Holocene Climatic Optimum, temperatures steadily increased and were 2.5°C higher than at present during 8000-5000 cal years BP. It is suggested that the GrIS started to re-advance after 4400 cal years BP due to cooling, with 0.5°C lower temperatures than at present around 2000 years BP. Within the LIA, Dahl-Jensen et al. (1998) identified two cold periods at 1550 AD and 1850 AD, with temperatures respectively 0.5°C and 0.7°C below the present values. At around 1930 AD, the temperatures reached a maximum and have slightly decreased thereafter.
The CO2 Greenhouse Effect: Climate Driver?
Davis et al., 2018     [T]he contemporary global warming increase of ~0.8 °C recorded since 1850 has been attributed widely to anthropogenic emissions of carbon dioxide (CO2) into the atmosphere. Recent research has shown, however, that the concentration of CO2 in the atmosphere has been decoupled from global temperature for the last 425 million years [Davis, 2017] owing to well-established diminishing returns in marginal radiative forcing (ΔRF) as atmospheric CO2 concentration increases. Marginal forcing of temperature from increasing CO2 emissions declined by half from 1850 to 1980, and by nearly two-thirds from 1850 to 1999 [Davis, 2017]. Changes in atmospheric CO2 therefore affect global temperature weakly at most. The anthropogenic global warming (AGW) hypothesis has been embraced partly because “…there is no convincing alternative explanation…” [USGCRP, 2017] (p. 12). …  The ACO [Antarctic Centennial Oscillation] provides a possible [natural] alternative explanation in the form of a natural climate cycle that arises in Antarctica, propagates northward to influence global temperature, and peaks on a predictable centennial timetable. … The period and amplitude of ACOs oscillate in phase with glacial cycles and related surface insolation associated with planetary orbital forces. We conclude that the ACO: encompasses at least the EAP; is the proximate source of D-O oscillations in the Northern Hemisphere; therefore affects global temperature; propagates with increased velocity as temperature increases; doubled in intensity over geologic time; is modulated by global temperature variations associated with planetary orbital cycles; and is the probable paleoclimate precursor of the contemporary Antarctic Oscillation (AAO). Properties of the ACO/AAO are capable of explaining the current global warming signal.
Smirnov, 2018     From this, it follows for the change of the global temperature as a result at doubling of the concentration of atmospheric CO2 molecules [is] ∆T = (0.4 ± 0.1) K, where the error accounts for the accuracy of used values, whereas the result depends on processes included in the above scheme. Indeed, we assume the atmospheric and Earth’s albedo, as well as another interaction of solar radiation with the atmosphere and Earth, to be unvaried in the course of the change of the concentration of CO2 molecules, and also the content of atmospheric water is conserved. Because anthropogenic fluxes of carbon dioxide in the atmosphere resulted from combustion of fossil fuels is about 5% [Kaufman, 2007], the contribution of the human activity to ECS (the temperature change as a result of doubling of the atmospheric carbon dioxide amount) is ∆T = 0.02 K, i.e. injections of carbon dioxide in the atmosphere as a result of combustion of fossil fuels is not important for the greenhouse effect.
Fleming, 2018     This manuscript will review the essence of the role of  CO2 in the Earth’s atmosphere. The logic of  CO2 involvement in changing the climate will be investigated from every perspective: reviewing the historical data record, examining in further detail the twentieth-century data record, and evaluating the radiation role of  CO2 in the atmosphere—calculating and integrating the Schwarzschild radiation equation with a full complement of  CO2 absorption coeﬃcients. A review of the new theory of climate change—due to the Sun’s magnetic ﬁeld interacting with cosmic rays, is provided. The application of this new theory is applied to climate-change events within the latter part of the Earth’s interglacial period. … The results of this review point to the extreme value of  CO2 to all life forms, but no role of  CO2 in any signiﬁcant change of the Earth’s climate. … The results of this review point to the extreme value of  CO2 to all life forms, but no role of  CO2 in any significant change of the Earth’s climate. … Many believe and/or support the notion that the Earth’s atmosphere is a “greenhouse” with CO2 as the primary “greenhouse” gas warming Earth. That this concept seems acceptable is understandable—the modern heating of the Earth’s atmosphere began at the end of the Little Ice Age in 1850. The industrial revolution took hold about the same time. It would be natural to believe that these two events could be the reason for the rise in temperature. There is now a much clearer picture of an alternative reason for why the Earth’s surface temperature has risen since 1850. … There is no correlation of CO2 with temperature in any historical data set that was reviewed. The climate-change cooling over the 1940–1975 time period of the Modern Warming period was shown to be influenced by a combination of solar factors. The cause of the Medieval Warm Period and the Little Ice Age climate changes was the solar magnetic field and cosmic ray connection. When the solar magnetic field is strong, it acts as a barrier to cosmic rays entering the Earth’s atmosphere, clouds decrease and the Earth warms. Conversely when the solar magnetic field is weak, there is no barrier to cosmic rays—they greatly increase large areas of low-level clouds, increasing the Earth’s albedo and the planet cools. The factors that affect these climate changes were reviewed in “Solar magnetic field/cosmic ray factors affecting climate change” section. The calculations of “H2O and CO2 in the radiation package” section revealed that there is no net impact of CO2 on the net heating of the atmosphere. The received heat is simply redistributed within the atmospheric column. This result is consistent and explains the lack of CO2 correlations with observations in the past. The current Modern Warming will continue until the solar magnetic field decreases in strength. If one adds the 350-year cycle from the McCracken result to the center of the Maunder Minimum which was centered in 1680, one would have a Grand Minimum centered in the year 2030.
Holmes, 2018     In short, there is unlikely to be any significant net warming from the greenhouse effect on any planetary body in the parts of atmospheres which are >10kPa. Instead, it is proposed that the residual temperature difference between the effective temperature and the measured near-surface temperature, is a thermal enhancement caused by gravitationally-induced adiabatic auto compression, powered by convection. A new null hypothesis of global warming or climate change is therefore proposed and argued for; one which does not include any anomalous or net warming from greenhouse gases in the tropospheric atmospheres of any planetary body. … A decline of 6% in lower tropospheric tropical cloud cover (15°N–15°S) occurred 1984 – 2000 according to the international satellite cloud climatology project’s data [29]. These years are contained well with the 1975-2000 period of warming, and an observed 0.4°C rise in global temperatures occurred over the same period. Scatter diagrams [55] of low cloud cover vs global surface air temperatures indicate that a 1% fall in low clouds equates to a 0.07°C rise in surface air temperatures – hence this change in cloudiness accounts for the entire observed rise in global temperatures during the 1975-2000 period, leaving no room for any effect from growing greenhouse gases.
Ollila, 2018         The temperature effects of the water and CO2 are based on spectral analysis calculations, which show that water is 11.8 times stronger a GH gas than CO2 in the present climate. … There are essential features in the long-term trends of temperature and TPW [total precipitable water], which are calculated and depicted as mean values 11 years running. The temperature has increased about 0.4°C since 1979 and has now paused at this level. The long-term trend of TPW effects shows that it has slightly decreased during the temperature-increasing period from 1979 to 2000. This means that the absolute water amount in the atmosphere does not follow the temperature increase, but is practically constant, reacting only very slightly to the long-term trends of temperature changes. The assumption that relative humidity is constant and that it amplifies the GH gas changes over the longer periods by doubling the warming effects finds no grounds based on the behavior of the TWP [total precipitable water] trend. The positive water feedback exists only during the short-term ENSO events (≤4 years). … The validity of the IPCC model can be tested against the observed temperature. It turns out that the IPCC-calculated temperature increase for 2016 is 1.27°C, which is 49 per cent higher than the observed 0.85°C. This validity test means that the IPCC climate forcing model using the radiative forcing value of CO2 is too sensitive for CO2 increase, and the CS [climate sensitivity] parameter, including the positive water feedback doubling the GH gas effects, does not exist. … The CO2 emissions from 2000 onward represent about one-third of the total emissions since 1750, but the temperature has not increased, and it has paused at the present level. This is worthy proof that the IPCC’s climate model has overestimated human-induced causes and has probably underestimated natural causes like the sun’s activity changes, considering the historical temperatures during the past 2000 years. … The RF [radiative forcing] value for the CO2 concentration of 560 ppm is 2.16 Wm−2 according to equation (3), which is 42 per cent smaller than 3.7 Wm−2 used by the IPCC. The same study of Ollila (2014) shows that the CS [climate sensitivity] parameter λ is 0.27 K/(Wm−2), which means that there is no water feedback. Using this λ value, equation (3) gives a TCS [transient climate sensitivity] value of 0.6°C only. This same result is also reported by Harde (2014) using the spectral analysis method. …There are both theoretical- and measurement-based studies showing results that can be explained only by the fact that there is no positive water feedback. This result reduces the CS [climate sensitivity] by 50 per cent. Some research studies show that the RF [radiative forcing] value of carbon dioxide is considerably smaller than the commonly used RF value, according to the equation of Myhre et al. (1998). Because of these two causes, the critical studies show a TCS [transient climate sensitivity] of about 0.6°C instead of 1.9°C by the IPCC, a 200 per cent difference.
Liu and Chen, 2018     CO2 and temperature records at Mauna Loa, Hawaii, and other observation stations show that the correlation between CO2 and temperature is not significant. These stations are located away from big cities, and in various latitudes and hemispheres. But the correlation is significant in global mean data. Over the last five decades, CO2 has grown at an accelerating rate with no corresponding rise in temperature in the stations. This discrepancy indicates that CO2 probably is not the driving force of temperature change globally but only locally(mainly in big cities). We suggest that the Earth’s atmospheric concentration of CO2 is too low to drive global temperature change. Our empirical perception of the global warming record is due to the urban heat island effect: temperature rises in areas with rising population density and rising industrial activity. This effect mainly occurs in the areas with high population and intense human activities, and is not representative of global warming. Regions far from cities, such as the Mauna Loa highland, show no evident warming trend. The global monthly mean temperature calculated by record data, widely used by academic researchers, shows R~2=0.765, a high degree of correlation with CO2. However, the R~2 shows much less significance (mean R~2=0.024) if calculated by each record for 188 selected stations over the world. This test suggests that the inflated high correlation between CO2 and temperature(mean R~2=0.765-0.024=0.741) used in reports from the Intergovernmental Panel on Climate Change(IPCC) was very likely produced during data correction and processing. This untrue global monthly mean temperature has created a picture: human emission drives global warming.
Laubereau and Iglev, 2018     Using a simple 1-dimensional model the global warming of the surface is computed that is generated by the increase of GHG and the albedo change. A modest effect by the GHG of 0.08 K is calculated for the period 1880 to 1955 with a further increase by 0.18 K for 1955 to 2015. A larger contribution of 0.55 ± 0.05 K is estimated for the melting of polar sea ice (MSI) in the latter period, i.e. it notably exceeds that of the GHG and may be compared with the observed global temperature rise of 1.0 ± 0.1 K during the past 60 years. … In conclusion we wish to say that we have performed a study of the infrared properties of carbon dioxide, methane, dinitrogen-oxide and water to estimate their contribution to the global warming in 1880 – 2015. Our results suggest that the IR properties of the CO2 are responsible for ~ 20% of the mean temperature increase of the surface and notably less for CH4 and N2O.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Swiss online Basel BAZ news site reported yesterday how the Yellow Vest fossil fuel tax protests have spread across Belgium and into the Netherlands, and so threaten to become a European phenomenon.
Previously it was thought that a move away from fossil fuels and higher taxes on them were the will of the people in Europe, and so citizens would readily accept higher taxes on them in order to get society to adopt the lean green energy diet. However that has suddenly turned out to be a gross misinterpretation by policymakers and activists.
Climate activists speechless – devastating signal
As the Yellow Vest protests intensify and spread, activists and delegates in Poland find themselves speechless as the begin to realize that a comprehensive transitioning over to green energies is not going to happen any time soon because their proposals are unmistakably generating anger. The signal to the world from France could not be more devastating to the climate protection movement.
The French have sent a loud and clear message.
The BAZ writes that the European governments are so spooked by the anger that in Brussels institutions such as the EU Commission, the EU Counsel and the EU Parliament had to be completely sealed off because of the demonstration. Police arrested some 100 protesters early as a preventive measure to keep the protest from escalating out of control.
Fuel taxes hurt the poor
Also police in the Netherlands sealed off Den Haag against protesters. The BAZ reported:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Several hundred people on Saturday also protested at the Yellow Vest demonstrations in the Netherlands against what they saw as the growing gap between rich and poor.”
Egregious arrogance, hypocrisy
One reason for the elevated level of anger is the arrogance and hypocrisy EU policymakers exhibit as they rush to impose green energies onto their population. While Eurocrats jet-set from one rescue-conference to another and lead the life of luxury on the taxpayers’ dime, they demand citizens tighten their energy and financial belts and go without.
One egregious example of such arrogance comes from the United States.  The Washington Examiner here reports how Vermont Senator Bernie Sanders spent $300,000 on private jet flights (in a single month!)while demanding citizens refrain from using fossil fuels and forgo their already modest lifestyles. The Examiner writes:
While private jets are a common tool for political campaigners, the same day the massive check was written to a private jet company, Sanders issued a call to arms to take on greenhouse gas emissions.”
Meanwhile President Donald Trump wondered if it was not time “to end the ridiculous and extremely expensive Paris Agreement.”

Since the protests began, France has decided to put off the high taxes on diesel and gasoline fuel for the time being. Expect other European countries to crank down their fuel tax rhetoric as a result.
Share this...FacebookTwitter "
"The war on wildlife crime is taking a new technology-driven direction. Rhinos are being fitted with GPS trackers, heart rate monitors and spy cameras – all embedded within their horns. These small but high-tech devices could be a game changer for anti-poaching efforts in Africa.  That’s the claim of conservation group We Are Protect, whose Real-time Anti Poaching Intelligence Devices (RAPID) have completed proof-of-concept trials on black rhinos in South Africa. The project now aims to move forward to field testing. Here’s how it works. The unit is fitted within the horn of a wild rhino – a painless operation as their horns are made of keratin, just like human nails or hair – and data is then relayed live to a centralised control centre which could be many miles away. If the animal’s heart rate suddenly becomes heightened or declines, this triggers immediate analysis of the in-horn camera footage (at HQ) while an armed anti-poaching team scrambles on a rapid response mission to intercept the poachers at the location provided.  The original impetus for RAPID came from the inability of teams on the ground to detect poaching quickly and effectively enough to catch the poachers and prevent the horn reaching the illegal markets. However, the reality is that we want to stop poaching happening in the first place. We want to save the rhino, not just its horn.  To achieve this goal RAPID should operate as a deterrent, not just an arrest mechanism. This has raised the question of whether RAPID-tagged rhinos should ‘“advertise” that they are carrying the device. But that could simply drive poachers to target untagged rhino. So, in order to achieve the aim of the project, to render poaching a “pointless exercise”, we need all individual rhinos to be fitted with RAPID and tagged to indicate so. That sounds expensive and it is not clear who would foot the bill. Footage giving us a rhino’s eye (or rather a rhino horn’s) view of the world is fascinating and should attract support. However, advanced publicity for this anti-poaching game changer may encourage poachers into a frenzy of killings before it is widely adopted. One South African game reserve saw a similar killing spree shortly before some of its rhinos were due to be dehorned. Let’s hope that the project receives sufficient financial backing to facilitate a comprehensive and speedy roll-out on the ground. If that is the case, then RAPID could be a really progressive step in the continuing war against wildlife crime. We badly need a practical and positive development. Despite growing concern, and increasingly desperate conservation actions, poaching continues to increase and rhino populations continue to decline, year-on-year. South Africa, which houses the core global populations of white and black rhinoceros, has already lost 749 rhinos to poaching this year, on course to match last year’s record 1,215 (itself a 9,000-fold increase from 2007).  Meanwhile, the remnant population of the northern white rhino continues its sad and apparently inevitable decline to extinction. It has dropped to a genetic cliff-edge with the recent death of Nabire meaning only four geriatric individuals survive in the world. The northern white rhino may be dead on its feet, but RAPID offers hope for other species. The We Are Protect team is already looking beyond rhino, and aims to expand the use of RAPID to other endangered creatures under attack from poachers, including elephants and tigers.  We need to throw everything we have, from all angles, at wildlife crime. If we cannot save iconic species like rhinos, elephants, and tigers it does not bode well for the less celebrated animals out there that are also suffering."
"
Share this...FacebookTwitterAlthough resistance to littering the landscape with industrial wind turbines continues to grow strongly and the power grid is becoming ever more unstable, the German government refuses to back off its expansion of wind and solar energy.

Protests groups reach over 1000 in number as wind turbine litter the German landscape. Photo: Windwahn.
Jonas Herrmann of the Swiss NZZ here comments how Germany “is struggling with its wind turbines”.
It started 28 years ago, when the German government enacted a law that forced power companies to buy up any green power produced, pay exorbitant prices for it and feed it into the power grid whether it was needed or not. Over time the installation of solar panels and wind turbines exploded and today many parts of the countryside have become littered with unsightly wind parks.
Ruined landscape, yet a long way to go
Yet, Germany today remains far away from supplying its energy needs through “green” sources.
The NZZ comments: “The landscape has changed in many places as a result. A longer drive through Germany inevitably leads past dozens of wind turbines.”
Moreover, every community has been impacted, Nikolai Ziegler, says the chairman of resistance group Vernunftkraft, which is the major umbrella association of wind power opponents. According to Ziegler: “In Germany there are more than 1000 citizens’ initiatives that are mobilizing against wind energy” and that these groups are getting involved in politics.
Wind and sun will never be able to do the job


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Not only are wind turbines ruining Germany’s idyllic landscape, but the NZZ writes that much of the resistance is also based on wind energy’s technical unreliability as a power supply. The Herrmann at NZZ cites engineering expert Dr. Detlef Ahlborn, who says wind energy is too erratic and thus unreliable.
According to the NZZ;
With the umbrella organization Vernunftkraft, everyone is convinced that wind and solar energy will never be able to ensure a secure power supply.”
Proponents in denial
This is a claim that the German government and green energy proponents refuse to acknowledge. Proponents in Germany believe that the problems with green energies will somehow go away and the supply will miraculously somehow smooth out if more and more volatile wind and sun capacity gets installed.
Critics like Nikolai Ziegler also criticize that there really hasn’t even been any real Energiewende (transition the green energies) so far because electricity is only one fifth of Germany’s total energy demand. Green energies provide only one third of that one measly fifth, and so “it’s relatively meaningless”.
The NZZ notes that “most of the leaders of the protest group Vernunftkraft are “male in the second half of their lives” who “are united by their anger at wind energy”, but adds most have a background in natural science almost half of them are professors.
“Path to the unknown”
Vernunftkraft is calling for an end to green energy subsidies, a stop to the construction of additional wind turbines and instead greater investment in gas-fired power plants
The NZZ writes:
However, a political majority is not in sight. Although the AfD and parts of the FDP [parties] believe the Energiewende is a mistake, the German government can hardly prevent a further expansion of renewable energies. Germany is thus still on the path to the unknown with the Energiewende.”
Share this...FacebookTwitter "
nan
nan
"Fishermen can’t win. The harder they work, the more successful they are, the more they are apparently despised. Take Scotland, for instance, where the EU (heavily influenced by well-financed NGO lobby groups) is attempting to exclude fishermen from large areas of the sea off the west coast that they may have fished for generations.  Most fishermen agree with conservationists that there is a need to protect deep-sea coral and other vulnerable ecosystems far beneath the waves. Fishing for species that live close to the sea bed, known as demersal fish, involves dragging a trawl over the sea floor which can disturb or bury other species found nearby.  These ecosystems can struggle to recover, especially if they are trawled regularly and aren’t used to being disturbed naturally. Many deep-sea species such as the orange roughy (Hoplostethus atlanticus) are extremely long lived, slow growing and have low rates of reproduction – some conservation organisations feel they should not be targeted at all. With agreement over the basic need for protection, the argument is instead over what rules should be applied. The EU and some fisheries managers would like to impose a blanket ban on fishing below 600m. The fishing industry argues this would protect areas that don’t need it and leave the sea above 600m vulnerable to increased efforts of fishing boats squeezed into a more limited area. The EU’s case was apparently given a “scientific basis” by a recent academic paper which argued for a blanket ban based on the idea biodiversity is greater below 600m, despite the fact that (as its authors acknowledge) fishing has had no noticeable impact on deep-sea biodiversity and despite the fact they used data from 1989 through to 2013 without analysing trends over time.   Perhaps the greatest fault in the paper is its use of data from scientific or pseudo-commercial nets rather than data from fishing boats. The authors then equate the results of scientific trawls with likely commercial catches. However fishermen don’t fish scientifically (or they would quickly go out of business); they fish in order to catch a particular species and to minimise discard rates. The particular fishery off the Scottish coast discussed in the paper has shrunk significantly since 2002. The boats still fishing are using much less destructive gear with larger mesh sizes and lighter ground gear that doesn’t impact on the seabed as much. To analyse deep-sea fisheries using some data which is almost 40 years out of date and then try to draw a conclusion that could have major economic implications on an important part of the fishing industry seems ambitious to say the least. The EU needs to think about who it listens to first – fishermen who have a vested interest in the renewal of their stocks, or NGOs who live for the next foundation, corporate or governmental handout? The deep-sea fishing industry, in fact the whole fishing industry, deserves some criticism for past actions that were wasteful and sometimes had an almost criminal disregard for the environment. Discard rates in some early trawl fisheries reached 80% and between 1992-2001 bottom trawling accounted for about 36% of global discards. But it is worth remembering that in the EU the quantity of discards were a product of management measures.  The industry is now focused on how it can sensibly deal with the forthcoming European “landings obligation” that will eliminate discards, requiring from 2019 fishermen to land everything that they catch, even if they do not have by-catch quota.  Well-resourced marine protected areas that have specific goals and measurable outcomes will be key, as conservationists hope fish will prosper in the protected areas and thus spill over into the “unprotected” sea. However it is ironic that, if protected areas are successful, it will become even more difficult for fishermen to comply with the discard ban and avoid catching fish for which they have no quota. This is one of the reasons we need highly-selective fishing gear, tailored to each boat and target species. We also need to expand consumer tastes to make otherwise discarded fish such as Baird’s slickhead a valuable commodity.  It’s a fact that catching fish takes fish out of the sea and that this has an impact on the environment. Yet wild-caught fish are free from additives, have been “reared” as nature intended and are generally an incredibly healthy foodstuff. It is also a fact that wild-caught fish are less costly in terms of carbon budget than pork or beef. And, unlike some sectors of the farming and aquaculture industries, wild fishing doesn’t depend on intensive doping with antibiotics, the gross simplification of habitats, or animals reared in intensive care wards.   We have to make choices – and I for one will choose wild-caught fish over farmed beef, salmon, chicken or pork every time. This article was amended on September 29, 2015 to remove a potential misrepresentation."
nan
"The government’s current energy policies have led to a sharp decline in the number of new onshore windfarms, raising fears that the UK may fall short of the renewable energy it needs to generate to meet its climate targets. Industry data shows the ­rollout of new onshore windfarms fell dramatically after the ­government scrapped subsidy schemes four years ago. According to official data from the Renewable UK trade association, 23 new onshore windfarms began generating clean electricity for the UK last year, but all but one of them had secured support from subsidy schemes before they were closed.  Last year’s total was a fraction of the 2014 peak when more than 400 new onshore wind projects began generating clean power for the first time. The 2019 figures are also well below the average set over the last decade of 208 new projects a year.  Renewable UK warned that the UK risked falling short of its aim of reducing carbon emissions to net zero by 2050 as the pipeline of projects that clinched support before the schemes were closed begins to run dry. Rebecca Williams, a director at Renewable UK, said the figures showed that the government’s current approach was falling short on the clean electricity needed to meet the UK’s legally binding climate targets. “This is a flashing red warning light on our net zero dashboard and we urgently need a new strategy from government,” she said. The findings are likely to increase pressure on the government to reverse the block on government support for new onshore windfarms, put in place by the former Tory prime minister David Cameron in 2016. The current energy policy blocks onshore wind developers from competing for support contracts, and has caused the rollout of new onshore wind capacity to fall to 629 megawatts (MW) last year, or a quarter of the onshore wind growth recorded two years ago. The government’s official climate adviser, the Committee on Climate Change, has suggested that the UK’s onshore wind capacity should increase by almost threefold in the next 15 years to meet climate goals at low cost. This would require the UK to grow its onshore wind capacity from 13,000 MW now to 35,000 MW by 2035, or an average of more that 1,400MW a year. The sole addition to the UK’s fleet of onshore wind farms under the government’s current energy policy last year – the Withernwick II project, in the East Riding of Yorkshire – has a capacity of 8MW, with just four turbines. “Onshore wind is one of the cheapest low carbon technologies in the UK, quick to build, and it’s hugely popular as the government’s own opinion polls show 78% of people support it,” Williams said. “As ministers get down to work at the start of a new decade, we need to see new policies which support the full range of clean power sources to transform our energy system.” ScottishPower, a major developer of renewable energy, has started planning for a major expansion of onshore windfarm projects across Scotland in anticipation of a government U-turn on support for wind power projects. Lindsay McQuade, the chief executive of ScottishPower Renewables, told the Guardian late last year that “if the commitment of net zero is to be a reality, I expect to see support from government to match it”."
"Europe’s weather systems tend to cross the Atlantic and slam into Britain, which should make the UK ideal for wind power. With very low running costs, cheap and easy integration into the grid in most of the country, and with wind being a mature industry that’s still evolving continuous improvements, how could it not be the country’s cheapest renewable?  Just look at the alternatives. There’s not that much hydro to be harnessed. Tide and wave power aren’t yet ready. Geothermal? This isn’t Iceland, not many volcanoes here. Straightforward, then? No, it never is. The government has announced it is to end subsidies for onshore windfarms from April 2016, a year earlier than expected. When asked about the decision to withdraw support from a growing industry, the Secretary of State for Energy and Climate Change, Amber Rudd, claimed solar energy is just as cost-effective as onshore wind. And that’s half-true: it has come down in price so far, so fast, that solar farms are bidding for deals as cheaply as some onshore wind farms.  Then again, this government also prefers more costly rooftop installations to solar farms. Anyway, solar and wind are complementary, not direct substitutes, with windfarms generally generating more power in winter.  Onshore wind is often more expensive than it needs to be in this country. Sure, 
some onshore wind in Britain is not only the cheapest renewable there is, it’s the cheapest electricity we’ve got from any source, once insurance, pollution and all the other costs are factored in. However quite a few planned UK onshore windfarms are more expensive than this. Bids to develop onshore wind came in at around £80 per MWh (8p per KWh) in the February 2015 round of CfD allocations, a bidding process meant to reveal the lowest available supply costs.  That’s about the same price as some proposed solar parks.  Onshore wind is cheaper in other countries such as Germany (between €0.05 and €0.11/kWh). That price premium for onshore wind in Britain seems to be back-to-front, given the UK’s powerful wind resource. There are several compounding factors. Many years of policy uncertainty and persistent meddling with the revenue schemes presents higher risks to investors. Planning regulations in England and Wales have created further uncertainty, with unpredictable local decisions. Often, rulings will be reversed on appeal, only for the energy secretary to step and reject the application. Investors, faced with higher risk, will require higher rewards.  Even more significantly, investors in windfarm supply chains can choose to locate instead in jurisdictions which offer far greater long-term clarity and security. This is why both Denmark and Germany have strong wind supply chains, and Britain’s is still nascent. Not only does that mean new turbines typically have to be shipped to the UK from factories overseas, it adds currency risk, and means that less of the money invested stays within the country. So, by removing the policy uncertainties, it is within the government’s power to remove part of the need for onshore wind to be subsidised. The chief assistance for onshore windfarm operators comes in the form of top-up payments from bill-payers, above what the operators receive from selling their electricity in the wholesale markets. The question is to what extent these are a subsidy at all.  Given the payment represents a transfer over and above the market price, it might seem surprising that this is even a question. But it has to be asked, due to a subtle process, known as the merit order effect. An electricity grid tends to rank different generators in order of marginal cost, prioritising the cheapest forms of generation. This is the merit order. Cheap electricity is brought online first, and the plants with the highest marginal generation cost are saved till last. The merit-order effect is the reduction in wholesale prices that comes about when more wind is generated. Wind is never the most expensive fuel on the grid, because its fuel is free. The cost of wind power is almost entirely in construction;  marginal generation cost is next to nothing. Therefore when the wind blows and power is generated, it knocks out the most expensive generator (and whether that’s coal or gas, depends on their relative prices, the carbon price, and the relative efficiency of the generators) and it lowers prices across the whole market. Previous research in Germany and Spain has found that these cost reductions outweigh the revenue support paid to wind. Wind is not subsidised in those two countries – indeed, quite the reverse, wind lowers total costs for consumers. The thing that is called a subsidy, whether existing schemes or future ones, acts to correct a market failure. First, it needs to figure out how much of these top-up payments merely reflect the merit order effect, simply levelling the playing field with regard to genuinely subsidised generators such as coal and gas. The rest is subsidy. But we can’t make true progress until we recognise this reality. Second, government policy could give windfarm developers much greater long-term assurances of a supportive and consistent policy environment, thus lowering their risks and hence lowering costs. Doing these will improve transparency, and reduce the cost of onshore wind further. It would give certainty to investors through decisiveness and leadership, and it would show that the government is taking a pragmatic and cost-effective approach to tackling climate change."
"“You are in no position to lecture the public about anything,” Golden Globes host Ricky Gervais told his audience in a pointedly irreverent opening speech on Sunday. By the evening’s end, following statements about the bushfires from actors including Russell Crowe and Cate Blanchett, he had apparently changed his mind – ending the evening with his own call for donations to the relief efforts. Charitable gifts will no doubt be welcomed by their recipients (a $500,000 pledge by another Australian actor, Nicole Kidman, emerged on the same day). But the evening’s most consequential remarks were those, including Mr Crowe’s and Ms Blanchett’s, that firmly linked the fires to global heating – directly challenging the denialism of the Australian prime minister, Scott Morrison, who, even in the face of record temperatures and unthinkable devastation, refuses to commit his government to stronger decarbonisation measures, or withdraw his support for coal production and exports. In an ideal world, it would probably not fall to film stars to advocate for evidence-based policies to protect the planet from catastrophe, particularly when such policies are supported by the UN and scientific institutions around the world. But while speeches and social media posts expressing sympathy for victims of this and other disasters, or promoting fundraisers and campaigns on other issues, are often and easily mocked, it makes more sense to focus on the policy failures that give rise to such efforts than to criticise pop or sports stars for their philanthropic activities, even when these appear clumsy or self-serving.  In the case of the climate emergency, the underlying failures are so grave and numerous as to remain extremely difficult for many people to take in. While denial of global heating itself is finally waning in the face of irrefutable proof, denial of the actions that are necessary to curb it (beginning with a 7.6% cut in emissions, every year for the next decade) is ubiquitous – as can be seen from the simple fact that emissions are still rising. Even as the bushfires dominate global headlines, climate-linked disasters in other parts of the world, such as a threatened famine in Zambia, or the battle for the Amazon being waged in Brazil, struggle to attract a fraction of the same attention. Anger is a justified response to such blatant climate injustices. Particularly when many of the worst-affected poorer countries are those with the lowest historic greenhouse gas emissions, philanthropy – even if it were forthcoming – would not provide an adequate form of redress. Lasting climate solutions will require a massive reallocation of global resources, with particular emphasis on infrastructure in developing countries. Only governments and international instituti ons have the necessary policymaking levers (hence the importance of the UN climate process). But where efforts such as those of Australian comedian Celeste Barber, whose bushfires fundraiser has made £20m, offer a reason to hope amid the grief and horror, is in the proof they offer that, when people truly believe that the future is imperilled, they want to help – and understand that this costs money. Politicians around the world should pay attention."
"
Share this...FacebookTwitterGermany used to be regarded as a global leader in the transition to renewable green energies — especially wind and solar power — a project dubbed the “Energiewende”. But this is no longer the case. Germany has fallen behind to the rear of the pack.
Ironically the USA is leading the world in cutting back CO2!
Germany’s “self-deception”
The Düsseldorf-based daily Rheinische Post (RP) here writes that it’s time for Germany to “face inconvenient truths” concerning green energies and that pragmatic (and not ideological) action is needed.
The title of the commentary: “Self-deception in the green energy transition“
Green, cult-like dream now colliding with harsh reality
For years the German government, activists and alarmist scientists promised that green energies — foremost wind and sun — would be plentiful, cheap and clean. “Hooray!” the entire exclaimed in jubilation.
But today in its commentary the RP concedes that “the reality looks totally different” and that it is requiring “an enormous effort” just to keep the power grids stable as waves of unpredictable green power repeatedly surge into the power grid.
According to the RP, emergency power grid interventions by grid operators cost electricity consumers last year 1,4 billion euros. German households consequently pay 47% more for their power than the average EU.
Energiewende: “risky, inefficient and expensive”
And so what have German consumers gotten in return in terms of climate and CO2 emissions for all the extra pain? Nothing.
German CO2 emissions have stagnated (i.e. haven’t fallen at all). And according to the RP: “The German transition to green energy is in reality risky, inefficient and expensive.”
Energiewende “derailed”

The RP comments that highly ballyhooed headlines of new record amounts of green energy being produced don’t change a thing with respect to the failing green energy transition, and notes that although green energies made up 37% of the gross share of gross power consumption, these clean energies amounted only to a measly 13 percent of the entire German energy mix!




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The RP asks: “How could the German flagship project have derailed in this way?”
German dependence on coal “cemented for years to come”
The main reason for the failure, the RP writes, was Germany’s panicked rush to exit nuclear power in the wake Japan’s Fukushima nuclear disaster amid a deeply-rooted, collective and decades-old German aversion to nuclear power. This lead to the German government shutting down half of its nuclear power plants overnight and diving blindly into a rapid, unplanned expansion of wind and solar power.
The decision, the RP writes, was driven by the aim to shut down nuclear power, and not to reduce CO2.


The result, the RP comments: “Unfortunately, both goals are in direct contradiction. The politically desired phase-out of nuclear power has cemented our [German] dependence on coal for years to come. Its share is still 42 percent.”
The RP then comments that if Germany were really serious about reducing CO2, the country would not shut down its remaining nuclear power plants, which produce no “greenhouse” gas emissions.
Green energies “a naive illusion”
The RP also writes Germany should reconsider its efforts “to demonize diesel engines”, which have considerably higher fuel efficiency than gasoline engines. The move to eliminate diesel engines will make CO2 reductions more difficult. The RP also notes that electric cars “are no alternative” in terms of CO2.
100% renewables “a naive illusion” 
The RP calls the idea of covering all Germany’s energy needs through renewable energy “a naive illusion” and expects that the country will have to accept the fact that it will remain dependent on fossil fuels also over the long-term.
Also the collectively naive Germans in general need to get realistic and serious about what going 100% green entails. The RP comments:
Anyone who has solar cells mounted on the roof and then flies mindlessly to vacation on the Maldives, has not understood the problem.”
Public also opposes CCS
The RP finally comments on other possible technical solutions that could be employed to make the pain of having to go without fossil energies bearable, namely subsidizing CCS technology. However, a great number of Germans oppose that technology as well.
The way things are going, the RP suggests, Germany will never be able to meet its CO2 reductions targets.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterScroll down to see some Media Bad Weather Exaggeration Award winners…
In the wake of Florence, climate ambulance chasers have been making wild exaggerations and claims.
WaPo Weirding
For example, the Washington Post editorial board claimed President Trump and climate change deniers were “complicit” in Florence because they play down humans role in increasing the risks our obstruction of addressing those risks.
Of course this is just the latest pathetic effort to criminalize climate science dissenters.
CNN fake news again
Meanwhile CNN even claimed there’s been a 40% increase in extreme storms since 1950, hat-tip Ryan Maue, who commented:

CNN has a great weather coverage team in Atlanta … but network in past has a checkered record on climate science using Bill Nye as their expert.  Lol!
Now, they just outsource it to the political team in NYC.  Mostly poorly sourced gibberish. They can do better. pic.twitter.com/GwwGj8GUBR
— Ryan Maue | weathermodels.com (@RyanMaue) September 13, 2018

In a nutshell, climate alarmists will say anything, no matter how absurd, to make the junk science look real. It’s time to come to terms with the reality that the mainstream media often deceives the public.
Media silent on “complicit” in hurricane disintegration
If climate skeptics are complicit in Florence, then on the other side of the coin skeptics also have to be responsible for the hurricanes that fizzle out.
At Friday’s Daily Update, veteran meteorologist Joe Bastardi posed a question to the climate ambulance chasers and folks at the Washington Post: “How come Florence didn’t intensify more? How come Isaac is falling apart at the heart of the hurricane season? […] How come everything is dying? There’s so much more than just simplistic arguments that are done for agendas.”

Media totally AWOL as Isaac and Joyce dissipate. Chart: Weatherbell Analytics.
Often things just don’t work out the way the alarmists would like them to. And so they need to resort to less than honest tactics to convey drama over to the audiences.
2018 Media Weather Exaggeration Award 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Bad weather reporting has recently seen a series of blatant exaggerations aimed at making viewers think things are much worse than they really are.
This year’s 2018 Media Bad Weather Exaggeration Award has to go to Hurricane Florence reporter Mike Seidel below of The Weather Channel:

His projectile stunt also didn’t go very well.
Previous winners
And what follows are winners from previous years. Of course this is not to say that extreme weather can be taken lightly. But it would be nice if reporters stayed accurate. Their credibility is already pretty ruined and such antics don’t help.
One blooper comes from an MSNBC reporter covering the extreme conditions from tropical storm Hanna back in 2008:

 
What follows is my favorite, Hurricane Irene in 2011:

 
Next is Ryan Maue’s favorite — well, at least it’s one he brought up recently. In October, 2005, reporter Michelle Kosinski is using a canoe when a regular pair of rubber boots would have sufficed. Can we believe anything we see on our screens?

 
Right on par with Michelle Kozinski’s stagecraft is ABC’s Lucy Yang’s fake deep water after heavy rains in New Jersey, 2010:

 
It’s got to be frustrating when people totally ruin your dramatic story of danger and peril. The next video is of Hurricane Sandy in Atlantic City, New Jersey, 2012…CNN embarrassed again:

 
Finally, Anthony Watts presents here Anderson Cooper’s tactic used to fake deep flood water.
Share this...FacebookTwitter "
nan
"The case of Russian scientists trapped in their remote Arctic base by a group of inquisitive yet hungry polar bears does not come as a surprise. By late summer, Arctic sea ice is at a minimum and polar bears are effectively landlocked in coastal areas eagerly awaiting the return of ice during the autumn freeze and the chance to hunt seals again. The Arctic summer is also the time of year when scientific activities are at their maximum, with bases operating at capacity and fieldwork operations at full flow, particularly in tundra and coastal regions. Polar bears are hungriest when scientists are busiest – “encounters” are inevitable. Researchers working in the Arctic, particularly in and around the Arctic Ocean and its coastal seas, usually have to undergo some type of polar bear encounter training before embarking on fieldwork. This inevitably involves familiarisation with a large calibre hunting rifle and getting practice on a shooting range. Most Arctic settlements and scientific bases have a designated area for target practice and this can be accompanied by a short course on polar bear awareness. A rifle is a “must have” and should be kept close to hand when out in the field. However, it is usually the last line of defence. A team of researchers in the field are likely to be equipped with flares and flare pistols – the latter equipped with special “flash-bang” rounds, aimed at scaring off inquisitive bears. Warning shots with a rifle should also work in deterring a bear, but equally the start-up of a noisy snowmobile engine should have the same effect. The best advice is to pay attention to your surroundings and stay alert. This may seem obvious when operating in the vicinity of one of the world’s largest predators, but it is very easy for scientists to become absorbed with the task in hand. A team of scientists huddled around a broken instrument or focused on a rare plant will not be aware of an approaching bear. Operating from scientific research ships carries its own risks. While the ship itself provides security, people operating on sea ice need protection. Surprisingly, visibility on sea ice is often restricted by the presence of ice ridges. These are formed when sheets of ice press up against one another and broken chunks of ice may extend up to three meters above the ice floe. The ridges serve as excellent cover for bears, who use them as hunting corridors, relying on their keen sense of smell to search out prey. For this reason, teams operating on sea ice usually have one team member designated to “ride shotgun”. Pump action shotguns equipped with shells fitted with solid lead slugs are commonly issued on Canadian icebreakers. In the past, trapping and hunting were the biggest threat to polar bears and some populations were decimated as a result. However numbers have stabilised at around 20,000 to 25,000 since an international conservation agreement was signed in the 1970s – though polar bears are still officially classified as vulnerable. These days, the biggest threats are climate change and pollution. As these marine animals are long-lived – a 15-20 year life span is not uncommon in the wild – they accumulate a variety of industrial chemicals that enter Arctic foodwebs through the atmosphere and ocean currents that flow northwards.  Legacy pollutants such as polychlorinated biphenyls (PCBs) and the pesticide DDT may have largely been banned, but they still linger in the environment. When I carry out fieldwork in the Arctic, it’s these sorts of chemicals I’m looking for. The pollutants “cycle” between air, soil and sea, eventually accumulating in snow, ice and marine sediments. Once present in seawater and sea ice they are picked up by tiny algae and plankton, which are eaten by fish, and then bigger fish, and so on. At each stage the concentration of these chemicals increases, until they reach astonishingly high levels in polar bears which sit at the top of the food chain.   Concern has grown recently about newer pollutants such as halogenated flame retardants and organofluorine chemicals used in the production of “non-stick” pots and pans. These chemicals interfere with the immune and hormonal systems of polar bears, and they may even be weakening their penis bones.  The effect of climate change, which is most pronounced in the Arctic, is to accelerate spring melt and delay winter freeze, meaning that bears remain landlocked for longer periods of time during the summer. This increases the risk of summer starvation and this, alongside the “co-stress” provided by a changing cocktail of contaminants, provides an existential threat to the polar bear. This brings us back to the poor Russian scientists holed up in their base. Bears will adapt and seek out new food sources during their summer wait. Hunger and starvation may make them bold and more persistent in their quest for food and is only likely to increase the frequency of human-bear encounters."
"The nuclear industry provides about 15% of the UK’s electricity, makes a vital contribution to the country’s carbon cutting ambitions and is a remarkably safe form of energy with no major accidents since the Windscale Fire in 1957. But despite all this, it still seems to suffer from disinterest and distrust from the public and these factors continue to dominate the nuclear narrative. The industry is green, safe and has the potential to create many high-tech jobs. Why then is the nuclear industry so often seen as a guilty secret rather than a national treasure, with most of the public opting for ignorance or ambivalence? Perhaps one reason the public has so far failed to embrace nuclear power is that people feel excluded from the journey it is taking and lack any influence over how new nuclear solutions might emerge. It is high time the industry found a way to make its case and forge its future, hand in hand with the British public. So here are a few thoughts on why this is so important and how, over time, it might be achieved. Nuclear power is making a key contribution towards the government’s Clean Growth Strategy which aims to reduce carbon emissions. Within this strategy, the government has committed to supporting the replacement of existing reactors as they come to the end of their lives. This has resulted in huge multi-billion pound projects at Hinkley Point in Somerset, Wylfa on Anglesey and Moorside in west Cumbria.   But all of these projects (particularly Hinkley Point) continue to attract significant controversy around affordability – a debate which does nothing to promote long-term public confidence.  To guard against nuclear accidents like Fukushima and Chernobyl – and in an attempt to make the public feel safe – the nuclear industry has always looked to shield, protect and distance society from risk. It has sought to offer reassurance through the power of its own expertise and the promise of strict control. Of course, telling the public they don’t need to worry about something they can’t hope to fully understand – and traditionally associate with cataclysmic destruction – is virtually guaranteed to get their palms sweating. So, for many, nuclear investment has never risen above the status of a reluctant distress purchase, and is often better not contemplated at all  In reality, the UK’s nuclear energy story encompasses all the features necessary to capture the public’s attention and hold onto it. It’s an amazing technical concept and a high stakes journey of risk and reward with the future of the planet as the prize. If the industry wants to truly engage, then surely it needs to find new ways to invite people along for the ride. One new approach to public consultation uses so called “hybrid forums”. These forums bring together scientists and a diverse range of concerned stakeholders (such as local citizens, pressure groups and academic experts). These forums are convened to let problems emerge and to create a vision of the future that is common to everyone.  One example of a hybrid forum took place to address chronic flooding problems in North Yorkshire. The forum enabled everyone who took part to share their knowledge and expertise and alight on the radical alternative solution of gradually arresting the flow of floodwater, rather than providing expensive defences in the area itself. Today’s nuclear grand challenges – like providing affordable nuclear power stations and disposing of nuclear waste – are “social” problems with resolutions which lie in creating and maintaining public support over many years. This is a common feature which makes them well suited to such a hybrid approach. The hunt is already on for a volunteer host community for a Geological Disposal Facility (GDF) for the underground disposal of radioactive waste. Volunteer communities are compensated for hosting the facility through community investment funding. With a GDF, radioactive waste would be put hundreds of metres underground. This is internationally recognised as the safest long-term solution to nuclear waste disposal. Having one in the UK will create jobs and guarantee investment for whichever community takes it on. There is also growing interest in Small Modular Reactors or SMRs. These are lower cost, factory-built units that provide localised power. Widespread adoption of SMRs as a more affordable alternative to large scale plants would mean many new nuclear sites would need to be established – many in urban areas. This, again, requires long-term public support.   SMRs have generated government and industry interest internationally because designers have suggested they may offer lower investment risk, cost less and offer greater compatibility with the electricity network. The University of Manchester has set up The Beam Nuclear and Social Research Network to investigate the social challenges bound up in the UK’s nuclear future. We want to tackle all these questions head-on and bring fresh insights. But the ultimate test will be whether these insights can be made to resonate within the industry itself. The nuclear debate must be expanded and enriched for the benefit of everyone. I hope that our research will help the general public to think more passionately about what the UK’s nuclear future could be like and whether current nuclear policy is taking us there."
"Greta Thunberg and fellow youth climate campaigners are demanding that global leaders immediately end the “madness” of huge ongoing investments in fossil fuel exploration and enormous subsidies for coal, oil and gas use. The 21 young activists are also calling on the political and business leaders who will be attending the World Economic Forum in Davos to ensure investment funds dump their holdings in fossil fuel companies.  “Anything less would be a betrayal against life itself,” said Thunberg and colleagues in an article in the Guardian. “Today’s business as usual is turning into a crime against humanity. We demand that you play your part in putting an end to this madness.” The burning of fossil fuels is the biggest driver of the climate emergency. Scientists predict catastrophic impacts unless deep cuts in emissions are made rapidly, but global emissions are still rising. “Young people are being let down by older generations and those in power,” the climate strikers said. “To some it may seem like we are asking for a lot. But this is just the very minimum effort needed to start the rapid sustainable transition.” Much of the world’s existing coal, oil and gas reserves must be kept in the ground to avoid the worst impacts of global heating. But investment in fossil fuel exploration and extraction remains high. Since the Paris climate agreement in 2015, the world’s largest investment banks have provided more than $700bn (£535bn) to fossil fuel companies to develop new projects, with the total investment estimated to be trillions of dollars. Fossil fuel companies argue that their products will be used for many years to come and that they have a pivotal role in shifting the energy system to zero emissions. But their investments in green energy are tiny compared with those in fossil fuels. Subsidies for fossil fuels also remain high despite a G20 pledge in 2009 to eliminate them. The IMF estimates such subsidies run at $10m a minute, or $5.2tn a year. “The fact that [ending investment and subsidies] hasn’t been done already is, quite frankly, a disgrace,” said Thunberg and colleagues. Investors managing funds totalling $12tn have already divested from coal, oil and gas, but the climate activists demand that “all companies, banks, institutions and governments immediately and completely divest from fossil fuels”. Mark Carney, the governor of the Bank of England, said in December that the financial sector was not cutting investments in oil and gas companies rapidly enough and warned that assets in the sector could end up “worthless”. He said in October that companies and industries not moving towards zero-carbon emissions would be punished by investors and go bankrupt. “It ought to be in every company and stakeholder’s interest to make sure that the planet they live on will thrive,” said the climate strikers, who come from nations across the world, including the US, Australia, Brazil, Russia, India and Nigeria. “But history has not shown the corporate world’s willingness to hold themselves accountable. So it falls on us, the children, to do that.” The agenda for the 50th annual meeting of the World Economic Forum, which begins on 20 January in Switzerland, lists four “urgent and important” global issues. The first is “how to address the urgent climate and environmental challenges that are harming our ecology and economy”. The climate strikers said: “The world’s leaders should invest their money in existing sustainable technologies, research and in restoring nature. Short-term profit should not trump long-term stability of life.”"
"Back in 1839, public health expert J F Murray published his article The Lungs of London, in Blackwood’s Edinburgh Magazine. Even then, city dwellers appreciated the advantages of open, green spaces. Murray described the benefits of the parks of London as “great vehicles of exercise, fresh air, health, and life to the myriads that congregate in the great metropolis”. Living in cities offers numerous advantages in terms of employment, education, healthcare and social communication, among others. But urban living also comes with its challenges: in particular, urban environments can put a strain on mental and physical health, because they tend to be noisy, polluted, overcrowded and hot.  Ecologists are increasingly turning their attention to urban areas, in an effort to find solutions to these problems. Their work is beginning to show us how cities can be designed to accommodate all the advantages – and minimise the disadvantages – of urban living.  Specifically, urban ecologists are considering how we can enhance “ecosystem services” for those living and working in cities. It is now widely recognised that ecosystems – including urban ecosystems such as parks, protected areas and waterways – provide essential services for people. Temperature regulation, air purification, noise reduction, human well-being, carbon storage (both above and below ground), water infiltration, agricultural production, pollination, and pest control are examples of the services that urban ecosystems can provide.  Of course, besides services there are also so-called disservices, such as noise pollution and high temperatures, that can be associated with open spaces. For instance, some people find that the dawn chorus of birds in spring affects their sleep patterns, or that they suffer from hayfever when there are high pollen counts. But now, armed with an understanding of ecosystems and the services they provide, ecologists are now able to shine some light on a central question in urban planning: should cities be designed so that intensive and extremely compact urbanisation sits alongside separate, large, continuous green spaces – an approach known as “land-sparing”? Or, is it better to adopt “land-sharing”, where compact green spaces are scattered throughout the urban sprawl?  A recent study by researchers from the University of Exeter and Hokkaido University, Japan, found that land-sparing is the most effective approach to maintain the majority of ecosystem services. But they also recognise that some degree of land-sharing is important, especially when it comes to the ecosystem services that benefit our well-being.  Being near high-quality green space can provide important health benefits, as well as “cultural ecosystem services”, such as places for recreation, spiritual and religious enrichment, education, cultural heritage, inspiration, social gatherings, and cultural diversity. If a city is to provide these services, it needs to be designed so that people can quickly and easily access green spaces as part of their everyday activities. The authors of the study concluded that the best way to ensure the optimum distribution of development and green space is to take a top-down, policy-led approach. Changing the design of a city is no easy matter, but we know from experience that it can be done.  As far back as 1809, architect John Nash began work on Regent’s Park in London, where much of his input can still be seen today. In 1858, Frederick Olmsted won the competition to design Central Park in the heart of New York. And in the 1870s, Baron Haussmann – who was charged with redesigning Paris – wanted to join the Bois de Boulogne with the Bois de Vincennes to make a green belt around the city.  These are all perfect examples of land-sparing, but it is worth noting that these green spaces were established when the cities were already in the process of being redesigned.  A more recent example of land-sparing is the 300 hectare Tempelhof Airport in Berlin. The site was earmarked for development, but the public voted to retain it as a large, open, green space in May 2014. Ingo Gräning, of the state-run Tempelhof Project stated: “No other city would treat itself to such a crown jewel [of open space]”.  Of course, not all cities have enough available land to “treat” themselves in this way. In densely-built cities like Hong Kong, the opportunity to create large open spaces may never arise. Berlin is an exception – many cities do not have the option of dropping a large park into a built-up area, and in most cases it is not feasible to combine lots of small parks and gardens into a large green area. A lot depends on the history of a city and its geography, and land-sparing is not an option for every location. Ebenezer Howard – the first modern urban planner theorist – recognised this, when he initiated the Garden City movement in 1898. His aim was to bring the advantages of nature to city dwellers, by introducing compact green areas and small parks into cities. The first examples of Howard’s organised land-sharing can still be seen today, in the UK towns of Letchworth and Welwyn. So when asking ourselves which approach is best, there is no straightforward answer. Whether land-sparing or land-sharing is most effective will depend on the context; factors such as the shape of the land and the existing developments in the area will all play a part. But there is no doubt that cities benefit from the services offered by urban ecosystems, and both land-sparing and land-sharing are important means of providing these advantages."
"Surprise will have been many people’s understandable reaction to learning that Extinction Rebellion, the environmentalist network, was listed by British counter-terrorism police alongside violent neo-Nazi and Islamist groups in a guide to “extremist ideologies”. The document, issued to schools, included instructions to look out for those who use “strong or emotive terms” when discussing climate change or pollution. Since 2015, teachers have been under a statutory duty to refer students suspected of extremist sympathies to the anti-terror Prevent programme, with education now the main source of referrals (in 2017-18 these included 2009 children under 15). A suggestion that participation “in planned school walkouts” could be grounds for suspicion is particularly egregious, given that the school strike movement’s stated aim is for governments to act on climate scientists’ warnings. But what is particularly dispiriting about this ill-judged document is that the bracketing of green groups with terrorists is far from a one-off. Instead, and as numerous activists spied on by police in the past know (including an unknown number of women tricked into sexual relationships by officers), the treatment of environmentalists as dangerous subversives is consistent with longstanding attitudes to green issues at the highest levels of the British state.  Such views do not have a monopoly. Sir Peter Fahy, the former police chief who led Prevent from 2010 to 2015, has criticised the approach to Extinction Rebellion as counterproductive. But at a time when public concern about the climate emergency in many countries has never been higher, with bushfires ravaging Australia and new analysis showing record rises in ocean temperatures, the decision of the home secretary, Priti Patel, to highlight alleged “security risks” from green groups when asked about the issue is grounds for alarm. Climate policymaking is a global challenge and the stakes in 2020 could not be higher. If legally binding cuts on greenhouse gas emissions are not agreed at a crunch round of UN talks in December, then the world will be in a very dark place indeed (experts say emissions must be reduced by 7.6% per year for a decade if we are to avoid the most destructive scenarios). With that summit due to be held in Glasgow, the UK government has a vital role to play. But so does civil society, including activist groups such as Extinction Rebellion. The litany of failures of climate policy so far suggests that unless millions of people exert pressure on their leaders, governments will fail to take the necessary steps. In this context, it is a grotesque distortion of reality to suggest that young people who join peaceful climate protests bear any resemblance to terrorists. Fossil fuel companies, and asset managers such as Vanguard that consistently oppose climate resolutions, show far greater recklessness with regard to human life. Extinction Rebellion’s founders may declare support for alternatives to capitalism, but their grasp of climate science belongs not beyond the pale, but in the mainstream. Of course, the police must prepare for the disruption caused by civil disobedience. Such actions do not command universal support and in some cases are planned to maximise pressure on police resources. But none of this has anything to do with counter-terrorism. The government’s delayed review of Prevent must now take place, with a thorough examination of this episode as part of its remit, and clear advice as to how those affected can seek redress."
"
Share this...FacebookTwitterA very recent study by Swedish scientists appearing in the journal Climate of the Past examining bottom water temperature (BWT) off the coast of Western Sweden (Gullmar Fjord) going back 2500 years found that “the most recent warming of the 20th century does not stand out.”

Team of researchers led by Irina Polovodova Asteman, University of Gotheberg, produced a record of bottom water temperature off the coast of western Sweden and found 20th century warming “does not stand out.” Photo: ResearchGate, University of Gothenburg
The 2500-year winter temperature record was of reconstructed by using a fjord sediment archive from the NE Atlantic and through analysis of oxygen isotopes and other methods. The study was based on an approximately 8-meter long sediment core extracted from the Gullmar Fjord (Sweden).
They found that the Gullmar Fjord d18O record mainly reflects variability of the winter bottom water temperatures with a minor salinity influence.
The researchers also pointed out that a comparison with instrumental winter temperature observations from Central England and Stockholm shows that the fjord record picks up the contemporary warming of the 20th century, see following diagrams:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




t

t

Chart: Polovodova et al 2018
According to the scientists, the Gullmar Fjord record shows a substantial and long-term warming during the Roman Warm Period (~350 BCE – 450 CE) which was followed by variable bottom water temperatures during the Dark Ages (~450 – 850 CE).
The Viking Age/Medieval Climate Anomaly (~850 – 1350 CE) is also indicated by positive bottom water temperature anomalies, while the Little Ice Age (~1350 – 1850 CE) is characterized by a long-term cooling with distinct multidecadal variability.
The team of Swedish scientists, led by Irina Polovodova Asteman, Department of Marine Sciences, University of Gothenburg, Sweden, noted “the most recent warming of the 20th century does not stand out, but appears to be comparable to both the Roman Warm Period and the MCA (Medieval Climate Anomaly).”
 
Share this...FacebookTwitter "
nan
nan
"It’s too early to say whether the prime minister, Scott Morrison, is speaking with a forked tongue when he says the government will “evolve” its climate change policy. What appeared on Sunday to be a shift in rhetoric on the government’s emission reduction targets may be meaningful – or it may yet prove to be deliberately duplicitous.  Morrison is clearly under pressure on the government’s unambitious climate change policy, an issue that may have remained conceptual for some if not for the horror bushfire crisis that has laid bare the consequences of a warmer planet. For months, the prime minister has refused to yield on calls for more ambitious action, saying the government was doing enough and would “meet and beat” its Paris target of reducing emissions by 26% to 28% of 2005 levels by 2030. But as the cries for action have become louder – including from a group of former fire chiefs who have clearly linked the fire crisis to the effects of climate change in Australia – Morrison is detecting the whiff of backlash. Despite his ill-judged family holiday to Hawaii, and what was arguably a tardy national response to the fires, Morrison is not politically naive. He knows that the political pressure over climate change is only becoming more intense, and will be most profoundly felt in inner-city seats held by moderate Liberals, particularly in Sydney, Melbourne and Brisbane. Like a verbal Rorschach test, Morrison’s media appearances on Sunday were open to interpretation, but designed to give the government wriggle room. A conservative Queenslander who works in a coal seat? Morrison wants you to hear the message that he won’t be changing course. But a moderate Liberal in Victoria? Morrison’s message for you is he plans to “go further” on emissions reduction. Does climate change cause bushfires? The link between rising greenhouse gas emissions and increased bushfire risk is complex but, according to major science agencies, clear. Climate change does not create bushfires, but it can and does make them worse. A number of factors contribute to bushfire risk, including temperature, fuel load, dryness, wind speed and humidity.  What is the evidence on rising temperatures?  The Bureau of Meteorology and the CSIRO say Australia has warmed by 1C since 1910 and temperatures will increase in the future. The Intergovernmental Panel on Climate Change says it is extremely likely increased atmospheric concentrations of greenhouse gases since the mid-20th century is the main reason it is getting hotter. The Bushfire and Natural Hazards research centre says the variability of normal events sits on top of that. Warmer weather increases the number of days each year on which there is high or extreme bushfire risk. What other effects do carbon emissions have? Dry fuel load - the amount of forest and scrub available to burn - has been linked to rising emissions. Under the right conditions, carbon dioxide acts as a kind of fertiliser that increases plant growth.  So is climate change making everything dryer?  Dryness is more complicated. Complex computer models have not found a consistent climate change signal linked to rising CO2 in the decline in rain that has produced the current eastern Australian drought. But higher temperatures accelerate evaporation. They also extend the growing season for vegetation in many regions, leading to greater transpiration (the process by which water is drawn from the soil and evaporated from plant leaves and flowers). The result is that soils, vegetation and the air may be drier than they would have been with the same amount of rainfall in the past. What do recent weather patterns show? The year coming into the 2019-20 summer has been unusually warm and dry for large parts of Australia. Above average temperatures now occur most years and 2019 has been the fifth driest start to the year on record, and the driest since 1970. Is arson a factor in this year's extreme bushfires? Not a significant one. Two pieces of disinformation, that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush have spread across social media. They have found their way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. Morrison’s allegiance to the party’s centre-right faction has given him more rhetorical flexibility in his response to climate change than conservative MPs ever allowed his predecessor, Malcolm Turnbull. But conservatives will become suspicious – and unruly – if the man they believe to be one of their own actually wants to back up this latest change in rhetoric with action or substantial policy change. On the other flank of the party, there is an emerging view – from a clutch of at least a dozen MPs – that climate anxiety can no longer be ignored. These MPs will be demanding more. Moderates are hoping that Sunday’s rhetorical shift is the first sign of a pivot – that of a pragmatic prime minister attempting to turn around the Queen Mary. But conservatives will be hoping that Morrison is all talk, no action. Morrison has been attempting to paper over the cracks within his partyroom by insisting that there is “no dispute” within the coalition that climate change is linked to the bushfire crisis, despite abundant evidence to the contrary. It was no accident that Morrison told his MPs last week in a phone hook-up to shut their collective trap on climate change policy until after the fires abated. Climate change policy has dogged the conservative side of politics for more than a decade, and there is no reason to expect that Morrison will be left off the hook. But he is not Tony Abbott, and nor is he Malcolm Turnbull; he carries none of the ideological baggage of his predecessors. This could prove a great strength for Morrison as he seeks to navigate a new policy path through such politically dangerous territory. Shifting course is, as the prime minister said on Sunday, “a challenging task”. But it’s now clear that the status quo is untenable."
"In late 2019, before the bushfires hit crisis level, concern about climate change in Australia was at record levels. Since then at least 27 people have lost their lives, millions of animals have died and the navy has been called in to evacuate beaches. The devastating impacts of climate change are tragically becoming real for many. And many, from bushfire survivors to business leaders to firefighters, are calling for action. As a result, we are in a moment where the opportunity to implement effective and long-lasting policy to lower Australia’s climate pollution could finally be within reach. Indeed, the independent MP Zali Steggall has announced her intention to introduce a climate bill into federal parliament in March. Meanwhile the New South Wales energy minister, Matt Kean, has asked the state’s chief scientist to identify opportunities for NSW to lead on climate action. Even the NSW Young Liberals have put forward a plan to act on climate.  To grasp this opportunity we must learn critical lessons from the past. This is not the first time that public support for climate action has been sky high, nor the first time that political opportunity for far-reaching policy has presented itself. In 2007 Kevin Rudd was elected with a huge mandate to act on climate. In 2011 the Gillard government, with support of the crossbench, implemented the extremely effective clean energy future package. And last year people across the country worked tirelessly to make the federal election a climate election. In all three of these cases, we lost in the how – how should Australia go about acting on climate? In the first instance, we lost momentum for action because we could not agree on the effectiveness of a policy – would the carbon pollution reduction scheme with its 5% emissions reduction target be a springboard for further action, or lock in rights to pollute for our biggest emitters? In the second case, climate deniers such as Tony Abbott weaponised the carbon price policy for political ends, running the extremely effective “Axe the tax” scare campaign. Furthermore, the carbon price was for many Australians an abstract policy idea disconnected from their lives but perceived to be hurting their hip pockets. In the third, a poll by the Australia Institute found that there was simply not enough awareness of the differences between the two main parties’ energy and climate policies. With renewable energy booming, the federal Coalition was able to paint itself has having a reasonable and sensible climate policy, even though it has anything but. I raise these painful moments in history not to rehash the past but rather to see what we can learn for the future. Because we need to recognise that from public policy and political perspective, climate change is hard – the causes (burning fossil fuels and reducing carbon sinks) are distant from the impacts geographically and temporarily. Its solutions practically are many and the policies needed often complex. Not to mention the fact that Australia has a powerful fossil fuel lobby and, in each of these moments, it took advantage of the disagreement, disconnection and lack of understanding to good effect. Looking forward, we are now presented with both a policy challenge and communications challenges. First, can those who care about climate unite behind practical solutions and policy options that will be: effective at lowering emissions; connect with real people’s lives; and are easy and compelling for the average person to understand? Second, can we communicate a set of success measures against which everyday Australians can judge the effectiveness of a policy or a government on climate? I propose five tests or questions that could help us meet these policy and communications challenges: Is carbon pollution going down in real terms? Can the government point to real-world action and policies that are being implemented now, this year, to lower emissions that are commensurate with the scale of the problem? Does the government have a plan to fully decarbonise every sector of the economy – electricity, transport, industry, buildings, agriculture and land use? And ones that address the biggest opportunities and threats, for example a renewable export plan and a bushfire plan? Do these plans deliver co-benefits in each sector that make people’s lives better? For example, creating new jobs, new industries, healthier and more liveable? homes, less traffic congestion, lower electricity bills and less air pollution. Is the government or policy reducing and removing support for fossil fuels and/or other causes of climate change? If the answer is no to these questions, the policy isn’t working, the government isn’t acting on climate, it’s unlikely to be popular and thus long-lasting and it isn’t fulfilling our obligations under the Paris agreement. The basic idea that underpins these tests is that actually to address climate change we need a plan, or in reality multiple plans. For too long, climate policy insiders and commentators have been obsessed with carbon pricing. Carbon prices, like other policies can be well designed and effective, or badly designed and ineffective. But whether a carbon price is well designed or not, it’s only one tool in the policy toolkit for decarbonising Australia. Other tools include regulatory changes, investment in research and development, new standards, support for new markets and so forth. A plan is needed for each sector of the Australian economy that brings together these different policy levers or tools and different actors to do the hard work of decarbonisation. Work, that the climate science says is urgently required but, if done right, could lead to a better, more prosperous Australia. The good news is we are starting to see different organisations calling for a plan. For example, WWF-Australia is calling for a climate plan and have done the research needed to communicate it to mainstream Australia. Farmers for Climate Action are calling for the development of a climate and agriculture strategy. The Climate and Health Alliance is advocating for a climate and health plan. While, Renew, the Australian Council of Social Service, the Energy Efficiency Council and many others are working on a plan for existing buildings that is starting to gain traction. The good news is all of these organisations are building diverse coalitions, talking about the non-environmental benefits that can be delivered by acting on climate in their respective sectors. Australian’s trust in its political leadership is at an all-time low, perhaps this is a moment that leaders across all states and territories to redeem our faith in politics and end the climate wars, with the humble task of drawing up a plan. Nicky Ison is the energy transition manager at WWF-Australia and a research associate at the Institute for Sustainable Futures at the University of Technology Sydney"
"Australia is a fire continent. Imagine California on the scale of the 48 contiguous states, but drier, more routinely kindled and with winds that can transform large swathes of land into a veritable fire flume. From time to time, its simmering flames boil over into seeming tsunamis of fire. And Australia has a culture to match. It has institutions to study, fight and light fire. It has a literature of fire, a folklore of fire and a fire art that is continuous from Indigenous bark paintings to modernist musings. It has special bushfire collections at its museums. It has a fire politics: on three occasions conflagrations have sparked royal commissions, and from 2009 to 2017, 51 official inquiries.  The worst fires have acquired names and become historical milestones, such as Red Tuesday (1898), Ash Wednesday (1983), Black Christmas (2001), Black Saturday (2009). Now they are joined by the as-yet unnamed megafires of 2019-20. Call them the Forever fires, for they seem inextinguishable, burning with implacable insistence and smoke palls that extend their reach far beyond the flames’ grasp. Yes, Australia and bushfire are old acquaintances. But the past 20 years feel different. The bad fires are more frequent, more eruptive and more damaging. The Black Saturday fires, which killed 173 people, struck with the cultural force of a terrorist attack, and seemed to call into question the very premises of a “first world” society on a land capable of such fury. The Forever bushfires deepen that query. But there are two other fires that provide a wider panorama. One is overt – the fires that burn living landscapes, the bush. The other fire is covert, because it burns lithic landscapes. These are the once living, now fossilized biomasses such as coal and gas that we combust to power our industrial economies. Those two fire realms are interacting in ways that are proving ever more entwined and threatening. That so many fires in Australia (and California) start from power lines is an apt metaphor for the way the two realms of fire interact. The secondary effects are not restricted to global warming or ocean acidification. They affect how people organize landscapes – their agriculture, nature reserves, transportation grids – all aspects of geography that, in turn, influence the character of bushfires. We have been burning our combustion candle at both ends. Now, it’s payback time, and the two types of fire are colluding. Australia’s predisposition to fire makes it an early flash point for what I like to call the Pyrocene. But many of the same phenomena are appearing in America – unstoppable fires, fire deaths and fire refugees, smoked-in and incinerated cities, damaged watersheds and post-burn floods, economic crunches from lost tourism, bankrupt utilities, snake-bit insurance companies. Wildfires moving from exurban fringes to city cores. Extended states of emergency. Prolonged and painful cleanups. Political anger. The areas of the US with a history of fire will suffer the worst burns, but the combustion miasma will seep into other, seemingly immune, parts of the country. Paradoxically, places like California long frequented by fire are better prepared to cope with the coming crises. Places unaccustomed to fires lack the institutions and infrastructure, and they will struggle. Even if fossil fuels somehow cease overnight, greenhouse gases will still take a long time to work their way out of the atmosphere, so the climatic effects will linger. This puts the immediate focus on coping with landscape fires. There is plenty to do – harden communities, get more good fire into the countryside, design to accept that landscape fire is not a freak apparition from the fringe but an informing fact of modern life. Wild, feral or prescribed, there is much more fire to come. We have created the fire equivalent of an ice age. The latest round of Australian fires will stop at the country’s shores. The Pyrocene, however, will affect all of us, and persist long into the future. Steve Pyne is an emeritus professor at Arizona State University, and the author of Burning Bush: A Fire History of Australia and most recently the second edition of Fire: A Brief History"
"Donald Trump is going to acquire a book. The book in question, as Gizmodo reported on Thursday, is titled Donald J Trump: An Environmental Hero, by Edward Russo. And the shocking news emerged as the president announced a rollback of environmental regulations at the White House, taking an axe to the environmental review process required for infrastructure projects. The move, which he pitched as a way around “endless delays” to various projects, poses a new threat to the climate and is likely to face legal challenges.  The president’s war on the environment is nothing new. His plan to bury his nose in a book is. Trump isn’t known for his literary bona fides. Though the bestseller The Art of the Deal helped make his name, it was ghostwritten by Tony Schwartz – who deeply regrets his work on the book. Ghostwriters have been involved in most, if not all, of his many other volumes. “He doesn’t read books and he doesn’t write them,” Schwartz told the Independent in 2018. (The late-night host Samantha Bee has developed a conspiracy theory that Trump can’t read at all.) But one subject fascinates the president so much that he’s willing to invest in a volume of prose. That subject is, of course, himself. The president highlighted Russo’s volume in his own defense after a question over whether he feels the climate crisis is made-up. “The environment is very important to me. Somebody wrote a book that I’m an environmentalist – it’s actually called The Environmentalist … I’d like to get it,” he said, before apparently contradicting himself and suggesting he already had it “in the other office”. Russo, who has advised Trump, describes himself as a lifelong advocate for the planet. His self-published work claims to offer “a personal picture of a man who doesn’t just care about success but the impact of his success on the world”. Trump, the book’s blurb says, offered Russo a job to ensure that Trump’s business developments wouldn’t “negatively affect habitats”, conjuring an image of a concerned Trump nodding thoughtfully as Russo warns of the toll his latest golf course could take on the local squirrel population. The book seeks to counter a narrative – supported by robust evidence, including Trump’s decision to pull the US out of the Paris climate agreement, his assault on Obama-era environmental rules, and his complaints about excessive toilet flushing due to low water pressure – that the president actually doesn’t care very much about the planet. Speaking to reporters on Thursday, Trump sought to paint a very different picture of himself. Asked about the climate crisis, he said, according to the pool report: “Nothing’s a hoax about that. It’s a very serious subject … I’m a big believer in that word, the environment.” That would seem to run counter to his previous claims that the climate emergency is a Chinese hoax and casting doubt on global warming during a snowstorm. As for Russo, his own brand of environmentalism seems a little shaky. He has hailed proposed EPA budget cuts, suggesting they will increase the agency’s “focus”. “Every time there’s lightning or thunder that, oh, it’s climate change,” he told the energy news site E&E News in 2017. “Climate change is a natural change in balance of the Earth, it happens all the time.” Whether the book’s claims of environmental heroism are accurate or not, the president appears to have developed an interest in the written word. We can only hope his newfound passion means a little less TV time."
nan
"The huge moorland fires at Saddleworth and Winter Hill in northwest England have shown just how serious a problem wildfires can be in the UK. Now the fires are out, it is time to look at how such catastrophes can be prevented in the future and why this critical environmental issue needs to be on the political agenda.  Our research has shown how informal local and national partnerships helped keep the flames under some form of control and can reduce the risk of future fires on this scale. But the government needs to support these partnerships and see wildfire as more than a fire service problem. Climate change will make such fires more common so the country must be ready. Managing moorland wildfire risk is not just about putting out fires. It is also about reducing the risk of fires starting and spreading. This involves the cooperation of many diverse interest groups, so fire and rescue services work collaboratively with other stakeholders such as mountain rescue groups, local councils, police forces and government agencies. As the Scottish government wildfire manual (section 8A.20) acknowledges, it would be impossible for fire and rescue services to attempt to address the risks in isolation.   Fire crosses property and administrative boundaries so cooperation between agencies and interest groups is vital. Informal partnerships have developed to coordinate efforts. Local fire groups have formed to share expertise and firefighting equipment. The Peak District Fire Operations Group (FOG was one of the first. It is six local fire services, three water companies, amenity groups and other landowners working together to prevent and prepare for wildfires. There are now at least 20 such groups across the UK, spurred by bad fire seasons in 2003, 2006 and 2011. These collaborations, championed by Northumberland Fire and Rescue Service among others, have changed the approach to fighting UK wildfires. 


      Read more:
      How climate change is increasing the risk of wildfires


 Fire groups train together and share resources. Standard gauge hoses now mean that fire brigades can join them together in a “water relay” to reach remote fires. The Peak District group includes Pennine helicopters – seen on the news dumping water on the moorland fires in Lancashire and Greater Manchester. The Lancashire FOG uses the Bay Search and Rescue’s large all-terrain vehicle – normally used to traverse Morecambe Bay’s sands – to ferry people and heavy equipment across soft peat moorland. Bolton Mountain Rescue served as tactical lookouts, spotting flare-ups at the Winter Hill fire. Land managers provide all-terrain vehicles and “fogging units” with fine sprays to wet vegetation, while countryside rangers and landowners bring local knowledge of the terrain.  Formal multi-agency working is also required at major incidents, including help from other emergency services, the military and utility companies. There is no separate national fire service for wildfires. Instead, the UK’s 54 fire services help each other, so wildfire training is vital for all crews.  Saddleworth Moor fire crews had help from a Wildfire Tactical Advisor, one of a new national “flying squad” of specially trained regional officers, recently set up by the National Fire Chiefs Council Wildfire Group.  The England and Wales Wildfire Forum and its Scottish equivalent share good practice nationally and raise awareness of wildfire issues. Although unfunded, they have become the “go-to” bodies for government on wildfire issues.   They collaborate with UK wildfire researchers to match practitioners’ needs with wildfire research expertise, although many research gaps still remain. Critically, the UK does not have a suitable fire danger rating system to predict when and where wildfires will occur and their impacts.  


      Read more:
      A high-adrenaline job: 5 questions answered about fighting wildfires


 Key fire service personnel in the UK have also gained valuable skills through international collaboration – for example, with the Pau Costa Foundation in Catalonia and the US’s Prescribed Fire Training Exchange (TREX). They learned how to predict wildfire behaviour by reading the landscape. Fire travels faster upwards on sunlit slopes and with the wind. Crews now use this knowledge in what is called indirect attack – this involves “starving” strategic locations in the fire’s path of fuel by mechanical clearing or controlled “defensive burning”. A more robust planning and prevention approach to wildfire has evolved over the last 20 years, thanks to these informal local and national partnerships and international training. But the UK’s wildfire problem has only recently been recognised by national policy. Major fires in 2011 were a catalyst for severe wildfire to be included in the National Risk Register. The Natural Hazard Partnership now includes wildfire in its daily hazard assessments.  


      Read more:
      How the land recovers from wildfires – an expert's view


 Local and national partnerships have proved an effective response, despite stretched resources, and deserve government support. Without these bottom-up initiatives, fire crews fighting the blazes on Saddleworth Moor and Winter Hill would have had an even more arduous task.   Wildfire is more than just a fire service issue. Any change in land use or land management which affects ignition sources (people) or fuel (vegetation) can also change wildfire risk, whether deliberately or unintentionally. Either way, planning ahead to manage wildfire risk should be firmly on the political agenda."
"A Dutch district court has ordered the Netherlands to cut greenhouse gas emissions to 25% lower than 1990 levels by 2020. This is several percentage points deeper than the 17% reduction the country had been envisaging. While such a ruling may seem astonishing at first, the move by civil society to take on individual states for a global collective lack of progress on emissions reductions makes perfect sense. Whether anything will change in the Netherlands in the short term remains to be seen. Instead, by setting a precedent and inspiring further actions, this ruling may have its greatest impact elsewhere in the world. The judgment implies that failure to address climate change and the harm it may cause is seen as a civil wrong in the Netherlands, within the scope of the tort law that people can appeal to when they have been wrongfully harmed. True, the Dutch government had argued that it is fully complying with its international obligations. But the judges point out that, since the Netherlands agrees measures should be taken to limit global warming to 2℃ above pre-industrial levels, the presence of a gap between international obligations and what would actually be needed to meet the 2℃ target does not take away an independent duty of care. The government could have seen this coming. The 25% figure is the product of Dutch scientific assessment work done about a decade ago and recently updated in the run up to Paris. This work was subsequently included in the IPCC’s Fourth Assessment Report back in 2007. Furthermore, the country’s present implementation of its energy strategy – based on a 2013 cross-party Energy Accord which focused on efficiency and renewable targets, rather than reduced emissions – will result in only a 17% reduction for the Netherlands. The gap is obvious. The judges rightly observed that at present the numbers do not add up to what is needed. They subsequently argue the Netherlands should do more: if you see a disaster coming but you don’t do enough to mitigate it, when you could have, you are liable. The same reasoning used by the Dutch judges for declaring tort law valid for dealing with climate change could be applied elsewhere. Each government has a duty of care towards its own citizens – and also towards other and future citizens. Developed countries have both ethical and legal obligations to cut greenhouse gas emissions – an obligation that holds even if adequate international agreements have not yet materialised. It’s interesting to see the climate science accumulated over the past decades by the IPCC being used directly by national judges. This approach may receive a boost after the Paris summit later this year, as it’s questionable whether governments will deliver a strong and legally binding agreement on emissions. If they don’t, judges in other countries could produce similar rulings on the liability of their governments – they’d simply have to use the IPCC’s UN-validated body of knowledge to make a scientific case that the efforts do fall short. The essence of the ruling is that states can be judged to have failed to meet their duty of care and that the discretionary power vested in states is not unlimited: their care may not be below standard. Scientists don’t agree on everything to do with the climate, never mind the public, so it is heartening to see how the judges were able to deal explicitly with uncertainty and risk. Even the best expert advice involves some element of value judgment – the 2℃ target itself does not flow directly from climate science, for instance, but from a value-led assessment of impacts and the possibilities of adaptation. We’re also not certain just how sensitive the climate system will be to increasing greenhouse gas concentrations, or how emissions can and should be distributed over countries and time. Yet the Dutch judges observed that the IPCC has always allowed for scientific uncertainty and in their ruling they effectively include assessments of uncertainty as part of the “facts” relevant for managing risk. In that way, the judges – while making brief reference to the precautionary principle – were able to use the 25% emissions reduction number derived from the IPCC report as a norm which is not met by the EU or the Netherlands. Concerning values, while the judges missed the value-laden nature of judging climate change “dangerous”, they made a strong plea for the value of “duty of care”: the state must “mitigate as quickly and as much as possible”. And while the influence of the government is limited and the effects of some measures may be uncertain, the court concludes that the state “has the power to issue rules or other measures, including community information, to promote the transition to a sustainable society and to reduce greenhouse gas emission in the Netherlands”. For now, let’s hope this judgment will neither be ignored by the Dutch government nor addressed only with short-term measures focused entirely on 2020 without regard for the bigger picture. It’s a moment for a deeper discussion on the transition to a low-emission economy, not only in the Netherlands but also in the European Union and globally. And Paris may show a way forward after all."
"
Share this...FacebookTwitterThere are large regions of the globe where observations indicate there has been no warming (even cooling) during the last decades to century. Climate models rooted in the assumption that fossil fuel emissions drive dangerous warming dismiss these modeling failures and project temperature increases of 3° – 10°C by 2100 for these same regions anyway. 

Four decades of Southern Ocean cooling
After warming from the 1940s to the mid-1970s, the Southern Ocean has been cooling since the late-1970s, which has consequently resulted in an increase in sea ice extent (Fan et al., 2014; Purich et al., 2018; Latif et al., 2017; Turney et al., 2017 ).
In their paper entitled “Natural variability of Southern Ocean convection as a driver of observed climate trends”, Zhang et al. (2019) suggest that the Southern Ocean cooling was driven by natural processes.
Zhang et al., 2019
“Observed Southern Ocean surface cooling and sea-ice expansion over the past several decades are inconsistent with many historical simulations from climate models. Here we show that natural multidecadal variability involving Southern Ocean convection may have contributed strongly to the observed temperature and sea-ice trends.”

Climate models, in contrast, had projected a rapid warming and significant decreases in sea ice extent during the last few decades.

Image(s) Source: Zhang et al., 2019
The East-Central U.S. has been cooling (about -0.6°C) since the 1950s
Partridge et al., 2018
“We present a novel approach to characterize the spatiotemporal evolution of regional cooling across the eastern U.S. (commonly called the U.S. warming hole), by defining a spatially explicit boundary around the region of most persistent cooling. The warming hole emerges after a regime shift in 1958 where annual maximum (Tmax) and minimum (Tmin) temperatures decreased by 0.46°C and 0.83°C respectively.”

Image Source: Partridge et al., 2018
Alter et al., 2017
“From 1910- 1949 (pre-agricultural development, pre-DEV) to 1970-2009 (full agricultural development, full-DEV), the central United States experienced large-scale increases in rainfall of up to 35% and decreases in surface air temperature of up to 1°C during the boreal summer months of July and August … which conflicts with expectations from climate change projections for the end of the 21st century (i.e., warming and decreasing rainfall) (Melillo et al., 2014).”

Image Source: Alter et al., 2017
Climate models project 3°C – 10°C warming in the Midwest (U.S.) by 2100
Even though climate models failed to simulate the last 50 to 100 years of temperatures for this region, hindcasting a dramatic warming instead of the observed cooling, the projections for 2100 are still predicated on CO2 emission scenarios (RCP4.5, RCP8.5) as the determinant of regional surface temperatures.  Consequently, the regional models project a warming of 3°C – 10°C over the next 80 years.
Hamlet et al., 2019
“For the two most widely used greenhouse gas concentration scenarios, Representative Concentration Pathways (RCP) 4.5 and 8.5 (Moss et al. 2008) (representing “medium” and “high” twenty-first century greenhouse gas concentration trajectories respectively), the Midwestern United States is projected to experience profound changes in climate by 2100, especially for (T). Projections for annual mean T over the Midwestern United States from 31 global climate models (GCMs) for the RCP8.5 scenario show an ensemble mean increase in T of about 6.5 °C (11.7 °F) by 2100 relative to the historical 1971–2000 baseline (Fig. S1) (Byun and Hamlet 2018). The projected change in the annual ensemble mean T for RCP4.5 over the Midwestern United States is about 3.3 °C (5.9 °F) by 2100 relative to the 1971–2000 baseline. The upper tail of the annual mean T distribution, represented by the 97.5th percentile of the 31 GCM projections for RCP8.5 (i.e., a “worst-case” scenario), is nearly 10 °C (18 °F) warmer than the historical baseline by 2100.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Image(s) Source: Hamlet et al., 2019
The North Atlantic hasn’t warmed since the 1800s
Grieman et al., 2018

Image Source: Grieman et al., 2018
Birkel et al., 2018

Image Source: Birkel et al., 2018

Reverdin et al., 2018


Image Source: Reverdin et al., 2018


Climate models project 3°C warming in the North Atlantic by 2100

Gervais et al., 2018
“Recent studies have documented the development of a warming deficit in North Atlantic sea surface temperatures (SST) both in observations of the current climate (Rahmstorf et al. 2015; Drijfhout et al. 2012) and in future climate simulations (Drijfhout et al. 2012; Marshall et al. 2015; Woollings et al. 2012). This “North Atlantic warming hole” (NAWH) is characterized in the observed record as a region south of Greenland with negative trends in SSTs of 0.8 K century-1 (Rahmstorf et al. 2015). In fully coupled global climate model (GCM) future simulations, the NAWH is seen as a significant deficit in warming within the North Atlantic subpolar gyre (Marshall et al. 2015; Winton et al. 2013; Gervais et al. 2016).  This local reduction in future warming is communicated to the overlying atmosphere and may impact atmospheric circulation (Gervais et al. 2016), including the North Atlantic storm track (Woollings et al. 2012).”

Image Source: Gervais et al., 2018
Hansen (2013): CO2 emissions will cause 20°C of global warming by ~2130
Back in 1989, Dr. James Hansen, the former head of NASA, predicted that New York City’s West Side Highway would be underwater within 20 years due to rapid global warming and the consequent rising sea levels.
A glance at a 2018 image of the West Side Highway  indicates that it is still very much above water, no lower than its position in 1936.
A few decades later (2012), Hansen was the lead author of a paper published by The Royal Society (2013) that indicated ever-growing fossil fuel emissions would lead to a nearly five-fold rise in atmospheric CO2 concentrations (to 1,400 ppm) within 118 years.
He then projected this CO2 increase and presumed 9 W m-2 forcing would cause a global surface temperature warming of 20°C by about 2130, with 30°C warming at the poles.

Image Source: Hansen et al., 2013
Hansen et al., 2013
“Let us now verify that our assumed fossil fuel climate forcing of 9 W m−2 is feasible. If we assume that fossil fuel emissions increase by 3% per year, typical of the past decade and of the entire period since 1950, cumulative fossil fuel emissions will reach 10 000 Gt C in 118 years [2012 + 118 years = ~2130 C.E.] … [T]he fossil fuel source required to yield a 9 W m−2 forcing may be closer to 5000 Gt C, rather than 10 000 Gt C.”
“9 W m−2 forcing requires approximately 4.8×CO2 [1400 ppm] … Our calculated global warming in this case is 16°C, with warming at the poles approximately 30°C. Calculated warming over land areas averages approximately 20°C. … Such temperatures would eliminate grain production in almost all agricultural regions in the world. Increased stratospheric water vapour would diminish the stratospheric ozone layer. More ominously, global warming of that magnitude would make most of the planet uninhabitable by humans.”
“Given the 20°C warming we find with 4.8×CO2 [1400 ppm], it is clear that such a climate forcing would produce intolerable climatic conditions even if the true climate sensitivity is significantly less than the Russell sensitivity, or, if the Russell sensitivity is accurate, the CO2 amount required to produce intolerable conditions for humans is less than 4.8×CO2 [1400 ppm].”
“Are there sufficient fossil fuel reserves to yield 5000–10 000 Gt C? Recent updates of potential reserves, including unconventional fossil fuels (such as tar sands, tar shale and hydrofracking-derived shale gas) in addition to conventional oil, gas and coal, suggest that 5×CO2 (1400 ppm) is indeed feasible.”
Given the documented modeled forecast failures and lack of extreme or dangerous warming in recent decades, is there good reason to assume that Hansen’s prediction of a 20°C warming over the next 110 years will be realized?
At what point do modeling failures lead to a reconsideration of the forcing mechanisms?
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGulf Stream is doing fine: Potsdam Institute horror story suffers bitter setback
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
The horror scenario from the movie The Day After Tomorrow keeps getting presented as a real plausible scenario for our future: Falling salt content of the upper Gulf Stream due to melting ice flowing into the Arctic is slowing down the North Atlantic Current (NAC), and so doom and gloom is about to sweep across the North Atlantic.
However a team of researchers led by Carina Bringedal from the University of Bergen recently studied the northern end of the North Atlantic ocean circulation (Bringedal & Eldevik 2018). The result: the inflow of warm water and the overflow of denser deep water are in good sync. And since 1998 we do not see any long-term divergence of the sort we would expect to observe when adding more fresh water that would slow the “pump” down.
On shorter timescales the currents are influenced by the winds and the NAO. On longer timescales the currents are influenced by the AMOC.
In short: There’s no sign of a “collapsing Gulf Stream” due to the anthropogenic warming of the Arctic and the associated melting of the ice:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 1: Transported water volume in the North Atlantic during the past 25 years. Chart: Bringedal & Eldevik 2018
Observed rainfall contradicts doom & gloom claims
In the published paper that concerns the doom and gloom forecasts related to the weakening Gulf Stream (Caesar et al. 2018), there’s a second reason that gets named: anthropogenic impacts are causing more rainfall over the North Atlantic.
Yet, the following chart shows this as well is not being observed:

Figure 2: Chart depicting rainfall in the North Atlantic over the past 35 years. Source: KNMI Climate Explorer. Data: NOAA.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter40-year veteran meteorologist Joe Bastardi at WeatherBell’s Saturday Summary shows how the Earth’s surface has cooled dramatically over the past three years and that Arctic sea ice is piling up.
Hurricane threat to East Coast due to natural factors
First at his most recent Saturday Summary, the 40-year meteorologist first warns that in-close developing hurricanes of the sort seen in the 1930s are a risk to the US East Coast this year, due the current Atlantic temperature pattern. The reason has nothing to do with CO2 in the atmosphere, but because of natural sea surface temperature cycles.
Sea surface temperatures see “pretty dramatic turnaround”
Next Joe Bastardi illustrates the stark sea surface cooling the globe has seen over the recent years. The following two charts show the “pretty dramatic” cooling that has occurred over the past three years, 2015 vs 2018:

Cropped from Weatherbell Saturday Summary.
The two images above show the surface temperatures of the globe for the years 2015 – 2018. Note the profound cooling that has taken place from 2015 to 2018.
Bastardi calls it “a pretty big flip” and “a pretty dramatic turnaround”.
Arctic turns frigid
As sea surface temperatures around Greenland and in the Arctic are currently below normal, they are having an impact on Arctic surface temperatures this summer.
Joe Bastardi notes that according to the Danish DMI, Arctic temperature has been below normal over the entire summer:

Moreover, Arctic mid-summer temperatures, north of 80°N latitude, have dipped to near freezing over the past days. This is likely in large part linked to the cold North Atlantic sea surface temperatures we’ve been witnessing. All this suggests ocean cycles, and not CO2, are the real Arctic drivers.
Snow and ice climbing past decade
The cold polar temperatures are naturally having an impact on Arctic snow and ice.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Japanese blogger Kirye tweeted here that Arctic sea ice volume is currently at the 4th highest level since 2003, thus defying the dire alarmist predictions of Arctic sea ice disappearing by now.

Arctic sea ice volume (m3) has eased off from third place and is now at the 4th highest level since 2003, and showing an upward recovering trend over the past decade. Chart: Kirye.
Also at the 11:50 mark of his Saturday Summary video, Joe shows that Arctic sea ice extent is well above the levels seen over the previous years.
Greenland gets buried in snow
According to Kirye here, warming and melting have also been AWOL in Greenland, which has been seeing a dramatic snow and ice mass balance increase:

Chart: DMI.
“Total nonsense” concerning Thailand monsoons
In his Saturday Summary, Joe Bastardi also sharply criticized the climate ambulance chasing we’ve witnessed from hysterical climate alarmists, who are desperately grasping at any straw they can find to keep the climate panic on life-support.
It was recently claimed that the group of Thailand teenagers and their coach got trapped in a cave due to monsoon rains which were induced by global warming!
But Joe Bastardi presents a chart showing that this year’s monsoon activity in Thailand is completely within the range of natural variability:

Chart: WeatherBell Saturday Summary.
Bastardi calls the claim the kids got trapped because of climate change “total nonsense”, and points out that the monsoons over Thailand over the past five years have been normal to even below normal!
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman climate skeptic Snowfan here reports that Germany’s DWD National Weather Service has been caught deliberately spreading climate alarmism ahead of the COP24 using “fake news” in its press release of December 3, 2018, where it announced:
2018 could be the warmest and driest year since 1881.“
Snowfan replied on December 9th that 2018 could not be “the driest year” because the German Weather Service knew plenty of precipitation was in the pipeline for December, 2018.
As Snowfan shows, the old record of 555.1 mm/m² of mean precipitation across Germany was set way back in 1959, (see chart below).

Germany’s mean annual precipitation since 1881. The green line shows how Germany’s mean precipitation has increased over the past decades. The 1981-2010 mean is close to 820 liters/sq m.
By the end of November 2018, an average amount of 482.3 mm/m² of precipitation had fallen in 2018 through November. As of December 8, 2018, an average of about 518 mm had fallen across the country.
Then on the 11th of December, Snowfan noted that the GFS forecast for precipitation in Germany up to Christmas day showed yet more rain on the way:

Defying the the GFS forecasts, the DWD went ahead and “expected” less than 30 liters/sqm of precipitation to fall across Germany by the end of the month. The purposely very low expectation of course allowed DWD to issue an alarmist press release warning that 2018 could set an all-time record for the driest year ever.
On December 11, Snowfan pointed out that this was not going to happen, and called the DWD claims “ridiculous nonsense”, adding:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




1. The year 2018 in Germany cannot be the driest year since 1881, the positive linear trend of precipitation in Germany since 1881 (green line in the DWD graph above) will remain.
2. In the last week of the completely senseless 24th World Climate Change Conference (COP24) in Poland’s largest coal mining district in Katowice, December 2-14, snow will fall heavily over the last week to cool the overheated climate brains.”
Today Snowfan writes that as of December 16, 2018, already about 81% of December’s mean precipitation has fallen so far.
On the DWD’s panic forecast of possibly the driest year on record issued on December 3, before COP24, Snowfan concludes:
There was no basis for it, there is none, and there isn’t going to be any ‘DWD 2018 driest year since since recordings began in 1881!'”
Currently only 15 l/m² are missing until the end of the month. According to a very recent outlook by the GFS, plenty more rain is forecast for Germany for the rest of December:

1959 was the record driest year ever, and will remain Germany’s record driest year until further notice – no matter what the DWD may insist.
Snowfan adds:
The DWD thus knew before the December 3, 2018 press release of the climate fairy tale of the driest year ever, and that there would be more heavy rainfall in Germany by the end of the year.
Could one call a deliberate climate false story a climate lie? Does the DWD German Weather Service, with an annual budget of about 347 million euros in 2018, have the state contract to organize climate alarm by repeatedly deliberately spreading climate lies?”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterYesterday German energy expert and scientist Prof. Fritz Vahrenholt commented at his monthly column at Die kalte Sonne site here on solar activity, CO2 and coal power in Germany.
Photo: Fritz Vahrenholt, source: Die kalte Sonne
Sun factor grossly underestimated
Lately the sun’s activity has been very quiet as the star at the center of our solar system transitions over to a new solar cycle. April sunspot activity was very low in May. Vahrenholt then cites a recent study by Lewis and Curry showing that climate sensitivity to CO2 is in fact “up to 45% less than what the IPCC and the mainstream of climate science would like to have us believe.” Vahrenholt comments:
What was interesting however was the reaction of the mainstream: the methods used by Curry and Lewis in the study were not doubted. However, it could mean – according to the mainstream – that the earth will react very differently to CO2 in the future, i.e. get warmer. That’s what we can call speculative science, namely trust in the models which in the past have failed and have not been able to depict ocean circulation and clouds.”

So with CO2 not being at the factor it was made out to be, and because the Paris Accord is based on the spectacle of a rapidly warming planet, Vahrenholt writes that the “foundation of the Paris Accord has collapsed.”
Only Europe and Canada exiting coal
Another reason the Paris Accord is collapsing is because it’s not going to do anything we were promised it would.
When it comes to coal, Vahrenholt notes, so far only Europe and Canada have expressed some sort of a commitment to exit coal, and then he reminds us China, India and all developing countries will still be permitted to continue “massively” expanding their use of coal. He writes:
In China 280,000 MW and in India 174,000 MW are going to be added. By comparison: the entire brown coal fleet in Germany has a capacity of 22,700 MW. 1600 coal-fired power plants will be built in 62 countries across the world, most of them, by the way, will be built by Chinese power plant builders with the help of credits from China. Approximately 15,300 MW in Pakistan, 16,000 in Bangladesh, and even Myanmar with 5100 MW. (Source: South China Morning Post).
In other words, Angela Merkel and her green punch drinkers think the climate is going to be saved if Germany shuts down 1/20 of what China and India are going to add. No wonder Trump dumped the idiotic Accord.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Coal to expand 43% worldwide
And to illustrate what a farce the Paris Accord has become, the German energy expert adds: “In total, coal power plant capacity will expand by 43% worldwide.”
Germany to lay out the blueprint for its own demise
Currently Germany is gradually growing obsessed with the idea of a coal exit, and is setting up a Coal Commission to launch the endeavor. The Commission “however will not be made up of energy, power grid and technology experts, but rather with Greenpeace, BUND and local citizens initiatives who are against brown coal,” writes Vahrenholt.
“The idea of including critics of alternative energy, which has become the largest destroyer of nature since WWII, never dawned on any politician.”
Green state fundamentalism
The Coal Commission of course should include Prof. Hans-Joachim Schellnhuber, fiormer director of the ultra-alarmist Potsdam Institute and architect of the Great Transformation masterplan, which calls for an immediate end to the economic model that is based on “fossil industrial metabolism”, making climate protection the “fundamental target of the state by which the legislative, executive and judicial branches are to align themselves.”
Paris absurdity

According to Vahrenholt, the phase-out of coal will mean the decarbonization of Germany, which in turn will mean its deindustrialization. This, according to Vahrenholt, all coming to the great delight of the Chinese
A dismayed Vahrenholt sums up:

“Trump was clever enough, to exit the Paris absurdity early enough.”

Share this...FacebookTwitter "
"In the scorching farmlands of south-west Bangladesh, a single coconut tree stands as a barometer of climate change. Dulal Mondal, 70, a farmer, points halfway up the tree about two feet off the ground to indicate where the waters came the last time the area flooded. “Next time if heavy rain comes I don’t think water will recede as there is no natural draining or anywhere for it to go,” he says. Mondal lives in the Jessore district of Bangladesh where increased levels of salt in the water, uneven rainfall and flooding are creating great uncertainty for a whole farming community. Bangladesh is one of dozens of countries on the frontline of the climate emergency. Here global heating is no theoretical calamity of the future, but a very real, present danger. By 2050, it is predicted that one in seven people in the country will be displaced by climate breakdown. The sea level is projected to rise by 50cm over this time period and Bangladesh may lose approximately 11% of its land. Deadly storms are usually a question of when, not if. Here, the climate crisis is so palpable that the debate is not about restricting carbon emissions or preventing global warming but about how to adapt to the change and survive in times of unpredictable weather. For example, Mondal says that where once his peers would farm mainly rice, now they have taken to fishing. They use floating cages, allowing fish to breed in a secure area. Also, if water levels rise, the cages will too, so flooding is less of an issue. “About 20 to 30 years ago there would be a minimum of two crops per farming family but now because of waterlogging we have no more than one,” he says. Each cage is owned by one home and yields about 15,000 taka (£135) in additional income for the families a year. It’s also a consistent source of food, which could be vital if natural disaster hits.  “In the last two years there was not too much rain but two years ago we were flooded,” Mondal says. “We worry about the future. If there is heavy rainfall the water could remain logged for a long period of time and we would have to take shelter on main road. We would stay there with our remaining belongings.” This farming evolution is just one element of a whole range of climate change adaptive practices taking root across southern Bangladesh, an area long prone to cyclones, rising sea levels and drought. “What’s important is investment in long-term development, to help people adapt to the effects that climate change is having now and help them to not only survive but thrive in their new climate reality,” said Adib Hossain, the head of programmes implementation at Practical Action, one of the charities helping to make changes. In this part of Bangladesh they have helped introduce effective fertilisers to increase crop growth as well as growing fish in cages and vegetation in sacks or beside rivers – a novel farming technique known as a “dyke garden”. Ever wondered why you feel so gloomy about the world - even at a time when humanity has never been this healthy and prosperous? Could it be because news is almost always grim, focusing on confrontation, disaster, antagonism and blame? This series is an antidote, an attempt to show that there is plenty of hope, as our journalists scour the planet looking for pioneers, trailblazers, best practice, unsung heroes, ideas that work, ideas that might and innovations whose time might have come. Readers can recommend other projects, people and progress that we should report on by contacting us at theupside@theguardian.com The cages are made using cheap materials. Bamboo poles form an outer frame that can float and is covered in netting. They have a top cover to prevent fish jumping and escaping, or being caught by birds. With a capacity of one cubic metre, they hold up to 300 fish at a time. These cages are used for two growing seasons each year. The fish can be fed on scraps and waste – duckweed, oil cake, kitchen waste, rice bran and snails – and in just a few months they grow to full size. A woman standing beside Mondal goes down in a small wooden boat and pulls up the mesh cage, within which fish jump up and splutter around. She drops the net and they swim around once more. For the worried farmers in this area, the introduction of these cages has been reassuring, a constant amid a lot of inconsistency. In the nearby district of South Atulia another innovative technique has been employed. Land here is being used for fishing, with pools of water separated by a cracked mud path and spiky vegetation. Omal Biswas, 48, has three daughters and an adopted son. He used to farm rice once a year and during the monsoon he would fish in freshwater. Now he is able to make more money with dyke gardening techniques, growing vegetables around pools of water used for fishing. Omal has just harvested a crop, he says. They grow bottle gourd, chillis, indian spinach, red amaranth, sponge gourd, ridge gourd and tomatoes. “Before this technology was used I would yield around 20-25,000 taka a year but last year I harvested 120,000 taka through using different varieties of vegetables and growing more in the year. “Now I can grow vegetables while fishing but I used to rotate the land. I eat the vegetables too,” he adds.  He adds that the additional income helps give them a better quality of life and now he has been able to buy six cows. “The cost of living is rising and the cost of production is increasing so it is a good portion of revenue,” he says. Practical Action isn’t the only charity supporting farmers. The National Agriculture Technology Program (NATP 2) by the World Bank has also helped people adopt resilient farming methods. Farmers have deployed ancient agricultural methods such as floating beds, which involve sowing crops onto floating islands made of the fast-growing water hyacinth. Crops such as cucumbers, gourds and eggplants flourish. Beds are raised so as to lie above the reach of tidal surges. In between, trenches serve as pools to farm fish and ducks. Others have turned to shrimp farming after land was flooded but Practical Action has helped people do this in a more effective way. Rubina Khatun is one woman who has benefited from this. “The cyclone affected my family. I swam across flood waters with my two sons and took refuge on the road and sheltered in a shop we own for two months. Then we returned to our home,” she says. Shrimp farming is now a major source of income for her family. The technique used to farm the shrimp more effectively includes using deeper water so the temperature does not change as quickly, and adding a fertiliser made from oil cake, date juice and sugar cane among other things. “I am not sure what I would do without it now,” Khatun says. “But this type of farming is weather dependent. We need rain. If there is less rainfall salinity increases.” Despite efforts to improve the situation, Bangladesh remains at the mercy of sharp changes in weather patterns. Deep uncertainty persists for millions, even if these newfound techniques are helped to mitigate environmental impact. “I am worried,” Khatun says. “Too much or too little rain, both are problematic.” For her, however, the concept of climate change is a world away. “I can feel it in terms of rain but I am not aware of this. I have heard non-government-organisations talking about it but just as a concept. All I know is shrimp farming is a major source of income out of all the ones remaining, so it’s a reassurance.” This article is part of a series on possible solutions to some of the world’s most stubborn problems. What else should we cover? Email us at theupside@theguardian.com"
"
Share this...FacebookTwitterThe upcoming 6th IPCC Sixth Assessment Report will be a “comprehensive assessment of the science” related to climate change and published in 2022. However, don’t expect it to be “comprehensive” at all as hundreds of scientific publications showing profound impacts by sun and oceans will go ignored.
Climate science has turned into a religion that centers on a single act of faith. Human CO2 is changing our climate.
In the past it was always understood that climate was impacted by a vast array of factors, such oceanic cycles, solar cycles, aerosols, cloud cover, etc. to name a few.

Images: NASA (public domain)
But over the years tremendous resources have been poured into an effort aimed at pinning the blame on man-made greenhouse gases. Models have been grossly distorted and corrupted to make CO2 the 90%+ climate driver.
Despite global temperatures having fallen by more than 0.5°C over the past two years due to the ending of an El Nino event, IPCC scientists continue to insist that trace gas CO2 is the main driver behi9nd climate warming. In the IPCC 5th summary report for policymakers, for example, solar and oceanic factors re described as having little effect on global temperatures:

Source: IPCC 5th Summary Report for Policymakers.
With such a disregard for natural factors, it is no surprise that we are already observing the spectacular failure of the climate models.
Not only have ocean cycles been grossly ignored in climate models, but so have solar factors. The sun is not constant in its behavior, and has been shown to act in cycles that have profound impacts on the earth’s climate system.
Research showing sun’s impact piles up
Despite all the effort to frame CO2, scientists are still conducting a formidable amount of research on the sun’s impact.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Indeed since the last IPCC report was released in 2013, there have been literally hundreds of scientific peer-reviewed publications showing that the sun directly and indirectly have a great impact on the earth’s climate. Yet IPCC scientists obstinately continue to refuse to acknowledge these in their models.
Back in 2013 I produced a list of 123 paper showing that the sun impacts global climate.
More than 600 published papers show clear solar impact on climate
NTZ guest author Kenneth Richard has been busy listing the papers as well. What follows are the list of papers showing the sun impacts global climate.
2012 123 papers had been published and ignored by IPCC 4AR
In 2014, 93 papers were published.
In 2015,  95 peer-reviewed papers were published
In 2016, 133 papers were published.
In 2017,  121 peer-reviewed solar papers were published.
In 2018, so far, ca. 60 papers.
That brings the total of scientific peer-reviewed papers that will be completely ignored by the IPCC to 625. If that isn’t fraudulent “science-based” policymaking, then what is?
Aim: human society in shackles
The aim of the IPCC is to ignore recognized standards of science, frame mankind for a nonexistent crime, and shackle human society. It’s the next planned slavery. The developing countries, who will be denied cheap and reliable energy, will bear the heaviest chains.
Share this...FacebookTwitter "
nan
"Rhinos have become one of the high-profile wildlife stories of the year, fuelled by a steady stream of depressing images of once-impressive rhino reduced to a bloodied mess. Heightened awareness among the general public is the dream for conservation biologists, who often struggle to generate widespread interest in their cause. But, while the media’s focus on the plight of Africa’s rhinos is commendable, it begs the question – why aren’t Asian rhino given the same attention? There are three rhino species in Asia (the Indian, Javan and Sumatran) and two in Africa (white and black). They’re all fairly similar: all five eat plants, weigh up to 2.5 tonnes and have a thick protective skin. Javan, Sumatran, and African black rhinos are classed as critically endangered by the International Union for the Conservation of Nature (IUCN). And the IUCN’s most recent assessments were made before the latest surge in poaching, So why are we in a situation where twice as many people attend Arsenal home games than there are rhino left in the wild? The recent surge has been driven by a relatively recent fad among the affluent middle classes of Vietnam, who consume ground rhino horn in drinks either as an aphrodisiac or hangover cure.  Yet despite Asian species appearing to be in a more perilous situation statistically, conservation spending on rhino appears heavily weighted towards African species.  More than 80% of money distributed by Save the Rhino between 2008-09 and 2012-13 went to programmes supporting conservation in Africa. Why? Even before the resurgence of rhino poaching in Africa, spending was biased towards the continent. It would be wrong to assume we have given up hope for the future of the species in Asia. Action plans exist for the Asian Rhino and governments and charities have committed to trying to conserve the species, by supporting dedicated rhino protection units.  The recovery of the one-horned rhino in Nepal – numbers are at their highest since the 1950s – is a result of the effectiveness of such measures, but you wouldn’t know it as hardly anyone reported it. So why are media outlets and conservation organisations focusing on African Rhino? Corruption, a recognised inhibitor to effective conservation, is arguably comparable in the regions that African and Asian species are found and can’t be used as an excuse. I also highly doubt that the global public value Asian species any less than African. It mainly comes down to one thing: money from tourism. Africa is largely made up of developing countries whose economies are based on agricultural, rather than industrial, output. Consequently tourism is an important stream of revenue for governments, private businesses and local people.   According to the World Tourism Organisation, wildlife watching represents 80% of annual sales for tour companies to Africa. The “big five” – lions, elephants, buffalo, leopards and rhino – are big money. In Indonesia and Nepal, where most of Asia’s wild rhinos live, tourists are mostly there for the beaches or the mountains. They simply aren’t as reliant on safari-dollars as a country like Botswana. The African rhino is therefore a perfect example of utilitarian-based conservation – the preservation of something because of its monetary value to humans. They are worth more, to more people, than their Asian counterparts and are as a result the focus of more conservation efforts.  This isn’t a criticism of those who invest huge amounts of time and effort protecting Africa’s rhinos. They undoubtedly believe in what they are doing and don’t want to see recent successes destroyed by a surge in poaching. But there is a trade off. The case of the African versus the Asian rhino exposes a complex side to conservation, one which the majority of people simply aren’t aware of.  The conservation of one species over another due its monetary value being higher, distracts from what the main reason to preserve biodiversity should be, and what I think the majority of conservationists believe in – because its loss is simply wrong."
"
Share this...FacebookTwitterGerman skeptic blog Science Skeptical here takes a look at the carbon footprint of Prof. Hans-Joachim (John) Schellnhuber, the former director of the ultra alarmist and activist Potsdam Institute for Climate Impact Research (PIK).
Professor Schellnhuber is so worried about man’s destruction of the climate through human CO2 emissions and the “fossil fuel metabolism” of our society that he’s written a number of books on the subject, warning we’re on the verge of burning ourselves to death.
Not surprisingly these vivid books have been very popular among end-of-world conspiracists and climate Armageddon believers. His latest: Selbstverbrennung (Self Immolation).

 Image: C. Bertelsmann Publishing. 
Mankind committing “collective suicide”
A short summary of his book explains how Schellnhuber warns that if “our civilization does not move to the often-mentioned two-degree limit, but much more dramatically to a warming of 3 to 4 degrees Celsius by the end of the century, the continued burning of fossil fuels threatens to lead to collective suicide.”
Himalayan glaciers on the verge of disappearing
The doomsday professor, known in Germany as the “Climate Pope” and whose every word is taken by most of the German mainstream media as infallible, once said that the ideal population for the planet is a billion people (meaning soon there will be 7 billion too many) and the Himalayan glaciers would be gone by 2030.
Do as I say, not as I do
So with Schellnhuber’s level of conviction, certainty and urgency, it would only seem logical that the Bavarian-born professor would himself be setting an example for the rest of us on how to live responsibly with CO2 and forego fossil fuels.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Unfortunately, like a Catholic Pope and Cardinals who allow themselves lavish life styles while preaching others not to do the same, Schellnhuber allows himself exorbitant CO2 and fossil fuel privileges. Do as I say, not as I do.
“Certainly fly 100 times a year”
According to Science Skeptical, Schellnhuber was interviewed in 2005 by Tagesspiegel. In the interview he confessed he was not doing his part in “protecting the climate”. When asked if he had ever calculated his own contribution to climate change, Schellnhuber responded:
Yes, it is quite high because I myself certainly fly 100 times a year.”
And when asked what car he drives:
A BMW from the new 1 series. It consumes 6 liters diesel [per 100 km], but that’s only half as much as my previous car.”
Science Skeptical then did a rough calculation of Schellnhuber’s CO2 output using the CO2 calculator provided by the German Ministry of Environment. The result, assuming normal consumer behavior, but flying 100 times a year, each flight on average 2 hours long: 50 tonnes of CO2 each year!
The average German emits only about 10 tonnes annually.
Skeptical Science next wonders how much CO2 the climate-doomsday-preaching Potsdam Institute with its 4.5 million euro super-computer, and all it’s jet-setting climate-rescuing scientists, emit into the atmosphere. Not a pretty picture. They all happily rely on the conveniences provided by the very fuels they profess to detest.
Contempt for regular workers
In terms of CO2, the employees at the PIK thus consume a multiple times what the average German worker does. But German workers, you see, really don’t do necessary worthwhile work, and so are producing CO2 needlessly. PIK workers, on the other hand, are rescuing the planet, and so their CO2 emissions are really necessary. 
 
Share this...FacebookTwitter "
"Every school in New Zealand will this year have access to materials about the climate crisis written by the country’s leading science agencies – including tools for students to plan their own activism, and to process their feelings of “eco-anxiety” over global heating. The curriculum will put New Zealand at the forefront of climate change education worldwide; governments in neighbouring Australia and the United Kingdom have both faced criticism for lack of cohesive teaching on the climate crisis. The New Zealand scheme, which will be offered to all schools that teach 11 to 15 year-old students, will not be compulsory, the government said. “One of the pieces of feedback we’ve got from teachers around the country is that they’re really crying out for something like this, because kids are already in the conversation about climate change,” said James Shaw, New Zealand’s climate change minister and co-leader of the left-leaning Green Party. “They’re seeing stuff on social media on a daily basis and none of it’s good news, and the sense of powerlessness that comes from that is extremely distressing.” Hundreds of thousands of school and university students around the world, including in New Zealand, walked out of their classes for a series of climate strikes during 2019, a year when scientists warned that climate change was an “existential threat to civilisation”. Young people feel betrayed and abandoned by older generations over their lack of action on the climate issue, and worry about it has increasingly sparked anxiety and depression, a group of British psychologists warned in September. A pilot of the New Zealand scheme, which ran in one school in the city of Christchurch in 2018, had led to the introduction of materials for the national roll-out that helped students process their emotions about the climate issue, Shaw told The Guardian. “Being in the conversation itself causes stress,” he said. By necessity, he added, students would “delve into the bad news” of the science explaining the climate crisis. But the resources had been bolstered with “quite an emphasis on talking through with students how they’re feeling about it,” he said. Materials created for teachers that were provided to the Guardian suggest students keep a “feelings thermometer” to track their emotions, learn how to change defeatist self-talk, and consider how their feelings could generate action and response. “It helps kids to see that it is a fixable problem and people are working on it, and there is something they can foresee for themselves in terms of their own futures,” said Shaw. Another tool in the curriculum helps students create and carry out an action plan on a particular environmental issue – such as creating an edible garden. The curriculum included text, video, and advice for teachers, the education minister Chris Hipkins said in a statement. “It explains the role science plays in understanding climate change, aids understanding of both the response to it and its impacts – globally, nationally and locally – and explores opportunities to contribute to reducing and adapting to it impact on everyday life,” he added. While the Paris climate agreement, signed in 2015, urges signatory countries to implement climate education, many countries who made the pledge have not fulfilled it, including New Zealand’s nearest neighbour Australia, according to the science publication The Conversation. While some parts of Britain have enacted their own climate literacy plans, there is not a nationwide curriculum to teach it. The Labour party urged such a policy last May. Italy will this year become the first country in the world to make sustainability and the climate crisis compulsory subjects for students, with material integrated into regular lessons, such as mathematics and geography."
"
Share this...FacebookTwitterOn June 13 Chris Mooney of the Washington Post wrote how Antarctica’s ice sheet was “melting at a rapidly increasing rate” and “pouring more than 200 billion tons of ice into the ocean annually” — all this according to “a team of 80 scientists”. The doomsday media response was immediate.
Mooney of course blamed CO2 for the speculated ice melt change, and renewed the calls for a cut in greenhouse gas emissions in order to save ourselves.
Adventurous conclusion
Firstly the CO2 ice-melt logic here is extremely flimsy and even preposterous: An already hugely uncertain 200 billion ton figure gets adventurously blamed on Co2 through a long, uncertain and highly complex chain of physical processes — one that ignores an array of natural factors.
“Rate increase” meaningless
Secondly, Mooney’s language sounds dramatic, but the reality isn’t dramatic at all. A worker with an annual salary of $100,000 who gets a raise of $100 this year compared to $50 a year earlier also sees “a rapidly increasing” pay raise “rate” (100%). In reality the raise was meaningless.
Mooney and the media here are using trick language to purvey fake images of significant activity.
Only 0.001% of the total mass
Though the (hugely uncertain) 200 billion ton ice melt figure may sound impressive, it is in fact very tiny compared to the entire Antarctic total ice volume, which according to Dr. Don Easterbrook’s book “Evidence-Based Climate Science: Data Opposing CO2 Emissions as the Primary Source of Global Warming Evidence-Based Climate Science” is estimated at 26.5 million cubic kilometers.
Artefact of statistical torture
200 cubic kilometers of 26.5 million cubic kilometers is in reality only about an estimated paltry 0.001% of the total Antarctic ice mass. And (if it were true) would have only a minor effect on overall sea level rise.
The scientists themselves admit there’s much uncertainty involved and that the calculated 200 billion ton ice loss depends in part on model assumptions. Read more here.
The 200 billion ton figure is indeed more an artefact of statistical torture and modelling. When it comes to complex Antarctic ice mass, you can make the paltry data that’s available say whatever you want.
In this case 80 scientists participated in the waterboarding of the data.
One decade is not climate, but rather weather variability
What is more, the authors compared the last decade to the one before. Well, changes seen in one decade and compared to the one earlier is what we call weather changes, not climate change. Just because one decade is wetter than the one before it, it doesn’t mean the next will be wetter as well. Junk science.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Reality: Antarctic ice area growing rapidly
The satellite imagery and data concerning Antarctic ice area, which go back almost 40 years, in fact show an increasing long-term trend, according to one recently published peer-reviewed study.

Antarctic cooling
And in order for Antarctica to lose ice through melting, the temperature there would necessarily need to rise. Yet the best satellite data we have on this show this is not the case at all.

Satellite data spanning four decades show no temperature increase. The RSS data in fact indicate slight cooling over the past decade where accelerated melting is being claimed. How can cooling cause more melting? Source: here.
Antarctic coastal surface stations show no warming
At Twitter, Japanese skeptic Kirye has been looking at NASA surface stations scattered over Antarctica, most of them near the coast, and found that many do not show any warming, e.g. Casey, Davis, Mawson, Syowa…
Other studies show ice growth!
Moreover NASA glaciologist Jay Zwally published a paper in 2015 showing ice sheet growth in eastern Antarctica had outweighed the losses in the western ice sheet, and so ice mass was growing and not shrinking.
And today Zwally is set to release a new study that will show that the eastern Antarctic ice sheet continues to gain enough ice to offset the losses in the west. “Basically, we agree about West Antarctica,” Zwally told The Daily Caller. “East Antarctica is still gaining mass. That’s where we disagree.”
Zwally believes ice sheet growth is anywhere from 50 gigatons to 200 gigatons a year, the Daily Caller reports here.
Ocean cycles responsible for west Antarctic ice melt
Ice loss in the western Antarctic ice sheet is suspected of being driven by “warm ocean water”, i.e. natural oceanic cycles, and not warming that still has yet to occur over the Antarctic.
Prof. Don Easterbrook concluded in 2016 concerning the West Antarctic Ice Sheet, which everyone loves to worry about:

The West Antarctic Ice Sheet is NOT collapsing, the retreat of these small glaciers is NOT caused by global warming, and sea level is NOT going to rise 10 ft.”

Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterUnearthed new evidence (Mangerud and Svendsen, 2018) reveals that during the Early Holocene, when CO2 concentrations hovered around 260 ppm, “warmth-demanding species” were living in locations 1,000 km farther north of where they exist today in Arctic Svalbard, indicating that summer temperatures must have been about “6°C warmer than at present”.
Proxy evidence from two other new papers suggests Svalbard’s Hinlopen Strait  may have reached about 5 – 9°C warmer than 1955-2012 during the Early Holocene (Bartels et al., 2018), and Greenland may have been “4.0 to 7.0 °C warmer than modern [1952-2014]” between 10,000 and 8,000 years ago according to evidence found in rock formations at the bottom of ancient lakes (McFarlin et al., 2018). 
In these 3 new papers, none of the scientists connect the “pronounced” and “exceptional” Early Holocene warmth to CO2 concentrations.  

  Mangerud and Svendsen, 2018
The Holocene Thermal Maximum around Svalbard, Arctic
North Atlantic; molluscs show early and exceptional warmth
“Shallow marine molluscs that are today extinct close to Svalbard, because of the cold climate, are found in deposits there dating to the early Holocene. The most warmth-demanding species found, Zirfaea crispata, currently has a northern limit 1000 km farther south, indicating that August temperatures on Svalbard were 6°C warmer at around 10.2–9.2 cal. ka BP, when this species lived there. … After 8.2 cal. ka, the climate around Svalbard warmed again, and although it did not reach the same peak in temperatures as prior to 9 ka, it was nevertheless some 4°C warmer than present between 8.2 and 6 cal. ka BP. … The occurrence of the blue mussel, Mytilus edulis, suggests that climate around Svalbard was 2°C warmer than at present as early as about 11 cal. ka BP.  The climate was about 6°C warmer than at present between 10.0 and 9.2 cal. ka BP, as shown by the presence of Zirfaea crispata.  One single specimen of Mytilus is dated to 900 years BP, suggesting a short-lived warm period during the Medieval Warm Period of northern Europe.”


Bartels et al., 2018
Wahlenbergfjord, eastern Svalbard: a glacier-surrounded fjord
reflecting regional hydrographic variability during the Holocene?
“During summer, AW [Atlantic Water] rises up to waterdepths as shallow as ~55 m. … Summer surface temperatures [1955-2012] range between up to 3°C at the northern mouth and <-1.5 °C at the southern mouth of the Hinlopen Strait, while winter surface temperatures vary between 0.5 and <~1.5°C (averaged, 1955–2012; Locarnini et al. 2013). … Increased summer insolation probably amplified the surface melting of the glaciers resulting in enhanced meltwater production and in a very high accumulation of finegrained sediments within the fjord […].”
“In addition, during the mild early Holocene conditions, summer sea-surface temperatures probably reaching 8–10°C [~5 – 9°C warmer than 1955-2012] (indicated by M. edulis findings as discussed in Hansen et al. 2011) may have contributed to reducing the number of glaciers that entered the fjord directly as tidewater glaciers and thus causing a diminished IRD input.  … In lake sediments from northwestern Spitsbergen a temperature drop of ~6°C is recorded between c. 7.8 and c. 7 ka [-0.8°C per century], which has been connected to a stronger influence of Arctic Water and expanding sea ice (van der Bilt et al. 2018).”


McFarlin et al., 2018
Pronounced summer warming in northwest Greenland
during the Holocene and Last Interglacial
“(Greenland)  Early Holocene peak warmth has been quantified at only a few sites, and terrestrial sedimentary records of prior interglacials are exceptionally rare due to glacial erosion during the last glacial period. Here, we discuss findings from a lacustrine archive that records both the Holocene and the Last Interglacial (LIG) from Greenland, allowing for direct comparison between two interglacials. Sedimentary chironomid assemblages indicate peak July temperatures [Greenland] 4.0 to 7.0 °C warmer than modern during the Early Holocene maximum [10,000 to 8,000 years ago] in summer insolation. Chaoborus and chironomids in LIG [the last interglacial] sediments indicate July temperatures at least 5.5 to 8.5 °C warmer than modern.”

Share this...FacebookTwitter "
nan
"The palm oil industry is no stranger to controversy. While the world has come to learn of the environmental issues linked to the oil’s production, claims have arisen that countless rural communities have been affected by land grabs by companies seeking to expand their production. That began to change in 2001, however, when World Wildlife Fund started to explore setting up a Roundtable on Sustainable Palm Oil (RPSO). By 2004, the roundtable had been formally established as a not for profit group, bringing together several types of industry stakeholder, including civil society organisations (CSOs) to represent the interests of rural communities on whose land large companies are growing oil palm. All members now work together to agree and develop a set of environmental and social criteria, and achieve a sustainable palm oil certification. As of May 2018, 3.57m hectares of land had been certified under the scheme, and the 3,920 members produced 19% of global palm oil (12.2m tonnes). While global data on the impact of RSPO certification on land grabbing episodes are hard to find, a 2018 report suggested that it had contributed to a 33% reduction in deforestation between 2001 and 2015 in Indonesia alone. However, these stats are now set to change following palm oil giant Golden Veroleum Liberia’s (GVL) withdrawal from the RSPO. The Singapore-based developer is one of Liberia’s largest investors who, according to its RSPO profile, is “committed to the sustainable development of palm oil in Liberia. This means protecting the environment and working harmoniously with local communities”. GVL’s leaving was triggered by the RSPO’s decision to sanction several member organisations – including GVL – who had been accused of violating the body’s key principle of free prior informed consent. The main purpose of this is to “ensure that RSPO-certified sustainable palm oil comes from areas without land conflicts or … grabs”.  GVL began operations in Liberia in 2010, amid hopes that it would boost local employment. It was awarded 220,000 hectares of land by the Liberian government for the cultivation of oil palm.  But soon after the company began operations, the people of the Butaw region became concerned that it was clearing sacred sites and protected forests, and encroaching on land without the free prior informed consent of the people. The forests near GVL’s Liberian plantations are also heavily populated with chimpanzees, leopards, pygmy hippopotamus and forest elephants which are significant not only to the local ecosystem but globally. Complaints were made to the RSPO in October 2012 by several CSOs, which even went so far as accusing GVL of negotiating deals with communities during Liberia’s Ebola outbreak. They argued that communities were desperate for income during the crisis and were easily coerced into signing their land away.  After years of back and forth, RSPO sanctioned GVL in February 2018, ordering the company to stop clearing new lands. A subsequent appeal was rejected and so GVL withdrew. The problem here is that if it is so easy for a company like GVL to leave the RSPO, what’s to stop others from doing it too? Their leaving could very well be the start of multiple large stakeholders in the palm oil industry going back on their social and environmental agreements. Numerous CSOs have tested the RSPO’s ability to sanction members over the years, with mixed results. In 2010, a complaint was brought against Sime Darby by the Forest People Programme. This subsequently forced the company to set up a sustainable partnership initiative with local communities affected by land grabs and Liberian environmental groups. The aim was to work together on guidelines for how the company could expand its operations.  However, my own recent conversations with Liberian government officials have revealed that both the company and government felt the RSPO intervention actually harmed the company’s ability to expand. Another case brought against Sime Darby has resulted in the complainant bringing action against the RSPO itself for its failure to make a decision. With such mixed results, it is almost surprising that no members have left the RSPO until now.  GVL has said that its leaving does not represent a “weakening of their commitment” to sustainable palm oil production. And it has even announced its own new sustainability action plan. All good in theory, but the RSPO was there to hold companies to account, and to give the people a way of making sure that global organisations cannot take their land. Although RSPO membership and adherence to its principles is voluntary, it has been a buffer, stopping large oil palm giants from potentially aligning with corrupt political elites in low income countries. It has stopped – to a certain extent – the erosion of the rights of poverty stricken rural communities, who may have the land beneath their feet taken away, or their local environment destroyed. The fact that any company could get away with a crime they had been accused of without any punishment – even when they held RSPO membership – makes one wonder what they may be able to get away with now that they are not bound by RSPO principles."
"Australia’s Great Barrier Reef made headlines in 2016 for all the wrong reasons. Part of the world’s largest coral reef had been turned almost white by warm seas and other stressors. The shocking sight drew worldwide attention to the process of coral “bleaching”. Bleaching occurs when water temperatures and other stressors are too extreme and disrupt the symbiotic relationship between the coral and the single-celled colourful algae which live inside them, causing the algae to be expelled and the white coral skeleton to become visible. Coral – technically an animal not a plant – can survive bleaching, but it is a sign of extreme stress and in the worst cases bleaching can cause the catastrophic loss of large areas of coral reefs. This is what happened with the Great Barrier Reef in 1998, 2002, 2016 and 2017. We know about those recent events as they have been widely observed and studied, but prior to the 1970s we have little understanding of coral bleaching due to scant observational records. This could mean that bleaching didn’t happen, happened very infrequently, that we didn’t know how to recognise it, or that we were not looking for it in the right places.  To better assess the survival chances of the Great Barrier and other coral reefs, we wanted longer-term records to help us understand how and why coral reefs end up bleaching in response to environmental change over the centuries. This in turn would give us a better sense of their ability to cope with recent rapid changes. Fortunately for us, coral colonies can live for hundreds of years keeping very good archives of their environment during that time. This is because, like trees, they have annual growth bands. The width, density and chemistry of the bands provides information on past growth rates, sea temperature and runoff from land during storms. To access those bands, scientists can drill out a long and thin “core”, removing a part of the skeleton without killing the coral itself. These cores can then be X–rayed or chemically analysed to understand the history of the coral – and its environment.  The Great Barrier Reef benefits from a wealth of cores extracted by scientists over the past four decades, giving a unique opportunity to understand patterns in past growth and bleaching, which can be identified from groups of successively very small bands in the coral skeleton. This new approach to reconstructing bleaching has allowed us to look back beyond the observational record, to reconstruct 400 years of bleaching along the Great Barrier Reef. We found that widespread bleaching had been occurring there since at least the 1600s. However, there has been a 10% increase in the proportion of corals affected since the late 1700s. Centuries ago, widespread bleaching was probably caused primarily by fluctuations in temperature. More recently, warm oceans have likely been compounded by other, human-induced, stressors including pollution or sediment and fertilisers washed into the ocean. Over the past 400 years, the time span covered by our cores, Great Barrier Reef corals have shown evidence that they can recover from widespread bleaching events. However, since the 1800s, both the number of such events and the number of corals involved have increased, indicating they may not be able to cope well with sustained increases in temperature, and are possibly reaching a tipping point. Future studies would benefit from longer cores, allowing us to look further back in time. Importantly, this 400-year record now allows us to identify that corals are moving out of a period during which they could cope with environmental change into one where they appear to be increasingly struggling. In the face of rapid and complex environmental change, coral reefs are not certain to survive."
"
Share this...FacebookTwitterFlorence shows that atmospheric water vapor dwarfs human emissions of trace gas CO2.
To put some perspective on the scale of water vapor and trace gas CO2 in our atmosphere, let’s compare the two in terms of rainfall from Hurricane Florence alone over the Carolinas and surrounding area.
Surely with man’s fossil fuel profligacy, the emitted CO2 must by far outweigh the water vapor associated with a single storm.
18 trillion gallons of rain
According to hurricane expert Dr. Ryan Maue, some 18 trillion gallons of water vapor could fall as rain from Hurricane Florence over the Carolinas’ region:

Forecast for total rainfall during next 7-days (data from @NWSOPC) is still roughly 10 trillion gallons for North Carolina.
Add in adjacent states that will also be impacted by #Florence gets up to about 18 Trillion total. pic.twitter.com/hpfHeJLA6o
— Ryan Maue | weathermodels.com (@RyanMaue) September 14, 2018


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





To better imagine the scale of this, that’s roughly 2400 one-gallon milk jugs for every man, woman and child on the planet.
70 billion metric tonnes
18 trillion gallons is roughly 70 trillion kg of water mass, which is 70 billion metric tonnes of water vapor in the atmosphere which will end up getting dumped on a few states over a few days by Florence.
Double the weight of human CO2 emissions in one year
How does this compare to human CO2 emissions into the atmosphere?
Globally and ANNUALLY, man emits about 36 billion metric tonnes of CO2 into the atmosphere. That means the water vapor falling as rain over the Carolinas’ region from Florence is double the weight of CO2 man emits into the atmosphere in an entire YEAR.
Human CO2 amounts pales in comparison to the daily global water vapor variations the planet sees. Clearly water vapor dwarfs CO2 in the atmosphere. Claiming that CO2 is the main driver is as silly as claiming President Trump is complicit in creating Florence.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterUnusually cold tropical Atlantic could suppress hurricane activity this year, says Colorado State University hurricane expert Phillip Klotzbach. However cold tropical Atlantic sea surface temperatures don’t necessarily mean reduced hurricane risk.
Colorado State University (CSU) hurricane expert Phillip Klotzback at Twitter commented that the tropical Atlantic sea surface temperatures are the 2nd coldest on record and that this could mean “significantly suppress Atlantic hurricane activity.”

Tropical Atlantic (10-20°N, 60-20°W) sea surface temperatures are currently 2nd coldest on record (since 1982).  Only year colder in early June was 1985.  Could  significantly suppress Atlantic #hurricane activity if anomalously cold SSTs persist. pic.twitter.com/9Rmobo9u3a
— Philip Klotzbach (@philklotzbach) June 6, 2018

Cold tropical Atlantic doesn’t mean fewer hurricanes hitting US!
However history shows that it is purely speculative that cold tropical Atlantic sea surface temperatures will act to suppress hurricanes hitting the US.
Klotzback notes that the coldest tropical sea surface temperatures seen in June were recorded in 1985, and looking at the 1985 US hurricane season Wikipedia tells us that season was in fact a rather nasty one for the entire east coast of the USA:
The 1985 Atlantic hurricane season featured eight landfalling tropical cyclones in the United States, including a record-tying six hurricanes, the most in a single year since 1916.“


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





 
1985 season record “destructive and disruptive”
Wikipedia writes that “the year featured average activity overall” but was “particularly destructive and disruptive for the United States, with damage amounting to a then-record US$4 billion.”
Further, Wikipedia adds: “The entire coastline from Brownsville, Texas, to Eastport, Maine, was under a gale warning at some point during the year and a portion of every state was under a hurricane warning.”
Bastardi warns of the “in-close” threat
Observing the 1985 hurricane chart, we see that the vast majority of the 11 named storms formed “in-close”, relatively near the US mainland.
Meteorologist Joe Bastardi warned in his May 26th WeatherBell Saturday Summary that warm waters near the coast needed real attention and harbored plenty of threat. In no way should people let themselves get casual about it.
So, don’t let all the cold tropical Atlantic surface water fool you into  thinking that the upcoming hurricane season is going to be on the light side for the US coast.
1985 shows us things can get pretty nasty even when the surface of the tropical Atlantic basin is cold.
===============================
Philip Klotzback is a meteorologist at CSU specializing in Atlantic basin seasonal hurricane forecasts. Avid runner, cyclist and hiker.
Share this...FacebookTwitter "
"We have just entered a new decade, a decade where every month and every day will be absolutely crucial in deciding what the future will look like. Towards the end of January, chief executives, investors and policymakers will gather in Davos for the 50th anniversary of the World Economic Forum.  Young climate activists and school strikers from around the world will be present to put pressure on these leaders. We demand that at this year’s forum, participants from all companies, banks, institutions and governments immediately halt all investments in fossil fuel exploration and extraction, immediately end all fossil fuel subsidies and immediately and completely divest from fossil fuels. We don’t want these things done by 2050, 2030 or even 2021, we want this done now – as in right now. We understand and know very well that the world is complicated and that what we are asking for may not be easy. But the climate crisis is also extremely complicated, and this is an emergency. In an emergency you step out of your comfort zone and make decisions that may not be very comfortable or pleasant. And let’s be clear – there is nothing easy, comfortable or pleasant about the climate and environmental emergency. Davos is a Swiss ski resort now more famous for hosting the annual
four-day conference for the World Economic Forum. For participants it is
a festival of networking. Getting an invitation is a sign you have made
it – and the elaborate system of badges reveals your place in the Davos hierarchy. The meeting is sponsored by a huge number of international banks and corporations. For critics, “Davos man” is shorthand for the globe-trotting elite,
disconnected from their home countries after spending too much time in
the club-class lounge. Others just wonder if it is all a big waste of time.  The 2020 meeting is being advertised as focusing on seven themes: Fairer economies, better business, healthy futures, future of work, tech for good, beyond geopolitics and how to save the planet. Young climate activists and school strikers from around the world will be present at the event to put pressure on world leaders over that last theme.  Young people are being let down by older generations and those in power. To some it may seem like we are asking for a lot. But this is just the very minimum of effort needed to start the rapid sustainable transition. The fact that this still – in 2020 – hasn’t been done already is, quite frankly, a disgrace. Yet, since the 2015 Paris agreement, 33 major global banks have collectively poured $1.9tn (£1.5tn) into fossil fuels, according to Rainforest Action’s report. The IMF concluded that in 2017 alone, the world spent $5.2tn subsidising fossil fuels. This has to stop. The world of finance has a responsibility to the planet, the people and all other species living on it. In fact, it ought to be in every company and stakeholder’s interest to make sure the planet they live on will thrive. But history has not shown the corporate world’s willingness to hold themselves accountable. So it falls on us, the children, to do that. We call upon the world’s leaders to stop investing in the fossil fuel economy that is at the very heart of this planetary crisis. Instead, they should invest their money in existing sustainable technologies, research and in restoring nature. Short-term profit should not trump long-term stability of life. The theme of this year’s gathering in Davos is “stakeholders for a cohesive and sustainable world”. According to the forum’s website, leaders will meet to discuss ideas and improve our global progress on climate change. Our request to them is perhaps not so far-fetched considering that they say they understand and prioritise this emergency. Anything less than immediately ceasing these investments in the fossil fuel industry would be a betrayal of life itself. Today’s business as usual is turning into a crime against humanity. We demand that leaders play their part in putting an end to this madness. Our future is at stake, let that be their investment. • Greta Thunberg is a 17-year-old environmental campaigner from Stockholm, Sweden. This article was co-written with youth climate activists Jean Hinchliffe, Australia; Danielle Ferreira de Assis, Brazil; Joel Enrique Peña Panichine, Chile; Robin Jullian, France; Luisa Neubauer, Germany; Licipriya Kangujam, India; David Wicker, Italy; Julia Haddad, Lebanon; Oladosu Adenike, Nigeria; Iqbal Badruddin, Pakistan; Arshak Makichyan, Russia; Holly Gillibrand, Scotland; Alejandro Martínez, Spain; Isabelle Axelsson, Sweden; Sophia Axelsson, Sweden; Ell Jarl, Sweden; Mina Pohankova, Sweden; Linus Dolder, Switzerland; Vanessa Nakate, Uganda; Tokata Iron Eyes, USA"
nan
"The UK has a rich history of marine biology, with famous scientists such as Charles Darwin who did pioneering work in the field, and strong research institutions with international expertise in marine sciences. So, surely then, scientists must know everything there is to know about the country’s coasts and rockpools? Unfortunately not. While there are scientific names for the overwhelming majority of marine species on the country’s shores, we don’t necessarily know everything about the organisms themselves – or what lives inside them.  Back in 2012, researchers looked at how much was known about the biology of marine species around Britain and Ireland’s coasts, and concluded that there were considerable gaps in scientific knowledge. This extensive review of biological data looked at almost 1,000 species, including 148 species of fish and over 800 species of invertebrates such as worms, crustaceans, sponges, sea urchins and starfish. They looked at eight types of biological traits that may be known for each – including diet, growth, dispersion and reproduction – and found that information for all eight traits was only known for 9% of the species. While 20% of the species had no biological traits recorded at all. Despite researchers working hard, very few of these gaps have been filled in the six years since that paper was published. This missing information is critical to safeguard and conserve the waters which surround the UK. Scientists can’t properly determine the effects of, say, climate change or pollution on marine life if the factors which determine things like the timing of their reproduction aren’t known. 


      Read more:
      Octopuses: How citizen scientists are uncovering their secrets


 And when we talk of creatures that live around the country’s shores, we can’t ignore the species that live on or inside them. Take parasites, for example. Trematodes, nematodes, microsporidians, paramyxeans, gregarines and protists aren’t household names in the kingdom of life. However, the typical animals that might be found around UK shores (crabs, worms, oysters and starfish) are home to multiple species of parasites. Some of these parasites are also home to parasites themselves (known as “hyperparasitism”). Parasites are considered the most abundant and diverse creatures on the planet, and they play an incredibly important role in how wildlife interact with ecosystems. Though microscopic, parasites can affect how fast organisms can grow or mature, make them exert abnormal behaviours, and influence where they live too.  They can even feminise their hosts, changing some crustaceans from male to female. Some time ago we discovered a microsporidian parasite was the cause of feminisation in the shrimp-like amphipod (Echinogammarus marinus). And we recently found out that two parasites combined, or possibly another new species of parasites (a paramyxean), might be involved in the feminisation too.  This amphipod also turned out to be host to an undescribed species of trematode parasite that can change its behaviour, making it more attracted to light – a consequence of which is that it’s more likely to get eaten, completing the parasites’ lifecycle. In just one quite common species we have found multiple undescribed species of parasites. Given the thousands of marine species around British and Irish shores, it is highly conceivable that there are many new discoveries like ours to be made. But more importantly, we must get to know the biology of known marine life and their parasites if we wish to understand how ecosystems function, the human impacts, and safeguard the environment’s future.  As the world has focused on unlocking human genomes, the costs of rapidly mapping the genetic blueprints of wildlife have fallen dramatically. Scientists have the tools at their disposal, to analyse the genes of animals that live on UK shores, and the organisms that live inside them. Each marine species is an island, home to multiple others, and only if we start to disentangle their genetic codes can we begin to understand to truly understand what life is like on the UK’s oceanic doorstep."
"What will become of UK energy policy now that the Conservative Party holds all the levers? The government has already given clear indications of its plans to pare back onshore wind in recent days. June 24 is the turn of offshore wind, when energy secretary Amber Rudd gives one of her first keynote speeches at the Global Offshore Wind Conference.  Rudd has been described as “really green” in the past, but that is unlikely to reassure the offshore wind industry. With the government apparently committed to nuclear and shale gas and oil, renewables companies are wondering if they still have a place at the table. Here’s how the policy landscape looks to us.  The government’s first big energy decision was confirmed with the announcement that the renewables-obligation subsidy scheme would be closing next April 1, a year earlier than planned. Confidence in the renewables industry has been wrecked as a result, though it goes further than that: the companies supporting renewables are the big power companies. The move is arguably as much a move against them as anyone.    Relations with the Scottish government have been damaged, with Nicola Sturgeon and others describing the decision as “wrong-headed”, “perverse” and “downright outrageous”. Scotland has backed onshore wind for more than a decade as a cheap and proven source of low-carbon electricity. According to industry body Scottish Renewables, the decision will cost Scotland alone up to £3bn in investment and put at risk many thousands of highly paid jobs.  The move will also hit consumer utility bills. Keith Anderson, chief operating officer of Scottish Power, has estimated it will cost consumers between £2bn-3bn in more expensive electricity generation. This will increase the risk of fuel poverty across the UK (which is much higher in Scotland than England). Even before the election, offshore wind was not a good place to be. The sector has seen many projects mothballed and a number of key players drop out altogether in the face of a subsidy regime that is insufficient. Offshore is already now much smaller than originally envisaged. It remains an expensive option in the UK even compared to new nuclear, and although costs are falling, it is not being deployed on the scale necessary to reduce costs to the point that it is commercially viable. If the subsidies are now cut, it will become a dead duck.  Compare Denmark, where the industry is now seeing costs fall dramatically through learning by doing. While the industry has benefited from highly competitive support mechanisms, deployment has been greatly facilitated by having 20% local ownership of projects. Shallower waters have helped too, but the UK could still learn from the Danish approach. Danish offshore wind costs are significantly less than the projected new nuclear build costs at Hinkley Point C in Somerset in the UK, the country’s first new nuclear plant since the 1990s.  The Tories have long backed new nuclear power as the panacea to combat the looming electricity crunch that is often talked about in energy circles. Yet new nuclear is proving so challenging across the world that delivering even one new station will be no easy task.  As Hinkley Point C has already illustrated, the financial costs of new nuclear are enormous, and construction overruns look inevitable. The government also faces an impending legal challenge by the Austrian government over the up to £25bn of state aid required to bring the project to fruition. This could delay completion by up to four years. Meanwhile Greenpeace is suing the European Commission for allowing the state aid to go ahead.  In sum, it might well be 2030 before we see the plant generating any new electricity for UK consumers – about seven years later than intended. This is a big problem for Rudd. Hinkley Point was promising to generate up to 7% of the UK’s electricity demand by 2023, at a time when big coal-fired stations in Scotland and England are closing. New and significant investment in energy infrastructure is needed before 2020 but it is currently unclear where this new generating capacity is going to come from.   David Cameron has also made clear the government’s commitment to shale gas and its desire to repeat the US revolution here. It promises new tax revenues, jobs and a more secure gas supply. Yet these benefits must be balanced  against the need to protect land and water supplies and manage hostile public opinion.  One widely overlooked issue is the infrastructure, which will take time and money to build. Fracking in the US requires an oil price to be at least $60 per barrel to be economical, and in some areas up to $100. With Brent Crude in the new era of mid $60 per barrel, is fracking economically feasible? Evidence from the US suggests not. Earlier this year the Commons environmental audit committee questioned whether fracking was compatible with UK climate-change targets. With the fifth carbon budget due soon to set targets beyond 2027, this presents Rudd with another conundrum. The UN climate change conference in Paris later this year may well prove a very challenging conversation for the government. It is hard to escape the conclusion that this central strand of the government’s new energy agenda has some serious credibility issues.  Put this all together and the government’s emerging approach to wind looks very unwise. New nuclear looks a very costly and unreliable drain on the government’s budget, while fracking looks expensive, incompatible with emissions targets and probably uneconomic at current oil prices. It remains to be seen if these technologies will yield any long-term and positive outcomes for the country. If the government gets it wrong, the consumer could be saddled with soaring electricity and gas bills for years to come. If ever we needed some sign of reprieve for UK renewables, it is now."
"Japanese knotweed, a widespread invasive non-native species in the UK, is seldom out of the news and can strike fear into the hearts of anyone who finds it growing on their property, house owner or developer alike. It is a tall, herbaceous and fast-growing plant that reduces biodiversity and can increase the risk of flooding.  Japanese knotweed – Fallopia japonica – is associated with a significant economic burden in the UK. Recently, a court in Wales ruled that homeowners were entitled to claim damages from Network Rail because rhizomes (the plant’s underground shoots) had extended below their properties. Japanese knotweed is subject to various legislation and mortgage lenders often require that an insurance-backed management plan for the plant is in place when it is present on or near a property before agreeing to a mortgage. The presence of the species can also result in a reduction of a property’s value. Japanese knotweed’s often quoted abilities to grow through concrete, damage buildings and extend destructive rhizomes seven metres from the above ground portion of the plant are among the most feared features of the plant. But it is exactly these supposed abilities that our new research challenges. I teamed up with lead author Mark Fennell and co-author Max Wade, both members of the environment and ground engineering team at global services firm AECOM, to present the most comprehensive study to date assessing the ability of Japanese knotweed to cause damage to built structures compared to other plants. What we found is at odds with what is currently accepted and may help to alleviate fears that the plant can grow through concrete or cause major structural damage to buildings. There are three primary ways plants can damage buildings: indirect damage though subsidence or heave; direct damage though collapse and impact; and direct damage through the accumulated pressure of plant growth. We assessed the evidence that Japanese knotweed can cause each of these types of damage and how the possibility of Japanese knotweed causing damage in these ways compares to other plants. A detailed survey of the literature revealed that indirect damage caused by plants is only possible on shrinkable clay soils, a type of soil that is not particularly common in the UK. Even where the most shrinkable soils are found, the biology and size of Japanese knotweed makes it less likely to facilitate this type of damage than large trees. This means that the risk of Japanese knotweed causing damage by modifying soil water content is extremely remote and only relevant in areas with exactly the right type of soil. Our next step was to conduct a survey of members of the Property Care Association and Royal Institution of Chartered Surveyors who have been involved in property surveys and treating or removing Japanese knotweed in the UK. Respondents were asked to report whether they had observed damage to buildings occurring with Japanese knotweed. Only between 2% and 6% of respondents reported any co-occurrence of Japanese knotweed and structural damage to buildings. Our paper also concluded that where Japanese knotweed is associated with damage, it is likely that the plants will have exacerbated existing damage, rather than being the initial cause of the damage.  Further to this, we asked respondents to report the lateral extension of underground shoots in cases where they had undertaken full excavations of Japanese knotweed. This allowed us to test the “seven-metre rule” commonly used to denote whether Japanese knotweed is likely to pose a threat to buildings.  We found that smaller stands of Japanese knotweed (less than four square metres in area) generally had rhizomes no longer than two metres and not beyond four, while 75% of larger stands had rhizomes extending no further than 2.5 metres. We received only one report of rhizomes over four metres in length. This shows that the fear of Japanese knotweed commonly having seven-metre rhizomes is unfounded and the use of the seven-metre rule is not robust for determining the likely lateral extent of these underground shoots. We then assessed 68 abandoned properties on three streets in northern England with a significant Japanese knotweed infestation, to determine whether these houses had damage caused by the presence of the plant. Many properties had Japanese knotweed present or nearby but we found no evidence to suggest that the dilapidation of the properties was caused by the plant. In fact, the other plants – particularly some woody trees – were visually associated with more damage. This area represented a near worst case scenario for houses that had been left to the mercy of Japanese knotweed and still we found no evidence for the plant causing damage. Overall, our study found no support for the commonly suggested ideas that Japanese knotweed routinely damages buildings and that its influence extends seven metres from plants above ground. Nor did we find evidence that it poses a major risk to built structures. Japanese knotweed remains a serious threat to Britain’s biodiversity, ecosystems and the amenity value of land, but these very real threats should not be confused with what our research shows to be myth more than fact. Japanese knotweed is no more of a risk to solidly built homes and buildings than many plants and less so than many woody species, particularly some large trees. 


      Read more:
      We've found the best way to control Japanese knotweed


 Our research highlights that the key to tackling invasive species lies in developing a detailed understanding of their biology and further highlights the ongoing need for new research and knowledge to help us to understand and, hopefully, address the emerging challenges presented by invasive non-native species."
"Quorn is to become the first major brand to introduce carbon labelling on its products. The new labels, aimed at helping consumers understand the environmental impact of their shopping, will start appearing on some products from June and on the entire Quorn range by next year.  From Thursday, the “farm to shop” carbon footprint data, certified by the Carbon Trust, will be available online for Quorn’s 30 best-selling products. Quorn claims to be the first meat-free food manufacturer to achieve third-party certification of its carbon footprint figures – via the Carbon Trust – which is being integrated into its own food labelling. It says that in 2018 its products enabled savings of 200,000 tonnes of CO2 equivalent compared with meat. The greenhouse gas impact of mycoprotein – the fungi-based protein used in Quorn products – is 90% lower than beef. The most comprehensive analysis to date of the damage farming does to the planet revealed that avoiding meat and dairy products is the single biggest way in which consumers can reduce their environmental impact, with animal agriculture a significant and fast-growing source of global greenhouse gas emissions. But while Quorn’s products may now be part of a booming industry of meat alternatives – and a key ingredient in Greggs’ new vegan steak bake – that has not stemmed criticism that they are heavily processed and a far cry from natural, plant-based foods. Peter Harrison, chief commercial officer of Quorn Foods, said: “This is about giving people the information needed to make informed decisions about the food they eat and the effect it has on our planet’s climate – in the same way that nutrition information is clearly labelled to help inform decisions on health.” Manufacturers are stepping up efforts to give consumers more information about the environmental impact of their products, despite previous attempts ending in failure. The UK’s largest retailer Tesco, for example, dropped its plan to label all its products with their carbon footprint, after promising “a revolution in green consumption”, blaming the work involved and other supermarkets for failing to follow its lead. Carbon Trust research in 2019 found that two-thirds of consumers support the idea of a recognisable carbon label to demonstrate that products have been made with a commitment to measuring and reducing their carbon footprint."
"Not so long ago, one of the reigning cliches around the subject of climate crisis was that it was a “looming catastrophe”. The situation was urgent, yes, and catastrophe was more or less imminent, but when people talked about it they mostly stuck to the future tense. It’s hard to identify the precise moment when the crisis moved from the horizon of popular imagination to the immediate foreground, but the spectacle in recent weeks of a continent in flames feels like a clear indication that the time of looming has ended and the catastrophe proper has commenced. The other day I messaged an Australian friend, a volunteer firefighter in Melbourne who had spent the week between Christmas and new year in East Gippsland, where thousands of people have been evacuated from their homes. After informing me she was home and safe, and requesting that I arrange for some Irish rain to be redirected down there, she sent me a photo she had taken on the job: an image of a narrow dusty road leading toward low hills dotted with trees, behind which the sky itself was a vast inferno of dark smoke and glowing flame. I stared at her photo for a long time, and kept returning to it all that day.  There was something both bizarre and instructive about the image, the way in which the gentle bucolic scene in the foreground was juxtaposed surreally against the literally hellish sky behind it. It made me think of René Magritte’s Empire of Light series of paintings, in which scenes of a residential street at night are presided over by a bright, daylit sky. It also made me think of what life is basically like now: a calm foreground with an inferno on the horizon. And it struck me that this would be a thing that would happen at the end of the world. People would point their phones at the fire in the sky, and they would send photos to their friends in other places. “This is what the apocalypse looks like here,” they would say. “How is it where you are?” There would be a great storm of content and engagement, and then there would be nothing at all. One thing that is often remarked about climate crisis is that the subject is characterised by a strange form of cognitive dissonance. You read about the melting ice caps, the rising temperatures, the mass extinctions, and you understand intellectually that something truly terrible is happening. It doesn’t feel like that on the nerve endings, though. On the nerve endings, it feels like an unseasonably warm day in January. But what is happening in Australia, and the images that are emerging from the fires, feels like a closing of the gap between the scientific evidence and the field of immediate perception. A little boy in a facemask in a small boat at sea, his hand on the outboard tiller, the sky behind him an incandescent haze. Two horses in silhouette against a burning forest. Crowds of masked people taking refuge on a beach. That same beach littered with the corpses of tropical birds. A kangaroo burned alive, trapped by a barbed wire fence. All these scenes suffused with a malignant red glow, as though put through an Instagram filter named “Inferno”. It looks like a film. It looks like a video game. It looks like what we have always imagined the end of the world would look like. In East Gippsland, where my friend had been dispatched to fight the fires after Christmas, the situation was so severe that the government issued an emergency warning telling the remaining residents that it was too late to evacuate. “You are in danger,” read the warning, “and need to act immediately to survive.” Here on the other side of the world, thousands of miles from the immediate peril of the fires, it’s impossible not to read this as a warning about the broader climate emergency. It’s the message we’ve been hearing from scientists and activists for decades. And it is undoubtedly the message of those apocalyptic images from Australia, bathed in the crimson radiance of catastrophe. If God himself were to materialise and deliver this message, it could not be any clearer, any more urgent. You may recall, in fact, that it was by means of a burning bush that God announced it was time to lead the Israelites out of Egypt. Yet the most disturbing thing about the images of the fires is not that they might signal the end of the world, but that they might signal how the world will continue. That we might just get used to large parts of the planet being on fire, and even larger parts of it being underwater. And more disturbing still, that we might harden our hearts against the people who live and die in the floods and the fires.  Because when I look at the images of those Australians crowded on the beaches, fleeing the smoke and the flames, there is a kind of double exposure effect, whereby I see the ghostly image of those other refugees who have come by boat to Australia from places where they were no longer safe, only to be held indefinitely and in appalling conditions on offshore detention facilities in the South Pacific. In the rest of the world, their suffering has been mostly ignored. These people know better than anyone what an apocalypse looks like. It’s not the melting of the ice-caps or the burning of the forests that seem to me to be the real apocalyptic scenario, but rather the slow atrophying of our moral imaginations; not the inferno itself, but the indifference of those of us who are not yet on fire. In this sense above all we are in danger, and we need to act immediately to survive. • Mark O’Connell is a writer based in Dublin. His book Notes from an Apocalypse will be published in April"
"We are all going to die. Since the end result is the same, perhaps the way it happens shouldn’t matter, but it does. Given the choice, I’d rather not burn to death. This is probably why the spectre of nuclear war remains so frightening, despite being highly unlikely. The radiation poisoning and horrific injuries we saw in the television series Chernobyl were a reminder of a time when we lived in vivid fear of the power of the atom, whether in the form of a missile or a meltdown.  So the nuclear threat as a preoccupation of our collective consciousness makes sense. But the outsize role it plays in our political discourse is hard to justify. The circumstances in which a nuclear weapon would be used by the UK are so far-fetched that nobody can really describe what they are. And yet every contender for the leadership of a national party is forced to answer the simplistic question: would you push the button? Jeremy Corbyn has been goaded since 2015 for refusing to say yes or no. His pacifist stance probably helped give “the button” an even bigger platform during the election campaign. And now it is becoming a motif of the Labour leadership contest, with Rebecca Long Bailey being asked the same question on BBC Radio 4 on Tuesday morning. The amount of attention given to the prospect of a hypothetical nuclear war seems grossly out of proportion, especially compared to the existential threat we are actually facing: the climate emergency. Labour’s Green New Deal policy, which Long Bailey helped write, was a central theme of her pitch for leader. Yet in the same radio interview she wasn’t asked about it once. The Conservatives mentioned the climate crisis just 10 times in their manifesto. They have no convincing strategy for reducing carbon emissions at the speed required to avert disaster. So, outside of the left, where is the debate? Where is the outrage? Where is the fear? This week social media was flooded with pictures of near-apocalyptic scenes of scorched koala bodies and houses engulfed in flames as images of the fires in Australia spread around the world. Meanwhile, one columnist fumed on Twitter about an environmentally friendly vegan meal served at the Golden Globes. Frankly, we ran out of time for this type of silliness long ago. Global heating is a clearer and more present danger than Britain becoming embroiled in nuclear war. But the latter offers a misleadingly simple scenario: one action is required, and no thought given as to what might come next (pushing the button would be the start of a nuclear war, not the end). The climate crisis, in contrast, is unavoidably messy, requiring a radical overhaul of every system, everything we buy, everything we eat. I can imagine why some would prefer not to think about it. Boris Johnson decided not to bother attending Channel 4’s Climate Debate during the election campaign, and was represented by an ice sculpture instead. In absenting himself, the prime minister effectively announced that, when it comes to the climate crisis, he will not push the button. As that existential threat draws nearer, he will sit back and take no action. But relax: at least he has confirmed he’s willing to save us all by starting a nuclear war. • Rachel Connolly writes about technology, cultural trends and politics"
"Lies have spread faster than grassfire during Australia’s unprecedented national emergency. They’ve ranged from the exaggerated to the outrageous.  One conspiracy bizarrely claims bushfires have been lit to clear a path for high-speed rail down Australia’s east coast. Others baselessly claim Islamic State is instructing its followers to wage war on the country with fire, that Chinese billionaires are using lasers to clear the path for new cities, or that eco-terrorists are trying to spur action on climate change by manufacturing a catastrophe. Accompanying these laughable mistruths, though, are more dangerous distortions. They are the ones being used to deflect from climate change’s role in creating longer, more severe fire seasons. Two pieces of disinformation stand out from the rest: that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush. Disinformation has spread across social media, finding its way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists like Alex Jones. Esteemed climate change expert professor Will Steffen, a member of Australia’s Climate Council and the inaugural director of Australian National University’s Climate Change Institute, is concerned at how disinformation has spread with such ease. “In my mind, I think it’s a serious issue and it is potentially very dangerous,” Steffen told the Guardian. “That’s because the bushfire situation is very dangerous … the evidence is overwhelming that climate change is playing a prominent role in worsening bushfire conditions across Australia. “People who are for whatever reason trying to put out false or extremely misleading information are actually doing a huge disservice to the risk to human life in the future, the risk to property, the risk to the natural world, and indeed the risk to economy.” Digital rights experts say the disinformation is yet more evidence that social media platforms are failing in their duty to act responsibly. “We need to see social media platforms playing a greater role in responding to the disinformation being shared on their platforms about the bushfires,” Digital Rights Watch chair Tim Singleton Norton said. “This needs to happen in tandem with effective government oversight, transparency, and accountability measures, as well as public education campaigns that give people the tools to identify misinformation.” Hazard reduction is absolutely an important factor when it comes to fire management ... but it is not the panacea There are nuggets of truth in some of the disinformation. Arson has always been a serious problem in Australia, particularly at times of heightened fire danger. Arsonists have been responsible for some of Australia’s worst bushfires, including a blaze during the horrific 2009 Black Saturday fires that killed 10 people, and arson is a common cause of ignition. New South Wales police say they have charged 24 people for lighting bushfires since November. This time around, though, the role of arson has been grossly exaggerated. Suggestions of an arson epidemic began to ferment on social media at the height of the crisis around New Year’s Day. On Twitter, much of the disinformation centred around the #arsonemergency hashtag. Queensland University of Technology senior lecturer Timothy Graham, an expert in social media analysis, took a sample of tweets from the hashtag and analysed them for characteristics typically associated with bots and trolls. His findings suggested a clear “disinformation campaign”. “Australia suddenly appears to be getting swamped by mis/disinformation as a result of this environmental catastrophe, and we are suffering the consequences in terms of hyped up polarisation and an increased difficulty and inability for citizens to discern truth,” Graham told the Guardian. Claims of an arson emergency were spurred along by some mainstream outlets. Channel 7, a major commercial television network, tweeted that police were “now working on the premise arson is to blame for much of the devastation caused this bushfire season”. The tweet neither reflected what police had said or what Channel 7 had itself reported in its news story. A story in the Murdoch-owned national broadsheet, The Australian, also falsely claimed that 183 arsonists had been arrested in the “current bushfire season”. That piece also went global. It was tweeted by Donald Trump Jr and followed up by InfoWars, a right-wing US website, which stated: “Authorities in Australia have arrested close to 200 people for deliberately starting the bushfires that have devastated the country, yet the media and celebrities continue to blame ‘climate change’ for the disaster.” The number was a gross exaggeration. It was arrived at by counting a range of bushfire-related offences other than arson – including contraventions of fire bans, for example – and used annual figures, not those for the current fire season, which began in September. The Australian subsequently updated its story. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. That claim was running hot on social media, and was given credibility by figures like federal Nationals MP Barnaby Joyce, a prominent Australian politician, who said “green caveats” were stopping firefighters from reducing fuel loads. This is at complete odds with statements by the RFS commissioner, Shane Fitzsimmons, who said the single biggest barrier to hazard reduction is the increasingly hot and dry weather and the “shrinking window of opportunity” within which managed burns could safely take place. Fitzsimmons said hazard reduction is also of little utility in fires as intense as those experienced in NSW this season. “Hazard reduction is absolutely an important factor when it comes to fire management and managing fire in the landscape but it is not the panacea,” Fitzsimmons said on Wednesday. Comments like Fitzsimmons’ have done little to stop the idea taking hold. Prime minister Scott Morrison has nominated the lack of hazard reduction work as a key issue he wants to investigate after the current crisis. At the same time, Morrison has demonstrated little appetite for strengthening climate action."
"
Share this...FacebookTwitterAuthors of a new paper published in the journal Science (Gebbie and Huybers, 2019) insist “the deep ocean ultimately plays a leading role in the planetary heat budget.” The global deep ocean has much less heat today than it had during both the Medieval Warm Period and the Little Ice Age.

Image Source: Gebbie and Huybers, 2019
A Bottom-Up Heat Flux?
The deep ocean may warm hundreds (to thousands) of years before hemispheric surface temperatures and CO2 concentrations do (Stott et al., 2007).
Image Source: Stott et al., 2007
This bottom-up hemispheric-scale heat flux – independent of CO2-forcing – may occur for land area as well.
“The increase of carbon dioxide concentrations occurred 2–3 thousands of years later than the heat flux increase and synchronously with temperature response.”  (Demezhko and Gornostaeva, 2015)
“GST [ground surface temperature] and SHF [surface heat flux] histories differ substantially in shape and chronology. Heat flux changes ahead of temperature changes by 500–1000 years.” (Demezhko et al., 2017)
 “During the Last Glacial Maximum 26–19 thousand years ago (ka), a vast ice sheet stretched over North America [Clark et al., 2009]. In subsequent millennia, as climate warmed and this ice sheet decayed, large volumes of meltwater flooded to the oceans [Tarasov and Peltier, 2006; Wickert, 2016]. This period, known as the ‘last deglaciation’, included episodes of abrupt climate change, such as the Bølling warming [~14.7–14.5 ka], when Northern Hemisphere temperatures increased by 4–5°C in just a few decades [Lea et al., 2003; Buizert et al., 2014], coinciding with a 12–22 m sea level rise in less than 340 years [5.3 meters per century] (Meltwater Pulse 1a (MWP1a)) [Deschamps et al., 2012].” (Ivanovic et al., 2017)
Deep ocean heat leads surface temperature change yet today?
A new paper indicates that the deep ocean in the Pacific has continued cooling in recent decades, extending the long-term cooling trend that commenced after the warmer-than-today Medieval Warm Period ended.
Other authors (Wunsch and Heimbach, 2014) have also documented a global-scale deep ocean (below 2,000 meters) cooling trend within the last few decades.
“About 52% of the ocean lies below 2000 m and about 18% below 3600 m. … A very weak long-term [1993-2011] cooling is seen over the bulk of the rest of the ocean below that depth [2,000 meters] including the entirety of the Pacific and Indian Oceans, along with the eastern Atlantic basin.”  (Wunsch and Heimbach, 2014)

Image Source: (Wunsch and Heimbach, 2014)
Little Ice Age conditions may still dominate in the deep ocean despite the dramatic rise in CO2 concentrations during the last few hundred years — from about 280 ppm during the late 1700s to well over 400 ppm today.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The global ocean below 2000 meters may actually be colder today than during the 18th century.

Gebbie and Huybers, 2019
The Little Ice Age and 20th-century deep Pacific cooling
“The ongoing deep Pacific is cooling, which revises Earth’s overall heat budget since 1750 downward by 35%.”
“In the deep Pacific, we find basin-wide cooling ranging from 0.02° to 0.08°C at depths between 1600 and 2800 m that is also statistically significant. The basic pattern of Atlantic warming and deep-Pacific cooling diagnosed from the observations is consistent with our model results, although the observations indicate stronger cooling trends in the Pacific.” 
“These basin-wide average trends are used to relax the assumption of globally uniform changes in surface conditions and to constrain regional temperature histories for 14 distinct regions over the Common Era by a control theory method. The result, referred to as OPT-0015, fits the observed vertical structure of Pacific cooling and Atlantic warming. Global surface changes still explain the basic Atlantic-Pacific difference in OPT-0015, but greater Southern Ocean cooling between 600 and 1600 CE leads to greater rates of cooling in the deep Pacific over recent centuries.”
“OPT-0015 indicates that the upper 2000 m of the ocean has been gaining heat since the 1700s, but that one-fourth of this heat uptake was mined from the deeper ocean. This upper-lower distinction is most pronounced in the Pacific since 1750, where cooling below 2000 m offsets more than one-third of the heat gain above 2000 m.”
“Finally, we note that OPT-0015 indicates that ocean heat content was larger during the Medieval Warm Period than at present, not because surface temperature was greater, but because the deep ocean had a longer time to adjust to surface anomalies. Over multicentennial time scales, changes in upper and deep ocean heat content have similar ranges, underscoring how the deep ocean ultimately plays a leading role in the planetary heat budget.”


Image Source: Gebbie and Huybers, 2019

A lack of long-term CO2→OHC correlation 
It may be worth a closer look at the graph of global ocean heat content (OHC, 0 m-bottom) during the last 2,000 years from Gebbie and Huybers (2019).

Image Source (bottom graph, heavily annotated): Gebbie and Huybers, 2019
It is interesting to note the multiple centennial-scale warming and cooling trends during the last two millennia that exceed the rate and amplitude of the ocean heat changes that have occurred since 1950, or since atmospheric CO2 concentrations began rising dramatically.
For example, despite the very modest  associated changes in atmospheric CO2 concentrations (< 5 ppm), it appears that both the 1850-1875 and 1925-1945 global warming periods in the 0-700 m layer exceeded the rate and amplitude of the heat content changes since 1950.
As the global oceans rapidly warmed and cooled in the centuries preceding modern times (i.e., the Medieval Warm Period and Little Ice Age), the corresponding CO2 concentrations were remarkably stable, neither rising with the warming or falling with the cooling.
Considering 93% of the Earth’s heat changes are expressed in the global ocean, and that just 1% of global warming is said to be reflected in surface air temperatures (IPCC, 2013), the lack of conspicuous correlation between ocean heat content and CO2 during the last 2,000 years would seem to undermine claims that atmospheric CO2 concentration changes drive zero-to-bottom global ocean warming.
Share this...FacebookTwitter "
nan
"Smoke from this season’s bushfires has turned the sun red, the moon orange and the sky an insipid grey. It has obscured iconic views tourists flock to see. Far more than an aesthetic problem, it has forced business shutdowns, triggered health problems and kept children indoors for weeks. City dwellers in south-east Australia have been forced to take a crash course in the finer points of air pollution. We’ve learned about the dangers of inhaling tiny PM2.5 particles (those 2.5 microns or fewer in diameter). We’ve learned that only a close-fitting P2 mask will do much to protect us. Still, we wear disposable paper masks and hold handkerchiefs to our faces, hoping any amount of filtering is helpful. Even for an historian of air pollution like me, this situation is a shock. It is not the first time Australia’s major cities have been shrouded in bushfire smoke. But the terrible air quality is unmatched in terms of severity, duration and extent. Historically, air pollution from smoke was considered outside human control and not subject to regulation. But these bushfires are clearly linked to global warming, for which government, corporations and individuals are responsible. It’s time to rethink the way we protect air quality. In recent weeks, apps such as AirVisual have confirmed what we city dwellers can already see and smell: since the fires on the north coast of New South Wales began in late October, our air quality has plummeted. The NSW government’s Air Quality Index data has shown that since late October, days when the index was higher than 100 – signalling exposure is unhealthy – have outnumbered clear days in Sydney, Newcastle and the Illawarra. Index readings above 2,550 have been recorded in Sydney, while the Monash monitoring site in Canberra reached a choking 5,185 at 8pm on New Year’s Day. Bushfire smoke has affected the cities of NSW and the Australian Capital Territory in the past. In late January 1926, when Canberra was just emerging as a city, a thick haze of smoke sat over the site. Fires came within metres of Yarralumla, the residence which, the following year, would become home to the governor general. In several years in the mid-1930s, bushfires burning to the north of Sydney left the city air thick with smoke. In October 1936, bushfire smoke forced a motor liner arriving from Hong Kong to warily enter the harbour sounding its siren, because it was invisible to signallers on South Head. A New Zealand pilot, flying into Sydney from Longreach the following month, had to fly blind in “great clouds of dense smoke” covering much of NSW. In 1939, Canberra was covered by what the visiting writer HG Wells described as a “streaming smoke curtain”. In the summer of 1944, Sydney was again enveloped in a smoke haze, this time from fires in the Blue Mountains and (later Royal) national park in November. Photographs published at the time show the Sydney Harbour Bridge barely visible through dust and smoke at midday. The ongoing fires were blamed for an increase in diseases of the ears, nose and throat, and for cases of influenza and pneumonia, leading to a shortage of hospital beds. In November 1951, all of NSW was said to be blacked out by bushfire smoke. In Sydney on the worst days, records show all four of the city’s airfields were closed because of “smoke-fog”. In each of these episodes, bushfire smoke disrupted transport, commerce, health and the enjoyment of the urban environment. But even as other forms of air pollution began to be regulated, smoke from bushfires escaped legislative attention. What was understood as air pollution were the unwanted byproducts of industrial processes, whereas bushfire smoke was viewed as natural. In NSW in 1866, an act based on British legislation restricted smoke from mills, distilleries and gas works. Further limitations on smoke production in built-up areas were included in later acts governing public health (1902), motor traffic (1909) and local government (1919). After the second world war Newcastle, the site of the country’s largest concentration of coal-burning heavy industry, began to pay closer attention to managing air quality. This pioneering work was given added urgency after 4,000 people died in heavy London smog in 1952. In 1958, a NSW parliamentary committee delivered a report into smoke abatement. It did not mention recent issues with bushfire smoke, and also dismissed the impact of domestically produced smoke. The subsequent 1961 Clean Air Act focused on air pollution from industry, transport and power generation. Air pollution legislation continued to evolve in following decades, targeting motor vehicle emissions in the 1970s, backyard burning of waste in the 1980s, and wood fires used to heat homes in the 1990s. These measures have been successful. A 2006 study found that between 1998 and 2003, on the limited occasions when standards for PM10 in six Australian cities were exceeded, the main sources were not industry or transport, but dust storms and bushfires (with the exception of Launceston, where heating fires were the main contributor). Today, bushfire smoke is excluded from air quality regulations, despite its obvious role in pollution. It is still considered natural and beyond human control. However, the link between the current fires and human-caused climate change, long predicted by climate scientists, suggests this exemption is no longer valid. As the Australian National University’s Tom Griffiths has written, the current fires in some ways repeat patterns of the past. But “the smoke is worse, more widespread and more enduring”. When Australia begins the recovery from these fires, our business-as-usual approach requires a rethink. Measures to protect air quality should be a major part of this. It is time that corporations, governments and societies which contribute to global heating be held to account for more frequent, intense and widespread bushfires, and the smoke which billows from them. Nancy Cushing is an associate professor at the University of Newcastle This piece was originally published in the Conversation"
"I recently flew to Florida to visit family. My round-trip economy seat emitted roughly two tonnes of carbon dioxide, according to one carbon offsetting website. By contrast, the average person in Britain is responsible for roughly seven tonnes for the entire year, already quite high by global standards. This makes me a climate change villain. Dumping such huge amounts of carbon into the atmosphere seems clearly morally wrong, because of the harm this will cause others. But carbon offsets let me fly with a clear conscience – for now. When I buy an offset, carbon emissions are reduced elsewhere, cancelling out those from my flight. It might involve planting or preserving trees, or installing cheap and efficient stoves. Offsetting my Florida trip cost £13 – a couple of drinks in the departures lounge. Convenient. But perhaps too easy? Offsetting clearly raises the scientific question of whether a purchase will really reduce global carbon emissions. This is difficult and controversial stuff, better suited to climate scientists and economists. Philosophers, by contrast, deal in hypotheticals. So let’s assume that offsetting “works” and it cancels out my flight emissions. Does that make the flight morally OK? Many people remain suspicious. The writer and environmentalist George Monbiot famously compared carbon offsetting to the sale of medieval Catholic indulgences, where the rich could buy themselves out of sin. Monbiot writes that from sellers of offsets, “you can now buy complacency, political apathy and self-satisfaction”. But I think he is wrong. In moral philosophy, so-called “consequentialist” theories say that when it comes to the rightness or wrongness of some action, the consequences are all that matter. If any ethical theory vindicates offsetting, it is this. Consequentialism has problems as a general moral theory. For example, it might license horribly unjust actions now, such as killing one innocent person because their organs will save the lives of five seriously ill people. Consequentialism cares only about the “total”, which seems wrong in the case of human lives: five saved lives don’t normally outweigh one murder.  Those who benefit from the offset might not be the same people harmed by the flight, but when it comes to climate, we should care (at least a bit) about the total amount of carbon in the air. So a focus on total emissions does seem at least partly correct about the environment. Another ethical worry is that offsets are only cheap because few people buy them. For instance, one cheap method of offsetting is to replace inefficient stoves in the developing world. This saves lots of carbon for little money. However these savings can’t go on forever, and when eventually the last stove is replaced, the schemes will get more expensive. In the philosophical jargon, cheap offsetting depends on “partial compliance”. But this is not always a problem: it’s not a moral problem for voting that if everybody voted, the queue at the polling station would be longer. Rising prices lead to a second worry. As philosopher Kai Spiekermann has noted, the robustness of the motivation to offset is a little dubious. Maybe I’ll pay the £13 now, but what about £200? What if I can’t afford that – will I really give up flying altogether? I’m not sure. But I think this problem is irrelevant to my Florida flights. If offset prices go up, and in a decade I fly without offsetting, then that will be morally wrong. Perhaps it will also show that my motivation this year wasn’t very robust. But it won’t show that this year’s flight-and-offset package was wrong. By analogy: suppose that you stop giving to charity when the economy crashes. This might show that your donations during the good times were not backed by very robust moral motivation – you only helped when it didn’t sting too much. That’s not great. But it doesn’t mean that your donations during the good times were morally wrong. Wouldn’t it be better if we all give up flying because of climate change, rather than fly and offset? Even defenders of offsetting often say this. But flying brings real benefits, even if only to a fraction of humanity. If we can get those benefits without harming the environment, then that’s a good consequence, which counts for something morally. Even thinking about offsetting can be beneficial. Spend some time with a carbon offset calculator, and you will likely face some uncomfortable truths. Rich people (in global terms) like travel, and one such truth is that there’s no carbon-friendly way to cross the ocean. Last year, my family took the boat from Southampton to New York for a close friend’s wedding, partly for climate reasons, and partly to avoid a flight with a toddler. We were dismayed to learn that the cruise ship was probably worse for the environment than flying would have been. As with tipping in American restaurants, a good slogan might be: “If you can’t afford the offset, then you can’t afford the flight.” But many people who oppose tipping on moral grounds don’t stop dining out. They just stop tipping, which is the worst of both worlds. Don’t be like that. So assuming, as I have been, that offsetting does work, stop worrying about the climate impacts of flying, if you can afford to offset – and actually do so."
"
Share this...FacebookTwitterA retired German climate scientist says the IPCC has ventured into “the red rev range of ideology and reality loss”, and adds there is no stringent scientific proof of CO2’s influence on climate
At the European Institute for Climate and Energy (EIKE), a German climate scientist, wonders if the IPCC and German media have lost their grip on reality as they place the blame for global warming on human CO2 emissions.
Prof. Dr. Horst-Joachim Lüdecke writes that the IPCC is in the “red rev range of ideology and reality loss” as the German media and politicians renew their calls to drastically cut back CO2 emissions in order to keep the planet from “dangerously overheating”.
The German climate scientist, however, says CO2’s impact on the climate are exorbitantly overblown.
Germany’s share of global CO2 negligible
First Prof. Lüdecke reminds that Germany’s share of global CO2 emissions is so puny that any reductions efforts by the country will have no detectable effect on global temperatures, and cites a Report of the PBL Netherlands Environmental Assessment Agency.
In the report’s Fig. 2.3 we see:
&amp;lt;img class=”alignnone size-medium wp-image-49858″ src=”https://www.eike-klima-energie.eu/wp-content/uploads/2018/10/pbl-2017-640×412.jpg” alt=”” width=”640″ height=”412″ srcset=”https://www.eike-klima-energie.eu/wp-content/uploads/2018/10/pbl-2017-640×412.jpg 640w, https://www.eike-klima-energie.eu/wp-content/uploads/2018/10/pbl-2017-768×494.jpg 768w, https://www.eike-klima-energie.eu/wp-content/uploads/2018/10/pbl-2017-1024×658.jpg 1024w, https://www.eike-klima-energie.eu/wp-content/uploads/2018/10/pbl-2017.jpg 1213w” sizes=”(max-width: 640px) 100vw, 640px” /&amp;gt;


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Image (Fig. 2.3): Emissions of climate gases worldwide (here)
As the chart shows, the European Union share of global emissions is only 9%. At 2.5%, Germany is a mere fraction of that.
“Already we see that our share globally is negligible,” Lüdecke writes.
“Fictional” damage
Lüdecke also doubts the large role CO2 is claimed to have on climate, and characterizes the notion the climate is somehow damaged by human CO2 as “fictional”.
“No stringent proof” manmade CO2 influences climate
The retired German professor also says that according to the scientific literature: “To date, there is no stringent proof that the anthropogenic, i.e. human-made (!) CO2 has exerted any influence on the climate which is clearly traceable to this source.”
Lüdecke adds that the temperature increase seen at the end of the 20th century is well within the range of natural variability and is not unusual and that, if anything, CO2 is good for the planet.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe European Institute for Climate and Energy (EIKE) posted a video of prominent German geologist Dr. Stefan Kröpelin, who in a presentation late last year in Munich called the notion of CO2-induced climate tipping points scientifically outlandish.
He also called the prospect of the Sahara spreading into Europe preposterous. 
EIKE recently wrote an article on the presentation and posted the presentation (in German). The article follows in English (headings added):
==========================================
The Green Past of the Sahara
Stefan Kröpelin geographer and geologist who, after his training at the Free University of Berlin, has been working at the Institute for Prehistory and Early History in Cologne since 1995. He is one of the most renowned expedition researchers in the field of “Climate, Cultural, and Landscape Change in Arid Africa,” and is best known for his scientific travels to Sudan and Chad. In his career he has undertaken about 60 expeditions, which have been presented in numerous popular science TV programs.
Sahara once a paradise
In his lecture, Dr. Kröpelin first gave an overview of the Eastern Sahara located in Sudan, Chad, Libya and Egypt. The region is the driest place on planet Earth today. But thanks to natural climate change over the millennia, this has not always been the case. On the contrary: if you think of the Hungarian researcher László Almásy, known from the book and film “The English Patient”, who discovered “swimmers” on cave paintings in Eastern Sahara as early as the 1930s, you know that the area was once a paradise.
Explorer Kröpelin was able to confirm Almásy’s assumptions through his work – and even add an almost unbelievable fact.
Higher temperatures 7500 years ago
The paradisiacal humid conditions in the east of the Sahara prevailed between about 8,500 and 5,300 B.C., i.e. after the last Ice Age and at the beginning of the Neolithic, when higher temperatures led to frequent rainfalls, and thus raised the groundwater level considerably, and allowed surface waters and rich vegetation.
As a result of the gradual drying up of the region over the last 7,000 years, the human inhabitants migrated south to present-day Sudan or later to Egypt, where they founded the Earth’s first advanced culture on the Nile with its fertile floods.

Video of Dr. Stefan’s lecture on the slow drying up of the Sahara on the occasion of the 12th IKEK in Düsseldorf in November, 2018
Cooling means a drying Sahara


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The slow drying out of the Sahara was caused by a successive cooling of the climate, analogous to the formation of savannahs through warming. Interestingly, today’s Sahara desert does not have the dimensions it had during the maximum of the last ice age about 20,000 years ago. At that time, the desert extended hundreds of kilometres further south into today’s Sahel zone.
Lake sediment, cave paintings unlock secrets of the past
How could Dr. Kröpelin reconstruct climate events in North Africa over the millennia? What natural climate indicators does the region offer?
One of the best sources of climate data are the deposits at the bottom of the largest lake in the Sahara, Lake Yoa in the oasis of Ounianga in north-eastern Chad, from which as much water evaporates every day as the city of Cologne consumes every day.
The loss is compensated by the abundant fossil groundwater resources. But it is not only hidden data deep in the ground that are suitable for precisely reconstructing the past of the climate in the last decades – the human settlement of the region and its legacies are also a reliable climate indicator. Particularly impressive in this context are the aforementioned cave paintings, which were able to withstand the sandstorms and the heat surprisingly well. These prehistoric works of art were not made in a short time, but over thousands of years. The depicted objects like the floating people or cattle herds stand for different phases of the colonization.
“Tipping Point” catastrophe theory contradicted

The proven gradualness of climate change at that time contradicts the “Tipping Point” catastrophe theory, which predicts a “climate collapse” with drastic changes in the environment in only one human generation. In fact, Kröpelin’s research shows that climate change in the Sahara has been so slow that people have hardly noticed anything about it during their lifetime.
Stefan Kröpelin also refers in this context to the political use of the current climate catastrophe theory, which is even misused for mass immigration policy.
The exponential increase in the world population over the next 50 years is the real problem facing our civilization.
A Sahara reconstructed timeline follows:


Cropped from video here posted above. EIKE
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterInnovation Award for Climate-Friendly Methane Cracking

Producing Hydrogen from Natural Gas without Emissions: German Gas Industry Honors a Process Developed by Researchers from Karlsruhe and Potsdam – KIT Spin-Off Ineratec Receives Special Award for Innovative Startups

The experimental reactor for methane cracking is part of the liquid metal laboratory at KIT (Photo: Amadeus Bramsiepe, KIT)
Generating energy from natural gas without climate-damaging CO2 emissions – that’s the promise of a new technology developed in a joint research project by scientists at Karlsruhe Institute of Technology (KIT) and the Institute for Advanced Sustainability Studies (IASS) in Potsdam. Natural gas, which mainly consists of methane, is converted into hydrogen and fixed carbon. For their work, the researchers have now received the German Gas Industry Innovation Award. KIT was also honored with a new special award for the most innovative startup which was presented to Ineratec, a spin-off of the research university.

“The German Gas Industry Innovation Award for the new methane cracking process is testament to the innovative spirit of our scientists,” says the President of KIT, Professor Holger Hanselka.
“The option of using fossil natural gas in a climate-friendly way in the future can make a major contribution to curb CO2 emissions. I am very pleased that we, as the research university in the Helmholtz Association, can make this important contribution to climate protection together with our partners.” The award was presented to the research team consisting of scientists from KIT and IASS on November 22 in Berlin. The research team also won an additional award voted for by the attendees at the ceremony. The event was held under the auspices of the Federal Minister of Education and Research, Anja Karliczek.
 
 The winners of the 2018 German Gas Industry Innovation Award from KIT and IASS in Potsdam (Photo: Claudius Pflug)
The new process makes it possible to use natural gas in a climate-friendly manner. “Instead of directly burning natural gas, which mainly consists of methane, we break it up into its components hydrogen and carbon,” says Dr Stefan Stückrad who has co-managed the research project at IASS. The hydrogen produced in methane cracking can be used as an energy source in fuel cell vehicles as well as for generating electricity and heat.
Applications in the chemical industry are also possible. “So far, hydrogen for the chemical industry has mainly been produced from natural gas by steam methane reforming. During this process, considerable amounts of carbon dioxide are released,” says Stückrad. In addition to hydrogen, very pure powdery carbon is created as a by-product during cracking, the importance of which is constantly increasing as an industrial raw material. For example, it is used in the production of elastomers, lightweight materials, printing inks and batteries.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Methane cracking is not a new idea as such and has previously been analyzed in experiments with gas phase reactors. “Conventional methods proved unsuitable for application at an industrial scale, though,” says Professor Thomas Wetzel from the Institute of Thermal Process Engineering (TVT) at KIT. “The carbon produced during cracking was deposited on the heated reactor walls as a solid layer, blocking the reactors in a short space of time. Other approaches on the basis of arc- or plasma-based reactors weren’t very successful either.” The research project from IASS and KIT has therefore chosen a fundamentally different approach for continuous pyrolytic methane cracking.
The basic idea is to use molten tin as a heat transfer and liquid medium in a bubble column reactor. Here, KIT scientists have applied their expertise in liquid metal research and technology. In the Innovation Award winning process, methane gas is continuously fed into a liquid metal column from the bottom, which is kept at a temperature of up to 1,200 degrees Celsius, and rises as a bubble swarm. The gas in the bubbles very quickly reaches the reaction temperature so that pyrolysis reaction takes place. “The bubbles open up on the surface of the liquid tin and release the gaseous hydrogen and carbon,” says Wetzel. “The carbon occurs as micro-granular powder that is easy to separate from the gas stream and easy to handle.”
The new technology is now for the first time enabling continuous operation of a reactor for methane cracking. A conversion rate as high as 78 percent has been proven on a laboratory scale. The groups of scientists are currently working on further optimizing and scaling the process to pilot level.
Producing synthetic fuels from renewable energy sources inexpensively is also an important element for the energy transformation. Huge systems are required to produce synthetic gasoline, kerosene, diesel and natural gas. Ineratec, a KIT spin-off, builds chemical reactors that are so compact that the assembled system fits in a shipping container and can be used anywhere. At the 2018 German Gas Industry Innovation Award ceremony the young company was honored with a special award for the most innovative startup.
The German Gas Industry Innovation Award
Every two years, the associations of the German gas industry present the German Gas Industry Innovation Award organized by the Association for the Efficient and Environmentally Friendly Use of Energy (ASUE). Award partners of ASUE are the German Technical and Scientific Association for Gas and Water (DVGW), the Association of the German Energy and Water Industry (BDEW) as well as the Zukunft Erdgas industry initiative. The awards are presented in four categories; the project from KIT and IASS on methane cracking was a winner in the “Research & Development” category. INERATEC was honored with a new special award for innovative startups.
Detailed caption: The experimental reactor for methane cracking is a 1.2-meter-high device made from quartz and stainless steel which contains molten tin. In the reactor, cracking takes place in methane bubbles as they rise up. The reactor is part of KALLA (KArlsruhe Liquid Metal LAboratory) where various technologies for the use of liquid metals are developed. (Photo: Amadeus Bramsiepe, KIT)
More about the KIT Energy Center: http://www.energie.kit.edu 
Hat-tip: Die kalte Sonne.

Share this...FacebookTwitter "
"Shrubs and grasses are springing up around Mount Everest and across the Himalayas, one of the most rapidly heating regions of the planet. The impact on water supplies of the small but significant increase in vegetation between the treeline and snowline is not yet known but could increase flooding in the vast Hindu Kush Himalayan region, which covers 4.2msq km(1.6m sq miles), feeds Asia’s 10 largest river systems and supplies 1.4 billion people with water. Scientists used satellite data to identify increases in vegetation in the inaccessible subnival (the highest zone allowing plant growth) ecosystem, made up of grasses and dwarf shrubs with seasonal snow. This ecosystem is known but could play a crucial role in the region’s hydrology, covering between five and 15 times the area of permanent glaciers and snow in the region. Studying images from 1993 to 2018 provided by Nasa’s Landsat satellites, researchers from Exeter University measured the spread of vegetation cover across four height brackets from 4,150 to 6,000 metres above sea level. The melting of Himalayan glaciers has doubled since the turn of the century, with more than a quarter of all ice lost over the last four decades. Research has suggested that its ecosystems are highly vulnerable to climate-induced shifts in vegetation. “A lot of research has been done on ice melting in the Himalayan region, including a study that showed how the rate of ice loss doubled between 2000 and 2016,” said Dr Karen Anderson, of the Environment and Sustainability Institute on Exeter’s Penryn Campus in Cornwall. “It’s important to monitor and understand ice loss in major mountain systems, but subnival ecosystems cover a much larger area than permanent snow and ice, and we know very little about them and how they moderate water supply.” It is not yet known how more vegetation might affect water supplies but studies of increased vegetation in the Arctic found that they delivered a warming effect in the surrounding landscape, with the plants absorbing more light and warming the soil. “That would be bad news for the Himalayas,” said Anderson. “The subnival zone is where seasonal snow is held and if it is warmer you will get flashy hydrology – quicker melt rates and an increased risk of flooding.” But Anderson said that more vegetation may not actually increase warming and flood risks in the Himalayas, with the only study in the region, in Tibet, finding that the water in the plants that is evaporated through their leaf surface actually exerted a cooling influence. “We really don’t know much about this area and we need to direct research attention towards it because it’s a major part of the water supply story in the Himalayas,” she added. The study, published in Global Change Biology, was made possible by Google’s new Earth Engine, which provides researchers with a freely accessible collection of government agency satellite data in the cloud. Previously, researchers would have had to build a super-computer to sift through the enormous quantities of satellite data. “It has really revolutionised this kind of work and enables large-scale, long time-series investigations like this to happen,” said Anderson."
"
Share this...FacebookTwitterGive Der Spiegel credit for offering some balance in a debate that sorely needs it…
Geology major, science journalist Axel Bojanowski just penned a commentary at Spiegel Online on the recent hot weather hype we witnessed in the wake of Europe’s warm and unusually dry summer.

Spiegel journalist Axel Bojanowski takes the recent climate heating hysteria head on, writing that the recent shrill claims by some scientists defy IPCC’s own findings. Photo image: cropped from Twitter here.
The title of his commentary: “Overheated – Forest Fires, Drought, Heat – Has The Climate Catastrophe Already Arrived? Time For A Cool Examination.”
Media “part of the problem”
Over the past couple of weeks, alarmists and media from the usual suspect institutes have been stopping at nothing to blame this year’s dry northern European summer on man-made climate change, and have renewed (from within their air-conditioned offices) calls for people to finally accept making the huge sacrifices needed to keep the climate system from “tipping” into irreversible catastrophe.
The Spiegel journalist comments on another shrill column, by Georg Diez, published a week earlier also by Spiegel. Diez echoed the doom and gloom presented to us in Losing Earth: The Decade We Almost Stopped Climate Change by Nathaniel Rich of the New York Times magazine.
According to Diez, it is now clear “what it means to live in a time of catastrophe”.
Here Bojanowski notes “it turns out that many reports are part of the problem.”
Global warming not known and “supported” until the 1990s
Firstly, Bojanowski calls the claim that we knew about global warming already back in the 1970s false, and that it was in reality first an idea that only came up in the 1980s and did not get scientifically supported until the 1990s. He then adds that “considerable uncertainties remain, that still have not been cleared away even until today.”
James Hansen “damaged trust in climate science”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Bojanowski also describes how James Hansen jumped the gun in 1988, and how his methods “damaged the trust in climate science even until today.” Another problem at the time was the media running with the most spectacular doomsday scenarios with the aim of capturing public attention.
Still fraught with “considerable uncertainties”
According to Bojanowski, although Hansens’s dramatic claims did thrust him into the pioneer role, they also contributed “to the division of society in the climate debate, which has made it more difficult to produce political solutions even today.”
He also points out that the media and alarmists continue to ignore the IPCC’s own findings on a number of fronts, such droughts, where he reports that drought scenarios as a consequence of climate change “are subject to considerable uncertainty, according to the UN climate report.”
‘Very sharp decline’ in the fires since 2001
The free-thinking Spiegel journalist also mentions how we seldom hear why fires worldwide have been on the decline over the past decades: “Since 2001, researchers have even noticed a ‘very sharp decline’ in the fires.”
“Debate in dilemma”
Bojanowski calls the media’s hope that exaggerations will motivate people to support climate change “a fallacy”. The more climate scientists hype up the science, the more people will turn away from the topic, he writes, citing sociologists.
Bojanowski’s assessment: “The debate is in a dilemma: only those who push themselves forward with hysteria, get attention.”
No new findings, old speculation
Finally the Spiegel journalist also expressed his surprise over how a recent shrill paper that announced the possibility a hot period was starting needed only 17 days to get published. Bojanowski noted that the paper “did not present any new findings” and that “it was about known speculations over so-called climate tipping points.”
Protecting climate protection
Without surprise, Bojanowski’s commentary was greeted by a less than friendly German reaction. He tweeted here of having been accused of “damaging climate protection”. Climate science dissent in Germany is not to be tolerated. Exercising dissent, or even just keeping a cool head, can make you an enemy of the cause.
 
Share this...FacebookTwitter "
nan
nan
nan
"The apocalyptic images of desolate, scorched landscapes following the wildfires in Greater Manchester and Lancashire are hard to reconcile with the lush, picturesque moorland scenery that had existed just days before. While the fight to extinguish these fires continues – and may do so for weeks – our thoughts turn to the recovery of the affected area that now exceeds 2,000 hectares in size. Words that have been used to describe the burnt areas in the media include “devastated”, “ravaged” and “barren” – but is this really the case? The question now is whether our moorlands, which are home to many rare and endangered species and play an important role in carbon and water storage, will be able to recover from this “relentless destruction”. The full scale of the impact to wildlife and the moorland habitat will not be known until the blaze is out but some of the immediate effects are clear. Animals that could escape the flames, such as deer and mountain hares, have moved to more hospitable landscapes. But those with more limited mobility, for example small mammals, reptiles, amphibians and insects, may not have been so fortunate.  The timing has been particularly crucial for species of ground-nesting birds, such as skylarks, meadow pipits, curlews and short-eared owls, whose nests and young are at risk of being burned. For plants, all vegetation above the ground will have been scorched and many seeds and root systems will have been destroyed by the heat. The fire may also be having effects on the soil – there have been reports of smouldering peat fires. Severe fire can act as a steriliser, essentially resetting the successional clock (how an ecosystem progressively changes over time) in an area by reducing complex and established communities of fungi, microbes, plants and animals to bare soil. At extremes it can also heat and damage the soil’s structure and community of organisms, which may trigger irreversible erosion. Of particular concern in these current fires is the burning and resultant loss of peat and its associated vegetation, which not only releases large quantities of greenhouse gases and accumulated pollutants (such as heavy metals) but also takes a long time to recover – peat forms at a rate of 0.5 to 1mm per year. As a consequence, the complex web of interactions between moorland species of vegetation is likely to take a long time to rebuild following such a severe fire, with some species possibly becoming locally extinct. The influence of fire can also expand beyond the burnt area. Peatlands occur mainly in upland areas covering the headwaters of most major British rivers and, as such, fires can cause large amounts of organic carbon to be deposited into rivers. This may have significant negative effects on river inhabitants. Much of the scientific literature on the ecological effects of moorland fires focuses on small-scale, controlled fires. Such fires have been used to manage moorland for grouse shooting and may also be an effective conservation tool. For example, studies from five Peak District moors demonstrate that controlled fires are important in maintaining plant diversity.  The lack of controlled burning in the affected areas is suggested as a contributing factor to the scale and intensity of the wildfires with fuel loads having built up over time. The effects of severe, uncontrolled wildfires are less well understood but there is growing evidence that they can have very serious ecological consequences.  But we must not to quickly write off the resilience of our moorland wildlife in the face of these fires. The earliest evidence of wildfires comes from 420m years ago and since then many species of plants and animals have developed ways to survive, regenerate and even take advantage of fire. Some species, such as pine and banksia trees, have gone so far as to become completely dependent upon fire to release their seeds and fulfil their life cycle. In addition to natural fires, species from the moorlands of northern Europe have experienced frequent controlled burns for over 150 years. Moorland plants possess an array of strategies to persist through fire including re-sprouting from protected buds (for example, purple moor grass) and underground structures called rhizomes (such as bilberry), or regenerating from seeds (heather).  These survival mechanisms may come as a direct result of these human-driven management strategies. For example, heather seeds from fire managed heathlands germinate more quickly when exposed to smoke in comparison to those from other infrequently burnt habitats. As a result they are better able to make the most of the bare, nutrient-rich soil exposed by the fire. So the recovery of moorland vegetation on scorched land may be quicker particularly if assisted by patches of unburned vegetation. It is the severity of these fires, which is yet unknown, that will be decisive to their ecological impact. Importantly, with upland fires becoming more frequent under climate change, we must find a management solution, such as the use of regular burns to control fuel loads, that reduces the impact of wildfires and preserves these internationally important ecosystems."
"Despite government commitments to nuclear power, the proposed new plant at Hinkley Point is still some way off. This matters as new nuclear plants could have a critical role in providing the UK with low carbon electricity, while maintaining secure supplies.  Once complete, the new Hinkley plant alone should provide around 7% of the UK’s electricity. However further delays could pose a threat to the security of the UK’s electricity supplies. So is the country facing a looming “power gap” in the early 2020s? Old coal and gas plants will be under increasing pressure to close in the next decade due to the UK’s domestic climate change commitments as well as European air pollution regulations. The EU’s Industrial Emissions Directive (IED) essentially forces plants that don’t meet its standards on emissions to choose between fitting clean-up technologies to remove harmful air pollutants, or accepting strict limits on their operation before a final closure by the end of 2023. This latter option is known as the “limited life derogation”. The full effect of the IED is not yet clear. However, according to Reuters, the UK plants which are currently expected to close before the end of 2023 as a result of the directive represent around 12,000MW of capacity. This is equivalent to around 20% of the country’s peak electricity demand. The major attractions of new nuclear plants in this context are their “baseload” –  or unfluctuating – output, along with their sheer size: the planned Hinkley plant’s output is 3,200 MW. For comparison, the UK’s largest existing offshore wind farm, the London Array, weighs in at 630MW. With Chinese investors showing interest, the government clearly feels nuclear offers the most direct route for filling the gap and thereby avoiding the lights going out. However, with the completion of Hinkley Point by its scheduled 2023 finish date now unlikely, and with firm final investment decisions for other mooted UK nuclear projects not yet taken, the country needs additional solutions. By 2030, nuclear could play a significant role in a heavily decarbonised UK electricity system. However its prospects for the more medium-term horizon of the early 2020s remain uncertain. Although individual renewable projects are small in comparison to nuclear power stations, the renewable industry as a whole is showing that it can deliver substantial amounts of capacity at a rate of megawatts-per-year that is starting to put nuclear planning timsecales firmly in the shade. The longer we wait for nuclear, the more the current government’s “mixed messages” about renewables may themselves seem a threat to security of supply.  Public objections to wind and other renewables have been much publicised; however, there is evidence that innovative approaches to ownership and distribution of benefits within local communities could substantially increase support. Yet even with lots more wind, solar and tidal power in place the UK may still need more conventional capacity by the early 2020s, as the scale of IED closures becomes clearer – not least because variable weather makes it hard for renewables to guarantee full availability at peak times.  It may be that as the European regulations begin to bite, there will be some requirement for new, cleaner gas plants, which could be built relatively quickly. However these plants would have an increasingly intermittent operating schedule, getting called into action only to meet peak demands, or to cover weather-related drops in solar or wind output.  The commercial case for building such rarely-operating plants would be dependent on them being able to make enough money back from this style of occasional operation. The government’s current approach – the “capacity mechanism” – is to pay a retainer fee to generators in return for guaranteeing their availability if called upon at short notice. Faced with a possible shortage of supply, we’ve so far looked at ways to generate more electricity – but, clearly, another is to reduce demand. This could take the form of reductions in the overall level of demand, for example due to increased efficiency – better technologies, switching off lights, and so on. However, just as effective could be shifting electricity usage to avoid coinciding with “peak demand”, the point at which the system is under greatest stress. People or organisations who take part in such arrangements should rightly be rewarded, for example with lower electricity tariffs for providing a useful service to the system and helping to reduce overall costs.  While such innovations are sometimes castigated with headlines invoking the three day week of the 1970s, or “third world” electricity systems, in fact they constitute an economically rational approach to the problem of supply and demand, under which both users and suppliers stand to benefit.  The question of security of supply itself could also benefit from some more sober analysis. Any story which raises the spectre of the lights going out implies it is the responsibility of the government, National Grid, or the energy suppliers to guarantee a system which never fails.  This is not the case. As with all aspects of life, risk is inherent, and the expectation of zero-risk is not reasonable. Rather, the question should be: how much are we willing to spend on reducing risk any further? For example, the capacity mechanism will reduce the risk of supply shortages, in part by guaranteeing back-up plants; however these guarantees cost money, and these costs fall on consumers through their bills. The more secure we want our system to be, the more we will have to pay for it. It’s time for a more constructive debate on the balance between security and cost, including innovative demand-side responses, in the context of our transforming electricity system."
"The “most realistic” plant-based steak to date has been revealed, mimicking the texture and appearance of a real cut of meat. The fake steak’s ingredients include pea, seaweed and beetroot juice, which are extruded into fine fibres to recreate muscle tissue. Its producer, the Spanish company Novameat, says the steak will be available in some restaurants in Spain and Italy this year before scaling up in 2021.  The enormous impact of cattle and other livestock on the environment has led a swathe of companies to create plant-based alternatives to meat, with the Beyond Meat burger and Greggs sausage roll among the vegan successes. But recreating the texture of whole cuts of meat is far more challenging than ground meat. “I started with steak I think because it is the holy grail of plant-based meat,” said Giuseppe Scionti, founder of Novameat. “It is the most difficult.” The company unveiled a 3D-printed steak in 2018, but the new steak has both the firm, fibrous texture and meaty appearance of a real steak, he said, making it the “most realistic” to date. The company is still experimenting with the taste, but Scionti said the company’ can use the ingredients already used to create convincing beefy burgers from plants. He expects a final formulation in the next few months. The key to the new steak is patented micro-extrusion technology that produces fibres between 100 and 500 microns in diameter. This allows the complex structure of real meat to be replicated, with muscle fibres and fat entwined. Existing extrusion technology produces much larger fibres. The 50g steak produced cost $1.50 (£1.15) to make, similar in price to current supermarket steak in the UK. But Scionti said the cost will drop when the process is scaled up. The company plans to commission a pilot plant in 2021 which can produce 50kg of steak per hour. But to reach a mass market, the company plans to licence its technology to existing food manufacturers who can develop their own recipes. Some plant-based alternatives to meat have been criticised for being as high in fat and salt as the food they are intended to replace. Scionti said plant-based alternatives do not contain cholesterol or the hormones and antibiotics often found in real meat. In future, he said, beneficial ingredients such as omega-3 fatty acids could be added. Novameat is not alone in developing plant-based steaks, with Israel-based Redefine Meat being a leading competitor. Unlike Novameat’s product, the Israeli company’s meat has been publicly tasted, receiving positive feedback, but the firm has not yet revealed a textured steak. Others include Atlast Food, which is using a fungus fibres to create textures similar to meat, and Emergy Foods. Another Israeli company, Aleph Farms, has produced a steak from real beef cells cultured in a laboratory, which, the firm says, will have a much lower environmental footprint than real meat. There is definitely a role for technology that can structure both plant-based and lab-grown meat into more complex products, said Rosie Wardle, at the Jeremy Coller foundation and advisor for CPT Capital, which has invested in Redfine Meat. “I’ve eaten early versions of the Redefine products and they were truly delicious,” she said. Novameat has attracted investment from New Crop Capital, a firm that also invests in some of the best known plant-based and lab-grown meat companies, including Beyond Meat, Memphis Meat and Mosa Meat. David Welch, at the Good Food Institute, which works with scientists and entrepreneurs to create alternatives to animal products, said: “To meet the growing global demand for meat with more sustainable plant-based products, we need to deliver the taste, texture, and appearance that meat eaters want.” He said new technologies such as Novameat’s bioprinting are useful: “They give plant-based meat manufacturers a wider array of tools to mimic all types of meat and seafood.” Scionti said the company aims to produce pork and salmon in the future. Recent scientific studies have found that huge reduction in meat-eating in rich nations is essential to cut greenhouse gas emissions and fight the climate crisis. “We believe it is important to provide an alternative,” said Scionti, who spent a decade researching tissue engineering at the Polytechnic University of Catalonia in Barcelona and other institutions. “This will help in the long term to decrease the need for land, water, energy and, of course, reduce the emissions coming from animal agriculture. “We want to be better than the other companies,” he said. “But we are all in the same boat. We want to be remembered for doing something good at this moment when the planet needs alternatives to meat. ”"
"It is said that on average, we take 66 days to form a new habit.  So when an initiative sets out to change our habits in just 24 hours, there’s cause for scepticism. World Car-Free Day aims to do just that. The thought is that by closing city centres to cars for one day a year, people will make a long-term switch to alternative modes of transport and help us to address the many problems caused by our dependence on cars.  Car-free days have been running for almost 20 years, with cities as far afield as Washington, Paris, Brussels, Stockholm and New Delhi participating. And though the impact of these initiatives has not been well evaluated, there are studies which suggest that events which disrupt the transport system can lead to longer term behaviour changes. Strikes and road closures, for example, force people to try something different, and alter their knowledge and perceptions of the travel alternatives on offer.  One worldwide 2002 study of over 70 road closures due to natural disasters and planned roadworks found that, on average, 11% of vehicles previously using the road could not be found in the surrounding area afterwards. A more recent study on the impact of strike action on the London Underground in February 2014 used data from travel cards to examine travel patterns before, during and after the strike. It found that 5% of travellers carried on using their newly discovered routes after the disruption was over. While these findings sound encouraging, it’s worth questioning whether the changes to travel patterns after a disruption are any greater than the day-to-day variability we see anyway. And if they are, there’s still no guarantee that enough people maintain these changes for long enough to alter overall travel patterns, such as the total kilometres driven from one year to the next. A three-year study on these topics confirmed that individual travel patterns undergo significant day-to-day and year-to-year churn. For instance, although over half of those who were asked by the researchers before and after the 2012 Olympics in London said they had changed their journeys to work during the games, three quarters said they did not always travel to work the same way on a typical day anyway.  Similarly, half of council employees in York revealed they could not be certain how many days they would travel in to the office in the following week. The study revealed that these variations were due to myriad reasons, from changing family and work schedules, avoiding bad weather or just feeling like making a change.  But if there’s so much churn and flexibility in the system already, why is it so difficult to achieve deep reductions in car use? For these reductions to materialise, we need more people to avoid taking single occupancy journeys in their car more of the time, so that being “multi-modal” – that is, relying on more than one mode of transport – becomes the norm.  But to achieve this, we’ll need a much broader understanding of how and what shapes people’s travel choices in the first place, and how this varies across locations and societal groups. The three-year disruption study suggests that we should think about these issues in terms of a broader “mobility system”.  The mobility system includes not only the transport system (infrastructure, legislation, fiscal arrangements like charges and fares, and public transport operators), but also the communication system (patterns of work, shopping and socialising as well as the information we use on the go) and the social context (the norms about how things are done, the know-how and resources of those in the system, including workplaces and communities).  At the centre of the mobility system are the activities which each generate travel and are influenced by the institutions and expectations in the system, such as school start and end times, or standardised business hours.  Unfortunately, the supporters of car-free day – like most policy targeting transport patterns – fall into the trap of thinking that altering the transport infrastructure and services is all that’s required to alter travel behaviour. While these initiatives can play a role in changing the behaviour of some people, for one day, occasionally, it is far from adequate to influence longer term changes at the scale required. Instead, we need to make changes across the whole mobility system, to continually reinforce greater uptake of alternative transport methods.  Flexible working hours, which relax rigid time and place constraints is an important part of the solution, as is wraparound childcare (such as before- and after-school clubs) to allow flexible schedules. Transport system solutions include payment systems to cater for multi-modal journeys such as the Mobility Mixx card in the Netherlands, which can be used to pay for all public transport, taxis, car pool, bike and car rental and park-and-ride tickets. Another option is seasonal reallocation of road space to pedestrian spaces or non-motorised road users as they did in New York.  We need to think more carefully about how, where and when activities are carried out, and then look at how transport provision fits with that. Only then could car-free days go from being rare annual events to part of making non-car journeys more likely, more of the time."
"In a globalised world, we routinely move enormous quantities of food around the planet in trade and for aid. Many countries, including the UK, would struggle to feed their populations without food imports. Most people are used to being able to buy a wide range of produce which domestic farmers would struggle – or find impossible – to grow. A typical example is the banana, once a prized exotic novelty, but now a staple in many country’s supermarkets. Bananas are one of the most widely grown, traded and eaten of all the crops – an essential and much-loved part of the diet for many people around the world. Modern bananas are sterile, containing only tiny residual seeds, so new banana plants are propagated from cuttings. The sterile domesticated banana is the result of ancient cross-breeding between wild species. In contrast, wild bananas are packed full of bullet-like seeds and contain very little edible fruit. Wild bananas can be found in the wet hot forests of New Guinea and South and Southeast Asia, but for many years the origin of domesticated bananas was a complete mystery. Finding ancient evidence for soft, sappy plants like bananas is extremely difficult at the best of times. The problem is worse in the tropical forests, because of the rapid decay of organic matter in the heat and humidity. The answer was to use phytoliths, a technique first experimentally used in the late 1950s and adopted by archaeologists in the 1970s. These are tiny, complex-shaped particles of silica laid down in plant cells. Silica is an extremely durable mineral, and silica phytoliths have been shown to survive for millions of years in suitable circumstances. Phytoliths have provided an exciting tool for archaeologists and palaeobotanists exploring the origin and history of tropical plants. Some phytoliths of domesticated bananas are distinctive, and therefore give us a tool to chart their appearance in ancient sediments. We have known for some time that phytoliths of cultivated bananas appear at Kuk Swamp in Papua New Guinea around 6,800 years ago. But how they spread into the wider world has not been clear, and has led to much debate. Later finds include those from Munsa, Uganda 5,250 years ago, and Kot Diji in Pakistan, 4,250 years ago. But the status of these finds as domesticated bananas has been disputed. We have been investigating ancient tropical forest use in Sri Lanka and Borneo for the best part of 20 years. Now, in Fahien Cave in Sri Lanka, in deposits about 6,000 years old, we have discovered phytoliths identical with those from cultivated bananas. The first people for whom we have evidence arrived at Fahien Cave perhaps as early as 46,000 years ago and used it for shelter regularly but intermittently thereafter.  Phytolith evidence tells us that from the beginning they were eating and using a variety of wild plants, including breadfruit, durians, canarium nuts, species of palm and bamboo – and wild bananas. Even today, the leaves, flowers, fruits, stems and rhizomes of the two wild banana species on Sri Lanka are still used. Ethnographic observations suggest uses as diverse as plates, food wrapping, medicines, stimulants, textiles, clothing, packaging, paper-making, crafts, ornaments and also in ceremonial, magic and ritual activities.  But after the earliest appearance of the phytoliths of domesticated bananas, about 6,000 years ago, we found that phytoliths of wild bananas declined sharply. Less than 1,000 years separates the first certain appearance of phytoliths of cultivated bananas at Kuk Swamp, the earliest example of domesticated bananas anyone has discovered, and the first appearance of phytoliths of domesticated plants in Sri Lanka. Only dispersal by sea, carried perhaps by migrating people, is likely to have been rapid enough to bring domesticated bananas to Sri Lanka an estimated 800 years after their first certain appearance in Papua New Guinea. It is possible that they were then spread into South Asia and Africa from Sri Lanka, or that bananas reached them directly, during the same migration. Ancient DNA studies suggest that movement of populations and interconnection between distant peoples in the ancient world was remarkably common. These early travellers seem, on several occasions, to have carried food plants with them, especially starchy staple crops. For instance, in an earlier paper, we suggested the carriage of swamp sago from New Guinea to Borneo about 10,000 years ago. This would have required a sea voyage of more than 2,000km, but the durable seeds of this important food plant could have been carried easily.  However, because domesticated bananas are sterile, reproduction has to be vegetative, so cuttings or whole plants must have been carried. The transport of banana plants or cuttings between Papua New Guinea and Sri Lanka would have been fraught with difficulty, as it most likely happened in open canoes – an amazing feat, even if the journey took many voyages over many years. These heroic journeys also occurred on land. For instance Martin Jones’ FOGLIP Project has charted the spread of millets, wheat and barley across Asia from the sixth millennium BC. The ancient dispersal of manioc from central South America to Mexico and of maize in the opposite direction has also been suggested.  What does all this indicate? Global connections and exchange may be perceived as part of the modern world – but it is becoming increasingly apparent that these tendencies are deeply rooted in our prehistory."
"
Share this...FacebookTwitter“Extreme sea level rise warnings based on predictions by never validated models, or speculations, that are defocusing coastal management from every other relevant situation, should be discharged.” — Parker, 2018


Parker, 2018
Sea level oscillations in Japan and China since the start of
the 20th century and consequences for coastal management
“Regionally, the sea levels in the PRD [Pearl River Delta, China] region and Japan show no significant acceleration from 1900 to present, but only oscillations. This result is consistent with the other coastal area of the world where long-term tide gauges are located. Policy making, and management, should therefore focus on adaptive measures linked to the monitoring by tide gauges and Global Navigation Satellite System (GNSS) of relative sea level rise and land subsidence. Extreme sea level rise warnings based on predictions by never validated models, or speculations, that are defocusing coastal management from every other relevant situation, should be discharged.”
“[T]he long-term tide gauges of the world show no significant sign of sea level acceleration since the start of the 20th century.”
“Ocean and coastal management in the area should be based on the accurate monitoring of the relative sea level rise and the subsidence of the land by coupled tide gauge and Global Navigation Satellite System measurements, rather than models’ predictions and speculations defocusing coastal management from more relevant situations than the non-existent threat of extreme sea level rise.”

Share this...FacebookTwitter "
"The impact of climate change over the past five months across Australia has caused climate change deniers within the media and governments to quickly update their tactics to a new, sinister position. Gone are the plans to just keep lying for the next decade that activists such as Greta Thunberg are predicting that the world is going to end in 2030, or to continue to flub and fudge the science – no real warming since 1998, 2005, 2010, 2016! Solar activity! Volcanoes! Greenland! Now of course the feculent minds of columnists and government MPs will continue to spout these lies – when has reality ever been an impediment to their effluent-driven utterances? But the months of fires across southern Queensland, northern New South Wales, the horrors of Gippsland, the NSW south coast and Kangaroo Island over Christmas and new year, the smoke haze across Sydney and Canberra and now Melbourne, has shifted forwards their timetable of obfuscation. Five months ago they could still get away with wheeling out the “now is not the time” line, or to confidently state that you cannot link this bushfire to climate change. But now such lines are greeted with universal scorn. Last year was the hottest and driest calendar year in Australia’s recorded history. That created the conditions for the fires, and they do not exist without climate change. At this point any climate change denier with access to a social media account will tell you that rainfall has actually increased over the past century in Australia. That is true, and also utterly irrelevant and designed to mislead. Climate change impacts have only really taken off since the late 1960s and early 70s, and not surprisingly, given the size and differing climates of Australia, the impact on rainfall has varied. Over the past 50 years the trend rate of rainfall in northern Australia has barely changed – if anything, it has risen a bit (great if you like rain and you live in Broome) but in south-eastern Australia the trend is clearly falling: So now that they are unable to say “now is not the time”, they have adapted. Rather than suggest no connection with climate change, they have shifted to arguing there is no connection between any particular climate change policy and bushfires. Scott Morrison argued last week on ABC’s 7.30: “You cannot link any individual single emissions reduction policy of a country – whether it’s Australia or anyone else – to any specific fire event. I mean, that’s just absurd.” Nothing Scott Morrison has said suggests any change in policy that will actually involve emissions reductions Yes, it is absurd, because no one is actually arguing that. But the prime minister is very good at defeating arguments no one is making. He is also very good at giving false hope. Right now columnists and journalists are writing articles expressing belief that maybe Morrison is about to shift the government’s climate change policy. Perhaps he will, but I have seen Charlie Brown try to kick this football before and I remain unpersuaded because I have listened to what the prime minister himself has said just this past week. Three times David Speers asked him on Sunday if the government would increase its emissions targets. Morrison responded with: “Well, the cabinet and the government will continue to evolve our policies.” Then he added: “What I’m saying is I’m not going to put someone’s job at risk, a region’s, town’s future at risk.” And finally: “What I’m saying is we want to reduce emissions and do the best job we possibly can and get better and better and better at it.” What he is saying is “no”. Nothing he has said suggests any change in policy that will actually involve emissions reductions. Instead he has quickly adopted the new go-to response of climate change deniers – that of the need to adapt and “improve resilience”. What does that mean? It means the next step in climate change denial – a step I joked grimly last month was not far away. Alas, it is no longer a joke. The new argument is that, yes climate change is probably to blame, but we can’t do anything about it, and anyway it’s too late now, so let’s “adapt”. And what does that adaptation involve? According to Morrison: “Building dams is key to that. Native vegetation management is key to that. Land clearing is key to that.” In other words doing the very things conservatives have been desirous of for the past century – building dams, reducing national parks and increasing land clearing. They will hand out grants to organisations and areas most electorally beneficial and all the while trumpet that they are dealing with the issue in a practical way, unlike the opposition which, they argue, will be trying to kill jobs. Conservatives hate dealing with the actual source of problems – they much prefer handing out the graft; which is appropriate when you realise climate change denialism is the biggest con in political and media history. And of course emissions will rise while they suggest they are actually being reduced. The line from Morrison is that we will “meet and beat” our Paris emissions reductions targets. The current figures from his own government show that rather than reduce emissions in 2030 by 26% below 2005 levels, we are on track to cut them by just 16%. But the real problem – one that needs much more attention than interviewers now give it – is the 26% target itself has no basis in science as being anywhere near enough to keep temperatures below 1.5C. The Intergovernmental Panel on Climate Change reported in 2018 that to keep global temperatures from rising above 1.5C, C02 emissions needed to “decline by about 45% from 2010 levels by 2030, reaching net zero around 2050”. Forty-five per cent, not 26%. And that is a 45% reduction of actual emissions, not including farcical “land use” figures. When we exclude land use, our 26% target really becomes closer to 15%. Morrison boasting that Australia will meet and beat its target is like someone boasting that they are beating their target of 10 minutes of exercise a day, and hoping everyone ignores that doctors recommended 30 minutes. A 45% cut of real emissions is well below what the government is targeting and miles below our current projections: The reality is, even while including land use, we are still well short of where we need to be: And so we enter the next stage of climate change politics – a subtle and sinister shift – the talk will be about practical measures of adaptation rather than of reducing emissions: gone will be direct action, in its place will be “direct adaptation”. It is a stage that, if successful, will signal the end for our planet. Greg Jericho writes on economics for Guardian Australia"
"
Share this...FacebookTwitterThe non-falsifiable climate catastrophe: No matter if it’s hot or cold – it always has got to be global warming
By Die kalte Sonne
(Text translated by P Gosselin)
The Central European heat summer of 2018 was a feeding frenzy for the followers of the climate disaster. The media turned it into sensational news and clearly saw climate change at work.
And then came the winter. In the US, this year (2018) saw one of the coldest Thanksgiving holidays of the past 100 years. That did not suit the PIK at all. Quickly there was a press release (22/11/2018) that blamed the cold spell on global warming:
Winter weather extremes in the US and Europe: messing with giant airstreams in the stratosphere
Over Thanksgiving, arctic air masses are predicted to bring record-cold temperatures and frigid winds to the Northeast of the United States. Driver for such winter weather extremes is often the stratospheric polar vortex, a band of fast moving winds 30 kilometers above the ground. In winter, when the polar vortex is disturbed by upward-blowing air masses, this can bring cold spells over Northeastern America or Eurasia, a new study now shows. And paradox as it might seem, climate change might further disrupt the complex dynamics in the atmosphere – bringing us not only more hot extremes in summer but potentially also cold spells in winter.”
Read more here.
No matter if it’s hot or cold, it always has to be global warming. The crazy world of climate alarm. If one follows this logic, there is no single weather condition that could refute the concept. The climate catastrophe model can not be falsified, no matter what the weather. This indeed breaks an important principle of science. 
But to ensure the well-being of mankind, scientific sacrifices must be made. With autocratic climate rule breaking all the laws of science is standard procedure.
Share this...FacebookTwitter "
"A staggering 235m items of unwanted clothing were forecast to be dumped in UK landfill in 2017, while the average American is estimated to bin 81lb (37kg) of used clothing annually. Overconsumption and the inevitable disposal of unwanted clothing has become a worrying global problem – and in many cases, this clothing is unnecessarily thrown away. Instead, it could be repaired or recycled. Filling landfill with clothing and textiles costs the UK alone an estimated £82m every year. But on the flip side, the consumption of clothing is hugely important to the economies of many countries, too. Research from The British Fashion Council, for example, found that fashion contributes £28 billion directly to the UK economy – and globally, it is a US$2.4 trillion industry.  Despite this, materialistic values and a widespread desire for having new things, twinned with fashion’s premise to create – and sell – different styles, has reduced the functional value of clothing, making it easily disposable. A staggering 100 billion items of clothing are being produced annually, and 50% of fast fashion pieces are disposed of within a year.  In fact, recent figures show that one rubbish truck of textiles is thrown away every second globally. Little wonder, then, that fashion has been dubbed “incredibly wasteful” – even by insiders.  Fashion and sustainability have historically had an uncomfortable relationship. The 2013 Rana Plaza disaster in Bangladesh, along with growing concerns over sweatshop labour, have seen fashion companies overhaul their social and environmental impacts. Consumers, meanwhile, have grown increasingly concerned about where and how garments are made. But while fashion takes strides to become ethical, there are still serious concerns over its environmental impact and contribution to climate change. Fashion is deemed to be one of the world’s most polluting industries – from toxic chemical use to water pollution and waste. Some 35% of the global total of microfibres in the oceans comes from clothes and textiles, meaning fashion is a major contributor to this pollution. By 2050, it is anticipated, the fashion industry will use up 25% of the world’s carbon budget.  So what’s the solution? A circular economy seeks to move beyond fashion’s linear model of take, make and waste, to close the loop, designing out waste and minimising environmental impacts. While fashion brands work to limit their polluting practices through the creation of organic, environmentally conscious collections, there is still a need to limit the sheer volume of waste that fashion creates.  Recycling has become an important initiative to address this. H&M, for example, has a successful garment collection scheme, repurposing their consumers’ unwanted clothing. Other brands, meanwhile, are using recycled materials to create clothing. Outdoor clothing brand Patagonia has made polyester fleece out of recycled plastic bottles.   While recycling could achieve circulatory by designing out waste, it is problematic environmentally. Recycling is energy intensive and may require use of further virgin materials. Additionally, while it resolves some of fashion’s sustainability issues, it does not adequately address the problem that consumers buy too much, and that the average number of times a garment is worn has declined by 36% since 2000. We must reconsider how fashion is sold, encouraging consumers to waste less, and ensure that garments have a longer life span. WRAP, the UK’s resource efficiency agency, has identified leasing as an innovative business model that gives clothes a longer service life, while reducing material use and carbon dioxide emissions. A recent survey conducted by Westfield Shopping Centre in London also proposed that clothing rental would become a key future trend.  The possible value of the clothing rental market in the UK is predicted to be £923m and the model is already well-established for certain items, such as dinner jackets and wedding suits for men. Despite this, there are currently just a handful of fashion companies that have adopted a leasing model. At Mud Jeans, for example, consumers can lease a pair of organic jeans, and after a year can keep, swap or return them. Girls Meets Dress, meanwhile, was founded in the UK in 2009, under the ethos that in a sharing economy ownership will become obsolete. In America, Rent the Runway has become a significant player in the fashion industry. These companies are built on change, but undoubtedly they face the challenges of the traditional sales-driven fashion system, along with consumer hesitation.   Our research has explored the potential for clothing rental among consumers. While we found there were opportunities certainly at the luxury end of the market, there was a definite resistance to rental of lower priced items, which were just too easy to buy.  If consumers are to engage, rentals need to be convenient, cheap, accessible and fulfil the desire for having something new. Consumers are open to change and leasing could help achieve a more circular fashion industry. However, there are issues to consider from transportation through to dry cleaning impacts. Clothing rental has the potential to reduce waste and increase the lifespan of garments, but to achieve a more sustainable industry a systemic change in business practice and consumer behaviour is needed."
"
Share this...FacebookTwitterProposed wind turbines in Switzerland’s Linth region have been rejected by local communities, the media report. Parts of Switzerland want no part of blighting their landscape in the name of environmental protection.
Hit-tip: a reader from Switzerland
Little wonder!
Here’s what wind energy opposition organization Linth Gegenwind (Linth Headwind) shows what the otherwise idyllic Swiss landscape would end looking like by 2040 if the projects went ahead.






An artist’s depiction of what the Linth region would look like by 2040 if proposed wind projects were approved. Sanity appears to have returned. Image: Linth Gegenwind.
Wind energy is losing its luster for many reasons, but among them is the obvious industrial blight to the landscape they cause.
Wind turbines in Bilten rejected
In the latest step to protect the landscape from industrialization, Swiss SRF public broadcasting here reported on November 6 that the up to 5 controversial wind turbines, which had been planned to be erected in the middle of a “densely residential area”, were rejected on the grounds they would lead to “landscape blighting”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The SRF quotes local Glarner government councilman Kaspar Becker:
We have come to the conclusion that it is not necessarily clever to pursue such things in densely populated areas.”
In response, wind energy opposition site Linth Gegenwind writes: “Common sense has prevailed!”
Honegg-Oberfeld wind park flat out rejected
Also recently the Swiss online appenzell24.ch has reported that the proposed Honegg-Oberfeld wind park was outright rejected.
On November 6, 2018, Appenzell24 wrote the local commission decided against the Honegg-Oberfeld district as a wind power location. Thus no wind farm can be built there.
On this, wind energy protest organization Linth Gegenwind writes at its website:
The reason is, above all, protection of the landscape. During the consultation process there were 60 in favor and 500 against the planned wind farm. Opponents also include Appenzell Ausserrhoden, St. Gallen, the state of Vorarlberg and the community presidents’ conference Ausserrhoden.”
According to the Appenzell24.ch, the 5 wind turbines with a hub height of 135 meters, would have resulted in “massive disadvantages for the landscape’s appearance”, according to opponents. 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWe’re seeing lots of headlines about heavy snowfalls and cold temperatures gripping Eastern and Southern Europe. Not surprisingly some activist scientists are blaming manmade global warming.

Expected snow depths by January 15. Chart: WXCharts.EU.
Junk theory: Global warming causing more snow extremes
Yet global warming logically isn’t supposed to be directly causing massive snow and bitter cold, and so there has to be some explanation for the unexpected cold and snowy weather. So to explain its all, a gaggle of activist scientists have concocted a theory that claims “unprecedented” Arctic sea ice loss over the past two decades has led to an increase in blocking over North America and Europe [e.g., Liu et al., 2012; Francis and Vavrus, 2012] and so is indirectly causing lots of snow and cold.
These desparate scientists then hope that the public and media will be gullible enough to buy into it.
Blocking is strongly tied to weather extremes in the midlatitudes (e.g., cold snaps, heat waves) and can persist for days to weeks [e.g., Black et al., 2004; Dole et al., 2011], so more blocking could mean more weather extremes as Arctic sea ice continues to decline (Note: Arctic sea ice in fact hasn’t declined in more than 10 years).
Analyses: no data to support the theory
However, a recent paper authored by Elisabeth A. Barnes, Department of Atmospheric Science, Colorado State University, says the data to support this just aren’t there.
The paper’s abstract:
Observed blocking trends are diagnosed to test the hypothesis that recent Arctic warming and sea ice loss has increased the likelihood of blocking over the Northern Hemisphere. To ensure robust results, we diagnose blocking using three unique blocking identification methods from the literature, each applied to four different reanalyses. No clear hemispheric increase in blocking is found for any blocking index, and while seasonal increases and decreases are found for specific isolated regions and time periods, there is no instance where all three methods agree on a robust trend. Blocking is shown to exhibit large interannual and decadal variability, highlighting the difficulty in separating any potentially forced response from natural variability.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The results of the analyses are summed up in the following charts of the paper’s Figure 3:

Time series of blocking frequencies for the three indices and four reanalyses for (a, c, and e) Asia in DJF and (b, d, and f) the North Atlantic in JJA. Trends significantly different from zero at 95% confidence are denoted by asterisks in the legend of each panel for Asia (1990–2012) and the North Atlantic (1980–2012). Filled circles (stars) denote the seasons following the 5 highest (lowest) years of September Arctic sea ice extent over the trend period. Blocking frequencies are averaged between 40° and 80°N for the 2‐D indices. Chart: Barnes et al (2014)
Not supported by observations
The findings reiterate those of Barnes [2013], The 2014 paper concludes that “the link between recent Arctic warming and increased Northern Hemisphere blocking is currently not supported by observations.”
Blocking events well within historical observed range
The paper adds:
While Arctic sea ice experienced unprecedented losses in recent years, blocking frequencies in these years do not appear exceptional, falling well within their historically observed range.”
In other words, the theory that global warming is causing more extremes due to melting Arctic sea ice is just plain crap. There’s no data to support it. It’s just a hypothesis – one that was rolled out in a desperate attempt to explain events that weren’t supposed to happen.
Correspondence to: Elisabeth A. Barnes:
eabarnes@atmos.colostate.edu
Search for more papers by this author
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNo one understands the causes of weather better than highly experienced meteorologists. And so when it comes to questions about extreme weather events, there is no one better to ask than prominent Swiss meteorologist Jörg Kachelmann (or Joe Bastardi in the US).
Yesterday at Twitter the veteran, high-profile Swiss meteorologist Kachelmann tweeted about an interview he had given with Austrian online magazine profil.at on the topic of extreme weather in Europe, and how the interview was withdrawn before publication.
Low-blow, dirty media
The main reason behind the withdrawal was Mr. Kachelmann taking issue with what he viewed as low-blow journalism by profil.at, who in the introduction needlessly brought up the phony rape charges lodged against Kachelmann 8 years ago by a scornful ex-girlfriend.
Though the former German flagship ARD television meteorologist was cleared of the charges and got through the legal ordeal, his reputation tragically did not survive the media feeding frenzy and gutter journalism.
To make a long story short, Kachelmann yesterday simply posted a draft of the unpublished profil.at interview at Twitter, before later taking it down.
But I managed to read it and so now report on its content.
Click-hungry sites hyping weather extremes 
In the interview, Profil.at questioned Kachelmann about the warmer European springs, weather extremes, serious scientists, and other issues.
On the subject of the recent warmer springs and more severe thunderstorm activity, Kachelmann responded that it has gotten warmer, but that the alleged higher frequency and intensity of extreme weather events has more to do with hype coming from places like Facebook and click-hungry Internet sites.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Not linked to climate change
Kachelmann added it’s normal for large weather patterns “to act up” and that it “has nothing to do with climate change”.
However he does attribute the warmer temperatures and higher humidity to climate change and that it is “statistically significant”, but then reminds that the statistics for weather extremes have yet to be shown as being significant.
“Completely senseless tweets from Greenpeace”
When asked about climate denialism and why people like Donald Trump get votes with climate change denialism, the Swiss meteorologist says: “There’s a lack of scientific knowledge on both sides.”
Next he cited examples from on social media:
Over the last weeks I’ve seen so many completely senseless tweets from Greenpeace and green politicians, who wish to blame without any doubt the daily weather on climate change, often with fake statistics, and so climate deniers are not alone. Serious scientists are working quietly between the embarrassing megaphones on both sides.”
Blame measurement instruments?
As an example of just how absurd the media can be, in the interview profil.at unwittingly displayed a remarkable ignorance of climate (which all-too often prevails among the climate-ambulance-chasing-media) in posing the question: “Are there reliable instruments today that would allow us to determine if a weather event can be attributed to climate change, or indeed to the weather pattern at hand?”
Blaming weather on climate change “idiocy”
Kachelman answers by telling profil.at that weather events unfortunately don’t come with a certificate of origin, and any claim that they do needs to be viewed as “unscientific idiocy”.
Share this...FacebookTwitter "
"Some wild west African chimpanzees are teetotallers, whereas others are frequent drinkers given the opportunity – consuming the equivalent of three pints of strong lager per day.  These findings have been reported in a scientific study that lends support to the drunken monkey hypothesis, which suggests humans and their primate relatives are attracted to the smell of alcohol because in our common evolutionary history this indicates the presence of energy rich, albeit fermenting fruits.  And this could help explain why people and some primates become addicted to alcohol. The latest study, published in the journal Royal Society Open Science, describes how a group of wild chimpanzees in Guinea occasionally found and raided the sites of palm alcohol production. Often drinking from breakfast until nightfall – although, interestingly, only on one occasion was an individual observed who had had a few too many. As I always tell my research group as we head off for a happy hour on Fridays – alcohol in appropriate doses increases creativity and of course helps us relax. It would appear that chimpanzees may also be regulating their intake. Most of us have experienced the consequences of not regulating our alcohol intake – and I like to illustrate this in lectures about social behaviour by citing a 1970s study which used pigs to study alcoholism in humans. Pigs housed in groups of seven were given access to lots of alcohol three times a day. However, unlike the chimpanzees, these pigs overindulged from day one.   Pigs have a fairly rigid pecking order, which of course is hard to maintain when everyone is drunk. In this experiment after a few days the pig that was third in the hierarchy sobered up and moved up to be the dominant individual in the group. The previously dominant pig, perceiving its loss of status, then also “dried out” and regained its place at the top of the food chain.  This situation cascaded down the social hierarchy, except for those at the bottom who appeared to sense they had nothing to lose from being inebriated. Thus – for species which need to maintain their social status and where politicking is important – being able to control one’s alcohol consumption is vital. Vervet monkeys living free on the Caribbean island of St Kitts have also developed a taste for alcohol and are infamous for stealing cocktails from tourists.  Studies have shown that if offered the choice between sugary water or sugary water with alcohol they choose the latter. And will drink enough to change their behaviour, but not necessarily enough to get drunk. A number of studies on the voluntary intake of alcohol in primates and rodents in laboratory settings have shown that manipulations such as separating individuals from their social group for significant periods of time can induce a significant increase in alcohol consumption. This pattern of drinking behaviour may become fixed for a previously stressed or anxious individual.  This explains to some degree why individuals may turn to alcohol – but not necessarily overindulgence.  If you overindulged regularly like the aforementioned pigs you would lose all your social standing. Furthermore, studies of addiction using a variety of highly addictive morphine-based drugs have shown that rats from an enriched environment (lots of space, stimuli and opportunities for social interactions) do not usually use freely available drugs to get “high”. But those moved to rat paradise from a stressful environment (solitary confinement in a small cage without stimuli) where they have become addicted to narcotics, usually give up their addiction.  One cannot help but feel there are important lessons to be learnt from such studies. The question then is, other than humans, which species if any regularly drinks to intoxication? As a child I remember watching videos of staggering elephants who had gotten drunk from eating fermenting marula fruits.  But apparently this documentary was a set-up.  Physiologists have calculated that for elephants to get drunk they would have to eat fermenting marula fruits at four times their natural consumption speed for a whole day: so while possible it is unlikely to be a common occurrence. The hardest drinker appears to be a species of Malaysian treeshrew that regularly drinks naturally occurring alcoholic nectar in doses that would intoxicate humans. But they don’t appear to get drunk, perhaps due to the long evolutionary association between these animals and alcohol. All this suggests that if the drunken monkey hypothesis is correct, humans and our ancestors were probably not regulars at nature’s bar. But as Berkeley primatologist Katherine Milton points out, it could just be that humans like the intoxicating effects of alcohol, especially because its use is often promoted culturally and drinking excessively is not frowned upon in all societies."
"
Share this...FacebookTwitterBy Kyoji Kimoto
kyoji@mirane.co.jp
1. Warmer period of the 1930s
In 1998 D. Dahl-Jensen et al. pointed out in the journal Science that the 1930s is 0.5°K warmer than the present time based on a bore-hole study of Greenland ice sheet.
The following data support D. Dahl-Jensen’s findings, from Soon 2012.

Also heat waves were far worse across the USA in the 1930s:

More heat waves in the 1930s.
The strongest hurricane was the Labor Day hurricane, which hit in 1935. Hurricane Irma and Harvey had much higher central pressure at landfall. (U.S .National Hurricane Center):

Strongest hurricane occurred in the 1930s.
2. Arctic temperature and sea ice extent
Parts of the Arctic were warmer in the 1930s:

Source: Real Climate Science.
Arctic sea ice levels were just as low in the 1930s as they are today:

Read more here.
3. NASA & NOAA altered the data
The climatic data above can be understood with solar activity change (aa Index) and ocean oscillation (Pacific Decadal Oscillation Index), see the 2 charts that follow.

(Archibald)
The Pacific Decadal Oscillation (PDO) index was also in its warm phase during the 1930s:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




PDO index was positive from1925 to1945. Data: Japan Meteorological Agency.
In summary, increasing solar activity with positive PDO index caused the warmer period of the 1930s. However, NASA and NOAA have made data tampering to stress recent warming.
Recent temperature data shows strong influence of ocean oscillation (El Nino) and no relation with CO2 increase as follows:

Source: Climate4you
4. MWP & LIA caused by changes in solar activity
Solar activity proxies show the MWP & the LIA in Japan and China as follows:

Chart above: Kitagawa, H. & Matsumoto, E., Geophysical Research Letters, Vol. 22, 2155-2158, 1995
 

Graphic above: Quansheng GE. et al., Advances in atmospheric sciences, Vol. 34, 941-951, 2017.
There are hundreds of other proxies worldwide that support solar activity as the main climate driver.
5. Sea level rise
Almost 25-years of meticulous data gathered by the Australian Bureau of Meteorology displays no discernible sea-level rise for Solomon Islands and Nauru. See the two graphs that follow:


Source: WUWT.
6. El Nino linked to solar activity
A publication by Njau (2006) showed El Nino starts at the year of sunspot minimum or maximum, thus showing that solar activity has a major impact on oceanic oscillations, which in turn powerfully impact weather and climate.
7. Extreme weather and solar activity
Bucha (1988) showed decreased solar activity causes meandering of jet stream which produces extreme weather in broad area. Since 2006 decreased solar activity has been causing heat waves, wildfires and heavy rainfall and snowfall all over the world.

Bucha (1988)
Share this...FacebookTwitter "
nan
"A heatwave has hit the UK, largely due to a flow of very warm air from southern Europe, and in particular the Iberian peninsula. Temperatures are expected to rise into the mid-30s Celsius. The media has picked up on the term “Spanish plume” to describe the current weather setup but it’s a phrase often misused. So what exactly is a “Spanish plume” and are we actually experiencing one? The origins of the term aren’t completely clear, although a 1968 paper on severe convective storms can probably claim the first usage. Regardless, by the 1980s the phrase “Spanish plume” was certainly in widespread use among UK weather forecasters, so the headlines over the past few days aren’t referring to anything new. As the Met Office pointed out last summer, a Spanish plume is a catchy name for a rather complex set of circumstances. It does indeed involve a flow of hot dry air from the Iberian peninsula across western France and into the UK.  But this in itself isn’t enough to constitute a Spanish plume in the full meteorological sense. To make a true Spanish plume, it’s crucial what happens to this hot dry air as it tracks northwards and how it interacts with air flowing from other directions. During the summer months, the air over Spain can become very hot if it is able to sit over the elevated plateau in the centre of the Iberian peninsula for several days. It will also be very dry as there isn’t a source of moisture near the surface. As an example, the air near Madrid at midnight on June 30 (Sunday night) had a relative humidity of only 24% (which is very dry) and a temperature of 38°C. Also important to note is that Madrid sits at about 600 metres above sea level. As this very hot dry air moves north on southerly winds it passes above the Bay of Biscay and western France where the air near the surface is still very warm but much moister; at midnight on June 30, it was 23°C in Bordeaux but relative humidity was 61%. The combination of these two air masses on top of each other, with warm and moist air near the surface and hot and dry air above, can be very unstable. In order to release this instability, the whole column of air, with the warm moist air near the surface and the hot dry air aloft, to be lifted in the vertical. Once this occurs then clouds, rain and potentially thunderstorms can form very rapidly. This can indeed happen as the air flows northwards, with the air being lifted not directly vertically but on a rather gentle upwards slope as it moves north and runs into the colder, denser air of northern France and the UK. This combination of circumstances can occur when there is a slow moving depression situated over the Atlantic to the west of the UK, with high pressure over central Europe. On some occasions this lifting can lead to the rapid development of intense thunderstorms over northwest Europe or the UK. A true Spanish plume occurs when all these circumstances conspire together to lead to intense storms. Such storms are being forecast – so it looks like the UK is indeed currently experiencing a true Spanish plume. These events are typically well-forecast several days ahead, as they evolve rather slowly, although it is usually more difficult to pinpoint exactly where any thunderstorms may actually occur. A Spanish plume will usually occur at least once a year over the summer period and sometimes much more frequently.  Some of the heaviest rain that has fallen in the UK, such as the 279mm that fell on Martinstown, Devon in July 1955 and for many years held the UK record for the most rain in one day, was caused by the Spanish plume scenario. However it’s important to realise that not every UK heatwave or summer thunderstorm is down to a Spanish plume."
"Carmakers could pull models from the UK, the automotive industry has warned, as Britain’s taste for polluting vehicles clashes with the difficulty of meeting post-Brexit carbon dioxide limits. Under new EU rules, average carbon dioxide emissions of almost all cars sold in 2020 and 2021 across the single market, including the UK, must fall below 95g a kilometre, with heavy fines for carmakers that miss individual targets designed to meet the goal. The heavier, fuel-inefficient SUVs favoured by Britons have been offset by the smaller, less polluting cars preferred in countries such as Italy. But after Brexit, when the UK plans to copy EU rules, this will no longer be the case, making a UK-only limit harder to hit. Mike Hawes, the chief executive of the Society of Motor Manufacturers and Traders (SMMT), the car industry lobby group, said: “[Carmakers] will have to look at their model mix … you’ve got to see whether that’s economic. The fines are going to be severe and all of them will do everything they can to avoid that. “It could be that you see a reduction in consumer choice through the removal of higher-emitting vehicles from not just the top end, but particular segments.” While having to pull models from sale would be a blow to the car industry, the rules could prove to be environmentally effective if they reduce sales of the most polluting models. Cars account for just over 18% of UK emissions, according to government figures, and action in the transport sector is considered crucial to cutting emissions to 51% of 1990 levels by 2025 and to reach net zero by 2050. Mel Evans, a climate campaigner for Greenpeace UK, said: “Carmakers are not obliged to aggressively market heavy, polluting cars. They know that we are in a climate emergency and yet keep accelerating towards the cliff edge, because bigger, dirtier cars have higher profit margins. And because they use more petrol and diesel, the oil companies cash in as well. “To address the climate crisis, manufacturers need to U-turn on petrol and diesel, stop spending millions drumming up demand for their dirtiest cars, and focus on electric vehicles for a post-oil world.”  The carbon dioxide emissions of cars sold to British consumers rose for the third year in a row in 2019, underlining the scale of the challenge for the industry as it tries to meet the new EU limits. However, the prospect of an imminent Brexit at the end of January will force carmakers to make choices before the end of 2020, when the implementation period is scheduled to end and the UK-only limits kick in. That could include choosing to sell electric cars in the EU rather than the UK if they judge Europe to be a more important market. Carmakers are rushing to bring to market new electric cars with zero exhaust  emissions – including Volkswagen’s ID.3, Vauxhall’s Corsa-e and an electric Fiat 500 – this year, but production will initially be limited as factories gear up. At the same time, they are keen to hang on to their profitable but polluting sales of internal combustion engines. Carmakers breaching their individual CO2 targets will pay fines of €95 (£83) for every gram they are over their limit, multiplied by the number of cars sold that year. Average UK emissions were 127.9g a kilometre in 2019, the SMMT said, 35% above the 95g target for 2020 and 2021. The UK is planning to adopt the EU fine structure after Brexit. Al Bedwell, an analyst at the car consultancy LMC Automotive, said he expected some higher-polluting models to be withdrawn from sale across both the EU and the UK in the next two years. However, he said major efforts to increase sales of battery electric vehicles (BEVs) might not work in the absence of consumer demand. “You can’t suddenly create a perfect environment to sell enough BEVs to make the problem go away,” he said. The Department for Transport said: “Our priority is to protect everyone from unsafe vehicles, including those that are damaging our environment, which is why we continue to work with industry to improve the emissions standards of all vehicles. “We have set out bold plans for driving down CO2 emissions and committed in our ‘Road to Zero’ strategy to pursue vehicle emissions regulation that is at least as ambitious as the current arrangements as we leave the EU.”"
"
Share this...FacebookTwitter[The most notable part of the documentary is the interview with Freeman Dyson, from 1:09:00 – 1:14:00]
In his new documentary “The Uncertainty has Settled“, Dutch filmmaker Marijn Poels focuses on climate science and politics and found that the issue is in fact as controversial and as UNSETTLED as any issue could possibly get.
The science climate change is far from settled and is in fact unsettled.

The production of the film took Poels to a variety of locations from Manhattan to the Austrian Alps.
The first part of the film depicts the plight of farmers in former East Germany (Saxony Anhalt), who are struggling to practice their livelihoods under the heavy burden of German agricultural regulation and market distortion that result from bureaucrats having decided that 0.01% of our atmosphere (man-emitted CO2) is a monumental problem.
That’s the narrative the media and leading politicians keep ramming. But a number of skeptics doubt it, and so Poels investigates if this doubt is just right wind politics or if there is something really behind it.
In the end he finds that the science is fully in dispute.
Belief we can stop climate change “enormously egocentric”
At the 38:00 Poels says that the [alarmist] Potsdam Institute refused to grant him an interview and so he set out for Hamburg to meet with climate scientist Hans von Storch, who is in the warmist camp.
Von Storch confirms that climate change is real, man-made and is a problem that needs to be dealt with seriously. But he adds that the claim that we can “rescue” the climate is “nonsense” and characterizes the claim the individual can play a role on controlling climate as “enormously egocentric”. Later in the film (1:04:45) von Storch says he doesn’t see climate change as a danger, but as “a challenge” that he is not afraid of.
CO2 as a climate driver “complete, delusional nonsense”
Next astrophysicist Piers Corbyn tells Poels that the amount of man-made Co2 in the atmosphere is like a “tiny blob of birdshit” and calls the claim that this is causing the climate to change “complete, delusional nonsense”. Corbyn also believes the globe will see continued cooling until about 2035. He calls the datasets showing warming “frauds”.
Freeman Dyson: 
Climate models “very dangerous game”…”they’re wrong”
Next Poels makes his way to Princeton where he meets with “living legend” Princeton physicist Freeman Dyson, one of the leading skeptic voices on man-made climate change.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Dyson has harsh, critical words for climate science and the models they rely on (1:10:30). He calls the science of climate modeling a “very dangerous game”, adding:
When you work with a computer model for years and years and years – always improving the model – in the end you end up believing it. […] It’s very difficult to remain objective.”
Models “wrong”…”disagree with observations”
On why we should not trust the models, Dyson says flat out: “Because they’re wrong. It’s very simple. They’re wrong.” Dyson says they “disagree with observations”. He then commented on modeling scientists:
Those people don’t look at observations. They are in a world of their own.”
“Scaring the public”
The 93-year old Princeton professor also notes that although the models are “very good tools for understanding climate”, they are a “very bad tool for predicting climate” and that these scientists “live by scaring the public”.
Climate theories are “very confused”
Dyson continues:
Unfortunately the thing has become so political it’s no longer science when you have strong political dogmas, as you say, on both sides.”
Overall Dyson advises that we need to believe the observations and pointed out that “the theories of climate are very confused.”
Herd, tribal mentality
He also told Poels a large sociological part of the problem is that climate scientists have in large part gotten caught in herd and tribal mentality.
It’s still more important to belong to the tribe than to it is to speak the truth.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAccording to a recent paper by Choujun Zhan et al, extreme precipitation events have declined over 90% of China.
Hat-tip: reader Mary Brown
Image right: Journal of Atmospheric and Solar-Terrestrial Physics
According to the paper’s abstract, a newly developed dataset containing daily precipitation in China at 0.5° intervals of longitude and latitude over the period 1961 to 2011 was statistically analyzed.
The authors found “the probability of rainy days has decreased over time for over 90% the surface area of China, and that the extreme precipitation and annual precipitation have decreased for most of the area in China.”
The results contradict the often made alarmist claim of more frequent and extreme weather events due to global warming.
Australia: “no trend in one day precipitation extremes”
In a recent paper titled “Variability and long-term change in Australian temperature and precipitation extremes“, the authors found that although in Australia minimum temperatures have increased, but maximum temperatures not so much, there was no trend in one day precipitation extremes.
The authors summarized in the paper’s abstract:

Daily precipitation extremes rarely exhibit long-term change over the century but are strongly modulated by the El Niño Southern Oscillation (ENSO). The relative importance of long-term change and climate variability therefore depends on the variable or index.
We conclude that in assessing the likelihood of climate hazards, one needs to consider the modulation of climate extremes due to both long-term change and climate variability. Our findings imply that when planning for adaptation, different emphasis needs to be given to changing temperature and precipitation extremes.”

Share this...FacebookTwitter "
"
Share this...FacebookTwitterLong-term data show that Germany’s summers have gotten wetter over the past three decades, thus contradicting widespread media claims to increasing droughts over Central Europe.
Retired German meteorologist Klaus-Eckart Puls presents an analysis of Germany’s hot and dry summer this year at The European Institute for Climate and Energy (EIKE).
This summer produced a number of blaring headlines which claimed the unusually warm and dry weather was an undeniable sign of things to come. Climate experts warn that summers in Germany will certainly get hotter and droughts will become increasingly common, along with episodes of heavy rainfall accompanied by destructive high water.
According Puls:
Climate alarmists and the compliant media have now predicted hot times and droughts – based a single summer – for the next 100 years and beyond [8]”
No trend towards droughts
However, the veteran meteorologist points out that weather services around the world and even the IPCC have yet to detect any real trends, especially for Central Europe, namely Germany:
Using data from the German DWD national weather service, a plot of summer precipitation in millimeters for Germany was and follows:
&amp;lt;img class=”alignnone size-medium wp-image-48871″ src=”https://www.eike-klima-energie.eu/wp-content/uploads/2018/09/Abb.RR_.KÄMPFE-640×384.png” alt=”” width=”640″ height=”384″ /&amp;gt;
Summer precipitation in Germany: June, July andAugust 1881-2018.
For the summer of 2018, it is estimated that Germany will see a mean precipitation of 128 mm, which will be slightly above the 124 mm record low seen way back in 1911. Summer precipitation has in fact been trending upwards over the past 30 years.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The above chart shows that there has been no trend in precipitation for Germany since systematic measurements began in 1881.
Early summer a bit wetter
And when analyzing the data for the period known as early summer (May, June , July), then we see that there has been a slight long term increase in precipitation for Germany since 1881:
&amp;lt;img class=”alignnone size-medium wp-image-48872″ src=”https://www.eike-klima-energie.eu/wp-content/uploads/2018/09/Abb.RR_.Puls_-640×452.jpg” alt=”” width=”640″ height=”452″ srcset=”https://www.eike-klima-energie.eu/wp-content/uploads/2018/09/Abb.RR_.Puls_-640×452.jpg 640w, https://www.eike-klima-energie.eu/wp-content/uploads/2018/09/Abb.RR_.Puls_-768×543.jpg 768w, https://www.eike-klima-energie.eu/wp-content/uploads/2018/09/Abb.RR_.Puls_-1024×724.jpg 1024w” sizes=”(max-width: 640px) 100vw, 640px” /&amp;gt;
May-June-July precipitation in Germany. Chart by Klaus-Eckart Puls.
Klaus-Eckart Puls also cites the IPCC concerning global trends for drought: no trend [10]. According to the the IPCC:
There is low confidence in a global-scale observed trend in drought or dryness“.
This summer Germany’s extreme drought intensity was more regional than national. Southern Germany for example, saw less extreme drought conditions, according to the data from the DWD.
To the south in Austria, the summer was also dry, but was only came in the Top 20 driest, according to the Austrian ZAMG national weather service.
In the Austria-wide evaluation (up to August 29, 2018) there was 20 to 25 percent less precipitation than the long-term average. This puts the result among the 20 driest summers in the since measurements began. […] At the top is undisputedly the summer of 1873 with 32 percent less precipitation than average.”
 
Share this...FacebookTwitter "
"A coalition of Scottish conservation groups has called for legally enforceable culls of deer to be imposed on private landowners and stalking estates, while raising the prospect of local communities becoming more involved in shooting and killing deer for food. The report, published by Scottish Environment Link (SEL), which includes the John Muir Trust, the National Trust for Scotland, RSPB Scotland and the Scottish Wildlife Trust, argues that a dramatic reduction in the country’s wild deer population is needed to tackle accelerating climate and biodiversity crises.  The report says deer can cause significant damage to emerging woodlands through grazing, and that they trample fragile peatlands, which are key to carbon absorption. Scotland’s deer population produces 5,500 tonnes of methane each year, the equivalent of 137,500 tonnes of CO2. The report also argues that more active culling could reduce accidents on rural roads. With no existing natural predators, the red deer population reached a peak of 400,000 in 2010. Deer management groups, often on sporting estates, kill certain numbers, but SEL wants the Scottish government to set and enforce higher targets.  Higher cull targets could involve other people in the deer management, they say. Noting that “for centuries, red deer stalking in Scotland has relied on paying clients and guests of private landowners, supplemented by professional stalkers”, the report suggests that in other parts of Europe communities are more involved in deer control. “In Norway, for example, over half a million people – almost 10% of the population – are registered hunters. Hunting on state land is considered a communal source of sustainable food, and local people have priority use. Game meat is an important part of Norwegian food culture, rather than a byproduct of trophy hunting, as is often the case here.” SEL argues that a similar culture could be encouraged in Scotland, moving away from the kind of management that focuses on “wealthy clients seeking a pair of antlers”, which necessitates a much higher deer population and resultant environmental damage. The report was published before the release of findings by the independent deer working group, set up by the Scottish government in 2017 to consider changes for management of the species. Mike Daniels, head of land management at the John Muir Trust, said: “We believe there is a growing appetite for change in how Scotland’s uplands are managed into the 2020s and beyond, and delivering sustainable deer management is a critical component.”"
"The new record represents the most stark demonstration that global heating is unequivocally real and driving the climate crisis. With emissions still rising every year, more heat is being trapped by greenhouse gases, and the ocean data is crystal clear: an unrelenting and accelerating rise for at least the past half century. Lijing Cheng, at the Chinese Academy of Sciences, said: “There are no reasonable alternatives aside from the human emissions of heat-trapping gases to explain this.” We live on the surface of the Earth, and so air temperature is the most common heat measurement. But two-thirds of the planet’s area is ocean and water can absorb far more heat than air. As a result, just 4% of the heat trapped by greenhouse gases warms the air and land. So to really see what is happening with global heating, you need to look at the oceans. Here, the signal is unmistakable, with every year in the past decade recording hotter oceans that the year before, bar one. In contrast, air temperature is more affected by the natural variation that overlies human-caused global heating. The hottest year for air temperature to date is 2016, thanks to an El Niño event, though 2019 may slot in at number two when the final data is available. The oceans and atmosphere are inextricably linked. Changing ocean heat means changing rains, and that means more floods in some places and more droughts and wildfires in others. Furthermore, hotter oceans mean more sea level rise, threatening cities from Shanghai to Miami and Rio de Janeiro to Alexandria. Hotter oceans also supercharge storms, with Kevin Trenberth at the US National Center for Atmospheric Research noting that a hotspot in the Gulf of Mexico in 2017 spawned Hurricane Harvey. That led to 82 deaths and caused about $108bn in damage. In 2018, a hotspot in the Atlantic Ocean near the Carolinas led to Hurricane Florence. Many coral reefs are already suffering from bleaching. But the increasing number of ocean heatwaves are affecting all life. For example, the hot “blob” seen in the North Pacific from 2013 to 2015 caused a major loss of marine life, from plankton and fish – including 100 million cod – to marine mammals such as whales. No, but it might lead to some. Climate tipping points are reached when particular impacts of global heating become unstoppable, such as the runaway loss of ice sheets or forests, or the release of the potent greenhouse gas methane from melting tundra. Some scientists think the world may already have crossed a series of tipping points. If so, the buildup of heat graphically demonstrated in the oceans shows why. Yes. The way to end global heating and tackle the climate emergency is to stop emitting greenhouse gases. Most importantly that means a rapid end to fossil fuel burning, plus the protection and regeneration of forests and cutting down emissions from farming, in particular from cattle. There is no time to lose."
"The leader of Germany’s Friday for Future climate protests has said she turned down a seat on the board of Siemens’ new energy business amid growing anger over its role in a controversial coalmining project in Australia as she feared she would lose the right to criticise the company. Luisa Neubauer, 23, the German face of the campaign group inspired by Swedish activist Greta Thunberg, who has campaigned alongside her, said on Monday the position would jeopardise her independence if she had taken up the offer from its chief executive, Joe Kaeser, made at a meeting in Berlin on Friday.  The two met as protests by Fridays for Future and Extinction Rebellion were held in 40 cities across Germany, including outside Siemens’ Munich headquarters, against a central Queensland coalmine that will open up one of the world’s biggest untouched coal basins. Neubauer had hoped to persuade Kaeser to withdraw from the project, for which Siemens has won an €18m contract to provide the rail infrastructure. At the meeting in Berlin, Neubauer was offered a position by Kaeser in either the supervisory board or leadership council of Siemens Energy, a spin-off business which hopes to head a new generation of energy-efficient technology. It is due to split from the main company in the spring and to go public in September on Germany’s Dax index. She said on Monday she had turned down the offer. “If I were to take it up, I would be obliged to represent the company’s interests and could never be an independent critic of Siemens,” she explained. “That is not compatible with my role as [a] climate activist.” The Carmichael mine was approved by the Austalian government in June and will be run by the Indian company Adani. It has become a cause for climate protesters who disapprove of a project which will contribute to global heating – especially at a time when large parts of Australia are already being wracked by bushfires blamed on the climate crisis. Kaeser, who has made much of the company’s pledge to become carbon neutral by 2030, last month tweeted his recognition of the activists’ complaints about the mine, promising he would “diligently look into the matter” and “get back” to the protesters. He pointed out a decision would “not be easy” due to the various interest groups involved, including shareholders, customers and the public. But on Sunday, following an extraordinary meeting of Siemens management, Kaeser announced the company was to go ahead with the project as it was legally obliged to remain committed to it, adding that at the same time it would become increasingly watchful of environmental concerns. “We have evaluated all the options and have concluded that we must fulfil our contractual obligations,” he tweeted. He promised the company would improve its future management of “protecting the environment” by establishing what he called “an effective Sustainability Board”. Activists say the coalmine project will produce an annual 27.5m  tonnes of coal and will contribute to global heating. They also point to the vast amounts of water it will require, as well as destruction of habitat and the need to transport the coal via the Great Barrier Reef, the largest coral reef in the world. The Australian Conservation Foundation called the decision “disastrous”, and pledged to continue its protests against the mine. It added: “With this decision, the company is showing its true face ... its climate change strategies have been revealed to be meaningless and hollow.” Neubauer has referred to the Siemens’ project as an “inexcusable mistake”. She told the news agency DPA: “We asked Kaeser to do everything possible to stop the Adani mine. Instead he will now profit from this disastrous project. “This is so last century, and Joe Kaeser is making an unforgivable mistake,” she added, emphasising that Siemens’ decision threatened climate goals to reduce the rise in global warming by two degrees."
"For most people in the developed world, getting access to clean drinking water is as simple as turning on a tap. Would that paying for water were so simple. But when we think about the water we consume, few of us realise that as much as 80% of its cost is associated with electricity use – a figure that’s as high in Britain as in drought-prone California. It is surprising, then, that the energy argument rarely features in discussions about preserving water. Yes, water is itself a valuable and vulnerable resource. But when we wash our clothes, have a shower or simply rinse a mug, we should also keep in mind that energy is going down the drain. Let’s talk about our water future alongside our energy future. In a recent report by the Consumer Council for Water, more than 60% of the 100,000 complaints received by water companies in the UK in 2014/15 were related to bills and charges. But how many people appreciate that the steady increase in the cost of water is because of rising electricity costs? Water companies in the UK should take pride in their recent achievements. They have undertaken significant infrastructural upgrades, improved efficiencies in the treatment of water and waste water and have bolstered their renewable energy portfolios.  This increase in renewable energy contributions has been driven by water companies’ commitment to reducing their greenhouse gas footprint by 80%, encouraging them to get more of their power from alternative sources.  Indeed, renewable technologies have the potential to provide enough homegrown power to make the sector self-sufficient. Scottish Water is leading the way in this, but it will still be a few years before savings can be passed on to consumers. Even then, can we guarantee that domestic users will ever benefit fully? The prevailing attitude in the UK is that our fickle climate is far too wet for water shortages, but the truth is that we are running low on water where it is most needed. Our cities are growing as more and more people move from rural areas, but the rain doesn’t necessarily follow them. Our water networks, therefore, are under more pressure than ever to move water around the country to where demand is highest. In some cases, the pressure can be too much and this can cause leaks. Fortunately, we have valves that can release the excess pressure safely. But pressure lost is also more energy wasted. For water companies, investing in micro-hydropower for energy recovery  and increasing network efficiency are two of the ways forward. These opportunities can generate enough electricity to light thousands of homes, while at the same time keeping our water under a controlled pressure. But we can also improve our ability to harvest rainwater and re-use greywater, which could meet a substantial proportion of Britain’s water needs and up to 94% of the demand in Ireland. This would make countries far less dependent on their tapped supply. Water companies and organisations such as Waterwise are already educating UK domestic consumers about why and how to make water savings. Together, they can make a big difference. When we discuss the future of the water sector, my colleague often quotes the Japanese saying “pursuing the last grain of rice in the lunchbox” – essentially to aim for perfection, and not to miss any of the little opportunities along the way.  It is a lesson that should be applied to our water supply, an area where “very good” shouldn’t be good enough. It is tempting for water companies to chase the big, easy solutions, but they also need to focus on the micro opportunities. Only then, can they get close to perfection, and save us all a great deal in water – and energy – costs."
"Atop Mount Lico in northern Mozambique is a site that few have had the pleasure of seeing – a hidden rainforest, protected by a steep circle of rock. Though the mountain was known to locals, the forest itself remained a secret until six years ago, when Julian Bayliss spotted it on satellite imagery. It wasn’t until last year, however, that he revealed his discovery, at the Oxford Nature Festival. We recently visited the 700 metre-high mountaintop rainforest in an expedition organised by Bayliss, in collaboration with Mozambique’s Natural History Museum and National Herbarium. As far as anyone knew (including the locals), we would be the first people to set foot there (spoiler: we weren’t). Since the rainforest’s discovery, Lico has received worldwide attention. That it captured the public’s imagination speaks volumes about how rare such places are. Humans are nothing if not adventurous, pushing our range boundaries like no other species can. But when almost every corner of the planet now shows signs of human activity, how do conservation scientists justify visiting and publicising these last bastions of untrodden nature?  From our perspective, the answer depends on what expeditions like this can teach us about the natural world, our place in it, and how to shepherd the wildest of places through the Anthropocene. Standing back and crossing our collective fingers is not always a winning strategy. This expedition formed part of a long-standing research programme into these mountains, that aims to provide evidence to legally protect Mozambique’s mountain forests. Currently none of northern Mozambique’s mountains are formally protected, either nationally or internationally. Finding new species is one way to highlight the importance of such sites and justify their protection. As well as exploring Mount Lico, the expedition was the first to undertake a biological survey of nearby Mount Socone. Every bit as majestic and species rich as the iconic Lico, Socone highlights the threat faced by many forests in Mozambique, Africa and elsewhere. Globally, one football pitch worth of forest is lost every second, driving countless species to extinction. The removal of trees from mountain slopes also leads to soil erosion, flooding in the wet season and water shortages in the dry season. On our first day on Socone, we set out to locate the middle of the forest using a satellite image and GPS. However, the difference between what this image was telling us and what we could see was vast. As we walked towards what the image showed as the heart of lush rainforest, we could see the warm glow of the African sun. Soon enough, we emerged from beneath the canopy and into newly established farmland. Without the protective cover of the forest, heavy rains will pound these exposed mountain soils, fresh cuts will need to be made, and so the cycle repeats. Media attention on neighbouring Lico, and the new species descriptions coming out of both sites, help to bring these conservation and livelihood issues to the world’s attention. Our brief footsteps on Lico will soon be overgrown, and the plants and animals that live there will continue to be protected by the same towering cliffs (more than 125 metres high) that have saved them up to now (without the help of world-class climbers, our expedition would not have been possible). But the impact of people goes far beyond where we have actually managed to set foot. Since the industrial revolution, humans have increased the amount of carbon dioxide in the atmosphere to levels higher than at any time in the past 400,000 years, increasing temperatures and changing weather patterns. Despite being situated on a fortress of rock, Lico’s forest is vulnerable to climate change, like every other ecosystem on the planet. The contrast between protection from direct human activities but exposure to climate change means that Lico has a lot to teach us. Most forests experience both of these processes simultaneously, and so it is difficult to unravel their relative and interacting impacts. Through the data collected on Lico, Socone and other forests worldwide, we gain a greater understanding of how human disturbance affects the ability of forests to respond to environmental change. Lico is a rare data point on this map: millennia of climate change and ecological response, played out in the absence of direct human disturbance. Reconstructing this history meant digging a two metre-deep pit in the forest, so that we could sample the layers of soil in the order that they accumulated. We tried to minimise any lasting effects on the forest (the hole was filled and topsoil replaced) but nonetheless, reasonable objections can be made against our disturbing this previously pristine site. What we gained were a series of time capsules: each little tin of soil contains information on the plants that grew, the fires that burned and the water that flowed, data that will be shared in open access repositories, allowing people worldwide to investigate this unique site without the need for further disturbance. What we learn from Lico will help the world understand how forests might be affected by future changes in climate. So were we really the first humans on Lico? Well, not quite. To everyone’s surprise, we found ancient pots, ceremonially placed near the source of a stream that flows to a waterfall down the side of the cliff. Were these placed there during a time of drought, as the waterfall ran dry and the crops failed?  Archaeologists and climate scientists are investigating. Given the pots pre-date local knowledge, the incredible inaccessibility and lack of any other signs of human activity, Lico’s forest remains one of the least disturbed on the planet. One thing’s for sure though – humans really do get everywhere."
"
Share this...FacebookTwitter“A number of biases internal and external to the scientific community contribute to perpetuating the perception of ocean calamities in the absence of robust evidence.”  – Duarte et al., 2015

Image Source: Larcombe and Ridd, 2018
Within a matter of days after the press release for a newly published Nature paper spewed the usual it’s-worse-than-we-thought headlines throughout the alarmosphere (Washington Post, BBC, New York Times), the paper’s results were assessed to have “major problems” by an author of multiple CO2 climate sensitivity papers (Lewis and Curry, 2015, 2018).
A glaring miscalculation was quickly spotted that changed not only the results, but consequently undermined the conclusion that estimates of climate sensitivity to doubled CO2 may be too low.
And yet the paper was able to pass through peer review anyway.
Dr. Michael Mann’s error-riddled 2016 paper
A few years ago Dr. Michael Mann was the lead author of an embarrassingly non-scientific paper fraught with glaring methodological and statistical errors.
A post-publication reviewer (statistician Dr. William Briggs) wrote in his point-by-point critique of the paper that “Mann’s errors are in no way unique or rare; indeed, they are banal and ubiquitous.”
Despite the glaring errors, the paper made it through peer-review and was published in Nature‘s Scientific Reports journal anyway.
“Hoax” papers can get published in 70% of peer-reviewed journals
Analyses indicate that “fake peer review” often goes undetected, and as many as 7 of 10 peer-reviewed journals are apt to publish a deliberately-written “hoax” paper.
“Any reviewer with more than a high-school knowledge of chemistry and the ability to understand a basic data plot should have spotted the paper’s shortcomings immediately. Its experiments are so hopelessly flawed that the results are meaningless. … The hoax paper was accepted by a whopping 157 of the journals and rejected by only 98. Of the 106 journals that did conduct peer review, 70% accepted the paper…”  (Murphy, 2017  The Failure of Peer Review)
A new paper cites analyses that find half of peer-reviewed science results are flawed, not replicable


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Earlier this year, a review paper (Larcombe and Ridd, 2018) published in the journal Marine Pollution Bulletin delivered a stinging rebuke to the modern version of science’s disturbing lack of replicability and verifiability.

Image Source: Larcombe and Ridd, 2018
The authors go on to detail a large volume of examples when peer-review failed to detect errors in Great Barrier Reef (GBR) coral research.
Confirmation bias appears to permeate the peer-reviewed literature, slanted in the direction of finding evidence for catastrophic decline in coral health.  This isn’t the first time that marine research has been called out for overselling calamity (see Cressey, 2015, “Ocean ‘calamities’ oversold, say researchers – Team calls for more scepticism in marine research.”) and falling “into a mode of groupthink that can damage the credibility of the ocean sciences”.
As just a single example among the many provided, Larcombe and Ridd reviewed the De’ath et al. (2009) study in which an “unprecedented” decline in GBR corals was alleged to have occurred between 1990-2005.
After a reanalysis of the measurements and methods used, Larcombe and Ridd used corrected data to show there has actually been “a small increase in the growth rate” of corals since the early 1900s (see below image) instead of the dramatic decline after the 1990s documented in the peer-reviewed paper.
These errors slipped past the reviewers’ notice too.   The publication of flawed results has seemingly become so common that it’s no longer even surprising.
“This paper [De’ath et al. (2009): Declining coral calcification on the Great Barrier Reef.] studied 328 corals on the GBR, and indicated a 14% reduction in growth rates between 1990 and 2005. It stated that the corals of the GBR are declining “at a rate unprecedented in coral records reaching back 400 years”. Subsequent reanalysis of the data indicated that the apparent recent reduction in growth rate was caused by a) problems with the physical measurements of calcification, which systematically biased recent growth bands to give lower growth rates (D’Olivio et al., 2013; Ridd et al., 2013), and b) an unjustified assumption that coral growth rate does not change with the age of the coral (Ridd et al., 2013). With these taken into account, the dramatic fall in growth rate after 1990 is no longer evident, and a small increase in growth rates since the early 1900’s appears (Fig. 6). Further, D’Olivio et al. (2013), working on a different set of GBR corals, showed an increase in coral calcification rates on middle and outer shelf reefs, which together represent 99% of GBR corals, of 10% for the period ~1950 to ~2005, but a decrease of 5% per decade between 1930 and 2008 on inner-shelf reefs, which represent only 1% of GBR corals. Therefore, it would be hard to glean from these datasets that there is a documented decline in coral ‘growth’ parameters, and even harder to attribute change to a particular cause.”

Image Source: Larcombe and Ridd, 2018
Share this...FacebookTwitter "
"The city of Plymouth, on England’s south coast, normally has fairly moderate tides. However this week it will have a 6m “supertide” – the highest tide in 18 years. This comes just days after the celebrated “supermoon”. In fact, many locations along the UK, US and Australian coasts will experience their highest tides for tens of years around September 29 or 30. Coastal roads in Miami, for instance, have already been closed in anticipation of exceptional tides. These high tides may bring water levels uncomfortably close to the tops of harbour walks and flood defences, emphasising the threat of rising sea levels. In the UK they are unlikely to be a major problem on their own unless they coincide with storms (a strong storm surge has a greater impact than even the most exotic of tides). However in other areas, like in parts of America and the Pacific, no storms are necessary: these high tides on their own can lead to nuisance flooding. Tides are controlled by changes in the position and alignment of the moon and sun relative to Earth. Every fortnight – at new moon or full moon – the Earth, sun and moon are in an approximately straight line as seen from space and the additional gravitational pull of the sun causes stronger tides, known as spring tides. Yet each month one set of spring tides is higher than the other. This is because tidal forces are strengthened when the moon is at “perigee” and its elliptical orbit takes it closest to Earth. Tide-generating forces are also enhanced when the moon is directly overhead at the equator, part of a cycle lasting 27.2 days – a so-called “draconic month”. Tides can differ over the course of a year, as the Earth moves from its closest (perihelion) to furthest (aphelion) point from the sun and back. More important is the variation in the sun’s position north or south of the equator, which causes the seasons. The tide-generating forces are greatest at the equinoxes in March and September when the sun is directly overhead at the equator. Spring tides are always higher at these times of year.  Over periods longer than a year, very large spring tides occur when all the astronomical factors we have mentioned earlier coincide.  Two longer-term motions of the moon’s orbit around the Earth are important. These motions (astronomers call them precessions) are the reason we are seeing unusually large spring tides this year.  The first precession is known as the cycle of lunar perigee, and influences tides about every four to five years. The elliptical orbit of the moon around the Earth slowly moves in relation to the sun, completing a full circuit every 8.8 years. This means at either the March or September equinox approximately every 4.5 years the moon is both at its closest point to the Earth, and is also overhead at the equator. The second precession is known as the lunar nodal cycle and is due to a very slow change in the moon’s orbit. Imagine the Earth’s orbit around the sun took place on an enormous sheet of glass – what astronomers call the ecliptic plane. The moon’s orbit cuts this surface at an angle of approximately 5 degrees. Over 18.6 years the moon’s orbit slowly rotates around so it cuts through the ecliptic plane in a different place.  One effect of this is to change how far above or below the equator the moon can reach in its orbit. In 2015 the moon is at the point where it deviates the least from the equator. This slightly increases the chances of the moon being directly overhead at the equator at any given point, and thus coinciding with the other factors that contribute to extreme tidal forces. A lot of things have to fall in place at once to generate record-breaking tides and this year the cycle of lunar perigee and the lunar nodal cycle nearly perfectly coincide, resulting in some of the highest spring tides for decades.  The authors help run the SurgeWatch website and would welcome any photos of high tides during this period."
"Rising temperatures caused by global heating are likely to increase deaths from road crashes, violence, suicides and drowning, according to new research, and will affect young people most. Deaths from injuries have long been known to be seasonal and the new analysis uses data on nearly 6m deaths in the US to calculate the impacts of a 2C rise in temperature, the main target set by the world’s nations. The scientists calculated that this increase would result in about 2,100 more fatal injuries every year in the US alone. People tend to go outside more and drink more alcohol on hotter days, while higher temperatures are known to increase rates of violence and suicide. The analysis did show a small reduction in the number of deaths related to falls among elderly people, probably because there is less ice in winter. Previous research on the impact of the climate emergency on health has focused on chronic diseases such as heart failure and infectious diseases including malaria. But deaths from injuries currently make up about 10% of all fatalities around the world and the impact of global heating on this had been little studied until now. The scientists say young people play vital roles in supporting societies and economies and that measures to tackle deaths from injury must be a public health priority. “Our results show how much climate change can affect young people,” said Prof Majid Ezzati of Imperial College London. “We need to respond to this threat with better preparedness in terms of emergency services, social support and health warnings.” Injury deaths were expected to increase in all nations as temperatures rose, he said, although local factors would influence the extent of the increase – for example, the standard of road safety or level of gun control. The world is currently on track for a 3-4C temperature rise, suggesting the increase in injury deaths could be even higher. The research, published in the journal Nature Medicine, is based on data on recorded deaths from injuries in every county in the mainland US between 1980 to 2017. It also used temperature data to find the months when the average temperature was 2C higher than usual. This enabled the researchers to account for the fact that people adapt to normal local conditions but are affected by unusual temperatures. Comparing the data allowed the scientists to estimate the annual increase in deaths that would result from a 2C rise. Men are already much more likely than women to die from injuries and the researchers found that 84% of the additional deaths were among men. The most affected age group was 15-34. Road crashes accounted for 42% of the extra deaths and suicide 30%. Deaths from violence and from drowning both made up about 14% of the total. Drownings increase in hot weather as more people swim. “There is a long history of work that shows injuries are fundamentally seasonal,” said Ezzati. “Some of this is obvious – people drown more in summer. We also know that warmth influences both our physiology and our behaviour.” The reasons deaths from suicide and violent assault increase in hot weather are not fully understood. But the researchers said it was possible that people spending more time outdoors had a higher risk of confrontations. People also tend to be more agitated in hot weather, and may drink more alcohol, which could lead to more assaults. Previous research indicates that high temperatures are associated with higher levels of mental distress, especially in young people. Injuries already kill more that 5 million people a year, more than HIV/Aids, tuberculosis and malaria combined, and such deaths are rising. Policies to tackle the climate emergency should include measures to combat deaths from injuries, said Shanthi Ameratunga and Alistair Woodward of the University of Auckland, New Zealand, in an accompanying commentary on the research. “The need to address this major public health problem is particularly urgent in low- and middle-income countries that experience over 80% of the global injury burden and are generally more vulnerable to the effects of extreme weather,” they said. “The public health community tend to forget that injury deaths are actually a pretty big factor [in overall mortality],” said Ezzati. “The emphasis on young people is an important aspect of the story, as they are educationally and economically active.”"
"
Share this...FacebookTwitterUsing data from the Danish Meteorological Institute (DMI), Japanese skeptic blogger Kirye just tweeted how Arctic sea ice volume has surged to the 3rd highest level in 16 years.

Data source. Danish Meteorological Institute. Chart source: Kirye.
Today, there’s not a climate ambulance chaser to be found in the Arctic. Some ten years ago, a number of leading experts predicted the summertime Arctic would be ice free by now. Boy, did they goof!
Here’s a chart by Kirye showing a year-by-year plot:

Source: Kirye.
Note that over the past decade the trend has been steady, even somewhat upward.
Once reason Arctic ice is expanding is likely in part due to the cold Atlantic, especially the North Atlantic.

AMM second lowest since 1948
Hurricane expert Philip Klotzbach at Twitter presents a chart showing the standardized AMM for the past July: it shows this year to be rather astonishing:

AMM Index 2nd lowest since 1948. Chart: Philip Klotzbach.
Klotzbach writes:
This July’s Atlantic Meridional Mode (AMM) index value was the 2nd lowest July value on record (since 1948), trailing only 1972. A negative AMM tends to be associated with colder tropical N Atlantic SSTs, higher sea level pressures and less active Atlantic #hurricane seasons.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Record low relative tropical Atlantic sea surface temperatures
Moreover, days ago Klotzbach also presented another chart depicting July, 2018, relative sea surface temperatures for the Tropical Atlantic (10°N – 25°N):

Chart: Philip Klotzbach.
As the chart shows, in July they reached a record low since measurements began in 1948. In fact there’s never been such a steep drop over an 8-year period.
The cold temperatures will serve to significantly dampen hurricane activity this year, Klotzbach points out.
Michael Mann hyperventilating, expert hints
Lately there’s also been quite a bit of (hysterical, climate-ambulance chasing) talk about the regional heat waves and “extreme” weather that have hit parts of the northern hemisphere. Obviously they’ve been ignoring the huge cold developments at places they used to like focusing on.
At PBS activist/alarmist scientist Michael Mann attributes it to manmade climate change. However, expert meteorologist Dr. Ryan Maue differs, tweeting here that the factor behind it all hasn’t been behaving unusual at all:
Interesting, climate scientist Michael Mann attributes the last month of extreme weather to a “slow”, “more wild” and “undulating” jet stream. But that’s typical of “summer” in Northern Hemisphere regardless of climate change.
Maue explains:
Typically this jet stream theory is related to Arctic changes e.g. sea ice depletion. Mixed answers from empirical & modeling studies. This direct causal link from climate change to the actual behavior of jet stream in a given month seems beyond our attribution capabilities.”
And:
However, this thinking is consistent w/null hypothesis that climate change impacts [affects, causes, intensifies] all extreme weather events [always]. These jet stream “slow downs” or blocking events are actually poorly understood features of the climate system.”
 
Share this...FacebookTwitter "
"Humans are generally getting better at dealing with their mess. In the UK, for instance, 45% of household waste is now recycled – yet that still means more than 12m tonnes are buried in the ground every year.  Burying that rubbish isn’t cheap, and neither is keeping it in the ground once there. Old landfill sites are covered with grass and turned into innocuous-looking hills filled with waste, and even they have to be monitored to make sure they aren’t contaminating the local environment. For instance, as material decomposes, greenhouse gases such as methane are given off. If there is not enough methane to make it economically viable to capture (and there usually isn’t) it often needs to be burned off to convert it to CO₂, a less potent greenhouse gas. There are also concerns that thousands of older sites, often built on flood plains or near the seashore, may be at risk from flooding or coastal erosion.  So what should be done about these old landfill sites? One answer may be to dig them up again. Old landfills do have valuable waste, the most obvious being processed metals, glass and electronics. Indeed, junk electronic goods such as old TVs or computers typically have higher concentrations of gold and rare earth elements per tonne than are found naturally in ore. A 2014 United Nations University report stated that each year more than 300 tonnes of processed gold are dumped in landfills – that’s 10% of the total amount mined worldwide. Belgium, for example, is already mining its old landfills, by extracting waste and filtering for metals and recyclable material. Digging up old landfills could well have a much lower environmental impact than mining in fresh rocks. For example, toxic chemicals like mercury and cyanide are used to find and isolate gold in regular mines. Recovery of materials from landfill could offer a much cleaner solution to feed our need for smart technology, energy storage and electric vehicles.   To demonstrate what all this would involve in practice, we took part in a BBC Four documentary that chronicled the history of rubbish and explored what we have thrown away and how this has changed over time.  Part of this work looked at a municipal landfill in England’s Midlands that closed in the 1980s - it’s now a big grassy knoll - we can tell its age when we dug into it and found dated newspapers. The site has a methane flare burning 24 hours a day which requires periodic maintenance, and the local council will have to keep monitoring things for the foreseeable future.   To locate potentially recoverable and valuable metals, we surveyed a section of the landfill using near-surface geophysics, looking for “hot spots” of high conductivity/magnetism which will be where concentrations of discarded metal will be buried. Once we had found where to look we dug down five metres. We found large amounts of processed metals, recyclable glass, discarded household artefacts, yellow pages, much of which we recycle now, as well as black plastic bin bags.  Interestingly we only found a few electronic items. This is in contrast to today’s landfills, which are full of mobile phones and gadgets and largely avoidable e-waste. Clearly existing old landfills could be, quite literally, untapped gold mines. With growing demand, coupled with scarcity of materials, including rare earth elements, these may be a valuable future national resource for much more than just metal. Waste companies have even recently suggested designing new landfills to capture energy from them and to deal with problematic waste streams such as plastics that can’t be recycled. For instance, heat from decomposing rubbish or burning waste could be trapped and turned into geothermal power, providing a “rubbish solution” to our energy problems too."
"BlackRock, the world’s largest investor, has joined an influential pressure group calling for the biggest polluters to reduce their emissions, after criticisms that it was undermining action addressing the climate crisis. The US investment firm has signed up to Climate Action 100+, a group of investors managing assets worth more than $35tn (£27tn), that pressures fossil fuel producers and other companies responsible for two-thirds of annual global industrial emissions to show how they will reduce carbon dioxide pollution. In February 2019, one Climate Action 100+ resolution put to shareholders of BP forced the British oil supermajor to describe how its strategy is consistent with the Paris climate accord. BlackRock, which manages assets worth $6.9tn including major oil producers such as BP, Shell and Exxon Mobil, has faced a mounting backlash for actions that activists said were preventing oil companies from being held to account. BlackRock has directly voted against multiple shareholder resolutions brought by Climate Action 100+. BlackRock chief executive Larry Fink’s annual letter to investors, expected ahead of the World Economic Forum in Davos on 21 January, has previously called on companies to take more action on the climate crisis. BlackRock has faced protests from environmental campaigners, who have accused the company of hypocrisy for routinely voting against shareholder motions directing boards to take action on the climate crisis. A spokesperson for the investment giant said: “BlackRock has become a signatory to Climate Action 100+. This is a natural progression of the work our Investment Stewardship team has done to date. We believe evidence of the impact of climate risk on investment portfolios is building rapidly and we are accelerating our engagement with companies on this critical issue.” BlackRock is understood to have been considering joining the climate crisis investor coalition for a while and its membership could signal a transformation in how the firm uses its influence to hold the planet’s biggest polluters to account. Fiona Reynolds, the chief executive of Principles for Responsible Investment (PRI), a UN-backed investment group, said: “In joining CA100+, BlackRock is responding to the demands of its asset-owner clients and other groups globally that they take meaningful action to address climate change.” Last year, an investigation by the Guardian revealed that BlackRock’s retail investment portfolio in fossil fuel companies totals more than $87bn and that it is the largest investor in some of the biggest polluters on the planet. Edward Mason, the head of responsible investment at the Church Commissioners, which runs the pensions for British clergy, said: “The Church Commissioners warmly welcome BlackRock to Climate Action 100+ and look forward to working together as we seek commitments from the world’s largest corporate greenhouse gas emitters to achieve emissions reductions in line with the goals of the Paris agreement. “We know from our previous engagement with companies on climate change just how important BlackRock’s support can be for moving companies forward. This is a hugely welcome decision by BlackRock and a step-change for the entire investment industry as it collectively grapples ever more seriously with the financial implications of climate change.” It is thought that BlackRock staff have become increasingly uncomfortable with the criticism from activists and other investors, including the British hedge fund manager Sir Chris Hohn, who last month accused BlackRock of “greenwashing”. In December, the American investors Boston Trust Walden and Mercy Investment Services submitted shareholder proposals to BlackRock, a publicly listed company in New York, calling on it to use its votes to pressure companies to align with climate targets. Timothy Smith, the director of shareowner engagement on the environment at Boston Trust Walden, said he hoped BlackRock’s decision to join the group would prompt other major asset managers such as State Street to start voting on environmental issues. BlackRock has previously argued that its influence is better used in engaging with company managers over environmental issues, rather than exercising their often considerable voting power. BlackRock reports the number of engagements it carries out every year, but does not offer any transparency over the content of those conversations or the position it takes on company-specific issues. • This article was amended on 10 January 2020. An earlier version incorrectly said BlackRock voted against the Climate Action 100+ resolution at BP. BlackRock supported the resolution."
"Victoria police say there is no evidence any of the devastating bushfires in the state were caused by arson, contrary to the spread of global disinformation exaggerating arsonist arrests during the current crisis. A misleading figure suggesting 183 arsonists have been arrested “since the start of the bushfire season” spread across the globe on Wednesday, after initial reports in News Corp were picked up by Donald Trump Jr, US far-right websites and popular alt-right personalities.  Some outlets are reporting this responsibly but the distorted version is all over garbage-tier rightwing media. pic.twitter.com/U9XxmzuKHl The figure included statistics from some states covering the entirety of 2019, rather than just the current bushfire season, which began in September. In Victoria, 43 alleged arsonists were counted among the 183 arrested “in the past few months” and “since the start of the bushfire season”. That Victorian figure was, in fact, the figure for the year ending September 2019, meaning it had no relation to the current bushfire season. “There is currently no intelligence to indicate that the fires in East Gippsland and the North East have been caused by arson or any other suspicious behaviour,” a Victoria police spokeswoman said. The reported figure of 183 also includes 101 individuals from Queensland who were “picked up for setting fires in the bush”. But a Queensland police spokeswoman said the figure included a broader range of offences than arson, including the breaching of total fire bans, and was not a total of arrests, but a total of “police enforcement actions”. “Enforcement action includes charging, restorative justice or cautioning,” she said. Queensland police said between 10 September and 8 January there had been 1,068 reported bushfires in the state, of which 114 had been deliberately or maliciously lit through human involvement and have been subject to police enforcement action. The Australian subsequently updated its story to say the figure covered people “arrested since the start of 2019”. Victoria police said they were investigating a suspiciously lit fire in Euroa on 4 January, which burned through a large area of land but damaged no properties. Its cause remained unknown. NSW police statistics show 24 individuals have been arrested for deliberately lighting bushfires during the current fire season. But a Rural Fire Service spokesman told Sky News on Wednesday that the majority of the larger fires in the state were caused by lightning, and that arson was a relatively small source of ignition. Arsonists have been responsible for some of the bushfires this season – though specific numbers are not yet available. There is also no doubt that arson remains a serious problem in Australia, particularly during heightened periods of fire danger. Arsonists have been responsible for some of Australia’s worst fires, including a fire that killed 10 people on Black Saturday in 2009. But exaggerated claims about arson during the current crisis have also been used to undermine the link between climate change and the longer, more severe bushfire seasons currently being experienced in Australia. Preliminary research from the Queensland University of Technology suggests bots and trolls are involved in spreading disinformation about arson on Twitter. Regardless of the source of ignition, Australia’s scientific agencies all state that climate change is creating longer, more severe fire seasons. On Wednesday, the RFS commissioner, Shane Fitzsimmons, shot down another common argument blaming environmentalists for holding up hazard reduction work. Fitzsimmons said the main obstruction to hazard reduction was weather conditions. Hazard reduction burns are particularly fraught at times of heightened fire risk. ""We are not environmental bastards.""@NSWRFS Commissioner @RFSCommissioner on hazard reduction burning, which he stresses is not the panacea for stopping fires spreading.#nswfires #AustraliaFires pic.twitter.com/Jcm803vBx9 “Hazard reduction burning is really challenging, and the single biggest impediment to hazard reduction burning is the weather,” he said. “And with longer fire seasons, earlier starts and later finishes to fire seasons like we’ve been experiencing in recent times, you get a shrinking window of opportunity for more favourable hazard reduction burning periods.”"
"Nature presenter Chris Packham has used his most recent column for BBC Wildlife Magazine to attack conservation organisations for not doing more to oppose fox hunting and badger culls, or to protect hen harriers. These groups aren’t happy, and the Countryside Alliance has called on the BBC to fire Packham, alleging that he is abusing his power to promote a political agenda they do not agree with.  But this is rather like members of the Labour Party asking for the head of David Cameron because he promotes political policies that are not to their liking. The alliance is a lobby group for rural interests, not a wildlife protection charity. There is necessarily some form of antagonism between the two opposing sides. In any case Packham is entitled to his views. He is not a newsreader for the BBC, but a presenter and journalist for TV series such as Springwatch. He is employed to provide his opinion on wildlife and conservation.  His writings are not the rants of a weirdo on social media, but of someone who holds a degree in biology and participates in wildlife conservation organisations – he’s president or vice president of conservation charities working on to protect bats, hawks, butterflies and birds. Packham is clearly speaking from the position of a well-informed insider. Conservation, including wildlife conservation, is about how we as humans use resources. Packham argues against the over-exploitation or inhumane control of wildlife, especially when it is not based on firm scientific evidence. Others in society prioritise their own desires to make a profit from wildlife or to hunt it – this will always result in conflict.   Fortunately we live in a society where such conflicts are no longer resolved by combat but by democratic processes. In the UK, fox hunting with hounds was outlawed by a vote in parliament and to try to restore it through some backdoor process is highly undemocratic. On fox hunting, Packham is merely stating the wishes of the majority of the UK population. In the case of the badger cull, his position is that held by many prominent scientists. Not that I agree with everything Packham says. I believe he was wrong to say that giant pandas are doomed to extinction and therefore we shouldn’t spend money on their conservation.  All species are doomed, eventually, to extinction, even our own –- the question is whether it will be through natural processes or by our own hand. This is again a political argument about the use of resources, but a useful one to think about for those who donate money to wildlife conservation. The challenges facing conservation organisations both in the UK and abroad are growing exponentially. And if these organisations are to fulfil their remits effectively they need not only to be patted on the back for the great work they are doing, but also to be reminded that there is always room for improvement, which is what I believe Packham has done. His words should be seen as a means of stopping these top conservation organisations from becoming complacent and spouting policies which try to please everyone and end up benefiting no-one.  Packham is creating debate and I would suggest to the Countryside Alliance that rather than calling for his dismissal they get themselves a credible and informed “big mouth” who believes in their cause. Let’s get some debate going.  If they believe their arguments in support of issues such as fox hunting are so compelling, then they should share them with the rest of us and let the democratic processes take care of the rest."
"Garden frogs and toads are in decline. The latest data from RSPB Garden Birdwatch reveals that we are seeing one-third fewer toads and 17% fewer frogs compared to 2014. Many people forget that our gardens can be important havens for wildlife. But with ponds drying up, amphibians are losing out.  We should be worried about these declines. Frogs and toads may not be our most glamorous garden inhabitants, but they offer an important opportunity to connect with wildlife within a domestic environment. As RSPB conservation scientist Dr Daniel Hayhow says:  Most people remember seeing tadpoles at the local pond or a toad emerging from under a rock while they were growing up. These first experiences with nature stay with us forever. Unfortunately, the sights and sounds of wildlife that were once common to us are sadly becoming more mysterious. These early connections with wildlife are being lost, leading to concerns that some children may be suffering from nature deficit disorder which can affect their mood and attention. Research shows that children are more familiar with Pokémon characters than they are with our native wildlife. We need to find more ways to encourage interactions with nature. Ponds, even small ones, are a great way of doing this.  Population declines in amphibians is caused by the reduction of garden ponds, and the reduced numbers of ponds in the wider countryside. We lost 50% of our ponds in the UK over the 20th century, and many that are left are in a poor condition because of pollution and lack of management.  Frogs and toads need clean ponds in which to breed, but outside the breeding season you’ll find them in tall grass and log piles. The fashion of keeping our gardens meticulously neat and tidy is leaving our wildlife with nowhere to hide. Amphibians also provide a very useful pest control service (they love eating slugs and snails) so encouraging them into gardens could bring many benefits.  So how do we help? The Freshwater Habitats Trust is leading the Million Ponds Project with the aim of creating networks of ponds. You don’t need to rebuild your garden to get involved, as even a small outside tub can be enough to provide a suitable habitat for amphibians.  If you are feeling more generous, then creating a larger pond can be a fun project – especially with children. Once put in, it will only take a matter of days before something decides to make it their home. It will usually be invertebrates and plants to begin with, but it won’t take long for it to be found by a nearby frog or toad population.  Another benefit of gardening with wildlife in mind, is that often it means that you need to do less work. Mowing your lawn less frequently provides a great habitat for wildlife. And creating a log pile, putting up nest boxes for birds or putting in a hole in your fence to allow access for hedgehogs, are all low-effort activities which are highly effective.  There are even ways to get involved if you do not have a garden. You can become a local “toad patroller”, helping toads to navigate roads safely as they migrate to their breeding ponds. Or you could become a citizen scientist by reporting whenever you see a frog or toad through Amphibian and Reptile Conservation, and taking part in the RSPB’s Wild Challenge.  Gardens in the UK might account for less than 2% of our total land use, but 83% of people live in urban areas. Small adjustments in gardens could lead to big changes in frog and toad populations – which would be good news for them, and provide gardeners young and old with a boost at the same time."
"The climate has been a persistent theme of Game of Thrones ever since Ned Stark (remember him?) told us “winter is coming” back at the start of season one. The Warden of the North was referring, of course, to the anticipated shift in Westerosi weather from a long summer to a brutal winter that can last for many years. An unusual or changing climate is a big deal. George R R Martin’s world bears many similarities to Medieval Europe, where changes to the climate influenced social and economic developments through impacts on water resources, crop development and the potential for famine. We’re interested in whether Westeros’s climate science adds up, given what we’ve learned about how these things work here on Earth. It’s not easy to understand the mechanisms driving the climate system given we can’t climb into the Game of Thrones universe and take measurements ourselves. It’s hard enough to get an accurate picture of what’s driving the world’s climate even with many thousands of thermometers, buoys and satellite readings all plugging data into modern supercomputers – a few old maesters communicating by raven are bound to struggle.  The fundamental difference between our world and that of Westeros is of course the presence of seasons. Here on Earth, seasons are caused by the planet orbiting around the sun, which constantly bombards us with sunlight. However the amount of sunlight received is not the same throughout the year.  If you imagine the Earth with a long pole through its centre (with the top and bottom of the pole essentially the North and South Pole) and then tilt that by 23.5 degrees, the amount of sunlight received in the Northern and Southern Hemispheres will change throughout the year as the Earth orbits the Sun. Clearly the unnamed planet on which Game of Thrones is set is missing this axis tilt – or some other crucial part of Earth’s climate system. The simplest explanation could be linked to spatial fluctuations in solar radiation (sunlight) received at the surface. A reduction in incoming solar radiation would mean more snow and ice likely remaining on the ground during the summer in Westeros’s far north. Compared to the more absorbent soil or rock, snow reflects more of the Sun’s energy back out to space where in effect it cannot warm the Earth‘s surface. So more snow leads to a cooler planet, which means more snow cover on previously snow-free regions, and so on. This process is known as the snow albedo feedback. The collapse of large ice sheets north of the Wall could also rapidly destabilise ocean circulation, reducing northward heat transport and leading to the encroachment of snow and ice southwards towards King’s Landing.   To descend into glacial conditions would require a large decrease in solar radiation received at certain locations on the Earth’s surface and likewise an increase would be needed to return to warmer conditions. This is roughly what happened during the switches between “glacial” and “interglacial” (milder) conditions throughout the past million years on Earth. This is controlled primarily by different orbital configurations known as “Milankovitch cycles”, which affect the seasonality and location of sunlight received on Earth. However, these cycles are on the order of 23,000 to 100,000 years, whereas Game of Thrones seemingly has much shorter cycles of a decade or less.   Around 12,900 years ago there was a much more abrupt climate shift, known as the Younger Dryas, when a spell of near-glacial conditions interrupted a period of gradual rewarming after the last ice age peaked 21,000 years ago. The sudden thawing at the end of this cold spell happened in a matter of decades – a blink of an eye in geological terms – and led to the warm, interglacial conditions we still have today.  Various different theories have tried to explain why this spike occurred, including the sudden injection of freshwater into the North Atlantic from the outburst of North American glacial lakes, in response to the deglaciation, which destabilised ocean circulation by freshening the water and reducing ocean heat transport to the North Atlantic Ocean, cooling the regional climate.  Less likely explanations include shifts in the jet stream, volcanic eruptions blocking out the sun, or even an asteroid impact. The shift from the Medieval Warm Period to the Little Ice Age that began around 1300 AD represents a more recent, and more subtle, example of a “quick” climate change. Although the overall temperature change wasn’t too severe – a Northern Hemisphere decrease of around 1˚C compared with today – it was enough to cause much harsher winters in Northern Europe. None of these events indicate the abrupt transitions from long summers to long winters as described in Game of Thrones – and they still all happen on a much longer timescale than a Westeros winter. However they do demonstrate how extreme climate shifts are possible even on geologically short timescales. Regardless of the causes of the long and erratic seasons, winter in Westeros won’t be much fun. It may even make the struggle for the Iron Throne between the various factions seem irrelevant.  Indeed the House of Stark’s motto: “winter is coming” may have a lesson for us here on Earth. Anthropogenic climate change is one of the biggest challenges facing humankind today and if left unmitigated the potential environmental impact on society may be far greater than any global recession. Stop worrying about the Iron Throne, everyone, winter is coming."
"It makes for a dramatic headline, but it is unfortunate that the Guardian has produced such a partial report on what a council meeting in York decided (York to ban private city centre car journeys to cut air pollution, 1 January). The city tried to ban cars from crossing a single bridge in 2014 and it ended in failure – not because the idea of banning cars wasn’t a worthy one but because sticks have to be accompanied by carrots or they do not work. Banning cars is the easy bit. But what do you put in its place? Light rail? Biogas buses? A tram network? An electric car hire scheme?  York declared a climate emergency in March 2019 and the cross-party climate change committee is charged with delivering a zero-carbon future. Liberal Democrat, Green and Labour councillors are working to transform our response to the climate emergency. The committee has recommended the council adopt a cumulative carbon budget for 2020-30 and a science-based approach to evaluating the carbon cost of our activities, projects, procurement and investment from here on in. The city’s Lib Dem-Green administration is considering introducing amendments to this year’s council budget to enable these proposed changes to be implemented. Turfing people out of cars without producing a viable and attractive alternative is a recipe doomed to failure. Major investment is required and we must take residents and businesses with us. I believe we can. There is no planet B.Cllr Christian VassieChair of climate change committee, City of York council • Your article on York highlights how important it is for both central and local government to take urgent action to reduce air pollution in our cities and tackle the climate crisis. Transport is the only sector where CO2 emissions are rising as our reliance on motor vehicles remains at an all-time high. If we are to reduce harmful emissions, we need to make walking and cycling the most attractive option for short journeys. Bike Life 2017 – the UK’s biggest assessment of cycling in cities – revealed that 53% of people would like to start cycling or cycle more, but its perceived danger is still a barrier. Initiatives to take more cars off the road would make people feel safer and more confident. However, this is only a first step. To see a significant reduction in air pollution and meet the target of becoming carbon neutral by 2050, the government must commit greater funding to build dedicated walking and cycling infrastructure in our towns and cities. Until we end our reliance on motor vehicles, we will continue to live with dangerous levels of air pollution. The government must take action to ensure all cities can introduce changes such as this, and that streets are designed with people in mind, rather than motor vehicles.Rachel WhiteHead of public affairs, Sustrans • Your editorial (27 December) says that “In the age of climate emergency the car is no longer the star”. The car has never been the star – more an asteroid that hurtles on our roads, too often out of control. A significant omission from your long editorial was the annual global strike rate: 1.35 million killed, countless millions suffering life-changing injuries, many of whom are pedestrians and cyclists. Any other machine with this killing record would not be tolerated by intelligent caring creatures. No mention was made of the behavioural changes that overcome some otherwise careful and considerate individuals. Once behind the wheel of their box, they are isolated, feel secure and, with terrifying power under their feet, become reckless toads of our roads. Phase out the car, run trains on our motorways, trams and buses on our A roads, walk and cycle shorter town and city distances. Learn to share again and liberate our urban centres from the tyranny of the private car with all its undeniable ills.Dick FollowsLancaster  • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"Australia’s unprecedented bushfires are a wake-up call to the world about the importance of tackling climate change, Bernie Sanders’ economic adviser said, and the country should consider implementing a green new deal to transition to a low carbon economy. Stephanie Kelton said Australia could benefit from an ambitious program of spending, similar to the one proposed by Sanders and others that aims to transform the US economy and help keep global heating below 1.5C.  She told the Guardian that Australia’s longstanding bipartisan commitment to running a budget surplus where possible was “economically illiterate”, and governments should concentrate on getting the economy running properly rather than “what number falls out of the box at the end of each fiscal year”. “As tragic as the situation is here, it does seem to be serving as a real wake-up call for people living in all other parts of the world – I mean, the world is watching,” she said. “People are really starting to come to terms with the realities of climate change as a result of seeing these images and the devastation here. “I don’t know if it will provide that breakthrough moment that is necessary for galvanising the world around a shared commitment to dealing on an ambitious scale with the threat of climate change, but it feels like it has the potential to unleash that.” Kelton is in Australia to speak at a conference on the Green New Deal and other economic issues in Adelaide on the weekend that is supported by the School of Economics of the University of Adelaide, where Kelton is a visiting professor. Kelton will also be meeting with businesspeople at private events organised by accounting firms. The idea of a Green New Deal has been championed by New York congresswoman Alexandria Ocasio-Cortez, who has pushed the idea within the Democratic Party. In the version that forms part of Sanders’ presidential pitch, it would involve the US government spending US$16.3tn on decarbonising the economy, including by moving to renewable energy, upgrading public transport and funding a “just transition” for workers who lose their jobs in the resources industry as a result of the changes. The deal “is an ambitious response to the imminent threat of climate change on a scale that is commensurate with the threat that we are facing”, Kelton said. “To do something like this in 10 years time requires a mobilisation that is sort of parallel to what we did in world war two”. She said the economy would look very different after a Green New Deal. “We’re building a care economy, we’re caring for our community, we’re caring for people and we’re caring for the planet,” she said. “You can imagine millions and millions of people being put to work doing jobs that are associated with building a cleaner, safer, more secure and more prosperous economy.” She said a lot of people thought there was a tension “between jobs and growth or taking care of the planet”. “What the Green New Deal says is that we don’t have to pick one. “People have more secure jobs, higher paying, better paying, more prosperous economies – more savings, more wealth.” Kelton said Australia could “absolutely” benefit from a similar program. “This is definitely not conceptually a program that couldn’t work in any country,” she said. She mocked the idea it was “too hard”. “Imagine if we had said that after the bombing of Pearl Harbor – oh, I don’t know if we can fight back against the Nazi invasion and the threat. I don’t know, it seems awfully hard.” She said that the US pulled off the original New Deal under president Franklin D Roosevelt in the early 1930s, when the country was “about as poor as it had ever looked”, with unemployment running at about 25%. “What did FDR do? He came in, he advanced an alphabet soup of programs … he just created employment for millions and millions of people. “When you’re under threat and the alternative is just to let it burn? Somehow we muster to solve big problems when our lives are at stake – and they are.” Kelton is also one of the leading proponents of modern monetary theory, a controversial economic school of thought that holds that governments should simply print more money to finance spending needed to revive the listless global economy – as long as doing so does not cause inflation to soar. This contrasts with conventional economic thinking, which generally holds governments need to finance spending in excess of their incomes by borrowing money. She has little time for the Australian political scene’s obsession with running a budget surplus. “I don’t want to be disrespectful, but it’s economically illiterate,” she said. “It is the wrong way for a government to behave – in other words, prioritising a budget outcome as if the numbers that get churned out of the budget box each year are what matter. “I always say that governments that behave this way are willing to force their economies to balance their budgets and what I would do is the opposite of that – I would use my budget, allow my budget to balance the broader economy. “I don’t care what number falls out of the box at the end of each fiscal year as long as it delivers good macroeconomic conditions. “So if I have full employment, if my inflation rate remains low, I am indifferent to the budget outcome.”"
"When a gunman entered Sandy Hook elementary school and murdered 20 children and six adults after killing his mother in their home, the shock was so great you could assume that America would undergo a profound shift in consciousness. In addiction parlance, Sandy Hook was the rock bottom moment – where things are so bad you know they can no longer continue as is. After rock bottom, there is a choice: stasis and misery or growth and transformation.  With Sandy Hook, many of us in Australia assumed that after the grief, there would be a reckoning: the National Rifle Association would lose much of its power and influence, its spokespeople and shills would become pariahs, and meaningful legislation would pass so that this tragedy wouldn’t happen again. Right? Wrong. Since Sandy Hook, when much of the world said “never again”, 2,348 mass shootings have occurred. The number rises every day. For America, a shift in national consciousness did occur, but powerful interests (and the politicians beholden to these interests) stopped growth and transformation. Stasis and misery followed. From the other side of the world, many Australians were confused and appalled. How hard can it be, we tweeted, lectured and hectored. Even our conservative former prime minister John Howard did the rounds of the US late-night shows to explain how he enacted radical gun reform measures, how Australia used the painful and shocking experience of the Port Arthur massacre to change and evolve. There was more than a hint of moral superiority in how much we liked telling Americans they must lay down their weapons, that they needed to wake up. But soon it will be our time to look in the mirror. This apocalyptic-seeming Australian summer is our Sandy Hook moment. We have to seize it and change our thinking, our priorities and our politics. In doing so we can change our country, our future, and transform ourselves into global leaders on climate change. These fires without precedent have the potential to profoundly shift the national consciousness. This summer could shake us awake – if we let it. But if we don’t do it now, while things are raw and real, we never will. The alternative is bleak: another lost year, another lost decade. That’s another year of willing yourself to forget that 49.7C day in Penrith, of trying to block out the pictures you saw on social media of charred animal carcasses and the ash you see falling from the sky and the image of the New Year’s Day sky that turned black at 4pm, of the people you saw on television who tried not to cry when they said their house had burnt down, but were thankful to be alive. Of the friends you had to call in the fire zone to check if they were OK. It’s trying to forget the footage you saw of the woman who ripped off her shirt and ran into the bush to save a burning koala. Of the photo you saw of the people standing in the sea in the middle of the night, in the dark, as the fire tore down to the shore. Of the exhausted Nelligen firefighter who had seen seven houses lost that day, who collapsed on the ground – but not before he told the prime minister to “get fucked”. Of the tornadoes made of fire lifting up fire trucks weighing tonnes, of nightmarish dashcam footage of flames coursing through a fire truck with people in it, of vast fire fronts meeting up that are too big too fight (and the forests, lit up at night, look like when you’re on a plane, flying low over a metropolis). Of the man who died in Batlow of a heart attack after helping defend his friend’s home. Surely these things are powerful and terrifying enough to change us? What might our transformation look like? It might look like a simple acknowledgement of causation between climate change and this summer’s fires. Transformation is recognising the facts: Australia is a climate vandal, led by wreckers. We are ranked the worst of 57 countries on climate policy. Australia is the largest exporter of coal to the world, a global top 10 deforester and a world leader in mammal extinction. Our carbon-loving prime minister, supported by the Murdoch media and fossil fuel industry, came into parliament carrying a lump of coal. Climate scientists have proven time and time again, the link between carbon emissions and global heating. The ferocity of these fires was predicted. Once this causation has been established in our minds, we can and we must demand that the government create a meaningful climate policy. The painful lessons of this summer could be transformative, if we allow them to be. Australia – having experienced the pointy end of the climate catastrophe – could become a leader in the global fight to reduce emissions. The alternative is stasis and misery – or even more awful (and currently unimaginable) – a worsening of the current condition, a death spiral. When rock bottom is hit, change can happen. Four thousand people evacuated to a beach on New Years Eve. This is rock bottom. The largest evacuation in Australia’s history. This is rock bottom. One third of the koala population on the New South Wales mid-north coast  being destroyed, and the entire ecosystem ravaged. Again, rock bottom. This is our Sandy Hook moment. We must seize it and demand an effective climate policy. Or nature will be forced to teach us her hard lessons – over and over and over again. Brigid Delaney is a Guardian Australia columnist "
"The now recalled guidance issued by counter-terror police that placed Extinction Rebellion alongside the likes of jihadists and neo-Nazis emerged at a problematic time for the government’s flagship anti-radicalisation programme, Prevent. The voluntary initiative is supposed to be under independent review after years of concerns about its impact on certain communities and on freedom of expression.  But just under a year after the review was announced by the Home Office, its chair, Lord Carlile, was forced to step down after a legal challenge to his appointment was brought on grounds of his partiality. The review was set to report back in August this year, but is currently without a leader and the clock is ticking. The criticism that prompted the review focused around three key themes: first, that the way the strategy is applied fosters discrimination against people of Muslim faith or background; second, its effectiveness (the last set of official figures revealed that still only one in 10 of referrals goes on to receive specialist support); and finally, that it inhibits legitimate expression. The last point is particularly pertinent given the fact that Extinction Rebellion and the environmental issues for which it campaigns were included on a list of “extremist ideologies”, which was then sent out to public sector partners, including teachers, who are under a legal obligation to refer the slightest suspicion that a person is vulnerable to said ideologies. Among evidence that a person may be vulnerable to Extinction Rebellion’s alleged extremist beliefs was speaking in “strong or emotive terms about environmental issues like climate change, ecology, species extinction, fracking, airport expansion or pollution”. Given the growing awareness of the climate emergency across the world – arguably due in part to the actions of Extinction Rebellion – this would make hundreds of thousands of people extremists. School strikers were singled out in the guidance – last year thousands of UK pupils, and millions worldwide, walked out of school in protest at government inaction on the climate crisis. The activist Greta Thunberg is a leading proponent of school strikes. This would have placed teachers – obliged to refer under the statutory duty, perhaps the most controversial element of the Prevent programme – under further pressure. The education sector is already the greatest single source of referrals to Prevent. Counter-terror police have been at pains to emphasise that Extinction Rebellion are not considered to be extremists and that the document was drawn up in error. Action has been taken to recall the document, but only after police were approached by the Guardian. It is also likely that the document, dated November last year, has been in circulation for around two months, and police chiefs are unable to say how many individuals and organisations received it. But there has already been at least one publicised case of an individual being referred to Prevent over their associations with Extinction Rebellion – Lyn Jenkins, a 69-year-old retired doctor, was referred by his NHS trust after telling them he wanted to be arrested during Extinction Rebellion protests. Prevent practitioners within police forces log every Prevent referral on a giant case management database – a database that the police insist was not a secret before the Guardian covered it last year, despite revealing that they do not inform individuals they are being listed on the database, pointing critics to a handful of buried references in highly obscure civil service documents online. For those concerned that they may have been referred to Prevent for their fears – and actions taken to address them – over the climate emergency, individuals are able to contact their relevant police force, ask if their details are held on the Prevent case management database, and then request that they be removed."
"The Indian state of Kerala has been devastated by severe floods. More than 350 people have died, while more than a million have been evacuated to over 4,000 relief camps. Tens of thousands remain stranded.  The crisis is a timely reminder that climate change is expected to increase the frequency and magnitude of severe flooding across the world. Although no single flood can be linked directly to climate change, basic physics attests to the fact that a warmer world and atmosphere will hold more water, which will result in more intense and extreme rainfall. The monsoon season usually brings heavy rains but this year Kerala has seen 42% more rain than would be expected, with more than 2,300mm of rain across the region since the beginning of June, and over 700mm in August alone. These are similar levels seen during Hurricane Harvey, that hit Houston in August 2017, when more than 1,500mm of rain fell during one storm. Tropical cyclones and hurricanes, such as Harvey, are expected to increase in strength by up to 10% with a 2℃ rise in global temperature. Under climate change the probability of such extreme rainfall is also predicted to grow by up to sixfold towards the end of the century. The rivers and drainage systems of Kerala have been unable to cope with such large volumes of water and this has resulted in flash flooding.  Much of that water would normally be slowed down by trees or other natural obstacles. Yet over the past 40 years Kerala has lost nearly half its forest cover, an area of 9,000 km², just under the size of Greater London, while the state’s urban areas keep growing. This means that less rainfall is being intercepted, and more water is rapidly running into overflowing streams and rivers.  One of the most striking things from the videos and images emerging from the area is the brown colour of the flood waters and the extreme damage caused by landslides. Our recent research has shown that geomorphology – the processes of erosion and deposition that shape the Earth’s surface – is sensitive to rainfall intensity, so more frequent and more extreme floods mean more rapid changes across our landscapes. The floods have been described as “the worst in 100 years” by Kerala state’s chief minister. Similar descriptions are often used to try and define the magnitudes of a flood, such as a “one-in-100 year flood event”, despite it being widely recognised that such descriptions are ineffective for communicating flood risk. Our ways of thinking about probability and the risk of flooding, as well as measuring its magnitude, are in desperate need of updating. The 100-year flood, the flood that has a 1% chance of occurring in any given year, does not register in public consciousness.  A different way of thinking about it is that a 100-year flood at a given location has close to a one in four chance of occurring within the term of a 25-year mortgage. A 25% chance your house will flood before you’ve finished paying for it is far more relatable and more likely to get people to consider and engage with their own individual risk. Likewise, governments, both regional and national, along with agencies and first responders, need to develop improved flood maps and update them to incorporate uncertainty. Alongside this, we need more effective communication and public engagement to develop flood risk literacy – long term this will help improve policy decisions. The UK’s 25-year environment plan is a step in that direction. Most critically we have to accept that, with the changing climate and changing patterns of rainfall, the behaviour of rivers will also shift. All our assessments of flood risk currently assume a static, steady-state system where rivers respond in the same way they have in the past. An increase in rainfall, and in particularly extreme events, will cause our landscapes to adjust. Rivers and their basins will become more dynamic and prone to change.  How quickly rivers change, and how quickly we respond with urban drainage and flood mitigation measures, will play a significant role in our evolving flood risk. Layered on this will be how rapidly societies, and their governments, begin to adopt more resilient ways of living with water.  Flooding is a challenge across individual, local, regional and global scales, and is set to increase in the future and its impacts will become more damaging. We need solutions across each of these scales to improve individual and societal resilience – so when flooding does occur it isn’t the disaster we are currently witnessing unfold in Kerala."
"“Two more just died in the last few minutes,” Tom Grant said as he inspected a lamb that had fallen to its haunches. “When they’re like this they give up. They just give up.”  Grant and a crew of helpers spent Tuesday carrying out the grisly task of burying about 200 sheep killed on his property near Cobargo near the New South Wales coast when fires tore through the area in the early hours of New Year’s Day. As he spoke to the Guardian, more of the lambs who survived the blaze dropped to the ground. “The only water I’ve got for the ones who are left is what’s in the troughs, and we’ve got very little feed,” he explained. “There are about 10 cattle we still haven’t found. If they do show up I don’t know what I’m going to feed them.” “A lot of them were our breeding stock for next season. We lost all four rams, too. It’s roughly $36,000 to $40,000. We’re insured though, so don’t feel too sorry for us.” A white pony which Grant had dressed as a unicorn for his grandchildren recently was also among the dead animals collected on Tuesday. Grant was one of dozens who lost his home in the blaze. As he used a tractor to lift sheep carcasses into a truck that then dumped them into graves dug with an excavator, his son Paul explained that Grant and his wife had built the home together as part of their retirement. “I think this will be it for them now,” Paul Grant said. “They’d talked about downsizing in the future and I think this will just speed that up. It’s pretty heartbreaking, though. Mum’s really gutted but I suppose at the end of the day it’s just things. Funny how life has a way of changing your plans for you, though.” All across the southern part of NSW, similar scenes are playing out as the clean-up continues.  More than 1,500 homes have been destroyed in the state since the start of the unprecedented fire season, and a record-breaking area of land – 4.9m hectares (12.1m acres), an area larger than Denmark – has been burned, according to the latest figures released by the Rural Fire Service. Almost 118 fires continue to burn across NSW with 50 uncontained. About 100km north, in the beachside suburb of North Rosedale, Dafydd Gwynn-Jones and his daughter Caitlin had driven down from their home in Canberra to find the ruins of the holiday house his parents built 41 years ago. As they dug through the rubble – “that was the door, that was the fridge” – searching for mementos that might have survived the fierce blaze that has levelled about 75% of this holiday suburb near Batemans Bay, they reflected on something that had always been there but now was not. “For my sister and I this house was pretty much the one constant,” Caitlin said. “We’ve lived in different cities, Sydney and Canberra, and different houses, but this was the one place that was constant. We tried to come here every year in the summer. Tried not to take it for granted.” The damage here is almost surreal. This small, out-of-the-way suburb was almost entirely levelled in the early hours of New Year’s Day. The panoramic views across the Pacific Ocean that drew holidaymakers are now offset by a brutal carnage. “It will take a long time to rebuild this place, a long time,” Dafydd Gwynn-Jones said. “But we absolutely will.” The bushfire emergency gripping the east coast of Australia did not begin with the New Year’s Day fires, and with more dangerous conditions expected this week it probably will not end with them either. But across hundreds of kilometres, the first week of 2020 has seen a trail of destruction. On Saturday, as thousands of Rural Fire Service volunteers battled an onslaught of  emergencies sparked by blazing heat and relentless winds, the Guardian watched as the sky in the Snowy Mountains town of Adaminaby turned black by 3pm. As the fire peaked over a ridge near the town and headed towards properties defended by thinly stretched fire crews, the RFS group captain, Scott Lonard, simply did not have the resources to protect all of them. “We’ll do our best but five trucks for this much space isn’t going to be enough,” he said.  While milder conditions on Sunday brought a reprieve for the mountains, a strong southerly wind only exacerbated things in the far south coast town of Eden. When it was evacuated on Sunday many in the town fled about half an hour north to Merimbula or west to Bega. When the evacuation centres in those towns began to fill, people began camping along the waterfront or under overpasses, a flood of people left with nowhere to stay and nothing to do but wait. “I don’t know when I’ll get back into Eden and to be honest I wouldn’t want to go back yet,” John Ironmonger said near the water at Merimbula on Sunday. “Everyone here has just been shuffled around from place to place.” When the Guardian spoke to Shelley Caban in her makeshift shelter on a bus on the Eden wharf, she had no idea whether the historic 150-year-old home she lived in with her husband and three daughters just south of the town had survived. By Tuesday it was still standing, but with conditions expected to deteriorate again the family are not out of the woods yet. “It came to literally within a paddock of the house and then the rain started,” she said. “In a weird way I’m kind of at peace with whatever happens now. I just want it to be over one way or the other.”"
nan
"New Zealand has experienced its fourth-warmest year since records began in 1909, with temperatures between 0.5C and 1.2C higher than annual averages across the country. There were 100 new daily temperature records set at spots around New Zealand.  The country has not experienced the severe weather extremes that have plagued neighbouring Australia and its climate is traditionally much more temperate. But the “trend towards warming shows that we are affected by climate change”, said Professor James Renwick, a climate scientist at Victoria University Wellington, in comments to New Zealand’s Science Media Centre. Renwick said that seas around New Zealand experienced “record warmth” in many locations. While the country’s climate was variable, mean temperatures had exceeded the 1981-2010 average in 80% of the past 20 years. “That’s how a warming climate works,” he said. “We see ups and downs but the chances of a warm year are increasing all the time.” Stronger than usual westerly winds blowing across the country had resulted in droughts. “The knock-on effect of this is we start 2020 with many eastern and northern regions of the country thirsty for some significant rainfall,” Lisa Murray, a meteorologist at New Zealand’s MetService, told the Science Media Centre. While rainfall was up in some parts of the South Island, large areas of the country had only 50-80% of their usual rainfall, according to National Institute of Water and Atmospheric Research figures. “This pattern is what we are likely to see more of as the climate changes this century, with more frequent drought and increased fire danger in eastern regions and in the northern North Island,” said Renwick. In other areas, however, flooding would be more common. “The average amount of moisture in the air is strongly related to temperature, so as the climate warms, heavy rainfalls become heavier and flooding becomes more common.” The MetService introduced a severe red weather warning in 2019 to caution people about destructive weather events that required immediate action, Murray said."
"
Share this...FacebookTwitterAnother paper titled The Solar Wind and Climate: Evaluating the Influence of the Solar Wind on Temperature and Teleconnection Patterns Using Correlation Maps lends great support to the claim that solar activity plays a major role in driving the Earth’s climate, and that CO2’s impact is being grossly overstated.
Hat-tip: Kirye.

The paper, authored by a team of researchers led by Japanese physical chemist Dr. Kiminori Itoh, photo right, examined the influence of changes in solar activity (solar wind in particular) on surface temperatures and major oceanic oscillations such as the Arctic Oscillation and the Pacific Decadal Oscillation, which have great impacts on regional and global climate.
The researchers feel that the major drivers of the Earth’s climate are more related to the sun and the oceans, and CO2’s role has been exaggerated.
Sun and oceans play great role
The paper cites, for example, Levitus et al., which found multidecadal temperature oscillations with magnitudes as large as 4°C for the Barents Sea at depths of 100–150m and that the timing of the oscillation coincided with the Atlantic Multidecadal Oscillation (AMO), a major factor in the Atlantic Ocean.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Chart: Itoh 2018.
IPCC models shoddy, major factors “not adequately represented”
The team of scientists found a clear influence of the solar wind on climate, and thus solar activity “should be considered much more than conventionally believed”.
The authors state, “once its mechanism becomes clearer and incorporated into climate models, it will greatly contribute to policy development.”
“The effectiveness of climate models is greatly reduced when the influence of the sun (and moon) is not adequately represented,” they state in the paper’s conclusion.
Dr. Kimimori Itoh has been a harsh critic of the mainstream, narrow scientific view that trace gas CO2 acts as the main driver behind global climate. He once called it “the worst scientific scandal in history” and that “when people come to know what the truth is, they will feel deceived by science and scientists.”
Dr. Itoh photo: cropped from Twitter.
Share this...FacebookTwitter "
"Scott Morrison has rejected criticism of the Coalition’s climate change policies amid the ongoing bushfire crisis, as a growing number of MPs privately concede that the government needs to do more to match the rising tide of concern over the issue. As firefighters continued to battle out-of-control bushfires across four states on Friday, the prime minister said it was “disappointing” that people were conflating the ongoing fire crisis with Australia’s emission reduction targets.  “We don’t want job-destroying, economy-destroying, economy-wrecking targets and goals, which won’t change the fact that there have been bushfires or anything like that in Australia,” Morrison told Sydney radio, 2GB. “The suggestion that there’s any one emissions reduction policy or climate policy that has contributed directly to any of these fire events is just ridiculous and the conflation of those two things, I think, has been very disappointing.” He said the government would “continue to consider our policies carefully here”, while conceding to the ABC that the bushfire crisis had elevated the debate over the government’s stance on climate change. “I think the public opinion on this issue, has been heightened across a whole range of factors and climate is one,” Morrison said. “But I mean, there are a range of other things … the drought, which is not unrelated to the issues we’re talking about, but the hazard reduction and how we manage that in the future, because hazard reduction has proved to be very difficult in recent times because of the drought.”  Experts have pointed to the link between climate change and an inability to undertake more hazard reduction burning, with hotter, drier conditions and a prolonged bushfire season narrowing the window of opportunity for the practice. When asked if a national inquiry into the fires that canvassed all issues, including climate change, could prompt a “recalibration” of the government’s climate change policies, Morrison said the government would review any recommendations arising from an inquiry. “I’m up to discuss all of those things and there’s no hesitancy or pushback from the government to address any of those things. And I think we have to address them calmly and rationally and in proper context and perspective.” But when pressed on whether he would revisit the vexed issue of energy policy – including the national energy guarantee that Morrison previously supported – the prime minister said that he believed the community wanted him to be “100% focused” on the response effort, rather than drawn into a policy debate. Coalition MPs have also been asked not to engage in public discussions about the government’s climate change policies until after the current bushfire threat has passed, urging a focus on the government’s emergency response. In a phone hook-up with government MPs on Thursday, Morrison also banned backbench MPs from doing any international media interviews, after conservative MP Craig Kelly was lambasted on UK television for denying the role of climate change. But as the prime minister fends off criticism for the government’s climate policies, a growing number of MPs are privately conceding that more needs to be done to match the growing level of public concern about the links between climate change and Australia’s drying climate. An update from the Bureau of Meteorology released on Thursday showed Australia recorded its hottest and driest year on record in 2019, with temperatures 1.52C above the long-term average. MPs say that the view being pushed by Labor and the Greens that the Coalition is not doing enough has penetrated, and will be politically damaging at the next election unless Morrison charts a more ambitious course. This would particularly be the case in inner-city seats where the issue was recognised as a key factor that won Labor votes in certain seats at the last election. A number of MPs have already joined a cross party pro-climate action group, the Parliamentary Friends of Climate Action group, including Liberals Tim Wilson, Dave Sharma, Jason Falinski, Katie Allen, Angie Bell and Trent Zimmerman. MPs told Guardian Australia that they believed the government needed to reposition on climate change, but recognised Morrison could not be seen to be responding in a knee-jerk fashion. The independent MP Zali Steggall, who defeated Tony Abbott on a platform of climate change action, is hoping that some Liberals wanting stronger action will cross the floor to support her bill to establish a climate change action framework. She is planning a public awareness campaign aimed at putting pressure on the government to allow a conscience vote on the legislation. Labor leader Anthony Albanese said the opposition wanted to see “strong action on climate change”, but the party was still considering its position following last year’s election loss. “We will announce our proposals based upon where we’re at closer to the election. We won’t let the government off the hook,” Albanese said. “[But] we want the government to act immediately. We will have strong policies, but they’ll be off the basis of what the starting point is. We don’t want the starting point to be the pathetic response with no climate change policy and no energy policy that we have from this government at the moment.” The environment minister, Sussan Ley, said the “majority view” within the Coalition party room was that climate change was an underlying factor for the fires. “I would say government policy reflects the majority view, and government policy is very clear about acknowledging that climate change and dry sequence years are increasing the frequency and the risk and the intensity [of fires],” Ley told ABC on Friday. She said the view of Kelly and a “minority” within the Coalition were not dictating the government’s policy approach."
"Two schools of thought regarding Hollywood environmentalism were on display at last weekend’s Golden Globes ceremony. In the blue corner were those determined not to stand idly by in the face of the mounting climate crisis, such as Cate Blanchett and Russell Crowe drawing attention to the Australian bushfires. Or Joaquin Phoenix, “not always a virtuous man”, who urged his fellow stars to look at themselves, too, and ditch the private jets. In the red corner was the lone, but unfailingly hectoring voice of host Ricky Gervais, railing against Hollywood hypocrisy. Should any of the winners find their minds drifting to politics while on the podium, they should “accept your little award, thank your agent and your God, and fuck off”.  It could be that the now near-regulation Gervais Golden Globes roast, playing to the court, is in fact an added layer of hypocrisy in the great Hollywood pageant. But it did at least draw attention again to the gap between good intentions and daily practice in the entertainment industry. Film and TV production has a hefty ecological footprint: a landmark 2006 University of California, Los Angeles (UCLA) study estimated that the industry produced 15m tonnes of CO2 a year. That might seem piddling next to the several billion tonnes emitted by the US economy that year, but in its principal sites of operation, such as Los Angeles, Hollywood was a big polluter – more so than the aerospace, clothing, hotel and semiconductor industries. The average film is estimated to produce 500 tonnes of CO2 emissions – as much as running 108 cars for a year With the cast and crew of top-end studio projects now running into thousands of people – from set-builders to sparks, masseurs and makeup artists, to high-end caterers and server-hungry special effects farms – there is no reason to think Hollywood is any less resource-hungry these days. The average film is estimated to produce 500 tonnes of CO2 emissions (equivalent to running 108 cars for a year), but this scales up with its budget; a $50m film can produce 4,000 tonnes. Who knows what something like Avengers: Infinity War racks up in production and beyond? If everyone’s favourite mauve Malthusian, Thanos, had really wanted to do his part for the environment, then finger-snapping half the people on the film’s jet-setting international press tour would have been a good start. Of course, Hollywood, a left-leaning eco-friendly constituency by nature, wants to do its part. From Phoenix to Leonardo DiCaprio, long a spokesman for environmental causes, it is not hard to find film stars and studio personnel who talk the talk and at least partially walk the walk, all the way down to their Prius. The Disney co-chair Alan Horn is the chair of the trustees of the environmental lobbying group Natural Resources Defense Council (NRDC) and in 1989 helped found the Environmental Media Association (EMA), which doles out Green Seal certification for movies that make efforts towards sustainable production. Most major film studios now have sustainability drives to encourage the use of clean energy on set and the recycling of production materials. Independent consultancies exist, such as Earth Angel and the Green Spark Group, to make this happen; the Green Production Guide – developed by all the major studios in the wake of the US pulling out of the Paris climate agreement – helps with finding such companies and calculating carbon footprints. Carbon-neutral productions, achieved through emissions offsetting, are now relatively common. Certain films make a point of pride, or at least of marketing, of their green credentials: Jason Bateman’s 2013 directorial debut Bad Words was the first fully solar-powered production. Unfortunately, it remains virtually impossible to meaningfully audit Hollywood’s eco-credentials because of a lack of overarching information. Only two of the big six traditional studios made their emissions totals freely available online in 2018: Disney (1.93m tonnes) and Sony-Columbia (1.34m). Along with those two, the others make varying corporation-wide pledges, but they remain as airily aspirational as a J Lo romcom: Universal, for example, touts its fuel-efficient transportation fleet as leading its zero-emissions drive, but will not put a date on zero-hour. Before its buyout by Disney, 21st Century Fox announced it was carbon-neutral in 2011, but the term then disappeared from later reports on the subject. The UCLA study, 14 years old and predating the recent sustainability boom, is still the only major overview available. But its authors admit that it is an approximate, anecdotal work, drawn from 43, mostly anonymised, interviews with people working in the industry. When it comes to understanding ecological footprints on a film-by-film basis, Hollywood’s famously gnomic accounting practices get in the way. Few productions release specific emissions information. The benchmark remains Roland Emmerich’s 2004 super-storm thriller The Day After Tomorrow, which because of its environmental theme, came clean about its carbon footprint: 10,000 tonnes, as estimated by Future Forests ($200,000 of a $125m budget was paid to offset this). So establishing general metrics for the ecological imprint of film productions that might help the industry as a whole whittle down emissions and wastage faster is still a far-off hope. The lack of both a clear roadmap and rigorous application leaves Hollywood open to the charge that its eco efforts, despite the growing momentum, are mere greenwashing. Disney’s emissions reductions (aiming at a 50% cut from 2012 levels by 2020) look good on paper until you realise that a high percentage are from its cruise-ship line – and it has just signed on for three more vessels (albeit powered by less-polluting liquefied natural gas). To go back to the Golden Globes, does it matter that this year’s guests were eating vegan in the overall scheme of an event with the kind of footprint that includes a $10,000 (£7,630) gift bag for VIPs? In the absence of true industry-wide practice, Hollywood eco initiatives remain piecemeal, and are usually opt-in or imposed by powerful stars with a conscience. It has been reported, for example, that it was Phoenix who persuaded the Hollywood Foreign Press Association to serve a vegan menu at the Globes. (The effect of his good work was rather undone when Stella McCartney commended him for his “bravery” in wearing a single tuxedo – hers – throughout awards season.) Maybe even the minimum gesture, carbon offsetting, is a form of cheap expiation that stops root-and-branch overhaul of how film productions are run. In the meantime, the disconnect between publicly declared environmentalism and daily practice in Hollywood continues. Not only is blockbuster film-making a resource-intensive activity, but it is part of a bigger superstructure of capitalist enterprise that is inherently ecologically costly. You have to remember that entertainment is market-driven. Audiences don’t want to hear about climate change To take two examples, 2018’s Jurassic World: Fallen Kingdom was touted for its sustainable shoot, distributing reusable water bottles to cast and crew, employing hybrid vehicles and using 75% LED lighting. It also contained product placement or commercial partnerships with Amazon, Jeep Wrangler, Dr Pepper, Dairy Queen and Doritos, among others; putting aside what this great network of commerce represents, the latter brand’s use of palm oil should have been reason enough to think twice. The Amazing Spider-Man 2, from 2014, has been brandished as a best-practice example, earning the EMA’s Green Seal for recycling practices that stopped 52% of the waste it generated from ending up in landfill. But how significant is this when the film comes slathered in placement for production company Sony’s laptops and mobile phones – built with components using rare-Earth elements, the extraction of which has a heavy impact? Hollywood is not alone in struggling with these contradictions. The value of small actions weighed against the bigger picture, whether these efforts are meaningful or self-deluding, is the great middle-class dilemma of the 21st century. But Hollywood is alone in its capacity to draw attention to these quandaries, through the subject matter it chooses to film. Here, again, its record is questionable – apart from documentaries such as An Inconvenient Truth. Environmental themes have never been catnip to Hollywood executives, despite the efforts of the likes of the NRDC to steer film-makers in this direction. Traditionally, they have crept into the context of certain top-tier films, such as Waterworld, AI or WALL-E, but less than a handful of mainstream directors, such as Emmerich, seem willing to engage with the issue directly. Maybe, as the global situation has darkened, there has been movement on this front. From Avatar to Mad Max: Fury Road to Interstellar to Blade Runner 2049 to Avengers: Infinity War to Aquaman, it does feel as if ecological collapse is now more fully normalised in the mainstream. But none of these films dared be explicitly political, whether out of fear of alienating the climate-sceptic middle-American audience, or just of tearing off the veil of Hollywood’s breezy escapism. The Asian mainstream – from Hayao Miyazaki’s longstanding ecological commitment to Stephen Chow’s recent eco-comedy The Mermaid and Bong Joon-ho’s Snowpiercer and Okja – does more heavy lifting. “The thing you have to remember is that entertainment is market-driven. Frankly, [audiences] don’t want to hear about climate change,” the director James Cameron – who is planning to make his Avatar sequels solar-powered and vegan-catered – recently told Variety. He remains doubtful about the impact of ecologically themed films: “I think you can insinuate these ideas into your storytelling. I’ve certainly done that with Avatar, but, frankly, Avatar came out 10 years ago. And in that time our population has grown by almost a billion people, and the effects of that alone on our environment and climate change are devastating. Does [storytelling] do that much good?” Perhaps the problem is the kind of storytelling. Maybe ecologically progressive thinking is too challenging to the capitalist paradigm of which Hollywood remains a central part. It is easier to put everyone’s planetary worst thoughts into the mouths of villains such as Thanos or Aquaman’s King Orm, or to let us wallow in postlapsarian dystopias than to write stories that envisage solutions, or even dig into the complexities. There is no magic gauntlet or golden sea-trident to wish away the climate crisis. But if Hollywood’s recent spate of ecologically conscious blockbusters is itself another form of greenwashing, then – as Cameron points out – we as paying viewers are ultimately responsible. Nothing illustrates this link between the entertainment industry and its consumers more directly than the rise of Netflix. Now, as cinema attendance continues to fall, we are ditching the collective viewing in favour of individual comfort that keeps the energy tab rolling every time we let the autoplay scroll through. It is the audiovisual equivalent of ditching public transport for private vehicles. The impact of this is huge: in 2018, video-related internet – 34% of which was accounted for by video-on-demand services – produced 300m tonnes of CO2; roughly the same as Spain. By 2022, Cisco estimates that 80% of internet traffic will be video-related in a field that is heating up as Disney+ and Apple TV+ chase down Netflix and Amazon. In his Globes speech, Gervais skewered the blind spot at the centre of Hollywood’s current tech obsession: “If Isis started a streaming service, you’d call your agent, wouldn’t you?” It seems like a matter of time before we are served up a Silicon Valley tech billionaire as blockbuster baddie, but that lets us off too easily. If we are demanding that Hollywood be honest about its ecological ledger, that means taking a long look in the black mirror, too."
"The impacts of the climate crisis are now clearly manifesting in ways beyond rising temperatures. In Australia, the conditions for severe bushfires are occurring far more regularly (hot days, dry land and high winds). And the country is now suffering its most intense bushfire season ever. The quantity of land burnt, the smoke pollution impacts, the temperatures and number of homes lost are all breaking historical records. At the same time, Australia is pioneering the denial of climate disaster. There is some interesting research around denialism. Researchers have essentially discovered a strong political divide when it comes to climate science: progressives are much more likely to accept it as fact than conservatives. And presenting climate deniers with scientific information in the hope that they’ll change their minds actually reinforces their rejection, because they are so taken aback by the information. This phenomenon affects solutions, too. If a policy proposal to reduce emissions conflicts with someone’s pre-existing beliefs – if it requires more government intervention in markets, for example – they tend to deny that the problem exists in the first place. Over the course of the past decade, Australia was a laboratory for this type of thinking. Research has shown that “climate scepticism gets substantial favourable exposure in mainstream Australian media”. As a result, Ipsos polling finds that Australia lags behind other nations in “acknowledging the threat of climate change”. And a renewable energy target of 42% – proposed in a landmark report by Australia’s chief scientist – was rejected by the conservative government partly because the number sounded too close to the opposition’s 50%. Rightwing media outlets in Australia have responded to the current bushfires by either refusing to give the story its due prominence or by spreading falsehoods. Specifically, there is a claim emerging that environmentalists have blocked hazard reduction efforts by supposedly opposing dry fuel loads being burned or manually removed. It isn’t one of those half-truths – there’s no truth in it at all. Once spread by a rightwing journalist over 10 years ago, it has been given a new lease of life as a meme on social media. There is a trajectory for memes like this: the idea emerges in the fever swamps of denialist groups, it slowly seeps into fringe blogs, and from those blogs into Australia’s rightwing media. Then fringe political players take it up, and it’s consequently absorbed by leaders from major parties. There is precedent for this phenomenon. In 2018, a fake Starbucks campaign supposedly offering free coffee to people of colour in the US was orchestrated on the 4chan message board; it was then featured on Fox News. There is already evidence emerging of 4chan boards trying to spread misinformation that fires are being started by Muslim terrorists. The latest story doing the rounds is that the fires have been caused by arsonists or even climate activists – and it has been particularly potent. It is currently somewhere between the blogs and the rightwing media; I imagine that it’ll be in the papers – and on the lips of politicians – shortly. In the comments of Sky News Australia tweets, the meme already dominates. The account of Gwyneth Montenegro, a “personal empowerment” influencer, tweeted to her 94k followers “climate terrorism, perhaps?”, which received thousands of retweets before being deleted. A Channel 7 Australia tweet declared that “Police are now working on the premise arson is to blame for much of the devastation caused this bushfire season”, receiving hundreds of retweets despite the voiceover in the clip stating: “7 News has been told that early indications are the south coast fires were likely started by lightning.” It was retweeted by the BBC journalist Andrew Neil with the judgment: “appalling”. The Australian government MP Craig Kelly appeared on Good Morning Britain, insisting that the climate crisis is not to blame for the shocking intensity of the country-wide disaster. Denialism comes directly from other leading Australian politicians. In 2013, this was more explicit, as when Tony Abbott said “fire is part of the Australian experience”, while then-environment minister Greg Hunt used Wikipedia to dismiss the link between the climate crisis and bushfires. The prime minister, Scott Morrison, always teeters at the edges of this style of disaster denialism, using coded digs that suggest there is nothing unusual about what’s going on. “We have faced these disasters before” and “I know how distressing that [smoke haze] has been, particularly for young people who haven’t seen it before” both stand out as examples of Morrison’s strategy: disguise straightforward climate denialism with appeals to “common sense”, collective memory or the misguided passions of young activists. When he won the election in May 2019, Morrison declared it a victory for the “quiet Australians”. That may have been true, but there are far fewer quiet Australians left today, as hundreds of thousands have experienced the largest mass evacuation in the history of the country. Still, anecdotal dispatches from Christmas dinner tables outline the success of rightwing memes in denying that Australia’s disaster is in any way related to the climate crisis. Morrison seals the deal, offering a comforting alternate reality that satisfies the craving to deny anything related to the climate crisis, whether it’s the science, the solutions or the impacts. If it works, it’ll kick off another decade of sustained inaction in a country that has incredibly disproportionate influence on the world’s climate system. This time, we must nip it in the bud. • Ketan Joshi is an Australian energy and climate science communicator"
"Mansour Rajeb is wrapping a plastic protective sheet around the branch of a date palm in his oasis near the village of Bchelli, in southern Tunisia. Tying it up, he lingers. “I’m worried,” he says. “The quality is getting worse. The dates are getting drier.” Like thousands of farmers across the region, the effects of the climate crisis and water scarcity are threatening his livelihood. “When the quality is poor, we receive lower prices. I’m earning less. This year, I’ll earn a third of last year, which was an average year.” On the road out of Bchelli, a gust of wind makes the sand rise like steam. Beyond the palm trees lies desert, a flat, barren terrain of scrub, rock and sand. Communities have survived here for thousands of years, but the changing environment may soon make it uninhabitable. Overall, temperatures here have risen by about 1C (1.8F) since 1988, according to data collected by the meteorological office in Tozeur, the capital of the region’s western district.  “Temperatures used to peak in August and then fall, but now the heat persists until October,” says Taieb Foudhaili of South Organic, a date exporting company based in Kebili. Given this pattern of warming, humidity levels are falling and the plants adapt by releasing water. The result, says Foudhaili, is a drier, poorer product. His company must now do more sorting to maintain quality standards. Global heating has also created shorter periods during which date palms can flower and pollinate, according to Nabila el-Kadri, an agronomist based in Kebili. As a consequence, Kadri has observed a decline in the productivity of dates per hectare. But it is not just rising temperatures causing anxiety. Over recent decades, and particularly after Tunisia’s 2011 revolution, unlawful plantations have spread like blots across the white landscape. The state has failed to exert proper controls. There are now 38,000 declared hectares (93,860 acres) of palm tree across the Kebili region, though Kadri believes the real figure could be as high as 50,000 hectares. More than half of the country’s dates are produced here. After olive production, dates are Tunisia’s second most valuable agricultural export, generating more than $200m (£154m) a year.  A consequence is growing water scarcity: date palms are thirsty. On each plantation, Kadri estimates there are between 100 and 140 palm trees per hectare, with each tree requiring roughly 20–25,000 cubic metres of water each year. Neither natural springs nor groundwater can meet this demand. Farmers are resorting to drilling and pumping water from aquifers. There are now about 30,000 wells across the country, some hundreds of metres deep. As many as half of these were drilled illegally, according to a 2017 report by Tunisia’s Ministry of Agriculture, and less than half of the water from wells is not renewable. Water levels are being increasingly overexploited across southern Tunisia.  “If we keep creating these new oases, with thousands of hectares of new trees, then over 10 to 15 years we won’t have any water left,” says Kadri. Some are already suffering. Rajeb says he has farmer friends who have already sold their trees in the new, poorly irrigated oases, because their crop was “so feeble”. Kadri says it is only a matter of time before date production as a whole will have to migrate north to Gafsa. Ultimately, the problems of global heating and water scarcity facing Tunisia’s date farmers arise from a similar myopia: a common failure to see things holistically. “We are only thinking about the product,” says Foudhaili, “when we should be thinking about the air, the tree and the soil. We need to change the way we think.” Many of Tunisia’s modern palm plantations are monocultures, producing the valuable Deglet Noor variety of date and little else. When this crop fails, farmers have little to fall back on. Lying in the shade of a palm tree in Chebika, 71-year-old Younes Belgasim is a figure of hope. His oasis is thriving. He is one of an estimated 18,000 people benefiting from a $5.7m World Bank project that launched in 2014. The project provided him with seeds for vegetables and fruit trees, helped him improve his land’s soil and irrigation, and allowed him to erect better fencing to protect his plot from local wild boars. The initiative supported Belgasim to restore a “three-level” system of inter-cropping. On his oasis, the date palms give shade to vines, banana, pomegranate and fig trees, while vegetables and wild grasses grow beneath. This system demands more from farmers, and it may deliver less immediate commercial payoff than date production. Both factors may deter farmers looking to earn their revenue in one date harvest season. But while some inter-cropping farmers in the oases say the system can demand more water, they also report that it maintains humidity levels, improves the soil quality and strengthens biodiversity. It also diversifies farmers’ assets. These successes suggest ecosystem-based farming can be a win-win: protecting farmers from climate, economic or disease-related shocks, while also preserving the natural environment. For this reason, Belgasim is more relaxed about the future. “It is getting hotter,” he says, “but I’m not worried about climate change.”"
"
Share this...FacebookTwitterDespite sea level rise, Tuvalu Islands surface area has grown 3% over the past decades
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
The South Sea islands are sinking. Send us money and visas for Australia and USA fast! That’s the underlying message of many media reports on the problem of sea level rise and their effects on the Pacific Coral Islands. Here science simply gets cast aside.
Since coral islands are made up of living organisms that have always lived just below the sea level, the islands “float” like ships on the surface of the ocean. When sea level goes up, so do the corals. This is already something you learn in geography lessons at school.
Paul Kench and his colleagues have now measured the shorelines of all 101 islands of Tuvalu for the last 40 years using satellite imagery. The result: The land area grew by just under 3% during this period, despite a fairly strong regional sea-level rise of 4 mm per year. Here is the abstract of the work that appeared in February 2018 in Nature Communications:
Patterns of island change and persistence offer alternate adaptation pathways for atoll nations
Sea-level rise and climatic change threaten the existence of atoll nations. Inundation and erosion are expected to render islands uninhabitable over the next century, forcing human migration. Here we present analysis of shoreline change in all 101 islands in the Pacific atoll nation of Tuvalu. Using remotely sensed data, change is analysed over the past four decades, a period when local sea level has risen at twice the global average (~3.90 ± 0.4 mm.yr−1). Results highlight a net increase in land area in Tuvalu of 73.5 ha (2.9%), despite sea-level rise, and land area increase in eight of nine atolls. Island change has lacked uniformity with 74% increasing and 27% decreasing in size. Results challenge perceptions of island loss, showing islands are dynamic features that will persist as sites for habitation over the next century, presenting alternate opportunities for adaptation that embrace the heterogeneity of island types and their dynamics.”

Source: Nature Communications
The discussion part of the paper states:
Results challenge existing narratives of island loss showing that island expansion has been the most common physical alteration throughout Tuvalu over the past four decades. Of significance, documented increases in island area over this period have occurred as the sea level has been rising.”
Share this...FacebookTwitter "
"A sperm whale’s “click” is the loudest sound produced by any animal – and it has an identifying dialect. In fact, according to a study published in Nature Communications, the whales aren’t born with different vocal chords or a bit of the sea particularly suited to a certain kind of click. They simply acquire their dialects from one another in the same way you or I might have taken on our parents’ accent – by copying what they hear. Sperm whales aren’t the only animals who learn like this. I have spent time with bottlenose dolphins, for instance, in many different locations around the world. One thing that has always struck me is that while these dolphins tend to do the same thing – such as hunt fish or play together – the way they do this can differ quite drastically between populations.  In the late 1990s, Andy Whiten best articulated this “feeling” that field biologists have had for a long time in his study of chimpanzees, the first systematic look at behavioural differences between populations.  Whiten and colleagues showed different groups of chimps did the same thing in drastically different ways, for example the way they used tools to catch ants. These differences spanned the whole activity repertoire of chimpanzees and the authors posited that the best way to explain this variation was simple: chimpanzees have culture. This discovery started the “culture wars”, largely between animal behaviourists and anthropologists, a debate which raised the question of when we could talk about cultural variations in animal behaviour. A scientific approach is to make predictions we can challenge with experiments and observations. For animals to have culture, the observed differences must not be explained by any other mechanisms. The first mechanism is simply genetics: these differences could be “hardwired” in the genetic differences between populations. The second mechanism is landscape differences: for example, a monkey will not be able to crack nuts with a rock if there are no rocks to hand. So the observed differences cannot be caused by the lack of opportunity or need caused by the animal’s environment. Since Whiten’s work, many people have registered differences in behaviour in a wide range of species, which we cannot attribute to these two factors. For example, the detailed genetic work of Michael Kruetzen and his team has helped to dispel the “hardwiring” argument for tool use in dolphins. Cultural differences are something we pick up from others and pass on, it is a social process. We acquire cultural habits from our social circles and importantly by not being exposed to the way other groups do the same thing. So in order for behavioural differences to be culture, they need to be socially learned. Social learning is again a process we now know exist in many of the species we suspect have culture.  Culture can also be a hindrance to forming social relationships; in our case the simple language barrier is often limiting the social interactions individuals can have. So culture and social structure are intertwined in some ways: you are more likely to pick up the habits of individuals with whom you interact; and the more you pick up these habits, the harder it becomes to interact with others outside your group. Back to whales. In the latest study, Maurício Cantor, Hal Whitehead and their colleagues show that cultural difference is the best way to explain why sperm whales live in multilevel societies. This social structure is best described as having several levels of organisation. In the case of sperm whales, individuals live with their extended families, which belong to clans. Whitehead, along with his colleagues, has elegantly shown over the past two decades that it is hard to explain the differences we observed between sperm whale clans without invoking culture.  In their new work, they show these clans are not just a passive aggregation of genetically related families. We need to invoke the influence of socially learned dialects in order to explain the observed clans which Whitehead has been following for two decades. This happened if individuals not only learned from others, but conformed to the most used dialect in their group. So clans are more likely to form because sperm whales learn dialects from their extended family. Multi-level societies emerge from cultural differences and this is another piece of evidence pointing at animal culture. So, animals have culture. Is that culture going to look the same as ours? No. Imagine spending your time underwater with limited vision, but great hearing, and a hankering for squid. The way you are going to interact with others is going to be different, what you can do with your environment is going to be different, your opportunities are going to be different. Different does not mean a “lesser culture”. It means that we have to work hard to leave our human references to understand that culture. Sperm whales learn from others’ habits, and dialects, which are going to shape their lives and influence the structure of their societies. Their culture is unique, so is ours, and the culture of bottlenose dolphins and chimpanzees."
nan
"
Share this...FacebookTwitterDespite hysterical headlines from the fake media claiming the weather is weirding out due to man-made climate change, recent studies show that it’s mostly superstition and that our modern climate in fact is well within the range of natural climate variability.
If one really wants to understand today’s weather and climate, it is essential to keep it in perspective with respect to what has happened over the past 1000 years or more. This is why a number of scientists are busy reconstructing past weather patterns at locations worldwide.
Central Asia climate likely dominated by natural cycles
First, a new study published in the journal Climate of the Past authored by a team of researchers led by Feng Chen of the Key Laboratory of Tree-ring Physical and Chemical Research of China Meteorological Administration found that drought records from western and eastern Central Asia capture the regional dry/wet periods and that analyses indicate the existence of centennial (100–150 years), decadal (50–60, 24.4 and 11.4 years) and interannual (8.0 and 2.0-3.5 years) cycles.
The authors suspect that they may be linked with climate forcings, such as solar activity and ENSO.

This would tell us that climate in Central Asia is greatly dependent on the natural factors of solar and oceanic cycles, and not CO2.
Western US droughts worse 1000 years ago
Another recent study just appeared in the Journal of Climate and was authored by a team of scientists led by Toby R. Ault, Department of Earth and Atmospheric Science, Cornell University. The findings indicate that the western United States was affected by several megadroughts during the last 1200 years, especially during the (MCA; 800 to 1300 CE).
The scientists found that such drought events are inevitable and occur purely as a consequence of internal climate variability. The researchers also concluded that the observed clustering of megadroughts of the Medieval Climate Anomaly were more likely to have been caused by either “external forcing or by internal climate variability”.
Canada: Scotian warm water “part of the natural variability “
The journal Continental Shelf Research published a study authored by scientists led by David Brickman of the Canadian Bedford Institute of Oceanography. The team examined the warm subsurface water temperatures in the Scotian Shelf region of Eastern Canada 2012, 2014, and 2015.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




They found that the observed warming trend should be considered as “part of the natural variability of the coupled atmosphere-ocean system”.
AMS: natural variability dominates observed trends
Another a team of scientists led by Elisabeth Kendon of the Met Office Hadley Centre in the United Kingdom published a paper in the journal of the American meteorological Society which found natural variability appears to dominate current observed trends over the southern United Kingdom (including an increase in the intensity of heavy summer rainfall over the last 30 years).
The authors, citing Sarojini et al., 2016, confirmed that the “attribution of rainfall trends to human influence on local and regional scales is not yet possible”. More uncertainty over the human fingerprint on global climate.
Central Europe precipitation anomalies even greater long ago
Finally a paper published in the International Journal of Climatology and authored by Petr Dobrovolný of the Department of Geography, Masaryk University, Czech Republic, reconstructed precipitation in Central Europe (Czech Republic).
 

Source: Dobrovolný et al., 2018.
Their findings revealed two long periods of low precipitation variability, in the 13th–14th centuries and 1630s–1850s, and that precipitation anomalies of larger amplitude and longer duration occurred in the earlier part of the last millennium than those found in the instrumental period. The new reconstruction does not indicate any exceptional recent decline in MJJ precipitation.
In summary, the new studies from all around the world show that weather extremes were as bad or worse in the past than they are currently. Today’s modern climate is in fact well in phase with natural variability.
The papers mentioned above are all presented by Kenneth Richard here.
Share this...FacebookTwitter "
"Fracking is relatively new and hi-tech – and even experts armed with cutting-edge instruments are only just beginning to get their heads around some of the risks involved. No one really knows exactly what it will mean in the medium to long-term. It’s not just that there aren’t enough informed opinions – there isn’t enough conclusive research anywhere in the world to enable anyone to make truly informed decisions on fracking and its risks. So why, then, would a county council in the UK be any different? The issue has come to a head as council officials in Lancashire, north-west England, decide on whether to let energy firm Cuadrilla begin shale gas operations at two sites in the region. Over the past decade, hydraulic fracturing of deep gas-rich shale formations – fracking – has become widespread in both the US and in Europe where there are estimated to be large reserves. Fracking relies on complex technological advances in horizontal drilling and hydraulic fracturing, where pressurised liquid is used to break open underground rocks and release natural gas. It is these advances which have made the production of shale gas economically viable. And fracking can indeed bring considerable benefits in some areas: significant economic growth, reduced carbon emissions and dependence on foreign oil imports. Yet scientists have uncovered numerous examples of potential environmental problems associated with fracking. The truth is that our current understanding of the links between fracking and freshwater and air contamination is still too limited to effectively reduce risks. Given this limited understanding, it seems unreasonable to expect regional authorities, like Lancashire County Council, to take on the burden of decision-making. Different risks are associated with different stages of the process. During exploration and drilling these include the destruction of various habitats and the contamination of drinking water due to spills, well leaks and drilling sludge stored on site, the depletion of freshwater supplies, leaks of volatile organic compounds, ozone and methane from well heads and machinery. During the fracturing and gas production stage, the major issues include surface water contamination, toxic chemicals in the fracturing mixture, depletion of water supplies, methane leakage, increased seismic activity, contamination of both groundwater and surface water, and increased emissions of greenhouse gases. Longer term, there is the risk of watershed contamination, continued leakage of methane and radioactive compounds in waste water. There is also the threat to human health and the environment from prolonged exposure to contaminants – not to mention reduced property values. The US experience should not be used as a model. There, the shale gas boom has in part leveraged the 2005 Energy Policy Act, which made fracking exempt from requirements of the 1974 Safe Drinking Water Act and, practically, limited research and controls on groundwater pollution. A study published in April 2015 in the Proceedings of the National Academy of Sciences in the US reports cases of groundwater pollution due to fracking in Pennsylvania. The detection of this was made possible only through the use of cutting-edge instrumentation not available in most commercial laboratories.  Another document released in early June by the US Environmental Protection Agency contains the results of a long-term study on the potential impact of fracking on groundwater resources. Although it shows that, thus far no consistent evidence has been found of widespread groundwater contamination due to fracking, the EPA recognises that this might well be an underestimation of these effects due to a lack of pre and post-development data, the short-term duration of available studies and limited or undisclosed information on fracking activities. These accounts confirm our limited scientific knowledge on the environmental impact of fracking. So extreme caution is needed before this technique is implemented safely in the UK. Lancashire County Council’s recommendation to allow shale gas exploration at one of the two sites may be allowed within the UK’s regulations, yet even so the council isn’t making a truly informed decision – there’s no such thing. We are surely expecting too much of regional planning authorities that cannot have the necessary expertise or knowledge needed to make a decision on the limited data that currently exists and perform site monitoring using conventional techniques. In order to fully understand fracking risks in the UK independent pilot studies are necessary before the technology can be safely implemented at a scale that makes it economically viable."
"The Trump administration on Thursday unveiled a plan to speed permitting for major infrastructure projects like oil pipelines, road expansions and bridges. It is one of the biggest deregulatory actions of the president’s tenure and comes at the cost of greatly narrowing the use of one of the country’s landmark environmental laws, especially assessments of how developments could exacerbate the climate crisis. Donald Trump is proposing changes that could allow projects ranging from oil pipelines to mines to move forward with far less federal review of their impact on the environment. The plan, released by the White House Council on Environmental Quality (CEQ), would help the administration advance big energy and infrastructure projects, such as the Keystone XL oil pipeline or roads, bridges and federal buildings. “For the first time in over 40 years today we are issuing a new rule under the National Environmental Policy Act (NEPA) to completely overhaul the dysfunctional bureaucratic system that has created these massive obstructions,” Trump said at the White House on Thursday. The proposal to update how NEPA, the 50-year bedrock federal environmental law, is implemented as part of Trump’s broader actions to cut regulations and oversight, a huge rollback effort that has dismayed and enraged environmentalists. Trump on proposed NEPA rollback: ""This is just the beginning. We will not stop until our nation's gleaming new infrastructure has made America the envy of the world again. It used to be the envy of the world, and now we're like a third world country. It's really sad."" “This proposal affects virtually every significant decision made by the federal government that affects the environment,” said the interior secretary, David Bernhardt, a former fossil fuels lobbyist. The proposed rule says federal agencies would not need to factor in the “cumulative impacts” of a project, which could include its impact on climate change, making it easier for major fossil fuel projects to sail through the approval process and avoid legal challenges. A statement from the League of Conservation Voters (LCV) president, Gene Karpinski, said: “President Trump is trying yet again to sell out the health and wellbeing of our children and families to corporate polluters. This misdirected proposal to change the implementation of the National Environmental Policy Act is one of the most egregious actions the Trump administration has taken to limit the federal government’s response to climate change yet.” He warned the implications for access to clean air and clean water and for public input “could be dire”. The proposal would also put one federal agency in charge of overseeing the review process, instead of giving multiple agencies oversight of the process and set a two-year deadline for environmental impact studies to be completed and a one-year deadline for less rigorous environmental assessments. Trump’s efforts to cut regulatory red tape have been praised by the industry. But they have so far largely backfired by triggering waves of lawsuits that the administration has lost in court, according to a running tally by the New York University School of Law’s Institute for Policy Integrity. Over the last few years, federal courts have ruled that NEPA requires the federal government to consider a project’s carbon footprint in decisions related to leasing public lands for drilling or building pipelines. Other proposed changes include widening the categories of projects that can be excluded from NEPA altogether. According to CEQ, the average length of a full-blown Environmental Impact Statement is currently 600 pages and takes 4.5 years to conclude. US federal agencies prepare approximately 170 such assessments per year. Trump, a commercial real estate developer before becoming president, frequently complained that the NEPA permitting process took too long. “It’s big government at its absolute worst,” Trump said of NEPA. Some of the country’s biggest industry groups, including the Chamber of Commerce and the American Petroleum Institute, also have complained about lengthy permitting delays. Environmental groups warned the plan will remove a powerful tool to protect local communities from the adverse impacts of a hastily designed and reviewed project. “Today’s destructive actions by Trump, if not blocked by the courts or immediately reversed by the next president, will have reverberations for decades to come,” said Rebecca Concepcion Apostol, US program director at Oil Change International, an environmental group. The plan will go through a public comment period before being finalized. Environmental groups are expected to challenge the final proposal."
"It’s encouraging to find agreement across the political divide on the potential of new technologies to combat climate change, reduce animal suffering and supplant massive agricultural subsidies. The Adam Smith Institute recently released a paper on the topic that made many of the same points as George Monbiot (Lab-grown food will end farming – and save the planet, Journal, 8 January). One overlooked benefit of lab-grown food is that it may help the UK tackle the crisis in housing affordability. As farming is superseded by precision fermentation, the significant amount of land currently used for livestock farming (including parts of the green belt) will be freed up for development in places that people actually want to live.  However, we’d take a different lesson from the promise of lab-grown meat. Free-market environmentalism and harnessing the power of innovative technologies – supported by market-based measures like a border-adjusted carbon tax – can successfully tackle the problem of manmade climate change without fundamentally uprooting the way we run society. Saving the planet doesn’t have to cost us the earth.Daniel PryorAdam Smith Institute • There are fundamental reasons why the Solar Foods system that George Monbiot refers to can’t compete with plants for sustainable food production. The supply of minerals for bacteria has to be assembled chemically, with all the chemical industry’s environmental downsides. By contrast, plant roots pull the right minerals in the right proportions out of mixed-up traces in the environment, using solar energy to fuel selective concentration at no cost, generating no heat or chemical pollution and requiring no purified water. The machinery by which plants acquire raw materials is itself built by the plant using solar energy in a non-polluting process, not made in a factory. Likewise, the light-energy-trapping machinery of plants is assembled on a planetary scale, with none of the unwelcome by-products of heat and chemical pollution associated with the fabrication of solar cells and wind turbines, and with the generation of hydrogen from water by electricity. The claim that “the hydrogen pathway used by Solar Foods is about 10 times as efficient as photosynthesis” is meaningless if we’re not told which aspects of the two processes are being compared. Unlike food from plants, no industrially generated food could provide the right mix of dietary constituents essential for health, such as balanced vitamins, minerals and bulk fibre. Supplying these as additives cancels any advantage of electric food. Plants are still the only source of food with long-term sustainability.David E HankeCambridge • There is much food for thought in George Monbiot’s paean to precision fermentation. He has undoubtedly made the case that agricultural business as usual is not an option. However, his techno-utopianism needs to come with a hefty side order of the precautionary principle. He acknowledges the likely impact on the agricultural sector, arguing that governments should “help farmers into other forms of employment” (that worked out well for the miners and steelworkers), and that “strong anti-trust laws” will limit the commercial rapaciousness of the new producers (ditto the digital giants and fossil fuel companies). Millions of people globally grow, hunt or raise food not to make money, but to feed their families. Where will they get the cash to buy the new stuff? The science may seem simple, but the politics is a minefield. On top of that we are talking about food, not fuel. Vitamin supplements are less effective for health and wellbeing than a varied, mostly plant-based diet. Will foods based on individual proteins meet all our dietary requirements as well as the complex foods we have evolved to consume? What will be the impact on our gut microbiomes? Or our immune systems? Taste, smell, colour and texture all play a part in palatability: enjoyment is a critical part of our food psychology. No doubt the food processing industry will rise to the challenge of making farmfree food fun, but it could take decades. A rapid switch to such foods would be a massive experiment on the global public: there would need to be clinical trials. We will not reap the potential advantages if the consequences are not fully explored.Georgina FerryOxford • Globally, over 1.3 billion people rely on livestock farming for their livelihoods, either as farmers or as part of the livestock food supply chain. Meat and dairy have known health benefits, and consumption of animal-based food during early life has been linked with lower levels of malnutrition and improved health outcomes. In many ways, British farming is the envy of the world, with high levels of sustainability and sensible land use – for example, most sheep are raised on land that could not be used for any other purpose – and the National Farmers’ Union has committed to the sector being carbon neutral by 2040. It is important to acknowledge that certain types of livestock farming may have issues with sustainability and climate change. But it is not true of all farming systems; and the issues that do exist are being dealt with using the latest research into genetics and biotechnology – for example, recent research has shown that certain types of seaweed can reduce methane emissions from cattle to close to zero. High-profile movements such as EAT-Lancet and Veganuary gain widespread press coverage, yet the fact that the World Health Organization rejected the EAT-Lancet recommendations was largely unreported, and a recent analysis of sales data showed that Veganuary in 2019 was not associated with a reduction in meat and dairy sales. Farmer data also shows that increased sales of alternative milks have not seen a corresponding reduction in dairy sales. The global food system, consumer choices and climate change are incredibly complex issues, and anyone who proposes simple solutions is almost certainly not in possession of all the relevant facts and data. Livestock are an important part of humanity’s future food needs.Prof Mick WatsonUniversity of Edinburgh • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitterNowadays the usual suspects are busily peddling the idea that Hurricane Florence’s intensity is due to climate change.
For example climate activist Stefan Rahmstorf of the alarmist Potsdam Institute blames Florence on global warming, telling the online Potsdamer Nachrichten (PNN) here: “In fact many of the strongest storms we have ever seen have occurred in the past years.”
Alarmist claims go down in flames
The German media and climate science establishment are out in full force implying recent hurricanes are mostly manmade and getting stronger and more frequent.
However, just as Kenneth Richard showed yesterday by presenting more than a dozen recent papers, when we look at the observed data, all these alarmist claims go down in flames.
Observed data refute alarmist/activist scientists
Firstly, climate ambulance chasing scientists, such as Messieurs Stefan Rahmstorf and Dim Coucou, like pretending storms are intensifying due to manmade global warming. Yet two days ago I tweeted a table showing that 75% of the most powerful hurricanes impacting the US actually happened before 1970, a time when CO2 was at supposedly safe levels:

9 of top 12 most powerful hurricanes making landfall in USA HAPPENED BEFORE 1970!! pic.twitter.com/GLR5Ksd8yE
— P Gosselin (@NoTricksZone) September 12, 2018

Although some people may think Florence is a major hurricane, it in fact made landfall as a Category 1 storm only – a far cry from the Category 4 many were warning us about just days ago — e.g. Erik Holthaus.
Hurricane number and strength not up
Prof. Philip Klotzbach recently tweeted two charts depicting the number of US landfalling hurricanes (Category 1-5) and major hurricanes (Category 3-5). If you’re a climate alarmist, then you may want to first take a seat before reading further:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Source: Klotzbach et al 2018
According to Klotzbach, “Since 1900 neither observed CONUS [Continental United States] landfalling hurricane frequency nor intensity show significant trends, including the devastating 2017 season.”
An unprecedented major hurricane absence
What is unprecedented is the long 12-year period from 2005 to 2017 which saw not a single major hurricane hitting the US. This is probably the most devastating and frustrating fact for the global warming ambulance chasers. That’s a glaring statistic that’s impossible to alter.
Western North Pacific cyclone frequency down 25%
The story is much the same in the North Western Pacific, where the following chart shows us cyclone frequency has been much lower over the past two decades compared to the two decades prior.

Source: Zhao et al, 2018
And using the data from the Japanese Meteorological Agency (JMA), skeptic blogger Kirye also tweeted that the number of typhoons being formed has declined modestly over the years:

Number of typhoons on the decline. Source: Kirye.
Hooligan storms
Cyclone bedwetters have even suggested that Florence’s odd track and stall at the Carolina coast is also a sign of climatatic weirding. Yet, weird storm tracks have always occurred and Florence is just run of the mill. For example, check out Typhoon Wayne back in 1986, which ran amok across the Western Pacific like a drunken hooligan:

Source: https://maps.wunderground.com/blog/
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe days of unlimited speed on Germany’s famed autobahns are indisputably coming to an end – probably soon. And thank God!
Hat-tip: achgut.com.
The online Mitteldeutche Zeitung MZ) here reports the Evangelical Church in Central Germany (EKM) is pushing to impose a speed limit on German autobahns, the motorways where drivers  in certain stretches are free to drive as fast as they dare.

The days of no speed limit on Germany’s famed autobahns are about to end. Photo: Darkone, CC BY-SA 2.5, (Wikipedia)
Quoting Christian Fuhrmann of the EKM, the MZ reports that cars should she limited to 130 km/hr and the Church will mobilize to send a public petition to the German Bundestag.
The MZ adds that the petition will be launched on Ash Wednesday and 50,000 signatures are needed.
According to the MZ: “The Central German Church covers large parts of Saxony-Anhalt and Thuringia and has about 700,000 members.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Church’s main reason for limiting the speed of cars to 130 km/hr on the autobahn is to reduce greenhouse gas emissions and exhaust fumes, which the Church says would translate to an emissions reduction of 2 – 2.5%. Also the high speeds and associated braking leads to more fine particle emissions from tire abrasion on asphalt surfaces, as well as more noise.
“A Confession to the Creator”
The MZ also reports that potential CO2 savings could be 2 million tonnes annually. Currently Germany emits some 900 million tonnes of CO2 equivalent gases annually.
The MZ adds:
“We see a world responsibility for ourselves, assigned by God,” said state bishop Ilse Junkermann. Mankind is destroying the foundations of life. The fight against it is “a confession to the Creator”.
Makes sense from safety alone
Personally I support a 130 km/hr limit, but not because of the silly climate reasons. Overall a limit is far safer, and some studies show it would likely improve over traffic flow efficiency and help reduce long traffic jams, which often result from messy car accidents. In the end less traffic jams means reaching your destination just as quickly as you would madly driving at breakneck speeds.
Also an autobahn speed limit could mean lower maintenance costs because the surface specifications for unevenness could be relaxed a bit. Any unevenness really becomes a factor when a vehicle is flying at 280 km/hr. With speeds at 130 km/hr, road crews would not have to be sent out to “repair” the road, which in turn means lane closures and again more traffic obstruction and slowdown.
One compromise could be to tolerate speeds of 160 km/hr (100 mph) during times and areas of light traffic.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe year 2018 could mark the beginning of the end of climate change alarmist reporting.  Projections of catastrophic melting of the ice sheets and sea level rise swallowing up the Earth’s coasts are increasingly undermined by observations. 

Extensive glacier and ice sheet melt resulting in an accelerated sea level rise threatening the world’s population centers living along the coasts is indeed the most legitimate threat posed by a global-scale warming trend.
Alarming sea level rise predictions abound.   Several meters of sea level rise due to catastrophic melting of the Greenland and Antarctic ice sheets have been predicted based on anthropogenic CO2 emissions scenarios.
For example, claims that we shall experience 260 centimeters (2.6 meters) of global sea level rise by 2100 unless we dramatically curtail our fossil fuel consumption have been published by authors like Dr. Michael Mann and Dr. Richard Alley (Garner et al. 2017).  These same authors even suggest seas will rise by 17.5 meters in the next 180 years (Mörner et al., 2018).

Image Source: Mörner et al., 2018
Despite the hackneyed practice of reporting “staggering” ice sheet melt for both Greenland and Antarctica in recent decades, the two polar ice sheets combined to add just 1.5 centimeters to sea level rise between 1958 and 2014 (graph from Frederikse et al., 2018) as global sea levels only rose by “1.5 ± 0.2 mm yr−1 over 1958–2014 (1σ)” or “1.3 ± 0.1 mm yr−1 for the sum of contributors”.
That’s about 7.8 centimeters (3.1 inches) of global sea level change in 56 years.
Even more significantly, satellite observations all across the globe show that the coasts of islands and sandy beaches and continents have not only not been shrinking for the last several decades, they’ve been stable to growing on net.  Along the world’s coasts, there is today more land area above sea level than there was in the mid-1980s (Donchyts et al., 2016), leaving scientists “surprised”.
“We expected that the coast would start to retreat due to sea level rise, but the most surprising thing is that the coasts are growing all over the world,” said Dr Baart.  “We’re were able to create more land than sea level rise was taking.”  (BBC press release for Donchyts et al., 2016)
Dr. Nils-Axel Mörner – a world-renown sea level expert who headed the Department of Paleogeophysics & Geodynamics at Stockholm University – and 3 other co-authors have concluded that sea level rise projections of 2.6 m by 2100 and 17.5 m by 2300 are “deeply flawed” and “not rooted in facts” (Mörner et al., 2018).
What follows is a very abbreviated summary of the dozens of alarmism-quelling papers published in 2018 pertaining to ice sheet melt, sea level rise, and coastal expansion.

Mörner et al., 2018
Estimating Future Sea Level Changes, Assessing Coastal
Hazards, Avoiding Misguiding Exaggerations, and
Recommending Present Coastal Management
“Tide-gauges offer records of the relative changes in sea level. Out of a total of about 2300 stations (PSMSL), “a global set of ~300 tide gauges that serves as the backbone of the global in situ sea level network” in the Global Sea Level Observing System (GLOSS). There is no objective, straightforward solution for estimating a global mean value. The University of Colorado chose 184 global tide-gauge records. Their rate of distribution has a marked peak in the zone from ±0.0 to +2.0 mm/yr with a mean value at +1.14 mm/yr. Because the majority of stations used include a component of regional subsidence and local sediment compaction, the true mean sea level value should be <+1.14 mm/yr. … Satellite altimetry is a new and important tool, which reconstructs the entire ocean surface changes. But nowhere do the measurements agree with coastal observations. Satellite altimetry exceeds tide-gauge records by about 300%. There have even been accusations of data manipulation [Mörner, 2018].”
“Garner et al. (2017) propose SLR of up to 2.6 m by 2100, 10.5 m by 2200, and 17.5 m by 2300 (Fig. 1). These SLRs are far greater than those that occurred during catastrophic melting of immense ice sheets at the end of the Pleistocene, so the question arises, where will all the water come from to produce these very large SLRs? Melting of small, temperate, alpine glaciers wouldn’t produce anywhere near the SLRs projected by Garner et al., so the only possible sources of water are the Antarctic and Greenland ice sheets. The projections of Garner et al. of SLR of 7–8 m per century would require about seven times the end of the Pleistocene SLR when immense ice sheets were collapsing under warming of up to 20 °F in less than a century. To get these huge SLRs would require melting of an immense amount of ice from the Antarctic ice sheet. The average winter temperature in Antarctica is about –55 °F and temperatures have reached as low as 135 °F, so any significant melting of the Antarctic ice sheet would require 55° + 32° = 87 °F of warming just to get to the freezing point plus another 10 degrees or so to melt much ice. So Antarctica would have to warm up by 90–100 °F to melt enough ice to substantially raise sea level.”
“Hazard prediction is important, but the essence of science is the testing of predictions by comparison with observational facts. Without that validation, predictions are really just idle speculations. The future sea level values given by Garner et al. [2017] are deeply flawed and therefore misleading for coastal planning. They must be rejected as nonsense. Sea level research has its own well established means of recording past and present sea level changes and from those data to estimate likely sea level changes in the future. There are also physical frames to consider, some of which are absolute and must not be violated. … [T]he values given by Garner et al. [2017] violate not only physical laws but also accepted scientific knowledge of glaciology. Therefore, their values must not be considered in coastal planning. We also question the reviewing process.”
“Is Greenland warming and the ice sheet melting away? Chylek et al. [2004] analyzed temperature histories of coastal stations in southern and central Greenland having almost uninterrupted temperature records between 1950 and 2000 and found that coastal Greenland’s peak temperatures occurred between 1930 and 1940, after which subsequent decrease in temperature was so substantial and sustained that current coastal temperatures “are about 1°C below their 1940 values.” At the summit of the Greenland Ice Sheet, the summer average temperature has decreased at the rate of 2.2 °C per decade since the beginning of measurements in 1987. Two weather stations, Godthab Nuu and Angmagssalik, on opposite coasts of Greenland, have the longest records, dating back more than a century. Both show similar annual temperature patterns–strong warming in the 1920 and 1930s followed by cooling from 1950 to 1980 and warming from 1980 to 2005. The significance of these recent temperature records is that they show that temperatures in the past several decades have not exceeded those of the 1930s and Greenland temperatures have fluctuated normally in step with global temperatures changes [Easterbrook, 2016].”
“Satellite and surface temperature records and sea surface temperatures show that both the East Antarctic Ice Sheet and the West Antarctic Ice Sheet are cooling, not warming. Satellite and surface temperature measurements show that the East Antarctic Ice Sheet is cooling, not warming, and glacial ice is increasing, not melting. Satellite and surface temperature measurements of the southern polar area show no warming over the past 37 years. Growth of the Antarctic ice sheets means sea level rise is not being caused by melting of polar ice and, in fact, is slightly lowering the rate of rise. Satellite Antarctic temperature records show 0.02 °C/decade cooling since 1979. The Southern Ocean around Antarctica has been getting sharply colder since 2006. Antarctic sea ice is increasing, reaching all-time highs. Surface temperatures at 13 stations show the Antarctic Peninsula has been sharply cooling since 2000. This indicates that the hypothetical “enhanced Antarctic Ice Sheet contribution” of Garner et al. [2017] is a serious mistake (Fig. 1) not anchored in facts.”



2. Ice melt from Greenland, Antarctica added just 1.5 cm to sea levels since 1958 
“For the first time, it is shown that for most basins the reconstructed sea level trend and acceleration can be explained by the sum of contributors, as well as a large part of the decadal variability. The global-mean sea level reconstruction shows a trend of 1.5 ± 0.2 mm yr−1 over 1958–2014 (1σ), compared to 1.3 ± 0.1 mm yr−1for the sum of contributors.” (Frederikse et al.,2018)


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





 
3. Ice mass gains in the rapidly-cooling Antarctic Peninsula since 2009  
“Two small glaciers on James Ross Island, the north-eastern Antarctic Peninsula, experienced surface mass gain between 2009 and 2015 as revealed by field measurements. A positive cumulative surface mass balance of 0.57 ± 0.67 and 0.11 ± 0.37 m w.e. was observed during the 2009–2015 period on Whisky Glacier and Davies Dome, respectively. …  Ambrožová and Láska (2016) reported a significant decrease (0.03–0.15°C a−1 [-0.3 to -1.5°C per decade]) in the temperature along the AP [Antarctic Peninsula] over the 2005–15 period with the most prominent cooling at the Bibby Hill station on JRI [James Ross Island]. … The cumulative mass gain of the glaciers around the northern AP [Antarctic Peninsula] indicates a regional change from a predominantly negative surface mass balance in the first decade of the 21st century to a positive balance over the 2009–15 period. The change in the glacier mass balance follows a significant decrease in the warming rates reported from the northern AP [Antarctic Peninsula] since the end of the 20th century. The mass gain is also consistent with the regional trend of climate cooling on the eastern side of the AP [Antarctic Peninsula].”   (Engel et al., 2018)

4. Collapse of Larsen C glaciers would add 0.25 to 0.42 of a cm to sea levels
“Here we apply numerical ice-sheet models of varying complexity to show that the centennial sea-level commitment of Larsen C embayment glaciers following immediate shelf collapse is low ( < 2.5 mm to 2100,  < 4.2 mm to 2300) [0.25 to 0.42 of a cm added to sea levels by 2100/2300 with Larsen C collapse]. Despite its large size, Larsen C does not provide strong buttressing forces to upstream basins and its collapse does not result in large additional discharge from its tributary glaciers in any of our model scenarios. In contrast, the response of inland glaciers to a collapse of the George VI Ice Shelf may add up to 8mm to global sea levels by 2100 and 22mm by 2300 [0.8 cm to 2.2 cm] due in part to the mechanism of marine ice sheet instability. Our results demonstrate the varying and relative importance to sea level of the large Antarctic Peninsula ice shelves considered to present a risk of collapse.” (Schannwell et al., 2018)
5. East Antarctica is gaining mass – it takes “millions of years” for “even partial retreat” 
“The East Antarctic ice sheet may be gaining mass in the current, warming climate. The palaeoclimate record shows, however, that it has retreated during previous episodes of prolonged warmth. … In terms of immediate sea-level rise, it is reassuring that it seems to require prolonged periods of lasting hundreds of thousands to millions of years to induce even partial retreat.” (Nature Geoscience, 2018)
6. No glacier-melt trend for Antarctica’s largest sea level rise contributor in 70 years
“Pine Island Glacier is the largest current Antarctic contributor to sea level rise. Its ice loss has substantially increased over the last 25 years through thinning, acceleration and grounding line retreat. However, the calving line positions of the stabilizing ice shelf did not show any trend within the observational record (last 70 years) until calving in 2015 led to unprecedented retreat and changed alignment of the calving front. … Despite the thinning and flow acceleration of PIG [Pine Island Glacier], and sustained, rapid thinning of the ice shelf over at least the past 25 years the position of the ice front had not shown any clear trend over 68 years of observations prior to 2015 (Bindschadler, 2002;MacGregor et al., 2012;Rignot, 2002).”  (Arndt et al., 2018)
7. East Antarctica gaining mass…projections due to ice sheet melt “overestimated”
“East Antarctic Ice Sheet (EAIS) mass balance is largely driven by snowfall. Recently, increased snowfall in Queen Maud Land led to years of EAIS mass gain. It is difficult to determine whether these years of enhanced snowfall are anomalous or part of a longer-term trend, reducing our ability to assess the mitigating impact of snowfall on sea-level rise. We determine that the recent snowfall increases in western Queen Maud Land (QML) are part of a long-term trend (+5.2±3.7% decade-1) and are unprecedented over the past two millennia. Warming between 1998 and 2016 is significant and rapid (+1.1±0.7 °C decade-1). Using these observations, we determine that the current accumulation and temperature increases in QML from an ensemble of global climate simulations are too low, which suggests that projections of the QML [Queen Maud Land] contribution to sea-level rise are potentially overestimated with a reduced mitigating impact of enhanced snowfall in a warming world.”  (Medley et al., 2018)
8. Globally, 73.1% of island coasts are stable, 15.5% are growing, and 11.4% are shrinking 
“This review first confirms that over the past decades to century, atoll islands exhibited no widespread sign of physical destabilization by sea-level rise. The global sample considered in this paper, which includes 30 atolls and 709 islands, reveals that atolls did not lose land area, and that 73.1% of islands were stable in land area, including most settled islands, while 15.5% of islands increased and 11.4% decreased in size. Atoll and island areal stability can therefore be considered as a global trend. Importantly, islands located in ocean regions affected by rapid sea-level rise showed neither contraction nor marked shoreline retreat, which indicates that they may not be affected yet by the presumably negative, that is, erosive, impact of sea-level rise. .. These results show that atoll and island areal stability is a global trend, whatever the rate of sea-level rise. Tuvaluan atolls affected by rapid sea-level rise (5.1 mm/yr; Becker et al., 2012) did not exhibit a distinct behavior compared to atolls located in areas showing lower sea-level rise rates, for example, the Federated States of Micronesia or Tuamotu atolls.”  (Duvat et al., 2018)
9. Since 1984, 48% of the globe’s shorelines have been stable, 28% are growing, and 24% are shrinking
“The application of an automated shoreline detection method to the sandy shorelines thus identified resulted in a global dataset of shoreline change rates for the 33 year period 1984–2016. Analysis of the satellite derived shoreline data indicates that 24% of the world’s sandy beaches are eroding at rates exceeding 0.5 m/yr, while 28% are accreting and 48% are stable. …. Erosion rates exceed 5 m/yr along 4% of the sandy shoreline and are greater than 10 m/yr for 2% of the global sandy shoreline. On the other hand, about 8% of the world’s sandy beaches experience significant accretion (>3 m/yr), while 6% (3%) are accreting more than 5 m/yr (10 m/yr). … Taking a continental perspective, Australia and Africa are the only continents for which net erosion (−0.20 m/yr and −0.07 m/yr respectively) is found, with all other continents showing net accretion.”  (Luijendijk et al., 2018)

10. “Despite sea-level rise” there has been a “land area increase in eight of nine atolls” since 1971
“We specifically examine spatial differences in island behaviour, of all 101 islands in Tuvalu, over the past four decades (1971–2014), a period in which local sea level has risen at twice the global average (Supplementary Note 2). Surprisingly, we show that all islands have changed and that the dominant mode of change has been island expansion, which has increased the land area of the nation. … Using remotely sensed data, change is analysed over the past four decades, a period when local sea level has risen at twice the global average [<2 mm/yr-1] (~3.90 ± 0.4 mm.yr−1). Results highlight a net increase in land area in Tuvalu of 73.5 ha (2.9%), despite sea-level rise, and land area increase in eight of nine atolls.”  (Kench et al., 2018)

11. Bangladesh coastal land area has expanded by 7.9 km2 per year during 1985-2015
“This paper draws upon the application of GIS and remote sensing techniques to investigate the dynamic nature and management aspects of land in the coastal areas of Bangladesh. … This research reveals that the rate of accretion [coastal land growth] in the study area is slightly higher than the rate of erosion. Overall land dynamics indicate a net gain of 237 km2 (7.9 km2annual average) of land in the area for the whole period from 1985 to 2015.”  (Ahmed et al., 2018)
12. 54% of ‘vulnerable’ SW Pacific Islands studied had shorelines that expanded from 2005-2015
“Summary: Atoll islands are low-lying accumulations of reef-derived sediment that provide the only habitable land in Tuvalu, and are considered vulnerable to the myriad possible impacts of climate change, especially sea-level rise. This study examines the shoreline change of twenty-eight islands in Funafuti Atoll between 2005 and 2015 … Most of the islands remained stable, experiencing slight accretion or erosion or a combination of both over time. The total net land area of the islands increased by 1.55 ha (0.55%) between 2005 and 2010, and it has decreased by 1.90 ha (0.68%) between 2010 and 2015, resulting in a net decrease by 0.35 ha (0.13%). … Results indicate a 0.13% (0.35 ha) decrease in net island area over the study time period, with 13 islands decreasing in area and 15 islands increasing in area.  Substantial decreases in island area occurred on the islands of Fuagea, Tefala and Vasafua, which coincides with the timing of Cyclone Pam in March, 2015.”  (Hisabayashi et al., 2018 )
Share this...FacebookTwitter "
"Nearly five billion people worldwide will use a smartphone by 2020. Each device is made up of numerous precious metals and many of the key technological features wouldn’t be possible without them. Some, like gold, will be familiar. Others, such as terbium, are less well-known. Mining these metals is a vital activity that underpins the modern global economy. But the environmental cost can be enormous and is probably far greater than you realise. Let’s walk through some of the key metals in smartphones, what they do, and the environmental cost of getting them out of the ground. Iron (20%), aluminium (14%) and copper (7%) are the three most common metals by weight in your average smartphone. Iron is used in speakers and microphones and in stainless steel frames. Aluminium is used as a lightweight alternative to stainless steel and also in the manufacture of the strong glass used in smartphone screens. Copper is used in electric wiring.  However, enormous volumes of solid and liquid waste (termed mine “tailings”) are produced when extracting these metals from the earth. Typically, mine tailings are stored in vast impoundment structures that can be several square kilometres in area. Recent catastrophic mine tailings spills highlight the danger of improper construction methods and lax safety monitoring. The largest spill on record occurred in November 2015 when a dam collapsed at an iron ore mine in Minas Gerais, Brazil, releasing approximately 33m cubic metres (enough to fill 23,000 Olympic swimming pools) of iron-rich waste into the River Doce. The waste inundated local villages killing 19 people and travelled 650km until it reached the Atlantic Ocean 17 days later. This was just one of 40 mine tailings spills that have occurred in the past decade and the long-term ecological and human health impacts remain largely unknown. One thing is clear though – as our thirst for technology increases, mine tailings dams are increasing in number and size, and so is their risk of failure. Gold and tin are common in smartphones. But mining of these metals is responsible for ecological devastation from the Peruvian Amazon to the tropical islands of Indonesia.  Gold in smartphones is used primarily to make connectors and wires but gold mining is a major cause of deforestation in the Amazon. Furthermore, extraction of gold from the earth generates waste rich in cyanide and mercury – two highly toxic substances that can contaminate drinking water and fish, with serious implications for human health.  Tin is used for soldering in electronics. Indium-tin oxide is applied to smartphone screens as a thin, transparent and conductive coating that gives touchscreen functionality. The seas surrounding Indonesia’s Bangka and Belitung Islands supplies about a third of the world’s supply. However, large-scale dredging of the seabed for the tin-rich sand has destroyed the precious coral ecosystem while the decline of the fishing industry has led to economic and social problems. What makes your smartphone smart? That’ll be the rare earth elements – a group of 17 metals with weird names like praseodymium that are mined mostly in China, Russia and Australia.  Often dubbed “technology metals”, rare earths are fundamental to smartphone design and function. Crystal clear smartphone speakers, microphones and phone vibration are possible due to small yet powerful motors and magnets manufactured using neodymium, dysprosium and praseodymium. Terbium and dysprosium are also used to produce the vibrant colours of a smartphone screen. Extracting rare earths is a difficult and dirty business, typically involving the use of sulphuric and hydrofluoric acids and the production of vast amounts of highly toxic waste. Perhaps the most disturbing and thought provoking example of the environmental cost of our smartphone thirst is the “world’s tech waste lake” in Baotou, China. Created in 1958, this artificial lake collects the toxic sludge from rare earth processing operations.   The valuable metals used to manufacture smartphones are a finite resource. Recent estimates indicate we will run out of some rare earths in the next 20 to 50 years, which makes you wonder if smartphones will still be around then. Reducing the environmental impact of smartphone use requires manufacturers to increase product lifetimes, make recycling more straightforward and be open about where they source their metals and the environmental impact. Around the world mining companies have made huge strides in practising more sustainable mining. But we as consumers also need to consider smartphones as less of a throwaway item and more of a precious resource that carries an enormous environmental burden."
"Due to the uncertainty of Brexit, property prices and the cost of living are on the increase while household salaries have remained the same. Home extensions and improvements therefore remain an attractive, financially viable alternative to relocating and buying a new property. Many homeowners are captivated by television DIY programmes, but are seldom aware of all of the potential pitfalls of engaging builders, the contract, and the quality standards required (for both materials and workmanship). Although most DIY programmes offer some important information, it’s easy to overlook these during the excitement – and stress – of getting the work done. “Jerry building” is a commonly used term to describe cowboy or fly-by-night operators who provide ridiculously cheap estimates and cash in hand offers that are difficult to refuse. Homeowners are seduced by the cheap price without much thought for the potential risks when construction work begins. Trying to address time-consuming and costly mistakes can then become a major problem. The flipside of this is that others are put off hiring anyone to do their work altogether. Brian Berry, chief executive of the Federation of Master Builders (FMB), recently stated that: A third of home owners are so anxious about the possibility of choosing a bad builder, they don’t commission any building work whatsoever. This means that the UK economy could be missing out on £10 billion of activity every year. The latest research undertaken by FMB reveals that, on average, homeowners “would spend £40,000 on major home improvement projects over the next five years if they could be guaranteed a positive experience”. So how can you achieve this? The following tips will help you find a bona fide builder at a reasonable rate. Check whether the builder is a member of a credible trade body, such as the Federation of Master Builders, the National Federation of Builders, and/or the Guild of Builders and Contractors. Members of these bodies are bound by a code of conduct. Ask about the builder’s experience and qualifications – it’s not enough that they have professional-looking letterheads and business cards. Do not hesitate to check their recent jobs – and speak to past and current clients if necessary. Don’t be shy. Professional builders won’t mind you conducting these checks. They realise how important it is for you to trust them and appreciate that their work is to a high standard. Only cowboy builders will be defensive and try to stop you looking too closely at their track record. Although there are several online websites – such as Rated People, My Builder, Trust a Trader and Find a Trade – that provide ratings for builders and local tradespeople, don’t rely on them too much. Due diligence is still required. Many builders offer insurance-backed warranties for their work. This may involve a small additional cost but does provide extra protection for you, the customer. But check the cost and the level of cover provided before you accept. Ask the builder who the insurance is provided by, and whether they are an established insurer. All of this will put you in a better situation if something goes badly wrong. Make a list of your requirements, and ensure the plans are in line with local planning permission guidelines and building regulations. If the job involves work to a wall you share with a neighbouring property, it may be subject to the Party Wall Act. Identify clearly what additional works are required – for example, rewiring, window replacements and decoration. Ask for a detailed breakdown of the estimate (item by item) and check how long  the estimate is valid for and how long the construction work will last. You can then draw up a contract using standard forms prepared by the trade bodies mentioned above. This should include an agreed contract duration (a start and completion date) and the key phases during the work. Rather than paying hefty deposits or for everything in one go, agree to make staged payments as each of these phases is completed – if you’re not sure how this works, seek advice from the Royal Institution of Chartered Surveyors who will put you in touch with local surveyors. This is critical. Many builders tend to front load the payments rather than spreading the cost across the duration of the contract, which makes it far harder for you to seek redress if anything goes wrong. Peace of mind is worth a little extra cost. Before releasing any stage payments, check with an appointed building regulations inspector that all works comply with building regulations. And ensure everything is in writing and above board. If someone is prepared to cheat on their taxes, are you sure they won’t cheat on you? An invoice and proper paperwork proves a relationship and, if a dispute follows, it can be helpful. Without it, how can you even prove your builder was doing the work? You can further strengthen your position by taking regular photographs of the works and keeping a log of their activities on a daily/weekly basis. And hold back a final payment until the work is complete, warranties and guarantees have been issued to you, and the job has been certified as completed by your building regulations inspector. If you’ve followed these simple tips, you can then sit back, relax and enjoy your new home."
"
Share this...FacebookTwitterAccording to a new paper published in the Journal of Geophysical Research, the observed mean thickness of the sea ice in the region north of (Arctic) Svalbard was substantially thinner (0.94 m) in 1955 than it has been in recent years (~1.6 m, 2015/2017).

Graph Source: Rösel et al., 2018

In 1955, the atmospheric CO2 concentration hovered around 315 ppm, about 90 ppm lower than today’s CO2 values.
It is widely assumed that the steep and substantial rise in CO2 concentration since the 1950s is largely responsible for warming the Arctic, and consequently the decline in the Arctic’s sea ice volume and extent (IPCC, 2013).  This assumption is significantly predicated on the observation that sea ice has undergone precipitous losses since the 1970s, which is when the satellite era began.
However, longer-term observational data do not appear to support the conclusion that Arctic region sea ice is driven by linear trends in atmospheric CO2 concentration.  Indeed, there is evidence that Arctic sea ice extent was comparable or lower than now in the 1940s and 1950s (for example, see this annotated graph from Gagné et al., 2017).  Several other recently published papers also fail to support a CO2 – Arctic climate connection, as detailed in several articles found here at NoTricksZone during 2018.
1. 20 New Papers Crush Claims Of A Man-Made Link To Arctic Climate Change, Glacier Retreat, Sea Ice
2. Groundbreaking AGW-Undermining Study: Greenland’s Warming, Ice Loss Due To Geothermal Heat
3. Another New Paper Shows Arctic Sea Ice Has Been INCREASING Overall Since The 1930s
4. 12 New Papers Affirm A 21st Century Cessation Of Arctic Warming And A Rapid Cooling Across Antarctica
5.  Arctic Temps 2°-6°C Warmer Than Today With 4.5 Fewer Months Of Sea Ice Coverage 2,000 Years Ago
6.  New ‘Consensus’ Science: HALF Of 1979-Present Arctic Warming & Ice Loss Is Natural
7.  In 2015, Climate Scientists Wrecked Their Own CO2-Forced ‘Polar Amplification’ Narrative
8. Activists Continue To Peddle Unsupportable Claims Of NEVER-BEFORE Climate Alarm, Ignoring New Science
Regional Arctic sea ice was thicker than now in the 1950s?
In another newly published paper, observations from an Arctic region north of Svalbard affirm that sea ice thicknesses were indeed much higher than today during the 1970s, or when the linearly-decreasing sea ice trend documented by satellites (conveniently) commenced.
However, looking closely at Table 3 (shown in the introductory graph above) from the same paper, we see that sea ice thickness values may have been lower in the mid-1950s (0.94 m) than they are today (~1.6 m thicknesses on average).
If sea ice was was thinner than it is now during the same period of time that CO2 concentrations were substantially lower than they are now, this documented observational evidence appears to again undermine the conclusion that CO2 concentration rises are significantly connected to sea ice losses – or to the Arctic climate in general.

Rösel et al., 2018
Thin Sea Ice, Thick Snow, and Widespread Negative
Freeboard Observed During N‐ICE 2015 North of Svalbard
“We present a continuous time series of in situ measurements from the N‐ICE2015 expedition from January to June 2015 in the Arctic Basin north of Svalbard, comprising snow buoy and ice mass balance buoy data and local and regional data gained from electromagnetic induction (EM) surveys and snow probe measurements from four distinct drifts. 
“The observed mean snow depth of 0.53 m for April to early June [2015] is 73% above the average value of 0.30 m from historical [1955, 1970s] and recent observations in this region, covering the years 1955–2017.”
“The modal total ice and snow thicknesses, of 1.6 and 1.7 m [2015] measured with ground‐based EM and airborne EM measurements in April, May, and June 2015, respectively, lie below the [1970s] values ranging from 1.8 to 2.7 m, reported in historical observations from the same region and time of year [but well above the sea-ice thickness values of 0.94 m for 1955].”

Share this...FacebookTwitter "
"Wildfires, drought and extreme heat have been the talk of the town and country across Europe this summer. Attention has now turned to Portugal and Spain, where temperatures at the weekend reached more than 46℃ in some parts of both countries – close to the all-time European record of 48℃, set in Greece in 1977. Records aside, the obvious question is what is causing the current Iberian heatwave and whether this might be a harbinger of the future. A number of factors can be identified. These include unusually warm sea surface temperatures in the North Atlantic, a wandering jet stream and associated “blocking” pattern of high pressure, a very dry land surface, and climate change.  The anomalous size and position of warm water areas in the North Atlantic this summer have shifted the so-called “polar front” northwards. This is the point where warm air from the south meets cold polar air, and any movement in the front will affect the distribution of high and low atmospheric pressure right across the Atlantic. This in turn influences the flow of westerly winds across the Atlantic and over Western and Southern Europe, especially the thin and fast “jet stream” in the upper atmosphere. This summer, an area of persistent high pressure or “blocking” has become established over Western Europe and the eastern parts of the Atlantic. Such blocking causes the jet stream to appear “lazy” and wander much further north and south than its average position.  The upshot of all of this is that atmospheric blocking and a very snake-like jet stream prevents low pressure systems, and the “bad” weather they bring, from heading eastwards across Western and Southern Europe. In such a situation, the usual fluctuations between good, and not so good, summer weather are largely put on hold. Instead, as Portugal, Spain and much of Europe have experienced, clear skies, lots of heat, and very dry surface conditions become the norm.  In certain circumstances, persistent blocking can even draw in very warm air from elsewhere. This is what happened in Portugal and Spain,  after intense heat caused an area of low pressure to form over Iberia. This “heat low” created the conditions for the flow of hot dry air from the Saraha Desert. Currently life in Portugal and Spain is not just in an oven, but more like a convection oven. Heatwaves in Portugal and Spain are not uncommon because this type of extreme weather is characteristic of the hot and dry summers in the Mediterranean climate region. Yet there is convincing observational evidence that heatwaves are happening more frequently across the Iberian Peninsula. Logically the question arises as to what extent the current heat is associated with climate change.  Although answering this question thoroughly would involve undertaking some well-designed climate modelling experiments, it’s safe to say that there is indeed a fair chance the current heatwave is associated with climate change. That is because heatwaves are now happening on a background of rising global temperatures so the base level of background temperature on which extremes are occurring has lifted somewhat compared to pre-industrial levels. And what of the question on everyone’s parched lips: are the current extremes the “new norm”? The short answer is no, not right now, as extremes of over 46℃ still constitute rare events. However, analyses of the pronounced 2003 European heat wave, which affected both Portugal and Spain, indicate that the very similar extremes of August 2003 could be fairly normal by the 2040s. This of course raises questions as to the habitability of places that already possess harsh summer climates. Most likely their sustainability will depend on the extent to which traditional climate adaptation strategies related to building and lifestyles can be pushed to the limit to cope with a new climate future typified by summers with temperatures in and over the mid 40s and how flexible people and businesses might be to the idea of going elsewhere or literally underground during summer."
"As a wildlife veterinarian, I often get asked about bats. I like bats, and I am always eager to talk about how interesting they are. Unfortunately the question is often not about biology but instead “what should I do about the ones in my roof?”.  With some unique talents and remarkable sex lives, bats are actually one of the most interesting, diverse and misunderstood groups of animals. Contrary to popular belief, they are beautiful creatures. Not necessarily in the cuddly, human-like sense – although some fruit bats with doey brown eyes and button noses could be considered so – but they are beautifully designed. This couldn’t be illustrated better than by the discovery of the oldest known complete bat fossil, more than 53 million-years-old yet with a similar wing design to those flying around today. To put it in perspective, 50m years ago our ancestors were still swinging from the trees and would certainly not be recognised as human. But even then bats already had the combination of thin, long forearms and fingers covered by an extremely thin, strong membrane, which allowed them to master the art of powered, agile flight.  Soon afterwards, fossils record another game-changing adaptation in the evolution of most bats, and that is the ability to accurately locate prey using sound (what we call echolocation). These two adaptations early in their history gave bats an evolutionary edge compared to some other mammals, and allowed them to diversify into almost all habitats, on every continent except Antarctica. There are now more than 1,300 different species, divided among 26 different families (compared to fewer than 500 primate species). Indonesia alone has 219 different bat species.  It is not just a quantity though – the variety is astonishing. The thumb-sized bumblebee bat of Thailand is the smallest species, weighing just two grammes. And like other insectivorous bats, it can eat its own body weight in insects every night. At the other end of the scale, some large flying foxes have wingspans of well over a metre and, having lost the ability to echolocate, eat fruit and nectar.  Everyone knows that some bats feed on blood, but despite the “vampire” myth, only three species actually feed on blood. And these haematophagous bats are only found in parts of South America. They also definitely don’t get tangled in your hair. Bats are far too good at flying.   If thus far I haven’t persuaded you to like bats, you must admit that they are useful. Bats defecate while regularly flying very long distances (up to 350km in one night), making them extremely effective at dispersing seeds. Add to that the fact that some fruit bats live in colonies up to 1m strong, and you can start to imagine their impact. So much so, they have been proven key in reforestation.  Another unappreciated and major role is as pest controllers. The sheer volume of insects that some bats species can eat makes them very effective at suppressing pest insects. Bats reduce the nuisance and disease threat of mosquitoes, and it has been estimated they save the US economy at least $3.7 billion every year through increased crop productivity and reduction of pesticide usage. Despite their ancient design, they show some remarkable talents. One of these is shared only by several select animals. Bats are vocal learners – able to learn and then imitate sounds even in adulthood. This is likely important for the development of the complex social organisation seen in many bat species. Most surprising of all is the recent revelation that they are also members of an even more exclusive and less salubrious club: animals known to partake in fellatio during copulation. Bats have had some bad press recently due to their association with infectious diseases, from rabies to Ebola. And they appear able to tolerate some viruses fatal to other species. If anything, that illustrates again why they should be respected, especially as various bat species are also endangered and therefore protected by law in many regions. So my response to those interested in what to do about the bats in their roof? Leave them alone."
