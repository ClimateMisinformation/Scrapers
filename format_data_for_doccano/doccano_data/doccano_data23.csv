"On an autumn afternoon in the Canadian prairies, golden wheat chaff blows from a rumbling grain dryer, shimmering in the sun like a snowfall. Clarence Zeleny stands beside the machine, irritation straining his face. “It’s giving me trouble today,” says the 83-year-old farmer as he studies the snaking tubes and wiring.  Dryers like this, which blast freshly harvested wheat and canola with warm air, are essential for farmers in the region as they attempt to salvage another poor harvest: weeks of rain and snow have left crops too wet to cut or sell otherwise. “Too many more years like this and farmers here might not survive,” he says. The patchwork of farms across the vast landscape of Canada’s western prairie provinces has long been the source of much of the world’s supply of canola seed and wheat. But farmers across the region are increasingly feeling pushed to the brink by an unfolding crisis that shows little sign of easing. This year’s dismal harvest marks the fourth poor season in a row – the worst run of bad luck in memory – and comes against a grim background of plummeting incomes and a trade war with China. “A farmer always says next year will be better,” says Norma Zeleny as she and Clarence lunch on cheese and crackers. Norma has helped run the family grain farm for nearly six decades. But the changes she’s witnessed over the years have made her question such received wisdom. “It’s sad because a lot of young people really do want to do farming. But they’re being discouraged.” According to Statistics Canada, farming incomes across the country dropped by 45% in 2018 – in Alberta the figure was closer to 70% – due to higher operating costs and interest rates and stagnant or falling crop prices. Meanwhile, the price of farmable land has soared, driven up by scarcity and speculation. When they first started their farm nearly 60 years ago, the Zelenys paid $100,000CAD (£58,500) adjusted for inflation, for 64 hectares (160 acres). A similar-sized plot now sells for more than six times the amount. The price of machinery has outpaced incomes: a combine harvester can cost nearly three-quarters of a million dollars, more than twice the cost of a house in town, and many farmers find themselves plunging ever deeper into debt. “It’s not uncommon for farmers to have millions of dollars in debt or to be very asset-rich, but cash-poor,” says Andria Jones-Bitton, an epidemiologist at the University of Guelph who studies farmers’ mental health. “One family I know have a $5m (£3m) loan over their head.” To make matters worse, Canadian farmers have spent nearly a year hostage to a diplomat dispute with China; Beijing halted all imports of canola from the country following the arrest of Huawei telecoms executive Meng Wanzhou in Vancouver on a US arrest warrant. The cold realities of modern farming in a globalised world have concentrated unprecedented pressures on individual farmers. Nearly half of all farmers in Canada feel immense stress from their job, according to research by Jones-Bitton. Although communities and government agencies are working to improve awareness of mental health, suicide has become a growing occupational hazard. In the US, the Centers for Disease Control found that farmers killed themselves five times more often than other sections of the population. Canada doesn’t track similar statistics with as much detail but Jones-Bitton said the country’s farmers die by suicide at rates much higher than other groups. “People say, ‘I’m worth more to my family dead than I am alive because of insurance’. It’s heartbreaking,” she says. ••• Sitting in the late morning sun at his kitchen table, Larry Kitz is exhausted. The night before, he seized the brief window of opportunity offered by a change in the weather and hired a team workers to harvest grain overnight in sub-zero temperatures. “There’s so many tentacles grabbing you at the same time – bank, weather, markets,” he says. He knows all too well the effect mounting stress can have on local farmers: his brother Gary, who ran the farm with him, killed himself two years ago. “Nothing was going right for him,” says Larry. “I reflect back and those fricking signs were there. The signs were there. I feel just horrible because dammit, it was happening.” He admits he comes from a region – and a generation – where speaking openly about mental health wasn’t encouraged. But after seeing how his girlfriend, a nurse of 25 years, meets friends as a way to process work-related trauma, Larry decided to follow suit. In recent weeks, he and a group of friends have met at a local diner to eat breakfast and openly discuss the challenges of life on the farm. “It’s the best damn therapy out there,” he says. It still takes an effort to share his concerns, he said, but speaking openly about the uncertainties of the harvest, the weather and the markets “makes a world of difference”. Other farmers are more bullish on both their mental health and their chances in the industry. Forced inside by a howling snowstorm, Braden Halina reclines in his garage, a can of beer in hand. The 28-year-old, from the town of Vegreville, Alberta, is a rarity, as fewer young people are taking up farming. After losing his father to suicide three years ago, Halina was forced to run the family farm. Now a father himself, he admits that the stresses of the job can seem daunting but he remains optimistic. “I’ve never really reached out for any help, because I don’t think that I need it, to be honest. I think I got it under control,” he says. Halina says he has developed defensive instincts that he hopes will better insulate him from the unpredictability of markets and weather. After all, he reasons, the world still needs people like him. “You need farmers. You fucking need farmers.” But the world that farms work in is changing. Experts predict the prairie region will warm in the coming years, potentially improving the growing season in some areas, but also increasing precipitation, which can delay the harvest. Many farmers in the area are sceptical about climate change science, but the area has already started to experience the effects; in 2017, forest fires hundreds of kilometres away in British Columbia blanketed the prairie region near Mundare with smoke, dramatically curtailing the growing season. While farmers debate how much to read into the changing weather, they also express frustration that their voices fall on deaf ears. Canada recently went through 16 weeks of election campaigning, with candidates criss-crossing the country in search of votes. But none of the party leaders, or the local candidates, spoke about the challenges farmers are facing, said Ryan Warawa, who farms 4,300 acres (1,740 hectares) outside of Mundare, Alberta. Like many in the prairies, he feels that the rest of the country is ignorant of the anxiety and desperation overwhelming farmers. “A farmer puts all his money and his heart into farming … and a lot of these city people haven’t got a clue what it takes to run a farm. No one cares about where their food comes from.” By late autumn, Ryan and his father, Danny, have nearly 1,400 acres (566 hectares) of unharvested wheat and canola in their fields. With weather jumping erratically between rain and bitter cold, the harvest is unlikely to be finished before winter sets in. Leaving the crop in the field might give them the chance to harvest the remainder in spring, but they will have to sell it for much less. If the trend of cold, damp days continues, “you might as well put a for sale sign up on the farm”, says Danny, who spurned retirement to help his son. To hedge against the increasingly bleak returns from wheat and canola, he points past the sheds and grain bins to a pasture he calls his insurance policy. Milling around the fields is a herd of 54 bison he recently purchased with his savings. “They’re my retirement,” he says with a laughs. “They pay me better than any bonds I could have bought.” Ryan estimates that they have $700,000 (£410,000) of wheat and canola left in the field – but they owe a similar amount to the bank. The family doesn’t own a grain dryer, which costs more than $130,000 (£76000), meaning no matter how hard they work or plan, the success of his operation will depend on the weather. “I got an 11-year old kid that absolutely loves the farm and would quit school tomorrow if I told him he could take over,” says Ryan, staring down at the ground, hands in pockets. “But I don’t want him to do this.” • Crisis Services Canada can be contacted on 1-833-456-4566. In the US, the National Suicide Prevention Lifeline is 1-800-273-8255. In the UK and Ireland, Samaritans can be contacted on 116 123 or email jo@samaritans.org or jo@samaritans.ie. Other international suicide helplines can be found at www.befrienders.org."
"The home secretary wants us to believe the substantial increase in child poverty is somehow not the result of policies pursued by the government since 2010 (Report, 22 November). And if the Tories were to be re-elected and child poverty jumps to over 5 million by 2022, as predicted by the Institute for Fiscal Studies two years ago, then presumably, again, we should not attach any blame to her party.David WinnickLabour MP for Walsall North 1979-2017 • Ten-year and eight-year sentences for the detectorists jailed for the theft of a Viking’s treasure; seven and a half years each for two men who raped a woman in a Soho nightclub (Reports, 23 November). Can I suggest that the respective judges attend a training course on the meaning of social justice.Steven BowditchCarlisle, Cumbria  • I wonder how many Guardian readers like myself missed BBC One’s Question Time leaders’ special on Friday night as it failed to make the TV schedule in your Friday paper. Wake up at the back!Phil LeeElslack, North Yorkshire • Anyone tuning in to see Would I Lie To You? on Friday night would have seen Boris Johnson instead and would probably have concluded they hadn’t missed it after all.Brian AllenBirdham, West Sussex • While appreciating the publicity given Mildura’s plight in Australia’s heatwave (Suffocating dust storm adds to town’s woes, 22 November) as a former resident I must point out that Mildura is not a town, having been proclaimed a regional city in 1934.Murray HedgcockLondon • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitter
I was notified by reader Ken of an interview conducted by German daily Augsburger Zeitung (AZ), appearing in the hard copy edition. Now posted here in German.
44-year veteran meteorologist Klaus Hager. Photo credit: University of Augsburg 
Interviewed was meteorologist Klaus Hager. He was active in meteorology for 44 years and now has been a lecturer at the University of Augsburg almost 10 years. He is considered an expert in weather instrumentation and measurement.
The Augsburger Zeitung writes that “hardly any of his colleagues are as familiar with the weather as the 73-year old is“.
“Fluctuations dominate climate, not trends”
The Augsburger Zeitung wanted to know Hager’s views on climate change. Hager doesn’t hold back any punches, claiming that “people are being deceived” on the subject and that man’s influence on the climate is very small.
On whether temperatures are warming in the Augsburg region, Hager says there is “no detectable trend showing this is so” and that it’s been cooling since 2005. When it comes to the climate variability, he agrees with Professor Lauscher of the University of Vienna: “Fluctuations dominate climate, not trends“.
Warming an artifact of new instrumentation
One reason for the perceived warming, Hager says, is traced back to a change in measurement instrumentation. He says glass thermometers were was replaced by much more sensitive electronic instruments in 1995. Hager tells the SZ (my emphasis):



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




For eight years I conducted parallel measurements at Lechfeld. The result was that compared to the glass thermometers, the electronic thermometers showed on average  a temperature that was 0.9°C warmer. Thus we are comparing – even though we are measuring the temperature here – apples and oranges. No one is told that.”
Hager confirms to the AZ that the higher temperatures are indeed an artifact of the new instruments.
Hager also calls climate change and climate protection “ideologically charged topics“.
“People are being deceived especially when it comes to reducing CO2.” He tells the AZ that weather depends on dozens of single factors – all of various weighting.
The AZ, seemingly stunned by it all, asks Hager: “So you’re saying that the calls for climate protection connected to CO2 are not serious?” Hager confirms, answering:
The CO2 taxes that are being levied are actually a sin against national wealth. If you want to stop the alleged climate change, then you need to ask what it’s all about and who profits from it at the expense of the citizens.”
Hager then explains how CO2 is only a trace gas and that its role in climate is overhyped.
When asked about how his position is completely contradictory to that of the mainstream, Hager scoffs at the notion:
You know I check facts and I want others to think about it and not to just swallow everything unfiltered- just because its the current zeitgeist. Manmade climate change will turn out to be a climate bubble. It’s going to pop like the forest die-off scare – and will do so because of nature – here I mean when solar activity falls again.”
I wonder how much longer he’ll lecturing at the university of Augsburg. Expect the warming-jihadists to go after him. Kudos to the Augsburger Zeitung for printing the interview!
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Iceland Monitor website here writes the North Alantic island is having its coldest summer in more than 20 years. According to the site:
The first thirteen weeks of summer this year have been the coldest in Reykjavik in over twenty years, reveals Icelandic meteorologist Trausti Jónsson.
The northern city of Akureyri fares even worse – one has to go back around thirty years to find a colder summer.”
Experts now say their are growing signs that this may be much more than a mere weather anomaly, and have more to do with an overall developing cooling trend. The Iceland Review site here writes that Met Office meteorologist Páll Bergþórsson warns how “Iceland may be entering a cold period“:
Iceland has enjoyed 25 years of above-average temperatures, Páll told Morgunblaðið, but those years may be over with a cold period taking over in the coming years.
‘The ocean here off Southwest Iceland is colder than usual and the cold is persistent after it first arrives,’ Páll stated.”
The cold is not isolated to Iceland, but appears to be spreading across the greater North Atlantic. Paul Homewood writes at his site on how the United Kingdom recently “saw one of the coldest July nights for many years“, with southern England setting a new record low of just 1°C on August 1st.
The cold gripping the North Atlantic likely is likely in large part due to cooling sea surface temperatures. The following chart from Climate4You shows how SST in June was at its lowest point in 14 years.

Share this...FacebookTwitter "
"It’s easy to see why motor cars are such a popular form of transport: they’re private, comfortable and convenient. But the popularity of cars can also be one of their biggest drawbacks. When there are too many of them and not enough road space, streets become congested and as a result, journey times become unpredictable, air pollution increases and we lose out on some of the economic benefits of city living.  Now, a new study suggests that the personal benefits we get from having a car could be improved by collective thinking. Researchers at MIT and Birmingham University used big data from five cities – Rio de Janeiro, Boston, San Francisco, Lisbon and Porto – to show how strategic route changes by a relatively small number of motorists could reduce the time lost to congestion by as much as 30%.  The authors crunched massive amounts of mobile phone data to identify travel patterns during peak morning commuting times in each of these cities. They confirmed that the time lost due to congestion in each city reflects a high demand for road travel, relative to the supply of road infrastructure. They found that the density and distribution of the population played a role in congestion levels, too. No surprises here.  But by modelling this data, the authors were also able to measure the potential benefits of optimising the system as a whole. This is where it gets interesting. The researchers calculated the detrimental effects of “selfish routing” – where individuals set out to minimise their own travel time – by comparing this approach with the travel times resulting from a “socially optimal” solution.  They modelled a scenario where drivers were equipped with an app which gave them the option to take a longer route for the good of all. The authors found that overall, it only took a relatively small number of motorists to choose longer travel times, to create significant benefits for others. By giving drivers the option to take a socially optimal approach, rather than a “selfish” one, the total time lost to congestion could be reduced by between 15% and 30%.  One of the main problems with congestion is that it makes it difficult to accurately anticipate journey times. By giving drivers the option to pick their route with a predicted journey time, drivers who need to be at their destination at a particular time will know when to set out while drivers who are more flexible can avoid the worst congestion. It’s a “win-win” situation.  Even so, the actual time savings for individual motorists were found to be marginal – a few minutes at most. The authors of the study said that “in the best case scenario, time savings would be imperceptible for the majority of the drivers”. Rather, the optimised routing would help cities to function better as a whole.  This offers a crucial insight for urban leaders looking to grow their city’s wealth and population. The research demonstrates that there’s limited scope for road-based solutions to the issues arising from urban congestion. Routine commutes to and from work make it difficult for drivers to be flexible, even if there were some incentive to take a longer, more socially beneficial route. The authors’ proposal may work better on the road networks between cities, where trips are longer and fewer drivers are inflexible when it comes to timing.  Ultimately, city authorities should recognise that offering alternative modes of transport will do a lot more to reduce congestion than giving motorists the option to be socially responsible drivers. For instance, rail in its various forms provides speedy and reliable travel for daily commuters, as well as tackling all the economic and environmental issues caused by congestion."
"Here’s a little story about hubris: an Australian prime minister wins a federal election no one gave him a chance in after running a relentlessly negative campaign against an opposition that bit off way more policy than the public was prepared to chew. The victory gave the leader enormous political authority within his caucus, the sense of invincibility in the public’s eyes and the enduring love of his base, emboldening him to let loose with his plan to remake Australia. He treats the vanquished with contempt, which seems their due given their implosion, all the while ignoring the fact that it was they, not he, who had determined the result. And three years later it’s all over, a defeat so crushing that it set the tone for the next decade. Scott Morrison’s no Paul Keating, but he risks falling into the same trap after an unexpected miracle victory. Because when the deafening, delirious cheers from a win you don’t expect subside, is it any surprise you wake up with a case of tin ear? Of course the difference is that Keating’s mistake was to make Australia bigger than it was ready to be: willing to be engaged in its region, ready to make peace with its history, prepared to sever the constitutional ties with the motherland. For Morrison it’s all about making Australia smaller: denying both its history and its present, cutting itself off from the world and, as I’ve argued previously, stifling any form of organised dissent. But as figures in this week’s Essential Report show, although Morrison may be willing his “quiet Australians” to remake themselves in his image, they really haven’t changed at all. When it comes to climate change – despite all the self-serving assertions that Labor’s ambition cost it power – people still believe the government is asleep at the wheel. In fact the number of people thinking the government isn’t doing enough is at an all-time high of 60%, significantly up from pre-election polling. As for all that “climate manners” baloney that as the east coast burns “now is not the time” to talk about climate change, Australians are stronger than ever here too: call a spade a flaming shovel, PM! The last leader to try this line on, Tony Abbott, generated way more purchase. Back then half the population rejected the link. Now 60% see the connection, and most of these reckon now’s a reasonable time to have the discussion. While the party breakdowns show Morrison is clearly playing to his base and the outliers to its right, the bulk of voters – including one-third of Coalition voters – see the dissembling as the smokescreen it has always been. Yet he blusters away, believing he has a mandate to refuse to confront the science that places more and more Australians at risk every year. Meanwhile he’s is desperate to airbrush the final days of the previous parliament from the record, particularly its historic failure to end cruelty on Manus and Nauru. The legislation sponsored by the interim member for Wentworth, Kerryn Phelps, that pushed forward the novel idea that doctors should determine whether a soul under Australia care should receive medical attention is a line in the sand for the PM. Again it appears he has mistaken his election win with a change in mood for the Australian public because the support for these measures, or something even more humane, remains above 60%. For all the talk on risks to sovereignty and the steady leaks of disclosures about the nature of the ailments of some of those seeking care, the debate has pushed up two points for each of the extremes, at the expense of the status quo. But really, nothing has changed. Here’s the truth behind these figures: the election result did not fundamentally change Australia or how Australians see themselves. They may have balked at Labor’s expansive agenda but they do want action on climate change and they are more than ever ready to think the government is not doing enough. And they want to see some basic humanity when it comes to asylum seekers. And that’s not all. The Australia that wondered why the government held out against a banking royal commission while laying into the unions before the election is the same Australia wondering why deregistering unions is now the government’s top legislative priority. The Australia that demanded that the government take meaningful action on family violence before the election will not now cheer on as the PM hands a review into the family law system to Pauline Hanson. The Australia that demanded the NDIS be funded adequately before the election is the same Australia that will see any attempt to prop up the budget with unspent funds as fiscal abuse of the needy. The government won the election by promising to do nothing. End of story. Like Keating before him, Morrison will believe his victory has changed Australia at his own political peril. • Peter Lewis is an executive director of Essential"
"
Share this...FacebookTwitterThis is one of those posts about things noticed, remembered, and linked while surfing the web.
It is well known that the local sea level is heavily influenced by wind speed and direction as well as barometric pressure. Most people are aware of storm surges associated with hurricanes, for example. The same thing happens on a near-global scale, and some of it is near-permanent. Here is a global map of sea level anomaly from the University of Colorado.

Figure 1 is the sea level rise trend since satellite radar altimetry began.
In Figure 1, the sea level in the Western Pacific has risen 10 or 12 mm per year, while the eastern Pacific, parts of the Southern Ocean, and a spot in the Atlantic, have fallen by 3 to 5 mm per year, over the satellite era.
The next interesting map comes from the European Space Agency (ERA). This map is generated by taking the sea surface height as measured by satellite and subtracting the gravity model from GOCE. The result is the sea surface height over the geoid.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 2 is the sea surface height over the Geoid. 
Note the difference in height between the western Pacific and the Southern Ocean, about 3 meters. The difference in height between the western Pacific and the coasts of North and South America is over a meter. These height differences drive ocean currents. These differences are maintained by wind and pressure differences. If wind and pressure change, the sea level changes accordingly.
 
Next are plots (Figures 3 and 4) from Garza et al 2012, of Sea Level Pressure (SLP), and wind changes over the 1980 to 2009 epoch.
The SLP has increased over the eastern Pacific and decreased over the western Pacific. North of 10°N, easterly trade winds have increased in the eastern Pacific and south of 10°N, they have decreased. These small changes, along with thermal expansion, have changed the relative sea level between the two sides of the Pacific Basin by 1%, one centimeter out of one meter. My point is that not all of the western Pacific sea level rise is due to warming, a great deal of it is due to wind and SLP change.
Do you remember the controversy last year about the trade winds? One paper had them increasing, due to global climate change; the other had them decreasing due to climate change. They were both right. They were just looking at different parts of the elephant. North of 10° North the winds increased; south of 10° North the winds decreased.
 
Share this...FacebookTwitter "
"Ikea’s parent company is to invest an additional €200m (£171m) in green energy and forest planting as part of a plan by the world’s largest furniture retailer to become carbon neutral by 2030. The investment is being made by Inter Ikea Group, the owner of the Ikea brand which is operated by a string of franchise businesses, the largest of which is Ingka Group. Inter Ikea Group said its €200m investment would be released in two phases. The first phase of €100m would be directed towards new renewable energy projects including heating, cooling and electricity generation. The group said investment would be in partnership with suppliers and directed towards parts of its supply chain where converting to renewable energy was more difficult – such as the textile industry, ceramics and glass production. The second tranche will be aimed at removing and storing carbon through reforestation and responsible forest management. Ikea said it was considering a variety of global regions for reforestation projects. The group statement said: “It is most likely that we will put an emphasis on projects in tropical and subtropical regions. This is because there is a vast amount of degraded land in need of reforestation, and forests in these regions grow faster making it possible to remove more carbon from the atmosphere.” Ingka Group, which has previously laid out plans to spend at least €3bn on sustainability investments, said this week that since 2009, it had pumped close to €2.5bn into renewable energy. The group now owns 534 wind turbines and 715,000 solar panels in 14 countries as well as a further 920,000 solar panels on store rooftops. The company, which operates 374 Ikea stores in 30 countries, has also invested in over 26,000 hectares of forest land, mostly in the US and Lithuania, taking its total ownership of responsibly managed forests to 208,700 hectares (about 2,000sq km) in five countries. The group has also invested in a plastics recycling plant, textile and mattress recycling and is trialling the sale of used, patched-up furniture in the UK as part of efforts to become more environmentally friendly. The investments have put Ingka Group on track to produce as much energy from renewable sources as consumed in its operations by next year. “We believe that the best way to minimise our climate impact and to contribute to limiting climate change to 1.5°C is mainly by reducing our greenhouse gas emissions – but we also need to remove existing carbon from the atmosphere. We can make a positive difference through our integrated supply chain, our global presence and our forest and climate expertise,” said Lena Pripp-Kovac, chief sustainability officer of Inter Ikea Group."
"
Share this...FacebookTwitterJust a quick post today, German site wobleibtdieglobaleererwaermung here writes that whenever one observes a number of datasets, they have one thing in common: There’s no detectable CO2 warming, and there”s verzylittle out there suggesting the warming will continue.
Most temperature datasets don’t show warming, sea ice doesn”t show it, lower troposphere temperature data do not show it, snow cover data don’t show it, historical climate cycles do not show it, and on goes the list.
wobleibtdieglobaleererwaermung now tells us that “the global satellite measurements by UAHv6 now show a warming ‘pause’ of 221 months spanning from March 1997 to July 2015, which is over half of the satellite record, which began in January 1979: (36×12+7 = 439 months/2 = 219.5 months).” See their first figure.
Even the current El Niño has not been able to stop the pause up to now. And once again the “Super El Niño” is struggling. True the current ElNiño is expected to end the warming pause, but only temporarilly as the expected subsequent La Niña 2016/2017 will compensate and once again continue extending the warming pause, possibly well beyond 20 years.
The gaping divergence continues
Even a slight trend warming would not be enough to salvage the global warming theory wreckage. The wobleibtdieglobaleererwaermung site reminds us: “The unfalsified measured global reality since 1990 continued to diverge again from the IPCC model projections again in July 2015“, see their second figure.
Moreover realistic estimations of global temperature development tell us to expect the opposite in the future (cooling), says wobleibtdieglobaleerderwaermung:
‘…Because of the thermal inertia in the climate system, formost the heat capacity of the ocean, the current temperature stagnation will turn into a cooling phase in the near future.’ Source: 2015 SO xxx Cf-Klima – Berliner Wetterkarte.”
Share this...FacebookTwitter "
"Poo comes in many different sizes, from the microscopic poo of the smallest invertebrates, to the largest poo of the African elephants who can each produce over 50kg per day. It also comes in many shapes, such as tubes (dogs), pellets (rabbits) or splats (cows), but the wombat is unique in the animal kingdom in that it produces cubic poo, and lots of it – around 80 to 100 cubes per night. The wombat is a large relative of the koala, native to Australia. It is solitary and nocturnal, living in underground burrows during the day but coming out at night to forage on grasses and other vegetation. It also sleeps a lot; an average of 16 hours per day. As it is nocturnal, the wombat has very poor eyesight, so it relies on its sense of smell to navigate and find food.  Poo is produced by all organisms – and species have adapted to utilise it in many different ways, such as a mechanism for seed dispersal, or a food source for animals including dung beetles. Poo can also provide information about the individual who produced it and their diet. The different textures, size, shape and smell can all help to identify the species that produced the poo – this information can be used to survey elusive animals such as the otter (which produces a distinctly fishy-smelling “spraint”“, and can also give an estimation of how long ago the poo was produced. Even dinosaurs have left fossilised poo behind, called coprolites.  However, poo is also very smelly, so it can be used by individuals to communicate their presence to others. Why is this needed? Although contests are frequent in the animal kingdom, they can be fatal – so are avoided if possible. One way of avoiding conflict is to mark your territory with a scent such as poo – this provides information on who you are and where you live. The wombat is highly territorial so uses its cube-shaped poo to mark its territory, preventing conflict. Wombats have been found to differentiate between various poos and show avoidance behaviour when presented with poo produced by predators and other male wombats. The hormonal content of poo can also be examined, for example so that males can tell when females are most fertile.  Wombats deposit poo outside their burrows and on the tops of rocks and logs, where they are more easily found by other wombats. The distinctive shape is an advantage as the flat sides of the cubes ensure they do not roll off their precarious locations. Wombat poo is cubic, not because the wombat has a square-shaped anus, but because it has a very long and slow digestive process, typically 14 to 18 days, which allows the digestive matter to become extremely dry and compacted. The wombat also has a very long digestive tract, allowing it to absorb the most nutrients and water from its food. The first part of their large intestine contains horizontal ridges that probably mould the poo into cubes, whereas the last part of the large intestine is relatively smooth, allowing the cubic shape to be maintained. The highly compacted nature of the poo means that the rectum is unable to contour the poo into the more usual tubular shape. So, the wombat, with is nocturnal way of life, poor eyesight but excellent sense of smell, uses poo as its main way of telling who lives where and if there are any strangers in the area (thus avoiding conflict), and as a way of increasing its reproductive success. It produces cubic poo as a result of its diet and long digestion. And, the cubic poo is the perfect shape for sitting on top of rocks and logs as it doesn’t roll away. Poo can be clever, too."
"
Share this...FacebookTwitterHamburg-Based Max-Planck-Institute for Meteorology: Aerosols Cool Less Than Previously Thought
By Sebastian Lüning, Fritz Vahrenholt
[Translated, edited by P Gosselin]

In our book “The Neglected Sun” we wondered a lot about the cooling effect of aerosols that was assigned in the climate models. Aerosols are tiny dust particles and droplets that act to diffuse sunlight and thus as a rule act to cool the earth. But by how much? In Chapter 5 of our book we wrote:
According to the IPCC, the cooling effect of aerosols offsets about two thirds of the power of CO2. In the IPCC’s view, aerosols reduce the warming generated by all greenhouse gases by 45 percent. But the uncertainty is large – it could be 15 percent, or even 85%, because we have only modest to low level of scientific “understanding of the relationships.”
Today very few are aware that the climate models generate far more warming than what we really produced over the last 100 years. The IPCC strategy: All the surplus heat is cancelled by aerosols until the models “fit”. The cooling joker is thus badly needed in order to maintain CO2’s high climate sensitivity.
In March 2015 we saw some progress in the aerosol discussion. One of the authors of the latest IPCC report claimed that the range of uncertainty concerning the effect of aerosols on climate had been greatly reduced thanks to new research findings, and in the meantime there’s been a lot of talk that the cooling potential of aerosols indeed had been significantly exaggerated in the past. The real cooling value is actually at the lower limits of the range assumed up to now by the IPCC.
The most important and boldest claims come from Bjorn Stevens, one of the three directors at the Hamburg-based Max Planck Institute for Meteorology (MPIM). That paper appeared in the Journal of Climate. What follows is the paper’s abstract:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Rethinking the lower bound on aerosol radiative forcing
Based on research showing that in the case of a strong aerosol forcing, this forcing establishes itself early in the historical record, a simple model is constructed to explore the implications of a strongly negative aerosol forcing on the early (pre 1950) part of the instrumental record. This model, which contains terms representing both aerosol-radiation and aerosol-cloud interactions well represents the known time history of aerosol radiative forcing, as well as the effect of the natural state on the strength of aerosol forcing. Model parameters, randomly drawn to represent uncertainty in understanding, demonstrates that a forcing more negative than −1.0 W m−2 is implausible, as it implies that none of the approximately 0.3 K temperature rise between 1850 and 1950 can be attributed to northern-hemispheric forcing. The individual terms of the model are interpreted in light of comprehensive modeling, constraints from observations, and physical understanding, to provide further support for the less negative ( −1.0 W m−2 ) lower bound. These findings suggest that aerosol radiative forcing is less negative and more certain than is commonly believed.
In general one should be careful not to overuse the word “sensational”. But here the word is most suitable. Surprisingly the German media has been deadly quiet on this. A Google news search reveals that there has not been a single article written about the paper. Undesirable news that the media prefer not to make public?
The implications of the paper were immediately recognized within the scientific community. On March 19, 2015, Nic Lewis explained the paper’s far-reaching implications at Steve McIntyre’s Climate Audit and Judith Curry’s Climate Etc.: Also the climate sensitivity gets further limited, and most likely is near the lower limit of the IPCC’s given range. Lewis’s calculations using the new Stevens value yield a most probable mean value for CO2 climate sensitivity (and indeed for the long-term “ECS”) of 1.45°C of warming for each doubling of CO2. The new total range suggested by Lewis ranges from 0.9 to 1.65°C per doubling of CO2. This is far below the IPCC’s latest range of 1.5 to 4.5°C per doubling of CO2.

Figure 1: Range of CO2 climate sensitivity according to calculations by Nic Lewis using the latest Stevens 2015 values. Source.
Bjorn Stevens was fully aware of the avalanche of reactions this would unleash. It is going to take awhile before his IPCC colleagues get over their indigestion and allow the new findings to flow into their modeling work. Until that happens, it is best to avoid any media storm. The MPIM intentionally did not issue a press release to announce the paper. As the English-language media busily discussed the logical consequences of the paper, the MPIM in Hamburg eventually found it necessary to put out a statement. On April 2, 2015, Stevens put out a statement saying that his paper only addressed aerosols and would not be appropriate for speculation on CO2 sensitivity. With it he buys himself a little public peace – for the time being. However the scientific community will not be able dodge the consequences of the paper over the mid to long-term.
 

Share this...FacebookTwitter "
"Three families of beavers are to be introduced on land managed by the National Trust as part of plans to ease flooding and improve biodiversity. Two Eurasian beaver families will be released next spring into enclosures at Holnicote estate on Exmoor, in Somerset, and another group will arrive at Valewood on the Black Down estate, on the border of West Sussex and Surrey.  Beavers were hunted to extinction 400 years ago in the UK for their fur, meat and scent glands. In recent years there has been a series of controlled reintroductions, including one by the government in the Forest of Dean, in Gloucestershire, as solutions are sought to tackle flooding. A wild colony also appears to have re-established itself spontaneously in the River Otter, in Devon. The schemes at Holnicote and Black Down are the first led by the National Trust and have been approved by Natural England. It is not yet clear how many animals will be brought in but it could be as many as 12: six adults and six kits. Ben Eardley, the project manager for the National Trust at Holnicote, said: “Our aim is that the beavers become an important part of the ecology at Holnicote, developing natural processes and contributing to the health and richness of wildlife in the area. “Their presence in our river catchments is a sustainable way to help make our landscape more resilient to climate change and the extremes of weather it will bring.” The beavers, which will live in two wooded enclosures, are one element in a range of measures being introduced at Holnicote that includes a pioneering project to return a tributary of the River Aller to its natural path.  Eardley said: “The beavers will help us achieve a more natural flow pattern, slowing, cleaning and storing water and developing complex river habitats. The dams the beavers create will hold water in dry periods, help to lessen flash flooding downstream and reduce erosion and improve water quality by holding silt.” Releases at both National Trust sites will be into fenced enclosures of 2-4 hectares (5- 10 acres) each so that the impact of the animals on the local ecology and the river can be properly assessed and understood. The beavers will be transferred from Scotland, where they have been successfully breeding since being reintroduced in 2006. The National Trust beavers are expected to breed and when the young become mature they will need to be moved, possibly to other sites owned or run by the charity. David Elliott, the lead ranger for Valewood, said: “Beavers are nature’s engineers and can create remarkable wetland habitats that benefit a host of species including water voles, wildfowl, craneflies, water beetles and dragonflies. These in turn help support breeding fish and insect eating birds such as spotted flycatchers. “There are just a handful of sites in the British Isles that have beavers. This is a different way of managing sites for wildlife – a new approach, using a native animal as a tool. “The beavers will live along the stream at Valewood and gradually create little ponds, dams and rivulets. Making a habitat that is perfect for them and for many birds, amphibians and invertebrates.” Both projects will be monitored with help from Exeter University and others, to note both ecological and hydrological changes to habitat. A footpath passes through the Valewood enclosure and close to one of the Holnicote pens so it may be possible for members of the public to glimpse the animals – though they tend to be active at dawn or dusk and can be shy."
"The Greens have launched what they describe as a radical and transformative manifesto with a warning that this could be the last general election where voters can choose MPs with a realistic chance of stopping runaway climate change. Unveiling the manifesto, based on 10 proposed bills on issues including the climate emergency and an economic vision based on equality, the Green co-leaders, Siân Berry and Jonathan Bartley, said their party was the only one taking the issue seriously.  Speaking at a wildlife centre in south-west London, Bartley castigated Labour and other parties for failing to match their commitment for net zero carbon emissions by 2030, at the centre of the manifesto plan for a “green new deal”. Labour’s conference passed a motion making this commitment, but it is believed the party’s manifesto will water this down. The green new deal would “decarbonise every sector of the economy by 2030, while delivering social justice across Britain”, Bartley said: “Our very planet is ringing the alarm. Hitting snooze for another 15 years simply isn’t an option.” He continued: “The Conservatives say net zero by 2050. Not good enough. The Lib Dems say net zero by 2045. Not good enough. “Labour members said net zero by 2030, but the party appears to be rowing the boat back. Not good enough. While the other parties are catching up, we’re racing ahead into the distance.” Berry told the launch that it was “the last election where we can take the first step down the right path, and that is what we must do”. Speaking afterwards, she stressed: “If we don’t get our carbon emissions down by 2030, there’s a 50/50 chance of tipping into runaway climate change, which doesn’t bear thinking about. “When I was a young person worried about climate change people would say to me: ‘You’re the future, your generation can sort this out.’ I can’t say that to the young generation, because there isn’t time for someone who is 15 now to get into power and do the things that are needed. It’s actually up to this generation of politicians. “Specifically, it’s those people elected in this election. The next set of MPs might be left with an impossible task.” The green new deal would seek to deliver on the 2030 target by reshaping the economy around industries such sustainable energy. The other nine promised bills cover: A second EU referendum. At least £6bn extra a year for the NHS. Scrapping university fees. A “sustainable economy bill” to ensure the economy functions within environmental limits. A “future generations bill”, requiring decisions to consider the needs of the future. Creating a universal basic income. Building 100,000 zero-carbon social rented homes a year. Improving tenants’ rights and lowering rents. Introducing proportional representation voting and an elected upper house of parliament. The Greens hope their distinct offering will cut through, amid signs the party could, as in the 2017 election, become marginalised during a tough Labour-Conservative battle. After good local election results, and an almost 12% vote share in May’s European elections, the party is now polling at about 3%. We believe that the escalating climate crisis is the defining issue of our lifetimes and that the planet is in the grip of an emergency. We know that our readers and supporters around the world care passionately about this too, as so many of you have told us. We want the Guardian to play a leading role in reporting on the environmental catastrophe. So at the Guardian we commit to the following: Read our full environmental pledge  Berry warned there was a danger of the Greens being squeezed but said the electoral system and wider political culture was to blame. “In general elections there’s always a squeeze, a focus on the two big parties. But our system is broken,” she said. Berry highlighted the first TV election debate on Tuesday, in which only Boris Johnson and Jeremy Corbyn will take part, with Berry and other leaders given a brief chance to contribute in a later programme. “The idea you’re going to have two people whose views on Brexit are not that far apart, you’re not going to have anyone there really holding them to account on their promises on the climate emergency, is ridiculous,” she said. “That’s a real symptom of how bad our democracy is in general.” The party, which has formed an anti-Brexit electoral pact with the Liberal Democrats and Plaid Cymru, has set its sights on eight new target constituencies, including Bristol West, Bury St Edmunds, Dulwich and West Norwood, Exeter, Forest of Dean and Isle of Wight."
nan
"The bog at Forsinard stretches to the horizon, a vast mosaic of greens and browns. The tallest plants here grow only ankle high, but even so, walking requires careful attention. Hummocks covered in heather (Calluna vulgaris) or cotton grass (Eriophorum spp.) offer lumpy but secure footing. Soggy patches of sphagnum moss are less predictable. These bogs, in northern Scotland’s Flow Country, are deceptive in more ways than one. Beneath the moss and the heather and the sedge lies one of the planet’s largest surviving expanses of peat – a nutrient-poor, carbon-dense mass of partly decayed organic matter. But here lies the peatland’s hidden strength: a prodigious ability to lock away carbon, making it an important resource in the fight against climate change. The bogs are also home to a diverse assemblage of species, many uniquely adapted to its unusual conditions, and provide a critical breeding habitat for migratory birds. In Britain and beyond, people have drained large swaths of peatland and converted it to pasture or crop land for centuries. An estimated 80% of Britain’s peat bogs have been damaged or destroyed. Today, however, the country is on the leading edge of a global peatland restoration movement, and the programme at Forsinard is among the largest of these efforts. Peat is made up of partly decayed plant parts, pickled in acid released by living sphagnum moss. Plants in the vast bog at Forsinard are both rooted in peat and laying down new peat as time passes – a process that began about 10,000 years ago at the end of the last ice age. A mass of healthy peat is about 90% water, which it filters and purifies, and houses a small group of specialised plants that have adapted to the extreme conditions of a nutrient-poor, waterlogged, acidic habitat. Scientists now know that peat ecosystems are the most powerful carbon sinks on Earth. They are capable of holding twice as much carbon per hectare as a pristine redwood forest, the planet’s second-most carbon-rich ecosystem, says Hans Joosten of the Greifswald Mire Centre in Germany. Scotland’s peat bogs, which comprise more than 20% of the country’s land area, hold about 75% of the carbon locked away in all British soils and vegetation – which is why their restoration has become such a priority. In the 1980s, the British government subsidised a blitz of bog drainage in order to plant exotic trees for marketable timber. (Since the first world war, when a lack of available timber hindered Britain’s war effort, the country has viewed creating forests as a national good.) The resulting plantations of lodgepole pine (Pinus contorta) and Sitka spruce (Picea sitchensis), species native to North America, failed to thrive. The Flow Country had been treeless for thousands of years for good reason. Peat soil is often too acidic and nutrient-poor to support healthy trees, and the Flow Country endures howling winter winds of up to 90mph, which can stunt their growth or yank them out by the roots. During the forestry boom, the government offered grants to those interested in ploughing up natural bogs to plant trees, and provided tax relief to wealthy forestry investors. Overall, 67,000 hectares (165,560 acres) – 17% of the ancient peatland of Flow Country – was drained. Some of Britain’s richest citizens reaped impressive profits, but usable timber was rarely produced. In most cases, the plantations have grown only spindly trees that are unsuitable for lumber, so are used as biofuel or simply abandoned. While these ill-conceived forests haven’t produced much wood, they did trigger one of the fiercest environmental battles in British history. Richard Lindsay had just begun to survey the life of the Flow Country when the government’s timber incentive programme began. He and his colleagues at the UK’s now-disbanded Nature Conservancy Council hurried to record the beauty and biodiversity of wild Flow Country bogs moments before ploughs began ripping them apart to create tree plantations. “We were literally running along right in front of the ploughs,” he remembers. “We would go and survey an area one day, and go back the next day to see the ploughs [pass] right through the area that we’d just surveyed.” Living in pop-up tents, walking long distances across the formidable bog, Lindsay’s crew explored an intricate world where water equalled life. They found a community of different sphagnum and sedge species – some adapted to live on the raised hummocks and ridges, others thriving in the lower, soggier spots. They discovered that the rolling terrain hid mazes of pools, where diving beetles moved busily between the surface and the bottom, caddisfly larvae trundled along inside protective shells they’d built from bits of clay and pebbles, and newts and frogs fed on the insects. This aquatic abundance also supported droves of migratory birds. Ornithologists who rushed to study the Flow Country found a spectacular array of breeding species. In April, when the migratory waders arrive, the bogs come alive with graceful birds flying, calling, and soon after, incubating their eggs. Throughout the spring and summer, wading birds stalk the edges of bog pools, picking off prey to feed their chicks. In addition to offering rich hunting grounds, the bog provides ideal camouflage. The grey, white, and black plumage of common greenshanks (Tringa nebularia), large sandpipers named for the light-green hue of their legs, disappears against the sedge and heather. Golden plover (Pluvialis apricaria) hatchlings look like little more than a heap of sphagnum moss when hunkered down atop the bog. The region is an essential habitat for breeding birds. The researchers found that the Flow Country hosted a startling 66% of Europe’s breeding greenshanks, 35% of the dunlin (Calidris alpina), and 17% of all European golden plovers. Divers – elegant, sharp-billed birds known as loons in the US – also raise families here: black-throated (Gavia arctica) and red-throated (Gavia stellata) divers nest among the small lakes of the blanket bog, often crossing the bog pools with young chicks on their backs. But as plantations grew up, the conifers formed dense, impassable thickets. Predators began to move in – hooded crows (Corvus cornix), red foxes (Vulpes vulpes), pine martens (Martes martes), and others that birds of the bog had never encountered before. The danger zone stretched hundreds of metres around each plantation, eliminating potential nesting habitat for unknown numbers of dunlin, golden plover, and willow ptarmigan (Lagopus lagopus). The new plantations brought other threats to the region’s native species. To prepare their land for timber, plantation owners ploughed up the bog, killing off the blanket of native plants that build peat and hold water on the landscape. Water drained away, eroding gullies and drying out the peat. Lindsay, now head of environmental and conservation research at the University of East London, sees bogs as superorganisms in which the plants work together to manage the flow of water and keep the system healthy. “If you cut an artery in your leg, it’s a small wound but can have profound effects on you,” he says. “In the same way, cutting a small part of a bog can have profound impacts because its entire hydrology is connected.” Armed with data from these scientific surveys, a group of advocates led by the Royal Society for the Protection of Birds (RSPB) and the Nature Conservancy Council launched a full-fledged battle to protect the Flow Country bogs. Finally, in 1988, after about 190,000 hectares (470,000 acres) of UK bogs had been drained and planted with trees, the government ended its financial incentives. By then, the Flow Country had been severely impacted. The RSPB acquired part of it – the 21,000-hectare (51,900-acre) Forsinard Flows reserve – in 1995. Within four years, an additional 146,000 hectares (360,800 acres) of Flow Country bog had been designated as a special protection area under the EU birds directive. At that point, the anti-plantation movement was driven solely by conservation concerns – Lindsay and others were working to protect the peatlands’ native species. It would still be a few years before ecologists came to appreciate another trait of the bog: its ability to store tremendous amounts of carbon (although only if it’s healthy – and wet). When bogs are drained, air exposure speeds up peat decomposition, causing the bogs to haemorrhage carbon into the atmosphere. “Peatland switches from a carbon sink in natural conditions to a carbon source in drained conditions,” says Roxane Andersen, a peatlands scientist at the University of Highlands and Islands in Thurso, Scotland. “Carbon that has taken thousands of years to accumulate could be released in much less time.” Major farming regions in Europe and North America – including the midwestern corn belt and California’s Central Valley – lie on drained peatlands that have been spewing carbon for centuries. “You cannot see these emissions,” Joosten says. “A meadow with cows looks like a rich agricultural landscape. [But] this area emits the same amount of CO2per hectare as driving 135,000 km (83,885 miles) in a mid-size car.” He calculates that drained peatlands produce about 6% of all human-generated greenhouse-gas emissions. “That’s an enormous amount for a source that had not been recognised before,” he says. Today, Scotland is pouring cash into eliminating the very forests that people were paid so generously to plant just decades earlier. The country has spent millions so far, including more than £10m for restoration work at the Forsinard Flows reserve. The Scottish government’s climate change plan aims to restore 250,000 hectares (617,800 acres) of peatland by 2030. Because drained peatlands give off carbon 20 times faster than intact peatlands can sock it away, the priority during restoration efforts is to re-wet the ground. At remote forestry sites, the trees are often so small that it would cost more than the timber is worth to truck it away. In these cases, the felled trees are left to rot in the plough furrows. Bog restoration takes time but today, 16 years after the restoration began, Andersen has found that a location within the Forsinard reserve known as Talaheel – one of the first sites to be forested and one of the first targeted for restoration in 1998 – has switched from carbon source to carbon sink, capturing about 60% as much carbon per hectare as the pristine control site. “Even though some of the plants growing there are not typical of undisturbed bog,” Andersen says, “on balance, they’re taking up more carbon than they release.” Now, with what she’s learned from Talaheel and other restoration sites, she believes that peatlands damaged by plantations can be transformed from carbon source to sink in fewer than 10 years. As she nimbly picks her way across the recovering landscape, Andersen gazes at the mottled emerald and olive of the open bog. She sees hope for the ecosystem’s ability to adapt. “Peatlands have been around for such a long time, slowly but surely forming peat,” she says. “That suggests they’re intrinsically very resilient.” If they can be restored to health, Andersen and other scientists believe that the peatlands will endure, even in a time of unprecedented change. Holding its secrets close, the bog hides a paradise for birds and beetles – and, deeper down, a vast stockpile of carbon we can’t afford to set free. A longer version of this story was originally published on bioGraphic, an online magazine powered by the California Academy of Sciences."
"We’re used to stories of towns and cities waking up to floodwaters invading their homes. In complete contrast, the Australian city of Wangaratta, 230km north of Melbourne, is dealing with a hairy weed invasion that looks like a scene from the horror edit of an American Western film classic. This “hairy panic”, known to scientists as Panicum effusum, is native to the area and is regularly found in pasture fields. It’s known to be weedy, meaning it grows fast and under the right conditions is able to form dense patches. In this instance hairy panic found the ideal conditions to exploit its weedy nature: an extremely dry summer and a nearby farmer said to have left his fields unmanaged.  With little moisture in the air the stems and seed of the plant dry out and are easily picked up and carried along by the wind, moving faster and further under high wind conditions. Houses are perfect barriers to the spread of this plant, entrapping an ever-increasing wall of tumbleweed. Unlike the native hairy panic, the classic tumbleweed from Hollywood westerns is actually a non-native invasive species. This Russian thistle (Salsola tragus) arrived in the US after being shipped as as flax seed to South Dakota in the 1800s. Native species can also be classed as invasive however, as the term generally applies to weedy species which bully out their neighbouring plants. Both plants produce lots of seeds and are blown around, so many of the same rules apply. Russian thistle is also tough to control in dry windy weather conditions.   However, unlike hairy panic, Russian thistle’s economic impact has been measured – it costs millions of dollars to keep highways free from pesky tumbleweeds, and the plant is know to harbour crop pests such as say’s stinkbug or the beet leafhopper which carries a virus that attacks vegetables. There are no known human health risks associated with hairy panic grass, although residents in Wangaratta are definitely not welcoming the disruption to daily routines with open arms. There is concern over sheep and other livestock eating too much of the grass which may lead to a condition called “yellow big head”, causing blistering of the skin. Luckily by the time the plant dries up it is no longer toxic. As hairy panic isn’t considered a fire risk, authorities are unable to assist in this instance – however annoyed locals may be. Perhaps legislation could be put in place for landowners to ensure efficient management of their pastures, particularly if their fields are near residential areas. The plant isn’t very tolerant of heavy grazing, but left to seed it grows rapidly. Grazing control may be considered as a management tool, although perhaps a contentious issue due to possible livestock disease.  Landowners are advised to wet pastures for times when dry conditions allow the weed to roll rampant through the streets. However in inland Australia during summer – hot and dry at the best times – “wetting pastures” is easier said than done. Both hairy panic grass and Russian thistle thrive in inhospitable conditions, such as low soil fertility, and quickly produce enough biomass to drive locals mad."
"
Share this...FacebookTwitterYesterday I wrote a post about how a 44-year veteran German meteorologist poured cold water on the hypothesis of a man-made global warming and pointed out that a change in temperature instrumentation is probably behind much of the reported warming that Germany has supposedly seen since the 1980s.
Klaus Hager also has a website. At this website he posted a meteorological bulletin, which he authored and was published as an annex to the Berliner Wetterkarte (Berlin Weather Chart).
That bulletin was about the results of his eight and a half year study where he compared in a side-by-side test the former glass mercury thermometers with the newer electronic thermometers, which were installed during the 1980s and 1990s by Germany’s DWD German Weather Service.
Earlier mercury thermometer method
Earlier temperature measurement was done using a mercury/alcohol glass thermometer, where readings were taken ten minutes before each hour. The daily mean temperature was computed using the “Mannheimer” hourly values 07h, 14h, and 2 times 21h, all divided by 4. The DWD used this formula until March 31, 2001. The extreme temperatures were read at the glass thermometer at 7 a.m. as the low, and 9 p.m. for the maximum. Temperature was measured inside an “English” weather hut.
New electronic system
The new electronic system, however, employs a completely different sensor technology, known as the Pt 100, where temperature is measured with two measurement sensors that check each other. Each second a value is generated and measured for an entire minute, i.e. minute mean. The daily mean temperature is calculated from 24 values, each at 10 minutes before the hour (e.g. at 8:50 for 9 a.m.) The extreme is calculated from the minute mean values between 00 h and 24h. Today they are recorded inside a plastic hut with slats (at first made of aluminum).
The advantages and disadvantages are listed in the annex below.
Hager writes that although electronic sensors and the comprehensive IT networking implemented by the German DWD Weather Service do offer many advantages, there are also a number of disadvantages which he says are of importance with respect to assessing climate change, especially when comparing old datasets from the mercury thermometers to the new datasets recorded by the electronic sensor technology. He writes that it’s close to comparing “an apple and an orange”.
Results of 8.5 year side-by-side test
Hager compared the two different measurement systems side by side at the GeiInfoAdvisory Office of Fliegerhorst Lechfeld from January 1, 1999 to Jul 31, 2007. The following is a plot of the differences between the two measurement methods:

Figure 1: Differences in the daily maximum temperatures from the Pt 100 compared to glass thermometers for 3124 days (ca. 8.5 years) conducted at the GeiInfoAdvisory Office of Fliegerhorst Lechfeld (from 4) – mean difference 0.93°C.  Figure from Rengelink, 2012)
Clearly the electronic thermometers produced warmer readings than the mercury thermometers.
Worse, Hager says, the German DWD Weather Service did not adequately investigate the two different measuring systems and compare them, writing that:
Although the DWD set up so-called climate reference stations at (way to few) locations and published the studies from the comparison measurements, the results unfortunately were not satisfactory. Here not the “old data was compared to the new data”, instead only the electronic thermometer was investigated in various locations, but were not compared with the glass thermometers, which are readily at hand.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Hager provides an example illustrating why one must be very wary when comparing data from the new electronic instrumentation to data taken from the old mercury thermometers. The following chart depicts an example comparison for the temperature measured using the two different methods on a single day, 12 November 2005:

Figure 2: Pt 100 measurements taken on 12 November 2005 at Fliegerhorst Lechfeld (WMO 10856) station. Red curve (upper) is the measurement sensor of the aluminum enclosure, showing daily mean temperature of 5.9°C. Blue curve (lower) is the Stevenson screen, showing daily mean temperature of only 5.2°C.
Hager writes:
Differing daily measured values from the old and new sensors for temperature measurement spurred the author [Hager] to conduct a comparison spanning from January 1, 1999 to July 31, 2006 at Fliegerhorst Lechfeld (WMO 10856) 8-1/2 years long, daily without interruption, among other comparison tests of mercury maximum glass thermometers in a Stevenson screen and a Pt 100 resistance thermometer inside an aluminum enclosure, both unventilated. The 3144 days yielded a mean difference of +0.93°C; the Pt 100 was higher than the mercury thermometer. The maximum daily difference even reached 6.4°C!
You can see the maximum difference in Figure 1, occurring in early 2006.
Hager also writes that the difference was between 0 – 1°C on 41% of the days, 1 – 3°C on 26% of the days, and over 2°C on 15% of the days [Here we assume that Hager made a typographical error and meant “1 – 2°C”]. Only on 15% of the days did mercury thermometers show higher mean temperatures.
Hager attributes the wide range of differences on factors such as cloudiness, sunshine duration, wind speed and air mass changes. The results, Hager writes, show that:
Earlier measured values cannot be compared to the values measured today for longer term temperature datasets without having interruptions in the overall dataset.”
Not only is the temperature sensing method very different than it was before, Hager writes that also the method for determining the daily mean temperature is different and thus another source of discrepancy. Earlier the “Manheimer” hours (7h +14h + 2 times 21h divided by 4 was used. Today the daily mean is comprised of 24 hourly values from 00 h to 23 h divided by 24.  “This too falsifies the quality of the recorded values,” writes Hager.
Hager concludes:
This all should give the current science something to think about, because actual practice tells us that there is a necessary rethinking when it comes to the theoretical and numerical approaches used for assessing the swings in climate.”
Annex:
Advantages/disadvantages of electronic measurement
Advantages:
– Considerable personnel costs savings due to elimination of visual readings.
– Possible densification of the measurement network through new sensor locations.
– Up-to-date and immediate availability of measured values.
– Extending the spectrum of measurements, e.g. radiation measurement.
– At times high measurement accuracy due to minimal sensor inertia.
Disadvantages
– Lack of comparability between the old measurements and those of the new sensors.
– Thermometer: formerly glass thermometer, today Pt 100 sensor.
– Precipitation measurement unit: formerly Hellmann pan, today with the teetering unit or the new weight measurement of precipitation.
– Humidity: formerly using the hair hygrometer, today it is the dew-point sensor or capacitive sensor.
– Wind speed: formerly using the cup anemometer, today with an ultrasound unit.
– Snow depth measurement: formerly measured by hand, today with laser or ultrasound device.
– Precipitation type and weather appearance of snow, rain, hail, and cloud observation are done by visual observation.
– Increased maintenance requirements for the sensors done by a maintenance center.
– Sensor downtime of various types with disruptions in the climate dataset.
– Onset of measurement techniques through other evaluations of daily means, see: Temperature Measurement at the DWD “Formerly and Today”.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter“O, what a tangled web we weave,
When we first practice to deceive.”
– Walter Scott
============================
By Michael Brakey, New Gloucester, Maine
Part 2/2
As an energy consultant, I have been implementing energy efficiency improvements over the past six years to help transform our very inefficient log cabin home in New Gloucester, Maine into one of the most energy efficient homes in the United States.
In order to measure the results, I wanted to compare apples-to-apples on heating and cooling demands. Therefore, I have been closely tracking and archiving local heating and cooling degree-day statistics over the last decade.
To do this I have local, unfiltered heating degree-day (HDD) history going back to 1893 from nearby Lewiston/Auburn. Seeing people are more familiar with degrees Fahrenheit (0F), I have converted the HDD to temperatures, and averaged them over running 11-year solar cycles. Those results are shown in the following chart:

While I was continually updating my local data, I also had cause to visit the National Oceanic and Atmospheric Administration’s (NOAA) website in January 2013 for data on the entire state of Maine. Here I noticed that NOAA’s data indicated that the state of Maine was a total of 1030F colder over the last 117 years compared to local Lewiston data. That worked out to 0.880F per year for “statewide” Maine compared to Lewiston in a southern interior climate.

That seemed reasonable because of the inclusion of northern Maine. I archived NOAA data for Maine, Ohio, Tennessee and the 48 contiguous states, as one entity.
Adjusted dataset twice in 18 months, adjustments totaling of 254°F
In early 2015, I revisited the NOAA website and updated my HDD and cooling degree-day (CDD) data for a local television presentation. Here I was shocked to discover that NOAA had not only rewritten Maine climate history for a second time in the last 18 months, but with all the tinkering they also screwed up southern interior Maine averages. Southern Maine temperatures were now colder than all of Maine as a whole! NOAA had inflated HDD figures so high that they had lowered Fahrenheit temperatures an additional 1510F summed over the years! Southern Maine interior was now 2540F colder over the last 119 years versus original Lewiston data. This means the NOAA rewrote Maine climate history to the extreme of lowering each year the equivalent of 2.120F per year colder. In order to counter Mother Nature’s recent cyclic cooling, the earlier historic years were lowered as much as five degrees while recent temperatures remained almost untouched.

Black line before adjustments. Green line after adjustments.
Past adjusted downward also throughout the USA
Upon comparing NOAA data from other states that I had archived in 2013 to current NOAA data, I found similar discrepancies:

Ohio’s historical temps were lowered total of 83.80F.
Tennessee’s record had been lowered total of 51.50
The U. S. temps for 48 contiguous lowered total of 73.40

Why all the alterations?
Why would NOAA be dramatically lowering temperature records for Maine as well as for other states? A picture is said to be worth a thousand words. In the following illustration I charted the different phases of change by NOAA in 2011 and then in 2014.


The black line shows the local data that I collected and archived from local Lewiston, Maine websites (see reference 1).
The blue line is data I downloaded in 2013 from NOAA’s website for the entire state of the Maine.
The green line is data I downloaded recently from the same NOAA website for the southern interior region of Maine, which includes Lewiston.

There was little if any difference between NOAA and local data in 1998 – until a few years ago. It was only after Mother Nature started cooling local temperatures that NOAA began altering the climate history record. The chart above shows three versions of a rolling 11-year average of historical temperature data since the early 1900’s for the Lewiston/Auburn area.
NOAA confirmed in writing that it’s altering climate data


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




NOAA was contacted and asked for an explanation. On May 6, 2015, NOAA confirmed in writing the massive changes to Maine’s data. NOAA stated the changes were intentional and justified! NOAA’s written statement included these words:
“…improvements in the dataset, and brings our value much more in line with what was observed at the time.  The new method used stations in neighboring Canada to inform estimates for data-sparse areas within Maine (a great improvement).”
NOAA’s statement about the need to recently introduce colder Canadian data into Maine’s past temperature history seemed fishy to me. How do they explain similar adjustments to the data for Maine’s southern interior region? 
Worse, they made southern Maine colder than the entire state of Maine! They also revised downward historic temperatures for Tennessee, Ohio, and the United States as a whole. Every U.S. state for which I kept archived NOAA data from 2013 had been adjusted in an almost identical manner.
On June 4, NOAA responded through a general Associated Press statement that they continually readjust thousands of weather data points to account for different measuring techniques through the decades (see part of article to right).
Public deserves facts, not fantasy
My question to NOAA is: Why?
Why does NOAA feel compelled to apply different measuring techniques to climate data? Why not give access to the raw collected data? Why must NOAA apply a master algorithm to the data that not only has been proven to be corrupted, but also whitewash major climate cooling events in recent years. The American public should be given facts not fantasy.
Could NOAA explain the recent climate measuring techniques implemented in the spring of 2014 that have resulted in the CD2 southern interior of Maine (seen in blue area of chart to right) being a third of a degree 0F colder per year when compared to the entire state of Maine?
Again this is fantasy over both fact and common sense. The information below is drawn from NOAA’s most current website. Below is NOAA’s most recent “adjusted data’ for Maine on their website.

NOAA simply ignoring reality
The charts above indicate that southern Maine has on average been 1/30F colder than all of Maine for the last 120 years! NOAA’s recent response to all these questions and observations can be found in their June 4th press release. They reiterated the same mantra; ignore satellite data, ignore facts given by non-scientist (and scientists alike) that disagree with NOAA’s climate data enhancements! We should just trust what NOAA tells us.
Trust is lost
Little wonder recent surveys indicated 76% of the American population does not trust the government to do what is right.
NOAA data cannot be relied on
As stated in yesterday’s post, decision makers in the state of Maine, and across America, cannot and should not rely on NOAA data for setting energy policy. If we are indeed experiencing regional cooling, then we should be encouraging insulation and less expensive sources of heating, such as natural gas, heat pumps, geothermal and future technologies associate with thorium and hydrogen.
However, based on NOAA’s data, which indicates a warming trend, lobbyists are focused on electric generation by means of wind and solar. It is important to gather data from other non-governmental sources to make sound decisions. It appears that we presently live in a nation where an agency of the Federal government has rewritten our climate history. Decisions worth trillions of dollars are being made based on fraudulent climate data.
Resources:

Black Swan Climate Theory, April, 2015, Mike Brakey, 1st series of five (5) short YouTube videos on NOAA climate adjustments https://www.youtube.com/playlist?list=PLDXMwo2SyaRse3GWujVHJGTLl9nvGAD59


151 Degrees of Fudging, May 2, 2015, Mike Brakey, Link: https://notrickszone.com/2015/05/02/151-degrees-of-fudging-energy-physicist-unveils-noaas-massive-rewrite-of-maine-climate-history/#sthash.9QtBzze0.SF5o7vzD.dpbs


NOAA E-Mail Confirms Large Scale Rewrite of U.S. Temperature Data, May 6, 2015, Mr. Derek Arndt, NOAA, Link: https://notrickszone.com/2015/05/07/noaa-e-mail-confirms-large-scale-rewrite-of-u-s-temperature-data-in-2014-improvements-in-the-dataset/#sthash.T6Bpcr1O.4fwNcmBn.dpbs


Black Swan Climate Theory II, Michael Brakey, June, 2015.  The six part PowerPoint YouTube series is also found at the following link: https://www.youtube.com/playlist?list=PLDXMwo2SyaRse3GWujVHJGTLl9nvGAD59 . The presentation takes you step-by-step through how it appears that leadership in NOAA unashamedly created a new master algorithm that was applied to the Maine data to rewrite climate history.The “Trick” to Controlling the Climate Agenda, Will be released in June, 2015. See link: https://notrickszone.com/2015/06/01/bombshell-comprehensive-analysis-reveals-noaa-wrongfully-applying-master-algorithm-to-whitewash-temperature-history/comment-page-1/#comment-1028832
Data-Set Changes Makes it Hard to Tell Real Story. See link: https://redneckusa.files.wordpress.com/2014/07/data-set-changes-makes-it-hard-to-tell-real-story.pdf

 
Share this...FacebookTwitter "
"Cities across the world are increasingly at risk from climate change. People living in extreme poverty are especially vulnerable, both because global warming will tend to hit developing countries the hardest, and because they have less money to throw at the problem. We used newly-available data to investigate how cities are responding to climate change and whether resources are being allocated efficiently or fairly. We expected there to be differences in spending between rich and poor. But we did not expect them to be so vast, with New York for instance spending more than £190 (US$260) per person to protect its people and infrastructure from the impact of climate change, while Ethiopia’s capital Addis Ababa spends less than £5 ($7). It seems the amount spent on climate adaptation is driven more by the amount of wealth at risk rather than the number of vulnerable people. Adaptation simply means any actions that anticipate the negative consequences of climate change – to human health, the economy or ecosystems – and attempt to minimise the damage. In big cities this might mean raising sea walls to tackle sea level rise or expanding drains to cope with bigger storm surges. We need a comprehensive picture of how much is being spent on these adaptation measures across the world. The Millennium Development Goals, despite their shortcomings, have demonstrated that measuring a problem provides an invaluable baseline from which improvements can occur. For this study, published in Nature Climate Change, we focused on spending in ten megacities. New adaptation spending figures were gathered and analysed using data triangulation, which draws on many different sources and types of data to arrive at more accurate estimates. Our work on this is part of a wider project on measuring the size of the green economy. Where ever you look, this “adaptation economy” remains a small part of the overall economy – a maximum of 0.33% of a city’s gross domestic product. Yet there are real disparities between cities. As you might expect, developed cities spend significantly more per capita. After all, most things cost a lot more in the US than in Ethiopia, and new drainage systems, air conditioning and so on are no different.  But this same disparity also applies as a percentage of city GDP. The three rich cities we looked at spend nearly half as much again as the developing cities (around 0.22% of city GDP, compared to 0.15%), even though climate change is a far scarier prospect for low-lying, flood-prone Jakarta or already-hot Addis Ababa than it is for London or Paris. Of course, cities in poorer countries have greater competing needs for their finances. Things Londoners or Parisians can take for granted such as clean water or basic healthcare are still pressing issues in Lagos or Mumbai.  Yet such disparity still has to end, particularly as between now and 2050 the major growth in urban populations will be in China, India, Indonesia and Nigeria. In these countries we need to think about how to boost cities’ resilience through far more adaptation funding. It can be done. Just look at Beijing, which stands out because the proportion of its economy devoted to climate adaptation was significantly higher than any other city in the study. Almost half of this was spent on changes to the built environment such as water efficiency retrofitting – a much higher ratio than any other city – with less going towards health or agriculture. The fact the Chinese capital is taking adaptation seriously is linked to strong central government policies, which encourage cities to face up to climate change. In China, all provinces have a comprehensive adaptation plan and a taskforce to deliver it. When governments offer leadership and policy certainty, things will happen. Most cities at least show solid growth in adaptation spending over the past five years, beyond their average GDP growth for the period. But adaptation spending was more volatile in Addis Ababa and Lagos, the cities in the study that spent the least in real, proportional and per capita terms, and heavily-dependent on a few specific projects. This should be a cause for concern. It is clear that insufficient funds are being spent to protect major population centres in developing and emerging economies. Our study is an early warning sign: we must remain focused on protecting people at risk, and not just the “capital”. Read this next: British power stations are burning wood from US forests – to meet renewables targets"
"
Share this...FacebookTwitterBy Ed Caryl
On 1 July 2014, NASA launched OCO-2, the second attempt at orbiting a global carbon dioxide observatory. In December, the first global map was released.

Compare this map with a frame from a previously released video showing a model of what the CO2 distribution was thought to be for roughly the same time period in 2006, the 1st of November.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Note the differences. There is much more CO2 coming from the tropical rainforests than the model predicts, and there is a sink, where CO2 is taken up, over Russia that the model does not have.
Since January, there has been no public disclosure of any further maps from OCO-2 on the OCO-2 website, except for a slide (their figure 5, shown below) from a webinar presentation that took place in February. This covers the period from late November to late December.

Compare this with a corresponding frame from the model video.

The reality measured by OCO-2 hardly resembles the model. The map released by NASA also seems to cut off CO2 sinks in the North Atlantic and Pacific. This may be excused by the sun angle in the Northern Hemisphere in December. NASA is surely learning a lot from OCO-2, but the findings may not be “politically correct”. We must await further data releases.
Share this...FacebookTwitter "
"Energy suppliers often refer to their industry as being caught in a “trilemma”, as people demand electricity that is both secure and cheap, while also being clean. But maybe it’s time to add a fourth consideration to the list – beauty. Just as we marvel at Roman aqueducts or Victorian railways, so we could design power plants, solar panels, turbines and other infrastructure to be beautiful additions to the landscape. As we move away from ugly coal and gas, we have a great chance to celebrate low carbon energy with imaginative new designs. UK energy minister Amber Rudd seems to agree. Speaking last year about nuclear energy, she stated: “I think it is a reasonable ambition to make sure that these big projects have aesthetic appeal as well [as being functional] to help win the public over.” Yet there are two problems to look out for. First, it is unreasonable to merely mask controversial or potentially environmentally damaging developments with a veneer of “attractiveness”. Managing public opinion with pretty designs does not supplant other valid concerns such as the choice of location or huge construction costs.  Second, even where “beautiful” design is sought as part of an environmentally responsible scheme, how individuals define and perceive “beauty” will certainly be a highly variable affair. One person’s majestic wind turbine is another person’s imposing eyesore. Like any type of architecture, judgements about beauty will depend on highly personal preferences, and how the new design relates to its existing context. The quest to find an appropriate aesthetic when designing novel infrastructure is not new. When the Victorians built the UK’s railway system a century and a half ago, the scale of this new technology and the visual and environmental changes it brought to urban and rural landscapes alike were immense – and hotly debated.  Engineers and architects designed large viaducts and impressive stations to be beautiful as well as functional. Though their alien structures were decried by some as ugly impositions, with time those same buildings have come to be part of the cherished character of British landscapes.  In the 1950s, nuclear power once again called for unprecedentedly large and unusual buildings. At Trawsfynydd in Wales, the leading designers of their time took up the challenge. Architect Sir Basil Spence and landscape architect Dame Sylvia Crowe designed a nuclear power station in a bold modernist style.  Although decades have passed and the plant has been decommissioned, opinions about its aesthetic value continue to be divided; some praise the architecture as “optimistic, triumphant [and] pioneering” while others would be happy to see the building completely disappear. We need innovative and sensitive design ideas for new energy systems, not just to “win over” the public but to actually improve the environment. Recent examples of well considered and multifunctional energy landscapes do exist.  At Georgswerder Energy Hill in the German city of Hamburg,  large wind turbines stand proudly atop an artificial mountain of landfill in a post-industrial area. Purified groundwater onsite is captured and used for energy, and the sunny side of the mountain is graced by solar panels. Visitors learn about renewable energy at a visitor centre before walking up to an elegant public “horizon line” walkway that encircles the mountain and gives expansive views of the city beyond.  In Norway, the Øvre Forsland hydroelectric power station similarly aims to be educative, to reflect the local context, and to unapologetically attract attention. One interesting example on the drawing board is the proposed Tidal Lagoon Swansea Bay. The power station consists of a large artificial lagoon formed by a sea wall, with water allowed in and out through underwater electricity turbines. Electricity is harvested from the difference between low and high tides. The plans include space for walkers and cyclists along the top of the sea walls, and an iconic, ark-shaped offshore visitor centre (pictured above, by Juice Architects) on the far side of the lagoon. Landscape architects LDA have already received the highest accolade in their field – the Presidents’ Medal – for creatively developing a scheme which “puts place-making at its heart and seeks to integrate a major renewable energy project into the lives of local people”.  Given the grim consequences of climate change and the political stakes associated with generating energy, the question of aesthetics may seem trivial. Investments in renewables obviously need to be based on more than just appearances. However, as society quickly transitions to better sources of energy, designers are embracing the opportunity to reflect and celebrate the change. Seeing how big power plants, as well as hugely important small-scale community initiatives, can fit within the landscapes that people use and enjoy is a real challenge.  There will probably never be a power plant or solar panel that everyone deems beautiful. But debating beauty and design alongside function is vital to achieve better renewable energy developments."
"Germany’s automobile industry is its most important industrial sector. But it is in crisis, and not only because it is experiencing the effects of a recession brought on by Volkswagen’s cheating on emissions standards, which sent consumers elsewhere. The sector is also facing the existential threat of exceedingly strict European Union emissions requirements, which are only seemingly grounded in environmental policy. The EU clearly overstepped the mark with the carbon dioxide regulation that went into effect on 17 April 2019. From 2030 onwards, European carmakers must have achieved average vehicle emissions of just 59 grams of CO2 per km, which corresponds to fuel consumption of 2.2 litres of diesel equivalent per 100 km (107 miles per gallon). This simply will not be possible. As late as 2006, average emissions for new passenger vehicles registered in the EU were around 161 g/km. As cars became smaller and lighter, that figure fell to 118 g/km in 2016. But this average crept back up, owing to an increase in the market share of gasoline engines, which emit more CO2 than diesel engines do. By 2018, the average emissions of newly registered cars had once again climbed to slightly above 120 g/km, which is twice what will be permitted in the long term. Even the most gifted engineers will not be able to build internal combustion engines (ICEs) that meet the EU’s prescribed standards (unless they force their customers into soapbox cars). But, apparently, that is precisely the point. The EU wants to reduce fleet emissions by forcing a shift to electric vehicles. After all, in its legally binding formula for calculating fleet emissions, it simply assumes EVs do not emit any CO2 whatsoever. The implication is that if an auto company’s production is split evenly between electric vehicles and ICE vehicles that conform to the present average, the 59 g/km target will be just within reach. If a company cannot produce electric vehicles and remains at the current average emissions level, it will have to pay a fine of about €6,000 (£5,150) per car, or otherwise merge with a competitor that can build electric vehicles. But the EU’s formula is nothing but a huge scam. Electric vehicles also emit substantial amounts of CO2, the only difference being that the exhaust is released at a remove – that is, at the power plant. As long as coal- or gas-fired power plants are needed to ensure energy supply during the “dark doldrums” when the wind is not blowing and the sun is not shining, EVs, like ICE vehicles, run partly on hydrocarbons. And even when they are charged with solar- or wind-generated energy, enormous amounts of fossil fuels are used to produce EV batteries in China and elsewhere, offsetting the supposed emissions reduction. As such, the EU’s intervention is not much better than a cutoff device for an emissions control system. Earlier this year, the physicist Christoph Buchal and I published a research paper showing that, in the context of Germany’s energy mix, an EV emits a bit more CO2 than a modern diesel car, even though its battery offers drivers barely more than half the range of a tank of diesel. And shortly thereafter, data published by VW confirmed that its e-Rabbit vehicle emits slightly more CO2 than its Rabbit Diesel within the German energy mix. (When based on the overall European energy mix, which includes a huge share of nuclear energy from France, the e-Rabbit fares slightly better than the Rabbit Diesel.) Adding further evidence, the Austrian thinktank Joanneum Research has just published a large-scale study commissioned by the Austrian automobile association, ÖAMTC, and its German counterpart, ADAC, that also confirms those findings. According to this study, a mid-sized electric passenger car in Germany must drive 219,000 km before it starts outperforming the corresponding diesel car in terms of CO2 emissions. The problem, of course, is that passenger cars in Europe last for only 180,000km, on average. Worse, according to Joanneum, EV batteries don’t last long enough to achieve that distance in the first place. Unfortunately, drivers’ anxiety about the cars’ range prompts them to recharge their batteries too often, at every opportunity, and at a high speed, which is bad for durability. As for EU lawmakers, there are now only two explanations for what is going on: either they didn’t know what they were doing, or they deliberately took Europeans for a ride. Both scenarios suggest that the EU should reverse its interventionist industrial policy, and instead rely on market-based instruments such as a comprehensive emissions trading system. With Germany’s energy mix, the EU’s regulation on fleet fuel consumption will not do anything to protect the climate. It will, however, destroy jobs, sap growth, and increase the public’s distrust in the EU’s increasingly opaque bureaucracy. • Hans-Werner Sinn, is professor of economics at the University of Munich. He was president of the Ifo Institute for Economic Research, and serves on the German economy ministry’s Advisory Council.  © Project Syndicate "
"The furore that erupted when David Slater, a British wildlife photographer, released a “selfie” taken by a macaque monkey in 2015 has only just reached legal resolution. The animal rights group, PETA (“People for the Ethical Treatment of Animals”), which had filed on behalf of the macaque, allegedly named “Naruto”, withdrew its suit against Slater when he agreed to give 25% of any royalties from the selfie to animal welfare charities. This case marks a high-profile opening salvo in a struggle that will be increasingly fought among animal rights activists, protectors of human intellectual property and defenders of the free market. The case has been generally reported as being about whether a macaque that took a selfie (and gained worldwide notoriety courtesy of Wikipedia) is entitled to copyright. While this account is fine as far it goes, the case also hints at the profound challenges that digital and animal cultures pose to the law’s recognition of human uniqueness. The story begins with Wikipedia, whose “open source” and “open access” approach to knowledge production makes it the ultimate free market in cyberspace. Basically anything is fair game for inclusion on its pages if it is not prohibited either by its own editors, who are largely crowdsourced, or some explicit legal ruling. When Wikipedia’s editors decided to feature the macaque selfie, Slater claimed that it was in violation of his copyright. The selfie had been taken while his camera was active but unattended in Indonesia, where he was on assignment photographing the rare monkeys. Wikipedia replied by saying that if anyone owned the copyright, it was the macaque who actually took the selfie. At that point, PETA got involved, suing Slater on behalf of the macaque for copyright infringement. The court had no problem dismissing the case, simply by arguing that copyright law was not designed to include animals as copyright-holders. But it also said that the law may be amended to include them in the future. In doing so, it tiptoed around the issue that PETA was keen on raising, namely, whether the monkey was morally entitled to whatever royalties might otherwise accrue to Slater as the copyright-holder. This helps to explain the out-of-court settlement, which left Slater the formal victor in the case. But that was really all that he was left with. Slater had been earning minuscule royalties from the selfie and even approached bankruptcy as PETA’s case against him dragged on. The most striking feature of the case is not the very idea that a monkey might hold copyright, but that the internet’s relatively unregulated market environment provided the opportunity to broach the issue. The placement of a photo in virtual as opposed to physical reality radically loosens our intuitions about ownership. This became clear in the recent flurry of cases around the multiple postings of nude celebrity selfies in social media. Defendants claimed loss of control over their image in a world where image control is everything. In a more profound sense, something similar is happening to the image of the human being itself in the monkey selfie case. The monkey selfie case managed to level the playing field between the human and the animal because the distinction between producer and consumer is largely erased in cyberspace. Unless the law intervenes, an online object can be reframed and reappropriated as the user wishes. And among these reframings and reappropriations are accounts of what makes the object what it is. In the end, only the explicit disqualification of animals from copyright law ended up saving Slater, even though some legal experts admitted that Naruto may have behaved toward the camera in a way that would make a comparably situated human eligible for copyright. Faced with Slater’s original claim to copyright infringement, Wikipedia interestingly gave little weight to the core of Slater’s argument, which was that had he not gone to Indonesia, photographed the macaques and even set up the camera so that they might use it, the selfie would never have been taken. (Of course, Slater was also the one who allowed the photos to go online in the first place.)  Instead Wikipedia focused on the particular monkey’s skill in arranging the camera so as to take the striking selfie. To the ears of animal rights activists, Wikipedia made Slater sound like an employer who claims ownership over his employees’ labour because he took the effort to set up the business for which they work. When only humans are involved, it’s called exploitation. Why not extend the same concept to the macaques? Whatever may have motivated Wikipedia to pursue this framing of the situation, it certainly resonates with the history of extending human rights. Thanks to Karl Marx, we understand exploitation as a form of injustice that comes when workers are denied the full fruits of their labour. Wikipedia opened the door to revisit Marx, and PETA charged through it. The original capitalist rejoinder was that the employer is the one who takes the initial risk, invests the capital and sets up the environment which makes the work possible and so the workers, who might otherwise not be employed, should be satisfied with a steady wage, not a share of the profits. One hears echoes of Slater’s defence here, including his claim that his photography was part of an effort to save the macaques from extinction. But bound up in this dispute is a disagreement about whether all producers are also creators. Historically, in the human sphere, Marx ultimately won this argument, largely by appealing to a conception of the human that is both universal and exceptional: all (but only) humans are both producers and creators. Like today’s copyright law, Marx recognised a clear species barrier between humans and other animals when it comes to creativity.  Cyberspace’s blurring of the producer/consumer distinction may be opening the door to reimagining “creator” more generally, as the source of whatever makes an object valuable to its user. In that case, the law may need to be adjusted to provide legal protection to “creative” animals in the same spirit as it historically provided protection to “creative” workers."
"Jeremy Corbyn has launched the most radical Labour manifesto in decades, promising an “investment blitz” that would leave no corner of the UK untouched and welcoming the hostility of billionaires, big business and dodgy landlords. Speaking at an upbeat event at Birmingham City University, where students and activists leaned over balconies adorned with banners setting out Labour’s policies, Corbyn urged the public to vote for “hope” at the general election in three weeks’ time. At the centre of the manifesto, called It’s Time for Real Change, is a large increase in public investment, funded by taxes on corporations and top earners. The Labour leader called it “a manifesto full of popular policies that the political establishment has blocked for a generation”, and it appeared significantly more radical than the party’s 2017 programme. Corbyn insisted that, as Labour has promised in 2017, there would be no tax rises for 95% of earners, with only those on incomes of more than £80,000 being affected. “You can have this plan for real change, because you don’t need money to buy it: you just need a vote,” he said. A Labour government would also give public sector workers a 5% pay rise next year, helping to offset the impact of the 1% pay cap that has been in place for several years, the manifesto says. One key revenue-raiser is an £11bn windfall tax on oil and gas companies which would create a “just transition fund” to help shift the UK towards a green economy without causing mass job losses. The one-off tax would be calculated according to an assessment of each firm’s past contribution to the climate crisis, Labour said, and could be paid over a number of years. The total is 10 times the £1.1bn the Treasury expects to raise from the oil and gas sector this year. Corbyn said: “We can no longer deny the climate emergency. We can see it all around us, as the recent floods in Yorkshire and the east Midlands have shown. We have no time to waste. The crisis demands swift action, but it isn’t right to load the costs of the climate emergency on to the nurse, the builder or the energy worker. “So a Labour government will ensure the big oil and gas corporations that profit from heating up our planet will shoulder and pay their fair share of the burden with a just transition tax.” The windfall tax is one of the most striking policies in Labour’s manifesto, and follows a string of significant announcements during the general election campaign, including: Free broadband for all, paid for by taxing tech multinationals and part-nationalising BT. A pledge to build 150,000 council and social homes a year by the end of the parliament. Six years of free training for adults and 1,000 new Sure Start centres. With Boris Johnson pressing home the Tories’ message that he will “get Brexit done”, Labour has been keen to shift the election debate to domestic policies – including its determination to tackle the climate crisis. Corbyn has also repeatedly underlined his determination to take on big business, deliberately putting himself on the side of “the many”, against “the most powerful people in Britain”. The proceeds of the new tax would go towards adapting the economy to tackle the climate crisis, including retraining workers from the oil and gas industries and investing in green technologies. As expected, Labour’s migration policy is significantly less liberal than the open borders motion passed at its conference in Brighton. The relevant passage says: “If we remain in the EU, freedom of movement will continue. If we leave, it will be subject to negotiations, but we recognise the social and economic benefits that free movement has brought both in terms of EU citizens here and UK citizens abroad – and we will seek to protect those rights.” Labour is also publishing a separate “grey book” alongside its manifesto, to show how it will fund its promises. It detailed tax increases worth £82bn a year. These would include a £9bn a year tax on financial transactions – the buying and selling of shares. Higher earners would also face tax increases, with those paid more than £80,000 subject to a 45p rate, and a new “super-rich” rate of 50p for those earning more than £125,000. Many of the new costs will fall on business, with income from dividends and capital gains being taxed at the same rate of income, for example. Labour’s trade union supporters have insisted that its ambition of making progress towards net zero carbon emissions by 2030 must be backed by strong protection for workers – including the creation of 1 million jobs in green industries. The windfall tax may prove controversial in Scotland, where Labour faces a tough battle against the Scottish National party, and where many voters have long felt they never benefited sufficiently from the country’s natural resources. The decision to focus the “just transition fund” partly on retraining oil and gas workers appears to be aimed at assuaging some of those concerns. Corbyn said: “North Sea oil and gas workers have powered this country for decades, often working under dangerous conditions. We won’t hang them out to dry.” In 1997, the New Labour government imposed a windfall tax on utilities companies, which were perceived to have made excess profits in the years after privatisation. The proceeds were used to fund welfare-to-work policies. Labour said £11bn was an estimate and the final figure would be based on an assessment of the cost of the retraining and investments in green technologies. Output from the North Sea peaked in 1999, but the industry is likely to argue that the tax would accelerate its decline."
"
Share this...FacebookTwitterOn the folly scale, the following story is right up there with the Antarctic Ship of Fools.
Unfortunately this one ended in a terrible tragedy.

Global warming researchers Marc Cornelissen and Philip de Roo believed to have perished in the Arctic. Photo Twitter.
The online Spiegel here reports that two Dutch researchers, Marc Cornelissen, 46, and Philip de Roo, 30, are assumed to have died in the Arctic. “They wanted to collect data about the melting ice cover.”
According to Cornelissen’s Twitter site, the pair began their expedition in late March. By early April they has set off on skis across Arctic sea ice accompanied by a husky. They had been posting daily reports at Twitter.
At times Cornelissen tweeted of unusually warm temperatures and even posted audios claiming to be skiing in shorts.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On April 29 things took a turn for the worse and the pair sent out an SOS while traveling near Bathurst Island, approximately 200 kilometers north of Resolute Bay.
On April 30 Cornelissen’s Twitter site posted that the two were missing.
Spiegel writes that it is suspected that one of the pair fell through “thin ice” and that their situation went unknown for a week. A Canadian search party found one body but the other member of the party remains missing. It is assumed that he has perished. Only the husky dog survived.
The site Cold Facts here posted a report stating that the ice conditions there were “very poor”. The two researchers are said to have been experts in their fields. Question: Why were the two trekking on ice conditions described as “very poor”? Shouldn’t experts know better?
Also it needs to be asked if the decision to send out two researchers on foot in dangerous and highly unpredictable conditions was a grossly negligent one. Who approved this? Today modern satellite altimetry and aerial instrumentation can measure ice conditions more far accurately, safely, and efficiently. Why send out two men on foot on thin ice when the Arctic melt season is well under way?
Personally I think the expedition smacks more of a piss-poorly judged publicity stunt by activists, and much less a scientific expedition to explore the unknown. This looks to be highly dim-witted and reckless adventurism in servitude of sensationalist science. There needs to be an independent inquiry into this accident.
Negligence in harsh conditions often carries a lethal price. Unfortunately some of us still have to learn the hard way.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHow many times must a hockey stick be broken, before alarmists stop wetting their beds? … The answer my friend, is blowing in the wind.
======================================
Second climate status report on the Baltic Sea Region: Medieval Warm Period was Half A Degree Warmer Than Today
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
[Translated, edited by P Gosselin]
In mid-May 2015 the second Climate Status Report on the Baltic Sea region was released. It was coordinated by the Helmholtz Center in Geesthacht, Germany. In a press release the institute explained:
The Second Assessment of Climate Change for the Baltic Sea Basin (BACC II), a recently published report, serves as a revision and expansion of the 2008 edition of the BACC book. ‘The current publication for the Baltic Sea area is a regional variant on the global report published by the Intergovernmental Panel on Climate Change (IPCC),’ says Prof. Hans von Storch, Director of the Institute of Coastal Research at the Helmholtz-Zentrum Geesthacht and initiator of the report. The comprehensive scientific survey includes work from 141 scientists from twelve countries. The project team was coordinated by the International Baltic Earth Secretariat at the Helmholtz-Zentrum Geesthacht and consists of meteorologists, hydrologists, oceanographers and biologists.
Warming continues
The current study takes into consideration observed climate changes for approximately the last two hundred years as well as possible changes that might occur by the year 2100. These projections are obtained from computer models. Warming air temperature in the Baltic Sea region has already been verified based on measurements, but the increase is seasonally and regionally different. The most drastic recorded increase in warming to have occurred in the northern Baltic Sea region was 1.5 degrees Celsius between 1871 and 2011 during the spring seasons. This number is well above the global warming estimates of up to one degree Celsius documented in the last IPCC report.”
The folks in Geestacht indeed forgot to mention a small detail in the press release, as you will soon see. The first two chapters of the report deal mainly with the climate development of the last 12,000 years and the last 1000 years:
Pages 25-49: Climate Change During the Holocene (Past 12,000 Years)
Irena Borzenkova, Eduardo Zorita, Olga Borisova, Laimdota Kalniņa, Dalia Kisielienė… Download PDF (1004KB)
Pages 51-65: The Historical Time Frame (Past 1000 Years)
Tadeusz Niedźwiedź, Rüdiger Glaser, Daniel Hansson, Samuli Helama, Vladimir Klimenko… Download PDF (912KB)“


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Obviously the Baltic Sea study goes far beyond the claimed 200 years. So out of curiosity, we examined the first two chapters. In the abstract of the 12,000-year chapter we discovered something interesting (emphasis added):
The Holocene climate history showed three stages of natural climate oscillations in the Baltic Sea region: short-term cold episodes related to deglaciation during a stable positive temperature trend (11,000–8000 cal year BP); a warm and stable climate with air temperature 1.0–3.5 °C above modern levels (8000–4500 cal year BP), a decreasing temperature trend; and increased climatic instability (last 5000–4500 years). The climatic variation during the Late-glacial and Holocene is reflected in the changing lake levels and vegetation, and in the formation of a complex hydrographical network that set the stage for the Medieval Warm Period and the Little Ice Age of the past millennium.”
The pre-industrial climate of the Baltic Sea region was everything but stable. According to the study during the period of 8000-4500 years before today, it was about 1 to 3.5 degrees Celsius warmer than it is today. This corresponds to the so-called “mid-Holocene climate optimum”. This is a warm period that is practically unknown to the public and not very well-liked by the media outlets. Suddenly we find a completely new meaning in the press release’s subheading “Warming continues”. It is getting warmer – but nowhere near as warm as it was during the 8000-4500 year before present period.
At the end of the abstract the attention shifts to the Medieval Warm Period, which is a part of the subsequent chapter by Tadeusz Niedźwiedź and colleagues. In the text describing the last 1000 years we find the well-known climate cycle that the IPCC tried to discard: the Medieval Warm Period, Little Ice Age, Modern Warm Period. The chapter writes:
According to the scientific literature, there are four climatic periods of the past millennium: the Medieval Warm Period (MWP 900-1350), the Transitional Period (TP 1350-1550), the Little Ice Age (LIA 1550-1850), and the Contemporary Warm Period (CW after 1850).”
Just how warm was it during the Medieval Warm period in the Baltic Sea region? Also here with this inconvenient question the authors do not shy away (emphasis added):
Recent investigations of Fennoscandia by Ljungqvist (2010) showed that the MWP [Medieval Warm Period] occurred between 800 and 1300. At that time, warm-season (May-September) temperatures exceeded the contemporary warming of the end of twentieth century by about +0.5°C. The start of the warming was noted between the ninth and tenth centuries, and the peak temperature appeared at the beginning of the second half of the twelfth century. In a winter temperature simulation over the Baltic Sea region (Schimanke et al. 2012) during that time anomalies reached their highest value of+0.8°C for the MWP.”
The text above is a clear statement. The Baltic Sea region was 0.5°C warmer 1000 years ago.
No one wanted in any way that this important condition get mentioned in the press release. How could it have been warmer 1000 years ago than it is today at a time when atmospheric CO2 concentration was extraordinarily low?
Share this...FacebookTwitter "
"
Share this...FacebookTwitterResponse to NOAA’s claim adjustments are improvements
By Mike Brakey
The email from NOAA’s Derek Arndt confirms that they conducted a massive rewrite of U.S. data in 2014. He also confirmed that the 1913 Maine climate data was indeed lowered a whopping 40F as noted in my article, Black Swan Climate Theory.
My response is based on actual unadjusted temperature data from the Lewiston-Auburn area of Maine, which I secured from a local source and provided in prior emails. (I have attached that data and links to the websites the data was extracted from).  As shown in Chart 1, between 1895 and 1937, the Lewiston-Auburn region (Zone 19 in Chart 2) was typically ¾0F warmer than Maine’s overall state average, based on NOAA data I downloaded in 2013.

Chart No. 1 & 2.
This data is the black line on Chart 1. I would expect the Lewiston-Auburn area to be slightly warmer than Maine as a whole because it is in southern Maine. Based on the 2013 data, Maine’s average temperatures were about ¾0F colder or less than those for Lewiston-Auburn during the period from 1904 to 1939, and again from 2008 through the present.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The green shaded area shows what the NOAA data would have looked like if that ¾0F difference had remained constant through 2015.  Looking at the year 1913, I might agree with Mr. Arndt that they had an error and I would understand a temperature correction of approximately  ¾0F, but not 40F.
Contradictory data
I am suspicious of the NOAA data, both the original from 2013 and the revised, between 1940 and 2008 because the Maine average temperatures are so significantly less than those for the Lewiston-Auburn region. The other oddity is that there was a downward trend in temperatures for Lewiston-Auburn starting in 1998. However, both sets of NOAA data show temperatures rising for the state of Maine during that same time period.
As well-intended as I believe most NOAA associates likely are, I implore NOAA to please make available the plain, unexciting, unfiltered temperature data (as typified by the green line in Chart 1 above).  If the RAW temperature data is always made available, I would be happy to entertain any theories and projections NOAA or IPCC wishes to make…as long as we all know the true base line (similar to what we have for the green line in Chart 1 with Lewiston-Auburn historical temperature data).
In conclusion, I implore NOAA to return credibility to its website, by getting out of the statistical smoothing and adjusting business and by just providing the scientific community with the basic unfiltered temperature data at all of its site locales. Let’s stay away from all the havoc created between Charts 3 and 4.

Chart no. 3 & 4.
Watch the entire series of YouTube videos on how I found the NOAA adjustments.
Share this...FacebookTwitter "
"Hermit crabs are well known for their ability to turn an empty shell into protective armour, but it seems that shells aren’t the only armour around. A new species of hermit crab that shelters in solitary corals has been discovered in southern Japan. Details of the discovery, made by scientists at Kyoto University, have just been published in the journal PLOS ONE. With bright red legs and brilliant white claws, the adult crab is just a few millimetres across but is capable of carrying coral bodies that are far larger. Named after the coral it carries, Diogenes heteropsammicola has a lot to gain from having a coral for a home. Throughout their lives most hermit crabs shift from shell to shell to get a better fit, competing with other crabs to get the best deal. But for this particular species, there is no need. Its body sits safely curled up inside a cavity in the coral – a space that grows with the crab, so it never needs to find a new shelter. To add to that, the coral comes with a sting, protecting the crab from would-be predators, like starfish, larger crabs and octopus. The crab certainly gets a good deal here, but what of the coral? Not all corals are the reef-building kind. Solitary corals, like those inhabited by these crabs, are often found on shallow sandy seabeds. Such a lifestyle comes with the risk of being buried by sediment and overturned by strong currents. To combat this, some (known as walking corals) have evolved an incredible partnership with other creatures to shift them out of the sand and on to pastures new. Walking corals literally use other species to do their walking for them. Until now, the key coral-shifting creatures we knew about were “sipunculans” – a type of marine worm that, in exchange for accommodation, would shuffle corals across the seafloor. Relationships like this are known as symbiotic and each partner, accordingly, is known to science as a symbiont. It is very unusual for a symbiotic relationship to change and – if it does – the new partner is usually from a closely related species. This is because both symbionts are heavily dependent on each other. They are also highly specialised, which makes working with another partner difficult. But hermit crabs have now been found inhabiting some of the corals in the Amami Islands, part of a chain that stretches southwards from Japan towards Taiwan. The crabs filled the exact same cavity often occupied by worms. They filled the same role: walking the coral out of trouble, and they even received the same shelter benefits in return. So how did this come about? I contacted Momoko Igawa, one of the scientists who made the discovery while surveying corals in the Amami and Okinawa Islands. She told me that typically a young coral first settles on a small shell that has already been colonised by a sipunculan. “The coral then grows over and ultimately beyond the shell, providing a coiled cavity for the equally growing worm partner,” she explained. It seems likely that a similar process led to hermit crabs inhabiting the corals. The corals provide shelter for the hermit crabs, protecting them from predators. In turn, the crab transports the coral about the sea floor, rescuing it when overturned by strong currents and stopping it from getting stuck in a sediment overload. As Igawa points out, these are mysterious animals with a remarkable evolutionary history."
"Gas is hugely important to the UK. The country uses more than 65 billion cubic metres to heat most of its 25m homes and generate around a quarter of its electricity each year. Despite efforts to move to renewable energy sources such as wind and solar, demand for gas is likely to remain high for the foreseeable future. Until 2004 all the gas the country needed was sourced from the UK, primarily from the North Sea and East Irish Sea. Since then, production has declined to the point where indigenous gas provides only 45% of the total. The shortfall comes from European pipelines (38%), particularly from Norway and Russia; and liquid natural gas (LNG) deliveries (17%), primarily from Qatar.  This dependency on foreign gas is precarious to say the least. We saw this in March 2013, for example, when an unseasonal cold snap almost left the country short of supplies. It was averted by an LNG delivery docking at Milford Haven in Wales in the nick of time.  This late in its lifespan, conventional new gas exploration in the North Sea is unlikely to reverse this situation. This is why many argue that the UK should consider all options, including onshore shale gas. They point to its success in the US and the recent announcement that Centrica will decommission the UK’s main gas storage site in the southern North Sea, making the country even more reliant on imports to meet the demand.  Meanwhile, opponents raise understandable concerns about the environmental impact of the hydraulic fracturing – fracking – that would be involved and on the industrial scale required. This seems to have resonated with the public, with support for fracking recently hitting an all-time low of 17%. The Conservatives included a commitment to shale production in their June election manifesto, but only if “we maintain public confidence in the process”.  Yet both sides tacitly assume that fracking would work if exploration drilling went ahead. They pay little attention to whether the country’s geology is suitable for shale oil and gas production. The implication is that because fracking works in the US, it must also work here. In fact, the UK’s geological history suggests this is probably wrong.  For a “sweet spot” suitable for commercial fracking, a number of geological criteria need to be met. The source rock needs a relatively high organic content, a good thickness, sufficient porosity and the right mineralogy. The organic matter must have been buried and heated in such a way as to produce large amounts of gas. There must also be a relatively simple geological structure.  The most successful US shale areas, such as the Marcellus, Barnett, Haynesville and Bakken, all lie at depths and temperatures that mean they are ready to expel their oil and gas when fracked. The basins in which these occur are primarily in relatively stable, undeformed areas away from the edges of active tectonic plates, which geologists refer to as “intracratonic” basins. They are characterised by continuous layers of rock with only gentle dips and few fractures or major faults. This all aids subsurface imaging, gas/oil detection and the directional drilling needed for shale exploration.  A cursory look at the geological map of the UK shows a very different proposition. The whole land mass has been significantly uplifted by a chain of geological events that started some 55m years ago with the upward rise of a plume of magma under Iceland. This helped break the tectonic plate in two, pushing Greenland and North America in one direction and the eastern segment containing the British Isles in the other, forming the Atlantic Ocean in between.  The crust moving east buckled against the stable tectonic interior of continental Europe, not only uplifting the British Isles but also tilting it so that north-west Scotland was elevated the most. For this reason, the oldest rocks in the UK are in places such as Lewis and Harris while the youngest ones occur in south-east England.  This movement profoundly affected many of the basins of sedimentary rock that make up the British Isles – including those considered to contain large shale resources. Areas once buried sufficiently deeply to experience temperatures where oil and gas are generated were lifted to levels where this could no longer occur – unlike in the US where the relevant rock formations remain at their greatest depth of burial today.  The UK rock formations have also been highly deformed by the buckling to create folds and faults that cause the shales to be offset and broken up into compartments. At the same time, the activity created pathways that have allowed some of the oil and gas to escape. One example is the Weald Basin of southern England. What originated as a major area for sedimentary deposits in the Cretaceous period between 65m and 145m years ago was subsequently deformed into a major anticlinal arch, such that the original basin now sits in its uplifted core. The margins of this tectonic fold are particularly well defined since they are marked by the steeply dipping chalk ridges that form the North Downs and South Downs in south-east England. As for other UK basins said to hold large quantities of shale gas, like those containing the Carboniferous Bowland Shale in Lancashire and West Lothian Oil Shale in Scotland, they went through an additional previous episode of deformation about 290m years ago. This has compounded their structural complexity.  In short, even where a shale source in the UK may have high organic content and thick and favourable mineralogy, the complex structure of the basins will be detrimental to ultimate recovery. Yet the only question that has been addressed to date is how large the shale resource could be in the UK. The inherent geological complexity of the sedimentary basins has not been fully appreciated or articulated. As a result, the opportunity has been overhyped and reserve estimates remain unknown.  At the very least, there is a need to factor this considerable and fundamental geological uncertainty into the economic equation. It would be extremely unwise to rely on shale gas to ride to the rescue of the UK’s gas needs only to discover it is 55m years too late."
"Outdoor air pollution is responsible for around 40,000 deaths in the UK each year, according to a new report by the Royal College of Physicians. It’s a scary headline number. However just as significantly this is also one of the first reports to recognise how important indoor air quality is to our health. After all, we spend around 90% of our time inside, whether at home, at work, or commuting. Indoor air pollution is not a new phenomenon. Since the dawn of history, humans have burnt wood, peat or coal to produce heat. The walls of caves, inhabited millennia ago, are covered with layers of soot and mummified bodies from the stone ages often have blackened lungs.  A passage in Leviticus indicates that Biblical people were aware that damp buildings were a health risk. In the 18th century it was recognised that “want of ventilation” resulted in increased rates of infectious disease. By the mid-19th century it was being reported that “deficient ventilation … (is) more fatal than all other causes put together”. Around the 1960s research into indoor air quality really began to take hold. Initially it highlighted the dangers of radon and tobacco smoke before extending to formaldehyde (a common household chemical that can cause cancers and respiratory problems) in the early 1970s, house dust mites and sick building syndrome later that decade, and eventually focused on allergies during the 1990s.   Since the millennium interest has moved towards developing countries where around 3 billion people cook and heat their homes using open fires and simple stoves burning wood and coal. The subsequent indoor air pollution results in 4.3m people a year dying prematurely.  The World Health Organisation estimates around 99,000 deaths a year in Europe from indoor pollution. Assuming these deaths are equally distributed across Europe one would expect around 9,000 deaths in the UK. While there is legislation to reduce exposure to pollutants in the workplace, as well as tobacco smoking legislation that now prohibit smoking in public spaces, it is extremely unlikely that any government would try and impose air quality standards in private homes. A typical home has lots of different sources of pollution: heating, cooking, cleaning, smoking, perfumes and furnishings. Even the simple act of moving about stirs up particles. Demands to improve the energy efficiency of buildings comes with the concern that more airtight homes could have an adverse effect on indoor air quality. The air inside your home may already contain all sorts of unwanted stuff such as particulate (microscopic bits of solid or liquid matter), carbon monoxide, oxides of nitrogen, formaldehyde, radon, and volatile chemicals from fragrances used in conventional cleaners. Then there are the “bioaerosols” – bacteria, fungi, viruses, house dust mites and bits of skin shed by furry or feathered animals. Even peeling an orange has been shown to increase the number of particles by several orders of magnitude. Although some indoor pollutants are unavoidable, there are various ways to reduce your exposure: Do as your grandparents did and open the windows to increase the ventilation. If you’re cooking it is important to use the extraction fan otherwise levels of nitrogen dioxide can exceed those on the most polluted roads. Don’t smoke indoors or use candles. If you have a wood-burning fireplace ensure it is fitted and used correctly.  Install a carbon monoxide detector as this “silent killer” leads to around 40 deaths each year in the UK. Chose hard-surface floors. They’re easy to clean, and carpets can let dirt and pet hair escape back into the air. Try to keep the humidity level in your home between 30% to 50% and always ensure proper ventilation in damp areas, such as bathrooms. This helps prevent mould which has been linked with upper respiratory tract symptoms. Some people are more sensitive than others including babies and children, elderly people, and those with respiratory problems such as allergies and asthma. Use a doormat to prevent dirt from entering into your home and/or ask people to take off their shoes when they visit you. Reduce your use of cleaning products or air fresheners,  especially those containing limonene (which gives the lemon citrus smell). Get some houseplants. Studies by NASA and the University of York for the BBC both found that plants could reduce levels of formaldehyde in the home."
"
Share this...FacebookTwitterIf there is anything that I can say about the German power grid, it is that power outages have been very rare since I’ve been here. But lately the ones that do occur seem to be doing so far more frequently, and there’s been a lot of talk about grid operators having to constantly intervene to prevent blackouts – something they rarely had to do 10 years ago.
Today T-Online news site here reports that areas near Cologne, Germany blacked out over the Easter weekend. Amusement park Phantasialand lost power three times – in 24 hours!
Hat-tip: DirkH
T-Online writes of “power chaos” as electricity went out for 45 minutes on Sunday and blacked out twice yesterday.
The cause of the outages is being attributed to “technical faults” and a “power supply error”. Parts of the Cologne area, for example the city of Bruhl where the power utility is located, also lost power.
There’s no indication that the erratic green energies such as wind and sun are behind the Easter weekend blackout. My guess is that in this case they are not because the weather conditions were quite stable and saw no spikes of any kind. Yet German blackouts seem to be occurring more frequently as the capacity of sun and wind increases.
Blackouts beoming more common
In 2005 a late November snowstorm across northern Germany caused power transmission towers to collapse under the weight of snow and ice, knocking out power for hours and even days in some regions.
In November 2006 a large part of Western Europe was blacked out as power giant E.on miscalculated on how to handle 10,000 megawatts of wind energy flowing through the power grid. The English Wikipedia page fails to mention anything about the wind energy.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In November 2012 the power in parts of Munich went out due to “a defective line”.  Also read more here. Later a city utility spokesman said, “It is suspected to be a power spike that somehow got through.”
Last year again in Munich during the busy Friday morning rush hour the power for 20,000 households went out because of a blown transformer station.
Germany’s power supply has become far more erratic and uncontrollable lately. The power chart for the last two weeks shows the tremendous power spikes that Germany’s power grid had to endure during recent stormy weather.

Source: Agora
The above chart shows a major and sudden power spike occurring on March 29 and a super spike that went off the chart on March 31 when a massive 76 gigawatts of wind power got uncontrollably fed in at 1 p.m. How the grid operators went about handling this may be the topic of a later post.
One thing is clear: the situation on Germany’s power grid has gotten far more unstable. German center-left/green weekly Die Zeit here conducted an interview with power expert Frank Umbach. When asked the question of how reliable the German power grid is, Umbach told Die Zeit:
The situation has gotten considerably worse. […] All risk assessments on supply stability show a worsening.”
Moreover Umbach tells Die Zeit that Germany narrowly missed “widespread outages” three times since the country shut down 8 nuclear power plants in 2011 and increased dependency on wind and solar power.
 
Share this...FacebookTwitter "
"When it comes to deciding which plants and animals to protect and which to remove, our approach might make even the most forthright nationalist blush if it were ever applied to people. The central question in the UK and many other countries is whether a particular species is native or non-native.  Rarer natives are more likely to have government money spent on their protection. The UK has a long list of them, including the likes of the spiny cockle, the moustached warbler and the sturgeon. Non-natives, on the other hand, may be rightly targeted for extermination if they threaten significant damage and are spreading fast – Japanese knotweed and rhododendrons being well known “invasive” examples.  On the face of it, native is good and non-native is bad. Not only do we make this distinction at UK level, we do it for species in Scotland, England, Wales and Northern Ireland. It may seem simple, but the very definition is less clear cut than it first appears.  Take the beech tree. This tree has long been considered non-native to Scotland and, in some cases, has been treated as an invader. It has been the subject of many back and forth arguments about whether it should be encouraged or removed.  Beeches colonised the south of England after the last Ice Age. They began spreading north but failed initially to establish themselves. This was due to competition with other trees and the subsequent rampant deforestation of the UK by our ancestors.  Nowadays, beeches are found throughout the UK, but considered non-native to Scotland for two reasons. The first relates to the arbitrary cut-off point that decides these things in the UK: about 7,000 years ago, the time of the post-Ice Age expansion of human agriculture. (Other countries take a different view of time for native/non-native purposes – the US dates it to 1492, the time of European settlement, for example.)  The second indicator is that beeches are considered to have been introduced to Scotland by people rather than spreading of their own accord. In reality, it has been easier to say this than to prove it. The most recent update to species maps for the UK mapped beeches as native “regardless of status” because it was so hard to figure out which had been introduced by people and which had made it themselves.  I recently co-published a paper which removed this uncertainty. By combining DNA evidence with historic information, we were able to identify the origin of populations of beech in Scotland and in northern England.  It is well known that beech grows and reproduces without problems in the Scottish lowlands. So while humans might have speeded its spread, beeches would have taken root in Scotland anyway. This led us to the conclusion that there is no justifiable reason to maintain its status as non-native, and we should just embrace it as another natural occupant of the Scottish landscape.  This beech controversy is strongly linked to our tendency to be resistant to change in the natural world. We think in terms of communities of plants, animals, fungi and bacteria that live together in the same place at the same time, and tend to view these as fixed and unchanging – something we can describe, quantify and map.  In truth, such communities change constantly as species move in accordance with changes in their environment – little different to how humans shift in response to things like war or economic hardship. With plants and animals, we pick a point in time 7,000 years ago and say the community that existed at that time is native and the species stops here.  The tree bumblebee is another interesting example. It is believed to have arrived from the continent under its own steam in about 2001 and spread rapidly up the country.  Like beech, its spread was made easier by humans – in this case by providing bird boxes and roof spaces that these bees are adept at colonising.  The tree bumblebee is a clear-cut non-native according to our established definitions. Yet its colonisation of the UK is believed to have been a natural event that would have occurred (more slowly) without human intervention.  It’s also part of a much bigger trend. A wide variety of species including birds, butterflies and other insects are on the move as our climate warms. Since 1995, some 11 species of dragonflies have returned to or newly arrived in the UK – one in five of all dragonfly species in the country.  We are likely to see many more of these developments as the climate keeps warming, sometimes with serious negative effects. It all challenges one of the fundamental principles of conservation, that of keeping things the same. How, then, do we overcome our resistance to change without abandoning efforts to stop the spread of invasive species altogether?  Certainly where an area is of particular biological, historical or cultural significance, we might continue to spend money trying to keep it that way. But more broadly, it makes sense to think in terms of harm and benefits.  With beech, we might say that while its expansion across Scotland is undoubtedly a threat to some woodlands, it represents a great opportunity when species like ash and oak are at significant risk from new pests and diseases. As for the tree bumblebee, rather than damaging ecosystems, it performs vital pollination services while other pollinators suffer unprecedented declines.  We should continue to use our limited conservation funds to fight invasive species that cause the most damage, while striving to stop human introductions of new species to ever more areas of the globe. But trying to turn back the clock to an arbitrary time in the past is a fool’s errand. Change is the new norm and will be for the foreseeable future. Perhaps the arguments around native and non-native need to stop forever looking back, and start looking forward, too."
"The strain of remaining on message for a whole hour in his head-to-head debate with Jeremy Corbyn seems to have been too much for Boris Johnson. It really wasn’t part of the plan for the prime minister to reveal ahead of time a rabbit due to be pulled out of the hat at the Conservative party manifesto launch – an increase to £12,000 in the threshold at which national insurance contributions have to paid. Although premature, the announcement dovetails with other Tory proposals – higher public spending, an increase in the national minimum wage to £10.50 and the decision not to go ahead with cuts in corporation tax. All are intended to win support among voters in the marginals in the Midlands and the north of England and to defuse the argument that Johnson is only interested in delivering for the rich. At the 2017 general election, the Tories had no offer to counter Corbyn’s anti-austerity programme; this time they do.  The prime minister’s pledge was a bit vague. Did it apply just to employee NICs or to the NICs paid by employers as well? How long would it take to raise the threshold from £8,632 to £12,000? And why £12,000, when it would make more sense to align the NICs threshold with the income tax personal allowance at £12,500? The answer to the last question was simple. Johnson meant to say £12,500 but got the figure wrong. Number crunchers at the Institute for Fiscal Studies have estimated that a NICs threshold at that level would cost £11bn a year if it applied to employees and the self-employed, and £17bn a year if employers were included as well. Quite legitimately, people are going to ask how this promise is going to be met because it is hard to square with the new, watered-down rules for the public finances that the chancellor, Sajid Javid, has come up with. These are that the government can borrow up to 3% of national output for public investment and that day-to-day spending will be matched by tax revenues by the middle of the next parliament. Javid inherited a bit of scope to cut taxes or increase spending from Philip Hammond but the increases in public spending announced in September and changes to the way the public finances are calculated mean that leeway has already been used up. And that’s before slower growth this year is factored into the equation. Hence it wasn’t that long before Tory spin doctors were obliged to come clean about one of the other questions: it would take time to hit the £12,500 threshold. To avoid breaking the fiscal rules or being forced to raise other taxes, the limit will be raised initially to £9,500, with a £2bn price tag. Voters should remember to read the small print. China is a totalitarian one-party state. Protests, as events this year in Hong Kong have shown, are discouraged. But if ever there was a country that needed its own version of Extinction Rebellion it is the world’s second biggest economy. Why? Because China’s appetite for coal-fired power stations is both staggering and scary. It is staggering because demand for the fossil fuel massively outweighs attempts elsewhere in the world to cut back on the use of coal. Thirty countries have agreed to phase out coal-fired power stations and between them in the 18 months to June they reduced capacity by 8GW. Yet over the same period China increased its capacity by 42.9GW. That’s scary because climate scientists say time is running out to tackle global heating. There will be no point in the rest of the world agreeing to the urgent and unprecedented changes demanded by the UN Intergovernmental Panel on Climate Change if a country as big and as resistant to external pressure as China’s growth model means it is pushing in the opposite direction. Globalisation has allowed western countries to outsource not just manufacturing jobs but their carbon emissions to China. At some cost."
"
Share this...FacebookTwitterThe Sun in May 2015, and Atlantic Waves
By Frank Bosse and Fritz Vahrenholt
[Translated, edited by P Gosselin]
Our primary “fusion reactor” remains in a weak phase in its current solar cycle, number 24 since systematic observations began in the year 1749. In May sunspot activity was below normal. The observed sunspot number (SSN) was 58.8. The mean of all previous cycles for the current 78th month into the cycle is SSN=79. Thus May saw 75% of the usual activity.

Figure 1: The current cycle 24 (started in December 2008) is shown in red and is compared to the mean cycle (blue) and to cycle no. 5 (black).
A pronounced lull
Figure 1 shows that current solar cycle 24 has never exceeded the mean (blue) at any time since it began. In the 78 months since the it began, SC 24 has always been below normal. This has never been observed for any previous cycle.  The low solar activity since December 2008 is unique when it comes to its consistency when compared to the other cycles since observations began!
Even when activity reached a maximum in October 2011 in the sun’s northern hemisphere, and in February 2014 for the southern hemisphere, it remained just below the mean value. Together with the delayed start of the cycle we now have a record 10 years of quiet solar activity.

Figure 2: The accumulated sunspot anomaly of all cycle up to the 78th solar cycle month.
Figure 2 depicts a comparison of all the cycles with respect to solar activity. So far the current cycle is in 4th place in terms of low activity. But 3rd place is very reachable because SC 7 saw high sunspot values in its last third of the cycle, and so the chances are good that the total activity of SC 24 will be quieter than the last cycles of the Dalton Minimum.
Atlantic waves…
…are really high when it’s stormy. In early May off the coast of Portugal one of the co-authors of this article came to realize this in a 14-meter long sail boat. But the Atlantic also created other types of waves in the past month. A team of scientists led by Gerard D. McCarthy of the University of Southampton went on the search for internal North Atlantic variability, see www.nature.com/nature/journal.html. They determined that the Atlantic Multidecadal Oscillation (AMO) not only has ups and downs in sea surface temperature (SST) in the extratropic Atlantic region, but that these temperature variations lead to changes in sea level (SSH) along the east coast of the USA. The pattern appears as follows:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Figure 3: The “circulation series” shown in blue. In the paper the SSH variation is determined by comparing the sea level south of and north of Cape Hatteras. The AMO is black. Source: Figure 3 of the cited McCarthy publication.
The relatively long time series of tide measurements at the East Coast is thus a proxy for the ocean heat content (OHC) of the North Atlantic. Its direct measurement since the 1950 entails large uncertainty. But beginning in 2004 it has been much more precise thanks to the submerged ARGO measurement buoys and the RAPID network.
What implications does this study have? First of all, the existence of natural Atlantic Multidecadal Oscillations is confirmed, and not only as a variation in sea surface temperature (SST) as it was previously defined. It is now sure that the AMO is a large-scale North Atlantic water mass circulation pattern. It is an independent internal natural variability of our climate system, and not just one involving global temperature.
Already in January 2013 we pointed to falling North Atlantic ocean heat content (OHC) since 2007. What follows is the data plot:

 Figure 4: The ocean heat content (OHC) of the extratropical North Atlantic since 1979. Source: Climate4you. 
In the paper and its accompanying press release it is explained that the current decline in the OHC means it is announcing that the probability of the North Atlantic cooling more than 10 years is very high. The AMO’s impact on temperatures in the northern hemisphere was major in the past, as the following plot shows:

Figure 5: The AMO (green) compared to temperature changes of the Northern Hemisphere (red). 
If the AMO exists as an internal variability, as the McCarthy paper tells us, then that could imply that 0.5°C warming seen in the northern hemisphere since 1975 was due to the AMO and that the remaining 0.5°C of warming was due to impacts from greenhouse gases and other factors, such as varying solar activity.
For estimating climate sensitivity from greenhouse gases, this has far-reaching implications: Up to now we were not able to completely exclude the impact of aerosols on the cooling of temperatures between 1945-1975, but now it is appearing as increasingly improbable. Indeed it is becoming more evident that the cooling was due to the weakening AMO during that time period (see Figure 3).
If indeed aerosols have a lesser cooling effect than previously assumed, then the climate sensitivity with respect to greenhouse gases must be less.  Since 1975 for the northern hemisphere it was not 0.26 °C / decade increase, but rather only 0.13. This is close to being identical to the southern hemisphere. We’ve often discussed this 50:50 order here …and once again we are confirmed.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMy father used to say that medical doctors were really gangsters in white coats. I used to think he was just being cynical, and so I pretty much dismissed it. Well it turns out his attitude allowed him to live beyond 90, and today I realize he was right all along.
What follows below is a reader comment by MJSnyder that really made my day. A couple of days ago I posted here on the consensus-led disaster of the lipid hypothesis. One reader got all upset about it and attempted to discredit the doctor whom I was citing with the aim of discrediting the science.
Of course one doctor doesn’t make science. But over the past years an entire chorus of doctors have emerged, and they are sharply criticizing the at times fraudulent science underpinning the lipid hypothesis. Even the government, having seen tens of millions of diabetics over the recent decades, has finally begun accepting the new results that fat and cholesterol are not killers after all and that they are actually healthy. Longstanding dietary guidelines are being amended.
I’ve switched to a high-fat, low-carb diet with vegetables and have seen amazing results when it comes to weight and examination test results. No more medicines for me. Of course this really bothers evil Big Pharma. But I’m not the only one who has seen success…
Here’s what one reader sent:
Pierre – Last year you had a posting on your life-style changes that intrigued me, so I followed the links, that lead to more links, that lead…..
I became convinced that the low carb diet was the way to go. So I switched to high fat, low carb. I’m now down 43 lbs, my blood pressure has normalized (now 5 pills less per day), my type II diabetes is controlled (7 pills less). I’ve also dropped Lipitor (cholesterol statin) and no longer have excruciating leg cramps.
My original goal was a loss of 80 lbs, but this has been so easy to attain that I’m thinking of extending it to 100 lbs.
I’m feeling so good about myself again that I’m seriously planning another cross-continent bicycle tour. That would the 3rd. I’m 71 years now.
Thank you Pierre – I’m very grateful for you sharing your personal experiences.
I’m convinced that the Climate Science industry and the Pharmacological industry are fraternal twins.
What’s incredible is that the cure is so simple and only involves nutrition adjustments – nothing more. Tens of millions have the opportunity to get better soon, in less than a year!
I’ve posted a couple of times on nutrition, and I think the reader means this post: https://notrickszone.com/2014/05/10/the-greatest-nutritional-and-pharmaceutical-swindle-of-all-time…
Or perhaps here: https://notrickszone.com/-how-consensus-science-may-have-almost-killed-andrew-revkin/
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn 2009 Al Gore predicted an ice-free Arctic by 2014. It never materialized – not even close.
Not to be outdone, John Kerry upped the ante and boldly proclaimed an ice-free Arctic by 2013. That too was utter nonsense.
In 2010 oceanography researcher Wieslaw Maslowski claimed: “Near ice-free summer Arctic might become a reality much sooner than GCMs predict“. This was reported in the press as “US Navy predicts summer ice free Arctic by 2016“.
Louis Fortier, scientific director of ArcticNet, a Canadian research network, said the sea ice was melting faster than predicted by the Intergovernmental Panel on Climate Change (IPCC).
An earlier National Climate Assessment report wrote that models that best match historical trends project a nearly ice-free Arctic in the summer by the 2030s.

Other real experts were less dramatic with their predictions. For example in 2009 Overland & Wang predicted that there would be an ice-free Arctic in the summer by 2037. A 2006 paper by Marika Holland et al. predicted “near ice-free September conditions by 2040”. Tony Heller, a.k.a. Steve Goddard, has an entire list of ice-free Arctic predictions.
Postponed again to 2050
Now polar conditions have stopped cooperating, and sea ice looks poised to defy the projections. A couple of days ago I wrote here about how natural cycles are now aligning to lead to more sea ice cover over the next one or two decades, and that global sea ice levels are back to normal levels – a fact that the end-of-world obsessors are finding difficult to come to terms with.
The recent sea ice developments even have the government-funded alarmist institutes now in a state of anyxiety. Already we are beginning to see them push back the predicted date of an ice-free Arctic. The latest example come from Germany’s prestigious, yet alarmist, Alfred Wegener Institute (AWI) for polar and ocean research – so reports Germany’s Deutschland Funk national public radio here in an interview with Christiane Habermalz, Arctic Ny Alesund station engineer of the AWI.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the interview Habermalz insists that the Arctic is the “hot-spot” of global warming, and that sea ice is melting faster than expected (Fact: it isn’t at all). She claims that the Arctic is warming 1.3°C per decade, basing that on only two decades of data: from 1993 to present. She also did not hold back from giving the impression that the trend would continue unabated, but then adding:
…in any case during the Arctic summer more and more of the sea ice is melting further and there are increasingly greater ice-free zones. That is something that also the scientists here at Ny Alesund have said, and that when the melting of the sea ice continues the scenario of an ice-free pole by 2040/2050 is very likely.”
2050? That’s a far cry from what we’ve been hearing from other experts over the last years.
There are some interesting statements here. First Habermalz is implying that it will take a sustained 1.3°C per decade of Arctic warming for this to happen. But as most people who have read about the Arctic know, temperatures there go in cycles. The warm cycle has already reached its peak and so the temperature level there needed to melt the ice by 2030 will not be reached. Thus the 2040/50 ice-free scenario won’t happen as calculated by the AWI. (By ice-free, we mean over a number of years, and not a single outlier year, which cannot be excluded). The AWI knows it, and so now we are seeing a conscious postponement of an ice-free Arctic.
Of course expect the AWI and similar institutes to keep ringing the alarm bells, but at the same time quietly move the goalposts back as reality dawns.
Finally, what do the experts project this summer’s Arctic sea ice minimum to be this year? Joe Bastardi tells us at his Saturday Summary here at the 13:15 min mark:

US government NCEP forecast for Arctic sea ice anomaly this year. Source: Weatherbell.
Obviously the AWI has gotten the message, and so now the Arctic horror predictions have been pushed back to a future time, one far enough into the future that by then everyone will have forgotten all the silly, hysterical predictions made during the 2000s.
 
Share this...FacebookTwitter "
"The Brazilian government has earmarked a vast tract of Amazonian land for mining. The so-called “Renca” reserve sits in the last great wilderness area in the eastern Amazon and contains lots of unique rainforest wildlife. The controversial decision to allow mining has since been rewritten to clarify that development cannot take place on indigenous lands that lie within the “Renca”, and then put on hold by a federal judge, pending support from congress. Protected areas such as the Renca are under threat right across the Amazon, and many have already been downsized or downgraded. Conservation is undermined by chronic underfunding of the national environmental protection agencies, the devolving of environmental enforcement to regional states that cannot cope, and by rural violence so severe that Brazil leads the world in assassinations of environmentalists.  The result of all this is an Amazon where 90% of logging is illegal and deforestation is increasing, where unprecedented wildfires burn each summer, and where large vertebrates are now going extinct for the first time since the Pleistocene. Brazil says mining and logging will boost national economic growth. Yet people in the Amazon remain some of the poorest and most marginalised in South America, and there is little evidence this kind of development has enhanced their quality of life. For example, the municipalities of Eldorado dos Carajás, Marabá, and Paraupebas, all of which surround large mining operations, have a human development index lower than that of Libya, a country stricken by civil war. And the construction of the controversial Belo Monte dam resulted in the regional capital of Altamira attaining the highest per capita homicide rate in all of Brazil, equivalent to 25 murders a day if scaled to a city the size of London. First, the companies driving the change are generally big multinationals based either in and around Rio and São Paulo (1,700 miles away) or abroad. Despite some municipal taxes, only a tiny portion of the profits remain locally. Development, as currently practised, also favours the wealthy over the poor. When protected areas are downgraded the chief beneficiaries are landholders who are able to log or mine their territory. Other social groups aren’t so lucky. Some are even actively attacked – either directly, as occurred in the assassination of ten landless movement squatters in a large Amazonian farm, or through legal changes, such as the downgrading of the rights of quilombolas, historical communities descended from African slaves, and indigenous peoples. Brazil’s ongoing “car wash” corruption scandal has led to allegations of worrying links between large development projects in the Amazon, such as the Belo Monte dam, and the diversion of state funds to political parties. If the purpose of development is political gain, there can be little hope for regional citizens.  Both Amazonian people and forests would benefit if we stopped evaluating development schemes solely in terms of the profits they could generate. This sort of narrow, economic assessment cannot truly capture the value of the Amazon’s forests: how do you put a price on conserving unique species, or mitigating global climate change?  The forests of the Renca are some of the most dense and slow-growing in the Amazon basin. Even deforesting just 30% of the area would effectively emit more than four billion tonnes of CO₂ into the atmosphere – equivalent to Brazil’s entire fossil fuel emissions over the past ten years. Unless climate change forms part of the decision making process in the region, Brazil will fail to meet its international commitments such as the Paris agreement. Development must also secure constitutional rights for everyone, not just those of the elites. Brazil currently has so called “differentiated citizenship”, where in practice there is a gradation of rights among citizens, depending on their race, social class or region. Local action is often the only defence against the expansion of mining or dams. Recent examples of a grassroots success include the Munduruku indigenous people, who are forcing various concessions by resisting megadams on the middle Tapajós River. Another example is the  practice of “counter-mapping” among indigenous peoples which entails them mapping their own territorial boundaries to defend their land from industrial agriculture, mining, dams and logging.
 
These alternative approaches are the best way forward in the Renca too. Instead of opening up the area for mining multinationals, Brazil should recognise the rights of local people and empower them to lead decision-making. Brazil nut harvesting is already big in the local economy and, along with ecotourism and carbon-payments (being effectively paid to not chop down a forest), could deliver sustainable development, while leaving the minerals in the ground."
"Australia’s long spell of hot and dry weather that has increased the risk of bushfires is set to continue into summer, with the Bureau of Meteorology warning communities should prepare for more severe fire danger. The BoM’s summer outlook shows a higher than usual chance of above-average day and nighttime temperatures for most of the country, and an above-average chance of drier than average conditions for large parts of eastern Australia.  The bureau said spring, which brought catastrophic fire danger to the east coast, was likely to have been one of the driest on record. Andrew Watkins, the BoM’s head of long-range forecasts, said there was an 80% chance of warmer than usual days and nights for much of the country through summer. The outlook is similar for rainfall, with coastal areas of Western Australia from the midwest to the Kimberley the only locations showing increased odds of wetter-than-average conditions. “Summer’s looking particularly dry with high odds of drier-than-average conditions right down the east coast, including Tasmania,” Watkins said. A positive Indian Ocean dipole, which moves weather systems that would typically bring rain away from Australia, and a negative southern annular mode, are driving the continued hot and dry conditions. The onset of the northern monsoon is expected in mid-summer, which Watkins said could increase the odds of closer to average rainfall from January and February. But he said communities should be preparing for severe weather risks and a continuation of severe fire danger over the coming months. “We’ve already seen significant bushfire activity during spring, and the outlook for drier and warmer-than-average conditions will maintain that heightened risk over the coming months,” Watkins said. The outlook for heatwaves is also heightened. Australia recorded its hottest summer on record in 2018-19. The recent spring bushfires caused six deaths and destroyed more than 600 homes. The BoM said this spring is likely to have been the fifth driest for NSW and one of its 10th warmest overall. The trend was the same in almost all other states and territories, with the exception of western Tasmania, where weather conditions were cooler and wetter than usual. Victoria recorded record-breaking heat in November in many locations but its mean minimum temperatures for spring are on track to be the lowest since 2003. Meanwhile, firefighters in New South Wales on Thursday were battling more than 150 blazes and issued a warning for residents to prepare for fires to worsen over the weekend. While there were no total fire bans in place for Thursday, the greater Hunter, greater Sydney, Illawarra-Shoalhaven, southern ranges, central ranges and northern slopes were under “very high” fire danger rating, as was the ACT. “With more than 150 fires burning across #NSW and the forecast of more hot and windy weather for the weekend please use this time to prepare. Review your bush fire plan, prepare your properties and discuss as a household what you will do if threatened by fire,” the NSW Rural Fire Service tweeted. On Thursday morning, 64 of the 157 fires across NSW were uncontained. The Bureau of Meteorology said lightning strikes from thunderstorms which hit Sydney and the state’s north-east on Tuesday had sparked fresh blazes, with an estimated 100 new fires igniting in a 24-hour period."
"
Share this...FacebookTwitterCharting the costs and effectiveness of renewable energy in Europe
A comparison of both the capital cost and energy production effectiveness of renewable energy in Europe.
By Ed Hoskins
(Some editing by P Gosselin)
The diagrams below show the cost and capacity factors of the major European renewable energy power sources: onshore and offshore wind farms and large scale photovoltaic solar generation. They are compared to the cost and output capacity of conventional gas fired electricity generation.
First two term definitions:
– Capacity factor:  installed nameplate capacity compared to the actual electrical energy output achieved.
– Capital cost:  comparison with the cost of equivalent electrical output produced by gas fired electrical generation.

Overall European renewable energy has almost 6 times lower capacity than conventional gas-fired power generation and it costs about 16 times more in capital expenditure alone.
In all the capital costs expended by 2013 in Europe amounted to some €1/2 trillion for approximately 170 gigawatts of “nominal” installed renewable energy generation. But because of the reduced capacity factor, those installations provide only approximately 30 gigawatts of real output electrical power.  That output amounts to only about 2.9% of the total European generating capacity of 1024 gigawatts [1].
The following is a table summing up performance of the various wind and solar sources. The

In addition, electrical output of renewable energies wind and solar power is intermittent and non-dispatchable. Their output cannot respond to electricity demand as and when needed. Energy is fed into the the grid in a haphazard, almost entirely random manner – depending on the weather, time of day and season.
In short, it is inefficient, exorbitantly expensive and often unavailable when it is needed, or severely excessive when it isn’t needed. It offers everything that makes a modern economy uncompetitive.
Renewable energy technologies
When it comes to wind and solar power, onshore wind power is the most effective form of renewable energy in terms of capital cost. It only costs approximately 9 times as much as conventional power generation. On average across Europe, the capacity utilization is about 23%.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Offshore wind too expensive
Offshore wind power is about 17 times more expensive to install, but its increased capacity factors mean that it should be significantly more productive than onshore installations. Nonetheless, in addition to the significant additional capital costs, offshore wind power appears to have major problems with costlier long term maintenance and questionable reliability [4].
The sun sends huge bills
Large scale photovoltaic solar power is proven to be the least economic renewable energy source, costing about 34 times more than gas fired power in terms of capital costs. However, solar power usually has reasonable maintenance costs. On average in Europe, solar PV yields roughly 11% of its nameplate capacity.
In addition to the impacts of cloudy weather, photovoltaic units are susceptible to performance degradation from ice or snow, or obscuration with accumulating dust in drier climates. Solar power might operate reasonably well at mid latitudes, but it is inevitably a poor investment in Northern Europe where yields are low because of latitude, adverse weather, the seasons and the daily rotation of the Earth.
Though the cost of the technical photovoltaic elements of the systems are reducing, these high-tech elements are becoming an ever smaller part of the final installation. The costs of the support infrastructure and linkages to the grid are irreducible. It is also clear that the service life of solar cells is limited, and degrades over time. System degradation of the DC to AC inverters is particularly significant:  they are an expensive element in any solar system with a limited operational lifetime.
Wind and solar make little sense
In summary the following analogy describes the nationally mandated use of renewable energy:
By law a family has to purchase two cars: one works well all the time, is cheap to buy, cheap to maintain and does not cost too much to run. But the other is very expensive to buy and only works about 1/6th of the time. However the fuel costs are very low. But by law the family is forced to use the expensive car if it is working even though it may well let them down at any time. At the same time the cheap car must be kept idling, using fuel but doesn’t go anywhere.
Readers can see Ed’s full analysis here.
 
Share this...FacebookTwitter "
"A coral scientist whose work is attacked in a mini-documentary from the Institute of Public Affairs says the rightwing thinktank has misrepresented her study. The IPA says its YouTube film, Beige Reef, is a “must watch” because it shows healthy Acropora corals living at Stone Island, near Bowen. This, the film claims, is in a place where a study published in 2016 claimed all those corals had died. But Dr Tara Clark, of the University of Wollongong, says the film’s central claim is wrong because her 2016 study did not make any such statement and the IPA’s film had focused on a different location. Clark told Guardian Australia: “Our work has clearly been misrepresented.” The IPA, which has been heavily funded by the mining magnate Gina Rinehart, is known for promoting fringe views on human-caused climate change. In the film, the IPA’s Dr Jennifer Marohasy claims the study, appearing in the journal Scientific Reports, reported that “there are no longer any Acropora at Stone Island” before showing footage taken from her filming expedition. “This claim is of course irreconcilable with what we saw,” she says in the film, which has been promoted by the Sky News commentator Andrew Bolt and the Liberal MP Craig Kelly. Clark’s paper does reference a visit to the site in 1994 by Dr David Wachenfeld, now the chief scientist at the Great Barrier Reef Marine Park Authority and a co-author on the study, and states that “no living Acropora colonies” were present at Stone Island at that time. This is the section of text highlighted by the IPA in the film. But Clark said the surveys of Stone Island for her 2016 study were conducted in 2012 and the information presented in the video had been misinterpreted. “For example, we never claimed that there were no Acropora corals present in 2012,” she said. The paper states that in 2012, in a deeper area from the reef flat, “living tabular Acropora [species] and Porites [species] colonies were occasionally found”. Clark said: “Marohasy’s interpretation of [my 2016 paper] is incorrect.” Clark said the two main aims of the study were to revisit the precise locations of historic photographs taken around 1890 – sites revisited by Wachenfeld in 1994 – and to test a method to date the death of corals. Clark also said her study was conducted “in a different location and environment” to Marohasy’s film, “making it a little like comparing apples and oranges”. Marohasy’s filming had taken place over subtidal reefs rather than over the reef flats that were the focus of her study, Clark said. The 13-minute IPA video features drone and underwater footage from a chartered boat trip to Stone Island, with extensive commentary from Marohasy. In a separate video promoting Beige Reef, the IPA’s policy director, Gideon Rozner, says what Marohasy found “refutes a key claim” in Clark’s paper “that there are no living colonies of Acropora coral at all”.’ Sign up to receive the top stories from Guardian Australia every morning Rozner says: “The suggestion that the Great Barrier reef is dying is based on claims like this from the Nature paper. If this is wrong then what else are they wrong about?” (Rozner and Marohasy say the study appeared in the “prestigious journal Nature” but in fact the study appeared in Scientific Reports.) Associate Professor Andrew Hoey, of James Cook University’s Centre of Excellence for Coral Reef Studies, said: “Concluding the reef is fine from a single visit to one section of one reef is ludicrous, and is akin to visiting a house that is left standing after a natural disaster (earthquake, tsunami, bushfire) and concluding there has been no damage. “Importantly the video [the IPA] show is of areas of subtidal reef, yet the study by Clark and others describes changes on the intertidal reef flat,” he said. Hoey added that a separate claim in the video that no bleached corals had been found was misleading, because “you wouldn’t expect to see any unless that area was experiencing an extended period of elevated temperatures at that time”. He said: “The majority of corals that bleached on the GBR in 2016 and 2017 died shortly after and were subsequently covered by algae within a few weeks.” The Liberal MP Craig Kelly shared the IPA video on his Facebook page, with the heading “YET ANOTHER CLIMATE ALARMIST LIE DEBUNKED.” Kelly wrote: “Everytime their lips are moving, those from the climate alarmist industry are peddling lies trying to recruit the naive and gullible to act as their useful idiots.” At the end of the video, a credit says the film was “produced with financial support from the B.Macfie Family Foundation”. In a response to questions from Guardian Australia, Marohasy pointed to sections of Clark’s study that she said backed her claim. She said that Clark and colleagues “took just two transects each of 20 metres at Stone Island” and stated in the study that “only nine dead corals were found along transects 1 and 2, and that these corals were covered in mud and algae.” She claimed Clark and colleagues had drawn “erroneous conclusions” from those transects. Responding, Clark said the reason they described the numbers of dead corals they found was because they were specifically seeking dead samples to test a dating method. Marohasy admitted the location of her filming was “just around the headland from the location of the two transects” but said she was planning further films that would show more live corals. Arguments over what conclusions could be drawn from the 1890 and 1994 Stone Island photographs were the catalyst for the censuring and then sacking of the James Cook University academic Dr Peter Ridd, who had complained about their use. With the IPA’s backing, Ridd successfully sued his old university, which is appealing the case."
"How do we stop the “arms race” in Easter egg packaging? Every year, supermarket shelves fill with garish, unnecessarily big boxes to exploit our shallow desires for the fanciest-looking chocolate eggs. The bigger the front face of the packaging, the more attractive it is, the more shelf appeal it has, and the more likely it is you’ll buy it. But more packaging also means more plastic, cardboard, energy – and waste afterwards. It’s big business. Every year, more than 80m boxed chocolate eggs are sold in the UK alone, leading to around £250m in sales. Meanwhile, food and drink packaging continues to cause environmental problems. Packaging uses resources and generates waste. The weight of food and drink packaging per person has not declined in the UK since figures were first generated in 1998 and 3% of the total environmental footprint of British households, measured by energy, still comes from packaging.  Faced with public concern in 2008, confectionery manufacturers made some progress in 2009 towards reducing Easter egg packaging but progress since then has not been tracked and manufacturers still seem to be locked into unnecessarily large, eye catching packaging. Sweets are usually an impulse or gift purchase, and sales are still largely driven by what they look like. Two identically-sized chocolate eggs will vary in how well they sell: the one with a larger shelf “facing” will tend to generate more sales simply because of its increased eye appeal.  The result is that Easter egg manufacturers and retailers are in an “arms race”, a race that demands eggs take up more and more space on the shelf. Each larger package means fewer individual units can be displayed in the same shelf space, leading to lower sales, which then requires higher profit margins to create the same revenue … and so on.  Meanwhile, confectionery manufacturers fear that discussing the problem between themselves and agreeing standards will be seen as restricting competition and they don’t want to fall foul of competition law. Buyers at the big supermarkets are in the same situation; they can’t talk to their confectionery suppliers unilaterally because they’d lose sales, but they can’t talk to suppliers collectively because they fear the wrath of competition law. Of course, Easter eggs need protecting. They’re only fragile shells of chocolate, after all, and poor packaging would arguably mean greater waste from damaged goods that have to be thrown away.  The challenge is to design gift packaging that uses as little material as possible – without limiting the egg’s “standout” on the shelf. Resizing primary packaging (the part that shoppers see) would reduce the cost of cartons and transport costs for the manufacturers; no one wants to pay for a lot of empty space surrounded by an attractive box. Retailers don’t really want to use precious shelf space on cartons containing lots of fresh air either. And smaller packs would also reduce the amount of waste we have to throw away or try to recycle from our homes.  Manufacturers of detergents, deodorants and food and drink have all seen the environmental benefits of cutting back on unnecessary packaging. But Easter eggs are bought almost entirely as gifts – looks are all-important, and size matters. Big British-based manufacturers have drawn up a Code of Practice for responsible packaging. It requires honesty. Manufacturers adopting this code no longer use packages with “double walls”, for instance, since any hollow space between the walls can mislead customers. However, this same code sets out the gifting dilemma, too:  When a product is conceived as a gift or luxury item, it is recognised that the packaging will reflect the presentational nature of the product and may be more elaborate than functionally necessary, but this does not mean that it should be excessive. A simple rule on the ratio of packaging to product could change the way the system works without any one supplier or retailer disadvantaging themselves against their competition. This sort of rule would mean less packaging, lower transport costs, less waste and retailers would be able to sell more per unit of shelf space. Consumers would also be more confident that they won’t be disappointed when they open up their Easter egg. It’s an example of how government regulations can be good both for businesses and consumers. What we suggest for Easter eggs has echoes elsewhere, from the changes in supermarket refrigeration displays to reduce energy consumption, to the call from businesses for a carbon price and clear consistent regulation from the recent climate change COP in Paris. Sensible regulation has worked elsewhere – and not all regulation is bad."
"
Share this...FacebookTwitterThe poles, we are told, are supposed to be the tell-tale barometer of global warming. No place is supposed to warm up as quickly as the poles.
And because there are practically no thermometers to speak of at both the North and South poles, we need a better way of getting an idea of how temperature is behaving at these remote yet “sensitive” regions of our planet.
Because ice melts when it’s warmer and freezes when it’s colder, polar sea ice cover could act as a good measurement tool in place of the mercury thermometer. Not only does it indicate air temperatures, but also water temperatures beneath the ice. It can be argued that sea ice extent is indeed a better way of measuring overall temperature than mercury thermometers. Fortunately NASA has been taking satellite excellent photos of both poles since 1979 and thus we have an accurate record of sea ice spanning 35 years.
As CO2 rises, global warming is claimed to be enhanced, and thus the poles should be warming, disproportionately many scientists claim, compared to other regions like those located near the equator. We should see it in the global sea ice record.
The following is a plot of CO2 vs global sea ice extent since 1979:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




 Graphic formed by combining WoodForTrees CO2 plot and the U. of Illinois sea ice anomaly plot.
The above chart shows that today’s global sea ice is basically at the same level as it was 35 years ago, back when CO2 was below 350 ppm. Moreover the overall trend is flat. There’s no correlation. CO2 has not caused sea ice to melt like it has been claimed to do. Not even close! The melting that did occur was very short in duration, less than 5 years, from 2005 to 2008.
The whole scare of a polar meltdown has been nothing but a huge load of bovine manure. The whole thing has been nothing but widespread hysteria in the collective paranoid mind of a society fanned by high tech, highly funded swindlers and a complicit media class.
The whole global warming scare arguably has been a power grab by an elitist cabal of lying bureaucrats who have deluded themselves into thinking they have all the answers and solutions.
It’s high time that the new generation of politicians start calling it out.
 
Share this...FacebookTwitter "
"Malcolm Turnbull says Australia will struggle to meet its Paris emissions target without rapid decarbonisation of the energy sector, and he says the Liberal party’s continuing failure to develop a coherent climate and energy policy is costing the country much-needed new investment in power generation. In a wide-ranging interview with Guardian Australia’s politics live podcast ahead of the publication of his memoir next year, the former prime minister said the Liberal party had struggled with climate change denialism since 2007 because climate change had morphed into an issue of “identity” rather than fact.  Other highlights of the interview included: Turnbull predicting Scott Morrison would have great difficulty curbing climate activism by adjusting the existing secondary boycott regime, saying: “I think it’s very likely not in line with the constitution.” He also argued the proposal floated by Morrison was fundamentally inconsistent with the principle of free expression. Turnbull saying the Murdoch media – “the dominant, the leading media group in Australia” – was a long-time promoter of climate denialism, making it harder to land a sensible policy. He laughed off this week’s statement from Rupert Murdoch that there was no denialism at News Corporation, declaring the proprietor was “not reading his own papers or watching his own cable news channels”. A flat rejection of the idea ventilated widely during the bushfire crisis that Australia had no material impact on climate change because it makes up only 1.3% of global emissions. “The reality is Australia has to take action to reduce emissions,” Turnbull said. “We have a commitment under the Paris agreement to do so. People also look to Australia as a developed country, a wealthy country, to take the lead, to take a leading role.” He said Australia’s current failure to act seriously to reduce pollution hampered its ability to persuade other countries to do their part. A declaration that it would be a major mistake if the Morrison government ended up subsidising coal, because “subsidising coal is about as crazy as it gets. The bottom line is renewables have won, that’s why no one in the energy sector is building new coal.” A swipe at the National party, noting some politicians claiming to represent farmers and people in the bush “were not speaking for farmers”, because farmers were battling on the frontline of a climate crisis. “The reality is people on the land are dealing with the consequences of a hotter and drier climate.” While Morrison and the minister for emissions reduction, Angus Taylor, declare regularly that Australia will meet its Paris targets in a “canter”, Turnbull – the prime minister who ratified the Paris agreement – expressed scepticism on the basis the government lacked a coherent set of policies to drive the necessary abatement. “I think in the absence of a rapid decarbonisation of the energy sector, we will struggle to get to the 26-to-28%, that’s why the national energy guarantee was very important,” he said. Turnbull said Australia might be able to land the 2030 target with help from Kyoto era carryover credits, but their use was controversial. He said it would be better for Australia to use carryover credits to meet the 2030 target as an insurance principle, invoking that accounting to get there if necessary, rather than have the Kyoto credits carry half the abatement task, which is Morrison’s current policy. He said the credits should not be a substitute for practical emissions reduction, because that only created problems down the track, as the 2030 target was just the first of a series of actions leading ultimately to net zero emissions by 2050. Turnbull said he’d met recently one of the largest renewable energy investors in the world, who told him companies were avoiding Australia because of the lack of policy and because of political risk. The former prime minister declared the energy sector was now “crying out” for settled policy, because the policy he attempted to implement, the national energy guarantee (Neg), had been blown up by “insurgents” and as a consequence of that “we have higher emissions and higher electricity prices”. He said Morrison and the now treasurer Josh Frydenberg had been fully on board with the Neg. The Neg was “a joint project” with Morrison and Frydenberg, he said, and it had enjoyed consistent support in the cabinet. But while Morrison and Frydenberg had been two of the government’s “keenest supporters” of the proposal, they would not bring it back because that would provoke the right wing of the Liberal party. Turnbull said they were aware there’s a group within the party “prepared to blow the show up if they persist with it”. Turnbull said Peter Dutton, who led the coup against his leadership, “never criticised [the Neg] to my recollection”. He said Taylor, the current energy minister, was “an internal critic but it was never entirely clear why”. He said the rump of sceptics inside the Liberal and National parties remained a barrier to sensible climate action. Turnbull said he continued to struggle to comprehend why climate change denialism persisted in the face of concrete evidence of warming. “There are plenty of odd beliefs out there and conspiracy theories but what I have always struggled to understand is why climate denialism still has the currency that it has, particularly given the evidence of the impact of climate change is now so apparent, and it is particularly apparent to people living in regional and rural Australia. “Precisely what has been forecast is happening.”"
"North Sea oil executives believe the ageing fossil fuel basin may still lead a global climate revolution by providing a testbed for clean energy breakthroughs. An industry report has revealed that the North Sea could emerge as an unlikely climate hero by becoming a global showcase for the energy transition after decades producing fossil fuels. The basin has produced almost 40bn barrels of oil over the last 40 years, but as oilfields decline the empty caverns could be used to store carbon emissions, according to PricewaterhouseCoopers. The advisory firm added that North Sea gas producers may eventually be able to produce zero-carbon hydrogen by using electricity generated by offshore wind turbines to split the carbon molecules from natural gas. The North Sea is already equipped with major offshore infrastructure, such as pipelines and platforms, which could be used to help transport and store the carbon emissions captured by UK factories and hydrogen producers. Drew Stevenson, PwC’s UK energy sector leader, said there is “huge potential” for the North Sea to help meet the “necessary urgency to move to a low-carbon world” by focusing on low-carbon innovations and new technology. PwC based its report on interviews with 20 key energy industry executives to pinpoint how the North Sea could adapt to a net zero-carbon future. “The appetite exists for the North Sea energy industry to play a significant role in the transition: investor sentiment is rapidly becoming more committed to low carbon technologies while smaller exploration and production companies are looking at ways to reduce the carbon footprint of their operations. All of this creates an opportunity for the North Sea to lead the way in the energy transition,” Stevenson said. The report comes after the government’s climate watchdog warned over the summer that the North Sea would need to embrace technology, such as carbon capture, to earn a role in the UK’s low-carbon future. Chris Stark, the chief executive of the Committee on Climate Change, told the Guardian following its climate progress report in July that the North Sea industry must make sure that it is part of the UK’s net-zero carbon story. “It would, of course, be an easier task to simply say that we shouldn’t bring oil and gas out of the ground but we know that there will potentially be some uses for those hydrocarbons, in particular for the production of things like hydrogen,” he said. “The key test for whether that can ever be a part of the future scenario is whether the sector itself is supportive of carbon capture and storage and whether the resources in the North Sea are used in an effective net-zero way. If there was ever a point for the industry to feel challenged, it’s now,” he added."
"
Share this...FacebookTwitterMax Planck Society: “Temperatures stagnant approximately since 1998, but at high level”
By Sebastian Lüning and Fritz Vahrenholt
[Translated/edited by P. Gosselin]
Attempting midterm predictions
The Max-Planck Society publishes the magazine “Max Planck Forschung” on a regular basis. In its 1/2015 issue beginning on page 68 one finds the article: “…and now on the climate of tomorrow”. The German language article is also available (pdf here). The article starts:

How will the climate appear in 10 or 15 years? Scientists have been unable to provide a satisfactory answer to this question – mainly because random changes play a large role in such mid-term time-frames. A natural fluctuation is likely also the cause of temperatures barely increasing over the past 15 years. Jochem Marotzke of the Max Planck Institute for Meteorology in Hamburg and his colleagues all over Germany are working intensively on a system that will deliver reliable prognoses for the coming years.”

Hiatus confirmed
In other words this is about the pause in warming since 1998 and the question of why none of the expensive climate models had correctly forecast the hiatus. Indeed this is a big problem, especially for the fraternity of the climate modellers, who in Germany are led by chief modeler Jochem Marotzke. His favorite excuse: “random changes”, which in his opinion are completely unpredictable. But that’s fatally wrong. His colleagues have long known better and have identified the 60-year ocean cycles as systematic climate drivers. See for example  here, here, here, here.
Scrambling to explain faulty models
First of all the Max Planck Magazine thankfully does confirm what all temperature curves now clearly show, but what a few climate activists clearly refuse to believe:
Another resaon was a phenomenon that at the end of the past decade it was visible that there was a temperature plateau, and this continues to occupy climate scientists today. The global warming that was in high gear during the 1980s and 1990s now appears to have been making a pause since the start of the new millennium. The temperatures have been stagnating since about 1998, but at a high level.”
Jochem Marotzke has recognized that this cannot continue on. Awhile back he launched the Project MiKlip with the aim of making more reliable prognoses. In the Max Planck Forschung (MPF) magazine it is stated:

Today, almost 10 years later, the science regarding decadal climate prognoses has come a long way. From 2011 to mid 2015 the German Federal Ministry for Science has financed the project MiKlip (Midterm Climate Prognoses), that Jochem Marotzke initiated and now coordinates as its director. In the meantime the application for the second phase has been made.”

Cooling Atlantic


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




We’ve reported on the MiKlip project before. The main result from the initiative so far is hardly known to the media because it is just too inconvenient. See our article “Over the midterm the climate prognoses of the BMBF MiKlip Projects: North Atlantic will cool down by several tenths of a degree by 2020″. Using a Google search, the environmentally activist Süddeutsche Zeitung has yet to report on this amazing prognosis. Activist climate website “Klimaretter.info” naturally has not done so either. Thus we are very curious on whether the Max Planck Magazine is now perhaps able to talk openly about this. In the article’s  title and introduction we see that this important information is absent. In England however, the University of Southampton recently came up with the same result but was much more transparent and proactive with the cooling finding. See our blog article “University of Southampton: Cooling ocean cycle will cause Atlantic to cool by half a degree Celsius over the coming decades, global warming hiatus continues and hurricanes will become less frequent“.
Max Planck Institute refuses to see ocean cycles
But instead of following the example from England, Marotzke continues to stick to his worn out chaos meme. MPF magazine writes:

Such forecasts however are still in the early stages. ‘There is still a lot of work that remains ahead of us,’ says the Hamburg-based scientist. Over the mid-term climate prognoses are burdened by a fundamental difficulty: the chaos of the climate system. As it is so with the weather, also the climate (the mean of weather) is also subject to natural fluctuations that more or less occur randomly. […] Climate scientists refer to these more or less random fluctuations as spontaneous or as internal variability. Due to such variations the global mean temperature can vary by 0.2 or 0.3°C from one year to the next. For scientists these variations are known as so-called ‘noise’ that superimpose the actual signal of global warming.”

Models’ hopelessly faulty assumptions
Here we would like to advise Marotzke: Try just once to apply the ocean cycles, like your colleagues in England are doing. Natural variability not only contains ‘noise’, but also quasi cyclic behavior that today are empirically well-known. However the sad truth is that climate models are unable to properly represent these known cycles. The problem is not with nature, rather it is in fact in the models. Also the weighting of the individual climate drivers is poorly understood. The IPCC table of radiative forcings for solar fluctuations has assigned a much too low value, one in fact that has absolutely nothing to do with the geological-empirically determined systematic impacts of the sun.
We suspect that Marotzke has painted himself into a corner and so has to continuously find excuses and ignore the ocean cycles that have been at play over the last 20 years, though many have long been aware of them (see our article: IPCC–cofounder Bert Bolin had all along been aware of the climatic role of ocean cycles).
Marotzke refuses to acknowledge low climate sensitivity
In the second part of the article the Max-Planck scientists discussed various possibilities as to why a warming pause happened. It was considered that the CO2 climate sensitivity may have been set much too high:
One possibility would be that the climate change drive in the models has been falsely assigned – i.e. the amount of radiative energy connected with a rise in atmospheric CO2 that gets trapped in the climate system or that gets reflected back out into space from aerosols. The values that the various models calculate for this magnitude vary widely. Another possibility is that the models over-estimate how sensitive the climate reacts to a rise in CO2. Some models assume that the global mean temperature will rise only 2°C from a doubling of CO2. Others assume that it will be more than 4.5°C warmer.”
But then a few lines later Marotzke and Co. abandon the possibility and return to their wild chaos theory. The MiKlip recognition of a cooling North Atlantic gets no mention at all. Instead the article concludes with a prognosis that anyone could have conjured up without millions in research money. Eventually someday the stupid temperature plateau will end. But as to when, no one really knows. An embarrassing conclusion. In the MPF magazine we read:

The temperature plateau is going to end sometime in the years ahead, as most scientists are convinced of this. It is likely that the warming of the earth’s surface will then progress even more quickly. At the latest when the trade winds blow over the Pacific more weakly the pause will be over.”

Other research groups here are clearer and more solid on this because they have a better grip on the unpopular ocean cycles than than the scientists in Hamburg do:

BBC: Global warming slowdown ‘could last another decade’
New paper in the Geophysical Research Letters: Ocean cycles will lead to a light cooling for the northern hemisphere over the coming 15 years.
Judith Curry projects warming pause to continue until the 2030s: Hans von Storch requests a vote of no confidence in such a case for C02
Japanese scientist postulates cooling beginning in 2015 and aging weather stations showing warm readings

Share this...FacebookTwitter "
"Five years ago, a magnitude 9.0 earthquake occurred 200km off the east coast of Japan, causing a devastating tsunami. The resulting waves affected 2,000km of coastline, killed some 18,000 people, destroyed nearly 110,000 buildings and damaged twice that number. It also triggered the meltdown at the Fukushima Daiichi nuclear power plant, which released toxic levels of radiation into the environment and remained the focus of worldwide concern for a long time afterwards. As we reflect on the terrible destruction of lives and livelihoods wrought by this natural disaster, one question springs to mind: how can we better protect ourselves from the next one?  After all, this was not the first such disaster to hit Japan. For example, the 1896 and 1933 Sanriku earthquakes – which reached magnitudes of 8.5 and 8.4 respectively – also caused deadly tsunamis. For that reason, Japan had already introduced a number of defences prior to 2011. Tsunami barriers were constructed both on and offshore, trees were planted along the coastline, vertical evacuation buildings were built to the highest standards and regular evacuation training was introduced.  But the sheer force of the 2011 tsunami took many by surprise. Most of the protective measures were designed to cope with magnitude 7.4 to 8.0 earthquakes, which occur every few decades in the region. This planning failure was partly due to the limited amount of recorded data, which only spans back 40 to 50 years and contains uncertainties about the location and magnitude of previous mega-earthquakes.  To improve warning systems and build effective defences, we need a detailed understanding of how the tsunami gathers height as it nears the shoreline, and how this affects the damage caused. As soon as the major search and rescue operation was completed, the Tohoku Earthquake Tsunami Joint Survey Group – made up of natural scientists and engineers from 63 universities – set out to gather this information.  The group’s measurements confirmed that when the first wave hit the coast, it was largest at the point nearest to the earthquake’s epicentre, as expected. But the shape and height of the coastline and seabed affected how far the tsunami spread inland, and to what depth. For instance, the low-lying southern part of the Tohoku coast experienced the worst flooding, with sea water reaching more than 5km inland.  By contrast, on the more northerly Sanriku coast the tsunami’s energy was concentrated into deep bays where water levels rose as high as 40m, damaging human settlements on mountain sides rather than ranging far inland. The effectiveness of defences varied along the coastline too. Tsunami barriers worked in some places but not in others. Breakwaters and seawalls, which were built to protect from storm surges and ocean waves, were completely or partially destroyed depending on where they were. The tsunami also overran coastal dikes and river embankments.  Many structures could not withstand the force of the tsunamis, or the damage caused by drifting vessels and wood debris. The ground liquefied and scour holes developed near foundations, causing the collapse of many buildings. Roughly two-thirds of the protective coastal forests were lost.  The post-tsunami survey and later research gathered detailed data about the causes and extent of the damage. This information can be used to reduce uncertainties when it comes to forecasting future events of this size. Thanks to this research, we now know more about the probability of similar earthquakes, have improved numerical models and can make better predictions about building failures. All of this will enhance the design and construction standards in Japan, and other countries that are prone to tsunamis. Before the end of 2011, the Japanese parliament had passed laws to establish “tsunami-safe cities”. This involved enhancing research and education, evacuation training and measures to prevent or mitigate the effect of tsunamis in the long term. The government also committed 25.5 trillion yen (£158bn) toward an intense, five-year period of rebuilding.   Next, the Reconstruction Design Council presented a plan to rebuild along Tohoku’s coast, based on new tsunami risk simulations and studies. The proposed protection was divided into two levels, which correspond to two classes of tsunamis, based on their magnitude and frequency. Level one (L1) are “smaller”, low-impact tsunamis that occur once every 10 to 100 years. Level two (L2) are rare, high-impact tsunamis which only happen once in several hundred to 1,000 years.  Structural measures such as seawalls, embankments and tree plantations will be designed and built to defend people and properties against L1 tsunamis. Soft measures such as land use zoning and evacuation plans will be implemented to protect human lives against L2 tsunamis.  Putting these improvements into practice has taken longer than expected. The main focus is still on rehousing those whose homes were destroyed. At last count, almost 59,000 of the 470,000 people originally displaced are still living in temporary accommodation.  In many locations, the ground level of sites for new houses must be raised before construction can begin. For example, in the port town of Rikuzentakata, the ground level was raised by about 10m, and two protective seawalls of 3m and 12.5m high are being built. Elsewhere, private houses will be relocated to higher ground, areas behind protective structures will be elevated and forests planted. The Miyagi prefecture proposes to refortify the coast with a tall seawall several kilometres long for tsunami protection.  All of these measures take time, and many have divided opinion: some inhabitants do not want to move from the coastal strip, but neither do they want their view infringed by a tall wall.  Although the scientific research carried out after the 2011 tsunami will help to protect Japan from future disasters, there will always be shades of uncertainty. After all, it is unlikely that every possible combination of events has been predicted and accounted for. That’s why it is crucial to continue monitoring for early warning signs, evaluating predictive models and building physical defences. Perhaps most importantly, we need to raise awareness of the risks of coastal living, and ensure that people are prepared to move quickly when the need arises."
"The world’s nations are on track to produce more than twice as much coal, oil and gas as can be burned in 2030 while restricting rise in the global temperature to 1.5C, analysis shows. The report is the first to compare countries’ stated plans for fossil fuel extraction with the goals of the Paris climate agreement, which is to keep global heating well below 2C above pre-industrial levels, and to aim for 1.5C. It exposes a huge gap, with fossil fuel production in 2030 heading for 50% more than is consistent with 2C, and 120% more than that for 1.5C. Scientists have warned that even the difference between 1.5C and 2C of heating will expose hundreds of millions of people to significantly higher risks of extreme heatwaves, drought, floods and poverty. The report was produced by the UN Environment Programme and a coalition of research organisations. It complements an earlier UN analysis showing the current Paris agreement pledges to cut emissions would still lead to a catastrophic 3-4C rise. “We’re in a deep hole – and we need to stop digging,” said Måns Nilsson, executive director of the Stockholm Environment Institute (SEI), which was part of the analysis. “Despite more than two decades of climate policymaking, fossil fuel production levels are higher than ever.” Most action to tackle the climate crisis involves reducing emissions, but Inger Andersen, head of the UN Environment Programme, said a focus on fossil fuel production was long overdue. Most of the action pledges made by countries under the Paris deal do not even mention changes to production. The UK is a “striking” example of this mismatch, said Cleo Verkuijl, at the SEI’s centre in Oxford, UK. It was the first major economy to commit to net zero emissions by 2050, she said, but also subsidises fossil fuel production at home and abroad and intends to extract “every drop of oil and gas” from its North Sea fields. In recent years, the UK oil and gas industry has received £176m more annually in government support than it paid in taxes, the report said. The Committee on Climate Change says cutting greenhouse gas emissions to zero by 2050 is necessary, affordable and desirable. Here are some of the actions needed to make that happen: • Petrol and diesel cars banned from sale ideally by 2030 and 2035 at the latest. • Quadrupling clean electricity production from wind, solar and perhaps nuclear, plus batteries to store it and connections to Europe to share the load. • Connection of new homes to the gas grid ending in 2025, with boilers using clean hydrogen or replaced by electric powered heat pumps. Plus, all homes and appliances being highly efficient.   • Beef, lamb and dairy consumption falling by 20%, though this is far lower than other studies recommend and a bigger shift to plant-based diets would make meeting the zero target easier. • A fifth of all farmland – 15% of the UK – being converted to tree planting and growing biofuel crops and restoration of peat bogs. This is vital to take CO2 out of the air to balance unavoidable emissions from cattle and planes. • 1.5bn new trees will be needed, meaning more than 150 football pitches a day of new forests from now to 2050. • Flying would not be banned, but the number of flights will depend on how much airlines can cut emissions with electric planes or biofuels.  The UK Oil and Gas Authority said in a statement: “Oil and gas will remain an important part of our energy mix for the foreseeable future, including under net zero scenarios. Maximising the economic recovery from the UK remains vital to meet those energy demands as long as they exist, and to reduce reliance on imports.” The report’s warning was strongly backed by senior figures. “Ensuring a liveable planet for future generations means getting serious about phasing out coal, oil and gas,” said Christiana Figueres, at Mission 2020 and is the person who delivered the Paris agreement in 2015 as the UN’s top climate official. “Countries such as Costa Rica, Spain and New Zealand are already showing the way forward, with policies to constrain exploration and extraction – others must now follow their lead. There is no time to waste.” Prof Nicholas Stern, at the London School of Economics, said: “This important report shows planned levels of coal, oil and gas production are dangerously out of step with the goals of the Paris agreement.” The report highlights the nations that are taking some action, including the closure of most coal mines in Spain and some in China, along with the end of new offshore oil and gas exploration licences in New Zealand and some parts of the Arctic governed by Canada, the US and Norway. Verkuijl said a global agreement to phase out production would be ideal but is difficult at present with the US under President Donald Trump, as the country is due to withdraw from the Paris agreement. But she said many Democratic presidential candidates have promised to cut fossil fuel production by restricting extraction on public land, for example, or removing subsidies. She said such a candidate beating Trump in the 2020 election would be a “gamechanger”. The report said it was crucial that workers in fossil fuel industries were helped into new employment as production ramped down. “Leaders need to [talk with] workers and their unions to plan a just transition away from fossil fuels,” said Sharan Burrow, head of the International Trade Union Confederation. The analysis is based on the published national plans of eight key producers: Australia, Canada, Russia, US, China, India, Indonesia and Norway, which account for 60% of global fossil fuel production. The plans of other big producers, including Saudi Arabia and Iran, are not publicly available. The researchers assumed these and other producers would maintain a similar share of global production to today at around 40%. • This article was amended on 20 November 2019 to clarify the description of the methodology. The researchers did not assume that producers such as Saudi Arabia and Iran would follow “similar paths” as the eight countries that were covered, but that those producers would maintain a similar share of global production as the eight countries that were covered."
"
Share this...FacebookTwitterUpdate: To the sheep of David Appell: https://notrickszone.com/2015/06/09/disastrous-scientific-consensus-finally-crumbles-after-60-years-of-deadly-failure/comment-page-1/#comment-1029797
====================================
Science has a way of calling itself the art of enlightenment, yet historically it has a nasty habit of taking us deep into dark dead-ends. Human history is filled with examples.
Whenever new theories get prematurely accepted as hard fact, policies usually follow and mislead society into new and ultimately disastrous directions. Dissidents are cast into academic exile. Eventually society gets led deep into a dark dead-end, light-years from the truth. Society wakes up and mends its ways only when real science is allowed to function once again.
So it was with the lipid theory, where cholesterol from high fat diets was claimed to be a major killer. Today, after 6 decades, it is turning out to be strikingly false.
That lipid theory was propelled in the 1950s by Dr. Ancel Keyes and his infamous, phony 7-country chart, which purported to show a direct link between heart disease and fat intake. Six decades long western societies were led to adopting the low-fat high carb diet for healthy living as a result. Today, after tens of millions having died horrible deaths from diabetes, heart disease and cancer, the science is only now finally beginning to admit it had gravely erred. The consensus science had been wrong.
Must read
Disclose.tv here has an article by Dr. Dwight Lundell, a veteran heart surgeon, who tells why it was wrong, and the horrendous consequences.
… we opinion makers insisted heart disease resulted from the simple fact of elevated blood cholesterol.
The only accepted therapy was prescribing medications to lower cholesterol and a diet that severely restricted fat intake. The latter of course we insisted would lower cholesterol and heart disease. Deviations from these recommendations were considered heresy and could quite possibly result in malpractice.”
The result he writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Despite the fact that 25% of the population takes expensive statin medications and despite the fact we have reduced the fat content of our diets, more Americans will die this year of heart disease than ever before.” […]
The long-established dietary recommendations have created epidemics of obesity and diabetes, the consequences of which dwarf any historical plague in terms of mortality, human suffering and dire economic consequences.”
Imagine that it took 6 decades to figure that out.
The same will be true when it comes to the CO2 and climate theory. The parallels are stunning. Like the lipid theory, the climate-CO2 theory is also based on an absurd hockey stick chart fabricated by a less-than-honest activist scientist. It’s going to take a few more decades, and probably here too tens of millions of premature deaths as well.
Consensus is the brake failure of science
It wasn’t until early last year that I rejected the old consensus on cholesterol and health and switched to a high-fat, low carb diet that includes lots of meats, eggs, Kerrygold butter and vegetables. Since then I’ve lost 20 lbs, my blood pressure has returned to normal, and my blood values are normal. I haven’t felt better in at least 20 years. This is what results from rejecting “consensus” science.
The lesson here? Consensus is the brake failure of science. When it happens we can only hope it doesn’t take us over a cliff. This is precisely what is happening today in climate science.
The 97% should have been ignored
Concerning heart disease, if earlier patients had ignored 97% of the doctors and followed the advice of the other 3%, many would still be alive and even healthy today.
Reading Dr. Lundell’s admission at the above link may change your life and make it immensely better.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s online business news magazine WirtschaftsWoche (business week) here has an interview with Professor Gonde Dittmer (right), who claims Germany’s transition to renewable energies so far has been a grand failure. The title of the WirtschftsWoche piece:
“Doubts over the government’s climate policy. The true aim of the Energiewende is not environmental protection.”
An illusion…not a single kilogram CO2 saved
Dittmer, a professor of mathematics and electrical engineering, tells WirtschaftsWoche that all the solar and wind energy installed so far has not saved a single kilogram of CO2 and that these renewable energies are not green at all.
He also calls the claim that 25% of Germany’s electricity is renewable “an illusion”. He tells WirtschaftsWoche that a wind turbine first needs to run 4 years before it compensates the energy that was needed to produce the system in first place. Dittmer says that instead of saving energy, solar and wind power have had the opposite effect: “To the contrary the result is increased CO2 emissions.”
Huge tab for the public
Dittmer also thinks that replacing older wind turbines with more efficient new turbines (repowering) is a gimmick that will make little difference. He blasts the renewable energy industry as a money-maker for a select few at the expense of the general public:
The true aim of the Energiewende is not the reduction of CO2 emissions – rather economic profit. […] It’s all about a redistribution from the bottom to the top.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Naivety, ignorance, ideology, illusions…”
Dittmer reminds us that when the subsidies run out and the costs mount, the consumers will be forced to pick up a massive tab, and that they have actually been duped to gladly do so.
The losers are, in addition to the climate, as you have correctly said, are private households who finance this system with compulsory levies. […] The Energiewende policy so far is based on naivety, ignorance, ideology, illusions and false incentives.”
Absurd
Dittmer, a retired professor, also calls the notion of setting up some windmills and solar panels and thinking that this will do the trick “absurd”. He tells WirtschaftWoche: “We don’t have the space for this, we don’t have the money and we don’t have the technology.”
In his view the solution to the “problem” is to drastically reduce energy consumption. He asks if it’s really necessary to heat every room in the house and to fly on holidays.
He also believes that the electric cars will be a folly because much of the energy gets wasted and that they would only further burden the current supply system.
Photo credit: www.gonde-dittmer.de/
Share this...FacebookTwitter "
"Labour’s 2019 general election manifesto, launched on Thursday by Jeremy Corbyn, is its most radical in more than 35 years. It will strike a chord with millions who want categorical change in Britain. The chord will be loudest with those who have seen life chances stall and fracture, and communities weaken, during the fiscally strangulated years that have followed the financial crash. It will ring out, too, for those who want inequality reversed, taxes increased to renew public services and the climate crisis placed at the centre of public policy. The manifesto raises the bar. Its ambitions match the seriousness of the times. The green agenda is the single most important pledge, an overarching imperative. But it is not the only issue the manifesto confronts in bold terms. The neglect of towns and regions, the need for modernised transport and infrastructure, the importance of reskilling, and of rights against employment injustice, the case for affordable housing, the demands for child and elderly care, a better deal in education and health spending all cry out too.  The manifesto is not historically as startling as it will be caricatured as being. The Britain that Mr Corbyn and his supporters are imagining is a leftwing form of social democracy for which, with relatively few changes of policy, it might have stood at various times between 1945 and 1983. Mr Corbyn is explicit that he wants to roll back the deregulatory revolution of the 1980s and restore tax and spend, national provision of social goods, and the state-managed sector – issues that were bedrocks of the postwar economic settlement – to the heart of public policy from which Margaret Thatcher expelled them. He wants to see the forward march of labour, which was halted in those years, resumed. But we are on the threshold of the 2020s, not the 1970s. The single most consequential thing that will be decided on 12 December is the enormity of Brexit, which will shape everything else that any new government, Labour or not, attempts in the new decade. Mr Corbyn’s Brexit offer is ambiguous. He will not say if he wants Britain to remain in Europe or not – and Labour is badly harmed by his evasion. Mr Corbyn is ambiguous too in his trade union agenda. Yes, employees absolutely need a stronger voice in their workplaces and over their terms and conditions. But what exactly does Labour mean by the repeal of “anti-trade union legislation” and scrapping “unnecessary restrictions on industrial action”? Over-mighty unions were part of the dark side of the 1970s. Enthusiasm for Labour’s general ambitions should not mean a free pass on such issues. Labour’s approach speaks to and connects with the deep injustices and unfairnesses of modern Britain. But a manifesto must be more than a utopian wishlist. Planting lots of trees is magnificent. But money does not grow on them. Even in tough times like these, and even in the face of Boris Johnson, a Labour manifesto is only as inspiring as its implementation is credible and as its party leader inspires confidence. Neither of these is a given. Pledges like scrapping universal credit, keeping the state pension age at 66 and abolishing tuition fees will be popular, but they carry big price tags, not all of which will be paid by the super-rich or business. “These are vast numbers, enormous, colossal,” said the Institute for Fiscal Studies. It added that Labour’s claim that only higher earners would pay higher taxes was “not credible”. Mr Corbyn has three weeks to win this argument. Just as questions of affordability cannot be wished away, so Mr Corbyn’s net dissatisfaction rating of minus 60 among voters cannot be ignored either. The Labour leader’s response on Thursday was to defy such scepticism. He would accept the hostility of the rich and the powerful, he said, echoing Franklin Roosevelt. Current polling suggests that many who are neither rich nor powerful have doubts too. Labour’s manifesto may in the end be more effective in consolidating the left’s control of the party than in transforming the most important election in decades. Mr Corbyn’s manifesto will raise many spirits, as its predecessor did in 2017. The question now is whether its strikingly ambitious radicalism can change the election outcome."
"Human society rewards individuals who can handle complex social interactions and control large groups of people. Extreme examples of this power are comedians who can fill stadiums entertaining 70,000 people, or politicians who, through their rhetoric and charm, convince millions of us to vote for them so they can run our lives. Intelligence, humour, and charisma are used to co-opt a greater share of resources for themselves and their family. In fact, many scientists now think this is exactly why we evolved a very large brain. Originally, large brains were thought to be essential for the making of stone tools, and this is why Homo habilis (skillful man) was thought to be the start of our Homo genus some 2.5m years ago. But we now know that many other animals make and use tools. We also know hominins living 3.3m years ago were already using stone tools half a million years before Homo evolved.  So why did we evolve a large brain if it wasn’t essential for tool making? One reason is that existing in a large social group is very mentally taxing. Those who are better at playing the social game will have more access to mates and resources and will be more likely to reproduce. As the groups get larger, so the computational power needed to keep up with the interconnections grows exponentially, as does the stress. Modern humans like to live and interact in communities of about 150 people. This magic number is found in the population of stone age settlements, villages in the Domesday Book (a census of England in 1085 AD), 18th-century English villages, modern hunter-gatherer societies, Christmas card distribution lists, and even modern Twitter communities – just to name a few examples. Groups of 150 are about what we would expect, when comparing the size of human brains to those of our relatives. Community size in primates is linked to the size of the neocortex region of the brain, where all social cognitive processing occurs. Other primates, with smaller brains, live in smaller groups. Species, such as the baboon-like mandrill of Central Africa, that do gather in larger numbers only contain females and children in their “horde” so these are not true mixed sex social groups. If one extrapolates the relation between brain and group size in other primates then humans with their very large neocortex extend the graph to a community size of 150.  This relationship is extremely useful as it means we have a way of estimating group size in our extinct ancestors. Those a few million years ago, lived in groups of 50 or so. The big change occurs with Homo erectus at about 2m years ago when groups jumped up to nearly 100; then Homo heidelbergensis at 130 and, of course, modern Homo sapiens at 150. Human ancestors with larger brains would have been better at hunting and gathering food, better at sharing the spoils, and better at fighting off predators.  Yet there are also significant survival risks associated with a larger brain such as an increased need for food. Mother mortality rates also increase due to what is known as the “obstetric dilemma”, which refers to the danger of giving birth to a baby with such a large head. While chimpanzees give birth relatively easily as their heads are significantly smaller than the birth canal, human heads are much larger, and so the baby has to twist twice to get through the hips.  For the selection pressure to continue – for brains to keep getting larger – there must have been huge rewards for being smart and having a bigger head. One of those rewards was better social skills. The increased complication of childbirth would require mothers to have help from others, and individual females who were more socially adept would get more help, therefore they and their infants were more likely to survive. This positive feedback loop drove the evolution of larger brains as a means of having greater social influence.  Underlying this social brain hypothesis is an internal arms race to develop the higher cognitive skills to enable greater social control. Clearly, with the emergence of Homo erectus, H. heidelbergensis, and eventually H. sapiens, the positives outweighed the negatives. In my latest book, Cradle of Humanity, I discuss how this was driven by rapid environmental changes in East Africa, increased competition for resources within the species as the population expanded, and competition with other species. We humans emerged from Africa with an extremely large, flexible and complex “social brain”. This has allowed us to live relatively peaceful lives around millions of others. This does not, however, mean that we live in harmony with each other, instead we have swapped physical conflict for social competition. We are constantly strengthening our alliances with friends and partners while working out how to keep up and if possible surpass our peers in terms of social position. And that is why it is so stressful simply being human."
"
Share this...FacebookTwitterBernd Atzenroth of central Germany’s online Märkische Allgemeine Zeitung (MAZ) reports on how a stork had its beak and main feathers chopped off by a wind turbine blade. So severe were the bird’s injuries that the animal had to be euthanized.
Photo of gruesomely injured bird
According to the online news site, the town of Struck is the location of a wildlife rescue center where injured animals are brought in for care.  Sadly the MAZ writes: “On Friday it was a stork, but it could not be treated – that’s how bad the injuries were.”
The site features a photo of the gruesomely injured bird. If you’re looking for a poster-child for depicting the hazards of wind turbines to wildlife, this is it.
The MAZ describes the reaction of the directors at the wildlife rescue center:
Angie and Uwe Löblich of the wildlife rescue center in Struck are used to seeing a lot. But the appearance of a stork that had been delivered to them on Friday left them speechless. We were struck with horror to see that the white stork was missing almost half of its beak, likely it had been chopped off by a nearby wind turbine.’ Also the left main feathers were missing. ‘The beak and the main feathers had been cleanly chopped off, and there is no doubt that it must have flown into a wind turbine,’ Angie Löblich is certain.”
Nature conservation groups playing down the hazard
One might think that nature conservation groups would be alarmed and outraged by the incident, especially in view of the fact that worldwide wind turbines kill an estimated millions of birds and bats annually. But this is hardly the case. For example Germany’s flagship nature conservation group NABU plays down the problem, maintaining that it is small compared to the hazards created by automobiles. According to the MAZ, NABU continues its staunch support of wind energy and believes the problem can be solved with planning.
Rare, protected species falling victim
The MAZ writes that this stork was hardly the first victim and describes a crane having part of its head chopped off, and of multiple birds dying at the rescue center or having to be euthanized shortly after their arrival. Included among the victims of wind turbines are rare and protected birds such as the honey buzzard, goshawk and Red Kite.
Share this...FacebookTwitter "
"Coldplay have pledged to make any tour in support of their new album “actively beneficial” to the environment. Frontman Chris Martin told BBC News that the British group was waiting to tour their new album, Everyday Life, so they can ensure such a tour is carbon neutral. “Our next tour will be the best possible version of a tour like that environmentally,” said Martin. “We would be disappointed if it’s not carbon neutral. We’ve done a lot of big tours at this point. How do we turn it around so it’s not so much taking as giving?” Coldplay are the latest musical act to address the impact of touring on the environment. Billie Eilish has announced plans to make her world tour “as green as possible” by banning plastic straws, encouraging fans to bring refillable water bottles and providing comprehensive recycling facilities. Every venue on the tour, commencing next March, will feature the “Billie Eilish Eco-Village”, where fans can learn about their role in the climate crisis. Those who pledge to fight the climate emergency with the organisation Global Citizen can earn free tickets to the sold-out shows. The 1975 are working towards making their tours carbon-efficient and have pledged to plant a tree for every ticket sold to their UK arena tour in February. The British band have also stopped producing new T-shirts, instead screen-printing a new design over old merchandise stock. Emma Banks, co-founder of leading tour agents Creative Artists Agency, questioned the need for musicians to tour at a scale that might require dozens of trucks to transport equipment. “While I certainly don’t want to be putting anybody out of business, I think we have to start being realistic and going, ‘OK, let’s just dial it down a bit,’” she told the BBC. Music festivals are also facing pressure to go green. This year, Glastonbury banned the sale of single-use plastic bottles across its site, offering 850 water taps and dozens of water kiosks. More than 60 major festivals, including Reading, Leeds and Download, have pledged to go plastic-free by 2021. Coldplay will play two shows in Jordan on 22 November, on the day their album is released, which will be streamed live. On 25 November, they play a one-off concert at the Natural History Museum in London, with all proceeds going to environmental law charity ClientEarth."
"The world may already have crossed a series of climate tipping points, according to a stark warning from scientists. This risk is “an existential threat to civilisation”, they say, meaning “we are in a state of planetary emergency”. Tipping points are reached when particular impacts of global heating become unstoppable, such as the runaway loss of ice sheets or forests. In the past, extreme heating of 5C was thought necessary to pass tipping points, but the latest evidence suggests this could happen between 1C and 2C. The planet has already heated by 1C and the temperature is certain to rise further, due to past emissions and because greenhouse gas levels are still rising. The scientists further warn that one tipping point, such as the release of methane from thawing permafrost, may fuel others, leading to a cascade. The researchers, writing in a commentary article in the journal Nature, acknowledge that the complex science of tipping points means great uncertainty remains. But they say the potential damage from the tipping points is so big and the time to act so short, that “to err on the side of danger is not a responsible option”. They call for urgent international action. “A saving grace is that the rate at which damage accumulates from tipping could still be under our control to some extent,” they write. “The stability and resilience of our planet is in peril. International action – not just words – must reflect this.” Prof Tim Lenton at the University of Exeter, the lead author of the article, said: “We might already have crossed the threshold for a cascade of interrelated tipping points. The simple version is the schoolkids [striking for climate action] are right: we are seeing potentially irreversible changes in the climate system under way, or very close.” “As a scientist, I just want to tell it how it is,” he said. “It is not trying to be alarmist, but trying to treat the whole climate change problem as a risk management problem. It is what I consider the common sense way.” Phil Williamson at the University of East Anglia, who did not contribute to the article, said: “The prognosis by Tim Lenton and colleagues is, unfortunately, fully plausible: that we might have already lost control of the Earth’s climate.” The new article comes as the UN warns action is very far from stopping global temperature rise, with the world currently on track for 3C-4C. The commentary lists nine tipping points that may have been activated. “We have this alarming evidence that part of the west Antarctic ice sheet may be in irreversible retreat,” said Lenton. “All the signals are that it is.” A similar situation appears to be occurring at the Wilkes basin in east Antarctica. The collapse of these ice sheets would eventually raise sea level by many metres. The massive Greenland ice sheet was melting at an accelerating rate, the scientists said, while Arctic sea ice is shrinking fast. “Permafrost across the Arctic is beginning to irreversibly thaw and release carbon dioxide and methane,” they said. The Gulf Stream current in the Atlantic, which warms Europe, has also slowed by 15% since the mid-20th century. “That is just about in the range of natural variability, but it is also hard to rule out that it is part of a longer downturn,” Lenton said. The scientists report that 17% of the Amazon rainforest has been lost since 1970. The tipping point, where loss of forest leads to it drying out, could lie in the range 20%-40%, they said. In temperate forests, especially in North America, heating has triggered more fires and pest outbreaks, potentially turning some regions from a sink for carbon to a source. In the tropics, corals are predicted to be wiped out by 2C of heating. A cascade of tipping points could occur because, for example, the melting of Arctic sea ice amplifies heating by exposing dark ocean that absorbs more sunlight. That may increase the melting of Greenland ice and permafrost areas. “Multiple risks can interact, with one change reinforcing another, and with warming of just a degree or two sufficient to result in dramatic cascading effects,” said Williamson. Prof Martin Siegert, at Imperial College London, said: “The new work is valuable. They are being a little speculative, but maybe you need to be.” He pointed out that the extremely rapid rate at which CO2 was being pumped into the atmosphere was unlikely to have ever occurred on Earth before. “It may mean that tipping points can occur in unexpected ways as there is no geological precedent for this rate of CO2 change.” The article reports that preliminary results from the latest climate models suggest global heating will be greater than expected, increasing the risk of tipping points. Prof Piers Forster, at the University of Leeds, disagreed on that point. However, he added: “I completely endorse their call for action. Although possibly low probability, the risks they identify are real.” Lenton said action would still have real benefits, by slowing the impacts and giving more time for people to adapt. He said: “This article is not meant to be a counsel of despair. If we want to avoid the worst of these bad climate tipping points, we need to activate some positive social and economic tipping points [such as renewable energy] towards what should ultimately be a happier, flourishing, sustainable future for the generations to come.”"
"London’s proposed “Garden Bridge” is no more. After years of controversy, the city’s mayor has finally sunk the idea into the Thames. The notion of a bridge covered in plants and trees spanning the river did have some merit. But it needed to be in the right place, with the right design, and the project needed to generate support from local Londoners. Thomas Heatherwick’s proposal appeared to lack awareness of this.  Nonetheless, the Garden Bridge’s failure shouldn’t be an excuse to rein in our ambitions. In order to deliver more innovative urban greening in London and beyond, there remains value in thinking bigger, bolder and greener. To actually deliver visions of such urban oases we should continue to dream. But we must also be realistic. Long before such a project even makes it onto the drawing board, architects, politicians and the public need to agree on certain vital questions. Who will eventually own it? How it will be funded? And who will be able to access it? The Garden Bridge was an example of what not to do. A lack of transparency lead to approximately £37m of taxpayer funding being lost in the project; the level of private funding lost remains unknown. Likewise, the pseudo-public nature of the bridge would have restricted access for groups, cyclists, and buskers, instead providing a corporate space underwritten by ongoing public investment. But this sort of thing can work, and there are many examples where derelict or brownfield land in urban centres has been transformed into multi-functional public spaces. Millennium Park, in the heart of Chicago, was built on a former rail yard and car park. The High Line in New York turned a disused elevated train line into a park, and there are similar projects in Atlanta and Seoul. Each brought disused transport infrastructure back into public use. There’s now a clamour among cities across the world to develop the “next” High Line – the latest proposal being a “Camden Highline” in north London. Such enthusiasm to follow the success of New York illustrates how cities want their brands to be associated with projects that are innovative yet also green and sustainable.  One of the big ideas behind the Garden Bridge was to create such an oasis in one of the world’s busiest and most polluted cities. Where successful interventions have occurred, they have been achieved with community (public and business) backing. The redevelopment of the Historic 4th Ward Park in Atlanta or the Cheonggyecheon River restoration project in Seoul would be very different projects without public support. Likewise, the Olympic Park site in London is largely publicly accessible 24/7, making it a multi-functional and valuable public space. Even in Milan where the Bosco Verticale – a pair of tree-covered skyscrapers – shows the architectural merit of innovation on private property, it is complemented by a new public park, allotments and communal spaces. What each of these projects does is to find a balance between funding, ownership and access, which helps to limit conflicts over use. Future projects should therefore take notice of what these investments got right, and the Garden Bridge got wrong. Developing truly valuable parks and open spaces is a delicate process. It requires a mixture of funding from public and private sources but should not be held hostage to the demands of private investors.  Publicly-funded projects need to meet the needs of the public and should reflect both local community and wider city-level aspirations. This may mean negotiating a prize-winning design for a more intuitive space that is functional for older people, families or children. The Maggie Daley Park in Chicago is an excellent example of this. There is also a need to ensure that ownership is transparent and that everyone knows their rights of use. This should be publicly and not privately focused, as there is a wealth of evidence to highlight the social, health, and economic value of accessible parks and gardens. Finally, the Garden Bridge should be a cautionary note for future investments. There are many projects in London, across the UK and globally that have worked with various partners to design, develop and manage parks and open spaces successfully. They have managed to grasp the needs of local communities, work with complex design and funding issues, and negotiate ownership and access rights. These projects are the ones we should be promoting as best-practice examples of what make a good public park. As they (nearly) say, one bad apple doesn’t spoil the whole bunch."
"
Share this...FacebookTwitterAccording to University of California pediatric endocrinologist Robert Lustig, the US had 6 million “seriously overweight” kids in 2001. Since then that number has skyrocketed to over 20 million.
Worldwide there are 366 million people with diabetes. By 2030, if trends are not curbed, 165 million Americans will be obese and by 2050 100 million will have diabetes. Lustig calls it “a standard pandemic” The related health costs will be astronomical – and unaffordable. No modern civilization can survive that.
Tragically these are the numbers that were necessary to finally get the US government to concede that its longstanding dietary guidelines (once solidly and irrefutably confirmed by the “vast consensus of scientific experts”) had been severely flawed for decades. Read here and here.
Why did it take so damn long for the government to wake up? It gets down to obstinate egomaniacal scientists, greedy food and pharmaceutical industries, and governments corrupted by the same industries. See here.
Because established scientists have a long habit of insisting their pet theories are right and scoff at those who challenge them, renowned German physicist Max Planck once wisely remarked, “Science advances one funeral at a time.” he noticed that false theories don’t die until their founders do. Sadly, as the case of nutritional sciences shows, hundreds of millions of people have gotten or are about to get early funerals. Hence, government science advances 100 million funerals at a time. Such is now the case with the science concerning saturated fats and human health.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The very same tragedy has begun in earnest in climate science today. Just as the saturated fat theory was founded on the junk science and phony 7-Country chart of Ancel Keys, the CO2 global warming theory was founded on the junk science of NASA scientist James Hansen and the dubious hockey stick graph of Michael E. Mann. And just as dissenters were ignored, marginalized and cut off from funding in the nutritional sciences, so are skeptic global warming scientists experiencing the same today. And just as a consensus among all scientists was claimed endorsing the saturated fat theory (fully backed by the National Academy of Sciences and virtually every American medical association), an illusionary 97% consensus is also being claimed in climate science today. And just as the American Dietary Guidelines were promoted and made official by a Democrat Presidential loser candidate (George McGovern), the global warming science and proposed energy dietary guidelines are being promoted today by Democrat Presidential loser candidate Al Gore. The parallels between the two sciences indeed could not be more stunning.
It would be nice if the parallels ended there, but it is unlikely they will. Just as the case has been with the saturated fat theory, the CO2 climate change theory now risks killing hundreds of millions in the future – thanks to energy poverty and starvation. Without energy, people die horrible deaths from exposure.
All of this could be avoided, of course, if only governments were honest in their interpretation of climate data and stopped making up excuses for colder and colder  winters, and 18 years of zero warming. Unfortunately that does not appear likely to happen anytime soon. Tragically it’ll probably take tens of millions of unnecessary premature deaths resulting from energy deprivation to get the governments to realize they have made a horrible mistake. Instead of making a course correction on the climate issue, the US government, led by NASA, is now altering the historical temperature data in a manner that would even make Ancel Keyes blush.
People can argue about the impacts of faulty science on human life. But one thing cannot be argued: Truth leads to life; lies lead to death.
Clearly the US policy will likely have to see another 100 million or so early funerals before it allows climate science to advance.
 
Share this...FacebookTwitter "
"Eighty this year, Judy Chicago’s hair is white and violet, and she’s wearing lipstick so plum-dark it registers as black. It’s a strident image that suggests she’s a fighter, which she is: funny and forthright, she has dedicated a career to courageous exploration of difficult subjects, from catastrophic injury to mental illness. Some things, though, can’t be fought: extreme weather has left her grounded in New Mexico, thousands of miles from Gateshead where a survey of half a century of her work opened earlier this month. I end up talking to her on a video call. This intervention of natural forces is grimly apposite. Chicago’s show at the Baltic focuses on extinction narratives and human responsibilities to the planet. She has spent the past three years contemplating mortality. The series The End: A Meditation on Death and Extinction turns from Chicago’s feelings about her own death to grief over what we are doing to our environment. “There’s not a lot we can do about the fact that we’re going to die, is there?” she says. “We can’t do anything about our own mortality, but we can definitely do something about what we’re doing to the other creatures on the planet, and [to] the Earth.” She really takes us through the fury, grief and terror surrounding ageing and death. From the tragicomic experience of seeing your mother’s body reflected back at you in the mirror, to the horror of dying hooked up to banks of machines in a hospital. She comes at death from many angles: philosophical, psychological and emotional. “Far more difficult than the mortality images were the extinction images,” she says. “That was really gruelling.” Paintings in the series show tropical frogs and arctic fauna facing habitat loss; elephants and sharks mutilated by hunters; scenes of deforestation and animal illness. “Intensive research about it really brought me face-to-face with a level of horror that I had not previously comprehended.” Death has long made its presence felt in Chicago’s life. Born Judith Cohen in Chicago in 1939, she married in 1961, while still a student in Los Angeles. Two years later her husband Jerry Gerowitz died in a car accident, making her a widow at 23. She started her career as an artist by injecting rainbow colour into the sombre arena of minimalist art. She learnt to wield a spray gun and painted crisply graphic symbols suggesting sex, fertility and birth on to the hoods of cars. The art world of LA at the time was so macho that Ken Price, Billy Al Bengston and Larry Bell – the surfing, biking, cigar-chomping stars of the scene – were known as “the studs”. “The most prominent curator in southern California refused to look at my work because, as he said, he couldn’t deal with ‘the fact that I was a woman and an artist, too,’” says Chicago. “I mean, it was just terrible.” In order to get seen in LA she “absolutely had to disguise my gender in my work”. Yet, instead of hiding, she decided to be true to herself. “That meant confronting the fact that even though art has no gender, the art world seemed unable to accept me because of my gender.” In 1970, an advert appeared in the pages of Artforum showing the artist leaning nonchalantly against the ropes of a boxing ring with the name “Judy Chicago” emblazoned on her sweatshirt like a prizefighter. The text read: “Judy Gerowitz hereby divests herself of all names imposed upon her through male social dominance and freely chooses her own name: Judy Chicago.” And thus she was reborn: Judy from Chicago, like Leonardo, the guy from Vinci. She moved to Fresno and founded a feminist art programme at California State University. Instead of concealing her gender, she was going to change the status quo, one battle at a time. And it was a battle. In 1975, Anaïs Nin encouraged her to write about her experience in Through the Flower: My Struggle As a Woman Artist. Rereading it today, she says, is painful: “There are very vivid descriptions of the difference between how I felt in my studio as an empowered individual, and how I would feel when I left my studio, and was viewed entirely through the lens of gender.” The fight was not simply for women artists to be seen, but to lay foundations for a new kind of art making that stepped away from ideas of the lone male genius and his proprietorial dominance over the natural world. “I remember having a huge fight with Richard Serra in the mid 1960s when he did a show at the Pasadena Museum,” she says. “He had a bunch of redwood trees chopped down, and piled them up in the museum. I was horrified and I told him. The next day he pounded on my studio door, waving Artforum, and said, ‘You may hate what I do, but they like it.’ I didn’t care. I was horrified by that imposition on the landscape, that arrogance.” At the time, Chicago was also making art out in the landscape, but she worked only with coloured smoke and bodies: materials that had minimal impact on the environment and left little trace. She always wants materials to sit lightly. That’s why she prefers spray painting: “I never liked oil paint, I never liked imposing paint on the surface.” In the mid 70s Chicago started the work with which her name is now synonymous. The Dinner Party is a vast triangular table with place settings in lushly glazed ceramics and embroidered cloth for 39 eminent historic figures, all of them women. The triangular base of the installation carries 999 further names glazed into ceramic floor tiles, the entryway is lined in tapestries, and historic information is displayed around the space on panels. More than just a historic rebalancing, it is an unabashedly erotic work: labial, drippy, carnal. Five thousand people attended the opening of The Dinner Party in San Francisco in 1979. It caused a sensation, but also uproar. The show was closed, and its exhibition tour collapsed. Yet the popular momentum accompanying the work was strong enough that a grassroots movement grew to tour it around the US and beyond. The Dinner Party is now permanently installed at the Brooklyn Museum. It has become a canonical work, not just of feminist, but of 20th-century, art. At the time it nearly destroyed Chicago’s career. She says she lost everything: her studio, her marriage, and her financial security. It is grotesque that The Dinner Party still feels so relevant 40 years later: that the same debates are raging about birth control, abortion and representation. “I think it’s incredibly sad that, at this point in America, young women are going to have to fight the same goddamn fight we fought in the 1970s all over again,” says Chicago. She quotes the historian Gerda Lerner – “Women live in a state of trained ignorance” – and says there’s a lack of awareness of the battles women have fought or the lessons they’ve taught. “As a result, we are still in the same cycle of repetition that I thought, in the naivety of youth, I was going to overcome by doing The Dinner Party with my own paintbrush.” Chicago pulled back from showing much of it at Baltic: “Much as I appreciate all the attention The Dinner Party brought me, for many decades it blocked out the rest of my production.” But there is plenty of other work to look at, for Chicago is prolific: about 8,000 works are logged in her studio database, everything from bronze sculpture to paintings on glass. There are grand series exploring big themes such as childbirth and the Holocaust. And there are more intimate works, such as Autobiography of a Year (1993-94), charting her day-to-day mental state, or Kitty City, an “investigation of inter-species relationships”, set in her home and starring herself, her husband Donald and their cats. She’s started to think about the art market and the value of her work, something she claims never crossed her mind until she got her first mortgage aged 60. “Now I’m 80, and, you know, in America it’s no fun to be old and poor,” she says. “So now I think I’d like to make some money, but other than that I never thought about it.” • Judy Chicago is at Baltic, Gateshead, until 19 April."
"What would you like to study next year? The Bengal tiger, or the African water rat? It is an important question, for rarely, it seems, is there an impetus to study species that are highly successful, numerous or considered “ordinary”. This continued momentum towards the weird, wonderful and endangered can frequently be driven by the fact that endangered and exotic species attract funding, high journal impact and equally importantly, publicity. “Ordinary”, “less cute” species do not. From the perspective of species conservation and biodiversity, there has been much discussion about the prevalence of prioritising large, highly-visible and aesthetically pleasing species over smaller, more everyday animals. Habitat conservation typically does benefit all species which live within a preserved area, and so flagship animals, which are often used to front campaigns and high-profile research projects, do help support other species by attracting public support – and money – to the cause. But scientists must be careful not to overlook our planet’s other, less “glamorous” creatures. They are vital to our understanding of biology. With finite time, money and resources, preference currently is given to those species in critical danger of persecution or immediate need of protection: pandas, tigers, rhinos. But the impact of this on our knowledge of animal biology – their physiology, energetics, ecology and behaviour – is not yet fully understood. A scientific study on the physiology of the African elephant (Loxodonta Africana), for example, is unlikely to inform greatly on that of the African water rat (Dasymys incomtus) despite the fact that they frequently share the same habitat.  Indeed, there is a chance that our focus on these exotic and endangered species is biasing our knowledge of animal biology. A recent review revealed that 42% of studies published in the selected journals focused on species listed as threatened. Conversely, only 4% involved research into those categorised as non-threatened.  This means that we tend to study those animals that are struggling to adapt and modify under the pressures of human activity worldwide. And as a consequence, we spend less time discovering how more common and “successful” species are seemingly able to adapt and change to these pressures, and the mechanisms, characteristics and traits that enable them to do so.  Phenotypic plasticity, the ability of an organism to change its observable traits in response to changes in the environment, has received much deserved attention in recent years, particularly in birds. It has been suggested that these species may well cope better with climate and habitat change. Early studies on phenotypic plasticity have, as perhaps a logical starting point, focused on nature’s extremists and athletes, in line with the fascination for studying exotic and endangered species.  Examples include long distance migratory shore birds, such as godwits, groups of which can migrate up to 11,000km over the open ocean without stopping. That these species are able to undertake such extensive and impressive migrations suggests a natural predisposition for plasticity of the body’s organs throughout the annual cycle, enabling them to cope with such energetically challenging and demanding events. Indeed, these species show much propensity for change in their digestive organs, muscles and fat stores.  Other species have shown very rapid changes in their migratory habits and routes. Classic examples, which have attracted considerable attention, are blackcaps  (Sylvia atricapilla) and chiffchaffs (Phylloscopus collybita) – both passerine birds which have, over the last 50 years, gradually begun moving from central Europe to overwinter in the UK, halting their migration post-breeding to sub-Saharan Africa, some 7,000km away. Why these unusual species would show this trait while other similarly-sized, closely-related birds with similar diets don’t is not fully understood. More work is needed on less “extraordinary” birds. Currently, the extent of this flexibility and what initiates such changes is unclear. Of course plasticity can only go so far in response to change. For example, metabolic rate cannot increase or decrease indefinitely, and at some juncture, anatomical factors will impose a limit on what degree of change is possible. This plasticity, however, has not been tested extensively in what one might consider a more “typical” or “ordinary” species, and particularly not in their natural environment. It is possible that these “normal” species are capable of demonstrating equally admirable plasticity in their characteristics, but the environmental scenario which requires its exhibition has not yet arisen. Evolutionary ecologist Massimo Pigliucci has suggested a potential reason why there are few studies on this: “This field often relies on studies that are low-tech and tedious to carry out, and yet demanding high personnel costs and long periods of time, a combination that is sometimes difficult to justify to funding agencies when compared with more ‘high-tech’ science.” Understanding the potential and capacity for change in particular species is vital for predicting the responses of different species to anticipated changes in the climate and general landscape.  A firm basis for understanding the capacity of a species to change can only come from a sound platform of good general knowledge of animal biology, in particular from those species which are numerous, prosperous, and operate successfully within a changing environment. Of course, important and vital research must continue into endangered species, but a longer and larger-scale outlook is critical if we are to recognise fully the extent of change that may take place in response to shifts in the climate. “Ordinary” should no longer be a dirty word when it comes to what is recognised and endorsed by funders and researchers."
"Hurricane Irma – one of the strongest on record to hit the Caribbean – recently scoured the islands leaving catastrophic damage in its wake. And just as we began to piece together the devastating and potentially long–term impacts of Irma, Hurricane Maria has now left another path of destruction. Puerto Rico, the British  dependency of the Turks and Caicos, and many other Caribbean islands have suffered what have been described as “apocalyptic conditions”.  When the world talks of the tragic and devastating consequences of severe hurricanes, the focus tends to be on the land, and the people who live in affected communities. Indeed, nearly 30 people have been reported killed, while Puerto Rico Resident Commissioner Jenniffer Gonzalez has said that the hurricane has set the country back by “20 to 30 years”. We see images of toppled trees, torn off roofs and severe flooding. But marine environments can be also badly affected by hurricanes, with potential long-term effects.  The force of hurricane winds, and the resultant tides and waves are so strong that both plants and animals are ripped from the sea floor leaving lifeless rubble and sediment behind. Hurricanes have a washing machine effect: they mix up coastal sediments with knock-on effects for marine life. Suspended matter left floating in the water column limits the amount of sunlight that reaches marine habitats and so reduces growth and recovery. Meanwhile in shallow coastal environments, debris, sewage and run-off continue to flow in to the sea long after the hurricane has passed.  The devastation of coastal environments, particularly seagrass meadows, can also result in long-term losses of the benefits that humans receive from them, such as fisheries support or coastal protection. Damage to these ecosystem services consequently impacts human well-being, because people can no longer rely on them for their livelihood and food supply.    Some of the most severely affected areas of the recent hurricanes in the Caribbean – Florida, Turks and Caicos, Puerto Rico, Cuba and the British Virgin Islands – all house extensive seagrass meadows. These shallow water marine habitats support valuable lobster fisheries, as well as shrimp, conch, and finfish fisheries. Seagrass also stabilises sediments and protects the white sand beaches that attract so many tourists to the region.  Previous hurricanes, cyclones, and typhoons (weather events which are essentially the same but have different names depending on where the storm happens) across the globe have shown the severe negative effects they can have on these vital seagrass meadows. The seagrass plants are ripped up or buried under sediments, leading to their suffocation. The extensive associated murky water leads to widespread loss of seagrass, as was seen in the years that followed hurricane Katrina hitting the US. Initial indications from the Everglades in Florida show that seagrass destruction in the wake of Irma is extensive, with large piles already being washed far onshore. This should ring alarm bells for Caribbean fisheries, as hurricanes Katrina and Rita led to losses in the seafood industry that reached billions of dollars. The Caribbean spiny lobster fishery business alone is worth more than US$450m, and directly employs 50,000 people. Healthy seagrass provides the best fishing grounds with the greatest revenue, and the recent hurricanes have the potential to decimate this.  But this is not just about money. Seagrass loss also threatens marine biodiversity and the health of charismatic species. After a severe cyclone in Australia in 2011, turtles and dugong starved due to the damaged meadows. In addition, seagrass is a marine powerhouse, which stores vast amounts of carbon in meadow sediments. When the seagrass is removed, this carbon is released back into the environment. Hurricanes have always been a part of life in tropical seas. The destruction they cause and their recovery have been observed throughout human history. What is alarming now, however, is the apparent increased frequency and intensity. The already poor state of the Caribbean marine environment restricts the ability of habitats such as seagrass meadows and coral reefs to recover from the effects of severe storms. Poor water quality and over-fishing, for example, promotes the overgrowth of algae, preventing recovery. With repeated hurricanes occurring over time periods that are insufficient for recovery to occur, this will only get worse. The severity of hurricanes Irma and Maria are a wake up call. We need a fundamental shift in how marine environments are protected to enable long-term sustainability for the food and income they provide. Many locations in the Caribbean, for example Puerto Rico, have ineffective marine protection rules and so destructive practices continue unchecked, meaning that when a disaster does occur, the environment is unable to recover. Although local actions against climate change are difficult to achieve, it is possible to manage river catchments to improve water quality, and focus on small scale immediate actions, such as implementation of marine protected areas to limit immediate and direct damage to coastal resources. Coordinated small scale actions will ultimately help enhance the resilience of the Caribbean Sea, and make sure that the environment can better recover from any future extreme events."
"When you think about things that are quintessentially British, you probably would not immediately put “flying” into that category – but you should. We Brits don’t just like flying, we love it. Data from the International Air Transport Association (IATA) shows that more Britons flew abroad last year than any other nationality. Roughly one in every dozen air passengers was British. Britons took to the skies 126.2m times in 2018, beating Americans and Chinese people into second and third place. Needless to say, this comes at an environmental price.  The UK aviation industry pumped 37m tonnes of carbon dioxide (CO2) into the atmosphere last year alone. That’s about 4% of the 918m tonnes that the global aviation industry emitted in 2018. And it’s an upward trend. The aviation industry is currently growing at between 4% and 5% a year, at which rate passenger numbers will double every 15-20 years. “UK CO2 emissions from aviation have doubled over the last 20-25 years and are predicted to grow into the future,” says Tim Johnson, the director of the Aviation Environment Federation, an environmental campaigning organisation that represents communities who are affected by noise and emissions, primarily around UK airports. The problem this creates for the aviation industry is acute, especially since in June 2019, the UK government signed into law a commitment to make the UK a “net zero” greenhouse gas emitter by 2050. By “net zero” this means that any greenhouse gases that are still used will have to be offset in some way. Schemes include buying and preserving parts of the world’s rainforests or planting new trees somewhere in the world, or more radical technology to literally pull the CO2 out of the air. Currently, aviation is responsible for about 2.5% of the world’s CO2 emissions. That may seem a small percentage, but this share of the total could increase significantly with the expected growth of air travel and the drive to greener operations in other industries. Accordingly the industry is looking to technology and engineering to help make aircraft more environmentally friendly. At the forefront of this is the electric engine. Electric engines for aircraft come in two forms. Rather like their motor car equivalents, there are hybrid electric engines, which would still burn fuel but can switch to battery power when appropriate, and there are fully electric engines that derive all their power from batteries. To Rob Watson, director of Rolls-Royce Electrical, the move to electric engines is a revolution that will usher in not just a more sustainable industry but a whole new era of flight. “A third era in aerospace is emerging around us now, and it is enabled by electrification,” he says. “From our perspective, it’s a really exciting opportunity for us to help pioneer this third era.” According to Watson, these eras of flight are driven by the available engine technology. First, it was piston engines to drive propellers, then it was jet engines, and now the electric engine promises to bring savings in both operating costs and environmental impact. “We are determined to play the part that you would expect from a company with Rolls-Royce’s engineering pedigree,” says Watson. To that end, Rolls-Royce has partnered with Airbus and Siemens to develop the E-Fan X, the latest in a series of hybrid electric demonstration aircraft. Following the successful flight of the E-Fan, a two-seater fully electric aeroplane that flew across the English Channel in 2015, the E-Fan X project received a large share of the £255m that the government committed to investment in the field last year, and is on course to begin test flights in 2021. This time instead of a fully electric personal plane, the company is adapting a small commuter aircraft based on the BAE 146 design into a hybrid electric. One of the aircraft’s four engines will be replaced with an electric engine running off batteries. “It is going to be the highest power hybrid electric aircraft that we have flown,” says Glenn Llewellyn, VP of zero emissions technology at Airbus. Following this, Llewellyn imagines one more test plane to demonstrate full electrification of all the engines, and then the plane can enter service. “Our target for the early 2030s is to have zero CO2 emission aircraft. This means completely eliminating CO2 per passenger,” says Llewellyn. To do this, he explains that the electricity stored in the batteries will come from renewable means such as solar panels and wind turbines. If all goes to plan, the first all-electric flights are likely to be small, island-hopping journeys, progressing to domestic and then short-haul flights. But unless there is a major breakthrough in the amount of charge a battery can hold, the batteries will simply be too heavy and take up too much space to be practical for long-haul flight. The bottom line is clear: however you approach the problem, long-haul flights will have to use traditional fuel-burning engines. But that doesn’t mean they will need to use the traditional fossil fuel, kerosine. Airlines are developing and testing Safs – sustainable aviation fuels. When the industry began investigating these a number of years ago, it was first thought that they would be biofuels, extracted from crops or plants, such as palm oil. However, the temptation of local farmers to cut down tropical rainforest to plant palm trees to sell to the fuel companies has seen airlines withdraw pretty quickly from that route. Instead British Airways and a number of others are turning to something that we make far too much of every day: rubbish. The fuel produced by chemically processing this rubbish is an artificial kerosine. Present rules allow it to be mixed in a 50/50 ratio with fossil kerosine. This is unlikely to change because the fossil kerosine contains naturally occurring chemicals that cause the rubber seals on a jet engine to swell, making them tight. Engine manufacturers rely on this process to make the engines Safe. Artificial kerosine does not contain these special molecules in anything like the same quantity and so cannot be used exclusively in current engines. Even if they could, Tim Johnson is sceptical that Safs would make a real difference. Last year, 7m litres were used on flights. “That sounds like a reasonable amount by volume but it’s enough to power the global aviation industry for 10 minutes,” he says, “so in terms of scaling up Safs, we’re a long way from making that a reality.” Added to this, they are twice the price of ordinary kerosine – a cost airlines may have to pass on to their passengers. There are other things that airlines and aircraft designers may be able to do to increase carbon efficiency. More effective air traffic control could prevent aircraft having to take detours to avoid congested skyways. Better wing design could reduce the drag of aircraft. Better carbon fibre manufacturing techniques could result in lighter airframes. And airlines could always squeeze more seats in. All of these together can offer small percentage-level improvements that will contribute towards reaching the 2050 target. It remains a big challenge, however, with a lot of risk. A delay in any one of the proposed technologies coming online, such as the electric engines or the sustainable aviation fuels, could torpedo any hope of hitting the net zero carbon emissions the law requires by 2050. If it becomes clear during the next decade that the target is unreachable on the current trajectory, some real pain may have to be endured by the industry and the people who use it. At the heart of the predicament is the fact that the airlines operate on very small profit margins, making their money through volume. This means that the growth of the industry is essential, yet this very growth is the chief obstacle in halting the environmental impact. At present, technological innovation is delivering a 1% per annum saving in carbon efficiency, but this is completely outstripped by the industry growing at 4-5% a year. Unfortunately, says Johnson, carbon offsetting schemes are little more than a temporary fix. Those schemes rely on some form of preserving or planting trees, but as the 2050 deadline approaches, all the countries we traditionally use for carbon offsetting, such as India, China and others in South America, are going to need those hectares to offset their own rising carbon emissions. “This is the fundamental obstacle to us reaching our environmental objective,” says Johnson. “If this industry were static in terms of people flying, all the improvements we’ve discussed would be improving the industry on an annual basis.” But they’re not. And that means only one thing according to Johnson: restricting the demand for air travel. It’s a conversation that an increasing number of people may already be having with themselves. The Swedish concept of flygskam or “flight shame” entered the lexicon this year. The Swiss bank UBS surveyed 6,000 people in the US, Germany, France and the UK and found that 21% of respondents said they had cut the number of flights they took during the last 12 months. A 2014 survey of 1,000 UK residents revealed that just 15% of Britons were responsible for 70% of flights and this led to calls for a frequent flyer tax. Some sort of carbon pricing scheme has also been suggested by the Energy Transitions Commission (ETC), an international organisation dedicated to roadmapping ways to a low carbon future. Under such schemes, carbon could be priced at up to £200 per tonne, and a proportionate contribution added to each plane ticket. Even if passengers in the west do think more carefully about flying, and the price of tickets goes up to deter them further, the decrease in passenger numbers will probably be outstripped by rising demand in developing economies such as India and China. That means globally the number of us flying will still rise, and that means to achieve net zero by 2050, airlines may have to expand into the carbon capture market, developing commercial technology to pull CO2 out of the atmosphere. Such technologies do exist but they are small-scale devices used to keep the air breathable on submarines and spacecraft. To scale these up to something capable of making a global impact will require serious investment in green startup companies and probably government incentives. To delay the investment in this technology almost certainly means having to abandon net zero carbon emissions by 2050, or the introduction of draconian measures to limit air travel in the coming decade, no matter what economic damage that does to the aviation industry. When it comes to aviation and the environment, one thing is certain, says Johnson. “We are going to have to have difficult conversations about how we hit our net zero targets.” "
"
Share this...FacebookTwitterThe year started out on the mild side in Central Europe, but since early May temperatures have been stubbornly on the low side.
“Rarity”: 5 consecutive June days of surface frost
Over northern Germany, for example, the last 10 or so days have been gripped by cold weather. The online Sudkürier here cites meteorologist Dominik Jung, writing how last week there was “a very unusual phenomenon: five days in a row in North Germany there was surface frost. That according to Jung is a rarity for June.”
Ground surface frost is already rare enough over the northern German lowlands in May, let alone June!
In Germany farmers and weather hobbyists often talk of these annual June cold spells, calling them Schafskälte – or “sheep cold”. They often occur in mid June when cold polar air grips the country.
“Record suspect low”
But this year the phenomenon appears to be especially pronounced.

German meteorologist Dominik Jung explains what’s behind this year’s “very unusual” June cold spell. Image cropped from: https://www.youtube.com/


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Not only last week was cold, but so is this week. In today’s wetter.net  forecast video, Jung tells viewers how this morning: “…around Hamburg ground-surface temperatures fell to -3°C. Yes, for this time of the year this is a record-suspect low.”
In the video the commercial meteorologist also says that after today’s milder temperatures the “grizzly summer weather” shows no signs of letting up. Daytime temperatures are forecast to stubbornly remain stuck in the 50s and 60s (14 – 20°C) over the rest of the week.
“Numerous days with ground level frost”
The online sachsen-fernsehen (Saxony television) writes that not only was the Hamburg region hit, but the cold was widespread across northern Germany:
“In Lübeck and Hannover, just above the ground readings of down to -2°C were taken. Even in Berlin early this morning the thermometer showed ground level frost with readings around 0°C. 
Precisely at Germany’s number 1 beaches, the North and Baltic seas, June has been quite fresh so far. The month’s half in the north has been about 1°C colder than the longterm mean. And with the numerous days with ground level frost that June has seen so far, it’s hardly a wonder.”
Drought also taking hold…
Moreover, large parts of northern Germany are being gripped by a deepening drought. Here as well no significant amounts of rainfall are in sight.
The latest buzz is that Germans should not be expecting any type of “barbecue summer” this year.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhat follows is something that should make anyone who makes dramatic predictions that ends up being totally wrong blush with embarrassment, and feel like a real fool.
===============================
By Sebastian Lüning and Fritz Vahrenholt, Die kalte Sonne
[Translated by P Gosselin]
In 2008 US broadcaster ABC News had a show on the climate danger. The most important news at the time: Already in just seven years, 2015, the climate will have gone crazy and climate catastrophes would be piling up.
All wrong, as we now know today.
This debacle aside, also today such clips continue to be produced. And when the predicted year arrives, everyone will have forgotten the crazy stories and predictions.

=============================
Milk $13 a gallon?
 Gas $9 a gallon?
 How much longer are we going to listen to these nuts?
Also watch the following:

And yet another spectacular fail here.
Share this...FacebookTwitter "
"Australia has suffered a devastating early bushfire season with fires across several states burning through hundreds of thousands of hectares and destroying hundreds of properties with the loss of six lives. New South Wales has been the most severely hit, with more than 1.65m hectares razed, an area significantly larger than suburban Sydney. All six deaths occurred in there and more than 600 homes were destroyed. At one point firefighters were battling a fire front about 6,000km long, equivalent to a return trip between Sydney and Perth. In Queensland, 20 homes have been lost and about 180,000ha burned. In Victoria, where the bushfire season usually starts later, 100km/h winds fanned more than 60 blazes during an unprecedented heatwave on Thursday. The most extreme warning, a code red, was issued for the north-western and central regions. The state’s emergency services minister, Lisa Neville, compared it to “the worst conditions you’d see in February or March”. Seven districts in South Australia were rated as being at catastrophic risk of fire on Wednesday as temperatures soared into the 40s. A blaze on the Yorke peninsula burned through about 5,000ha, damaging at least 11 properties and injuring 33 people. Western Australia has also experienced early bushfires in several regions, with fears of much worse to come over summer, and there were minor bushfires this week in Tasmania. Australia has always had devastating bushfires, a point emphasised by some columnists and newspaper editorials, but scientists say the fire conditions this year are without parallel on several fronts. Let’s start with the situation in NSW. Over the past 50 years, there have been just two calendar years in which more of the state has burned than this year: 1974 and 1984. With this year, those two were much larger than any other year, as this graph shows, based on data from the University of Wollongong’s centre for environmental risk management of bushfires: This year, which still has six weeks to run, sits fractionally behind 1984. Both are a long way behind 1974, when more than 3.5m hectares burned. But scientists says fire conditions today are fundamentally different, and fundamentally worse in many ways, when compared with some of the fires experienced in the past. The centre’s director, Ross Bradstock, says the 1974 fires burned through largely remote country mostly in the state’s far west, devouring green, non-woody herbaceous plants. The conditions were created by above average rainfall which produced ample fuel in outback grasslands. By contrast, the fires in the east of the state this year have been fuelled by a lack of rain. The extent of the fires is in significant part driven by the amount of dry fuel available, some of it in highly unlikely places, and the amount of dry fuel is linked to the record-breaking drought. Rainfall between January and August 2019 was the lowest on record in some areas, including the northern tablelands of NSW and Queensland’s southern downs. Parts of both states experienced record low soil moisture. As temperatures and wind speeds increased but humidity remained low, conditions were primed for small fires to become major conflagrations. Bradstock says it has put NSW in uncharted territory: “For the forests and woodlands in the eastern half of the state, this is unprecedented. “Natural features in the landscape which often impede fires, like these wetter forest communities, are just burning. There is likely to be long-term ecological and other environmental consequences.” The director of the fire centre at the University of Tasmania, David Bowman, says the unprecedented nature of the fires this spring can be seen through their intensity and geographical spread across the country, noting at time of writing there were fires in five states. The extent of the bushfire risk is illustrated through Bureau of Meteorology data of the cumulative forest fire danger index across winter. The map shows the overwhelming majority of the country, with a few exceptions in Victoria, central Queensland and western Tasmania, experienced between “above average” and “highest on record” fire conditions in winter when compared with the average since 1950. Bowman says the extraordinary nature of the fire season is clear on several measures: the extent of area burned, and the underlying dryness and poor air quality affecting people across the country. Smoke in NSW and Queensland has prompted a rise in people seeking emergency treatment for respiratory problems. But as illustrative evidence he emphasises the areas affected in which fire has never or rarely burned in the past, including rainforests, wet eucalypt forests, dried-out swamps and organic matter in the soil where the water table has dropped. He says one of the most striking images of the extreme fire conditions in recent weeks were those of a devastated banana plantation at Taylors Arm, west of Macksville, in northern NSW. He lists it alongside the loss of other landscapes – including Gondwana-era vegetation in the Tasmanian world heritage wilderness area that in some cases had not burned for more than 1,000 years – as evidence of change. “There’s just layer upon layer upon layer of differences,” Bowman says. “If you narrow your frame you can say ‘nothing to see’. But if you broaden your aperture, it’s clear. “I wrote a book on Australian rainforests. I’ve seen every Australian rainforest biome, and the fact that multiple versions of these ecosystems right around the country are burning all within the same couple of years … This is a really confronting warning light.” They largely back the scientists. As has been widely reported, 23 former fire and emergency services chiefs from across the country have jointly warned climate crisis is making bushfires deadlier and the season longer, and called on the government to act. Neil Bibby, former chief executive of Victoria’s Country Fire Authority and one of the 23, says: “It has been the last couple of years where we have been realising things have started to change and this is the new future … It will only get worse.” The chief executive of the Australasian Fire and Emergency Service Authorities Council, Stuart Ellis, says this bushfire season already has an “enduring nature”. “[It’s] just relentless,” he says. Andrew Gissing, an emergency management expert at the Bushfire and Natural Hazards CRC and a consultant with Risk Frontiers, says an analysis of building losses from bushfire seasons back to 1925 suggests this season is already the third worst in NSW. In Queensland, about a third of all financial losses from burned buildings since 1925 have occurred this year. No fire can be blamed on climate change alone, but Bowman says the rise in higher temperatures, extreme dryness, worsening fire seasons, extreme bursts of fire weather and behaviour and the spread of fire across the country all align with scenarios painted by climate change projections. Greenhouse gas emissions have a clear impact on rising temperatures and, through that, an indirect link on increased dryness in eastern Australia. A recent study found the extreme temperatures that drove historic 2018 bushfires in northern Queensland were four times more likely to have happened because of human-caused climate change In short, climate change can and does makes bushfires worse. Bradstock says a range of published research has found escalating atmospheric concentrations of greenhouse gases are increasing the risk of the type of fires affecting NSW’s eastern forests, but reducing the likelihood of a similar fire to that experienced in 1974. The elevated scores on the forest fire danger index in winter this year meant not only that the risk of bushfires was significantly heightened as the warmer seasons began, but opportunities for hazard reduction burning had been limited in some parts of the country – although NSW authorities still managed to meet its annual target of 135,000ha of prescribed burning. Sarah Perkins-Kirkpatrick, from the University of New South Wales’ climate change research centre, says studies by the CSIRO and others have found the fire season has got longer, particularly in eastern Australia, where it is starting earlier. This is expected to continue until 2050 at least. “We know that catastrophic conditions are now more likely to occur, and into spring as well,” she says. On this year, Bradstock says: “I guess the most concerning thing to emphasise is it’s not over. We’re not even into summer yet.”"
"Young activists frustrated and frightened by Democrats’ inaction on the climate crisis occupied the office of the top Democrat in Congress on Monday to mark the beginning of a hunger strike. Roughly a dozen strikers with Extinction Rebellion are taking part in a global climate hunger strike that nearly 300 people have pledged to join.  They say the House speaker, Nancy Pelosi, is holding back progress, so they are targeting her instead of top Republicans. They are demanding that she meet with them for an hour on camera before they call off their hunger strike. “Every day the evidence piles up at your desk, but you have yet to pass even symbolic legislation recognizing the climate crisis as a national emergency. With all due respect, you have failed,” the group said in a letter to Pelosi. Pelosi’s office contested allegations of inaction but did not say whether Pelosi or her staffers would meet with the protesters. In a press statement, Pelosi cited a bill the House passed to keep the US in the Paris climate agreement, which Donald Trump is exiting. The international pact is voluntary, and experts say it is not strong enough and also not being upheld by many countries. Extinction Rebellion calls for governments to declare a climate and ecological emergency, cut heat-trapping pollution to net-zero by 2025 and create a citizen’s assembly to direct a way forward. Their demands are far more aggressive than most environment organizations. They want radical change to keep world temperatures from climbing 3C or beyond the normal of just a century ago and disrupting human civilization. Thousands of scientists warn of a future that threatens “untold suffering”. On Monday, the strikers were given vitamins and supplements and weighed before beginning their protest. Not all of the hunger strikers were present. Some will participate in the sit-in later this week, when they are able to miss work. Pelosi’s office issued a press statement but did not respond directly to Extinction Rebellion. Seventeen-year-old Sophia Kianni, in a speech she planned for the hunger strike said “it is deeply saddening and shameful that we must resort to a hunger strike just to get our leaders to care about their children’s futures. Our nation’s leaders would rather watch climate activists starve than give us the time of day.” She accused Pelosi of employing “cowardly politics”, and “worrying about alienating big businesses”. Nick Brana, a spokesman for Extinction Rebellion in Washington, accused Pelosi of holding back a resolution to declare a climate emergency and a Green New Deal and “neutering” a special House climate committee that does not have the power to subpoena fossil fuel companies or the ability to write legislation. Twenty-year-old Giovanni Tamacas, whose Washington hunger strike the Guardian reported on in August, said he joined Extinction Rebellion because he felt other climate activism groups were not disruptive enough. He came to the organization after some of its protesters stripped off their clothes to draw attention to the crisis in the British parliament. Young people around the world have been striking from school on Fridays in solidarity with Greta Thunberg. Celebrity activist Jane Fonda, 81, is also protesting at the US Capitol every Friday too and has been arrested multiple times. “The way that this movement is going is we’re going to need more and more extreme actions in order to bring the climate crisis to the forefront of the debate, and you know it’s going to take mass participation in civil disobedience and direct action,” Tamacas said."
nan
"One thing I remember vividly from my childhood is The Day of the Triffids. In John Wyndham’s apocalyptic novel, the triffids were carnivorous plants that didn’t need roots and had developed three legs to allow them to find prey (whose nitrogen they fed on instead). They were originally bred by humans to provide high-quality vegetable oil, since the growing population’s demand for food was outstripping supply. Initially contained on farms, the triffids escaped following an “extreme celestial event” and began to terrorise the human population.  Replace “breeding” with “genetic modification” and you have the contemporary cautionary tale about the threat of “Frankenfoods” to human health and the environment. But this raises another question – if we ignore their potential, what does it mean for human food requirements in the future? The Day of the Triffids was first published in 1951, right at the start of the “green revolution”. The latest thing was breeding new varieties of cereal which were high-yielding. Together with other newly developed technologies including machinery – tractors and irrigation pumps – and synthetic inputs like pesticides and fertilisers, this helped double major commodity crop production between 1960 and 2000 to 2 billion tonnes worldwide, rebutting Malthusian fears about the world failing to feed its growing population.  In the last decade, the rosy glow has worn off a little. Growth in world crop yields has declined and is even stagnating, perhaps due to climate change – especially stress from heat and drought. Yields are no longer increasing fast enough to keep pace with projected demand. If current trends continue, we’ll need to expand our crop land by 42% by 2050. As a consequence, forests will be lost. Along with associated costs from requiring more water, plus the effects on biodiversity, this will increase agriculture’s greenhouse-gas emissions significantly. In total, agri-food is set to emit enough greenhouse gases to surpass the entirety of the 1.5℃ temperature-rise target called for in Paris for 2050.  There are basically two options: we can increase yields to meet demand without expanding area, and/or we can reduce demand enough to allow supply to catch up. Increasing supply in a sustainable way is perfectly possible. Some of this is about increasing efficiency through better farming, such as using precision agriculture to target the right amounts of fertilisers and pesticides to the right places.  Some of it is about changing land management to get the most out of agricultural land while maintaining ecosystem services, for example by managing the edges of fields as buffer strips to prevent chemicals being washed away by heavy rains; and as places with lots of wild flowers where bees can thrive to improve crop pollination. And some of it is about developing new animal and plant varieties that are more efficient, more productive or better able to cope with the changing environment. New varieties can come about from various means. Conventional breeding continues to be important. But modern laboratories have given us more strings to our bow. Not all biotechnological approaches are genetic modification in the legal sense. Using chemicals or X-rays to create genetic variation has long been a mainstay of “conventional breeding”, for example. Other techniques – such as CRISPR – are arguably post-GM, in that they can involve the clinical editing of single genes without leaving a signature of foreign DNA. CRISPR can produce identical plants to those produced conventionally, but much faster. Yet for some people, biotechnological crop or livestock modification conjures up “triffidophobia”.  Just how wary should we be about new technologies? Conventional breeding has served us well, but can’t keep up with demand or the speed with which the weather is changing. Any change in farming practice has associated risks that need to be assessed and managed, but these also need to be weighed against the risks of doing nothing. To increase food supply to meet projected demand, farming in the same way as we do now, the emissions from deforestation and other changes will lock us into a world of 4-5℃ of climate change. Together with other significant costs to the environment and human health and well-being, that’s probably a greater risk than the alternative.  It is difficult to guess how much biotechnological approaches will contribute to the solution, though. We still need to develop precision agriculture and smarter land use. And even if the gaps between current and required yields are halved – a big ask across the world – we’ll still need more land to meet demand. This would still impact on the likes of our water supply and create enough warming to challenge the Paris targets.   This is where the second option comes in – decreasing demand. Globally, we feed livestock about a third of all the calories we grow – enough to feed all the people in Asia. About a third of the food we grow is also lost or wasted. And across the world, many people overeat enough to make themselves ill through obesity, diabetes and so on. If we made wiser purchasing and consumption decisions, potentially we could halve current global demand for food. That would create space for sustainably feeding the growing population as well as growing biofuels and carbon storage in new forests. For me, the message is clear. We are unsustainably using the planet’s resources to produce the food we demand, and there will be very negative results if we continue  on the same trajectory. New technology can help, but needs assessed as it is developed. Old technology still has a role; as does reducing waste, over-consumption and meat-heavy diets. There is no simple answer but there is a toolbox, and we’ll need every tool at our disposal to address the challenge we created. Our technology won’t produce The Day of the Triffids, but without it, we may create a future Apocalypse Now. For more coverage of the debate around GM crops, click here."
"The New South Wales government was advised six months ago that Sydney’s water storage levels could be at “emergency levels” by May next year unless it started planning immediately. A cabinet-in-confidence document prepared by state-owned agency WaterNSW warns that storage levels could fall to 40% by Christmas and were likely to reach what are considered emergency levels – about 35% and declining – by mid-next year if the coming summer is hot and dry. Sydney’s storages have slumped from 96% full in April 2017 to less than 46%. Ian Wright, a University of Western Sydney scientist, likened the trajectory to “a ski-slope”. The WaterNSW document says inflows since early 2018 had been the lowest on record and water use across the city had been higher than expected. It had increased the risk that some critical supply areas, such as the Illawarra, may run out of water in about two years. Titled “drought supply options study”, the document says storages will become increasingly difficult to manage if they fall below 30%. Storages have depleted at a faster rate during this drought than during the millennium drought, when they fell to 33%. It does not explicitly mention climate change, but warns of the need to plan for “a scenario where climate doesn’t follow history and we get a follow-up drought before recovery”. Sign up to receive the top stories from Guardian Australia every morning “The only options left to us at this point are large-scale desalination plants,” it says. The NSW Greens’ water spokeswoman, Cate Faehrmann, said the document showed the government’s 2017 metropolitan water plan was based on data from the 1939 drought, and ignored years of expert warnings of lower water availability due to climate change and population growth. “It’s grossly negligent for the government to be planning for water security based on historical trends. Unless they factor in reduced water availability under a hotter climate we don’t stand a chance,” she said. A spokeswoman for the water minister, Melinda Pavey, said the government was investigating measures to support Sydney’s water supply and was already taking steps. People in Sydney use more water per person than Melburnians, but the spokeswoman said water use in Sydney fell last financial year, both in total and per capita terms, after investment in water efficiency programs. The government had also preemptively introduced level one water restrictions when dam levels reached 53.5%, before the 50% trigger was reached, and last week announced that level two restrictions would start on December 10, ahead of the 40% trigger point. Average per person water use had fallen from 211 litres to 183 litres a day, the spokeswoman said. She said the government was considering expanding the city’s desalination plant, which is operating at full capacity and supplies 15% of daily water demand, and work had commenced on a strategy to be released next year that would integrate water and sewerage planning. It could increase the use of recycled sewage water, a step long called for by experts. “This will be an adaptive plan for Sydney’s water and sewerage needs out to the year 2080,” the spokeswoman said. Faehrmann said experts had urged the government to invest in large-scale water recycling and stormwater harvesting during the millennium drought but consecutive administrations had failed to act. She said Pavey needed to explain why she did not introduce more water saving measures after receiving the WaterNSW advice in May. “She knew all of this while Sydney had no enforced water restrictions whatsoever,” she said. Wright, a senior lecturer in environmental science, said the government should adopt a water pricing mechanism similar to other states that charged consumers higher rates when they used large amounts. “It is the only jurisdiction that doesn’t have blocked pricing,” he said. He said bringing in level two restrictions earlier than planned and considering an expansion of desalination was welcome, but said the desal plant should have been operating at full capacity much earlier. He urged the government to do more. “Where are the big recycling projects?” he said."
"
Share this...FacebookTwitterUPDATE: http://www.thelocal.de/20150612/reagan-to-gorbachev-tear-down-this-wall
========================================
Sorry for the interruption in blogging and comment moderation over the past 24 or so hours – I was a bit swamped by other things. But now things are back on track. I’ll be posting back at normal speed tomorrow.
Though I missed the anniversary date by two days, The following video is a nice flashback … to 28 years ago:

I don’t know about you, but I get goose bumps every time I hear that last sentence.
I’m glad to say that during a recent visit to Berlin, President Reagan was prominently featured at the Checkpoint Charlie Museum, a must-see if you’re visiting the German capital. If you go, I suggest starting the visit at the top of the museum and working backwards.
Reagan’s (spineless) advisors actually crossed out the “Tear down this wall” sentence, deeming it too provocative. But Reagan ignored it. Less two and a half years later the wall came crashing down.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA few days ago the German ZDF national television late evening news presented a profile of the 2014 Starmus Festival in Tenerife, which featured distinguished Nobel prize scientists and astronauts (last September).
Hat-tip Wolfgang Neumann at facebook.com. 
Example of those in attendance were Harold Kroto, Steven Hawkins, and astronauts Charlie Duke, Walter, Alexey Leonov, and Apollo 7 Astronaut Walter Cunningham.

Former astronaut Walter Cunningham. Image cropped from ZDF “heute journal”.
A video of the ZDF newscast is posted here at the network’s website. The part of interest begins at the 16:10 mark where the ZDF begins its the segment on Starmus. The really interesting, and unexpected, part begins at the 18:05 mark where ZDF British Nobel prize chemist Harold Kroto comments on CO2 and climate, which follows (in part translated from the German voice-over):



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Even if there is no global warming, it is still in the interest of humanity to find an alternative to fossil fuels. As a chemist I’m telling you that it is almost criminal to burn them.”
But former astronaut Charles Duke doesn’t buy Kroto’s view:
A single volcano emits more climate gases into the atmosphere than man does. I don’t think we are responsible for the global warming.”

And neither does astronaut Walter Cunningham buy into the global warming theory:
Those who are sounding the alarms have corrected their claims multiple times. It is one of the greatest scientific fiascos of all time.”
It’s quite a surprise that Germany’s leading politically correct national television, ZDF, showed that sound byte, and did so in an untypically neutral way. Too late now – millions of Germans heard what undoubtedly will serve as seeds for doubt.

Readers here who are familiar with German climate politics of course are expecting certain PIK scientists to pick up the phone and to vigorously scold the ZDF for their “irresponsible” journalism, for giving a few seconds time to highly qualified skeptics.

 
Share this...FacebookTwitter "
"The European parliament is split over whether to declare a global climate emergency before next week’s crucial UN summit. If passed, the climate emergency resolution – to be voted on on Thursday – would throw down the gauntlet to incoming European Union leaders. The European commission’s president-elect, Ursula von der Leyen, is expected to take office on 1 December, having promised “a European green deal” in her first 100 days.  The draft resolution states there is “an environment and climate emergency in Europe and globally” and declares the EU will “take action accordingly”. “It is a message to European citizens, to young people, to say that Europe is the very first continent to declare a climate emergency and to act accordingly,” said Pascal Canfin, a French MEP who chairs the European parliament’s environment committee and co-authored the resolution. The text also references the US president Donald Trump’s decision to begin formal withdrawal from the Paris climate agreement earlier this month. “We need to send a signal that after Trump’s decision, Europe is more than ever committed to deliver,” said Canfin, an ally of the French president, Emmanuel Macron. While the climate emergency resolution is supported by many Liberals, Socialists, Greens and the radical left, the centre-right European People’s party (EPP) – the European parliament’s largest group – is uneasy about the word “emergency”. A source said the German word der Notstand was associated with the name of an infamous law of the Nazi era. The EPP has tabled an amendment stating that the parliament “declares a climate and environmental urgency” [sic] and calling on the EU to take “urgent action”. “I fully underline that we see the urgency of the issue. We need to prioritise this,” said the EPP leader, Manfred Weber, when asked whether his group would back the climate emergency text. The parliament’s political forces are also divided over how quickly Europe should cut emissions to reach a target of net zero emissions by 2050. In a separate vote on Thursday, the European parliament is expected to approve a resolution stating that current EU climate targets are “not in line” with the 2015 Paris climate agreement, which calls for keeping global heating “well below” 2C above pre-industrial levels while aiming for only a 1.5C rise. The EPP supports an emissions reduction of “at least 50%” by 2030 (compared with 1990 levels), while Liberals and Socialists would go to 55%. The Greens argue that anything less than 65% is inadequate. “We have to realise that to meet the Paris agreement there are … very, very strict limits of carbon dioxide and other greenhouse gases that we can release into the atmosphere from now for the next hundreds of years. And if we choose to release that much during this next decade then we can’t keep the temperature below 2C,” said the Swedish Green MEP Pär Holmgren. Holmgren, a meteorologist and well-known TV weatherman until elected to the European parliament this year, advised the Thunberg family on climate science long before Greta began her school strike. Holmgren told the Guardian that he was frustrated with political leaders using Greta’s name, but not taking sufficient action: “There are so many quoting Greta, or saying we have to listen to Greta, or saying we have to keep global warming below 1.5C … and to hear someone say that, and then still not deliver? “Yes, there is a climate emergency and it has been for many decades, but if you want to say that then you have to do something about it as well.” Others say a 55% emissions reduction goal for 2030 is in line with scientific advice. “We are politicians, so we need to bring society on board. We are not drafting an IPCC report,” Canfin said. “We are drafting something that will apply to business, SMEs, agriculture, farmers and citizens.” The Greens’ preferred goal of at least 65% is based on a recommendation by the Climate Action Network (CAN) Europe, a coalition of 1,700 NGOs that bases its analysis on an an IPCC report on how to keep global heating below 1.5C. That report shows other pathways to cut emissions, but some increase the risk of overshooting the 1.5C ceiling on temperature rises, which scientists say is essential to avoid the most dangerous consequences. The scale of the task was outlined by the UN environmental agency on Tuesday, when it reported that global emissions must fall by more than 7% each year from now until 2030 to stay within the 1.5C limit. Most EU member states have signed up to a goal of net zero emissions by 2050, although Poland, the Czech Republic and Hungary continue to hold out, as they await promised EU funds to help their economies go green. The EU has focused its attention on the more distant 2050 target, fearful of damaging splits over the imminent 2030 deadline. “We have been campaigning on the increase of the 2030 target for years and it was disgracefully ignored,” said Klaus Röhrig, EU climate and energy policy coordinator at CAN Europe. The EU’s current objective is to cut emissions by 40% by 2030, which was “shockingly insufficient” Röhrig said."
"The world’s use of coal-fired electricity is on track for its biggest annual fall on record this year after more than four decades of near-uninterrupted growth that has stoked the global climate crisis. Data shows that coal-fired electricity is expected to fall by 3% in 2019, or more than the combined coal generation in Germany, Spain and the UK last year and could help stall the world’s rising carbon emissions this year. The steepest global slump on record is likely to emerge in 2019 as India’s reliance on coal power falls for the first time in at least three decades this year, and China’s coal power demand plateaus. Both developing nations are using less coal-fired electricity due to slowing economic growth in Asia as well as the rise of cleaner energy alternatives. There is also expected to be unprecedented coal declines across the EU and the US as developed economies turn to clean forms of energy. In almost 40 years the world’s annual coal generation has fallen only twice before: in 2009, in the wake of the global financial crisis, and in 2015, following a slowdown in China’s coal plants amid rising levels of deadly air pollution. The Guardian has updated its style guide to introduce terms that more accurately describe the environmental crises facing the world. Instead of “climate change”, the preferred terms are “climate emergency, crisis or breakdown” and “global heating” is favoured over “global warming”. The scale of the climate and wildlife crises has been laid bare by two landmark reports from the world’s scientists. In October 2018, they said carbon emissions must halve by 2030 to avoid even greater risks of drought, floods, extreme heat and poverty for hundreds of millions of people. In May 2019, global scientists said human society was in jeopardy from the accelerating annihilation of wildlife and destruction of the ecosystems that support all life on Earth. The editor-in-chief, Katharine Viner, says: “We want to ensure that we are being scientifically precise, while also communicating clearly with readers on this very important issue. The phrase ‘climate change’, for example, sounds rather passive and gentle when what scientists are talking about is a catastrophe for humanity.” Other terms that have been updated include the use of “wildlife” rather than “biodiversity”, “fish populations” instead of “fish stocks” and “climate science denier” rather than “climate sceptic”. Damian Carrington Environment editor The research was undertaken by the Centre for Research on Energy and Clean Air , the Institute for Energy Economics and Financial Analysis and the UK climate thinktank Sandbag. The researchers found that China’s coal-fired power generation was flatlining, despite an increase in the number of coal plants being built, because they were running at record low rates. China builds the equivalent of one large new coal plant every two weeks, according to the report, but its coal plants run for only 48.6% of the time, compared with a global utilisation rate of 54% on average. The findings come after a report from Global Energy Monitor found that the number of coal-fired power plants in the world is growing, because China is building new coal plants five times faster than the rest of the world is reducing their coal-fired power capacity. The report found that in other countries coal-fired power capacity fell by 8GW in the 18 months to June but over the same period China increased its capacity by 42.9GW. In a paper for the industry journal Carbon Brief, the researchers said: “A 3% reduction in power sector coal use could imply zero growth in global CO2 output, if emissions changes in other sectors mirror those during 2018.” However, the authors of the report have warned that despite the record coal power slump the world’s use of coal remained far too high to meet the climate goals of the Paris agreement. The US – which is backing out of the Paris agreement – has made the deepest cuts to coal power of any developed country this year by shutting coal plants down in favour of gas power and renewable energy. By the end of August the US had reduced coal by almost 14% over the year compared with the same months in 2018. The EU reported a record slump in coal-fired electricity use in the first half of the year of almost a fifth compared with the same months last year. This trend is expected to accelerate over the second half of the year to average a 23% fall over 2019 as a whole. The EU is using less coal power in favour of gas-fired electricity – which can have roughly half the carbon footprint of coal – and renewable energy."
"More unwanted “stuff” at Christmas? No thanks – try giving a tasty treat instead. Chocolate workshops at the National Trust’s medieval Powis Castle and Garden near Welshpool, include handmade chocolate robins and stars, and sparkly chocolate shards (19 December, £27.50). In York – original home of Rowntree’s and Terry’s factories – chocolate workshops at York Cocoa House range from drop-in lollipop-making (£3.75), to masterclasses on specialities, such as ganaches and caramels (various dates, £55 adult, £28 child). In the Gloucestershire Hills, Harts Barn Cookery School in the Forest of Dean is running Christmas cookery classes throughout December, including children’s edible decorations and edible gifts classes (gingerbread men, marshmallow penguins, chocolate lollies and reindeer pretzels, 15 December, from £25), and Christmas chocolate-making for adults (1 December, £50), with truffles and more to take away. For something savoury, learn the secrets of creating quick pickles at the Salt Box sustainably minded cookery school’s Pickle like a Pro workshop (11 December, £45) near Redhill in Surrey, which also includes a festive drink and a two-course meal. Classes take place in a private woodland glen and cosy barn. Piece Hall in Halifax – a recently restored 18th-century cloth hall that now has independent shops and eateries around its vast courtyard – is running a series of Christmas events and workshops, including making felt decorations with heritage cloth (17 December, £5.50) and felted snowman sessions for children (ages 6 and over, 21 December, £7.50). In Surrey, the Royal Horticultural Society’s 97-hectare Wisley Garden – one of the UK’s most-visited gardens – has a workshop on “living baubles” – known in Japan as kokedama (£15, 4 December), alongside free children’s decoration-making sessions using woodland materials (14-15 December). Also for children, and inspired by a new exhibition, Flights of Fancy: the Wondrous World of Quentin Blake (running until April 2020), The National Trust’s Nymans house in West Sussex is running decoration workshops (various dates, £3). In Glasgow, Locavore, an organic and sustainable food shop and cafe close to Queen’s Park, has a workshop (23 November, £10) on upcycling old books to become paper decorations, such as intricate snowflakes and folded trees. Choose from an array of textures and colours to make fabric wreaths at Water Lane Boathouse in Leeds’s Granary Wharf. The former 19-century shipment warehouse is now a laid-back waterside pub run by the team behind the city’s multi-arts venue, Belgrave Music Hall. A few miles to the west in Saltaire, the preserved Victorian industrial village in Shipley, the Craft House will be running origami textile wreath workshops (£55, 14 December) and papercut light-up wreaths (£30, 24 Nov). Round the corner, Salts Mill, a former textile mill turned art centre, has shops, restaurants and Christmas events. At the National Trust’s Gibside, an 18th-century estate in Tyne and Wear, there will be paper wreath-making sessions (£45, 7 December) in Garden Cottage in a restored walled garden. Also using paper, the NT’s Arlington Court near Barnstaple in Devon has festive paper flower wreaths sessions (£8, 23 December). To go fully-zero waste, make decorations that can be eaten after use: on the edge of the Lake District, medieval Sizergh Castle and gardens near Kendal is running gingerbread decoration workshops (14-15 December, £3.50), for all ages. Brits pull an estimated 154m crackers every Christmas. Recent calls to ban them because of the amount of plastic waste they produce have seen a surge in eco-friendly alternatives. Shrewsbury Museum and Art Gallery, in the centre of the historic Shropshire town, has eco cracker-making session (£20, 24 December), using recycled materials and filler choices including fair trade chocolate, handmade bath bombs and bee-friendly seed bombs. As part of the Zero Waste Goods Christmas Market at the Boiler House, on Brick Lane in east London, fabric, plus natural and upcycled materials will be used to create reusable crackers (£24, including entry to the market, 7 December). In Hull, UK City of Culture 2017, eco-cracker and wrapping paper workshops (4 December, £19.99), are on offer at cocktail bar and creative space the Brain Jar in the Old Town – named one of Britain’s “hippest neighbourhoods” last year. Run in association with nearby zero-waste store the Eco Shed, sessions will also include vegan mince pies and fizz. Bristol – the UK’s first European Green Capital – is not to be outdone, of course. Craft company Hunter Gatherings is running eco-friendly cracker- and stocking-making workshops (from £28, various dates) at Convoy Espresso – a cafe in two Airstream trailers at the Paintwork creative quarter, and at Brockley Stores farm shop, 10 miles south-west of the city. Shop-bought gift paper is often plastic-based and can’t be recycled. The National Botanic Gardens of Wales, in Llanarthney, is running a sustainable gift wrap and tag workshop (£11.50, 1 December, including entry into the gardens), using materials fully compostable or recyclable after use. In Dundee, zero-waste shop the Little Green Larder has an eco gift wrap workshop (30 November, £15), which includes paper, gift bags and cards, nibbles and a festive drink – all a 20-minute walk from the regenerated waterfront area and new V&A. With the chance to create a linocut stamp to take away and use for printing your gift wrap every Christmas, Paper Moon Print Studio is running a workshop (11 December, £32) at Liverpool’s Static Gallery. This multi-arts venue is in a former warehouse close to the city’s creative Ropeworks district, which also made the “hippest neighbourhood” ranking last year. Also including a take-home stamp is a festive linocut workshop (27 November, £33), at Grade II-listed Didsbury Parsonage on the outskirts of Manchester. In Coal Drops Yard, in London’s King’s Cross, independent printer Hato Press has festive gift wrap printing (£10 donation, all proceeds donated to Shelter, 28 November and 5 December), using FSC-certified and recycled paper . The workshops will be held at new indie magazine and clothing shop Kiosk N1C, part of a programme of charitable festive events in the shops and restaurants of this recently regenerated city space. Looking for a holiday with a difference? Browse Guardian Holidays to see a range of fantastic trips  This article contains affiliate links, which means we may earn a small commission if a reader clicks through and makes a purchase. All our journalism is independent and is in no way influenced by any advertiser or commercial initiative. By clicking on an affiliate link, you accept that third-party cookies will be set. More information. "
"Demolition work is the most dangerous job in construction, which itself is one of the industries with the highest injury rates. The tragic building collapse and loss of life at the disused Didcot A power plant in Oxfordshire is a stark reminder of just how dangerous demolition can be.  One person is dead and three are still missing after a large part of the main boiler house collapsed on February 23. While it’s far too early to know what actually caused the accident, there are a number of reasons why buildings can collapse unexpectedly during – or just prior to – demolition.  Firstly, and most significantly, contractors may not fully appreciate the structural principles of the building they are dealing with. For example, if a key component – which could be an obvious large girder or something as small as a nut on a particular threaded steel rod – is removed the remaining building could become less stable and must be checked by a competent structural engineer.   Failing to understand the consequences of altering or removing key parts of a structure was tragically demonstrated when a building in Stanley Road, Liverpool collapsed in 2000, killing one person. A steel beam had been bent back to allow access for a skip lorry and steel wall ties had been removed. Workers on the site weren’t aware that alterations over time meant these walls had become more structurally important. Problems of structural stability are further compounded by recent trends in environmental sustainability and the emergence of the “circular economy”, where components and contents of buildings are recovered for resale, reuse or recycling. For example, when a power plant is decommissioned recovery of machinery and equipment is to be expected. Precious metals can be sold on, brick and timber can be reused, and even the concrete can be crushed and recycled.  This presents significant hazards as workers are required to work in the building to “deconstruct” the various elements, rather than use a long-reach demolition rig from a safe distance. It is not unusual to essentially cut a hole or doorway in the wall to allow large machinery to be easily moved in and out. An additional consequence of this method is it allows wind to flow through the building, which can “load” the walls beyond their tolerance levels.   If the cumulative effects of removing fixed machinery that could very well be attached to structural elements of the building, removing parts of walls, and other parts of the building are not considered, then the consequences could be catastrophic. Explosions are the other main risk. In Didcot’s case, one avenue for investigation might be accidental detonation. After all, three of Didcot’s disused cooling towers were demolished with explosives in July 2014. However, cooling towers are relatively simple structures which lend themselves to explosive demolition rather than excavators or dismantling piece-by-piece. The building that collapsed was probably planned to be demolished by one of these more conventional means. However, such specialist explosive work is invariably undertaken under the control of an experienced explosives engineer, so the more obvious source of an explosion might come from what fuelled the building – gas or coal. Gas may build up in the plant itself, leak from pipes over time, or could be present in a “live” pipe that was thought to be “dead” or isolated. In these cases, a spark or source of ignition could easily set off an explosion. Such explosions tend to kill indirectly, as the force causes walls to explode and the roof to fall down, crushing the workers below. This is what happened when corroded 35-year-old gas pipes caused the 2004 Stockline Plastics factory explosion in Glasgow which killed nine people. Coal dust can also cause these sorts of explosions. In fact, most types of dust can cause an explosion if airborne and sufficiently agitated. With the right dust/air ratio, a substantial dust cloud can easily be ignited and cause an explosion equally as devastating as gas. Early reports indicate an explosion just prior to the collapse at Didcot, though this was later denied. However, any causes identified here can only be considered as potential avenues for investigation. The UK’s Health and Safety Executive’s investigation will undoubtedly uncover the actual cause (or causes) of the collapse in due course.  Hopefully lessons can be learned for the future. But, of course, this will be of little consequence to the families of the dead and missing workers."
"
Share this...FacebookTwitterAwhile back I announced I was disassociating myself from the Catholic Church because of their growing acceptance of the wacky man-made global warming theory. How can it be that the Church, symbol of truth and morality, would accept a science that is built on outright lies, flakey theories, deception and fortunetelling? That’s no Church for me.
Some readers thought that I may have acted to hastily, and advised me to at least wait until the Pope releases his upcoming encyclical on the topic. Maybe the Vatican is not really quite going in that direction.
Unfortunately that hardly seems to be the case. All signs are pointing to a Vatican that is ready to accept the bogus science. One can only speculate about what earthly benefit they may be getting in return. Even the Vatican’s soul can be bought.
For example the Vatican writes in a December 11 press release concerning the Lima Conference that climate protection is “a grave ethical and moral responsibility” and that “the consequences of environmental change […] remind us of the grave consequences of mismanagement and inaction.” and that “The time for seeking global solutions is running out” claiming there exists “a clear, definitive and unpostponable ethical imperative to act”.
I’d say the Vatican’s position is quite clear. The press release continues:
Pope Francis thus emphasised that an ‘effective battle against global warming will be possible only through a responsible collective response that sets aside particular interests and behaviours and develops free from political and economic pressures’.”
Other Vatican press releases on the subject use the same language.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Today the catholicphilly.com reports on the Pope’s upcoming visit to the Phillipines. It writes: “A worldwide campaign is emerging among Catholic individuals and organizations concerned about climate change and protecting the environment. The Global Catholic Climate Movement went public Jan. 14, coinciding with the visit of Pope Francis to the Philippines.”
Okay, this does not appear to be a direct initiative from the Vatican, but it is one that is awfully close to it. As more Catholics adopt global warming, it is only a question of time before the Church becomes divided.
Also new today is that Catholics in Australia are joining global movement to curb climate change. Great, these Catholics now believe in rain-dancing and indulgences.
They write:
We accept the findings of scientific leaders, such as the Intergovernmental Panel on Climate Change (IPCC), that humanity’s greenhouse gas emissions are contributing to widespread and mostly harmful changes to planetary systems. We are certain that anthropogenic [human-made] climate change endangers God’s creation and us all, particularly the poor, whose voices have already spoken of the impacts of an altered climate.”
It’s one thing when the members leave the Church, but it’s quite another when the Church leaves its members – and joins up with a flakey movement that is based on phony data, deception, slimy politics and fortunetelling. I have no desire to follow the Vatican in this folly. The Church has to come back to the truth, and not the other way around.
The Vatican would be very wise make an immediate course correction and to take a neutral position on the issue.
PS: My “Pope’s “to-do list” is meant to be satirical.
Share this...FacebookTwitter "
"President Donald Trump’s vow to hit North Korea with “fire and fury like the world has never seen” is an unveiled threat to unleash America’s most potent weapons of mass destruction onto the Korean peninsula. According to many defence analysts, the risk of nuclear confrontation over Europe and the Indian subcontinent has also increased in recent years. In a more hopeful turn of events, 122 countries voted in June to adopt the United Nations Treaty on the prohibition of nuclear weapons in New York. The “ban treaty” will make nuclear weapons illegal for ratifying countries, and many see it as an opportunity to kick start a renewed effort towards multilateral disarmament. Supporters of the treaty argue that even a limited, regional nuclear war would produce a catastrophic and global humanitarian crisis. Equally, other analysts suggest that the reality is not as severe as is often depicted. In March this year, Matthias Eken, a researcher of attitudes towards nuclear weapons, wrote in The Conversation that their destructive power “has been vastly exaggerated” and that one should avoid overusing “doomsday scenarios and apocalyptic language”. Eken argued that nuclear weapons are not as powerful as often described, on the basis that a 9 megaton thermonuclear warhead dropped over the state of Arkansas would only destroy 0.2% of the state’s surface area. He also observed that more than 2,000 nuclear detonations have been made on the planet without having ended human civilisation, and argued that if we want to mitigate the risk posed by nuclear weapons, we must not exaggerate those risks. Eken’s sanguine approach towards nuclear weapons stands in contrast to the more dramatic rhetoric of global humanitarian catastrophe and existential threats to humanity. So what is the basis for the latter? The greatest concern derives from relatively new research which has modelled the indirect effects of nuclear detonations on the environment and climate. The most-studied scenario is a limited regional nuclear war between India and Pakistan, involving 100 Hiroshima-sized warheads (small by modern standards) detonated mostly over urban areas. Many analysts suggest that this is a plausible scenario in the event of an all-out war between the two states, whose combined arsenals amount to more than 220 nuclear warheads. In this event, an estimated 20m people could die within a week from the direct effects of the explosions, fire, and local radiation. That alone is catastrophic – more deaths than in the entire of World War I. But nuclear explosions are also extremely likely to ignite fires over a large area, which coalesce and inject large volumes of soot and debris into the stratosphere. In the India-Pakistan scenario, up to 6.5m tonnes of soot could be thrown up into the upper atmosphere, blocking out the sun and causing a significant drop in average surface temperature and precipitation across the globe, with effects that could last for more than a decade. This ecological disruption would, in turn, badly affect global food production. According to one study, maize production in the US (the world’s largest producer) would decline by an average by 12% over ten years in our given scenario. In China, middle season rice would fall by 17% over a decade, maize by 16%, and winter wheat by 31%. With total world grain reserves amounting to less than 100 days of global consumption, such effects would place an estimated 2 billion people at risk of famine.  Although a nuclear conflict involving North Korea and the US would be smaller, given Pyongyang’s limited arsenal, many people would still die and ecological damage would severely affect global public health for years. Additionally, any nuclear conflict between the US and North Korea is likely to increase the risk of nuclear confrontation involving other states and other regions of the world. A large-scale nuclear war between the US and Russia would be far worse. Most Russian and US weapons are 10 to 50 times stronger than the bombs that destroyed Hiroshima. In a war involving the use of the two nations’ strategic nuclear weapons (those intended to be used away from battlefield, aimed at infrastructure or cities), some 150m tonnes of soot could be lofted into the upper atmosphere. This would reduce global temperatures by 8°C – the “nuclear winter” scenario. Under these conditions, food production would stop and the vast majority of the human race is likely to starve. Eken suggests that both the scenarios of a limited regional nuclear conflict and an all-out war between US and Russia are unlikely. He may be right. However, both scenarios are possible, even if we can’t reliably quantify the risk. Continued adversarial rhetoric from both Donald Trump and Kim Jong-un about the use of nuclear weapons is not making this possibility any smaller. What we can say, is that the doctrine of nuclear deterrence represents a high-risk gamble. Nuclear weapons do not keep us safe from acts of terrorism, nor can they be used to fight sea level rise, extreme weather, ocean acidification, biodiversity loss or antimicrobial resistance. This is why so many medical and public health organisations have been campaigning to make nuclear weapons illegal. Regardless of how many need to be exploded to cause a catastrophe or produce an existential threat to humanity, and regardless of the risk of this happening, the adage that “prevention is the best cure” remains the case when it comes to these abhorrent and dangerous weapons. Research papers and discussions on the public health and environmental effects of nuclear weapons will be part of the Health Through Peace 2017 conference at the University of York in September."
"Although most species of plants on Earth have flowers, the evolutionary origin of flowers themselves are shrouded in mystery. Flowers are the sexual organs of more than 360,000 species of plants alive today, all derived from a single common ancestor in the distant past. This ancestral plant, alive sometime between 250m and 140m years ago, produced the first flowers at a time when the planet was warmer, and richer in oxygen and greenhouse gases than today. A time when dinosaurs roamed primeval landscapes. But despite the fact dinosaurs went extinct 65m years ago we have a better idea of what an Iguanodon looked like than of how the ancestral flower was built.  This is partly because these first flowers left no traces. Flowers are fragile structures that only in the luckiest of circumstances can be transformed into fossils. And, as no fossil has been found dating back 140m or more years, scientists have only had a limited sense of what the ultimate ancestor would have looked like. Until now. A major new study by an international team of botanists has achieved the best reconstruction to date of this ancestral flower. The research, published in Nature Communications, relies not so much on fossils as on studying the characteristics of 800 of its living descendant species.  By comparing the similarities and differences among related flowering plants, it is possible to infer the characteristics of their recent ancestors. For example, because all orchid species have flowers in which one half is the mirror image of the other (bilateral symmetry), we can suppose that their ancestor must have had bilateral flowers. By comparing those recent ancestors to each other it is then possible to go a step further back in time, and so on, until eventually we reach the base of the flowering plants’ family tree. In some respects, the original flower resembles a modern magnolia: it has multiple, undifferentiated “petals” (technically tepals), arranged in concentric rings. At its centre there are multiple rows of sexual organs including pollen-producing stamens and ovule-bearing ovaries. It is hard to resist the temptation to imagine ancient pollinators crawling in this flower, collecting pollen grains while unknowingly helping the plant to produce seeds.  The new study helps to settle the controversy about whether early flowers had separate sexes, or whether both male and female reproductive organs were combined in the same flower. Previous evidence pointed to different answers. On the one hand, one of the earliest diverging lineages of flowering plants, represented nowadays only by a rare shrub from the Pacific island of New Caledonia called Amborella, has flowers that are either male or female. On the other, most modern species combine both sexes in the same flower.  The authors of the study settle the question and show that the ancestral flower was a hermaphrodite. This means that early flowering plants could reproduce both as a male and a female. Combined sexes can be advantageous when colonising new environments as a single individual can be its own mate, and indeed many plant species colonising remote oceanic islands tend to be hermaphrodite. Maybe the combination of sexes helped early flowering plants to outcompete their rivals. Despite the apparent similarity with some modern flowers, their ultimate ancestor has a few surprises up its sleeve. For example, botanist have long thought that early flowers had floral parts arranged in a spiral around the centre of the flower as can be seen in modern species such as the star anise. The new reconstruction, though, strongly suggests that early flowers had their organs arranged not in a spiral, but in series of concentric circles or “whorls”, as in most modern plants. The early flower had more numerous whorls, however, suggesting flowers have become simpler over time. Paradoxically, this simpler architecture may have given modern plants a more stable base upon which to evolve and achieve more complex tasks such as sophisticated interaction with certain insects as in orchids, or the production of “flower heads” made of dozens or hundreds of simpler flowers as in the sunflower family. Although now we have a good idea of what one of the earliest flowers may have looked like, we still know little about how that flower came to be. The detailed steps leading to its evolution are unknown. Perhaps we will have to wait for the discovery of new fossil flowers spanning the gap around 250m-140m years ago, before we can understand the very origin of what is the most diverse sexual structure on the planet."
"The climate emergency has risen to the top of the UK’s election agenda in a way that would have been “unthinkable” even five years ago, leading environmentalists have said, predicting that it augurs a permanent change in British politics. On Wednesday, Labour took the unprecedented move of putting green issues as the top section of its manifesto, the first time one of the UK’s two major parties has done so. Jeremy Corbyn led the appeal to voters with policies including an £11bn windfall tax on oil and gas companies, a million new jobs in a “green industrial revolution” and commitments on moving to a net-zero carbon economy.  “Such focus on climate and the environment would have been almost unthinkable five years ago,” said Shaun Spiers, executive director of the Green Alliance. “Tackling climate change runs through this manifesto in a way that is unprecedented from either of the main parties ahead of a UK general election.” “It would not have been possible five years ago,” said Tom Burke, chairman of environmental thinktank E3G and former adviser to several governments, who said the move marked a permanent change in British politics, as younger voters in particular were “energised” over the environment. Public anxiety had been fuelled by people seeing extreme weather around the world, and the rise of climate activism in movements such as Extinction Rebellion and the school climate strikes reflected that. “The politicians are following the public on this, not the other way round.” Public concern over the climate is “unequivocal”, and people “back decarbonisation by a massive margin”, said Richard Black, director of the Energy and Climate Intelligence Unit. “The UK has never had an election like this one in terms of the profile of climate change. To have all the major parties supporting a transition to net zero within a few decades, and competing with each other on policies to deliver, is unprecedented.” Labour disappointed many green campaigners by failing to put a date on its commitment to a net-zero carbon economy. After union pressure, a proposal to mandate the transformation by 2030 was watered down to “achieve the substantial majority of our emissions reductions by 2030”, which should imply swifter and stronger action than the Tory pledge to decarbonise by 2050, but leaves room for interpretation. There was also no frequent-flyer levy, despite increasing concern over aviation emissions from the independent Committee on Climate Change, and a heavily hedged green light on airport expansion. “Labour’s manifesto stops short of getting full marks – its policy for tackling exploding aviation emissions is not fit for purpose,” said John Sauven, executive director of Greenpeace UK. “And the commitments on plastic pollution and waste do not go far enough.” Ryan Shorthouse, director of the Conservative thinktank Bright Blue, accused the party of wanting too much state control in calling for nationalisation of energy, water and railways. “[The Labour manifesto] equates to a significant and unprecedented expansion of state expenditure and control. They envisage a super-spending, suffocating state. But voters are not stupid – the state cannot and should not deliver everything.” Burke believes Labour’s stance on Brexit will also alienate many environmentally minded voters. “Brexit is appallingly bad for the environment. The Labour party wants to do good things on the environment and wants do that within a strong EU – Corbyn is letting them down.” However, pushing the climate emergency back to the political periphery would no longer be an option for any party, he said. “This is mainstream now.” The Liberal Democrats, while focusing on Brexit, have also made the climate emergency a key priority, promising to generate 80% of the UK’s electricity from renewable sources by 2030, to bring forward to 2045 the deadline for net-zero carbon, and to expand electric vehicles and ban fracking. The Green party wants to spend £100bn a year for the next decade on the climate crisis, replacing high-carbon infrastructure and creating jobs. This weekend, the Conservative manifesto is expected to include policies on combatting climate change, reconfirming its commitment to net-zero carbon. Next year, thanks to Theresa May’s offer to the UN, the UK will host the most important international summit on the climate since the 2015 Paris agreement was signed, requiring a massive diplomatic effort if the government is to make it a success. But the party may be hampered by its recent see-sawing on environmental policies, with incentives to low-carbon development withdrawn, home insulation schemes closed and incoming housing regulations scrapped. Spiers said: “This will be a big moment for UK politics if the Conservatives show a similar level of ambition [to Labour].”"
"The ocean is deep. In fact, most of it is deep. Officially anything deeper than just 200 metres is considered the “deep sea”, but the average depth of the entire ocean is about 3.5km and the deepest point – the Challenger Deep in the Mariana Trench, in the western Pacific – is a little short of 11km down. That means that most of the living space on Earth is in the deep sea. We scientists like to categorise things and the ocean depths are no exception. Depths from the surface to 0.2km is known as the “littoral zone”, from 0.2km to 3km, the “bathyal zone”, and from 3km to 6km, the “abyssal zone”. Anything deeper than that is the “hadal zone”.   The hadal zone is largely comprised of deep trenches caused by tectonic plate subduction that drive the vast abyssal plains steeply down to depths of 11,000 metres in places. But even here, animals thrive, blissfully unaware of how little attention they receive. Here’s an insight into their incredible world. The term “hadal” comes from “Hades,” which refers both to the Greek kingdom of the Underworld and the god of the Underworld himself, Hades (brother of Zeus and Poseidon). The term can also mean the “abode of the dead”. In modern times, Hades is seen as evil, but in mythology he was often portrayed as unreasonably “stringent” rather than actively malicious. Interestingly, he strictly prohibited the inhabitants of his dominion to leave, which is a rather apt analogy for hadal fauna, as these species are often confined to trenches and are rarely capable of going elsewhere.  The extreme depths of the hadal trenches were discovered using “bomb sounding”, whereby someone threw a half-pound block of TNT off a ship and the echo was recorded on board the ship. This method was used to sound the depths of many trenches, but the exact depth of the deepest point, currently in the Mariana Trench, is still difficult to compute. Four other trenches, all in the Western Pacific, also exceed 10km: the Tonga, Kuril-Kamchatka, Philippine, and Kermadec trenches.  The HMS Challenger expedition (1873 to 1876) was the first to sample hadal depths – having collected sediment from about 8km – although it could not confirm whether or not the sediment was merely the remnants of shallower animals. The 1901 Princess Alice expedition successfully trawled specimens from over 6km. However, it was a 1948 Swedish expedition, which successfully trawled a variety of species from 7km to 8km in the Puerto Rico Trench, that finally proved that life existed at depths greater than 6km. In 1956, the first photographs of the hadal zone were taken by none other than Jacques Cousteau in the Romanche Trough in the Atlantic. The hadal zone comprises a series of disjointed trenches and other deep spots. There are 33 trenches and 13 troughs around the world – 46 individual hadal habitats in total. The mean depth of the trenches is 8.216km. The total area of the hadal zone is less than 0.2% of the entire seafloor but accounts for 45% of the total depth range. It is therefore surprising that the deepest 45% of the sea is rarely mentioned in deep sea literature. Of the 33 hadal trenches, 26 (84%) are located in the Pacific, three are found in the Atlantic (8%), two (4%) in the Indian Ocean, and two (4%) in the Southern Ocean. The majority run up the western Pacific. Most of the hadal trenches in their modern form are believed to have formed 65.5m years ago during the Cenozoic period. Earth appears to be the only terrestrial planet with subduction zones and plate tectonics. Both Mercury and the Earth’s moon are tectonically dead. Mars appears to have tectonically ceased, and Venus is dominated by thick lithosphere with mantle plumes. On Earth, subduction zones produce continental crust, which can protrude from the ocean (the continents). It has been speculated that without subduction, the land would still be underwater and terrestrial life, including humans, would never have evolved. Bottom water temperatures are cold and vary between 1°C and 4°C. However, hydrostatic pressure increases linearly by 1 atmosphere (atm) for every ten metres of depth. The pressure at hadal depths therefore ranges from 600 to 1,100 atmospheres. The pressure at the deepest point is, therefore, equal to a one tonne weight being placed on the end of your finger. Many marine organisms are found at hadal depths and the most common groups are the polychaetes, bivalves, gastropods, amphipods and holothurians. All of these groups are found at full-ocean depth and often in large aggregations. Contrary to popular media, the hadal zone is not a mysterious realm inhabited by aliens or “monsters of the deep”. Instead, it is a poorly understood region largely inhabited by hoppers, snails, worms, and sea cucumbers. In fact, the upper trenches are inhabited by little pink fish and bright red prawns. In the 1970s, the Puerto Rico Trench was a pharmaceutical waste disposal site. The figures are astonishing: in just five years, more than 387,000 tons of waste material was discarded in the trench, an amount equivalent to 880 Boeing 747s. In addition, the ill-fated Apollo 13 mission to the moon in 1970 carried a radioisotope thermoelectric generator (RTG) that was supposed to remain on the moon with the lunar lander. The RTG contained 3.9kg of plutonium-238, and in the end was jettisoned over the south-west Pacific, where it reportedly survived re-entry and settled in the Tonga Trench at a depth of 6km to 9km where it should now remain radioactive for several thousand years. The 2011 magnitude 9.0 Tōhoku-Oki earthquake off Japan was caused by a fault rupture in the Japan Trench. The event and subsequent tsunami left about 20,000 dead or missing and affected more than 35 coastal cities. The quake was followed by 666 aftershocks that exceeded magnitude 5.0. The energy involved in high-magnitude earthquakes originating in trenches is immense. The 2004 Sumatra-Andaman earthquake in the Java Trench caused a sufficiently massive release of energy to alter the Earth’s rotation, shortening the day by 2.68 microseconds. Similarly, the Tōhoku-Oki earthquake shifted the Earth’s axis by between 10cm and 25cm, shortening the day by another 1.8 microseconds. One of the most common analogies used in trench science is “Mount Everest would fit into the Mariana Trench with a mile or so to spare”. This is true, and from an evolution and physiology perspective it is immense. Likewise, exploring these extreme depths is highly problematic. But how far is 11km really? The Mississippi River is 11km at its widest point, Manhattan Island is twice as long as the Mariana Trench is deep, and assuming the average running speed of Mo Farah at the 2012 Olympics, he could run 11km in 30 minutes. Given how easily we can affect our planet over far larger distances, our effective proximity to these “extreme” locations means even the deepest places on Earth are no longer pristine – and remain hugely vulnerable."
"Most Europeans take pride in recycling. A good citizen separates glass from plastics, biowaste from metal cans and brags about it to their friends. Recycling helps soothe some of the anxiety driven by endless consumption.  However in Russia, recycling comes with a sense of shame. This is reflected by the fact that more than 80% of Russian domestic waste ends up in landfill, and most of the rest is incinerated. For comparison, Europe’s best recyclers – Austria and Germany – reuse well over 60% of their municipal waste while the UK manages 39%. A 2012 report by the International Financial Corporation, part of the World Bank Group, found that Russia’s waste recovery rate was “nearly zero”. I first became aware of negative social attitudes to recycling in Russia during research in Samara (formerly Kuybyshev), the country’s sixth largest city and which lies in a twist of the river Volga 1,000km from Moscow. Until the collapse of the Soviet Union it was a closed city hosting aviation and automobile industries. Along with a team of Russian and Finnish researchers, we wanted to immerse ourselves in the local culture and learn about the potential for developing eco-innovations in an economy undergoing rapid transition. The results of which were published late last year.  We focused on how people dealt with their waste. At first the task didn’t seem too gratifying as the people whose lives we followed told us they threw all their waste in the bin and that there was neither waste separation nor recycling.  But as we observed their daily lives, we noticed some people leaving beer bottles under the staircases of their apartment building. We also saw bottle collection points outdoors under trees or in shabby basement premises. The outdoor collection points were tended by women who told us their salary was some 200-300 roubles (about £2) a day, but they refused to tell who collected the bottles and paid their salary. We were usually thrown out of the basement recycling places as soon as it turned out we wanted information. When we asked people whether they ever took bottles to these recycling points, most regarded the question as ridiculous. The question made a lot of sense to us as the families we asked were from the low-income tiers of society and could certainly have used the extra money. Probing the issue further we were told that “only alcoholics, drug addicts or poor babushkas [elderly women] who clean corridors” take bottles to recycling points. In addition to the bottles, we also saw used cardboard neatly packed as if it was going somewhere. But nobody seemed to know who it belonged to and where it was heading for. Once, when taking a photo of one such cardboard pile, a bulky man came shouting loudly and chased us away. It’s not easy to get access to companies in Russia, but we were lucky to find one waste management firm willing to talk to us. One morning we met the CEO in his office. After some champanskoye (sparkling wine) and chocolate he took us to visit his company’s landfill site. The company focused primarily on landfill, he told us, because to get involved in recycling or reused items was too risky a business; and waste fragments of any value, such as bottles and metals, were already in the hands of the mafia. Integrating this informal, underground recycling with official efforts to deal with waste is tough.  To give one example, we recently worked with Baltika brewery in St Petersburg, which wanted to start bottle collections because of the environmental policy of its parent company, Carlsberg Group. As part of an intensive course on corporate sustainability, an enthusiastic group of international and Russian students were asked to design bottle collection and recycling methods that would encourage Russians to recycle. Baltika wanted to set up an independent, stand-alone system.  Knowing about the informal bottled recycling, which seemed to be as well-organised in St Petersburg as it was in Samara, I suggested a collaboration with independent recyclers, given there was a system already up and running. The question was met with a cold response: such informal bottle collectors were regarded as criminals. In Russia, informal recycling identifies you as some kind of undesirable. It is a heavily stigmatised activity and ordinary Russians make an effort not to be seen doing it. People also view many recycling companies as either having links to organised crime, or risking conflict with such groups. So at both an individual level and more organised corporate level there are major barriers to setting up the types of systems taken for granted in other parts of Europe. And despite the best efforts of citizens and companies, don’t expect to hear about major advances in systematic large-scale recycling in Russia any time soon."
"We live in a world where large numbers of people are connected by just a few degrees of separation. But while having friends of friends all over the globe can be great for holidays, trade and networking, travel also allows viruses to move like never before. Zika is the latest “explosive pandemic” to be declared a global emergency by the World Health Organisation. But viruses don’t just target humans – they can infect all forms of life from bacteria to bananas, horses to honeybees.  A lethal combination of the Varroa mite and the deformed wing virus has resulted in the death of billions of bees over the past half century. In a study published in the journal Science, colleagues from the Universities of Exeter, Sheffield and I report how the virus has spread across the globe.  Honeybees are geographically separated into two distinct groups, a single species from Africa, confusingly known as the European honeybee, and six other species, all from Asia. The European honeybee is the main species managed by humans, purely because of its ability to make the most honey per colony. In the 1950s these European bees were taken to Asia to improve honey production, and at some point the Varroa mite jumped the species barrier from its native Asian honeybee across to the Western one. Over the next 50 years, the mites spread around the world with the global trade in European honeybees.  Within three to five years of the mites’ arrival, bee colonies started to collapse on a massive scale. Natural wild populations were soon wiped out, as were millions of managed colonies. For decades it was thought that bees were being sucked to death by the mites, as the mites feed exclusively on the bees’ blood. This idea was supported by the appearance of bees in heavily-infested colonies with dry, crippled wings. But more recent research showed that the Varroa mite was, in fact, a carrier rather than a killer, transmitting deformed wing virus directly into the bloodstream. Though bees suffer from various viruses, these are usually found at very low levels and move between bees via food or during mating. The Varroa mite’s totally new transmission route changed the game. Some infected honeybees had crippled wings so could not fly and died quickly, but although most infected bees had normal wings their lifespan was shortened by up to 50% by the virus – causing inevitable colony collapse.    Over time, the virus evolved into a single killer form, now known as the A-type, and it is this which has since spread to bee colonies globally. By analysing data from bees and mites collected around the world, the evolutionary history of this pathogen was reconstructed to reflect how it was spreading. We learned that the deformed wing virus originated within European honeybees themselves, and not their Asian relatives or the mites. The Varroa mite just happened to be particularly effective at spreading the virus. The current pandemic started in the mid-20th century and its spread mirrors that of the Varroa mite. European and North American honeybee colonies were found to be the main transmission hubs, which is to be expected since they are key areas in the global bee trade.  Honeybees and other pollinators are all interconnected via trade, which creates an ideal situation for the rapid spread of pathogens and parasites worldwide and between species – including bumblebees. There are many parallels between the global spread of deformed wing virus and other insect-borne human pathogens such as the Zika virus. And as international trade and travel continues to increase we can expect to see many more emerging viruses impacting both human and animal health. But our genetic history indicates we are well adapted to survive these emerging pathogens, and there are a number of Varroa infested honeybee populations around the world that can now survive without any form of mite control. Natural selection wins again it would seem."
"
Share this...FacebookTwitterTornadoes are normally associated with the famous Tornado Alley of the US Midwest. But they also occur from time to time in Germany.
Nowadays the drama-seeking media are quick to report on any tornado event that gets recorded, and so often there’s the mistaken perception that their frequency is rising (of course due to man-made weather brewing). Moreover the media have no qualms about their readers and viewers making that erroneous leap in thought.
Earlier this month Germany was hit by some relatively severe tornado activity. In Augsburg earlier this week 150 homes were damaged by a twister. The media naturally put the topic on center-media stage.
Flagship daily Süddeutsche Zeitung [South German News], SZ, even conducted an interview with the DWD German National Weather Service on the subject of tornadoes and what might be their cause. Over the recent years the DWD has become a rather avid activist and promoter of the man-made global warming theory. But in the SZ interview, the DWD was refreshingly fully honest, and resisted blaming German tornado activity on climate change.
First the SZ asked DWD meteorologist Lars Kirchhübel about how tornadoes are formed and why they are so dangerous. Then about halfway through the interview the topic switches to the impacts of climate change on tornadoes: The SZ asks, “Are they becoming more frequent in Germany – and are they a consequence of climate change?”
The SZ gives us the DWD’s reply:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Tornadoes are not forming more frequently than earlier, we are simply made more aware of them says DWD expert Kirchhübel. Between 20 and 60 tornadoes are know each year in Germany. It has been only over the last few years that those involved have recorded them with their mobile devices, and so thus enhance the people’s perception.”
And on whether there is a discernible trend linkíng tornado activity to global warming, Kirchhübel tells the SZ that the dataset is too short and that there has been no discernible trend so far. He adds:
Also a clear relationship with climate change is not verifiable.”
About a week ago NoTricksZone posted another report on German tornado activity here, and it found that the trend is actually downward for the past 15 years, and not “no trend”:

Number of confirmed tornadoes in Germany since 2000. Trend has been significantly downward over the past 10 years. Source: DWD.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman skeptic site Die kalte Sonne here directs our attention to an article on Germany’s record warm 2014 year in German national daily, Die Welt.
The Die Welt article quotes German commercial meteorologist Dominik Jung of wetter.net, who is often quoted in the German print media. Here’s the Die kalte Sonne post in English!
=============================
Dominik Jung warns of uncertain climate forecasts: “Us meteorologists know just how difficult forecasts for the next 5 to 10 days are. So how certain can 50-year trends be?”
By Sebastian Lüning and Fritz Vahrenholt
(Translated/edited by P Gosselin)
Exemplary reporting on the 2014 German temperature record appeared on December 30, 2014 in Die Welt. The daily allowed meteorologist Dominik Jung to get a word in. Jung puts the temperature trend in important context: 1000 years ago during the Medieval Warm Period it was at least just as warm in Germany as it is today. One needs to be careful when using the word “record”. What follows is an excerpt from the Die Welt article:
For the first time we have the number ten before the decimal point for Germany’s annual mean temperature. The mean temperature was around 10.2°C. ‘That’s a one hundred year record. Never has it been so warm in Germany,’ says meteorologist Dominik Jung at the weather site wetter.net. […]
‘One must clearly state: The temperature trend for Germany is clearly upwards over the last 130 years. And naturally this is climate change,’ said Jung. He then adds: ‘But: Climate is always changing. The earth’s climate has been subject in part to large fluctuations. During the Medieval Period there were both warm and icy times. So this pattern isn’t really anything new. However, there’s a lot of controversy in the ongoing discussion concerning what impact man has on the on the current increase in the mean temperature. Today that still has not yet been adequately determined.’ […]
‘We are a long way away from the severe drought summers, or winters without ice and snow – just a look out the window is already enough. These extreme scenarios help very little. They only serve to spread uncertainty. We do not know what will be 30, 40, or 50 years into the future. Chill out: Us meteorologists know just how difficult forecasts for the next 5 to 10 days can be.’ Jung has doubts on ‘How accurate the 50-year trend will be.'”
You can read the entire German article at Die Welt.
=======================
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman climate science critical group Klimakontroverse.de is holding its next meeting at the Freizeitheim Linden in Hannover, Germany, 19 February, at 7:30 pm.
The group regularly has meetings on climate and is known for taking the discussions directly to the public, but doing so with respect, courtesy and politeness. It writes:
The main topic of the next meeting is the reliability of the temperature measurements. There’s the frightening suspicion that NASA (GISS) has manipulated the temperatures upwards. How much of this is true?
At the last meeting we discussed the topic of 2014 being the warmest year in Germany and worldwide since records began.
Short summary:
Germany: Despite the warmest year since records began, the overall trend shows no increasing temperature, (see 1 and 2), over which the German DWD Weather Service has yet to inform the public.
Globe: 2014 was a warm year, like 2010, but it was the warmest with only 38% certainty. The Met Office in Great Britain has even distanced itself from the claim that it has been the warmest ever because the temperature was only 0.02°C above the old record, which is well within the range of uncertainty (Met Office).
Satellite measurements show no evidence of an especially warm 2014 (UAH).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The warm temperatures of 2014 were weather and therefore do not symbolize any temperature trend. The stagnation in global temperature persists.
Satellite measurements by RSS: No temperature increase in 18 years:

Source: The huge stop extends once again.
If you have questions about climate or energy, we’ll gladly answer them.
The discussion is easy to follow and an open discussion that includes varying points of views are at the forefront, and will remain the most important characteristic of this initiative.
Those interested in joining the Hannover discussion are welcome to contact (in English if you prefer): Achim Fahnenschild: info@KlimaKontroverse.de. 
 
Share this...FacebookTwitter "
"Dog owners might disagree, but as far as evolutionary biologists are concerned, all dogs are just dogs. It may seem odd that Canis (lupus) familiaris extends from rabbit-sized Chihuahuas to Great Danes which can be almost the size of a small pony, whereas seemingly much smaller differences place many animals into separate species or sub-species. One has to dig a bit into evolutionary theory for this to make sense. The dog is a direct descendant of the grey wolf (Canis lupus), with evidence that lots of different wolves fed into the dog gene pool over the years. In the course of dog domestication, their behaviour, morphology and physique has changed, and differences among dog breeds are indeed astonishing. Imagine if future palaeontologists were to find Chihuahua remains in the fossil record: this animal would appear to have little in common with wolves.  But these differences among dog breeds – and between dogs and wolves – aren’t enough to warrant recognition as distinct species. Dogs are simply too young, from an evolutionary perspective. It usually takes hundreds of thousands of years or more for mammals to evolve into distinct new species, requiring the slow accumulation of mutations that cause inheritable changes to its physical characteristics – or “phenotype”. Archaeological data and analysis of DNA from today’s dogs and wolves, as well as ancient remains, suggest that domestication started about 16,000-40,000 years ago, with most current dog breeds originating in the past 200 years. Charles Darwin pointed out that humans have accelerated the process of selection by choosing particular individuals for breeding, based on certain desired characteristics – what we call artificial selection. Natural selection generally requires much more time, because it acts on novel variants introduced into the gene pool through the slow process of chance DNA mutation. Nevertheless, the power of artificial selection in generating extreme phenotypes does not change the fundamental fact that dog breeds have been separated for only a short evolutionary time. This means that dog breeds differ drastically in their appearance and other characteristics, while most of their genomes are still very much alike. Comparing different breeds, most of their genomes indeed show only little differentiation. In other words, Chihuahuas and Great Danes are overall very similar to one another. The vast physical differences are largely driven by relatively few loci (regions) in the genome. These loci have a large phenotypic effect, leading to strong differentiation among breeds.  This is particularly interesting for evolutionary biologists, and pinpointing such regions in the genome has for example recovered the genetic basis of size variation among dog breeds. We now also have an understanding of the mutations that control traits such as coat characteristics and ear floppiness. So if breeds are that similar to one another in their genomes, how are the vast differences maintained? The obvious answer is the mating pattern we impose on our dogs – we keep breeds separate by preventing interbreeding between them.  The fact humans keep them apart is crucial here. Species are commonly defined as “groups of interbreeding natural populations that are reproductively isolated from other such groups”. This requires hybrids between distinct species to either be non-viable (such as the proposed “humanzee”), or for their offspring to be infertile like most mules, or the more exotic “ligers”. In both these cases there would be complete reproductive isolation between the two groups, whether they be humans and chimps, lions and tigers, or Labradors and poodles. Yet two entirely different dogs will produce perfectly fertile offspring, and many modern breeds in fact originated in this way. Of course in some cases other factors might make mating very tricky. A female Chihuahua would have trouble naturally delivering a male Great Dane’s offspring, for instance. But though some breeds would never mate with each other without human intervention, middle-sized breeds could provide the link between extremely large and small dogs.  Street dogs are a vivid illustration of this point – they show how the distinct gene pools of dog breeds can rapidly mix once the restrictions of artificial breeding are removed. Moscow’s famous feral dogs have existed separate from purebred pets for at least 150 years now. In this time they have largely lost features like the spotty colouration that distinguish one breed from another, or the wagging tails and friendly behaviour towards humans that distinguish dogs from wolves. So genetic exchange would still be common among dog breeds, were they allowed to reproduce freely. In that sense, dog breeds would not be classified as separate species under most definitions. If those Chihuahuas and Great Danes don’t look like the same species right now, it’s only because humans are constantly maintaining a barrier between them."
"
Share this...FacebookTwitterFred F. Mueller at the European Institute for Climate and Energy (EIKE) here writes about how the storm that swept across Europe in late March exposed the lies of the German Energiewende (transition to renewable energies).
With the current rate of growth in renewable energy installations, Mueller writes that it’s just a question of time before the grid gets overloaded just by the renewable energies under certain weather conditions and that it will no longer be possible to dump the surplus  uncontrollably fed in power into neighboring power markets.
Mueller writes how at the end of March Germany saw a combination of high winds and lots of sunshine. During the recent storm there was lots of wind energy production accompanied by lots of solar power production due to large gaps in cloud cover.
According to German flagship national daily Frankfurter Allgemeine Zeitung (FAZ) the surplus energy led to massive costs to power consumers and double digit million costs for the power grid operators, who naturally will simply pass these costs along to the consumers. The situation in late March was so precarious that hundreds of wind turbines were ordered switched off.
The FAZ reports that a record amount of power was fed into the grid due to the strong winds and abundant sunshine: At 2:15 pm a total of 44 gigawatts of sun and wind energy were fed in, which equals the power output of 31 nuclear power plants.
EIKE author Rolf Schuster has compiled the data on installed solar/wind capacity in Germany as of the end of February 2015: a total of 78 gigawatts of capacity that comprises 40 gigawatts of wind and 38 gigwatts of solar. Had the storm hit later in the spring, the situation would have been even worse because more solar power would have been produced, probably another 10 gigawatts.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Rolf Schuster compiled the results of the storm in Table 1: Datum = date; Stunde = hour; Preis = exchange price; Menge = amount; Summe1 = sum 1; Summe2 = sum 2.

Table 1: The nominal exchange losses stemming from the negative prices on 29 – 30 March. Note: Every figure under 50 €/ MWh in reality means that most conventional power plants had to incur losses (Figures from EEX: Table Rolf Schuster)
According to the data in the hours leading up to the storm, power with a market value of almost 3 million euros had to be “given away for free” to foreign markets at negative prices. However, Mueller writes, that was only a small part of the costs. Grid operators wound up losing anywhere from 10 million to 60 million euros during a three day period. According to the FAZ, a total of 20.3 gigawatts of reserve capacity had to be used in order to stabilize the power supply in south Germany. Moreover hundreds of wind turbines had to be taken offline. Yet the affected windpark operators still got paid for the power they did not produce – as is required by Germany’s renewable energy feed-in act. These costs eventually get paid by the consumer.
This time the power grid withstood the overloading from the storm. But Mueller writes that whoever believes the worse is now behind and we all can sit back and relax with the knowledge the power grid can withstand anything, they are being terribly naïve. In Germany within the scope of the Energiewende, it is planned to install approximately 330 gigawatts of wind capacity and possibly 100 gigawatts of solar capacity by 2050.
The result, Mueller writes, is that already on moderately windy and sunny days the grids will become overloaded with “green power” because there is still no storage technology available. The physics is clear: this will inevitably lead to a “collapse in the power supply”. Here so-called “power autobahns” (major cross-country transmission lines), which certain profiteers of the Energiewende are trying to sell us as the wonder cure against the consequences of their own politics, aren’t going to help.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s DWD National Weather Service has developed a nasty habit of putting out warmed up press releases for announcing monthly mean data, and then later very quietly revising the data downwards.
Result: the public believes that warming is happening when in fact there really isn’t any.
German skeptic site wobleibtdieglobaleerwaermung (whereistheglobalwarming) writes a post titled: “What’s wrong with the DWD? Once again a downward correction. June 2015 was 0.2° Celsius colder than reported in the press releases“.
It describes how the June 2015 mean temperature for Germany was overstated by 0.2°C in its press release. It adds:
Also in the two earlier months of May and April, and the entire spring of 2015, the press releases reported a mean temperature that was elevated 0.2°C. DWD correction: May and spring 2015 were 0.2°C less ‘warm’ than announced in the press releases – spring 2015 now 1.4°C colder than a year earlier.
The overly hasty DWD press release announcing the June 2015 data states:
” …The first month of the summer with a nationwide mean temperature of 16.0 °C was 0.6°C above the international valid reference period of 1961 to 1990. Using the 1981 to 2010 reference period the deviation was still 0.3°C…”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Here the wobleibtdieerderwaermung site also points out yet another sloppy error made by the DWD: the difference between the two reference periods for June is in fact 0.4°C, and not 0.3°C, citing a 2014 DWD press release here.
So, did the DWD issue a correction to inform the public of the true June 2015 result, that it was in fact cooler then they had claimed earlier? The wobleibtdieerderwaermung writes:
At the DWD homepage http://www.dwd.de/ one finds at a well hidden location, after a total of seven (7) clicks, the value of 15.8 °C for June in Germany – all the way down, to the right.”
In other words, the DWD made sure to bury the real results, to keep them as much out of sight from the public as they could.
wobleibtdieerderwaermung suggests that the DWD ought to issue a new press release with the following content so that the public can be properly informed:
…The first month of the summer with a nationwide mean temperature of 15.8 °C was 0.4°C above the international vaild reference period of 1961 to 1990. Using the 1981 to 2010 reference period the deviation was only 0.0°C, and thus was exactly the mean for the WMO reference period…a climate warming in Germany’s June 2015 is thus not detectable over the last 35 years.”

So what’s compelling the DWD to engage in the habitual deceptive behavior? wobleibtdieerderwaermung speculates that all this probably has nothing to do with error and has more to do with “political intentions”.
Yet another government institution that we can no longer believe. Little wonder trust in government is near an all-time low.
Share this...FacebookTwitter "
"After the flood, the terrible reckoning: this week it emerged that one of the most ancient churches of Venice, containing the city’s earliest remaining mosaics, had been hit by the tides that overwhelmed the city during the past week. The Byzantine Santa Maria Assunta Basilica, dating to 639, was inundated three times. Half of Venice’s 120 or so churches are thought to have suffered damage. The flood waters affected 85% of the city, causing devastation to the shops, businesses and homes of Venetians who struggle to preserve one of humanity’s most beautiful achievements as a living city. Those residents have been grievously let down. Some disasters are unforseeable. This one was all too predictable. Tides high enough to flood Venice were once exceptional events, but, of the 10 highest tides in its history, half have occurred during the course of the last 20 years. The world’s seas are rising, due to the climate crisis, and Venice has anyway been sinking, by around 1mm a year, into the soft terrain on which its foundations were built. Given this ominous context, the failure to complete a flood barrier project launched in 2003, which is now running 10 years behind schedule, shames the successive Italian governments that have overseen the plan. A corruption scandal, cost overruns and muddled management mean it will not be in place until 2022 at the earliest. The inadequacy of the regional Veneto council, controlled by Matteo Salvini’s League, was vividly captured by its rejection of measures to tackle the climate crisis last week – a decision taken minutes before its chambers on Venice’s Grand Canal were filled with saltwater. But the inquest into this disaster should have a remit that goes beyond flood prevention. The world has loved Venice without caring for it. The Piazza San Marco Association has observed that the city had become so depopulated that it would be difficult to find the electricians, plumbers and carpenters needed to repair the damage. Venice, it said in a statement, “was moving ever closer to a real and irrevocable end”. The local population now stands at around 55,000, down from 175,000 in the postwar period and around half of those residents are 65 or older. More than 1,000 Venetians leave for good each year. The intrusive nature of mass tourism, fuelled by the constant flow of cruise ships which damage and pollute the environment, has led to protests that the city is becoming a theme park. Numerous properties are rented out to visitors through Airbnb, further hollowing out the centre and rendering its labyrinthine streets all but impassable for much of the year. There has been much talk about solutions, but little meaningful action. On 1 December a consultative referendum will be held on whether to separate the administration of Venice from the mainland town of Mestre. The desirability of such a separation is moot, given the level of economic interdependency; that it is being contemplated at all indicates the current level of despair. A mission from the Unesco World Heritage Centre is due to make an advisory visit to Venice early next year. In the wake of last week’s events, that trip should now become a catalyst for action, with international assistance, to save the city for generations to come. This is a debt owed by the present to the past as well as the future. • This article was amended on 26 November 2019 because an earlier version said that the 10 highest tides in the history of Venice occurred during the course of the last 20 years. In fact, of the 10 highest tides in its history, half have occurred in the past two decades."
"
Share this...FacebookTwitterWhat else can be said about all the doom and gloom nonsense from UN scientists surrounding the atolls and sea level? A new paper that is just out should make them red with embarrassment.
This new paper tells us that the atolls are doing just fine and are gaining in area! Read the paper’s abstract that now follows.

Coral islands defy sea-level rise over the past century: Records from a central Pacific atoll

Abstract
The geological stability and existence of low-lying atoll nations is threatened by sea-level rise and climate change. Funafuti Atoll, in the tropical Pacific Ocean, has experienced some of the highest rates of sea-level rise (∼5.1 ± 0.7 mm/yr), totaling ∼0.30 ± 0.04 m over the past 60 yr. We analyzed six time slices of shoreline position over the past 118 yr at 29 islands of Funafuti Atoll to determine their physical response to recent sea-level rise. Despite the magnitude of this rise, no islands have been lost, the majority have enlarged, and there has been a 7.3% increase in net island area over the past century (A.D. 1897–2013). There is no evidence of heightened erosion over the past half-century as sea-level rise accelerated. Reef islands in Funafuti continually adjust their size, shape, and position in response to variations in boundary conditions, including storms, sediment supply, as well as sea level. Results suggest a more optimistic prognosis for the habitability of atoll nations and demonstrate the importance of resolving recent rates and styles of island change to inform adaptation strategies.”


Don’t you just love it when observational data clash with hysterical crystal ball model projections?
Share this...FacebookTwitter "
"Tonight, Channel 4 will host the first ever election debate on the climate crisis. All of the major party leaders have confirmed their attendance, save for Boris Johnson and Nigel Farage. The Brexit party doesn’t have a climate platform, so that squares, but Johnson would be a curious absence. The Conservative government recently passed a commitment to reach net-zero emissions by 2050; the party’s manifesto repeats that pledge, and includes new spending for environment and climate policies. Until now, the Tories haven’t seemed afraid to talk climate. This distinguishes them from other rightwing parties in the English-speaking world. The US and Australia especially seem doomed to forever re-fight the climate denial battles of the mid-00s – witness Donald Trump’s tweets about cold weather contradicting “global warming”, or the now Australian prime minister, Scott Morrison, triumphantly brandishing a chunk of coal in parliament.  But in the UK, since they overwhelmingly supported the 2008 Climate Change Act, the Tories seem to have come around and fully accepted the science. No one in the party openly questions the link between carbon emissions and warming, or the need for action. Its once-vocal science denier fringe has been almost entirely silenced, or, like former minister Ann Widdecombe, decamped to the Brexit party. But it should be clear to us now that it is possible for leaders to accept the scientific consensus, attend the meetings, meet the activists, nod gravely, sign the pledges and then effectively do nothing. It’s time to ask whether this approach is really a marked improvement on denying the climate crisis altogether. There is a term currently floating around activist circles, “new denialism”. This is attached to ways of thinking that acknowledge the reality of climate change, but don’t lead to what the Intergovernmental Panel on Climate Change calls the “rapid, far-reaching and unprecedented changes in all aspects of society” needed to avoid 1.5C warming. New denialism accepts the basic atmospheric science, but rejects the immense volume of further scientific work suggesting that we can change things – either because it would be too disruptive to our current way of life, or to the way we’ve organised our economy. It can seem like a vague category: it encompasses over-cautious incremental policies and tepid market-based solutions; insistence that some not-yet-existing technology will emerge to wipe out our carbon debts; and even arguments that we’re too far gone, and should focus our efforts on adaptation. These all acknowledge the problem, but reject the solutions that scientists insist on: immediate, radical reductions in carbon emissions. This seems markedly less evil than the cartoon-villain propaganda of climate science deniers. And at close range it is. But any future moral accounting of the climate crisis is unlikely to distinguish bad faith from good intentions; rather it will be weighed in megatonnes of carbon, which hit another all-time high this year. As the academics Philip Mirowski, Jeremy Walker and Antoinette Abboud noted in 2013, the thinktanks behind climate denial never thought they would win the war of ideas with academic science – they simply wanted to stall for as long as they could anything that would threaten the interests of the fossil fuel industry. Seen this way, new denialism isn’t anti-science specifically – it’s a reactionary project, which seeks to uphold or reassert the status quo. And if denialism is about stopping action, then anything that needlessly obstructs action is denial. Ultimately, then, there’s no fundamental difference between outright denialism and new denialism. New denialism is visible in the gaps between words and actions: oil companies claiming to decarbonise while approving enough fossil fuel production to shoot us well past 2C; governments promising emission reductions with no credible plan to do so. Two weeks ago the UN called the majority of existing climate policies “totally inadequate”. The truth is, the Tories are fine with that. Johnson won’t talk climate today because Labour and the Liberal Democrats have unveiled transformative multi-billion pound infrastructure programs and regulatory measures that would actually address the climate crisis, while the Conservative manifesto commits more spending to potholes than to electric vehicles. It’s the same bait and switch that has kept climate action stalled for decades: promise, then don’t deliver. Johnson’s purported commitment to a 2050 target won’t stand up to scrutiny from the public, or from the other parties – but it’s still there in the manifesto, a grand signpost pointing absolutely nowhere. The Tories have got credit over the years for their rhetoric on climate – from supporting the Climate Change Act to David Cameron’s “greenest government ever”. The reality has been less impressive: they have failed to enact any major policy and outright killed promising programmes such as zero carbon homes. And yet, they’ve avoided major condemnation as long as discussions inched along, committing to new targets without plans to achieve them, the rhetorical consensus intact. The other parties have broken that, thankfully, by promising bold action that acknowledge the true demands of the crisis. We say a person who won’t accept tough realities is in denial. We shouldn’t be scared to extend that label to Johnson and his party. • Stephen Buranyi is a writer in London"
"Last year, 6m tonnes of “wood pellets” harvested from forests in Louisiana, Georgia, Florida, Alabama and Virginia were shipped across the Atlantic, to be burnt in renewable “biomass” power plants. This was almost double the 2013 figure – the US “wood pellet” industry is booming.  Demand is largely driven by European countries wanting to meet targets set out in the EU’s Renewable Energy Directive. Half of the pellets exported from the US were used to generate electricity in Britain’s massive Drax power station, which is slowly converting from coal to biomass in order to reduce carbon emissions and claim valuable “Renewable Obligation certificates” for green electricity. So can it really be sustainable to transport wood halfway round the world to burn in a power station? Many environmentalists don’t think so. A consortium of NGOs recently argued that the EU should exclude wood from its renewable energy targets. They claim the industry is felling large areas of hardwood wetland forests across the south-eastern US, causing a loss of biodiversity and a net increase in carbon emissions. Even when the forest regrows it does not store as much carbon in biomass and soils as the original – and it’s certainly not as good for wildlife. A UK government study found that electricity generated from regenerated forests could have a carbon intensity five times higher than coal. Burning wood also releases nitrogen oxides and carcinogenic compounds. So why burn wood to meet renewable electricity targets when cleaner options such as wind, solar, hydro or tidal power have a much lower environmental impact? Wind and solar power are already expanding rapidly and will be key in future, especially as we get better at storing energy. But in the meantime, these clean but intermittent power sources can’t yet replace coal.  Coal produces 39% the world’s electricity, alongside a third of all carbon dioxide emissions and a wide range of other toxic emissions. Yet for all its faults coal has two big advantages: it’s cheap, and it can operate continuously to provide a minimum “baseload” level of electricity.  It’s relatively easy to modify a coal plant to burn wood instead – fuel handling and injection systems need to be adapted to handle the wood pellets instead of pulverised coal, but the combustion process is otherwise similar. It’s a quick and comparatively cheap way to shift towards renewables. For this to be worthwhile however, the amount of carbon emitted by extracting, processing, transporting and burning wood pellets must be significantly less per unit of power (MWh) generated than the equivalent for coal. This can be ascertained through carbon accounting, or “life cycle assessment”. Perhaps surprisingly, trucking wood pellets 200km to a port and transporting them 7200km by ship isn’t a deal-breaker in terms of carbon emissions. Since large ships carry massive cargoes efficiently at low speed, transport contributes around 40kg CO2 per MWh electricity generated. Significantly more carbon (more than 100kg per MWh) is emitted by the drying, grinding down and shaping required to transform harvested wood into small, easy-to-handle pellets.  Even this still has a far lower carbon intensity than UK coal though, so transport and processing clearly doesn’t stop wood power being a sustainable option. But here’s where it gets complicated. Whereas burning coal releases carbon that had been stored in the ground for millions of years, CO2 emissions from burning wood are part of a continuous biological cycle. Carbon in wood was only recently taken out of the atmosphere through photosynthesis, and replacement tree growth will suck it back out again.  However the time taken to replace that carbon varies hugely depending on whether you’re harvesting large trees from ancient forests, or small branches from new plantations. We also have to consider how these American forests would have been managed without any wood pellet demand. The government study notes that wood from intensively-managed plantations could mean more carbon taken up by growing trees than emitted by the transport and processing of the pellets, leading to a net reduction in emissions even before avoided coal emissions are accounted for. Conversely, as referred to earlier, the study found that if wood pellets are sourced from regenerated natural forests, carbon emissions could be five times higher than from burning coal. So the type of wood that is burned is crucial. What’s the most likely effect?  Fortunately America has lots of spare wood lying around that would otherwise be burned or wasted. Drax and other big players claim their pellets are sourced from such “forest residue” – saw-mill scraps, trees that died naturally, or were too misshapen to be used as lumber, small twigs, and so on – though environmental groups dispute this.  Whatever the truth right now, there’s certainly lots of potential in wasted wood. Between 14% and 63% of the currently spare forest residue in the US would be sufficient to meet the UK’s entire biomass demand in 2020. A recent academic paper suggested that even after accounting for possible forest carbon loss, electricity generated from US wood pellets is still far cleaner than coal.  There are some regulatory safeguards in place too. Power station operators need to prove that electricity generated from wood is clean enough to count as “renewable” in terms of UK and EU policy. The worry here is that increasing demand from the well-regulated European energy sector could displace existing wood demand from unregulated sectors towards unsustainable sources such as pristine forests. Ultimately, the environment would benefit more if American wood was used at home to reduce the huge quantities of coal burned there, and European rural economies would benefit more if renewable energy targets were met using local wood. But in the meantime, US forests provide a cheap source of wood pellets for European power generators to meet renewable energy and carbon reduction targets.  It’s not the long-term goal of 100% clean, renewable energy that humankind is capable of achieving but, from where we are right now, it’s a step in the right direction."
nan
"
Share this...FacebookTwitterGerman online finanztreff.de here reports on the opinion recently expressed by Prof. Hans-Werner Sinn, Director of the renowned Munich-based ifo-Institute for Economic Research, regarding Germany’s attempted move into renewable energies, primarily solar and wind power.
Currently about 25% of Germany’s energy supply is “green”.
At a conference of experts in Berlin Sinn is quoted by Dow Jones as saying that the installation of “renewable energies in Germany has already reached its limits” because there is just nowhere near enough storage capacity available to balance out the sharp and volatile supply spikes of wind and solar power.
Sinn also ridiculed the idea of using electric cars as a means to store the green energy, calling the notion a “PR gag”. He added that 159 million BMW i3 vehicle would have to be put on the streets, i.e. thus nearly tripling the number of cars currently on the streets. A preposterous solution.
On using green energy to produce gas, Sinn calls it a horribly expensive alternative that would cost about 24 cents per kilowatt-hour; Russian natural gas by comparison is only 3 cents per kilowatt-hour, he says.
“It would get expensive very rapidly,” Sinn warned.
Currently Germany’s Ministry of Environment is proposing the investment of 1 trillion euros for a new energy supply system. Sinn calls that idea “a monstrous gamble with an uncertain outcome“, and one that harbors “a real risk” of Germany “gambling away its prosperity“.
So how will German policymakers react to Professor Sinn’s assessment? Well, if they don’t heed his warnings, then there’s really no one left out there who may still be able to talk sense and reason back into the policymakers’ heads.
Should the policymakers ignore the warnings of the renowned Ifo Institute, then the only thing left is to learn it the hard, painful way. Knowing today’s German intellectual obstinacy of the elite class, the odds of that are better than even.
Share this...FacebookTwitter "
"The largest wildfire ever recorded in Greenland was recently spotted close to the west coast town of Sisimiut, not far from Disko Island where I research retreating glaciers. The fire has captured public and scientific interest not just because its size and location came as a surprise, but also because it is yet another signpost of deep environmental change in the Arctic.  Greenland is an important cog in the global climate system. The ice sheet which covers 80% of the island reflects so much of the sun’s energy back into space that it moderates temperatures through what is known as the “albedo effect”. And since it occupies a strategic position in the North Atlantic, its meltwater tempers ocean circulation patterns.  But Greenland is especially vulnerable to climate change, as Arctic air temperatures are currently rising at twice the global average rate. Environmental conditions are frequently setting new records: “the warmest”, “the wettest”, “the driest”. Despite its size, the fire itself represents only a snapshot of Greenland’s fire history. It alone cannot tell us about wider Arctic climate change.  But when we superimpose these extraordinary events onto longer-term environmental records, we can see important trends emerging.  Between 2002 and 2016 the ice sheet lost mass at a rate of around 269 gigatonnes per year. One gigatonne is one billion tonnes. One tonne is about the weight of a walrus.  During the same period, the ice sheet also showed some unusual short-term behaviour. The 2012 melt season was especially intense – 97% of the ice sheet experienced surface melt at some point during the year. Snow even melted at its summit, the highest point in the centre of the island where the ice is piled up more than 3km above sea level.  In April 2016 Greenland saw abnormally high temperatures and its earliest ever “melt event” (a day in which more than 10% of the ice sheet has at least 1mm of surface melt). Early melting doesn’t usher in a period of complete and catastrophic change – the ice won’t vanish overnight. But it does illustrate how profoundly and rapidly the ice sheet can respond to rising temperatures.  Despite its icy image, the margins of Greenland are actually quite boggy, complete with swarms of mosquitoes. This is the “active layer”, made up of peaty soil and sediment up to two metres thick, which temporarily thaws during the summer. The underlying permafrost, which can reach depths of 100m, remains permanently frozen.  In Greenland, like much of the Arctic, rising temperatures are thawing the permafrost. This means the active layer is growing by up to 1.5cm per year. This trend is expected to continue, seeing as under current IPCC predictions, Arctic air temperatures will rise by between 2.0°C and 7.5°C this century.  Arctic permafrost contains more than 1,500 billion tonnes of dead plants and animals (around 1,500 billion walrus equivalent) which we call “organic matter”. Right now, this stuff has been frozen for thousands of years. But when the permafrost thaws this organic matter will decay, releasing carbon and methane (another greenhouse gas) into the atmosphere. If thawing continues, it’s estimated that by 2100 permafrost will emit 850-1,400 billion tonnes of CO₂ equivalent (for comparison: total global emissions in 2012 was 54 billion tonnes of CO₂ equivalent). All that extra methane and carbon of course has the potential to enhance global warming even further.  With this in mind, it is clear to see why the recent wildfire, which was burning in dried-out peat in the active layer, was especially interesting to researchers. If Greenland’s permafrost becomes increasingly degraded and dry, there is the potential for even bigger wildfires which would release vast stores of greenhouse gases into the atmosphere.  Major changes in the physical environment are already affecting the species that call Greenland home. Just look at polar bears, the face of Arctic climate change. Unlike other bears, polar bears spend most of their time at sea, which explains their Latin name Ursus maritimus. In particular they rely on sea ice as it gives them a deep-water platform from which to hunt seals. However, since 1979 the extent of sea ice has decreased by around 7.4% per decade due to climate warming, and bears have had to adjust their habitat use. With continued temperature rise and sea ice disappearance, it’s predicted that populations will decline by up to 30% in the next few decades, taking the total number of polar bears to under 9,000. I have considered only a handful of the major environmental shifts in Greenland over the past few decades, but the effects of increasing temperatures are being felt in all parts of the earth system. Sometimes these are manifest as extreme events, at others as slow and insidious changes.  The different parts of the environmental jigsaw interact, so that changes in one part (sea ice decline, say) influence another (polar bear populations). We need to keep a close eye on the system as a whole if we are to make reliable interpretations – and meaningful plans for the future."
"The so-called “Heathrow 13” Plane Stupid climate activists have been given suspended prison sentences for trespassing on the airport’s runway. The case – and the decision of the judge to hand down custodial sentences at all, even if they were suspended – illustrates the way judicial attitudes to unlawful climate activism have seesawed over the years, and the harsh treatment meted out to the activists may yet backfire.  In 2008, six Greenpeace activists who had admitted causing criminal damage at Kingsnorth power plant were found not guilty by a jury, following a week of expert testimony on coal and climate change. It seemed a significant moment for the UK climate movement. Their “lawful excuse” defence justified their actions to fight global warming, and appeared to offer campaigners a way to make governments take both notice and action. But subsequent acts of mass disobedience faltered: in April 2009, 114 activists planning to shut down Ratcliffe-on-Soar power station were pre-emptively arrested in a case which ultimately brought to light the extent of police infiltration of the environmental protest movement. Later that year 29 activists were found guilty of “obstructing the railway” by a jury in Leeds after the judge refused to allow them to present a necessity defence and call expert witnesses to justify their “hijacking” of a coal train at Drax power station. And in June 2010, nine Plane Stupid activists were found guilty by a jury and fined for breach of the peace after they had broken into Aberdeen airport and played golf on the runway, dressed as Donald Trump. Taking non-violent direct action in order to “put climate change on trial” seemed at a dead end. The trial of the Heathrow 13 may have changed all that. In fact, the activists probably owe a vote of thanks to district judge Deborah Wright. History tells us that social movements not only mobilise when conditions are favourable; they also mobilise in response to threat, especially where that threat is widely seen as an injustice. The court’s guilty verdict was to be expected, but the judge’s threat to impose the maximum sentence of three months imprisonment succeeded in producing a wave of sympathetic media coverage, internet petitions and an impressive and sustained show of solidarity from 300 or so supporters outside the court. Criminal trials are social theatre: Wright’s promise of a punitive sentence turned this one into a political event. In so doing, the trial reminds us that the courts, especially the criminal courts, are a site of battles over legal and political legitimacy. Trials like that of the Heathrow 13 are, in the strict sense, about the causes that motivate action, the weighing of harms and the acceptability of specific conducts – but they are also about the scope that democratic societies afford for small groups of citizens to challenge what they perceive to be injustice in the name of the collective good. Though the Heathrow 13 were spared jail time, a suspended prison sentence for a non-violent minor crime, committed by (largely) first-time offenders, arguably remains extraordinary and excessive. In 2006, sitting in a High Court appeals case of anti-war activists who had committed aggravated trespass and criminal damage at RAF Fairford on the eve of the invasion of Iraq, Lord Justice Hoffmann formalised a basic bargain: where activists act in a publicly accountable way – with restraint, sincerity, and a sense of proportion – then police, prosecutors, and magistrates should show sensitivity and equal restraint, taking the conscientious motives of protesters into account. Activists are aware of the bargain: the Heathrow defendants certainly were, and it is a staple of advice for would-be environmental disobedients. But this sentence throws the bargain into confusion. By acting with less restraint – and causing more damage – activists can potentially secure a jury trial. Though the potential penalties are more severe, this move typically works in favour of the activists as juries, in general, are less likely than magistrates to convict in these sorts of cases (despite the Leeds and Aberdeen verdicts). But if magistrates are now imposing jail time, actual or suspended, for minor offences, then acting with restraint starts to appear less attractive. If you’re going to be dealt with harshly for aggravated trespass, you may as well cause criminal damage too, because that might get you a more favourable trial. This year will see a concerted wave of climate disobedience across Europe, as activists react, post-Paris, both to the lack of a concrete action plan by Western governments and to the apparent necessity of citizen action in order to force governments do anything meaningful at all. In the UK, we should expect more climate disobedience, not less: the Heathrow 13 trial raises the stakes."
"Self-driving cars will change how we live, in all sorts of ways. But they won’t just affect us humans – the coming revolution in autonomous transport has significant implications for wildlife as well. Nature conservationists and planners need to think hard about the impact of driverless vehicles, most notably in terms of renewed urban sprawl. In some ways, wider developments in automotive technology bode well for the environment. Electric cars will increasingly replace the internal combustion engine, and that should, in theory, reduce carbon emissions and health-afflicting air pollution. Through minimising traffic jams, driverless cars may also reduce overall energy use. Unlike human drivers, computers can avoid the “concertina” effect of needless acceleration and braking that exacerbates congestion, and won’t be tempted to “rubberneck” when passing an accident. And, as autonomous vehicles aren’t restricted by human reaction times, it may make sense to increase speed limits for them on major inter-city routes. So driverless cars promise a future of faster journey times with much reduced environmental impacts. They may even mean less wildlife roadkill. But it’s the very efficiency of driverless cars that poses a challenge for planners and conservationists. The threat is an unchecked increase in low-density urbanisation. Autonomous vehicles promise a future in which passengers are free to use their time productively (working, for example). And they can park themselves (or be part of a shared pool) which saves yet more time in the morning rush. Coupled with faster journey times, the incentives to live further out of town will increase significantly.  There are both push and pull factors at work here: sky-high residential prices in most cities push people away from urban centres while healthy environments and green living pull people towards the hinterlands. The limiting factor in suburban spread is often travel time, either by public or private means. Driverless cars fundamentally alter the equation. Existing planning policies are based on our current transport systems. Green-belts, for example, are designed to reduce urban sprawl by restricting development within a buffer zone around an urban area. However, the reduced transport times offered by driverless cars make it easier to live outside the belt while still working inside. So these loops of green are in danger of becoming a thin layer in a sandwich of ever-spreading suburbanisation.  This is, of course, a familiar challenge since the rise of the automotive age in the 1940s. However, the solutions designed by planners have been calibrated for a human-driving automotive system – not for the supercharged future of driverless transport. Other examples of planning protection for wildlife include nature reserves, national parks and (in the UK) “Areas of Outstanding Natural Beauty”. Such areas have either strict controls on development, or do not permit it at all. However, they are nice places to live in or nearby. The coming revolution in automotive journey times and the ability to work behind the (computer-driven) wheel will make living in such areas increasingly compatible with a commute to the nearest city.  Natural habitats being lost entirely or splintered into ever-smaller fragments have long been understood as some of the primary causes of species extinctions across the world. Renewed urban sprawl threatens to increase the magnitude of both habitat loss and fragmentation. These threats are well known among conservationists, but there are differences of opinion on how best to respond. For example, eco-modernists advocate a strategy of “land-sparing”, whereby human activities are concentrated into urban areas and vast tracts of land are set aside for nature. There are many cultural and ethical problems inherent in herding humans into cities, but the near-term planning issues posed by autonomous vehicles will exacerbate the challenge given they will boost demand to live in “unspared” lands. Alternatively, some conservationists advocate “land-sharing”, in which human communities redesign the way we farm and live so as to co-exist with wildlife, cheek-by-jowl. Autonomous vehicles pose significant challenges for either approach, by supercharging the fragmentary effect of road systems. Whichever approach is taken, we’ll need to redesign existing systems and policies to take account of the increased range that driverless transport facilitates. This may involve new zoning laws to protect wider areas of countryside than at present. It certainly requires further development of green infrastructure, habitat corridors and “greenways”.  It might also involve engineering solutions, especially given the fact that autonomous vehicles should be much more amenable to being driven underground. It is possible to imagine a future in which the famous bear bridges of Banff are tiny precursors to a vast programme in which rural highways are covered with forests of green. Retro-fitting roads into tunnels won’t be cheap, but it becomes easier when human drivers are taken out of the equation. Software drivers are less bothered by artificial light and more efficient at mitigating the congestion impact during construction. Much conservation policy is based on planning for the world we live in now. Strategic conservation planning needs instead to take account of likely futures. And in a future of driverless cars, that is likely to result in the mega cities of the 20th century becoming the mega sprawls of the 21st. Unless, of course, planners and conservationists rise to this new challenge."
"
Share this...FacebookTwitterResistance to wind power in Germany is snowballing. And it needs to be noted that this resistance is grass roots and sustained almost entirely by volunteers and privately donated time and effort.
In the latest wind energy critical site www.vernunftkraft.de here has a report summarizing the performance of Germany’s wind turbines in 2014. Again the result is so ugly that the wind industry does not want anyone to see it.
Vernunftkraft.de writes in response to the wind industry’s recent boastings of yet another successful “record” year:
Rolf Schuster finalized the evaluation of the actual wind energy feed-in data in order to counter the propaganda with honest figures.
The most important result: 14.8 percent.
The following diagrams depict the installed capacity in light blue shading, i.e. the cumulative capacity of all Germany’s wind turbines.
As is easy to see, the installed rated capacity has been expanded because new turbines were installed over the course of the year. This is the so-called ‘record’.
The dark blue area shaded depicts the energy that was actually fed in. Here it is easy to see that wind energy is extremely volatile. During some quarter-hour periods the roughly 25,000 turbines indeed delivered a lot of power. But at other times they delivered practically nothing.
One does not even see any real available baseload – a sort of reliable minimum output to rely on.”

Germany’s 2014 installed wind turbine rated capacity (shaded light blue), and the actual power fed in (dark blue). The average: 14.8%! Chart by Rolf Schuster, see here.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The next three charts at Vernunftkraft.de (not shown here) show the January-April, May-August and September-December periods respectively with a higher resolution so that readers can get a better idea of the extreme volatility one gets with wind energy.
The following table sums up the “honest figures” one really gets with wind turbine energy:

Source: Rolf Schuster, here.
The left box shows a total of 39,612 MW of installed rated capacity. The maximum energy fed in was 29,687 MW (74.9% of rated capacity) briefly in December. The absolute minimum was only 24.0 MW (0.06%), probably barely enough to power a single large cement mill.
The average was 5868 MW or 14.8% of the installed rated capacity.
Theoretically that means 85.2% of the rated capacity did nothing the entire year. Imagine a company where only one of seven workers ever show up for work.
The box above on the right also provides interesting figures. They show that Germany’s wind turbines as a whole ran at between 0 to 10% of their rated capacity 45.5% of the time (3986.75 hrs)! The turbines, which the German government says will become the “workhorse” of the German power industry, ran at over 50% of their rated capacity only for 461 hours, or just 5.2% of the time.
It’s little wonder that wind turbines have been assigned the failing grade of “F”. But what else could one possibly expect from a student who shows up for lectures and does his homework only a few times per semester, and stays in bed 6 out of 7 days a week? And now comes the funny part: The parents of this lazy, total-failure-of-a-student are forced to pay Ivy league level tuition – 20 years long! And don’t expect the lazy bum to have a degree of any sort when he walks off campus at age 38.
Little wonder vernunftkraft.de calls wind turbines the sloth of the energy industry.
 
Share this...FacebookTwitter "
"The replacement for the EU-US Safe Harbour agreement that was ruled unlawful by a European court last year may well fail the same legal tests as its predecessor. The new agreement, called Privacy Shield, seems to be little more than a new name strapped onto what are largely the same data sharing protections, or lack of them, contained in Safe Harbour. Safe Harbour dated from 2000 and allowed US and European companies to exchange data without officially conforming to the relatively strict requirements of European data protection legislation. The European Court of Justice has ruled it to be unlawful following a challenge brought against Facebook – but also in the light of Edward Snowden’s revelations about US government mass surveillance programmes. Safe Harbour provided firms with considerable leeway – considered a box-ticking exercise – with little if any real protection for individuals.  While mass surveillance is a concern, it is difficult to police due to the nature of national security as a secretive business with very little transparency or public accountability. But the terms under which firms do business is certainly within the realms of oversight. Now the European Commission has announced an “agreement in principle” on the new EU-US Privacy Shield. The full text of the proposed agreement has not yet been made available, but the wording of the European Commission and US Federal Trade Commission announcements reveals a number of problems. FTC Chairwoman Edith Ramirez said:  Under the agreement … the Federal Trade Commission will continue to prioritise enforcement of the framework… We will continue to work closely with our European partners to ensure consumer privacy is protected on both sides of the Atlantic.   But the FTC’s own assessment makes it clear that enforcement was not a major priority under Safe Harbour. Only latterly were some of the most high-profile data controllers such as Google, Facebook and MySpace fined for their breaches. Several studies have suggested that enforcement had been very lax indeed. From the European side, EU commissioner Vĕra Jourová used careful wording to imply stronger protections for EU citizens’ privacy without any concrete provisions: The new arrangement will provide stronger obligations on companies in the US to protect the personal data of Europeans. Of course, without any clear statement of what those obligations are or how they will be enforced, these words have an empty ring to them. Talk of “stronger monitoring and enforcement” is meaningless unless there are penalties associated with any breaches.  Three provisions are outlined. Where, under US law, public authorities can access personal data transferred under the new arrangement they will be subject to clear conditions, limitations and oversight. There will be the “possibility” of raising any complaint in this context with an ombudsman. And there will be an annual joint review of the implementation of the new arrangements. But while this will involve representation from national security agencies, there is no mention of any role for consumer representatives. Similarly, there is little reassurance to be found in the proposed safeguards and remedies.  While companies will be given deadlines to respond to complaints, there is no suggestion that these will be enforceable, nor which country’s law would apply. Would European citizens have the right to take a case to the US courts? European data protection authorities can refer complaints to the FTC, but there’s no indication that they would be taken any further, nor are there any provisions for Europeans to gain redress there. An alternative dispute resolution procedure is mentioned, but without any indication of who the mediator would be and whether judgements would be enforceable. Finally, the prospect of a US ombudsman is mentioned – but again without any detail that might explain their powers, independence and what sort of oversight would be in place. It seems clear that the main aim of the EU-US Privacy Shield is, as critics have stated, to give US-based companies an easy way of handling personal data from European citizens without having to provide the full protections afforded by the EU’s Data Protection Directive.  Seen this way, Safe Harbour could be viewed primarily as a way of preventing data protection legislation from jeopardising transatlantic trade. Why the urgency to rush to replace such a leaky arrangement, demonstrated to be full of holes? The headlong rush to agree and implement this badly thought-out follow-up agreement is perplexing when there are already other means in place. For example, model clauses for consumer contracts, or the technology to obtain informed consent directly from customers to process personal data outside the EU. With that in mind, it’s difficult to see how the proposed new arrangement is any different in intent to the one it replaces."
"As night closes in across Kentucky a small chubby spider makes a silk line between two plants. She then moves along her “trapeze wire” and waits. After a while a moth approaches within range, and the spider unleashes a swinging sticky ball, ensnaring the moth and pulling him in to be eaten. The attacker is a bolas spider, and she hunts by releasing an odour that precisely matches the chemical composition of female moth mating pheromones. The male moth is lured in, but instead of getting a mate, he gets eaten. Bolas spiders are just one of a plethora of animals and plants which are highly skilled at thriving through trickery and deception. Charles Darwin and his contemporary Alfred Wallace both appreciated the functions of deception in their theory of evolution. However, modern science has started to uncover just how devious many species can be. One of the main uses of deception in nature is to secure food. The fork-tailed drongo is a bird found in Southern Africa that lurks around group-living species, including meerkats, and might at first appear helpful because it sounds alarm calls when a predator approaches. However, much of the time the drongo’s calls are made when no predator is around. The drongo watches as a meerkat digs up a juicy beetle and then makes a false alarm call, which causes the meerkat to flee, allowing the bird to swoop down and claim the prey for itself. The alarm calls drongos use even mimic those made by the animals they exploit.  But stealing food seems benign compared to the deception of predators, which use mimicry and enticement to lure victims directly into the jaws of death. Many web-building spiders use bright colours to attract prey, and carnivorous plants also use overt signals and mimicry to attract victims. The Venus flytrap produces smells that mimic food, luring in flies, and some pitcher plants have been shown to use attractive fluorescent glowing blue colours. These colourful signals work by exploiting “preferences” that many animals have in their sensory systems to be drawn to conspicuous stimuli.   The second use of deception is in survival, with the most common method being camouflage. This can involve matching the general colour and pattern of the environment, or can be much more specialist. On his eight-year voyage around the Malay archipelago, Wallace encountered the butterfly Kallima in Sumatra and was astounded at how closely its wings matched the colour, shape, and structure of dead leaves. Many specimens even had markings mimicking patches of mould.  Resembling other objects for protection is common in nature. Some excellent early evidence for evolution and natural selection was provided by Henry Bates, an entomologist who travelled to the Amazon with Wallace. Bates noted that many  edible butterflies mimicked the colour and behaviour of toxic species, and were avoided by attackers. 
Another striking example is jumping spiders, some of which mimic the appearance of ants, which predators often avoid owing to their strong defences. Organisms also cheat for reproductive reasons. Orchids have an astounding range of approaches which they use to get insects to pollinate their flowers, while offering no reward. One method is to lure male insects with smells and colours resembling a potential mate, like bee orchids that attract male bees. Other species create the false promise of food. One flower from Hainan Island, China, mimics the alarm pheromones and appearance of bees, thus attracting a ferocious predatory hornet. And once mating has been achieved there are young to be cared for. The common cuckoo, a notorious cheat, lays its eggs in the nests of other species, so the foster parents rear the cuckoo chick instead. The cuckoo often even lays eggs that mimic the colour and pattern of those of their host, so the host can’t tell the difference.  Insects can be equally devious, seen in the behaviour of cuckoo bees, and the audacious  slave-maker ants. The workers of these remarkable animals often have one function alone – to raid the nests of other ant species and steal the brood. The captured ants then integrate with the host colony, dutifully carrying out all the main tasks of the nest, from cleaning and rearing young to defence.  The struggle to survive and reproduce is intense for all organisms, and we should not be surprised that cheats are everywhere. What’s remarkable is the extent to which animals and plants exploit one another and the level of sophistication involved. Nature is a brutal place, so it’s a good idea to cheat and deceive if you want to be successful."
"
Share this...FacebookTwitter
Sun-powered Solar Impulse 2 aircraft is to circumnavigate the globe “without a drop of fuel”. However it will in fact need thousands of litres of fuel from support planes. Photo credit: Brussels Airport, Creative Commons Attribution-Share Alike 2.0 Generic license.
There’s been a fair amount of hype surrounding the Swiss Solar Impulse 2 project where it is being attempted to go around the world in a purely solar-powered aircraft, “without using a drop of [fossil] fuel“. It is being billed as a landmark flight, signifying a milestone in green aviation. However, nothing could be further from the truth.
Hat-tip: Reader Konrad.
The fixed-wing aircraft departed Abu Dhabi on March 9 and has since landed in India. From there it will continue to China, Hawaii, Phoenix, New York, Morocco before finally coming full circle back to Abu Dhabi sometime in August, 2015 – “without emitting any climate gases”. Full planned route here.
The pilots Bertrand Piccard and André Borschberg will alternate as the craft makes a series of stops along its journey. The plane is able to carry only a single pilot and no passengers. The aim: “We want to show what’s possible with innovative technologies,” Piccard boasted.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The 2200-kg pioneering aircraft has a wingspan that is comparable to that of an Airbus A340. According to Wikipedia lithium polymer batteries will store and power 10 hp (7.5 kW) motors with twin-bladed propellers. The upper wings have 11,628 photovoltaic cells. The major design constraint is the capacity of the lithium polymer batteries. See plane specs here.
Of course the entire flight is supposed to be done “solely” using renewable energy from the sun, and not use a single drop of aircraft fuel. But when one examines the flight more closely it turns out that mission indeed involves a huge fossil fuel carbon footprint.
According to an audio report by SRF Swiss Radio and Television the Solar Impulse 2 mission involves the substitute pilot, a technical ground crew “of dozens of people” and tonnes of equipment and logistical supplies that have to be flown behind using conventional charter flights. The “fossil fuel-free” Solar Impulse 2 journey is in fact being made possible only with the use of tens of thousands of litres of aviation fuel. This is a fact that is being almost entirely ignored by the media.
The SRF reporter tells listeners:
It is so that the entire group, the team members, are multiple dozens of men and women, have to fly behind in charter planes. This naturally is the less sustainable aspect of the entire project, but it just isn’t possible any other way. This involves one cargo plane for transporting all the equipment, and a small passenger plane on which the entire group travels to the destinations.”
A promotion video here shows how the aircraft was transported from Europe to its start point in Abu Dhabi earlier this year: With a Boeing 747!
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterDirk Notz of the Hamburg-based Max-Planck-Institute: Arctic sea ice could again expand in the coming decade
By Sebastian Lüning and Fritz Vahrenholt
(Translated/edited by P Gosselin)
Over the past 30 years Arctic sea ice has shrunk considerably. Although both in 2007 and 2012 negative records were reached, the ice recovered in the years that followed.
Former US Vice President and climate activist Al Gore was clearly impressed by the 2007 melt record and so in 2008 he declared the Arctic could be completely ice free by 2013. The year 2013 came and went, but the ice stayed. Using the same alarmist bullhorn, US Senator John Kerry also announced that the Arctic sea ice was set to melt away, read here:
The truth is that the threat we face is not an abstract concern for the future. It is already upon us and its effects are being felt worldwide, right now. Scientists project that the Arctic will be ice-free in the summer of 2013. Not in 2050, but four years from now.“
The idea of an ice-free Arctic from both politicians obviously had been whispered to them by IPCC scientists such as Wieslaw Maslowski. The BBC reported here on December 12, 2007:
Scientists in the US have presented one of the most dramatic forecasts yet for the disappearance of Arctic sea ice.
Their latest modelling studies indicate northern polar waters could be ice-free in summers within just 5-6 years. Professor Wieslaw Maslowski told an American Geophysical Union meeting that previous projections had underestimated the processes now driving ice loss.”
Looking back at these completely failed prognoses, one would at least expect a return to reason. But this has not been the case for some. There are still climate alarmist scientists who continue insisting that the Arctic sea ice only has a few years left. They’re dead sure. The same is true with the end-of-the-world. And when the predicted end of the world fails to happen, the goalposts get pushed back, or the focus switches to some other end-of-world scenario.
One of the more outspoken believers of the Arctic death spiral is Peter Wadhams of the University of Cambridge. In 2012 he announced to the world the prognosis that Arctic sea ice would disappear within four years. Today, two years later, the trend is in the opposite direction. It doesn’t look good for Wadhams and his prognosis. Now even some of the most obstinate alarmists think the same. For them the apocalyptic visions are really starting to get annoying. During a sea-ice conference in September 2014 in London, Gavin Schmidt had harsh words for Wadhams via Twitter:
“Some anticipation for Peter Wadhams. Audience members already crying,” “Wadhams still using graphs with ridiculous projections with no basis in physics,” “Wadhams now onto methane pulse of 50 GT. But no better justified than his previous statements,” and “Wadhams clearly states that there is no physics behind his extrapolations.”
The latest prognoses come from James Overland and Muyin Wang, who published them in the Geophysical Research Letters in May, 2013. Here they employ three prognosis approaches which look at the end of the ice in 2020, 2030 or 2040. What follows is the abstract:
When will the summer Arctic be nearly sea ice free?
The observed rapid loss of thick multiyear sea ice over the last 7 years and the September 2012 Arctic sea ice extent reduction of 49% relative to the 1979–2000 climatology are inconsistent with projections of a nearly sea ice-free summer Arctic from model estimates of 2070 and beyond made just a few years ago. Three recent approaches to predictions in the scientific literature are as follows: (1) extrapolation of sea ice volume data, (2) assuming several more rapid loss events such as 2007 and 2012, and (3) climate model projections. Time horizons for a nearly sea ice-free summer for these three approaches are roughly 2020 or earlier, 2030 ± 10 years, and 2040 or later. Loss estimates from models are based on a subset of the most rapid ensemble members. It is not possible to clearly choose one approach over another as this depends on the relative weights given to data versus models. Observations and citations support the conclusion that most global climate model results in the CMIP5 archive are too conservative in their sea ice projections. Recent data and expert opinion should be considered in addition to model results to advance the very likely timing for future sea ice loss to the first half of the 21st century, with a possibility of major loss within a decade or two.”
Other scientists have become more cautious, as they were burned too many times in the past with overly hasty projections. Sea ice scientist Dirk Notz of the Hamburg-based Max-Planck-Institute for Meteorology declared in September 2014, in response to a request made by Pierre Gosselin of notrickszone.com, that because of the variability over the coming decade the ice could just as well expand as it could shrink. Interestingly in the model graphics provided by Notz for the coming decades, there are no ice free polar seas to be seen. What follows is the exact wording of the notable e-mail from Notz to Gosselin:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Dear Pierre,
Thanks for being in touch, and sorry for the slow reply. I was at a meeting with surprisingly little internet access. Regarding the bet: I’d be very careful to place a bet in either direction, simply based on our understanding of the system from climate-model simulations. These basically say that on short time scales, such as from one decade to the next, internal variability can cause both an increase or a decrease of the ice coverage. To exemplify this, I’ve attached a slide that shows 30-year long trends from our climate-model simulations.

There you see 30-year long trends for different start dates in our simulations, which vary wildly. This would even more be the case for 10-year long trends. Hence, I wouldn’t put money on a further decrease of the ice cover in the years to come, nor on the opposite. I’ve also attached a plot showing two of the simulations with our Earth-System Model, which suggest that there might be slightly less sea ice in the next decade, but other simulations show a slight increase on these short time scales.

Hence, on time scales such as one decade, the ice cover could well increase a bit (as you are suggesting), but it might also decrease. This depends in my opinion primarily on weather patterns in individual summers – nothing we can predict at the moment. Having said this, however, one of the presentations at the meeting I’ve just been to by Andrey Proshutinsky went in the same direction as you’re suggesting, namely that because of ocean cycles there will be a recovery of sea ice in the years to come. However, I don’t believe this to be a very robust finding that I would put money on at the moment. It’s nevertheless certainly something that we’ll investigate more in the time to come. […] Please let me know if any further questions should come up.
Best wishes,
Dirk”
With all the long-term prognoses we are also naturally interested in how things will develop with Arctic sea ice over the coming year (2015). In her blog Judith Curry provided a forecast Blog in October 2014. She expects the ice in the summer of 2015 to at least reach the extent seen in 2014:
And finally, my prediction for 2015 sea ice minima. I predict minimum sea extent will be the same or greater than 2014, with a continued recovery of sea ice volume. I expect continued recovery in the Atlantic portion of the Arctic, with continued low sea ice extent in the Siberian Arctic. My decadal scale prediction is either no trend in sea ice minima or an increase (I do not expect continued decline in the coming decade).”
It doesn’t look good for Peter Wadhams and the followers of the climate-alarmism movement.
 
Share this...FacebookTwitter "
"It is more than ten years since Al Gore’s documentary An Inconvenient Truth brought climate change to the masses. At its heart, it showed the former US vice-president giving a comprehensive global warming slide show – warning of the dire consequences if we do nothing about the climate crisis.   The film grossed US$24m in the US and US$26m internationally. Not only was the film a financial success but it was also a critical success and won two Oscars. An Inconvenient Truth has been credited for raising international public awareness of climate change and re-energising the environmental movement. The documentary has been included in science curricula in schools around the world. It was also instrumental in Al Gore sharing the 2007 Nobel Peace Prize with the Intergovernmental Panel on Climate Change (IPCC).   A decade on, Gore has made a follow-up entitled An Inconvenient Sequel: Truth to Power. This film updates us on the major changes that have occurred over the past decade; including the accelerated retreat of the ice caps, extreme weather events and the historic signing of the Paris Climate Agreement in 2015.  The sequel is different to the first film – it is much more biographical and focuses on how Gore became the great climate change communicator and what he has been doing with his charities to build awareness and train future climate change leaders around the world.  Had this film been released a year ago, its optimistic tone would not have seemed out of place. It is almost as if the filmmakers had assumed there would be a different election result. The film has been hastily edited to include Donald Trump’s withdrawal from the Paris Agreement. The end of the film seems out of kilter with the optimistic tone of the rest of the film, which occasionally borders on triumphant. I interviewed Al Gore and we mainly focused on politics and how to deal with bipartisanship. We both believe that it will be in the political realm where the fight to solve climate change will be won or lost. Watch the interview here Mark Maslin: It’s clear that the first film had a huge impact. So what is the motivation behind you doing a sequel? Al Gore: When we reached the ten-year anniversary of the first movie it seemed like an appropriate time to present what’s new in the previous decade – and there have been two very big changes and a third that occurred during the filming of the movie.  The first is that unfortunately the climate-related extreme weather events have of course become far more common and more destructive. Mother nature is speaking up in a very persuasive way.  The second big change is that the solutions are here now. A decade ago you could see them on the horizon but you had to have the technology experts reassure you that they’re coming, that they’ll be here – well now they’re here. And for example electricity from wind and solar has fallen so quickly in price that in many regions it’s much cheaper than electricity from fossil fuels and soon will be almost everywhere. Electric cars are becoming affordable. Batteries are now beginning to decline sharply in price which will be a real game-changer for the energy industry. LEDs and hundreds of new far more efficient technologies are helping to stabilise and soon reduce emissions. I was struck in the middle of your film by a profound statement: “To fix the climate crisis we need to fix democracy”. And then the film moved on to another topic. How do you think we can fix our democracies now in the 21st century? Well, big money has hacked our democracy even before Putin did. And it accompanied the transition from the printing press to television, when all of a sudden candidates – especially in the US – were made to feel they have to spend all their time begging rich people and special interests for money so they can buy more TV ads and their opponents. And that’s really given an enormous unhealthy and toxic degree of influence to lobbyists and special interests. Now just as television replaced the printing press, internet-based media are beginning to displace television and once again open up the doorways to the public forum for individuals who can use knowledge and the best available evidence. If you believe in democracy as I do and if you believe in harvesting the wisdom of crowds, then the interaction of free people exchanging the best available evidence of what’s more likely to be true than not will once again push us toward a government of by and for the people. One quick example. Last year the Bernie Sanders campaign – regardless of what you might think about his agenda – proved that it is now possible on the internet to run a very credible nationwide campaign without taking any money from lobbyists and special interests or billionaires. Instead, you can raise money in small amounts from individuals on the internet and then be accountable to them and not have to worry about being accountable to the big donors. There was a poignant moment in the film when you’re sitting in front of the Senate hearing – and there’s a Republican senator and he’s just not hearing what you’re saying. In a two-party system, how do you reach out to those Republicans – and some of the Democrats – that still don’t to get climate change? Well, part of it is related to the changes necessary in the financing of campaigns. A famous journalist in the US, over a century ago, Upton Sinclair wrote: it is difficult to get a man to understand something if his salary depends upon him not understanding it. And if you substitute campaign finance for salary, you get part of the answer.  But I know for a fact that there are many Republican members of the Senate and House who know that what they’ve been advocating is wrong and would like to crawl back from the end of the limb they’ve put themselves on. And as more and more people express the passionate view that we’ve got to solve the climate crisis that can give them the backbone to change their position, some of them already have. There’s a new Noah’s Ark caucus the Climate Solutions Caucus in the Congress – a reference to the biblical deluge but also a reference to the fact that they only can join by twos one Democrat one Republican – and more Republicans are now switching sides. You’ve done a great job at communicating climate change around the world – but perhaps you being a very prominent, highly respected liberal Democrat has incensed some Republicans and actually hardened their view against climate change. Do you feel that’s fair? I don’t think that’s fair at all and in fact there’s been a great deal of social science research that shows that’s completely inaccurate. You may know Joe Romm – a great climate blogger – he has compiled all that research. For two and a half years after the first movie, bipartisanship increased significantly on this issue. The Republican nominee in 2008, John McCain, had a very responsible position on this issue. But what happened was in the wake of the Great Recession the carbon polluters launched the Tea Party movement – some of them joined on their own, but they actually provided the seed money and insisted that climate denial be a part of that political movement. The polluters have done exactly what the tobacco companies did years ago when they hired actors and dressed them up as doctors and put them on camera to say there are no health problems with cigarettes – 100m people died as a result. Well, now the carbon polluters have taken that same approach hiring the same PR firms spending more than a billion dollars to put out pseudo science and false information. They’re not necessarily going to win the debate. They just want to give the appearance that there is a debate – in order to paralyse the political process. But people are seeing through it now. What struck me about the interview – and also the film – is that Gore is making two very clear points. First is that now all the solutions to climate change exist. There is a wonderful sequence in the movie where he meets Dale Ross, the mayor of Georgetown in Texas. The mayor describes Georgetown as the reddest city in the reddest county in Texas – and he’s a conservative Republican. But he sees moving toward renewable energy, as just making sense. As his job is to deliver the best value for money to his taxpaying citizens and wind and solar are the cheapest energy source.  The second is that Gore makes the profound statement that Western democracies are broken and in order to solve the climate crisis they need to fix democracy. In the interview, Gore suggested that big business has bought many politicians and this must be unpicked so that they are free to make informed unbiased decisions.   He sees social media as the great leveller as campaigns can be run on much smaller budgets reducing the power of party donors. He also suggests in the film that educating both politicians and the electorate on the damages of climate change will make a significant difference. But this is the same rhetoric we here from intellectuals all the time – if the poor people were properly educated they would make the correct political decisions.   In the post-truth era this neatly sidesteps issues of growing inequality, poverty and a general feeling of disenfranchisement. In this way, An Inconvenient Truth was the right movie at the right time and An Inconvenient Sequel is the wrong movie at the wrong time. At the end of the film, Gore makes an impassioned rally speech – part Winston Churchill and part Martin Luther King – which even the hardened sceptic couldn’t help but admire. He finishes by declaring the tag line of the film: “It’s time to fight like your world depends on it.”  Given the forces of big business and Trumpism aligned against climate action, we all need to be as passionate, optimistic and committed to a new safer cleaner future as Gore – because he is right, the world does depend on us acting now."
"
Share this...FacebookTwitterIf anyone needed more proof showing that former US Vice President Al Gore is a pathological serial exaggerator, look no further. He has proven it yet again, this time at the World Economic Forum in Davos, Switzerland, a location where dozens of world economic leaders have flown with private jets.
The Guardian reports here, quoting Mr Gore:
I think that these extreme weather events which are now a hundred times more common than 30 years ago are really waking people’s awareness all over the world [on climate change], and I think that is a gamechanger.”
This gaffe is even worse than his remark claiming that the core of the earth is 1 million degrees hot. It’s truly embarrassing that a vice president of the United States could say such a dumb thing.
In Gore’s view we can only assume that a 100-fold increase in extreme weather events is what it would take to get policymakers to take real action. The reality, however, is that there has been no detectable increase at all. Thus it all means we are light years away from “the climate crisis” Gore likes to hysterically bellow about.
And let us recall what the last IPCC report concluded on the subject of extreme weather event trends: No data exist showing extreme weather events have become more frequent. That’s from the IPCC itself.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Gore is obviously a very desparate man trying to get attention. He’s beginning to appear like the village marketplace fool.
Now responsible journalists are shaking their heads at Gore’s doozy of an exaggeration.

For example Spiegel science journalist Axel Bojanowski has reacted in a head-shaking way at Gore’s mega-whopper, calling “curious” and sarcastically commenting at Twitter:
Why have there been 5 IPCC reports?
Gore delivers another blow to the global warming science. Let him keep talking.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe latest 17 June 2015 edition of Weltwoche from Switzerland has a commentary on the Vatican and its encyclical on climate titled: “A Matter of Faith“.
The commentary believes the Vatican is out of place with Its recent encyclical on climate science, reminding readers that the Vatican hardly has a stellar record when it comes telling Catholics what true science really is, and that today It is wrong with Its claim there is a consensus on the issue.
“Galileo is chuckling”
The Weltwoche article writes in its introduction:
With an encyclical the Pope is attempting to teach correct climate policy. The Catholic Church has long since always proven its sense for true science. Somewhere Galileo is chuckling.”
Weltwoche recounts the Church’s debacle surrounding Galileo, writing that it took the Catholic Church over 300 years to apologize for having falsely accused the 17th century physicist, who claimed the Church had been wrong in thinking the earth was the center of the universe.
“The Amen to the reporters of the IPCC”
Yet under Pope Francis the Church appears to have learned nothing from its long history of intellectual blunders, and Its Little Ice Age and bad-weather witch-hunts. Weltwoche writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Pope Francis is now sending the encyclical “Laudato Si” to his bishops, which reads as the Amen to the reporters of the IPCC and the capitalism critics, such as Naomi Klein.”
Weltwoche describes how Pope Francis claims there is a “scientific consensus” and that as a result “mankind has to change its lifestyle“.
A Hail Mary to reverse crumbling consensus?
Weltwoche also writes how major media outlets such as The Guardian and Reuters have cheered the Pope’s word on the issue, hoping it will finally tip the scales in favor of radical environmental change. But this reaction was expected, writes Weltwoche:
The jubilation can be explained because the consensus in the science has been crumbling: The temperature has not been rising in what will soon be 20 years and it remains below all prognoses as a result. With increasing desperation, instead of abandoning their refuted models and theories, the climate scientists offered more than 50 explanations.”
Stiff opposition
Weltwoche then describes a growing atmosphere of shrillness pervading among climate scientists and activists, but on the other hand emerging countries have been unimpressed by the ever more shrill alarms being sounded. A climate treaty faces stiff opposition from the US Congress, and for this reason Pope Francis plans to visit Washington in September, Weltwoche writes, adding that His Holiness plans to have a talk with Catholic and House Speaker John Boehner:

However the Holy Father will barely be able to teach him much, and not at all the Chinese, and certainly not the Indians, who will first bring their citizens out of poverty, just as the encyclical demands. And to do that they need affordable energy, foremost coal.”

 
Share this...FacebookTwitter "
"The future role of gas in the UK is the subject of significant debate. There is controversy about how much gas we could use and for how long, and whether this will be compatible with statutory climate change targets. As North Sea supplies decline, there are also starkly differing views about whether some of the gas we will need in future should come from domestic shale gas resources. Despite the number of headlines about shale gas, there has been very little development activity so far. Fracking for shale gas has only been carried out at one site near Blackpool, where operations by Cuadrilla caused minor earthquakes in 2011. This means that it is almost impossible to determine whether significant UK shale gas production would make economic sense. The recent falls in oil and gas prices have added to this uncertainty, but are likely to make commercial viability more challenging. During the recent 14th licensing round for onshore oil and gas, 159 areas were awarded licenses for development – 75% of these were for unconventional oil and gas extraction, which has sparked local debates in many of the affected areas. Two planning applications submitted by Cuadrilla for exploration at sites in Lancashire were recently turned down by the local council on the grounds of noise and traffic. One of these was refused against the advice of council officers. An appeal by Cuadrillia is currently underway. Whether or not it goes in favour of the council or the developer, it raises broader questions about the role of local democracy and decision-making.  Last August the government announced the introduction of fast-track planning regulations designed to limit the length of local planning processes for unconventional oil and gas operations. Greg Clark, the secretary of state for communities and local government, also said he expects to have the final say over the Lancashire applications.   This intention to constrain local planning processes has understandably led to concerns about local democracy. It is not the first time national government has tried to intervene in local decision-making, especially when it comes to the development of new large-scale infrastructures or natural resources. While national government may emphasise a particular course of action, like the development of shale gas, there is no guarantee that local decision-makers will simply agree. Furthermore, selective limits on local planning risk exacerbating public mistrust. A Sciencewise project on public engagement with shale gas and oil, commissioned by the government, revealed significant unease among participants about decision-making processes.  Given that large-scale changes to energy infrastructures are very likely to be required across the UK as the energy system decarbonises, this issue goes well beyond shale gas. Local opposition has also been significant for other energy developments such as wind farms, solar farms, gas storage sites and electricity transmission lines. The government’s approach to different energy sources appears to be inconsistent – most notably between onshore wind and shale gas. In contrast with the approach for shale, local planners will determine whether new onshore wind projects go ahead or not. Ministers have defended this situation on the grounds that a lot of wind farms are already being deployed, while shale gas is at a very early stage.  Although the government’s regular energy opinion poll no longer asks specific questions about onshore wind, other polls suggest it still has significant public support - as well as being the cheapest low carbon electricity generation technology. The focus on shale and wind could also be a missed opportunity for a broader conversation about the UK’s sustainable energy transition. This conversation should not be restricted to which technologies or resources should be used, and what they might cost. Previous research from the UK Energy Research Centre suggests that people are also interested in how energy systems can reflect values such as fairness, sustainability and efficiency. A focus on individual sources like shale gas in isolation leaves little space for this broader conversation to be held."
"
Share this...FacebookTwitterBandarq ialah jenis permainan menarik yang di tawarkan laman pokerqq sekarang ini. Permainan tiket laman BandarQ Online yang lain lain seperti dominoqq, aduq, pokerqq, capsasusun secara secara sipil di ambil dari permainan yang ramai dimainkan sambil masyarakat. Permainan judi yang dimainkan dengan 32 tiket domino. Dalam tutorial ini akan dibeberkan dengan jelas bagaimana Anda akan mengangkat Bandarq Online. Mari kalian mulai dengan cara mendapatkan jackpot bandarq online, merinci rangking kartu dari yang terbesar sampai terkecil.
Peraturan Dasar BandarQ Online di Website BandarQ
Dikala memainkan bandarq online, Anda akan segera menunjukkan ke meja. Sebelum masing-masing kartu Anda akan menabalkan taruhan yang berharap Kamu mainkan taruhan ini berdasarkan nominal asalkan berada di batas-batas meja. Bagus Kamu dan dealer akan dibagikan 2 kartu. Dari setiap 2 kartu yang dibagikan, maka tiap pemain serta Bandar akan mengadu jumlah kartu hal yang demikian. Bila Bandar mempunyai jumlah kartu Sembilan maka telah di pastikan akan membela semua taruhan.
Kartu yang kalian dapatkan akan di berkelahi sama Bandar. Bila order jumlah kartu yang sama maka pemain akan menurut. Tapi jiga pemain order jumlah kartu Sembilan ataupun Q / qiu atau kiu maka Bandar bakal membayar double terhadap tokoh. Ini ialah sedikit profit menjadi pemain
Ingatlah kalau bandarq online di laman qq, tujuan Anda adalah memenangkan permainan. Jadi Kamu menerima kartu yang total nya lebih besar daripada bandar. Pada dasarnya tersebut berarti Anda berharap menyusun 2 kartu Anda menjadi sebaik mungkin supaya bisa menang dan menikmati hasil kemenangan hal yang demikian.
Pemasangan taruhan bervariasi. Akan tetapi masing-masing dari anda yang menang tak akan pada kenakan tarif lebih daripada 3%. Ini mungkin nampak cukup mahal, melainkan sesudah bermain game untuk provisional waktu. Anda akan merekam bahwa banyak keuntunga dari bermain game ialah bisa menerima profit yang kian besar kalau kerap menang beruntun. Dan kerap nampi kartu Q atau sembilan.
Bandarq Online di pelataran pokerqq ialah game yang menarik yang membikin Anda berpikir. Ini ialah permainan keterampilan, salah satu yang tersendiri lebih menyenangkan bagi banyak orang kalau tak menjalankan pilihan menaikan taruhan. sebab Anda akan menerapkan hoki Anda sendiri untuk membela permainan. Rupanya bahwa bermain terus tak selalu sempurna pula. Permainan ini beresiko besar karena emosi pemain. Stop la bermain kalau telah menang. Bila Dikau berharap permainan yang dahsyat dan tahan lama pada meja di mana Anda bermain, pakailah nominal perakitan yang kecil.
Bila kedua kartu menaklukkan kartu bos, pemain memenangkan malah duit atau 1: 1 untuk taruhan mereka (meski bank mengambil komisi 3% daripada kemenangan Anda). Bila Dikau cuma mempunyai jumlah kartu yang serupa, putaran berakhir beserta kekalahan dan berlanjut di dalam permainan berikutnya.
Share this...FacebookTwitter "
"Everyone used to call Helen Tandy “the Grinch” at Christmas. She would get odd looks and long sighs from friends and family when she tried to explain that she didn’t want gifts and wouldn’t be buying any either. Christmas crackers – “a horrible waste: a bang, some tat and then it’s all chucked away” – were banned at her home. Shiny wrapping paper (which can’t be recycled) made way years ago for plain brown or newspaper, then, last December, she tried furoshiki – the Japanese art of fabric wrapping. Tandy’s artificial tree will next month be wheeled out for its 31st Christmas, and will be decorated from a carefully stored box of decorations handmade or collected, one by one, over the years. “I didn’t want to get to the end of Christmas Day and look around and feel like we’d made a week’s worth of waste in just a few hours,” says Tandy. “I couldn’t stomach it.”  Tandy, 50, works as an ethical financial adviser in Chester and lives with her husband and 22-year-old son. Eight years ago, she quit her job in mainstream banking and audited her life against her impact on the planet; she now runs sustainability workshops as a climate ambassador for the Women’s Institute and a Friends of the Earth co-ordinator, “Back then, people thought I was weird, but now they’ve started to engage and talk differently. More people understand why it’s not right for Christmas to become a consumerist nightmare. I’m not religious at all but the pandemonium of sales and buying things for the sake of buying something goes against what the festive season is all about.” It’s safe to say that her husband and son weren’t fully on board when Tandy first started scaling back on what she considered unnecessary waste. “I’ve dragged everyone along with me and in some ways they were kicking and screaming to start with, but they’ve come to realise that we need less stuff and more time together. When I buy presents now, they’re experiences, not objects”. A Tandy-style family Christmas – more sustainable, less wasteful and better for the environment – might have seemed anachronistic or simply mean a few years ago but there are signs that many more families will be opting for an eco-friendly Christmas this year. Activists behind Buy Nothing Day and Green Friday, which both encourage supporters to spend nothing and celebrate sharing and mending instead, are mounting a direct challenge to the rampant commercial frenzy of this week’s Black Friday. But can a growing backlash against buying really make a difference? “It’s more about a personal sense of relief,” says Léon Pearce, a 28-year-old sound engineer who lives with his musician wife, Rebecca Hawley, in Liverpool. Opting out and “not buying stuff I don’t really need” puts him more at ease with his conscience, he says. “It’s as if something quite negative has just gone from my life.” The couple are embarking on their first Buy Nothing Christmas this year. “I haven’t always been anti-consumerist,” he says. “Until six months ago I was quite a clothes addict. I justified it to myself by never buying fast fashion and choosing more expensive stuff that would last a few years. But now I don’t care so much about the latest clothing or trends, and I have much more money. I do miss browsing around shops looking at nice things, but just not enough.” For their first Christmas together, four years ago, Pearce says he bought his wife lots of gifts. “All the presents were of a certain type. They probably weren’t things that would get thrown away as that’s never been my vibe, but it’s definitely going to be different this year. It sounds really cheesy but the main gift is being together and committing to not working, because we both work a hell of a lot. Ours are the sorts of jobs that take up your life rather than nine to five, so it’ll be phones off and laptops off for a couple of days, That’s more than enough.” Pearce has been inspired in part by his involvement with Extinction Rebellion and a growing distaste for unsustainable consumption of “stuff”. “We both stopped buying from Amazon a few months ago, which was a new challenge, and I consciously began boycotting Black Friday three years ago. We always used to take advantage of Black Friday for work – buying audio and musical equipment, microphones and gadgets and that sort of thing.” The couple have urged friends and family not to buy them anything or, “if they really must, it has to be something edible or a bottle of wine we can all share rather than something wrapped in plastic wrapped in wrapping paper”. Not having children, Pearce admits, makes having a green Christmas much easier. “The youngest person we would normally buy a gift for is 12, and in some ways he’s the most supportive of what we’re doing. He understands it.” According to a study by waste management company Biffa, the UK creates 30% more waste than usual over Christmas. This includes an estimated 227,000 miles of wrapping paper and 114,000 tonnes of plastic packaging. Retailers may well not welcome this shift. November and December traditionally account for over 20% of total annual sales, and as a British Retail Consortium spokesperson says, 2019 has been “an incredibly challenging year” on and offline. Sales growth in the past 12 months has fallen to its lowest ever level – just 0.1%, compared with 2.8% a decade ago. The BRC put the blame on “weak consumer demand” reportedly propelled by “Brexit uncertainty” rather than the anecdotal view that Brits have simply reached “peak stuff”. Maud Barrett, 36, a textile artist originally from Paris who now runs a social enterprise in south London teaching DIY and crafting skills, says it is becoming clear that “wasteful accumulation of things” can’t be considered the norm for much longer. “It’s a pressure,” she says. “It has an impact on your wellbeing. We’re so much happier since we stopped just buying things: it really helps not having the worry.” This year she, her husband and their three-year-old daughter and 10-year-old son will be trying to minimise the family’s carbon footprint by celebrating their second secondhand Christmas. It hasn’t always been easy. “Both my kids want stuff,” she admits. “But both of them are very aware of my ideals of life and how I want us to be as a family so they do understand. They’re not always happy but, well, they understand and my husband is also more on board.” Barrett’s growing unease with mass consumerism was sparked by a period of living in the Middle East. “We were there for four years for my husband’s job,” she says, “and had no real contact with nice independent shops or places that could make a difference with sustainability. I was so annoyed about the amount of waste we created – like buying bottles of water every day – and the lack of choice we had, that I promised we would change our habits hard and fast when we moved back to London.” This year, she says there will be “one or two” presents for the children – her daughter wants Barbies and her son wants an XBox – but none of them will be box fresh from the shops. “My partner won’t necessarily get anything until I address an actual need that he has – it could be something boring like work shirts – and he will now apply the same rules for me. I don’t want something for the sake of it: that doesn’t make me happy.” Instead, Barrett says, they have built family traditions that “aren’t about things: things don’t make people happy”. Their traditions, she says, make the most of the most luxurious commodity of all: time together. “We arrange a few weekends where we do crafts as a family – we make decorations like baubles and collages, or the children make toilet roll decorations. I look for ideas on Pinterest, but it’s about creating memories, doing things together that they look forward to.” Despite this, market researcher Mintel predicts that Britons will still spend £48.7bn this December, an increase of 3.8% on the same period last year. Matthew Sparkes, a sociology lecturer at Cambridge University, says that though qualitative evidence may be scant, his hunch is that “environmentally aware consumers are going to be a middle-class phenomenon at this stage. People who have the capacity to engage in countercultural consumerism by making their own presents and so on will have a different outlook and social network.” Sparkes points out that consumer credit in the UK is higher than at any time in history, which suggests that it will be some time before ethical consumption makes a significant dent in the UK’s Christmas economy. “Class undercuts all aspects of consumption, he adds. “Someone with very limited social resources will feel very different social pressures: they will want their kids to fit in. Having the option to opt out [of shopping] is a luxury in itself. If you’re on a zero-hours contract, you’re not necessarily thinking about sustainable consumption. The pressures are so different and are underpinned by the structural issues that drive consumption.” That the health of the nation is considered to be shaped by its economy and how much its people spend is one factor, says Sparkes. That consumption – be it mindlessly acquisitive or mindfully guilty – shapes individual identity is another. In this sense, buying lots or deliberately buying very little at Christmas can both become ostentatious signifiers of class. It’s easier to forgo presents when one already has a considerable level of comfort and disposable income. Tandy agrees. In her opinion, a change at government level is needed for there to be a significant swerve in public opinion. “I feel quite sad going through the town centre [in the run-up to Christmas]. I think about the people who go into debt at Christmas for the sake of two or three days because they feel this overwhelming need to be like everyone else. And all this stuff is pushed on you so much. For instance, I used to be very aware of the car I drove: it was a status symbol. I thought it was stuff that made a person – the car you drove, the house you had – and over time I realised it isn’t. It’s the people you’re with – your friends and family – that counts.” Shiny wrapping paper that doesn’t hold its shape when scrunched into a ball isn’t recyclable. Switching to plain brown paper or newspaper fastened with ribbon and string rather than sticky tape and plastic bows is one way to reduce waste. Wrapping presents in lengths of fabric, following furoshiki (the traditional Japanese art of wrapping items in decorative cloth), is another option that is growing in popularity. Research shows that experiences provide more lasting happiness than objects – and so a gift of tickets to a show, paying for a course or activity, a Netflix subscription or membership of the National Trust might be another option. An estimated 6 million real Christmas trees end up in landfill each year. Many local authorities run recycling schemes, where they collect the trees and turn them into woodchip or compost for parks. This is an improvement, but it’s worth looking out for tree recycling and tree rental schemes, where trees are hired out for Christmas then replanted. "
"By continuing to delay significant reductions in greenhouse gas emissions, we risk handing young people alive today a bill of up to US$535 trillion. This would be the cost of the “negative emissions” technologies required to remove CO₂ from the air in order to avoid dangerous climate change.  These are the main findings of new research published in Earth System Dynamics, conducted by an international team led by US climate scientist James Hansen, previously the director of NASA’s Goddard Institute for Space Studies. The Paris Agreement in 2015 saw the international community agree to limit warming to within 2°C. The Hansen team argue that the much safer approach is to reduce atmospheric concentrations of CO₂ from the current annual average of more than 400ppm (parts per million) back to 1980s levels of 350ppm. This is a moderately more ambitious goal than the aspiration announced in Paris to further attempt to limit warming to no more than 1.5°C. Many climate scientists and policymakers believe that either the 2°C or 1.5°C limits will only be possible with negative emissions because the international community will be unable to make the required reductions in time.  The most promising negative emissions technology is BECCS – bioenergy with carbon capture and sequestration. It involves growing crops which are then burnt in power stations to generate electricity. The carbon dioxide produced is captured from the power station chimneys, compressed, and piped deep down into the Earth’s crust where it will be stored for many thousands of years. This scheme would allow us to both generate electricity and reduce the amount of CO₂ in the Earth’s atmosphere. BECCS has important limits, such as the sheer amount of land, water and fertiliser required to satisfy our energy demand. Perhaps more importantly, it doesn’t exist at anything like the scale required of it. Thus far only small pilot projects have demonstrated its feasibility. Other negative emissions approaches involve fertilising the ocean to increase photosynthesis, or direct air capture which sucks CO₂ out of the air and converts it into plastics or other products.  The Hansen team estimate how much it will cost to extract excess CO₂ with BECCS. They conclude that it would be possible to move back to 350ppm mainly with reforestation and improving soils, leaving around 50 billion tonnes of CO₂ to be mopped up with negative emissions technologies (the plants grown for BECCS take in the CO₂, which is then sequestered when burned).  But that’s only if we make significant reductions in rates of emissions right now. If we delay, then future generations would need to extract over ten times more CO₂ beyond the end of this century. They estimate costs between US$150-350 for each tonne of carbon removed via negative emissions technologies. If global emissions are reduced by 6% each year – a very challenging but not impossible scenario – then bringing CO₂ concentrations back to 350ppm would cost US$8-18.5 trillion, spread over 80 years at US$100-230 billion a year.  If emissions remain flat or increase at 2% a year, then total cost balloons to at least US$89 trillion and potentially as much as US$535 trillion. That’s US$1.1 to US$6.7 trillion every year for eight decades.  To give these numbers some context, the entire US federal budget is about US$4 trillion, while annual spending by all countries on military and defence is US$1.7 trillion. Humans have pumped over 1.5 trillion tonnes of CO₂ into the atmosphere since 1750. It is not just the amount, but the rate at which this CO₂ has been added.  The oceans can absorb extra CO₂ but not fast enough to remove all human inputs and so it has been progressively building up in the atmosphere. This extra CO₂ traps more heat than would otherwise escape out into space. More energy is therefore entering the climate system than leaving it.  Over decades and centuries the climate will move back into balance with the same amount of energy leaving as entering. But this will be at a higher temperature with among other things less ice, higher sea levels, more heatwaves, and more floods. The last time the Earth’s climate experienced such an energy imbalance was the Eemian interglacial period some 115,000 years ago. At that time global sea levels were six to nine metres higher than today.  The Hansen team argues that even maintaining the current energy imbalance risks locking in several metres of sea level rise. That is because slow processes such as melting ice sheets still haven’t “caught up”. The longer the climate is held out of balance, the greater their effect will be. One argument against making drastic cuts to greenhouse gas emissions is that it will harm economies as our industries are still largely fossil fuelled. Responding to climate change needs to balance the desire to continue to grow economies today with avoiding disastrous climate change or prohibitively expensive remedies tomorrow.   Whatever assumptions you make about economic growth, or however much you discount future costs, it’s unimaginable that US$535 trillion could be afforded. While these costs will be spread over 80 years, this will also be a period in which the global population will increase from seven billion to perhaps 11 billion and beyond. Humanity will need to grow enough crops to feed these billions while fuelling BECCS schemes at a time when climate change will already be impacting food production. There are also no guarantees that BECCS or any other negative emission technologies will actually work. If they fail then large amounts of CO₂ could be released very rapidly with disastrous consequences. By delaying significant carbon emission reductions we risk handing both an impossible financial and technological burden to future generations. Our children and grandchildren may be unable to understand how we negotiated such an arrangement on their behalf."
"In 1707, a Jesuit missionary from what is now the Czech Republic named Samuel Fritz published one of the first detailed maps of the Amazon River. Fritz spent much of his life in the region and his map names and locates (often incorrectly) many of the Amazonian forest peoples he encountered. In this sense, his map helped tie them to certain places, and to particular colonially-defined identities.  While Fritz was mapping out the Amazon, other Europeans were hard at work in tropical forested countries across the globe, drawing up boundaries that ignored and criminalised forest peoples’ customary rights to live in their ancestral territories.  Maps have always been part of the imposition of power over colonised peoples. While map-making might be thought of as “objective”, it is fundamentally political, a necessary part of controlling a territory. Maps inscribe borders, which are then used to include some and exclude others. During a late 19th-century rubber boom, Amazonia became increasingly well mapped out as the young nations of Peru, Bolivia, Brazil and Colombia vied for territorial control. The rights and interests of Amazonian peoples were never included in this process and they would be continually denied rights, recognition and citizenship from these nations until the 1980s and 1990s. Even following legal recognition, their territorial rights – critical for their continued existence – are still often ignored in practice. These marginalised people are now working together to reclaim the process of mapping itself. In the central Brazilian Amazon there has been a recent flurry of “counter-mapping”, used by forest peoples to contest the very state maps that initially failed to recognise their ancestral territorial rights. Counter-mapping first came to prominence in the 1990s, when it was particularly influential in Indonesia. Back then, it was rudimentary and new maps were produced by hand. Today, communities have access to GPS and smartphones and are able to walk along trails marking out their territorial claims.  In Brazil counter-mapping falls under the wider term of “auto-demarcation”, which also includes various other forms of territorial monitoring that would normally be carried out by the state. The goal is to safeguard the integrity of territory, defined as much more than just land (schools, for example, are one stated objective).  In Brazil, recognition of forest peoples’ territorial rights can take decades. The government, acting in the interest of rural elites, is currently attempting to roll back these rights.  The Munduruku people of the middle Tapajós river, a southern tributary of the Amazon, provide the most iconic example of counter-mapping. The auto-demarcation of their ancestral Sawre Muybu territory is part of a wider Munduruku political movement Ipereğ Ayũ against dam construction and industrial mining on their land. Neighbouring riverine peasants who self-identify as “the Beiradeiros,” are counter-mapping their community of Montanha-Mangabal to resist land grabbing, illegal mining and logging. The Beiradeiros and the Munduruku have passed from being enemies to allies through joint political action against major proposed hydroelectric projects and now work together to auto-demarcate their respective territories. But can counter-mapping really liberate these communities? Research on counter-mapping in Nicaragua and Belize in the 1990s and 2000s shows it did result in the recognition of indigenous land rights. But land can’t fix everything. Even reclaiming their land couldn’t free indigenous peoples from colonial social relations. State-indigenous relationships continued to be oriented around property rights, the basis of modern politics.  Counter-mapping can also be ineffective. In the Chaco region of Bolivia, years of stalled land titling led some Guaraní indigenous people to give up on state recognition of their territory. Instead, they signed an agreement with Repsol, a Spanish oil company, which acknowledged their property rights. Despite this having no legal standing in Bolivian law, the Guaraní saw an agreement with an oil company as better than a state land title. In central Brazilian Amazonia, however, auto-demarcation has in some cases forced the government to act. For instance, the Munduruku have gained official recognition of their territory, Sawre Muybu. Auto-demarcation then can be understood as a combative form of dialogue with the state, of struggle for access to territorial rights, much more than just the materialisation of these rights.  The indigenous peoples of the middle and lower Tapajós are now considering the links between their struggles and those of the Zapatista movement in southern Mexico, where auto-demarcation was used as part of reclaiming their sovereignty.  The degree of political agency and empowerment that Amazonian forest peoples acquire through the process of auto-demarcation is striking. Independent of whether it leads to state action and guarantees of territory, this is an important achievement."
"Angus Taylor has scheduled a discussion with state and territory energy ministers about the planned overhaul of the Morrison government’s emissions reduction fund, a move following the government’s decision to quietly appoint an expert panel to come up with new ways to cut greenhouse gas emissions. According to the draft agenda for Friday’s Coag energy council meeting, obtained by Guardian Australia, the commonwealth has scheduled a discussion about the $2.55bn ERF, now rebadged the Climate Solutions Fund, at the long delayed meeting of federal and state energy ministers. Ahead of Friday’s meeting, the first in nearly 12 months, Taylor has signalled he wants to pursue a series of deals with the states to roll out new generation and transmission – an approach that has followed the Morrison government’s decision to ditch the national energy guarantee (Neg). The Neg was a casualty of the federal Liberal party’s leadership eruption last August. The Coalition initially faced pressure from some of the Liberal state governments, including New South Wales, to revive the Neg, which was supported by most stakeholders in the energy sector. But with Canberra refusing to reboot the Turnbull-era policy mechanism that combined reliability standards and emissions reduction for electricity, the states have in more recent times pursued a plan B, giving Canberra specific wish lists of projects they want assistance with. Taylor has not ruled out the side deals including direct assistance for emissions reduction in the states, and the Morrison government has been quietly pursuing an overhaul of the ERF, appointing a panel of four business leaders and policy experts to suggest options to expand it. The conversation at the Coag meeting on Friday is expected to seek state and territory buy-in for the planned overhaul of the fund, which has been heavily criticised for failing to deliver substantial emissions reduction from the industrial sectors of the economy. It is likely the states will want cash from the fund to drive abatement in their jurisdictions. Sign up to receive the top stories from Guardian Australia every morning A discussion paper flagging the ERF overhaul, first reported by Footprint, says the fund has been successful in generating carbon offsets from native vegetation and landfill projects, largely because they cost relatively little and do not require businesses to make substantial operational changes. But it says the scheme has done little to cut emissions through energy efficiency projects and from industry, agriculture and transport, in part due to high upfront and transaction costs. The emissions reduction fund works as a reverse auction, rewarding landowners and businesses that make cheap, viable bids for taxpayers’ support to cut pollution. The most recent auction bought emissions cuts equivalent to only 0.01% of Australia’s annual greenhouse gas pollution after officials found just three projects worth backing. The paper says the government is looking at ways to attract more participants from industry and agricultural businesses. Stakeholders report there is a diversity of views within the reviewing panel, headed by Grant King, the outgoing president of the Business Council of Australia and a former chief executive of Origin Energy, about how to refashion the scheme, and the process is operating on a tight timeframe. Ahead of Friday’s meeting, Victoria has asked the Morrison government to fast-track work on the KerangLink – a transmission line increasing power transfer capability between the Snowy area and Melbourne. The request from Victoria follows a similar pitch from the NSW government, which has asked Canberra to underwrite new generation to replace the Liddell power station, and either underwrite or de-risk new investments in transmission that have been highlighted as urgent by the Australian Energy Market Operator. The side deal with NSW is understood to be close to sign-off. South Australia has not telegraphed its wishlist publicly, but says it will pursue options for expanding the state’s abundant renewable energy resources in ways that deliver more affordable and reliable power to consumers. But the ACT has expressed alarm about the current trajectory. The ACT’s energy minister, Shane Rattenbury, says the Morrison government should be implementing a coherent national plan to secure Australia’s energy future rather than cutting a series of deals with states it regards as friendly. Rattenbury has also expressed concern that ministers at Friday’s meeting of the Coag energy council will be herded into a decision about hydrogen that will be “a backdoor means of propping up the coal sector”. Friday’s agenda includes a briefing from the chief scientist, Alan Finkel, on the national hydrogen strategy and governance. Victoria has also sought and scheduled a discussion about a review of the reliability standard, which Taylor supports."
"
Share this...FacebookTwitterOnline weather site www.wetter24.de here today writes about the devastating Heinrichflut (Heinrich Flood) of 1965, back when CO2 was only 320 ppm, well below the often claimed “safe” level of 350 ppm that some alarmists like to have us think would bring us much less extreme weather.
Worst flood in the region’s collective memory
In 1965 the spring and early summer had been cool and wet. In the early afternoon on Friday July 16, 1965, in the central German region between Paderborn, Kassel and Gottingen, the skies darkened quickly and torrential rains fell. Within a matter of hours large areas became submerged under water. Rivers and streams swelled and swept houses, livestock and property away. 16 people were killed. It was the worst flood in the region’s centuries-long collective memory. Had the storm hit during the night, the loss of life would have been far worse, experts say.
The following aerial photos were taken the next day and show the aftermath of the July 16 flood:

Bad Karlshafen. Source: here.

Eberschutz. Source: here.

Imarshausen. Source: here.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





 Karlshafen. Source: here.
Cold air trough formed between two air masses
What caused the freak weather of 1965?
According to Wikipedia in mid July 1965 a mass of warm air flowed northwards from the subtropics and collided with cold Arctic air flowing down from Scandinavia. On the backside of the warm air mass over northern France a so-called cold air trough formed and led to the warm becoming completely surrounded by the cold air. The warm air lifted above the cold air mass, leading to severe thunderstorms and torrential precipitation. The region’s hilly terrain and river valleys served to exacerbate the situation.
200 mm in 24 hours
In an area between Paderborn and Kassel and Fritzlar precipitation amounts of 100 mm fell in just 2 hours. In other areas between July 14 and July 17 up to 200 mm of rain fell in 72 hours. In Dalheim alone over 200 mm fell in 24 hours.
What does all this mean? It means that freak weather events are also common in times of low atmospheric CO2 concentrations and “global cooling”. It all gets down to weather and not climate. Weather catastrophes are not going to be prevented by practicing “green” rituals and CO2 voodoo.
Despite alarmist claims that weather extremes are becoming more frequent, objective observers see no trend change in extreme weather events in Germany or world wide.
Sources:
https://de.wikipedia.org/wiki/Heinrichsflut
http://www.wasserverband-diemel.de/historisch.php
https://www.youtube.com/watch?v=8b9Y8YyOd1E 
Share this...FacebookTwitter "
"In a remote corner of far-western Brazil lies the Vale do Javari, home to one of the greatest concentrations of isolated or entirely “uncontacted” tribes in the Amazon. Unlike indigenous lands elsewhere in the country, which have been colonised and polluted, the Javari’s very inaccessibility has kept it largely untouched. But the people who live there remain extremely vulnerable. Recently, illegal gold miners in the region were alleged to have boasted of a brutal mass murder of ten members of an uncontacted tribe.  The allegations emerged a decade after the UN General Assembly adopted its Declaration on the Rights of Indigenous Peoples (UNDRIP) on September 13, 2007. The declaration was a result of decades of tireless campaigning by indigenous activists across the world, yet ongoing horror stories of abuses deep in the Amazon show how far countries like Brazil still have to go. The UNDRIP affirms indigenous people, as a collective or as individuals, must enjoy the same human rights as everyone else. It also says they must give “free, prior and informed consent” regarding the use of traditionally held land or resources. A vast majority of states voted in favour of the declaration, with just 11 abstentions and four votes against (Australia, Canada, New Zealand and the US), and it today remains the most comprehensive international instrument on the rights and status of indigenous people. In the decade since UNDRIP was adopted all four of the initially opposed states have now expressed their support, as have two of the abstainers, Colombia and Samoa. Indigenous groups have used it as a framework to successfully challenge their treatment by states and even corporations. Activists themselves speak of another unanticipated outcome of the UNDRIP negotiation process: the growth of a well-connected global indigenous movement. Yet, as with all UN declarations, UNDRIP is non-binding. And this inevitably means big delays in transforming international standards into local laws – never mind actually enforcing those laws. Brazil is a good example. The country’s constitution, written following its transition from dictatorship to democracy in the 1980s, gave indigenous people various legal and political rights. Brazil also signed UNDRIP and the earlier International Labour Organisation Convention on Indigenous and Tribal Peoples, which demands respect for the culture, spirituality, social and economic organisation of these groups. But the state is still repeatedly accused of mistreatment and human rights abuses, particularly in relation to land. In 2016, the UN’s special rapporteur on the rights of indigenous peoples went to Brazil and found “a disturbing absence of progress” and, in some areas, “a worrying regression”. Although the government has rejected these particular observations the recent alleged massacre would indicate that much more needs to be done to protect, respect and empower indigenous Amazonians. The Fundação Nacional do Índio (FUNAI), the government body tasked with monitoring and protecting indigenous groups, has an unusual history. Created in 1973 as a predecessor to the discredited Indian Protection Service, the foundation’s original aim was to assimilate indigenous communities into the Brazilian mainstream so that the resources of the Amazon region could be more effectively harnessed for economic growth by the military regime. But after staff witnessed the death and dispossession associated with the vast trans-Amazonian highway project, its objectives were altered to reflect a growing concern with protection and preservation rather than assimilation.  Today, FUNAI’s role includes safeguarding remote indigenous territory from would-be farmers and miners. Groups under its jurisdiction include more than 100 uncontacted tribes who, as Survival International point out, are among the most vulnerable peoples on the planet. Their protection poses a very particular set of challenges. A brutal history of disease and violence shows that leaving them alone is necessary for their very survival, yet their unique isolation also means they can’t participate in the political system or access any means of judicial redress.  However, in the face of soaring public debt, the Brazilian government slashed FUNAI’s budget in 2016, forcing it to shut down many of its regional offices. The cuts have been overseen by conservative president Michel Temer, who currently holds a mere 5% approval rating, and they have been hastened by the presence of a dominant right-wing voice in congress. Both president and congress stand accused of pandering to the interests of a wealthy agri-business lobby that is committed to dismantling FUNAI together with an array of environmental protections that limit agricultural and extractive activities in the Amazon. With Brazil’s main opposition, the Partido dos Trabalhadores (Worker’s Party) still mired in an epic corruption crisis, a heavier burden falls on federal prosecutors and civil society to ensure the state honours both its legal and moral obligations in the area of indigenous peoples’ rights. Although the past year has seen a notable rise in domestic mobilisation by indigenous activists, it is not clear how effective this has been: recent protests in Brasilia over land reforms were met with rubber bullets and government inaction. As the alleged massacre in the Vale do Javari shows, Brazil’s uncontacted tribes may be protected by a UN declaration in theory, but in practice they remain very vulnerable."
"You will not be surprised to learn that the climate crisis is a big and complicated problem. But when I started Not Cool, a Climate Podcast, I honestly hoped that if I could just talk with a few climate experts, we could clarify the facts and outline straightforward solutions. Thirty-one experts and 26 interviews later, I realize how mistaken I was, with more questions now than when I started. But I’ve also learned some amazing facts about how nature works, how humans work, and how to start addressing this crisis.  Zoning laws might seem inconsequential, but they can also save lives. The deadly fire in Paradise, California, and the flooding from Hurricane Harvey were as much about lax zoning laws as they were about extreme events caused by climate breakdown. Regardless of how quickly we bring down our emissions, we have some warming already locked in, which means there will be more fires, hurricanes and rising sea levels. Zoning laws help people stay safe in more extreme and frequent disasters. Integral to our zoning laws are the building materials we use. Cement, for example, accounts for approximately 8-10% of all global carbon emissions. Roughly half of those emissions come from the carbon removed during the process of making cement, while the other half result from the energy required to make cement. Steel poses similar problems. Ironically, these carbon-emitting materials are often used in climate change adaptation solutions like sea walls. Fortunately, nature provides incredible tools for addressing and adapting to climate change. Mangroves – essentially forests that grow along coastlines – are near magical solutions that came up in multiple interviews. They help prevent erosion and protect coastal regions from waves and rising sea levels. The trees are a haven for biodiversity, which could be partly why coral reefs seem to thrive in their presence. And mangroves also sequester a lot of carbon, which can help address both global heating and ocean acidification – an effect of the increased carbon in the oceans. Our oceans take in a shocking amount of carbon – about 25% to 30% of all emissions. We can thank our oceans for ensuring that climate breakdown isn’t worse, but that also means that ocean acidification is a huge problem, especially in polar regions where the colder water absorbs more gas. Though some people hope technical solutions like geoengineering could help address global heating, these won’t help ocean acidification. There are two types of geoengineering, more accurately known as climate engineering. One highly contentious method involves injecting particulates, such as sulfur aerosols, into the sky to minimize solar radiation and decrease temperatures. The problem with this approach is that if countries disagree about optimal global temperatures, we can’t just suddenly stop the geoengineering systems, as this would cause global temperatures to rise quickly and dramatically. But if left unaddressed, serious international disagreement could lead to war. The other – far less contentious – geoengineering option involves pulling carbon out of the atmosphere. Though technologies for this exist, they’re not yet affordable or scaleable. But nature could again help here, as more forests could absorb more carbon, cooling the Earth. The Amazon rainforest is not the world’s lungs; it’s our sweat glands. Most of the oxygen we breathe actually comes from marine organisms like phytoplankton (another reason to be grateful for oceans). Instead, forests are useful because they pull moisture from the soil and expel it through their leaves, cooling the Earth just as sweat cools our bodies. So not only are forests vitally important for reabsorbing the carbon we emit, they also decrease temperatures. Unfortunately, many forests – especially the Amazon – face deforestation. Some researchers fear that if even 25% to 30% of the Amazon rainforest is cut down, the loss of moisture could change its basic makeup, transforming it from a rainforest to a savanna. This threat remains speculative, but is it possible we’ve already passed other critical tipping points? Climate systems like to be in equilibrium. If we push them out of equilibrium, past their tipping points, we could trigger feedback loops and exacerbate global warming. For the most part, these are considered future threats, so it was disconcerting to learn that we may have already tipped the West Antarctic Ice Sheet into a state of irreversible melting. If that’s the case, we can expect ocean levels to rise even more than predicted with current warming levels. On the other hand, many of the experts I spoke with also hope we may be on the verge of a human tipping point. As many pointed out, past cultural shifts happened slowly, then suddenly. If climate crisis awareness and concern increase at their current pace, we may yet be able to make the changes necessary to ward off the worst climate threats. Perhaps one sign that we’re nearing a human tipping point is the incredible scientific consensus surrounding climate change. I didn’t formerly care that 97% of climate scientists agree about climate change. I cared about the actual scientific studies that clearly show the Earth is warming. But consensus is more relevant than I realized. First, this level of scientific consensus doesn’t occur unless the science is really robust. Second, most people don’t have time to read all of the science. They have to put their trust in experts, and when 97% of experts say something is true, the public typically listens. The problem is that many people don’t realize how strong climate consensus is. Talking about the climate crisis can have a powerful impact. Just talking more can help address confusion about climate facts and help us all realize that public consensus regarding climate change is quite broad. This doesn’t mean quoting climate science to your conservative uncle at a holiday dinner. You could have a conversation about the money you saved by getting an electric car or bike, or that you want solar panels because they make you more self-sufficient and will save you money in the long run. Looking for another easy way to address the climate emergency? Talk to your bank. Many banks help fund the fossil fuel industry, and if yours is doing so, you can switch to a bank or credit union that doesn’t. As an individual, you can and should vote – but while we wait for better climate policies, moving your money could be one of the most impactful actions you can take to de-fund the fossil fuel industry. Fun statistic: people are more likely to leave their spouse than their banks. Perhaps the most important thing to know about the climate crisis is that solutions exist. It is political will we lack. Many people worry about convincing climate deniers that climate breakdown is real, but deniers make up a very small percentage of the population. Our real focus should be on convincing those in power that the majority of us want to see strong political action. That happens when we talk to each other, when we talk to our representatives, and when we talk to our financial institutions. Individual climate action is critical, but this is ultimately a societal problem, and the solution must be societal as well. Ariel Conn is the host of Not Cool, a Climate Podcast, the former director of communications and outreach for the Future of Life Institute, and the founder of Mag10 Media, an organization dedicated to improving science communication"
"
Share this...FacebookTwitterRainer Hoffmann of the German language Klimamanifest has produced a short clip on the 2°C target we keep hearing about.
According to activists the globe mustn’t be allowed to warm up more than 2°C over its 1900 level, otherwise it will tip into an irreversible and unstoppable spiral to climate catastrophe that will lead to “the end of civilization as we know it”.
Many of us have been misled to believe that the 2°C was established by leading climate scientists and even made to “international law” that now has to be strictly adhered to, and that CO2 emissions must start falling by 2020. Prof Hans-Joachim Schellnhuber (0:18 mark), Director of the ultra-alarmist Potsdam Institute for Climate Impact Research, for example, claimed on German public television on July 3, 2011, that the 2°C target indeed was “international law” and that CO2 emissions needed to start falling by 2020 if humanity was to have any chance of reaching the 2°C target.

But these are two patented alarmist falsehoods. Don’t take it from me, but from the climate scientists themselves.
On December 3, 2014, Schellnhuber admitted that the 2°C target was not international law (0:53) and then postponed the year CO2 emissions would have to start dropping by an entire decade, to 2030. Suddenly we got goalposts that were not international law and had been moved out another 10 years.
2°C target is purely political
On the question of: Is the theoretical 2°C target a scientific one? The answer to that question is also a definite “no”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On February 2, 2010, Prof. Dr. Christian Schönwiese (1:27) told FAZ journalist Christian Bartsch on German public television:
They formulated a 2°C target. It is not from a climate scientist, or a physicist, or a chemist, but from an outside person who simply plucked it out of thin air and said ‘2°C'”
Bartsch asks Schönwiese rhetorically:
“So it’s no scientific target?”
Schönwiese acknowledges: “Right.”
At the 2:03 mark of the video, Prof. Hans von Storch in a speech he made in January, 2011 confirmed Schönwiese:
We are in a time where scientists and politicians claim, or at least suggest, the science, in the form of the IPCC, or the German Advisory Council on Global Change (WBGU), has shown that the 2°C target is scientifically mandatory, and is thus no longer a political question that has to be negotiated by society, but rather a target that policymakers only must execute – quasi an order. However the IPCC has never in any way presented the 2°C target as mandatory. Rather this was done by a few scientists, or shall I say: politicians disguised as scientists.”
 
Share this...FacebookTwitter "
"As four reactors at the Fukushima Daiichi Nuclear Power plant suffered catastrophic cooling failures and exploded in March 2011, the world watched in disbelief. For Japan, this was not just the greatest nuclear disaster since Chernobyl. It was “the most severe crisis … since World War II.”  Five years on, the nation continues to struggle with the effects. Towns up to 40km from the plant remain a dead-zone: desolate and uninhabited. As many as 100,000 people still remain displaced, unable to return to their homes. Workers at the Tokyo Electric Power Company (TEPCO) still don claustrophobic masks and rubber suits to venture into the Fukushima facility. Their job is to decommission the plant safely, a task that plant manager Akira Ono recently said was “about 10% complete”. The task is beset with setbacks and spiralling costs. In December 2011 the government estimated that managing Fukushima would cost US$50 billion. By 2014 this had nearly doubled to include US$19 billion to decommission the Fukushima plant; US$22 billion to decontaminate the surrounding area; US$9 billion to build temporary storage facilities for nuclear waste; and US$43 billion to compensate the victims. Today even this looks hopelessly optimistic.  Fukushima is now the biggest civil liability case in history. More than two million people have sued TEPCO and US$50 billion has already been paid out. This is already equivalent to 49 Exxon Valdez oil spill settlements, and experts predict the total cost of compensation could rise to US$120 billion.  One notable subplot has been compensation for cases of suicide. A court’s landmark decision that TEPCO pay US$470,000 to the heirs of a 58-year-old farmer’s wife named Hamako Watanabe could prove much more costly. The Watanabe family were evacuated from the village of Yamakiya in April 2011, losing their farm and leaving them with a US$140,000 mortgage on their now uninhabitable home. Watanabe became severely depressed and during an authorised one-night visit to their home in June the same year, she burned herself to death.  Other bereaved families have also come forward. Two similar cases are now underway, and the Japanese government anticipates that as many as 56 suicides could be tied to the disaster. And this looks conservative: the NHK broadcasting service has put the number at 130. What is certain is that the number is rising. A further 19 evacuees took their lives in 2015 and there is no reason to believe 2016 will be any different.  Officially the buck for everything stops with TEPCO. Under Japanese nuclear-liability law, the nuclear operator is responsible for the full cost of an accident, even if it is not proven to be negligent. In practice, the Japanese taxpayer is bearing most of the burden. TEPCO’s liability may be unlimited, but its assets are not. Despite the country’s seismic history, TEPCO’s private insurance policy did not cover earthquakes or tsunamis. And in accordance with regulations introduced in 2009, TEPCO was insured through private policies and state indemnities for up to only US$1.1 billion: about a fiftieth of the damages paid out so far.  The government has been forced to prevent TEPCO’s bankruptcy – over and above all of its other Fukushima-related outgoings. It has bought a majority share and has continued to finance compensation payments through a series of indemnity agreements and loans in the form of government compensation bonds. The state has also enacted retroactive legal guidelines that obligate other power companies and financial institutions to contribute to the compensation effort.  One has to ask whether the concept of unlimited liability has any real meaning when the operator’s capacity to pay is so limited. It also raises questions for other parts of the world. In the UK, for example, nuclear liability is capped at a mere US$220m, less than two hundredths of what TEPCO has already paid in compensation claims. Japan is evidently not the only country that should be taking lessons from Fukushima. The article originally said that the TEPCO payouts to date are 400 times that of Exxon Valdez, as opposed to 49. It also said that the dead zone around the plant was 10km, but now says 40km."
"Donald Trump has done many things to tarnish America’s reputation, but his decision to walk away from the Paris Agreement is probably the most internationally symbolic and damaging. That a US president can put climate change denial at the centre of his climate and energy policy is truly unprecedented, and it is difficult to remember an administration that has been so intent on undermining the intellectual and scientific findings on global warming. Fighting back against Trump’s climate folly seems to be an uphill task. Even the impending publication of the Climate Science Special Report, drafted by scientists from 13 federal agencies, is unlikely to do much. The final report is expected to warn of the dangers of climate change, but it will most likely be surreptitiously sidelined.  One of the reasons behind Trump’s bullish attitude might be to do with public opinion in the US. In a poll carried out by Yale University in 2016, 70% of Americans said they believed in global warming and 58% believed that it will harm Americans. However, only 40% believe that it will actually impact them individually. Furthermore, just 24% said they heard about global warming in the media every week. In a poll conducted by the Pew Research Centre this year, 76% said terrorism should be a top priority for the administration. Only 38% mentioned global warming. The polls suggest that Americans might be concerned about global warming and want more to be done about it. But they are more likely to be worried about, say, Kim Jong-un than climate change. It appears that confronting Trump – or any other climate denier – on the basis of facts simply won’t work. The challenge should perhaps be to first rally public opinion until there is an overwhelming consensus that serious and urgent action is needed. One practical short-term solution might be to shift the public discourse from “climate change” to “pollution”. Focusing on pollution has three advantages that may mean it moves public opinion better than global warming. First, pollution is tangible. The fact that glaciers are melting might be alarming but it is not something that most of us experience in everyday life. And why would a rise in temperature matter as much to someone living in Sacramento, California, where it is already hot and where one can find shelter in air conditioned buildings?  Pollution, however, can be experienced on a daily basis and causes nuisances of all sorts. The same Sacramento resident who is indifferent to global warming might be concerned with the pollution in their local urban river parkway, for instance. In addition, reports claiming that there are millions of annual deaths from air pollution have a different, more personal ring from those making the more abstract claim that “global temperatures” are rising fast. Americans also seem to be more concerned about the environment than global warming. In the same opinion poll carried out by Pew, 55% of Americans saw “the environment” as a priority, a similar score to crime or poverty (and comfortably ahead of the military, immigration or “global warming”). They seem to be more worried about the quality of air and water where they live rather than losing sleep over a global climate phenomenon.  What might also be encouraging is a poll carried out by the Center for American Progress this year which showed around two-thirds of those who voted for Trump opposed the idea of privatising or selling off America’s national forests and public lands. Whether this is a strong enough basis for there to be a rallying of the public is difficult to know. Nevertheless, focusing on the local environment is a good start. A focus on pollution might also actually open up the debate on the environment and encourage some kind of grassroot reaction. Too often the discourse on the environment and global warming has been dominated by scientific experts and politicians. As such, the public might believe that this is a matter of scientific debate that somehow they cannot participate in, without some prior knowledge. After all, what can you, personally, contribute to a debate on carbon dioxide parts-per-million, or melting glaciers? Would you even know either was a problem if scientists hadn’t warned us? By contrast, feeling the effects of environmental pollution does not require expert knowledge. The public can express remedial actions and suggestions, without having to pretend that they understand atmospheric science. Moreover, actions are more likely to be taken on a local level if the focus is on local pollution. The public should be scientists’ first ally in this battle. Any language and issues that engage people against Trump’s climate folly in whatever way should be the priority for scientists and policy makers seeking to address the problem."
"
Share this...FacebookTwitterGerman public radio Deutschlandfunk (DLF) reported earlier this year that scientists have discovered that twice as much snow has been falling in the Ural Mountains than 100 years ago.

Yugyd Va National Park. Public domain photo.
Hat-tip: Die kalte Sonne here.
The DLF reports:
Ural: snow causing the tree line to rise.
Climate change does not only mean that the temperature is increasing, it can also change the precipitation patterns. In the Ural Mountains of Russia significantly more snow is falling in the wintertime than 100 years ago. The development is having surprising consequences: The bigger amounts of snow is causing the tree line to rise. […]
In the summertime in the Urals its has not gotten notably warmer over the past 100 years. The wintertime temperatures, however, have increased from minus 18°C to minus 16°C. Warmer low pressure systems are bringing more precipitation to the mountains. In the Urals today twice as much snow is falling than 100 years ago. And that is having an impact on the treeline.”
According to the DLF, a team of German and Russian scientists say the tree line is currently rising at a rate of about 4 to 6 meters per decade.
The scientists believe that the doubled snowfall serves to protect young saplings during the winter and allow soil conditions that foster growth during the summer time. Photos of the region has allowed the scientists to determine treelines that today are up to 60 meters higher than 100 years ago.
 
Share this...FacebookTwitter "
"As urbanisation and modernisation reach unprecedented levels, road congestion has become a modern day menace. Heavy traffic is associated with air pollution, safety risks, and losses in terms of accessibility, economic competitiveness, sustainable growth and social cohesion. If we are determined to make our cities attractive and sustainable, we must respond to these challenges.  There are a number of measures available to address this problem; either by restricting conventional car use, or providing viable alternatives. None of these solutions is more up-and-coming and marketable right now than the shared use of mobility resources – for example, car sharing. And none of them more environmentally friendly than cycling, which more and more people see as a realistic way of making shorter trips.  Put these two together, and you get bike sharing: an innovation that combines the best qualities of both solutions, while extending the reach and scope of public transport. To be clear, bike sharing refers to rental schemes, whereby civilians can pick up, ride and drop off bicycles at numerous points across the city – usually at automated stations.  The benefits of bike sharing schemes include transport flexibility, reductions to vehicle emissions, health benefits, reduced congestion and fuel consumption, and financial savings for individuals.  But the most special quality of public bicycles is the idea of sharing. By sharing with others through a publicly available scheme, individuals can use bicycles on an “as-needed” basis, without the costs and responsibilities associated with ownership. In doing so, these schemes allow people who may not otherwise use bicycles, to enjoy the benefits of cycling; whether they’re tourists or locals.  Bike sharing schemes can also act as a door opener for increased bicycle use, by making a strong visual statement that bicycles do belong to a city’s streets. According to my research, commuters using on-road transport can see bike sharing as a powerful on-street “cycling promotion campaign”.  What’s more, other studies report that cycling increased in cities which implemented bike sharing schemes, noting that these results reflect the combined impact of improvements to cycling facilities, as well as the provision of bike sharing schemes. Some go even further by suggesting that the introduction of bike sharing systems can cause cycling to be seen as a safe and normal mode of transport, in contexts where it’s not common. Bike sharing is a concept originating back to the 1960s. However, it was slow to catch on until better technology was developed, which could provide real-time information about the scheme, track the bikes and help safeguard against theft.  Now, bike sharing is booming at an unprecedented rate, largely due to the reasonably low cost of the schemes, and how easy they are to implement compared with other transport infrastructure. And it’s an easy win for governments and urban societies, which can boost their green credentials by embracing such an environmentally friendly design.  In 2004, only 11 cities had adopted bike sharing. Today, more than 1,000 public bicycle schemes of varying sizes and specifications run in more than 50 countries, across five continents.  Europe’s biggest scheme is the Paris Vélib’, with 1,800 stations and more than 20,000 bikes. Hangzhou, China hosts the world’s largest system – three times bigger than Vélib’ – which is set to expand to 175,000 bikes by 2020. Perhaps the most sophisticated scheme is Copenhagen’s Bycyklen, which has a fleet of electric bicycles featuring weather resistant tablets with GPS. According to recent research into Gothenburg’s Styr & Ställ scheme, if bike sharing is properly promoted, the general population of the city feels that such schemes offer a pro-environmental, inexpensive and healthy mode of transport. In particular, they were seen to complement the city’s public transport services, and give the city a more human-friendly feel. But research and experience tell us that there can be problems with bike sharing. For example, although the usage rate of these schemes tends to vary globally between three and eight trips per bicycle per day, some facilitate as few as 0.3 trips per bicycle per day.  Apart from under use, schemes can also prove slow to expand, or come up against sluggish and complicated planning procedures. They can create political friction, too, if local authorities are unwilling to forsake street parking spaces for bike stations. Strict cycling regulations can also be a roadblock: in both Melbourne and Brisbane, Australia, compulsory helmets were found to deter many potential riders. Safety concerns and a lack of cycling infrastructure – such as bike lanes – were also found to affect uptake. Despite these difficulties, bike sharing schemes are, on the whole, a win for everyone. Rebranding something as conventional as urban cycling in a way that embraces the philosophy of shared resource economies and is well accepted by the public, is a timely investment for actively promoting sustainable transportation. Cities that come up with strong and coherent plans will find that recognisable bike sharing schemes can form a powerful and positive part of their image. Meanwhile, civilians of all stripes stand to benefit from clearer roads and cleaner air – whether they cycle or not."
"
Share this...FacebookTwitterThe last couple of days I posted on an 8.5 year side-by-side test conducted by German veteran meteorologist Klaus Hager, see here and here. The test compared traditional glass mercury thermometer measurement stations to the new electronic measurement system, whose implementation began at Germany’s approximately 2000 surface stations in 1985 and concluded around 2000.
Hager’s test results showed that on average the new electronic measurement system produced warmer temperature readings: a whopping mean of 0.93°C warmer. The question is: Is this detectable in Germany’s temperature dataset? Do we see a temperature jump during the time the new “warmer” system was put into operation (1985 – 2000)? The answer is: absolutely!
1900 to 1985: almost no warming
Josef Kowatsch, an independent scientist and regular contributor at EIKE, has looked at the German temperature dataset and discovers that Germany’s mean temperature indeed coincidentally jumped by a similar 0.9°C during the same period. First he sent me a chart depicting Germany’s annual mean temperature from 1900 to 1985, measured using the old glass mercury thermometers:

For 85 years the trend was pretty much consistent, hovering at about 8.2 or 8.3°C. As indicated by the bold black line, there was an increase from 1900 to 1935, followed by a slight decrease from 1935 to 1985, i.e. in a time when CO2 emissions were rising strongly worldwide.
1986 – 2000: massive warming
Next Josef sent me a second chart depicting Germany’s mean temperature trend while the country was transitioning over to the new electronic measuring system, described here, from 1986 to 2000:

Here we see the trend for the period rising strongly, from about 8.4°C to 9.3°C, i.e. precisely during the instrumentation transition period! This too happens to be a rise of 0.9°C, which coincides precisely with the results of the side-by-side temperature measurement test Hager conducted over 8.5 years comparing mercury thermometers to electronic ones. That could be a sheer coincidence, but on the other hand it is screaming to be investigated.
2000 to present: no warming


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Next Kowatsch provided a chart showing Germany’s mean annual temperature for period 0f 2000 to present, i.e. the period that has been using the new electronic measurement system:

Here we see there is no longer any rising trend, but that the mean temperature is at a new, higher plateau. As a result, almost the entire mean annual temperature rise Germany has seen since 1900 occurred during the single short 1986-2000 period. Josef Kowatsch commented (by e-mail):
In these 15 years, did CO2’s greenhouse gas effect suddenly go into action? Who switched on the CO2 greenhouse gas effect for these 15 years?”
Moreover, didn’t Germany’s national DWD Weather Service check and calibrate the new electronic system to be sure it would produce results similar to the earlier used mercury thermometers and thus ensure the recording of reliable data? Hager says they never did, and it seems they were quite content to adopt the warmer readings.
The following chart is a plot of Germany’s mean annual temperature over the entire 1900 to present period:

Chart adapted from here.
To me this all appears to have all the elements of an epic instrumentation debacle that is as bad and sloppy as any could get. Again, I repeat: Hager writes that the DWD never conducted any systematic comparison tests in order to be sure the new electronic ones were producing reliable daily data.
If this is really the case, then we can be happy that the DWD is not in the business of calibrating altimetry systems for commercial jets.
Of course the 1986 – 2000 rise likely is not solely an artifact of poor instrumentation calibration, as part of the warming is surely due to the natural ocean cycles which pushed global temperatures up during the end of the 20th century. However, the results of Hager’s comparison test are difficult to ignore and raise lots of questions.
 
Share this...FacebookTwitter "
"Scott Morrison has argued there is no direct link between Australia’s greenhouse gas emissions and the severity of fires ravaging the continent, even suggesting Australia could increase its emissions without making the current fire season worse. Under pressure due to a record season of early bushfires and the accusation by a coalition of former fire chiefs that the government has avoided the issue of climate change, Morrison said on Thursday there was no “credible scientific evidence” that cutting Australia’s emissions could reduce the severity of bushfires.  On Thursday Morrison defended the government’s handling of the bushfire season, telling ABC’s AM it had put additional resources into emergency services and praising the “outstanding” response and coordination of state governments. Morrison said he “took issue” with the suggestion by Greg Mullins, the former chief of NSW Fire and Rescue, and 23 other fire chiefs that the government was not adequately prepared. Explaining why he didn’t meet Mullins, Morrison said the government already had the same advice about the impact of climate change from “existing fire chiefs doing the existing job”. At first, Morrison appeared to accept that climate change was affecting the severity and frequency of bushfires. “These are things that are very well known to the government – the contribution of these issues to global weather conditions and to conditions here in Australia are known and acknowledged,” he said. “In February I acknowledged the contribution of those factors to what was happening in Australia – amongst many other issues.” Morrison then said “the suggestion that any way shape or form that Australia, accountable for 1.3% of the world’s emissions, that the individual actions of Australia are impacting directly on specific fire events, whether it’s here or anywhere else in the world, that doesn’t bear up to credible scientific evidence either”. “Climate change is a global phenomenon and we’re doing our bit as part of the response to climate change – we’re taking action on climate change,” he said. “But I think to suggest that at just 1.3% of emissions, that Australia doing something more or less would change the fire outcome this season – I don’t think that stands up to any credible scientific evidence at all.” The comments follow a controversy in September when the minister responsible for drought and natural disasters, David Littleproud, said he doesn’t “know if climate change is manmade”, before a total about-face. The link between rising greenhouse gas emissions and increased bushfire risk is complex but, according to major science agencies, clear. Warmer weather increases the number of days each year on which there is high or extreme bushfire risk. Australia’s response to climate change has been ranked one of the worst in the G20, with rising greenhouse gas emissions since the Abbott government abolished the carbon price in 2014. Australia’s target of 26%-28% emissions reduction by 2030 will require it to cut emissions by 695m tonnes cumulatively across the next decade. The Morrison government said more than half of that cut, 367m tonnes, would come from carryover credits from overperformance of earlier targets and not from practical emissions reduction. The centrepiece of federal climate policy is the $2.55bn emissions reduction fund, now rebadged as the climate solutions fund, a reverse auction processes that pays landowners and businesses to cut pollution. The most recent auction bought emissions cuts equivalent to only 0.01% of Australia’s annual greenhouse gas pollution after officials found just three projects worth backing. The government has been quietly pursuing an overhaul of the emissions reduction fund, appointing a panel of four business leaders and policy experts to suggest options to expand it, and will consider the issue with the states at a meeting of energy ministers on Friday. On Thursday Morrison refused to give further details of his proposed crackdown on environmental protests and secondary boycotts, saying the government would make announcements when it had “finalised those arrangements”. The attorney general, Christian Porter, has suggested measures could include extending the prohibition on secondary boycotts to environmental campaigns, and a crackdown on environmental litigation and use of litigation funders for class actions against mining companies. In a speech to the Business Council on Wednesday, Morrison flagged an overhaul of environmental approvals for major projects to reduce the length of time it takes for businesses to navigate environmental approvals."
"For years, optimists have talked up carbon capture and storage (CCS) as an essential part of taking emissions out of electricity generation. Yes, build wind and solar farms, they have said, but they can’t be relied on to produce enough power all the time. So we’ll still need our fleet of fossil-fuel-burning power stations; we just need to stop them pumping carbon dioxide (CO₂) into the atmosphere.  Most of their emphasis has been on post-combustion capture. This involves removing CO₂ from power station flue gases by absorbing them into an aqueous solution containing chemicals known as amines.  You then extract the CO₂, compress it into a liquid and pump it into a storage facility – the vision in the UK being to use depleted offshore oil and gas fields. One of the big attractions with such a system is it could be retrofitted to existing power stations.  But ten years after the UK government first announced a £1 billion competition to design CCS, we’re not much further forward. The reason is summed up by the geologist Lord Oxburgh in his contribution to the government-commissioned report on CCS published last year: There is no serious commercial incentive and it will stay that way unless the state demonstrates there is a business there.  The problem is that the process is costly and energy intensive. For a gas-fired power station, you typically have to burn 16% more gas to provide the capture power. Not only this, you end up with a 16% increase in emissions of other serious air pollutants like sulphur dioxide, nitrogen oxides and particulate matter. Concerns have also been expressed about the potential health effects of the amine solvent used in the carbon capture.  You then have to contend with the extra emissions from processing and transporting 16% more gas. And all this before you factor in the pipeline costs of the CO₂ storage and the uncertainties around whether it might escape once you’ve got it in the ground. Around the world, the only places CCS looks viable are where there are heavy state subsidies or substantial additional revenue streams, such as from enhanced oil recovery from oilfields where the CO₂ is being pumped in.  Well, say the carbon capture advocates, maybe another technology is the answer. They point to oxy-combustion, a system which is close to reaching fruition at a plant in Texas.  First proposed many years ago by British engineer Rodney Allam, this involves separating oxygen from air, burning the oxygen with the fossil fuel, and using the combustion products – water and CO₂ – to drive a high-pressure turbine and produce electricity. The hot CO₂ is pressurised and recycled back into the burners, which improves thermal efficiency. It has the additional advantage that CO₂ is also available at pressures suitable for pipeline transportation.  It is, according to some enthusiasts, the “holy grail” of CCS. Admittedly it looks promising, but I wouldn’t go that far. It’s not suitable for retrofitting existing power stations. With many existing stations viable for several decades, this will do little for immediate emissions. And you are still obtaining and moving fossil fuels in large quantities, with the resultant emissions along the way. Finally, my experience would indicate that there is always  very significant cost growth with new technology scaled up to industry.  One UK post-combustion CCS project that was cancelled earlier this year was the joint-venture between SSE and Shell at the Peterhead gas-fired ation in northeast Scotland. It aimed to capture 10m tonnes of CO₂ over a 10-year period and store it 2km under the North Sea.  Let’s put this saving into context. The diagram below summarises the amount of power produced and used in the UK. It shows that the country uses 108 terawatt hours (TWhrs) of domestic electricity per annum.    UK electricity generation/consumption Of this domestic usage, 16% goes to cooking. Boiling kettles makes up 34% – that’s 5.9TWhrs per annum, the equivalent of a 670MW power station. Domestic kettle use is particularly inefficient as we regularly overfill our kettles. We could save at least half the energy if we boiled only what we need to make tea and coffee.  That would negate the need for 335MW of power. Now compare that to what CCS would have saved from Peterhead – 85% of a 400MW gas turbine, or 340MW. Simply by not overfilling our kettles, we could remove about the same amount of CO₂. Unlike CCS, let alone oxy-combustion, we could do this immediately, for free, and cut our electricity bills and remove various air pollutants at the same time.  Of course, being kettle smart will only deliver a fraction of the UK’s required carbon reduction goals. It’s only about 3TWhrs out of the approximately 170TWhrs produced by gas-fired power in the UK each year. But it hopefully illustrates why energy efficiency is a much smarter way of reducing carbon and other harmful air emissions than CCS.  If we took the same approach to lighting, computer monitors, TVs on stand-by, running water and everything else, it becomes a very different proposition. If we could achieve the aim of a carbon-neutral house, we could shut down half the UK’s existing gas-fired power stations. And if industry and other non-domestic consumers made energy savings of the order of 20%, that would bring down the gas-fired power requirement by a corresponding percentage.  Is 20% realistic? As a chemical engineer with a 40-year industrial career, I am confident it is. Key areas to be considered would be pump and compressor efficiency, energy use in separation processes, combined heat and power, furnace fuel management, green concrete and energy integration. Together with the government giving greater priority to renewable energy like offshore wind and solar, you have a viable plan for delivering the UK’s carbon goals. CCS may still have its place, but as a means of removing carbon emissions from burning things like wood and rubbish as opposed to fossil fuels. Suffice to say it looks more promising on that front.  But in short, it is time for governments to stop wasting time and money on technologies like CCS that aren’t working. They need to finally get serious about leading a major drive for energy efficiency instead."
"There is an invidious strain of centrism in Australian media and politics that is one of the most powerful forces against effective action on climate change. It is a strain that has become more virulent in response to protests by Extinction Rebellion and the raised voices of those who care not to genuflect to the systems that have led us to the current crisis.  It is a strain that conservatives use to their advantage. Two weeks ago, as New South Wales and parts of Queensland burned, the prime minister was at pains to argue that now was not the time to talk about climate change. And the centrists agreed. This week Scott Morrison was ready to talk about climate change and he had the script all prepared. Morrison told the ABC’s Sabra Lane that “the suggestion that any way, shape or form with Australia accountable for 1.3% of the world’s emissions, that the individual actions of Australia are impacting directly on specific fire events, whether it’s here or anywhere else in the world, that doesn’t bear up to credible scientific evidence either”. It’s a line straight out of the climate-change denial playbook. No one is suggesting if we had a price on carbon there would be fewer bushfires, or it alone would significantly reduce global temperatures, but that does not mean Australia cannot make a difference. Only on climate change do you ever hear conservatives argue we are powerless. Our economy is only around 1.5% of the world’s total GDP and yet we have no qualms in going to the G20 every year and pushing our agenda. But on climate change? Sorry, we are impotent. Except we’re not. We are the 15th biggest emitter in the world, the biggest on a per capita basis among advanced economies. We have massive power, because we are wealthy enough to show what can be done. If we do nothing, it becomes a strong reason for anyone who emits less than us either in total or per capita to do the same. And the problem is we are using what power we have to obstruct action on climate change. Morrison argued that “if anything, Australia is an overachiever on our commitments, on global commitments, and for 2030, we will meet those as well with the mechanisms that we’ve put in place and we’ll ensure we do achieve that”. What utter tosh. Our Kyoto commitment is based on the dodgy counting of land use; and our commitment to Paris targets doubles down on that dodginess by using carry-over credits from the Kyoto target – something nations such as the UK are now fighting hard to have removed. Our target is also well below what scientists say is needed to keep temperature rises below 1.5C. Thirteen months ago the UN issued a report that concluded we have 12 years to do something to limit climate change, after which it will be too late to keep the rise in temperatures below 1.5C. The science has not changed in that time; all that has is we now have only 11 years. But this week it was reported that fossil fuel production by 2030 is set to be double that which is needed to keep temperature rises below 1.5C. We are failing, and Australia’s own policy is ensuring that failure will continue. But heck, pointing that out will seem biased, and so the centrist looks for a chance to appear balanced. It is why they have grabbed onto the disruption of Extinction Rebellion and loud claims by the Greens – because the centrist loves nothing more than being able to tell both sides to calm down. A clear example of this came this week from former ALP cabinet minister Craig Emerson, who wrote an opinion piece in the AFR denouncing tribalism that he argues is killing civil discourse. In it he suggested that “national socialism is resurgent. But so is international green socialism – a variant of white supremacism”. Yes, nothing like suggesting sections of the environmental movement are racists to get that civil discourse going. Emerson suggested this white supremacism occurred when “well-off greens demand the races of Asia and Africa forgo economic development using fossil fuels to rectify the sins we white, affluent humans have inflicted on the planet”. Yes “the races” of Asia and Africa. Emerson didn’t help his case against tribalism by spending most of the week on Twitter berating Greens supporters and suggesting the ALP was the only major party doing anything good on climate change (if the ALP isn’t the biggest force of tribalism in Australian politics, I clearly need to invest in a new dictionary). He further weakened his cause by suggesting that people were arguing that poorer nations needed to shift immediately to 100% renewable energy. No organisation or person of any note is arguing this (although Emerson did find a random person on Twitter). But worse, this argument that fossil fuels help poorer nations is a retread of the old argument that “coal is good for humanity” that Tony Abbott was pushing in 2014, and which was easily debunked at the time. It was the same argument that saw coal mining companies argue to leaders of the G20 that coal was needed because the WHO had reported that 4 million people die prematurely from household air pollution because “nearly 3 billion people use primitive stoves to burn wood or biomass to cook and heat homes”. Except what the WHO actually noted was that “around 3 billion people cook using polluting open fires or simple stoves fuelled by kerosene, biomass and coal”. And yet Emerson’s article, which pushed specious arguments about demands for immediate change to renewables, which likened sections of the environmentalist movement to white supremacists, and which echoed lines from mining companies was met with gushing praise from some very senior journalists. That’s because the column called for calm and reason, and centrists love calm and reason and love even more to praise anyone calling for it. And so in the space of five years we went from an argument pushed by Tony Abbott and mining companies to encourage more coal mines being shown to be clearly fallacious to it now being praised as part of a reasonable approach. This is because centrists care more about being seen to be neutral than whether that neutrality is worthy, or worrying if the centre has moved. It is the force that has journalists and politicians arguing that we should not make the perfect the enemy of the good, and yet spending little time examining how good something has to be before the perfect becomes its enemy. Not all extremism is equal and no force of social or economic change happened due to people refusing to make waves. It happened because people were prepared to go to prison, be attacked, and seek to disrupt those who would go about their lives ignoring the issue. Centrists love the final vote that sees change occur – where politicians from both sides sit together and agree; they care only in retrospect for the work, suffering and effort over decades that leads to that change. And they ignore that throughout those decades, the powerful in the media and politics actively prevented change occurring by spending more time calling for calm and reason than noting reality. And so long as powerful journalists believe that arguments are worthy purely because they call for a middle ground, then ever will they be a force that prevents effective action on climate change. Greg Jericho is a columnist for Guardian Australia"
"
Share this...FacebookTwitterI just got back to Germany earlier today after spending 2 weeks out in the states. The overnight transatlantic flights after such a period always give me major jetlag. I’m not the type that sleeps on planes and I don’t cope well at all with the time shifts.
Lots of photos here to tell you what I’m feeling right now. I’m struggling just to keep awake, which I plan to do until 9 pm. I have to keep moving outside in the fresh air. If I sit down for even just a couple of minutes, the exhaustion floods in.
So, no blogging today. Be back tomorrow!
Share this...FacebookTwitter "
"Just after calling the general election, Boris Johnson’s government made two almost simultaneous policy announcements that encapsulated the longstanding contradictions of environmental policy over the past decade. His decision to announce a moratorium on fracking – which, as the Labour party pointed out, was a temporary commitment rather than a ban – made headlines and was heralded as a signal of green intentions, but the go-ahead for a new deep coalmine in Cumbria was slipped out to little fanfare.  The conflicting signals were in keeping with a decade of environmental policy under the Conservative-led coalition and two Tory governments, during which U-turns and flip-flops have cheered and infuriated campaigners and green businesses alike. A 25-year environment plan and a target for net zero carbon emissions by 2050 have been highlights since the last general election, but the policies needed to implement them remain mired in confusion. “[There has been] a disjunction between the government’s willingness to say the right things, and even to put them into legally binding targets, and their unwillingness to make the tough choices we need to achieve them,” said Doug Parr, chief scientist at Greenpeace UK. “The 2050 net zero target, while not as soon as we would like, is a real achievement. [But] it is still accompanied by road-building, new licences for oil drilling, a third runway at Heathrow and stubborn opposition to onshore wind and solar.” Nick Molho, executive director of the Aldersgate Group of green businesses, said: “The story of the last 10 years is also that of a missed opportunity to cut emissions in key areas such as buildings and transport. We have seen incredibly slow progress.” Planning rules for onshore windfarms were changed and subsidies drastically scaled back from 2018, since when scarcely any new onshore windfarms have been built. Meanwhile, solar installations – vaunted under the coalition – have plummeted after incentives for households were taken away. A nine-year freeze on fuel duty, at a cost of £9bn a year to the Treasury, has buoyed fossil fuels and contributed to a 3% rise in transport emissions in the last five years. There have been similar reversals in housing, one of the biggest sources of emissions. As chancellor, George Osborne scrapped the zero carbon homes standard on the eve of its planned introduction in 2016. The number of existing homes fitted with new insulation had collapsed by early 2016 and has never recovered, after the government ended home insulation programmes. While ministers talked up the prospects of electric vehicles to tackle the climate emergency and the air pollution that contributes to 40,000 premature deaths a year, tax breaks that encouraged their purchase were scrapped last year. In June, the Society of Motor Manufacturers and Traders said sales of the cars had plunged by nearly 12% year on year. Before the government promised under Theresa May to phase out diesel cars in 2040, it fought a bitter campaign in the courts to avoid having to meet clean air requirements. There has also been confusion over the planned expansion of Heathrow: Boris Johnson promised to “lie in front of the bulldozers”, while Theresa May’s cabinet backed the developers.  These mixed signals across a wide variety of areas have produced mixed results. While greenhouse gas emissions from energy generation have fallen, largely owing to the long-term shift away from coal, carbon from transport has grown. There has also been an impact on jobs, with a drop of nearly a third in the number of renewable energy jobs, according to the union Prospect, and job losses in home energy efficiency. Mike Clancy, Prospect’s general secretary, said: “The last decade has been a masterclass in overpromising and underdelivering on environmental policy. This election needs to be a wake-up call that the climate emergency needs a serious rethink on austerity.” Policies for the natural environment and animal welfare also hang in the balance. While the government recently promised small-scale animal welfare improvements such as banning primates as pets and microchipping cats, a new influx of Tory MPs could result in a challenge to the hunting ban, and the party still firmly supports the controversial badger cull. Farmers, usually reliably Conservative in their voting patterns across most of England, have been promised taxpayer funding to reduce emissions and air pollution and preserve wildlife, but the agriculture and environment bills that would enable these policies have been left in limbo. The UK will next year host the most important climate conference since the signing of the 2015 Paris agreement. That will mean unprecedented scrutiny for the new government’s plans, and an opportunity to bring coherence to what has often been a piecemeal approach to environmental policy – and to prove that the UK’s environmental commitments will be upheld after Brexit. “Over the last 10 years we’ve seen a few steps forward for the environment, but the scales are heavily tipped towards policies which spell disaster for people and the planet,” said Dave Timms, head of political affairs at Friends of the Earth. “We’re living in a climate and ecological emergency. Tough regulation and massive investment in the right places are what we urgently need.”"
"Bluetongue disease, a virus which attacks sheep and cattle, has broken out in France, leading to fears that some time this year infected midges are likely to be blown across the channel and bring the disease to the UK, according to a recent government report.  By mid-February 184 farms had been infected throughout France. A 150km restriction zone has been thrown up around them in an attempt to control the disease. It’s easy to see why – northern Europe’s most recent outbreak between 2006 and 2010 caused an economic loss of hundreds of millions of pounds while more than 2m sheep across Europe have died since 1998 as a direct or indirect consequence of bluetongue.  Just as malaria is carried from human to human by infected mosquitoes, bluetongue is transmitted from animal to animal by female biting midges. The virus mainly affects sheep, goats, cattle and deer – it doesn’t do anything to humans.  The name bluetongue was given for the characteristic swollen and blue-purple coloured tongue in infected animals, especially sheep. However, this is a rare feature and most don’t actually get a blue tongue at all. More common symptoms include fever, low milk production, haemorrhages, mouth and nasal ulcers and problems with reproduction. In previous European outbreaks nearly half of the infected sheep died from the disease, while mortality rates in some sheep breeds can be up to 70%. Meanwhile cattle often carry the virus without actually suffering from any of the symptoms. Cows can be the perfect invisible source of a bluetongue outbreak within a farm. Bluetongue virus is widespread in the Americas, southern Asia, northern Australia, Africa and Europe. As with all other viruses, bluetongue is constantly mutating. Of the 27 different genetic forms (called serotypes) only one has caused large outbreaks in northern Europe: bluetongue serotype 8.   Serotype 8 emerged across northern Europe from France to Germany in 2006, 550km from previous outbreaks in Italy and Spain, and reached the UK the following year. A large vaccination programme eventually got things under control and by 2012 northern Europe was once again declared free of bluetongue. It remained that way until August 2015. The latest outbreak was first reported around Louroux-de-Bouble, a village in one of the major cattle areas in the centre of France. In total 27 cattle and 6 sheep were found to be infected. French authorities deployed a 150km control zone around the infected farm and started localised vaccinations.   It’s thought unlikely that this will stop the spread of bluetongue. While the majority of today’s infected farms are concentrated to the south of the first infection, the latest – reported on February 10 – was found 200km to the north. If bluetongue keeps spreading northwards, aided by the mild midge-friendly winter, and arrives in the farms along France’s north coast later this year then there is a very good chance it will jump across the English channel and British livestock will become infected. A UK government report says there’s a 60-80% likelihood this will happen by the end of summer. Midges can be carried downwind for long distances – comfortably far enough to cross the channel, which narrows to just 30km (20 miles) at the strait of Dover. Infected midge-blowing is probably what caused the UK’s 2007 bluetongue outbreak and the 2012 outbreak of Schmallenbertg, another livestock disease transmitted in the same way.   Bluetongue can also be introduced through the movement of live animals  or through infected semen and embryos, but these are legally restricted and therefore the risk is very low. Wild boar, deer and other wildlife act as “reservoirs” for the disease, periodically passing it on to midges, and thus back into livestock. The most dangerous and unpredictable way for the disease to spread uncontrollably remains the combination of midges and infected wildlife.  The control zones we currently have aren’t enough. They’re supposed to contain bluetongue outbreaks through restricting animal movements, vaccination and surveillance – yet the effectiveness of these zones has never been evaluated, so each country responds in different ways. The exact source of this latest infection is unknown – often the case with bluetongue outbreaks – which makes it more difficult to predict the development of the disease. In the UK, vaccine production was stopped after northern Europe was declared bluetongue-free in 2012, so supplies are very limited.  Yet vaccination is the only way to stop the spread of the disease. Models show that to prevent an outbreak, at least two-thirds of the farms at risk must be vaccinated in a relatively short time. At the moment negotiations are in place to produce enough vaccine for Britain’s sheep and cows. This is going to be expensive. Farmers need more support and EU or national governments should subsidise part of the cost where necessary. Environmental and animal agencies should also look out for infected midges and infected wild animals along the south coast – catching a British bluetongue outbreak as soon as possible will determine how quickly and successfully it can be controlled."
"
Share this...FacebookTwitterThe Northeast USA is being socked by frightful cold and massive snow. The brutal New England winters are back and now we are witnessing last ditch efforts by disgraced climate scientists to blame the brutally cold winters on a warming planet (which in reality has not warmed in 18 years).
At his latest Saturday Summary at WeatherBell Analytics, chief meteorologist Joe Bastardi delivers a stinging critique of Michael Mann’s recent claims: “Sea surface temperatures off the coast of New England right now are at record levels, 11.5C (21F) warmer than normal in some locations.” Mann also claimed there’s two times more moisture in this warm air, and thus is responsible for the turbocharged snowy icebox winter Boston has been experiencing.
At his Saturday Summary Joe thoroughly demolishes these claims.
Falsehood 1: It’s 11.5°C warmer than normal “off Cape Cod”
Joe calls Mann’s assertions a mistake, and shows that the area of warm sea surface water “off the coast of Cape Cod” is in fact way off the coast. At the 2:25 mark Joe shows how the waters along the eastern seaboard “are close to normal” and that a small patch of 3°C above normal water is some 1000 kilometers off the coast, and that a larger patch of 5°C above normal water is in fact 2000 kilometers off the coast (see following figure):

Dr. Mann’s warm water is in fact 2000 kilometers “off the coast”. Cropped from WeatherBELL.
Joe tells his viewers, and Dr. Mann, at the 3.00 mark:
There’s no way that that moisture is getting fed back into New England.”
Climatologists need to learn how to read a weather chart
So why would a climatologist like Mann make such an absurd claim? Joe tells us that a climatologist making a statement does not understand how the weather works, and advises them to first learn how to read a weather chart (2:15) before making such statements.
Falsehood 2: Heavy snow due to warm sea surfaces
The real reason it snowed so much over New England, Joe explains, is because of the “tremendous horizontal temperature gradient” in the area where extremely cold Arctic air clashes with normal temperature maritime air (3:30). It’s the cold, stupid!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




At 5:27 Joe explains:
Where this storm was embedded, it’s cooler. You cannot use the argument that we use for warm eddies, and hurricanes where we see some blow up over the warm eddy. You can’t use that with these.”
Falsehood 3: Two times higher water vapor in the air
At the 5:45 mark the veteran Penn State graduate meteorologist shows the water vapor situation in the region where the storm developed:
During this time of the snow blitz over New England, the mixing ratios, which is the water vapor, is below normal! It’s below normal! It’s not above normal! In the area that we’re targeting, this period that we’re looking at, that had all this snow, is below normal.”
Snow (surprise!) is due to cold
The reason why water vapor is so low is “because it’s so darn cold”. The heavy snowfalls are related to the extreme cold, and not the unrelated warm patch 2000 kilometers “off Cape Cod” (6:10).
At the 7:47 mark Joe summarizes on warmist climatolgists’ claims:
If they’d looked at this, they would have seen how bogus their argument is. There is nothing above normal in that area. What happened was that it was so darn cold that it creates a very strong horizontal temperature gradient. […] It’s not because it’s so much warmer and humid off the eastern seaboard; it’s the exact opposite reason in this particular case. […] It’s because it’s cold.”
At the 9:30 mark Joe shows a chart of the AMO which that he says “has major implications“. The AMO has dipped sharply downwards, and although the current PDO is warm, it will turn colder within a couple of years. Implication: don’t expect global warming anytime soon.
Also Joe explains how cold winters across the United States are predominantly dependent on the ENSO. In years of El Nino spikes, US winters do greatly tend to be colder.
In summary this year’s brutal New England winter has nothing to do with the bogus, made-up explanations being served up by climatologists who are desperate to salvage their disgraced science.
 
Share this...FacebookTwitter "
"Imagine you are the government’s Minister for Transport: the economy is prospering, global oil prices are falling, and airlines are ordering hundreds of new airliners and investing in infrastructure in order to expand their flight networks. Tourism and the service industry are booming, and the public appetite for cheap air travel appears insatiable. But your government also is committed to radically reducing the greenhouse gas emissions, such as carbon dioxide, that cause climate change.  It’s an obligation that has huge implications for all sectors of the economy – none more so than the energy-intense transport sector, and particularly aviation. Can technological advances and engineering offer a means to have your cake and eat it? To cut emissions while not interfering with the economic and employment boom generated by the industry – not to mention how popular cheap air travel is with voters. While the airline industry is quick to reassure that technical solutions, such as improved materials, engines and biofuels, and market-based measures can provide a fix, our research has found these to be examples of “technology myths”.  Most Ministers for Transport would take the low-risk option of the promise of technocratic and market approaches to the problem tomorrow rather than take more direct action today. Industry promises and reassurances offer time to address the attractive opportunities provided by greater mobility and economic growth. Both are key government objectives. The reality of the effects of rising aviation industry emissions on climate change has been known for decades, yet the industry and its emissions has continued to grow without constraint. Aviation emissions proved too contentious to be dealt with under the Kyoto Protocol, and the European Union’s efforts to bring international, non-European aviation emissions into the EU Emissions Trading Scheme were blocked by the industry. Published in the journal Transportation Research Part D, our study sheds some light on the “promise” of technical solutions through a 20-year examination of how they were reported in the media and the extent to which they were subsequently implemented. We found that new airline industry technology, including airframe, engine and alternative fuel breakthroughs, have been consistently presented by the industry as essential to building an ecologically sustainable aviation industry.  But the discussion of them continues to give credence to the myth of zero-emission flight – shielding the industry from closer scrutiny of its efforts to meet emission targets and improve sustainability practices. The clearest examples of such myths are solar and electric flight. Last summer, the Solar Impulse 2 solar-powered aircraft attempted to fly around the world. This single-seat aircraft required enough solar cells to cover a wingspan the size of a 500-seater Boeing 747 airliner to generate enough power even to carry its single pilot aloft. Even those involved in the project admit it will never replace current air transportation. Electric flight is equally problematic, as it requires a 15-fold increase in the energy density of lithium batteries (power supplied by weight of battery) in order for commercial flight to become possible. While some industry experts claim that this is not beyond the realm of possibility, it’s unlikely to arrive before 2035, and even then a very long aircraft development and fleet replacement process would follow. All this is far too late to avoid dangerous climate change. The more viable option of replacing aviation kerosene with biofuels also comes with caveats. The most efficient biofuels reduce CO2 emissions by up to 90%, but are inefficient to store and create land use competition with agriculture for crops. Others are more space efficient, but unable to deliver net energy (the energy content of the produced kerosene is lower then the energy required to turn the feedstock into kerosene).  The cost of biofuels is also underestimated. For example, a recent Independent Transport Commission (ITC) report to the UK government recommended that carbon emissions need not be a show-stopper for further development of Heathrow and Gatwick airports. The report’s claim that biofuels will be commercially viable is reached by comparing the cost of ready-to-use aviation kerosene with the cost of existing biofuel feed stocks such as wood pulp and palm oil. But this is not a useful comparison because no aircraft will ever be able to leave the runway on pure palm oil alone, but must run a blend of fuels. At the same time, the report states that CO2 emissions are likely to be mitigated by a 1.6% annual improvement in fuel efficiency and operations – conveniently ignoring the fact that the volume of air traffic continues to grow at 5% each year. The fact remains that aviation, a steadily growing and polluting industry, remains outside major climate agreements such as those agreed at the Paris COP21 conference last year. The myth of sustainable aviation remains intact, and the industry ducks regulation once more."
"
Share this...FacebookTwitterWe keep hearing that the climate and weather forecasting tools are gaining in sophistication, and correspondingly in reliability. Climate model simulators claim to be able to see decades, even centuries, into the future!
Yet Spiegel Science journalist Axel Bojanowski has an analysis here which looks at the recent spate of failed El Niño predictions by the NOAA, and shows that these forecasting tools are still terribly lacking. His latest piece: “Change in global weather: El Niño embarrasses meteorologists“. (Here I’m not sure why Bojanowski (or his editors) chose the term ‘meteorologists’ because much of the work is arguably done by climate scientists.)
It is an accepted fact that the El Niño cyclic changes in the equatorial Pacific surface temperatures have major impacts on the global weather, especially the northern hemisphere. Thus it would be useful if scientists were able to predict them with some degree of rough accuracy.
Unfortunately accuracy is still a long way off as forecasters falsely predicted an El Niño four years long, and only now has it finally begun to take hold. Bojanowski writes:
Seldom have meteorologists been made to look so foolish. Four years long they published the same prognosis: Soon an El Niño would be taking hold in the Pacific.”
The Spiegel journalist describes how last June experts were “80% sure” a powerful El Niño was in the works, and how in 2013 “a peer-reviewed paper in a well known science journal” boasted of new forecasting methods for El Niños. Sadly, these experts aren’t anywhere near getting it right. So, as a result, Bojanowski writes, they have recently become “considerably more cautious” with their forecasts. Embarrassment does that.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Bojanowski describes how the ENSO’s impact on global weather patterns, wildlife, and even regional sea levels, and how NOAA experts have had to admit the latest El Niño has been an unexpectedly tame one – in stark contradiction to forecasts made earlier. He writes: “The inaccurate forecasts of the past year has forced the scientists to rethink their methods, said NOAA expert Gabriel Vecchi in the journal ‘Nature’.”
Numerous buoys out of order!
Bojnowski also writes that the biggest problem is reliably predicting the weakening of the tradewinds, and says this has become difficult because “numerous buoys have ceased to function over the years” and so are no longer able to measure the changes in sea surface temperature.
That is certainly an interesting revelation presented here by Bojanowski. Still, NOAA El Niño forecasters should not feel too bad about their measurement and forecasting woes because it could be much worse. For example their climate colleagues haven’t gotten their global temperature forecasts right in over 18 years!
And concerning what can be done in place of the “numerous” out-of commission buoys, perhaps the NOAA El Niño scientists could consider using the “filling in the data” method and simply apply the measurements made by the closest functioning buoy (even if it is 1000 kilometers away). After all the global surface temperature scientists seem perfectly satisfied with that particular method. The data-fill-in method would surely allow the NOAA El Nino experts to make forecasts that are just as spectacularly accurate as those of the global warming climate scientists.
Flashback: wattsupwiththat.com/el-nino-sea-monitoring-half-dead-already/
 
Share this...FacebookTwitter "
"Tree planting is suddenly the zeitgeist. Tabloid newspapers, utility companies and oil corporations are pledging to plant trees by the million, in some cases before Christmas. Even the Brexit party is on to it. The Woodland Trust has launched its “big climate fightback”. This Thursday, on Channel 5, Chris Packham and John Humphrys host Plant a Tree to Save the World. It’s not as catchy as Plant a Tree in ’73, the last time tree planting genuinely caught the public imagination. Then, the government launched a national tree planting campaign as a response to Dutch elm disease. Today, NGOs and businesses are leading the way while successive, recent governments have made unambitious pledges, which they have failed to keep. There is no national tree planting strategy in England. It is shameful. Meanwhile, we are losing ash trees by the million to ash dieback.  In July, Ethiopia began a huge nationwide strategy in which 350m trees were planted in one day (at current rates in England and Wales, this would take us 140 years). In 2017, 1.5 million Indian volunteers planted 66m trees in 12 hours in Madhya Pradesh. The government in New Zealand launched a plan to plant a billion trees by 2027 (including 83m this year). In Pakistan, the programme to plant a billion trees to combat the effects of climate change was completed ahead of schedule in 2017. Their new target is 10bn trees. I will plant trees on the edge of my small woodland in the Black Mountains this week – birch, aspen, field maple and a dozen tiny oaks that I grew from acorns – as I have done every year for a decade and a half. In the community woodland I help manage, we’ll continue to plant diverse species under the ash we expect to lose. My neighbour, Keith Powell, is finalising plans to plant 175,000 broadleaf trees on the upland common behind our homes. Trees give life. It’s hard to overstate their benefit. They are fundamental to our rural and urban landscapes, our lives and the future of this planet. Trees reduce soil degradation on farms, provide vital habitat for wildlife, supply us with food, heat and medicine, safeguard water quality, give shade, build biodiversity and create spaces to walk lightly and breathe deeply in our cities. Trees diminish flood risk, improve air quality by absorbing pollution and yield a renewable resource in the form of timber. Most importantly, in the climate emergency, trees sequester carbon. They absorb carbon dioxide from the atmosphere, storing it in their trunks, branches and roots, before releasing oxygen back into the air. Trees mitigate climate change and tree planting is now recognised as one of the best ways to tackle this global crisis. Some of the trees I planted 15 years ago are nearly 10 metres tall. Watching them grow and turn with the seasons reminds me that time passes, which encourages me to live as well as I can. I won’t be around to see most of these trees reach maturity, but that is the point: if you take the trouble to plant trees now, someone may walk through your woodland or down your street a century or more into the future and think well of you, even though they don’t know your name. Planting a tree is also, for me, a simple act of faith. As the American poet W S Merwin wrote: “On the last day of the world I would want to plant a tree.” We have to engage, as families and schools, as communities and as a nation, on fixing the future. We cannot wait for the government to lead on tree planting. We have to do it ourselves. And the time is now. Rob Penn is the author of The Man Who Made Things Out of Trees"
"Bedbugs have a lousy reputation at the best of times, but these unfortunate insects have taken a particularly firm kicking recently. An announcement that their genome had been sequenced was framed not as a remarkable scientific accomplishment but as useful information to help us humans destroy our enemies. It’s not hard to see where the animosity comes from. Though bedbugs – known to scientists as Cimex lectularius – will feed on bats, chickens and domesticated animals, it is their taste for human blood that causes problems. After widespread DDT usage largely wiped them out in the mid-20th century they have made a strong return in recent years, with many becoming resistant to modern pesticides.  The bedbug problem is getting worse. Infestation horror stories have popped up in most major cities and a pest control team was even asked recently to exterminate bedbugs on an offshore oil rig. We tend to associate bedbugs with dirty living conditions, but this is a myth – they don’t actually choose dirty homes over clean ones. Unusually for many blood-sucking insects, bed bugs haven’t (yet) been implicated in spreading disease to the humans they bite, so that’s one small thing in their favour, though they are suspected of carrying organisms that cause leprosy, oriental sore and the bacterial brucellosis, and may be able to transmit Chagas disease. So can we defend these bugs, or is insecticide the only solution? Bedbugs suck blood, which contains the DNA of people they fed on. Human DNA extracted from live, frozen and dried bedbugs has proven suitable for DNA profiling. Some scientists say we could therefore use the bugs as a source of evidence to prove a particular person had been in a bedroom. Cimex are also wingless and don’t stay on their hosts after feeding. They tend to remain near the source of food though, so unlike other blood-feeders such as mosquitoes or black flies they can be present at a crime scene long after the perpetrator has fled. Bedbugs are highly specialised for what they do. Like other Hemiptera (true bugs) their mouthparts are specially adapted to suck liquids, using needle like mandibles and maxillae to form hollow tubes, complete with pumps for saliva and suction. The saliva they inject prevents blood from clotting as they feed and in their gut, and their abdomens expand to allow them to feast on larger meals. All these features are a product of natural selection – and bedbugs are still changing, fast.  Then there is winglessness, which often evolves in species where flight is either too expensive in terms of energy, unnecessary in the absence of predators, or too risky in terms of living on a windy island. Many insects have short winged or wingless forms, but most of them have winged relatives, suggesting that once wings were present and functional. In fact, a close look at Cimex shows that it still has tiny front wings. Add to this host-seeking ability and rapid evolution of resistance to insecticides, and the bedbug becomes a useful model organism for scientific investigation. Our need to understand a rapidly evolving species drove the complete bedbug genome sequencing. Among other things, scientists discovered the common bedbug split from those that feed on bats about a quarter of a million years ago, which means bedbugs predate modern humans by about 45,000 years. This may be an example of speciation in progress.  Our ancestors likely first associated with these nocturnal feeders while seeking shelter in caves. So bed bugs can tell us something about human history. They were certainly biting ancient Egyptians, and Roman scholar Pliny mentioned them in 77AD. It was the Romans who called them “Cimex”, which means bug, and they were recommended to treat ear infections and snake bites. The genome research also shows how bedbugs have adapted to rely on a bacterial parasite called Wolbachia, that lives inside the bug’s guts and helps them conjure vital vitamins out of their blood only diet.  Thanks to bedbug research we now know a lot more about the genes that confer pesticide resistance, which may lead to new insecticides useful for the control of this and other species. Pests and pesticide resistance are in constant battle and a reminder of the resilience of species to survive. Bedbugs and other household pests could even be regarded as advantageous to the economy in that they keep people in work. More than 1,000 pest control companies provide employment in the UK alone, part of an annual market worth about £330m. Then there are the chemical firms manufacturing pesticides, companies that make vacuum cleaners, washing powders and (as a last resort) new mattresses. So sleep tight, and if the bedbugs do bite, think about their contribution to forensic entomology, evolution and the economy."
"
Share this...FacebookTwitterReader Jimbo left a comment which I’ve upgraded to a post.
Below he presents a list of 25 examples where climate alarmism organizations and scientists were more than happy to take in big money from Big Oil and industry. Even Michael Mann (Example no. 19) benefitted from the Koch Brothers!
============================
By reader Jimbo
We are often called fossil fuel funded climate change deniers. So you can imagine my shock when I came across these past and present takers of fossil fuel money. Imagine if skeptics hauled in such money.
1. Climate Research Unit (CRU)
History
From the late 1970s through to the collapse of oil prices in the late 1980s, CRU received a series of contracts from BP to provide data and advice concerning their exploration operations in the Arctic marginal seas. Working closely with BP’s Cold Regions Group, CRU staff developed a set of detailed sea-ice atlases,
This list is not fully exhaustive, but we would like to acknowledge the support of the following funders (in alphabetical order):
…British Petroleum…Greenpeace International…Reinsurance Underwriters and Syndicates…Sultanate of Oman…Shell……
2. Sierra Club
TIME – 2 February 2012
Exclusive: How the Sierra Club Took Millions From the Natural Gas Industry
TIME has learned that between 2007 and 2010 the Sierra Club accepted over $25 million in donations from the gas industry, mostly from Aubrey McClendon, CEO of Chesapeake Energy—one of the biggest gas drilling companies in the U.S. and a firm heavily involved in fracking…”
3. Delhi Sustainable Development Summit
[Founded by Teri under Dr. Rajendra Pachauri chairman of the IPCC]
2011: Star Partner – Rockefeller Foundation
2007: Partners – BP
2006: Co-Associates – NTPC [coal and gas power generation] | Function Hosts – BP
2005: Associate – Oil and Natural Gas Corporation Limited, India | Co-Associate Shell
4. Berkeley Earth Surface Temperature (BEST) project
Berkeley Earth team members include: Richard Muller, Founder and Scientific Director……Steven Mosher, Scientist…
Financial Support First Phase (2010)
…Charles G. Koch Charitable Foundation ($150,000) The Ann & Gordon Getty Foundation ($50,000)…
Second Phase (2011)
…The Ann & Gordon Getty Foundation ($50,000)…
Third Phase (2012)
…The Ann & Gordon Getty Foundation ($50,000)…Anonymous Foundation ($250,000)…
Fourth Phase (2013)
…The Ann & Gordon Getty Foundation ($100,000)…
5. 350.org
350.org caught up in fossil fuel ‘divestment’ hypocrisy
[Rockefellers Brothers Fund] RBF has given 350.org $800,000 in recent years and almost $2 million to the 1Sky Education Fund, now part of 350.org, according to foundation records.”
6. Union of Concerned Scientists
The 2013 Annual Report PDF
UCS thanks the following companies that matched members’ gifts at a level of $1,000 or more….Chevron Corporation…”
Annual Report 2002 PDF
The Union of Concerned Scientists gratefully acknowledges the following individuals and foundations for their generous contributions of at least $500 during our fiscal year 2002 (October 1, 2001–September 30, 2002)…”
Friends of UCS
The Friends of UCS provide substantial support for the ongoing work of the organization…Larry Rockefeller…Matching Gift Companies…BP Amoco Matching Gift Program…Philip Morris Companies, Inc…”
7. University of California, Berkeley
CalCAP, Cal Climate Action Partnership
What is CalCAP?
 The Cal Climate Action Partnership (CalCAP) is a collaboration of faculty, administration, staff, and students working to reduce greenhouse gas (GHG) emissions at UC Berkeley.”
8. University of California, Berkeley
UC Berkeley News – 1 February 2007
BP selects UC Berkeley to lead $500 million energy research consortium with partners Lawrence Berkeley National Lab, University of Illinois.”
9. Climate Institute
About Us
The Climate Institute has been in a unique position to inform key decision-makers, heighten international awareness of climate change, and identify practical ways of achieving significant emissions reductions…
Donors
American Gas Foundation…BP…NASA….PG&E Corporation [natural gas & electricity]…Rockefeller Brothers Fund, Shell Foundation…The Rockefeller Foundation…UNDP, UNEP…”
10. EcoLiving
About
…EcoLiving provides events and hands-on workshops to teach Albertans about ways to reduce our collective ecological footprint, create more sustainable and energy efficient buildings, and share information about local environmental initiatives and services…”
Sponsors
2008 Sponsors: …ConocoPhillips…Shell 2009 Sponsors: …ConocoPhillips Canada…2013 Sponsors:…Shell FuellingChange…”
11. Nature Conservancy
Climate Change Threats and Impacts
Climate change is already beginning to transform life on Earth. Around the globe, seasons are shifting, temperatures are climbing and sea levels are rising…… If we don’t act now, climate change will rapidly alter the lands and waters we all depend upon for survival, leaving our children and grandchildren with a very different world…”
12. Washington Post – 24 May 2010
…What De Leon didn’t know was that the Nature Conservancy lists BP as one of its business partners. The Conservancy also has given BP a seat on its International Leadership Council and has accepted nearly $10 million in cash and land contributions from BP and affiliated corporations over the years….The Conservancy, already scrambling to shield oyster beds from the spill, now faces a different problem: a potential backlash…”
13. America’s WETLAND Foundation



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Restore-Adapt-Mitigate: Responding To Climate Change Through Coastal Habitat Restoration”
PDF
Coastal habitats are being subjected to a range of stresses from climate change; many of these stresses are predicted to increase over the next century The most significant effects are likely to be from sea-level rise, increased storm and wave intensity, temperature increases, carbon dioxide concentration increases, and changes in precipitation that will alter freshwater delivery…”
Sponsors
World Sponsor: Shell
 Sustainability Sponsors: Chevron, ConocoPhillips, ExxonMobil
 National Sponsors: British Petroleum”
14. Green Energy Futures
About Us
Green Energy Futures is a multi-media storytelling project that is documenting the clean energy revolution that’s already underway. It tells the stories of green energy pioneers who are moving forward in their homes, businesses and communities.
Gold Sponsor: Shell”
15. World Resources Institute
Climate
WRI engages businesses, policymakers, and civil society at the local, national, and international levels to advance transformative solutions that mitigate climate change and help communities adapt to its impacts.
ACKNOWLEDGING OUR DONORS (January 1, 2011 – August 1, 2012 PDF 5MB
…Shell and Shell Foundation…ConocoPhillips Company…”
16. Purdue Solar
Navitas Takes 1st at SEMA 2013
Last week, Purdue Solar Racing took home first place in the Battery Electric division at the 2013 Shell Eco-marathon. The winning run reached an efficiency of 78.1 m/kWh (a miles per gallon equivalency of approximate 2,630MPGe)…”
17. AGU Fall Meeting
9-13 December 2013
Thank You to Our Sponsors
The AGU would like to take the time to thank all of our generous sponsors who support the
2013 Fall Meeting and the events at the meeting.
ExxonMobil…….BP, Chevron…..Mineralogical Society of America…”
18. Science Museum – Atmosphere
About our funders
…exploring climate science gallery and the three-year Climate Changing… programme. Through these ground-breaking projects we invite all our visitors to deepen their understanding of the science behind our changing climate.
We believe that working together with such a wide range of sectors is something that we’ll all need to be able to do in our climate-changing world….
Principal Sponsors: Shell…Siemens…”
19. Dr. Michael Mann
WUWT – October 15, 2013
…it is enlightening to learn that his current employer, Penn State, gets funds from Koch, and so does where Dr. Mann did his thesis from, the University of Virginia. Those darn facts, they are stubborn things. See the list that follows…”
[Comments]
Jimbo October 16, 2013 at 11:49 am
Why stop at Koch funding?
Exxon Mobil Corporation
 2012 Worldwide Contributions and Community Investments
…..Pennsylvania State University [$] 258,230…”
20. Stanford University
New York Times – 21 November 2002
By ANDREW C. REVKIN
Exxon-Led Group Is Giving A Climate Grant to Stanford
 Four big international companies, including the oil giant Exxon Mobil, said yesterday that they would give Stanford University $225 million over 10 years for research on ways to meet growing energy needs without worsening global warming….In 2000, Ford and Exxon Mobil’s global rival, BP, gave $20 million to Princeton to start a similar climate and energy research program…”
21. National Science Teachers Association – Jun 11, 2012
by Wendi Liles
You are invited this summer to the 4th Annual CSI: Climate Status Investigations free climate change educator professional development in Wilmington, DE…. You will also get to participate in a climate change lesson with the staff from Delaware Nature Society to investigate the effect of climate change on their urban watershed…..a few fun giveaways thanks to our sponsors-DuPont, Agilent Technologies, Lockheed Martin, Chevron, Delaware Nature Society…”
22. Duke University
ConocoPhillips Pledges $1 Million to Climate Change Policy Partnership at Duke 2007
ConocoPhillips, the third-largest integrated energy company in the United States, has pledged $1 million to support an industry-university collaboration working to develop policies that address global climate change, Duke University President Richard H. Brodhead announced Wednesday.”
23. Alberta Water Council PDF
Growing demands from an increasing population, economic development, and climate change are the realities impacting our water allocation system.
…Breakfast Sponsor: ConocoPhillips Canada…River Level Sponsors….ConocoPhillips Canada”
24. University of California, Davis
 Institute of Transportation Studies PDF
10th Biennial Conference on Transportation and Energy Policy
Toward a Policy Agenda For Climate Change
 Asilomar Transport & Energy Conferences
VIII. Managing Transitions in the Transport Sector: How Fast and How Far?
September 11-14, 2001. Sponsored by US DOE, US EPA, Natural Resources Canada, ExxonMobil, and Chevron (Chair: D. Sperling)…”
25. Washington Free Beacon – 27 January 2015
Foreign Firm Funding U.S. Green Groups Tied to State-Owned Russian Oil Company
 Executives at a Bermudan firm funneling money to U.S. environmentalists run investment funds with Russian tycoons
A shadowy Bermudan company that has funneled tens of millions of dollars to anti-fracking environmentalist groups in the United States is run by executives with deep ties to Russian oil interests and offshore money laundering schemes involving members of President Vladimir Putin’s inner circle……The Sierra Club, the Natural Resource Defense Council, Food and Water Watch, the League of Conservation Voters, and the Center for American Progress were among the recipients of Sea Change’s $100 million in grants in 2010 and 2011….“None of this foreign corporation’s funding is disclosed in any way,” the Senate Environment and Public Works Committee wrote of the company in a report last year…”
 
Share this...FacebookTwitter "
"As the world grapples with climate change, we urgently need to find ways of reducing our CO₂ emissions. Sectors which rely heavily on fossil fuels, such as energy and aviation, are commonly held to be the worst offenders. But what most people don’t realise is that there’s another culprit, hiding in plain sight; on the streets of our cities, and in the buildings where we live and work.  In 2007 alone, steel and concrete were each responsible for more CO₂ emissions than the entire global aviation industry. Before reaching the construction site, both steel and cement must be processed at very high temperatures – and this takes a lot of energy. So how can we reduce our dependence on these “dirty” materials, when they play such a crucial role in construction? One option is to use natural materials, such as wood. Humans have been building with wood for thousands of years, and wooden structures are currently experiencing a minor resurgence – partly because it’s a cheap and sustainable material.  But there are some disadvantages to building with wood; the material can warp in humid conditions, and is susceptible to attack by pests such as termites. And while natural materials, such as wood, are appealing from an environmental perspective, they can be unsatisfying for engineers who might wish to make components in a specific shape or size. So what if, instead of using natural materials as we find them, we make new materials that are inspired by nature? This idea started to gain traction in the research community in the 1970s and really exploded in the 1990s, with the development of nanotechnology and nanofabrication methods. Today, it forms the basis of a new field of scientific research: namely, “biomimetics” – literally “copying life”.  Biological cells are often referred to as “the building blocks of life”, because they are the smallest units of living matter. But to create a multi-cellular organism like you or me, cells must clump together with a support structure to form the biological materials we’re made of, tissues such as bone, cartilage, and muscle. It’s materials like these, which scientists interested in biomimetics have turned to for inspiration.  In order to make biomimetic materials, we need to have a deep understanding of how natural materials work. We know that natural materials are also “composites”: they are made of multiple different base materials, each with different properties. Composite materials are often lighter than single component materials, such as metals, while still having desirable properties such as stiffness, strength and toughness.  Materials engineers have spent decades measuring the composition, structure and properties of natural materials such as bone and eggshell, so we now have a good understanding of their characteristics.  For instance, we know that bone is composed of hydrated protein and mineral, in almost equal proportions. The mineral confers stiffness and hardness, while the protein confers toughness and resistance to fracture. Although bones can break, it is relatively rare, and they have the benefit of being self-healing – another feature that engineers are trying to bring to biomimetic materials.  Like bone, eggshell is a composite material, but it is around 95% mineral and only 5% hydrated protein. Yet even that small amount of protein is enough to make eggshell very tough, considering its thinness – as most breakfast cooks will have noticed. The next challenge is to turn this knowledge into something solid. There are two ways to mimic natural materials. Either you can mimic the composition of the material itself, or you can copy the process by which the material was made.  Since natural materials are made by living creatures, there are no high temperatures involved in either of these methods. As such, biomimetic materials – let’s call them “neo-bone” and “neo-eggshell” – take much less energy to produce than steel or concrete.  In the laboratory, we have succeeded in making centimetre-scale samples of neo-bone. We do this by preparing different solutions of protein with the components that make bone mineral. A composite neo-bone material is then deposited from these solutions in a biomimetic manner at body temperature. There is no reason that this process – or an improved, faster version of it – couldn’t be scaled up to an industrial level.  Of course, steel and concrete are everywhere, so the way we design and construct buildings is optimised for these materials. To begin using biomimetic materials on a large scale, we’d need to completely rethink our building codes and standards for construction materials. But then, if we want to build future cities in a sustainable way, perhaps a major rethink is exactly what’s needed. The science is still in its infancy, but that doesn’t mean we can’t dream big about the future.  “Biomimetic materials: re-thinking how we build stuff”, a talk by the author, is part of the Cambridge Science Festival."
"The concentration of climate-heating greenhouse gases has hit a record high, according to a report from the UN’s World Meteorological Organization. The jumps in the key gases measured in 2018 were all above the average for the last decade, showing action on the climate emergency to date is having no effect in the atmosphere. The WMO said the gap between targets and reality were both “glaring and growing”. The rise in concentration of greenhouses gases follows inevitably from the continued surge in global emissions, which was described as “brutal news” for 2018. The world’s scientists calculate that emissions must fall by half by 2030 to give a good chance of limiting global heating to 1.5C, beyond which hundreds of millions of people will suffer more heatwaves, droughts, floods and poverty. But Petteri Taalas, the WMO secretary-general, said: “There is no sign of a slowdown, let alone a decline, despite all the commitments under the Paris agreement on climate change. We need to increase the level of ambition for the sake of the future welfare of mankind. “It is worth recalling that the last time the Earth experienced a comparable concentration of carbon dioxide was 3-5m years ago. Back then, the temperature was 2-3C warmer and sea level was 10-20 metres higher than now.” Three-quarters of the emissions cuts pledged by countries under the Paris agreement of 2015 are “totally inadequate”, according to a comprehensive expert analysis published earlier in November, putting the world on a path to climate disaster. Another report has found that nations are on track to produce more than double the fossil fuels in 2030 than could be burned while keeping heating under 1.5C. “The [CO2 concentration] number is the closest thing to a real-world Doomsday Clock, and it’s pushing us ever closer to midnight,” said John Sauven, head of Greenpeace UK. “Our ability to preserve civilisation as we know it, avert the mass extinction of species, and leave a healthy planet to our children depend on us urgently stopping the clock.” The WMO report, published on Monday, found the global average concentration of CO2 reached 407.8 parts per million in 2018, up from 405.5ppm in 2017. It is now 50% higher than in 1750, before the industrial revolution sparked the widespread burning of coal, oil and gas. Since 1990, the increase in greenhouse gas levels has made the heating effect of the atmosphere 43% stronger. Most of that – four-fifths – is caused by CO2. But the concentrations of methane and nitrous oxide, the two other key greenhouse gases, also surged in 2018 by a higher amount than the annual average over the past decade. Methane, which is produced by cattle, rice paddies and fossil fuel exploitation, is responsible for 17% of the heating effect. Its concentration is now more than double pre-industrial levels. Nitrous oxide, which comes from heavy fertiliser use and forest burning, is now 23% higher than in 1750. The observations are made by the Global Atmosphere Watch network, which includes stations in the Arctic, high mountains and tropical islands. “The record rise in greenhouse gas concentrations is a cruel reminder that for all the real progress in clean technology, we have yet to even stop global emissions increases,” said Nick Mabey, chief executive of think tank E3G. “The climate system cannot be negotiated with. Until we stop new investment in fossil fuels and massively scale up green power the risks from catastrophic climate change will continue to rise.” When the world’s nations agreed the Paris deal in 2015, they pledged to ramp up their promised emissions cuts by the annual UN climate summit in 2020, which will be hosted by the UK in Glasgow. This year’s summit needs to do vital preparatory work and begins on 2 December in Madrid, Spain. Chile had been due to host but cancelled because of civil unrest. Richard Black, director of the Energy and Climate Intelligence Unit in the UK, said: “This record level of greenhouse gases should act as a sobering reminder to governments that so far they are collectively reneging on the pledge they made at the Paris summit, of attempting to keep global warming to 1.5C. That window is closing, and Chile, Italy and the UK [must] use all the diplomatic tools they have to put emissions on a trajectory closer to what science recommends and the public want.”"
nan
"
Share this...FacebookTwitterThe online Swiss Handelszeitung (Trade News) reports on the world’s second largest reinsurer Swiss Re, and on the losses from natural catastrophes for 2014. Let’s recall that natural catastrophes are supposedly becoming more and more frequent due to the alleged man-made climate worsening from manmade CO2 emissions.
Hat-tip: Kurt
However the Handelszeitung writes that preliminary estimates show that the Swiss reinsurer saw “markedly less damage claims than in previous years” and far less loss of lives. Fortunately this is lots of good news, but the catastrophe-obsessed media are refusing to report it.
Deaths plunge almost 60%!
According to preliminary Swiss Re estimates, total economic losses from natural catastrophes and man-made disasters were USD 113 billion in 2014, down from USD 135 billion in 2013. Out of the total economic losses, insurers covered USD 34 billion in 2014, down 24% from USD 45 billion in 2013.
The 2014 loss amount is way below the annual average of $188 billion dollars for the past 10 years, 1.e. over 41% less.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Swiss Re press release writes that disaster events have claimed around 11,000 lives this year – down almost a whopping 60% from the 27,000 fatalities in 2013.
“No major hurricane”
The Zurich, Switzerland based reinsurer attributes the reduced damage in part to “the mild hurricane season“. It adds: “No major hurricane made landfall in the US, the ninth year running that this has happened.”
“Very low temperatures and heavy snow”
Moreover, the major losses resulted from cold events. The Swiss Re writes that “2014 started with extreme winter conditions in the US and Japan and, as the year drew to a close, the Northeast US was once again gripped by very low temperatures and heavy snow. The storms in the US at the beginning of 2014 alone caused insured losses of USD 1.7 billion. This is above the average full-year winter storm loss number of USD 1.1 billion of the previous 10 years. In mid-May, a spate of strong storms with large hail stones hit many parts of the US over a five-day period, resulting in insured losses of USD 2.9 billion, the highest of the year.”
Another myth bites the dust.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterRoger Lewis of the UK online Spectator presents a highly interesting portrait of environmentalist, doomsday-believer Dylan Evans and his Utopia Experiment. Lewis concludes from it: “Designs for living always end in tears, or worse.”
So disconnected from reality was Evans, and academic, that he believed he could actually make himself a better life departing the comforts of the modern age and getting back to the natural beauty of raw survival with other like-minded persons – in the raw climate of northern Scotland of all places.
Strangely Evans selected a site that he thought would allow the generation of electric power to accompany his natural living.
Some excerpts on how his “Experiment” turned out:
Evans admits that his utopia was doomed to failure. It attracted only idealists and disaffected romantics when what was needed were people with practical skills… […]
…the small group began to disintegrate. One member even started to invent his own religion, building a shrine. […]
He himself was soon fed up with sleeping under rancid fleece blankets  … the sanitary arrangements were grotesque. […]
It soon became apparent that ‘the whole experiment had been a huge mistake’. […]


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Evans was eventually detained under the Mental Health Act in a maximum security psychiatric hospital. […]
He fretted unduly about global warming and ‘the looming energy crisis’… Evans, the doctors concluded, was already craving the abyss and in the throes of panic-attacks and a breakdown.”
If the story of Evans tells us anything, it is that it vividly illustrates how far out to lunch academics in the ivory towers can sometimes become. Why on earth would policymakers ever listen to their loony utopian ideas to begin with? Evans just proved that its all lunacy.
Evans and the loads of past academics show that their radical formulae for rendering utopian life are pure delusions of deranged minds. Yet these are precisely the minds behind the doomsday global warming scenarios, and the advocacy of a carbon-free utopia.
The proof that these minds are deranged is the fact that none, except for Evans for a brief time, are willing to give up the carbon life themselves. Man was destined to escape nature, and not to stay at its mercy.
Finally one cannot help but notice the contempt loony academics and pseudo-intellectual journalists hold for humans. Lewis writes;
It’s best to muddle along as we are, not because human beings are morons or suckers, or traitors to the cause, but because life is meant to be messy, muddled, contrary, comic.”
Actually, as Evans clearly illustrates, the real morons are the academics and all the gullible media and policymaker idiots who believe the utopia that they preach. At least there is hope for Lewis as well, who seems to grudgingly concede that maybe the current system isn’t so bad after all and sure beats living in the cold mud.
 
Share this...FacebookTwitter "
"The 1987 treaty that stopped the pollution causing a hole in the ozone layer is rightly seen as a major success story. It’s arguably the most successful international environmental agreement ever. It’s true that, 30 years on from the signing of the Montreal Protocol, the Antarctic ozone hole still reappears every year. Yet the protocol really is working and its continued development means that it is doing more good than ever, including helping the fight against climate change. In 1985, scientists made the unexpected discovery that the Earth’s ozone shield, located in the stratosphere about 20km-30km above the surface and essential for life, contained a huge hole over Antarctica. The cause was quickly established to be chemicals, notably chlorofluorocarbons (CFCs) used as aerosol propellants and refrigerants, which are stable at low altitudes but release ozone-destroying chlorine and bromine when they break down in the upper atmosphere. It took just two years for intensive research, building on work on ozone depletion from the 1970s, to provide enough evidence for politicians representing every country in the UN to take action. They agreed to limit production of CFCs and other related gases. Signed on September 16, 1987, the Montreal Protocol put the brakes on increasing ozone depletion. This prevented the catastrophic scenarios of large, global-scale ozone depletion that would have severely damaged animal and plant life at the surface through large increases in ultraviolet (UV) radiation. For example, skin cancer rates in humans would have increased greatly. Despite the success of the protocol, a large Antarctic ozone hole continues to appear every spring in the southern hemisphere. In fact, the hole continued to grow for almost 20 years after the Montreal Protocol was put in place, with the largest hole recorded in 2006. This is because the process by which the atmosphere can cleanse itself of the stable CFC molecules takes many decades. Even though the emission of these chemicals has now largely stopped, the CFCs already in the atmosphere will carry on releasing their chlorine and bromine for decades to come, as they are slowly broken down by sunlight in the upper atmosphere. As such, the ozone hole will take about three times longer to disappear than it did to appear, eventually closing sometime in the second half of the century. In the meantime, the thinner ozone shield will lead to some increased levels of surface UV and changes to surface winds and temperature, especially in the southern hemisphere. Even over the past ten years, scientists have struggled to detect the first signs of repair. Polar ozone loss is driven by the formation of stratospheric clouds at low temperatures. This means ozone depletion is worse after colder winters because more cloud particles form. So natural variations in the meteorological conditions in the stratosphere – occasionally enhanced by volcanic eruptions that can replicate the role of the clouds – have helped to mask the small recovery trend. Despite this, scientists have finally started to observe the expected increase in ozone. Comparing the current behaviour of the atmosphere with detailed computer models that remove the effect of meteorological variations shows that recovery really has started. As a result, researchers have a high degree of confidence that the Antarctic ozone hole will gradually decrease and return to its 1980 size, when it first became detectable, by about 2050. It is now a question of being vigilant for other unknown factors and checking that the recovery proceeds as expected. The process of protecting the ozone layer didn’t end when the Protocol was signed, and it has continually evolved with periodic amendments to place stronger controls on ozone-depleting gases and to bring new ones into the agreement. Most recently it has been drafted into the fight against man-made climate change. The ozone-depleting gases being controlled by the agreement are also very potent greenhouse gases. Like carbon dioxide, they very efficiently absorb infra-red radiation and so contribute to global warming.  In the latest amendment to the Montreal Protocol, signed in 2016, policy makers agreed to limit the emission of the compounds designed to replace CFCs, hydrofluorocarbons (HFCs). These gases, used for example in air conditioning units, do not lead to ozone depletion but are greenhouse gases. So bringing them under the umbrella of the Montreal Protocol will help reduce future climate change. We all owe a debt of gratitude to the scientists, politicians and industry leaders who created such an effective and flexible agreement which, 30 years on, is doing what it set out to achieve and more."
"
Share this...FacebookTwitterDespite the trillion-dollar campaign aimed at curbing fossil fuels, the use of coal continues to rapidly expand and is acting to finally pull undeveloped countries out of extreme grinding poverty.
Investors Business Daily (IBD) here reports “coal use is surging across the globe“, citing the National Academy of Sciences, which says there’s an “unmistakable coal renaissance under way” and that coal “has again become ‘the most important source of energy-related emissions on the global scale.'”
Hat-tip: AndyG55
The NAS study shows coal use is expanding strongly in poor Asian countries like India and China, mainly because of its high affordability. IBD writes: “In sum, using coal is a stepping stone to prosperity.”
The IBD site adds that 1,200 coal plants are planned across 59 countries, that coal use around the world has grown about four times faster than renewables, and that China’s reliance upon coal will keep growing:
And according to U.S. government projections, China will add yet another U.S. worth of coal plants over the next 10 years, or the equivalent of a new 600-megawatt plant every 10 days for 10 years.”
The IBD blasts the Obama Adminstration’s plan to cut back on coal use in the USA, writing that the President is living in a “dreamland” and that “the rest of the world has no intention of following Mr. Obama’s act of economic masochism” and that the plan “will cost America hundreds of thousands of jobs” and “the poor will be hurt most“.
Strangely despite surging coal consumption, global temperatures have not risen in close to two decades. Consequently the once highly ballyhooed global warming theory is crumbling,
Read more at Investor’s Business Daily.
Share this...FacebookTwitter "
"News Corp executive chairman Rupert Murdoch has said “there are no climate change deniers around I can assure you” after he was asked at the corporation’s AGM why his company gives them “so much airtime” in Australia. Murdoch was speaking in New York on Wednesday when he received a question from a proxy for Australian activist shareholder Stephen Mayne. Murdoch was asked about the company’s “stance on climate change”. The questioner asked: “What do you believe is the global role of News Corp in the geopolitical climate? If you do believe in climate change, Mr Mayne is interested to hear why News Corp gives climate deniers like Andrew Bolt and Terry McCrann so much airtime in Australia?” Murdoch responded with a promotion of his company’s corporate carbon reduction goals, saying “we have reduced our global carbon footprint by 25% six years ahead of schedule”. Murdoch, 88, who was born in Australia, said News Corp was the first North American media company to commit to “science-based targets to limit climate change” and the company had cut its energy costs by US$18m ($26.5m) since 2014. He also said his company was sourcing its print paper from certified sustainable sources. Murdoch then added: “There are no climate change deniers around I can assure you.” Bolt, a political commentator and blogger for News Corp Australia, is known for promoting the views of climate science deniers, and for his own attacks on “alarmists” and his derision of climate change science. Bolt also has a nightly show on Sky News where he often interviews guests who reject that humans cause climate change. Business writer McCrann is known for attacking the viability of renewable energy in his columns. In an interview on Sky News in early November, McCrann was responding to a question about a statement from 11,000 scientists warning of a climate emergency. McCrann said: “I am sceptical of that word ‘scientist’. I think if you substitute ‘loon and hysteric’ then that is getting more accurately to the description of who these people are.” A 2013 study of climate coverage in Australian newspapers found that one-third of coverage was sceptical and pointed to News Corp titles as the dominant factor. At the time, News Corp said: “News Corp and its newspapers do accept the scientific consensus. There is no company edict on the line to take – editorial control rests with the editors.” Murdoch himself has given conflicting messages over time on his view of the science and impacts of climate change. In 2006, Murdoch appeared to shift his views away from scepticism, saying the planet “deserves the benefit of the doubt”. Since then, his views appear to have reverted back. He told Sky News in 2014 that climate change should be treated with “much scepticism.” In 2015, Murdoch tweeted from a flight over the North Atlantic where he spotted sea ice: “Global warming!” Just flying over N Atlantic 300 miles of ice. Global warming! pic.twitter.com/loXwe7lwtK Later that year, Murdoch tweeted that a United Nations climate meeting would spark “endless alarmist nonsense”, and said he was a “climate change sceptic not a denier”. A climate change skeptic not a denier. Sept UN meets in NY with endless alarmist nonsense from u know whom! Pessimists always seen as sages In October 2018, Bolt himself described Murdoch as a sceptic, claiming that many mainstream media outlets had stopped quoting Murdoch’s views on the issue since his 2006 statement."
"A year ago, a black scar appeared on the far north Queensland landscape. Satellite images and photographs show the aftermath of a bushfire that burned in world heritage tropical rainforest for 10 days. Almost no one noticed when the Japoon national park caught fire – mature rainforest trees destroyed across about 250 hectares. A single story in a local newspaper, focusing on how the fire started, appears to be the only time it has been reported. Experts and rainforest authorities say the remarkable extent of the damage, across an environment supposed to naturally suppress fires, is among the clearest evidence that climate change has shifted the paradigm in the tropics. “When the rainforest was burning, the first thing we learned was that it can burn,” says Leslie Shirreffs, the chair of the Wet Tropics Management Authority. “The fire came outside from adjacent land, but ordinarily when it came to rainforest it would stop.” Last week the authority released a climate adaptation plan that acknowledged the impacts of climate change on 900,000 hectares of north Queensland tropical rainforest and its ecosystems. The authority has previously said climate change damage to the forest is as bad as coral bleaching on the reef. Shirreffs says the plan takes into account observations made by Indigenous traditional owners, including things such as changing seasonal indicators and rainfall patterns, and changing bird behaviour. The adaptation plan focuses on strategies to help build resilience, such as land restoration to strengthen wildlife corridors, pest control and protective habitat elements that might provide species shelter during climate extremes. Climate threats to the rainforest come in many forms. There is a threat from tropical cyclones, which experts say will increase in intensity and impact due to climate change. Recent extreme heat events are also worrying. Centuries-old heat records were broken in north Queensland last year, including at forest mountain peaks which recorded a six-day run of temperatures above 36C. Some creatures, like the rare lemuroid ringtail possum, are unable to survive when temperatures rise above 29C. “The data now shows that lemuroid ringtail possums and potentially other mountaintop species could become locally extinct, at what was previously their most abundant site, within the coming decade,” Shirreffs says. “When you have a 900,000-hectare world heritage area you assume there’s an inbuilt resilience. But that’s without anticipating some of the extremes that are now happening.” The fire broke out after the forest canopy had already been damaged by two other natural disasters. During the past 15 years the area had been hit by two severe tropical cyclones – Larry and Yasi. Vines that had grown into the cyclone-damaged canopy would carry the fire from the forest floor and into the tops of the trees. The dry season had been unusually long and temperatures were at extreme highs for almost a week. At the same time Queensland experienced its first ever “catastrophic” fire conditions, sparking threats to lives and property that diverted most of the attention elsewhere, while the Japoon national park burned. Shirreffs said it was unclear how the rainforest would respond to the fire damage but there were already some worrying signs, including Siam weed, an invasive plant that has begun growing in the burnt area. “We do see [responding to climate change] as a test and it can be sobering what happens around the place, but the wet tropics is a remarkable place, it’s one of the best managed world heritage areas in the world,” she said. “We have to look at the practices we know make forests stronger and we need to step things up. We need to do some out-of-the-box stuff. We don’t have a lot of power while the world gets its carbon budgets in order, but we need to do things that we can.”"
"The Coalition is too closely linked to the fossil fuel industry to be able to contemplate a future without coal, oil or gas. As climate change-induced crises continue through Australia, they must distance themselves from the industry associations and their lobbyists, and face up to a future which is different from the past, one that can be both exciting and beneficial to all Australians. While unprecedented bushfires burn across the country – first in New South Wales and Queensland, then in Western Australia and now in South Australia and Victoria – it is worth pausing for a moment on the word “unprecedented” to let it sink in. Unprecedented does not mean unexpected. At BP, over 20 years ago, we acknowledged climate change and what it would bring and that we needed to reduce emissions. Our acknowledgment brought cries of foul from industry associations and many peer companies. Here in Australia, I argued long and hard inside the Business Council of Australia for a similar acknowledgement of climate change. I failed. Global greenhouse gas emissions each year are not reducing, they are accelerating. The scientific community has been issuing increasingly urgent calls for rapid reductions in emissions with the foresight that global warming trends will bring these kinds of “unprecedented” conditions. The federal government chooses to ignore them. Three decades on from the first report of the Intergovernmental Panel on Climate Change, Australia’s emissions are growing again, as are our fossil fuel developments. Sign up to receive the top stories from Guardian Australia every morning Australia is now the second-largest gas exporter, the second-largest thermal coal exporter and the largest metallurgical coal exporter on the planet. We push our products with the zeal of a drug lord – we do not care about the future misery we are creating. A dangerous game of brinksmanship is on display across the country, as major corporations collaborate with governments to open up more and more basins for exploitation at a time when they know full well the consequences. At the same time, we are the sunniest and windiest inhabited continent on the planet, capable of reducing not only our own emissions through rapid deployment of renewable energy but also creating export industries of a clean future. And yet the government is invested in the past and protecting the status quo. It dares not to rock the boat in which it sails. And Australia is seeing the consequences of this failure as we speak. And so the question – still – is: Why? Australia’s fossil fuel industry has an uncomfortably close relationship with governments, particularly through their industry associations and lobby groups. Many will recall the time that Scott Morrison, thentreasurer, brought a lump of coal into parliament back in 2017. But how many of us have wondered how he came by this prop? It was a gift. A neatly shellacked lump of coal, of course, so Morrison didn’t get any dirt on his hands, was gifted to him by the then CEO of the Minerals Council of Australia, Brendan Pearson, a man who earlier this year moved across into an advisory role in the office of now prime minister Morrison. I have seen how industry associations, in Australia and overseas, are simply the mouthpiece of those who are invested in the status quo. The nature of these groups causes them to move at the pace of the slowest, and the standard of the lowest – bankrolled by those who are most heavily invested in the past. The problem, as we are now seeing, is that the industry associations are also heavily invested in our political processes, to the detriment of us all. Our politicians are afraid of the future. They are afraid of foresight. They too are invested in the past and walk backwards into a warmer future. The Coalition must turn its back on the industry associations and their lobbyists, face the future and act in the interests of future generations. Because current generations are turning their backs on them. • Greg Bourne is a climate councillor and former head of BP Australasia"
"
Share this...FacebookTwitterProfessor Fritz Vahrenholt and Dr. Sebastian Lüning recently took a look at the odd behavior of former IPCC author Peter Wadhams, who now suspects the oil industy of being behind the accidental deaths of three climate colleagues.
Three British scientists have lost their lives since 2013 – all three had been involved in Arctic research. One was killed by lightning, another fell down some stairs, and the other killed in a bicycle accident. This series of unfortunate, yet totally unrelated, incidents is enough to have Wadhams thinking it may well be a sinisterly crafted campaign orchestrated by Big Oil.
The Telegraph reported:
Three scientists investigating melting Arctic ice may have been assassinated, professor claims
Cambridge Professor Peter Wadhams suspects the deaths of the three scientists were more than just an ‘extraordinary’ coincidence […] The three scientists he identified – Seymour Laxon and Katherine Giles, both climate change scientists at University College London, and Tim Boyd of the Scottish Association for marine Science – all died within the space of a few months in early 2013. Professor laxon fell down a flight of stairs at a New year’s Eve party at a house in Essex while Dr Giles died when she was in collision with a lorry when cycling to work in London. Dr Boyd is thought to have been struck by lightning while walking in Scotland. […] Asked who might have wanted them out the way, [Wadhams] replied: “I can only think of the oil lobby but I don’t think the oil lobby goes around killing people.”

Read the entire aricle at The Telegraph.
Vahrenholt and Lüning write that Wadhams’s behavior appears to be part of a larger pattern of behavioral eccentricity. They write:”Already in the climate discussion he’s been turning off his colleagues totally with his hysterical climate catastrophe scenarios.” For example Wadhams is among those who promote the Arctic sea ice death spiral, telling the world in 2012 that the Arctic would be toast by the year 2016. Even the most hardcore alarmists think that particular scenario is preposterous. Last September Gavin Schmidt wrote at Twitter:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Some anticipation for Peter Wadhams. Audience members already crying, ‘Wadhams still using graphs with ridiculous projections with no basis in physics,’ ‘Wadhams now onto methane pulse of 50 GT. But no better justified than his previous statements,’ and ‘Wadhams clearly states that there is no physics behind his extrapolations.’”
The Arctic sea ice Armageddon is not the only nutty fantasy Wadhams is obsessed with. He is also hysterical about the methane bombe. Spiegel Online reported in 2013 that a group of leading scientists declared an imminent climate catastrophe.
Scientist Gail Whiteman of Ersmus University in Rotterdam calculated together with Chris Hope and Peter Wadhams of the University of Cambridge how expensive climate change at the poles could be for the entire world. The researchers arrived at a figure of 60 trillion dollars– that is about equivalent to the entire global output for 2012. […] In 2010 Natalia Schachowa of the University of Fairbanks in Alaska for the first time reported on the unsettling phenomenon of methane release in Siberia, and that it could be a sort of Arctic time bomb.
It turns out that this time bomb is pure fantasy from hysterical minds. There is no scientific basis for it. The estimates of damage are also of no value.
Renowned climate scientist Judith Curry made it clear in an article at her blog titled “Arctic time bomb (?)” that a large number of colleagues do not share the Arctic methane catastrophe. Even Gavin Schmidt of NASA sees only a minimal chance of a rash release of methane in the Arctic. Tipping point specialist Tim Lenton of Exeter University also sees no urgent danger and sees a process happening only on a scale of tens of thousands of years. A report by Carolyn D. Ruppel in 2011 also shows the same. Curry also mentions other critical opinions, like those of David Archer of the University of Chicago who calls the methane climate bomb scenario “completely baseless”.
Lüning and Vahrenholt conclude that when one considers the recent conspiraicy theories made by Wadhams along with his wild climate claims, “A picture is created of a man who has manoevered himsefl into a  extremely far fringe corner in the climate dicussion. Wadhms has squandered is credibilty. There should be no place for an activist. on a referee panel like the IPCC.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterU. of Southampton: We won’t know whether or not sea level is accelerating until 2020-2030. Mojib Latif: models must first take natural variability much more into account
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(Translated and edited by P Gosselin)
Forecasts have long since fascinated man. There’s something mystical about looking into the future. The oracle of Delphi, a look into the crystal ball, reading tea leaves: indeed the error rate is high, yet that does not deter people from paying more money for more far-fetched predictions.
The ClimateChangePredictions.org website has taken on the task of putting climate change predictions on the test stand to see whether or not they have anything to do with reality. One nice example is sea level rise. Currently sea level is rising 2 – 3 mm per year, and if the trend remains stable, a sea level rise of 25 cm is expected by the end of the century. However this does not keep some attention-seekers from announcing much higher rises to the public. At the ClimateChangePredictions.org website here you will find a highly interesting list of prognoses.
Australian climate scientist John Church predicted 3 m by 2100. For others that figure is much too low, and we are threatened instead with 7 m – or even 100 m! We almost get the impression that the higher the bid, the better the chances of winning – at least that’s the impression we get from the media.
Serious studies show just how absurd the sea level rise bidding has become. Within the framework of a European research program supported by a total of 10 million euros, a consortium of 24 institutes investigated scenarios for future sea level rise. Participating among them was the Bremerhaven-based Alfred Wegener Institute (AWI). The main aim of the 2009 to 2013 ice2sea program was to quantify the melting of land-based ice masses. In May 2013 the researchers presented their Final Report (pdf here). The consortium of scientists concluded that the most probable scenario for sea level by the end of the century is a rise of only between 16.5 cm and 69 cm. That was a bitter disappointment for the alarmists in the field.
So what purpose do the alarmist prognoses serve? Some originate from government organizations, who use them to prop up their aggressive climate policy aims. In the USA the Obama Administration warned of a rise of a rise of 2.10 m by the end of the century – far remote of the mainstream science.
The most recent IPCC report also appears to have lost all contact to reality, which despite all the careful prognoses found in the scientific literature, claims there is a rising danger from sea level rise. Here people like to look 2000 years into the future, absolute nonsense when one considers the numerous poorly known sea level trends.
Who is finally going to blow the whistle on the shrill alarmists and their predictions of a coming flood? When prognoses are far beyond the fringes of the accepted range, it should cause us to stop, think and cast doubt on apocalypse forecasters. For the press they couldn’t care less and gladly view it as a convenient source of attention-grabbing spectacular climate stories.
Within the scientific community, however, scientists see the predictability of sea level far more critically. In March 2015 a group of scientists lead by Mohammad Bordbar – which also included Mojb Latif – published a study that took the natural variability of sea level into greater account. The abstract of the paper stated that we can no longer continue to ignore these processes. The paper appeared in Nature Climate Change. The abstract reads:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Effects of long-term variability on projections of twenty-first century dynamic sea level
Sea-level rise1 is one of the most pressing aspects of anthropogenic global warming with far-reaching consequences for coastal societies. However, sea-level rise did2, 3, 4, 5, 6, 7 and will strongly vary from coast to coast8, 9, 10. Here we investigate the long-term internal variability effects on centennial projections of dynamic sea level (DSL), the local departure from the globally averaged sea level. A large ensemble of global warming integrations has been conducted with a climate model, where each realization was forced by identical CO2 increase but started from different atmospheric and oceanic initial conditions. In large parts of the mid- and high latitudes, the ensemble spread of the projected centennial DSL trends is of the same order of magnitude as the globally averaged steric sea-level rise, suggesting that internal variability cannot be ignored when assessing twenty-first-century DSL trends. The ensemble spread is considerably reduced in the mid- to high latitudes when only the atmospheric initial conditions differ while keeping the oceanic initial state identical; indicating that centennial DSL projections are strongly dependent on ocean initial conditions.”
Natural variability currently makes it impossible to determine if the speed of sea level rise is beyond the range of natural variability. The University of Southampton also explicitly reports this in a press release dated 9 May 2014. It is necessary to first understand the natural processes and to account for them in the development of sea level rise before an anthropogenic signal can be identified and quantified. It’s indeed going to take another 5 to 15 years before scientists are able to decide whether or not sea level rise has accelerated in an unusual manner. What follows is the press release in its entirety:
“Back to the future to determine if sea level rise is accelerating
Scientists have developed a new method for revealing how sea levels might rise around the world throughout the 21st century to address the controversial topic of whether the rate of sea level rise is currently increasing.
The international team of researchers, led by the University of Southampton and including scientists from the National Oceanography Centre, the University of Western Australia, the University of South Florida, the Australian National University and the University of Siegen in Germany, analysed data from 10 long-term sea level monitoring stations located around the world. They looked into the future to identify the timing at which sea level accelerations might first be recognised in a significant manner.
Lead author Dr Ivan Haigh, Lecturer in Coastal Oceanography at the University of Southampton, says: “Our results show that by 2020 to 2030, we could have some statistical certainty of what the sea level rise situation will look like for the end of the century. That means we’ll know what to expect and have 70 years to plan. In a subject that has so much uncertainty, this gives us the gift of long-term planning.
“As cities, including London, continue to plan for long-term solutions to sea level rise, we will be in a position to better predict the long-term situation for the UK capital and other coastal areas across the planet. Scientists should continue to update the analysis every 5 to 10 years, creating more certainty in long-term planning — and helping develop solutions for a changing planet.”
The study found that the most important approach to the earliest possible detection of a significant sea level acceleration lies in improved understanding (and subsequent removal) of interannual (occurring between years, or from one year to the next) to multidecadal (involving multiple decades) variability in sea level records.
“The measured sea levels reflect a variety of processes operating at different time scales,” says co-author Dr Francisco Calafat, from the National Oceanography Centre. He adds, “One of the main difficulties in detecting sea level accelerations is the presence of decadal and multi-decadal variations. For example, processes associated with the North Atlantic Oscillation have a strong influence on the sea levels around the UK over multi-decadal periods. Such processes introduce a large amount of ‘noise’ into the record, masking any underlying acceleration in the rate of rise. Our study shows, that by adequately understanding these processes and removing their influence, we can detect accelerations much earlier.”
Co-author Professor Eelco Rohling, from the Australian National University and formerly of the University of Southampton, adds: “By developing a novel method that realistically approximates future sea level rise, we have been able to add new insight to the debate and show that there is substantial evidence for a significant recent acceleration in the sea level rise on a global and regional level. However, due to the large ‘noise’ signals at some local coastal sites, it won’t be until later this decade or early next decade before the accelerations in sea level are detection at these individual tide gauge sites.”
The findings of the study, funded by the Natural Environmental Research Council (iGlass consortium), are published in this months issue of the journal Nature Communications.”
 
Share this...FacebookTwitter "
"Global carbon emissions from the aviation industry are growing faster than expected, and pose a serious risk to the world’s climate efforts if left to grow unchecked. The rise of flygskam, or “flight-shame”, has spurred airlines and travel companies to offer customers the option of offsetting the carbon emissions of their flights. But not everyone is convinced that climate sins can be absolved through projects based on simple carbon accounting. Offsetting involves calculating the emissions of a trip or activity and then purchasing “credits” from projects that prevent or remove the equivalent amount of greenhouse gases elsewhere. Many accredited carbon offsetting schemes involve planting trees to absorb carbon dioxide from the atmosphere, which according to recent research could play a major role in helping to tackle the climate crisis. Other schemes invest in renewable energy projects which save carbon emissions by replacing fossil fuels alternatives. Growing awareness of the climate crisis, and the “Greta Thunberg effect”, has driven demand for carbon offset schemes. The amount of investment from people who hope to “cancel” their carbon footprints has climbed fourfold in recent years, according to the offsetting watchdog Gold Standard. EasyJet’s pledge to fly carbon neutral follows a string of other airlines which hope to encourage passengers to keep flying despite climate concerns. At least 10 other airlines – including Air New Zealand and Air Canada – offer carbon offsetting to their passengers. British Airways said this year that it plans to start offsetting the carbon from all its domestic flights from 2020. For passengers travelling further afield BA offers a carbon calculator and a range of accredited offset schemes to invest in. The schemes include reforestation in the Amazon basin and fitting low-smoke stoves in Sudan. Royal Dutch Shell offers drivers which fill up at its petrol stations in the UK and the Netherlands the chance to “drive carbon neutral” at no extra cost by using carbon credits from conservation projects in Peru, Indonesia, the US and Britain. In short, airlines plan to use carbon offsetting to address the aviation’s expanding carbon footprint while continuing to increase the number of flights they offer every year. The aviation industry plays a growing role in the climate crisis by releasing hundreds of millions of tonnes of carbon into the atmosphere every year. The global carbon emissions from commercial flights are rising up to 70% faster than predicted, according to the International Council on Clean Transportation, because of growing demand for air travel in developed countries. The group said emissions increased by a third between 2013 to 2018, the equivalent of building 50 coal-fired power plants, and may triple by 2050 if left unchecked. If airlines hope to avoid a backlash against the industry while still increasing the number of flights they operate, then offsetting is the quickest answer. Not all airlines have taken up carbon credits. American Airlines, the world’s biggest airline, does not offer an offset scheme. Instead, it has taken “many meaningful steps to reduce fuel consumption and CO2 emissions” such as buying new planes which are more fuel efficient. Green groups are clear that the best way to reduce emissions from the aviation industry is to take fewer flights. Many fear that carbon offsetting may do more harm than good by offering airlines a licence to keep polluting and encouraging travellers to continue to choose the most polluting option. There is also concern among environmentalists that the confusing state of carbon accounting may mean that projects fall short of neutralising the damage caused by air travel in the first place. Greenpeace UK described easyJet’s carbon offset scheme as “jumbo-size greenwash” and warned that expert analysis has cast serious doubts about whether offsetting schemes work at all. Instead, policymakers should put in place a frequent flier levy to curb the number of flights and their climate-wrecking emissions, Greenpeace said. Other groups have urged passengers to view carbon offsets as a last resort which can be used as a positive nudge to donate to green projects – not as a solution to the climate crisis. The early days of voluntary carbon offsetting were relatively unregulated and open to abuse. Today, a flurry of watchdogs have emerged to verify carbon offset schemes and projects which help to make the carbon savings. These include the American Carbon Registry, Climate Action Reserve, Gold Standard, Plan Vivo and Verra, which offer many hundreds of projects for business and individuals to choose from. Gold Standard offers carbon offsets which help install low-smoke stoves in Rwanda and build wind power projects in Rajasthan, India. C-Level will offset carbon emissions by helping to restore grasslands in Mongolia and reducing deforestation in Tanzania."
"Is Britain really using far less food, fuel, metals and materials now than at the turn of the century? Have we reached “peak stuff”? Certainly the UK Office of National Statistics figures for 2000-2013 seem to suggest this is the case. The problem is that these figures don’t take into account the full range of materials that went into the products we import. The ONS calculates the effects of trade on the UK’s materials use in a way that takes into account everything required to produce any goods consumed in Britain, whether they originated in the UK or abroad. This is called the total raw material consumption, and is effectively the country’s “material footprint”. To reach this figure, ONS takes the materials extracted from within the UK’s territory, subtracts those materials involved in the production of exported goods, and adds materials that are involved in the production of imported goods.  Removing the impact of exported goods is straightforward because we know the total materials that are required to make UK products. But in order to estimate the materials involved in imports, we need to know how much of each different type of product we import, from where, and how efficiently industries are in the country that produces that product. The problem is that the ONS assumes that UK imports have the same profile as the European average when in reality the UK’s trade partners will be different. This is important because production practices vary worldwide and knowing exactly where the UK imports from will give a more accurate number for the material footprint. So our research group tried to calculate the UK’s material footprint taking this production variation between countries into account. To do this we used a model of global trade that understands how industries trade with other industries all over the world. What we found was that while domestic material consumption has fallen (the blue portion of the figure below), this has been overshadowed by rising imports – particularly from China and the rest of the world where material efficiency is, on average, worse than Europe. We found an estimated material footprint for the UK for 2011 that was 18.5 tonnes of material per person, with 57% of this originating from China and the rest of the world. In 2001 this proportion was 47%, and in 1970 it was just 15%. This is considerably higher than the figures reported by the ONS for 2011 where the material footprint is 10.3 tonnes per person. Our figures also reveal a sharp increase of consumption until the economic crisis in 2008, and a study by Thomas Wiedmann and colleagues published recently concluded something similar: that Britain’s material footprint has risen over the last 20 years, peaking at around 25 tonnes per person in 2008. The ONS report on the other hand points to a general decline in UK material consumption, and particularly that this decline comes despite a growth of GDP at the same time. Could this be, as has been suggested, due to UK households purchasing fewer resource-intensive goods – for example, by replacing physical items such as CDs and books with digital media? In fact our research shows that both the increase prior to the economic crisis in 2008, and the fall that followed it, are mainly driven by the use of construction materials. ONS data for the construction industry shows that the value (in 2013 prices) of construction industry work increased from £44 billion in 2000 to £81 billion in 2007, before dropping to £66 billion in 2009. House building rose from 176,850 completions in 2000 to 226,420 in 2007, plunging to 137,280 in 2010. This is matched by a reduction in the portion of the material footprint between 2008 and 2009 made up by construction materials, which fell by 7.3%, ores by 1.0%, and fossil fuels by 3.9%. So have Western economies like Britain really hit “peak stuff”? We’d argue that the materials required by the UK follow the patterns of economic growth more closely than the data reported by the ONS. Speculation that this has peaked seems premature while we are still in a period of economic recovery. Only time will tell if we can successfully decouple the link between GDP and material use – buying less even as we grow richer."
"When you think of China, animal welfare probably isn’t the first phrase that springs to mind. In a country known for its fur farms, bile bears and live animal eating, you could be forgiven for assuming everyone is in on the act.  Given China’s track record when it comes to animal exploitation – much of which was sanctioned by government – it’s not surprising the Middle Kingdom still has a bad reputation. A year ago, I too would have said it was accurate. But, after making two research trips to the country in the past year, I can firmly say my head has been turned. Never would I have imagined China would become one of my top countries in the world for conservation and animal welfare.  My first impression upon arriving back in Beijing after 20 years in May 2015, was not good – for a start the smog was much worse than I remembered it.   I was in the country to participate in an international zoo animal welfare conference, a workshop at Beijing Normal University, and to visit some wildlife sites in Sichuan Province. At the conference, scientists from all over China and from many Chinese zoos presented their work showing how they were creating highly-stimulating enclosures for zoo animals. It was excellent quality research. This is all the more impressive when we realise that there is not the massive public pressure found in Europe or North America to improve the well-being of captive animals. I knew I’d see some amazing species while in China, though I expected them to be largely confined to small islands of green in the midst of a highly modified and human-impacted landscaped. But entering the mountains of Sichuan reminded me that China still has vast areas of relatively pristine land. I visited one such area, Tangjiahe Nature Reserve, in search of large goat-like antelopes called takins and the golden snub nose monkey. Sadly, we didn’t encounter any monkeys, but I did however find the park was full of Chinese tourists. This may not sound that unusual, but – rather ironically – national parks in many less developed countries are rarely visited by the nationals of that country. Tour operators in such countries often think of ecotourism as the sole preserve of foreign tourists. Despite what many people might think, all the national parks I visited in China were extremely well organised with great infrastructure. For example, there were CCTV cameras on trails and even on mountaintops, which permitted the observation and control of tourist behaviour in ecologically sensitive areas. In fact, tourists were only permitted entry to the best wildlife areas when accompanied by a trained guide – and special authorisation was required to enter the most sensitive areas of all. In Chengdu I visited Animals Asia’s bear sanctuary, where bears previously kept for bile farming are rehabilitated. The sanctuary is compromised of many large and highly enriched bear enclosures, a bear hospital and a poignant bear graveyard. Currently it is home to more than 150 bears who will live out their days there in some comfort, before becoming residents of the aforementioned graveyard. This centre had been set up by Europeans, but it was largely staffed by locals doing amazing work while training other Chinese institutions.   In September 2015, I returned to China with six of my PhD students to see those elusive golden snub nose monkeys. We went to participate in a postgraduate workshop about animal conservation – and again what struck me was the passion the young Chinese scientists had for wildlife and conservation.   Yes, China still has many serious problems when it comes to animal welfare, with much of its wildlife forced to retreat into the mountain fortresses of the Tibetan Plateau. But there is hope. China is now producing many young scientists and biologists who do not simply see their work as a job, but more as a vocation. The access these scientists have to funding and technology, and their increasing contact with foreign institutions, mean things are looking up."
"
Share this...FacebookTwitterAlthough over the last 2 years the current solar cycle saw some activity, it recently has quieted down considerably and it continues on the path to being one of the quietest since observations began over 350 years ago. -PG
===============================
The Sun In March 2015
By Frank Bosse and Fritz Vahrenholt
Translated, edited by P Gosselin
Last month our sun gave a really sluggish impression. The sunspot number (SSN) was only 38.4: only 46% of what is normal at this time into a cycle for all the cycles observed since 1750.

Fig. 1: The current solar cycle 24 compared to the mean of all previous cycles (blue) and to solar cycle no. 1, 1755-1766, (black).
Comparing the individual cycles to each other further confirms that the current cycle is a quiet one compared to those we saw in the second half of the last century:

Fig. 2: Comparison of all the solar cycles. The figures represent the summed SSN deviation from the mean for first 76 months into the cycle, for all cycles. The current cycle so far is the 4th most inactive since observations began in 1750.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The current cycle is the quietest since solar cycle no. 7, which occurred around 1830. When it comes to the question of why, the polar magnetic fields of the sun are decisive. We reported on this in detail (see “The sun in Jaunary 2014 and news about the polar solar field“). Its been a few months since the last data recording and today we are 2 years past the suspected smoothed maximum. The polar fields went through the zero-point already in March 2013, as can be seen from the data from the Wilcox Solar Observatory (WSO). There it can be seen that especially the north polar field is still barely established.
How does that compare historically?
Recording of data for the polar fields first began in the early 1970s, which means the time period is still too short to allow real comparisons to be made. But in a paper from 2012 the authors led by Andrés Muñoz-Jaramillo used the observations of solar flares made since 1900 as a proxy for the sun’s polar fields. The lead author of the paper kindly agreed to share the data with the authors of this article and so it is possible to compare the current relationships with the long-term series:

Fig. 3: The relative strength of polar solar fields since 1900.
Here it is clear to see that in the second year past the cycle peak, the polar fields have never been so weak. Consider that the strength of the sun’s polar fields during the solar sunspot minimum is a decisive indicator for the activity of the next solar cycle. A very recent paper by Robert Cameron and Manfred Schüssler confirms this.
We only need to be patient a little longer and to pay further attention to the ongoing development of the sun’s polar fields in order to attempt a forecast. The preliminary indications do point to a low level of activity and thus perhaps an even weaker solar cycle 25 beginning around 2022.
 
Share this...FacebookTwitter "
"Until the advent of cheap credit and cheaper item costs, for many consumers in the 1960s, 1970s and 1980s rental was the most accessible way of obtaining products such as televisions, video recorders and washing machines that were high cost and frequently required repair. Now we buy cheap and pile high or just chuck out when something stops working – even if we could fix it.  The consumption of household goods in Western society is now at its upper limit, so much so that Steve Howard, Ikea’s head of sustainability, said it had reached “peak stuff”. While he was quick to say that this did not contradict Ikea’s target to double sales by 2020, he suggested a break from a prevailing “take, make, use, throw” economic model towards a circular model that encourages repair, reuse and collaborative ventures that share the use of products. At the heart of the circular economy is the sharing economy, in which products and services are leased for a time. It’s about access rather than ownership, and any number of things can be shared, from transport, property and consumer goods (such as tools and kitchen appliances), as well as skills and knowledge.  Participation in the sharing economy lets you use under-utilised assets and even spare time to earn additional income. There have been routes to borrowing items for many years – hiring formal clothing for events, for example, or car sharing schemes that are now commonplace in many cities. And despite more recent funding cuts, public libraries still offer access to books, music and films, while big businesses such as Amazon Kindle, Netflix and Spotify mean there is no need to actually own physical, hard copies of media items. But sharing, borrowing and reusing is now becoming something that businesses are actively engaging in. Take the Riversimple Rasa – a hydrogen fuel cell car that has been designed specifically within a car-share business model.  After an initial failure, SpaceX’s attempts to recover and reuse its Falcon 9 booster met with success, and in 2017 one recovered booster was used to launch a communications satellite. Rival company Blue Origin is also developing its reuseables. It means that in the age of space travel, we may already be taking advantage of cheaper, recycled technology. Back down to Earth, local community schemes have the potential to share expensive and rarely used items and change the way household goods are consumed. Grassroots examples include the Library of Things in London, a community business providing low-cost access to items such as DIY tools, sewing machines, camping and gardening equipment, carpet cleaners, projectors and musical instruments.  While sustainability is at the heart of the project, which resists an own everything, throwaway culture, the library is also a social space with a practical purpose. It reinvents the traditional models of renting, swapping, bartering and gifting, and also offers a place to meet and learn new skills through classes, workshops or one-to-one instruction in cooking, sewing, furniture making and general DIY skills.  This kind of scheme empowers people to use the items they borrow and to do things for themselves. And given that the average electric drill is in use for just 15 minutes each year, and is kept in storage for the rest of the time, it’s clear that many “household” items don’t really need to be owned at all. And sharing or borrowing means a better environmental impact.  The right to ownership and property is deeply rooted in Western culture for reasons from social status to convenience. Nevertheless, increasing the number of items that are leased or rented is feasible – the sharing economy offers financial savings and access to better quality goods in the short term, while reducing people’s personal carbon footprints, and in the case of projects like Library of Things and repair venture, Restart, a greater sense of community and skills sharing. Established businesses may see these enterprises as a threat to their business models. After all, if consumers share or rent things, this might impact on sales. However, it could instead incentivise manufacturers to produce more reliable, durable products which they would retain ownership of and lease to consumers, remaining responsible for maintenance and replacement costs. This would mean further incentives to design and produce longer-lasting, reliable products which could easily be repaired or re-manufactured and passed onto less demanding customers at a lower cost.  Sharing as part of a circular economy promotes better efficiency in materials, which reduces the lifetime carbon emissions of products that are designed and maintained for optimum life spans and used more intensively. It allows for a growth in consumption without the corresponding demand for resources. This is one area that needs addressing if we are to stand a chance of reaching the targets set in the Climate Change Act and meeting commitments under the Paris Agreement."
"Romania’s prime minister, Mihai Tudose, recently raised the prospect of reopening the country’s huge Roșia Montană goldfield. The area had been mined from Roman times until the last state-run operation closed in 2006. An application by a previous government to make the area a UNESCO world heritage site has now been withdrawn, paving the way for new development.  Roșia Montană is nestled in the Carpathian mountains and, with 314 tonnes of gold, has Europe’s largest known deposits. A short-term mining bonanza promises employment for thousands of labourers and hundreds of millions of Romanian Leu in investment in the EU’s fastest-growing economy. But is the boom really worth it? After all, gold mining has historically resulted in long-term, chronic environmental problems. Roșia Montană is big, but the threats posed by acid mine drainage are bigger. The problem is, if completed, the so-called Roșia Montană project would use “cyanide amalgamation” to extract the gold from its ore body. This is the same cyanide used to poison people, fish and elephants. It has a toxic past in Roșia Montană, too: back in the 1970s, a copper mine in the area needed somewhere to store its cyanide-contaminated waste and the nearby village of Geamana was evacuated and flooded. It has been submerged under toxic waters ever since.  Geamana is one of Romania’s greatest ecological disasters, surpassed only in 2000 when a gold mine in Baia Mare in the north of the country spilled an estimated 100 tonnes of cyanide into a river. The latter incident was described as Europe’s worst environmental disaster since Chernobyl. No wonder that when the government first mooted the resumption of mining in 2013, it led to weeks of protests – protests which now threaten to erupt again. Cyanidation was the breakthrough gold mining technology of the 1890s, when it enabled Anglo mining conglomerates to make colossal profits from low grade ores. Simply put: cyanidation involves mixing finely crushed ores (referred to as “sands” or, when water-based, “slimes”) in a weak cyanide solution (usually calcium cyanide). This solution is then mixed in large tanks and the gold separated from its ore body.  The process increases yields of gold but produces immense quantities of highly-toxic waste that releases acid and metals into the environment. Around 90% of all gold extracted worldwide uses this method. The waste from cyanidation is a fine rock solution that is left in open air ponds while the concentration of acid is reduced to legal limits. The risk here is from dam failure or breakages in the lining of waste ponds, which can lead to catastrophic spills or leakage through the porous land surface into the water table.  In nearly all metal mines, and some coal mines, acid drainage occurs because of the oxidation of iron ore found alongside precious mineral deposits. Uncovered by the mining process, the iron reacts with the air and releases sulphuric acid into the water. This process can last centuries. Spills from cyanidation waste are more short-lived, but more highly toxic than acid mine drainage occurring through iron oxidation.  The ratio of waste to metal recovered in gold mining is vastly disproportionate: the Fimiston Super Pit, near the West Australian town of Kalgoorlie, and until recently the largest open cut mine in the world, has returned approximately 1,640 tonnes of gold since operations began there in 1989. But that’s only a small portion of the 15m tonnes of rock extracted per year. On a more personal scale, a single gold wedding ring generates 20 tonnes of waste. Cyanidation poses catastrophic ecological risks because cyanide leaks so easily into groundwater. Historical parallels suggest the Romanian proposal will most likely leave a toxic legacy. In 2015, as the US Environmental Protection Agency attempted to drain polluted water from the Gold King Mine, Colorado, which was closed in 1920, more than 3m gallons were accidentally spilled into the Animas River. The polluted plume turned the entire river a deep mustard yellow. Water acidity levels increased 100-fold, and in some places a thousand times over levels considered safe for wildlife.  The spill only posed no threat to fish in the Animas because ongoing pollution had already killed them. But the plume drained into the San Juan, a larger and cleaner river that flows into the spectacular Glen Canyon and, eventually, the Grand Canyon. There, the pollution threatened rare birds and endangered fish like the Colorado pikeminnow and razorback sucker. EPA chief Scott Pruitt returned to the site at the beginning of August this year vowing to complete the clean-up after the agency had “walked away” from the problem. At a water treatment plant installed on the site, 500 gallons of mercury and arsenic-laced water a minute flow from the Gold King Mine. The clean-up could take a decade and has already cost the EPA US$29m. The EPA has estimated that the cost of cleaning up just 156 mines in the US could be between US$7billion and US$24 billion. Clean-up on most sites will take decades – those with acid drainage will require water treatment in perpetuity. Acid drainage is a little-known global crisis. The UN has even labelled it the second biggest problem facing the world after global warming. In the US, an estimated 22,000km of streams and 180,000 acres of freshwater reservoirs are affected by acid mine drainage. Rivers and lakes in Arizona, Patagonia, Guangdong (China), Ontario, Papua New Guinea, and at Rio Tinto in Spain, to name just a few, have all been polluted by acid mine drainage. In South Africa, the problem is chronic. These threats are prescient. Brazil recently announced a huge reserve in the Amazon rainforest has been earmarked for mining, including gold. In New Zealand, local activists fear the Karangahake Gorge is now under threat after a large, high-quality gold seam was found in the region. Around the Yellowstone National Park, mining companies are positively salivating at the possibility that Obama-era restrictions will be lifted, granting access to 3,000 tonnes of proven in-ground gold reserves. In Peru, marines have been dispatched to wage war against illegal mining on the River Santiago in the northern Amazon, which has done enormous damage to the region’s bio-diversity and placed the livelihoods of 70,000 indigenous Awajúns and Wampís at risk. Multinationals hold out the promise of sustainable development through mining. But without careful forethought we’ll find ourselves dealing with chronic pollution for centuries."
"
Share this...FacebookTwitterNo blogging today. Just want to wish everyone a Happy Easter!
Thanks for all the kind words in yesterday’s post. It really means a lot to me and encourages me to keep blogging.
Share this...FacebookTwitter "
"An estimated 6,000-14,000 tons of sunscreen are deposited into coral reef areas of the sea every year. The chemicals we rub onto our skin might help prevent skin cancer but we’re only just beginning to understand the environmental impact of sunscreen – and the initial assessments are not looking good. But early stage research suggests that nature might provide a solution to this emerging problem if we can mimic the way that some plants and animals protect themselves from the sun. Sunscreen is vital to helping prevent skin damage from ultraviolet radiation (UVR) that can cause melanoma and other skin cancers. They contain a number of ingredients that act as UVR filters, absorbing and scattering the radiation and stopping it from reaching the skin. Many studies have demonstrated the benefits of regular sunscreen use, including long-term studies in Australia that have shown reduced skin cancer rates.. The potential problem is that many ingredients used in sunscreen products are synthetic organic molecules, like those used to make plastics. These molecules are designed to be highly stable and so they don’t break down when they enter the environment. As a result, sunscreen ingredients are detectable in species including fish, sea mammals such as dolphins and even marine dwelling birds. The impact of these molecules on the environment isn’t fully understood but is a growing focus of research. We know that some filters have a similar structure to the hormone oestrogen and mimic can its action. This can cause hormonal changes and even alter the sex characteristics of some fish. UVR filters have also been linked to coral bleaching.  These concerns are being monitored by many regulatory agencies. The European Chemicals Agency has listed eight out of the 16 most commonly used sunscreens in Europe as a potential threat to the environment and health, raising the ultimate possibility of a ban. Fears about damage to coral reef systems has already led to bans of particular sunscreen ingredients in some coral hotspots such as Hawaii. These fears are currently relatively minor – but ways to improve the safety and biocompatibility of sunscreens need to be investigated. As is often the way, the answer may lie within the very environment that is being affected. Many marine species are continuously exposed to high levels of UVR throughout the day and have evolved efficient ways to prevent damage. For example, microorganism species such as cyanobacteria and algae produce a group of compounds called mycosporine-like amino acids (MAA), which act as UVR filters. These are passed up the food chain to animals such as corals, invertebrates and fish, which then store the compounds in tissues exposed to UVR such as the skin, eyes and eggs. MAA efficiently absorb UVR and convert it to harmless light and heat, and aren’t broken down by the radiation.  There is also evidence that these compounds can act as potent antioxidants, another very beneficial property that most synthetic filters don’t have. Solar radiation can cause highly reactive atoms or molecules, known as free radicals, to break away from other bigger molecules. Free radicals can cause what is known as oxidative damage to tissues, but they can be neutralised by antioxidants The potential for these compounds to be applied to human health, particularly as sunscreens, is only just beginning to be explored. They have shown excellent potential in laboratory models. The next step is to translate this to human studies to truly understand their potential. In the meantime, it’s very important for public health that people don’t stop using synthetic sunscreens. So far, there is only limited evidence for the potential ecological harm of sunscreens, especially at the concentrations at which UVR filters are found in the environment. But the effects of UVR on the skin are well known and proven beyond any doubt."
"Jeremy Corbyn has urged the public to vote for his “manifesto of hope” as he unveiled plans for the most dramatic increase in tax and spending in more than half a century if Labour wins power next month’s general election. In an upbeat launch event at Birmingham City University, the Labour leader said he welcomed the hostility of the billionaires, bad bosses and dodgy landlords who would lose out from his policies. Experts were taken aback by the scale of Labour’s spending plans, which dwarfed the substantial increase in the size of the state envisaged in the party’s 2017 manifesto. “See this [2019] manifesto and vote for the person who’s struggling who you don’t even know,” Corbyn urged the public, adding: “How can any government claim it cares about our country when it cares so little about the people who live here?” With Labour still trailing significantly behind the Conservatives in the polls, party strategists hope the manifesto will help to tempt wavering voters. Corbyn said it was “full of popular policies that the political establishment has blocked for a generation”. The slim red volume, titled It’s Time for Real Change, included a number of fresh announcements, in addition to the policies announced earlier in the campaign. Key plans include: Universal free broadband, delivered by part-nationalising BT and paid for with a tax on tech companies. An immediate 5% pay rise for public sector workers, plus above-inflation increases for future years. 100,000 new council houses a year by the end of the parliament. 1 million new jobs as part of a “green industrial revolution”. Nationalisation of rail, water and mail, and new powers to allow councils to take control of bus services. Corbyn promised an “investment blitz”, which he said would leave no part of the country untouched, and suggested the deindustrialisation that begun in the 1980s would be reversed. “Margaret Thatcher’s government wiped out huge swathes of Britain’s industry. We will rebuild it, as green industry,” he said. Torsten Bell, the director of the Resolution Foundation thinktank, said: “This spending increase would be comparable to the first Wilson government and would mean the UK having a bigger state than Germany.” Corbyn acknowledged his plans were radical, saying they would transform society, but he insisted there would be no increase in income tax, national insurance or VAT for 95% of taxpayers, with only those paid more than £80,000 a year paying the price. “You really can have this plan for real change because you don’t need money to buy it. You just need a vote, and your vote can be more powerful than all their wealth,” he said. But with the plans requiring an extra £82bn a year in tax revenue by the end of the next parliament, some analysts said the changes envisaged, including a significant increase in corporation tax, would be likely to have knock-on effects lower down the income scale. Paul Johnson, director of the Institute of Fiscal Studies, a leading economics thinktank, said: “The truth is of course that in the end corporation tax is paid by workers, customers or shareholders so would affect many in the population.” He added: “If you want to transform the scale and scope of the state then you need to be clear that the tax increases required to do that will need to be widely shared rather than pretending that everything can be paid for by companies and the rich.” Ryan Shorthouse, the founder of Bright Blue, a liberal conservatism thinktank, said Labour’s plans would amount to “a significant and unprecedented expansion of state expenditure and control. They envisage a super-spending, suffocating state.” One of the most eye-catching tax rises is an £11bn windfall levy on oil and gas companies, which Labour said would pay for a “just transition fund” to lessen the impact on jobs and communities of the move towards a net-zero carbon economy. It said the new tax would be levied according to the companies’ historical contribution to climate change and that some of the proceeds would go towards retraining workers from the oil and gas industries declines, and creating new green jobs. As expected, the policy on immigration was somewhat less liberal than the pro-open borders motion passed at Labour party conference in Brighton. The manifesto said: “If we remain in the EU, freedom of movement will continue. If we leave, it will be subject to negotiations, but we recognise the social and economic benefits that free movement has brought both in terms of EU citizens here and UK citizens abroad – and we will seek to protect those rights.” Most of Corbyn’s speech focused on his promises for domestic policy. But he also sought to take the fight to Boris Johnson over the UK leaving the EU, attacking the prime minister’s promise to “get Brexit done” as “a fraud on the British people”. “His sellout deal will be just the beginning of years of drawn-out, bogged-down negotiations and broken promises … and his toxic deal with Donald Trump will take even longer,” the Labour leader said. As Corbyn warned of the risk a bilateral trade deal with the US could leave the NHS exposed to “rapacious American corporations”, the audience of activists broke out into a chant of “Not for sale. Not for sale.” The Conservatives have dismissed Labour’s claims about the risk of privatisation of the health service as scaremongering, but Tory candidates say the idea has been resonating with voters and is beginning to crop up spontaneously during canvassing. Many policies in the Labour manifesto were also in the 2017 document, including the abolition of student tuition fees. However, there was no sign of a plan to alleviate the burden of existing student debt, which the shadow chancellor, John McDonnell, had hinted at earlier this week. Answering questions after his speech, Corbyn said that student debt was something the party was considering. “We are looking at ways in which we can stabilise it; in which we can bring about some relief,” he said."
"
Share this...FacebookTwitterNow that it’s spring, it’s as good a time as any to look at polar sea ice. Climate scientists have told us time and again that global warming would first be been at the Earth’s poles.
Well, if that is true, then we need to start worrying about cooling.
In the Arctic the following chart shows a clear stabilization taking place over the past 8 years with an upward trend over the last five years:

Source: Cryosphere Today, Arctic Climate Research, University of Illinois
It needs to be pointed out that there are many factors impacting sea ice. Among them are ocean currents and cycles, and prevailing weather patterns. In summary, however, the once feared “death spiral” remains totally absent.
Had the past five years been centered about the -1.75 million sq km anomaly in the Arctic, then the warmists may have had a point. But that is not the case as the Arctic sea ice is close to 1 million square kilometers above the alarm level.
A number of high-profile scientists and meteorologists also are now projecting growth in Arctic sea ice over the next 10-20 years as major oceanic oscillations shift to their cooler phases.
Record-smashing Antarctica, warming totally AWOL
If you are a global warming alarmist, then the situation is even more confounding at the south end of the Earth. Especially at the Earth’s southern pole is warming totally AWOL.

Source: arctic.atmos.uiuc.edu/cryosphere


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Because Antarctica is surrounded by water, trends there do behave differently then what goes on in the land-surrounded Arctic.
Consider the following stunning points about Antarctica:
1. Antarctic sea ice has been above normal for almost 3 years uninterrupted.
2. Three years uninterrupted above normal sea ice is unprecedented over the satellite record.
3. Record after record sea ice highs have been set during that period.
4. The trend for the last 10 years has been stunningly strong.
5. The long-term 30-year trend is strongly upwards.
From Antarctic sea ice trends, there’s absolutely no indication that there’s any warming going on down there. If scientists had been warning of cooling, they’d be having a much easier time today convincing the public.
Indeed Antarctica is the very place that AGW alarmist scientists don’t want anyone to look at. In fact today there’s almost no climate data they want you to see – only the “adjusted” surface temperatures that they themselves cook, manipulate and alter.
Global sea ice trend positive since 2006!
Finally charts and data on total global sea ice show absolutely no alarm. Global sea ice has been at a normal level for almost 3 years now. Overall the recent trend is upward, thus indicating cooling – and not warming:

Source: arctic.atmos.uiuc.edu/cryosphere
The above global sea ice anomaly chart shows that there was a brief downward trend from 2004 to 2012, but that loss has since been completely wiped out. The overall trend since 2006 is upwards. In fact the mean of the last 2 years is as high as it was 35 years ago.
Don’t listen to the doom and gloom of the government bought climate scientists. You can look at the data yourself. A good place to do this is over at Anthony Watts’s sea ice page here.
 
Share this...FacebookTwitter "
"Italy plans to cut back on the number of visitors allowed into Cinque Terre, a particularly picturesque section of its north-western coast. Around 2.5m tourists visited the area in 2015; this year, numbers will be limited to 1.5m. Such a drastic move raises questions about the impacts and benefits of mass tourism – and particularly cruise ships. This region of the Italian Riviera, characterised by its charming seaside villages set against rugged terrain, was once difficult to access and off the beaten path of mass tourism. Cruises helped change all that.  These ships began docking in the nearby port of La Spezia just a couple of decades ago, and several now arrive every week. This brought immediate economic benefits to the region. However, as the numbers of tourists have grown each year, the strain on local infrastructures has become too much to bear. Last year, nearly 650,000 of those Cinque Terre tourists came from cruise ships. These are small villages in precarious locations and therefore lack the necessary water, sewerage, electrical, and transportation services to accommodate such a rise in demand. While there are a few public toilets in Cinque Terre, these are not enough – and residents now report tourists using footpaths and even private gardens to relieve themselves. None of this is new. Venice should already have provided a warning of the damage wrought by too many cruise ships. More than half of the historic city’s population has left since 1980, when its popularity as tourist destination skyrocketed, and fewer than 58,000 people live in the city today. Their numbers are dwarfed by the 100,000 or more tourists per day during the peak summer season, up to 30,000 of whom are on a cruise. Most major ocean liners hold 3,000 or more passengers. These large ships allow the number of visitors to the city to exceed its physical capacity, as determined by hotel rooms. This makes everyday life cumbersome. Strolling tourists clutter the footpaths, pausing to take photographs. There are lengthy queues for water taxis, the rates of which have risen because of demand. This is reflective of prices throughout the city. Within the city, tourism is prioritised because of the money it brings in. Property prices continue to rise and residents find it difficult to afford housing in the city. Market stands are steadily closing down as they cannot compete for space in the campi with cafés and pubs, let alone the souvenir shops bursting with Venetian masks. Basic services for life in the city are diminishing. Each year cruise ships dump about 1 billion gallons of waste into the sea. They’re supposed to eject it into the deep ocean, however sometimes they dump closer to shore, presenting serious health risks. When the Costa Concordia struck ground off of Italy’s coast in January 2012, the disaster once again shed light on the ecological damage cruise ships can cause. After human-rescue efforts were exhausted, marine biologists, fearing toxins (such as petrolchemicals and human waste) would enter the water, worked quickly to move coral and sponge species to safer areas nearby. In particular, about 200 giant fan mussels were manually relocated. The waters and fragile coral reefs around Caribbean islands can be particularly affected by big cruise ships. Coral reefs are a crucial tourism attraction, and an essential part of their marine ecosystem, but two-thirds of the region’s coral is threatened by human activity. In one incident last December, the Zenith, a 12-deck vessel carrying more than 1,800 passengers dropped anchor near the Grand Cayman’s coral reef and destroyed large chunks of it as the anchor and its chain dragged across the ocean floor. While there are regulations against damaging the Cayman’s coral reef, the ship was inside the anchorage area. Thus, there remains no compensation for the damage, just a public statement of grievance about the incident. Some places have even deliberately demolished their coral reefs. Falmouth, on Jamaica’s north coast, has dredged its port to clear the way for the very largest ships, such as Royal Caribbean’s 6,000-passenger Allure of the Seas and the Oasis of the Seas. While trade journal Port Technology assures that care was taken and modules installed to help rebuild coral elsewhere, environmentalists say the project destroyed 35m cubic feet of coral reef and two square miles of mangroves. Cruise ships aren’t all bad, of course. They are a part of the mass tourism trend that has democratised travel and opened up activities which were once reserved for the wealthy. Cruises provide a way for millions of people to go abroad and experience different cultures. This is not without merit.  But the industry’s tremendous growth is rapidly degrading its destinations – the very products it promises. Its continued financial success is based on the sustainability of these destinations. If the cruise industry does not see this as enough reason to impose regulations, then the international community has a responsibility to step in, both for the people who live in destinations that depend on tourism and for ourselves as tourists who want there to be a world to see well into the future."
"Over the last 30 years, floods have killed more than 500,000 people globally, and displaced about 650m more. In a recent paper published by the Centre for Economic Performance, we examined why so many people are hit by devastating floods. We looked at 53 large floods, which affected more than 1,800 cities in 40 countries, from 2003 to 2008. Each of these floods displaced at least 100,000 people from their homes.  Of course, part of the problem is that many cities were originally built near rivers and coastlines. For a long time, these cities’ residents benefited from lower transport costs, because they were close to ports and the trade which occurred there. But these days, modern land transport often makes these historical advantages obsolete, as more cities rely on highways and railways than on ports. Yet history is not the only reason why flood-prone locations are overpopulated. For one thing, rising sea levels and a changing climate are putting more cities’ residents at risk. And what’s more, new homes are still being built in flood-prone areas around the world.  This is largely because private developers do not bear the full social cost of building on cheap land on flood plains. Instead, governments typically foot much of the bill for building and maintaining flood defences. As a result, developers do not take on the full risk of constructing homes in areas that are prone to flooding, and many people looking for new homes for their families move into these buildings. And so, the global population at risk of flooding keeps growing. To contain this large and growing social problem we should, at the very least, tighten the control over construction in flood-prone areas. Or, even better, home builders who insist on constructing new houses in flood plains should be required to bear the full costs that they impose on society in the long run. Another part of the problem is that people continue to live in flood-prone locations, even in the aftermath of large floods. There is no widespread movement towards safer areas.  Low-lying urban areas are hit by large floods about three to four times more often than other urban areas. This is partly because some low elevation areas are close to coastlines and rivers. But in fact, our study found that the risk of large-scale flooding is still higher in low elevation areas, even after we adjust for their proximity to these amenities.  Despite this higher risk of flooding, low-lying urban areas concentrate more economic activity than safer urban areas. This is true even in the parts of the world that are prone to extreme rainfall, such as the basins of major South Asian rivers, where the risk of large-scale flooding is particularly high. It is true that farmers in these areas sometimes benefit from the flood soils, but city dwellers generally do not. When cities are devastated by large floods, low-lying areas sustain more damage than other areas. But, like other parts of flooded cities, the low elevation areas recover rapidly. You may think that this recovery is good news. But unfortunately, it means that economic activity does not move to safer areas, so it remains at risk from the next big flood.  And sure enough, the odds of being hit again by a large flood are higher for cities that have already been flooded before – so the cycle of flooding repeats itself. We are not saying that the rising risk of floods should make people abandon thriving cities. But the pattern of repeated large floods is common even in economically marginal areas, where the case for living on flood plains is not always convincing. In our study we found that even cities that are prone to large-scale flooding often contain higher elevation areas that are safer, and that’s where new construction should take place. Flooding is a devastating and recurrent problem that afflicts many of the world’s cities. We need better policies to ensure that we do not mistakenly subsidise new construction on the flood plains, so that the problem of flooding does not get any worse – especially as sea levels rise."
"The price of offshore wind continues to fall dramatically. The UK government’s latest round of contracts for renewable generation have just been announced, and they show the costs of subsidies have halved in just two years. Cheap wind power is a great source of low carbon electricity, and it’s good news for politicians who may have been worried about subsidies bumping up household bills. But the scale of investment in offshore wind raises bigger, more systemic questions. The contracts – known as Contracts for Difference (CFDs) – pay operators of renewable energy installations a fixed price per unit generated for 15 years, regardless of what happens to the actual wholesale price of electricity in that time. For operators, this removes a lot of uncertainty about investing in relatively new and expensive technologies such as offshore wind because the subsidy and a guaranteed market for their power mean they can be confident they will recoup their costs. Contracts are awarded through an auction, where eligible developers bid against each other for projects being constructed in any given year. The projects with the lowest costs are awarded a contract, so ensuring the eventual cost to consumers is kept down. This is the second such auction for CFDs, and was limited to offshore wind, biomass, and energy from waste. More established technologies such as onshore wind and solar were excluded from the auction process. The results compared with the first auction are pretty spectacular. In 2015, two offshore wind projects were awarded contracts at £120 and £114 per megawatt hour (MWh). Two and a half years later, two projects are priced at £58/MWh, while a third is £75/MWh. This is a 50% fall in the level of subsidy, and makes offshore wind significantly cheaper than new nuclear power (the equivalent contract for Hinkley Point C is around £93/MWh). Offshore wind has dominated all three allocations of CFDs, with around 70% of the total awarded. In part this is because it can deliver on a much larger scale than other renewables; one of the new contracts is for a huge wind farm off the Yorkshire coast which could power up to 1.4m homes. It is also the result of the government’s shift towards an explicit industrial strategy that intends to use the development of offshore technology to stimulate economic growth. But the scale of this will profoundly shape the country’s electricity system. As the proposed wind farms are as large or even larger than conventional fossil fuel or nuclear stations, the UK will continue to rely on relatively few individual plants. Renewables could of course mean lots of small-scale wind and solar farms, leading to a more decentralised system. But a big offshore boom will lead to more centralisation. The level of investment needed to build an offshore wind farm is enormous, and therefore only open to a handful of large companies with access to the necessary funds. This reduces the potential for new entrants into the market, and excludes all the new investors who had begun to put their money into smaller scale, onshore projects over the past few years. The prices of the contracts awarded in this round are also so low that there must be the prospect that some of the projects are not actually built. This is partly because the costs of turbines and cables might not decline as quickly as expected, but is also related to Brexit. A decline in the pound means the cost of importing the necessary materials might well increase to the point where the subsidy on offer is not enough to allow investors to recoup their costs. While the impact of this might be relatively slight for a small scale, onshore project, it will be much larger for a complex, very capital-intensive wind farm built many kilometres out to sea. The UK could afford to lose a few smaller hilltop wind farms, but losing a massive offshore project would put a huge dent in its renewables output. So, the decline in offshore wind costs is fantastic, and a real endorsement of a rapidly-developing technology. But the bigger picture shouldn’t be neglected here. The UK is putting a lot of eggs into one basket. Centralised generation increasingly excludes new entrants, and literally concentrates power in the hands of a few very large developers. That makes life easier for policy makers who have fewer firms to deal with, but concentration also increases the risk of collusion and, in the longer-term, will mean less innovation. While increased generation from renewables is a desirable thing in itself, it is a real pity to be neglecting the increased levels of participation in the system which smaller scale projects offered. If Britain continues along this route, the days of community energy groups and energy co-ops may well be over."
"
Share this...FacebookTwitterWintertime is when people especially need reliable power for their homes, living and workplaces – especially in a northern country like Germany.
Unfortunately wind and solar power just aren’t able to come through and deliver when the chips are down.

The above chart shows German power supply by the various sources available and demand over the last 30 days. The lion’s share of Germany’s installed renewable energy (wind and sun) went just about completely AWOL three times during the period. Chart source: Agora.
 Dark blue – conventional power (fossil and nuclear)
 Medium blue – wind
 Yellow – solar
 Green – biomass
Germany today has a combined installed wind and solar capacity of close to 80,000 MW (see chart below). But as the chart above shows, often they put out only a tiny, measly percentage of that.

Germany installed sun and wind capacity (2013). Source Wikipedia. 
And on the seldom occasions when the sun and wind do both happen to be in supply at near full capacity, the power grid gets severely overloaded, conventional power plants have to throttled, massive amounts of surplus energy need to be dumped at negative prices in foreign countries, power plants have to shut down (and lose money), yet can never be taken off line. Overall the German energy production system system is market hostile where demand is ignored and supply is uncontrolled.
Recently, German energy giant E.ON announced it is getting out of conventional power generation business altogether: too risky and no foreseeable profits in the future.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Former German Economics Minister and socialist party honcho Wolfgang Clement calls the German Energiewende “a disaster“.
in a recent stinging op-edpiece, environmentalist centre-left Die Zeit called the Energiewende “a blunder with ugly consequences“.
Renewable energy expert Prof. Fritz Vahrenholt recently called Germany’s energy policy “suicidal”.
Late last year, German Vice Chancellor and socialist party leader Sigmar Gabriel called the mad rush to green energies “ruinous” and said “others think we’ve lost our marbles“.
Overall in Europe wind puts out on average a measly less than 15% of its installed rated capacity.
Much of Germany’s solar system manufacturing, which in its heady days employed tens of thousands, have shuttered their operations – leaving a silicon rust belt in its wake and tens of thousands of disillusioned workers.
To top it all off, Germany’s coal consumption has risen, and not fallen as green energy proponents hoped.
But don’t expect to read this at Winston’s Wikipedia, or to hear any of it from Europe’s green energy swindlers.
 
Share this...FacebookTwitter "
"Antarctica and Greenland may be two of the most remote places on Earth but what happens in both these vast landscapes can significantly impact on human activity further afield. Recent changes seen in vast ice sheets could have serious implications for millions of people around the world who live in coastal areas. These ice sheets store enough water to raise sea levels by over 60 metres, and there are some very worrying signs about their stability, especially in West Antarctica.  The real problem lies in the fact that ice sheets are reacting to increases in air and ocean temperatures and contributing to rising sea levels, currently estimated to be around three millimetres a year. While it is clear that ice sheet contributions to sea level rise have accelerated in the last decade or so, there is much more uncertainty about how ice sheets might respond in the future. With one recent study giving estimates which ranged from 60 centimetres to three metres by 2300. And that’s just from Antarctica. This uncertainty stems from the way ice sheets lose mass and transfer water to the oceans. In Greenland warmer air temperatures melt the ice sheet surface, which then causes water to drain off into the ocean. But in Antarctica, temperatures are so cold that very little of the ice sheet ever melts.  So how does Antarctic ice make its way to the ocean? The answer lies in ice streams, which are zones of the ice sheet that flow much faster than the surrounding ice at hundreds of metres per year. The ice streams then discharge ice into the ocean in the form of icebergs that eventually melt.  Ice streams can be unpredictable as they can turn on and off and change their position. Measurements show that there are about 50 major ice streams in Antarctica, which account for around 90% of the ice that is lost each year.  Ice streams make predicting future changes in ice sheets very difficult. While it’s relatively easy to estimate how much more melting might occur if air temperatures increase by say 2°C, nobody really knows what will happen to the ice streams.  A different approach to predicting the future is to look to the past and see how ice streams responded to previous periods of climate warming. In our paper, we reconstructed past ice stream activity, when an ice sheet the size of Antarctica disappeared over North America at the end of the last ice age between around 20,000 and 7,000 years ago.  This “North American Ice Sheet” covered most of Canada and by using satellite imagery to view land forms it left behind, we were able to map the location of all of the major ice streams that were once active in this ice sheet. We then used an existing database to track the retreat of the ice sheet over time – and estimated when the ice streams switched on and off. We also worked out how much ice the streams might have discharged from the ice sheet. We found ice streams switched off as the ice sheet retreated, having much less influence on the dynamics of the ice sheet. This means that the larger ice sheets simply have more ice streams and vice versa. This shows that the collapse of the North American ice sheet was mostly caused by increased melting of the ice sheet’s surface and not necessarily by ice streaming.  Ice streams in Greenland and West Antarctica are contributing to sea level rise which is likely to continue for at least the next century or so. Our reconstruction clearly showed ice streaming is much more likely to take place when the ice sheet is in contact with the ocean and slides over a bed of soft, slippery sediments. This confirms that some parts of West Antarctica may be especially vulnerable. While not everyone agrees the North American ice sheet is a useful comparison for the present day ice sheets, it is the only comparison we have of an ice sheet as big as Antarctica experiencing a rapid warming, and eventually complete disappearance. So when it comes to the millions of people around the world who live in coastal areas, only time will tell if what we have learnt from the past has relevance for the future."
"I desperately want to eat, but I would rather have a future. It’s day 10 of Extinction Rebellion’s global climate hunger strike and more than 500 people have ended their fasts. I am not ready to end mine. I am willing to starve to death, if that would help initiate real climate action, because I refuse to stand by and allow my nieces and nephews to live through a dark age of starvation, disease, and war. For the past week I’ve felt exhausted, dizzy, angry, and desperate. Now I mostly wake up sad that it has come to this. My parents tearfully urged me to stop, but how can I, when Intergovernmental Panel on Climate Change (IPCC) models estimate temperatures that would make the planet unlivable? The Paris agreement pledged to prevent 2C of warming, a rise in temperature that will bring disasters all around the world, including the United States. Such disasters are already killing and displacing people, mostly in poor countries, who did little to create the crisis. Central America is experiencing its sixth straight year of drought. At 3-5C, global civilization would devolve into wars over precious resources. This must be prevented at all costs.  I have no money and no power over our government. I have only my body, so I will fast until Nancy Pelosi agrees to a one-hour on-camera meeting with Extinction Rebellion. She presents herself as an ally of climate justice. I hope she will show compassion for my suffering and the suffering of millions of others before my body, our society, and the planet pass the point of no return. My sacrifice is meant to communicate the gravity of our situation and propel others into action. While I fantasize about scarfing down my famous cheesecake, there are too many lives on the line to give up now. A recent US army report says our military and national power grid could collapse by 2040. We will run out of food and our society would break down. At just 2C of warming, the tropics will have to be evacuated. Where will 40 million Central Americans go? Dr Hans Joachim Schellnhuber, a coordinating lead author of a key IPCC report, estimates the carrying capacity of a 5C planet at below 1 billion people. That means eight billion deaths. It’s impossible to capture that horror in words. Activists have tried to protect us for decades – the Sierra Club, Greenpeace, indigenous peoples – but the influence of money in our government has easily overpowered them. In essence, they failed. In 2015, US fossil fuel subsidies totaled $649bn, more than the defense budget and nearly 10 times what Congress spent on education that year. My hope rests with the young people who know they’ve been betrayed and are refusing to accept their fate. To prevent catastrophe, the solutions are simple: we need to reach net-zero emissions by 2025 and reduce atmospheric CO2 levels thereafter. Achieving this requires ambitious legislation. We need a massive movement of nonviolent civil disobedience to force our government into action. From the Suffragettes to the Freedom Riders to Gandhi’s Salt Marchers, non-violent civil disobedience has proved itself to be the most effective tactic for bringing about rapid social change. Extinction Rebellion has adopted this principle, and some of us have escalated the action to a hunger strike because of our desperation. If governments refuse to act now, crop failure could plunge the world into hunger. “Climate emergency” is the Oxford Dictionary’s word of the year for 2019. We need to change our behavior, our society, and our laws, and make it the act of the year. I desperately want to eat. I want to live a long life and have kids and a dog and grow old with my partner. I certainly don’t want to die at the age of 27, but I am willing to do what is necessary to advance action against this climate emergency. Speaker Pelosi, we are asking for one hour. Please meet with us. I would rather we all have a future. Eric Tien is an Extinction Rebellion protester"
"
Share this...FacebookTwitterIsraeli scientist Nir Shaviv recently posted at his site an article on the effects of cosmic radiation on climate. At the end he summarizes:
The results have two particularly interesting implications. First, they bring yet another link between the galactic environment and the terrestrial climate. Although there is no direct evidence that cosmic rays are the actual link on the 32-million-year time scale, as far as we know, they are the only link that can explain these observations. This in turn strengthens the idea that cosmic ray variations through solar activity affect the climate. In this picture, solar activity increase is responsible for about half of the twentieth-century global warming through a reduction of the cosmic ray flux, leaving less to be explained by anthropogenic activity. Also, in this picture, climate sensitivity is on the low side (perhaps 1 to 1.5°C increase per CO2 doubling, compared with the 1.5 to 4.5°C range advocated by the IPCC), implying that the future is not as dire as often prophesied.
The second interesting implication is the actual value of the 32-million-year oscillation. The relatively short period indicates that there is more mass in the galactic plane than accounted for in stars and interstellar gas, leaving the remainder as dark matter. However, this amount of dark matter is more than would be expected if it were distributed sparsely in a puffed-up halo as is generally expected. In other words, this excess mass requires at least some of the dark matter to condense into the disk. If correct, it will close a circle that started in the 1960s when Edward Hill and Jan Oort suggested, based on kinematic evidence, that there is more matter at the plane than observed. This inconsistency and indirect evidence for dark matter was also advocated by John Bahcall, who for many years was a Faculty member here at the IAS.”
Read the entire post here.
 
Share this...FacebookTwitter "
"Technological improvements mean that the phones, tablets, computers and other electric devices we find so essential are cheaper and more powerful than ever. But this means we upgrade them sooner and they quickly become unwanted or obsolete, and are thrown away. The huge amounts of waste electrical and electronic equipment – WEEE, or e-waste – that results is quickly becoming a major worldwide environmental, economic and health problem. A recent report by the European Union-funded Countering WEEE Illegal Trade project found that only just over a third of Europe’s e-waste ended up in official collection and recycling programs. The rest, amounting to over 6m tonnes a year, was either exported (1.5m tonnes), recycled in ways that fell outside the law (3.15m tonnes), scavenged (750,000 tonnes), or simply thrown in the bin (750,000 tonnes). Considering the vast quantities of e-waste produced worldwide, where this waste ends up is a serious concern. Considering the energy and materials-intensive process of manufacturing it in the first place, so is the impact on the world’s natural resources and environment. But not all e-waste is the same. Different equipment can contain hundreds or even thousands of different substances, some of which are potentially highly toxic, while others are extremely valuable. This has led to theft: in 2012 the EU estimated that theft of valuable components and materials from e-waste was worth between €800m and €1.7 billion. Much of electronic waste is made of metals: gold, lead, nickel, silver, tin and zinc, alongside valuable reusable plastics. Hazardous elements include materials such as asbestos, batteries, printed circuit boards, and printer toner cartridges. Throwing away high-value materials represents a huge waste. However, the economics of extracting them don’t always work in the West. Instead, e-waste exported to developing countries ends up in informal recycling schemes run by individuals, and sometimes criminal gangs. In some countries this has dominated the e-waste recycling chain, with equipment burnt in open fires or processed with hazardous acids in order to recover valuable metals.  Properly organised recycling schemes have emerged in developed countries, with the EU leading the way in adopting the “producer pays principle”, which requires manufacturers and sometimes importers and distributors to fund the collection and recycling of their products – and to ensure they’re disposed of using environmentally sound methods.  In the European Union, this first appeared as the 2006 WEEE Directive, which included rising national e-waste recycling targets, and a further directive in 2012 that broadened what counted as e-waste and introduced tougher restrictions on illegal waste export. Each year around 9.5m tonnes of e-waste are disposed of in the EU. It is also estimated that of the 1.3m tonnes of undocumented electronic waste exported, 70% was functioning equipment – which could potentially have continued to be used. Electronic waste was at first just dumped in landfill sites. But the danger of the highly-toxic elements in e-waste escaping landfill sites – into the water table, for example – meant that tighter controls were needed. Problems related to e-waste disposal in developing countries are worse, and already cause significant environmental and health problems. The open burning of plastics, widespread general dumping, malpractices associated with improper dismantling and treatment of e-waste as observed in countries such as China, India and Nigeria can result in serious health consequences.  Places such as Guiyu in China and Agbogbloshie in Ghana have become notorious for their unregulated, heavily polluted, sweatshop-dominated, digital dumps. Metals do not degrade in the environment and so can accumulate, contaminating the soil and groundwater, bioaccumulating in the creatures living in them. Beyond the cost to the environment and health is the economic cost. The loss of precious, useful and often rare materials from unprocessed e-waste is very significant. Materials found in modern electrical and electronic products include metals classified as critical raw materials which are in short supply. Ethical concerns linked with e-waste include reports of child labour in its treatment and handling, especially in some parts of Asia and Africa. Illegal shipment of e-waste from affluent countries to poorer developing countries that lack the facilities to properly treat such wastes is widespread. The evidence points to a close link between ethical malpractice in e-waste handling and environmental damage and health problems. Preventing illegal e-waste shipments could alleviate – if not necessarily eradicate – these effects. With the world’s population expected to grow to nine billion by 2050, and a corresponding leap in the amount of waste electronics that we consume and discard, we urgently need to get a grip on this problem and introduce proper laws, regulations and procedures that will ensure that electronic waste is safely dealt with."
"
Share this...FacebookTwitterThe latest post by Frank Bosse and Fritz Vahrenholt looks at solar cycle 24 in January, and the climate impacts of the North Atlantic. The two authors write that the IPCC models may be in for a bitter surprise.
==================================
The sun in January 2015 and Atlantic prognoses
By Frank Bosse and Prof. Fritz Vahrenholt
(Translated, edited by P Gosselin)
Solar report January 2015
Last month the sun reached a sunspot number of 67.0 and thus was once again below normal in activity: It reached 85% of what is normal for the particular cycle month.

Fig. 1: The mean activity of the sun since systematic observations have been conducted is shown in blue and the current cycle (24th cycle, red), along with the relatively similar Cycle No. 1 of 260 years ago.
The red curve shows that the sunspot maximum is now over. Up to now that was not so easy to identify because instead of the usual pronounced maximum (compared to the mean curve in Fig. 1), there have been two peaks with a pronounced dip between them.
Observation of the sun’s polar magnetic fields brings certainty rather than guesses. We reported on this in detail before the end of the year. In short the polar fields have a zero polarity during the solar sunspot maximum. The difference of north polar field and south polar field is zero, yet it can occur often when the fields do not reverse at the same time. During the current cycle the fluctuation about the zero line was quite intense:

Figure 2: The difference between the polar fields of the sun, source: leif.org.
The zero value was first approached in fall 2012, in early summer 2013, and again at the beginning of 2014. The maximum dragged on for some 15 months. But now the trend appears to be clearly away from zero and the maximum to be behind us for good. The month with the highest activity was month no. 63 of the cycle, February 2014, with a SSN= 102.8.
We are seeing an unusually weak cycle with a delayed start and delayed maximum. Another thing is noteworthy: The polar fields are building up only very slowly, especially the solar north pole is dipping as before close to zero. Could that be an indication of an even weaker cycle to follow? It is still too early to determine this, but we will know in a few years. What follows is a comparison of all the cycles:

Fig. 3: The summed deviations from the mean value (blue in Fig. 1) for all cycles for all months up to the current one. The right bar in Fig. 3 is growing deeper into negative territory. This indicates a strongly reduced solar activity since approx. 2006.
North Atlantic harboring a bitter surprise?
As some readers may recall, we reported earlier here on the North Atlantic and we suspected that a relatively significant reduction in the Atlantic Meridional Overturning Circulation (AMOC) could be in the pipeline. Since then there have been additional mesurements of this near surface warm current, which impacts the Atlantic part of the Northern Hemisphere and to some extent other large regions of the Northern hemisphere. Our earlier prognoses are now confirmed:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Fig. 4: The AMOC strength between 2004 and spring 2014. Source: climate-lab-book.ac.uk.
It is the decisive element that controls the AMO, and probably the approximately 65-year temperature oscillation. Earlier it had been positive, the transition from negative to a positive phase precisely coincides with the time frame that most climate models were parameterized: between 1975 and 2004.

Fig.5: The AMO since 1870, Source: climatedataguide.ucar.edu. The signal is determined by measuring surface temperatures of the entire North Atlantic and the deviation from the linear long-term trend. The AMO thus expresses an internal variability.
The additional added heat from the variable oscillation may have led to the models having calculated an excessive forcing from greenhouse gases, just as the AMO will also not be accounted for in the newest CMIP5 models when it comes to the global and northern hemisphere temperatures.
Getting back to the AMOC, if it weakens, it will lead to a falling heat content in the North Atlantic at depths from 0 to 700 meters and so less heat getting conveyed towards the North Pole. This is precisely what has been observed since 2007:

Fig. 6: The heat content of the upper 700 meters in the region of impact of the AMOC, Chart source: Climate Explorer. 
It is highly likely that the focus of the AMOC-effect can be found in the sub-polar gyre, which is a relatively small area of the sea in the North Atlantic located off the southern tip of Greenland: 45°N…60°N; 50°W…20W°. Here we are seeing truly dramatic events:

Fig. 7:  The heat content of water between 300 meters depth and 125 m of the sub-polar circulation. The depth limit was chosen in order to exclude falsifications from the effects of atmospheric processes. (Image source: Argo Marine Atlas)
Beginning in the spring of 2014 (after the end of the available direct measurement in Fig. 4) we see the occurrence of a steep drop. Also the forecast of the British Met Office for the next years is now taking this development into account and foresees with some certainty for the next ten years global temperatures at the lower end of the models’ ranges. It is also stated very carefully that a temperature stall could occur over the next 10 years, which for the models would be a real large-scale catastrophe. Just as we wrote back in January, 2014:
The AMO] is not accounted for in the IPCC models and would limit the trend rise in global temperatures since the beginning of the impact of greenhouse gases to about 1°K/ century.  How much longer will we have to wait before the IPCC finally accepts the multidecadal oscillations, as it already has here and is shown in other works?”
The North Atlantic is indeed a special region and could contribute much to understanding our climate. Also a greater impact by the sun than what has been considered up to now would be possible. A new paper by authors in China and Scandinavia examined high resolution proxy summer temperature data from northern Iceland and came to the result that the fluctuations there over the last 3500 years correspond to solar activity, and do so significantly over long time frames (centuries and millennia).

Fig. 8: The coincidence between North Atlantic summer temperatures and solar activity in the gray range over the last 3500 years (top), with the correlation (middle) and significance (bottom – the lower the p -value, the greater the certainty) of the relationship . Source: Figure 5 of the above-mentioned paper.
When one looks very closely at Fig. 8, one sees a time delay in temperature with respect to solar activity characteristic numbers. And when one now looks at Figure 3 of post and notice the especially high activity until the end of the 1980s and the rather dramatic drop afterwards, what do you think the solar drive will do to the Atlantic temperatures?
Things could become very bitter for the IPCC forecast models! With much excitement we look forward to how the climate unfolds.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOver the last couple of days at their Die kalte Sonne blog Geologist Dr. Sebastian Lüning and professor of chemistry Fritz Vahrenholt have focused their attention on sea level rise.
On Monday they wrote a piece titled: “Sea level rise lagging behind expectations: Now only ‘data massaging’ helps“.
In their post the two authors present a number of charts and cite many papers. In the end they conclude that sea level rise has not accelerated at all, despite what the media and a few alarmist scientists may otherwise claim.
Lüning and Vahrenholt write that sea level acceleration is the result only when one dubiously fudges the data:
What would you think if a soccer game ended with a score of 3:1, but the result later changed to 3:3?”
Today Lüning and Vahrenholt followed with another post on sea level rise, which shows that the methodology used at times by scientists to compute and project sea level rise leaves little to be desired.
========================================
What climate models have not taken into consideration up to now: Up to one third of the sea level rise traced back to ocean salinity


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
[Translated/ edited by P Gosselin]
For over one hundred years there has been a network of coastal tide gauges around the world that serve to measure the sea level. The hard data that is recorded play a decisive role in determining sea level rise. Because some coastal locations are rising and some are sinking, the corresponding vertical movement has to subtracted from or added to the tide gauge readings respectively. Using satellite measurements, today this can be corrected with reasonable accuracy. In March 2014 in a paper in the Geophysical Research Letters a team of scientists led by Guy Wöppelmann conducted a global revision of all GPS corrected coatal tide gauge measurements for the 20th century. The result is interesting: While sea level rose an average of 2.0 mm per year in the northern hemisphere, it was only about half as much in the southern hemisphere: 1.1 mm/year. What follows is the paper’s abstract:
Evidence for a differential sea level rise between hemispheres over the 20th century
Tide gauge records are the primary source of sea level information over multi-decadal to century timescales. A critical issue in using this type of data to determine global climate-related contributions to sea level change concerns the vertical motion of the land upon which the gauges are grounded. Here we use observations from the Global Positioning System for the correction of this vertical land motion. As a result, the spatial coherence in the rates of sea level change during the 20th century is highlighted at the local and the regional scales, ultimately revealing a clearly distinct behavior between the northern and the southern hemispheres with values of 2.0 mm/year and 1.1 mm/year, respectively. Our findings challenge the widely accepted value of global sea level rise for the 20th century.
The rise in sea level over the past 150 years is foremost attributed to the thermal expansion of the warmed water and the melt water from glaciers and the ice caps. But in November 2014 in the Environmental Research Letters Paul Durack showed that also ocean water salinity also contributed to sea level rise to a non-negligible extent. The Lawrence Livermore National Laboratory reported in a press release:
The team found that there was a long-term (1950-2008) pattern in halosteric (salinity-driven) sea level changes in the global ocean, with sea level increases occurring in the Pacific Ocean and sea level decreases in the Atlantic. These salinity-driven sea level changes have not been thoroughly investigated in previous long-term estimates of sea level change. When the scientists contrasted these results with models, the team found that models also simulated these basin-scale patterns, and that the magnitude of these changes was surprisingly large, making up about 25 percent of the total sea level change. ‘By contrasting two long-term estimates of sea level change to simulations provided from a large suite of climate model simulations, our results suggest that salinity has a profound effect on regional sea level change,’ Durack said. ‘This conclusion suggests that future sea level change assessments must consider the regional impacts of salinity-driven changes; this effect is too large to continue to ignore.‘
Attribution for the causes of observed sea level rise obviously is struggling with serious problems. No one has properly taken the changes in salinity into account.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Ed Caryl
Recently, Roy Spencer posted a graph that appeared to be a data record of some kind for the last 100 years. Then he revealed that it was generated in Excel with a simple random number function. The graph showed details that resembled things like El Niño’s and La Niña’s, pauses, and sudden warming and cooling.
I decided to repeat his graph introducing cycles into the mix. We know that the climate follows ~60 (AMO ocean cycle), ~210 (de Vries or Suess solar cycle), and ~1000 year (un-named) cycles (approximately). The following is a graphic of what happens if these cycles are introduced into the random number generator. The graph extends to 1014 simulated years by month. The random number generator is constrained to + and – 0.5, and each month adds 0.9 of the value of the previous month. The cycles use the sine function (SIN()) with input from the fractional year value, multiplied by 0.1 to produce a 62 year cycle, 0.029 to produce a 215 year cycle, and 0.006 to produce a cycle just over 1000 years. For this last cycle the COS function was used to shift the cycle phase by 90 degrees. Each month, 1/40th of each cycle value is added along with the 0.9 of the previous month. This produces a graph that roughly resembles earth’s climate over the last 1014 years with extension to the next 200.

Figure 1 is a simulation of the last 1014 years, with the applied climate cycles shown.

Figure 2 is a magnification of the last 214 years from Figure 1. Blue is monthly data, black is the annual average, the red trace is the simulated AMO 62-year cycle.
Each re-calculation will completely change the data, but similar features always appear. In this iteration, an El Niño appears at 1999, that looks just like the real El Niño of 1998. We see a warming trend in the early twentieth century, and another in the late twentieth century, just like the real warming trends.
In figure 1, we see a Medieval Warming period and two periods of Little Ice Age. A minimum is seen that resembles the Dalton Minimum of the early 1800s, and the cool 1910s and 1970s appear. Even the cool Maunder Minimum appears in the correct place. Most of this result is not coincidence because the 62-year cycle is timed to match the real AMO, and the 204-year and 1000-year cycles roughly match real solar activity.
In this simulation, two successive warming periods very like the actual twentieth century warming periods, can occur from natural cycles alone, no extra “forcing” from CO2 is required.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So, what will the future bring? Now that we have this model, that reflects the past, as we know it, with general accuracy, can we project that into the future? Sure…this is just an Excel spreadsheet after all. I pasted on 200 more years. As I did so, Excel of course recalculated the whole table. So here is a second example of the last 214 years that it came up with, in case someone accuses me of “cherry-picking”. Note that we get much the same pattern of warming and cooling, with a couple of El Niño’s in approximately the right place in the last 20 years.

Figure 3 is another calculation of the same period as in figure 2. The black trace is an annual average of the monthly data. All three cycles are shown.
Note the resemblance between figures 2 and 3. Each is a different calculation using different random numbers, yet the small addition of non-random sine wave cycles pushes the output into shapes that resemble the climate that happened in this period.

Figure 4 is the future, as projected by our model. The black trace is an annual average of the blue monthly data. All three cycles are shown.
As you can see, the future holds nothing to fear. There will be a few El Niño’s in the next ten years, then a moderate cooling as we come off the peak of the 62 and 204 year cycles. There will be more of those in mid-century, as the AMO rises again, then more cooling for a period at the end of the century as both of those cycles bottom out. No extensive warm periods will appear until late in the twenty-second century, as both peak again.
This model is not new. On the side-bar of this blog, an illustration from Nicola Scafetta’s model is similar, with the addition of some shorter cycles. An earlier post on this blog from a paper by Prof. H. Luedecke and C.O. Weiss (cited above) also used a similar model. The chief addition is random “weather”.
No CO2 molecules were harmed in the generation of these graphs. Nor, for that matter, were they considered.
For those with Excel expertise, I have posted the file to Dropbox here.
Share this...FacebookTwitter "
"The most shocking political development of 2019 may be the end of the nearly three-decade old consensus that the public doesn’t care about the climate crisis. People were hopelessly and permanently apathetic, the argument went, or unable to see beyond the present. They were said to suffer what Ted Nordhaus and Michael Shellenberger memorably called “apocalypse fatigue”, a numbness brought on by years of scientific warnings about a dismal future. And this in turn meant they were uninterested in, if not outright hostile to, any kind of meaningful climate action. All of this appeared to be backed up by data. Years of polling and other measures of public engagement showed that even as awareness of the crisis grew, there was no interest in changing anything.  But after an unprecedented wave of popular climate protests – centred around the latest and most terrifying scientific predictions – recent polling suggests that orthodoxy has suddenly and dramatically reversed. A YouGov poll found that more than half the country backs a national target of zero carbon emissions by 2030, a policy that as recently as a year ago was offered only by the Green party. Other polls suggest that two-thirds of the country believes the climate crisis is the biggest issue facing humankind, and that it has overtaken the economy on voters’ list of concerns. There have been suggestions that the climate crisis will be a central issue in the upcoming general election – it’s even being called “the climate election” – and a majority of Britons say that it will influence the way they vote. The public now appears to want to take part in the politics of climate change. The trouble is, such a thing barely exists. This sounds ridiculous, because we have clear evidence of at least two kinds of climate politics: the familiar international conferences, with rooms filled with bureaucrats and national leaders parachuting in for the final handshakes and signatures; and the recent actions by grassroots groups such as the school strikers and Extinction Rebellion. But between the insulated world of international negotiation and street-level protest there is almost nothing. For most people, politics means national politics, and a choice of policies delivered by ideologically distinct national parties. But for nearly a generation, climate politics has hovered in the almost apolitical space of international treaties, out of the reach of the public. Climate policies have been formulated in broad and loosely defined terms that politicians can all agree on. They commit to future targets that would seem to require radical changes in the way we live, but those decisions remain unmade, because the major parties have never brought them in front of a national electorate. The UK’s own Climate Change Act of 2008 – often touted as the most progressive climate legislation in the world – neatly illustrates the limits of climate politics as they currently exist. The act passed with an overwhelming majority, and committed the UK to an 80% emission reduction by 2050 (since increased to 100%). It started from a premise everyone agreed with: that climate change was a problem, and that we had to do something about it. But 10 years later, the question of what exactly we will do has hardly been addressed. The government hit its first two mandated climate targets largely by tinkering with policy out of the public eye, decommissioning coal plants and supporting renewables where it was easy to do so. The next steps, though, would require transforming more visible and tangible aspects of public life – whether they are the boilers we use to heat homes, the kinds of food we eat, or the way the countryside is balanced between exploitation and protection – and would involve stronger government intervention, and spending, than has been committed before. There aren’t currently any plans to do that, and so as it stands the UK is expected to miss the 2025 and 2030 targets. This is how the politics of climate change has always played out. Targets are made by consensus, but policies are never brought forward because they would involve change, and thus be contentious, partisan – the stuff of real politics. Instead, we’re left with a framework that is never filled in, a set of guy-wires meant to steady a bridge that is never built. For a long time our leaders haven’t been held to account for this; they’ve been safe knowing the public doesn’t care enough to demand more. That appears to have changed over the past year, and the initial response is promising: the declaration of a climate emergency by parliament, and MPs convening a public assembly on the climate crisis are good starts. But they’re still in the realm of acknowledgement and declaration. They need to go further than that, by presenting people with an actual political choice. Not just a choice of different future targets, but the policies to deliver them. The Greens have been offering those kinds of policies for years. Now Labour has indicated it will bring forward its version of a green new deal, likely a path to net-zero carbon by 2030 backed by new regulations and a massive government spending programme on infrastructure and housing. It’s unclear what the Conservative platform will be, but, several months ago, 41 Tory MPs produced a draft manifesto with market-based initiatives that they believe will deliver net-zero by 2050. These visions are likely to be attacked by some as reckless, or ineffectual. But they are serious proposals because they place their policies within a political vehicle familiar to each party’s voters, and to the wider public. They indicate that the climate crisis may be about to descend from the lofty realm of consensus into the arena of real politics. That can only happen when the public is given – or demands – a proper democratic choice. • Stephen Buranyi is a writer in London"
"The eco documentary 2040 is a gentle antidote to environmental anxiety. Directed by Damon Gameau, it imagines a world 20 years from now, free from the climate crisis that’s gobbling up our globe. Committed to changing the nihilistic narrative surrounding climate change, Gameau takes his audience on a search for solutions and offers up a message of hope. As 2040 is released, however, the doom and gloom of the climate crisis Gameau’s documentary takes pains to avoid is inescapable. Australia is ablaze. New South Wales, where he lives with his wife and two children, is experiencing the worst bushfires the country has ever seen. His daughter, to whom 2040 is dedicated, is unable to attend school. For Gameau, the irony of this tragedy stings. “Thousand of school kids were derided for protesting against the very thing that’s now forcing them to miss school,” he says. “People are so frustrated. They’re overwhelmed. They’re angry. Our government is still denying that the fires are climate related. The cognitive dissonance is remarkable.”  Gameau’s frustration at his government’s refusal to acknowledge the climate crisis is noticeably absent from this film. Shifting the focus away from horrific stories of floods and fires, of political ignorance and denial, 2040 is instead a blueprint for the way out of the mess. “There’s been a failure of imagination,” he says. “Instead of constantly beating people over the head with how bad things are, we need to inspire them.” In 2040, Gameau interviews a host of environmental experts, showing us networks of solar panels, seaweed platforms, the electrification of transport and decentralised energy grids: all solutions to the climate crisis and all of which exist today. Quirky editing has experts perching on toasters, tin roofs and wind turbines as they explain the intricacies of each. It’s unusual and engaging. The message: we must put these ideas into practice if we’re to make any difference. Gameau says he made 2040 for his daughter’s generation. The film returns repeatedly to warm interviews with children, gently reminding us whose future is at stake. Asked to imagine themselves as adults, kids giggle at the thought of chocolate rain and rocket boots. Climate change is their biggest concern. Unprompted, they speak of hopes of an end to deforestation and dream of “meat grown from a seed”. One imagines an “intergalactic rubbish dimension”. “It’s their future,” Gameau says. “We’ve got to show them there are people who care about that.” With the success of the school strikes, which has seen more than a million children take to the streets to demand government action on the climate crisis, I ask Gameau if it’s not the kids who need convincing, but the adults. “Kids voices are working,” he says. “People are waking up.” He is determined to use 2040 as a tool for change. It has been projected on to the walls of the UN. A copy of the DVD will be sent to every Australian MP. A screening in the UK parliament is planned for the New Year. In an effort to reach as many young people as possible, 2040 has been screened free for children in Australia and the Into film festival has rolled out free screenings for schools in England. Delegates to the Youth Climate summit attended a screening in New York. Even singer-songwriter Ellie Goulding has had a private screening. Could 2040 mark the beginning of the “Greta effect” in documentaries? Gameau thinks so. ‘“Governments, Hollywood, the fossil fuel industry – they’ve always known that film is incredibly powerful,” he says. “We’ve got to be clever and start using the medium for our own benefit.” With Extinction Rebellion keen to encourage film-makers to focus on the climate crisis, I asked Will Skeaping, co-editor of This Is Not a Drill: An Extinction Rebellion Handbook, how useful he thinks film can be to the cause. “Film-making is vital,” he says. “We need to bring this crisis into all forms of conversation. Film, as the most accessible medium, is one of the best ways to do that.” Gameau’s documentary shows us there is a way out of the climate crisis. It listens to children, then amplifies their voices. Though the film focuses on the personal changes we can make, Gameau has harnessed the medium to target the political, too. Afterwards, it’s over to us. As Skeaping says: “It’s about getting people out of the cinema and on to the streets.” • 2040 out now in the UK. A Q&A with Damon Gameau and climate activist Jack Harries is on Friday 22 November at Everyman Broadgate, London EC1. "
"At the start of each year, Norway hands out new licences for offshore oil and gas development. Typically, these “Awards in Predefined Areas” (APA) receive little coverage outside of the specialist media. But this year was more controversial, after the country’s energy minister argued that the environmentally-sensitive Lofoten islands “must at some point come into play”. Lofoten is a unique and stunning archipelago in Norway’s far north, where huge unspoilt mountains rise out of the ocean. Located at the end of the gulf stream, it’s unusually mild for somewhere beyond the Arctic circle. Large coral reefs found to the west of the islands mean that the region’s cod-filled waters are protected by domestic laws and international conventions. Despite the energy minister’s comments, no licences were actually offered immediately next to Lofoten – this time. And those that were offered in the region were all further from Lofoten than the closest existing one, which is around 70km from the south-west edge of the islands and is operated by state-owned Statoil, who are yet to start drilling. Nonetheless even the prospect of future development was enough to worry environmental groups, and has led some to question the country’s commitment to addressing climate change despite the 2015 Paris agreement. The collapse in oil prices over the past two years has delayed or cancelled many expensive new projects around the world. Lofoten has emerged as a cheap alternative as the islands are close to the mainland and the surrounding waters are relatively shallow.  Drilling in the area was prohibited under Norway’s 2006 management plan for sustainable use of the Barents and Norwegian seas. But the resources are hard to ignore – there are an estimated 1.3 billion barrels of oil in Lofoten and neighbouring Vesteralen and Senja. (By comparison, the UK’s entire resources are estimated to be up to 21 billion barrels.) In 2013, Norway’s Labour prime minister Jens Stoletenberg supported an impact assessment study on development in the area, but following the election that year the new Conservative-led coalition agreed not to drill in these areas, around the protected island of Jan Mayen, or in the so-called High Arctic region.  With the Conservatives still in power, opening up Lofoten would represent a backtrack. Yet it’s not just Lofoten. This year’s round of exploration licenses was also notable for the number offered in the Norwegian Sea, 24 out of a total 56 – with 27 in the North Sea and five in the Barents Sea. This is the highest number since the current system was introduced. It highlights the financial difficulties facing oil and gas companies, but also suggests a change in the geography of Norwegian oil and gas development. The next wave of exploration work was long expected to take place in the Barents Sea, off Norway’s northern coast. However the lack of previous infrastructure to build on and some disappointing reports of smaller than expected oil discoveries means the economics there are challenging. This was an issue back when oil prices were riding high, and the drop since then has further dimmed the prospects of developing the Barents. Norway is also concerned about the future of gas demand in Europe. What’s the point of setting up drilling rigs and pipelines in the Arctic if no one wants to buy it? Gas has been caught up in the EU’s drive to reduce its dependence on Russian energy, and difficulties with the EU emissions trading scheme have so far stymied hopes that it could be the bridging fuel to a predominantly renewable future.    In May 2015 Norway’s parliament asked the country’s US$857 billion sovereign wealth fund, Norges Banke, to divest from coal power – a move applauded by climate activists. But less than a year later this latest round of new oil and gas developments has drawn criticism from those who claim opening up new fields will undermine Norway’s commitment to tackling climate change, just weeks after the Paris deal.  Even though development at Lofoten is unlikely in the near future, the minister’s comments on opening the area up at some point could be reflective of a wider trend across the world. For all the big talk about fighting climate change, the basic truth remains: future production of oil and gas is central to the Norwegian economy, while the EU will still want a secure supply of these fossil fuels – especially gas."
"Unlike parsley, sage, rosemary and thyme, wild marjoram missed out on a role in the classic song Scarborough Fair, made popular in the 1960s by Paul Simon. But it does have a key additional advantage over most herbs. People know it best under its widely-used alternate name of oregano, which is also the scientific name – origanum vulgare. It is a common feature of Italian cooking and a native around Europe and in the UK. More importantly though, it is one of the best of all plants for attracting bees, butterflies and other pollinators to your garden.  The most widely grown and appreciated garden favourites, of course, are those with attractive flowers. And there is a common assumption that those plants which delight human eyes will also be the most attractive for bees and other flower-visiting insects. Research at the Laboratory of Apiculture and Social Insects at the University of Sussex can give a more empirical take. One project carried out in 2011-2012 saw 32 varieties of summer flowering garden plants grown in beds and counted the insects visiting them – 87% of which were bees. The plants selected were all summer-flowering varieties often grown in gardens. All were attractive to the human eye. However, they were very different as far as the insects were concerned. The most attractive to them were marjoram and agastache, a herbaceous perennial with simple, aromatic leaves and small flowers in dense spikes. These two had 100 times as many insects as the least popular, the pelargonium, which belongs to a large group of frost-sensitive plants used for summer bedding.  It is a simple lesson. By choosing suitable varieties to provide nectar and pollen, gardeners can make a big difference. Our research show that helping bees and flower-visiting insects needn’t come at a cost. In a 2012 survey of over 200 varieties of asters, also known as Michaelmas daisies, at the British National Collection in Picton Gardens, Herefordshire, the varieties that attracted more insects were just as easy to obtain, easy to grow, and attractive to the human eye. Prices are similar, although that depends mainly on the size of the plant when you buy it. So, how good for insects are the flowers grown in parks and gardens? In the East Sussex town of Lewes there is a beautiful park, Southover Grange Garden, which is carefully managed to provide magnificent floral displays in spring and summer. We counted the insects on 79 varieties in full bloom in August 2012. The results were surprising. The park appeared to be a bee paradise, but only three of the varieties were highly attractive to flower-visiting insects. On 24 varieties we saw no insects in any of the 15 counts made, and on a further 37 there were very few. Clearly, there is room for improvement. Many garden flowers are more show than go: bred for many bright petals instead of food for the bees.  Many gardeners in the UK get their plants from one of more than 2,000 garden centres and retail nurseries. They are popular destinations for plants and equipment (and for a cup of tea and a slice of cake). They play an important role in what British gardeners end up growing and what insects will be able to visit. Garden centres normally sell plants in bloom with each variety in a distinct patch. This makes it easy to monitor the insects. In 2015 we counted the insects on the 59-74 plant varieties in full bloom on sale in five garden centres and one nursery in Sussex. We made 12 counts over one day in each. We even brought in our own marjoram plants to set up two comparison patches of a variety we knew to be very attractive. We found a similar pattern to that seen in the other two studies. Most varieties on sale had few bees and other insects, and a small number had many. Our marjoram did well, as expected, but 4.5% of the plants on sale turned out to be even more attractive, with an average of 26% more insects. Strong performers included the deep magenta flowers of cosmos bipinnatus “Sonata Carmine” and caryopteris x clandonensis “Heavenly Blue”, a compact shrub with clusters of dark blue flowers. Some of the plants on sale, about 15%, were marketed as bee-friendly, and just over half of those appear on the Royal Horticultural Society’s “Perfect for Pollinators” list. How good were these? Well, the average looks good: recommended plants attracted three times as many flower-visitors as the rest. However, many plants in that group were unattractive to insects or underperformed. Equally, some non-recommended varieties such as iberis “Masterpiece” and alstromeria “Inticancha Dark Purple” did really well. The labelling appears to be inconsistent and certainly over-optimistic. Perhaps “better for pollinators” would be more accurate.  Our research shows that the public could be making their gardens much more attractive to bees and other insects simply by more careful flower choice. And garden centres can be part of this, by improving stocks and by educating customers to favour more of the highly attractive varieties.  Many of the plants of the family lamiaceae, the mint family, are great for pollinators. That includes marjoram as well as thyme, lavender and Russian sage (perovska). Others, such as heleniums and some dahlias are in the daisy family. Different varieties bloom at different times, and can provide valuable additional food across the whole summer to a whole range of flower-visitors.  If you want to help bees and other insects in your garden, have a look round your garden centre on a sunny summer day. Plants with 10 insects, even five, per square metre when in full bloom are the ones to go for. But don’t buy a plant that you don’t like. There are plenty of bee-friendly varieties, so a win-win situation is possible: chose plants that you – and the bees – both love."
nan
"English children are apparently “not engaging with nature”, according to a major two-year study. We’ve previously heard that they don’t know a calf is a baby cow, and that names of trees and flowers have gone from junior dictionaries to make way for words like “broadband” or “analogue”. Fears about the lack of time spent outdoors have prompted high-profile campaigns to encourage a “free-range, nature rich, outdoor childhood”. Now I spent a huge proportion of my youth doing exactly the kind of tree-climbing and roaming this movement advocates. I’ve worked for conservation organisations involved in these campaigns, and I’ve researched how people benefit from gardens. So why do pleas to get children back into nature leave me a little uneasy? The research featured in the latest news reports was led by Natural England, a government advisory body. The headlines are that 88% of English children have visited the natural environment in the last year, and that 70% go at least once a week. The media of course focused on the negative side of these figures – the 12% not visiting the natural environment. We might accept that, as this is the first reporting of this survey, we don’t know what the trend is across recent years, because there are two bigger questions to consider.  The first is with the very idea of engaging with the “natural environment”. In 1976 the Welsh author and academic Raymond Williams suggested that nature may be the most complex word in the English language. Some ecologists deny humans can ever be disengaged from it as we are part of it. Human geographers have long argued that cities are natural phenomena, made through the combined effort of humans and ecological processes. This might seem semantic, but there are practical implications to the difficulty of agreeing what nature is and where you can find it. Natural England’s survey counts a range of places including urban parks, mountain or moorland, children’s playgrounds and allotments, although not – perhaps perversely given evidence of how they benefit people and wildlife – private back gardens. Regarding all these places as “natural” emphasises their similarity. But they’re hugely varied and engaged with in different ways so can have distinct benefits. What a child does in a small city playground is likely very different from how he or she experiences the open landscape of a national park. Rather than thinking of all places with a good amount of greenery as natural and therefore beneficial, we need to distinguish which features and characteristics can have positive affects. By understanding this it becomes possible to plan environments which support positive, healthy engagement. The second issue is the risk of conflating place and activity. My research on community gardeners, for instance, showed that what one does when outdoors is as significant in terms of well-being as the very fact of getting out and among the plants. To know what activities to encourage, we need to be more specific about what we actually want to achieve. If increased physical activity is a priority then time spent cycling to school or playing in a safe street may be better than a trip to see the countryside largely from the back of a car – and more readily accessible.  The other reason for a more detailed picture of children’s outdoor activities is to avoid the risk of presenting a homogenising picture which holds up a certain type of engagement with nature as the ideal. Think of hikers in cagoules forging on through all weathers, or peering through binoculars at a barely visible bird. But these pursuits are off-putting for many, and can squeeze out other outdoor activities which might have broad appeal.  The notion of the “great outdoors”, invigorating countryside and bracing fresh air is also highly culturally specific, closely tied to a “white British” identity. These associations can lead non-white ethnic groups to feel excluded from the countryside, and visit less often. The Natural England survey found that children from black and minority ethnic households are less likely than those from white families to regularly visit natural environments. It is not clear how much this is associated with income or living in cities. But the survey shows that even visits to urban greenspaces vary with ethnicity, suggesting it’s not just down to location. For some people the outdoors simply doesn’t seem that great. Natural England and others have been working to address this by deliberately engaging with minorities to understand why they may be unlikely to visit natural environments. Research available so far suggests that different cultural groups have varied motivations for spending leisure time outdoors, with people of Asian heritage more likely to seek a sociable experience of eating and gathering, for example. So there is more to learn here. Williams concluded that the word nature has powerful effects on any argument, so we should be “especially aware of its difficulty”. With this in mind I suggest we are wary of all the good that can be masked when we talk about “engaging with nature”. Children can enjoy the outdoors in many different ways and this can start right on their doorstep."
"
Share this...FacebookTwitterA few years ago at a social event I had a brief discussion with a secondary school teacher who happened to be on some sort of committee in Hannover which decided the textbooks the children at Lower Saxony upper secondary schools were to use.
On that subject I told her I thought that the geography textbook our children were using was designed to indoctrinate the kids on the subject of climate change, and that it dissuaded them from critical thinking on the subject. My opinion was that the schools should teach children, and not indoctrinate them.
Needless to say, I got quite a stern, German-style reaction. I’ll never forget the icy, piercing look in her eyes, one that made my grade school principal Arlene Simons look angelic by comparison. Parents, especially cowboys, obviously were not expected to question the state when it comes matters concerning the education of children.
The following is a letter written by a biology teacher, posted at Die kalte Sonne site. It was sent to one of Germnay’s larger textbook publishers: Ernst Klett Verlag.
======================================

Answers are requested: How do school textbook publishers handle the climate discussion?
To: Klett-Schulbuchverlag
From: Teacher of Biology and Chemistry [anonymous in order to avoid problems with colleagues]
Sent: 18 March 2015
Dear Ladies and Gentlemen,
Because the general contact-page at your website is blocked, I am using this address and requesting that you pass my comments on the subject of climate change on to the responsible editors:
In the preparation of my lessons (Biology Grade 7) in your textbook Prisma Biology 2, ISBN 978-3-12-068390-2, I came upon an illustration depicting the causes of climate change which I find to be unserious and unscientific. Under the heading, ‘The greenhouse effect is being enhanced’ one finds the following text: ‘Over the past decades scientists have been measuring a steady increase in greenhouse gases in the atmosphere. At the same time the average temperature of the earth has risen because the heat trapping gas barrier is getting tighter…“
Here the illusion of a causal relationship is being given, when this is everything but certain. Why do you not provide the development of the mean global temperature over the past? This would allow the pupils to see that warm periods have always occurred, long before man could have had an impact on the earth’s atmosphere. The pupils would be able to recognize that the climate in the Middle Ages was similar to today’s climate and that it provided significant benefits to the people living back then.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




My view is that it is scientifically unserious to show only an increase over the last decades. Here it is being suggested that there weren’t any climate changes earlier.
Why don’t you show how little the share of man’s CO2 is in the earth’s entire CO2 budget?
Why do you not mention the ongoing discussion on CO2 climate sensitivity?
Why do you not mention that the global mean temperature of the earth has not risen over the past 18 years, even though the CO2 atmospheric concentration of the atmosphere has risen during the same period?
Why do you not mention that many studies have shown that in the past temperature increased first, and then CO2 and methane concentration followed, and thus the driving force for the earth’s temperature could not have been these gases?
And why do you fail to mention that the climate models, which projected a significant warming of the earth, have been proven false?
What I find to be especially manipulative and unserious is the exercise: ‘Evaluate the single information sources using this sentence: Who posted what, and with what intention, in the Internet?“ This is all about speculation and the manipulation of 13-year olds who do not yet possess the knowledge necessary for assessing the seriousness of a source in the Internet. It may very well be that the ideological stipulations of political parties may lead a school textbook publisher to depict the reality as such, so that it fits the political narrative. But this has absolutely nothing to do with science. Serious would be to show in a neutral manner the different views on climate changes of the last 150 years, side by side, and to provide as many of the known facts as possible.
Yours sincerely”

=======================================
Well, don’t expect the Lower Saxony Ministry of Education to give this letter an A+ by any means.
Today Germany’s kids are being told what they can be critical about, and climate science is certainly not one of them. Even the concerns of parents are being dismissed by what appears to be a state apparatus that has gotten excessively arrogant on the subject. Indeed it’s back to school – the old nasty German one of thought control.
And it’s unbelievable that the climate of intimidation in academia has become so aggressive that the biology teacher fears being identified, and thus chose to stay anonymous. This should make anyone pause and think.

Share this...FacebookTwitter "
"Last year Justin Milne got into trouble for acting like he ran the ABC, giving directions for staff to be sacked or telling management what they should do. But no one seems to mind the current ABC chair’s forthright style. Ita Buttrose is in demand and she grants interviews and makes statements that occasionally sound like she, and not David Anderson, is the managing director. Or at least that’s how certain media outlets interpret her comments, to be fair to Buttrose. Headlines such as “Ita Buttrose urged to scrap MeToo documentary” and “Ita Buttrose pulls ABC’s Q&A show over ‘call to violence’” add to this perception. In the last few weeks she has “pulled Q&A”, made comments about bias and political correctness, and now has appeared to veto a staff-led climate emergency group to develop ways to report on the climate crisis. The Australian reported that Buttrose had “ruled out” the creation of a staff advisory group after the paper revealed ABC staff had suggested to colleagues they form an “ABC-staff climate crisis advisory group” and some staff welcomed the idea enthusiastically in a leaked email chain. Buttrose was asked about the initiative, which the Oz saw as something sinister, on ABC Adelaide’s Mornings with David Bevan. She told Bevan, “it was one of those ideas that is not going to happen”, perhaps meaning it was not going to form official policy. “Policy is decided by the leadership, not by members of the staff,” Buttrose said, adding that it was not her call but that of the leadership team. “I haven’t had anything to do with it,” she said. But Weekly Beast can reveal the staff move has not been stymied at all. Staff are free to discuss climate change coverage among themselves and are still planning to go ahead with the advisory group, with 77 people expressing an interest already. There has been no edict from above to stop the email chain. Meanwhile over at News Corp, executive chairman Rupert Murdoch’s claim that “there are no climate change deniers around I can assure you” has left people wondering whether the Oz will get an edict from above that it needs to stop publishing climate deniers. Clearly editor-in-chief Chris Dore doesn’t have the memo yet because on Friday the paper published denier-in-chief Ian Plimer declaring “We are not living in a period of catastrophic climate change”. The Tracey Spicer-fronted documentary Silent No More is being furiously re-edited and thoroughly legalled by the ABC ahead of its scheduled broadcast on Monday, in the Four Corners timeslot. The ABC was forced to apologise last week for failing to blur out the names of three survivors of sexual abuse or harassment before releasing the #MeToo film to a handful of reviewers last month. With just a few days to broadcast the three x 42-minute documentary was not available for preview, and on-air promos were conspicuously absent from ABC TV because of the last-minute checks. This fuelled rumours it was going to be pulled from the schedule at the last minute. But the ABC says it is going ahead as planned. “The ABC again reiterates that no names, images, emails, stories or any other details – identifying or otherwise – of anyone who has suffered sexual abuse or harassment will be broadcast in Silent No More without their explicit consent,” a spokesman said. “We refer you to our full statement.” The problems arose when Spicer agreed to be filmed reading out survivor stories from her computer screen and some details of the confidential messages were shown in the documentary. The debacle has exposed how vulnerable the ABC is when it outsources its programs to the independent sector. This film may air in the prestigious Four Corners spot but it has not been produced by ABC news and current affairs journalists.  There is a lot riding on the three-parter, which cost an estimated $200,000 to $250,000 per hour, funded in part by Screen Australia. After a month of razzle-dazzle and sizzle reels, Australia’s five free-to-air networks’ 2020 program launches came to an end on Wednesday with SBS’s multicultural feast for 500 media and advertisers at Sydney’s The Cutout at Barangaroo. They saved the best for last. With a budget a fraction that of Ten, Nine and Seven, and significantly smaller than its bigger public service sibling, the ABC, SBS delivered a slate rich in original, diverse and surprising content. Starting off with Ten unveiling its new MasterChef judges last month, the other networks offered several crass reality shows packed with advertorials, with drama and documentary an afterthought. The ABC’s offering was more interesting, with a raft of local dramas – Stateless, Fallout, Mystery Road, Harrow and The Heights – but it lacked the spark of the SBS schedule. Your guide to the year ahead across SBS channels.https://t.co/3CzZ6TvR4Y Highlights include Rachel Perkins’ First Wars, a polemic documentary series about the 100-year history of the frontier conflict between the Indigenous population and the settlers; SBS’s first period drama, New Gold Mountain, and topical documentaries, Who Gets to Stay in Australia?, Addicted, Jess Hill’s See What You Made Me Do and Come Fly with Me. With the proliferation of streaming services now available, don’t forget SBS on Demand, which is free. The Australian Financial Review really loves the Microsoft chief executive, Satya Nadella. Nadella has been the subject of no fewer than 10 articles over four days, starting on 18 November. They have been, in the main, fawning and very lengthy running to thousands of words. Sign up to receive the top stories from Guardian Australia every morning “Nadella charmed the pants off the audience” at the AFR’s Chanticleer lunch this week, where he was interviewed by AFR journalist Tony Boyd, readers were told. “Under Nadella’s leadership, Microsoft has successfully positioned itself as the world’s “good tech” company,” another piece said. Microsoft CEO Satya Nadella says trust is key when it comes to growing a business. https://t.co/QBb7KeMq9y A Microsoft employee was even quoted saying she loved listening to her boss. “Microsoft sales director Tiffany Wright said she liked hearing Nadella respond to the Financial Review’s Chanticleer columnist Tony Boyd’s questions on Microsoft’s company culture, and the idea of gravitating towards the good parts of company culture and ditching the bad during his rise to the top.” “Nadella cracked guests up with his easy sense of humour, regaled tales of his childhood growing up in India, and talked about his path to the top of Microsoft with likeable humility,” readers were told, in case they hadn’t worked out what a great man he was. The Chanticleer lunch in Sydney is a nice little earner for the Fin, but even that doesn’t explain the overkill. Boyd had a disclosure at the end of his articles – “The author’s self-managed super fund owns shares in Microsoft” – but that wouldn’t explain the enthusiasm for the CEO either. Editor Michael Stutchbury says there was no commercial objective for the lunch “other than showcasing the power of the Australian Financial Review’s brand and delivering high value content to our paying subscribers”. “Our lunch attracted the cream of Australian business,” Stutch said. “The Financial Review’s coverage of the event was driven solely by the capacity of Australia’s biggest business and finance newsroom and Australia’s leading business technology news masthead to meet the demands of our paying subscribers. The Nadella stories were among our most read stories of the week. “I’d be surprised if, within its lesser means, the Guardian Australia didn’t give blanket coverage to any similar lunch it managed to organise with Satya Nadella – or the likes of Jeremy Corbyn!” Worst front page story of the week has to go to the Courier-Mail for this shocker. The story is not just distasteful, it’s plain wrong. Weekly Beast understands the man wasn’t medevacced to Australia because of a “botched penis enlargement”, but for an entirely unrelated medical condition. He did attempt a backyard penis enlargement, but it did not lead to his evacuation. Tomorrow's front page, tonight! You'll never guess how a botched penis enlargement got an asylum seeker into Oz https://t.co/tvXk0nYCkB pic.twitter.com/LbYYdiI93w The ABC has had a couple of interesting corrections recently. The first was for a report from the ABC in Pilbara which claimed that Elijah Doherty was “run over in 2016 by 56-year-old Wayne Martin”. The Indigenous teenager was run over by a 56-year-old man, but it wasn’t Martin, and the offender’s identity is still suppressed by the court. “On November 11 ABC Pilbara reported that Wayne Martin ran over Elijah Doughty in Kalgoorlie in 2016,” the correction said. “This was not the case. Wayne Martin was the Western Australia chief justice at the WA supreme court where the case was held. The 56-year-old man responsible cannot be identified.” The second one was a correction which it says it didn’t need to make but did so “in good faith”. A reader was concerned that an ABC Eyre Peninsula article stated that teenagers had walked through an “untouched” landscape in 1843 when Indigenous people had been in Australia for many thousands of years. The ABC said the article did say they were “the first western people” to walk south of Streaky Bay and included a picture caption which clearly stated that they “walked on beaches no westerners had ever stepped on”. “Nevertheless, in good faith, the ABC amended the article to state: ‘In 1843 two teenagers fled the brutal life of a whaling station at Fowlers Bay on the far west coast of South Australia and walked more than 500 kilometres through a pristine landscape to be rescued’.” Journalists who work for digital media startups or digital-only publications – like Daily Mail Australia – will be treated equally to their print colleagues under a landmark Fair Work ruling handed down on Thursday. The Media Entertainment and Arts Alliance welcomed the decision, which they said “removes the award’s outdated focus solely on print journalists which placed digital workers at a disadvantage”. Digital journalists will now have access to minimum standards for wages, penalty rates, overtime and other conditions of employment such as hours of work and breaks just as their print colleagues do, the media union said. The MEAA media federal president, Marcus Strom, said: “Digital is the reality of all newsrooms today. It’s about time the award caught up with the working lives of our members.” Guardian Australia’s journalists have access to penalty and overtime rates under their enterprise agreement, which came into effect in July 2019."
"The UK government is proposing a ban on the sale of new petrol and diesel vehicles by 2040, in a move that echoes a recent announcement in France. Setting this sort of media-friendly target is a positive and welcome response to the challenge of air pollution across UK cities. But delivering the infrastructure, research and development support and incentives to switch to greener cars will be the hard part. If conventional vehicle manufactures start getting nervous, then environment secretary Michael Gove may find the road to an electric future needs to be paved with more than good intentions. Planned well, a ban on sales of conventionally fuelled vehicles could deliver long-term benefits for both air quality and economic investment in post-Brexit UK. There is no question that a switch to alternative-fuelled vehicles would significantly improve air quality in towns and cities. The actual benefit will not be felt for many years, however, given the slow replacement rate for vehicles. Still, it does establish a clear direction of travel for public investment and as battery prices are set to tumble over the next decade, it will be one more reason for businesses to switch to greener vehicles. The 2040 target should encourage big electric vehicle manufacturers to invest in the UK. The country is a significant consumer market and has strong production capabilities in green technologies, especially the use of lightweight materials. BMW, for instance, has just announced it will build the fully electric Mini at its plant in Oxford. An even clearer example of policy driving private investment is Chinese carmaker Geely’s investment in a new hybrid model of the London taxi to take advantage of the capital’s new “ultra low emission zone”. Then there is the question of infrastructure. The UK has 6,535 charging stations, which sounds like a lot. But compare that to Norway, which has slightly more stations for a population less than a tenth the size. The number of charging points will have to rise to the hundreds of thousands.  New homes are required to have charging points by 2019, but installation costs £1,000 in existing houses. Subsidies can reduce the cost, but will need to be taken up on a vastly greater scale. And even this won’t help those dependent on on-street parking or multi-story living. A comprehensive infrastructure would certainly cost hundreds of millions. And even if successful, the government faces another headache – lost fuel duty could leave a hole in the budget of between £9 billion and £23 billion by 2030. Equally important is the need to think about energy supply. The widespread adoption of electric vehicles could put a strain on the grid at a time when fossil fuels are being phased out and a higher share of more volatile renewables is taking over. This means the government will need to think seriously about how excess power is stored during the hot, blustery days that favour solar or wind farms, and how to manage demand from electric vehicles when there is not enough sun or wind.   For car manufacturers, 2040 is several production cycles away. This gives them and the government time to think creatively about mass electrification. Roads that charge your car as you drive would need a big initial investment but would make electric cars significantly cheaper and better.  Self-driving cars and the trend towards mobility being a service you buy on demand through firms such as Uber might mean some people eventually don’t need to purchase vehicles at all. But these technologies are still many years away from the mainstream. This highlights a key point: that a shift to sales of alternative fuelled vehicles will not immediately reduce air pollution and will do nothing to impact on congestion. Only a more comprehensive policy of shifting people to different modes of transport will achieve this, and here the government’s commitment shouldn’t be relied upon. On an optimistic note, there are good reasons to imagine that a shift to greener vehicles may occur anyway. Pete Harrop, chairman of industry analysts IdTechEx, is bullish, predicting driving ranges of up to 1,000 miles and electric vehicles that can harvest solar electricity and act as batteries to store renewable power. “Electric vehicles are not simply catching up with conventional vehicles,” he told us. “They are overtaking.”  It’s clear which way the wind is blowing. Norway, as market leader, wants to ban sales of new petrol and diesel vehicles by 2025, and the German upper house has debated a 2030 target.  By 2040, internal combustion engines may no longer be able to compete in the market. But whether the UK’s infrastructure is ready for millions more electric vehicles remains to be seen."
"The Syrian civil war has raged for more than six years now. You’ve probably heard the following story linking it to climate change: an intense drought, made more likely thanks to global warming, caused “mass migration” within the country from rural to urban areas, which in turn contributed to the 2011 uprising which then escalated into civil conflict.  This narrative assumes that there is a relationship between drought, migration and conflict. However, the connection is not so clear-cut. Our worry is that putting too much emphasis on the climate overlooks the role of political and socio-economic factors in determining a community’s vulnerability to environmental stress. Conflict is not inevitable in the face of drought. That’s one conclusion from our work on drought and resource management in Syria. In our research, we broke down the popular “climate war” claim into two parts – the link between drought and migration, and the link between migration and conflict – to see if and how these factors fit together. We started with the very idea of environmentally induced migration. The problem is that it’s very difficult to determine the actual reasons why people leave home and look for opportunities elsewhere – a changing environment is likely to be only one among several factors and not necessarily the most significant. For instance, having the capital to move is a major factor for migration, so only those who can afford to move in response to drought are able to.  In the case of Syria, there has been no scientifically proven link between reduced rainfall or failed crops, and rural-urban migration. The evidence that has been used to prove the drought-migration link comes from displacement reports published by the Syrian government and UN assessment missions. The two phenomena are claimed to be linked because they coincided in time. Scientifically, however, this is not enough.  The drought which affected Syria has been described as a severe, multi-year drought that lasted between 2006 and 2010. But rainfall levels in 2006, 2007, 2009 and 2010 were close to normal, both in Syria as a whole and in the northeastern “bread basket” region. This suggests that only 2008 was a real drought year. A drought can be devastating for one community but barely noticed in another. Just look at the Kurdistan region of Iraq, which was affected by the same dry period as Syria but without any mass migration flows at the time. A community’s vulnerability to drought is more important than the drought itself. Various factors meant Syrian farmers were particularly vulnerable to drought. An overuse of water to nourish thirsty crops such as cotton had left the land dry and degraded. The government had also cancelled subsidies for fuel used to power irrigation pumps and to take produce to market – and it had dismantled a micro-finance network that had served as an income security net. A national drought strategy that had been approved in 2006 was not implemented once the rains dried up. The second stage of the Syrian narrative is that migration causes violent conflict. While some research does suggest a connection, there is also evidence suggesting no strong link at all. By simply looking at migration flows past and present, we can see that violent conflict is rare. In fact, migration may actually strengthen social and economic conditions in receiving communities in the developing world. While urban migration does not cause development per se, sustained economic development does not occur without it. Religious, social and ethnic integration may also improve as contact with one another increases. However, migration can also promote conflict, through increased competition for resources and services, and tensions due to ethnic and demographic changes. The potential for conflict in a given urban space is mitigated by factors such as the destination area’s ability to absorb migrants, the permanency of people’s migration, and whether there is already social and/or political instability. In the case of Syria, there was a mass exodus of farming families from the worst drought-affected areas in the north of the country (the agricultural bread basket of Syria) to the nearby cities of Damascus, Hama and Aleppo. However, what role this migration played in helping to fuel the uprisings and then the conflict is far from clear.  The initial protests broke out in the city of Daraa, in the south-east of the country, in response to the arrests and mistreatment of a group of youths allegedly caught painting anti-government graffiti. What started as a provincial uprising spread to other parts of the country where deep-seated socio-political dissatisfaction had been simmering for years. What this sequence of events highlights is that the conflict is a culmination of several interconnected factors that had been steadily developing over decades. While drought, migration and conflict may all be linked by association, such links are not established facts and, in the case of Syria, they are difficult to gauge. What can be said with much greater certainty is that economic struggles stemming from drought vulnerability, the loss of subsidies and the loss of agricultural wages did contribute to widespread dissatisfaction with the government. And it was this dissatisfaction which served as a rallying cry to unite people in opposition."
"Dear readers, The Guardian believes in open journalism, which is why we’ve never put up a paywall. Your continuing support allows us to keep our reporting and analysis accessible to readers across the world. Last year you helped us raise more than $1m in our year-end campaign. Here’s some of the journalism that support funded and the impact it had across the country: Next year America will face a momentous choice. The future of the White House, the supreme court, abortion rights, climate policy and a range of other issues are in play – at the same time that misinformation makes rigorous reporting more important than ever. And across the world, similar challenges lie ahead: the rise of far-right populism, escalating inequality and a growing number of autocrats in power. That’s why robust fact-based, independent reporting is critical: now through January, we hope to raise $1.5m to fund our journalism in 2020. With your help, we’ll continue to fight for the progressive values we hold dear – democracy, civility, truth. Please consider making a contribution. And as always, thanks for reading."
"
Share this...FacebookTwitterAccording to the news (the Associated Press, Seth Borenstein) 2014 is the hottest year on record. His numbers come from NOAA and NASA, so of course they are correct (sarc off).
And of course the record Seth is quoting only goes back to the last half of the Nineteenth Century, so that leaves out the Medieval Warm Period, the Roman Warm Period, the Minoan Warm Period, the Holocene Climate Optimum, and previous interglacials, but I digress.
Several things are left out of most of the discussions on the relative warmness of 2014:

Statistically, averaging thermometer readings that are accurate to 1 degree and sussing out a record that differs from another year by 0.01°C is one problem.
Spatially, averaging grid boxes that have as few as one thermometer, (and more than a few have zero!) with grids boxes that have scores of thermometers is another problem.
Correcting (homogenizing) a city thermometer by adjusting adjacent rural thermometers upwards to “correct” for the urban heat island is a whole different problem.
Pretending that changing the measuring instrument type and numbers, as well as the measurement times world-wide in the 1980’s and 90’s, didn’t change the resulting readings is also a large problem. See here and here.
This report is also guilty of “cherry-picking”. If it is the Meteorological Year that is picked, December to November, the record is still held by 2010, by 0.01°C. If it is satellite data (UAH) that is picked, 1998 is still the record, 0.15°C warmer than 2014.


Figure 1 is the latest GHCN and UAH Meteorological Year (December through November) data, along with the difference plot when the data are matched (normalized) at 1979.
In Figure 1, except for El Niño years, satellite data is not warming nearly as fast as the GHCN global data. The difference is now averaging more than 0.1°C.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




GHCN adjustments
GHCN is constantly changing their data. Every time they get new data, they completely recalculate the whole database all the way back to 1880. This gives ample opportunity for confirmation bias to adjust the numbers. Here is an example. I had downloaded the global data last September, with numbers updated through August. Just now, I downloaded the current data with the numbers through December, completing both the meteorological and calendar years. Here is a chart of the monthly differences between the two data sets for the last 17 years Beware. This data will change every time they get new data and recalculate. The chart shown was from data downloaded at 1 PM eastern time on January 18th, 2015, today. It is different from the data I downloaded last Friday.

Figure 2 is a plot of the changes in GHCN data for all the months since 1998 up to August of last year. The vertical scale is in 1/100 degree C.
The changes are small, but they are nearly all in one direction, warmer. One would think that data corrections would be in both directions, some warmer, some cooler, but in the last 17 years, a total of 200 months, only three months were corrected in the cooler direction. Note that in the last year the corrections were mostly in the warmer direction by .02° or more. Only one, August in the September update, was cooled. It was completely offset by the July change. All the changes in the first six months of 2014 were sufficient to make 2014 the warmest calendar year.
 
Share this...FacebookTwitter "
nan
"Do the same rules that govern human attraction also apply to our choices of fruit and vegetables? Plenty of evidence suggests we do look for similar traits in both people and produce, and our perceptions of food are clearly affected by what it looks like. Each year we waste 1.3 billion tonnes of food worldwide, a third of the total produced. This unbelievable figure is partly made up of “ugly” fruit and vegetables – those that are perfectly edible but rejected by supermarkets due to their blemished skin or unusual shape.  In March 2015 I opened a pop-up Ugly Food Shop in a mission to change perceptions of ugly food. I became interested in why it was ever rejected in the first place, and whether supermarkets either dictated or answered to a desire for perfect veg.   Since then, ugly foods seem to be making a comeback. A flurry of excitement accompanied the launch of British supermarket Asda’s “wonky veg box” which, for just £3.50 (US$5), promises to feed a family of four for a week. So have we always cared about the shapeliness of our bananas, or are we only now becoming more receptive to the idea of bendy vegetables? Theories of human attraction suggest beautiful people are generally considered to be more honest, more social and more successful. Ultimately, we seem to be programmed to find attractive people more likeable – even newborn babies spend more time gazing at the prettiest among us. Symmetry is critical here, as symmetrical faces are easier to visually process and signify genetic health. From an evolutionary perspective, selecting a mate with even features is a safer bet, as asymmetries can be caused by disease and infections during physical development. Although it makes sense that we would naturally select produce that is the most likely to be free from disease, in reality imperfections in the shape of fruit and veg have no real bearing on their nutritional content or taste, and no evolutionary advantage. An alternative explanation is that we “eat with our eyes”. Colour has a huge impact on how we perceive taste, with multiple studies demonstrating how a variety of learned and natural responses can influence the communication between our eyes and brain to determine taste. For example, professional wine tasters admitted to being a little suspicious while drinking white wine visually disguised as a full-bodied red, however they ultimately trusted their retinas over their taste-buds, until the trickery was revealed. Equally, altering the colour of vanilla ice cream can determine it’s reported taste, with brown vanilla ice cream described as chocolate, pink as strawberry, and green as mint. Given these findings, it is understandable that it will always be the disfigured potatoes that are left on the shelf. However throwing away a few lonely spuds has nothing on the millions of tonnes of fruit and vegetables which are denied even the chance to make it through the supermarket doors.  Thanks to global abundance and international trade, supermarkets can now be more selective. Much of the food deemed ugly is damaged on long boat trips – literally a fruitless journey – while ugly produce grown closer to home is also rejected, imposing harsh conditions on farmers. The needless waste of both imported and homegrown fruit and veg seems senseless; however if consumers are unaware of it, they can do nothing to change it. Attitudes seem to be shifting though, thanks largely to high-profile coverage of massive food waste. Ugly food is becoming more popular, and social influence has a huge impact on our behaviour. Wonky veg can be rebranded to enhance that social influence, for instance our shop marketing campaign focused on “humanising” a team of unfortunate fruit and veg, giving consumers something to root for. More than just fashion, the multiple benefits of “ugly” foods are admired as it is both cheap and helps to cut waste. The ugly comeback shows awareness and social influence can override a natural instinct to select symmetrical and unblemished fruit and veg. Whether this is a trend capable of withstanding the rise and fall of passing fancy, only time will tell. However in the meantime if we can cut waste and spend less, that definitely sounds appealing to me."
"Of all the horrors that might befall the burnt-out, the flooded, the cyclone-ravaged and the drought-stricken Australian this summer, perhaps none could be viewed with more dread than turning from their devastated home to see advancing on them a bubble of media in which enwombed is our prime minister, Scott Morrison, arriving, as ever, too late with a cuddle. It’s fair to say that Morrison has pulled off other roles with more conviction – the shouty Commandant of the Pacific camps perhaps his most heartfelt to date, the Gaslighter-in-Chief his most audacious, his Mini-Me to Donald Trump’s Dr Evil not without tragicomic charge – but sorrowful Father of the Nation has begun to feel a firebreak too far.  In Australia we are all now being treated as children, quietened Australians, most especially on the climate crisis. While the climate crisis has become Australians’ number one concern, both major parties play determinedly deaf and dumb on the issue while action and protest about the climate crisis is increasingly subject to prosecution and heavy sentencing. In Tasmania, the Liberal government intends to legislate sentences of up to 21 years – more than many get for murder – for environmental protest, legislation typical of the new climate of authoritarianism that has flourished under Morrison. As Australia burns, what we are witnessing nationally is no more or less than the criminalisation of democracy in defence of the coal and gas industries. In this regard, the climate crisis is a war between the voice of coal and the voice of the people. And that war is in Australia being won hands down by the fossil fuel industry. Which brings us back to that industry’s number one salesman, the prime minister, standing there in the ash in the manner of Humphrey B Bear on MDMA, as, mollied up, he pulls another victim in the early stages of PTSD into his shirt, his odour, his aura – such as it is – and holds them there perhaps just a little too long. Sometimes, at his most perplexing, he lets that overly large head loll on the victim’s shoulder and leaves it there. Prayers and thoughts naturally follow. Perhaps it is just his way. Certainly, the prime minister is an unusual issue of two stock types frequently derided in broader Australian culture: the marketing man and the happy-clappy. But in fairness to both tribes, he seems to draw on the worst in both traditions and make of them something at once insincere, sinister and vaguely threatening. Perhaps it’s the slightly up and down smile, the uneven mouth and crooked teeth, a lack of symmetry that can be attractive in some here seems to suggest nothing more than an untrustworthy menace. After all Elvis made of his sneer an alluring smile. Scott, with his reverse magic, makes of his every smile a sneer. Still, his wisdom would seem to be that if he is seen to be very good at feeling our pain we won’t ask him what caused the wound. And therein the problem. The prime minister must accept that public men are judged by public acts. Real empathy would mean speaking honestly to our nation about what the climate catastrophe means for our economy, our environment, our society, and each of us and for each of us personally. All this theatre hides a deeply cynical calculation: that Australians will keep on buying the big lie, a lie given historic expression last Thursday morning when on national radio the prime minister declared that Australia’s unprecedented bushfires were unconnected to climate change. The same day the New South Wales government announced that Sydney dams had in the last 12 months received just 10% of the normal water inflows and declared level two water restrictions as numerous country towns face the prospect of no water. And on this day, when Sydney was blanketed in bushfire smoke, when much of Victoria was declared code red, fires were burning out of control in South Australia, and “climate emergency” was declared word of the year by Oxford Dictionaries, Morrison said that “to suggest that at just 1.3% of emissions, that Australia doing something more or less would change the fire outcome this season – I don’t think that stands up to any credible scientific evidence at all”. This is an argument entirely in bad faith. Two days before saw the release of a major UN report that forecast Australia to be the sixth-largest producer of fossil fuels by 2030. Between 2005 and 2030 Australia’s extraction-based emissions from fossil fuel production will have increased by 95%. By 2040, according to the report, on current projections the world’s annual carbon emissions will be 41 gigatonnes, four times more than the maximum amount of 10 gigatonnes required to keep global heating below 1.5C. According to the Economist: “The report lays much blame on governments’ generosity to fossil-fuel industries.” The report details at length how Australia supports its fossil fuel industries. Actively working through legislation, subsidy and criminalisation of opposition to enable Australia to become one of the world’s seven major producers of fossil fuels makes Australia’s actions directly and heavily responsible for the growing climate catastrophe we are now witnessing in Australia. It gives the lie to the nonsense that we will make our Paris commitments “in a canter”. It cannot be explained away. It cannot be excused. Australia is actively working hard to become a major driver of the global climate crisis. That is what we have become. The same day Morrison went to the Gabba, got photographed with cricketers and tweeted: “Going to be a great summer of cricket, and for our firefighters and fire-impacted communities, I’m sure our boys will give them something to cheer for.” To the question does he think we are that stupid, the answer was implicit in an interview the same day when the prime minister justified not meeting with 23 former fire chiefs and emergency services leaders calling for a climate emergency declaration in April, claiming the government had the advice it needed. He went on to say that: “We’re getting on with the job, preparing for what has already been a very devastating fire season.” Only he’s not. Getting on with the job would be calling a moratorium on new thermal coalmines and gas fracking. Getting on with the job would be announcing a subsidised transition to electric vehicles by 2030. Getting on with the job would be working to close down all coal-fired powered stations as a matter of urgency. Getting on with the job would be calling a summit of the renewable energy industry and asking how the government can help make the transition one that happens now and one that creates jobs in the old fossil fuel energy communities. And getting on with the job would be going to the world with these initiatives and arguing powerfully, strongly, courageously for other countries to follow as we once led the way on the secret ballot, women’s suffrage, Antarctic protection, the charter of human rights. We are not a superpower, but nor are we a micronation. We have an economy the size of Russia’s. Our stand on issues whether good or bad is noted and quoted and used as an example. And one only has to look at the global standing of New Zealand to see the power of setting a moral and practical example, and the good that flows from it for a nation and its people. Australians everywhere are ready to get on with the job of dealing with climate change. We just need a prime minister to lead us. In the meantime though we are left with a mollied-up Humphrey B Bear. That same day, news broke of a panicked attempt by the federal government to administer some desperate triage over the growing costs to ordinary Australians of climate change in the form of perhaps the most ill-considered piece of policy in recent political history: to underwrite insurance premiums in north Queensland where premiums on homes in cyclone-affected areas are becoming unaffordable. Major insurers have been warning for years that many homes will no longer be insurable as the consequences of climate change are felt and have been demanding action on climate change. The government has done nothing and now wishes to use taxpayers’ money to hide the growing costs to individual Australians of climate change. If the government does go ahead with this panicked response the precedent established is pregnant with catastrophe for the public purse. According to a detailed report by SGS Economics and Planning released at the beginning of this year more than 1.6 million Sydneysiders are at high risk of flooding or bushfires, about 2 million Brisbane residents face extreme risks from cyclones, and more than 4.4 million people in NSW and Queensland live in areas with extreme or high risk of cyclones. It will be impossible for any government to subsidise the premiums of Townsville residents with cyclone risk and not offer it to those in Huonville whose fire risk also increases yearly. And yet the government will not act on the fundamental problem that leads to those risks, choosing instead to use the public purse to hide the growing evidence of its failure. The man who brandished a lump of coal and told us not to be scared, the man who last October told farmers to pray for rain, the man who says there is no link between the climate emergency and bushfires, the man whose party has for 30 years consistently and effectively sought to prevent any action on carbon emissions nationally and internationally will finally have to answer for the growing gap between his party’s ideological rhetoric and the reality of a dried-out, heating, burning Australia. And as the climate heats up ever quicker, and as the immense costs to us all become daily more apparent, that day draws ever closer. Many political commentators tend to view Morrison as some political genius, the winner of the unwinnable election. But history may judge him differently: a Brezhnevian figure; the last of the dinosaurs, presiding over an era of stagnation at the head of a dying political class imprisoned within and believing its own vast raft of lies as the world lived a fundamentally different reality of economic decay, environmental pillage and social breakdown. A corrupted, sclerotic system incapable of the change needed, surviving only by and through a dull repression of dissent and dissenters can, nevertheless, seem eternal – until the hour it crumbles. At some point something gives. Something always gives. The longer the impasse, the more denied the common voice, the greater and more terrible that future moment. We still have other, better choices. We need leaders who will enable us to make them. Morrison’s Pentecostal religion places great emphasis on the idea of the Rapture. When the Rapture arrives, the Chosen – that is, those Pentecostalists with whom the prime minister worships and their controversial pastor – will ascend to Heaven while the rest of us are condemned to the Tribulation – a world of fires, famine and floods in which we all are to suffer and the majority of us to die wretchedly, while waiting for the Second Coming and Scott and co wait it out in the Chairman’s Lounge above. Could it be that the prime minister in his heart is – unlike the overwhelming majority of Australians – not concerned with the prospect of a coming catastrophe when his own salvation is assured? In any case, as a Christian whose faith is built on a direct reading of the gospels, the prime minister would know the most compelling and convincing form of betrayal has always been the embrace and kiss."
"Global heating is “supercharging” an increasingly dangerous climate mechanism in the Indian Ocean that has played a role in disasters this year including bushfires in Australia and floods in Africa. Scientists and humanitarian officials say this year’s record Indian Ocean dipole, as the phenomenon is known, threatens to reappear more regularly and in a more extreme form as sea surface temperatures rise. Of most concern are years in which the sea surface off the coast of Africa warms up, provoking increased rains, while temperatures off Australia fall, leading to drier weather. It is similar to El Niño and La Niña in the Pacific, which cause sharp changes in weather patterns on both sides of the ocean. Caroline Ummenhofer, a scientist at Woods Hole Oceanographic Institution in Massachusetts who has been a key figure in efforts to understand the importance of the dipole, said unique factors were at play in the Indian Ocean compared with other tropical regions. While ocean currents and winds in the Atlantic and Pacific can disperse heating water, the large Asian landmass to the north of the Indian Ocean makes it particularly susceptible to retaining heat. “It’s quite different to the tropical Atlantic and tropical Pacific events. There you have you have steady easterly trade winds. In the Indian Ocean that’s not the case,” Ummenhofer said. “There is a certain season where you have easterly winds. Otherwise you have seasonally reversing monsoon winds, which makes for very different dynamics.” Recent research suggests ocean heat has risen dramatically over the past decade, leading to the potential for warming water in the Indian Ocean to affect the Indian monsoon, one of the most important climate patterns in the world. “There has been research suggesting that Indian Ocean dipole events have become more common with the warming in the last 50 years, with climate models suggesting a tendency for such events to become more frequent and becoming stronger,” Ummenhofer said. She said warming appeared to be “supercharging” mechanisms already existing in the background. “The Indian Ocean is particularly sensitive to a warming world. It is the canary in the coalmine seeing big changes before others come to other tropical ocean areas.” Australian climatologists have pointed to this year’s dipole as at least one of the contributing factors in the bushfires. Jonathan Pollock, of Australia’s Bureau of Meteorology, said this dipole was “up there as one of the strongest” on record. Gemma Connell, of the UN’s Office for the Coordination of Humanitarian Affairs, raised concern over the impact of stronger and more regular Indian Ocean dipole events on Africa. “What we are seeing from the current record events is large-scale flooding across the region. Entire swathes are under water, affecting 2.5 million people,” she said. “And putting it in the broader picture of the climate crisis, this flooding is coming on the back of two droughts. What we are seeing, and what we are going to see more of, is more frequent climatic shocks coming. And all that is on top of the violence and conflict that has already displaced many of the people involved. “In Kenya, for example, the region hardest hit has been around Lake Turkana, where there are already global malnutrition rates above 30% following drought. People are trying to cope with back-to-back shocks and their resilience has been eroded.” Another concern for Connell and other humanitarian officials is that although climate scientists are racing to try to develop predictive modelling, there is disagreement over whether stronger Indian Ocean dipole events will lead to a wetter climate for Africa or a drier one. “As non-meteorologists trying to plan ahead, we’re being faced with complex and changing scenarios. We’re just running to keep up. Looking now at southern and eastern Africa, with failed rainy seasons and then flooding, none of it looks normal,” she said. “The new normal is a severe weather events. Looking at the Indian Ocean dipole’s effects, you have to see this is as a preview of what can be expected in other parts of world. And while I’m not surprised that attention of the world is elsewhere, that is still unforgivable given how many are suffering from a phenomenon the rest of the world helped create.” "
"
Share this...FacebookTwitterFace it. When it comes to environmental protection, the EU can be awfully strict. Drop just a single molecule of something hazardous out somewhere in nature, and expect it to be treated like the crime of the century. That’s the way it usually is with eco-bureaucrats, except of course when it comes to green energies like ugly wind turbines. There everything suddenly has no real environmental impact, and so they get a free pass.
German news weekly Der Spiegel here recently reported on how windmills are now polluting the North Sea through their corrosion protection systems. Spiegel writes:
With the continued expansion of wind parks out to sea, over the coming decades thousands of tons of toxic metal compounds will be brought into the North and Baltic Seas. The reason is the use of so-called sacrificial anodes. These are for preventing the corrosion of the steel bases of the wind parks.
Spiegel describes how these sacrificial anodes, which contain heavy metals, dissolve over time in the water and that no environmental impact study has ever been conducted. According to Spiegel just the interior corrosion protection of each steel tower will dump up to ten tons of aluminum over its 25-year lifetime. Yes, “each tower”!
With plans to install 6500 turbines out to sea by the year 2020, Spiegel calculates that this means 13,000 tons of aluminum rubbish could end up in the North Sea.
The German weekly also writes that the electrical method of corrosion protection, such as that used on ships, is also possible, but that the method is too expensive due to “higher maintenance requirements”. After all, wind power is already unaffordable enough!
So in Europe are 13,000 tonnes of chemical rubbish getting dumped into the sea anything to really worry about? Obviously not if they comes from “green” sources.
Photo credit: Bard 1.
 
Share this...FacebookTwitter "
"There are parts of Louisville, Kentucky, that are enveloped in green, where towering trees arc over broad avenues and walkers, joggers and bikers enjoy beautiful parks designed by Frederick Law Olmsted, the man who drew up plans for Manhattan’s Central Park. Even on the hottest days of summer, these neighbourhoods feel comparatively refreshing next to the more sun-baked quarters of the city, where shade is often an unavailable commodity on the street.  Cities are their own climates, often hotter than their surroundings due to the way surfaces like asphalt trap heat even as cars and buildings exude it. When a city is markedly warmer than surrounding rural areas, it is called an urban heat island – and Louisville ranks among the worst heat islands in the US, according to a 2014 study, with an average temperature difference of 2.7C (4.8F). Worse still, a 2012 study by Georgia Tech’s Urban Climate Lab found that Louisville was the fastest-warming urban heat island in the nation. Part of the reason for Louisville’s temperature extremes is geography. But a lot of it comes down to trees. Donald Trump is pulling the US out of the Paris climate accord - meanwhile sweltering US cities are facing ever greater challenges on coping with heat and the climate crisis. This year saw the hottest July on record and many US cities have endured heatwaves - including those  as far north as Alaska, where thermometers hit 90F (32C) for the first time.  This week Guardian Cities is examining the growing challenges for US cities and the best ideas for reducing the impact of the climate crisis on communities.  Mark Oliver, special projects editor, Guardian US A study commissioned by Louisville in 2015 found that the city had lost 54,000 trees a year between 2004 and 2012, reducing the city’s canopy cover from 40% to 37% over the period. Today, canopy cover is likely to be around 27%, according to Cindi Sullivan, executive director and president of the nonprofit TreesLouisville. Trees provide shade while also lowering the temperature of their surroundings through evaporative cooling. Without action, it is feared the tree canopy will continue to decline as trees fall due to storms, pests and age – a scenario that could see the city’s rapid warming continue, alongside a number of other deleterious effects. “Without a robust tree canopy,” said Sullivan, “our air quality is going to continue to decrease, stormwater and flooding from these extreme weather events is going to increase, the effects of draught are going to increase. There will be more health problems.” And while Louisville may be among the worst heat islands, the problems seen here are replicated nationwide – the city was only fifth-worst US heat island in the 2014 study, behind Las Vegas, Albuquerque, Denver and Portland, Oregon. “Most cities by the middle of the century [will be becoming] increasingly dangerous places to be outside,” said Brian Stone Jr, who wrote the Georgia Tech report on urban heat islands. “So if no steps are taken, that will just be amplified.” He added: “I think this is a non-trivial health-related issue for all large cities in the US. “It isn’t just that heat is uncomfortable – it kills people and is only set to get worse as the climate crisis continues.” While individual cities have little ability to impact the planet-wide climate crisis on their own, they do have the ability to temper the urban heat island effect within their own borders. Louisville is hoping to do just that. When it was named the fastest-warming US city in 2012, it did not take its new superlative lightly. The city created an office of sustainability, hired an urban forester and tapped Stone to conduct an urban heat management study, the first of its kind for a major American city. The city’s main approach to cooling itself has been twofold: promoting the use of more “cool surfaces” for paving and roofs to reflect radiation and heat away, but, more importantly, encouraging the planting of trees. “You need to do both. It’s not one silver bullet,” said Maria Koetter, formerly head of the city’s office of sustainability. TreesLouisville offers free trees to Louisville’s residents that can either be delivered to them or picked up. The group, in conjunction with the city, also offers a rebate to residents of up to 40% of a tree’s price – up to $80 – for trees they purchased themselves. Sullivan says that with 70% of the land available to plant in Louisville privately owned, getting individual families and businesses to plant trees is the only way the city can preserve and ultimately grow its tree canopy. “Five or six decades ago you wouldn’t move into a house without planting a tree, because that tree was your air conditioning,” she said. “So the idea that trees are a valuable asset is something that is not front of mind anymore for many people.” The Depave Project aims to plant trees in parking lots, and the city is offering rebates to residents and businesses that use cool roofs. Meanwhile, the University of Louisville’s Green Heart Project has just started to plant the first of its 10,000 trees in south Louisville neighbourhoods as part of a study looking into the impact on greenery on health that it says is the first of its kind. Aruni Bhatnagar, the professor of medicine leading the project, calls it “a community-based clinical trial in which instead of pills, we have trees.” The main hypothesis of the estimated project, which is expected to cost $20m, is that planting trees will reduce air pollution and thus improve cardiovascular health. But Bhatnagar says they will also be looking closely at secondary outcomes: when it’s greener and cooler, will residents be more inspired to exercise outside, lowering rates of diabetes and obesity? Will stress and anxiety levels drop? Will trees shield enough noise that sleep quality and duration improves? In cities like Louisville, tree canopy cover often corresponds directly with things like race and income, bringing heat, lack of shade and the associated heat-related health problems to areas already suffering other inequalities. An NPR analysis of 97 major US cities this summer found that poorer neighbourhoods were more likely to be hotter in more than three-quarters of the cities. Sullivan said a TreesLouisville analysis had found that Louisville neighbourhoods that were red-lined in the 1930s – that is, where loans and other services were refused based on racial discrimination – have 22% canopy cover today, while those that weren’t red-lined have 49%. In announcing the city’s study of its heat island problem in 2016, Louisville mayor Greg Fischer said: “We know that too often the zip code where you are born can correlate with negative health outcomes. That’s unacceptable.” But getting Louisville to a tree canopy cover to the city’s goal of between 40% and 45% may prove difficult. Reaching those goals could take decades and cost north of $1bn, according to the city’s canopy study. Money is tight and the city, despite its commitment to the heat island issue, recently folded its office of sustainability into another department and laid off Koetter, the office’s director. “I wouldn’t say we are necessarily on the path” to addressing the heat island effect, says Koetter. “I would say we are aware of what needs to happen.” She added that to meet its tree canopy goals, Louisville needed to plant about 100,000 trees a year for the first 10 years of a canopy building program, but that she did not see the city as being able to generate enough revenue to do that. Stone, the Urban Climate Lab director, pointed out that New York City was able to plant 1 million trees over the course of eight years, but said he was less optimistic that Louisville could reach its tree canopy goals. In 2017, Louisville passed an ordinance requiring that trees removed from public rights of way must be replaced. A new tree-protecting ordinance that would require developments to maintain certain levels of tree canopy cover is currently being considered by the city’s metro council. “We’re in a situation right now where many tree advocates and environmentalists think it doesn’t go far enough, that the percentage of trees that need to be saved in new developments needs to be increased,” said Bill Hollander, the councilman who introduced the proposal. “We also have some members of the development community saying it goes too far.” Sullivan of TreesLouisville said the proposed ordinance is a step in the right direction, but that more needs to be done – and fast. “There’s an old eastern adage that says the best time to plant a tree is 20 years ago. The second-best time is now,” she said. “We’re way behind, I’d say decades behind other communities that have already figured some of this out.” Ebony Pryor, 42, hopes the planting being done now will make a difference. She works as a business manager at New Birth Church in Rubbertown, a largely industrial area of the city known for its chemical plants. In the summer, eggy, sulfury smells waft into the church on some days and the heat is relentless. “It’s just straight sun and it’s 10 degrees or more hotter down here than other parts of the city,” she said. “That’s where the trees come in. The trees will be able to take some of that smell out – and definitely shade the area.” TreesLouisville recently planted young trees at New Birth Church, the first of 10,000 trees the group plans to put in Rubbertown in the coming years. “While you don’t seen an immediate effect, over time it will improve and help the quality of life down here,” said Pryor. In 10 or 15 years, “I think it’s going to be beautiful – and smell good.” Follow Guardian Cities on Twitter, Facebook and Instagram to join the discussion, catch up on our best stories or sign up for our weekly newsletter"
nan
"
Share this...FacebookTwitterHere’s the story the major mainstream media would prefer not to mention at all.
Hat-tip: Die kalte Sonne site here.
At the online finanznachrichten.de there’s a short report about a recent Swiss vote on a Greens-Liberals energy tax initiative. The result:
92 percent voted against the initiative that would tax the consumption of non-renewable energies such as oil, gas, coal and uranium instead of having a value added tax. According to the Greens-Liberals it would be an effective instrument for reducing energy consumption and for promoting renewable energies.”
In summary on a few fringe activists in Switzerland are interested in taxing reliable and still affordable fossil and nuclear energy.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Swiss Blick.ch called the result “an historic debacle” and “the most massive slap up beside the head ever” that a citizens’ initiative has ever suffered in Switzerland. Blick.ch writes:
The failure was historic – no initiative has ever gotten a result of less than 10 percent.”
Die kalte Sonne comments on the result, reminding us that it was…:
…the most clear rejection by the citizens since the founding of the modern Swiss federal state in 1848. It is also notable that the parties who supported the petition for a referendum, “The Green-Liberals” and “The Greens”, were not even able to convince many of their own voters. Both parties together represent 13.8% of all voters.”
Die kalte Sonne also comments on the lopsidedness of the result, claiming that it is the sort that one is accustomed to seeing in “hardcore communist states”. Only this time the vote was free and offered a choice.
 
Share this...FacebookTwitter "
"Samanth Subramanian argues that “the great trick of online retail has been to get us to do more shopping while thinking less about it – thinking less, in particular, about how our purchases reach our homes” (Deliver us, 21 November). But consumers have never taken much interest in where stuff comes from or how it is delivered. In a survey of UK adults back in 2009, only 14% claimed to have “some knowledge” of the “role of logistics in the economy”. When logistics works, which is most of the time, it is taken for granted and ignored. As a result, few people have any sense of the complexity, transport-intensity, environmental impact and social costs of modern supply chains, not just on the “last mile” but all the way back to the raw material source. Greater public awareness of distribution systems upstream of the home and shop could help to promote more sustainable patterns of consumption and more informed debate on subjects such as Brexit, climate change and the gig economy, all of which have an important logistical dimension.Prof Alan McKinnonKühne Logistics University, Hamburg, Germany • Join the debate – email guardian.letters@theguardian.com  • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitterDepending on which global temperature data one looks at, temperatures have not increased in the last 18 or so years. The reasons proposed have been various, ranging from natural cycles to increased aerosols, to heat escaping to space or the deep ocean.
Perhaps there are some other reasons that have not been considered. The following is a simple list, with illustrations. The list is divided into two sub-lists. Things that are natural and things that are anthropogenic or man made.
SOME NATURAL REASONS
 1. It’s The Atlantic Multidecadal Oscillation (AMO)

The AMO has been at the top of it’s warm phase since 1998. The index doesn’t get much higher than it is now. It can only go down from here. It was at a similar peak during the warm 1930s through the 1960s. It was negative during the cool 1970s. The peaks of the AMO tend to be flat for a couple of decades before flipping cool. We don’t know what drives the AMO. Data here.
2. It’s The Pacific Decadal Oscillation (PDO)

The PDO has been trending down since the early 1980s. It also was up during the 1930s and negative during the 1970s. The AMO and the PDO are the natural ocean cycles that climate scientists talk about. The PDO reached a peak in the 1980s and has been declining since. This index is volatile. The PDO has a huge effect on weather on the Pacific Coast of North America. Data here.
 3. It’s The AMO and PDO together

They are sometimes roughly added together. (Even though they are not measuring the same thing.) If one adds them together, it can be seen why the late 1930s were warm and the 1970s cool. The sum (green trace) reached a peak in 2000 and is now declining because of the declining PDO. (Computed by author.)
4. It’s the sun

The sunspot number (SSN) average has declined since the mid-1990s. One can see a cause for the 1970s cooling in the SSN, but not for the 1930s warming. The early 20th century cooling may have been caused by the low SSN around the turn of the century. The sun is excused for the recent pause because the total solar index (TSI) changes only by a fraction of a Watt/m2 over large changes in SSN. But other factors may be in play. (Source: WDC-SILSO, Royal Observatory of Belgium, Brussels.)

5. It’s cosmic rays
The neutron count is an indicator of the cosmic ray flux at the top of the atmosphere. Here is the neutron count at Oulu, Finland since 1965. It is thought that cosmic rays seed cloud formation. Therefore high recent count is providing cooling clouds. Graphic downloaded from here, the Sodankyla Geophysical Observatory, University of Oulu, Finland.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




6. It’s clouds and earth’s albedo
Albedo and cloud cover reached a peak in the 1998-2000 era, at the beginning of the pause. Clouds, especially high clouds, reflect solar energy. Each 1% of albedo change translates to 1 W/m2. There is another graphic of albedo from the EarthShine project, here. All the albedo data show a significant rise in albedo after 1998. The cosmic ray/neutron count may not match the albedo/cloud cover, but cloud cover really did increase. Graphic used by permission of Dr. J. Floor Anthoni, and seen here.
PAUSE IS ANTHROPOGENIC
I mean by anthropogenic that man may have caused the pause by manipulating the temperature data. These manipulations seem to enhance the warming trend in support of politics, though the stated intent for many was to enhance accuracy. Here are some examples:

7. It’s the time of observation (TOBs) adjustment
Observing times have been gradually changed from afternoon to morning hours. The bias from this adjustment was about 0.2°C for TMax and 0.25°C for TMin. This impacts the historic data, but also, this adjustment is now finished. Most measurement sites now use morning observing times and no more changes will be made, hence the pause. No more warming will come from this source. The TOBs adjustment is clearly visible in the DIFFERENCE BETWEEN RAW AND FINAL USHCN DATA SETS graphic below, though it is only half of the total. Figure from here.

8. It’s all adjustments including TOBs
This graphic shows the result of all adjustments: homogenization, sensor changes (CRS vs MMTS), and TOBs. Note also that the warming due to all these changes is about 0.5°C, much of the warming that is supposed to have taken place since 1950. Note that these changes went flat during the 1990s decade.  Note the similar shaped curve to the TOBs adjustment with a flat shape in recent times. There should be no more warming from this source. Figure from NOAA/NCDC here.
9. It’s the number of stations

Since 1980, the number of stations reporting temperature data has declined by half. Some of the decline was due to the collapse of the Soviet Union. This resulted in loss of data from the Russian high arctic and Siberia, among the coldest land stations in the Northern Hemisphere. Some of these stations have resumed reporting in recent years, but most have not.
Other stations in Africa and Asia were closed by newly independent former colonies. World-wide, many stations closed instead of being upgraded. On average the remaining stations are at lower elevations and in warmer, populated areas. This situation has now stabilized. Figure from NASAGISS here. A discussion of this problem is here.
These are nine possible reasons for the pause. One or two are sufficient. Nine is overkill.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWe already have Climate Audit, but now it looks like we may be getting “Climate Scientists on Trial”. Here’s a site you’ll want to subscribe to, bookmark – or at least visit on a regular basis:
climatechangepredictions.org
As the name says, it focusses on earlier climate predictions made by the global warming alarmists (and there have been many) and compares them to what really happened. The climatechangepredictions.org site is run by Ian Hipwell, a retired lawyer from Sydney, Australia.
I think Ian will be a real asset because in his profession one is often trained to hold people’s feet to fire. Many like to say or write things, but are they able to back it all up later on. After all people who listen to these experts often act and make decisions based on the things said, and thus may incur either benefit or major damage as a result.
Alarmist scientists have said lots of things in the past, and it’s time to go back and look at them. The approach could be something like: Mr. Scientist, 15 years ago you said snow and ice would be things of the past, yet we are now seeing record snowfalls and harsh winters. Which is the lie?
In an e-mail to me Ian has written that although he is not scientifically trained, he has “followed the climate change issue as a hobby for some years. It was the name calling by AGW supporters that first made me suspect that the case wasn’t as strong as we had been led to believe.”
He writes that his intention is “to invite people to consider that perhaps the science isn’t settled after all“. Yes, the jury is still out.
And because so many of the earlier predictions made over the past 40 years have been within the realms of absurdity, Ian writes that the blog will surely provide a fair amount of humor. Indeed. For us skeptics the earlier claims of snow being “a thing of the past” and the Arctic being ice free by 2014 still continue to be the source of much laughter.
I think having this kind of blog, which devotes effort on examining past predictions, is a great idea because this is what science really gets down to. After all if the observations contradict the hypothesis and predictions, then the hypothesis is simply wrong.
 
Share this...FacebookTwitter "
"Hurricanes in the Caribbean and deadly floods across South Asia have once again raised the issue of climate justice.  The association between such events and climate change is now beyond serious question: we have had 30 years of well-founded scientific warnings about the relationship between increasing global temperatures and the incidence and severity of extreme weather. Much more problematic is the question of responsibility for climate change itself, and who should justly pay compensation for the resulting damage. This is complicated, and there are no clear categories of winners and losers, or responsible and blameless. Consider how the benefits from greenhouse gas emissions are usually divorced from the impacts of climate change, yet hurricane-hit Texas owes much of its wealth to oil. Or look at the extraordinary inequalities among those affected by the storms – most are relatively poor, but a few are among the world’s richest people. International debate on climate justice has usually occurred within the UN, via its Framework Convention on Climate Change (UNFCCC), in a process which led to the Paris Agreement. For much of the time since its inception in 1992 there was a heavy focus on cutting emissions rather than on adaptation to the damaging consequences of climate change.  Responsibility for global warming was usually framed as an obligation for developed states to make the initial moves to reduce their emissions, under the concept of “common but differentiated responsibilities and respective capabilities”. Climate justice was seen as something developed states owed less developed states, and were obliged to deliver so the latter had an incentive to cut their emissions, too. However, by the Bali conference in 2007 it was clear that climate-related sea level rise and extreme weather events were already happening. Adaptation was therefore moved up the agenda alongside emissions cuts. In crude terms, if the developed world wanted a new comprehensive agreement on tackling climate change it would have to provide sufficient guarantees of assistance for the less developed majority. These included a proposed US$100 billion per annum Green Climate Fund but also new form of compensation for “loss and damage for countries vulnerable” to hurricanes and other climate-related disasters. The “loss and damage” mechanism made it into the 2015 Paris Agreement but has not yet been fully implemented. It was a controversial topic, however, as it raised the question of liability or even reparation for climate damage. Direct responsibility was both difficult to establish and resolutely rejected by developed countries. The problem is these issues are discussed within the context of a system of self-interested nation states. Climate change requires a global, concerted effort, yet entrenched political structures within each country reinforce competitive and antagonistic outlooks. It is always difficult, for example, to make the case for foreign governmental assistance when this is ranged against domestic poverty. To be sure, some of the more progressive rich countries do reflect a “communitarian” approach which recognises some moral obligations to assist vulnerable states. This goes beyond the strict minimum in international law of the avoidance of harm, but it certainly does not admit any direct responsibility or liability. At most, this conception of international climate justice is based upon a recognition that the populations of other countries should not be allowed to deteriorate below minimal standards of human existence and is common to other areas of humanitarian assistance and disaster relief. Yet such state-based thinking remains unable to handle the complexity and all-encompassing nature of climate change. What’s needed is an alternative “cosmopolitan” approach to climate justice. Under cosmopolitanism the focus is on individual human beings and their needs and rights, all of whom would exist in one community where nationality is considered irrelevant to moral worth. This means a Bangladeshi farmer or Caribbean fisherman have as much right to be protected from the impact of global warming as someone in Texas or London and, in this sense, cosmopolitan climate justice mirrors the evolution of international human rights principles.  Nationality is often used to indicate development, or vulnerability to natural hazards, yet such categories are essentially misleading. As illustrated by flooded homes and destroyed roofs everywhere from Barbuda to Houston, it is more useful to think of rich and poor (or safe and vulnerable) people rather than countries.  True climate justice will have to reorientate the debate away from state sovereignty and international standing towards a focus on personal harm. A system of individual carbon accounting would also help so that people make a contribution to poverty reduction  and disaster relief appropriate to their wealth and lifestyle.    As hurricanes engulf numerous countries at once, and indirectly affect even more, climate change powerfully illustrates the need for creative thinking about a truly global cosmopolitanism in which the avoidance of human suffering comes before self-interest and it is recognised that there are many poor and vulnerable people in “rich countries” and fabulously rich people in “poor countries”."
"
Share this...FacebookTwitterHow often have we heard the older folks reminiscing about good old fashioned New England winters we used to get 50 years ago? Well, they’re back.
Ironically today’s winters are in fact so tough that journalist Jason Samenow of the online Washington Post here predicts that we may remember the current one “for generations“.
A “severe cold” is set to blast the eastern U.S. later in the week. And bitter cold is projected to persist well into March.
The WaPo writes that “parts of New England could witness its coldest air in years” and that frosty conditions will dip “into central and parts of south Florida“.
According to the WaPo, the cold “can be traced to the polar vortex” coming from the North Pole regions, and that the winter will likely leave a deep imprint in our minds:
For areas of New England buried under multiple feet of snow, the added element of uncompromising cold will present extreme mid-winter conditions that may be recalled for generations.“
Cold plunging from the North Pole deep into the middle latitudes normally means the polar air gets replaced, usually by warmer air from the south. Yet Arctic regions are also seeing polar vortex-like cold effects, with places in Alaska dipping close to -60°F, writes the WaPo.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The cold that is to grip the US east coast is set to come in two waves. The second wave will originate in Siberia, says the WaPo, and temperatures will be at levels that are 30°F below normal along the entire east coast of the US, with bitter cold literally effecting more than 100 million people.

Source: Weatherbell Analytics
Scientists are baffled by the recent severe cold winters that have struck North America. Ten years ago, when North America saw balmy winters, scientists were trumpeting cold and snowy winters as those of the 1960s and 70s, were “a thing of the past“. Now these old fashioned winters are back from the photo albums and the same red-faced scientists are now claiming these are global-warming frigid winters.
The truth and reality are that this has nothing to do with global warming, but has everything to do with natural cycles…the very ones that have sent global warming packing for 18 years.
Scientists have yet to explain how one distinguishes between a global-warming frigid winter and one that is an old fashioned cold one. Both are the same and arecaused by the same thing: predominant pattern of Arctic air dipping far south for the greater part of the winter season.
 
Share this...FacebookTwitter "
"The first ever election leaders’ debate focusing on the climate crisis will be broadcast by Channel 4 next week, with the prime minister the only major party leader set to be absent. Channel 4 News said it was awaiting confirmation from Boris Johnson as to whether he would take part and could place an empty chair in the place of the PM if he declines to attend.  The campaigners Possible – who have been pushing for a leaders’ head-to-head on the climate emergency – said it was a historic moment which put global heating front and centre of the election campaign. During the ITV live leaders debate on 19 November, the Conservative party re-branded their press office account on Twitter as 'factcheckUK', to tweet anti-Corbyn points during the programme to its 75,000 followers. On Twitter accounts there is a username - in this case @CCHQpress - and a screen name, which appears more prominently. The Conservatives changed the screen name to 'factcheckUK', and also changed the logo and biography of the account to read 'fact checking Labour from CCHQ'. No explicit mention of the Conservative party name in full was made, so users would have to know that CCHQ is an acronym for 'Conservative campaign headquarters' in order to understand who was providing the fake fact-checking service. Because the @CCHQPress account on Twitter is 'verified', it means when it appears it has a blue check mark next to the name, to show that Twitter has 'verified' that the account is who it says it is. This was retained while the account was tweeting under the false name 'factcheckUK'.  Martin Belam Max Wakefield, the director of Possible, said: “With poll after poll showing huge demand for emergency action from the political parties this has to be our first climate election. “It’s in the prime minister’s hands to make this happen, show leadership on the defining issue of our time – and prove he’s ready to take on the challenge if elected.” Earlier this week leaders from all the main opposition parties wrote to Johnson urging him to take part in any televised debate on the environmental emergency before the election. The Labour leader, Jeremy Corbyn, the Scottish National party leader, Nicola Sturgeon, the Liberal Democrats leader, Jo Swinson, and the co-leaders of the Green party, Jonathan Bartley and Siân Berry, argued that the public had a right to know what political leaders intended to do to avoid “the irreversible impacts of environmental breakdown”. All have agreed to take part in next week’s debate. In the letter they stated: “The climate and nature emergencies threaten everything we hold dear; the jobs we do, the health service we rely on, the houses we live in and the food that we grow and eat. The public are right to look to us, their politicians, for leadership. The ambition of our response must match the scale of the challenge.” The Conservatives, whose environmental record was condemned by leading climate scientists and former government advisers this week, told Possible that Johnson would not participate because he did not want environmental issues to be “siloed”. The Tory party has been approached for comment. The idea of a televised climate debate has gained widespread support since it was launched by school strikers, students and pensioners’ groups earlier this month. More than 500 scientists – including Sir David King, a key government adviser on the climate crisis until 2017 – have backed the plan. Beccy Speight, the RSPB’s chief executive, said: “We must have the opportunity to scrutinise those vying to be our next prime minister on how they will deliver action at the unprecedented scale required.” In the past two weeks, the campaign has also received support from more than 70 organisations with a total membership of more than 10 million, including the Women’s Institute, the National Trust and the National Education Union. And more than 188,000 people have signed a petition supporting Possible’s campaign. The climate emergency has been forced up the political agenda in the past year as growing evidence of the crisis – from floods to wildfires, record temperatures to melting ice – has become impossible to ignore. In the UK, hundreds of thousands of schoolchildren have taken to the streets to demand action and Extinction Rebellion protests have brought large parts of London to a standstill."
"Student activists at Cambridge have accused the university of attempting to greenwash its relationship with oil and gas firms by stealing their group’s name for a university project. Cambridge University is to launch its Cambridge Zero initiative at an event in London next week. The project’s website, which is already live, touts it as a “bold response to the world’s greatest challenge”.  It says that, along with developing greener technology, it will “harness the full power of the university’s research and policy expertise, developing solutions that work for our lives, our society and our economy.” The project is to be led by Dr Emily Shuckburgh, a climate scientist and mathematician who previously spent 13 years as a researcher with the British Antarctic Survey. Cambridge Zero’s portfolio of research will include work on zero-carbon energy alternatives, policies, industries, financial processes, transport and climate repair. The university says its 2018 carbon reduction strategy makes it the first university taking science-based steps to achieve “absolute zero” net carbon by 2048. Cambridge has come under criticism for its links to the oil and gas industry, most recently over a £6m donation from Shell to a laboratory studying methods of hydrocarbon extraction. The university has begun to lobby journalists for positive coverage of the launch. Critics from the student-led Cambridge Zero Carbon society, who have been campaigning for the university to divest from fossil fuels, say it is a public relations stunt designed to divert attention from continuing links to oil and gas giants. “Taking our society’s name, which has stood for climate and reparative justice, for the university’s fossil fuel-partnered PR stunt spin initiative in order to give social legitimacy to climate criminals is exceptionally unhinged and morally bankrupt,” a spokesperson for the group said. Campaigners expressed concern about Shuckburgh’s work on a 2013 project with oil exploration company Schlumberger, and said that Shuckburgh had shared stages at events with oil executives. Activists also raised concerns over Cambridge Zero’s planned partnership with the BP Institute – a university institute endowed and part-funded by the oil giant BP – to research geo-engineering techniques, including carbon capture. In a letter to the Guardian after the initial publication of this article, Shuckburgh said she had never given a talk at an event organised by BP. “As a prominent climate scientist, I have been on many panels talking about climate science and there have been occasions on which oil executives have been on the panels too.” This in no way implied a connection with the fossil fuel industry, Shuckburgh’s letter said. She said that as principal researcher on a 2013 grant provided by the National Environment Research Council she had used data from Schlumberger ship surveys to contribute to work on fuel efficiency and to academic writings. The project was not for Schlumberger, the letter said. In 2012, 2015 and 2018 she had given climate science talks to masters students at the BP institute, a research institute at Cambridge university. A joint letter by the EcoNexus and Biofuelwatch advocacy groups accused Cambridge Zero of “Orwellian spin” by describing the work as “climate repair”. They said: “Geoengineering is a fantasy technology that at best legitimises the ongoing ecocide and genocide perpetuated by fossil fuel companies, and if implemented would have a devastating and unpredictable impacts on ecosystems and human communities around the world.” A university spokesman said: “Cambridge Zero is the University of Cambridge’s response to calls for action on climate change. It harnesses the research, innovation and policy ideas from more than a thousand academics across the university with a singular focus on decarbonising the modern economy. Dr Emily Shuckburgh is one of the UK’s leading climate scientists with a 25-year academic career dedicated to scientific discovery exclusively related to climate science at Oxford, MIT, Cambridge and the British Antarctic Survey.” • This article was updated on 24 and 26 November 2019: to include a response provided by Dr Emily Shuckburgh; and to remove unfair implications about her interactions with the fossil fuel industry, for which the Guardian apologises."
nan
"Much of Britain’s infrastructure is long past its sell-by date. This is partly down to ineffective financing, a lack of investment, and a government preference for fancy megaprojects over boring-but-crucial things like the energy grid. History shows, however, that there is another, simpler reason. This is the neglect of project management, namely, the planning and construction of infrastructure projects. Nowhere has this been more evident than in the UK’s pitiful record with power stations. Just look at Hinkley Point C. In its desire to avoid British consumers subsidising construction, and its belief that the private sector could simply build a nuclear power plant, the government has effectively handed over project management responsibilities and oversight to French state energy firm EDF. This means it now has little say in or control over any construction problems, the cost of which EDF will recoup through a very generous fixed price for the electricity the plant generates. Under the present arrangement, the British government cannot do much about the fact its flagship nuclear project is already £1.5 billion over budget and a year behind schedule. Failure to ensure that power plants are built on time and on budget goes back much further. In fact, long lead times, engineering problems, cost overruns, and construction delays have been problems in the UK since the early 1960s. A 1963 select committee report on the electricity industry pointed out that it took five years for a station to be commissioned in the UK, compared to two-and-a-half years in the US and just 13 months in Japan. A few years later, the National Board for Prices and Income found that incomplete power stations were costing the taxpayer around £30m a year in annual interest payments alone, roughly £345m in today’s money. Nuclear power plants were by far the worse. In the mid-1960s, the UK decided to build a series of plants using a British-designed advanced gas cooled reactor (AGR) that had never been built on a commercial scale. Construction was hampered by engineering problems, however. For example, Dungeness B station in Kent, the first AGR station, started construction in 1965 and was meant to be completed within five years. But the station wasn’t connected to the grid until 1983, and didn’t start commercial operation until 1985, 15 years behind schedule. As early as 1969, the Wilson Committee, which was set up to examine the causes of these delays, pointed to inefficient management. Project managers responsible for overseeing construction were either incompetent or had little incentive to speed things up, and the committee recommended more authority should be exerted over them. Its suggestion was echoed that same year by the select committee on science and technology, which argued that inadequate attention on site had led to many breakdowns of power station generators. The problem was the government did not take much heed of these recommendations. Records held at The National Archives from this period show there was little urgency among civil servants or politicians to rectify the situation. Nuclear energy was considered  crucial to Britain’s energy security and industrial strategy, but much less importance was placed on ensuring that the nuclear plants were built on time. Roy Mason, minister of power in the late 60s, went so far as to obstruct the construction of a nuclear power plant to appease the National Union of Mineworkers. In fact, there seemed little realisation within government that a key to successful infrastructure project lay in efficient project management – and the the ability to construct on budget and on time. Hinkley shows that this same tendency to overlook the importance of project management still exists today. It’s just one aspect of infrastructure policy, of course. But until the government starts making project management more of a priority there is no guarantee the UK will get its infrastructure right. Funds and financing are important but what actually happens on construction sites is equally, if not even more, crucial."
"Jeremy Clarkson has made what could be the biggest reversal of his 30-year career. The anti-environmental columnist has, for the first time, accepted the existence of global heating after seeing the impact for himself. Clarkson’s epiphany came as he and his Grand Tour co-stars ran into difficulty while filming a 500-mile boat race from Siem Reap in Cambodia to Vung Tau in Vietnam.  The group’s jet boats slowed to a crawl and they were forced to wade through Tonlé Sap lake in the usually vast Mekong river system, which has been affected by water shortages. “The irony is not lost on me,” he told the Sunday Times. “A man who hosted a car programme for 30 years, limited to 7mph by global warming.” He described enduring “two days of absolute frustration” as the group had to be towed through the river, which had been reduced to a “puddle”. The former Top Gear host confessed he found the “graphic demonstration” of global warming “genuinely alarming”. However, Clarkson does not appear to have yet embraced the green movement he once dismissed as “eco-mentalists”. “But we don’t blame mankind for it,” he said. “We’ll let Greta [Thunberg] do that.” He took yet another dig at the 16-year-old Swedish campaigner in his interview, accusing Thunberg of having no answers to the climate crisis. “‘Ooh, we’re all going to die.’ Right, tremendous. Now go back to school,” he said. “But I genuinely hope people people are working on what on earth to do about it.” Clarkson had previously used his column in the Sun to label Thunberg a “spoilt brat”, following her speech at the United Nation’s climate action summit in September. “How dare you,” Thunberg scolded world leaders at the New York summit. “‘You have stolen my dreams and my childhood with your empty words.” In 2009, environmental campaigners dumped manure on Clarkson’s lawn in response to his attitude to global heating. Grand Tour, the lavishly funded series that Clarkson started after his acrimonious departure from the BBC’s Top Gear, returns to Amazon Prime on 13 December. The BBC revealed on Saturday that Thunberg will guest-edit a Christmas special of Radio 4’s Today programme. The campaigner is set to speak to leading figures in the fight against global heating and has commissioned reports from the Antarctic and Zambia."
"
Share this...FacebookTwitterStefan Rahmstorf: No pause, anywhere!
By Michael Krueger
[Translated by P. Gosselin)
“No pause, anywhere!” announced Stefan Rahmstorf in his latest article at KlimaLounge. And he added: “As our long-term readers know, there’s been a steady global warming since the 1970s, though it has been superimposed by the usual short-term fluctuations, it has not slowed down or accelerated by any significant means. […] As there has not been any slowdown, there has not been any pause or hiatus of any kind in warming.”
But this is easy to check over. To do this I’ve gotten the data on global temperature from the NOAA, plotted them and added the linear trends for the periods of 1970-2015, 1980-2015, 1990-2015, 2000-2015 and 2005-2015. (By the way, NOAA also uses the NASA GISS dataset for global temperature).

What is seen above is that the trend since 1970 has been in decline. The rise in the trend lines is becoming less and less., i.e. flatter and flatter. Meanwhile the global warming scientists have been telling us for year/decades that global warming would accelerate more and more as greenhouse gases increased.
In fact just the opposite has been true.
Here once again is the NOAA data in its original form from the NOAA site for the period of 1998-2015.

There are actually people who see in it an unabated global warming (in the range of 1/100 of a degree). Hard to believe. Yes, you only have to believe in it, and suddenly you’ll see it. It’s like the blotch images in psychology.
Share this...FacebookTwitter "
"More than 50m people in Pakistan are at risk of arsenic poisoning from contaminated groundwater. That’s according to a study recently published in the journal Science Advances, based on samples from 1,200 wells across the country. Arsenic cannot be removed from groundwater through common processes such as boiling or filtration – instead it requires expensive procedures such as reverse osmosis which are beyond the reach of most poor people. Contamination is particularly worrying in this case as Pakistan is unusually dependant on a single, vast underground natural reservoir known as the Indus basin aquifer. The aquifer covers an area of 160,000km² – making it slightly larger than England – and spans Pakistan’s border with India.  Arsenic contamination may not even be the most alarming thing about the aquifer, however. At current rates of groundwater mining there is considerable risk the wells will eventually run dry. Both Pakistan and India have historically subsidised electricity and diesel for running agricultural wells that tap into the aquifer. Groundwater users only pay for the energy used to mine the resource; the water itself is not metered or priced. The aquifer is literally free for anyone to tap into by drilling a well – whether it is for agricultural, industrial or domestic purposes.  Both countries are taking out far more water than is being replenished by rain or rivers. In fact, India extracts more groundwater than any other country in the world (not just from the Indus), and Pakistan is fourth in the list. The Indus aquifer is already the second most “overstressed” groundwater basin in the world and, at current rates of use, reserves like this may be “severely depleted” over the next few decades.  More than 300m people live in the largely agricultural and extensively irrigated Indus basin. Of the total water used for irrigation about half comes from the aquifer below ground, rather than rainwater or the river itself and its various tributaries. There are irrigation canals, but their flow is concentrated in the summer monsoon period and isn’t as readily available as groundwater. Despite increased concerns over groundwater use, governments on both sides of the border have been encouraging farmers to produce and export water-intensive food crops and livestock products. Given lots of water from a fast-diminishing aquifer is needed to produce everything from a grain of rice to a slab of beef, this trade amounts to “virtual water” exports. “Virtual water” refers to water embedded in trade products. A country that exports rice is in effect also exporting the water that is used to grow rice. This is why water-starved countries such as Saudia Arabia have stopped growing products like wheat. Importing food instead essentially means they “import” water rather than using their own scarce reserves. Key exports from India and Pakistan including rice, sugar, cotton and textiles all require lots of water to produce. In addition, both governments are incentivising the growth of meat exports through the use of various subsidies, without considering the water footprint. Pakistan’s halal meat export trade has grown more than ten-fold in the past decade, for instance – mainly to water-scarce  countries such as Saudi Arabia.  Growing development pressures and increasing industrialisation in India and Pakistan also contribute to increased groundwater stress and pollution. Though official estimates say industry uses a mere 2% of the groundwater extracted in India, and even less in Pakistan, the reality is likely to be much more. In the Indus region, the aquifer is crucial for water-intensive sectors such as textiles or leather and, in practice, industrial mining of the region’s groundwater is not metered or priced. Most industrial units also discharge untreated effluents in unlined pits, which eventually seep into the ground and has resulted in severe contamination of the water table. In India, some states where groundwater levels are critical now require a license to drill new wells. In Pakistan, however, unlicensed drilling continues. The current legal framework for groundwater is spread across a variety of instruments both from colonial and post-colonial times, as well as local customs that often conflict with each other. Property rights are largely defined by an archaic piece of colonial legislation, the Easements Act of 1882, which allows landowners to effectively collect and dispose of underground water as long as it is not a part of a public irrigation network.  Most of the elaborate state irrigation bureaucracy serves to manage and distribute surface water – not the aquifer. India has recently established a Central Groundwater Board, but in Pakistan monitoring and management still happens in silos, with no particular institution taking responsibility for the conservation of the resource."
"
Share this...FacebookTwitterRecently I published an opinion by Harvard astrophysicist Willie Soon concerning the dubious “2014 hottest year ever” claim.
That post is doing very well and continues to be widely shared in the social media – so much so that the piece stung a sensitive nerve over at Climate Nexus. But instead of rebutting Dr. Soon point-by-point, Climate Nexus produced an openly sophomoric rant with the usual name-calling we are all accustomed to from alarmists who run out of arguments.
Here’s what Climate Nexus wrote at their “DENIER ROUNDUP”:
“Denier-for-Hire Preaches About Prostituting Science
While we would normally ignore the low-grade blogs like NoTricksZone as well as bottom-tier, fossil fuel spokesmen-for-hire like Dr. Willie Soon, the two have come together for a post that is just too good to pass up.
NoTricksZone wanted a comment from Soon about how 2014 is shaping up to be the hottest year on record. His reply was a perfect example of a classic defense mechanism identified by Sigmund Freud called psychological projection—where one projects a problem of their own onto others. We see this regularly in deniers who claim “alarmists” ignore or cherry-pick evidence and engage in ideologically driven groupthink, as well as in deniers who name their deceptive and misleading blog “NoTricksZone.”
In this case, it’s Dr. Soon implying that the World Meteorological Organization and anyone else who notes this year’s record heat is “prostituting science.” Which is interesting, considering all of Dr. Soon’s grants since 2002 have come from the fossil fuel industry! Together with Sallie Baliunas, Soon has received over $1 million from dirty energy interests since 2001, according to a number of documents uncovered by Greenpeace.
So here we have someone who’s taken literally hundreds of thousands of dollars from the American Petroleum Institute, ExxonMobil, Charles G. Koch Foundation and other fossil fuel interests with the express purpose of casting doubt on man’s influence on climate, saying independent scientists are “prostituting science.”
I think Freud may want a word with you, Dr. Soon. So have a seat on the couch, and tell us, how is your relationship with your mother?”
No surprise here that Climate Nexus kept the entire focus away from all scientific points made by Soon. Emotionally, it seems they never developed beyond puberty.
On the accusations of Dr. Soon being a “denier-for-hire”, we refer readers to the response Dr. Soon sent to the Guardian already years ago:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




I do not write papers because ExxonMobil or Greenpeace pays me to, but because my academic researches demonstrate that the sun, not carbon dioxide, is the chief driver of Arctic temperatures, and that much of the ‘evidence’ for the bears’ imminent demise is speculative. Indeed the population has increased fivefold since the 1950s, mainly because of restricted hunting. Where the Arctic has cooled, bears dwindle: where it has warmed, they increase.
Polar bears evolved from brown bears 200,000 years ago and therefore must have survived the last interglacial period, when global temperatures were many degrees warmer than the present. More perspective and less prejudice, please.
Willie Soon”
Well, let’s not look at the BILLIONS in funding the IPCC alarmists get. Or Phil Jones taking money from Saudi Arabia…or Stanford taking from Exxon-Mobil. Although the list is long and lavish, funding is the popular instrument used to distract audiences from the shite-quality science underpinning alarmist claims. Under the bottom line, the real issue is the integrity of the science and observations, and not who funds it.
And even though skeptics are out-funded by several orders of magnitude, the alarmists are still losing the scientific debate. Running and hiding, dodging debates in public, and refusing to disclose data and code also hardly convince the objective audience.
On the subject of Freud, if he were alive today, I suspect he’d be really interested in psychoanalyzing the frustrated end-of-world-obsessed alarmist who only can derive satisfaction from crystal ball quality catastrophe scenarios.
“Low grade” sites?
Freud might also be interested as to why Climate Nexus characterizes NTZ as a “low-grade” site. According to Alexa (15 Dec), Climate Nexus global ranking is: 1,532,673. NoTricksZone global ranking is 148,886. Sort of like the Queens Park Rangers calling West Ham United a low-grade team in the Premier League. Who’s projecting here?
And who sponsors who?
NoTricksZone: private citizen Pierre Gosselin.
Climate Nexus: Rockefeller Philanthropy Advisors.
Case closed.
 
Share this...FacebookTwitter "
"Leaders from all the main opposition parties have written to Boris Johnson urging him to take part in a televised debate on the climate crisis before the election. The Labour leader, Jeremy Corbyn, the SNP’s Nicola Sturgeon, Jo Swinson of the Liberal Democrats and the Green party’s Jonathan Bartley and Siân Berry argue that the public have a right to know what political leaders intend to do to avoid “the irreversible impacts of environmental breakdown”. “The climate and nature emergencies threaten everything we hold dear; the jobs we do, the health service we rely on, the houses we live in and the food that we grow and eat,” they wrote in the letter sent to Johnson on Tuesday. “The public are right to look to us, their politicians, for leadership. The ambition of our response must match the scale of the challenge.” The Conservatives, whose environmental record was condemned by leading climate scientists and former government advisers earlier this week, have failed to respond to questions from the Guardian regarding a climate debate. But a memo sent to the organisers of a public campaign for a climate debate said Johnson would not participate because he did not want environmental issues “siloed”. The idea of a televised climate debate has gained widespread support since it was launched by school strikers, students and pensioners’ groups earlier this month. More than 500 scientists – including Sir David King, a key government adviser on the climate crisis until 2017 – have backed the plan. In a statement, the experts said: “As scientists, we confirm that the youth movement’s concerns are well-founded and rest on highly robust scientific evidence. “Hence, we join their call for a political party leaders’ debate on climate and nature where candidates will outline and discuss their parties’ plans to tackle the climate and ecological crises.” In the past two weeks, the campaign has received support from more than 70 organisations with a total membership of more than 10 million, including the Women’s Institute, the National Trust and the National Education Union. And more than 188,000 people have signed a petition supporting the campaign being run by climate charity Possible. Max Wakefield, the director of Possible, said the poll in December must be the UK’s “first climate election”. “It’s time for all parties to recognise this is the fight of our lives, and debate how to go about the urgent changes we must make to win it.” The climate emergency has been forced up the political agenda in the past year as growing evidence of the crisis – from floods to wildfires, record temperatures to melting ice – has become impossible to ignore. In the UK, hundreds of thousands of schoolchildren have taken to the streets to demand action and Extinction Rebellion protests have brought large parts of London to a standstill. Anna Taylor, the co-founder of UK Student Climate Network, which helped organise the school strikes, said: “Young people now want to hear leaders’ plans to return our futures to us, because that is precisely what is at stake.”"
"Bumblebee queens are a common sight on a spring day, their large furry bodies flying industriously from flower to flower. At this point they will have just awoken from a long hibernation – the much smaller worker bees die off each year, leaving the new queens to survive winter alone. Eating nectar and pollen from these flowers is therefore essential for the queens to build up their energy and fat stores. Once they are fully restored, which can happen within a few days, the queens will look for a nest-site, perhaps an abandoned mouse nest, where they will build up a honey pot and pollen stores prior to laying eggs and founding a new colony of bumblebees.  While this all sounds fairly easy – how hard is it to find flowers in the spring, after all? – the colony-founding stage is actually the most stressful part of the bumblebee lifecycle. Bad weather, starvation, and predators like great tits mean the queens often fail to make it through the winter. The last thing they need is another challenge. But recently, a new potential threat to bumblebee queens has appeared. Neonicotinoids are a class of insecticides that are used on agricultural crops and in gardens to control insect pests. Unfortunately, as well as controlling insect pests, numerous studies have shown that they can also damage beneficial insects like bumblebees. This is because neonicotinoids get into the nectar and pollen of both the crops and the wildflowers that grow nearby, and so into the food of bees.  The European Union imposed a moratorium on their use in crops attractive to bees back in 2013, and similar restrictions are being considered by nations around the globe. During this moratorium, scientists are trying to find out how neonicotinoids affect bees, so we can make evidence-based decisions about their use.  Given the importance of queens and the colony-founding stage in bumblebees, colleagues and I decided to investigate whether exposing queens to neonicotinoids would lead to a reduction in egg-laying and subsequent colony founding. Our results have just been published in Nature Ecology & Evolution. Gemma Baron, the PhD student who led this work, first gathered evidence that bumblebee queens were collecting nectar and pollen from both oil-seed rape – a major neonicotinoid crop and one very attractive to bees – and from wildflowers growing nearby. This meant queens could be consuming these insecticides in the wild. However, to determine the impact of such exposure, we had to turn to the laboratory and the computer.  After mating hundreds of queens in the lab, she then put them through an artificial hibernation in a fridge, before placing them in a special bumblebee rearing room. Half of these queens were given a neonicotinoid, thiamethoxam, in nectar at concentrations and quantities they could experience if foraging in and around crops treated with the chemical. The other half were given uncontaminated nectar. Both groups were given as much pollen as they wanted.  Egg-laying by these queens was then recorded over a ten-week period. It turns out that exposure to thiamethoxam made queens 26% less likely to lay eggs, and therefore to found a colony. This seems like a big impact, but what would it actually mean in the real world? Doing experiments with bumblebee queens in the wild is basically impossible. They can fly for kilometres, and frequently abandon artificial nests if allowed to forage freely. So to understand how our lab results might relate to bumblebee populations in the natural world, we turned to mathematical modelling.  Taking advantage of what is known about the dynamics of bumblebee populations in the wild, we factored in the impact of the neonicotinoids we had identified in the laboratory. We found that if bumblebee queens fed on nectar contaminated with thiamethoxam this could increase the probability of their population going extinct by at least 28%.  What does all this matter? Bees are essential pollinators of both crops and wildflowers, and bumblebees provide nearly half of all pollination in northern temperate regions like the UK. Given that their populations are already falling, we need to understand why they are declining in order to maintain and increase their numbers.  Our results suggest that exposure to neonicotinoid insecticides could have dramatic impacts on bumblebee queens, leading to fewer bumblebee colonies, less pollination, and ultimately population extinctions. Studies like this provide the evidence that policy-makers need if we are to develop sustainable agricultural systems that provide the food we need without harming the bees we rely on, not just for pollination but for that iconic buzzing on a summer’s day."
"
Share this...FacebookTwitterThe Germany-based European Institute for Climate and Energy (EIKE) held another conference on climate and renewable energy last March. One of the speakers was Prof. Dr. Dieter Ameling, an expert in heavy industry. EIKE has posted his presentation. 

In the presentation Ameling calls Germany’s Energiewende (transition to renewable energies) a real threat to industry, warning that the country faces a de-industrialization.
Already, Ameling reminds us, every day the Energiewende in Germany is progressing and that the damage already done is getting even worse and that “foremost it will soon be irreparable“.
Subsidies’ vast divergence from earlier projections
At the 5:15 mark he calls the German government’s 2022 targets for renewables “economic nonsense” and will result in “electricity getting continuously more expensive“.
His following chart shows a comparison of the German government’s projected green energy subsidies compared to that of reality:

The gray bars show the government’s projected annual subsidies in billions of euros. The blue bars depict the real skyrocketing subsidies. In 2014 the subsidies rose even further, to 23.6 billion euros. Chart: Dr. Dieter Ameling.
“Unaffordable” and “absolute imbecility”
The big problem, Ameling emphasizes, is the huge supply-volatility in wind and sun, which are totally weather-dependent. At the 9:35 mark the retired professor calls the German state of Bavaria’s energy-mix plan for 2022 as something that “cannot function“…”is unaffordable“, and “is absolute imbecility“. 
The chart at the 11:20 mark shows how Germany has one of the highest electricity prices worldwide, more than double the rate found in USA, Canada, or Russia. 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




At the 13-minute mark another chart shows the huge gap in natural gas prices between Germany (10.7 cents per gas unit) and the USA (only 3.7 cents per gas unit). Thanks to fracking, gas prices in USA have tumbled while in Germany poor households barely can afford to heat their homes.
Germany’s skyrocketing electricity prices
At the 13:34 mark Ameling displays a chart showing Germany’s electricity price development:

Since 2000 the price of electricity in euro-cents/kwh in Germany has more than doubled! Currently a 4-person household is paying over 366 euros a year just for the green energy feed-in tariffs alone. Ameling warns that figure will continue to rise rapidly.
Exodus of industry leaving Germany, Europe
Later in the presentation Ameling shows how the energy-intensive industries such as cement, glass, steel, chemicals etc. are being hit hard by the skyrocketing energy costs. In Germany alone 3.5 million jobs depend on the steel industry. At the 19:03 mark Ameling warns that the exodus of industry “has already begun” with heavyweight companies such as ThyssenKrupp, Norsk Hydro, BASF, SGL Carbon and Voest moving operations abroad.
1 trillion euros!
How much is Germany’s Energiewende projected to cost? In 2013 former Environment Minister Peter Altmaier told the Frankfurter Allgemeine Zeitung it would cost Germans 1 trillion euros!

At the end Ameling summarizes, announcing that the “Energiewende has failed” because it is simply too expensive and too volatile. The infrastructure that is needed to handle it is not even in place. Unless Germany radically alters the current direction of its Energiewende, Ameling says it will be “bye bye Germany“.
He ends the presentation with the following Friends of Science image, reminding us that CO2 is not even the driver of climate.

Share this...FacebookTwitter "
"Labour has softened its pledge to find a path to net zero carbon emissions by 2030 after unions pushed for a target of significant progress rather than a firm commitment. The party’s autumn conference had passed a motion setting 2030 as the target for net zero emissions, but trade unions raised concerns about the risk to jobs and industry.  Rebecca Long-Bailey, the shadow business secretary, insisted on Monday that the party would remain on the “pathway” towards net zero emissions by 2030, in line with the conference motion. However, sources present at Saturday’s clause V meeting finalising the party’s manifesto said the GMB trade union and some other union representatives had pushed for softer wording, aiming for progress rather than completion. One source said the aim in the manifesto would be for a “significant majority” of carbon emissions to be eradicated by 2030. Labour for a Green New Deal, which brought the motion, said it was happy with Long-Bailey’s pledge of a pathway towards net zero by 2030 and confident that the leadership was supportive of strong action on the climate crisis. The GMB had pushed back firmly against a firm target of 2030, fearing it could lead to mass job losses. Tim Roache, GMB’s general secretary, had previously warned: “The proposal to do it by 2030 threatens whole communities, threatens jobs, and frankly GMB members in communities right up and down the UK have heard it all before. “This will mean within a decade people’s petrol cars being confiscated. This will mean families can only take one flight every five years. Net zero carbon emissions by 2030 is utterly unachievable.” Environmental campaigners had been alarmed on Monday by Barry Gardiner, the shadow international trade, energy and climate change secretary, saying on the BBC that Labour’s target was still net zero “well before 2050”. But they were mollified by Long-Bailey’s tweets saying: “Ours will be the most radical manifesto ever written, especially on climate. “We are a constitutional democratic party with its roots in the labour movement. Energy workers are understandably fearful and distrusting about the transition because they have been abandoned through past industrial transitions. “We will only succeed by working with those workers and communities to develop a credible industrial strategy that ensures they will not be left behind by the transition. “Our manifesto will set out a pathway towards net zero by 2030. I look forward to setting out these plans in more detail over this campaign.” A spokesman for Labour for a Green New Deal said it was “great to see Rebecca Long-Bailey restate Labour’s commitment to forging a pathway to net zero 2030”. He added: “From housing to electricity to transport, Labour has laid out radical plans to decarbonise our economy by 2030 and transform it for the many.” Labour’s green industrial revolution agenda remains one of the most ambitious climate policy platforms of any mainstream party in Europe. To get close to net zero by 2030 will require a huge transformation of the economy and energy supply systems – although its advocates say it would also boost the economy by hundreds of billions of pounds a year. The 2030 pledge is just one of many areas where party conference motions are likely to be softened for the election manifesto. An ambition to “maintain and expand free movement” will translate into a compromise immigration policy, that acknowledges the rules could change if Brexit goes ahead. And the radical conference motion suggesting assets of private schools could be seized is more likely to take the form of saying tax loopholes should be closed for them. Teacher and campaigner Holly Rigby, who runs the Labour Against Private Schools group which led the motion, said they had met with McDonnell just two weeks ago and asked for their private school reforms to be included in the party’s manifesto. She said: “We had a really positive meeting in the lead up to clause V. We were really happy with how the meeting went and we felt we were listened to and I feel reassured personally that what happened at conference will be turned into action. “We have always said that the most important thing is that private schools and inequality is wrong and we want the Labour party to take some action on this, and that it goes further than in 2017.” The motion passed at conference was to include in the manifesto a commitment to integrate all private schools into the state sector by withdrawing charitable status and all other public subsidies and tax privileges, including business rate exemption. It also called for the endowments, investments and properties held by private schools to be redistributed democratically and fairly across the country’s educational institutions. Rigby said no matter what the final wording of the manifesto, the issue was now at the heart of the political consciousness of the party and had cut through to voters across the country. She said: “The most important thing is we raise the issue in wider society and that this inequality is unjust and we have started that conversation in a way that hasn’t existed before. “It’s in people’s minds now and it’s up to the Labour party to decide how to move forward and make sure that inequality is challenged.” "
"Every year, the NEC in Birmingham, England, becomes a magnet for dog lovers, as more than 22,000 canines assemble for Crufts. Founded by travelling dog-food salesman Charles Cruft in 1891, Crufts has become one of the world’s largest and most prestigious dog events. Here, you can meet dogs of every shape and size, see inspiring human-dog partnerships and shop for all things dog-related. There’s always a fascinating mix of people in attendance – and this year, I get to be among them.  So what is it about Crufts I find so enthralling? Well, far from being a beauty pageant for pampered pooches, these days Crufts is a celebration of all things canine – and for a self-confessed “dog person” like me, that’s an exciting prospect. But more importantly, Crufts challenges me to reflect on the bond between humans and dogs from a scientific perspective.  There is no doubt that humans and dogs have a prolonged evolutionary relationship. Since dogs were first domesticated, humans have selectively bred them to bring out particular physical and behavioural characteristics. Selective breeding has resulted in the wide diversity of about 400 pedigree dog breeds recognised today, from the diminutive Chihuahua to the Great Dane. But sadly, many pedigree dog breeds suffer from defects and diseases, which affect their welfare and longevity – these are often a consequence of inbreeding.  Yet it seems that science is coming to the rescue of our doggy companions. Recent research has shown that rates of inbreeding in many pedigree dogs are actually declining from a high in the 1980s and 1990s. This suggests that dog breeders are becoming better informed, and improving their practices. For example, genetic tests are now used by many dog breeders, to ensure that breeding animals are genetically healthy.  Crufts provides an ideal place to educate and inform dog owners, breeders and puppy hunters about the value of such health tests.  Increasing our awareness of issues associated with all dog breeds – including “designer” cross-breeds such as cockapoos and labradoodles – can only improve quality of life for both dog and owner.    The deep bond between people and their dogs is also demonstrated in a wide range of canine activities at Crufts: from the frenetic relay races of flyball, to the precise movements of dog and handler in obedience. These activities offer a physical and mental challenge for dogs and owners alike. And with rising levels of canine obesity mirroring that of the human population, strategies to improve physical activity levels for both species will be of significant mutual benefit.  Crufts offers a great platform to promote schemes such as “Get Fit with Fido” – a weight loss competition run by the Kennel Club. Research suggests that many pet dogs aren’t walked daily, so showcasing mutually enjoyable physical activities, such as agility training, might just encourage some dog owners to get a little more active with their pets. The activities at Crufts can help us to understand the science behind what makes a good canine athlete: from gundogs, to “dancing” dogs in the canine freestyle event, to world-class agility dogs. In fact, canine performance science is a rapidly growing area of interest, encompassing genetic selection, puppy rearing, training, housing, handling and health for working dogs. Crufts visitors will see many dogs trained using methods which have been improved by new insights into canine learning – a simple way that science has contributed to canine welfare.   Yet this relationship goes both ways: in fact, dogs can be credited with providing many human health benefits, beyond the customary “walkies”.  Dog owners report higher levels of perceived health than non-dog owners, and were found to have more vitality, and better social lives and mental health. One famous study even suggested that dog owners lived longer after a heart attack than non-dog owners. Whether this is a genuine effect of pet ownership, or a sign that people who own pets tend to have a particular personality type, has not been established – but it remains an area of fascination for those interested in the human-dog relationship.  Of course, assistance dogs such as guide dogs, hearing dogs and mobility dogs are essential companions and lifesavers. What’s more, anecdotal reports of dogs signalling to their owners the onset of diabetic hypoglycaemic attacks or epileptic fits have been confirmed by scientific study. So-called “therapy pets” play a valuable role in homes, hospices and hospitals, making patients happier and acting as non-judgemental confidants. Some dogs have even been trained to detect prostate cancer, putting a whole new spin on the “lab test”.  Many organisations involved in the training of these dogs are represented at Crufts, and the “Friends for Life” award recognises their exceptional bravery, support and companionship. There is no doubt about it: we humans share a special connection with our canine companions. And Crufts is the perfect place to celebrate it."
"Walking the galleries of a natural history museum, you might be left with the impression that not all animals were created equally. (Of course, if you study the displays about evolution, they’ll tell you that they weren’t created at all.) There is a noticeable bias in what kinds of animals museums choose to display: on the whole, the huge, exotic, rare and extraordinary get more than their fair share of shelf-space. As a result, natural history museum galleries are not accurate reflections of the nature they might be thought to represent. Around 80% of described species are arthropods – the group that contains insects, crustaceans and arachnids; and around 80% of living individual animals are nematode worms. As is commonly argued by specialists in these fields, these ecologically and numerically dominant groups are not given the attention they statistically deserve. But there is another group that is also regularly banished from most museums: those more mundane animals that feature heavily in our everyday lives, as pets, livestock and scientific subjects. They are not deemed special enough. Do people want to go to a museum to see animals that we can find on our plates, on our laps and on our streets? It is thought that we would rather see dinosaurs, dodos and giant whales. So these animals are rarely represented in natural history museum displays. That is why we at UCL’s Grant Museum of Zoology have dedicated an exhibition to these somewhat sidelined creatures – to give them a chance to tell their stories. By staging this exhibition, which we have called The Museum of Ordinary Animals, we want to highlight the boring beasts that have changed the world, including dogs, rats, cats, cows, chickens and mice.  Ordinary animals are everywhere, and the ways they interact with our lives are endless and varied. We have invited them into our homes as pets; their role in our diets has changed us biologically; they are critical to modern medicine and they hold huge symbolic value in many cultures. These animals have had profound impacts on humanity and the natural world, and we have learned extraordinary things from them. While (most) natural history museums are dedicated to communicating that the species on display are a product of evolution, many of these ordinary animals were in fact created: they have come into existence through unnatural means. Humans have been domesticating animals ever since dogs were formed from wolves, though the process was often not deliberate. Other domestic species were deliberately brought into being, at least to some extent. The breeding of livestock such as cattle, goats and sheep would ease the growing human population’s problem of the over-hunting of wild animals. Others still, such as domestic hamsters, were only created in recent decades, to fill human scientific and aesthetic desires (they were intended as lab animals before they became pets). So is their “unnaturalness” the reason why ordinary animals have largely been removed from natural history museums? The concept of some animals being outside the boundaries of “nature” is an interesting one (it’s worth saying that some people argue that humans are a natural species, and therefore everything we do is “natural”, but I think that’s a dead end, as it renders the already abstract concept of nature meaningless). The natural history of these species is not the same as the rest of the animal kingdom’s. We can think of them more in the context of social history, as their stories are so utterly intertwined with our own. Studying chickens, for example, allows the worlds of evolution, archaeology, genetics and theology to interweave. UCL geneticist Mark Thomas, who contributed to the exhibition, tells us that around 1,000 years ago, there was massive evolutionary pressure for domestic chickens to be able to lay eggs all year round and to be less aggressive (allowing for the confinement of many individuals in a small space). At the same time, chicken bones become significantly more common in the archaeological record, showing that people were eating more of them. Remarkably, this coincides with a decree from Benedictine monks to avoid eating four-legged animals on fast days. Birds and eggs were exempt. Although chickens were first domesticated around 6,000 years ago, the features that essentially led to the chickens we know today (including battery hens), were arguably brought about by a religious diktat. Among the most ubiquitous of ordinary animals is the house mouse, originally from India. We have a collection of around 9,000 house mouse skeletons in the Grant Museum, collected from islands around the world: humans have given them near global distribution. The skeletons are the result of a study into the effects of island living on evolution. Museum storerooms are full of such objects: but they are intended for research, not display. When we visit museums we have the chance to see that evolution has produced some extraordinary species and mind-blowing diversity: it is these exotic and glamorous animals that we tend to find on display. But it’s important to remember that the more ordinary species - which are often the product of human intervention as much as evolution – also have incredible stories to tell us. The Museum of Ordinary Animals runs until December 22 at the Grant Museum of Zoology, UCL, London."
"We live in a world drowning in objects: households with a television in each room; kitchen cupboards stuffed with waffle makers, blenders and cappuccino whisks; drawers filled to bursting with pocket-sized devices powered by batteries – batteries which themselves take a thousand times more energy to make than they will ever provide.  Just over a century ago, “disposability” referred to small, low-cost products such as disposable razors and paper napkins. Today, practically everything is disposable – it is culturally permissible to throw away anything from a barely-used smartphone, television, or vacuum cleaner, to an entire three-piece suite or fitted bathroom. This has led to the serious problem of electronic waste. In the European Union, mountains of scrapped circuit boards and other computer junk are growing three times faster thank any other type of waste in the EU. We generate 40 tonnes of waste in the process of manufacturing just one tonne of electronic products – yet 98% of these products are discarded within just six months of purchase. Given the huge quantities of precious resources (including gold and other rare metals) that find their way into our gadgets, it would surely be worth us taking more care of them, repairing them when broken, and keeping them for longer. In fact, the opposite is happening: product lifespans are shortening as material culture becomes increasingly disposable.  The notion of a “throwaway society” is nothing new. American economist Bernard London first introduced the term “planned obsolescence” in 1932 as a means to stimulate spending among the few consumers who had disposable income during the depression. The concept was popularised by Vance Packard in his The Waste Makers in 1964. In fact, the concept of disposability was a necessary condition for America’s cultural rejection of tradition and acceptance of change. There is a different approach, however – one of emotionally durable design, which can help us to reduce the consumption and waste of resources by building a more lasting relationship between us and the products we buy. Simply put, it helps us design products that are built to last longer, and provide a longer-term experience.  The term “emotional” is used here because wasteful patterns of consumption and waste are driven, in large part, by emotional and experiential factors. We tire of things, novelty wears off all too quickly and we fall out of love with them, so to speak. Considering emotional durability at the design stage helps us to wean people off their desire for the new, and can shape new and sustainable business models. Here, longer-lasting products have the potential to build economic models around creating robust products, upgrade and repair services, and brand-loyal customers – all without excessive waste.  In design terms, we can support greater levels of emotional longevity when we specify materials that age gracefully, and that develop quality over time. We can design products that are easier to repair, upgrade and maintain throughout their lifespan. These are effective product life extension strategies, and while they can come at an increased cost at point of purchase, they generate revenue downstream, through the introduction of service and upgrade packages. Extending the life of a product has significant ecological benefits. For example, take a toaster that lasts about 12 months. Even if the toaster’s life is extended to just 18 months through more durable design, the extra longevity would lead to a 50% reduction in the waste consumption associated with manufacturing and distributing it. Scale this up to a national or international population of toaster-buyers, and it’s clear how significant an impact this could be. There is a growing sense that the consumer electronics industry must transition from a linear economy to a circular one. A circular economy is one in which resources are kept in use for as long as possible. The maximum value is extracted from them, while materials and energy are recovered or recycled as much as possible at the end of any product’s life. This is a seismic shift in thinking, affecting everything from the design and delivery of short-life products, to that of longer-lasting material experiences.  Simply having more stuff stopped making people in Britain happier decades ago. The New Economics Foundation (NEF) argues for an economy of better, not more. One in which things age gracefully, where they last and can be repaired many times before being recycled, allowing us to share better the surplus of stuff we already have. Designing products that can be kept for longer nurtures a deeper relationship with both the product and the brand, which increases the likelihood of brand loyalty maturing.  Such emotionally durable design doesn’t just make sense from an environmental and resources perspective, but can be seen as a commercially viable business strategy in an increasingly competitive globalised world."
"Ursula von der Leyen has said the EU as the world’s “trading superpower” will lead the fight against the “existential threat” from the climate crisis, and offered a waspish farewell to the Brexit party, as MEPs backed her new European commission to start work on 1 December. The European parliament, sitting in Strasbourg, approved the new college of commissioners, headed by the EU executive’s first female president, by 461 votes to 157 with 89 abstentions on Wednesday, giving her a larger majority than her predecessor, Jean-Claude Juncker.  Von der Leyen said the level of support she had secured, while less than that for José Manuel Barroso in 2004 and 2010, was a vote of confidence in what she described as an “agenda for change”. The Green party, which has been unconvinced by the radicalism of Von der Leyen’s approach, abstained in the vote and anti-EU parties including Italy’s far-right League and France’s National Rally rejected the proposed commission. The commission, which will be formally approved by leaders on the European council on Thursday through a written procedure, is forming a month later than intended as a result of MEPs rejecting the original nominees from Hungary, France and Romania. Von der Leyen’s hour-long speech to MEPs lacked the ad-libbing of Juncker, who was never shy of causing controversy, and offered few eye-grabbing policy initiatives. But when Brexit party MEPs clapped and cheered at the mention of Brexit, the incoming commission president strayed from her notes. “A vast majority of this house seems to be happy about the fact a very, very, very small group in this house would not be able to clap as loud any more,” Von der Leyen said. “And I have never, ever made any secret about that fact that I will always be a remainer.” She added: “We will respect the decision taken by the British people. We will work closely together on solutions to common challenges, especially security matters. But one thing has to be absolutely clear: whatever the future holds, the bond and the friendship between our people are unbreakable.” Von der Leyen repeatedly emphasised that her top priority upon taking office this Sunday was dealing with the climate emergency and ensuring the end of carbon emissions by the middle of the century. The commission is set to unveil its “green deal” on 11 December. She said: “This is an existential issue for Europe – and for the world. How can it not be existential when 85% of people in extreme poverty live in the 20 countries most vulnerable to climate change? How can it not be existential when we see Venice under water, Portugal’s forests on fire or Lithuania’s harvests cut by half because of droughts? This has happened before but never with the same frequency or intensity.” Von der Leyen said the commission would look to robotics to move people out of occupations that she suggested should no longer be carried out by people. She said: “We will automate work that is wearisome for us humans: carrying heavy loads, performing repetitive tasks in factories or in offices. And this will give us time. Time for what distinguishes human beings. Time for what computers can’t do: empathy and creativity.” Von der Leyen said she wanted the commission to be “geopolitical”. “We can be the shapers of a better global order”, she said. She made a thinly veiled reference to the policies of Donald Trump in a section of the speech criticising those who sought confrontation and unilateralism. Of the transatlantic relationship, she said: “Yes, we have issues – without any doubt. But our ties have lasted the test of time. While we are speaking, thousands of students, researchers, entrepreneurs, artists continue to build zillions of friendships, business contacts and science projects. These myriad of fine threads woven together make a bond that is stronger than any individual point of discord.” On a personal note, Von der Leyen – who was born in Germany and spent much of her childhood in Brussels where her father was an official – said her commission would seek to lead in the fight against cancer across the EU. “When I was a girl, living in Brussels, my little sister died of cancer at the age of 11,” she said. “I remember the utter sense of helplessness of my parents, but also of the medical staff who looked after her with such care. Every one of us has a similar story or knows someone who has. The number of cancer cases is rising but we are getting better at diagnosis and treatment. Europe will take the lead in the fight against cancer.” Phil Hogan – trade Known in Ireland as Big Phil, Hogan will oversee the post-Brexit trade talks. This is his second term in the commission. As agriculture commissioner he was given the nickname Farmer Phil by the European commission president, Jean-Claude Juncker. Hogan has not shied away from intervening in the Brexit debate: at one point he warned people to ignore the views of the “three stooges” – Boris Johnson, Nigel Farage and Jacob Rees-Mogg. Věra Jourová – values and transparency In 2006, Jourová spent a month in a Czech jail on false corruption charges. Now she will oversee the sensitive issue of democratic backsliding. Hungary and Poland have been accused of undermining the independence of their judiciaries in recent years. Ursula von der Leyen has suggested she will look to link member states’ record on the rule of law with EU funding. Virginijus Sinkevičius – environment and the oceans At 29, Lithuanian Sinkevičius is the youngest ever EU commissioner and the first to be born after the fall of the Berlin wall. He graduated in 2012 with a degree in economics and international relations from Aberystwyth University and has studied courses at the universities of Maastricht and Oxford. He became an economics minister in the Lithuanian government at the age of 27. Thierry Breton – internal market A former chairman and chief executive of the IT firm Atos and one-time finance minister under Jacques Chirac, Breton was chosen for this big portfolio by the French president, Emmanuel Macron, after MEPs rejected France’s first choice, Sylvie Goulard. She had been accused of using a European parliament assistant for domestic political work when she was an MEP. Breton doubled Atos’s revenues between 2008 and 2019 to around €12.3bn by moving into cloud computing and big data. Ylva Johansson – migration, asylum and internal security Migration remains one of the biggest challenges for the EU, with criticism growing about the bloc’s funding of the Libyan coastguard and the deplorable conditions in which migrants are detained by the authorities in Libya. Johansson, a former minister in the Swedish government, has said she wants a new pact among the member states on migration and an overhaul of asylum rules. But she admitted to MEPs during hearings that there would not be any new proposals during her first 100 days in office."
"
Share this...FacebookTwitterIt’s a good thing Germany still has a lot of conventional power supply from coal and nuclear on line. Otherwise the entire country would have blacked out this morning during the partial eclipse of the sun. Conventional fuel saved the day.
As the following diagram depicts, there was almost no wind output from Germany’s 40 or so gigawatts of installed wind capacity over the last 36 hours. The country’s wind turbines called it an early weekend.

Wind energy (blue) has virtually disappeared over the last 36 hours. Solar disappears every night, and often during the day in the wintertime. Often less than 1% of Germany’s electrical demand gets supplied by wind and sun. Source: agora.
German wind and solar power disappeared this morning and over the last 36 hours, leaving fossil and nuclear power to step in to the rescue. The following chart of Germany’s energy supply and demand shows how wind has gone AWOL already 11 times since January 1:

Since January 1, Wind power failed to show up some 11 times. On average about 85% of the installed capacity doesn’t show up to begin with. Charts cropped from agora.
The point here is that it doesn’t matter how much wind and solar capacity gets installed. Once the wind stops blowing and the sun does’t shine, which is often enough, you get no power – period. Imagine if a doctor sold you an artificial heart that could run for 100 years, yet the heart pumped only sporadically, sometimes at only a beat or two a minute over for hours or even days. So it is with wind and solar energy. Our society needs a steady and constant supply; it can’t afford to constatntly stall and sputter, otherwise it collapses and dies.
Today’s partial eclipse had little impact
Today’s partial eclipse of the sun did not strain Germany’s power grid as much as feared. Fog and cloudy weather over northern Germany helped to dampen the feared fluctuation. Sunny day projections of 12,000 megawatts of power going offline in just an hour followed by 19,000 megawatts surging online in an hour warned that the grid could be destabilized. Here’s what the sunny-day scenario solar feed-in looked like:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Sunny day solar power feed in into grid during eclipse. Source: cropped form here. Animation by: pvspeicher.htw-berlin.de.
What actually happened was nowhere near as bad as feared:

Fluctuation was far less than feared. Source: SMA.
As the sun’s energy disappeared, conventional fuels saved the day.
What follows is a photo I took outside near peak time of the partial eclipse in northwest Germany, where it was overcast:

 10:45 this morning. Looks like a typical dreary day in north Germany.
In general, power companies and grid operators had months to prepare for the eclipse. Lapses and wild fluctuations in wind and sun energy are common (see above) and so today’s eclipse was manageable though with considerable effort. Power companies asked large consumers such as aluminum smelters, cement plants and glass manufacturers to ramp down their production before the event. That would not have been necessary with conventional power.
 
Share this...FacebookTwitter "
"To predict what type of Earth lies ahead of us, we scientists usually turn to complex computer simulations. But how can we test whether these models are remotely accurate? Perhaps the best solution is to turn to instances in the geological past when Earth’s climate experienced similarly rapid warming. One such event is the Palaeocene-Eocene Thermal Maximum (PETM) that occurred 56m years ago. In our latest research, we have identified the cause of this well-known warm period. Its links to present day climate change are clear. Just prior to the PETM, Earth looked very different than it does today. The polar regions were devoid of ice sheets, with temperate or even subtropical forests along the coastlines of Antarctica, and Arctic Canada resembling the swamplands of modern Florida. The deep oceans were about 10°C warmer than today, and warm climate zones were all shifted polewards. Against the background of this “greenhouse world”, the planet warmed by at least a further 5°C over a few thousand years at the onset of the PETM. Life in the deep sea suffered disproportionately; many species went extinct and parts of the deep ocean became anoxic (oxygen depleted). On land, the water cycle strengthened, leading to both floods and droughts. It took about 150,000 years for Earth’s climate to naturally recover from this “fever” and regain some sort of equilibrium. Here’s the really worrying part: 5°C over a few thousand years is breakneck speed in geological terms, but is still nothing compared to our current rate of warming. In fact, if we keep burning fossil fuels at our current rate, the worst-case scenarios suggest we could hit 5°C by the end of the century. So what can the PETM tells us about the future? It has long been suspected that the warm period was triggered by increasing greenhouse gas concentrations in the atmosphere. These gases absorb and trap solar heat, which is why any significant increase unavoidably leads to global warming.   We know there was a huge release of “new” carbon into the atmosphere and oceans at the time, thanks to analysis of 56m-year-old sediments. Yet where this carbon came from has always been disputed. Carbon can be emitted as carbon dioxide or methane (aka CH₄) and both are greenhouse gases. Some say the PETM carbon was methane from marine sediments, while others have advocated methane from thawing Antarctic permafrost or the impact of a large comet releasing carbon from rocks. In our study recently published in Nature, we identified the distinctive chemical fingerprint of this carbon – it pointed not to methane, but to emissions from intense and prolonged volcanic activity. We also show that atmospheric CO₂ levels more than doubled in less than 25,000 years.  This makes sense: at the same time, Greenland and North America were drifting away from Europe, creating the North Atlantic Ocean and a string of volcanic activity along what is now the Mid-Atlantic Ridge. We found more than 10,000 Gigatonnes of carbon must have been released into the atmosphere by volcanic activity during the PETM, which is an order of magnitude higher than all currently-accessible fossil fuel reserves taken together.  But the rate of emissions would have been at least 20 times slower than today. Given how much CO₂ was released, the resulting global warming was about what we would predict based on calculations of current climate sensitivity.  So what would volcanoes large enough to affect the climate like this actually look like, in practice? We could imagine a series of sky-blackening eruptions along the lines of Laki in Iceland which caused temperatures to drop across the Northern Hemisphere when it erupted in the 18th century. But, given we know the PETM volcanism largely took place under water and at a slower pace, perhaps the best modern equivalent would be the “black smokers” still found today in the deep North Atlantic – but lots of them. The carbon released by these vents would bubble up to the surface and kick off a cycle that would eventually affect the oceans themselves. First, extreme PETM warmth led to faster weathering of rocks and soil, which meant more nutrients like phosphorus were being washed into the sea. This in turn stimulated plankton growth. When the plankton died they drifted down to the seafloor and gradually stored that same carbon in deep marine sediments.  While this chain of events aided the removal of carbon from the ancient atmosphere it also led to oxygen starvation in some parts of the deep sea – analogous to the “dead zones” that form today in areas like the Gulf of Mexico where an excess of nutrients is washed into warm water. We found the PETM was caused by massive carbon emissions from Earth’s interior. It thus has many parallels to today, where we are ratcheting up CO₂ levels in our atmosphere and oceans by burning fossil fuels that have been buried for millions of years. This extra carbon is, in effect, permanent on human timescales. The PETM is giving us an increasingly clearer picture of what Earth will be like if we carry on, and take our planet to places it has not been in at least 56m years."
"Last week Coldplay announced they were to stop touring until they were sure it would be carbon neutral; now Massive Attack are partnering with academics to map the carbon footprint of the music industry. The researchers from Manchester University’s Tyndall Centre for Climate Change Research will analyse data from Massive Attack’s touring and recording schedule to look at three key areas where CO2 emissions are generated: band travel and production, audience transport and venue.  The aim is to provide information and guidance to the wider music industry so that it can reduce its negative environmental impact in light of the increasing climate emergency. “In an emergency context, business as usual – regardless of its nature, high profile or popularity – is unacceptable,” wrote Robert Del Naja, AKA 3D, Massive Attack’s vocalist, in an article for the Guardian, explaining the collaboration. He said the band had tried carbon offsetting for almost 20 years, paying to have trees planted, prohibiting the use of single-use plastics and travelling by train wherever feasible. But they had come to the conclusion that “offsetting creates an illusion that high-carbon activities enjoyed by wealthier individuals can continue, by transferring the burden of action and sacrifice to others – generally those in the poorer nations in the southern hemisphere”. Del Naja said the band did not want to stop playing big shows or festivals, but that huge change was essential for the planet’s future. “Given the current polarised social atmosphere, uplifting and unifying cultural events are arguably more important now than ever, and no one would want to see them postponed or even cancelled. The challenge therefore is to avoid more pledges, promises and greenwashing headlines and instead embrace seismic change,” he wrote. Dr Chris Jones, a research fellow at Tyndall Manchester, said: “We will be working with Massive Attack to look at sources of carbon emissions from a band’s touring schedule. Every industry has varying degrees of carbon impact to address and we need partnerships like this one to look at reducing carbon emissions across the board. “It’s more effective to have a sustained process of emissions reductions across the sector than for individual artists to quit live performances. It will likely mean a major shift in how things are done now, involving not just the band but the rest of the business and the audience.” The collaboration will produce a framework based on data gathered from Massive Attack’s forthcoming tour. This year, Glastonbury festival banned single-use plastic, and an increasing number of artists are taking steps to reduce their environmental footprint. In an interview with BBC News last week, Coldplay’s frontman, Chris Martin, said the group were waiting to tour their new album, Everyday Life, so they could ensure such a tour was carbon neutral. “Our next tour will be the best possible version of a tour like that environmentally,” said Martin. “We would be disappointed if it’s not carbon neutral. We’ve done a lot of big tours at this point. How do we turn it around so it’s not so much taking as giving?” The solo artist Billie Eilish’s next tour, in March, will feature the “Billie Eilish eco-village”, where fans can learn about their role in the climate crisis. Those who pledge to fight the climate emergency with the organisation Global Citizen can earn free tickets to the sold-out shows. The 1975 are working towards making their tours carbon-efficient and have pledged to plant a tree for every ticket sold for their UK arena tour in February. The British band have also stopped producing new T-shirts, instead screen-printing a new design over old merchandise stock."
"
Share this...FacebookTwitterAfter the European heat wave of last week, the pendulum has swung to the other extreme.
Currently the weather pattern dominating Central Europe is bringing unusually cold air over the continent, and early this morning regions in a number of countries were hit by ground surface frost.
Parts of Belgium, Luxemburg, Germany, Switzerland, Austria and the Czech Republic saw surface frost – even down to the lower elevations (Belgium is hardly a mountainous region).
German site Wetter24 twittered here a map depicting the frosty areas gripping this 10th of July, 2015. Also see map here.
Swiss meteorologist Jörg Kachelmann here writes and supplies a link showing a German video reporting conditions that the German Eifel region woke up to early this morning. At the 1:50 mark the video reports:
We saw fields that were snow-white. That on the tenth of July I have never seen before. My colleague Fabian had also never seen this before. It just looked wonderful. We just thought that indeed we are not in autumn or spring; we are actually in July. These pictures impressed us, and that we found this frost.”
Apparently the “greenhouse effect” of atmospheric CO2 was unable to trap the heat and prevent frost from forming at ground level.
Yesterday Aonach Mor and Strathallan in Scotland saw frost. So did Blackpool and Exeter in England!
Central Europe and Great Britain were not the only places at the middle latitudes of the northern hemisphere that saw frosty conditions. ABC News here reports that “Tioga Pass was closed from 4 miles west of Jct 395 to the Yosemite National Park entrance gate, due to snow.”
Also the southern hemisphere has seen cold weather as well. The forecast for Australia is calling for below normal temperatures.
Share this...FacebookTwitter "
"Modern biofuels have been touted as a greener alternative to petrol and diesel since the early 1900s. It seems like a good idea on paper, and they do work – but their use and production doesn’t come without problems.  The first generation of biofuels – mainly ethanol made from plant crops – and second generation, derived from plant and animal waste streams, both had environmentalists and others concerned about the competition for land and nutrients between biofuels production and food production. It was with a lot of hope, and hype, that production of the third generation of biofuels was started. Unlike their predecessors, these biofuels are derived from algae, and so in theory the food vs fuel dilemma of crop-based biofuels would be solved.  Fossil fuel oil and gas originated from ancient algae in large measure, so the concept here is to replicate the essence of the creation of fossil fuels, albeit accelerated and optimised with modern chemical engineering. It was claimed that using algae would be much more efficient than creating biofuels from terrestrial plants and that the technology would make use of poor quality land not able to grow other crops. Millions of dollars, euros and other currencies have been spent trying to get the algal marvel to work. Much of the money has been directed at refining the engineering process, electrically lighting the crop – which grows in a liquid suspension – harvesting and draining it. The solution to optimisation was seen as primarily technological non-biological, though species selection and growth conditions were also acknowledged as important factors. However, it turns out that the hype has been misplaced. Our research has found that the production of algal biofuels is neither commercially nor environmentally sustainable. The attainable production levels are a fraction of those that were claimed. The amount of biofuel produced from prolonged culture of algae in pilot-scale systems is actually not too dissimilar from those of terrestrial plants: around 5,000 to 10,000 litres per hectare per year.  In fact, the rate of production from algae growing in the vast ponds required for truly massive production is, for a given area of land, similar to that seen in the most productive areas of the ocean. It amounts to around 4g of carbon from CO₂ fixed into biomass per square metre every day. So what’s the problem? Why aren’t algal biofuels as good as had been hoped? Quite simply, it’s biology. The dream has been broken not by failings in engineering, but by the inefficiency of biochemistry. Simulations of microalgal biofuel production show that to approach the 10% of EU transport fuels expected to be supplied by biofuels, ponds three times the area of Belgium would be needed. And for the algae in these ponds to produce biofuel, it would require fertiliser equivalent to 50% of the current total annual EU crop plant needs. Ironically, such ponds would also need to be located near heavy industry which produces CO₂ to provide the level required by the microalgae for photosynthesis. The problem with third-generation biofuels has always been scaling up the production rates measured in small culture flasks to growth in thousands of cubic metres in size. In the larger cultures, the biomass density of the algae – needed to make the culture and harvesting processes economical – defeats desired growth rates because the organisms shade light from each other. This means that they do not get the sunlight needed to photosynthesise and produce the carbon-rich compounds needed for to make the biofuel fast enough. There have also been misunderstandings of how the algae react to their environment. Importantly, those vital carbon-rich compounds only really accumulate in cells that are nitrogen-limited and so are growing slowly. Early production estimates assumed high carbon-rich content in fast-growing cells but this has not proved to be the case.  Could we not genetically modify a solution to the inherent biological inefficiency? Perhaps, but should we really tamper with factors that are so fundamental to life on Earth and risk generating unstoppable harmful algal species that could destroy fisheries and damage drinking water supplies? Even if we did create the perfect algae for biofuels production, the need for all that fertiliser and CO₂ would remain. Ultimately the public have paid for this failed vision – but their money has not been wasted. If there’s one thing that humans need more than fuel it is food – and this work can help us understand how to better grow microalgae to support the farming of fish and shellfish, and produce dietary supplements, like Omega-3. Mass microalgal production could also create food containing omega fatty acids to farmed fish, for example, meaning that we would no longer need to fish in rivers and oceans to make fishmeal for them. The future for mass microalgal cultivation is still literally and metaphorically green, it just does not rest with biofuels production."
"Let’s start with the good bits in shadow chancellor John McDonnell’s speech on “rewriting the rules of our economy”. Forcing big accounting firms to split their auditing and consulting units is justified: current conflicts of interest are too great. One can applaud the push to get workers on to boards. And enhanced voting rights for long-term shareholders is an idea worth exploring. If McDonnell had stopped there, he would have had a worthwhile package of reforms. But he moved on to territory that ranged from radical to vague to plain odd. Try this: “All executive remuneration packages in large companies [will be] subject to an annual binding vote by stakeholders, including shareholders, employees and consumers.” Lloyds Banking Group has 30 million customers in the UK. There are 16 million holders of a Tesco Clubcard. Are these companies to hold an annual mini-referendum, as it were, before executives can know what they’re being paid for the year? A vote among all consumers would be unworkable. Companies that do not take adequate steps to decarbonise their businesses “will be delisted from the London Stock Exchange”. But surely incentives and penalties should apply equally to quoted and non-quoted companies. Then there’s McDonnell’s favourite “inclusive ownership funds”, meaning a transfer of 10% of a group’s shares, over a decade, to an employee fund. The model has been recast so that dividends for workers would relate only to UK profits, but basic flaws remain. The Treasury ends up a big winner as it collects all dividends over £500 a head; the 10% transfer represents heavy dilution for current owners, including pension funds; and it’s not obvious how foreign multinationals could be strong-armed to participate. One could go on. An “excessive pay” levy requires a definition of excessive. And, if you’re going to rearrange financial regulation, you must first define the role of the Bank of England, which wasn’t mentioned in the speech. The business world will hate most of it, which was perhaps the point. There is a need for big ideas to address obscene remuneration and restore trust in business. But they must be clear and workable, and some of the shadow chancellor’s plans fall well short of that requirement. What do you get for £21m, the cost of Slaughter & May’s independent report into last year’s IT fiasco at TSB? A document that generates a squabble – but that’s about all. Certainly, Richard Meddings, chairman of TSB then and now, has no intention of resigning, despite a finding that his board lacked “common sense” during the “replan” phase of the IT upgrade. Meddings’ view is that the report “doesn’t paint the full picture of [the data] migration”. TSB says there are “aspects … with which the board does not agree.” Meanwhile, Paul Pester, the former chief executive who was ousted shortly after the calamity, is gunning for Sabis, the tech contractor on the job and, like TSB, a subsidiary of Spanish bank Sabadell. “Sabis rolled the dice by running tests on only one of TSB’s two new data centres,” claims Pester. At this point, an outside observer will scream in frustration. After the great crash of 2008-09 the bankers pleaded, in as many words, that “nobody was responsible because everybody was responsible”. The refrain from TSB feels the same, albeit a botched IT job – even one that cost £350m and seriously annoyed nearly 2 million customers – is less serious than a full-on collapse. To get the full account, we’ll to have wait for the findings of the Financial Conduct Authority, which is semi-obliged to name a few names. Bring it on. The relationship between TSB and Sabadell looks to have been dysfunctional but somebody has to be judged to be responsible. Airlines have a choice when it comes to global heating, writes Larry Elliott. They can take steps themselves to limit their carbon footprint now or they can wait for tougher curbs to be imposed on them later. EasyJet’s announcement of an offsetting scheme shows they will plump for the former. The aviation industry is under increasing pressure to “do something” about the climate emergency. It can sense the way the wind is blowing, and the cost – £25m compared with annual profit of £427m – is surprisingly small. There will undoubtedly be more tree-planting and reforestation announcements over the coming months. Whether there are enough schemes currently available to provide all the offsetting required is unclear. But what is certain is that carbon-offsetting can at best be a stop-gap solution, until such time as the industry cracks the problem of how to go electric. That day is still some way off."
"One question that arises from the announcement by the UK government that new diesel and petrol cars will be banned by 2040 is what it means for biofuels. If cars running on fossil fuels will be substituted by electric cars, it could imply that all liquid transport fuels will be eliminated.  Around 5% of the volume of the average British tank of petrol or diesel comes from biofuels at present. It is produced from various sources, including corn, wheat, sugar beet and waste ranging from rotten vegetables to used cooking oil.  Biofuels in the UK by feedstock type The large-scale use of biofuels dates back to the 1970s, when they were first introduced in Brazil through government incentives to build vehicles that could run on 100% ethanol produced mainly from sugar cane. Brazil remains a leader in biofuels, despite ups and downs over the years. More than a quarter of petrol content must comprise ethanol – and most vehicles can run 100% ethanol if they choose to.  Elsewhere biofuels have enjoyed varying fortunes. They became a popular possible alternative in the 1990s as a consequence of the rise in the oil price. More recently, more than 60 countries across the world require some blend of biofuels at the fuel pumps as part of their commitments to cut greenhouse gas emissions, and have also launched biofuel production programmes. Yet progress has become very slow in many countries. Among the reasons are the period of low oil prices and the fact that it uses much more farmland to increase biofuel proportions in fuel tanks.  So will anyone bother to keep striving towards sustainable liquid fuels now that the end of petrol/diesel vehicles appears in sight? The answer has to be yes, for a couple of important reasons.  The first is hybrid vehicles, which have been far more successful than purely electric ones to date. These engines that run on a combination of liquid fuels and recharged batteries will play a major part in the transition towards complete electrification. If the UK is to move towards a complete ban on fossil fuels in transport, new hybrids are likely to increasingly depend on biofuels.  The second point is that the transport system is about far more than roads. Aviation, shipping and haulage are all significant and they have a much more limited scope for electrification. They will continue to rely heavily on liquid fuels  – to which end the US navy recently launched its first biofuel-powered aircraft carrier, for example.  So if we’re still going to need biofuels, how do we make the most of them? I was a member of a working group of the Royal Academy of Engineering that recently produced a report about the sector commissioned by the UK’s departments for transport and energy.  The report, which involved a meta-study of a number of research papers about the sector, said biofuels would undoubtedly play an important role in meeting the UK`s commitments towards climate change. It called for a combination of incentives and careful regulation to avoid risks and unintended consequences, such as crops being diverted from food production.  It proposed incentives to encourage so-called second-generation biofuels – those which predominantly come from waste and have a far better emissions profile than biofuels from dedicated crops such as soya or corn. It proposed to incentivise growing biofuel crops on land that was unsuitable for food production, while generally capping crop-based biofuels to help prevent them from taking up space that could be for food crops. It also proposed that the minimum blend level in the UK be increased from its current 4.75% (more work is required to determine what might be realistic). If the government approached biofuels in this way, there could be indirect benefits  – giving farmers an extra incentive to plant more crops, for example, as well as improving crop yields and making farming processes more efficient. The amount of land dedicated to farming could also rise as a result.  My message is therefore that we will need biofuels for the foreseeable future despite the UK government’s 2040 ban. By prioritising the right kinds of biofuels through subsidies and caps, we can minimise their drawbacks and maximise their advantages over petroleum fuels. The 2040 ban, far from meaning the end of liquid biofuels, should be seen as an important opportunity for the sector."
"Sierra Leone is still reeling from the effects of a mudslide that killed nearly 1 000 people, left hundreds missing and rendered thousands homeless. After about five hours of heavy rainfall, the mudslide came down Mount Sugar-Loaf and almost wiped out Mortome. This is a relatively new settlement which emerged as a result of the rapid urbanisation of Freetown, Sierra Leone’s capital city. The heavy downpour also caused huge flooding that inundated the city, including areas previously unaffected by heavy rains.  For the past five years floods have become almost an annual occurrence in Freetown. Whenever they occur, such as the floods in 2015, they overwhelm the capacity of government. They affect nearly the whole city, causing a huge humanitarian crisis.   Freetown is a coastal city built on wooded hills. Though mudslides are a rare event, this incident was not surprising. Over the past 10 years research papers and civil society organisations have repeatedly warned the government, and individuals who choose to build in unstable areas, that the city faces a serious threat from deforestation on the peninsula.    As the city pushes up into the mountains, the population pressures are taking a toll on the forest. Trees are being cut down by people who want land for housing and those who cut wood for their daily needs. About 14.7% of dense forest in 1986 was converted to built-up by 2015.   This increases the risk of mudslides as trees usually prevent run-off and forests hold water. When there is prolonged or intense rainfall in places with no trees, the soil becomes saturated and erodes.  There have been calls to stop the extension of settlements into the peninsula’s hills and for the government to better manage the city’s development. But the authorities have rarely taken steps to address this. Action ahead of rains is occasionally taken, but this is done at a household level. It consists of measures such as clearing drains, strengthening  house foundations, repairing roofs and pruning trees to prevent damage if branches were to fall. In response to the recent tragedy, the city’s director of surveys and land, Christian Pratt, pointed out that: The laws are there to control development but the attitude of citizens is a serious concern. We have done several sensitisations…we set up a cut off line and brought it to the attention of people but these were not heeded. Inaction caused a predictable tragedy. What nobody expected was the scale of damage it caused.  The simple truth is that people are living where they shouldn’t be, in areas that are now vulnerable to both flooding and mudslides.  Typically, the poor suffer the most whenever there is a disaster in Freetown. This is because they tend to live in high risk areas, such as slopes or coastal slums. In this case, though, well built homes were also affected as they were located in unstable areas. There are several reasons why people live in these areas and under these conditions.  Firstly, most places have developed chaotically. Houses have often been built by powerful or influential individuals without following basic, town and country planning, rules.  Secondly, there has been a lack of good spatial planning. With limited available land the city should have managed the use of land better. Settlements should have been clearly laid out and provided with services like water and sanitation before houses were built. Thirdly, there has been a surge in demand for home ownership combined with a widespread practice of public land grabs by both the poor and the rich.  Fourthly, as seen above, warnings about the environmental dangers were disregarded.  Freetown is already home to 40% of the country’s urban population. The city’s population was over one million in 2015 and is expected to increase by 3-5% in its various wards. Unless urban planning is taken seriously there’s a risk that more locations could experience similar events, potentially more devastating than this one.  Several steps are needed urgently. Legislation in settlement planning and land use must be reviewed and improved. Instead of focusing on evictions, relocation and resettlement, political action should respond to the reasons people live in risky areas.  Finally, the relevant government bodies need skills training in disaster risk reduction and land use planning."
"Climate change is not something that will just go away. It is already affecting global biodiversity, food security and human migration, and the situation is not expected to improve soon. Rising temperatures and regular extreme events will produce new selection pressures.  These will force many species to move to find more suitable conditions, or adapt. Their ability to respond to these pressures will depend on the rate and extent of change, their ability to adapt to new conditions or their ability to move away. Understanding how biodiversity responds to climate change requires an interdisciplinary perspective, combining ecological, molecular and environmental approaches.  As part of our work to establish a new way of studying biodiversity, we developed an integrated framework to help guide conservation efforts by identifying wildlife populations under threat from climate change. We assign levels of risk to populations based on their exposure to changing climate conditions, their sensitivity due to genetic variation and their ability to alter their range (range shift potential). We show how our approach can be applied in a bat species, the grey long-eared bat, Plecotus austriacus. This bat is one of the rarest mammals in the UK, with a population estimated at less than 1,000 individuals. This bat has also been in decline across Europe. Our previous work showed that its geographic distribution is limited by climate, and current patterns of genetic variation were shaped by changes to the climate. We collected wing biopsy samples for genetic analysis from eight populations in the Iberian Peninsula and two populations in England – the southern and northern edges of their range. We used ecological modelling and climate data to look at where changes are likely to be most extreme. And to identify climate-driven genetic adaptations we looked at genomic data. This allowed us to assess which populations are likely to be most sensitive to the effects of climate change. Finally, we use a combination of genetic and geographic data to predict the ability of populations to track suitable conditions in the future. We show that while conditions in the UK could actually improve for the bat, populations in southern Europe that hold the key to the survival of the species as a whole could be devastated. We identified those likely to be most sensitive to future changes because they do not contain enough climate-adaptive variation.  We also looked at landscape connectivity to show populations that will become isolated in the future. As the suitability of the environmental changes, the movement of individuals will be affected. This will limit the ability of populations to move to more suitable areas, and limit the chances of spreading adaptive genetic variation into populations that are at risk. We identified one population, along the eastern coast of Spain, as being high risk. It will be exposed to high changes in the suitability of the climate, has a low levels of climate-adaptive genetic variation and will experience limited landscape connectivity.  We identified two other populations in the central regions of Spain that are medium-high risk. Despite high exposure to changes and limited connectivity, they have a higher frequency of adaptive genetic variation. In contrast, populations along the Atlantic coast of the peninsula and in the UK are at lower risk from climate change, because they will experience less change in the suitability of the climate, and keep higher landscape connectivity. Assigning levels of threat to populations can help us to set conservation priorities. Conservation management can focus on rescuing high risk populations. This could be by moving of the population to more suitable areas, or moving individuals with the right adaptive variation into the population.  But such intense management is likely to be costly and irrelevant when considering the number of species likely to be in need of these measures. Alternatively, we could focus on reducing threats to medium and medium-high risk populations by increasing landscape connectivity, this would allow range shifts and the spread of adaptive genetic variation.  Long-lived, slow-reproducing species with smaller population sizes are unlikely to adapt to climate change fast enough by spreading new mutations. They will depend on the spread of adaptive genetic variation caused by the movement of individuals between groups. Therefore a better understanding of movement processes and landscape connectivity is needed for predicting population persistence under climate change.  The framework we developed can be widely applied to other population groups and ecological systems to help decide how to focus conservation efforts to help species survive."
"I trampled clumsily through the dense undergrowth, attempting in vain to go a full five minutes without getting snarled in the thorns that threatened my every move. It was my first field mission in the savannahs of the Republic of Guinea. The aim was to record and understand a group of wild chimpanzees who had never been studied before. These chimps are not lucky enough to enjoy the comforts of a protected area, but instead carve out their existence in the patches of forests between farms and villages. We paused at a clearing in the bush. I let out a sigh of relief that no thorns appeared to be within reach, but why had we stopped? I made my way to the front of the group to ask the chief of the village and our legendary guide, Mamadou Alioh Bah. He told me he had found something interesting – some innocuous markings on a tree trunk. Something that most of us wouldn’t have even noticed in the complex and messy environment of a savannah had stopped him in his tracks. Some in our group of six suggested that wild pigs had made these marks, while scratching up against the tree trunk, others suggested it was teenagers messing around.  But Alioh had a hunch – and when a man that can find a single fallen chimp hair on the forest floor and can spot chimps kilometres away with his naked eye better than you can (with expensive binoculars) as a hunch, you listen to that hunch. We set up a camera trap in the hope that whatever made these marks would come back and do it again, but this time we would catch it all on film. Camera traps automatically start recording when any movement occurs in front of them. For this reason they are an ideal tool for recording wildlife doing its own thing without any disturbance. I made notes to return to the same spot in two weeks (as that’s roughly how long the batteries last) and we moved on, back into the wilderness. Whenever you return to a camera trap there is always a sense of excitement in the air of the mysteries that it could hold – despite the fact that most of our videos consisted of branches swaying in strong winds or wandering farmers’ cows enthusiastically licking the camera lens, there is an uncontrollable anticipation that maybe something amazing has been captured. What we saw on this camera was exhilarating – a large male chimp approaches our mystery tree and pauses for a second. He then quickly glances around, grabs a huge rock and flings it full force at the tree trunk. Nothing like this had been seen before and it gave me goose bumps. Jane Goodall first discovered wild chimps using tools in the 1960s. Chimps use twigs, leaves, sticks and some groups even use spears in order to get food. Stones have also been used by chimps to crack open nuts and cut open large fruit. Occasionally, chimps throw rocks in displays of strength to establish their position in a community.  But what we discovered during our now-published study wasn’t a random, one-off event, it was a repeated activity with no clear link to gaining food or status – it could be a ritual. We searched the area and found many more sites where trees had similar markings and in many places piles of rocks had accumulated inside hollow tree trunks – reminiscent of the piles of rocks archaeologists have uncovered in human history.  Videos poured in. Other groups working in our project began searching for trees with tell-tale markings. We found the same mysterious behaviour in small pockets of Guinea Bissau, Liberia and Côte d’Ivoire but nothing east of this, despite searching across the entire chimp range from the western coasts of Guinea all the way to Tanzania. I spent many months in the field, along with many other researchers, trying to figure out what these chimps are up to. So far we have two main theories.
The behaviour could be part of a male display, where the loud bang made when a rock hits a hollow tree adds to the impressive nature of a display. This could be especially likely in areas where there are not many trees with large roots that chimps would normally drum on with their powerful hands and feet. If some trees produce an impressive bang, this could accompany or replace feet drumming in a display and trees with particularly good acoustics could become popular spots for revisits. On the other hand, it could be more symbolic than that – and more reminiscent of our own past. Marking pathways and territories with signposts such as piles of rocks is an important step in human history. Figuring out where chimps’ territories are in relation to rock throwing sites could give us insights into whether this is the case here.  Even more intriguing than this, maybe we found the first evidence of chimpanzees creating a kind of shrine that could indicate sacred trees. Indigenous West African people have stone collections at “sacred” trees and such man-made stone collections are commonly observed across the world and look eerily similar to what we have discovered here. To unravel the mysteries of our closest living relatives, we must make space for them in the wild. In the Ivory Coast alone, chimpanzee populations have decreased by more than 90% in the past 17 years.  A devastating combination of increasing human numbers, habitat destruction, poaching and infectious disease severely endangers chimpanzees. Leading scientists warn us that, if nothing changes, chimps and other great apes will have only 30 years left in the wild. In the unprotected forests of Guinea, where we first discovered this enigmatic behaviour, rapid deforestation is rendering the area close to uninhabitable for the chimps that once lived and thrived there. Allowing chimpanzees in the wild to continue spiralling towards extinction will not only be a critical loss to biodiversity, but a tragic loss to our own heritage, too. You can support chimps with your time, by instantly becoming a citizen scientist and spying on them at www.chimpandsee.org, and with your wallet by donating to the Wild Chimpanzee Foundation. Who knows what we might find next that could forever change our understanding of our closest relatives."
"
Share this...FacebookTwitterTrillions are being spent on the completely wrong scenario, an independent veteran meteorologist implies. Instead of warming, we need to worry about the coming 125-year cool period, which has already begun.
A former National Weather Service (NWS) meteorologist has spoken out in a just released 49-minute video that looks at climate change and what lies ahead.
The recent cold winters and expanding polar ice caps are ominous signs of a global cooling that has already begun, maintains David Dilley, now President and Founder of Global Weather Oscillations, Inc. Claims of warming have not been properly founded.
Photo right: David Dilley, Global Weather Oscillations
Dilley has forty-two years of professional experience in the meteorology and climatology and many publications. He was with NOAA for twenty years. Not only is the government wrong with its claims of a coming warming, Dilley accuses the federal government of fiddling with global temperature data with the aim of producing a false picture of what is going on.
In his must-see video presentation dubbed “Is Climate Change Dangerous?“, he examines the many drivers and factors behind climate change and why we need to focus on the real problem of a coming cooling.

Here are the points he makes in the video:
1. The 18+ years temperature pause is real. (4.09)
2. Natural cycles are behind the current pause.
3. Ice cores show CO2 lags temperature. (5.00)
4. 7000 years ago there was 50% less Arctic ice. (8.20)
5. The 1000-year cycle is real. (9.20)
6. Planet has been cooling over past 10,000 years. (9.34)
7. Natural cycles are driving our climate. (10.04)
8. Shows cooling from 2023 to 2150.
9. Current warming is perfectly natural.
10. Milankovitch cycles driving large-scale cycles. (13.00)
11. Gravitational forces can bulge Earth’s core by 1.4 km (15.35)
12. Gravitational forces impact global temperature (17.20)
13. Warming and cooling both begin at the poles (17.48)
14. Arctic warming/melt was caused by warm ocean pulses (19.50)
15. “Now starting to see a dramatic cooling in the Arctic“. (22.50)
16. “Arctic is cooling rapidly now. Rapidly!” (24.06)
17. Both poles are cooling rapidly now. (25.05(
18. Poles don’t show signs of warming. (26.30)
19. Western drought and Eastern cold due to 26-year cycle. (27.55)
20. Polar vortices due to Arctic/global cooling. (29.25)
21. Lunar cycles correlated with warming/cooling cycles. (31.30)
22. Rapid global cooling by 2019. (32.00)
23. “Temperature fiddling” are “more political than anything”. (32.56)
24. “Could be the biggest scientific scandal ever”. (33.20)
25. IPCC using “estimated temperatures”. (34.00)
26. How the government manipulated, rewrote data. (36.00)
27. “This is temperature fiddling.” Not the truth. (36.45)
28. NASA, NOAA’s “politically driven press releases”. (37.00)
29. Met Office calls NOAA’s 2014 claim untrue. (38.00)
30. Major data fiddling, cheating by NOAA. (39.50)
31. “The 97% consensus is bogus”. (41.00)
32. John Cook cooked the consensus data. (41.30)
33. 85% meteorologists say climate change is natural. (42.20)
34. Global cooling is the real danger. (43.20)
35. Volcanoes and cooling often correlated. (44.00)
36. Crop failures from cooling “very likely”. (45.45)
37. “Extremely cold” from 2025 to 2050. (46.36)
38. Global cooling next 125 years. (47.00)
39. “The cooling is coming”.
Share this...FacebookTwitter "
"A blood-sucking, disease-spreading, whining creature is always going to be a hard sell, even to nature lovers. And the dreaded mosquito is now the prime suspect behind the sudden arrival and explosive spread of Zika virus in Central and South America. Zika is transmitted by a mosquito vector Aedes aegypti, a pan-global tropical species already well known for spreading diseases such as yellow and dengue fever.  There are only around 3,500 species of mosquito, which is modest for a family of insects – but their impact on human health and welfare is catastrophic. Female Anopheles mosquitoes carry the parasite that causes up to 500m cases of malaria a year while the Asian Tiger Mosquito, Ades albopictus, spreads dengue fever and the chikugunya virus. Mosquitoes have been ready vectors for emergent diseases such as West Nile virus and now Zika.  Mosquitoes are credited with causing more misery and loss to humanity than any other organism (with the obvious exception of ourselves). Mosquitoes are unlovely creatures, all twitchy legged and whining, their larvae infesting miasmas and dismal swamps. And under the right conditions they are mobile and expansionist pioneers, perfectly at home in the disrupted habitats we create. Which begs the question: what good do they do – and if we could wipe them from the face of the Earth should we? As pointed out by ecologist Sarah Fang, the consensus is that mosquitoes do not do any unique or particular good that would be missed. If you judge them according to ecologist Charles Elton’s gentle but evocative idea of each creature having a niche – much as every English village has a cast of characters who have their place such as butcher, baker and policeman – then mosquitoes seem to have no special purpose on the face of it. So one wouldn’t miss them, surely? Arguments in favour of mosquitoes fall into two broad categories. First that their sheer numbers are an essential link in some food webs, notably the Arctic tundras where, for a few brief weeks in summer they hatch in extraordinary numbers, creating visible clouds of adults and a very rich food supply to migratory birds that have come north to exploit this bounty.  Fang also suggests that the mosquitoes’ assaults may be ferocious enough to divert the migration lines of caribou with possible consequences at a landscape scale as the herds’ grazing and trampling shift location. In an unusually exact link between mosquitoes and their predators, a study of foraging Little Forest Bats, Vespadelus vultuernus, in eastern Australia revealed a very heavy reliance on adults of the mosquito Aedes vigilax. So, that Little Forest Bats need mossies may be as good a case as mosquitoes can muster. Juvenile mosquitoes are also important in some freshwater foodwebs, including as prey to specialists such as the mosquito fish, Gambusia affinis or in the tiny pools of water held in the leaf bases of pitcher plants and bromeliads high in the rainforest canopy. In among the canopy trees a miniature fauna of vividly coloured poison dart frogs and crabs thrive in the bromeliad pools, called phytotelmata, feeding off the bodies of drowned juvenile mosquitoes. But despite poison dart frogs and bats having their own fan club among ecologists and nature enthusiasts, they are unlikely to sway the majority of people in favour of mosquitoes. The second argument is that mosquitoes have a more general role providing ecosystem services such as pollination by adults or driving the release of nutrients as their young feed on organic detritus. But although mosquitoes can act as pollinators for orchids and golden rods, among other plants, they don’t have a monopoly – they are not especially suited to this role and there are plenty of other pollinators to take their place.  While the decline of the honey bee is a prominent example of an ecosystem service at peril, mosquitoes are just another one of the many pollination bit-part players, an unloved understudy that can be written out of the part. Their significance has always been to menace.  As the Portuguese explorer João de Barras said of the tropics: God has placed a striking angel with a flaming sword of deadly fevers, who prevents us from penetrating into the interior to the springs of this garden. So there seems no great reason to defend mosquitoes. Their destruction would lift a terrible curse from humanity. Except for one nagging doubt … All that warm, nutritious blood suddenly available. There are plenty of other midges and mites, black flies and fleas out there just waiting for the opportunity to step in. Be careful what you wish for."
"Beavers have recently made a tentative return to Britain. Scotland has led the way, with an official trial population in Knapdale, a remote area of lochs and forest in the west of the country; and another in Tayside to the east, suspected to come from private-collection escapees and unlicensed releases. Further south, a small feral population in Devon in south-west England is currently being tolerated by officialdom and admired locally, while there are also plans for a trial in mid-Wales. Should we let these beavers take up permanent residence? The Scottish government has first refusal. It is overdue to make a decision on the back of five years of scientific monitoring and other evidence. While conservationists wait with bated breath, we think there’s only one sensible choice – beavers should be allowed back. The EU’s Habitats and Species Directive has been the cornerstone of conservation policy in Britain for the last 30 years. It actively encourages member states to consider reintroducing formerly native animals. The Eurasian beaver is a good candidate, having dwindled in mainland Europe to a handful of small isolated populations by the late 19th century. Thanks to the directive, it is now re-established across most of its former range, making Britain something of a laggard. The beaver became extinct here 400 years ago. In fact, Knapdale represents the first legal attempt to reintroduce an extinct native mammal to the country.  None of this is about nostalgia. Beavers are often referred to as “ecosystem engineers” and herein lies much of the reasoning and controversy behind their reintroduction. There is extensive evidence from Europe and North America that wetlands created by beaver dams benefit everything from water plants, dragonflies and amphibians to fish and ducks to song birds and bats. In Knapdale, damming by beavers transformed a small pond into a wetland of a type and complexity probably unseen in Britain for centuries.  Beavers can also restore habitats without the need for a bulldozer or planning permission. On the Bamff estate on Tayside, we found that grazing by beavers trebled the number of wetland plants over a nine-year period. Where raised water levels saturated a meadow thanks to damming of ditches, the number of plant species increased by 49% and the multitude of habitats created increased the total diversity of aquatic invertebrates by almost 30%. Indeed the benefits were even further reaching. We found that the beaver dams also acted as a sink for agricultural pollutants, and may also help to reduce the risk of flooding. Individually these findings are not that surprising, though it is unusual to demonstrate them all in parallel. So it’s a no-brainer? While the Scottish public are broadly supportive of reintroducing these dog-sized, rather retiring herbivores, farmers, foresters and some anglers are less keen. Beavers get accused of damaging farm crops and commercial plantations through feeding, tree-felling, blocking streams, causing floods, undermining flood embankments and clogging up fish-spawning gravels.  These concerns are often legitimate and locally significant, and need to be addressed. Yet there are tried and tested ways of mitigating beaver impacts borrowed from the US and Germany that have already been trialled in Scotland, including live-trapping, electric fencing and so-called “beaver deceivers” for managing pond levels. At the same time, beavers have been wrongly held responsible for some high-profile flooding incidents and there remains a widely held but entirely mistaken belief among some anglers that they eat fish. In fact, the most recent analysis in Scotland suggests that beavers generally have a positive impact on the likes of trout.  The reality is that beavers, people and fish have co-existed for thousands of years. There is no reason why in principle this should not continue, even if beavers change the landscape and the landscape itself has changed in their absence. The successful reintroduction and effective management of beavers in central Europe testifies to their adaptability. Beavers bring multiple environmental benefits and the risk of local but manageable disruption shouldn’t eclipse these. In some senses the “beaver question” is a metaphor for the much bigger question of what sort of environment we want in Britain in future. Beavers are potentially at the vanguard of a wider movement called rewilding – transforming landscapes through everything from less intensive farming to reintroducing keystone species. Saying yes to beavers doesn’t mean opening the floodgates to all supposedly desirable species from bison to lynx, but it recognises that we can cope with changing how we run our land, and that the alternatives might be better. On the other hand, saying no to beavers would shut the door on any bigger ambitions, perhaps for decades.  This is also not about going back to the Stone Age – indeed taking land out of production might require more intensive farming elsewhere to address concerns about food security. Instead of imposing rewilding, we must seek the cooperation of landowners. We might incentivise this with subsidies to recognise the ecosystem services that species like beavers provide, while compensating inconvenienced landowners. And as well as mitigating against the impacts that reintroduced creatures can cause, we’ll need to think more about the wider risk of further divorcing people from nature by creating wilderness areas.  But be all that as it may, the positives greatly outweigh the negatives. When it comes to conservation, we have lacked ambition for too long. Saying yes to reintroducing beavers is the sort of bold and forward-looking move that would resurrect the UK’s conservation credentials."
"EasyJet is set to become the world’s first major airline to operate net-zero carbon flights across its entire network, after announcing it would offset all jet fuel emissions. The British budget airline said it would start offsetting all flights from Tuesday, which it said would cost about £25m in the next financial year through schemes to plant trees or avoid the release of additional carbon dioxide.  Johan Lundgren, the airline’s chief executive, said longer-term solutions were also needed. “We recognise that offsetting is only an interim measure, but we want to take action on our carbon emissions now,” he said. “Aviation will have to reinvent itself as quickly as it can.” EasyJet’s move surpasses the recent pledges of rival airlines, including British Airways, whose parent company, IAG, promised last month to be carbon-neutral by 2050 and to start offsetting all domestic flights next year. The German airline group Lufthansa has launched a business fare where European flights are automatically offset for corporate customers from 2020. There is mounting pressure on the aviation industry to address its environmental impact. The UN agency ICAO has launched a limited global offsetting programme, Corsia, whereby governments have agreed to offset any growth in emissions, but campaigners argue this does not go far enough. Lundgren argued that EasyJet was “together, all in all, doing more than any other major airline within this area. Customers increasingly expect companies to do something about it and it is fundamentally the right thing to do.” The airline said it had secured a relatively low price as it had signed a three-year contract for wholesale offsetting, equating to less than £3 per tonne of CO2 or £25m a year. Lundgren said that the 17 different projects were “verified to the highest standards … audited and monitored to deliver actual offsets”. The airline plans to develop its own schemes to continue offsetting after the three-year period. EasyJet’s move, however, is unlikely to assuage environmental criticism, in a year during which it has launched domestic flights between Birmingham and Edinburgh, which are linked by fast rail routes, and expanded its airline capacity by more than 10%. EasyJet also announced it had signed a memorandum of understanding with the manufacturer Airbus to work in partnership to develop electric and hybrid electric planes for short-haul European flights. Lundgren said he hoped it would be “an important step towards making electric planes a reality”. The airline said it would continue working with Wright Electric, a US firm that has developed a nine-seater electric plane expected to start flying in the coming weeks. Lundgren said easyJet would take further measures including reducing the number of empty seats flown – although the proportion left empty on the average flight increased to 8.5 in every 100 seats last year. EasyJet reported pre-tax profits of £427m for the year ending 30 September, in line with previous guidance but down 26% on 2018, a drop it ascribed to rising fuel prices and a tough operating environment – although it was boosted by strikes at rivals BA and Ryanair. A record 96.1 million passengers flew with easyJet last year. EasyJet has also relaunched its package holiday business as a stand-alone division, looking to increase customer numbers following the collapse of its major competitor Thomas Cook. A new easyJet Holidays booking site will launch in the UK before Christmas, with the division aiming to at least break even in its first financial year. Lundgren said that, despite Thomas Cook, the package holiday was “not in any way shape or form in decline” and that easyJet was well placed to capitalise on a market worth £60bn a year in Europe. EasyJet expects to start flying routes as early as next February using airport slots at Gatwick and Bristol acquired from Thomas Cook’s administrators."
"
Share this...FacebookTwitterI can hear it already. Like the climate activists who now deny there was a global cooling scare 40 years ago, in 10 years time or so we’ll be hearing the media and all the proponents of the low-fat/high carb diet claiming that this too was never a consensus.
Remember how eating saturated fats was supposed to cause artery-clogging, dangerous cholesterol and hence had to be avoided at all times? Day after day we were indoctrinated to follow the government’s and doctors’ guidelines of eating high carb, low fat foods. The science was fully endorsed for decades by the AMA, AHA, etc.
The food industry responded by filling store shelves with Twinkie and Cocoa Puffs-quality “foods”. Today tens of millions are afflicted with horrendous ailments like diabetes, heart disease and malnutrition.
Fortunately a few people ignored the totally bogus consensus nutritional recommendations and continued consuming high fat diets that included real butter, chicken, beef, cheese, eggs, fat-dripping bacon …and more eggs, along with their vegetables. The Telegraph here writes about how one person ate bacon and eggs every day almost her entire life and has just turned 116! In her kitchen she has a sign with a what I’d call a really sensible nutritional guideline:
“Bacon makes everything better!”
On the other hand we could continue corroding and oxidizing our bodies with carbs, or even follow the example of tech guru Steve Jobs, who had top chefs cooking a strict vegan diet for him daily. Jobs wound up dead at only 56. His “healthy” diet may have been deemed responsible, and friendly to the environment. But it certainly was not healthy or friendly to him.
Share this...FacebookTwitter "
"Global agreements to aim for “well below” 2℃ warming are nice enough, but now it’s time to develop some detailed policies to help us get there. Ships and planes are significant sources of greenhouse gases, and their emissions are projected to rise. Currently, both sectors exist outside national level frameworks and are not explicitly referred to in the international Paris deal. So what changes can we expect? A recent IMF paper on the global economic implications of the Paris agreement suggested that international shipping and aviation fuels should have a levy applied to them to create both revenue and encourage reduced emissions. The IMF proposes US$30 per tonne of CO2 emitted. A scheme already exists in Europe, where every flight from one EU country to another is included in the Emissions Trading Scheme and CO2 emissions must be accounted for and “paid for” using permits – in essence applying a price to the flight’s emissions.  The primary difference between the IMF’s proposed levy and a global ETS is over how the carbon price is set. In a levy, the price is chosen by policymakers and reviewed periodically, in an ETS a carbon market and an emissions target (or cap) is used to set the price. The IMF suggests putting a little over half of the revenue aside for developing countries as compensation for trade losses. The remainder (around US$25 billion) would contribute to the US$100 billion Green Climate Fund, which helps poorer nations cope with the effects of global warming. This is unpopular with many in shipping and aviation who understandably question why their sectors should provide such a large share. After all, they still only represent a combined 4% of global greenhouse gas emissions, so why contribute to 25% of the fund? The money could be used in other ways, of course, such as to purchase offsets from other industries or to fund investment in research and development on cleaner ships and planes. But it’s not clear whether offsetting would genuinely help reduce emissions, whereas the latter would be hard to administer and ensure that all countries benefited equally. What would a carbon tax mean for the price of international air travel or the cost of the food, fuel and goods that arrive by sea?  Burning a tonne of either ship or jet fuel creates about three tonnes of CO2, so the IMF’s proposed levy would create a surcharge of about US$90 per tonne of fuel consumed. Fuel costs around US$300 per tonne at today’s low oil prices, so a levy would increase a company’s fuel costs by about 10-30%. But fuel is just one component of a ship or plane’s total costs and therefore the prices that customers pay for flights and goods. In practice, markets that determine overall prices can and do vary by more than the probable effects of a levy (at least at the level IMF propose). Oil prices have fallen dramatically in recent years, for instance, but that hasn’t produced substantially cheaper transatlantic flights or consumer goods from China. The focus on levies and revenues like that proposed by the IMF risks missing the point. Keeping warming at well below 2℃ needs absolute emission reductions – fast.  Unfortunately, current evidence is that US$30 a tonne for CO2 would not deliver the absolute emission reductions required over coming decades. This is partly because demand for shipping and aviation doesn’t closely match price fluctuations – there are often few alternatives, and both industries are key to keeping the modern world up and running. So if higher costs passed on to consumers still don’t reduce demand then we must reduce the emissions per ship. However eco-friendly vessels won’t pop up overnight. Making progress requires new technologies, either those that improve the efficiency of existing ships’ hulls and propulsion machinery, or those that create entirely new ships powered by renewable or alternative fuels.  Developing these technologies will take some time. But to create these technologies there also needs to be a clear signal that this is the direction shipping is going. Otherwise investors won’t have confidence in the R&D, infrastructure and start-ups necessary to help shipping transition.  None of this rules out carbon pricing – this in itself can be part of a “clear signal”. But the extent emissions are actually reduced really needs to be considered, as without this we just end up moving money around the world while remaining on a course for climate catastrophe.  The global agencies responsible for regulating shipping and aviation both meet later this year, with greenhouse gases and climate-change issues high on the agenda. These meetings will be crucial because transforming both into low-carbon industries will only become harder the later we start."
"The global climate crisis could lead to more renewable electricity being generated by spurring faster wind speeds for the world’s growing number of windfarms, according to research. Scientists have discovered that the world’s shifting ocean circulation patterns may have triggered a rapid increase in wind speeds over the last 10 years. The international research team analysed data from 9,000 international weather stations since the late 1970s and found that wind speeds had unexpectedly increased after a three-decade slowdown. Dr Zhenzhong Zeng, a professor at Princeton University and the lead author of the report, said the research team was surprised by the findings after setting out to study the slowdown in global wind speeds. The faster than expected wind speeds could help increase the amount of renewable electricity generated by each turbine by more than a third to 3.3m kilowatt hours (kWh) by 2024. Zeng said the unexpected acceleration is likely to have played a bigger role in improving the efficiency of windfarms in the US than technological innovations. The research paper, published in the peer-reviewed journal Nature Climate Change, suggests that faster global speeds may continue for at least another decade in what would be a major boost for windfarm owners. Dr Adrian Chappell, a professor at Cardiff University and a co-author of the report, said the rapid increase in global wind speed bodes well for the expansion of renewable energy which will be central to keeping global heating to below 2C. The findings mark a major reversal in a trend of decreasing wind speeds over the last three decades – known as global terrestrial stilling – which threatened to halve the world’s wind power potential by the end of the century. We believe that the escalating climate crisis is the defining issue of our lifetimes and that the planet is in the grip of an emergency. We know that our readers and supporters around the world care passionately about this too, as so many of you have told us. We want the Guardian to play a leading role in reporting on the environmental catastrophe. So at the Guardian we commit to the following: Read our full environmental pledge  Previous studies have found that increased “roughness” on the Earth’s surface, from new buildings and urbanisation, has acted as a buffer by slowing wind speeds by up to 2.3% every decade since the late 1970s. But the latest research has demonstrated that large-scale ocean and atmospheric circulation patterns could be making wind speeds faster again. The study found that the main drivers of the world’s quickening wind speeds were the Pacific decadal oscillation, the North Atlantic oscillation and the Tropical North Atlantic index. Zeng said that the effect of global heating on the world’s wind speeds remained largely uncertain because rising temperatures would have a diverse range of impacts that are not fully understood. “We believe our study advances [the] understanding on how climate change affects wind, and we appeal for more scientists to focus on this important climate variable,” he said. “The study of wind can also shed light on the dynamic mechanisms of climate change.” • The article was updated on 19 November 2019 to reflect a correction notice from Cardiff University. The original press statement said higher wind speeds could help increase wind power output by more than a third to 3.3m kilowatt hours (kWh) by 2024. After publication, the university said the figures refer to the output of one wind turbine. This has been corrected."
"The world is facing three existential crises: a climate crisis, an inequality crisis and a crisis in democracy. Will we be able to prosper within our planetary boundaries? Can a modern economy deliver shared prosperity? And can democracies thrive if our economies fail to deliver shared prosperity? These are critical questions, yet the accepted ways by which we measure economic performance give absolutely no hint that we might be facing a problem. Each of these crises has reinforced the fact that we need better tools to assess economic performance and social progress. The standard measure of economic performance is gross domestic product (GDP), which is the sum of the value of goods and services produced within a country over a given period. GDP was humming along nicely, rising year after year, until the 2008 global financial crisis hit. The global financial crisis was the ultimate illustration of the deficiencies in commonly used metrics. None of those metrics gave policymakers or markets adequate warning that something was amiss. Though a few astute economists had sounded the alarm, the standard measures seemed to suggest everything was fine.  Since then, according to the GDP metric, the US has been growing slightly more slowly than in earlier years, but it’s nothing to worry about. Politicians, looking at these metrics, suggest slight reforms to the economic system and, they promise, all will be well. In Europe, the impact of 2008 was more severe, especially in countries most affected by the euro crisis. But even there, apart from high unemployment numbers, standard metrics do not fully reflect the adverse impacts of the austerity measures, either the magnitude of people’s suffering or the impacts on long-term standards of living. Nor do our standard GDP measures provide us with the guidance we need to address the inequality crisis. So what if GDP goes up, if most citizens are worse off? In the first three years of the so-called recovery from the financial crisis, about 91% of the gains went to the top 1%. No wonder that many people doubted the claims of politicians who were then saying the economy was well on the way to a robust recovery. For a long time I have been concerned with this problem – the gap between what our metrics show and what they need to show. During the Clinton administration, when I served as a member and then chairman of the Council of Economic Advisers, I grew increasingly worried about how our main economic measures failed to take into account environmental degradation and resource depletion. If our economy seems to be growing but that growth is not sustainable because we are destroying the environment and using up scarce natural resources, our statistics should warn us. But because GDP didn’t include resource depletion and environmental degradation, we typically get an excessively rosy picture. These concerns have now been brought to the fore with the climate crisis. It has been three decades since the threat of climate change was first widely recognized, and matters have grown worse faster than initially expected. There have been more extreme events, greater melting of glaciers and greater natural habitat destruction. It is clear that something is fundamentally wrong with the way we assess economic performance and social progress. Even worse, our metrics frequently give the misleading impression that there is a trade-off between the two; that, for instance, changes that enhance people’s economic security, whether through improved pensions or a better welfare state, come at the expense of national economic performance. Getting the measure right – or at least a lot better – is crucially important, especially in our metrics- and performance-oriented society. If we measure the wrong thing, we will do the wrong thing. If our measures tell us everything is fine when it really isn’t, we will be complacent. And it should be clear that, in spite of the increases in GDP, in spite of the 2008 crisis being well behind us, everything is not fine. We see this in the political discontent rippling through so many advanced countries; we see it in the widespread support of demagogues, whose successes depend on exploiting economic discontent; and we see it in the environment around us, where fires rage and floods and droughts occur at ever-increasing intervals. Fortunately, a variety of advances in methodology and technology have provided us with better measurement tools, and the international community has begun to embrace them. What we have accomplished so far has convinced me and many other economists of two things: first, that it is possible to construct much better measures of an economy’s health. Governments can and should go well beyond GDP. Second, that there is far more work to be done. As Angel Gurría, secretary general of the Organisation for Economic Cooperation and Development, has written: “It is only by having better metrics that truly reflect people’s lives and aspirations that we will be able to design and implement ‘better policies for better lives’.” Joseph E Stiglitz is a Nobel laureate in economics and the co-author of Measuring What Counts: The Global Movement for Well-Being"
"We are often told that curtailing the freedom of business is coercive and undemocratic. But by what democratic principle should corporations and billionaires decide the fate of current and future generations? When a government releases them from regulation, it allows them to determine whether other people live or die. No one elected them to do so. Even businesses with apparently strong credentials cannot be trusted with this extraordinary power. Take Marks & Spencer, famous for its “Plan A” environmental standards. Its goal, it says, is “to be a zero waste business across all that we do … we already send zero waste to landfill.” But a few days ago, it commissioned a wraparound ad in a limited number of Metro newspapers, in which a video screen was embedded promoting Christmas jumpers. The screen, battery, electronics and casing were designed for a single use. For the first time ever, environmental policies are now central, almost everywhere. But they have scarcely been mentioned in most of the media coverage It’s hard to think of a more profligate form of disposability. Marks & Spencer’s defence of this disgusting waste is that “the video screens can be recycled via electrical appliance collection points”. In other words, it’s up to the people who were handed the free paper to clear up the mess the company made (not that these complex materials can be fully recycled, anyway). I expect 99% of the screens went straight to landfill. This week we discovered that greenhouse gases in the atmosphere have reached record levels, just as they need to be plummeting in order to avoid climate catastrophe. The first task of all governments is now to stop powerful interests, like M&S, from trashing the habitable planet. This is the main criterion by which we should judge political parties. With this in mind, I read all the manifestos for the UK general election published so far. I was immediately struck by a remarkable gulf: between their emphasis, and the media’s emphasis in reporting them. For the first time ever, environmental policies are now central, almost everywhere. But they have scarcely been mentioned in most of the coverage, which is all about Brexit, spending pledges, immigration and the usual 20th-century themes. It’s a reminder that the most environmentally dangerous industry we face, largely controlled by billionaires, is the media. This is not to say that the manifestos have got it right. The Brexit party’s content-free “contract” is a total joke. The Democratic Unionist party writes as if it has been leafing through the dictionary, trying to discover what “environmental” means. Some of the Tory party’s pledges are promising, but they’re so vague that it could wriggle out of most of them. Labour’s transformation is genuinely exciting, but is beset by some important contradictions. Plaid Cymru’s proposals are pretty good, but it has a blind spot on farming (it wants to maintain the EU’s disastrous common agricultural policy, apparently without modification). The Liberal Democrats, mostly, get it. But only the Greens have really grasped what it means to democratise our relationship with the living world. One extraordinary feature of this election is that growth, for some parties, has become almost a dirty word. It is mentioned only twice in the Labour manifesto, both times with qualifications. The Lib Dems have made a crucial breakthrough, arguing that GDP should no longer be a government’s central objective; it should focus instead on wellbeing. This is a policy the Greens have been urging for years. By contrast, for all its talk about a “green industrial revolution”, the Conservative party is still bloviating about “unleashing” businesses and igniting growth through such disastrous projects as the Oxford-Cambridge expressway. It really hasn’t thought this through. Almost all the parties, even the DUP, now talk about green transitions and a circular economy, but with radically different levels of detail. Labour’s threat to delist any company that fails to tackle our environmental emergencies directly addresses the issue I raised at the beginning of this column. Its green new deal, sustainable investment board and green transformation fund are all crucial steps – though it is profoundly disappointing to see Labour fudge the 2030 target for a net-zero economy that was agreed at the party conference. There are some major contradictions, such as its conditional support for new airports, and its adoption of the National Farmers Union target for carbon-neutral food production by 2040. Net-zero in the rest of the economy means that farmland must be used as a massive carbon sink, so farming needs to achieve not zero but a big negative figure, and by 2030 not 2040. Labour’s rural policies are generally weak, and there are gaps in its rail and roadand energy plans. If it forms a government – minority or majority – it should invite the Greens’ Caroline Lucas to be environment secretary, importing the deep engagement it lacks. While I disagree on a couple of minor issues with the Greens, their manifesto sets the standard against which the others can be judged. The scope of the Lib Dems’ new thinking is one of the biggest surprises in this election. The new duty of environmental care it proposes for private and public bodies, its proposed zero-waste and nature acts, its suggestion of new taxes on frequent flyers, legal protection for public space and support for rewilding are all new and welcome. But there is still too much voluntarism: it urges but does not compel banks and corporations to reform their environmental standards. We cannot rely on market forces and corporate goodwill to defend us from catastrophe. We should vote for parties – in this case Green or Labour – that allow us to make collective decisions about our common interests, leading to democratic intervention. No one has the right to choose whether or not to destroy our lives. • George Monbiot is a Guardian columnist"
"The banded mongoose, a small social mammal of the African savannah, is known to be one of the most cooperative and helpful of all animals. They live across central and southern Africa in family groups of up to 28. Individuals routinely feed and protect the offspring of other group members, and when one of their own is threatened they gang up together to defend against attack from predators or a rival team of mongooses. But life is not all friendly cuddles between team-mates. Recent research shows these animals have a dark side. In the latest study of these mongooses, published recently in the Proceedings of the Royal Society B, researchers from the University of Exeter, Liverpool John Moores University and I show how competition between relatives can lead to mass evictions.  The drama ensues when the presence of greater numbers of offspring and younger siblings compromise the productivity – breeding success – of senior group members. Over a period of days, the happy family’s territory then becomes a chaotic battleground between relatives. The conflict is ultimately resolved by the older, dominant individuals evicting their younger team-mates en-masse. Shrieking battle cries accompany the civil war, with mothers and fathers chasing and wrestling their own daughters and sons, and elder brothers and sisters attacking their younger siblings. The tension is palpable, and the wounds can be bloody as well as psychological. The evictees do not want to leave and try to hang on in there, before surrendering and fleeing after days of sustained persecution. Eviction is not the only behaviour used to alleviate reproductive competition within groups of banded mongoose. Infanticide has been recorded, with adults killing the pups of fellow group-members, and there is also evidence that a female may abort gestating young during periods of stress, and that to do so increases the chance that she is not herself evicted. We must take care not to judge such behaviour within a human context, however. Eviction, infanticide and abortion may appear callous, but ultimately those mongooses that are evicted will usually go on to disperse successfully and found new groups with a refreshed gene pool (thanks to reduced inbreeding). This latest study shows the value of long-term research and collaboration. When I first arrived in Uganda’s Queen Elizabeth National Park back in 1996, to investigate these mongooses as part of a partnership between the University of Cambridge and the Uganda Wildlife Authority, I never imagined that these same mongooses would continue to be monitored by researchers over the subsequent two decades. We are now at a stage where today’s field researchers are following the great, great, great, great, great … offspring of the original group members. Such studies, monitoring the life history of multiple generations of individuals within populations, provide a remarkable insight into the evolutionary ecology of species, and tell us a great deal about how and why animals behave the way that they do.  I have spent much of my life as a behavioural ecologist studying cooperative animals, including banded mongooses but also chimpanzees, grey mouse lemurs, and even social spiders. Perhaps the most fascinating aspect of these societies is that while we observe cooperation on the outside, closer inspection often reveals that such apparent friendly helpfulness is underpinned by conflict and the threat of aggression. Sometimes your best friend can turn out to be your worst enemy."
"And another one bites the dust. The year 2014 was the warmest ever recorded by humans. Then 2015 was warmer still. January 2016 broke the record for the largest monthly temperature anomaly. Then came last month.  February didn’t break climate change records – it obliterated them. Regions of the Arctic were were more than 16℃ warmer than normal – whatever constitutes normal now. But what is really making people stand up and notice is that the surface of the Earth north of the equator was 2℃ warmer than pre-industrial temperatures. This was meant to be a line that must not be crossed. Two degrees was broadly interpreted as the temperature that could produce further, potentially runaway warming. You can think of it as a speed limit on our climate impact. But it’s not a target speed. If you are driving a car carrying a heavy load down a steep hill you’re often advised to change down from top gear and keep your speed low, as if you go too fast your brakes will fail and you will be unable to stop. Less braking means more speed which means less braking – a dangerous runaway feedback loop. Hopefully the hill flattens out and you have enough straight road ahead to recover. If you don’t then you will be stopping much more abruptly.  We are currently swamping the Earth’s ability to absorb greenhouse gases. 2015 saw the largest annual increase in carbon dioxide since records began – far higher than the Earth has experienced for hundreds of thousands of years.  More carbon dioxide in the atmosphere means higher temperatures. There is already one positive feedback loop in operation; the extra warming from our emissions is increasing the amount of water vapour in the atmosphere, which further increases temperatures. Fortunately, this is not a very strong feedback loop.  Unfortunately, there seem to be other, much more powerful ones lurking in the event of further warming. Tipping points such as the thaw of permafrost and release of the very powerful greenhouse gas methane in large quantities would drive world temperatures well beyond the 2℃ threshold.  Even if we came to our collective senses and rapidly reduced carbon emissions at that point, we would still have to revert to drastic geoengineering to rein in further warming. There is no guarantee that such climate brakes will work. If they fail, our civilisation would be on a collision course with a much hotter planet.  The safe–unsafe threshold of 2℃ recognises the significant amount of uncertainty there is over where dangerous warming really begins. It could be at more than 2℃. Hopefully it is. But it’s not impossible that it is less. We need to bear in mind that it was only the northern hemisphere that crossed the 2℃ line. Also, we need to factor in the monster El Niño that is having an effect on temperatures across the globe. In 2014, I predicted that 2015 would break record temperatures. This is not due to any psychic powers on my part, but the then very clear El Niño signal that was emerging.  So while temperature records may continue to be set for the rest of 2016, by the end of this year the situation should have cooled somewhat. Right? At times, it feels as if such statements are offered up as prayers in the hope that we are not in fact witnessing the beginning of abrupt and sustained climate change. But what’s even scarier is the political, economic and social reaction to these landmarks in climate change.  Have you heard any political speeches referring to these recent climate change records? Not one of the major Republican presidential candidates even “believes” in human-produced climate change, let alone that it is something to worry about.  How was the stock market this morning? It appears febrile enough to lurch from euphoric boom to catastrophic bust on the basis of bland statements from central bankers but proves remarkably deaf to evidence that the entire industrial and financial system is headed for disaster. Know what’s trending on Twitter as I write? A photoshopped giant dog, the latest Game of Thrones trailer and Kim Kardashian’s naked body. Actually, it’s mainly Kim Kardashian’s naked body and people’s responses to it. Followed by people’s responses to the responses.  It would be churlish of me to deny people the pleasure of looking at pictures of a photograph of a cuddly dog adjusted in order to make it appear both cute and monstrous. But we appear disinterested, either through denial or desensitisation, to the environmental changes happening right in front of our eyes. There are sure to be more climate records broken this year. But we treat them as we treat new fashions, phones or films. More novelty, newer features, more drama. We seem unable to understand that we are driving such changes. Record breaking changes that will ultimately break our civilisation, and so scatter all that we obsess and care about."
"I was five years old in 1997 when my mum took me with her to the polling station and let me scratch a wobbly X on the ballot paper. My main impression of the general election was it meant that I didn’t have to go to school that day, and that voting Labour had something to do with Mum buying the biggest watermelon I’d ever seen from the Turkish shop on the way home. More opaque was why she cried the next morning, or phoned her sister just to repeat “This is amazing … it’s just amazing” over and over. I think I understand her a bit better now. For a struggling single parent with two young kids, the end of 18 years of continuous Tory rule felt like being let out of a dark room.  Today, we’ve come through nine more such years. We’ve seen Grenfell; the Windrush scandal; £5bn of cuts to disability benefits; 4 million children at risk of malnutrition owing to poverty; a parliament of landlords voting against a measure that would ensure all homes were fit for human habitation; rough sleepers in Westminster evicted after a complaint by the Commons chaplain about their “ongoing stench”. The home secretary, Priti Patel, standing in a food bank, shifting the blame for growing poverty on to the local councils whose budget her government had cut. The last decade has seen our politicians turn into vandals, and a hatchet taken to the social contract. What we have witnessed is nothing less than, in the Italian theorist Franco Berardi’s words, “the slow cancellation of the future”. Austerity hasn’t just decimated our public services. It has corroded the political imagination. The suggestion that the government might exist to improve people’s lives rather than oversee the managed decline of our society is greeted as somehow preposterous. We’re told the things that we had in the past would be unreasonable to have in the future. Politicians who got their university education for free tell the young that tuition fees are simply a fact of life. The return to corporation tax to about 2010 levels is regarded as akin to Maoism. And Boris Johnson, who has been otherwise careful to avoid the miserable determinism of Theresa May’s 2017 campaign, fell back on the familiar bleat that there’s no way to “magic up” money for those who have borne the brunt of Conservative economic policy. Nowhere is our country’s atrophied capacity to imagine better more apparent than in the political class’s response to the climate emergency. Sure, Extinction Rebellion occasionally lurch into self-parody, but no amount of hippy-dippy nonsense could be more shameful than Adam Boulton’s tirade on Sky News this year in which he accused climate activists of being “the incompetent middle-class” and “self-indulgent”. That a broadcaster rumoured to be paid £400,000 a year can get away with calling others moneyed and out of touch has permanently damaged the part of my brain responsible for processing irony. There’s something fairly insane about a media culture that praises Michael Gove as an environmentalist hero for using a reusable cup while simultaneously delegitimising protest movements associated with climate justice. Aided and abetted by a supine media, the government has been allowed to miss a six-month deadline set by parliament to address the climate emergency. We are already on course to miss the dreadfully unambitious target set by May to reach net-zero carbon emissions by 2050. And despite large swathes of South Yorkshire still being under floodwater, Brexit continues to be trotted out by broadcasters as the defining issue of this election.  There are problems with the Labour party. They have not committed to preserving freedom of movement in all circumstances; they have stuck with a prohibitionist approach to drugs; they have not stamped out antisemitism as ruthlessly as they ought to. But I will not let perfect be the enemy of hope. At its heart, the Jeremy Corbyn project represents the return of the future. In 1963, Harold Wilson promised that a “new Britain” would be forged in “the white heat of technology”. Now Labour vows that a green industrial revolution will bring in hundreds of thousands of jobs in renewable energy, green construction and transport infrastructure. How could we possibly afford to do all this? How could we possibly afford not to? What could be more urgent than securing a sustainable future on the only planet we have to live on? Somehow money always turned up when we needed to bail out the banks or pay for no-deal posturing, keep May in power with a bung for the DUP, or clean up after Chris Grayling. It gets harder to believe that “there is no alternative” to economic misery when, quite clearly, there is when the Tories need it. What’s at stake in this election? The future, and the possibility of its return. • Ash Sarkar is a senior editor at Novara Media, and lectures in political theory at the Sandberg Instituut"
"
Share this...FacebookTwitterWater shortages at Lake Baikal: climate activists ignore important climate cycles
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
[Translated, edited by P. Gosselin]
Not long ago we corresponded with the Helmholtz Asscoiation over a somewhat botched article about Lake Baikal. They simply assumed that the climate at the lake had been constant before industrialization – a fatal flaw.
On May 6, 2015 the activist groups of 350.org and Global Voices followed and committed similar flaws when they misinterpreted the current climate changes as “unique” and as “something that had never occurred before“. At Global Voices we read [translated from the German]:
According to experts, climate change is the cause of Russia’s shrinking Lake Baikal.
[…] The Russian Minister had clear words for the drop in the water level: ‘The climate’. So what on earth has happened with the climate? Experts assume that precipitation amounts in the Baikal region fluctuate in cycles of several decades. What is now happening, however, is clearly out of the pattern of normal variation. At the end of March the water level for example fell 9 cm below the critical value. Such a water shortage has not been observed in over 100 years. According to the Ministry for Catastrophe Protection, the water amount finding its way into the lake in the summer and fall of 2014 was only 65% of the climatic normal. The drying of Lake Baikal is taking place within the backdrop of a dramatic climate change in Russia: According to the Rosgidromet Meteorological Center, the rise in the mean temperature occurred here 2.5 times faster than it has globally. Climate change is leading to a rapid rise in the frequency of natural catastrophes, including drought.”
It’s nice to see that activists are at least recognizing precipitation cycles on a decadal scale. However they fail to take the longer term hundred-year or millennial cycles into account. The lowest lake water level in the last 100 years? That is only a tenth of a 1000-year cycle that is clearly described in the literature. See: “Study by the University of Alberta: 1000-year climate cycles triggered by solar activity fluctuations“ or “Climate at Lake Baikal pulsed in sync with the sun over the past 5000 years“.
In January, 2015, Sputnik News discussed the reasons for the water shortage. In addition to a pronounced drought in the previous year, also the hydropower plant removed too much water from the lake:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Over the past twelve months the lake water has dropped a record 40 cm to a sixty-year low — just shy of the critical mark of 456m. Some experts blame this on the local energy companies, but officials and biologists attribute the drop to last year’s drought.”
No word on this at 350.org/Global Voices. Instead they prefer to dramatize the warming of the past 70 years:
Lake Baikal is indeed warming. According to a study published already in 2008, the temperature of the surface water of Lake Baikal has risen already 1.21°C since 1946.”
Why do the activists cite a study from 2008 when there is more up-to-date data available that extends to today? Why the seven-year omission? We want to know more about this and so we look at the Lake Baikal GISS temperature record for the past 130 years at New Scientist:

The answer: In 2007 there was an extreme warm peak that obviously some people wanted to fully use in the statistic. In truth the temperatures have been falling again at Lake Baikal since 2004, measured with the 5-year running mean. In principle temperatures at Lake Baikal already have stagnated since 1988. Moreover the activists failed to mention that 1000 years ago, during the Medieval Warm Period, Lake Baikal was once similarly warm as it is today, perhaps with similar warming spells during the transition phase.
Share this...FacebookTwitter "
"Venezuela is sinking ever deeper into a political and economic calamity. Inflation is above 700% and GDP is more than a third below 2013 levels. The country with the world’s largest proven oil reserves is now the world’s most indebted country – no other nation has a larger public external debt as a share of GDP or of exports. Living standards have truly collapsed. Many factors have contributed to Venezuela’s current crisis including mismanagement of oil wealth by former president Hugo Chavez and the current leader, Nicolás Maduro, and criminality, lawlessness and the black market. While all of these have undoubtedly had a part to play, the falling price of oil is the most significant factor. However the connection between this and an economic crisis in South America is not as obvious. What’s going on in Venezuela is the unintended consequence of Saudi Arabia’s policy of keeping oil prices deliberately low for political reasons. The price of oil, as with any other commodity, is regulated through supply and demand. When there is an oil surplus, or a reduction in demand, the price will fall.  At the start of 2014 the global supply and demand for oil was fairly balanced, at around 92m barrels a day. But production started to escalate thereafter, and by late 2015 the average daily supply reached 97m barrels, more than a million barrels per day ahead of demand. This surplus caused a sharp drop in the price of oil. Part of this increase in supply was from American shale oil, extracted through fracking, but mostly it was the result of the Saudis deliberately pumping large amounts of oil for political reasons. As the only oil-producing country with sufficient reserves to regulate the market in this way, Saudi Arabia is considered the “swing producer”. Even though US shale production has reduced some of the Saudis’s swing power, the oil kingdom has still the capacity to produce more than it does currently and is therefore still very much capable of crashing the market.   It seems the Saudis are trying to achieve two aims. The first is to drive US shale producers out of business and consolidate the Gulf state’s leading role in global oil. Producing oil from shale via fracking is expensive, around US$60 a barrel, while the cost of natural oil is no higher than US$7 a barrel. Saudi Arabia hopes the drastic decrease in oil prices, to well below US$60 a barrel, will make it unprofitable for American shale producers to drill at their current rates. The second aim is to destroy the economy of Iran, the Saudi kingdom’s main competitor in the Middle East. This would thus limit Tehran’s ability to continue funnelling hundreds of millions each year to the Syrian regime, and Shia militias in Iraq, Yemen and elsewhere.  Oil markets have always been at the heart of the Saudi-Iranian struggle for regional hegemony. Back in 1977, when Iran was planning extensive nuclear power plants and envisaging the spread of its influence throughout the Middle East, the Saudi regime swamped the markets, expanding oil production from 8m to almost 12m barrels a day, sharply cutting the oil prices.  Iran watched billions of dollars in anticipated oil revenues vanish, and the Shah was forced to abandon his plans for nuclear investment. Manufacturing collapsed, inflation skyrocketed, unemployment rose steeply – and before long economic troubles had destroyed all support for the Iranian monarchy. The rest is history: the regime collapsed in two years and was replaced by Ayatollah Khomeini’s Islamic republic. It seems, after some hesitation and discussions in the early part of 2014, Saudi Arabia launched this oil price war in tandem with the US. America supported the policy as it wanted to undermine the influence of oil-dependent Russia, something it apparently considered more important than supporting its own fracking sector, while access to cheap imported oil is good news for US consumers and industry in general. Whether or not there was a clearly planned and agreed strategy, there seems to be an unmistakable convergence of interests between the Saudi and US positions. This strategy of keeping the price of oil down has not necessarily destroyed either the Russian or Iranian economies however. Instead, the hardest hit oil-producing nations are in South America and Africa, where petro-states such as Libya, Angola, and Nigeria are suffering.   But the worst affected country of all is Venezuela, the most disastrously oil-dependent state in the world. Oil accounts for 96% of exports and more than 40% of government revenues. It is still unclear whether the Saudi-US oil price strategy will ever achieve its main goal of crushing Russian and Iranian power and influence. But one thing is clear: the world oil market will continue to be extremely volatile, and smaller, less powerful nations will continue to be caught up in the wider battle. This article was amended on August 10 to more accurately reflect the status of global oil supplies before 2014. Supply was not “constant at around 80m barrels a day” but instead grew steadily throughout the previous five years."
"
Share this...FacebookTwitterWhat About Climate Change?
By Ed Caryl
In last week’s on-line issue of the Georgia Tech Alumni Magazine (Volume 90, Number 4), Judith Curry and Kim Cobb contributed their thoughts on the issue of climate change in two short essays.
Photo: Kim Cobb; source: Georgia Tech.
These essays were obviously intended to oppose each other. As one would expect, Ms. Curry wrote a low-key, well reasoned opinion piece urging caution and a measured approach to a more efficient use of our energy resources. She emphasized the considerable uncertainty in climate science:
The climate has always changed and will continue to change. […]
There is growing evidence that the climate is less sensitive to adding greenhouse gases than has been predicted by climate models.  Solar variability, volcanic eruptions and long-term ocean oscillations will continue to be sources of unpredictable climate surprises.”
On the other hand, Ms. Cobb has NO doubt that disaster is at hand, and dismisses those who disagree with a wave of the hand. For example:
Nobody with any knowledge on the subject denies that carbon dioxide (CO2) derived from the burning of fossil fuels is measurably warming the planet.”
“Measurably”? Ms. Cobb, could you share that measure with us? Even the IPCC can’t decide this measure plus or minus 100%. That isn’t a measure! That is a wildly adventurous guess.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




As Judith Curry implies, the measure of climate sensitivity is declining almost with each new paper on the subject. Even the IPCC acknowledges that. Studies based on data place climate sensitivity somewhere between zero and one degree. Only papers based on models put the number higher, all with huge uncertainty ranges. KC says:
Nobody denies that the risks of climate change will accelerate as greenhouse gas emissions accelerate.”
To that breath-taking statement I have a question. What are the “risks” of climate change? So far, those risks seem to be fewer hurricanes, fewer tornados, warmer winters, longer growing seasons, enhanced crop growth due to higher CO2 levels, and warmer nights due to urban heat islands. Those “risks” will also accelerate IF emissions accelerate. Emissions from the US and the EU are falling along with their economies. Emissions are rising and will rise in the developing countries as they pull their citizens out of energy poverty. Both the drivers of increased emissions and the chief “risks” all seem good things. Reduced emissions often result in bad things.
The down-side seems restricted to sea-level rise. For most of the world, subsidence and uplift govern local sea level and these factors have nothing to do with climate change. For the rest, if we judge from the past, 17 cm of sea level rise in the next 100 years should not be a big problem. For island nations, coral growth easily keeps pace. Cobb claims:
And nobody denies that, given the long lifetime of CO2 in the atmosphere, the climatic response of our current emissions will play out over the lifetimes of our children and our grandchildren. They will inherit our generation’s climate debt, and its accrued interest, potentially in the form of irreversible impacts.”
“Long lifetime”? I wonder if she is as worried about the national debt? Each year only about half of the human carbon emissions remain in the atmosphere. This is called the CO2 “airborne fraction”. In the long term this fraction is falling (See Figure 3 in this link) as emissions increase, because the biosphere is greening and pulling out increasing amounts of CO2. With CO2 “half-life” at one year, if global emissions decrease, within a few years CO2 content in the atmosphere would begin falling. Then those “irreversible” positive impacts that I describe in my previous paragraph would begin to disappear. According to Cobb:
It is equally likely that future impacts will be less than or greater than those projected by climate models.”
Ms. Cobb has evidently not seen a comparison of the climate models and data. So far, 95% of the models are running too hot compared to real measurements. This is obviously not “equally likely”. The models have failed to predict reality, and will continue to fail because they are written with an over-estimation of warming due to CO2. Future impacts will be far less than the climate models indicate.
Ms. Cobb is an alarmist. All her opinions are biased by that alarm. Her lack of skepticism makes her resemble more an end-of-world preacher rather than a thoughtful scientist.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
The online North German NWZ daily here has an article on a speech given by University of Konstanz physics professor Dr. Gerd Ganteför on the subject of Germany’s transition to renewable energies, the so-called Energiewende, and on the general irrationalities pervading German climate science.
He says that the country appears to have “a desire for demise“.
In a presentation called “The Energiewende – Vision and Reality“, he reminded the audience of earlier end-of-world scenarios that never materialized, such as “the end of oil, forest die-off from acid rain, ozone hole”. He thinks that the German population “can be convinced of anything, ‘as long as it’s bad!‘” the NWZ reports.
Ice age approaching
Ganteför told the audience that the climate is going to change anyway even without the influence of man. And on a millennial scale: “The current warm phase will end at that we are approaching a new ice age.” He also told the audience that eliminating light bulbs and using smaller vacuum cleaners are not going to rescue any climate whatsoever.
Energiewende will fail


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So far in Ganteför’s view the Energiewende has been limited only to a transition in the electricity supply and that this will fail due to the lack of storage technology.
Removed from scientific fact
The NWZ also writes that Ganteför “criticizes the ‘false fear’ in the public discussion: Germany has become far too removed from the scientific facts and is too caught up in the current zeitgeist: ‘Indeed we are all going to die, but not because of the climate catastrophe,’ was his prediction at the end.”
Photo credit: http://www.faszinationphysik.ch/.
Gerd Ganteför is also the author of the German language books: Climate, the demise of the world is not taking place and Is everything NANO or what?: Nanotechnology for the curious.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNASA has an interview with James Hansen (still) up at its site here.
Here we see that “surface air temperature” (0 to 50 feet) is not even yet defined, let alone can it be determined. This does not only present lots of uncertainty in its determination, but also plenty of opportunity for measurement and interpretation mischief. Hat/tip: Reader Dennis.
Here The NASA interview (my emphases added):
==================================

GISS Surface Temperature Analysis
The Elusive Absolute Surface Air Temperature (SAT)
The GISTEMP analysis concerns only temperature anomalies, not absolute temperature. Temperature anomalies are computed relative to the base period 1951-1980. The reason to work with anomalies, rather than absolute temperature is that absolute temperature varies markedly in short distances, while monthly or annual temperature anomalies are representative of a much larger region. Indeed, we have shown (Hansen and Lebedeff, 1987) that temperature anomalies are strongly correlated out to distances of the order of 1000 km.
Q. What exactly do we mean by SAT ?
A. I doubt that there is a general agreement how to answer this question. Even at the same location, the temperature near the ground may be very different from the temperature 5 ft above the ground and different again from 10 ft or 50 ft above the ground. Particularly in the presence of vegetation (say in a rain forest), the temperature above the vegetation may be very different from the temperature below the top of the vegetation. A reasonable suggestion might be to use the average temperature of the first 50 ft of air either above ground or above the top of the vegetation. To measure SAT we have to agree on what it is and, as far as I know, no such standard has been suggested or generally adopted. Even if the 50 ft standard were adopted, I cannot imagine that a weather station would build a 50 ft stack of thermometers to be able to find the true SAT at its location.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Q. What do we mean by daily mean SAT ?
A. Again, there is no universally accepted correct answer. Should we note the temperature every 6 hours and report the mean, should we do it every 2 hours, hourly, have a machine record it every second, or simply take the average of the highest and lowest temperature of the day ? On some days the various methods may lead to drastically different results.
Q. What SAT do the local media report?
A. The media report the reading of 1 particular thermometer of a nearby weather station. This temperature may be very different from the true SAT even at that location and has certainly nothing to do with the true regional SAT. To measure the true regional SAT, we would have to use many 50 ft stacks of thermometers distributed evenly over the whole region, an obvious practical impossibility.
Q. If the reported SATs are not the true SATs, why are they still useful ?
A. The reported temperature is truly meaningful only to a person who happens to visit the weather station at the precise moment when the reported temperature is measured, in other words, to nobody. However, in addition to the SAT the reports usually also mention whether the current temperature is unusually high or unusually low, how much it differs from the normal temperature, and that information (the anomaly) is meaningful for the whole region. Also, if we hear a temperature (say 70°F), we instinctively translate it into hot or cold, but our translation key depends on the season and region, the same temperature may be ‘hot’ in winter and ‘cold’ in July, since by ‘hot’ we always mean ‘hotter than normal’, i.e. we all translate absolute temperatures automatically into anomalies whether we are aware of it or not.
Q. If SATs cannot be measured, how are SAT maps created?
A. This can only be done with the help of computer models, the same models that are used to create the daily weather forecasts. We may start out the model with the few observed data that are available and fill in the rest with guesses (also called extrapolations) and then let the model run long enough so that the initial guesses no longer matter, but not too long in order to avoid that the inaccuracies of the model become relevant. This may be done starting from conditions from many years, so that the average (called a ‘climatology’) hopefully represents a typical map for the particular month or day of the year.
Q. What do I do if I need absolute SATs, not anomalies ?
A. In 99.9% of the cases you’ll find that anomalies are exactly what you need, not absolute temperatures. In the remaining cases, you have to pick one of the available climatologies and add the anomalies (with respect to the proper base period) to it. For the global mean, the most trusted models produce a value of roughly 14°C, i.e. 57.2°F, but it may easily be anywhere between 56 and 58°F and regionally, let alone locally, the situation is even worse.
Return to GISTEMP page.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIt’s clear: none of the intended aims were reached during the two-week UN mega climate conference in Lima.
Some baby steps were made. And of course they are being sold to the public as important progress on the road to a binding treaty in Paris next year. No one believes it.
What was achieved, unfortunately, were some real tangible and permanently visible negative results: 1) another huge junket bill for the taxpayers, 2) one large carbon footprint from the hundreds of international flights, and 3) worst of all, one forever-ruined historical treasure, the Peruvian Nazca lines – all thanks to the IPCC emboldened environmental activist group, Greenpeace.

Lima’s permanent result: a trampled, ruined Peruvian historical treasure during a Greenpeace publicity stunt. Image: Greenpeace. 
That’s the sorrowful result of this year’s climate conference. And no other has gone down as having been more destructive as this one. The ruin of the more than 2000 year old Nazca lines site was the icing on the IPCC cake.
Politically Lima finished with the same familiar result as usual – for the 20th time. The tens of billions of dollars that the UN and the IPCC have wasted on the climate issue, which is now unraveling as a grand hoax, could have done a heck of a lot more good for the environment had the money been invested directly in environmental protection technologies for smokestacks, clean water supplies, sanitation, medicine, and education in the third world. Instead, all the money is gone and the useless climate circus continues on its global tour.
The UN has failed miserably, abjectly. It’s time to disband the IPCC. The UN’s leadership performance and its trail of destruction, all punctuated by the Nazca lines, are an international civic disgrace that needs to be ended for good.
Regarding results on a climate treaty, they were almost non-existent. As I predicted here yesterday, the only result was an illusionary agreement with lots of intentions and back doors. Twenty conferences should be enough to tell any sane person that this is all a cynical charade by parasitic bureaucrats.
German Federal Environment Minister Barbara Hendricks, obviously fed up with the conference, left already on Friday.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




WWF official Regine Gunther said: “The Lima Conference was a waste of time and energy.”
On the climate treaty results of the Lima Conference, what follows are some reactions from the German language media.
Axel Bojanowski at Spiegel:
Thus the Lima Conference failed to reach its decisive target: Actually a precise outline of a world climate treaty was supposed to be drawn up. It was supposed to become clear which measures could lead to a peak in CO2 emissions by the year 2030.”
The Austrian Der Standard writes:
The 195 countries agreed on a final text in Lima during the night into Sunday. It defined only vague criteria for national climate commitments, which are to be introduced in the Spring of 2015. Environmental groups spoke of a ‘dangerously weak text’.”
The Swiss Tagesanzeiger:
Climate conference with only a minimal target
The treaty countries have produced a document of about 40 pages that contain all the important elements that an effective climate treaty needs. However the document contains a long series of options that will lead to days of debate. At the forefront of the conflict points fairness, new order and trust, everything is indeed open as to whether or not an acceptable treaty will be reached in Paris.
 
Share this...FacebookTwitter "
"The climate crisis is poised to deliver a severe blow to America’s most threatened animals, with a new study finding that almost every species considered endangered is vulnerable in some way to global heating. Of the 459 animal species listed as endangered by the US government, researchers found that all but one, or 99.8%, have characteristics that will make it difficult for them to adapt to rising temperatures. An array of threats faces these species. The California condor, once close to being completely wiped out, faces increased risk of contamination in hotter conditions. Key deer, found only in the Florida Keys, face losing habitat to the rising seas. Whole classes of animals including amphibians, mollusks and arthropods are sensitive to the greatest number of climate-related threats, such as changes in water quality, shifting seasons and harmful invasive species that move in as temperatures climb. Mammals, such as the north Atlantic right whale and Florida panther, also face increased hardships, albeit on fewer fronts than amphibians, mollusks and arthropods. Despite the overwhelming peril faced by America’s endangered species due to the climate crisis, the report, published in Nature Climate Change, found a patchy response from the US government. Federal agencies consider just 64% of endangered species to be threatened by the climate crisis, while just 18% of listed species have protection plans in place. “This study confirms that the climate crisis could make it even harder for nearly all of our country’s endangered species to avoid extinction,” said Astrid Caldas, a study co-author and a climate scientist at the Union of Concerned Scientists. “While agencies have increasingly listed climate change as a growing threat to species whose survival is already precarious, many have not translated this concern into tangible actions, meaning a significant protection gap still exists.” Aimee Delach, senior policy analyst for climate adaptation at Defenders of Wildlife and Caldas’s co-author, said the Trump administration’s decision to weaken its interpretation of the Endangered Species Act was “disastrous” and likely to further slow down the response to climate threats. In May, a landmark UN report warned that 1 million species around the world were at risk of extinction, with global heating one of the main pressure points on biodiversity. This year a small brown rat called the Bramble Cay melomys, which lived on a small island off northern Australia, became the first mammal known to have become extinct due to human-driven climate change. Nearly half of Australian species are threatened by the climate crisis, researchers have found. A spokesman for the US Fish and Wildlife Service, which oversees the endangered species list, said that while a species may be sensitive to changes in the climate, this sensitivity may not be so severe as to warrant being put on the list. “Our process for determining this looks at five factors: threats to a species’ habitat, overutilization, disease or predation, existing regulatory mechanisms, and other factors that may affect its continued existence,” he said. “Through this scientifically rigorous process we examine and account for the effects of climate change.”"
"By 2050, two thirds of the world’s population will live in an urban area. Until recently, we knew little about how wild animals were coping with the growth of all those towns and cities. The field of urban wildlife ecology has since emerged to fill this gap. Urban ecologists have found some species, like Britain’s hedgehogs, have struggled to cope. But other species, often called “synurbic”, have proven themselves very adaptable and, in some cases, they can actually live at higher densities in cities.  One species capable of modern urban living is the red squirrel. Understanding how they behave in towns and cities, a topic that is relatively unexplored, could help their long-term conservation. Red squirrels are found in cities right across mainland Europe, for example in Finland, France, and Poland. It is likely they were once also found in many UK towns too. However, Britain’s native squirrel is now a very rare sight, thanks to decades of habitat loss and the introduction of the larger and more competitive grey squirrel from North America. But one town where the reds haven’t disappeared is Formby, in Merseyside, the study site for my PhD researching the urban ecology of red squirrels. Formby is one of few red squirrel strongholds in England and one of the only remaining urban areas where they can be found at all.  Red squirrels can easily be spotted in gardens throughout the town. Local residents are passionate about protecting their unusual wildlife, with many of them providing supplemental food and volunteering locally with conservation organisations. These organisations manage the extensive woodland to the west of the town, where they supply additional food themselves, and employ dedicated “squirrel officers” who help maintain “grey squirrel-free” habitats. In addition to the woodland, the town itself contains ideal habitat, with hedgerows and trees lining the roads and gardens, which provide corridors for the squirrels to move through. Urban areas also typically have fewer natural predators, such as buzzards. Unfortunately, invasive grey squirrels like all these things too and, given the chance, they would colonise the town and displace the reds. However, a combination of grey squirrel control (including protection from their advances on one side by the sea), supplemental feeding, suitable urban green spaces, and careful monitoring by volunteers and rangers have meant that the reds have clung on in Formby, despite greys replacing them elsewhere in the UK.  The longer-term strategy is to manage the area in favour of the reds. This could involve, for example, planting trees which the reds can easily exploit but the greys are less able to, like native conifers and small-seeded broadleaved trees such as birch or ash. Greys instead prefer large-seeded broadleaves, such as oak and beech. However, there are downsides to living alongside people. For instance, several studies have flagged road traffic as the biggest cause of squirrel mortality. Despite fewer natural predators, there are higher numbers of pets, such as cats and dogs, that can injure and even kill squirrels. In addition, some of the trees in the town may be gradually lost as residents landscape their gardens, further fragmenting the remaining habitat. Even the widespread supplemental feeding could have hidden negative consequences. In Formby, well-meaning residents provide lots of peanuts: one of the squirrels’ favourite foods. Unfortunately, peanuts are low in calcium and alone do not give the required nutrition that a squirrel needs.  If feeders are not cleaned thoroughly and regularly, this could also contribute to another outbreak of squirrelpox virus or other diseases. This suggests that residents, who are enthusiastic about feeding the squirrels (and should continue to do so), perhaps need to be provided with more information, such as on what to supply for a varied diet. Much of the research and conservation of red squirrels in the UK is carried out in more rural areas, such as Kielder Forest in Cumbria, often along the interface with the invasive grey squirrel. However, managing urban sites for the benefit of the native reds could be a useful alternative conservation tool, through making the most of the benefits of living alongside people.  For example, local volunteers could act as a free and dedicated workforce for conserving and monitoring the red squirrels, as is the case in Formby. This could be employed in the nearby towns, or even elsewhere in Britain near squirrel strongholds, to hopefully encourage the reds to disperse and reoccupy areas as they become free from greys. This is currently occurring in Wales, with reds crossing over from the island of Anglesey onto the mainland as rangers remove greys from the area around nearby Bangor. An urban management plan could also create the opportunity to develop more green spaces and wildlife-friendly gardens. This would benefit all of the local biodiversity, not only squirrels, as well as the people. This is what my research aims to explore over the next few years: how have red squirrels adapted to urban life, and how do the associated resources and risks affect their ecology. By understanding this, we can hopefully develop a strategy to better protect this charming native species."
"As a millennial, a university student and a human, I thank you, Guardian, for your 2019 environmental pledge (It’s time to act, 17 October). Yours is a news outlet that many of my generation are sharing all over social media. You speak the truths we speak and believe in. We young people sometimes feel unheard and brushed away or simply ignored when we speak our minds. So thank you for pledging to use language that recognises the severity of the crisis we’re in; it is something that is rarely done. With the current fires surging through our precious lands, it is a time of stress, loss and sadness, and one that we are not accustomed to. We are angry. Listen to our generation more, hear our voices and follow our movements. We are the future, after all; one day everyone will have to listen, so why not start now.Courtney LucasTarragindi, Queensland, Australia"
"
Share this...FacebookTwitterSpiegel science journalist Axel Bojanowski interviews Oliver Geden, climate expert at the Berlin-based German Institute for International and Security Affairs – SWP. He is also an advisor to the German government. 
2°C target “an illusion”
In the interview Geden calls the 2°C limit target “an illusion that has been fed by politicians and scientists“.
Geden tells Spiegel that scientists and politicians have calculated how much CO2 is allowed to be added to the earth’s atmosphere before the temperature climbs 2°C, but that they have dithered and dallied so much that theoretically no more CO2 emssions will be allowed globally by the year 2044. Thus the 2°C target is already a grand pipe dream.
“Very dubious” CO2 accounting tricks
In the interview Geden believes Paris will fall far short of what is necessary to reach the theoretical 2°C target, and
As a result the climate negotiators will use many calculation tricks which I think are very dubious.”
He expects policymakers to use tricks like “negative” future emissions from CCS technology, or growing trees. However Geden, a warmist and promoter of ending fossil fuels, calls negative emissions in the interview “political science fiction“.
Geden tells Spiegel that 500 million hectares of forests would have to added to the globe, an area equivalent to one and half times India!
Many developing countries would go into resistance if we demanded they stop using the land for food and to grow trees for stroring CO2 instead.”
The negative emissions calculations being put forth are in fact now so out of touch that Geden sarcastically tells Spiegel:
Scientists might as well just assume in 2070 green martians will land on earth as rescuers and suck the CO2 out of the atmosphere.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Climate science reputation damaged
Bojanowski then asks Geden if all the carbon accounting tricks are hurting the reputation of climate science. Geden confirms that it is, reminding us that:
Five or six years ago it was consensus that greenhouse gas reductions of three percent annually were not realistic. But then emissions rose like never before – and suddenly the IPCC claims that six percent is doable. Precisely in a phase when CO2 emissions are rising liker never before the optimism is suddenly growing that drastic savings are possible. All this just to keep the 2°C story alive.”
Geden adds that scientists are forced to play along with the nonsense because they see the risk of getting less research funding.
The tendency is that those who supply the policymakers with the desired studies and models are better off.”
Science hubris
Geden also points out that “many climate scientists are idealists who wish to rescue the planet;..”
He believes that many scientists are suffering from “hubris” and actually “believe that the earth’s system is controllable“. He slams Hans-Joachim Schellnhuber’s WBGU which in 2011 “proposed a Great Transformation of Global Society to combat global warming”.
It was the first work since the fall of communism that called for the restructuring of the entire world according to a plan.”
Science being “led around “by the nose”
Joachim Müller-Jung at Germany’s flagship Frankfurter Allgemeine Zeitung (FAZ) writes a commentary on the “political fever” that has swept through the science community as the Paris Conference approaches. 
Müller-Jung writes that “science is allowing itself to be led around by the nose by politicians and economists.”
Müller-Jung describes the 2°C limit as “utopian”.
Share this...FacebookTwitter "
"After fears the Loch Ness Monster had “disappeared” last winter, a new sighting in May 2017 was celebrated by its enthusiasts. The search for monsters and mythical creatures (or “cryptids”) such as Nessie, the Yeti or Bigfoot is known as “cryptozoology”.  On the face of it, cryptozoology has little in common with mainstream conservation. First, it is widely held to be a “pseudoscience”, because it does not follow the scientific methods so central to conservation biology. Many conservation scientists would find the idea of being identified with monsters and monster-hunters embarrassing.  Moreover, in the context of the global collapse in biodiversity, conservationists focus their attentions on protecting the countless endangered species that we know about. Why waste time thinking about unknown or hypothesised creatures? Most people are rightly sceptical of sightings of anomalous primates or plesiosaurs in densely populated regions that have been surveyed for hundreds of years. However, while there are strong ecological and evidence-based reasons to doubt the existence of charismatic cryptids such as Nessie and Bigfoot, conservationists should not automatically dismiss enthusiastic searches for “hidden” species. In fact, cryptozoology can contribute to conservation in several ways.  Firstly, the process of mapping out the world’s species is far from finished. Conservationists aim to protect and preserve known plants and animals – but it is not always appreciated how many remain “undescribed” by scientists. Since 1993, more than 400 new mammals have been identified, many in areas undergoing rapid habitat destruction. The number of undescribed beetles, for example, or flies, let alone microscopic organisms, will be huge. We are entering a new age of discovery in biology with descriptions of new species reaching rates comparable to the golden era of global exploration and collection in the 18th and 19th centuries. The advent of methods such as DNA barcoding offer the possibility of automated species identification.  A recent mathematical model predicted that at least 160 land mammal species and 3,050 amphibian species remain to be discovered and described. Other predictions suggest that a large proportion of undescribed species will go extinct without ever being recorded or conserved at all – a phenomenon we might term “crypto-extinction”.  The father of cryptozoology, Bernard Heuvelmans, argued that “the great days of zoology are not done”. In the sense that so many species remain undiscovered, he was correct. The main principle behind cryptozoology is soundly zoological: species exist that humans have not discovered or described. The quest to locate and protect the world’s biodiversity is one that conservation and cryptozoology share, even if cryptozoologists tend to focus their attentions on the large, mythical and monstrous, over the small, plausible, and non-mammalian species in our midst. Cryptozoology involves rampant speculation and unconventional surveying methods. But controversial new “findings” can inspire a renewed quest to better map out the natural world. This was the case with the cryptid spiral-horned ox, never seen by a scientist in the flesh and known only from a few horns found in a market in Vietnam. The debate between rival camps of zoologists about whether the ox existed pulled together historic accounts, local folklore, and samples of museum specimens – all classic cryptozoological methodologies. The second reason why conservationists should not automatically discount cryptozoology is its shared history, co-evolving with conservation in the 20th century and interesting many conservationists along the way.  One notable connecting thread comes through Peter Scott, the founder of the World Wildlife Fund and creator of the Red Data Book method of classifying endangered species. Scott first grew interested in Loch Ness Monster reports in 1960 and in the same year wrote to Queen Elizabeth offering to name the – undiscovered – cryptid Elizabethia nessiae in her honour. Although the Queen was said to be “very interested”, her advisers wrote back saying it would be inappropriate to attach her name to something viewed as a monster or likely to be a hoax.  In an infamous article in Nature in 1975 Scott published underwater photographs appearing to show a creature with a diamond-shaped flipper. Scott and his co-author, the American Nessie enthusiast Robert Rines, named the creature Nessiteras rhombopteryx with the intention that it could then be preemptively protected under the Conservation of Wild Creatures and Wild Plants Act (1975). Although he knew that grainy photographs were insufficient taxonomic evidence in the long term, Scott argued “the procedure seems justified by the urgency of comprehensive conservation”. For Scott, conservation was at the heart of the hunt for Nessie. Scott was not the only curious conservationist. In his book Searching for Sasquatch, Brian Segal examines several other mainstream conservationists who grew interested in cryptozoological ideas and endeavours. More recently, when specimens of a species named Homo floresiensis were found on the island of Flores in Indonesia in 2003, Henry Gee, an editor at Nature, wrote:   If animals as large as oxen can remain hidden into an era when we would expect that scientists had rustled every tree and bush in search of new forms of life, there is no reason why the same should not apply to new species of large primate, including members of the human family. Given conservation’s haunting relationship with the problem of absence, is it time to bring cryptozoology, in some form at least, in from the cold? A rapprochement would demand changes on both sides. Cryptozoology’s appeal currently comes from its celebration of the anomalous and monstrous. A “post-monstrous” outlook might aid in forging new coalitions, and a stronger focus on plausible undiscovered species (such as the thousands of smaller amphibians and mammals predicted to exist) than on charismatic, but highly unlikely, cryptids.   The third way that cryptozoology can contribute to conservation is through the sense of wonder. From the conservation perspective, something might be learned from the Nessie and Bigfoot hunters about telling new stories of weird and wonderful discoveries alongside the more familiar tales of flagship species decline.  Instead of rebuffing them, conservationists might consider enlisting cryptozoologists as part of a wonder zoology that accelerates conventional taxonomic efforts. Indeed, the EDGE of Existence conservation initiative is doing exactly this by focusing its attention on “weird” endangered species.  Other examples of wonder zoology include the descriptions of new (although known to local people) primates by Marc van Roosmalen in the Amazon, and the “lost world” of new species found in or near Vietnam’s Vu Quang Nature Reserve in the 1990s. One promising model of how conservationists and cryptozoologists might engage is sketched out by the paleozoologist Darren Naish. Naish’s “sceptical cryptozoology” does not dwell on the question of whether cryptozoology is pseudoscientific or not but focuses instead on the ground it shares with conventional zoology. Stories of the discovery and rediscovery of species routinely punctuate the depressing catalogue of extinction after extinction. Wonder and speculation – however untethered – must play a role in energising conservation actions.  Although no one expects conservation NGOs to start searching for Bigfoot, it would be remiss of them to ignore the powerful ecological imagination that can be inspired by cryptozoology."
"
Share this...FacebookTwitterBy Dennis Ambler and Pierre Gosselin
Few institutes have been as adamant and dogmatic about man-made global warming as the Potsdam Institute for Climate Impact Research (PIK), headed by German climate doomsday professor, Herr Professor-Doktor Hans-Joachim Schellnhuber.

German climate doomsday professor Hans Schellnhuber forced to postpone climate doomsday scenarios due to natural factors, but insists warming is still happening, and it will be worse – at a later time in the future. Photo: PIK
The institute has long maintained that the science was settled, and was instrumental in formulating a master-plan for re-organizing global society and watering down democracy in order to avert the modeled disaster. Their master-plan calls for allotting more power to an elite group of “visionary” scientists – like to Herr Doktor Schellnhuber himself.
So today it’s all the more surprising that they are announcing a paper that concedes natural factors indeed are more powerful than the 0.01% CO2 atmospheric concentration added in part by humans over the last 150 years. This is a milestone for the PIK, which earlier claimed they could not find any real evidence of other factors driving the climate.
Their press release writes (emphasis added):
So far it seemed there were hardly any major natural temperature fluctuations in Antarctica, so almost every rise in temperature was attributed to human influence,” says Armin Bunde of Justus-Liebig-Universität Gießen (JLU). ‘Global warming as a result of our greenhouse gas emissions from burning fossil fuels is a fact. However, the human influence on the warming of West Antarctica is much smaller than previously thought. The warming of East Antarctica up to now can even be explained by natural variability alone.’ The results of their study are now published in the journal Climate Dynamics.”
They had us going there for a minute, but no, it isn’t a real admission they were wrong: global warming has been merely hiding behind natural variability as well as in the oceans, they insist.
The press release continues:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The scientists did not only analyze data from individual measuring stations but also generated regional averages. The results show a human influence on the warming of West Antarctica, while this influence is weaker than previously thought.
However, the warming of Antarctica altogether will likely increase more strongly soon.
Soon? How long are we to wait? Many are losing patience in their long wait for the promised catastrophe. Suddenly things look as if they are losing their urgency.
For several years temperatures in Antarctica, but also globally, have been increasing less rapidly than in the 1990s. There are a number of reasons for this, e.g. the oceans buffering warmth.
The study now published by the German team of scientists shows that man-made global warming has not been pausing – it was temporarily superimposed and therefore hidden by long-term natural climate fluctuations like in Antarctica.2
How do they know it’s temporary? From their models? Well, they have been wrong since day 1. Obviously there’s much more to the climate system than just trace gas CO2.
‘Our estimates show that we are currently facing a natural cooling period – while temperatures nonetheless rise slowly but inexorably, due to our heating up the atmosphere by emitting greenhouse gas emissions,’ explains Hans Joachim Schellnhuber.
‘At the end of this natural cold spell temperatures will rise even more fiercely. Globally, but also in Antarctica which therefore is in danger of tipping.”
The good Herr Dr. Schellnhuber never lets you down. Just be patient longer than we thought. The catastrophe that we promised is just taking longer to get here – but when it does, by golly, it’ll be a lot worse – you’ll all be sorry for not doing what we told you.
This is taking on comical dimensions.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAs Germany piles on more sporadic energy from wind and solar into its power grid, stability concerns are growing.
Increasingly volatile energies like wind and sun are turning out to be more of an expensive nuisance rather than a benefit.
Researchers at the Germany-based Fraunhofer-Instituts für Optronik, Systemtechnik und Bildauswertung, Institutsteil Angewandte Systemtechnik (IOSB-AST) have studied the risk of grid overloads caused by renewable energies at the community level, the online Ostthüringer Zeitung (OTZ) writes here.
The result, reports the OTZ:
Already in just a few years power will have to be stored locally as well. […] And the answers in their study are, depending on the perspective, thoroughly alarming or spurring for policymaking and economy.”
According to the OTZ, a team of researchers led by Peter Bretschneider at the Fraunhofer’s IOSB-AST conducted a 3-year study, where they literally built a statistical mock-up city of 30,000 that included a downtown, residential areas, commercial district, solar installations and wind parks. “A total of 1847 residential and business buildings that included everything from grandma’s little house to office complex for public officials.”
And so that the mock-up city simulates what is typical today in Germany, it also had everything a town would expect to have with the current German feed-in act:
4456 ‘grid elements’, i.e. power lines, transformers, large points of consumption and feed-in systems, foremost photovoltaics on the roofs.”
Even the homes were provided with the thermal insulation that they are expected to have later on.
The OTZ continues:
Next the Fraunhofer scientists electrified their simulated city. Then using meteorological data they allowed the sun to rise and set, the wind to blow, the temperatures to change – just like in real life.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Next they extrapolated outwards to the expected conditions of the year 2018 and 2023, leaving the local power grid unchanged and allowing more wind and solar energy to come online as expected from the provisions of the feed-in act. How did the city’s power grid fare? The OTZ tells us the shocking results, and they aren’t pretty:
Already today in the simulated city one of the 14 network nodes gets sporadically overloaded. In 2018 the impacted transformer comes under serious stress 22 days a year, and so does another transformer. Five years later three nodes are impacted by long-term frequent back-feeding of surplus solar energy in the medium-voltage grid. At least one cable in the area exceeds ‘the limits of thermal loading’. […]  ‘Yes, a transformer would be glowing – and the cable would go up in smoke,’ system engineer Sebastian Flemming explains the results in layman’s terms.”
The OTZ asks what this all means for the citizens? Flemming responds: “Blackout, for the entire city.”
In the wintertime this would be most inconvenient, and for some possibly even fatal.
Flemming adds that even if a blackout were averted, the wild frequency fluctuations in the grid would have “grave consequences” for many electrical appliances and systems. The OTZ writes:
None of today’s productions systems in the economy could function under such fluctuations, especially everything that is computer-controlled.”
In other words, it would not even take a blackout to cripple a city.
The OTZ then asks what can be done with the surplus electrical energy that will surely result from the wind and sun. Here once again the financially and technically unfeasible storage systems get brought up. Another solution mentioned is the conversion of the electricity into heat for supplying warmth to homes.
But the online OTZ daily writes that solutions appear to be a ways off, and so it warns:
Time is running out: According to the study, beginning in 2018, the first transformers are threatened with prolonged overloading.”
Do these findings of the Fraunhofer Institute surprise us? Not at all. It’s been known for a long time that the feed-in of solar and wind power leads to crazy, uncontrolled power surges in the grid. Supply stability remains the glaring problem that too many among us continue to deny.
Prepare for blackouts!
Share this...FacebookTwitter "
"Antarctica is a vast icy wasteland covered by the world’s largest ice sheet. This ice sheet contains about 90% of fresh water on the planet. It acts as a massive heat sink and its meltwater drives the world’s oceanic circulation. Its existence is therefore a fundamental part of Earth’s climate.  Less well known is that Antarctica is also host to several active volcanoes, part of a huge “volcanic province” which extends for thousands of kilometres along the western edge of the continent. Although the volcanic province has been known and studied for decades, about 100 “new” volcanoes were recently discovered beneath the ice by scientists who used satellite data and ice-penetrating radar to search for hidden peaks.  These sub-ice volcanoes may be dormant. But what would happen if Antarctica’s volcanoes awoke? We can get some idea by looking to the past. One of Antarctica’s volcanoes, Mount Takahe, is found close to the remote centre of the West Antarctic Ice Sheet. In a new study, scientists implicate Takahe in a series of eruptions rich in ozone-consuming halogens that occurred about 18,000 years ago. These eruptions, they claim, triggered an ancient ozone hole, warmed the southern hemisphere which caused glaciers to melt, and helped bring the last ice age to a close. This sort of environmental impact is unusual. For it to happen again would require a series of eruptions, similarly enriched in halogens, from one or more volcanoes that are currently exposed above the ice. Such a scenario is unlikely although, as the Takahe study shows, not impossible. More likely is that one or more of the many subglacial volcanoes, some of which are known to be active, will erupt at some unknown time in the future. Because of the enormous thickness of overlying ice, it is unlikely that volcanic gases would make it into the atmosphere. So an eruption wouldn’t have an impact like that postulated for Takahe. However, the volcanoes would melt huge caverns in the base of the ice and create enormous quantities of meltwater. Because the West Antarctic Ice Sheet is wet rather than frozen to its bed – imagine an ice cube on a kitchen work top – the meltwater would act as a lubricant and could cause the overlying ice to slip and move more rapidly. These volcanoes can also stabilise the ice, however, as they give it something to grip onto – imagine that same ice cube snagging onto a lump-shaped object. In any case, the volume of water that would be generated by even a large volcano is a pinprick compared with the volume of overlying ice. So a single eruption won’t have much effect on the ice flow. What would make a big difference, is if several volcanoes erupt close to or beneath any of West Antarctica’s prominent “ice streams”. Ice streams are rivers of ice that flow much faster than their surroundings. They are the zones along which most of the ice in Antarctica is delivered to the ocean, and therefore fluctuations in their speed can affect the sea level. If the additional “lubricant” provided by multiple volcanic eruptions was channelled beneath ice streams, the subsequent rapid flow may dump unusual amounts of West Antarctica’s thick interior ice into the ocean, causing sea levels to rise. Under-ice volcanoes are probably what triggered rapid flow of ancient ice streams into the vast Ross Ice Shelf, Antarctica’s largest ice shelf. Something similar might have occurred about 2,000 years ago  with a small volcano in the Hudson Mountains that lie underneath the West Antarctica Ice Sheet – if it erupted again today it could cause the nearby Pine Island Glacier to speed up. Most dramatically of all, a large series of eruptions could destabilise many more subglacial volcanoes. As volcanoes cool and crystallise, their magma chambers become pressurised and all that prevents the volcanic gases from escaping violently in an eruption is the weight of overlying rock or, in this case, several kilometres of ice. As that ice becomes much thinner, the pressure reduction may trigger eruptions. More eruptions and ice melting would mean even more meltwater being channelled under the ice streams.  Potentially a runaway effect may take place, with the thinning ice triggering more and more eruptions. Something similar occurred in Iceland, which saw an increase in volcanic eruptions when glaciers began to recede at the end of the last ice age. So it seems the greatest threat from Antarctica’s many volcanoes will be if several erupt within a few decades of each other. If those volcanoes have already grown above the ice and their gases were rich in halogens then enhanced warming and rapid deglaciation may result. But eruptions probably need to take place repeatedly over many tens to hundreds of years to have a climatic impact.  More likely is the generation of large quantities of meltwater during subglacial eruptions that might lubricate West Antarctica’s ice streams. The eruption of even a single volcano situated strategically close to any of Antarctica’s ice streams can cause significant amounts of ice to be swept into the sea. However, the resulting thinning of the inland ice is also likely to trigger further subglacial eruptions generating meltwater over a wider area and potentially causing a runaway effect on ice flow."
"Tackling the climate emergency forms the centrepiece of the Green party’s appeal to voters, with an eye-catching proposal to spend £100bn a year – more than any other party – on a transformation of the economy to reach net zero carbon emissions by 2030. Policies on housing, transport, industry and the economy all flow from this central premise: that failing to see off the climate crisis would spell disaster, while tackling the challenge correctly can revitalise both the economy and the social fabric of the country.  The proposed Green New Deal would require close to £1tn in government borrowing over the next decade, during which time the UK would be transformed to a net zero carbon economy. Renewable energy would be expanded to produce most of the country’s power, with wind alone producing 70% of electricity by 2030. New support for solar, geothermal, tidal, hydro and other renewable sources would provide most of the rest, while subsidies to fossil fuels would be abolished. Large-scale batteries, an overhaul of the grid and new interconnectors to mainland European neighbours would help counter any intermittency of supply. A carbon tax on all fossil fuel imports and domestic extraction would be progressively raised to phase out fossil fuels, while home insulation – every home to be adequately insulated by 2030 – and energy efficiency improvements in industry would reduce demand. The party’s estimates the Green New Deal would create millions of jobs, assisted by £2bn a year investment in training and skills. Transport is now the UK’s biggest source of emissions, and the Green party plans rely heavily on improving public transport. HS2 would be scrapped, and the money spent instead on electrifying all intercity railways, building new routes and creating a government-owned rolling stock company for electric trains. No new petrol or diesel cars could be sold after 2030, and a frequent flyer levy would apply to people taking more than one return flight a year. Airport expansion would cease. Agriculture is another major source of emissions. The Greens would plant 700m new trees, more than 10 times the number of other parties, restore hedgerows and designate some areas for rewilding to restore wildlife and natural habitats. Farmers would be encouraged to diversify into forestry and new urban farms created. Revenue raised by a new 5% tax on meat and dairy products would be returned to farmers to help them move to low-carbon methods. Increase NHS funding by £6bn a year, and a further £1bn a year on nursing education. Provide an additional £4.5bn a year to fund councils to provide free social care to people over 65 who need support in their own homes. Roll back the privatisation of the NHS and give the health secretary the duty to ensure the NHS is properly staffed. Mental health services to be on a par with physical health, and anyone needing mental health therapy to receive it within 28 days. End the “hostile environment”. Replace the Home Office with a Ministry of Sanctuary, responsible for a new immigration system with no minimum income rules for visas, full workplace rights for migrants, the right to work for asylum seekers and recourse to public support for migrants and asylum seekers who need it. Recompense those affected by the Windrush scandal and a national Windrush Day bank holiday to recognise the contribution migration has made to UK society. Abolish undergraduate tuition fees and write off the student debts of recent graduates who paid £9,000 tuition. Schools to receive an additional £4bn a year, with a long-term aim of bringing class sizes down to 20 pupils. Formal education to start at six years old, with early years education available and free childcare of 35 hours a week. Remove charitable status from private schools and charge VAT at full rates on fees. Corporation tax to be raised from 19% to 24%. Flatten tax for individuals, by merging income tax, national insurance, capital gains, inheritance and dividend tax into a single consolidated income tax. Everyone to receive a universal basic income of £89 a week for adults, £178 for pensioners. Council tax and business rates to be replaced with a land value tax. Women to occupy 40% of board positions in major companies. Reduce short prison sentences and create specialist women’s centres. Restore youth services to combat knife crime, and make policing more community-based. Decriminalise drug use in favour of a regulated system of licensed sales at fixed prices, with government responsible for sourcing sustainable supplies of opium and coca from developing countries. Ban advertising of alcohol and other drugs, and place a minimum unit price on alcohol. Cancel the Trident nuclear programme. Replace the Ministry of Defence with a Ministry for Security and Peace, with the promotion of peace as a key foreign policy objective, along with helping other countries combat climate chaos and dealing with the impacts of climate-related disasters. Spending on overseas aid to be increased from 0.7% of GDP to 1%. The government’s activities in selling and encouraging the sale of arms to be closed down, along with all subsidies and support for the UK arms industry’s export of weapons. People living in privately rented accommodation to be given new rights through an end to no-fault evictions and controls placed on rent. End right-to-buy sales of council homes, and scrap the help-to-buy scheme. Councils to be granted funding to build 100,000 new homes a year, all constructed to high environmental standards. Exemptions to the land-value tax for pensioners or people on low-incomes, so they are not forced to move. A second referendum, in which the Greens would campaign to stay in the EU and push for reforms to make its institutions more transparent, as well as replacing the UK’s own parliamentary voting system with proportional representation, votes for 16-year-olds and an elected second chamber."
"Students and alumni from Harvard and Yale disrupted the annual football game between the two elite universities on Saturday, occupying the field in New Haven, Connecticut, at half-time and demanding the colleges divest from investment in fossil fuels. More than 200 protesters stalled the high-profile game for around an hour, many chanting: “Hey Hey! Ho Ho! Fossil fuels have got to go!” The protest was briefly booed by some in a crowd of 44,989 and discussed widely on social media. After the protest had delayed the TV broadcast of the game and pushed it toward sunset in a venue without floodlights, most of the protesters left the field voluntarily, escorted by police officers. A handful who remained were told they would be arrested. The number of arrests made was not immediately available. Students began campaigning in 2012 for both schools to stop investing in oil and gas and coal companies that contribute to the climate crisis. Both universities refused, arguing that they would be in a better position to encourage corporate climate action if they remained shareholders. “They believe that they can engage with these companies and get them to change their fundamentally extractive business models, which we think comes from a place of naivety amounting to gross negligence,” Nora Heaphy, an undergraduate at Yale, said. “It’s absurd to make those kinds of claims. So since then our campaign has moved away from administrative engagement, recognizing that it is often a stalling tactic.” A few months ago, hundreds of students at both universities walked out of class for a global climate strike. Last year at Yale about 50 students, community members and professors occupied the investment office until they were arrested. Heaphy has been arrested twice. Both schools have massive endowments invested across the economy, including in fossil fuels. Harvard’s is worth $39bn, Yale’s $29bn. Activists believe that if the universities divest, hundreds of institutions will follow them. Students at other prestigious schools are locked in similar battles. At the Massachusetts Institute of Technology (MIT), one group is opposing the decision to accept $3m and name an auditorium after the oil company Shell, which some experts call an example of the “colonization of academia” by fossil fuel corporations. A recent Guardian investigation revealed that 20 companies are responsible for a third of all carbon emissions since 1965. Internal documents from Exxon show the company knew the oil and gas industry would drastically alter the Earth’s climate decades ago and launched sophisticated campaigns to convince the public otherwise. Caleb Schwartz, a Harvard undergraduate, said no shareholder resolution could “sufficiently address the impact that Exxon has had on the climate crisis and on our politics” and added: “Ultimately, these companies need to go out of business in order for us to have a safe and livable future.” MIT has accepted funding from Shell to renovate a lecture hall in the Department of Earth, Atmospheric and Planetary Sciences, a highly visible space used for large classes for first-year students. “The significance of this is not the $3m in and of itself, which is pennies both to Shell and, frankly to MIT,” said Geoffrey Supran, an MIT alum who studies the history of global warming politics with Naomi Oreskes at Harvard. “The significance of this is this is part of a systemic trend – the invisible colonization of academia by the fossil fuel industry.” Supran said MIT received more industry funding than any other non-medical university in America. Students at MIT say they are offended by the message the naming of the auditorium will send to the academic community. The department is home to both climate scientists and researchers exploring more efficient ways for drillers to extract oil and gas. Advocates at MIT have pushed for the university to divest from fossil fuels. “Many of the things that MIT has said they would do, they haven’t done,” said Catherine Wilka, a graduate student in climate physics and chemistry. Wilka said she was “frustrated with the lack of evidence we’ve seen that this strategy of constructive engagement has changed anything about the fossil fuel companies’ intended business plans for oil and gas extraction – even as the science has painted an incredibly direct picture of the consequences if we don’t transition away from fossil fuels soon”."
nan
"Coldplay fans are bereft at the prospect of being unable to see the band’s new double album Everyday Life performed out in the wild, after Chris Martin told the BBC that they would not be touring it. Instead, the band will spend the next year or two figuring out how best to put on a “sustainable” and “actively beneficial” live experience that places environmental concerns above scale and convenience, addressing the climate-ravaging issues of flying and single-use plastic, for example, in the live music industry. The future they imagine is a para-, para-, paradi... oh, never mind.  In an era that sees celebrities criticised for speaking out about the climate emergency, then strung up again for flying to do so, of course it is Coldplay who are putting their money where their mouths are. I will not hear a word said against Coldplay. When actors use tear sticks to help them cry during emotional scenes, I wonder why they don’t just pipe in Fix You on a loop instead. Coldplay’s later career has pulled off the impressive feat of bringing the aesthetic of a decades-old semi-illegal world music festival in the Midlands to a global audience. Chris Martin is a superstar, a stadium frontman who clearly loves being on stage in front of thousands, even though he carries the vibe of a GCSE drama teacher who can’t stop talking about his Monday night reiki course. I love Coldplay. I don’t see how anyone can fail to love Coldplay. Coldplay’s vast money mountain should make the prospect of not touring an album a little easier on the financial front, even though playing shows is one of the only ways left for most musicians to make a living from music. As a result, it will be tougher for performers at a lower level to follow their example. However, Martin has already thought of that. “I think it is a question of just accepting that you have to do your best, not to be over-zealous in criticising others because everyone will catch up if you prove it is easy to do the right way,” he said. He’s the Elon Musk of carbon-neutral touring. Basically, trust him, he’s got this. One of the biggest issues, when it comes to live concerts, is the audience. We are a huge part of the problem, comprising a significant proportion of a tour’s carbon footprint by simply making our way to the show. I like watching live music and so I want Coldplay to fix this. Here’s an idea to get them started. If Chris Martin stopped making guest appearances during literally everyone’s sets at Glastonbury, it might just be enough of a cut to save us all. Christmas has come early for Dolly Parton fans. Thanks to Netflix’s exuberant policy of commissioning absolutely loads of stuff, it has served up Dolly Parton’s Heartstrings, eight really long episodes of drama, each adapted from a Parton song, with the source material of course including Down From Dover and Jolene (but sadly not Baby, I’m Burning – maybe season two?). Parton introduces each one ,casing the entire endeavour in a retro jacket, and while it is predictably schmaltzy and spectacularly drawn out – these are stories taken from minutes-long songs, after all –it does offer the TV movie comfort of a Sunday afternoon under a blanket. Better, though, is Dolly Parton’s America, the podcast hosted by Radiolab’s Jad Abumrad, which has been exploring how Parton unites a divided country. Abumrad has spent time with Parton, a notoriously charming but ungiving interviewee, and has spun it into gold as bright as her smile by speaking to family, friends, colleagues and, crucially, those most affected by her music. The episode on her “Dollitics” expertly pulled apart the union anthem 9 to 5, while Jolene got an instalment of its own, and it is brilliant, informative and just about as entertaining as the legend herself. Congratulations to The Vivienne, the deserving winner of the inaugural RuPaul’s Drag Race UK, who walked away with the kind of underwhelming prizes that only the BBC could offer with a straight face: three badges and the promise of a “digital series” with the show’s producers. Given the budgetary restraints, you’d be forgiven for thinking that might end up being an Instagram story, perhaps, at a push, a YouTube video. But no. The production company has already announced two follow-up series: The Vivienne Takes Hollywood and Morning T&T, which pairs the winner with her fellow finalist Baga Chipz, and has them reprising their Trump and Thatcher impersonations for a spoof talkshow. The Vivienne was the perfect reality TV contestant and the inevitable winner. She started strong, coasted at the top, dipped to the bottom, learned her lesson, then got her game back right when it counted. She had a serious, sympathetic backstory and she went on that crucial journey. The only disappointment was the lack of surprise, because she’d been the clear frontrunner since episode one. As a longtime Drag Race viewer, the format had been flagging. It started to feel like there were more series than RuPaul has had birthdays and, as a result, it was in danger of becoming too meta, more about the show than the people on it, with contestants constantly referring to previous contestants, the cultural touchstones eating themselves. Drag Race UK has been a crude, smutty, utterly British defibrillator that has given it all a new lease of life. Its contestants were mucky, its drag more disruptive than one might have predicted and it provided one of the sweetest TV moments of the year, when Cheryl (formerly) Cole met her namesake Cheryl Hole. Now that’s the kind of wholesome family entertainment I want my licence fee to fund. • Rebecca Nicholson is an Observer columnist"
"You have probably never seen a great crested newt. If you’re in the UK, you’ll usually only hear about them when construction work is halted because they are found at a building site. In the past month alone, relocating these protected animals has caused delays to new roads, a huge rail freight hub, a 1,400-home development and a football club’s state-of-the-art £14m training complex. Even an illegal rave in Norfolk only made the news because it was too close to a protected breeding site. As a European protected species, great crested newts and their habitats are fully protected by law, so a development which risks disturbing them can only go ahead if approved plans are made to relocate them to another suitable habitat. It might seem reasonable to hope that, after Brexit, there will be less “red tape”, and that we can get on with building without worrying about a few newts. But these creatures are worth worrying about. Even if you’ve never seen one, their fate and yours could be linked. Great crested newts are large, up to 15cm long, and can be found in ponds across northern Europe. When not breeding, they are are nocturnal, and tend to spend the daytime hiding away – one reason humans rarely spot them.  As they go about their day-to-day lives, these newts perform important functions which inadvertently benefit humankind. We may say that they contribute to “ecosystem services”. One service is the cycling of nutrients from water to land and back again, thanks to their complex lifecycles. This contributes to soil fertility, a service our overworked soils desperately need if we are to provide enough food for a growing population.  They also eat small biting insects like midges. Aside from being irritating to humans, midges are also responsible for transmitting diseases such as bluetongue to livestock. These diseases have animal welfare implications, as well as knock-on effects on the cost of food production. Predicted rises in temperatures in the UK, associated with global climate change, mean that we are likely to see more of these insects in future, and more insect-borne diseases. Some functions within an ecosystem will be carried out by more than one species, and it’s true that the UK’s six other native amphibian species (the common frog, pool frog, common toad, natterjack toad, smooth newt and palmate newt), all contribute ecosystem services in similar ways. Yet it is the great crested newt that makes the news, thanks to its special protection status and its tendency to be found in sites which are earmarked for development. It may be that newts are utilising the new ponds that frequently develop in post-industrial land and brownfield sites because agricultural intensification and development has reduced the availability of field ponds and other habitats.   The UK could of course give up on protecting these newts, and rely instead on other native amphibians to fulfil their functions. But this would be a very risky move.  In ecology, a species may be termed “redundant”, if other species within an ecosystem carry out the same functions. But the existence of a redundant species is not pointless. It may become extremely important after a major event, such as a fire or an earthquake, as part of the adaptive process which allows an ecosystem to keep functioning. How do we know which species will be important in the future? We don’t really. We can make predictions about what will happen in the environment, of course, but there is a lot of uncertainty in any complex system: events could unfold along a variety of different paths. We are currently in the middle of the sixth mass extinction event of the past half billion years. Amphibian species across the world are declining faster than any other class of animal. Every time we lose a species of amphibian, or indeed of any animal or plant, we suffer the loss of genetic material. This material, the earth’s biodiversity, is vital for our planet’s resilience. To cope with changes (and there are certainly plenty of those around), the living planet needs variety, providing the capacity to adapt. Without this, we are vulnerable to potentially catastrophic consequences resulting from even small environmental disturbances. It’s not possible to save every single species, and we can’t always tell which will become the most important to us. This means we have to concentrate our conservation efforts where they have the greatest chance of success. But with great crested newts we have a good chance, especially as new techniques allowing us to detect traces of newt DNA in water mean that surveying for their presence is cheaper and quicker than ever.  It’s in our best interest to make use of these techniques, and keep working to conserve this species. We humans are part of the same network as all other life on earth, dependent on the same finite resources. Great crested newts might just turn out to have a key role in our own survival."
"Each summer, a large part of the Gulf of Mexico “dies”. This year, the Gulf’s “dead zone” is the largest on record, stretching from the mouth of the Mississippi, along the coast of Louisiana to waters off Texas, hundreds of miles away. Around 8,776 square miles of ocean, an area the size of New Jersey or Wales, is almost lifeless. John Muir, the famed naturalist and early conservation campaigner, once said that: “When we try to pick out anything by itself, we find it hitched to everything else in the Universe.” His point was that everything in nature is connected, and that no part of our ecosystem exists entirely independently from any other. It is perhaps no surprise then that ultimate cause of the Gulf of Mexico’s dead zone can be found many miles inland. Fertilisers used by farmers then wash into the Mississippi River and eventually into the sea, where nutrients such as nitrogen and phosphorus stimulate an explosion in microscopic algae, creating huge “algal blooms”. The algae then die and sink to the bottom, where they decompose. But the same bacteria which decompose the algae also use the sea’s oxygen during the process, leaving an “anoxic” ocean. Fish and other mobile sea creatures are able to escape the suffocating dead zone. Less lucky however are the sponges, corals, sea squirts and other animals who live their lives fixed in one place on the sea bed. Low oxygen levels place them under great stress and we have seen huge mortalities. Such losses will of course ripple up the food web, creating a negative chain reaction of increasing mortality rates in larger and larger animals. The “dead zone” has grown this year due to increased rainfall in America’s Midwest washing ever greater amounts of nutrients into the Mississippi, which ultimately end up in the Gulf. Not only is this a huge conservation issue – the Gulf contains key nursery habitats such as mangrove forests, sea grass beds and coral reefs that benefit adjacent fisheries – but it also has huge consequences for the local fishing economy, particularly the shrimp industry. Steps are under way to slow down the ecological disaster. Some farmers in the Mississippi basin are using large grassy zones along waterways in order to soak up the agricultural fertilisers and filter out many of the nutrients before they make their way down the Mississippi to pollute the Gulf. However, it remains to be seen whether such measures are effective – and US farmers certainly need to greatly reduce the nitrogen and phosphates they use. In the century since Muir’s death, things have sped up. A larger population demands more food which means more deforestation, more farmland and more fertiliser. The increase demand placed on our land is ultimately affecting the marine environment. These losses are unsustainable. The marine environment is integral for all life on earth, from an ecological and economic point of view. If we keep losing ecosystem services such as coastal nursery habitats and spawning grounds at this current rate, it will not just be an area the size of a state that is a dead zone, but the whole Gulf, or even whole oceans."
"
Share this...FacebookTwitterGerman experts Sebastian Lüning and Fritz Vahrenholt tell at their Die kalte Sonne site us why the 2013 Cowtan and Way paper has proven to be a flop.
========================================
Failed spectacularly: Arctic data hole theory for the warming pause collapses
By Sebastian Lüning and Fritz Vahrenholt
(Translated, edited by P Gosselin)
For quite some time climate scientists have been desperately seeking an explanation for the unexpected warming pause. On November 15, 2013 in the Süddeutsche Zeitung Christopher Schrader declared that the solution had been found: There was no pause; the data had only been missing from the Arctic.
Climate change without pause
According to the data, the earth had not warmed over the past years. However, this impression is likely related to missing data from the Arctic. And there the temperature appears to have risen much more strongly than the global average.[…] These [temperature] measurements have large holes: Approximately one sixth of the earth is not covered. Foremost in the Arctic there are not enough thermometers. But according to all signs it is warming considerably more quickly than the rest of the planet. An English and a Canadian scientist now show how this hole can be closed up with estimated values and how the supposed warming pause practically disappears. Kevin Cowtan of the University of York and Robert Way of the University of Ottawa refer to satellite data. […] Thus ultimately Cowtan and Way arrived at the result that the Arctic warmed eight times faster than the rest of the planet. Before that it had been thought that it was warming three times faster.”
Unfortunately Schrader did not mention that the two scientists were climate activists who were close to the IPCC-friendly Internet platform Skeptical Science. Yet, he still was unable to let slip out a couple of critical words about the two authors:
However the process is too complicated in order to find widespread recognition. Doubt will be stirred up among many because both authors have no name in climate science. Kevin Cowtan is a theoretical physicist and computer specialist at the Department of Chemistry at his University. Robert Way is still busy writing his doctorate dissertation.
It’s been a full year since the appearance of the dubious paper by Cowtan and Way, one that was highly praised by Stefan Rahmstorf. So just how was this pioneering paper received by the science community? On January 29, 2015 the answer from their colleagues appeared in the Geophysical Research Letters. The dodgy Arctic data fill-in model has failed spectacularly and has been soundly rejected. The answer to the pause is not to be found in the Arctic as Cowtan and Way suspected, rather it is to be found at the lower geographical geographical latitudes, as a team of scientists of the Danish Meteorological Institute in Copenhagen led by Hans Gleisner reports in a new publication. What follows is the paper’s abstract:
Recent global warming hiatus dominated by low-latitude temperature trends in surface and troposphere data
Over the last 15 years, global mean surface temperatures exhibit only weak trends. Recent studies have attempted to attribute this so called temperature hiatus to several causes, amongst them incomplete sampling of the rapidly warming Arctic region. We here examine zonal mean temperature trends in satellite-based tropospheric data sets (based on data from (Advanced) Microwave Sounding Unit and Global Navigation Satellite System Radio Occultation instruments) and in global surface temperatures (HadCRUT4). Omission of successively larger polar regions from the global mean temperature calculations, in both tropospheric and surface data sets, shows that data gaps at high latitudes cannot explain the observed differences between the hiatus and the prehiatus period. Instead, the dominating causes of the global temperature hiatus are found at low latitudes. The combined use of several independent data sets, representing completely different measurement techniques and sampling characteristics, strengthens the conclusions.
Share this...FacebookTwitter "
"A novel way of monitoring air pollution in London has taken flight. The Pigeon Air Patrol has set loose a legion of winged “scientists”, complete with small backpacks containing sensors that measure levels of nitrogen dioxide, and several other pollutants. This is just the latest in a range of high-profile citizen science projects that use small, low-cost air quality sensors (not all of which are strapped to pigeons). If the media hype is to be believed, start-up companies from London to San Francisco are now using these sensors to provide detailed information on air pollution levels where people actually live and work.  The ambition is to create a democratisation in information, better informing the public and enabling lifestyle decisions that limit their exposure – and creating data that pressures local authorities to clean up the air its residents breathe. This is big news when you consider that in the UK alone air quality is estimated to be responsible for over 30,000 premature deaths a year.  The UK government currently invests significant money into measuring real-time air pollution at around 150 air quality monitoring sites, where highly trained personnel operate expensive, high-tech instruments. The costs run to many millions of pounds a year – but why bother when a flock of pigeons could provide a much higher density of measurements for a fraction of the price?  Atmospheric scientists love their gadgets and invest significant time and money in developing and running equipment to measure the chemical composition of the atmosphere. Yet very few have embraced this apparent sensor revolution – and even fewer have published data on them in scientific literature.  Despite the user-friendly apps, clever websites and considerable media publicity with crowd-sourced funding, virtually none of this new monitoring tech – pigeon-borne or otherwise – has supporting evidence that it can provide accurate measurements in the real atmosphere. The assumption being that it must be – and very few people have any way of checking for themselves. We have spent the past 12 months at the Wolfson Atmospheric Chemistry Laboratories looking into just how well these low-cost air monitoring sensors perform, with an interesting result: when relying on data from these sensors you must be very cautious indeed. We exposed different sensors to a wide range of chemicals and conditions that they would encounter in the real world, and compared the data with more established technologies. The majority of sensors tested did indeed respond to the chemicals they are designed to measure and, after calibration, could measure realistic ambient concentrations in short, controlled laboratory experiments. But we also found that many of the sensors also responded to a whole range of other pollutants and that responses from these chemicals could swamp the device and give artificial readings.  We also saw large sensor-to-sensor variability: 20 identical commercial air quality sensor units running side by side for two weeks reported pollution numbers that differed by up to a factor of ten. Overall, our results found that the quality of the data fed back by some low-cost sensors can be misleading – often reporting pollution to be worse than it actually was – and, in some cases, completely wrong. As an atmospheric chemist, whose career has been spent building and testing instruments to measure chemicals in the atmosphere, the results from these experiments were no great surprise. Our atmosphere is an incredibly complex mixture and the concentrations of pollutants are actually very low. For example, the current EU air quality guideline for nitrogen dioxide is about 20 molecules in every billion.  Atmospheric measurement technology is constantly improving and miniaturising, but over the decades improvements have been gradual and incremental. In my opinion, this new approach in air pollution sensors is simply trying to leap too big a gap in one go. Are these just the complaints of an elitist scientist, moaning about the public getting in on our research area? Perhaps these sensors are just a bit of fun? It all depends of course on how the data are used. If the aim is to simply engage public interest in the issues, then perhaps the quality of data doesn’t matter. But what if an asthma sufferer makes medication decisions based on the read-outs of their local sensor?  If the road outside your house was closed because of a high pollution warning from a sensor, you would want this to be based on the most accurate data available. In many developing countries low-cost sensors are being installed  to manage often-chronic air pollution problems in place of more expensive traditional monitors. Should policy and investment in these places be based on technologies without acknowledging their weaknesses as well as their strengths? Even the UN Environment Programme has promoted a low-cost pollution sensor, but has never published real-world data that demonstrates the sensors work in this application. If we can cut through the hype, there really is fantastic potential for sensor systems in understanding human exposure, managing emissions and supporting effective policy. Undoubtedly these sensors work to some degree but, like all measurement science, the hard yards need to be done in the lab first in order to understand how this technology performs in the complex mixture that is our atmosphere. Less emphasis on websites and apps and rather more on characterisation and calibration will ultimately help solve some of these problems."
"
Share this...FacebookTwitterGermany’s so-called Climate Consortium here has published a telling statement on this year’s “record warm year” in Germany and the reasons behind it. The Climate Consortium represents the collective position of all Germany’s scientific climate institutes.
Although the statement claims the record year “fits very well in the picture of a long-term global temperature increase” it now concedes major natural fluctuations in the climate system. Less than 3 years ago, on February 6, 2012, the same site posted the following in a hasty response to skeptic book Die kalte Sonne:
Pure natural fluctuations ­- such as changes in solar activity – on the other hand cannot be mainly responsible for the global warming of the past decades.”
What a difference a couple of years can make. Now they are blaming precisely these “natural fluctuations” for the “warming pause”.
Yesterday’s statement was authored by Germany’s top appointed climate experts (some are well-known IPCC scientists): Jochen Marotzke, Paul Becker, Gernot Klepper, Mojib Latif and Monika Rhein.
Does anyone think they will do the honorable thing and admit that Die kalte Sonne authors Prof. Vahrenholt and Sebastian Lüning claims had merit after all? Professional and honorable scientists would certainly do so.
On the surface the latest German Climate Consortium statement does its best to give the façade of a warming planet, but in the text the truth comes gushing out. They write that at 10.3°C, Germany this year is set to break the previous 2000 and 2007 record (9.9°C) for the highest mean annual temperature since recording began in 1881. But the statement then cautions:
However, only the global mean temperature is a reliable indicator of global warming. If one takes the preliminary data for the months of January to November 2014 as a reference, then, since systematic data recording began, fourteen of the last fifteen warmest years occurred in the 21st century.
Moreover it is too early to talk about an end to the now 15-year long ‘warming pause’ and to assume an accelerating warming over the coming years. The global earth’s surface temperature is subject to year-to-year and decadal fluctuations. Only with the following years will it be possible to judge to what extent global warming of the earth’s surface will resume.”
This is an interesting statement. The scientists now concede that natural factors now dominate, and 2) that the upcoming years will answer the hotly debated question concerning the extent of man-made warming.
And we all thought it was all settled.
More concessions, admissions soon likely


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Given this year has been an El Nino year, and that such years are normally followed by the cooler La Ninas, and that current solar activity cycle is well into its second half, temperatures over the next several years may lead to even more difficult concessions and admissions from warmist scientists. Expect the 2015 – 2022 period to make or break the AGW science.
90% of the missing heat absorbed by oceans
The German Climate Consortium statement continues:
In addition to solar radiation and volcanic activity, the oceans are a major climate factor. Recent scientific results show that the world’s oceans have stored 90 percent of the energy resulting in the climate system from greenhouse gases over the past 40 years. Phases of increased heat absorption alternate with phases of less absorption. Thus connected with this are fluctuations of the sea surface temperatures.”
As an example the Climate Consortium paper then describes the effects of El Nino on global surface temperatures.
Here we see again that they concede the oceans are a major driver of the surface temperatures – a real natural fluctuation. And although they chose not bring it up, it only logically follows that they would also have to concede that both the Pacific and the Atlantic Decadal Oscillations (PDO and AMO) are major drivers of the global surface temperatures. But they did not bring it up. Maybe it’s because admitting this would necessarily mean that the strong 1980 – 1998 warming would have to be in large part attributed to the oceans, and NOT Co2. That medicine seems to be still too bitter to swallow.
The statement adds:
The interaction between the ocean and the atmosphere is an important reason for the decelerated rise in global surface temperatures since the start of the millennium.”
The German Climate Consortium statement ends by pointing out 2015 could also break a new global surface record (depending on the dataset one uses) because the impacts of an El Nino on global temperature lag by up to one year.
Warming now facing huge obstacles
Record or not, we can all safely assume that 2015 will be a warm one globally. But after that the warmists will really have to start sweating. Chances are good that a La Nina will follow, and its cooling effects will be further compounded by the death of SC24 and an AMO heading down towards its cold phase.
Right now it’s best to ignore all the day-to-day hollering and to just be patient. The next 8 years or so will decide the issue once and for all. After that there will be no excuses for not acting – in one direction or the other.
 
Share this...FacebookTwitter "
"Legal & General has defended its decision to retain Shell as one of the top stocks in its climate-conscious fund despite a pension client raising concerns about the oil corporation’s inclusion. PensionBee, an online pension provider that handles £650m worth of client assets, said it was being inundated with questions from its customers about the composition of one of Legal & General Investment Management’s Future World Funds, which counts Shell among its top 10 holdings. “While Shell has made some progress in the right direction, our customers are asking us on a daily basis whether Shell’s business model is sufficiently transitioning to a low-carbon economy to warrant continued inclusion in this responsible investment plan,” PensionBee’s chief executive, Romi Savova, said in a letter sent to LGIM this week. PensionBee, which has more than 60,000 customers, is believed to be one of the fund’s top five owners, with about £50m invested. LGIM’s Future World Funds are governed by its “climate impact pledge”, which means it can exclude companies over poor governance and weak climate disclosures, as well as lobbying politicians on policies that risk accelerating the climate crisis. Big oil companies need to cut their carbon emissions by 35% by 2040 to achieve the goals of the Paris climate agreement, according to a recent report by the financial thinktank Carbon Tracker. But Shell is forecast to increase its combined oil and gas output by 38% by 2030. “This is a puzzling situation and one that is compounded by Shell’s refusal to disclose its future production schedule and whether it is indeed on track to meet its global obligations,” Savova said. LGIM, which is one of the UK’s biggest fund managers with £1tn in assets, has acknowledged that the oil and gas industry cannot continue to expand if the world is to meet climate targets. “However, there is no widespread agreement on what individual companies need to do,” it told PensionBee. The fund manager stressed the need to “balance” environmental and financial concerns when putting together the investment portfolio. “The fund has already significantly reduced exposure to hundreds of carbon-intensive stocks. Further exclusions might have unintended financial impacts. For example, Shell is one of the largest payers of dividends in the UK.” LGIM said it was seeing “positive signs” from the oil company, which this year announced plans to quit the American Fuel and Petrochemical Manufacturers lobby group over differing views on climate policy. Shell has also gone further than most of its peers by setting carbon reduction targets that include customer emissions and investing in low-carbon technologies, the asset manager said. LGIM, which has become one of the most outspoken fund managers over the climate crisis, said the oil company could do more and it was pushing for greater transparency on how Shell’s production plans aligned with the Paris agreement. LGIM also plans to monitor how Shell meets its emissions targets. The investment firm said if it had significant concerns about Shell’s climate strategy it would vote against the chair of the business or dump its shares from its Future World Fund. Shell said the company fully supported the Paris agreement and had already invested billions of dollars in a range of low-carbon technologies including biofuel and wind power. “We’re committed to playing our part, by addressing our own emissions and helping customers to reduce theirs.”"
"
Share this...FacebookTwitter[Sticky post…new articles follow after this one.]
=====================================
By Ed Caryl
This is a follow-up to the article AWI’s Sloppy Antarctic Peninsula Science…Overlooked GISS Temperature Data, Snowfall Amounts. The reality is that the situation at the South Pole is worrisome.
Ocean around Antarctica markedly colder since 2006…
It is difficult to believe that global warming/climate change is doing anything to the glaciers of the Antarctic Peninsula and the Western Antarctic. Here is why: The ocean around Antarctica has been getting markedly colder since 2006; sea ice is increasing, especially since 2012; and land temperatures have been cooling since the El Niño of 1998.
0 – 100m ocean temperature plummeting:

Figure 1 is the upper 100 meters of ocean south of 60°S. There’s been a rapid cooling since about 2007. Negative numbers are used to select latitudes in the Southern Hemisphere. The source is KNMI, link.
Sea ice skyrockets…

Figure 2 is the Southern Hemisphere sea ice area anomaly. The source is KNMI, link.

Figure 3 is a plot of the annualized ocean temperature and Southern Hemisphere ice extent using the KNMI data from figures 1 and 2. Ocean temperature is inverted to show that the ice extent matches the cooling ocean. Note the correlation between the two curves. 
Antarctic Peninsula sees dramatic cooling…



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 4 is a plot of the temperature anomalies at 13 Antarctic stations on or near the Antarctic Peninsula. The baseline is the 1998 to 2014 average for each. Antarctic peninsula has been cooling since 2000. Data source: GISTemp, link.
There is a lot a variation in the annual average temperatures for these stations, especially in the years where there were only two stations reporting, Esperanz and Faraday. For that reason, the average in figure 5 begins in 1963 when O’Higgins began reporting.

Figure 5 is the average anomaly for the stations in figure 4.
There were two peaks in temperature, one in 1989 and a second during the El Niño year of 1998 which caused a steep upward in temperature world-wide, and especially in Antarctica. But since then there has been a dramatic cooling. There is no “hiatus” on the Antarctic Peninsula, there is marked cooling.
Larsen Ice Shelf station cooling at a rate of 18°C per century
Cooling is especially true of the very location everyone is concerned about, the Larsen Ice Shelf. There is an automated weather station (AWS) there that has been reporting continuously since 1995.

Figure 6 is the annual average temperature at the Larsen Ice Shelf. The source is GISTemp.
Figure 6 shows the step in temperature in 1998 at the Larsen Ice Shelf. The trend in cooling after 1998 is 1.8°C/decade, the second fastest cooling on the Peninsula. Butler Island is cooling faster, at 1.9°C/decade. (Of course 18°C/century cooling is meant as sarcasm, and is only a trick that warmists like to use.)
Result: exploding sea ice
It is easy to see why the sea ice around Antarctica is increasing. The average ocean temperature from the surface to 100 meters dropped below the freezing point in 2008 and has stayed there. It is hard to melt ice when the water it is floating on is below the freezing point of fresh water, and seldom rises above that temperature.
The Southern Ocean around Antarctica has similar warming and cooling cycles as the North Atlantic, just not as strong. The cycle is now going negative, and temperatures on land and in the ocean are going sharply cooler, with ice increasing. There is no warm ocean water melting ice shelves from below. The ocean is getting colder and is below freezing most of the time. Any increase in ice calving off the glaciers must be from increased snow feeding those glaciers or geothermal heating from volcanism under the ice.
Welcome to reality.
Share this...FacebookTwitter "
"Something happened in 2017. Australia is second only to Canada in welcoming immigration on a large scale. Our faith in the benefits of accepting newcomers of all faiths and races is rock solid. But a couple of years ago we began to grow impatient about the government’s management of the immigration program, impatient in particular about overcrowding in our cities. This is the verdict of the Scanlon Foundation’s 2019 Mapping Social Cohesion report, published on Tuesday. The mission of the foundation for the past decade or so has been to measure how this migrant nation hangs together. In that time an extraordinary 50,000 of us have been polled to track the hopes and fears that sweep Australia – and not just about immigration. The author of the reports, Prof Andrew Markus of Monash University, finds most Australians now share “an underlying concern about the government not properly managing the situation – the impact on overcrowding, house prices, environment”. Markus is one of this country’s leading authorities on the politics of race and this is the 12th report he has written for the Scanlon Foundation. His findings are a civilised rejoinder to those who skew politics to the far right in this country that their racist constituency does not speak for the nation. But in 2019 Markus fears impatience with government management might imperil majority support for Australia’s immigration program. “This has not yet occurred, but the potential is evident.” We are not Europe. Asked every year to name the most important problem facing their countries, Europeans have lately nominated immigration. “It’s sort of cooled down a bit now,” says Markus, “but even to the present day when people are asked what’s the main issue for the EU, they still nominate controlling population movement and immigration.” Not in Australia. We always put the economy at the top of the list. Immigration came in fourth in 2019, nominated by 6% of us. In second place on the list, after an abrupt rise, is the environment and climate change. Markus has never seen such a sudden surge. The last was after the the Lindt cafe siege, when for a few years about 10% nominated national security and terrorism as the great problem facing the nation. “But this year climate change went not to 10, it went to 19,” says Markus. “And that’s so far ahead of the third issue. There’s a lot of daylight there.” The importance of the shift is underlined by the discovery that climate sceptics have all but lost traction. In 2011, when 11% of us said climate change was our biggest worry, another 6% nominated overreaction to those fears as the great problem facing Australia. The following year, the sceptics outnumbered the climate worriers almost two to one. Not any more. Against the 19% nomination for climate change in 2019, the sceptics could muster, at best, a contrary 1%. Markus sees this shift as an acute challenge to Canberra. “Morrison has got an opportunity to actually rebuild some capital in effective government,” he says. “But he’s got this issue of climate change. If he doesn’t deal with that, which is emerging as a major issue, that could very seriously damage this government.” Markus began his work at the end of the Howard era and the arrival of Kevin Rudd. In those years of hope and renewal, the Scanlon survey showed nearly half of us believed government did the right thing for the Australian people almost always or most of the time. But with Rudd’s collapse in 2010 went a good measure of trust in government. It has never recovered. In the weeks before Malcolm Turnbull’s downfall, the Scanlon survey of 2018 revealed only 29% believed in the good intentions of Canberra. After the re-election of the Morrison government this year, the figure is essentially unchanged at 30%. It’s a long slide, but Marcus disputes claims in other surveys that Australia is experiencing a catastrophic loss of faith in democracy. “There are some people out there who do surveys with small samples,” he says. “And with small samples from one year to the next you will get variability. And that produces headlines. “But we’ve got I think the most rigorous way of surveying. We actually do it in two different modes – by telephone and by self-administration – and what that is showing is much more a picture of ‘steady as she goes’ rather than dramatic decline.” The education line cuts across the immigration debate like a mighty trench They shift a little, and the shifts have lately been gloomy, but year in and year out the steady findings of the Scanlon surveys define Australia: 90% of us have a sense of belonging to this place. 87% are proud of the Australian way of life. 85% agree multiculturalism has been good for Australia. 84% report having a happy 2019. 80% welcome resettlement in Australia of refugees assessed abroad. 79% oppose selecting immigrants by race. 73% believe Australia is a land of economic opportunity where, in the long run, hard work brings a better life. 71% believe globalisation is good for the country. 68% believe accepting immigrants from many different countries makes Australia stronger. 62% are optimistic about Australia’s future. Then there’s the darker side: 61% of Australians disapprove of asylum seekers making their way here by boat. 47% of us have little or no concern about the treatment we mete out to asylum seekers in PNG and Nauru. 40% in 2019 admit negative or very negative feelings towards Muslims. The level of hostility to Muslims was masked until a couple of years ago, when the Scanlon Foundation began parallel tracking its research. Telephone interviews over the years showed 21% to 25% of us hostile to Islam. But these figures essentially double when surveys are completed in private and online. The gap between the two sets of results shows us to be a polite people. We hesitate to admit personal unhappiness or gloom for the future of the country. We clearly don’t enjoy confessing to strangers that we’re in financial trouble. A little of our optimism about the impact of mass immigration evaporates online. We’re even shy of confessing to strangers that we don’t much like Christians – only 4% would own up to that on the telephone in 2019, but 14% said so clearly online. Markus argues that while our sunny picture of the country darkens a little when we answer in private, those Australians most hostile to race speak loud and clear however they are surveyed. “The views of the hardcore negative types are pretty constant irrespective of the surveys,” says Markus. “And often it’s around 10% of the population. Now it would be a worry if self-completion surveys then showed it wasn’t 10% but it was 20% to 25%. But it’s actually pretty constant.” So who are the most hostile to immigration? Easy answer: One Nation voters. The 2019 report shows One Nation voters are profoundly pessimistic about Australia’s future; loath globalisation; don’t give a rats about the environment; are scathing about the motives of government; dismiss multiculturalism; are fiercely hostile to Muslims; couldn’t care less how harshly we treat asylum seekers; and are the only group in the survey – young and old, rich and poor, city and country – where most still hanker for the old White Australia policy of selecting migrants by race and religion. How important here is the city/country divide? Not at all on the importance of climate change. Wherever we live in cities or the bush, we agree that after the economy, the climate is the single biggest problem facing Australia today. But on immigration, the gap between city and country widens significantly. The 2019 survey found that outside the capital cities there was an 8% drop in support for multiculturalism; a 4% rise in those wanting immigrants selected by race and religion; a 6% fall in those concerned about the treatment of refugees; and, though the bush is where migrants don’t settle and governments are desperate to send them, a nine-point jump to 49% of those who believe Australia’s immigration intake is too large. The fundamentals are sound, even as about one in 10 of us continue to rage against this new Australia of many faiths and many cultures But this is not the most dramatic divide revealed in the Scanlon surveys over the years. The education line cuts across the immigration debate like a mighty trench: Only 27% of university graduates say Australia takes too many immigrants, but for those who never finished high school the figure is 70%. Nearly 90% of graduates applaud multiculturalism but only 61% of those who never finished school. Among graduates, 58% worry we treat refugees too harshly, but their fears are shared by only 32% of who never finished school. While a rump of 14% of graduates still wish immigrants could be chosen by race, support for the old White Australia position more than doubles to 35% who never finished school. Western Australia emerges from the survey as a fascinating puzzle: wildly optimistic about the future of the nation, peculiarly trusting in government, little perturbed by climate change and not particularly worried about the size of the immigration intake. But of all mainlanders, West Australians are most keen to select immigrants by race and are, by a long shot, the most hard-hearted about Australia’s treatment of refugees. Nothing Canberra has done to its prisoners in PNG and Nauru in the past couple of years has budged the national 50:50 split between the indifferent and the sympathisers. Markus says: “It’s pretty rock solid.” But when these figures are broken down by political alignment, Markus sees signs of movement. Thirty per cent of the Liberal constituency say Australia is being too harsh, compared with 87% of Greens. The 2019 figure for refugee sympathisers in Labor ranks is 61%. “It is a huge problem for Labor,” says Markus “because the government with its constituency can keep doing what it’s been doing, but it really wedges Labor.” Are Christians notably more compassionate? Certainly not Anglicans. In 2019 only 39% of them could muster some sympathy for the asylum seekers Australia is putting through the mill out in the Pacific. Markus doesn’t blame their God. He says gently: “Conservative old Australia.” Though not quite so bleak, the figures for the other faiths put paid to the notion that the churches are mighty reservoirs of sympathy for refugees. On the subject of the Pacific solution, Catholics come in slightly under the national split, with only 46% of them reporting some or a great deal of concern for what Australia is doing to refugees. That’s typical. On issues such as the size of the immigration intake, support for multiculturalism, a hankering for the right to pick migrants by race and confidence that immigrants improve our society by introducing new ideas and cultures, the churches don’t put the attitudes of the rest of the community to shame. At best they merely mirror them. Markus ran some figures for Guardian Australia which show that on nearly all questions asked in the survey – including concern for climate change – the progressive horse to back is those who nominate No Religion. Overall, Markus is a grim optimist. Reports of discrimination are too high, but not for the moment growing higher. The fundamentals are sound, even as about one in 10 of us continue to rage against this new Australia of many faiths and many cultures. It’s in the government’s hands whether we continue to support what is in world terms very high support for large scale immigration. Markus is at pains to emphasise that multiculturalism backed by almost all of us is a two-way street. “They’re saying we recognise that diversity is good, that diversity has made us a better country. You get very high levels endorsing the notion that immigration improves society by bringing new ideas and cultures. “But on the other hand, it’s two-way because the expectation is that immigrants will, over time, be more like us. It’s not an endorsement of pluralism. It’s an endorsement of a two-way change and obviously in that change the immigrants are changing more than the host society.” But we’re all changing? “Yes. We’re moving. But they’re moving more.” "
"Australia’s peak scientific institution has told an inquiry into the reliability of Great Barrier Reef science that it is “greatly concerned” over a trend to cherrypick and misrepresent scientific evidence. In a submission to a Senate inquiry, the Australian Academy of Science’s president, Prof John Shine, wrote that selective use of science and misrepresentations were “dangerous” and would lead to “poor outcomes”. The inquiry, introduced by the Nationals senator Susan McDonald and the Liberal senator James McGrath, is looking at the evidence linking pollution from farm runoff to degradation of the reef. In the months leading up to the inquiry, industry groups including Canegrowers and AgForce had sponsored a speaking tour by the controversial scientist Dr Peter Ridd, who claims that the reef is not being damaged by farm pollution. He also disputes evidence for human-caused climate change, and claims that mass coral bleaching events on the reef are natural. The campaign had aimed to pressure the Queensland government to withdraw proposed legislation, which later passed, that set limits on nutrients, sediments and chemicals running into the reef’s catchments. Australia’s former chief scientist Ian Chubb, who chairs an expert panel of reef scientists, likened the campaign to the tactics used by the tobacco industry when it attacked the science linking its products to cancer. In his submission, Shine wrote: “The Australian Academy of Science is greatly concerned about a recent tendency to ‘cherrypick’, dismiss, misrepresent, or obscure scientific evidence or smear individual scientists.” Later in the submission, he added: “A commonly used tactic in opposing or advocating for policy positions is to ‘cherrypick’ scientific findings rather than consulting and analysing the body of literature systematically. “Cherrypicking evidence to support a decision or position is dangerous and leads to poor judgment and outcomes.” The academy said it backed the methods and findings of a 2017 Scientific Consensus Statement on the impacts of poor water quality of the reef. The Australian Environment Foundation – a group that promotes climate science denial and supported Ridd’s tour – has also written to the inquiry, repeating Ridd’s claims that science linking farm pollution to the reef was “demonstrably wrong or unreliable”. • Sign up to receive the top stories from Guardian Australia every morning Dr Jennifer Marohasy, a former long-serving director at the AEF who now works at the Institute of Public Affairs, claims in a submission that water quality is improving along the reef, and that governments were conspiring to “maintain the perception of declining water quality”. Last week one reef scientist explained to Guardian Australia that Marohasy had misrepresented her work in an IPA video. The submissions also reveal a split among Queensland’s canegrower industry groups. The Proserpine and Bundaberg districts continued to question the science in their submissions, while groups in Cairns and the Herbert River said farm runoff was damaging to the reef but challenged the need for regulation. The Queensland Farmer’ Federation also said it had “no reason to question that land-based runoff continues to impact water quality in the GBR, and that agricultural activities contribute to this”. As reported by Guardian Australia, the federation’s newly elected president, Allan Dingle, the chairman of Bundaberg Canegrowers, has been an enthusiastic backer of Ridd’s claims. He has characterised the science underpinning the Queensland government’s laws as “unsubstantiated scaremongering”. The farmers’ federation manages more than $4m of taxpayer-funded water quality improvement grants from the federal government’s controversial grant to the Great Barrier Reef Foundation. A submission from the Department of the Environment and Energy highlights how the world heritage committee had expressed concern in 2017 that water quality on the reef was not improving. The committee will review the reef again next year. In August the Great Barrier Reef Marine Park Authority downgraded the reef’s long-term outlook from “poor” to “very poor” for the first time, citing impacts from climate change as a key driver. The Senate inquiry is due to issue its report in October 2020."
"
Share this...FacebookTwitterThe Sun in April
By Frank Bosse and Prof. Fritz Vahrenholt
[Translated, edited by P Gosselin]
The sole real source of energy for our planet also was also below normal in April: The sunspot number (SSN) was 54.4. Taking the average of the previous 23 cycles, that is only 70% of what is average for this month into the cycle.
Compared to March activity rose some 46%. These short-term changes however are usual noise in the overall signal, which says the entire activity since the current cycle began has been only 53% of the mean value since 1750.

Figure 1: Current solar cycle 24 (red), the mean solar cycle (blue) and the similar solar cycle  no. 7, which took place from 1823 to 1833 and was the last in the Dalton Minimum.
The comparison with solar cycle no. 7 could see increasingly large deviations in the months ahead, as solar activity increased markedly, as depicted by sharp peaks of the black line in Figure 1. Such a development appears highly improbable for solar cycle no. 24. What follows is a comparison of all cycles:

Figure 2: The accumulated solar cycle sunspot anomaly for all cycles 77 months into the cycle. The current cycle began in December 2008.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Figure 3: The speed of the solar wind, which impacts the Earth’s upper atmospheric layers, has fallen off since the early 1990s. It is expressed as the geomagnetic Ap Index. It is a measure of the sun’s impact on the Earth’s magnetic field. Source of the image: Climate4you.
Not only the Earth is impacted by the solar winds, but also the entire sun’s surroundings far out in space. The heliosphere reacts to the stream of particles from the sun. When it is weaker – as is the case during times of solar minima – more cosmic radiation from the Milky Way can penetrate into the Earth’s atmosphere. This is measured here on Earth, e.g. in Moscow since 1958:

Figure 4: Changes in cosmic radiation
During the solar sunspot number maxima (compared to 2000) the solar wind is stronger and thus reduces cosmic radiation by up to 20% when compared to the minima in activity. The current cycle (maximum is already over) is bringing only about an 8% reduction. Over the entire period since 2006 there has been significantly more cosmic radiation than any such period since 1958.
Another factor involved with solar activity is UV radiation. It strongly depends on the sunspot number because the ultraviolet radiation is produced in the areas near sunspots. Unlike the other visible ranges of the spectrum, sunspots in UV images appear brighter than the surrounding areas. Although UV radiation mainly has an impact in the stratosphere, there are top-down effects that lead to impacts to the troposphere.
The signals for solar activity all continue to point to “very low“. We can all wait with suspense to see what impacts the low solar activity will have.
Original German version here.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn former times, the job of official climate witch-hunting had been one of the German Ministry of Environment, which even went so far as to identify, target and attack skeptic US and German scientists and journalists – all because they held non-alarmist views on climate change. Fortunately that activity turned out to be somewhat embarrassing, and thus the activist Ministry thought that it was best to end it.
But not to worry, the witch-hunting business has found a new home: at the site of the end-of-world climate conspiracy theorists: Klimaretter.info – a leading alarmist site run by a group of highly influential climate doom-infatuated persons.
Hat-tip: Die kalte Sonne
Klimaretter.info (in English: climate rescuers.info) is now offering a new, very special service to readers: They now have the chance to deliver “explosive disclosure material” on climate skeptics and their clandestine activities at an anonymous letter box: The klimaretter.info site explains:
Here you can discretely and anonymously deposit internal documents, information, data sets, bank accounts, and similar material when you think that the public needs to know about it.”
The klimaretter site even promises that materials will be handled in “strict confidentiality”, and that tracing back to the discloser will not be possible.
Many of us of course will naturally view this as a step back into the old authoritarian, go-after-the-enemy days in darker German times. Is this all they have left? Are they totally bankrupt of argument in the arena of debate that they now have to resort to gutter skimming and dumpster diving? Perhaps they ought to get in touch with Peter Gleick to find out how to acquire explosive documents.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So who are these people at klimaretter.info? A look at their website tells us a lot already. It’s mainly made up of a group of powerful lobbyists working on behalf of the renewable energies industry, or the reinsurance industry. Among the publishers at Klimaretter are Hartmut Grassl, former director of the WMO and the Max Planck Institute for Meteorology in Hamburg. According to other sources, it turns out he is also a foundation board member of reinsurer Munich Re!
Other klimaretter.info publishers like Claudia Kemfert, Gero Lücking, Jens Mühlhaus, Matthias Willenbacher or Klaus Franz are directly connected to the multi-billion dollar green energy industry. Kemfert is also a member of the Club of Rome.
Pots ought to be careful about going around and calling others black.
Send in your explosive documents
Already skeptic site Die kalte Sonne tells here that the klimaretter.info secret letter box has gotten some success. Die kalte Sonne writes that they have delivered a comprehensive package of “explosive material” consisting of (1) important scientific papers on the sun’s impact on climate, (2) a bank statement of an explosive visit to a pizza eatery concerning the last international climate conference and (3) discrete sea level data showing an average rise of 1.5 mm/yr. But don’t get your hopes up that we’ll be reading about that at Spiegel, or Die Zeit.
Die kalte Sonne also would like to know who are the generous donators to Al Gore’s Climate Reality Project.
If readers here should happen to have in your possession explosive information like photos, documents, bank transactions, e-mails, datasets, etc. that you feel the public needs to know about, then do send them to the confidential letterbox of the climate rescuers at klimaretter.info here. Perhaps you ought to send them the cream of the Climategate e-mails.
 
Share this...FacebookTwitter "
"Greta Thunberg is to swap leading the global fight against the climate crisis for the more stressful experience of directing a group of high-profile BBC presenters, after being announced as one of this year’s guest editors for Radio 4’s Today programme. The environmental activist will take control of an episode of the BBC’s flagship radio news programme at the end of this year, speaking to leading figures in the fight against global heating and hearing from indigenous, frontline activists. Thunberg, who led school strikes around the world, has also commissioned reports from the Antarctic and Zambia, as well as a Mishal Husain interview with the governor of the Bank of England, Mark Carney.  The 16-year-old, currently sailing across the Atlantic ocean to attend the UN Climate Action Summit in Madrid, had only just been born when the Today programme began the tradition of appointing public figures to guest edit programmes in the quiet news days between Boxing Day and New Year’s Eve. This year’s line-up also includes Lady Hale, the president of the supreme court, who is due to retire as the UK’s top judge when she turns 75 in January. She will give listeners a tour of her North Yorkshire hometown and the supreme court, while challenging the audience to “explore the issue of coercive control”. Hale, a former law lecturer who has campaigned for greater diversity in the judiciary, hit the headlines in September when she delivered the supreme court ruling that Boris Johnson’s government had illegally suspended parliament. She has since been immortalised in a children’s book charting her journey from Richmond to the top levels of the legal profession. The Turner prize-winning artist Grayson Perry will work with the Today team to examine “stereotypes and conventional thinking” during his episode, while another guest editor spot will go to the rapper and spoken word artist George the Poet, who will report from Uganda and explore issues around identity. The final guest editor slot will go to Charles Moore, the former editor of the Daily Telegraph, who will focus on freedom of expression in modern society. Moore, who wrote the authorised biography of Margaret Thatcher and founded The Rectory Society for fans of clergy dwellings, has previously criticised the BBC over its perceived anti-Brexit bias."
"Catastrophe is looming for the banana industry. A new strain has emerged of a soil-borne fungus known as “Panama disease” which can wipe out entire plantations – and it is rapidly spreading around the world. Farmers in Australia, Latin America and across Asia and Africa all fear the worst. The fungus is almost impossible to stop or eradicate. It moves through soil, so contamination can be as simple as infected dirt travelling from one farm to another on the sole of a shoe, or as complex as soil particles blowing on the wind across long distances – even across oceans, in theory.  Faced with huge losses to a global industry, many have called for a new strain of disease-resistant “superbanana”. However, this would be just another temporary fix. After all, the world’s most popular banana, the Cavendish, was itself the wonder fruit of its day, being introduced in the 1950s after an earlier strain of Panama disease destroyed its predecessor.  The fungi simply adapted and fought back, though, until the Cavendish also became susceptible. Panama and other diseases will continue to do so until we seriously reform how we grow and market bananas.  The banana industry is its own worst enemy. The huge farms where most exported bananas are grown are ideal for pests. These plantations are monocultures, which means they grow only bananas and nothing else. With very few shifts between crops over the years, and lots of tropical sunshine, there is an abundant and year-round supply of food for pests without any breaks, in time or space, to disrupt the supply and lower the disease pressure. Banana producers spend a third of their income on controlling these pests, according to a study I published in 2013. Chemicals to control microscopic but deadly worms are applied several times a year. Herbicides that control weeds are applied up to eight times a year, while bananas may be sprayed with fungicides from a plane more than 50 times per year in order to control Black Sigatoka, an airborne fungus.  And those bags that are wrapped around each individual banana bunch? They’re lined with insecticides to serve as both a physical and chemical barrier to insects feeding on and damaging the skins. All of this amounts to approximately one litre of active ingredients for every 18.6 kg box of bananas that is exported to consumers in the global north. It’s a huge, long-running problem for the industry and the new strain of Panama disease may just be the nail in its coffin. Or maybe this is the wake-up call the export banana industry so desperately needs. Given the way the fungus spreads, containment and quarantine are hardly long-term solutions. Some experts, especially those entrenched in the business of growing export bananas, argue that we need to breed or genetically modify a new type of banana that is resistant to the latest strain of Panama disease. But this is harder than it sounds. Modern bananas – the tasty yellow ones – don’t exist in nature; they were bred into existence around 10,000 years ago. They reproduce asexually, which means they don’t have seeds and every banana is a genetic clone of the previous generation.  This lack of genetic variation makes breeding a new banana particularly challenging. If one Cavendish is susceptible to a disease, all others will be too. When all bananas are clones, how do you create the genetic variation from which traits for better disease resistance can be identified and nurtured? A new banana would also have to be tasty, durable enough to withstand long voyages without bruising, and bright yellow. Looks really do trump pest-resistance. A new type of banana introduced during a previous Panama disease panic back in the 1920s was rejected by consumers for going black on the outside, even when it was ripe and sweet inside. Today, banana growers are in a fight for survival, continuously applying newly-formulated fungicides in an effort to keep ahead of the diseases. But they are acutely aware that they are losing ground. While breeding a new banana staves off the current problem, history has already shown that this doesn’t get to the root of the problem, which is the design of the production system. We need to ditch the massive farms. Around the world, millions of small-scale farmers already grow bananas in a more organic and sustainable way. Alongside bananas are cacao, avocado, mango, corn, orange, lemon and more. A mix of crops creates more stable production systems which rely on fewer, if any, pesticides and generates diverse income sources, handing local people greater food sovereignty. Farms where bananas are mixed in with other crops are also more resilient to climate change which is likely to hit banana-producing regions – developing countries – harder than most. Yes, this would mean fewer bananas are grown. Sustainable agriculture simply can’t keep up with the megafarms. But if we learned to ignore the odd blemished or undersized banana, then the actual amount sent to market need not drop at all.  The farmers themselves should be okay as they’ll make up their income by producing different crops. Breaking the dominance of the banana multinationals should also distribute wealth among more farmers and empower the regions where they’re grown. As a consumer, ask yourself this: isn’t that a far better way to spend your money?"
"
Share this...FacebookTwitterDr. Sebastian Lüning’s and Professor Fritz Vahrenholt’s “Die kalte Sonne” site here bring us a perfect example illustrating how debate losers like to handle debate: simply declare it over and walk away. (Translated and edited by P Gosselin)
===========================
The Heinrich Böll Foundation runs a climate blog called “Klima der Gerechtigkeit (Climate of Justice). Author Lili Fuhr writes regularly there on topics like “James Hansen predicts much higher sea level rise over the coming decades: 2°C more is much too much!” or “Pope opposes emissions trading in climate protection”. In the reader comments there really isn’t much going on. Perhaps there’s a very strict moderation in place? Indeed at the site it is stated:
We are beyond whether climate change is taking place and whether it is caused by man. It is aseptic to continue this debate. Now it gets down to having a discussion on what is the best way to combat it [climate change].“
Following the Boll Foundation’s logic we’d also lead an aseptic debate. This saddens us naturally because we are convinced that climate is changing, and that this always happened in pre-industrial times. Perhaps readers would like to inject a little life to Lili Fuhr’s blog and leave a few comments? Here you can go to her blog. Kalte Sonne chief Editor Sebastian Lüning tried, and within 50 milliseconds a reply page appeared bearing the message: “Spam deleted”. That’s what we call an especially rash and consequential comment oderation..
 
 
Share this...FacebookTwitter "
"Llamas recently have become a relatively common sight around the world. Whether you live in England or New South Wales, Canada or New Zealand, you don’t have to go too far to find a llama now. Indeed thousands of llamas are registered in the UK, where the species has emerged as a popular (if seemingly unlikely) choice for many aspiring livestock owners and is winning new admirers by the day.  While the llama is currently on the up, its history has not always been so rosy. Reared intensively by the Incas, llamas suffered severely at the hands of the Spanish conquistadors and still lack the genetic diversity they enjoyed in Pre-Columbian times. But over the past few decades, llamas have flourished as a global commodity, fulfilling novel roles and gaining an international profile.  So how has the llama gone from near extinction to global sensation? The ancestors of the llama originated in the Great Plains of North America around 40-50m years ago and migrated to South America 3m years ago, when a land bridge formed between the two continents. Llamas themselves are believed to be descended from guanacos – their wild cousins – and were first domesticated around 4,500BC.  As the only livestock to be domesticated by humans anywhere in the New World, South American camelids fulfilled a role in the Andes equivalent to horses, cattle and sheep in Europe, furnishing ancient Peruvian civilisations with transportation, clothing and sustenance. They occupied a crucial place in the cultures of the Nazca (c. 200BC-600AD), Moche (c. 0-700AD), Wari (c. 600-1000AD) and Chimu (c. 1300-1470AD). Llamas are most closely associated with the Incas, who used them as beasts of burden and sacrificed thousands of the animals every year to their gods. In the month of Capac Raymi (January), for instance, they sacrificed 100 camelids with “long wool and stiff straight tails”; in the following month, Camay (February), they sacrificed 100 “light brown” camelids, “white from the knees down, with white heads”.  While such large numbers of sacrifices might have been expected to seriously reduce llama numbers, careful management ensured that the flocks survived and prospered. The Incas refrained from killing female llamas, to ensure that stocks remained for breeding. They also developed a novel method of treating a disease called “carache” (probably scabies), burying afflicted beasts “at once, deep in the ground” to prevent them infecting the entire flock. They also conducted a census of camelids every November to calculate their number, recording the results in quipus – knotted threads employed as a form of account keeping.  Unfortunately, such careful practices were not maintained after the Spanish conquest, and the llama faced annihilation. While some wild species (such as jaguars) likely benefited from the arrival of the Spanish – and the consequent reduction of the human population of the Americas – llamas suffered the same fate as their human owners. Over-exploited for their meat, attacked by newly imported diseases and out-competed for grazing by sheep, llamas perished in huge numbers, experiencing a demographic decline of 80-90% in the first 100 years after the conquest. Llamas were initially very much victims of globalisation, their numbers plummeting dramatically during the “Columbian Exchange” of the 16th century. But since then, llama populations have gradually rebounded and extended their range beyond South America. Between 1773 and 1778, the veterinary school at Alfort in France possessed a llama, which was examined by the famous naturalist George Louis Leclerc, Comte de Buffon. In 1805, the first llama to be exhibited in Britain was put on display at Brookes’s Menagerie in London, and by 1829 London Zoo owned two llamas. One of these – of the white variety – was described as “gently, mild and familiar”; the other – a brown animal – as “morose” with a penchant for spitting at visitors. Today, llamas are big business and their uses have expanded to include livestock guarding, therapy and agility training. In Peru and Bolivia, the animals continue to be used as beasts of burden in rural areas and retain some of their sacred connotations. They also appear increasingly as tourist attractions, gambolling around the Inca ruins at Machu Picchu and posing for photographs in Cuzco and other tourist hot spots. In 2014, the Bolivian government lobbied the United Nations to make 2016 the International Year of Camelids, emphasising the “economic and cultural importance of camelids in the lives of people living in areas where they are domesticated”.  Beyond South America, llamas have been employed to protect sheep, comfort the sick and stock many a hobby farm. In the US, a llama named Rojo conducts regular visits to hospitals, schools and old people’s homes in Oregon, while a golf course in North Carolina employs several llamas as caddies. Llamas have also been used in various parts of the globe to protect livestock from predators, shielding sheep, calves and poultry from attacks by foxes, wolves and coyotes.  The llama is one victim of globalisation to survive demographic catastrophe and come out the other side an international animal, loved, farmed and traded around the world."
"Labour’s “green new deal” – or “green industrial revolution” – puts a radical environmental plan at the heart of the party’s election offer. It proposes a massive programme of state investment to rapidly decarbonise the economy, which it says would create hundreds of thousands of green jobs.  The party says the programme would also transform the way people live – from upgrading the UK’s entire housing stock and revitalising public transport to boosting renewable wind and solar industries and decarbonising the country’s energy supply. Although the initial investment would be large, advocates say that would be dwarfed by the cost of not tackling the escalating climate crisis and point to wide-ranging economic benefits, which experts say would total at least £800bn by 2030. The green new deal aims to tie far-reaching environmental action to a worker-led “just transition”, where the rapid move from a carbon-based economy to a sustainable system is led by – and benefits – ordinary people. The party, which at its conference backed plans to hit zero emissions by 2030, has also said it would ban fracking and boost electric car infrastructure. The Tories say they want to double science and research spending to £18bn in the next parliament, with an unspecified amount going to new green technology. The party says it also wants to increase the number of public electric vehicle charging points so that everyone in England and Wales is within 30 miles of a charging point, with an investment of £500m. The party, which has been criticised over its record on onshore wind and solar power, says it will build more offshore windfarms, increasing the UK’s target capacity from 30GW to 40GW by 2030. It has also announced plans to plant 30m trees a year by 2025. It would create “clusters” of carbon capture and storage expertise around the country for £800m in the next decade, and a cabinet-level committee will oversee the commitment to reach its target of net zero carbon by 2050. It has also announced a review of the HS2 high-speed rail project and a moratorium on fracking. The party says it will establish citizens’ assemblies to thrash out new policy measures to tackle the climate emergency. It wants to revive the green investment bank, sold off by George Osborne, and end the sale of petrol and diesel cars by 2030. It would support onshore and offshore wind and solar power, with a target of 80% of electricity from renewable sources by 2030, and says all new homes would be fitted with solar panels. It says it would declare a nature crisis and work towards an international Paris-style agreement on preserving the natural world and biodiversity. It has pledged to plant 60m trees a year and impose a moratorium on airport expansion, including Heathrow. The party would ban fracking and new coalmines and has set a net zero target of 2045. The Greens say they would raise £100bn by borrowing every year for the next 10 years to pay for tackling the climate crisis through upgrading infrastructure, including shifting electricity generation to a low-carbon footing, insulating the UK’s draughty housing stock and expanding public transport. They aim to bring forward the UK’s target for net zero carbon from 2050 to 2030 and would scrap nuclear power and expand renewable energy. They are in favour of ending airport expansion, including Heathrow, scrapping HS2 and halting the current road-building plan, spending the money instead on local transport improvements. They would ban fracking and all fossil fuel expansion. The SNP is aiming for a 75% reduction of all emissions by 2030, net-zero carbon by 2040 and net zero for all emissions by 2045. It is proposing to “phase out the need” for petrol and diesel cars and vans by 2032, investing in active and sustainable travel by doubling cash for walking and cycling to £80m a year. It is introducing a deposit return scheme for drink containers to increase recycling and reduce littering. And an expert panel is looking at what else can be done to reduce demand for single-use items. It has banned fracking and underground coal gasification and says it is “championing the principle” of climate justice."
"
Share this...FacebookTwitterWith a whopping efficiency of up to 60.75%, it is considered the world’s most efficient gas-fired power plant; it’s the ultimate when it comes to turbine engineering (see following promo video).

“Answer to climate protection” to be mothballed! World’s most efficient gas-fired power generation plant to shut down as a consequence of a run-amok “Energiewende”.
No other conventional power plant on earth is able to extract as much energy from what gets put into it. And because it burns natural gas, the 1400-megawatt Irsching gas-fired Siemens SGT5-8000H power generating units emit relatively low amounts of CO2 and pollutants.
Yet its operators, among them energy giant E.on, are aiming to mothball the recently installed modern gas-fired facility for good. The reason? It’s losing money because Germany’s renewable energy feed-in act, which allows conventional plants to operate only when the wind and sun aren’t putting out.
Hat-tip: EIKE here.
The Irsching gas-fired power generators are unable to operate at a profit because the facility has to yield to wind and solar energy, which are mandated to be fed first into the grid by law. The result: the modern gas turbines are forced to operate intermittently when the sun and wind are AWOL, which means they are unable to cover their high operating costs. The dirtier coal power plants have lower operating costs, and so they are making a comeback. Result: the green energy revolution is leading to more CO2 emissions, and not less.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to FOCUS magazine, the Irsching gas-fired plant located near Ingolstadt in southern Germany has become “the symbol of the faulty development of the Energiewende” – Germany’s ongoing transition to green energies.
Industry association leader Hans-Joachim Reck, complains: “It’s the paradox of the Energiewende that now the cleanest and most efficient power plants in Germany, the gas-fired power plants, cannot earn money.”
The gas-fired Irsching facility isn’t the only one that risks being shut down because they are prevented from operating at their capacities and efficiencies. FOCUS writes: “approximately 50 applications to shut down similar plants have been submitted across Germany“. As more and more erratic solar and wind power come online, the less efficiently gas-fired plants operate. As a result, Germany’s stable component of its power grid is eroding rapidly.
So how bad has Germany’s energy policy become, outsiders may ask? At EIKE economist Dr. Klaus Peter Krause tells us:
What the political leadership has inflicted with its ‘Energiewende’ and continues to inflict is a ‘farce to the tenth power’. When it comes to the financial burden for Germans and the entire [German] economy, it will surpass the also ruinous euro bailout policy.”
That’s awfully ruinous.
The shutting down of gas-fired plants has already put the south German power supply stability at risk. Already the federal government has intervened and forbidden the mothballing of several gas power plants. This of course will only serve to further burden the power utilities with even more costs. Eventually those too will get passed on to German consumers, who are already paying the second highest electricity rates in the world. Little wonder 600,000 households can no longer afford it.
So far only about a quarter of Germany’s power is supplied by renewables. The target is 90% by 2050. Little wonder many experts think the whole system is going to collapse well before that.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhen a science finds itself having to resort to using professional marketing campaigns to get the public to buy it, then you can be reasonably sure something is awfully wrong.
Geologist Dr. Sebastian Lüning responds to and mocks the Potsdam Institute’s report released together with the World Bank.
===================================
Learning from the PIK means learning how to win: Clever Climate Marketing 2.0
By Dr. Sebastian Lüning
(Translated by P Gosselin)
When it comes to the business of climate change, we are dealing with lots of money. Thus it is only natural that the World Bank is getting into the act and playing the climate doomsday music. But to do this, it needs an ally. Fortunately there’s the Potsdam Institute for Climate Impact Research (PIK), which is sort of a mill that regularly churns out and markets new, entertaining horror scenarios.
The World bank has contracted the PIK to conjure up an entire series of climate alarms. Part 3 of the cooperation came to light in November 2014. Of course here one finds nothing new. Yet again the attempt was made to shock a climate-weary public with the usual old Biblical extreme-weather cocktail: hellish heat, huge floods and giant cyclones descending from the heavens.
Their efforts seem to have been accompanied by a professional marketing department that took on the task of coming up with hard-hitting marketing slogans and catchy messages. And so this is how they got the title ‘Turn down the heat 3‘, which also could be the name of a rock album. Hats off. The same can be said for the slogan: “Confronting the new normal”. Sounds great.
So why can’t us climate skeptics do the same? In our reports we all too often use ineffective terms, calling the other side names like “stupid alarmists”, “swindlers”, or “senseless”. What if instead we used terms like “Let’s get back to reason 5.0″ or “Accepting and understanding the Medieval Warm Period”?
Overall the structure of the PIK press release and the psychological fundamental elements used are carefully considered and crafted. The claim “Climate change impacts foremost the world’s poor” really does play on the heart strings:
‘Global warming impacts in the next decades are likely to hit those hardest that contributed least to global greenhouse gas emissions: the global poor.’ Developing countries are expected to experience the most severe climate impacts, notably in the tropics, while lacking the means to build resilience. And within these countries, again those parts of the population with the least means are most vulnerable to additional stress.”
A great marketing gag: the evil westerners are destroying the climate, particularly in developing countries. From a scientific point of view, it is totally baseless, yet it sounds really good and almost no one will dare to challenge the claim. That simply does not befit the rich westerner. Here for example the coral horror would be of much worth. Here’s how it’s written by the PIK:
In the Caribbean, coral reefs are threatened of significantly higher probabilities of annual bleaching already at 1.5-2 degrees warming… .”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Apparently knowledge of the latest literature on that subject is quite lacking at the PIK. Otherwise the Potsdam scientists would have known that the coral reefs have turned out to be far more warmth-resistant than previously feared. Yet the cooperation between the World Bank and the PIK has far less to do with facts, and much more with moral declarations formulated in catchy language that makes for good prose. The PIK director puts on his best act to mislead:
‘Tackling climate change is a matter of reason, but also of justice,’ says the report’s lead-author Hans Joachim Schellnhuber, director of PIK.”
This method would also work effectively for the climate realists side. For example we could write:
‘Recognizing the climate’s natural variability is a matter of reason, but also of justice,’ says Sebastian Lüning, DkS website director and number 2 lead author of the sustainable climate report ‘Die Kalte Sonne’.”
As is known since the discovery of the motion picture in Hollywood, a good story has a happy ending and allows for a bright outlook. Thus it is no surprise that this technique also gets used by the PIK and the World Bank:
‘The good news is that we can do something about it’
[…] The good news is that we can take action that reduces the rate of climate change and promotes economic growth, ultimately stopping our journey down this dangerous path. World leaders and policy makers should embrace affordable solutions like carbon pricing and policy choices that shift investment to clean public transport, cleaner energy and more energy efficient factories, buildings and appliances.”
A positive call to action is simply far more effective than making threats. The phrase “Good News” has been successfully employed in religions for a very long time, and also by cults. “The good news: You can transfer one third of your income to the account of our religion founder, and so cleanse yourselves of all your sins.”
Us skeptics should do as the PIK does and band together with a top performing team of marketing experts and psychologists so that we too can promote our scientific messages in the suitable format.
This step is not only a matter of reason, but also of justice. Learning from the PIK means learning how to win.
=======================
Sebastian Lüning is a geologist who has published numerous papers in his field. He is co-author of the climate science skeptical book: The Neglected Sun.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIt has been clear for a long time to those who simply observe climate that temperatures are driven by, in the long term, orbital and Earth tilt cycles, the Milanković cycles, in the medium term by solar cycles with ocean cycles. like the Atlantic Multi-Decadal Oscillation (AMO), and in the short term, by ocean and atmosphere cycles like the El Niño Southern Oscillation (ENSO).
A few researchers have used this information to project the future. An example can be found on the sidebar of this blog. A problem with these projections is that factors such as volcanoes cannot be predicted. Due to the chaotic nature of most ocean cycles, these also cannot be used to predict the future. Only the AMO is regular enough to extend into the future, and then only for one or two cycles.
The sun is our source of energy, and it also has cycles. The 11-year sunspot number cycles (SSN) are regular but seem not to affect climate in any cyclic way. Only the integrated energy over whole cycles seems to push temperatures, and this affect seems to be delayed by about one whole sunspot cycle. Here is a history of the last 150 years and a simple projection to 2050.

 
Figure 1 is a chart of the main influences on global temperature over the last 150 years. The red trace is based on the SSN processed with an 11-year trailing average. The purple AMO trace has been smoothed with a 9-year centered average. These were then combined with the annual average central Pacific El Niño 3.4 to produce the orange trace. The orange trace is a model of global temperature before volcanic cooling. The vertical green lines are named volcanic eruptions, the height of the lines is the volcanic eruption index (VE) using the right side scale. The blue trace is the global annual temperature average as published by GHCN.
For over a hundred years, the orange model follows the GHCN temperature closely except where perturbed by volcanic activity. Volcanoes can warm the atmosphere if they are primarily ash eruptions, or cool the atmosphere if they loft large amounts of sulfur dioxide into the stratosphere. The Askja eruption and caldera collapse in Iceland in 1875 produced primarily ash. That eruption plus a Grand El Niño the following year produced a warm year in 1876. The VE6 eruption of Krakatoa in 1883 and Tarawara three years later, produced five years of cool climate.
Santa Maria and Novarupta were two more VE6 eruptions, that along with a cool sun and a negative AMO sent temperatures plunging in the early 20th century. From 1918 until 1975, temperatures followed the ocean cycles and the sun very closely. Smoke and soot from WWII, along with a strong El Niño in 1942, may have caused the warming from 1939 to 1945. In contrast, a strong La Niña in 1975 that lasted for two years produced a pronounced cooling. This was the “ice age scare” of the late 1970’s.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




After 1978 a serious divergence began between this model based on sun and ocean cycles and the GHCN measurements, leading to the current 0.6°C difference. For UAH satellite measurements this difference is less, from 0.3°C to 0.45°C, depending on the level set for the 1979 record beginning relative to GHCN.
To account for this difference, the reader is urged to note the changes over the years to the global temperature records as found by the following reporters:
– Steven Goddard: Data Tampering At USHCN/GISS and about a thousand other posts on the same subject.
– Paul Homewood: Posts Tagged Temperature Adjustments, and Another GISS miss: warming in the Arctic – the adjustments are key
– Ira Glickstein: The PAST is Not What it Used to Be (GW Tiger Tale)
– Willis Eschenbach: The Smoking Gun At Darwin Zero.
– MS at The Hockey Stick: Paper finds more smoking guns of temperature data tampering in Northern Australia.
– Ed Caryl: A Light In Siberia. This was also posted here. And Is GISS Also Cheating In The Arctic?
– Jennifer Marohasy: Corrupting Australia’s Temperature Record, along with here, here, and others.
– Michael and Ronan Connolly: Global Warming Solved
These adjustments can account for the whole difference between the model and the GHCN temperature record. It is not necessary to invoke any CO2 warming. If it is there, it is very slight, on the order of 0.1°C.
The model indicates that it has been cooling since 2010, and that the cooling will continue as solar output declines and the AMO goes negative. Yes, the years from 1998 to 2010 were warmer than the 20th Century average because the globe was at the peak of all the natural cycles. But it is all downhill from here.
Cooling next 30 years
Solar activity is going into a decline as well. We don’t yet know if this decline will be to a Dalton Minimum-like level or a Maunder Minimum level. The model projection into the future does not contain ENSO or volcanic data as that data cannot be predicted. But it will get cooler for the next thirty years. The AMO will turn positive some time in mid-century, and solar output may not decline as much as indicated, so another full-blown ice age is not beginning, but a Little Ice Age may be starting. See here for further projections into the future based on the deVries 230-year cycle and the 1000-year Suess cycle.
 
Share this...FacebookTwitter "
"On the flat, marshy stretches of Maryland’s eastern shore, not a huge amount has changed since Harriet Tubman escaped from slavery here 170 years ago. Rivers and streams lace a wedge of land dotted with wood-board churches and small towns. Crabs and oysters are plucked from the adjacent Chesapeake Bay. The climate crisis is set, however, to completely transform low-lying Dorchester county, threatening to submerge some of the key heritage associated with Tubman, the celebrated abolitionist whose daring missions helped free scores of slaves from bondage in her homeland. If planet-warming emissions aren’t radically scaled back then swaths of the Harriet Tubman Underground Railroad national historical park, only established in 2013, will be inundated at high tide by 2050, according to projections by University of Maryland scientists. A $22m (£17m) Tubman visitor centre, completed in 2017, is set to be severely menaced by the rising waters, the analysis finds, along with several churches connected to Tubman and Joseph Stewart’s canal, where timber was transported from a business that had enslaved her father. “Dorchester county is a poster child as to what the rest of the world can expect with flooding,” said Peter Goodwin, president of the University of Maryland Center for Environmental Science. The county doesn’t rise more than 1.5 metres (5ft) above sea level and is exposed on three sides to the bay, which can act as a funnel to push storms on to the land. The seas could swell by as much as 60cm by 2050, a situation compounded by the fact the land is sinking, a hangover caused by the retreat of ice sheets from the last ice age. “It’s worrying,” Goodwin said. “The county is beautiful but it’s going to look very different. If we can get ahead of things and plan for the future then you can help define what the shoreline will look like. The problem is if you don’t do that then people are going to drift away and the culture will be eroded.” The situation is causing alarm among those who have highlighted Tubman’s legacy. “These landscapes are rapidly vanishing because of climate change,” said Kasi Lemmons, director of Harriet, a new film based on Tubman’s life. “Losing landmarks such as these underscores the need to protect and preserve the land and our national history for the generations to come.” Proximity to water for communication, transportation and food has long been intrinsic to Dorchester county but flooding is increasingly chipping away at the routines of day-to-day life. High-tide water lapped in residents’ front yards and is now reaching porches. Carelessly parked cars can end up sodden. School buses struggle to get down roads that are in constant repair. The storms are getting fiercer, as the water and atmosphere warms. The encroaching tides now also imperil the cultural touchstones of Tubman’s life. The former slave was born in Dorchester county in 1822 and despite suffering a severe head injury managed to escape to Philadelphia as a young woman. She then helped guide more than 70 enslaved people north to freedom via a network of safe houses and routes known as the Underground Railroad. Several locations on the Harriet Tubman Underground Railroad Byway, a driving loop of important Tubman sites, are already being eroded, according to Tubman’s biographer Kate Clifford Larson. “We’re not going to have those landscapes to tell those amazing stories if something doesn’t happen quickly,” Larson said. “In the 20 years I’ve been to these sites I’ve seen them start to disappear because of the water seeping in. “Some of the roads become impassable and you have to wait out until the water recedes. And some of the precious, really precious, African-American historical and cultural sites are at the most danger right now because they are in the lowest-lying areas.” Larson frets about where the resources will come to protect places such as the New Revived Methodist church in Smithville, in the heart of Tubman’s former community that often has a waterlogged graveyard. “They are going to need to move the graves and that costs a lot of money,” she said. “It’s frightening how quickly these sites are becoming threatened.” The Rev Darlene Dixon has only been the pastor of the New Revived for five months but has already experienced being temporarily cut off from her church by a storm that pushed 15cm of water on to the roads and on to the cemetery. “People are concerned, and naturally I am, too,” Dixon said. “The biggest part of their angst the unknown – which storm, which high tide will cause major damage.”  Dixon said a seawall may have to be erected to protect the church but that may not stop the surrounding community, already one of the poorest in Maryland, crumbling away as the flooding intensifies. “People here have big hearts but there are not many people left in the community because they want to make a living. There’s the fear of the water too,” she said. “We are seeing change occur before our eyes.” The National Park Service, which oversees the Tubman park, is putting together an assessment of the threats it faces. Deanna Mitchell, the park superintendent, said she reassures tourists that the visitor centre has been built on a relatively elevated piece of land with sea-level rise in mind. “It’s a beautiful facility and the landscape is beautiful, too,” she said. “Every time I go to work I’m immediately in a mode of reflection. I see that with visitors, too. “I’m optimistic that we can address whatever comes our way if people can come together on this. We are nine miles away from Chesapeake Bay, which gives us a sort of buffer. But that’s not a cure-all. There’s no way to deny that there’s sea-level rise.”"
"
Share this...FacebookTwitterHat-tip: European Institute for Climate and Energy
German power producer EnBW has sent a letter (see below) to its customers informing them that the situation was under control as tomorrow’s solar eclipse is poised to put Germany in partial darkness shortly before noon and to test the country’s power grid stability.
Because of the eclipse, up to 12,000 megewatts of PV power could disappear from the grid (if it’s sunny) in a mere hour at around 10:00 a.m. Then, shortly before noon, 19,000 megawatts could surge into the power grid in just an hour as the moon allows the sun’s radiation to shine back in unhindered.
EnBW warns of possible grid instability and the disruption of frequency sensitive industrial machinery as a result. In Germany power generators themselves are not allowed to operate power grids. Independent grid operating companies perform that task.
EIKE writes that the letter seems to pre-emptively point the finger at the grid operators should blackouts or disruptions occur.
What follows is that letter, translated in English (German version thanks to J. Kowatsch):
========================
Re: Partial solar eclipse on March 20, 2015:
 Your power supply is in good hands
Dear Ladies and Gentlemen
On March 20, 2015, a partial solar eclipse will occur over parts of Europe. This natural phenomenon will also have impacts on the power supply. As your partner for all matters concerning energy, we have put together a few important facts.
The solar eclipse will begin in Spain and end in Scandinavia. In Germany between ca. 9:10 and 12:00 noon up to 82% of the sun will be covered by the moon. If the sky is overcast, then the possible impacts will be very limited. However on a sunny day it will lead to a drop in power generation from PV systems of up to 12,000 megawatts in Germany, which is equivalent to 12 large power plants. Beginning at about 10:50 the power will then increase by up to 19,000 megawatts within about an hour.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The four power transmission grid operators in Germany are responsible for ensuring the usual system stability. The challenge is to completely balance the drop and the later subsequent rapid increase in power fed in from the PV systems by using many flexible power generations units. The power transmission grid operators have prepared well for this event. The employees at the grid control and switching centers have been trained for this special situation, and control centers will be manned with extra personnel on March 20, 2015.
Yet the chances of disruptions cannot be fully excluded. For example frequency fluctuations can effect sensitive systems (CNC machines, robots and other computer-controlled systems, etc.). Should you have any concerns, we recommend that you drive your systems down to a stable condition.
You will find more information at a mutual press release by the four power transmission grid operators dated 23 February, 2015, which we have enclosed. Moreover you will find at “Zeit online“ a fuctuial article as well as a video animation [scroll down] which illustrates very nicely the possible impacts on power feed-in by PV systems in Germany on a sunny day: http://blog.zeit.de/gruenegeschaefte/2015/03/03/sonnenfinsternis-energiewende/.
Have you got questions? Then give me a call. I’m gladly at your service.
Sincerely
Sales & Solutions GmbH
i.V. Christoph Schade
Mail: c.schade@EnBW.com
Enclosed: Press release by the four power transmission grid operators from February 23.
=============================
 
Share this...FacebookTwitter "
"We’re really only just learning about the impact Hurricane Irma has had on the Caribbean, especially for residents of disaster affected areas.  How can we tell their stories, and ensure their voices and experiences are not ignored? Here are four things the media could focus on: Local Caribbean residents are the real “losers”, not the tourists. They haven’t had a flight delayed, cancelled or temporarily inconvenienced by a hurricane. Instead, they have had their lives, livelihoods and homes devastated, and recovery will be a protracted process that will take many years.  The poorest and most marginalised populations across the region will be the most affected. Irma’s unequal impacts are starkly illustrated by looking at Richard Branson’s Necker island, which is part of the British Virgin Islands (BVI). Most of the buildings on Necker and other BVI islands were destroyed or badly damaged in the hurricane. Branson himself, however, was able to safely hunker down in his private cellar while Irma wreaked havoc.  Location, or the severity of hazards, cannot sufficiently explain why Irma had such a severe impact. There needs to be an acknowledgement of why Caribbean nations are far more vulnerable to natural hazards than the US.  This requires a long hard look at the political and economic situation of these islands. For example, several reports have raised worries over the heavy reliance on a handful of sectors, such as agriculture and tourism, which will be severely impacted by Irma in the long-term. Countries with diverse economies are better able to recover following a disaster; but Caribbean countries will find recovery far more challenging, given their low economic diversity. However, reports of destroyed hotels or ruined crops also conveniently ignore local history. As Leon Sealey-Huggins, an expert in Caribbean development based at the University of Warwick, points out, these economies were effectively forced to restructure economically towards these sectors, in light of a debt crisis that was largely due to their insertion into an unequal global system following independence. News reports should expose this side of the Caribbean’s colonial history, and add to the argument that Britain, France and the Netherlands, in particular, should be doing more to help. If coverage of previous large disasters is anything to go by, we are about to see an influx of images of distressed Caribbeans being saved, rescued and cared for by international relief organisations. However, it is important to stress that local civil society is often heavily involved. These may be formal, already established organisations, or they may be grassroots groups that form spontaneously in the wake of disaster.  Following Typhoon Haiyan, for instance, a huge cyclone that devastated the Philippines in 2015, two local NGOs, Coastal Core International and the Centre for Empowerment and Resource Development, were able to exploit their local knowledge and work effectively alongside the government. This sort of collaboration is crucial: local and international organisations mustn’t work in silos. Too often, there is a media frenzy of physical destruction and human agony, and a focus on short-term relief operations. This will draw attention to the disaster, and likely galvanise many charity donations from overseas. However, it will also serve to turn the disaster into a spectacle – and the slow process of rebuilding roofs or clearing trees from roads isn’t much of a spectacle. More attention must be given to long-term recovery. This is often forgotten about, and public engagement dries up. Granted, disaster recovery is not as “sexy” as response and relief. However, this phase is absolutely critical, and is an opportunity to recover society in a way that meets the needs of local people."
"
Share this...FacebookTwitterThe Lima Climate Conference has been extended another day as countries are still unable to reach an agreement on how much to cut emissions and who has to pay how much. But there are mounting signs that the talks may have fallen apart.
This morning NTV German public television writes that German Environment Minister Barbara Hendricks already left Lima Friday evening, even leaving an hour before the official end. The title of the NTV article: “Sobriety in Lima – Hangover mood at the climate conference.”
The NTV first reports on all the hope and optimism that had led up to the Conference, but that the realities of clashing national interests and responsibilities quickly dampened the mood as the conference wore on during the second week.
NTV writes:
In Lima it was already clear on Friday that important questions still could not be resolved. ‘The road to success in Paris remains remains long,’ German Environment Minister Barbara Hendricks observed. The Treaty’s bindingness will first be decided in Paris in any case.”
Already it appears that negotiators in Lima may be headed only to a watered down document full of intents, declaring that the parties agree to try to agree in Paris next year.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Hendricks’s early departure
There are no details as to why the German Environment Minister left already on Friday with the business unfinished. NTV writes:
The German negotiation leadership is now in the hands of State Secretary Jochen Flasbarth. The environmental protection organization Greenpeace criticized the Minister’s departure. ‘I find it already remarkable that the German Environment Minister has departed early, after Germany had played a spirited and progressive role,’ said Stefan Krug, head of the political representative in Berlin. ‘At such moments, when the negotiations are so precarious, it is extremely important that ministers remain engaged with their colleagues behind the scenes in order to strive for a solution.'”
NTV also writes of disappointment by German socialist EU Parliamentarian Jo Leinen: “Unfortunately it looks like we will be going home with a document that will contain many vague and soft formulations.”
That may very well be the case. But don’t expect the coming UN press releases to say so. Expect them to declare a breakthrough and success.
UN Climate Circus no. 20.
 
Share this...FacebookTwitter "
"Unlike us, plants have ample self-control when it comes to choosing how much they eat. Ironically, as humanity struggles with an obesity epidemic, plant breeders are trying to make crops eat more. When you see a field of wheat in summer, the spikes of grain rippling gracefully in the breeze, you probably won’t have guessed that the plants are fat. Yet, compared to the wild grasses they are bred from, the ears of modern cereal plants are grotesquely obese. They have larger and more numerous grain, laden with vast reserves of starch, way in excess of what they actually need. This excess weight is our food. With year-on-year gains from conventional breeding beginning to peter out and an ever-expanding human population to feed, the race is on to find new ways to persuade plants to put on even more weight. And it turns out that an effective way to do this is to interfere with the signalling systems that control the rate at which plants synthesise their food. For plants, “food” means carbon dioxide from the atmosphere which they turn into sugars by photosynthesis, and nitrates in the soil which are metabolised to form amino acids. Plants then monitor the concentration of sugars and amino acids in their tissues and grow more rapidly when they “sense” that food is available. This is a “feed-forward” control system. But that’s not the whole story. Plants also have genetically programmed limits on growth. These limits ensure they produce the right tissues, of the right size, at the right time. They also stop the plant trying to grow when it is damaging to do so, for example when the weather turns bad.  When a plant comes up against its growth limits, food begins to accumulate and this generates a “feedback” signal causing the plant to turn down the food production systems. Effectively the plant realises it is full and stops eating. But what if we could tweak the controls? Could we then make crops even more obese? Experiments with the sugar control system suggests that the answer is a resounding yes.  A team of researchers from agrochemists Syngenta and Rothamsted Research made a single genetic modification to maize plants to prevent the accumulation of trehalose-6-phosphate, a key sugar monitored by the plant. Essentially, the plants were tricked into “thinking” that they were not producing enough sugar and as a result they increased production. This, in turn, seems to have triggered the feed-forward system because the genetically-modified plants produced up to 50% more grain in well-watered conditions and outperformed unmodified plants by 123% in drought conditions. If the same changes could be engineered for the nitrogen control system, then not only might we achieve even higher yields, but we could also address the agricultural run-off problem at the same time. Millions of tonnes of nitrate fertiliser are applied to fields every year but much of it remains unconsumed by crops. And when it rains, the excess runs off the fields, polluting nearby rivers and lakes. The difficulty is that, despite decades of research, the signalling system that underpins nitrogen appetite control has remained something of a mystery. Until now. In a study recently published in Plant Cell, a Swiss-German team describe how they uncovered part of the system lurking in a surprising place.  Quite by accident, they found out that a specific form of vitamin B6 (known as a vitamer) tells the plant when it is full of nitrogen. The first clue was that the vitamer accumulates in plants in parallel with ammonium, one of the immediate products of nitrate metabolism. The second was that plants with unusually high amounts of the vitamer had impaired growth that could be overcome by supplying ammonium.  Although not all the details are yet clear, the most telling observation was that the accumulation of the specific B6 vitamer led to the nitrate metabolism system being turned down – it works as an appetite control system. Perhaps the main reason we are having to retune the settings on the appetite systems of crop plants is that they are held back by their evolutionary history. The grass species that were domesticated to form cereal crops such as maize, rice and wheat are likely to have grown in poor soils – and plants that have adapted to such soils generally have conservative food strategies. This means they take up only as much as they need to grow and produce seed for the next generation. So it’s not surprising that when we throw nitrogen fertiliser at their cultivated descendants, they don’t gorge themselves on the unexpected feast. A mismatch between evolutionary history and modern conditions is also behind the human obesity epidemic. Just as with crops, the solution could lie in tweaking appetite systems; we just need to work out how to go in the opposite direction."
"British Gas has raised electricity prices by 12.5% and its rivals are likely to follow suit. Another round of inflation-busting increases has put calls for an energy price cap back on the agenda.  When then Labour leader Ed Miliband first proposed a cap in 2013 it was dismissed by the Tories as coming from a “Marxist universe”. Four years later, Theresa May flirted with the idea ahead of the 2017 election, while Labour included the policy in its manifesto. But whatever it is, it’s not a Marxist idea. For a start, the price cap won’t work because the market is not only broken, it never worked in the first place. Incredibly high start-up costs mean energy is a natural monopoly, in which a small number of companies have been protecting significant investments in fossil fuels and nuclear power since the sector was first privatised.     Yes, you can regulate markets, but that requires a regulator with both sufficient teeth and the nerve to use them, and one which does not believe that switching suppliers is the answer to all its problems. British Gas’s move will add £76 to an average family’s bills each year. In theory, people could simply choose a different supplier, most likely from another of the “Big Six” energy firms who dominate the UK market. But there are lots of reasons why people won’t switch.  First of all, humans are generally poor at envisioning their future circumstances. Offer someone an amount of money in six months’ time, and then see how quickly they’ll take a fraction of that now instead.  Second, energy supply is something householders fundamentally rely on, and the difference between one supplier and another really isn’t that much extra if you’re happy with the service you have. So for those who can afford it, paying less than a tenner extra a month to avoid the hassle and for a bit of reassurance they won’t be left hanging in the case of a power cut is going to be worth it. And there are many more reasons people won’t switch, simply because humans are highly complex and rarely completely rational creatures. The belief behind the cap is that up to 10m “disengaged” Big Six customers could’ve been protected from price hikes if they’d switched.  This may be true, especially in the short term or if they’d switched away from the Big Six, but it conveniently ignores the fact that a common cause of price hikes is governments signalling their intent to intervene in the market. And unlike governments, energy suppliers think in decades, so any threat of a cap will merely be seen as a signal to drive up prices while they can, and then start lobbying like hell to get the cap raised by justifying the need for more of their costs to be passed to the consumer. An effective regulator might withstand this onslaught, but if we had an effective regulator there wouldn’t be a need for the cap in the first place. The problem with competition in the energy market is it encourages the sort of collusion and price fixing that even classical liberal economist Adam Smith warned about centuries ago. You can’t completely design out the potential for collusion because suppliers and network operators have to work together, otherwise the lights go off. And those who control the greatest assets in the market will exert the greatest influence on it – it doesn’t have to be active collusion, it’s a natural feature of imperfect markets.   Competition also means companies waste vast amounts of money paying staff to develop competing applications for different locations and technologies, when what is really required is a national strategy that sets out what is needed, and where, over the sorts of multi-decade periods energy suppliers need to justify investment. And then why bother wasting money putting those contracts out to tender? It clearly hasn’t worked for the railways. A price cap is hardly a “Marxist” solution to all this. A traditional Marxist energy policy would of course start with renationalising the industry, as energy supply is an issue that requires strategic planning at a national level. A Marxist solution would also push highly-skilled workers towards the socially-productive renewables sector, which even government estimates say could support more than 35,000 jobs across the UK.  Where eco-socialists, including myself, sometimes differ from traditional Marxism is on quite how much state ownership we see is necessary. I see a lot of value in community ownership because it doesn’t just help solve the energy problem, it also helps make people and communities more resilient. Towns and villages can’t become energy cooperatives overnight, however. They need investment, technical expertise, and an awful lot of support to get up and running. Does that sound Marxist? We already do it with private companies. The Labour manifesto included support for a publicly owned energy company in each region, and the SNP has proposed something similar. It’s not a complete solution, but it’s a big step in the right direction. Maybe it’s another idea Theresa May could consider borrowing?"
"
Share this...FacebookTwitterO/T
I’ve been waiting patiently for the German media to react to the explosive undercover video of a Planned Parenthood (PP) director, Deborah Nucatola, rolled by the Center for Medical Progress.
Warning – not easy to watch for people who even have just an inkling of compassion or any sense of humanity:

Sadly all this evil is happening now, and within the borders of the global “beacon of liberty and democracy”, of which I am a citizen, the United States of America.
It’s now been three days since the shocking video has been released and the reaction from the German media has been almost totally muted – just as I expected. Why? Here the predominantly center-left German media need time to carefully craft and spin the shocking story in a way that will not cause too much public disgust. They’ll get to it, though – dryly and curtly, and then rapidly move on to other things.
One major media outlet has gotten around and done a report on the PP video: the center-left Süddeutsche Zeitung (SZ) here – penned by Claus Hulverscheidt. How did he spin it?
As expected Hulverschidt presents the video as something that is part of an orchestrated attack campaign on a reputable “health and family planning provider”, of course one led by right-wing “Republikaner” (a harsh derogative in Germany) such as Jeb Bush, Ted Cruz, Carly Fiorina.
Hulverschidt bends over backwards to depict the PP franchise abortion organization as “not just some organization” but as a respective one “that has made a name for itself” in services like “family planning“, “cancer prevention” and “the search for health insurance for low income earners“. He writes of PP:
“Especially in large cities it enjoys great respect among women, is supported by celebrities such as actress Scarlett Johansson, and gets funding from the federal government in Washington.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Hulversheidt claims that the damage done by the video is not so much because of what Deborah Nucatola says at the dinner table, but because of the matter-of-fact way she says it: one professional speaking to another in her field. Never mind Nucatola openly admits in the video that PP centers are harvesting baby parts, organs and tissue for profit (maybe not PP’s profit, but certainly that of its scrupulous buyers).
Hulverscheidt concludes his piece:
In any case she indeed does say that they are operating in an ethical-moral gray zone. But with the help of the tissue samples, there is the opportunity to achieve progress in the fight against incurable diseases like Alzheimer and Parkinson, which otherwise would not be possible.”
Sorry, but the generational cannibalization of the unborn to the tune of millions of lives is not the way to cure diseases. Only a hopelessly, morally bankrupt and twisted mind could think so. Also disturbing is that Hulverscheidt fails to even bring up a single point or argument on behalf of the defenseless unborn.
Also no surprise, given the leanings of the SZ: Hulverscheidt does not bother to provide a link to the video itself to his readers, probably in the hopes they will just believe his every spin and not bother watching and deciding for themselves.
He also fails to mention that even Planned Parenthood Director Gloria Feldt is disturbed by the video and denounced (through clenched teeth, no doubt) “what seems to be totally inappropriate.”
This circling of wagons around a pet issue and defining it as black vs. white is typical of the German media, especially also when it comes to climate change, for example.
The media providing cover for an organization as loathsome as PP tells me that there are still many dark undercurrents at work in modern Germany.
Shame on Germany’s media.
Full version here.
Share this...FacebookTwitter "
"Australia needs to develop policies and structures to prepare for the health impacts of climate change because we have not moved quickly enough – domestically or internationally – to reduce emissions and mitigate the risk, Labor’s health spokesman, Chris Bowen, believes. Bowen will use a lecture at Sydney University on Wednesday night to argue a health response to climate change would not be necessary if there was a robust international policy response to emissions. “But the world, and Australia, has failed to act with appropriate seriousness and haste, and so we will need specific policies to deal with the health impacts of climate change,” he will say.  A copy of the lecture shows Bowen will point to estimates that by 2030, 250,000 people around the world will die each year as a direct result of a warming planet. But what was often missing from the public debate in Australia “is an understanding that severe climate change, of the type the globe is currently on track to experience, isn’t just about the frequency and severity of weather events”. “It is about changing climate zones, desertification, ocean acidification, ecosystem collapse; these impacts threaten our food supply, our economy, our security and of course our health,” it says. “As some have put it, climate change is so dangerous to health that it threatens to unwind 50 years of progress in improving public health outcomes, as well as adaptation to already unavoidable impacts from climate change.” Bowen will argue that climate change means more prevalent natural disasters and heatwaves in a country already prone to both, and the arrival of disease: “Countries not so far to our north are prone to vector-borne diseases. It would not take too much more of an increase in temperature for us to be prone to those diseases.” He will challenge the Morrison government to add climate change to the list of national health priorities. There are nine priority areas agreed between the commonwealth and the states – cancer control, cardiovascular health, injury prevention, mental health, diabetes mellitus, arthritis and musculoskeletal conditions, obesity and dementia – and the health minister, Greg Hunt, has proposed a 10th: medicines safety. Bowen will say adding climate change “would raise awareness of the importance of the challenge of climate change health and set out a road map for dealing with it”. The United States, a climate laggard under the Trump administration, has a significant program of climate change, disease control and prevention research, and Britain also has a sustainable development strategy: “But in Australia we have no such equivalent. “This is despite the fact we are more exposed than most, and our medical community is increasingly vocal on the issue, from Doctors for the Environment, to the Australian Medical Association, which recently declared climate change to be a health emergency.” Guardian Australia revealed in September that the AMA had formally declared climate change a health emergency, pointing to “clear scientific evidence indicating severe impacts for our patients and communities now and into the future”. The landmark shift, delivered by a motion of its federal council, brought the organisation into line with forward-leaning positions taken by the American Medical Association, the British Medical Association and Doctors for the Environment Australia. The American Medical Association and the American College of Physicians recognised climate change as a health emergency in June 2019, and the following month the British Medical Association declared a climate emergency and committed to campaign for carbon neutrality by 2030. The World Health Organisation has recognised since 2015 that climate change was the greatest threat to global health in the 21st century, and argued the scientific evidence for that assessment was “overwhelming”. The AMA president, Tony Bartone, said climate change meant higher mortality and morbidity from heat stress, injuries and mortalities from severe weather, increases in the transmission of vector-borne diseases, food insecurity resulting from declines in agricultural outputs, and higher incidences of mental ill health. Bowen will say he has been struck in his first six months in the health portfolio by the number of clinicians and medicos who have engaged him on climate change.  “As one senior doctor put it me powerfully recently: ‘Doctors listen to the science of the climate change and its health impacts like we listen to the science of vaccination and the impacts of not vaccinating. They are as clear as each other, and ignoring the science of climate change would be akin to supporting anti-vaxxers.’ ”"
"Announcements by airlines that they will offset their carbon emissions (Can carbon offsets tackle airlines’ emissions problem?, 19 November) misleads passengers into thinking that they are doing something to stop the atmosphere overheating. They are not. All that is accomplished is no net increase in atmospheric CO2. The message that needs to be conveyed is that far more offsetting is required to help reduce the upward trend in temperature. To double the calculation would be a good start. In the absence of carbon taxes or a frequent flyer levy, airlines (and cruise companies) should be required to inform passengers of this fact. It doesn’t matter too much whether the airline or the passengers pay, or if the cost is shared, as long as it happens.Patrick CosgroveChapel Lawn, Shropshire  • EasyJet is now reported as having jumped on the carbon offsetting bandwagon, claiming that all its flights will become “carbon neutral”. It might be wise for this scheme now to be recognised as little more than a comfortable delusion. Projected into the future, all airlines and indeed petrol companies could claim they were carbon neutral by adding typically a few percent to either ticket or pump prices. Indeed, Shell is already offering such a scheme. While the price of “offsetting” will inevitably increase, the Earth could warm irreversibly beyond a dangerous 1.5 or 2C threshold. Yet we could all still be driving and flying whenever we wished, having been told we were having no net impact. Carbon offsetting is basically dishonest in that it purports to offer a way of saving the world that is commensurate with a business-as-usual scenario. It is not a substitute for rapid reductions in fossil fuel energy use.Dr Stephen WozniakSidmouth, Devon • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitterIt appears leading German politicians have no interest in dealing with facts.
Last March geologist Dr. Sebastian Lüning, co-author of the climate science skeptic book “The Neglected Sun“, wrote a letter to German Chancellor Angela Merkel. Sadly he never got a reply.
Therefore he has posted the following letter at the Chancellor’s “Direct to the Chancellor” website here.
You can support Dr. Lüning’s request for answers and democratic participation by clicking “dafür stimmen” (in favor), circled in yellow in image below, at the end of the letter at the above link. You’ll have to enter the code in the box.

Here is Dr. Lüning’s letter in English:
The Fight against global warming





<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Dear Chancellor Merkel
I am referring to the article “The fight against global warming: Climate protection has priority” at: http://www.bundesregierung.de/Content/DE/Artikel/2015/02/….
1) You wrote (with reference to Germany):
‘Extreme weather events are becoming more frequent’
On which scientific publications and time periods are you basing this on? According to my knowledge most studies have found Central Europe has had no increase in weather extremes over the past 100 years.
2) You presented ‘heavy rains and storm flooding are on the increase’ and ‘the five largest natural catastrophes of 2014’ as examples of extreme weather events. Such a list can be drawn up for any desired year. Climatically relevant, however, in this relationship are foremost long-term trends of the last 100-300 years. How does these look? What is the intent of your list?
3) You wrote:
‘Climate change is leading to high costs. The total costs arising from natural disasters in 2014 worldwide was 110 billion dollars. One cyclone in India for example caused damage of seven billion dollars.’
However, scientific papers show that the observed rise in global extreme weather insurance damage is almost completely based on socio-economic reasons.
4) You quote Peter Höppe of reinsurer Munich Re: ‘Damages from thunderstorms and bad weather have been shown to be on the increase in various regions such as the USA and Central Europe.’
And what about other regions on Earth? How do things look when it comes to the global mean? And can it be excluded that natural fluctuations/shifts are at play here?
Thank you in advance for your reply.
Kindest regards
Sebastian Lüning


Share this...FacebookTwitter "
"Stop! Don’t send that email. Don’t offer thanks or send a jokey message. If you do, you will add to your carbon footprint. Be rude, say nothing – and save the planet. A new study commissioned by energy company OVO reckons Brits send more than 64m unnecessary emails every day, and that if every adult in the UK sent one fewer “thank you” email a day we would save more than 16,433 tonnes of carbon a year – equivalent to 81,152 flights to Madrid or taking 3,334 diesel cars off the road.  These are the sorts of stats beloved of green energy companies trying to get a bit of free publicity. But it’s all true, according to Mike Berners-Lee, a professor in the environment centre at Lancaster University, author of How Bad are Bananas: The Carbon Footprint of Everything, and brother of Tim Berners-Lee, inventor of the web. True in very general terms anyway: he probably won’t vouch for all those flights. How can one little email destroy the planet, I ask Mike Berners-Lee, who advised OVO on the research. “When you are typing, your computer is using electricity,” he says. “When you press send it goes through the network, and it takes electricity to run the network. And it’s going to end up being stored on the cloud somewhere, and those data centres use a lot of electricity. We don’t think about it because we can’t see the smoke coming out of our computers, but the carbon footprint of IT is huge and growing.” The electricity I grasp; the cloud is a bit beyond me. “It’s made up of enormous data centres all over the world,” Berners-Lee explains. “They are burning through huge amounts of electricity.” Super-efficient communication and storage is killing us. Every silver lining has a cloud. Berners-Lee admits the numbers are “crude estimates”, but says they are a useful way of making a general point. “When we take a small action to cut carbon,” he says, “it’s a message to yourself that you care about the climate emergency.” Does he blame his brother for all this? He laughs. “Many good things have come out of the web,” ... but only if we use it selectively. Now, how on earth do I file this piece? "
"The media is at the forefront of generating awareness over environmental issues. It is easy to name influential films like An Inconvenient Truth or note advances made by The Guardian’s environmental reporting. But what is often missing from this discussion is the environmental costs of producing media in the first place. Whether these be the energy that powers Al Gore’s visually stunning presentations or the materials – wood pulp, ink, detergents, cleansing solvents – required for printing a newspaper, there are considerable environmental costs involved. The media industry has slowly come to realise these costs, often as a result of prodding from NGOs like Greenpeace or in the form of policy (such as the BBC requiring carbon reporting for all its productions). The print sector has elaborate mechanisms in place to use recycled paper and minimise the use of harmful toxins. Similarly, the film and television sectors have started to develop carbon calculators to allow productions to assess – and curtail – their emissions. To date, emissions reductions have focused on materials and practices that adhere to the traditional production pipelines for different sectors. The newspaper industry focuses on paper; broadcasting on the travel of journalists and crew; the film industry on production management. But of course, most of the operations of contemporary media companies are now thoroughly digital. Films are shot on digital cameras, online workflows allow for centralised management of editing, newspapers are increasingly accessed online. Contemporary digital media is pervasive and proliferating, and raises fundamental questions over the capabilities of the industry to account for its environmental impact by focusing largely on traditional production methods.  Indeed, when these companies observe their environmental performance, digital operations often present a daunting challenge. Academic work on the production and delivery of digital content as well as on the devices on which they are accessed has been conducted. Yet this discussion has not penetrated the public consciousness or even parts of the industry. Many assume that digital media is more environmentally friendly than traditional forms. Take publishing – there’s far less paper used, right? The publisher Schibsted, for example, argues that the move to digital has reduced its emissions by more than 50% from 2009 to 2015. Yet it is not always clear what to include within these measurements. Schibsted has, for example, focused on the type and volume of energy needed to power devices in terms of reading time. But other considerations, such as the use of files and access to cloud services, provide more complex challenges. Cloud services provide endless backups which are seen and marketed as a way to ensure one’s data is preserved indefinitely against disruption. But increasing information flow from servers to terminal devices and using remote hosting can lead to a considerable increase in the amount of energy used. Certainly, they provide for efficient corporate conduct and management of information, but they are also a quintessential example of anthropocentric logic. The image of the immaterial cloud ignores the grounded realities of the data centres, still often at least partially powered by coal. The Guardian picked up on these debates in 2015 and commissioned extensive research on the publishing sector. It draws on studies that suggest that the internet accounts for 8% of the total energy consumption in the UK. Greenpeace estimates that the ICT sector comprises 2% of global emissions – on par with the airline industry.  A study by the VTT Technical Research Centre of Finland estimates that digital content production comprises, at the high end of estimates, 50% of the total climate emissions of newspaper publications. The majority of emissions are generated by consumer choices in accessing said content (going as high as 87% of total emissions from online publications). These depend on the particularities of the devices used, the electricity mix powering data servers, the grid which consumers use to access data, their means of downloading/streaming content (wifi vs ethernet), and how much time they spend reading the material.  Any attempt to understand the digital emissions of a publisher would therefore rely on an overwhelming number of factors and variables including reader habits, data farms, internet service providers, device manufacturers, and the operations of the media companies themselves. And most difficult of all, 50% or more of these emissions take place outside of the control of the media company. These concerns are not only prominent in the publishing sector. Calculating the total emissions of a company like the BBC or 20th Century Fox is even more complex. The problems for the industry are to do with not only agreeing on similar notions of transparency and common standards of accounting, but also of collecting data from sources far outside their remit. There are no definitive ways to calculate and assess the footprint of digital media – as there arguably has been with more traditional production methods. The problem is that tracing material emissions extends all the way down the supply chain for media production and beyond to consumption practices, including how often a file is accessed and on what kind of devices. When compared to heavy industry, the footprint of media production is small. But as the use of digital proliferates, our digital footprint can and will have consequences – and we should work out how to measure this sooner rather than later. Sectors such as publishing may have alleviated environmental concerns by turning attention to recycled paper and suchlike. But the seeming immateriality of digital calls for much more extensive attention to the sector’s footprint. The proliferation of digital media necessitates urgent self reflection and regulation as well as the establishment of much firmer and more comprehensive policies to address these emissions.  The question of responsibility is clearly a tortuous one when 50% of these emissions take place outside of the control of the media company. Cross-sectional collaboration is required here, but the impetus for this goes back to the media company as well as the wider policy environment. Environmental sustainability may soon no longer be a marginal inconvenience (or a tool to generate positive PR), but emerge as a strategic, financial priority."
nan
"
Share this...FacebookTwitterNo warming in Antarctica. Southern Ocean Cooling Down
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
[Translated by P Gosselin]
In Antarctica if a single piece of ice breaks off, the media worldwide go into a frenzy: How could it happen? That’s got to be climate change. Yes, global warming is striking Antarctica with full force and is rearing its ugly head. Every iceberg that breaks off at the edge of the ice sheet is a sign of climate catastrophe. Amen.
But also during pre-industrial times chunks of ice broke off regularly. This is how ice sheets work: Snow builds up on the continent and then gradually moves towards the coast. What’s new?
So just how much has Antarctica warmed over the last years and decades? One reads or hears very little about this in the media. Therefore we’d like to take this knowledge deficit as an occasion to look more carefully at the temperature history of the great white continent.
Paul Homewood once posted on the temperature development of the past 35 years, using the satellite measurements:

There’s been no detectable warming. It was cold earlier and it is cold today! No Trend.
Perhaps the thermometer at the Amundsen Scott Base at the South Pole has found warming? Based on GISS data, Paul Homewood generated the following curve:

Also in the region of the South Pole station there has been no detectable warming, and that over the past 50 years.
In the next step we leave the mainland and examine the ocean to see if it may have warmed around Antarctica. Bob Tisdale put together the temperature curve based on the KNMI Climate Explorer data:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Again we find no warming here as well. To the contrary the Southern Ocean has even cooled over the past 35 years.
In June 2014 Marshall et al. confirmed the cooling trend in a Paper in the Philosphical Transactions A. The abstract states:
In recent decades, the Arctic has been warming and sea ice disappearing. By contrast, the Southern Ocean around Antarctica has been (mainly) cooling and sea-ice extent growing. 
In the paper’s main section the authors add:
Over the last few decades, the two polar regions of our planet have exhibited strikingly different behaviours, as is evident in observed decadal trends in surface air temperature shown in figure 1. The Arctic has warmed, much more than in the global average, primarily in winter, while Arctic sea-ice extent has decreased dramatically. By contrast, the eastern Antarctic and Antarctic plateau have cooled, primarily in summer, with warming over the Antarctic Peninsula and Patagonia . Moreover, sea-ice extent around Antarctica has modestly increased.
Appearing in the same year in the Annals of Glaciology was a paper by Ekaykin et al., where the temperature development of Central Antarctica was reconstructed over the past 350 years. The researchers found characteristic 30-50 years cycles. Interestingly it was warmer than today back in the 1940s than today. The following is the paper’s abstract:
Multiple climate shifts in the Southern Hemisphere over the past three centuries based on central Antarctic snow pits and core studies
Based on the results of geochemical and glaciological investigations in snow pits and shallow cores, regional stack series of air temperature in central Antarctica (in the southern part of Vostok Subglacial Lake) were obtained, covering the last 350 years. It is shown that this parameter varied quasi-periodically with a wavelength of 30–50 years. The correlation of the newly obtained record with the circulation indices of the Southern Hemisphere (SH) shows that the central Antarctic climate is mainly governed by the type of circulation in the SH: under conditions of zonal circulation, negative anomalies of temperature and precipitation rate are observed, whereas the sign of the anomalies is positive during meridional circulation. In the 1970s the sign of the relationship between many climatic parameters changed, which is likely related to the rearrangement of the climatic system of the SH. The data suggest that during the past 350 years such events have taken place at least five times. The stable water isotope content of the central Antarctic snow is governed by the summer temperature rather than the mean annual temperature, which is interpreted as the influence of ‘post-depositional’ effects.
And when we look even further back in the past, we find more surprises. During the last interglacial, the Eem Warm Period of 130,000 years ago, it was 3.5 to 4.0°C warmer than today. This was reported by Parennin et al. in a publication appearing in February 2015 in the Climate of the Past Discussions.
On this matter a paper by Conway et al. appearing in 1999 in Science is interesting. Back then the authors recognized that the West Antarctic ice sheet shrank foremost during the mid Holocene, i.e. some 5000 years ago. The scientists suspect that the melting process started already during the early Holocene some 10,000 years ago and has continued on without any external influences until today:
Past and Future Grounding-Line Retreat of the West Antarctic Ice Sheet
The history of deglaciation of the West Antarctic Ice Sheet (WAIS) gives clues about its future. Southward grounding-line migration was dated past three locations in the Ross Sea Embayment. Results indicate that most recession occurred during the middle to late Holocene in the absence of substantial sea level or climate forcing. Current grounding-line retreat may reflect ongoing ice recession that has been under way since the early Holocene. If so, the WAIS could continue to retreat even in the absence of further external forcing.
Today we would like to conclude with a curious “discovery” On May 23, 2014. Spiegel Online brought us a frightening climate alarm story:
Ice melt: Irreversible chain reaction feared in Antarctica
[…] “A large piece of the ice cap in West Antarctica finds itself at a stage or irreversible retreat,” NASA scientist Eric Rignot of the University of California, Irvine. In the previous calculations by the IPCC concerning sea level rise the phenomenon was not adequately taken into account. In a study that was recently published in the “Geophysical Research Letters” the scientists lead by Rignot studied the retreat of all six large glaciers.”
Just awful…so, who brings us this terrible news? Does Eric Rignot really know what he’s doing? Hold on to your seat: Rignot is in fact not a climate scientist. He’s an electrical engineer…just in case someone complains later on that a non-Phd does not qualify anyone to participate in the climate discussion…
Share this...FacebookTwitter "
"Bristol is the latest city to propose a clean air or low emissions zone. These improve air quality by excluding the most polluting vehicles. Good news for the health of 100,000 people who live in the centre of Bristol – but not everyone is happy. One common objection is that zones only accelerate changes that would happen anyway as old vehicles wear out and are replaced. However, poor air is estimated to cause a health burden of more than 200 early deaths each year in Bristol, 9,600 in London and 32,000 UK-wide.  Air pollution has been described as the ‘new tobacco’ by the head of the World Health Organization. Over 90% of the world’s population suffers toxic air and research is increasingly revealing the profound impacts on the health of people, especially children. Children and babies’ developing bodies are most at risk from toxic air, with 300 million living in places where toxic fumes are six times above the international guidelines.  A comprehensive global review found that air pollution may be damaging every organ and virtually every cell in the human body. It causes issues from heart and lung disease to diabetes and dementia, and from liver problems and bladder cancer to brittle bones and damaged skin. The systemic damage is the result of pollutants causing inflammation that then floods through the body, and from ultrafine particles being carried around the body by the bloodstream. A Canadian study recently linked air pollution nanoparticles to brain cancer for first time In the UK, while deaths attributed to air pollution have halved in the last four decades, most urban areas have illegal levels of air pollution. One in 20 deaths in the UK is still attributable to small particle pollution alone. Damian Carrington, Environment editor A study in London suggests that children in the most polluted areas are growing smaller lungs, a change that is not fully recoverable. Balanced against these impacts, we cannot justify delay. Early analysis of London’s ultra-low emission zone showed a decrease of 29% in nitrogen dioxide from traffic alongside major roads. Changes in outer London, well away from the zone, were used to estimate what would have happened without the scheme – just 7% decrease. Others worry that polluting vehicles will divert, moving the problem. However, studies from Germany and London show the opposite. The cleaner vehicles required in these zones also drive in the surrounding area, spreading the benefit."
"As Victoria issued a code red bushfire alert and Melbourne sweltered through a record-equalling November temperature, the residents of Mildura walked out of their homes at midday on Thursday to see a dust storm rolling in. On a day of catastrophic fire danger and 40C heat, high winds swept the dry topsoil into the air and across the state. In Mildura, in far north-western Victoria, dramatic footage and pictures showed the sky turn an angry red.  Residents told Guardian Australia it was like a “wall of dust”, a danger to asthmatics, and “unliveable”. And, for many, it is not even the worst dust storm this year. In May residents reported a storm as the town’s worst in 40 years. Josh Maloney, a 17-year old student at Mildura Senior College, said he had seen Thursday’s dust storm come in during class. “I’m standing in the middle of dust storm right now,” he told Guardian Australia. “We noticed through the windows that the sky had turned this dark, thick orange. We could feel this thick dust on the tables. “This is bad but recently there have been probably been three or four a week.” Sophie Appleby, 35, was working from home with her one-year-old child, with the windows closed and the doors shut. “What is really eerie is that everything goes quiet,” she said. “There’s no birdsong, there’s nothing. It’s really bizarre and you know you are in the worst of it when the birds stop singing. “I have been here for 10 years and have never experienced anything like this. We used to have a dust storm a year, this is now a weekly basis. At its worst I couldn’t see across the road. This time the heat, because it is 40C, coupled with the dust just made it unliveable. You couldn’t go outside. Wild footage from #Mildura pic.twitter.com/MrYvOJJEd2 “It is really concerning to have young children and to feel like you can’t leave your house. You’re kind of trapped.” Appleby said the extended drought had devastated farming communities and made the dust storms more frequent. “We haven’t seen rain in months. It is absolutely climate-induced. The drought in this region is crippling farmers. And the dust in the sky is that farmers’ topsoil. When you put it into perspective like that it is terrifying.” Maloney, who took part in the school climate strike, agreed. “Within the last 12 months dust storms have been a lot more regular,” he said.  “We’ve had two or three really bad ones. This is probably the second worst one this year … it’s a lot to do with mismanagement, this partially man-made drought. “If anyone wants to call this completely natural circumstances, I think they would be kidding themselves, and a lot of this is due to mismanagement of our own resources.” A fellow resident, Narelle Hahn-Smith, said greed and the diversion of irrigation water had made conditions worse. This is my reality today, another dust storm in Mildura, and a fire on our outskirts pic.twitter.com/yP5jUxI2K6 “I’ve lived in Mildura for 52 years,” she said. “We do get dust storms if we’ve had a dry winter but because we’ve had two seasons of failed crops our farming district is struggling. “If you’ve got zero allocation of water there is less water going on to crops, which causes less evaporation, which causes less rain. It is an ongoing cycle. My feeling is that part of our drought is man-made through greed. The Darling River has been seriously interfered with higher up. “I’m an asthmatic so I’ve had to stay inside today. We’ve had a couple of dust storms a week for several weeks now and we haven’t even hit summer. I can’t imagine how bad it will over summer.” Sara White captured the moment the dust rolled in. “You could almost see to the end of the street, then within a matter of 20 seconds you could only see 50 metres down the road,” she said. 10:30am vs 12:14pm in Mildura! #duststorm pic.twitter.com/G5SXvfwZIi “It was like an orange hue, not dissimilar to when you have bushfire smoke everywhere. The sun was trying to come through but it can’t, and you just get an orange glow. You get grit in your eyes, in your mouth. “It’s something that we are getting quite used to over here and it’s not something I would prefer we get used to.” “The dust storms are becoming incredibly frequent. I actually asked my next -oor neighbour, he is 84 years old and has lived in Mildura most of his life. I asked if he had seen it like this before. He said he hasn’t seen anything like this since 1944-45.” Appleby, who also has a six-year-old in school, said it was scary to think that this would be the future for her children. “We are seeing the effects of climate change firsthand in this region and these increasing dust storms are just one part of that,” she said. “It’s terrifying to think of the future. Is this the new normal for my children that I can’t take them outside to play, that we can’t leave the house? That’s scary.”"
"Nigel Farage is hoping to enlist the climate science denier Donald Trump to help lead a global campaign to plant billions of trees to capture CO2. The Brexit party leader, a friend of the US president, is due to make the announcement in Westminster on Friday as his party launches its version of an election manifesto. Described as a “contract with the British people”, the party’s focus on the environment with the support of the US may be part of an attempt to broaden its appeal to voters beyond those looking to vote for a hard form of Brexit. Speaking to the Guardian, Farage said the UK should become the face of a worldwide UN initiative. “The UK should spearhead a global initiative at the United Nations to plant billions of trees around the world and I have every confidence Britain would get support from the American administration on this,” he said. “If it’s true that an area the size of Devon and Cornwall is removed from the Amazon every year, then we have a lot of work to do – and quickly.” Farage is also pledging to ensure Britain recycles all of its own waste and to make it illegal for it to be exported overseas to be burned, buried or dumped at sea. Trump pulled out of the Paris climate change agreement, aimed at keeping the planet’s temperature rise below two degrees this century. He said the agreement placed an unfair burden on the US to meet targets while big polluters in Asia were not signatories. In 2018 he also caused controversy when he said he did not believe a finding in the US government’s fourth national climate assessment that the country’s economy would be hit by the climate crisis. Tree-planting initiatives are said to be gaining ground among rightwing parties globally as a way of reclaiming the climate debate from the left. Farage, who recently secured a rare interview with the US president on his LBC radio show, is said to be keen to work with Trump on pushing environmental policies. Farage’s Brexit party has had a difficult start to the campaign after its formal offer to the Tories of an electoral alliance was rebuffed by Boris Johnson. After coming under pressure not to split the vote among those on the right and in favour of Brexit, Farage pulled out candidates in 317 Tory-won seats. He had hoped the government would give him a free shot at Labour-won seats in return, but this was also rejected by Johnson. While it won the most seats in the European parliament elections, polls show support for the party has dropped to 3%. Another tranche of its offer to voters is political reform through referendums. Farage is expected to say at the launch in Westminster that the party would introduce “citizens’ initiatives” to allow people to call referendums, subject to a 5 million threshold of registered voter signatures. There would also be time limitations on repetitive votes of at least 10 yrs. Farage, who is not standing at the election, said: “We need wholesale change in Westminster and our plans will ensure that millions across this country feel like they can be heard in a politics that isn’t listening to them any more.”"
"For most of us, commuting is a task to be endured. Busy, noisy and often cramped, the world’s underground transport systems are places that we humans tolerate as a matter of necessity. But not so for Moscow’s “metro dogs”. A number of strays have taken to riding the city’s underground railway – and remarkably, they seem to know where they’re going. Of Moscow’s 35,000 odd stray dogs, about 20 are thought to travel regularly on the city’s underground rail system. These dogs seem to be able to identify which trains to board, and where to alight. It appears that they can recognise humans who will give them a treat or a pat – and avoid those who won’t. They also show an impressive ability to deal with the noise and activity of the busy metro system, which many pet dogs would find distracting and stressful – indeed, they can often be found relaxing and sleeping in the crowded carriages.  So how did Moscow’s stray dogs learn this behaviour? Well, dogs have co-evolved alongside humans for several thousand years. During that time, they have developed the capability to recognise and respond to our physical and emotional signals. While most animals have trouble interpreting the social cues of other species, dogs are unusually adept at responding to human behaviour. This evidence goes some way to explaining how Moscow’s metro dogs know who to approach and who to steer clear of.  These social skills strongly suggest a degree of convergent evolution between dogs and humans. This occurs when different species evolve similar traits while adapting to a shared environment. So, the abilities of the metro dogs might even suggest that they have developed coping mechanisms similar to those of their fellow human commuters.   But Moscow’s stray dogs have an even stronger motivation to venture into the metro system. Dogs learn through positive associations – this forms the basis for the modern reward-based methods we use to train both working and pet dogs. For example, we can teach a dog to “sit” on command by rewarding that behaviour with treats. These positive reinforcement strategies generate reliable and consistent responses from our canine companions, as well as safeguarding their welfare.  It seems likely that the metro dogs have learned to associate the subways with warmth and food. So the strays return, time and time again, much like the pet dog that repeatedly “acquires” dinner from the kitchen counter. For the metro dogs, the rewards of food and shelter are probably worth the risk of negative experiences, such as being shooed away, hurt or worse: one poor pooch, called Malchik, was stabbed to death in the subway, to the dismay of many Muscovites.  In this way, the metro mutts might serve as an interesting model for training pet dogs, since they show us that particularly powerful rewards will overcome incidental negative experiences. Explaining how the metro dogs navigate the underground transport system is a bit more complicated. Given that the canine nose is substantially more sensitive than our own, it’s distinctly possible that they choose which stations to disembark at, based on scent. But studies suggest that dogs often use many sensory cues to find their way, and do not rely on smell alone.   So, the metro dogs probably use many indications including smell, lighting, passenger movement and perhaps even specific people to get their bearings in the subway. It has even been suggested that the dogs come to know the stations by name, by listening to the announcements over the tannoy. We know that dogs can learn words, so this is a possibility. But in this case, we can’t be sure whether the dogs genuinely know the names of specific stations, or simply associate some of them with food.  The final puzzle is how the dogs are able to time their journeys. This is a tough one, because it’s difficult to prove that dogs can even grasp the concept of time: many pet owners will receive identical welcome responses from their dogs, whether they have been absent for one minute or one hour. These observations suggest that dogs may perceive the passage of time very differently to humans.  Even so, many animals thrive on routine, and dogs are no exception. The regular goings on in Moscow’s metro – the opening and closing of stores, the peak hour rush and the system’s nightly shutdown – could be encouraging the dogs in their travels. The dogs are likely to associate these routine happenings with positive experiences, much like the excitement of a pet dog on hearing their owner’s car pull into the driveway after a day at work.   Moscow’s metro dogs represent an extremely interesting example of the domestic dog’s ability to adapt to a world built for humans, by humans. They show us that dogs have developed the capability to read human behaviours and respond accordingly, and to integrate themselves into our daily customs and practices. Understanding how dogs respond to the changing human world can help us understand both them, and ourselves, much better."
"Labour has announced plans to plant 2bn trees over the next 20 years and create 10 new national parks, as part of a rewilding policy intended to tackle the climate emergency and help natural habitats. The proposals also include an investment of £1.2bn to restore habitats such as woodlands and peat bogs in England, and extra funding for national park authorities. An extra £2.5bn would be used for a tree-planting programme covering national parks, other publicly owned land, farmland and “natural corridors” along parks, cycle routes and canals. Labour said it would increase funding for national parks by 50%. None of the 10 proposed new national parks have been decided on, but ideas suggested by Labour include the Malverns, Chilterns, Lincolnshire Wolds and north Pennines. Part of the decision would rest on the state of environmental degradation in the areas being considered as well as the potential for capturing carbon emissions and improving biodiversity. The entire programme, once completed, could store up to 47m tonnes of carbon emissions each year by 2050, Labour said, while new wild habitats would benefit endangered birds, animals and insects. The party said an estimated 20,000 jobs would be created in areas such as forestry management, and a total of 1m jobs under a wider plan to reshape the economy on a sustainable basis. On Wednesday night, Jeremy Corbyn told supporters in Falmouth at a rally to promote the party’s “green industrial revolution”, that the 2016 Paris climate agreement did not go far enough. He said: “I want to lead a Labour government that next year will host the next climate change conference, and which will be much stronger than Paris. “Our government will be one that will be very environmentally conscious, it will bring about a net zero emissions. Our government will work on the world stage to achieve that as well.” Part of Labour’s 1m green jobs plan will also include nationwide home refurbishments,creating jobs through insulation upgrades, as well as in offshore wind and carbon capture. The jobs will also come from hydrogen and tidal energy expansion, port infrastructure, flood defences and plastics recycling. With just two weeks until the election, Corbyn warned supporters: “Everything is going to be thrown at us in the next two weeks. Every bit of abuse that the right wing press can find. Every bit of abuse that the wealthiest in our society can throw at people that want to bring about real change.” Friends of the Earth welcomed the plan but said parties should remember that “trees will only help fix the climate crisis if emissions cuts happen at the same time”. Guy Shrubsole from the environmental group, said: “This is by far the most ambitious tree-planting pledge we’ve seen from a political party. Tree cover in the UK needs to double as part of the fight against climate breakdown and this means adding 3bn new trees, and fast. If sustained, Labour’s promised tree-planting rates would achieve this by 2050.”"
"Oxford Dictionaries has declared “climate emergency” the word of the year for 2019, following a hundred-fold increase in usage that it says demonstrated a “greater immediacy” in the way we talk about the climate. Defined as “a situation in which urgent action is required to reduce or halt climate change and avoid potentially irreversible environmental damage resulting from it”, Oxford said the words soared from “relative obscurity” to “one of the most prominent – and prominently debated – terms of 2019.”  According to the dictionary’s data, usage of “climate emergency” soared 10,796%. Oxford said the choice was reflective, not just of the rise in climate awareness, but the focus specifically on the language we use to discuss it. The rise of “climate emergency” reflected a conscious push towards language of immediacy and urgency, the dictionary said. In 2019, “climate” became the most common word associated with “emergency”, three times more than “health emergency” in second. In May, the Guardian updated its style guide to clarify that “climate emergency” or “global heating” would be favoured over “climate change” or “global warming” (although the original terms are not banned) – to better reflect the scientific consensus that this was “a catastrophe for humanity”. The Guardian has updated its style guide to introduce terms that more accurately describe the environmental crises facing the world.
Instead of “climate change”, the preferred terms are “climate emergency, crisis or breakdown” and “global heating” is favoured over “global warming”. The scale of the climate and wildlife crises has been laid bare by two landmark reports from the world’s scientists. In October 2018, they said carbon emissions must halve by 2030 to avoid even greater risks of drought, floods, extreme heat and poverty for hundreds of millions of people. In May 2019, global scientists said human society was in jeopardy from the accelerating annihilation of wildlife and destruction of the ecosystems that support all life on Earth. The editor-in-chief, Katharine Viner, says: “We want to ensure that we are being scientifically precise, while also communicating clearly with readers on this very important issue. The phrase ‘climate change’, for example, sounds rather passive and gentle when what scientists are talking about is a catastrophe for humanity.” Other terms that have been updated include the use of “wildlife” rather than “biodiversity”, “fish populations” instead of “fish stocks” and “climate science denier” rather than “climate sceptic”. Damian Carrington Environment editor Hundreds of cities, towns and even countries have also declared “climate emergencies” during 2019 – from Scotland in April, the UK parliament in May, Canada, France and the city of Sydney in Australia. “In 2018, climate did not feature in the top words typically used to modify emergency, instead the top types of emergencies people wrote about were health, hospital, and family emergencies,” the selection panel said. “But with climate emergency, we see something new, an extension of emergency to the global level.” And for those protesting that “climate emergency” is two words, as the Australian Broadcasting Corporation’s resident linguist explained in 2017, single words can consist of two parts. Such multipart constructions, like “heart attack”, “man-of-war” or the 2017 American Dialect Society word of the year “fake news”, are commonly accepted by linguists as words. “Climate emergency” beat the words “climate crisis”, “climate action”, “climate denial”, “extinction”, “flight shame”, “global heating” and “plant-based”, which were on the shortlist. The dictionary’s word of the year is chosen to “reflect the ethos, mood, or preoccupations of the passing year” and should have “lasting potential as a term of cultural significance”. “In 2019, climate emergency surpassed all of those other types of emergency to become the most written about emergency by a huge margin, with over three times the usage frequency of health, the second-ranking word,” Oxford said. Previous choices for word of the year include “toxic” in 2018 and “youthquake” in 2017."
"Most of the world could switch to 100% renewable energy by 2050, creating millions of jobs, saving millions of lives that would otherwise be lost to air pollution, and avoiding 1.5℃ of warming. That’s the bold claim of a major new study by Stanford professor Mark Jacobson and his colleagues, published in the journal Joule. Such work can be controversial. Jacobson and his team had previously produced a similar “energy roadmap” for the US alone, which sparked a fierce debate about whether it was feasible or even possible to power the country only with wind, water and solar by mid-century. One rebuttal earlier this summer, by a team of scientists led by Christopher Clack, claimed Jacobson’s plan didn’t have enough energy storage, was unrealistic about hydropower and completely disregarded nuclear power and carbon-capture – it was, they said, a “poorly executed exploration of an interesting hypothesis”.  The original authors responded by saying “there is not a single error in our paper” and highlighting the critics’ links to the fossil and nuclear industries. The debate had quickly turned into a personal feud on the pages of prominent academic journal PNAS and even Twitter.  Jacobson’s work has been politically influential, despite all the bickering. Many cities have joined his 100% renewables movement and public figures such as Bernie Sanders and the actor Mark Ruffalo have pledged their support.  Now Jacobson has upped the ante by publishing this new analysis of 139 countries across the world. However, it is likely that it will also be criticised along similar lines as it uses simplifying assumptions and still evades a detailed modelling of the three largest problems we face in the transition to sustainable energy: storage (especially large scale and long term), intermittency (both generation and demand) and trade (influenced by national security agendas just as much as by economics). Nevertheless, it can still be regarded as an agenda-setting, hypothetical description of the future, rather than a scientific pathway. But this is just what we need. Debates over energy modelling rarely make front page news, but this one did. We believe the world needs more discussion and awareness of the sheer complexity of the problem, as well as a positive vision of the future to aim for. And that requires work that is ambitious – and long-term. The energy transition is one of those “wicked problems” – by the time you realise you took the wrong action, it may be already too late.  It’s true that 2050 is a whole generation away, but this is exactly the sort of timescale over which we need to think about switching to clean energy. Change doesn’t happen overnight. Even if a holy grail technology was invented today, history teaches us that it would still take decades to make it viable on an industrial scale and many more years to deploy worldwide.  And let us not forget that radical energy inventions happen perhaps once or twice a century, with no guarantee they will keep occurring. Therefore we must look to the alternatives that are already being deployed on a large scale: wind and solar. The possibility of continuing to rely on fossil fuels along with carbon capture and storage is fading away, given both the practically nonexistent commercial deployment so far and the associated risks. On the other side, renewables are already the cheapest option for providing (variable) power in many countries, significantly below fossil fuels and nuclear power, while both hydropower and bioenergy are limited to certain regions and cannot easily scale up.  With the cost of wind and solar set to fall even further, the real question is what additional infrastructure we deploy to support it. This certainly includes batteries, which are predicted to become dramatically cheaper.  But there is also something else: inertia. This is partly technical: cheaper renewables and climate policies will leave a legacy of “stranded assets” such as the unnecessary Chinese coal-fired power plants that will probably never be turned on, or the UK’s nuclear plant at Hinkley Point C, already twice as expensive as offshore wind. But renewables must also battle against political and social inertia. Our societies are becoming ever more complex, and energy (especially electricity) plays an increasingly central part in supporting this complexity. An “energy transition” isn’t enough; what’s required is a total societal transformation. This societal transition can only be discussed in conjunction with other critical systems like transport or manufacturing and trends such as the rise of big data analytics, artificial intelligence or the internet of things. These are the fields which have the potential to actually revolutionise and enable the large-scale transition to renewables. And the large energy companies already know this. Take transport. Recently, many countries have come up with plans to ditch petrol cars and go electric. These policies will need to join up with plans to store more energy and build more turbines and solar panels (if they don’t, emissions may increase). But they’ll also rely on developments in artificial intelligence, governance, the concept of car ownership and even insurance. The  ideal of replacing all fossil-fuel vehicles with electric, comfortably charging every night, may be impeded by an antiquated grid or by insurers that choose not to cover damage or fires. An optimizing centrally controlled algorithm or a consumer-based dynamic pricing system could resolve this, but there are limited laws and precedents for this – another example of technology already being far ahead of what is politically or socially feasible.  People need to be clear that renewables are the way forward. We may differ with Jacobson and his team over the best type of energy storage, but there is a lot of value in this sort of ambitious roadmap. It emphasises the scale of the challenge, and, if done right, it should bolster general opinion and inspire action. The Paris Agreement was a good example of target-setting but details matter. We know that the future will not be anything like we imagine – “all models are wrong” after all. But physical limitations suggest there won’t be a magical new source of energy; the technologies we need are already here. Like Polynesian navigators, we need to look beyond the horizon to “see” the unknown destination we are heading to."
"I started learning driving only three years ago, and – inevitably – failed my first test. Naturally, I was disappointed: but then it occurred to me that I could avoid the whole issue, if only I could get my hands on a driverless car. And this triggered the research question: what would the overall impact on travel demand, energy use and carbon emissions be if driverless cars were readily available to the likes of you and me?  I joined a few like-minded academics in the US – Don MacKenzie and Paul Leiby – to research how the automation of road transport might affect energy use, and to quantify the potential range of these impacts. We found that a widespread adoption of self-driving vehicles could indeed help to reduce energy consumption in a number of ways. For example, on motorways, automated vehicles can interact with each other and drive very closely as a “platoon”. This can reduce the total energy consumption of road transport by 4% to 25%, because vehicles which follow closely behind each other face less air resistance.  What’s more, when vehicles can interact with each other and road infrastructure – such as traffic control systems – this will smooth out the traffic flow. The result will be less congestion and a reduction in energy use of up to 4%. On top of this, automated “ecodriving” – a driving style which controls speed and acceleration for more efficient fuel use – can reduce energy use by up to 20%. When you are riding in your self-driving car, obviously you won’t be at the controls, so you will no longer be able to enjoy the rapid acceleration of your driving days – so perhaps the desire for more powerful engines could diminish. And given that vehicle safety is expected to improve dramatically in self-driving cars, some of the heavy safety features could be removed, making cars lighter. Each of these changes could reduce energy use by up to 23%.  So far, so good – all of these mechanisms improve the efficiency with which a car travels. But, as a society, our interest lies in reducing total energy use, or total carbon emissions – and energy efficiency forms only one half of this picture. Our total carbon emissions also depend on the demand for travel. So, while improving the energy efficiency of cars by automating the driving process will reduce the carbon emissions of individual vehicles, the overall impact of this change will depend on how many people use them. For instance, consider what would happen if large numbers of people switched to self-driving cars from travelling by train. We generally prefer the privacy and convenience of travelling by car, but using public transport means we can concentrate on other stuff – such as reading a book or getting some work done. A self-driving car offers all of these benefits. As a result, we found that driverless cars could prove so attractive that they increase car travel by up to 60% in the US.  As you can see below, the features of driverless cars may have a range of impacts on energy consumption – both positive, and negative.  Self-driving cars could also encourage a completely new group of people to own vehicles – for example, the elderly, the disabled and possibly those too young to drive themselves. This would increase the welfare of that demographic by giving them greater mobility. Yet travel demand, energy use and carbon emissions would all rise: our estimate for the US is an increase between 2% and 10%. But it’s not all bad news: self-driving cars could encourage a move away from current car-owning culture to a car-sharing or on-demand culture. This opens up a few different possibilities. For one thing, by making the per-mile costs more visible to the user, car sharing or automated taxis could reduce travel demand from individuals. Yet these shared automated cars may still travel empty for some parts of their trips, so this option could lead a reduction of energy use between 0% to 20%.  But even greater energy savings are possible if the size of the self-driven shared car is matched to the trip type: for example, if a one-person commute trip is undertaken by a compact car, while for a family leisure trip a medium-sized sedan is used. This approach could reduce energy demand by 21% to 45%. One thing we haven’t touched in great detail is the potential for self-driving cars to encourage a switch to alternate fuels such as electricity and reduce carbon emissions. Imagine the car dropping you off at your destination and finding a charging point to recharge itself.  So, automation does have the potential to reduce energy use for road transport. But this is not a direct result of automation per se; rather, it is due to how automation changes vehicle design, operations and ownership culture. It’s also interesting that some of the energy-saving benefits of self-driving cars are possible at a lower level of automation, through increased interaction between vehicles and infrastructure.  It is clear that the benefits of self-driving cars will depend on how we use them. The widespread adoption of automated vehicles could well have some unexpected effects, so it’s vital that we find and implement ways to realise the full energy-saving and carbon-reducing potential of self-driving cars. Until then, we’d better keep practising our driving."
"Just 2% of the election debate was spent discussing the climate crisis. That includes the second Jeremy Corbyn gave it in his opening statement. When it was finally discussed – for a scant 45 seconds in the last 10 minutes – Corbyn was heckled after highlighting the effects our changing climate would have on the world’s poorest, with a jeer of “Oh, here we go!”. For those of us who work on raising awareness and finding solutions to the climate crisis, it was chilling. Corbyn himself looked shocked and seemed to gesture to the audience as if to say, “See what I’m working with?”  Implied in the audience intervention was the idea that caring about the plight of the world’s poorest is the preserve of tiresome, do-gooding snowflakes. Who cares about the people at the whims of climate change-related extreme weather events? They’re on the other side of the world anyway, right?  Thankfully, it is increasingly a minority of Brits who laugh off the climate crisis. Just this week Ipsos Mori noted that, when asked to list the most important issues facing Britain today, the environment and pollution had leapt up the chart, with 21% of respondents saying it was important to them. This is its highest recorded score since July 1990, a six-percentage-point rise from September, pushing this topic into fourth place (after Brexit, health and crime but above education, inequality, housing, the economy and immigration). Similarly, polling from YouGov at the end of last month shows a majority of voters say climate change will influence the way they vote. For under-25s, it’s near three-quarters. But we clearly can’t rely on demographic changes to push the dial towards climate action. We need action now. Climate activists always say this, but what we do in the next few years really is vital. The urgency required to deal with our environmental crisis means this has to be the climate election, whether we’d rather be talking about Brexit or not. The heckle seemed to derive from the view that the Labour leader is a bleeding-heart liberal who puts Brits last. Without wanting to suggest he should cave in to nationalist rhetoric at the first sign of resistance, Corbyn might well have avoided this by pulling the conversation back to a more domestic frame, skewering the prime minister on the recent floods, the Tories’ near-ban on onshore wind or their lack of action on cold, uninsulated homes. The Labour leader did move on to refer to “unusual weather patterns” and extreme air pollution in the UK, as well give a plug to Labour’s “green industrial revolution”, but it seemed almost like an afterthought. I’m sure in his post-debate debrief he was told this was a missed opportunity, and many of my fellow activists in the climate movement might be taking this as a sign that we need to be careful to always speak to domestic concerns first. And yet, at the same time, we can’t keep sugar-coating the impact of our emissions on the rest of the world. We should be able to have a grown-up national debate on the climate crisis as an issue of global inequality, including the often exploitative and damaging role the UK has played. And why not have it at a point when voters are at their most engaged and politicised? The sort of ambitious climate action we need in order to limit the damage globally is going to be difficult. It will require radical action against the big oil corporations – but it also means a change in our individual behaviour and routines too. We need drastically heightened levels of tree planting – it can’t just be a few more saplings here and there – and that’s going to mean more of us eating less meat. We need to cut flying, and driving too, and change our heaters and cookers. It’s vital we get these conversations right or they could go sour, fast. And although comments like those made in the leaders’ debate are beyond the pale, changing hearts and minds will have to involve challenging parochial approaches to climate action too. We need to do this well. Protests for climate action have been extremely powerful in the last year, and will no doubt continue to be so throughout the election and into next year. Looking ahead, we may be better served by a community-organising approach, one that focuses more on personal relationships and, above all, listening to people across the UK, rather than simply shouting our campaign messages ever louder. Older people who may not identify with environmental protest groups need to be listened to, engaged with and have clearly explained to them the ramifications of inaction on climate change. Otherwise, jeers such as “Oh, here we go!” could be just the beginning of a climate crisis culture war, where eco-fascism rises to the surface. This doesn’t mean simply agreeing to views we find abhorrent, but neither does it mean dismissing them in the way Corbyn’s “See what I’m working with?” gesture seemed to imply either. We need conversations, genuine ones where we listen to each other, and we need to be bold enough to go out and have them with people we disagree with. We can speak to a variety of values and approaches when it comes to climate change without pandering to banal nationalism. But we need to listen to them and – above all – involve them in the changes our society needs to avert climate catastrophe. • Alice Bell is co-director at climate change charity Possible and is writing a book on the history of the climate crisis."
"It’s mid-February and along Britain’s south coast gilt-head bream are drifting from the open sea into the estuaries. Meanwhile, thousands of little egrets are preparing to fly to continental Europe for breeding season, though a few hundred will remain in the UK.  Across northern Europe, young wasp spiders will soon scamper out of their silky egg sacs. And this summer, countryside visitors throughout the south of England will catch sight of iridescent blue flashes as small red-eyed damselflies flit across ponds.  These events all have one thing in common: they’re happening much further north than they would have as recently as 20 years ago. It’s not just a European thing. Polar bears are on the move, umbrella trees are creeping northwards through the US, and tropical birds in New Guinean mountains are retreating uphill. Southern Africa’s iconic quiver tree, which provides refridgeration in its hollowed out trunks, is itself escaping the heat and heading away from the equator. Across the world species are moving from their natural habitats. Fingers point at climate change. As areas become too hot or dry, many wildlife populations are declining. But on the flip side, some species are showing up in places that were historically too cold or wet.  The story we usually hear is of terrible declines in plants and animals. The Pyrenean Frog is languishing on mountaintops on the Spanish-French border, for instance, unable to move to cooler climes. Magellanic penguin chicks are dying in storms brought on by climate change. Costa Rica’s golden toads, which are actually a rather amazing bright orange, are thought to have been driven to extinction by warmer, drier weather, among other factors.  So why are so many species threatened by climate change, while others, like the gilt-head bream, little egret and wasp spider, are able to thrive? Colleagues and I have just published a paper that tries to answer this question. Our team, led by Alba Estrada, wanted to understand why some species decline in the face of climate change while others colonise distant habitats. Colonisation might avoid extinctions and may even make some species more successful than they were before climate change. If we could predict which species can and can’t colonise new locations, we could decide which are most in need of conservation.  How far individual animals or plant seeds can move was long thought to be the most important factor. For example, the wasp spider has probably spread so quickly by using an extraordinary technique called ballooning: releasing fine threads of silk into the air and floating for many kilometres on them.  But other characteristics also turned out to be highly important. For example, how quickly plants and animals can breed, how well they can compete with other species for resources, and what kinds of food they can eat or habitat they can live in. The upshot of this is that we might be able to predict which animals will thrive under climate change. The wood mouse is found throughout continental Europe, up to the southern tip of Norway and Sweden. As climate changes, we think the mouse will move north into Norway, Sweden, and Finland because it can breed quickly, live in lots of habitats, has a broad diet, and individuals can travel a long way.  On the other hand, consider the European ground squirrel. This small rodent currently lives in southeast Europe, though large parts of the rest of the continent will become suitable as the weather warms. However, we think it might stay just where it is because it can only live in grasslands – and climate change won’t suddenly turn farms and forests into meadows. It’s encouraging to know that some species are doing well under climate change, and that northern European wildlife lovers can look forward to seeing some exotic plants and animals in their countryside. There are some headaches, however. Those gilt-head bream are munching away on the local shellfish, which might be taking food away from the native fish. Small red-eyed damselflies look great, but they could become all too common around British ponds and outcompete native species. Several birds that have colonised the UK from warmer climes seem to be have been helped along by wetland conservation areas. Could the very methods we use to protect wildlife be helping some dangerous species to spread? There are good reasons to both welcome these newcomers with open arms, and worry about the damage they might do. Climate change is once again posing us some tricky conservation questions."
"
Share this...FacebookTwitterGerman meteorologist Dominik Jung writes at wetter.net that the first preliminary forecast for Central Europe for the upcoming summer issued by the NOAA does not look very favorable. Expect a “grisly summer”, he writes.
He writes that over the last 10 years spring has generally been on the warm and sunny side, but that Central Europeans have had to pay a price for that by having to put up with wet and variable summer weather.
Models wrong 11 out of 12 years!
Jung then reminds us that the climate models have been very wrong with their 2003 predictions that Central Europeans in the future would have to expect hot, barbecued summers like the one seen in 2003. Back then climatologists warned the public to get used to such summers, as it was all consistent with global warming. Turns out that prediction has been a complete flop. Jung writes:
Do you recall the climate prophets after the hottest and driest summer of all time in the 2003 prophesizing more drought summers? None of that has occurred. Of the 11 summers that followed, 7 were wetter than the long-term mean, i.e. too much rain. Moreover predictions of sustained heat waves failed to come true. Four summers turned out to be almost normal and only one single summer was about 15% too dry. The majority of the past summers saw no large heat waves. It was hot only for a few days, with really cooler days with thundershowers in between.
That could be again the case this year. According to the long-term trend of the US weather service, March and April could turn out to be warmer, sunnier and drier than normal. A few days ago the first trend for the months of June, July, August was calculated by the US colleagues and things don’t look better than the past – in fact it looks a little worse!
This year could be a grisly summer. The US long-term model sees no summer month that will be warmer than the long-term average. All three summer months should be at near normal temperatures and accompanied by more precipitation than normal. August is forecast to be especially wet.”
But Jung warns that these are only long-term projections and that one should not put too much stock in them. Many readers here are aware that the seasonal forecasts made by the US weather services (and those of the UK Met Office) often leave much to be desired.
In fact assuming the opposite would likely be a better prediction.
 
Share this...FacebookTwitter "
"Kelsey Juliana, a youth climate activist from Oregon, is joining forces with Gabriela Hearst, a fashion designer whose clothes are worn by Lady Gaga and the Duchess of Sussex, to ignite a trend they hope will become a global sensation. Juliana, 23, is the lead plaintiff in a group lawsuit suing the US government for breaching the human rights of her generation by failing to take action to protect the environment. The case, Juliana v United States – which goes by the unofficial name of Youth v Gov – aims to have the US supreme court order the government to dramatically change energy policy. Hearst – who, with her husband, John Augustine Hearst, the scion of the magazine empire, has a net worth estimated at £1.5bn – is providing financial backing for the case.  As they prepare to speak in front of an audience of designers, supermodels, editors and luxury industry CEOs at the Business of Fashion Voices conference, Juliana and Hearst hope that their constitutional action to protect the rights of young people to a clean environment can snowball into the next decade’s most era-defining trend. “Fashion sets the tone for society. Right now, we need to imagine a new way of living and fashion can help us do that,” says Juliana. “And fashion has young people driving it, just like climate action does.” Juliana, who filed her case aged 15, has taken part in many protest events, including marching 1,600 miles from Nebraska to Washington DC in 2016, but believes that lawsuits give those too young to vote a way to stand up for their right to a habitable planet. “All movements – the women’s movement, the gay rights movement – have cemented themselves in law and in the culture with a constitutional change,” says Hearst of their choice of a legislative rather than protest-based challenge. “It’s important to solidify this by going through the traditional route.” There are currently 1,390 lawsuits against governments and fossil fuel corporations in more than 25 countries, according to the Sabin Center for Climate Change Law. Last month, a group of 15 young Canadians filed La Rose v Her Majesty the Queen, alleging that the Canadian government’s energy policies have violated their rights to a stable climate. Juliana notes that “there are more cases coming up all over the world”. Many climate activists would decline an invitation to speak at a fashion event, given that it represents one of the world’s most polluting industries and sits uncomfortably at the crossroads of still-growing consumerism and increasing awareness of the need for change, but Juliana is “excited to be here. All facets of our society currently operate in a way that is problematic – the way we eat, the way we travel, what we buy. I am totally guilty of buying fast fashion, because I don’t have the resources to buy luxury fashion. But I was in Amsterdam recently and it was inspiring to see how much secondhand clothes and taking care of clothes are part of the culture there. What if we saw fashion come to represent a new way of living?” Fashion has always symbolised intergenerational strife and is, in that sense, a fitting stage for a crisis in which the Greta Thunberg generation are voicing increasing anger towards older people. “I want to be on stage to showcase how young people are stepping up to the bat, and ask the professionals and heads of industries in the audience to stand with us,” says Juliana. “My future is at risk in a way that isn’t the case for old people. I won’t sugarcoat it – I feel disappointment, disgust and rage. But my primary emotion is love – a deep, deep love for life and for the planet.” Hearst staged New York fashion week’s first carbon-neutral catwalk show in September, working with the consultancy EcoAct to calibrate and offset each element of the carbon footprint. However, shesays: “Sometimes, I think I should just stop producing products. Definitely, people should buy less.” Britain, she says, is better placed to lead a change of lifestyle than the US, “because here you experienced world war two and so you understand frugality and resilience, which is the mentality we are going to need to access. In America, those challenges haven’t been seen since the civil war.”Other speakers at the Voices conference, which begins on Thursday, include the Observer journalist Carole Cadwalladr, Clare Farrell of Extinction Rebellion and the photographer Juergen Teller."
"Colombia is the second most biodiverse country in the world, as measured by species richness. But over the past half century it has also been home to a brutal civil war, inflicting death and displacement on its citizens, with negative repercussions on its natural environment. However grim, conflict itself is not necessarily bad for biodiversity. While the lack of governance in war zones can encourage illegal mining and deforestation, a resulting reduction in development can also mean the natural environment is not exposed to pressures it might otherwise face. So, peace brings a fresh environmental challenge. In November 2016 the Colombian government and the Revolutionary Armed Forces of Colombia (FARC) signed a peace agreement to put an end to more than five decades of conflict. The optimism has since been tainted by delays in the process and an increase in the number of human rights activists murdered this year.  All this makes it a delicate time for Colombia and its natural riches. Brigitte Baptiste, director of the Humboldt Institute in Bogotá, described the period as a “great ecological experiment”. Throughout the text of the peace agreement, the goal of maintaining social and environmental sustainability was stressed. It called for the establishment of agricultural workers’ associations, for example, with the aim of protecting the environment, while substituting illegal drug crops for food production. The agreement also set out plans for environmental zoning to mark out the agricultural frontier. It’s not going to be easy. Since the signing of the peace agreement there have been some worrying trends. Deforestation increased by 44% in 2016, primarily in areas previously controlled by the FARC. These figures are aligned with some recent research showing a correlation between the presence of the FARC and lower levels of deforestation, due to the guerrilla group maintaining a level of control over the forests in its territory. Production of coca (which goes into making cocaine) is also on the increase, due in part to a perverse incentive for coca farmers to increase the size of their crops in order to receive greater subsidies for switching to alternative crops as part of the peace strategy. Aside from illegal activity, there are major national plans for development, including mining concessions and a massive infrastructure programme of 8,000km of roadways, all of which put Colombia’s biodiversity under threat. However, peace also creates opportunities. Colombia could now improve its governance and conservation policies, and properly monitor the biodiversity of zones previously off limits during the conflict. For instance, 88 new species have been discovered in Colombia since the peace agreement in areas previously considered too dangerous for research.  At the International Congress for Conservation Biology (ICCB) held in Cartagena, Colombia in July 2017, conservationists from Colombia and across the world discussed some of these key opportunities. Protected areas are being expanded, and there is a major drive for more eco-tourism – especially for bird lovers.  Colombia’s national development plan promotes a strategy of green growth and “as much market as possible, and as much state as necessary”. Consequently, new market-based conservation initiatives are emerging that attempt to find a compromise between economic development and nature conservation.  One example is the emergence of “biodiversity offsetting”. This aims to compensate for the environmental impacts of large mines, dams or roads by conserving or restoring an ecosystem of greater or equal biodiversity value as to that that is being damaged. But these mega projects still tend to become sites of conflict. In fact, the Environmental Justice Atlas lists 125 environmental conflicts in Colombia (only India has more), most of which arise from mining or drilling for oil and gas.  Popular consultations are now cropping up around Colombia, where communities have been voting against mining in their territories. Many feel that their livelihoods and the extractive industries are strongly incompatible: “agua, vida o minería” (“water, life or mining”). Meanwhile, Baptiste, in her plenary speech at the ICCB, spoke of “minería sí, pero no así” (“mining yes, but not in that way”), outlining a wish for responsible mining and a belief in the existence of solutions that can make development compatible with nature conservation. Baptiste presented a breakdown of where biodiversity is located in Colombia and who is in charge of it, with protected areas representing 14-18% of the national territory, and mining and energy concessions representing 25%, around 1% of which has thus far been transformed by mining activity. It is critical that conflict between armed groups is not simply replaced by conflict between communities and mega projects over the protection of their livelihoods and environment. It is unclear as yet how life, both human and non-human, will evolve in Colombia after the conflict. Certainly, there is a long road ahead to transition this country into a truly post-conflict nation. The challenge, and the opportunity, is to build a peaceful society while maintaining its biological and cultural diversity, and develop a model for other biodiversity-rich countries affected by war."
"Gene-modifying techniques could reduce the greenhouse gas emissions from livestock, helping to feed the world while combating the climate emergency, scientists have said. “Conventional [genetic] selection is extremely powerful,” said Mike Coffey, a professor of livestock informatics at Scotland’s Rural College. “At this point in time, GM [genetic modification] is not allowed in Europe, but some of these technologies could have great potential promise.”  Eileen Wall, the head of research at the college, said work was under way, without using GM, to formulate better diets for ruminants to reduce the methane they produce, but using GM could give a greater range of options. “You could have novel genes in plants to make less methane.” Methane associated with livestock production is an increasing contributor to the climate emergency, as the world’s appetite for meat shows no sign of slowing down. The amount of land required to be cultivated to feed livestock adds to the problem, with its associated fertiliser use and deforestation. Many studies have suggested that moving to a diet based largely on plants and containing much less meat than is currently consumed in rich countries will be vital to combatting the climate crisis. It would also be healthier, as consumers in the rich world are eating more meat than is recommended, though poorer people struggle to get enough protein. Using GM technology in plants for human consumption and in animals is banned in Europe. However, the UK could loosen restrictions after Brexit. Any such move would be highly controversial among some farming campaigners, in part because it could open up rifts with the EU over trade. Rob Percival, the head of policy at the Soil Association, cast doubt on the potential climate benefits. “GM is a distraction – we already have the solutions to the climate crisis at our fingertips. The focus should be on empowering farmers to adopt more nature-friendly agroecological farming systems and shifting diets to create demand for more sustainable food,” he said.  “Instead of looking to risky and unproven technologies and chemicals as a sticking plaster, we should be tackling the root causes of these crises, putting farmers in the driving seat of sustainable innovation.” Geoff Simm, the director of the global academy of agriculture and food security at the University of Edinburgh, said farmers were feeling “demonised” by campaigns encouraging people to adopt vegan diets to protect the climate.  Calculations of the harm done by eating meat are usually based on US production techniques, which are highly intensive and involve grain-feeding. In the UK, by contrast, cows and sheep are more likely to graze outdoors, often using land that would not be viable for crop production, which means their associated emissions are far less. In the UK there is also far more overlap between the beef and dairy industries, with more than half of beef production coming from the dairy herd, which also makes for lower emissions. Conventional breeding techniques have also played a role in cutting livestock emissions, with the UK now producing more milk from fewer cattle than it did 25 years ago."
"
Share this...FacebookTwitterNever the trust the media, let alone political leaders.
When they tell us global warming is real while sea ice at the poles is at normal levels and snow is falling in Jacksonville, Florida and in the Arabian desert, should we believe them?
Probably not – especially when one looks closely at the climate data. And certainly not at all when one looks at how they report the news on how world leaders “bravely” demonstrated in Paris “alongside” more than a million people in response to the Charlie Hebdo terrorist attack.
Most readers by now are aware of the STAGED photos and images of the 50 or so world leaders standing and “marching united with” the more than one million demonstrators in Paris last Sunday. In reality it was all staged to deceive television viewers all over the world.

World leaders stage their Paris, Charlie Hebdo, demonstration. Image cropped from here.
German Television’s mass deception
Now someone has just put up a montage of various news clips from some German public television news networks, showing how they used the stagecraft to deceive viewers into thinking our leaders were bravely demonstrating at the front row against terrorism in the Paris march of last Sunday.

At the 0:40 mark the video informs the viewers up ahead of the deception the media used:
Observe the targeted deception of the viewers through the use of camera angles, sound clips (the side streets were dead quiet) and the audacious lies of the news anchors and correspondents”.
What follows are some examples I’ve translated in English.
At the 0:55 mark Germany’s ZDF describes how more than a million people demonstrated in Paris to “send a clear signal of unity and to march for freedom of expression, tolerance and against terror”.
At the 1:12 mark, the ZDF anchor tells its millions of viewers:
And among them, arm-in-arm, the leaders and countries from all over the world.”
The reality is that these world leaders were in fact too afraid to appear “arm-in-arm, should-to-shoulder” with the masses. In effect they actually demonstrated their capitulation to terrorism, admitting the terror worked and that they are now too afraid to appear with the public. Congratulations terrorists, your aim has been achieved – at least among our leaders. Obviously real courage is something only for the masses.
At the 1:32 mark the ZDF switches to a correspondent “on location”, and shows how the world leaders seem to be marching along with the one million-plus demonstrators.
At the 1:34 mark the correspondent reports on the leaders:
These here are also demonstrators. More than 50 government leaders and high officials from all over the world march together.”
Looking at the video image, one sees Angela Merkel and others even seemingly waving at people. The sad truth is that it was all an act.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




At the 2:00 mark, the same ZDF correspondent describes:
The world’s political elite on the street, side-by-side, with the people.”
Sorry, but they weren’t “with the people”. It’s just the media willfully disseminating organized deception to millions of viewers all over Europe and the world.
Later in the video a ZDF Special Report shows more of the same: brave world leaders marching hand-in-hand with the people, “to send a signal against terrorism“.
At the 2:52 mark there are more images deceiving the viewers into thinking the world leaders were marching with the people. Even Bibbi Netanyahu is getting in on the act. The deception continues at the 3:38 mark…courageous leaders seemingly risking their lives to demonstrate in unity in public with their people.
Truth: leaders were cowering behind the demonstrators
The aspect that annoys me in particular is that these leaders found the situation to be too dangerous, yet had no qualms about letting the more than a million and half demonstrators put their lives at risk on the street. Bravery for you, but not for me.
The truth is that the world leaders, by staging in an empty highly secured street, were in effect cowering in the last rows behind the demonstrators, and not bravely leading them in the front row as we were misled to believe.
At the 4:30 mark the video shows how Germany’s flagship ARD Television also uses the same mass deception, the news anchor announces:
More than 40 world leaders participated in the march.”
At the 6:40 mark the ARD in a special report again showed “world leaders marching with the people“.
At the 7:51 mark viewers see world leaders in the “front row”, seemingly bravely leading the million-plus person march. Here we notice audio of people cheering and demonstrating in the background, when in reality the footage was recorded on a secluded street where the side streets were completely empty and silent!
At the 8-minute mark the correspondent reports the names of the important figures present in the front row: Merkel, Hollande, Netanyahu and Abbas.
At the 8:06 mark the correspondent declares that it’s:
“A front row who are declaring: ‘We will not be intimidated!'”
These are the very people who send our sons and daughters to the battlefield.
At the 9:08 mark yet another ZDF report shows world leaders marching with the people, labeling them at the 9:20 mark: “Politicians as demonstrators.”
The topping on the cake comes at the 10:00 mark, where the ZDF correspondent even asks:
When was there ever a time where government leaders, or leaders of 50 nations, have come onto the streets as demonstrators, over a kilometer-long stretch that was not even completely safe? That was something particularly special.”
The mainstream media cannot be trusted. Little wonder that demonstrators in Germany refer to them as the “Liar Press”. I guess we should sarcastically start calling them “the Truth Press”.
 
Share this...FacebookTwitter "
"Australian officials have told major business groups there will have to be a diplomatic solution to a standoff between the Morrison government and other nations about whether the government can use carryover credits from the Kyoto period to meet its Paris target. Guardian Australia understands diplomats from the British high commission signalled their objection to Australia using carryover credits during a recent meeting of the Australian Industry Greenhouse Network, which includes major emitters such as BHP and Woodside, and industry associations.  Australian officials responded by saying the government intended to use carryover credits despite the opposition, and there would need to be a diplomatic solution at the looming United Nations climate talks in Madrid. British officials, according to sources with knowledge of the meeting, said everything was negotiable in the context of the UN talks, but using carryover credits should not become a substitute for climate action. The British high commission in Canberra declined to comment on a presentation delivered during a private meeting. Carryover credits are an accounting system that allows countries to count credits from exceeding their targets under the soon-to-be-obsolete Kyoto protocol periods against their Paris commitment for 2030. Australia will need to cut emissions by 695m tonnes cumulatively across the next decade to meet its 2030 target. The Morrison government said more than half of that cut, 367m tonnes, would come from accounting and not from practical emissions reduction. Australia’s stance is controversial, and a number of countries have objected, including the European Union, Pacific nations and Canada. Environment department officials recently told Senate estimates they were unaware of any countries other than Australia planning to use the controversial credits to meet their international climate commitments. The Australian Industry Greenhouse Network meets regularly. The most recent conversation, including diplomats and Australian officials, is scheduled as a precursor to the UN climate talks in Madrid starting on 2 December. Officials from the foreign affairs department have been briefing stakeholders ahead of the meeting. Foreign affairs officials told stakeholders that Australia would not discuss an increase in its headline commitment – a 26-28% emissions cut by 2030 compared with 2005 – in Madrid and did not expect carryover credits to be a major focus at the meeting. They said the environment department was working on a long-term climate strategy that would be released for feedback early next year. This is consistent with a commitment Morrison made at the Pacific Islands forum in Tuvalu in August, when – after rejecting heavy criticism by island nations of Australia’s support for coal – he signed Australia up to pursuing efforts to limit global warming to 1.5C and produce a 2050 strategy by 2020. His statement said the strategy “may include commitments and strategies to achieve net zero carbon by 2050”. The context for the conversation at the network meeting was rising concern in the business community about the continuing lack of resolution to article 6 of the Paris rulebook, which is the section of the agreement promoting international cooperation, including allowing countries to trade their emissions allowances, or credits. Despite Scott Morrison’s frequent, strident criticisms during the May election of a plan by Labor to allow high emitting businesses to use international permits to reduce their pollution at least cost, Australia’s official position in the UN negotiations is it supports the use of permits. But it remains unclear whether a consensus on the rules will be reached in Madrid. The issue of whether Australia can use carryover credits from the Kyoto period is a separate but related issue to the disputes about article 6. Carryover credits are not mentioned in the Paris agreement, under which countries nominate their own targets (known as nationally determined commitments) and explain how they plan to reach them. It means there is nothing in the text that prevents Australia from using them, despite the objections. They could be banned only through consensus, which would require Australia to agree. The government said Australia was entitled to use the carryover credits as they reflected its efforts in “beating” the targets set under the Kyoto protocol. Critics say Australia has access to the credits only because it has made unexacting commitments, including allowing its emissions to continue to increase under the protocol’s first stage, and the point of the Paris deal is to significantly ramp up action over time, not just loopholes."
"In the wake of the devastation caused by Hurricane Harvey and Hurricane Irma, it was reported that up to 80% of home damages were not insured. Insurance schemes are widely advocated as a means of facilitating recovery from – or resilience to – natural and human-made disasters. For those without insurance, or who are under-insured, recovery prospects are bleak. Many such people – who are often already living in precarious situations – will leave their homes, never to return, or will live in properties that are unfit for habitation.  But our research suggests that even for those fortunate enough to have insurance cover, the path to recovery is tortuous. Flood-afflicted communities have likened dealing with loss adjustors, insurers, and subsequently contractors to being as “traumatic as the flood itself”. More fundamentally, the industry’s promotion of a rapid return to normality undermines efforts to create a more resilient society by reducing opportunities to adapt to future flooding. It is little wonder that there are fears that many places will increasingly suffer from repeated flood events. To take just one example of this challenge, it is reported that Houston has now experienced its third one-in-a-500-year flood in just three years.  The aftermath of any disaster provides opportunities to rebuild in a way that  reduces the impacts of future such incidents. With respect to flooding, this includes opportunities to install flood-resilient building materials, to move services such as electricity cables and power sockets above flood levels, or to use property-level protection measures such as door barriers that might keep water out of a building.  In practice, however, insurers often take complete control of rebuilding efforts, arranging for authorised contractors to conduct reinstatement work. Of course, insured homeowners are initially relieved that some of the financial burden of  rebuilding efforts will fall elsewhere. But the insurer also becomes the de-facto property owner. Homeowners – often temporarily relocated at some distance from their properties – lose control of key decisions regarding the reconstruction of their homes.  Understandably, the emphasis of all concerned is to “bounce back” and to be rehoused with things as they were as quickly as possible. As a rule, insurers do not pay for anything that could be referred to as “property betterment”. Instead, they promise to reinstate a property to its original condition (the condition it was in the day before a flood or a storm struck). This precludes adaptation and protection – measures that might limit the impact of a future flood, even if these interventions are at little or no cost to the overall rebuilding project. This is particularly problematic in the face of climate change. To understand the systemic limits to adaptation, we must examine the fundamentals of insurance. In return for a modest annual payment, insurers provide assistance in the form of financial compensation or services after a disaster. Insurance therefore transfers risk from those immediately exposed to a hazard to another entity. However, this transfer of risk brings concerns. When the costs of hazards such as floods fall elsewhere, there can be an erosion of willingness to reduce exposure or to encourage less risky behaviour. 
Insurers have long recognised this contradiction and refer to it as a “moral hazard”. In practice, the integration of adaptation measures that might mitigate flooding or that can help reduce the impacts of a flood can be disincentivised by the moral hazard. An associated concern is referred to as “risk-pooling”. Insurance premiums are pooled into a fund that is used in the event of a peril occurring. This dissipates financial exposure throughout all policyholders. While this may be good for reducing the costs to citizens at high risk, it has wider effects that we need to acknowledge. Beyond this there are broader concerns that insurance, with its focus on annual premiums, encourages people to inhabit areas that should be avoided altogether over the long term – areas where flooding is inevitable.   Insurers are crucial to disaster recovery initiatives, promising security in the face of uncertainty and the restoration of business as usual for civil and commercial life. Yet in the face of increasingly severe floods, the promotion of this approach rather than adaptation means that insurance has “maladaptive” tendencies. These are actions (or inaction) that may provide short-term benefits – but ultimately increase the vulnerability to future changes in flood risk prompted by climate change and other land-use factors. Put differently, as insurers promise a rapid return to a pre-shock “normality” this creates the conditions for repeat events and misses opportunities to adapt. Insurance facilitates recovery – but at what cost? We believe it insulates from the costs of living with risk, fosters moral hazard and stops property owners from adapting to risk. Perhaps our misplaced faith in insurance means that we are destined to treat the symptoms but never the actual causes of climatic hazards."
"The imprinting of climate emergency into the public consciousness, achieved by the school strikes and mass activist arrests, seems to have generated more introspection than positive action. The debate around personal sacrifice, hypocrisy and lifestyle change is playing at high volume and, as recently highlighted by the climate expert Michael Mann, this presents a danger that popular demand for catastrophe-avoiding systemic change could get lost in the mix.  This debate is just as alive (and equally confused) within the music industry. Headline emphasis is often placed on issues such as single-use plastics or band travel by air. Important as those things are, evidence shows that factors such as audience transportation and venue power account for as much as 93% of all the CO2 emissions generated by major music events. As a band that has toured globally for several years, we’ve had cause to reflect on this. Concerns over our own carbon impact and those of our wider industry aren’t new to us, but the urgency is. Last year, the UN Intergovernmental Panel on Climate Change called for “rapid, far-reaching and unprecedented changes in all aspects of society” and said carbon emissions were harmful, regardless of the fun had in their generation. In other words, what goes on tour doesn’t stay on tour. We’ve taken unilateral steps for nearly two decades – like many bands, we’ve paid to have trees planted, prohibited the use of single-use plastics and travelled by train wherever feasible. We have explored advanced carbon offset models, but in researching these programmes serious issues arose. First, the concept of offsetting creates an illusion that high-carbon activities enjoyed by wealthier individuals can continue, by transferring the burden of action and sacrifice to others – generally those in the poorer nations in the southern hemisphere. Evidence suggests that offset programmes can wreak serious havoc for the often voiceless indigenous and rural communities who have done the least to create the problem. Ultimately, carbon offsetting transfers emissions from one place to another rather than reducing them. The European commission has warned that 85% of projects were unlikely to deliver “real” or “measurable” reductions, while the UN environment programme recently stated that offsetting cannot be used by polluters “as a free pass for inaction”.  We’ve also discussed ending touring altogether – an important option that deserves consideration. In reality, however, an entire international roster of acts would need to stop touring to achieve the required impact. In a major employment industry with hundreds of acts, this isn’t about to happen. Any unilateral actions we take now would prove futile unless our industry moves together, and to create systemic change there is no real alternative to collective action. So today we’re announcing the commissioning of the renowned Tyndall Centre for Climate Change Research to map the full carbon footprint of typical tour cycles, and to look specifically at the three key areas where CO2 emissions in our sector are generated: band travel and production, audience transport and venue. The resulting roadmap to decarbonisation will be shared with other touring acts, promoters and festival/venue owners to assist swift and significant emissions reductions. The stark reality is that failure to do so could mean matters are taken out of our hands. In recent months, (thanks in no small part to those strikes and those arrests) 245 local authorities across the UK have declared a climate emergency, with 149 setting targets of zero emissions by 2030 or earlier. In the festival sector alone, this number includes the licensing authorities for each of the five best-attended UK outdoor events: Glastonbury, Download, Reading/Leeds, V Festivals and Creamfields. Their event plans will now inevitably include mandatory rules on carbon emissions, and so the likelihood of licences being granted without emissions being dramatically and continually reduced is slim. Given the current polarised social atmosphere, uplifting and unifying cultural events are arguably more important now than ever, and no one would want to see them postponed or even cancelled. The challenge therefore is to avoid more pledges, promises and greenwashing headlines and instead embrace seismic change. The report produced by the Tyndall Centre will not provide a panacea, and we know implementation of its findings will require significant change for us and our colleagues across the industry who are as keen as we are to create change. But in an emergency context, business as usual – regardless of its nature, high profile or popularity – is unacceptable. • This article was written by musician Robert Del Naja on behalf of Massive Attack"
"The one thing never to forget about global warming is that it’s a timed test. It’s ignoble and dangerous to delay progress on any important issue, of course – if, in 2020, America continues to ignore the healthcare needs of many of its citizens, those people will sicken, die, go bankrupt. The damage will be very real. But that damage won’t make it harder, come 2021 or 2025 or 2030, to do the right thing about healthcare. But the climate crisis doesn’t work like that. If we don’t solve it soon, we will never solve it, because we will pass a series of irrevocable tipping points – and we’re clearly now approaching those deadlines. You can tell because there’s half as much ice in the Arctic, and because forests catch fire with heartbreaking regularity and because we see record deluge. But the deadlines are not just impressionistic – they’re rooted in the latest science. In the aftermath of the Paris climate accords in 2015, for instance, many researchers set 2020 as the date by which carbon emissions would need to peak if we were to have any chance of meeting the accord’s goals. Here’s an example of the math, from Stefan Rahmstorf and Anders Levermann. Under the most plausible scenario, they wrote, “even if we peak in 2020 reducing emissions to zero within 20 years will be required,” and that is an ungodly steep slope. But if we wait past 2020 it’s not a slope at all – it’s just a cliff, and we fall off it. As the former UN climate chief Christiana Figueres put it when she launched Mission 2020, “Everyone has a right to prosper, and if emissions do not begin their rapid decline by 2020, the world’s most vulnerable people will suffer even more from the devastating impacts of climate change.” Here’s another way of saying it: the Intergovernmental Panel on Climate Change reported last autumn that if we hadn’t managed a fundamental transformation of the planet’s energy systems by 2030, our chance of meeting the Paris temperature targets is slim to none. And anyone who has ever had anything to do with governments knows: if you want something big done by 2030, you better give yourself a lot of lead time. In fact, it’s possible we’ve waited too long: the world’s greenhouse gas emissions spiked last year, and – given Trump, Bolsonaro and Putin - it’s hard to imagine we won’t see the same depressing thing this year. Which is why, I guess, it’s a good thing that 2020 is an election year in the US, and that the Democratic party finally seems willing to talk seriously about climate change. If it nominates Sanders or Warren, maybe the kind of aggressive approach that shakes things up is possible. But America is just one country; we also need to pressure our real global government, which has its headquarters not in Washington but in Wall Street. Last year banks increased their already staggering lending to the fossil fuel industry; if that continues there’s no chance of turning this round in time. If you’re looking for optimism, at least we come into 2020 on a roll. The great climate strikes of this September were the largest demonstration of climate activism in history, with 7 million people in the street. And April 2020 marks the 50th anniversary of Earth Day – it could be a day for an even more massive outpouring. The planet is running a hideous fever, and the antibodies – all those protesters – are finally kicking in. It’s a race, and we’re behind, and we better start catching up right now."
"You know that greenhouse gases are changing the climate. You probably know drinking water is becoming increasingly scarce, and that we’re living through a mass extinction. But when did you last worry about phosphorus?  It’s not as well-known as the other issues, but phosphorus depletion is no less significant. After all, we could live without cars or unusual species, but if phosphorus ran out we’d have to live without food. Phosphorus is an essential nutrient for all forms of life. It is a key element in our DNA and all living organisms require daily phosphorus intake to produce energy. It cannot be replaced and there is no synthetic substitute: without phosphorus, there is no life. Our dependence began in the mid-19th century, after farmers noticed spreading phosphorus-rich guano (bird excrement) on their fields led to impressive improvements in crop yields. Soon after, mines opened up in the US and China to extract phosphate ore – rocks which contain the useful mineral. This triggered the current use of mineral fertilisers and, without this industrial breakthrough, humanity could only produce half the food that it does today.  Fertiliser use has quadrupled over the past half century and will continue rising as the population expands. The growing wealth of developing countries allows people to afford more meat which has a “phosphorus footprint” 50 times higher than most vegetables. This, together with the increasing usage of biofuels, is estimated to double the demand for phosphorus fertilisers by 2050. Today phosphorus is also used in pharmaceuticals, personal care products, flame retardants, catalysts for chemical industries, building materials, cleaners, detergents and food preservatives. Reserves are limited and not equally spread over the planet. The only large mines are located in Morocco, Russia, China and the US. Depending on which scientists you ask, the world’s phosphate rock reserves will last for another 35 to 400 years – though the more optimistic assessments rely on the discovery of new deposits. It’s a big concern for the EU and other countries without their own reserves, and phosphorus depletion could lead to geopolitical tensions. Back in 2008, when fertiliser prices sharply increased by 600% and directly influenced food prices, there were violent riots in 40 different developing countries. Phosphorus also harms the environment. Excessive fertiliser use means it leaches from agricultural lands into rivers and eventually the sea, leading to so-called dead zones where most fish can’t survive. Uninhibited algae growth caused by high levels of phosphorus in water has already created more than 400 coastal death zones worldwide. Related human poisoning costs US$2.2 billion dollars annually in the US alone. With the increasing demand for phosphorus leading to massive social and environmental issues, it’s time we looked towards more sustainable and responsible use. In the past, the phosphorus cycle was closed: crops were eaten by humans and livestock while their faeces were used as natural fertilisers to grow crops again.  These days, the cycle is broken. Each year 220m tonnes of phosphate rocks are mined, but only a negligible amount makes it back into the soil. Crops are transported to cities and the waste is not returned to the fields but to the sewage system, which mainly ends up in the sea. A cycle has become a linear process. We could reinvent a modern phosphorus cycle simply by dramatically reducing our consumption. After all, less than a third of the phosphorus in fertilisers is actually taken up by plants; the rest accumulates in the soil or is washed away. To take one example, in the Netherlands there is enough phosphorus in the soil today to supply the country with fertiliser for the next 40 years. Food wastage is also directly linked to phosphorus overuse. In the most developed countries, 60% of discarded food is edible. We could also make agriculture smarter, optimising the amount of phosphorus used by specially selecting low-fertiliser crops or by giving chickens and pigs a special enzyme that helps them digest phosphorus more efficiently and therefore avoid extensive use of phosphorus-heavy growth supplements. It takes vast amounts of energy to transform phosphate ore into “elemental phosphorus”, the more reactive and pure form used in other, non-agricultural sectors. Inventing a quicker route from raw rocks to industrially-useful compounds is one of the big challenges facing the future generation. The EU, which only has minimal reserves, is investing in research aimed at saving energy – and phosphorus. We could also close the phosphorus cycle by recycling it. Sewage, for instance, contains phosphorus yet it is considered waste and is mainly incinerated or released into the sea. The technology to extract this phosphorus and reuse it as fertiliser does exist, but it’s still at an early stage of development. When considering acute future challenges, people do not often think about phosphorus. However, securing enough food for the world’s population is at least as important as the development of renewable energy and the reduction of greenhouse gases. To guarantee long-term food security, changes in the way we use phosphorus today are vital."
"
Share this...FacebookTwitterScience-ethically dubious: Stefan Rahmstorf silent on large body of dissenting Gulf Stream results in newspaper interview
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
[Translated, edited by P Gosselin]
There was an interview with Stefan Rahmstorf in the German daily Märkischen Allgemeine Zeitung (MAZ) on March 23, 2015:
A tipping element on which the globe’s future hinges
Climate scientist Stefan Rahmstorf and his colleagues at the Potsdam Institute for Climate Impact Research have evidence of a further weakening of the Gulf Stream.”
That’s old hat. As we have already reported here, other teams of scientists unfortunately have been unable to find any such weakening of the Gulf Stream, and so Rahmtorf is pretty much standing all by his lonesome in the middle of nowhere. And that did not did not remain unnoticed by the MAZ, which persisted courageously:
MAZ: Climate skeptics such as former Environment Hamburg Senator of Fritz Vahrenholt characterized the weakening of the Gulf Stream as part of the natural cycles.
Rahmstorf: I’d be curious to see evidence of that – unfortunately Herr Vahrenholt has published practically nothing in the scientific literature. We also looked for natural cycles and have determined that there have not been any significant fluctuations over the past 1000 years.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




True, Fritz Vahrenholt did not publish anything on that topic. But others have to a great extent and Vahrenholt quoted them. This is how science works: You do not need to research everything yourself, rather you turn to the large research networks and peer-reviewed literature. Notable here are for example studies from the University of Rhode Island, NASA, University of Heidelberg, University of Hamburg. The scientists in Hamburg have just recently shown natural cycles. It is quite amazing that suddenly Rahmstorf is unable to recall any of these studies and prefers to indulge in some Vahrenholt-bashing. Apparently the MAZ also found his excuse hardly helpful and continued to persist:
MAZ: Climate scientist Mojib Latif also does not believe in the currently diminishing speed of the Gulf Stream.
Rahmstorf: The current weakening has also been confirmed by other studies. We simply track the stream with the help of proxy data further back in time. In a 2004 study fellow scientist Latif used temperature differences from the North and South Atlantic in order to determine the speed of the stream. Here it was not taken into account that we had an aerosol blocking of the sunlight because of air pollution in the northern hemisphere. This effect cannot be so clearly separated from that of a change in the stream; thus we have refined his methods.
Who believes? Rahmstorf here is peddling to a newspaper his very one-sided view as the supposed consensus within the science field. Embarrassing and science-ethically very unclean. That’s a shame.
===============
It seems Rahmstorf may have a growing habit of not playing cleanly. -PG
Share this...FacebookTwitter "
"One of the big problems with the world’s heavy carbon emissions is that they are driving up the levels of carbon dioxide in our oceans, which is making them more acidic. The surface pH of the oceans has already dropped from 8.1 to 8.0 over the past couple of decades, and is projected to reach 7.7 by 2100 – a huge change in biological terms.  This is reducing the carbonate in the water that marine organisms including shellfish, corals and sea urchins depend on to make their shells and exoskeletons. I co-published a study two years ago into how this would affect mussels. By simulating the ocean conditions of 2100, we found that their shells did not grow as large and were harder and more brittle. Now, in a new study, we have seen fascinating signs of them adapting to these changes.   When we looked at the mussel shells of the future in our first study, we found they fractured considerably more easily. This made them more vulnerable to predators such as birds and crabs – and also to stormy conditions, since the stronger waves can bang them against rocks and other mussels. As an economically important food source across the world, it has worrying implications for those who depend on them to make their living – indeed, mussel farmers tell me they are noticing these changes even now. It also raises the prospect of similar problems for other shellfish such as oysters and cockles, not to mention sea urchins and corals. Our new study took the work further by using a combination of X-ray techniques to understand how ocean acidification causes these changes and how the organisms continue to make their shells in spite of it.  Marine organisms such as mussels create shells in several stages. They take up the carbonates and calcium in sea water through their tissue and convert them into a substance known as amorphous calcium carbonate (ACC). They essentially move this substance to the correct location in their body and convert it into a harder substance called crystalline calcium carbonate (CCC), which comprises the bulk of the shell. But they also keep some carbonate in ACC form, which they use for repair purposes – not unlike the way humans grow bones.   Our “future mussels” had to cope with the uptake of fewer carbonates overall, but what they did was to convert a lower proportion into CCC than usual – hence they grew less shell. Instead they kept more as ACC, which seemed to be a repair mechanism to combat the increased risk of shell damage from having more brittle shells.  So is this a sign that nature will find a way to cope as the oceans get more acidic? Not necessarily. The mussels might have been retaining more of the repairing ACC, but they are vulnerable while the shell is fractured, and might not live long enough to fix it.  We also don’t yet know whether they would have enough ACC to keep their more brittle shells in a good enough state of repair. To find out, you would have to look at what happens to them over a number of generations. This is what we intend to look into next. This research will have huge implications for other marine organisms producing calcium carbonate shells and exoskeletons including shellfish, corals and sea urchins. In the meantime, ocean acidification undoubtedly means huge changes for the creatures that live there, with consequences that are extremely difficult to predict."
"An increasing proportion of voters worry Australia is not doing enough to reduce the risks of climate change, and more people see a direct link between warming and bushfires, according to the latest Guardian Essential poll. Ominously for the Morrison government, which bristles at regular public criticism it is not doing enough to reduce the risks of the climate crisis, 60% of the sample of 1,083 voters believes Australia should be doing more. This is up from 51% in March. Just under half the sample, 43%, believes it is likely bushfires are linked to climate change, and argues it is entirely appropriate to discuss that link during an emergency of the scale we’ve seen around Australia over the past fortnight. When this question was last put to survey respondents in 2013, only 27% of the sample had this view. While Scott Morrison has accepted the link between climate change and natural disasters, the prime minister has argued – including in parliament on Monday during a statement on the bushfires – that it is not appropriate to get into that debate while a disaster is in progress. The Labor leader, Anthony Albanese, responded to Morrison’s comments on Monday by arguing Australia does not have the luxury of time to defer important discussions. But Albanese said it was important that public discussion of the issues be “sober” and not rancorous. Voters most likely to think Australia is not doing enough to deal with the risk of climate change are under 34, and support Labor or the Greens – although the latest Guardian Essential survey indicates that 46% of Coalition voters in the sample share this view. The poll indicates that 61% of the sample believes that climate change is happening and is caused by human activity. That level of support is consistent with readings taken in March this year and October of last year. While that view is supported by 74% of Labor voters in the sample and 89% of Greens voters, it is supported by just under half of Coalition voters, 47%. Just over a quarter of the sample (28%) says people aren’t witnessing climate change, they are witnessing a normal fluctuation in the Earth’s climate. Perceptions are different depending on the age of voters. People aged 18-34 are most likely to accept anthropogenic climate change (74%) and voters over 55 are least likely to (50%). A separate poll of 25,000 Australians aged 15 to 19, released on Tuesday, shows a sharp rise in concern for the environment and climate change in both cities and regional areas. As part of the 18th annual Mission Australia youth survey, people were asked to name the three most important issues for Australia. Behind mental health, the environment was ranked the second most important issue, chosen by 34% of young people, with more than half of those citing climate change. In 2018, the environment was ranked eighth, nominated by just 9% of young people. The chief executive of Mission Australia, James Toomey, said young people were feeling disenfranchised and this was driving them to find other ways to be heard “such as climate strikes.” He said: “The growing public dialogue and experience of issues, such as extreme weather events and drought, are clearly affecting young people’s view of the world.” Essential said the proportion of people who think it is likely that the bushfires are linked to climate change, but that it is inappropriate to publicly raise this issue during disasters, has remained fairly constant over time. In this fortnight’s poll, 17% of the sample express that view while 14% had that opinion in 2013. Morrison defended the Coalition’s record on climate action during question time on Monday. He contended that Australia was in that group of countries which is “beating, the commitments that we have made to the world, and we will continue to do that”. “Australia is doing its bit when it comes to dealing with climate change,” the prime minister said. But he said the government had no intention of adopting “reckless targets supported by the Greens and the Labor party”. The prime minister said it was an “outright lie” to argue that if the Coalition had adopted higher emissions reduction targets then the bushfires would not have happened. While Australia has committed under the Paris agreement to reduce emissions, pollution has risen consistently since the Coalition repealed the carbon price shortly after winning government in 2013. In an interview with Guardian Australia’s politics podcast last week, the former prime minister Malcolm Turnbull cut across Morrison’s regular protestations that enough is being done by noting that Australia would struggle to meet its Paris emissions target without rapid decarbonisation of the energy sector. • Sign up to receive the top stories from Guardian Australia every morning Turnbull also said the Liberal party’s continuing failure to develop a coherent climate and energy policy was costing the country much-needed new investment in power generation. There has been controversy post-election about the reliability of opinion polling, as none of the major surveys – Newspoll, Ipsos, Galaxy or Essential – correctly predicted a Coalition victory on 18 May. The polls instead projected Labor in front on a two-party-preferred vote of 51-49 and 52-48. The lack of precision in the polling has prompted public reflection at Essential, as has been flagged by its executive director, Peter Lewis. Guardian Australia is not now publishing measurements of primary votes or a two-party-preferred calculation, but is continuing to publish survey results of responses to questions about the leaders and a range of policy issues. The poll’s margin of error is plus or minus 3%."
