"From lochs and lakes to rivers, ponds and canals, there is a diverse range of freshwater habitats in the UK, which is good news not just for biodiversity but also the economy, where they are collectively valued at £39.5 billion. Rivers in particular are highly biologically diverse environments, home to a wide variety of plants, invertebrates and fish. But linked together within a river catchment, they are prone to invasion by alien species that can spread quickly between these interconnected habitats. Invasive alien plant species are of one of the biggest concerns to river environments. These contribute to the loss of native plants and invertebrates, as well as altering soil chemistry and impeding river flow. It costs the UK government around £1.7 billion to control invasive alien species and an estimated £6m alone to control the well-known troublesome Japanese knotweed (Fallopia japonica). Read more: Invasive plants have a much bigger impact than we imagine  Himalayan balsam (Impatiens glandulifera) is an alien plant from the Himalayas introduced to Britain in 1839 by Victorian botanists, and is a prominent and familiar sight along UK waterways. Growing to up to a colossal four metres tall, this annual plant is a serious competitor to native British plants. Himalayan balsam is listed on Schedule 9 of the Wildlife and Countryside Act in England and Wales which makes it an offence to plant or allow the species to grow in the wild. However, Himalayan balsam is so widespread it is increasingly challenging to tackle. Strategies for managing this species involve prevention (such as awareness campaigns and enforcing legislation to prohibit entry or spread), complete removal of the species (generally not feasible within river habitats due to their interconnected nature), and control (such pulling up individual Himalayan balsam plants prior to seeding). The most effective method of control so far, particularly for Japanese knotweed, is herbicide spraying. However, there are collateral risks to water quality and aquatic animals and plants from herbicide run-off when these plants are close to waterways. The classic signs of invasion by Himalayan balsam is a wall of vivid pink flowers and a sickly sweet smell along river banks. Most sites we have studied have been invaded for over ten years, but curiously often neighbour an almost completely green length of the same river bank. What is it about these uninvaded areas along a river that makes them immune to this alien species? If we can understand the conditions which promote or deter the pink wall, the information could be used to manage these Himalayan balsam populations. The local environment, as well as the native plant community, determines whether an invader can establish, and thereafter expand its population. Competition between plant species for resources such as space and light is brutal. It’s a battleground out there, and not all species can win. Common native plants, such as the stinging nettle, butterbur and canary reed grass, can be direct competitors of Himalayan balsam.  A study we conducted aimed to untangle the direct and indirect effects of the environment and competition on the abundance of Himalayan balsam along rivers. We surveyed sites along rivers across Scotland which varied in environmental conditions, such as the number of river flood events per year. These rivers also had areas along the bank that were heavily invaded by Himalayan balsam, close to an area which had more dominant native species and no invasion. Compared to native plants such as common reed grasses  that dominate lowland riverbanks, Himalayan balsam dislikes overly moist conditions. Instead this plant prefers drier, steeper riverbanks where it can compete more effectively with native plants. A river inundated by flood water is therefore not ideal habitat for this invader, but native dominant species accustomed to occasional waterlogging are less negatively affected. This knowledge provides us with vital information to manage Himalayan balsam indirectly, by manipulating conditions on riverbanks, such as making them less steep so that they retain more water, which Himalayan balsam dislikes. Unfortunately, river engineering practices often involve straightening and over deepening rivers. Combined with abstracting water for agriculture, this leads to drier riverbanks during the summer, which benefits Himalayan balsam. In contrast, the restoration of rivers often strives to create gently shelving riverbanks and a more sinuous channel. This means that water is retained, riverbanks are moister and native species are favoured at the expense of Himalayan balsam. In 2018 Britain experienced one of its hottest, driest summers. Changing climate is likely to provide conditions which enable invasive alien plants to thrive along rivers. Hence, managing species in light of their environmental preferences is so important. Our study showed that a large abundance of dominant native plant species are more able to resist invasion by Himalayan balsam. So there has never been a better time to embrace our native species, even a river bank favourite such as the humble stinging nettle."
"Exposure to air pollution has a staggering effect on human health.  It is thought to cause around 7m premature deaths each year worldwide, with around 40,000 occurring in Britain.  These premature deaths can occur through air pollution increasing the likelihood of heart disease and stroke, or through exacerbating existing lung diseases such as chronic obstructive pulmonary disease (COPD) or asthma. My colleagues and I recently showed that air pollution particles can even damage the immune system. Governments can of course take action, regulating sources of pollution such as car exhausts, factories or wood fires, or implementing less obvious measures such as strategic tree planting. Indeed a new EU report says member states need to take more effective action to improve air quality and make the public aware of the problem.  However, there may be another issue in terms of how we actually measure air pollution, and what it means for human health. Air pollution is frequently underestimated, either through monitoring in the wrong places, or through limitations of the detection methods. However, research presented by Jacqueline Hamilton at the British Science Festival suggests that we need to look in much greater detail at the causes of air pollution in the environment.   Hamilton, an atmospheric chemist based at the University of York, is an expert in detecting the compounds that can contribute to the formation of some of the most damaging particles in air pollution. She says that rather than looking at particulate air pollution in isolation, we need to look at some of the substances that can generate air pollution particles, which she calls “missing emissions”.  One key pollutant, which Hamilton terms “large hydrocarbons”, may be causing more of a problem than has been realised. These substances contain high numbers of carbon atoms, and are found in higher concentrations in diesel than in petrol. Large hydrocarbons can be released into the air by vehicles which use diesel as a fuel. While new cars have low hydrocarbon emissions levels, older cars, as well as buses and taxis, can release high concentrations of diesel hydrocarbons from their exhausts.  The key issue is that while they are not particularly toxic in themselves, large hydrocarbons can actually react with other substances in the air to generate damaging nano-sized particles, what we normally think of as “particulate air pollution”. These particles have been shown to be extremely toxic to human health.  While there have been successful efforts to reduce the hydrocarbons that are emitted into the environment, we have previously known very little about how large hydrocarbons are released as they are so difficult to detect. Hamilton, however, has been able to use new high resolution “chromatography” technology that hasn’t been used before to detect emissions from diesel engines. She used this technique to measure a busy traffic area in London and identify the composition of all the hydrocarbons released. She found extremely high concentrations of large hydrocarbons. In fact, her data suggests that using current models, some hydrocarbon components of diesel emissions, such as those with 12 and 13 carbon atoms, may be underestimated by a factor of at least 70.  This is a concern, as there is very little monitoring of large hydrocarbons in terms of air quality. There is a well established network of over 300 air sampling units distributed throughout the UK which continually measure the nitrogen dioxide and particle concentrations in the air we breathe. However, there are only four monitoring sites that can measure hydrocarbons.   I spoke with Hamilton and she said that it was critical for more research to be performed to understand the chemistry of large hydrocarbons. This is essential if they are to be incorporated into the air quality models used by the government to understand air pollution exposure. She noted that it was still unclear how driving conditions could contribute to large hydrocarbon release from diesel vehicles, and that more work in the lab, and in the field, is urgently needed. The UK government has recently closed its consultation on its 2018 clean air strategy and the outcomes are due to be published in March 2019. Until then, it is clear that we need to continue to take action on both the known, and the “missing emissions” if we are to reduce the number of deaths attributed to air pollution."
"Without cooling, the supply of food, medicine and data would simply break down. We consume large amounts of energy and cause a great deal of pollution keeping things cool yet compared to electricity, transport or heat, cold has received very little attention in the energy debate; neither the UK, USA nor the EU yet has an explicit policy on cold.  Global demand is booming – and incremental efficiency improvements are unlikely to contain the resulting environmental damage. We need radically new technology. In rapidly developing nations investment in cooling is starting to boom as rising incomes, urbanisation and population growth boost demand. But the industry remains rudimentary and has enormous headroom to grow: in India, just 4% of fresh produce is transported in refrigerated vehicles currently compared to more than 90% in the UK; China has an estimated 66,000 refrigerated vehicles to serve a population of 1.3 billion, whereas France has 140,000 for 66 million. But these disparities seem unlikely to persist. India projects that it needs to spend more than US$15 billion on the cold chain over the next five years. For industrial use, cold must generally be maintained through a whole supply chain – think of how seafood can remain frozen from trawler to supermarket. We call this the cold chain. Cold chain growth is currently based on diesel-powered technologies that produce grossly disproportionate emissions of nitrogen oxides (NOx) and particulate matter (PM). The fridge you might find on a supermarket home delivery van consumes up to 20% of the vehicle’s diesel, but emits up to six times as much NOx and 29 times as much PM as the engine. It also uses HFC refrigerants harmful to the atmosphere. At the same time, however, vast amounts of cold are wasted, for example when liquid natural gas (LNG) is turned back into gas at import terminals. This cold could potentially be stored as liquid air or liquid nitrogen then recycled to reduce the cost and environmental impact of cooling in buildings and vehicles. This insight has stimulated new thinking aimed at creating business and environmental value from the efficient integration of cold into the wider energy system, now known as the “cold economy”. The cold economy crucially involves the recycling of waste cold and “wrong-time” energy such as excess wind power generated at night when demand is low to provide, through novel forms of energy storage, low-carbon, zero-emission cooling and power. Big changes in the energy market over the next decade will spur the adoption of tidal power, solar power, offshore wind and other novel technologies. This in turn will require far greater integration of different forms of energy generation and consumption – and it is increasingly clear this now means joining up not only heat, power and transport, but also cold. This is an important opportunity: with the right support, the cold economy could develop into a large industry that simultaneously reduces greenhouse gas emissions, improves air quality and replaces environmentally destructive refrigerants with benign alternatives – as well as generating thousands of new manufacturing jobs. The cold economy is the subject of a new policy commission entitled Doing Cold Smarter, launched by the University of Birmingham this month. It will assess not only how the growing demand for cooling can be met without causing environmental ruin, but also the potential benefits both in the UK and emerging markets.  What will we come up with? You’ll have to wait until the commission’s final report is published this autumn. But it should be full of thought provoking – even cool – ideas."
"Zones of ocean known as Marine Protected Areas (MPAs) are all the rage. They have no single or agreed definition, but essentially they are areas of sea in which human activity is restricted or prohibited in order to preserve and protect marine habitat and species. They may be small coastal areas or very large offshore expanses of ocean. MPAs are established by local or national governments in order to address actual or potential threats to the marine environment, to create “blue corridors” and to safeguard the breeding and feeding grounds of various marine species. The thrust for large-scale MPAs is driven by global targets tied to international obligations under the Convention on Biodiversity 1992. Currently the global target is to protect 10% of the world’s oceans by 2020. But in September, at a side event to the United National General Assembly, the UK environment minister, Michael Gove, proposed that the global target be increased to 30% by 2030. This is not a new idea but it is a big ask, given the current conservative estimate that only around 3% of the world’s oceans are protected. The strongest advocates and lobbyists for large-scale MPAs are conservation charities, research institutes and individuals who catch the attention of the media, such as WWF,
National Geographic’s Pristine Seas Initiative, Pew Trusts, and the DiCaprio Foundation. Arguments are made that the most effective MPAs cover large areas (including reefs and the breeding and feeding grounds of open-ocean species such as sardines or tuna), in which all extractive marine activity by humans, such as fishing or mining, is prohibited, and which are maintained as no-take areas for an extended period of time. The case for creating such protected areas seems like an obvious win in environmental terms. But the science supporting such arguments is inconclusive and mixed, not least owing to lack of sufficient data, especially studies that take a longer-term view. Very large MPAs are also difficult to patrol, despite promises of using satellite and drone technology. Some appear to be little more than “paper parks”, protected in name only with overfishing and so on still happening. The oceans are regarded as part of the “global commons” and the heritage of mankind. And indeed they should be treated as such. But in the “blue” credentials race between nations seeking to declare ever bigger MPAs, there are a number of real political problems. Large-scale MPAs tend to be declared in areas where there is least likely to be major opposition, especially from fishers. Overseas dependencies and territories are particularly popular. It is much easier to declare large no-take marine protected areas around remote island overseas territories with small, economically dependent, politically weak, communities than coastal areas where articulate, well-resourced commercial interests voice opposition. The UK, for example, has declared large MPAs around the British Indian Ocean Territory and Pitcairn and it is proposing to do so around Ascension Island, South Georgia, St Helena and Tristan da Cunha. It has pledged to safeguard over 4m square kilometres of ocean around the territories by 2021.  While there may well be noble environmental reasons for doing this, there can also be significant political effects. A 2010 Wikileaks cable suggested that one motivation behind the MPA around the Chagos islands was to prevent resettlement of locals to their homeland. The locals sued the UK government – and although the UK’s Supreme Court has since rejected that this was a motivation, resettlement clearly remains an issue and was referred to by the International Court of Justice in the request for an opinion by the United Nations General Assembly. The UK is not alone. France, has declared a large MPA around New Caledonia; the US around Hawaii; and Chile around Rapa Nui Rahui (Easter Island). The largest protected areas are all in such distant waters. The legal procedure for declaring an MPA, meanwhile, often skips full democratic debate. In some cases they can be achieved by presidential fiat or executive order. All this means that those whose livelihoods are likely to be impacted by restrictions or prohibitions on human activity in an MPA may have little or no involvement in the decision-making process. Meanwhile, there is often no guarantee that promises made about the benefits of the MPA to local inhabitants – such as employment in eco-tourism, better fish size, large catches in the longer term, or profitable visits by teams of researchers and scientists – are delivered. Linked to this is the fact that the management of MPAs is not always representative. Local or indigenous people have been known to be marginalised. Management is sometimes dominated by the organisations that lobbied for the creation of the MPA is the first place. For example, where resources are limited, NGOs or researchers funded by these NGOs are often relied on. MPAs are also sometimes used as a trade-off by small states surrounded by large seas to reduce their financial burdens and attract inward investment as well as international approbation. An example is in the Seychelles, where a US$22m national debt owed to overseas lenders was traded to a US-based NGO (The Nature Conservancy) in return for an undertaking that future repayments by Seychelles will be paid into a trust fund directed at the conservation of two extensive MPAs. Taking steps to address concerns about our shared marine resources is of course commendable. But “ocean grabbing” through the declaration of MPAs is a worry, especially if nations agree the higher target to be achieved in a fixed time. Already there are calls by those urging caution for advocates and lobbyists to adopt ethical guidelines and suggestions for better and more equitable models of management. In some cases these are being heeded. Nevertheless, the targeting of small island states and the role of charitable organisations in what are, ultimately, political decisions, needs to be questioned. This article was edited on October 23 to clarify certain points."
nan
"All across the world, we hear uplifting stories that reflect the fast changes in the energy scene. The developed world is consuming less energy than ten years ago. Carbon prices are at the highest level in a decade. Costa Rica now generates more than 99% of its electricity from renewables. Yet the Paris climate targets seem in jeopardy and most forecasts say not enough is being done. Why? In truth, nearly nobody is doing enough to cut emissions by the 11-19 gigatonnes thought necessary to restrict the increase in the world’s temperature to 1.5℃ by 2050. While Europe has done so much in the past and has an 18% renewables share of electricity generation, now it is stalling. Donald Trump has taken the US out of Paris and is trying to revive the coal industry, while taxing imported solar panels. The developing world, which tends to be more heavily reliant on fossil fuels to produce power, will have taken note. This matters, because energy demand from non-OECD countries is currently around 60% of the world total. Consumption is still rising fast, with growing numbers of connected homes a key factor. Electricity generation by source, 2017 It is difficult to generalise, however. China has invested massively in renewable energy – US$127 billion (£99 billion) in 2017 alone, which is head and shoulders above any other country. The new solar capacity China installed during that year equates to several Hinkley Point nuclear power plants. With heavy government support, China has made excellent progress reducing energy consumption per unit of GDP, and an even better job at reducing carbon emissions per unit of GDP.  India is further behind. Where China announced that every household had access to electricity in 2015, India is still going through a major electrification push. It has doubled the proportion of homes connected to over 80% since the turn of the century, though millions of homes still don’t have electricity.  India’s electricity system relies primarily on cheap domestic coal, accounting for about three quarters of consumption. India is therefore heavily relying on coal to fuel its economic growth, and the electrification push is rapidly driving up demand – putting further stress on the power grid, too. China had an even greater dependency on coal a few years ago; now it is more like two thirds for electricity and 60% for energy overall.  India/China growth rates 2011-2017 But if India has more work to do, there are signs it is moving in the right direction. Investment in renewable power did finally top that of fossil fuel generation last year, and the country recently earned praise for its efforts in this area.  In sharp contrast to these countries, Russia has a Soviet legacy of full electrification. Yet power generation from renewables last year, excluding hydro-electricity, was only 0.1% of total output. Russia is instead pushing for more nuclear power, which is unpopular in the West. On the other hand, its coal dependency for electricity is in the low teens; most Russian power comes from gas.  Meanwhile, Africa, the Middle East and Southeast Asia have all seen strong increases in power generation and CO₂ emissions over the past decade. Recent data also contains stark warnings for the future: Indonesia, Pakistan and the Philippines all increased CO₂ emissions above 5% in 2017, mostly through significant increases in coal-fired electricity output. Many developing countries have resisted pressure from the West to decarbonise in the past, arguing Western industrialisation caused most of the problem in the first place, and it will be even harder to persuade them in the current climate. So it is important to realise it is not purely a straight choice between cheaper fossil fuel power and renewables (or nuclear): additional options often get overlooked.  Coal’s share of global electricity production is the same as 20 years ago. Yet newer plants have at least made generation more efficient. Between 1997 and 2016, fuel savings in power generation were 8% for coal and 16% for natural gas. Coal plants in developing countries are approaching the efficiency levels of the developed world, while gas plants have seen improvements worldwide.  We are also underplaying an opportunity with gas. When you compare new gas and coal plants, the carbon emissions from gas are between 50% and 60% lower per unit of power output. In this respect, the fact that gas-fired electricity output has almost tripled in the last 20 years is to be welcomed. Persuade some countries to switch future plants from coal to gas and you make a big difference to emissions. Methane emissions are a controversial downside, but there is still a case for gas.  Share of global electricity generation by fuel  Yes, replacing fossil generation plants with renewables is a quicker way to decarbonise electricity, but we need to be realistic. This will involve building a phenomenal amount of capacity – and we’re moving too slowly. Global investment in renewables actually fell last year. To turn this around, reducing costs is vitally important, as is carbon pricing – the UK is a prime example of how this can effectively remove coal from the energy mix. Nonetheless, scores of new fossil-powered plants are in the offing worldwide, and developing nations in particular are just not going to build enough renewables to reach the Paris targets. By 2040, renewables are still forecast to have a smaller share of power generation than oil, gas or coal. Carbon capture and storage is also growing too slowly. It is important to emphasise that electricity is not the only issue – it only accounts for about 40% of the increase in final consumption up to 2040. Another understated challenge, for example, is the growing use of oil in transport. Yet if there is an electric car revolution, a substantial share of that demand will shift into electricity – and it will only be as clean as its source.  But given the reality of where the world, particularly the developing world, is heading, we should only expect so much of renewables. We must also focus on plant efficiency and encouraging switching from coal to gas-fired power. I am not saying this will make the Paris targets achievable, but it will get us closer than being dogmatic about renewables. We need to recognise where we are and tackle carbon emissions from all possible ends."
"
Share this...FacebookTwitterA modest long-term (1800s-present) declining trend in ocean pH values predominantly occurred prior to 1930, or before anthropogenic CO2 emissions began rising precipitously. Since 1930, seawater pH trends have risen slightly, meaning sharply rising CO2 has been coincident with less, not more, ocean “acidification”.

Image Source (lower graph): Wei et al., 2015
Is “acidification” occurring too rapidly for species to adapt?
Scientists (Wei et al., 2015) estimate that the ocean’s global mean surface pH may have declined (i.e., become less alkaline and thus more “acidic”) by -0.07 to -0.08 in the last 200 years — from ~8.12 during pre-industrial times to 8.04 to 8.05 today.
It is commonly claimed that this long-term decline in pH, or “acidification”, is occurring far too rapidly for the oceanic biosphere to adapt.  Consequently, there are alarmist claims that the pH changes in the last few hundred years are so extreme they will lead to a mass extinction event.

Image Source: Wei et al., 2015
A pH change of -0.07-0.08 over 200 years is an overall long-term pH change rate of about -0.0003 per year.
By way of comparison, from one season to the next, or over the course of less than 6 months, pH levels naturally change by ±0.15 pH units, or twice the overall rate of the last 200 years. 
On a per-decade scale, the changes are even more pronounced.  Oceanic pH values naturally fluctuate up and down by up to 0.6 U within a span of a decade, with an overall range between 7.66 and 8.40.  This is decadal rate of pH change is larger than the overall 200-year trend (0.07-0.08) by a factor of 8.

Image Source: Wei et al., 2015
If the oceanic biosphere was incapable of adapting to the modern rate of long-term change (-0.07-0.08/200 years), or to the frequently-realized seawater “acidic” values of 7.7 or 7.8, one would think this vulnerability would have been observed at some point in the last 200 years.
Reconsidering the “acidification” starting point
Many of the highly cited pH trend studies choose a starting point from the recent decades rather than from a long-term record.  Dore et al. (2009), for example, chose 1988.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Using recent decades has the effect of illustrating that rapid pH decline, or “acidification”, coincides with dramatically rising CO2 emissions.  This is the intended representation, of course, because it is assumed that we humans are responsible for “acidifying” the oceans.

Image Source: Wei et al., 2015
What if we choose 1930 as the “acidification” starting point?
If CO2 emissions predominantly drive trends in oceanic pH, the correlation between pH decline and an explosive rise in emissions could presumably be established beginning around the 1930s, or when CO2 emissions began to rise dramatically.
Interestingly, an entirely different pattern emerges if we use 1930 rather than more recent decades as the starting point for pH trend detection.
Namely, the long-term decline in pH can mostly be found in the decades prior to the 1930s, or when steep increases in CO2 emissions were not occurring.
The post-1930s period even suggests a slightly rising pH trend.
In other words, after CO2 emissions began rising precipitously in the 1930s, the oceans have become less “acidic”.
This determination would appear to undermine the claim that human activity, and not natural variation, is what drives the long-term declining trend (0.07 to 0.08) in oceanic pH.



Image(s) Source (lower graph): Wei et al., 2015
Share this...FacebookTwitter "
"
Share this...FacebookTwitterDespite all the talk about the need to transition over to green energies, Germany’s progress — in especially wind energy — has ground to a complete halt.
German news site iwr.de here reports that the expansion of wind energy in Germany has “come the a stop” as the government has scaled back subsidies and enacted stricter permitting laws.
“As in April 2019, only nine new wind turbines went into operation nationwide in May,” IWR reported. “The year 2019 threatens to be a disaster for the wind industry in Germany.”
The IWR reported further: “In the first five months of 2019, only around 60 new onshore wind turbines went into operation nationwide. This is the result of an IWR evaluation of data from the market master data register of the Federal Network Agency (BNetzA).”
“A catastrophe” for wind power
At Twitter green energy activist Prof. Volker Quaschning called the collapse a “catastrophe”, tweeting that the expansion of wind power “collapsed completely”. He added that “it will be impossible to meet the CO2 reduction targets” and that 40,000 jobs in the wind industry are “on the brink”.

Katastrophe beim #Klimaschutz: Ausbau der #Windkraft bricht seit 2018 komplett ein. Erreichen aller #Klimaschutzziele wird so absolut unmöglich. >40.000 Jobs auf der Kippe.#Groko @peteraltmaier @CDU @spdbt @markus_Soeder#FridaysForFuture #ParentsForFuture #scientists4future pic.twitter.com/pycp1UgOqT
— Volker Quaschning (@VQuaschning) June 8, 2019

Wind power in Germany has been met with increasingly fierce protest from citizens, especially from traditional environmentalists, who reject the industrialization of the landscape. Others point to wind energy’s volatile power supply, cost, noise pollution, general ineffciency and danger to birds and ecosystems.
Share this...FacebookTwitter "
nan
nan
"
Share this...FacebookTwitterThere has been a flurry of major May cold weather and snow reports coming in from a variety of regions across the globe, leaving global warming alarmists speechless.
Australia in ice box
For example, weather site electroverse.net here just reported on how the entire Australian land mass is getting walloped by extreme cold as the winter season begins there.
“It’s a cold snap affecting the whole country, it’s a big one,” says Bureau of Meteorology (BOM) forecaster Sarah Scully. Temperatures would be 10C below normal “even in the Northern Territory and Queensland.”
German mountain peak sees 6 meters of snow – in May!
Much of Europe has also been seeing unusually cold temperatures as well. Germany’s highest peak, Zugspitze, recently saw snow pile up to 6 meters – in May.
“That’s “the most in 20 years,” reported Michael Krueger of Science Skeptical.
“Very remarkable” snow in Corsica
Dalmatia, Croatia has seen “its coldest May start since records began and a “very rare and very remarkable” just blanketed the Mediterranean island of Corsica.
“Very Rare and Very Remarkable” May Snowfall Blankets the Mediterranean Island of Corsica

New England: “Been brutal”…can’t remember such “delayed” spring
In North America in New England on May 13th, Vermont, New Hampshire and Maine were forecast to get snow, and not just dustings, but real cover.
Vermont-resident and NTZ reader Indomitable Snowman PhD wrote by e-mail 2 days ago: “It’s been brutal.  I can’t remember a ‘spring’ – ever – that has been this slow and delayed.  The grass is starting to turn green, but there is barely a hint of leaves on the trees.”
“Huge piles of snow” linger
Indomitable Snowman Phd – also a pilot – also described how he had just flown some friends up to Quebec City on May 12th and how on the way up they could see “there was still some snow in the forest and in the ditches”:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Snow still remains on the ground in mid-May over southern Quebec, Canada. Photo: Indomitable Snowman PhD.
And upon landing at CYQB (Quebec City airport), he wrote: “There were still huge piles of snow on the grass between the taxiways and behind the perimeter fence from the dumping of snow during the winter”. See photo:

Piles of winter snow remain at Quebec City airport in mid-May, with bare trees in background. Photo: Indomitable Snowman PhD.
On the way back, inbound to Burlington, Vermont, they flew past Mount Mansfield. What follows is footage shot BEFORE more snow fell the very next night (May 13-14):

https://notrickszone.com/wp-content/uploads/2019/05/KBTV-ILS33.mp4


Footage by Indomitable Snowman PhD.
As the footage shows, one might think it’s February over Vermont, and not mid-May!
By the early morning of May 14, the National Weather Service (NWS) in Vermont reported snowfalls of 3.5 inches in Danville, 2.3 inches in Williamstown, 2.5 inches in Plainfield and 2 inches in Marshfield. Mount Washington in New Hampshire even saw a foot of new snow. Mid-May!
Major Greenland glacier “slams on the brakes”
A sign that the globe, or at least a major part of the Arctic (a claimed “climate canary in a coal mine”) has been seeing a major warming slowdown is that European satellites have been showing how a mighty Greenland glacier has “slammed on the brakes”. The Global Warming Policy Foundation site reports:


In the 2000s, Jakobshavn Isbrae was the fastest flowing ice stream on the island, travelling at 17km a year. […] But now it’s all change. Jakobshavn is travelling much more slowly, and its trunk has even begun to thicken and lengthen.”


 


Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Kirye
and P. Gosselin
Once predicted to be ice-free by climate “experts”, the Arctic ice has not lost any volume over the current decade.
Using the modelled ice volume data from the Danish Meteorological Institute (DMI), we see June 15 volume trend has been flat since 2010:

Data source: DMI
Next we examine the fluctuating ice volume, going back to March 2006:

Data source: DMI
The above plot shows how Arctic ice volume has not gone down in 13 years, i.e. since climate experts began warning in earnest that the Arctic had entered a “death spiral”.
Strongly correlated with natural Atlantic ocean cycles


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




That the Arctic has plateaued at a low level does not surprise a number of climate and weather experts, who say it is natural and in large part connected to the North Atlantic sea surface temperature oscillations:

Atlantic Multidecadal Oscillation Index according to the methodology proposed by van Oldenborgh et al. 1880-2018.
Arctic ice strongly connected to natural ocean cycles
Note how September minimum ice shown below corresponds to the AMO index, which indicates changes in North Atlantic sea surface temperatures.
Little wonder alarmists always like starting their charts in the late 1970s.
Antarctic Dome A Sets New Record Low!
Ending on an anecdote, Swiss veteran meteorologist Jörg Kachelmann tweeted Antarctic Dome A station set a new record low at -82.7°C for this station yesterday.

Gestern gab es an der Antarktis-Höhenstation Dome A mit -82:7 Grad einen Kälterekord für die Station seit Beginn der Messungen dort.https://t.co/Ez5co6nh6w
— Jörg | kachelmannwetter.com (@Kachelmann) June 16, 2019

 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe weather sensitivity of activists
By Frank Bosse and Prof. Fritz Vahrenholt
(Translated/edited by P. Gosselin)
Have you noticed it too?
Over the last years it’s been climate change that is to blame for everything. Whether it’s storming outside or snowing, whether it’s not storming or not snowing, whether it’s thunderstorming with a lot of rain, or if it’s dry: everything is said to be climate change. What kind of weather would not show climate change? Any deviation from the mean is now a sign of climate change?
There are some who oppose this logic.
Swiss meteorologist Jörg Kachelmann is a shining example. On Twitter, he recently got peppered with accusations that he’s supplying the “climate deniers” with ammunition.
Carbon has made an immense contribution
This article could show the opposite because we too are convinced that mankind is changing the climate, and the use of coal, gas and oil in the entire value chain of industrial society has brought it about. On the other hand, mankind would not be where it is today without the positive effects of carbon in human nutrition, energy supply, mobility, poverty alleviation, the fight against disease with medicines and many other achievements that we owe to the combined efforts of generations before us.
And it will take some effort to get the effects of our actions under control by about 2100. Any earlier date for an Armageddon is fiction, serious science agrees.
Task for a century, not a legislative period
We would like to refer once again to what we derived in July 2017: How high can the concentration of CO2 in the atmosphere increase in order not to surpass the 2°C target: around 600 ppm? Assuming current (2017) 407 ppm CO2 and a current average growth of 2.11 ppm per year, the 600 ppm would be reached in 2108. Of course it would be necessary to reduce global CO2 emissions to near zero by the end of this century – a task for three global generations and not for three German legislative periods.
Desperate activists seizing upon every anomaly
Activists don’t see it that way. They announce the checkered flag will be waving for mankind in just 12 years.
But it’s difficult to justify this, so they try to take advantage of any weather. For example, it can get warm in Finland when the wind blows from the south in summer. This shouldn’t be surprising given the high solar radiation, but the activists now hype it up to turn the weather into climate.  It is quite easy to calculate how many days the daily maximum temperature there exceeded 26°C.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The number of days over all of Finland with a maximum temperature of over 26°C. Data source: E-OBS (KNMI)
It’s easy to see that warmth over Finland happens every now and then and that real conclusions cannot be drawn. There is no reason to panic about hot Finnish days.
No evidence of anthropogenic influence on cyclones
Another dubious claim that is often made is that climate change is causing more / stronger tropical storms such as hurricanes (in the Atlantic) and typhoons (in the Pacific). In recent years, we’ve seen a number of articles of this type whenever there’s been a tropical storm. A simple thermodynamic conclusion gets drawn: Warmer water contains more energy and makes storms worse.
Yet, a recent study by world-leading researchers on this topic makes it clear that it is not so easy. They find many uncertainties, and in particular that Atlantic hurricanes are not attributable to climate change, not even the associated extreme precipitation:
To date, there is no convincing evidence of a detectable anthropogenic influence on hurricane precipitation rates,…”
No trend in German precipitation
Since 2019 could be a rather active hurricane season, we have tobe prepared that climate change will be blamed by activists. But this conclusion, according to science, is not justified. It’s simple scaremongering! But we all know Greta Thunberg’s call: We want panic!
Also often reported: Forest fires in this country [Germany] are largely due to the “climate crisis”. Forest fires are the result of drought. Yet, it is not the heat that is to blame, but rather the lack of precipitation. And what about summer in Germany?
 

Summer precipitation in Germany since 1880. Source.
The DWD German Weather service notes: no trend has been found.
Why are they lying?
It was unusually dry last year, so yes there were more forest fires. All those who exploit a weather event for their agenda have to ask themselves: What kind of agenda is this for which you have to lie so much?
Share this...FacebookTwitter "
"Think of rainforests and the picture is inevitably one of a dark and forbidding realm where life is abundant, yet alarmingly cryptic. Rather than the sense of space offered by long, iconic grassland vistas, distance is compressed into tangled webs of foliage, veiling both predators and prey. Diffuse and difficult to access proteins, carbohydrates and fats increase the chances of encountering an array of lurking dangers. For these reasons, it has long been thought that humans were only able to colonise rainforests in the last few thousand years, after the development of agriculture. In fact, we still have no clear idea when humans first began to inhabit rainforests. But mounting evidence is deconstructing the idea that rainforests – that is, forests requiring between 2,500 and 4,500 mm of rain a year – were hostile “green deserts” to early hunter gatherers.  In South Asia, there is now compelling archaeological evidence that Homo sapiens rapidly adapted to life in rainforests. At Niah Cave in Borneo, toxic plants obtained from nearby rainforest habitats were being processed as far back as 45,000 years ago, soon after people were first documented in this region. In Sri Lanka, there is evidence for direct reliance on rainforest resources at least 36,000 years ago. And a paper published in Nature last year reported the presence of humans in a rainforest environment on Sumatra dating back to a staggering 70,000 years ago. If early humans could adapt to the rainforests of South Asia, then perhaps they also did so much earlier in Africa at the inception of our species. While this is not a new suggestion, we now know that our species first arose in Africa more than 300,000 years ago, leaving plenty of time for our ancestors to adapt to varied habitats.  But finding conclusive evidence for rainforest habitation is difficult. Rainforests are very challenging fieldwork environments, not least because the warm and wet conditions mean that very little of the archaeological record survives the test of time.  In addition, Africa’s rainforest ecologies are fragile, sustained by annual levels of rainfall that are at the lowest limit of what is required to maintain a rainforest. This means that there were frequent episodes of rainforest fragmentation in prehistory, making it difficult to establish the environmental context of past human habitation in regions that are forested today. With the exception of a few dedicated individuals, Africa’s rainforests have barely been explored for their potential role in human evolution. Despite the many problems described above, there are tantalising suggestions that humans used and perhaps lived in African rainforests far before the development of agriculture some 8,000-9,000 years ago. It is also becoming apparent that this line of research has growing implications for how we understand our evolutionary history. Rigorous ethnographic studies have demonstrated that the availability of wild plant foods have been considerably underestimated in Africa’s rainforests, and there is some evidence supporting the ancient exploitation of such resources. An ancient hominin tooth from Central Africa indicates that our hominin ancestors were already living in mixed environments at the edges of forests around 2.5m years ago. Composite foraging tools argued to be forest adapted may have appeared as early as 265,000 years ago and have been found across vast regions of modern rainforest. And new evidence published this year shows that humans were exploiting mixed tropical forest/grassland environments in Kenya up to 78,000 years ago.  Later human fossils dating to around 22,000 years ago from the Democratic Republic of Congo and 12,000 years ago in southern Nigeria feature enough distinctive morphological features to suggest that the populations they belonged to did not often mix with others from elsewhere in Africa. Specifically, these fossils bear more physical similarities to people living between 100,000-300,000 years ago than their contemporaries. It’s possible that they were separated because they had adapted to life in very different environments. My fieldwork in tropical West Africa has also uncovered striking cultural similarities. Some groups living here up to 12,000 years ago were making stone tools that were more typical of people living in similarly earlier time periods. This is not akin to findings from elsewhere which emphasise the late presence of a single artefact form in an otherwise “advanced” tool kit. My findings from Senegal could easily be transplanted to a situation 50,000 or 100,000 years earlier, and they would not look out of place. Why were people here maintaining such ancient material cultural traditions when populations elsewhere had begun to experiment with agriculture? Did they choose to sustain strong cultural boundaries? Or were they cut off, either by distance or some other factor? While we are still working to establish the environmental context of these sites, it seems plausible that regions of dense forest may have played an important role in separating – and hence diversifying – early Homo sapiens populations. Such regions represented discrete human habitats, heralding the beginnings of our adaptability or “ecological modernity” and adding to the gamut of processes driving the significant physical variation of early members of our species. Indeed, such processes of diversification may even have been the cauldron of our biological plasticity and behavioural flexibility, as I argue in a recent paper. The plot thickens further at this point. It seems that our species shared Africa with other, more genetically divergent hominins such as Homo heidelbergensis, Homo naledi and perhaps other as yet undiscovered species. There are even suggestions that there may have been gene flow between Homo sapiens and one or more such hominins. If proved, the shifting patchwork of Africa’s diverse environments – including rainforests – may therefore also have played a role in facilitating the late persistence of such species and subsequent episodes of gene flow with Homo sapiens. It’s possible that the last groups of species such as Homo heidelbergensis hid out in forests. Given the extraordinary discoveries of the last decade, it is certainly wise to keep an open mind and shy away from overly dogmatic assertions about human evolution. This is particularly the case when so little is known about vast swathes of Africa, whose rainforest regions alone cover 2.2m square miles. The only inescapable fact is that there is a lot yet to be discovered."
"Sainsbury’s, Lego and H&M are among the businesses to make a prestigious A-list of companies that are deemed to be at the forefront of the charge to tackle the “existential” climate crisis. The list is compiled by non-profit group CDP which scores companies based on the environmental data they voluntarily disclose on its platform. Just 2% of the 8,000 companies it scores made the A-list, with Nestlé, Unilever, BT and Walmart among the 179 to make the cut. A focus on the climate emergency was not at the expense of business success, CDP said, with companies on the A-list also outperforming peers on the stock market by 5.5% a year. The company also has an F-list for companies that did not submit a response for climate change in 2019 – with Amazon and Facebook among the 9,225. Dexter Galvin, CDP’s global director of corporations and supply chains, said the A-list were “blazing a trail for others to follow”. He said: “Other companies should look to these leaders for inspiration and learn from them.” “The latest science says we need global emissions to urgently peak and start declining by 7.6% a year to avoid the worst impacts of the climate crisis,” continued Galvin. “Companies can and should become part of the solution rather than part of the problem.” With the financial performance of companies on the A-list better than their rivals, Galvin said this demonstrated that “leading on climate action is good business in today’s economy” and would be “essential business in tomorrow’s economy”. Unilever points to the success of its trophy sustainable brands – a group of 28 that includes Dove, Hellmann’s and Sunsilk – which are growing much faster than the rest of its business. The brands, which accounted for more than half of the group’s €51bn (£46bn) sales last year, are those that are the furthest ahead on meeting the company’s sustainability goals. A-list companies scored highly because of their transparent and comprehensive disclosure of climate data. Examples of best practice include setting science-based targets, shifting to renewable energy and incentivising suppliers to reduce their emissions. Lego, for example, was praised for increasing its use of recycled materials and plant-based plastics; two years ago it started selling Lego pieces made from plant-based plastic sourced from sugar cane. Sainsbury’s, meanwhile, has pledged to halve the amount of plastic packaging it uses over the next six years. H&M, the Swedish group that also owns & Other Stories and Cos brands, is aiming to have 100% recycled or sustainably sourced materials by 2030. CDP says investors and purchasers are calling for transparency and action from companies on how they are responding to climate change. "
nan
"In an editorial on Saturday, the Weekend Australian defended the News Corp paper’s climate coverage in response to criticism that it had underplayed the bushfire crisis and chosen to highlight concerns about arsonists and hazard reduction rather than explain the climate change drivers of the horrendous season. The editorial said: “In our coverage, the Australian’s journalists report facts about how to tackle bushfires and about how to deal with the impact of climate change. Second, we host debates reflecting the political division that exists in Australia about how to address climate change without destroying our economy.”  It said its coverage of the bushfires had been “wilfully and ineptly misrepresented by the New York Times and Guardian Australia as climate denial”. The Australian newspaper’s editorials, like its news stories, accept the basic premise that humans cause climate change and that action should be taken. The newspaper also covers diligently the news around the climate policy debate and the implications of climate change for business. But its defence of its bushfire coverage ignores its prolonged willingness to expose readers to a regular diet of misrepresentations on climate change science on its opinion page, as well as outright denial of the breadth of science linking fossil fuel burning to dangerous climate change. In November, as the bushfire crisis was unfolding, News Corp’s executive chairman, Rupert Murdoch, told his annual general meeting: “There are no climate change deniers around, I can assure you.” The next day the Australian ran a column from the mining industry figure and geologist Prof Ian Plimer, who wrote: “It has never been shown that human emissions of carbon dioxide drive global warming.” The organisation Climate Feedback asks climate scientists to fact-check articles and opinion columns. Like three previous Plimer columns, the group gave the article its lowest rank for scientific credibility, saying it was “a mixture of misdirection, misleading claims and outright falsehoods”. Last month, two days after the Bureau of Meteorology declared that 17 December 2019 had been Australia’s hottest day on record, the Australian published a story quoting a long-time critic and climate science “sceptic” questioning the bureau’s methodology. The story quoted “climate scientist” Dr Jennifer Marohasy but did not mention that Marohasy works at the Institute of Public Affairs, a Melbourne thinktank heavily financed by the mining billionaire Gina Rinehart and known for promoting climate science denial. The story reported Marohasy’s criticisms of a widely used technique known as homogenisation that corrects for known errors in data, even though the data used to calculate the hottest day record is not homogenised. The Australian has a long history in this space. There have been lots (understatement alert) examples of climate science denial at The Australian over the years. I have written about lots of them. A thread.  In 2009 it published a column that dismissed climate science as a “fraud” pushed by “warmaholics”. In response, an exasperated Dr Michael Coughlan, then chief climatologist at the Bureau of Meteorology, said: “The Australian clearly has an editorial policy. “No matter how many times the scientific community refutes these arguments, they persist in putting them out – to the point where we believe there’s little to be gained in the use of our time in responding.” In 2013 a study of News Corp’s coverage of climate change found it was a dominant voice in the country’s media on the subject. The Australian wrote more on it than any other outlet, and almost half its comment pieces expressed doubt about the science, including 100% of seven editorials analysed. Only 18% of news stories expressed doubt, the study said. In 2013 the newspaper ran a front page story with the headline “Sea rise ‘not linked to warming’ ”, based on a study which it later admitted it had “misinterpreted”. The same year it ran a news story claiming that “experts” were worried about a coming ice age. The article relied on five-year-old quotes lifted from a blog by a group that has claimed carbon dioxide is a “coolant” and not a greenhouse gas. The Australian has also published stories sympathetic to claims that wind turbines make people sick. In 2012 the Australian Press Council upheld a complaint against the newspaper after it ran an article by a British climate science denier, James Delingpole, in which he quoted an anonymous sheep farmer who had compared the wind energy industry to a paedophile ring. After the press council’s judgment, Delingpole returned in the Australian to say he stood by “every word” of his story “especially the bit about paedophiles”. One of the Australian’s most flagrant and regular deniers has been Maurice Newman, the former ABC chairman and adviser to Tony Abbott who believes climate scientists are part of a global socialist plot. “The scientific delusion, the religion behind the climate crusade, is crumbling,” Newman has written. On checking one column, a scientist Newman had quoted to back his argument that global cooling was on the way said the claims were “scientifically ludicrous”. As recently as last week Newman referred to “the media left, Hollywood and the rest of the global warming cult”, comparing them to “ancient druids”. Even while covering the topic of hazard reduction, the Australian has turned to climate science deniers. On New Year’s Eve it ran an opinion column by Viv Forbes that advocated a revival of traditional fire management techniques, while blaming the intensity of the fires on a lack of hazard reduction and the creation of national parks. The column did not mention climate change. Forbes spent more than 40 years in the coal industry – a connection not disclosed in the column – and leads a project against the Paris climate agreement that says fossil fuel emissions are not changing the climate, and that increasing concentrations of CO2 are “improving the environment, not harming it”."
"Sea levels are rising and climate fires are burning. Unless the world acts urgently to combat the climate crisis, it will be too late to do anything other than shuffle around the deckchairs on the Titanic. So says the World Economic Forum, the body that organises the global elite’s annual shindig in the Swiss ski resort of Davos. Each year the WEF asks experts what are likely to be the greatest threats over the next decade; this year, for the first time, the top five risks all related to the environment.  Let’s park the cynicism for a minute. Yes, to be sure, there’s something nauseating about billionaires flying in from around the planet in their private jets to tell the rest of us we need to do more to reduce our carbon footprint. That said, the WEF report suggests it is a dangerous fallacy to assume that new ways of doing things can be phased in slowly over the next 20 or 30 years. Yet the political incentives to put off action for another day are strong. Governments in democracies have regular elections to fight, and they have seen what happened to Emmanuel Macron’s popularity after his attempt to raise fuel duty prompted the yellow vest protests. In Britain there are pressures on ministers to agree measures to boost growth that would be counter-productive from a climate emergency perspective. The battle to save the airline Flybe from collapse and the looming decision over the high-speed rail line HS2 illustrate the dilemma for a government that claims to want to tackle climate change and Britain’s glaring regional economic imbalances. If ministers had decided not to support Flybe earlier this week, Europe’s biggest regional airline would have seen planes grounded and 2,000 jobs put at risk. The chancellor, Sajid Javid, has said he will consider scrapping air passenger duty (APT) on domestic flights as part of his March budget. Would tossing this particular lifeline to Flybe allow Boris Johnson to escape the charge that he is a southern toff who is not remotely serious about levelling up the regions? Yes, it would. Would it be consistent with the aim of tackling the climate emergency? Not remotely. The best tax systems are those that penalise things a country wants less of while encouraging things it wants more of. Scrapping APT would do the opposite: indeed it would be both environmentally damaging and regressive, since it is the better-off – on average – who fly intercity in the UK. APT is not the world’s best-designed green tax, but at least it recognises that there are hidden costs to air travel, and that those doing the polluting should pay. Scrapping the £13 charge on domestic flights would, according to the basic laws of economics, encourage more people to fly. On the other hand, allowing Flybe to go to the wall would hack off a lot of voters, many of whom have just broken the habit of a lifetime and voted Tory. One alternative to flying is to take the train, yet the decision over whether to give approval to the high-speed link between London and the north of England presents another tough choice. Until now, the case against HS2 has primarily been about its cost to the taxpayer, and there is certainly reason to be worried on this score: the costs have spiralled since it was first mooted. An initial £34bn price tag now stands at £88bn, according to the latest estimate. At the outset, taxpayers were supposed to get £2.30 back in economic benefits for every £1 spent. That is now down to between £1.30 and £1.50 for every pound invested, a figure that relies on no further cost rise and much higher train frequency than on other high-speed lines – both heroic assumptions. But HS2 also has an environmental cost. A detailed report into its impact on wildlife says it will irreparably damage five internationally protected sites, almost 700 local wildlife sites, more than 100 ancient woodlands and 33 legally protected sites of special scientific interest. An HS2 spokesperson says the data is not new, and that the line will provide a cleaner and greener way to travel. But, increasingly, HS2 looks an enormously expensive way of adding some extra capacity to the rail network. Critics say there are less environmentally damaging and cheaper alternatives that would generate greater economic benefits to the UK in general and the regions in particular. They are right, and it is really quite scandalous that there has not been more careful consideration of whether the cash for the project (which will almost certainly end up costing more than £100bn) could be better spent. Ministers will probably give it the go-ahead anyway. Johnson has been something of an HS2 sceptic, but does he want his first big post-election domestic decision to be the abandonment of a project supported by Labour councils in the north, especially given that a third runway at Heathrow is going ahead? It would seem that, once again, infrastructure spending was being concentrated in the prosperous part of the country. The political optics would not be good. In their different ways, the cases of Flybe and HS2 tell us much about modern Britain. When it comes to making decisions, the short term triumphs over the long term every time, especially when a powerful corporate lobby gets to work. Ministers say they see no contradiction between a growing economy and protecting the environment, and proudly boast that they are pledged to make Britain a net zero-carbon economy. But that happy day is not planned to arrive until 2050. If the rest of the world follows Britain’s example, that will be a couple of decades too late. • Larry Elliott is the Guardian’s economics editor"
"The BBC is about to screen its first climate change-dedicated documentary in some years. The show, Climate Change by Numbers, is all about the statistics at the heart of the effort to understand the scale and pace of human influence on our climate. Three mathematicians – Hannah Fry, Norman Fenton and David Spiegelhalter – explore the background to three numbers: BBC Four chief Cassian Harrison said the show “puts aside the politics to concentrate on the science”. Nice try, but no: science and politics can’t be separated on this or indeed any other topic where there are wide economic and social consequences, and a good dose of uncertainty.  But everyone involved in the programme is doing us a great service in reminding us that climate science ought to be allowed to be just interesting sometimes. And this kind of approach offers a far more sturdy basis for public conversation than tired insistence upon a monolithic scientific “consensus”. In an exemplary move for a TV show the team includes three academic consultants. Two of them, Tamsin Edwards from The Open University and Doug McNeall from the Met Office Hadley Centre, have long been very active on social media inviting people into an understanding of their work as unfolding and ambitious. Tamsin asks us to learn to love the uncertainty in climate science: We haven’t always sold the idea of uncertainty as not only inevitable but even exciting, and we’ve sometimes over-simplified our communication. That pause in warming of the atmosphere surprised the media and public, even though scientists always expected this kind of thing could happen in the short term. This fits nicely with my own argument that appears in a book of essays Culture and Climate Change: Narratives. As a social scientist and policy researcher with a particular interest and involvement in the media I’ve long been frustrated by the predominant tactics aimed at mobilising public concern. Phrases like “the science is finished” and “the greatest challenge facing humanity” have sought to enrol the public and politicians in a grand cause. But these approaches may alienate as many as they attract. It is far more robust to headline the natural science of climate change as a hugely ambitious risk assessment, the main contours of which have changed little since the early 1990s, and then explain that the rest of the research and policy effort is a big, messy risk management process. It is often forgotten that the IPCC’s First Assessment Report back in 1990 insisted “we are confident that … uncertainties can be reduced by further research. However, the complexity of the system means that we cannot rule out surprises.” Focusing on risk frees the natural science to become a lot more interesting on its own terms, enchanting even. Explaining it as a backroom risk assessment operation, and inviting everyone into that room now and again to follow progress will help to build trust and engagement in some of the most interesting, complex and difficult questions human beings have ever set themselves.  But the natural science is only one, albeit centrally important, part of the climate change story. In cultural terms, climate change is a difficult body of new knowledge that holds significance for all the challenges that humanity has always faced regarding shelter, comfort, food and mobility. In media terms, however, the topic often seems strangely disconnected from mainstream business, politics and everyday life.  Climate change is one of the strongest drivers of innovation in engineering and design, and is spurring radical new thinking in the arts, humanities and social sciences. It is catalysing major advances in lighting, mobility, communications, architecture, food and energy. It is also driving far-reaching and entirely novel conversations about where and how we redraw the boundaries of ethics and politics across time and space.  Not everyone is going to find all of this interesting. But slivers of these themes will be important to pretty much everyone. Giving full rein to the mad diversity of ideas set in motion by this difficult new knowledge helps to engage those people who are bored or alienated by an over-generalised and repetitive chorus of projected woe."
"Last summer, on the Isle of Arran, off the west coast of Scotland, we watched an excited young lad walking down to the water’s edge, fishing rod in hand. Sadly, his chances of catching anything were slim to remote.  Once plentiful stocks of cod, haddock and plaice have almost completely collapsed in the Firth of Clyde, the area of sea in which Arran sits, following a century of poor fisheries management. Nowadays more than 99% of the commercial fisheries landings there are not for fish, but for shellfish such as prawns and scallops, which don’t take a bait. Motivated by this dramatic change in their local marine environment, two Arran residents, Howard Wood and Don McNeish, formed the Community of Arran Seabed Trust back in 1995. They quickly seized on the idea of using marine reserves – areas of sea where fishing and other extractive uses are restricted – as a way to bring back the marine life they had previously enjoyed as scuba divers. Reserves had been used to great success in New Zealand and the Philippines, where the benefits appeared to have spilled over to the areas open to fishing. However marine reserves were non-existent in the UK at the time.  Finally, after over a decade of campaigning and building community and scientific support they got their reserve in Lamlash Bay in October 2008. It was small (only 2.67 km2 in area) but significant, being the first and still the only fully protected marine reserve in Scotland. We’ve looked at the Arran reserve in our research. Our findings, published this year in the journals Marine Biology and Marine Environmental Research indicate marine life is starting to flourish once again.  Complex seabed habitats formed by seaweeds and other plant-like creatures are recovering. These in turn act as a magnet for juvenile scallops, cod and other tasty species.  Adult scallops are benefiting too, growing in size and reproductive capacity. High levels of breeding within the reserve are likely to be seeding surrounding fishing grounds. Marine reserves, such as that on Arran, are the most protected form of Marine Protected Area (MPA).  Due to their perceived benefits for both conservation and fisheries, the use of MPAs has grown spectacularly over the past two decades. They now cover 2.8% of the world’s oceans, and the 2010 Convention on Biological Diversity set an ambitious target for this to grow to at least 10% by 2020. Both the UK and Scottish governments are rolling out further MPAs. There are strong arguments for the conservation value of MPAs. Clearly, if you protect ecosystems from activities which damage them, you expect benefits.  Indeed, global analyses consistently find greater biodiversity and species size and abundance inside MPAs.  Certain habitats such as coral reefs and seagrass are highly sensitive to any kind of human disturbance, and protecting these areas should be a no-brainer given their ecological importance. Atlantic cod, for instance, rely on seagrass for shelter while they’re still growing. However, the added restrictions these MPAs might put on fisheries has been met with strong resistance. In response to this lobbying pressure, it appears likely that UK governments will allow fishing to continue in the majority of the MPAs.  While low impact fisheries such as creeling and line fishing may be compatible with the conservation features in some MPAs, in many cases the most damaging types of fishing such as scallop dredging will be allowed to continue.  There are also no plans for any further highly protected MPAs, such as the one at Arran, to be established. Surely this is a wasted opportunity. Perhaps if the fishing industry could be convinced such MPAs would actually benefit fisheries, they would be met with less resistance. Proving that highly protected MPAs benefit fisheries is difficult, but recent advances in genetics have conclusively demonstrated that disproportionately high amounts of young fish can be exported from marine reserves to neighbouring fishing grounds on tropical coral reefs.   Some scientists claim there is little evidence for them working in the cool temperate seas around the UK. But the Arran marine reserve story adds to the benefits that MPAs have provided to scallops around the Isle of Man and in Lyme Bay, and to lobsters around Lundy Island. Furthermore, recent modelling of the English Channel marine ecosystem concluded that highly protected MPAs were the best bet for both fisheries and conservation.  Crucially, the key to the success of the few MPAs in the UK to date has not just been getting the science right, but involving and getting support from the local community and fishing industries. Zoning arrangements divvying up the Clyde between fishermen and fish replenishment areas have just been proposed. This surely has to be the way forward."
"
Share this...FacebookTwitterTwo recent scientific publications underscore how mass extinction events are associated with global cool-offs, glaciation and sea level fall, and NOT warmer climates.

Life thrives when the globe gets tropically warm. Photo credit: NASA, public domain
There’s been a lot of hype and hysteria surrounding the claims that the recent, modest global warming supposedly will have dire impacts on species diversity and survival.
But the wild claims fly in the face of what the earth’s history shows us: Biodiversity and species thrived in warm periods, and struggled during the cooler ones.
Now scientific results published in two recent papers suggest this yet again. What follows are the abstracts from the 2 papers along with links to them:
1. Fujisaki et al., 2019
To constrain the redox conditions and related nitrogen cycles during the Middle Permian (Guadalupian) to latest Late Permian (Lopingian) deep mid-Panthalassa, we determined the abundances of major, trace, and rare earth elements along with the carbon and nitrogen isotope ratios in shales interbedded with deep-sea cherts that are well-exposed at the Gujo-Hachiman section in the Mino-Tanba belt, SW Japan. … However, unlike the oxic and nitrate-rich deep-Panthalassa, we speculate that oxygen-depleted (i.e., anoxic/euxinic) and bioavailable nitrogen-poor conditions developed in the deep Tethys immediately before the Guadalupian-Lopingian boundary (G-LB). These environmental stresses were potentially driven by a global cooling episode (Kamura event) together with the unique paleogeography, i.e., no contact with polar ice caps in the Tethyan Ocean. Upwelling of the anoxic watermass accumulated in the deep Tethys during the global cooling episode likely triggered oceanic anoxia in the shallow-marine regions around the G-LB [Guadalupian-Lopingian boundary, Mid- to Late Permian], which eventually resulted in the G-LB mass extinction. … In the latest Guadalupian (Capitanian), the appearance of the global cooling episode was proposed based on various lines of evidence; e.g., the lowest sea-level during the Phanerozoic (Haq and Schutter, 2008), the preferential extinction of tropically adapted fauna (Isozaki and Aljinović, 2009), the migration of mid-latitude fauna toward tropical domains (Shen and Shi, 2002), and the occurrences of mid-latitude tillites (Fujimoto et al., 2012) and alpine glacial deposits in high altitudes (Fielding et al., 2008). The high δ13Ccarb values during this period were also interpreted to indicate high primary productivity and leading to an effective burial of organic matter promoted by the global cooling episode (Kamura event; Isozaki et al., 2007a, 2007b, 2011). The global cooling episode potentially affected biological activity in the shallowmarine domains; i.e., the low eustatic levels invoked delivery of fluvial organic matter to shelf because of the increased land area, which likely resulted in increase of organic matter, expansion of the oxygen minimum zone (OMZ), and enhanced denitrification in the water column.”
2. Smolarek-Lach et al., 2019
Mercury Spikes Indicate a Volcanic Trigger for the Late Ordovician Mass Extinction Event … We conclude that our Hg and Hg/TOC values were associated with volcanic pulses which triggered the massive environmental changes resulting in the Late Ordovician mass extinction. … Mercury enrichments have also been described for the middle and latest Permian extinctions. Sanei et al.’s study of the latest Permian mercury enrichment in the Canadian High Arctic, attributed this to emissions from the Siberian Traps [flood volcanism] with deleterious environmental consequences. … [T]he Hg enrichment in the Katian geochemical record (the ornatus anomaly) is interpreted as a volcanic event that triggered severe cooling. It has been suggested that the upper pacificus anomaly is connected with a volcanic eruption which triggered an albedo catastrophe and the rapid expansion of ice sheets.”
Share this...FacebookTwitter "
"What would our energy system look like if the move to a low-carbon society wasn’t left to governments and big energy companies but was instead led by civil society?  We are all used to the debate between states and markets, private vs public provision in shaping the direction of the energy sector; but communities, citizens and local authorities together can form a “civic” energy sector that could revolutionise the way we generate and use energy.  People in the UK are not well served by the current energy market. Investigations have found poor competition, a slow switch towards renewables, and the value in the system being captured by international companies, with very little economic benefit remaining at a local level.  But there is another way, identified by Realising Transition Pathways, a consortium of researchers from across nine UK universities. Existing community energy projects – run by groups of citizens – could link with new roles for local authorities as energy service companies to form a “civic” energy sector.  This civic sector would expand on the work of energy crowdfunding platforms such as Pure Leapfrog and mutual models such as Energy4All to provide new ways for ordinary citizens to invest in local energy resources.  The growth of a civic energy sector would be bad news for the large utilities. The UK’s traditional Big Six energy providers would lose ground in both the generation and supply markets and would need to shift their business models to provide new services. Civic energy would need some early support, but it could soon become the natural preference over what an increasingly outdated utilities sector is offering, having failed to anticipate the potential of local energy and what customers want from their energy providers. Distributed energy would need both technological and institutional change. It would require lots more small and medium scale renewables – more solar, onshore and offshore wind, biogas heat and power plants, and marine energy such as tidal generation. All of these new technologies would need to connect to much smarter distribution grids than we currently have and would require new ways of moving power from the bottom up as well as the top down.  However our work shows that local energy doesn’t mean energy independence; indeed in a civic energy future, interconnection between regions, across the UK and internationally would be critical to balance the system. This wouldn’t mean and end to big power plants, just far fewer of them. These connections would be aided by a smarter, more responsive electricity grid. This could mean a shift to tariffs based on when you use energy rather than how much you use. Consumers would have to be much more engaged. In order to develop a distributed energy system households and businesses would need to get serious about energy efficiency and be more responsive to smart meter data.  Local authorities will also be vital as, in a distributed network, consumers would likely get bills from their local authority energy company. These bills would be for services such as a “warm home” or “hot water” as opposed to the relatively crude system of just paying for energy by volume needed. The old system of paying for how much you use means big utilities can’t stomach a big fall in consumption, so why would they help you really reduce your bill?  If you were paying for “heat” and “light” rather than power by the unit, your energy supplier would want to to keep you warm and your house lit as cheaply as possible,  which means big investments in energy efficiency.  Local authorities are in a great place to do this as they are trusted far more than current utilities.  But of course not all local authorities have the same resources. The north-west of England is not as suited to solar as the south-east, for instance, and the mountainous north of Scotland can provide much more hydro-electricity than the flat farmland of the Fens.  In order to move to a distributed energy system, we would need to carefully plan for maximising energy resources in each region. Achieving this new type of energy system will be challenging – but it is possible."
"
Share this...FacebookTwitterDespite reports of relatively high regional rates of sea level rise, the Atlantic Coast of the United States has actually been expanding in recent decades after rapidly shrinking prior to the 1960s.

A 2001 Salon magazine “terror in the skies” alarmism article featured a Dr. James Hansen late-1980s prediction that New York City’s West Side Highway would be underwater within 20 years.

Image Source: Salon.com
Of course the West Side Highway is not underwater today.
Nor does it appear that there have been any detectable changes to its shoreline position since 1936.
In fact, outside the realm of popularized alarmism, it is well known that geological processes are more determinative of relative sea level changes than climate factors contributing to sea level rise or fall (i.e., glacier melt or advance).
Piecuch et al. (2018) concluded “the majority of large-scale spatial variation in long-term rates of relative sea-level rise on the US East Coast is due to geological processes that will persist at similar rates for centuries.”

Image Source: Piecuch et al., 2018


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Pfeffer and colleagues (2017) assessed 849 coastal sites and determined that geophysical processes, or vertical land motion (VLM) trends (ranging from −13 to +16 mm yr−1 ), “have been recognized as a dominant component of the total relative sea-level variations observed at coasts” at locations throughout the globe.

Image Source: Pfeffer et al., 2017
In a new paper, Armstrong and Lazarus (2019) indicate “trends in recent rates of shoreline change along the U.S. Atlantic Coast reflect an especially puzzling increase in accretion, not erosion.”
The numbers are indeed “especially puzzling” for those immersed in sea-level-rise alarmism.
From 1830 to 1956, shorelines eroded at the rapid rate of -55 cm per year on average. Since 1960, the U.S. Atlantic coast has been expanding (accretion) at a rate of +5 cm per year.
The authors seek to provide a “plausible” explanation for this “enigmatic pattern” by suggesting “beach nourishment” (infrastructure development) may explain the tendencies for shorelines to grow as sea levels rise.
For those who do not ascribe to sea-level-rise alarmism, the recent reversal to shoreline accretion is not puzzling and needs no such “plausible” explanation.
Instead, these trends are consistent with a pattern of shoreline growth “all over the world” for the most recent decades.

Image Source: Armstrong and Lazarus, 2019
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman climate skepticism may have awakened, and ironically it may in large part be an unintended consequence of the “Greta demonstrations”. Germans may be finally getting fed up with the hysteria that has emptied out schools and turned into an ambush on their industrial jobs.
German geologist Dr. Sebastian Lüning, who together with Prof. Fritz Vahrenholt runs German climate skeptic site Die kalte Sonne, was recently interviewed by the conservative Junge Freiheit TV in Berlin (In German).

While the mainstream media focus almost exclusively on the ultra-alarmist climate scenarios, Lüning takes a far more moderate, non-alarmist view of climate and  man’s impact on it.
In Lüning’s view, natural factors play an as big, or even bigger. role on climate than humans do.
Recent warming “not unusual”
In the interview, Lüning explains how the assumptions made by the CO2 alarmists fall apart when tested against the observations of the past. The experienced German geologist explains why the modern 20th century warming is nothing unusual and that the same has already occurred numerous times over the past 10,000 years.
Start of industrialization coincided with end of Little Ice Age
One problem, Lüning says, is that scientists like to begin their temperature charts right before industrialization began in earnest, which happens to coincide near the temperature low point of the Holocene. He says that the term “pre-industrial” has been the source of “lots of confusion”.

Medieval and Roman times were warmer. Image: Die kalte Sonne
Natural factors at work
Lüning reminds listeners that the question concerning how much of the recent warming can be attributed to man is still being hotly debated, and that we know that natural factors have always been in the driver’s seat in the past. Personally Lüning believes that the real figure is closer to 50-50, with a likelihood that natural factors are a bit more than half.
He thinks the CO2-based climate models so far have been unable to explain the climate variability of the past, but that those based on natural factors and the past changes are far better.
97% consensus claim very misleading
On the claims that there is a 97% consensus among climate scientists that man is now driving the climate, the geologist – who is also co-author  of the book: The Neglected Sun – says that claim is totally misleading:
The study is often cited, but unfortunately misunderstood. If you look closely at the study, then you quickly see that it has to do with a completely different question. That Co2 drives warming, most people – even the large majority skeptics – concede CO2 warms, but it gets down to the question of how much. […] All those who think it’s just a little bit get also lumped into the 97%. I’m in the 97%. Donald Trump is a part of the 97%, as he recently said that it is possible that CO2 warms.”
Preindustrial global temperature much worse
Next Junge Freiheit (JF TV)  asks if a one-degree temperature rise would be so bad. “Is today’s temperature worse than the level of 1850?”
Lüning replies, reminding us that 1850 was the Little Ice Age and how it was “really a difficult time”. Lüning added:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




We had crop failures. We had cold. We had disease. We really should appreciate that we no longer live in the Little Ice Age because that one degree of warming was urgently needed. No one would want to go back to this cold period.”
Concerning another 1°C of warming ahead, he says that it would not be only bad news. “There would be winners and there would be losers.” He points out that especially Canada and Siberia would profit.
Emotionalized – kids should return to school, learn fundamentals
Lüning is also critical of the “Greta demonstrations” which he says “have moved the discussion from a factual one to one that is emotional”. He adds: “It’s good that the youth are getting involved, but they should return to school and learn physics, chemistry and geography and all the fundamentals of climate science.”
Strongly filtered press
Lüning also sharply criticizes the press, saying the issue has been “strongly filtered”:
Everything that is negative gets sold as headlines. And things like it’s been cooling for the last 3 years naturally get no headlines. What gets reported is very selective.”
Lüning calls the media “filtering” a fundamental problem that should not be happening in the 21st century.
Published literature far more balanced than media
When asked if the the published science is as imbalanced as the media, Lüning responds: “Not at all.” He says a new (non-alarming study) comes out almost daily, but the media refuse to report on it and instead they “prefer to report on alarmist ones, particularly from an institute located close to Berlin.”
Catastrophe very unlikely
Finally, when asked if we need to worry about the planet going under, as many projections range from manageable to catastrophic conditions ahead:
I see very many indications showing that it’s going be at the lower end of the range, towards manageable. That doesn’t mean we don’t need to do anything. But we don’t need to be preparing for the worst case scenario.”
In Lüning’s view, the path is very long and it should be taken one step at a time. He also tells JF-TV that climate science is still poorly understood and that more research needs to be done. He sees no need to hysterically put the entire economic system in question.
Viral: Nearing 50,000 views in just 2 days
On a positive note, since the JF-TV interview was released on Youtube just 2 days ago, it has been viewed already almost 50,000 times. For a German climate skeptic video, this is nothing short of phenomenal!
Perhaps in Germany it’s one thing to protest climate change, but maybe people are now getting fed up with kids not going to school and instead irrationally turning the discussion into a hysteria.
I asked Dr. Lüning what he thought about the video getting so many views. His reply by email:
People want to see a more balanced climate discussion, involving all views, not just the most extreme alarm scenarios.”
Germans are also starting to get fed up with the onslaught on their industry and jobs.
Share this...FacebookTwitter "
"James Murdoch claims he has never watched Succession, the drama series that documents the professional and personal rebellions of a billionaire media family suspiciously similar to his own. But his comments attacking the family business’s record on climate crisis coverage – which blindsided other parts of the family – suggest he may have picked up a few pointers from the HBO show. The declaration that he and his wife, Kathryn, felt “frustration with some of the News Corp and Fox coverage” of the climate crisis, particularly the “ongoing denial among the news outlets in Australia, given obvious evidence to the contrary”, focused an awkward light on the family’s businesses – but could help James differentiate himself from his father, Rupert, and brother, Lachlan.  His statement raised eyebrows, not least because until 18 months ago James was at least nominally responsible for Fox News output as boss of its parent company. He is also still a director of News Corp, which owns the family’s newspaper interests. Peter Barnes, a board member, said the board had yet to discuss the comments. But making a public stand on the issue has also helped the 47-year-old make clear to the wider world that he is heading in a different direction from the family business, as he looks to make investments in media companies with a more liberal standpoint. He has already donated to the US presidential campaign of Democratic candidate Pete Buttigieg, joined the board of Elon Musk’s Tesla, and made clear he wants to distance himself from the conservative outlets associated with his surname. Alice Enders, of media analysts Enders, suggested Murdoch had always had a genuine and sincere concern about environmental issues throughout his career: “He and his wife believe in this so fundamentally and so strongly. They obviously believe that the media has a very important role in this.” She added: “It’s very unusual to decide that the public domain is the best place to air a difference of views.” The move caps a long journey for an individual who has often seemed uneasy with his enormous privilege, without ever rejecting it. After dropping out of Harvard in the mid-90s and working as a cartoonist, he helped to run the pioneering New York hip-hop record label Rawkus Records, providing funding for the operation. According to one person who visited the offices in this period, the twentysomething had “pierced ears and eyebrow, dyed hair, a goatee, and a poster of Chairman Mao on his wall in New York”, apparently rebelling against his family while also using its funds to subsidise his interests. After exiting the music industry – having sold a majority stake in Rawkus to his father – he was brought into the family business, having a brief stint advising on internet investments during the dotcom boom, followed by a spell running Asian pay-TV operator Star. But he shocked the British media scene when he was appointed as chief executive of BSkyB, a listed FTSE 100 company, at the age of 30. It was during this time that he became increasingly concerned about climate change, inviting former US vice-president Al Gore to give a talk on the topic, and was an early convert to making businesses carbon neutral. Following a stint at the European arm of News Corp – where he was in charge as the phone-hacking scandal ravaged its newspapers and forced the closure of the News of the World – he became chief executive of 21st Century Fox until it was sold to Disney at the end of 2018. While there had been suggestions that James – until recently seen as the heir apparent – would join the combined behemoth, he instead walked away with billions of dollars. In the process, he left his brother in charge of a new, much smaller, Fox Corporation, which controls a group of television channels including Donald Trump’s favourite outlet, Fox News. Enders said that Murdoch’s approach to the environment contrasted with his father’s focus on profits at all costs. While it would be hard for the likes of Fox News to U-turn on the issue of the climate crisis, she suggested it could encourage journalists within the organisation to voice their concerns about coverage: “There’s a lot of people who are going to be standing up at News Corp meetings making these points.” Individuals who have worked with Murdoch at BSkyB insist that his commitment to environmental issues is sincere, while also pointing to the influence of his wife, Kathryn, who put her name to the joint statement. In recent days she has used Twitter to share links to stories about investment company BlackRock putting climate change at the centre of its investment strategy and a story in the Murdoch-owned New York Post suggesting conservatives have answers to climate change. She also linked to an article in Vice – an outlet in which James’s company recently bought a minority stake – blaming the bosses of large fossil fuel producers for the bushfires in Australia. The piece is withering about claims that arsonists are responsible for the natural disaster unfolding in Australia, mocking “Rupert Murdoch’s rightwing media outlets” for spreading such claims, which have “been given a huge platform in the US by Donald Trump Jr and Sean Hannity” – critiquing both the president’s son and one of Fox News’s most prominent hosts. On Wednesday it appeared that at least one part of Rupert Murdoch’s newspaper empire was listening. The Northern Territory News – one of the company’s most rambunctious tabloids – ran a front-page editorial breaking with the party line of many other Murdoch outlets: “Now is not the time to play the blame game,” its front page declared. “Now is the time to discuss climate change.”"
"
Share this...FacebookTwitterThe “Green New Deal” is a multi-trillion-dollar plan proposed by Ocasio-Cortez in February of 2019 and backed by almost one hundred members of Congress, including most of the Democratic presidential hopefuls.
Among a slew of other sacrifices, the program would force our prosperous society to replace diesel and gasoline-powered vehicles with electric vehicles and meat eating with vegetarianism. Liberty would be replaced by stifling government regulation.

The Green New Deal And Climate Change – What You Need To Know explains why the “Green New Deal” is neither green nor scientific, and needs to be rejected.
Lynne Balzer’s new book The Green New Deal And Climate Change – What You Need To Know explains how the climate science that’s driving the radical policy initiatives is flawed, fraught with outright scientific fraud and how all the proposed green initiatives are in fact anti-green because they would end up irreversibly ravaging our environment.
50 years of wrong predictions
This book details the 50-year history of climate change alarmism that began in the 1970’s with its dire warnings about global cooling caused by mankind and how that term changed first to “global warming” and then to “climate change” when the warming stopped.
None of the predictions, ten-year survival warnings or tipping points given during the past five decades has ever materialized.
Ms. Balzer, a schoolteacher from America’s heartland, presents compelling reasons why wind turbines, solar power and biofuels are not only impractical but would actually greatly damage the environment.  The book exposes the serious flaws in the science behind the entire manmade global warming scenario and the scientific impossibility that carbon dioxide, a trace gas, could be responsible for warming the planet.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Balzer explains how prominent climate scientists have been hiding data and attempting to destroy other scientists who disagreed with their claims.
The right antidote for the truant FFF school kids
The Green New Deal and Climate Change: What You Need to Know is essential reading for all voters and policy makers.
It’s also the ideal book for the FFF school-striking kids to read because it’s written by a schoolteacher in terms that are easily understood by laypersons.
Every responsible parent or grandparent needs to give this book to their children so that they will be able to view the climate issue critically, calmly, rationally and objectively.
Ms. Balzer’s book concludes that the energy “solutions” specified in the Green New Deal are neither green nor sustainable and that so-called renewable sources of energy, such as wind and solar power and biofuels, are not only impractical and economically devastating, but also very damaging to the environment.
The “Green New Deal” is one social engineering lesson we’d be far better off going without.
ABOUT THE AUTHOR
Lynne Balzer taught science on the high school and college levels over her career. A project director for Faraday Science Institute in Oklahoma, she has researched this issue for years.
Share this...FacebookTwitter "
nan
"Skateboarders aren’t too popular with civic authorities. Routinely demonised as vandals and as a danger to other members of the public, they are often portrayed as an antisocial nuisance to be excluded by law or sometimes lured away to officially sanctioned skate parks. Skaters, being predominantly teenage lads, can seem like an alien and dangerous sub-species, scowling from beneath hoodies festooned with zombies, occult runes or lewd cartoons.  Yet the real trouble with skateboarding is that it challenges the dominant use of cities, which remain controlled by civic and corporate interests whose primary purpose is to run the place as a machine for consumption. Pesky skaters are at very least an unruly nuisance getting in the way of valued customers, or, worse still, are enjoying the cityscape for free, a specific symptom of a general teenaphobia. Iain Borden, the UCL professor whose ground-breaking book first brought the place of skaters in the city to attention recently suggested skating had achieved a more positive place in many cityscapes around the world, now recognised as a creative, challenging and healthy activity.  To an extent this is true. Skateboarding builds confidence and the social capital that can combat social exclusion, alcohol and drug abuse. The sport is becoming respectable with skateboarding designed into some spaces and superb new skate parks.  However civic respectability may not be part of the attraction.  Central to skateboarding is the sense of the skaters’ local scene, a heritage and culture that may be inscrutable to non-skaters. Skate culture is powerful social glue. Skaters will tell you that they can turn up in an unfamiliar city, skateboard in hand, and immediately be welcomed to join in with the locals.   Skateboarders’ bonds can also come as a surprise to city authorities. In the autumn of 2014 the city council in Norwich proposed a ban on skateboarding throughout the city centre. Norwich’s new skate park had been built, according to the council, on “the tacit understanding” that skaters would not use the city centre. On the evening of the council debate to herald the ban the public gallery of the town hall was packed with skaters, with more beside left outside unable to fit in following a demonstration and a public petition with more than 6,000 signatures.  The council withdrew its immediate plans for a ban although the possible use of a restriction, a Public Spaces Protection Order, has been mooted. This new PSPO legislation also threatened skaters in the town of Kettering, while more typical bans are also looming in Barking and Bristol. Iain Borden’s global optimism can seem a bit too sunny down at street level. Skaters are not out to cause conflict. They would much prefer to be left to their own devices, often out of sight and out of mind. While the ominous hoodies and garish logos may look like trouble, it is worth taking time to watch skaters using their favourite spots, as against the fleeting encounters on the high street.  Skate scenes are very sociable, with their own etiquette for taking turns, working out tricks for competitions and looking out for each other. The sport fuels creativity through photography, video and graphics. Skaters treasure and look after top spots, raising money to build ramps and blocks. The spots may not be theirs to own, but they are very good at colonising a city’s forlorn and forgotten corners.  In my city of Newcastle upon Tyne the top local site, the Wasteland, was an old factory floor – skated for more 20 years. “Our summer home” the skaters would say – and they visited it up until the very day when developers finally excavated the concrete, including the parting graffiti: “Farewell our fair weather friend”.  A new wasteland has been found, again a demolished factory site – and money has been raised from DIY skate competitions to build new ramps and blocks. Revealingly the same site is also features on a recent list of Tyneside’s top eyesores.  The skater’s eye sees the city differently. In Tyneside their other favourite site is across the river in Gateshead. Called Five Bridges it is a windswept plaza where pedestrian walkways converge under a vast and gloomy flyover. It is an unlovely space, but Gateshead Council put more than £11,000 into building skate ramps and jumps – a great deal of money to invest in entertaining unruly youths.   It did so after an elderly resident had told her councillor about the skaters who hung around on the plaza. Bracing himself for the usual complaints the councillor was surprised to hear that she liked it when the skaters were there because then it felt safe to walk through. So don’t think of skaters as hooligans and vandals. They are much more like a badly dressed version of the Boy Scouts, although the skaters I got to know through my research are not so keen on that cosy description. Maybe a better idea is like the elves in the fairy tale The Elves and the Shoemaker, a mysterious and often invisible presence busily making the city a better place to live."
"It comes as quite a shock when the ground beneath your feet, your house or your field suddenly disappears leaving a hole. This hole may be tens of metres or more deep, and it will eventually lead into a cavity which may extend downwards for hundreds of metres below the ground.  We call these sinkholes, and they are a global problem. Sometimes sinkholes are a purely natural phenomenon, but they may also be associated with previous industrial activities, most commonly mining. So how do scientists like us detect a sinkhole before they appear at the surface? The geology of the rocks beneath you is a clue to the possibility of sinkholes. Limestone is prone to dissolution by groundwater which can, over time, create enormous networks of underground caves known as karst. These can collapse downwards due to gravity, leading to great surface depressions and subsidence damage and even the complete loss of houses. Poorly mapped and recorded historic mine workings in coal, salt, potash, tin and copper often leave voids in the ground. These voids may eventually come to the surface over time as the roof progressively collapses. These collapses can be gradual, or can happen suddenly, with surface depressions appearing overnight without warning. Such rapid events are often associated with changes in groundwater or during excessive rainfall events. In a region where all of the surface rocks are limestone, such as Florida or large parts of China, it is difficult to avoid the risk which these pose as there is often little prior warning.  In densely populated areas, such as the UK, a lack of available land is leading to brownfield sites being utilised, often without adequate prior knowledge or ground investigation. Compensation is available for some kinds of collapse, such as coal mining liabilities which are covered by The Coal Authority, but many of the other causes are seen by insurers as “Acts of God” and cover is expensive or difficult to obtain. We have both worked on the problem of sinkholes everywhere from gold mines in Australia to the Middle East, particularly in Kuwait and the Dead Sea, and the Bahamas. We’ve also been all over the UK and Ireland, looking at mining cavities in South Wales, Yorkshire and the Potteries, and collapses from medieval robbing of chalk for mortar beneath a major road near London.  Over the years, we have become experts in measuring the Earth’s gravity at ultra-high precision to a few parts in a billion. This is known as microgravity. We can use this to detect a cavity, or even a partially-filled area with less density than the surrounding rocks, long before any collapse reaches the surface.  Often, we are called in after the first collapse has occurred to detect all of the other potential sinkholes nearby. Developers need to start thinking about this kind of work before building commences. An additional innovation we have developed is to carry out what are known as 4-D, time-varying, repeated microgravity surveys at intervals of months to years. This enables us to detect changes in gravity, which suggest that the cavities are propagating towards the surface and potentially becoming unstable. We have been observing a problematic section of the Trent and Mersey Canal in Cheshire since 2002 and have repeated readings on more or less an annual basis. Over this period, the microgravity results suggest increasing anomalies and that the underlying salt mines which were the reason why the canals were constructed in the first place are becoming less stable. This may be due to leakage from the canals themselves or more frequent intense rainfall as the climate changes.  A recent collapse of a section of the same canal nearby at Middlewich, which caused great disruption and almost led to loss of life, has brought our work into sharp focus.  The proposed route of Phase 2 of HS2 is planned to cross a significant portion of this Cheshire Salt Field where subsidence is very common and the engineering challenges for this high-speed line will be considerable. We have contributed to a new Channel 5 series on sinkholes that has covered this issue and our work in some depth. We hope to be able to give guidance on how the area should be fixed and where this technique might be utilised to map other vulnerable areas along this network of waterways. After all, it is possible to do something about sinkholes – if they can be detected in time."
"
Share this...FacebookTwitterAccording to German online business daily Handelsblatt here, German electricity are set to get significantly more expensive in 2019 due to the power grid becoming 8 percent more expensive to use.  This will make already painfully high electricity prices even more excruciating. 

The Handelsblatt cites calculations by German think tank “Agora Energiewende”, which reports that revenues for the network operators total 24 billion euros this year.
According to Agora, “Costs previously referred to as grid costs are expected to rise by a total of six to eight percent.” For household customers the grid already amounted to 7.17 cents per kilowatt hour in 2018, which compared to 6.79 cents per kilowatt hour levied for the renewable energy feed in tariffs. This year it was 6.41 cents.
According to the Handelsblatt, “The EEG levy and grid fees thus add up to amounts of over 50 billion euros” annually. The rising grid fees are due to “massive investment in grid expansion to integrate renewable energies into the grid”. And because Germany’s Energiewende (transition to green energies) still finds itself in the early stages, the costs are projected to keep rising.
In Germany, electricity prices of around 30 cents per kilowatt hour for private consumers are among the most expensive worldwide, and are in fact “the highest in Europe” Handelsblatt reports.
What is especially warped about Germany’s electricity market is that one kilowatt-hour of electricity “is available in wholesale for less than five cents”, reports the Handelsblatt. This shows how grotesquely distorted the price structure has become since renewable energies have been mandated and nuclear power plants taken offline. .
The high end-user prices have become a huge burden on private individuals and energy intensive companies alike. German think tank Agora is demanding reforms and more transparency in the country’s murky electricity pricing structure.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Kirye
Correction: 7 of 9 stations show no warming (not 8 of 9).
April data have been coming in, and they show that warming has been missing at many sub-Arctic stations over the past decades.
Canada cooling
Looking at 9 stations in Canada, where data from the Japan Meteorology Agency (JMA) are mostly complete, we see that the month of April hasn’t warmed at all despite all the hollering about a “climate warming crisis”.

Data source: JMA
In reality, the data show for April temperatures at 7 out of 9 Canada stations have been declining over the past 30-plus years!
Sweden no April warming in 2 decades
Next we look at data from 6 stations in the Nordic country of Sweden:

Data: JMA.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In Sweden, using stations with good data availability, we see that as a whole there has been no real April warming trend over the past 2 decades.
Irish spring is cooling
The same is true for the North Atlantic island of Ireland:

Data source: JMA
 
In fact, 5 of the 7 stations examined in Ireland have seen April cooling since 1993, a time when all the global warming hype was just getting started in earnest.
No warming at Antarctic station in 50 years
Finally. we move to the other end of the globe, Antarctica, and look at a plot of the annual data from the Japanese Showa research station:

Data source: JMA.
In an alleged time of “rapid warming”, nothing of the sort is actually happening. The Showa station, founded in 1957, in fact shows there hasn’t been any warming there in 50 years!
Share this...FacebookTwitter "
"From an unmanned submersible, protected by a casing of stainless steel almost an inch thick and a window made from super strong sapphire crystal, we can observe the life that thrives at our planet’s most extreme and darkest depths. Thanks to technology and sheer material strength, we can temporarily trespass into this high pressure environment. But in stark contrast to the robust deep sea imaging equipment we rely on, the creatures our camera records look extremely fragile.  Four-and-a-half miles beneath our research vessel, which was floating on the surface of the Pacific Ocean, we captured footage of several previously undiscovered species of hadal snailfish. With delicate fins and transparent, gelatinous bodies, they are some of this environment’s most enigmatic inhabitants, fish that – at first glance – look like they should be incapable of surviving under such enormous pressures. And yet, it appears they are thriving in this strange world. In spring, a team of 40 scientists from 17 different nations conducted an expedition to the Atacama Trench, which runs along the west coast of South America. We were there to find a particular snailfish.  On a previous expedition, our principal investigator (Alan Jamieson) had photographed a snailfish with long, wing-like fins at a depth of 7,000 metres. Only one species, Notoliparis antonbruuni was known to inhabit this area at such a depth. It had been described from a single specimen, so badly damaged that we are not able to use it to identify our images of living animals. We wanted to find this elusive winged snailfish again to learn more about it and observe it in its natural habitat. These hadal snailfish tend to live at depths between 7,000 and 8,200 metres (“hadal” simply means anywhere below 6,000 metres), but their apparent rarity is perhaps misunderstood. Because of their extreme habitat (at least for humans), they are difficult to observe rather than actually “rare” as we know it. And with the right equipment and opportunity, we were confident, after ten years of study, that we knew where and how to find them.   The Atacama Trench is part of the Peru-Chile subduction zone, a large 590,000 square kilometre area where one tectonic plate is being forced under another and the ocean floor quickly plunges to more than 8,000 metres. Its volume is almost the same as the neighbouring Andes mountain range, which the tectonic subduction zone also creates, and exploring it is no easy feat. We deployed our freefalling cameras 27 times – from the relative shallows at 2,500 metres to the trench’s deepest point, Richard’s Deep, at just over 8,000 metres. This enabled us to take more than 100 hours of video and 11,000 photographs at the seabed – and the results did not disappoint. The snailfish we were looking for made an appearance – and it wasn’t alone. Two other previously unknown hadal snailfish species were present in the footage. In fact, all three species appeared in the same shot on one occasion. Out of necessity, they were given quick, stand-in names: we called them the “purple”, the “pink” and the “blue” Atacama snailfishes. The “blue” appeared to be the “winged” species Jamieson had recorded previously. Its long trailing fins and prominent snout resembled the Ethereal snailfish we had recorded on another expedition to the Mariana Trench, far away on the other side of the Pacific.  The “pink” species, meanwhile, was more robust and was closer in appearance to the Mariana snailfish (Pseudoliparis swirei) that we described in 2017 and which also inhabits the Mariana Trench. To see these two species – with such different body plans – sharing a trench again got us thinking: they must be doing something different to one another down there to both carve themselves a niche. The third species, a small purple fish, looked more like the snailfish we would expect to see on the shallower abyssal plains – at a depth of around 3,500 metres. But one of these purple snailfish, just 9cm long, followed its invertebrate prey into one of our traps. This small fragile fish is currently the only physical specimen of the new species and should eventually allow us to give it a formal scientific name. And while we much prefer our video of the living animal, only a physical specimen can be deposited in a museum and used to formally describe a new species. Once on the surface, we photographed this specimen while it was suspended in chilled seawater – its body is simply too fragile to support itself in air and we didn’t want it to suffer the same fate as the poor blobfish, which, for the record, really aren’t that sad-looking (their jelly-like bodies just collapse when exposed at the surface). Over the following months, we then put the specimen through several stages of preservation to avoid shrinking its largely gelatinous body. So that scientists (and the interested public) don’t have to fight over access to a single, fragile specimen, it was also CT scanned at the Natural History Museum, London, creating a detailed 3D digital model of it, inside and out. Such digital back ups are gaining traction in science – take the Scan All Fishes project, for example. And disasters like the recent fire at Brazil’s National Museum, which will have wiped out many unique specimens, also show why they are so important. But what have we discovered about these mysterious creatures? First, as fish approach the absolute extremes of the environmental conditions that they can cope with, they do not simply eke out an existence but thrive. It is also emerging that some trenches support not only a single specialist species but multiple species with body plans that hint at different lifestyles within the trench.  Second, the snailfish family (Liparidae) is not only the absolute winner of the deepest fish award (having been found in multiple other trenches), but species are living in trenches that at times are over 10,000km apart and entirely isolated from one another. Incredibly, snailfish exist at these extreme depths, wherever these extreme depths are, and in numbers never thought possible. And the snailfish is just one story that emerged from our expedition. Over the coming months, we will continue to process the huge amount of data we collected, the most we have ever gathered on a single voyage. Our assessment of the large mobile animals we filmed will feed into the project’s larger goal to understand the biological and chemical processes within the trench as a whole."
"
Share this...FacebookTwitterThe publisher of conservative Swiss weekly “Weltwoche” and SVP National Council member Roger Köppel commented in an interview with the Baseler Zeitung (BaZ) on children skipping school to demonstrate for climate, and the climate movement in general.

Weltwoche publisher Roger Köppel. Image: https://twitter.com/KoeppelRoger
In the interview Köppel called the climate movement a “political mass trance that that is currently rolling over us” and that children have been prompted to skip school and protest an “infantilization” of politics.
In the interview, Köppel notes that the planet has warmed “only one degree since 1860” and that this increase is nothing unusual in a historical context.
“Dangerous” state intervention


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




When the BAZ points out that his opinion is more one from the fringes, Köppel dismisses it, telling the “Evangelium of climate prophets” is being challenged by renowned scientists like Richard Lindzen “while policymaking is already convinced that this climate hysteria is to be understood as absolute truth.”
He tells the BaZ that “it is dangerous that the state is massively intervening in our economy and energy supply.”
“State collective much more dangerous”
Later in the interview Köppel calls the belief that man has the main control over climate “presumption, religious delusion and self-denial.” When asked whether or not the state indeed should take action with regards to the “climate crisis”, Köppel replied “no”  and added: “The state climate collective is much more dangerous than climate change.”
“Dangerously one-sided” debate needs to be countered
So aggressive were the questions posed by the BaZ that Köppel asked: “Stop with this CO2 demonization”, telling the BAZ: “We have a hype about the climate. I’m talking about a new solar religion, a kind of political trance. It is the duty of citizens to take countermeasures. The debate is dangerously one-sided.”
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterGermany may be soon re-introducing a dark period where political opponents are simply declared mentally ill by the state and forcibly hospitalized for “treatment”.

Image: One Flew Over the Cuckoo’s Nest, 1975
A case for psychotherapy
In a recent paper dubbed “The Denial of the Apocalypse – Dealing with the Climate Crisis from the Perspective of Existential Psychotherapy” appearing in the German Das Psychotherapeutenjournal (The Psychotherapist Journal), author Fabian Chmielewski explains which “denial processes are effective and what the psychotherapists could and should concretely do about it”.
Panic over climate change is normal
According to Chmielewski, a psychologist with a practice in Hattingen, being in panic about the rapidly approaching climate apocalypse is in fact rational behavior, while having doubts and remaining calm about it is abnormal and thus needs to be addressed.
The journal’s editorial, written by Hans Schindler, comments that although Chmielewski’s paper is contentious, it is “a suitable impetus for the necessary debate about the socio-political responsibility of our professional group and for the discussion about the possibilities – and limits – of engagement in our roles as psychotherapists and citizens.”
Leading journal in Germany
Das Psychotherapeutenjournal is not just some crackpot publication that gets little attention in Germany, rather it is indeed the organ of the Bavarian State Chamber of Psychological Psychotherapists.
The journal is co-financed by the membership fees of the other German state chambers and sent throughout Germany. It is the central organ of a corporation under public law, which represents the profession of psychotherapists by law.
Concrete psychotherapeutic ‘interventions’
The abstract of Fabian Chmielewski paper:
A broad consensus of serious research warns of the scenario of a soon inevitable spiral of man-made climate change. Nevertheless, both large sections of the population and decision-makers do not seem to be adequately interested in the impending destruction of the world as we know it. The gloomy prophecies of climate scientists are played down or even denied, the necessary climate policy steps are not taken. The article looks at these phenomena from the perspective of existential psychotherapy and tries to point out possible causes and mechanisms of this repression as well as to derive concrete psychotherapeutic ‘interventions’. It also argues for the active participation of psychotherapists in health campaigns against this widespread “existential neurosis”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Chmielewski claims that the “Fridays for Future” strikes and demonstrations are the clearest and most media-effective indication of the impending doomsday scenario, and calls for the implementation of the drastic climate policy measures demanded by science and that both doctors and psychologists warn of the health consequences of climate change and give it top priority. Here, he suggests, panic is the psychologically appropriate response.
Top human health priority
Chmielewski notes that at its annual general meeting, the Marburger Bund (association of physicians) demands: “Stopping climate change caused by humans and its consequences for human health must also be given absolute priority in health policy action”.
“Existential threat”
In the paper, Chmielewski writes that in recent times, various psychologists and psychotherapists have marked climate change as an “existential threat” (Psychologists for Future, 2019).
And when it comes to scientific dissent with regards to the upcoming climate doomsday, auditor Chmielewski writes that despite the scientific certainty of climate doomsday:
Nevertheless, important decision-makers are either completely denying man-made climate change or trivializing it and the urgency of the pressure to act. […] A large part of the population does not seem to be adequately interested in the impending destruction of the world as we know it and – as Brick and van der Linden (2018) put it – has only one lethargic “yawn” left for the apocalypse. Even more questionable seems to be the motivation of people to reject the human cause of climate change as a lie – sometimes with astonishing aggressiveness and with reference to untenable conspiracy theories.”
Suggesting compulsory hospitalization, medication
Also commenting on Chmielewski’s paper at the critical German achgut.com here, Air Tuerkis notes that generally therapists are rightly afraid to impose a certain point of view on people. But according to Chmielewski: “Exceptions are to be made, however, if an acute own or foreign endangerment is present”.
Tuerkis continues:
The concept of an ‘acute danger to oneself or others‘ is quite explosive here. It releases the therapist, for example, from the duty of confidentiality. The term normally aims at impending criminal offences that pose a danger to life and limb and above all a the danger of suicide. In Bavaria the legislator speaks of a danger to public safety to a considerable extent.”
A ‘considerable and acute danger to oneself or others’ is even sufficient as a reason for compulsory hospitalisation and compulsory medication. In this case, the patient could be admitted provisionally for up to 48 hours without a court order.”
In other words, back to the dark days days of Soviet-style punitive political psychiatry. Dissenters should be medicated into changing their views.
=======================================================
Suggested other reading: Prof Richard Parncutt suggests death penalty for influential climate deniers.
And here’s another whopper: 10:10 No Pressure.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAnother new paper published in Paleoceanography and Paleoclimatology casts further doubt on the paradigm that says CO2 has historically been a temperature driver.
Evidence from the tropical Atlantic indicates today’s regional temperatures (15.5°C) are 7.5°C colder than a peak temperatures (23°C) between 15,000 to 10,000 years ago, when CO2 hovered around 220 ppm.


Image Source: Reißig et al., 2019
“[T]he Tobago Basin core 235 subSSTMg/Ca record is highly variable and ranges from ~13-23°C, which is approximately three times as much as at Beata Ridge.. In Tobago Basin, the subSSTMg/Ca decrease by ~2°C from 30 ka BP (18°C) to the onset of HS1 (16°C). Within HS1, the subSSTMg/Ca increase continuously by 2°C, while at ~15.5 ka it rises abruptly by ~6°C up to maximum temperatures of 23°C. The abrupt subSST rise is delayed too the reconstructed SST rise at the beginning of HS1 by Bahr et al. (2018) (Fig. S7). Subsequently, subSSTMg/Ca scatters around 20°C until the beginning of the Bølling-Allerød (B/A). During the B/A and the YD the subSSTMg/Ca remains higher than ~19°C, abruptly increases up to ~22°C at mid YD, while steadily decreasing afterwards reaching modern values of ~15.5°C in the mid Holocene. Lowest subSSTMg/Ca of ~13°C are observed after ~7 ka BP. On average, the LGM subSSTMg/Ca are warmer by ~2.5°C than during the Holocene.”
“[T]he subsurface temperature variability is a robust climate signal in the tropical W Atlantic. Both records show an increase of ~5°C in subSSTMg/Ca from the LGM to the early YD and a subSSTMg/Ca decrease by ~7-8°C during the Holocene suggesting that both sediment cores are influenced by the same oceanographic changes. Notably, the mid Holocene subSSTMg/Ca in Tobago and Bonaire Basins remain cooler by ~1.5°C and ~3°C, respectively, than during the LGM.”
“At Tobago Basin and Bonaire Basin, the deglaciation is characterized by abrupt rises in subSSTMg/Ca by ~5.5°C at the end of HS1 and by ~6°C at the middle of the YD to peak values of up to ~23°C and ~22°C, respectively, accompanied by changes towards saline conditions (mean δ18Osw-ivf of ~2.25‰ and ~2‰, respectively (Fig. 3). These highly variable changes occur within less than 400 years.”
“In contrast to modern conditions Tobago Basin core 235 was influenced by a warm water mass between 30-10 ka BP, indicated by elevated subSSTMg/Ca (~2.5°C warmer than the modern conditions).”
Share this...FacebookTwitter "
"

PlayStation3 is out. I’m under-whelmed. The most odd part of this is
that people are actually leaving their jobs, schools, and family to camp out in
front of stores to be first to get a GAME. Go figure. Are they so lacking for
meaningful things in their life that this becomes the most important thing?

For those who wonder why there’s a bunch of hoopla surrounding this game,
part of the reason that it is so anticipated is that this game box has a very
powerful CPU and GPU (graphics processing unit) combo that gives tremendous
real-time 3D rendering capability for unsurpassed realism. Reportedly up to 2 Teraflops per second (2 trillion floating point operations per second) which is the kind of performance a supercomputer like a Cray used to boast ten years ago. While the PS3 isn’t quite there yet for 100% photorealism in real-time, I anticipate PS4 or PS5 to render things so realistically you won’t be able to discern it from photographic or film imagery. Here is an image
from the PS3 game ""Gran Turismo"". Is it real or rendered?



Another feature of the PS3 is the built in Blue-Ray DVD
player, which plays HDTV DVD’s now starting to be available. Hi-Definition TV is
catching on and for gaming with a big 52"" flat panel it can be an immersion
experience. I’ve seen demos at the Consumer Electronics Show (CES) in Vegas. Its
really getting hard to tell what is real anymore.
Living in alternate reality is OK for some people…its
a diversion. But I worry about the kind of folks whom get so addicted to this
that they have to camp out to get the next game. What sort of future do they
have? Gaming doesn’t put food on the table, nor help our economy, or foster good
citizenship.
My son will be asking for these games someday. When that
day comes I plan to call up Michael Jones and ask him to help me give my son a
crash course in hiking the natural world.
In the meantime, I may just buy one of these:



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7eaa1657c7',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterThe German language Epoch Times here reports how the entire editorial board at the Wall Street Journal (WSJ) commented how the “German government under Angela Merkel was running the “world’s dumbest energy policy”.
“Devastating comment”
After having wasted billions of euros on renewable energies, saddling consumers with ultra high power prices, shutting down nuclear power plants, Germany has just decided to shut down its coal power plants by the year 2038. The Journal writes on the move to exit coal:
Having wasted uncountable billions of euros on renewables and inflicted some of Europe’s highest energy prices on German households and businesses, now Berlin is promising to kill the one reliable power source Germany has left.”
The Epoch Times calls the Wall Street Journal commentary “a devastating comment on the conduct of political decision-makers in a country that is not geopolitically considered an explicit opponent of the US.”
Even exceeds Europe’s “stupid environmental policy”
The Epoch Times, along with the Wall Street Journal, also says that “although stupid environmental policy is routine throughout Europe, with reference to the fuel taxes of French President Emmanuel Macron, who had triggered the protests of the yellow vests, the looming German renunciation of coal, however, would easily exceed even this standard.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Last reliable source will be shut down
“After the leadership in Berlin had already wasted countless billions of euros on renewable energies and had imposed the highest energy prices on European households and companies, Germany was now also offering the prospect of the end for the only reliable source of energy left to the country,” The Epoch Times wrote.
The Epoch Times also questions Berlin’s move with regards to pollution, writing that if the government complains that it is unduly polluting the environment, then it must ask itself why it had been “making the wrong political decisions for more than a decade” since it decided to burn more coal in lieu of the nuclear power plants which were shut down in 2011 in the wake of the Fukushima accident.
Green folly, dangerously dependent
And as Germany pushes to complete its Nord Stream 2 monster pipeline for delivering gas from Russia, the WSJ believes that Germany is dangerously making itself energy dependent on foreign countries. Just the compensation that has to be paid to coal power plants operators for the early shutdown will cost consumers 40 billon euros, the Epoch Times writes.
The WSJ does not think Chancellor Merkel will come to her senses, but hopes her successor Annegret Kramp Karrenbauer will. The WSJ adds:
Her successor will have the opportunity to name Ms Merkel’s green folly, and Germany’s troubled electricity customers should hope that this is the case.” &amp;amp;amp;amp;lt;img class=”wort-pixel” src=”https://vg06.met.vgwort.de/na/408ebf488a494fa392946e22f769ddd4″ alt=”” width=”1″ height=”1″ /&amp;amp;amp;amp;gt;&amp;lt;span id=”mce_marker” data-mce-type=”bookmark” data-mce-fragment=”1″&amp;gt;​&amp;lt;/span&amp;gt;
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAlarmists say that sea levels are rising rapidly, and unless we act now to take over the climate using the secret man-made CO2 reduction method, soon New York and even Cologne, Germany, will end up in water. At least that’s the alarmist scenario that the Truth Media like to tell us about.
However, a number of studies and tide gauge data tell us a very different story. Hat-tip: reader Mary Brown.
The latest study titled: Holocene sea-level change and evolution of a mixed coral reef and mangrove system at Iriomote Island, southwest Japan, by Yamano et al tells us that sea levels were more than 1 meter higher 5100 to 3600 years ago than they are today they, or 0.4 meters when corrected for tectonics.

The paper’s abstract follows:
Exposed fossil microatolls and core samples from a coral reef and a mangrove forest at the Yutsun River mouth, Iriomote Island, southwest Japan, reveal the internal structure and temporal changes in the sedimentary processes of a mixed reef–mangrove system. Evidence from the core samples and fossil microatolls suggests sea level reached its present position before 5100 cal yr B.P., and a relative sea-level highstand of 1.1–1.2 m above the present sea level occurred from 5100 to 3600 cal yr B.P. This was followed by a gradual fall in relative sea level. The tectonically corrected sea-level curve indicates a stable sea level after 5100 cal yr BP., with a sea-level highstand of up to 0.4 m between 5100 and 3600 cal yr B.P.
A nearshore reef dominated by massive Porites and arborescent Acropora initially developed at 6500–3900 cal yr B.P. Reef development was potentially terminated by relative sea-level fall and sediment discharge from the Yutsun River that affected the backreef environment. An offshore coral reef reached present-day sea level by 1000 cal yr B.P., forming a wave break that enabled the foundation of mangrove forest on the fringing reef after ∼1000 cal yr B.P. The reef development was significantly delayed compared with other coral reefs in the region with similar medium-to high-energy conditions, but it provided a calm environment in the backreef area that allowed the development of mangroves. These features demonstrate the chronology and causal relationship between coral reef and mangrove development under the influence of Holocene sea-level change and river discharge.”

The peer-reviewed study is yet more cold water on the heated alarmist claims of a rapidly accelerating sea level rise.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




NOAA: tide gauges measure only 1.7 – 1.8 mm
Tide gauges are also showing a much slower sea level rise. Just recently the NOAA here announced that had adjusted its tide gauge data for 2018 and now says the average global sea level rise rate is only 1.7-1.8 mm/yr, as opposed to satellite data which show a rise of over 3 mm per year.
Naturally, the tide gauge data are more crucial because they measure sea level rise at the coast where people actually live.
According to sunshinehours.net:
That’s a measly 5.6 inches by 2100. 
The map of relative sea level trends provides an overview of variations in the rates of local sea level change at long-term tide stations (based on a minimum of 30 years of data in order to account for long-term sea level variations and reduce errors in computing sea level trends based on monthly mean sea level).
The variations in sea level trends seen here primarily reflect differences in rates and sources of vertical land motion.
Areas experiencing little-to-no change in relative sea level are illustrated in green, including stations consistent with average global sea level rise rate of 1.7-1.8 mm/yr. These are stations not experiencing significant vertical land motion.“
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAccording to the calculations of Dr. James Hansen, the radiative influence derived from the increase in CO2 during the last deglaciation was so negligible that it equated to “a third of energy required to power a honey bee in flight” (Ellis and Palmer, 2016).

Image Source: Ellis and Palmer, 2016
Between about 22,000 and 17,000 thousand years ago, Earth’s sea levels were about 120 meters lower than they are now because much of the Earth’s seawater was locked up in kilometers-thick continental ice sheets.
Then, about 14,500 years ago, nearly the entire Northern Hemisphere abruptly warmed up by about 4-5°C within a span of about 20-30 years as sea levels rose at rates between 3 and 6 meters per century (Ivanovic et al., 2017).  Northern Hemisphere sea surface temperatures warmed by 3°C in less than 90 years during this time.

Image Source: Ivanovic et al., 2017
The last ice age ends and the Holocene begins
The Earth cooled and warmed and cooled and warmed for the next 3,000 years, during which time there was a gradual overall increase in global temperature of about 5-6°C superimposed on the abrupt decadal- and centennial-scale climate undulations.
By 11,700 years ago, when Greenland warmed up by 10°C within about 50 years (Steffensen et al., 2008), the last ice age glacial period ended and the Holocene interglacial warmth we now enjoy officially commenced.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Image Source: Muschitiello et al., 2019
The honey bee-sized magnitude of CO2’s influence during the last deglaciation
There are many adherents to the Shakun et al. (2012)-endorsed position that “increasing CO2 concentrations is an explanation for much of the temperature change at the end of the most recent ice age.”
And yet one has to wonder how this conclusion could have been reached when the explosive warmings of degrees-per-decade occurred without any clearly detectable changes in CO2.
Not only that, but as Ellis and Palmer (2016) point out, Dr. James Hansen’s calculations of CO2’s radiative influence during the ~5,000 years of the Pleistocene-to-Holocene 5-6°C deglaciation suggest a 0.006 W/m² per decade CO2 forcing during this period, which is “about a third of the energy required to power a honey bee in flight.”

Image Source: Ellis and Palmer, 2016
With this vanishingly small forcing magnitude, why is it nonetheless thought that CO2 is a macro-level driver of Earth’s temperatures and a determinant of deglaciation transitions?
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn and interview with flagship German business daily Handelsblatt here, Danish economist Björn Lomborg warned of the “inefficiency in climate protection” and says Germany is a “deterrent example” in this respect.
“Gigantic costs”
He told the Handelsblatt that the once highly praised “Energiewende” was “poorly implemented” and that the costs will be “gigantic”.
Image: Twitter.
“Germany, with its promotion of renewable energies, is a particularly deterrent example in this respect. Such mismanagement adds up to gigantic additional costs,” said Lomborg.
Great doubts concerning costs
The high profile  Danish economist also told the Handelsblatt that the goal of climate neutrality makes no economic sense, saying: “That is easy to say, but extremely difficult to implement. I have great doubts as to whether all these states will be able to answer the question of what it will cost in the end.”
Lomborg also told the Handelsblatt that bans would be counterproductive, and that consumers will simply spend the money they save by not flying on other CO2-causing products. “The only sure way to reduce CO2 emissions is to make people poor.”
Technology is the key
Lomborg says that he supports a CO2 tax over the short-term to reduce CO2 emissions but that that ultimately the only way will be through improved technology, and not political measures. “We need innovations to combat climate change. That must be our first priority. […] The key then is innovation.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Citizens will rise up against bans
Lomborg says technical innovation is better than demanding people pay 16% of GDP on climate protection. “People don’t want that. They will then vote for politicians like Trump or Bolsonaro.”
Only one percent comes from wind and sun
When it comes to wind and sun as a supply of energy, Lomborg says that ultimately the huge costs will have to be correctly taken into account, and warns that they are far from being a cheap supply.
“You have to see the cost of the whole system. […] And we should not lose sight of the dimensions: According to the International Energy Agency (IEA), one percent of global energy demand is currently covered by wind and sun, while the IEA estimates that it will be about four percent by 2040,” Lomborg told the Handelsblatt.
Going it alone, shifting emissions “crazy”
And the Danish economist warns against Europe going it alone on CO2 reductions. If it does, ” then the energy-intensive industry will disappear in the direction of the USA or Asia. It is crazy to drive the energy-intensive industry out of Europe and shift emissions to other regions of the world.”
Education and development
Lomborg also told the Handelsblatt that the best way to protect developing countries from climate change is to invest in their education and health care – so that they will be able to “get themselves out of sheet metal huts.” Storms wreak far greater damage on impoverished societies than on developed ones.
“If we lead people out of poverty, they will become less vulnerable to the consequences of climate change and to many other challenges. Yes, we must fight climate change, but we must do it intelligently,” said Lomborg
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman climate science skeptic Michael Kruger of Science Skeptical here writes that the earth has become GREENER and more fertile due to more CO2 and warming.

Source: Zhu et al 
Hard to believe, but the earth is not turning into a desert and more arid due to the CO2 increase in the atmosphere, like alarmist scientists and media like us to believe it is, but rather it is becoming greener and more fertile.
This is what scientists have found through the analysis of satellite data over the last four decades.

A study published in 2016 in Nature Climate Change proves that the earth has become considerably greener over the past decades.
For their study, the researchers led by Zaichun Zhu evaluated vegetation data recorded by three satellites between 1982 and 2009. The evaluation showed that since 1982, the plant world has become more luxuriant and thus greener on a large part of terrestrial land surfaces.
Area “twice the size of the USA”
“The biggest greening trends can be seen in the southeast of North America, in the northern Amazon region, in Europe, Central Africa and Southeast Asia,” said Zhu and his colleagues.  “This greening, which we have observed, is comparable in scale to an additional green continent twice the size of the USA,” says Zhu.
To find out exactly what is responsible for this increase in plant material, the scientists fed ten global ecosystem models with data on greenhouse gas emissions, land use and the development of climate factors such as temperature and precipitation. The result: 70% of the earth’s greening is due to the fertilizing effect of rising CO2 levels and 30% to climatic effects and other effects such as climate change, nitrogen deposition and changes in land cover.
Thus, in the high latitudes and in Tibet and other highlands of the mountains, the rise in temperatures is responsible for the fact that the vegetation there became more luxuriant. “Warming promotes photosynthesis and prolongs the growing season,” the researchers explain.
Increasing precipitation in the Sahel and South Africa
In the Sahel and South Africa, on the other hand, increasing precipitation is becoming noticeable. This makes the region more fertile and greener.
The rise in CO2 emissions and climate change therefore favor the greening of the earth and plant growth. Even Syria has greened.

The earth has become greener over the past 4 decades. This is the main conclusion of an international study published in Nature Climate Change on 25 April 2016. In 40 percent of the world’s regions, a significant increase in leaf biomass was observed between 1982 and 2015, only 4 percent showed significant losses of vegetation. The vegetation corresponds to the size of a continent twice the size of the USA.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The desert regions have also become greener, such as the Sahel on the border with the Sahara, the Fertile Crescent, which stretches across Turkey, Syria, Iraq and Iran, and the former region of Carthage in North Africa, which used to be the granary of Ancient Rome.
These areas were already green and fertile in the climate optimum of the Holocene directly after the last ice age. From there, in the course of the Neolithic revolution, agriculture spread to Europe and Northern Europe.


The Sahel region has been greening for four decades:


This has been shown by a variety of studies.
Sahara shrinks by over 700,000 sq. km.
In 2018, Venter et al. recorded an eight percent increase in timber vegetation in sub-Saharan Africa over the last three decades using satellite imagery.
According to Wikipedia, the Sahara covers an area of around 9.2 million square kilometers. Eight percent of this corresponds to more than 700,000 square kilometers. This is an area almost as large as Germany and France together!

Lake Chad is growing
Even Lake Chad at the south edge of the Sahara is growing again and getting greener.

A greener Europe
Also in Germany it has not become more arid over the last four decades, as the media and climate impact researchers have recently informed us. Quite to the contrary:

Above all the north, the east, the low mountain regions and the Alps have become greener, as the satellite data show. The forest area is also growing in Germany, which is over 30% wooded. Between 1992 and 2008, the forest area in Germany “grew by an average of 176 square kilometers per year”.
Share this...FacebookTwitter "
"Although many supporters of Donald Trump seemingly believe that global warming is a hoax, almost everyone else agrees that the climate emergency should be at the top of the list of important policy issues. Identifying the problem, however, is not much use unless we also identify the appropriate tools to address it. In my own field of specialisation, central bankers have caught climate-change fever. Under the leadership of Christine Lagarde, for example, both the International Monetary Fund and now the European Central Bank have declared the planet’s climate health to be “mission critical.”  To be sure, financial institutions must fundamentally rethink some things in the light of the climate crisis. For example, a bank or insurance company calculating risks to real-estate loans would make a serious mistake if it followed the standard methodology and plugged into its formulas the probability of a flood based on data from the past 100 years. Instead, it should take a forward-looking approach, which means using estimates of the increasingly elevated probability of such disasters. But central banks and international financial institutions simply lack the necessary tools to have first-, second-, or maybe even third-order effects on greenhouse-gas (GHG) emissions. So, what policy tools would have first-order effects? In the US, the “green new deal” signals commitment to the climate cause. But I fear that the legislative proposal that its congressional supporters have introduced will do more harm than good. It includes extraneous measures such as a federal jobs guarantee. This proposal creates a factual basis for a lie that US climate-change deniers have long been telling: that global warming is a hoax promoted as an excuse to expand the size of government. That is a sure-fire way to generate votes for Trump in November. Technological innovations in areas such as solar power certainly will play a big role in mitigation. But technology is not a policy. Subsidies are a policy. There is a case to be made that governments should subsidise research in climate science and relevant technologies. There is also a strong case that policymakers should allow free trade in solar panels, turbines and other equipment, to lower the cost of generating renewable energy at no cost to domestic taxpayers. But the policy that will move us closest to achieving global environmental targets, such as those in the Paris climate agreement, at relatively modest economic costs, is to raise the price of emitting carbon dioxide and other greenhouse gases. If, for example, solar power or other renewables can in fact meet most of our energy needs at a reasonable cost, then a high carbon price will encourage that result. And if some other technology or approach is needed, the carbon price will reveal that as well. The price of carbon can be raised via one of two policies: a carbon tax or cap-and-trade, that is, a system of quantitative emission limits with tradable emission permits. In theory, the two approaches are equivalent: the quantity of carbon permits is calculated carefully, so that the resulting price when they are traded is the same as the price that would be achieved by the tax. In the real world, however, there are significant differences between regulating prices and quantities. The most important differences relate to uncertainty and political economy. For starters, it would be great if policymakers could commit to a century-long rising path for the carbon price. People could then plan far ahead. Firms would know with certainty the penalty for building long-lasting coal-fired power plants. But, even assuming a miraculous burst of multilateral cooperation, today’s leaders cannot bind their successors 50 years into the future, which rules out precise certainty about the future price or quantity of GHG emissions. What is critical, though, is quickly to establish the expectation that the price of carbon will follow a generally rising path in the future. To achieve this, governments must start increasing the price today; lofty statements from public officials and optimal calculations from climate modellers will not do the job. Predicting political economy, meanwhile, is extremely difficult. In the climate-change arena, everything is judged to be “politically impossible,” and was even before Trump. Even so, at the global level governments are probably more likely to agree to quantitative emission targets – as in the 1997 Kyoto protocol and the 2015 Paris accord – than to a global carbon tax, which would be considered too severe an invasion of sovereignty. When it comes to the national implementation of any global effort to limit CO2 emissions, however, I lean toward a carbon tax over tradable emission permits. Previous attempts to introduce emission permits, such as the EU’s emissions trading system, have revealed a tendency to mollify industry by issuing more permits than originally intended and giving too many to legacy firms. The logic of doing so is to “make them whole,” but this can result in windfall gains when the firms sell the permits. In any case, putting the price of carbon on an upward path, whether via a carbon tax or cap-and-trade, is the right tool for the job. Obviously, no single citizen can expect to solve the problem of climate change alone. But whereas some individual actions are mainly symbolic, others can have an effect that is at least proportionate to the number of citizens undertaking them. For frustrated young people, one piece of advice is clear: while going to a Greta Thunberg-inspired demonstration is fine, registering and voting is critical. If Americans aged 18-24 were to turn out and vote in the same proportions as older age groups, Trump would almost certainly not be re-elected. With Trump gone, the US could rejoin the Paris agreement and adopt effective measures to combat global warming – and other governments would lose an excuse they currently have to delay action. • Jeffrey Frankel is a professor at Harvard University’s John F Kennedy School of Government. He served as a member of president Bill Clinton’s Council of Economic Advisers © Project Syndicate  "
"
Share this...FacebookTwitterFritz Vahrenholt: Merkel’s stricter climate targets to cost Germany another 3 trillion euros.



The stricter climate protection targets recently announced by Chancellor Angela Merkel at a Protestant Church Congress would put a considerable burden on the German economy and every single household.
If the goal formulated by Merkel to increase the CO2 reduction target from 90 to 100 percent by 2050 were really achieved, then it would result in additional costs of around 3000 billion euros, according to a calculation by the former Hamburg Senator for the Environment, Fritz Vahrenholt (SPD).
7.6 trillion euros, twice Germany’s GDP
The cost of achieving climate neutrality by 2050 thus would rise from an estimated 4600 billion to 7600 billion euros. This is about twice as much as Germany’s gross domestic product in 2018, according to the magazine Tichys Einblick in its issue published Monday.

For these figures, Vahrenholt relies on a study commissioned by the Federal Government on the costs of the Energiewende (transition to green energies), which the National Academy of Sciences Leopoldina, the German Academy of Engineering Sciences (acatech) and the Union of German Academies of Sciences and Humanities presented in November 2017.

Additional 320 euros per month per household
According to the study, the researchers expect costs for reaching the 90 percent target to reach 4600 billion euros by 2050. According to the study, this corresponds to an average additional burden on households in Germany of 320 euros per month.

Reductions getting increasingly difficult, expensive



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




An increase in climate protection targets beyond the 90 percent aim, as Angela Merkel has now formulated as a target, is particularly expensive because all “favourable” possibilities for CO2 reduction and replacement have already been exhausted.
“The technical expenditure for any further reduction is much higher since all potentials for direct electricity use have been exhausted and low-cost fossil natural gas must be replaced by elaborately produced synthetic energy sources,” the researchers wrote in 2017.
3000 billion euros for last 10% reduction
On the basis of the cost assumptions made by the researchers, Vahrenholt extrapolated the costs for the last ten percent. According to this approach, the costs for the last ten percent are 3000 billion euros. By way of comparison, in their government report the researchers stated that the additional costs of increasing the climate protection target from 85 to 90 percent amounted to 1300 billion euros.
1050 euros per household – per month!

If the demand of the “Fridays for Future” demonstrators were met and climate neutrality were to be achieved by 2035, the costs would be incurred in a shorter time. According to Vahrenholt, the cost burden would rise to 1050 euros per household – per month!
You can read the detailed cost calculations in the last Monday edition of Tichy’s Einblick. You can also find the article on the Internet here.
www.tichyseinblick.de

Share this...FacebookTwitter "
"
Share this...FacebookTwitterDuring the last few hundred years, species extinctions primarily occurred due to habitat loss and predator introduction on islands.  Extinctions have not been linked to a warming climate or higher CO2 levels.  In fact, since the 1870s, species extinction rates have been plummeting.

Image Sources: Loehle & Eschenbach (2012), BBC, Wrightstone, 2019
In the past it has been widely reported that high and abruptly changing CO2 concentrations led to climate conditions that were “too hot for complex life to survive” on the planet.
More recently, though, scientists have determined that the opposite may have been true: mass extinction events occurred during periods of global cooling, expansive ice sheet growth, and marine-habitat-destroying sea level drops of more than 100 meters.
In fact, of the 5 previous mass extinctions, volcanism-induced glaciation is thought to be responsible for the 1st, 3rd, and 4th events, with the 2nd unknown and the 5th from an aseteroid impact.  None of these explanations have ties to CO2 concentrations or sudden warming.

Images Source: Jones et al., 2017, Phys.Org

Image Source: Creveling et al., 2018

Image Source: Isozaki and Servais, 2018

Image Source: Wu et al., 2014

Image Source: Kani et al., 2018
As suggeted above, scientists usually attribute the mass extinction cooling events to the same mechanism previously thought to cause sudden-onset warming: widespread volcanic eruptions.
More volcanism means more sulfate aerosols blocking out solar heat from penetrating into the ocean.  With “repeated clusters” of volcanic events gradually accumulating over time, decades to centuries of cooling can ensue.

Image Source: McGregor et al., 2015

Image Source: UPI.com
New (2019) research suggests that the global cooling extinction events could have been triggered by a solar-astronomical influence.
Again, this suggests no clear link between mass extinctions and CO2-induced or sudden-onset warming events.

Image Source: Isozaki, 2019

Image Source: Fang et al., 2018
Share this...FacebookTwitter "
"Austerity has led to an ugly food bank boom across the UK. Civil society – led by the Trussell Trust – has created a network which meets emergency needs for those unable to afford food. Those judged eligible are given food boxes containing a three-day supply of food. And now, sitting alongside food poverty in our Victorian-wannabe society, our poorest citizens are also threatened by fuel poverty. Around 17% of UK households struggle to meet their domestic energy needs, and the resulting exposure to cold, damp and mould in homes is linked to a range of respiratory and cardiovascular health problems, “excess winter deaths”, developmental problems for children and mental health concerns. These problems have prompted energy company Npower to consider spending up to £20m on an initiative to create “fuel banks”. Similar to food banks, fuel banks will provide vouchers to those in dire need to meet their energy costs for a certain period of time, either from or alongside food banks. This could work by offering emergency credit vouchers for those who pay for their gas or electricity through keypads. On the face of it, fuel banks are well-intentioned. Depending on the details (eligibility conditions, the value of the vouchers, and so on), they could allow some respite during short-term emergencies. People facing sanctions on their social security payments, for instance, or low-income households with other budgetary crises – particularly during winter.  There is also some evidence that those receiving emergency food boxes from food banks are unable to use their contents if they need to be heated or cooked, due to being unable to afford gas or electricity. Providing energy vouchers alongside food boxes therefore seems sensible, and may go some way towards alleviating the survivalist dilemma faced by some households of “heating or eating”. But let’s not get carried away. Fuel banks can be no more than a sticking plaster for people who can’t afford heating – fuel poverty requires emergency surgery, not first-aid.  Policies which subsidise energy prices tend to be inefficient and only work for a limited time. People fall into fuel poverty due to a combination of badly built homes, high energy prices and low incomes and yet fuel banks and energy subsidy schemes simply focus on the symptoms without addressing the causes. Furthermore, any praise for Npower’s benevolence must be tempered by reminding ourselves that it retains a profitable position as one of the UK’s “Big Six” energy providers. The symbolism is also concerning – what do fuel banks say about our society’s desire to properly grapple with fuel poverty? Their development is another step towards what social geographer Stefan Bouzarovski terms the “privatisation and residualisation” of fuel poverty policy (in England – the relevant powers are largely devolved), where action is no longer funded from general taxation, and overall ambition is curtailed so only the most vulnerable are targeted. Perversely, fuel banks could undermine the case for effective action on fuel poverty: “Look, we’re already doing something about it – why should we bother regulating housing or energy?” Helping the fuel poor escape their predicament requires much more than the temporary, selective relief of a few from an energy giant with a corporate social responsibility agenda. We all have the human right to an adequate standard of living which includes food and a safe, warm home – a society which respects human dignity must keep eradication as the ultimate goal of fuel poverty policy. Political ambition, effective policies on housing, energy and low incomes and a commitment to the fulfilment of human rights are what the fuel poor desperately need – not charity."
"The international community has widely acknowledged the severe threats posed by the impacts of climate change to a series of human rights, including the rights to life, health, and an adequate standard of living. But a stark gap has emerged between this acknowledgement in global climate policy – evidenced by a non-binding clause in the preamble of the Paris Agreement – and their actions to meet promised targets. How can we hold governments accountable to their human rights duties? A Dutch case recently upheld by the appeals court might hold the answer. In June 2015, The Hague District Court and a group of 886 concerned citizens, united by the environmental interest group Urgenda Foundation, made history. This, the first successful climate change case brought on human rights and civil law grounds, saw the Dutch government ordered to reduce their greenhouse gas emissions by a minimum of 25% on 1990 levels by the year 2020.  Three years on – against a backdrop of intense scrutiny and after an appeal lodged by the government – The Hague Court of Appeal upheld this decision on October 9. Indeed, it has gone significantly further in affirming the duties of care owed by the state to its people. The court considered the weight of the scientific evidence presented by the Intergovernmental Panel on Climate Change (IPCC) and the recommendations of successive UN conferences to reach an informed conclusion on the required mitigation targets commensurate with the prevention of dangerous climate change.  Significantly, the judges reached this decision by applying the European Convention on Human Rights: the right to private and family life and the right to life more broadly. As such, this case reaffirms the existence of obligations on the part of the state to take concrete measures to prevent the infringement of these rights where the authorities are aware of the existence of a real and imminent threat.  These obligations were held to extend to industrial activities which threaten the rights of people within the state’s jurisdiction. Based on an analysis of the scientific evidence, the court concluded that climate change presents a real and imminent threat to the enjoyment of citizens’ rights as spelled out in the EU convention. They ruled that a 25% emissions reduction is the minimum required to fulfil the government’s duty of care. The Urgenda appeal decision was handed down too early for the findings of the most recent IPCC report on global warming of 1.5ºC, which was published the day before the ruling, to be integrated into the judges’ reasoning. But these findings will significantly strengthen the evidential basis of future claims. The IPCC report outlines the stark increase in the risks to human health, food and water security, and livelihoods associated with 2ºC of warming, when compared to 1.5ºC. The evidence presented on human health, including the increased risk of heat-related morbidity and mortality, projected with “very high confidence”, is particularly striking. The climate is currently 1ºC warmer than pre-industrial levels, and with the planet projected to reach 1.5ºC as early as 2030 if current trends continue, the alarm on the imminence of the threat to human rights has been sounded.  No legally binding human rights provisions or remedies are provided within the international climate change regime. And so we must turn to the courts to clarify state duties. The Urgenda case sets an encouraging precedent. And there are many more examples of rights-based claims being brought against governments in Belgium, Canada, Colombia, the UK, and even against the EU institutions. This marks a sea change in the use of human rights to hold policymakers to account for their inaction on climate change.  In the face of the severity and imminence of the environmental risks we face, the approach to human rights protection adopted by the Urgenda judges is crucial. If courts focus on the imminent risks to human life and health, cases brought forward by particularly climate-vulnerable groups should be prioritised. Individuals most at risk from rising temperatures and extreme weather events – including those whose livelihoods, socio-economic status, and geographic susceptibility result in them being disproportionately affected – would have the strongest claims. Civil society organisations have a crucial role to play in facilitating access to justice for such individuals, for whom entrenched structural barriers often mean that individual access to the courts remains out of reach. To effectively accommodate climate risks of this nature the existing legal doctrine will need to be adapted, bringing together environmental principles and human rights. The role of the courts themselves is being called into question by climate litigation: the separation of powers between policymakers and the judiciary is embedded in legal systems around the globe, yet the protection of fundamental rights is intended to transcend this divide. It is the duty of the courts to act as a check on executive action and, in this case, inaction, where the enjoyment of rights is in jeopardy.  Never before has the role of the courts been so significant in influencing the path of global policy. In the face of inadequately ambitious action by policy-makers, civil society movements and the courts are the agents of change securing climate action."
nan
"As bushfires raged across Australia’s south-east, Scott Morrison responded to questions about the climate crisis by stressing the nation-state’s weakness, not its power. Australia produces just 1.3% of global emissions, he said, and it wasn’t credible to suggest that “doing something more or less” would change a worldwide phenomenon.  Yes, he did insist his government was acting. We were, he said, “doing our bit” and “carrying our weight”. Those are lines with which you might dismiss an overzealous charity panhandler: “I’ve already given, thank you!” They’re a response to a tiresome obligation. They’re not a promise of solutions. Morrison has not said that temperatures will stabilise and the climate emergency will be averted. How could he? The only international mechanism currently in place stems from the Paris accords, the agreement by which the nations of the world pledged to keep global temperature rises below 2C. But Paris is palpably failing. None of the major powers will meet their targets – and no other plan exists. In democratic theory, the modern state legitimates itself through a simple bargain: we pay its taxes and obey its law. In return, it protects us and keeps us safe. The increasing inability of states to keep that pact in respect of climate will only become more obvious, exacerbating an already widespread cynicism about the political class. Paradoxically, a growing perception of state impotence will almost certainly be accompanied by ever more aggressive demonstrations of state power. In Australia, Morrison’s supporters talk about fuel loads and arson. In part, the pivot away from climate represents a simple bait and switch. After the world recorded its second-hottest year ever, conversations about hazard reduction help drown out conversations about climate. But the new focus also shifts the debate in a direction the government likes. If environmental bureaucracy had prevented hazard reduction (it didn’t), the answer lies in slashing green tape, an easy extension of an already existing ideological commitment to deregulation. More importantly, the identification of (a largely bogus) arson outbreak transforms an ecological crisis into a law and order problem, paving the way for new legislation and fresh penalties. And that’s something the state can deliver. Think of Morrison’s almost instant response to the needles-in-the-strawberry affair. Decrying fruit saboteurs as “cowards” and “grubs”, the prime minister introduced harsh new laws that would send them to jail for as long as 15 years. More police powers and increased sentences play to the strengths of what Nietzsche called “the cold monster”, allowing the leaders who announce them to sound stern and authoritative. Accordingly, in Australia in 2019, politicians spent more time discussing how best to punish environmental protesters than they did devising legislation that might protect the climate. Peter Dutton, for instance, called for activists to be “shamed”, jailed and cut off welfare. “These people are anarchists and fringe-dwellers and they should face the full force of the law,” he said. No government minister used similar rhetoric about carbon polluters. Similarly, in Queensland, the Labor premier Annastacia Palaszczuk almost certainly can’t deliver the jobs that rural supporters of Adani think the Carmichael coalmine will bring them (the employment promises keep shifting) and nor can she save the Great Barrier Reef (since that would entail stopping climate change). She can, however, rush through Joh-era style laws to jail Extinction Rebellion members. The state, by definition, possesses a monopoly on coercion. As a result, politicians incapable of any real policy agenda know they still unleash force. As Morrison himself says, the core responsibility of a prime minister is to “keep Australians safe”. If the 2019-2020 fire season really does foreshadow the new normal on a warming planet, governments face a looming crisis of legitimacy, precisely because there’s nothing safe about a country in flames. We’re likely, then, to see politicians asserting authority in an all too traditional way, with an increasing resort to the rhetoric of national security. As I have argued previously, it’s not difficult to imagine what Morrison’s slogans of “resilience and adaption” might mean in the context of, say, climate refugees. For decades, we’ve seen asylum seekers used as targets whenever a weak leader wants to look tough. Global heating will make future governments seem extraordinarily weak – even as a huge new wave of refugees arrives. In the midst of a genuine emergency, with the army already on the streets, the likely conjunction of climate and border politics does not bear thinking about. • Jeff Sparrow is a Guardian Australia columnist"
"The global food system has a lot to answer for. It is a major driver of climate change, thanks to everything from deforestation to cows burping. Food production also transforms biodiverse landscapes into fields inhabited by a single crop or animal. It depletes valuable freshwater resources, and even pollutes ecosystems when fertilisers and manure washed into streams and rivers. The planet can only take so much of this stress. Staying within its environmental limits will require a global shift towards healthy and more plant-based diets, halving food loss and waste, and improving farming practices and technologies. That’s what a team of international researchers and I found in a new study published in the journal Nature. The global food system has fundamentally altered our planet and the resource base humanity depends on. Food production is responsible for about a quarter of all greenhouse gas emissions and therefore is a major driver of climate change. Agriculture occupies more than a third of the Earth’s land surface and has led to reductions in forest cover and loss of biodiversity. Farming also uses more than two thirds of all freshwater resources, and the over-application of fertilisers in some regions has led to “dead zones” in oceans. Without concerted action, we estimated that the environmental pressure of the food system could increase by 50-90% by 2050 as a result of population growth and the continued Westernisation of diets. At that point, those environmental pressures would exceed key planetary boundaries that define a safe operating space for humanity. Crossing planetary boundaries would increase the risk of destabilising essential ecosystems. Among others, it could lead to dangerous levels of climate change with higher occurrences of extreme weather events; affect the regulatory function of forest ecosystems and biodiversity; result in disruptions of water flows with impacts on the global hydrological cycle; and pollute water bodies such that it would lead to more oxygen-depleted dead zones in oceans. Fortunately, such a situation can be avoided. We combined detailed environmental accounts with a model of the global food system that tracks the production and consumption of food across the world. With this model, we analysed several options that could keep the food system within environmental limits. Here is what we found: Climate change cannot be sufficiently mitigated without people eating a lot less meat. Adopting healthy and more plant-based diets globally could reduce the greenhouse gas emissions of the food system by more than half, and also reduce other environmental impacts, such as those from fertiliser application and the use of cropland and freshwater, by a tenth to a quarter. In addition to dietary changes, improving management practices and technologies in agriculture is required to limit pressures on agricultural land, freshwater extraction, and fertiliser use. Increasing agricultural yields from existing cropland, balancing application and recycling of fertilisers, and improving water management, could, along with other measures, reduce those impacts by around half. Finally, halving food loss and waste could, if achieved globally, reduce environmental impact of food production by up to a sixth. Many of the solutions we analysed are already being implemented in some parts of the world, but it will need strong global coordination and rapid uptake to make their effects felt. Take the necessary improvements to farming technologies and management practices, for instance. That would require a lot more investment in research and public infrastructure, it would need the right incentive schemes for farmers to ensure they don’t miss out financially, and things like fertiliser use and water quality would need much stronger regulation. Tackling food loss and waste will require measures across the entire food chain, from storage and transport, through food packaging and labelling, to changes in legislation and business behaviour that promote zero-waste supply chains. When it comes to diets, comprehensive policy and business approaches are essential to make serious changes possible and attractive for a large number of people. Important aspects include school and workplace programmes, economic incentives and labelling, and aligning national dietary guidelines with the current scientific evidence on healthy eating and the environmental impacts of our diet. As an individual, you can help by adopting a healthier diet with less meat. You can call on business to reduce waste across their supply chain and offer more plant-based food options. And you can hold politicians to account by demanding strong regulation of environmental resource use and pollution."
nan
"Sir David Attenborough has said it is “palpable nonsense” to suggest that Australia’s bushfire crisis has nothing to do with climate changeas he warned “the moment of crisis” has arrived. The 93-year-old British naturalist made the direct link between the ongoing bushfires and climate change during an interview with the BBC published on Thursday.  “As I speak, south-east Australia is on fire. Why? Because the temperatures of the Earth are increasing,” he said. “We have been putting things off year after year. We’ve been raising targets, saying ‘oh well, if we do it in the next 20 years …’ the moment of crisis has come.” More than 10.7m hectares of land have burnt so far in the Australian bushfires, including 80% of the Blue Mountains, and 50% of the Gondwana world heritage rainforests. While Australian prime minister, Scott Morrison, has talked down suggestions there are climate change deniers in his party, several Australian government MPs have continued to downplay the role of global heating on the bushfire crisis, and Morrison has attempted to pivot the debate from acting on climate change to resilience and adaptation. Attenborough said the world can no longer prevaricate and delay decisions, and the change needed to be made not by appealing to optimism but by highlighting it is a life or death decision. “This is not just having nice little debates and arguments and then coming away with a compromise. This is an urgent problem that has to be solved,” Attenborough said. “And what is more is that we know how to do it, that’s the paradoxical thing, that we are refusing to take steps that we know have to be taken. “And every year that passes makes those steps more and more difficult to achieve.” He said China needed to step forward and announce it is curbing carbon output because of climate change, and everyone else would “fall into line”. “That would be the big change that one could hope would happen.” He said the public mood had already shifted. “People can see the problem, particularly young people can see the problem, and that must force governments to take action.”"
nan
nan
"Some of the biggest companies in the world are funding climate misinformation by advertising on YouTube, according to a study from activist group Avaaz. The group found that more than 100 brands had adverts running on YouTube videos on the site that were actively promoting climate misinformation. The brands, including Samsung, L’Oreal and Decathlon, were unaware that their adverts were being played before and during the videos.  “This is not about free speech, this is about the free advertising YouTube is giving to factually inaccurate videos that risk confusing people about one of the biggest crises of our time,” said Julie Deruy, a senior campaigner at the group. “YouTube should not feature, suggest, promote, advertise or lead users to misinformation.” For the report, Avaaz examined videos pushed to users when they search “global warming”, “climate change”, or “climate manipulation” on the site, focusing particularly on those giving high prominence by YouTube’s recommendation algorithms. It found that 16 of the top 100 videos on the first term contained misinformation, as did eight of the videos found under “climate change” and 21 of those under “climate manipulation”. “YouTube has previously taken welcome steps to protect its users from anti-vaccine and conspiracy theories,” Avaaz argued, “but has not acted with equal force against broader misinformation and disinformation content, including climate misinformation.” The group called on YouTube to implement new policies to prevent the further spread of climate misinformation on its platform. It said the site should: Include climate misinformation in its “borderline content” policy, which limits the algorithmic distribution of videos that do not reach the bar required to fully remove them from the site. Demonetise misinformation, “ensuring such content does not include advertising and is not financially incentivised. YouTube should start immediately with the option for advertisers to exclude their ads from videos with climate misinformation.” Work with independent fact-checkers to inform users who have seen or interacted with verifiably false or misleading information. Provide transparency to researchers by releasing data showing how many views are driven to misinformation by its own recommendation algorithms. In a statement, YouTube said Avaaz’s report had its own transparency problems. “We can’t speak to Avaaz’s methodology or results, and our recommendations systems are not designed to filter or demote videos or channels based on specific perspectives. YouTube has strict ad policies that govern where ads are allowed to appear and we give advertisers tools to opt out of content that doesn’t align with their brand. We’ve also significantly invested in reducing recommendations of borderline content and harmful misinformation, and raising up authoritative voices on YouTube. “In 2019 alone, the consumption on authoritative news publishers’ channels grew by 60%. As our systems appear to have done in the majority of cases in this report, we prioritise authoritative voices for millions of news and information queries, and surface information panels on topics prone to misinformation – including climate change – to provide users with context alongside their content. We continue to expand these efforts to more topics and countries.” A L’Oréal spokeswoman said: “The information promoted by these videos is in direct contradiction with L’Oréal’s commitments and the work we have been carrying out for many years to protect the environment. We are collaborating with YouTube teams asking them to use all the technological means at their disposal to better inform the platform’s users about the nature of these videos and to limit their impact.”"
nan
"Scallop fishing attracts controversy. Dredgers scrape scallops out of the hollows they make for themselves in the seabed, and in the process disturb seaweed and other sea life that lives fixed to the bed. Even among senior marine scientists there is disagreement as to whether it is possible to do this sustainably. Most agree that certain vulnerable habitats such as seagrass and maerl beds should never be dredged, but that in some other areas dredging may be no worse than the disturbance from storms or currents. Scallops are also valuable – only mackerel and prawn fisheries are worth more to the UK. All this has led to battles between British and French ships over access to fishing grounds in the Bay of Seine off the coast of Normandy in northern France. The most recent conflict in the so-called “scallop wars” saw 40 small French boats try to chase off five larger British boats. Stones were thrown and boats collided, but there were no injuries or sinkings. Though what they were doing was totally legal in this case, the nomadic fleet of large British vessels doesn’t always help itself. Several high profile cases have found against them for fishing where they should not in UK and French waters, not keeping accurate records, landing bycatch species they don’t have quota for, or as in the case of Honeybourne III, which took a starring role in the recent altercation, landing undersize scallops.  The UK’s scallop fishers have also not made many friends among lobster/crab fishermen. A minority of scallop boats spark annual protests by Yorkshire fishermen as they tow away any lobster and crab pots that lie in their path.  The scallop wars have two underlying, root causes. The first is that there are two groups of fishermen, targeting the same species in the same area but under different rules. A local regulation prohibits French boats from targeting scallops in the Bay of Seine until October 1 each year. But this French regulation does not apply to British boats.  In previous years the French fishermen have persuaded the larger UK boats to stay away until October by transferring extra European fishing allocation to them, so they can fish in other areas. This year, with Brexit looming, and after increased numbers of British boats fished the area in 2017, this “gentleman’s agreement” broke down. Although it is legal for boats from Britain, Ireland and other countries to fish in the area before October, it must be incredibly frustrating for the French fishermen. Over a decade ago France instigated highly progressive management measures for its scallop fishery, including limits on licences, reductions in boat and gear size, time restrictions, and increases in dredge mesh size. It was tough on French fishermen at the time, but as one French fisheries scientist once told us: “No pain, no gain.”  Now scallop stocks in the Bay of Seine are at near record levels, but vessels from other countries are catching them before the French are even allowed to go fishing themselves. In comparison, although there are now efforts to improve the sustainability of the scallop fishery around the UK, catch rates are declining, while the the number of scallop fishing boats has increased from 135 a decade ago to more than 200. The second root cause is that nomadic boats from the UK and other countries have no links to the local community that depends upon the scallops in the Bay of Seine. Small boats, such as the French use, have a limited range and depend entirely on what they can catch in the area. In such situations where there are extensive kin ties and shared communities, fishermen are much more likely to develop informal agreements with regard to who fishes where. Of course, such tensions work both ways. For many years the French trawled for sea bass in the English channel, disadvantaging UK fishers who were banned due to concerns they would catch too many dolphins by mistake. The French fishery was only stopped by the EU when sea bass stocks collapsed. Neither side has come out of this well. What the UK boats did by fishing in the Bay of Seine may have been legal, and the French response overly aggressive, but they would have known they were asking for trouble and their own retaliation was over the top – and possibly illegal. As Barry Deas, chair of the national representative body of fishermen pointed out, this is just a skirmish before the battle of Brexit. Ships from elsewhere in the EU take more fish from UK waters than the British fleet does and many in the fishing community would like to see reform that addresses what they see as an injustice. The problem is that most fish are not scallops, which rarely move, but instead undergo annual migrations across international boundaries. Therefore preventing fishing in one area may not necessarily reduce access to stocks.  In the absence of robust international agreements that manage stocks rather than areas, and respect the fact that fish do not care about human boundaries, the North Sea could become the new Mediterranean, where poor regulation and disagreement between EU and non-EU states has resulted in a steady decline in stocks. On top of the regular movements of fish, the North Sea fisheries will be challenged by climate change induced movement of fish out of UK waters (something that is already evident with mackerel). In the face of Brexit we should be aiming to improve international relations, not damage them. Otherwise fish stocks and the wider marine environment are likely to suffer most – at which point everyone loses."
"
Share this...FacebookTwitterOver the course of a 12 hour period on a cloudless day, 500 Wm-2 of solar energy pummels past the ocean surface to depths of 20 or more meters, warming up the first 2 meters of the ocean by 2.0 K.

Image Source: Fairall et al., 1996
In contrast, the infrared radiation absorbed and re-emitted in all directions by CO2 molecules cannot penetrate past the ocean’s 0.1 to 1 mm “thick” skin layer.

Image Source: Skeptical Science blog
Clouds and Ocean Domination
How much solar radiation is absorbed by the Earth system’s heat reservoir – the oceans, where 93% of the globe’s heat energy resides – is significantly determined by changes in decadal-scale cloud cover.
Direct short wave and long wave (i.e., “greenhouse effect”) forcing from the reduction or increase in cloud cover dominates as the modulator of Earth’s energy budget changes.
CO2’s influence is minimal and easily overwhelmed in these processes, as “the greenhouse effect of clouds may be larger than that resulting from a hundredfold increase in the CO2 concentration of the atmosphere.”


Image Source: Ramanathan et al., 1989, Wielicki et al., 2002
Satellite observations of decadal-scale cloud cover changes indicate that between the 1980s and 2000s about 3 to 6-7 Wm-2 of direct short wave forcing was additionally absorbed by the Earth’s oceans.  This may account for the warming trend in recent decades.

Image Source(s): Ogurtsov et al., 2012 , Pinker et al., 2005, Goode and Palle, 2007
CO2’s Honey Bee-Sized Contribution
According to a widely cited analysis of the CO2 radiative contribution to the Earth’s greenhouse effect, there was a 0.2 Wm-2 per decade forcing associated with a CO2 change of 22 ppm during 2000 to 2010.
The seasonal mean range for DWLWR (downwelling long wave radiation) reaches amplitudes of ~30 Wm-2 over the course of months.  This range is more than a 100 times larger than the entire DWLWR CO2 forcing contribution over 11 years.

Image Source: Feldman et al., 2015, Okulaer, 2015
CO2 concentration changes are registered in parts per million (ppm, 0.000001).  This means that for the 100 ppm rise in CO2 from the last glacial period to the warm interglacial we enjoy now (from ~180 ppm to ~280 ppm), the gaseous representation of CO2 in the atmosphere rose from <2 parts in 10,000 parts to <3 parts in 10,000 parts.
Since it took about 5,000 years for CO2 to rise by 1 part in 10,000 parts, this is the forcing equivalent of 0.006 Wm-2 per decade using the calculations of Dr. James Hansen (and the IPCC).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




A CO2 forcing of 0.006 Wm-2 per decade is “about a third of the energy required to power a honey bee in flight.”
Image Source: Hansen et al., 2012 and  Ellis and Palmer, 2016
Uncertainty, Errors 10-100 Times Larger Than CO2 Forcing
According to the Intergovernmental Panel on Climate Change (IPCC), uncertainty in the factors influencing the ocean heat flux reach amplitudes of 20 Wm-2.  This uncertainty is more than 10 times larger than the entire forcing contribution from CO2 since 1900 (<2 Wm-2).
“Unfortunately, the total surface heat and water fluxes … are not well observed. The uncertainty in the observational estimate is large – of the order of tens of watts per square metre for the heat flux, even in the zonal mean.” – IPCC AR4 (2007)

Image Source: IPCC AR5 (2013)
The IPCC also identifies error ranges for long wave (LW) forcing that range between 5-15 Wm-2.

Image Source: IPCC AR4 (2007)
The Earth’s energy budget is assumed to be imbalanced, as more energy is said to be absorbed by the system than leaving it.
During 2000-2010, Earth’s energy imbalance was believed to be 0.6 Wm-2. The uncertainty range for this value was ±17 Wm-2, meaning the energy imbalance could have ranged anywhere from -16.4 Wm-2 to +17.6 Wm-2, which is more than ten times larger than “the changes to the net surface fluxes associated with increasing greenhouse gases in the atmosphere.”

Image Source: Stephens et al., 2012
The ARGO data measuring ocean heat content launched in the early 2000s, but the coverage still leaves much of the non-uniformly warming and cooling regions of the ocean unsampled.  Sampling errors can range anywhere from 10 to 200 Wm-2.

Image Source: Hadfield et al., 2007
Renowned Climate Scientists Ask A Never-Answered Question
In late 2013, five American Physical Sociey (APS) climate scientists published a framing document designed to re-examine the physical basis for the IPCC’s “consensus” position(s) on climate change.
Using the IPCC’s acknowledgement of ocean data uncertainty and low confidence that an anthropogenic signal can be detected amid the noise of natural variability, a cogent question was posed pertaining to the claims of certainty that humans exert fundamental control over the the climate of the Earth system.
The question has never been answered.

Image Source: American Physical Society
Share this...FacebookTwitter "
"Catching a glimpse of the northern lights is apparently the top experience for Britons compiling a “bucket list” of must-do experiences before they die. It’s not surprising, the aurora borealis is a breathtakingly beautiful natural phenomenon, but one that is seldom seen from the British Isles. Nevertheless, on the morning of March 18, the British press were reporting a brilliant display of the northern lights the previous night.  Social media was overflowing with photographic evidence of a display stretching from Scotland to Somerset.  But what had brought the lights to the UK that night? The story begins in the early hours of March 15, when a magnetically active region of the Sun’s surface crackled and erupted, hurling billions of tonnes of the solar atmosphere out into the solar system.  Unless you have a keen interest in our local star, you were probably unaware this had happened.  It didn’t make the news.  But for scientists studying how solar activity affects the space environment surrounding our planet, it was the start of an interesting couple of days. Within hours, the trajectory of this magnetised outpouring of subatomic particles had been modelled.  The cloud, known as a coronal mass ejection (CME), was heading in our direction at about one million miles an hour.  It looked like it would deliver a glancing blow to planet Earth some time on March 17, but what would happen if it did?  Space weather forecasters the world over set to work. A likely outcome in this scenario is that the arrival of the CME will trigger a geomagnetic storm.  This occurs when the magnetic field within the CME couples with the Earth’s magnetic field, allowing energy and matter to transfer from the CME to the near-Earth space environment.   The most obvious symptom of a geomagnetic storm is more intense aurora borealis due to the increased inflow of electrically-charged particles to the Earth’s upper atmosphere.  But less attractive side-effects include disruption to hi-tech navigation and communications systems, and the risk of damage to satellites and power grids.  Space weather forecasting, while still in its infancy, is a serious business. By March 16, forecasters at the US Space Weather Prediction Center were predicting the CME would trigger a geomagnetic storm in the days that followed.  Then, at around 4am UK time on March 17, it engulfed NASA’s Advanced Composition Explorer (ACE) satellite, the space weather monitor that constantly samples the solar wind upstream of the Earth.   For the first time since it left the Sun, it was possible to measure the orientation of the magnetic field inside the CME.  The orientation of this field, the remnants of the Sun’s magnetic field torn away when the CME was launched, is crucial. It controls the coupling between the CME and the Earth’s own magnetic field.  Although it can take almost any orientation, if the field inside the CME points southwards, it will oppose the Earth’s magnetic field (which, as any compass shows, points north) and these opposite polarity fields interact strongly.  If the CME’s field points northward, the interaction is much weaker. The satellite revealed that the field inside the incoming CME was strong, and as it streamed past the Earth over the course of the morning, it fluctuated between northward and southward orientations, triggering mild geomagnetic disturbances.  Then around noon, the CME’s magnetic field turned southward and stayed southward for the next 12 hours. The strong and sustained coupling poured energy into the magnetosphere, the region of space normally dominated by the Earth’s magnetic field, triggering the strongest and longest geomagnetic storm of the Sun’s current 11-year cycle of activity. Excited aurora-spotters all over the globe weren’t disappointed.  As night fell, the northern lights, and their southern counterpart the aurora australis, lit the skies with dancing displays of green and red light.  Normally concentrated in ring-like ovals that circle our planet’s magnetic poles, the auroral zones expanded equatorward, pushing auroral displays as far south as Kansas and Virginia in the northern hemisphere, and as far north as New Zealand and Australia.  In the UK, those hoping to see the aurora were battling a blanket of mist and fog that settled across much of the country, but many of those with clear a view of the sky reported sightings of the northern lights. Although the biggest geomagnetic storm of the current solar cycle, this St. Patrick’s Day storm was not a once-in-a-lifetime space weather event.  Mid-latitude aurora sightings are rare, but typically occur a handful of times in each 11-year solar cycle.  The current solar maximum is not as intense as the previous peak in 2003 and the frequency and severity of geomagnetic storms has been lower.  Over the coming days, high-tech infrastructure operators will look at how their systems responded to the storm, but the early indications are that there were no significant problems. So if this wasn’t a unique event, why did it make the headlines? One reason why public interest in the northern lights has increased since the previous solar cycle is the advent of social media and mobile technology.  Now anyone can sign up to space weather alerts and have warnings of solar flares, CME eruptions or geomagnetic activity delivered to the phone in near real-time.  Hopeful aurora spotters can find out what others in their country or region are seeing and interact with them easily, most commonly by using the #aurora hashtag. Lancaster University’s AuroraWatchUK service is Britain’s most popular aurora alerting system and uses real-time magnetic field measurements from across the UK to sense the geomagnetic disturbances associated with the northern lights. Social media channels now mean our alerts can reach huge numbers, improving the odds of people seeing the aurora from their back garden.  During the St. Patrick’s Day storm, our social media posts reached more than 200,000 people, with thousands of shares and retweets. For UK-based aurora-spotters, geographic location, weather and light pollution are not ideal.  But if you want to tip the odds slightly in your favour, as well as looking up, you should really think about looking at your phone."
nan
"
Share this...FacebookTwitterWorld leading sea level expert Prof. em. Nils Axel Mörner presents some stark examples that show how the IPCC and climate activists are wildly exaggerating their claims of rapid sea level rise.
================================================
12th IKEK: Nils Axel Mörner – the Kattegat and others among test areas for sea level
Prof. em. Nils Axel Mörner auf der 12. IKEK München, Bild EIKE
By EIKE
Mörner studied the Kattegat Sea between Denmark and Sweden. In this region sea level has not increased as announced by climate alarmists, but instead decreased. The actual oceanic increase in the past 125 years can be estimated as modest at 0.9 mm per year.   
Stockholm’s tide record is the second longest in Europe; the mean long-term change in sea level is a decline of 3.8 mm per year. The country itself is rising 4.9 mm per year due to the post-glacial rise of the continental landmass. The difference of 1.1 mm per year is the true oceanic component.
Nova Scotia: sea level 700mm higher back in 16th century
In addition to European locations, Mörner also looks at the Indian Ocean and the Pacific. He has just returned from the Ouvéa area off Nova Scotia. In the 17th century, the sea level was 70 cm higher, as confirmed by immutable geomorphological facts. 
At that time, the “Little Ice Age” with larger glaciers prevailed in the Alps (as Professor Patzelt showed). How could more liquid water be present at the equatorial area at the same time?
 

Video of the lecture (in English!)  by Prof. em. Axel Mörner at the 12th IKEK in Munich. 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The phenomenon thus proves that the IPCC is wrong. 
In warm times, the sea level does not rise globally. The reason for this is the so-called rotational eustasy of the planet: In the north, the volume of water increases a bit, at the equator it remains about the same. 
Sea level at Fiji Islands, Maldives, Goa has dropped since 1950s
Also other islands or coastal regions show a sea level change, such as the island Ouvéa, also the Fiji Islands, the Maldives and Goa in India. Here, too, the oceans sank around 1700, rose around 1800 and sank again after 1950.  
Solar driven
Global sea level changes followed the moon’s tidal super cycles, which in turn stem from the large solar cycles. The sun also affects the Gulf Stream in the North Atlantic, which brings warmth to Western and Northern Europe. At maximum solar activity, the Gulf Stream flows northeast and sea level rises. During a solar minimum, the Gulf Stream flows from east to southeast and sea level drops to the north.
“CO2 no factor”
Mörner emphasized that the solar cycles and gravity of our neighboring planets, the solar wind and the moon, determined our climate and our environment. The carbon dioxide greenhouse effect has no place. 
IPCC climate science in part “anti-scientific nonsense”
With his presentation in Munich, the speaker wanted to send a message to the world climate conference COP24 in Katowice / Poland, which took place shortly after the EIKE conference. That message is: “Some of their statements fall into the area of ​​anti-scientific nonsense. The polar ice does not melt so quickly and the sea level does not rise in a short time. ” 
Mörner recommends observing physical laws and the evidence from nature for the procedure of determining sea level.
Share this...FacebookTwitter "
"Harvard law students have disrupted a recruiting event for Paul Weiss, the law firm representing ExxonMobil in climate lawsuits, in an escalation the protesters hope will open a new front in climate activism in the legal world.  The oil giant is facing a series of lawsuits in the US related to claims that it knew petroleum products were heating the planet and sought to persuade the public otherwise. The students say Paul Weiss has cultivated a reputation as a liberal corporate law firm, despite representing oil companies, tobacco and big banks. Ted Wells Jr, a partner at the New York firm, is a prominent Democratic donor. During a reception at an upscale restaurant in Cambridge, Massachusetts, a group of students unfurled a banner reading “#DropExxon” and began chanting over a speaker from the firm that they wouldn’t work for Paul Weiss as long as the firm worked for Exxon. They live-streamed the event. The protest follows another demonstration at the Harvard-Yale football game in November, when students from both universities swarmed the field at half-time. The protesters say they want to bring accountability to the legal world, where attorneys traditionally have been expected to accept that all entities deserve representation regardless of their deeds. The action is especially jarring because the field’s culture dictates professionalism. Organizer Aaron Regunberg said the protest action will be a shock to the Harvard Law School community, where students are taught that their job requires them to remain neutral about the actions of clients. “But if you don’t start these conversations – if you don’t start forcing people to reckon with the reality of what the work that Paul Weiss is doing for Exxon, for example, means – then there’s never going to be any change,” Regunberg said. “And it’s clear from the science that we have just a few years left to address climate change.” Asked how he would explain his participation to future employers, Regunberg said: “I went to law school because I believe in the power of our legal system to be a force for good, and using aggressive tactics to enable corporate polluters to literally continue lighting our future on fire to me is the antithesis of what lawyers should do.” Paul Weiss successfully defended Exxon against a lawsuit from New York’s attorney general alleging the company misled investors about climate regulation risks. The publication Law.com named the firm’s lawyers “litigators of the week”, for delivering a “cool win” for Exxon in the $1.6bn suit. The firm has also initiated suits against the state government officials bringing cases against Exxon, accusing the top lawyers in Massachusetts and New York of an alleged illegal conspiracy. One judge dismissed those allegations, writing that the relief Exxon sought was an “extraordinary” attempt to “to stop state officials from conducting duly-authorized investigations into potential fraud”, based on “extremely thin allegations and speculative inferences” that are altogether “implausible”. The Guardian has contacted Paul Weiss for comment."
"
Share this...FacebookTwitterRecord cold temperatures, transportation disrupted, fire extinguishers freeze as “coldest air mass ever” sweeps over Japan’s northern island of Hokkaido.
By Kirye

 
 
 
 
As the Asahi Shimbun here reports, Japan’s northernmost main island of Hokkaido has been gripped by a deep freeze with the temperature plunging to -31.8°C in Rikubetsu on February 9.

Chart: Japan Meteorology Agency (JMA)
Three other observation stations in Hokkaido “also reported temperatures below minus 30 degrees,” the Japanese online daily reports.
10 stations set new record lows
In total yesterday, February 9, in Hokkaido Prefecture, 10 stations saw their temperatures reach record lows:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Image from the Japan Meteorology Agency (JMA)
Although some media outlets are claiming the record cold is due to a phenomenon that is often implied as being new and caused by global warming, it is in reality what people simply used to call a plain old ‘cold wave’.
The NOAA reports here that the “polar vortex” is in fact nothing new at all, and that the term had been used already 166 years ago, back in 1853!
Global warming causing “coldest ever” air masses?
The Japan Times here reported that it was “the coldest air mass ever recorded” to hit Hokkaido”.
How can global warming be causing record cold air masses? Air masses are supposed to be getting warmer, and not colder. Climate scientists are desperately scrambling to explain the inconvenient cold events.
Referring to the Japan Meteorology Agency (JMA), The Japan Times have written: “The agency said a cold air mass with a temperature of minus 24.4, the lowest seen since it began compiling such data in 1957, was hovering about 1,500 meters above Sapporo, which saw the mercury drop to minus 12.5 in the morning.”
Frozen fire extinguishers at nuclear power plant!
The cold is so severe that it even froze a fire extinguisher system at a nuclear power plant in Hokkaido, “due to a record cold weather,” reported the NHK World here.
Meanwhile further south in Tokyo, snow fell yesterday. The forecast is calling for cold conditions to grip Japan in the days ahead.
============================================
Pierre contributed to this article.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn the first 5½ months of 2019, over 200 scientific papers have been published that cast doubt on the position that anthropogenic CO2 emissions function as the climate’s fundamental control knob…or that otherwise serve to question the efficacy of climate models or the related “consensus” positions commonly endorsed by policymakers and ²²²²mainstream media sources.
These 200+ new papers affirm the position that there are significant limitations and uncertainties inherent in our understanding of climate and climate changes, emphasizing that climate science is not settled.
More specifically, the papers in this compilation support these four main skeptical positions — categorized here as N(1) – N(4) — which question climate alarm.
N(1) Natural mechanisms play well more than a negligible role (as claimed by the IPCC) in the net changes in the climate system, which includes temperature variations, precipitation patterns, weather events, etc., and the influence of increased CO2 concentrations on climatic changes are less pronounced than currently imagined.
N(2) The warming/sea levels/glacier and sea ice retreat/hurricane and drought intensities…experienced during the modern era are neither unprecedented or remarkable, nor do they fall outside the range of natural variability.
N(3) The computer climate models are neither reliable or consistently accurate, and projections of future climate states are little more than speculation as the uncertainty and error ranges are enormous in a non-linear climate system.
N(4) Current emissions-mitigation policies, especially related to the advocacy for renewables, are often ineffective and even harmful to the environment, whereas elevated CO2 and a warmer climate provide unheralded benefits to the biosphere (i.e., a greener planet and enhanced crop yields).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In sharp contrast to the above, the corresponding “consensus” positions that these papers do not support are:
A(1) Close to or over 100% (110%) of the warming since 1950 has been caused by increases in anthropogenic CO2 emissions, leaving natural attribution at something close to 0%.
RealClimate.org: “The best estimate of the warming due to anthropogenic forcings (ANT) is the orange bar (noting the 1𝛔 uncertainties). Reading off the graph, it is 0.7±0.2ºC (5-95%) with the observed warming 0.65±0.06 (5-95%). The attribution then follows as having a mean of ~110%, with a 5-95% range of 80–130%. This easily justifies the IPCC claims of having a mean near 100%, and a very low likelihood of the attribution being less than 50% (p < 0.0001!).”
A(2) Modern warming, glacier and sea ice recession, sea level rise, drought and hurricane intensities…are all occurring at unprecedentedly high and rapid rates, and the effects are globally synchronous (not just regional)…and thus dangerous consequences to the global biosphere and human civilizations loom in the near future as a consequence of anthropogenic influences.
A(3) The climate models are reliable and accurate, and the scientific understanding of the effects of both natural forcing factors (solar activity, clouds, water vapor, etc.) and CO2 concentration changes on climate is “settled enough“, which means that “the time for debate has ended“.
A(4) The proposed solutions to mitigate the dangerous consequences described in N(4) – namely, wind and solar expansion – are safe, effective, and environmentally-friendly.
To reiterate, these 200+ papers compiled in 2019 thus far support the N(1)-N(4) positions, and they undermine or at least do not support the “consensus” A(1)-A(4) positions.  The papers do not do more than that. In other words, it is not accurate to claim these papers prove that anthropogenic global warming (AGW) positions are invalid, or that AGW claims have now been “debunked”.
Below are the three links to the list of  2019 papers amassed as of the 17th of June, 2019, as well as the guideline for the list categorization.
Skeptic Papers 2019 (1)
Skeptic Papers 2019 (2)
Skeptic Papers 2019 (3)

Part 1. Natural Climate Change Observation, Reconstruction
A Warmer Past: Non-Hockey Stick Reconstructions 
Warming Since Mid/Late 20th Century?
Lack Of Anthropogenic/CO2 Signal In Sea Level Rise 
Sea Levels Multiple Meters Higher 4,000-7,000 Years Ago
A Model-Defying Cryosphere, Polar Ice
Part 2. Natural Mechanisms Of Weather, Climate Change  
Solar Influence On Climate
ENSO, NAO, AMO, PDO Climate Influence
Modern Climate In Phase With Natural Variability
Cloud/Aerosol Climate Influence
Volcanic/Tectonic Climate Influence
Antarctic Ice Melting In High Geothermal Heat Flux Areas
Mass Extinction Events Caused By Glaciation, Sea Level Fall 
The CO2 Greenhouse Effect – Climate Driver?
Part 3. Unsettled Science, Failed Climate Modeling

Climate Model Unreliability/Biases/Errors and the Pause 
Urban Heat Island: Raising Surface Temperatures Artificially
Failing Renewable Energy, Climate Policies
Wind Power Harming The Environment, Biosphere
Elevated CO2: Greens Planet, Higher Crop Yields
Fire Frequency Declining Since 20th Century Began
Global Warming Reduces Mortality. Cold Kills.
No Increasing Trends In Intense Hurricanes
No Increasing Trend In Drought/Flood Frequency, Severity
Natural CO2 Emissions A Net Source, Not A Net Sink
CO2 Change Lags Temperature Change
Miscellaneous
Share this...FacebookTwitter "
"Wheat has been found in a settlement on England’s south coast dating back to 6000BC – 2000 years before farming reached Britain. This finding overturns many cherished archaeological beliefs – or myths – about the era. Though they were once patronised as simplistic hunter-gatherers, it turns out early Britons must have been active traders with the agricultural superpowers of their day in France and the Balkans. It’s time to reassess Mesolithic man. The introduction of farming is usually regarded as a defining historic moment for  human societies. Agriculture creates the conditions for permanent settlement, urbanisation and complex societies.  The positive impact and significance of farming, starting during the period known as the Neolithic, is often contrasted harshly with preceding hunter gatherer cultures. These societies, associated with a period entitled the Mesolithic in Britain (c. 10,000-4000 BC), were relatively mobile and the passage of time has been unforgiving in respect of the survival of their material culture.  This has meant a tendency to presume the peoples of pre-farming Britain were socially simple and geographically isolated. The recent TV show 10,000 BC, which approximates this period, perpetuates the view that life at this time was simply “nasty, brutish and short” with little for people to do other than eat hazelnuts as they waited patiently for wiser peoples from the East to arrive along with the lifestyle benefits of the new technology – farming. Yet Mesolithic societies were as complex as any other. For instance, the earliest built ritual monuments in Britain, usually associated with farming societies, emerged as early as 9000BC near Stonehenge and one structure in Scotland may represent a calendrical device nearly 5000 years older than the first historical calendars.  The first permanent homes and domestication of animals including the dog also occurred before the introduction of farming.  Yet, the use of grain and specifically wheat, remained essentially absent and a key indicator of farming in regions far from south west Asia, where grain was domesticated 12000 years ago.  Consequently, a debate continues as to whether farming was introduced following colonisation by groups already practising agriculture or the new technology was adopted by indigenous hunter gatherer populations. Was farming a movement of people or ideas? Farming is thought to have been introduced to Britain in around 4000BC, perhaps held back by the island’s new isolation following sea level rises at the end of the ice age. The same processes, however, also provide an opportunity to preserve evidence and Britain’s continental shelf has exceptional archaeological potential.  To investigate whether early traces of farming might be preserved in sediments on the sea bed, we gathered a team from the Universities of Birmingham, Bradford and Warwick, together with the Maritime Archaeology Trust. Our results, just published in the journal Science, suggest that grain, rather than indicating the onset of farming, was actually present in Mesolithic settlements in Britain 2000 years before local agriculture. We found evidence of grain after analysing DNA recovered from the uniquely preserved Bouldnor Cliff off the south coast of Britain. In the past ancient DNA has most commonly been obtained from anatomically intact material, such as hair, bones and teeth. It has only recently become clear that DNA can also be retrieved from other materials, including sediments, or SedaDNA – a discovery which has the potential to revolutionise the field.   The sedaDNA sequences at Bouldnor Cliff suggested a mixed habitat of oak forest and herbaceous plants, much as we would expect.  We found traces of animals that could indicate human activity – lots of dogs, for instance, and aurochs (ancestors of the modern cow), as well as deer, grouse and rodents. However, in later sediments, dated to 6000 BC, the results revealed the presence of Einkorn wheat. This was 2000 years earlier than expected and at a time when the cutting edge of agriculture may have lain in the northern Balkans or possibly on the Mediterranean coast of France. What does this mean? In the absence of direct evidence for cultivation, it seems likely that wheat was imported rather than grown locally. If so the implications are considerable.   The presence of wheat suggests the existence of a web of social networks stretching between Mesolithic Britain and the advancing Neolithic front far to the south and east. Far from being simple or isolated, the Mesolithic peoples of southern Britain were probably engaged in trading or gifting exotic foodstuffs across much of continental Europe – it seems absolutely unreasonable to imply that hunter gatherer groups were passive recipients in such an exchange. The results also indicate that key historical events, including the arrival of people in the Americas and agricultural development of Southeast Asia, may also be best explored through investigating the extensive land masses that were lost to the seas as a consequence of global warming.  The results of the work at Bouldnor Cliff now suggests that that such landscapes also retain caches of genetic material that may not be preserved or even represented on land. If so the analysis of marine sediments may be an archaeological “game-changer”."
"The climate debate seems to be as polarised as ever. While joint political pledges offer some hope that climate change no longer has to be a partisan issue, a look at the comments below most articles on global warming says otherwise.  Some put this is down to differing core values, others point to psychological outlooks. However our research highlights an overlooked element – language itself and labelling opinions can frame public debate as polarised and antagonistic. Labels are everywhere in the climate debate, including politicians railing against “flat-earth climate sceptics”, popular science writers calling their critics “climate change alarmists”, and even others who argue that people who use the word denier should themselves be called “global warming Nazis”. These labels are not only offensive, but they also polarise the debate into opposing “us and them” factions. This has important knock-on effects, as the perception of widespread scientific and policy disagreement makes the public less certain climate change is happening and lowers support for climate policies. Categorising and grouping people is a fundamental part of the human cognitive process, helping us understand and assimilate the vast amount of information we face each day. Labels are used in all walks of life, but when it comes to climate change, Susan Lawler’s words could not be truer: “their meaning is opposite to their definitions”. For example, “scepticism” implies seeking the truth, constant questioning and is a fundamental scientific tenet – it famously took Thomas Edison 1,000 attempts to invent the light bulb, refining his approach along the way – but these days it is applied to all sorts of positions and rationales. The use of the term “denier” is also particularly contentious and obstructive – however all labels in the debate can contribute to polarisation, regardless of their origin. Crucially, no labels exist to identify those who are not actively engaged in the climate debate (with the label “lukewarmer” arguably on the sceptical end of the spectrum, rather than identifying the unengaged general populace). The debate is therefore putting people off from engaging in constructive dialogue.  Firstly, labels have pejorative undertones which frame the debate as antagonistic and combative, allowing uncriticised stereotypes to develop. Using labels directly influences the way in which individuals are seen in the eyes of others, rather than attempting to understand how underlying political or ideological viewpoints can contribute to individual opinion formation. Secondly, labels only identify those at polarised extremes, encouraging these groups’ identities to harden and become less open to dialogue. This delays public understanding about climate change by contributing to a “logic schism” across which dialogue and real policy action is less politically viable. Labels foster an environment where preservation of one’s ideology and group identity takes priority over constructive deliberation of knowledge or evidence. Essentially who one is becomes more important that what one is arguing. Thirdly, labels fix opinions and increase their likelihood of transforming into stereotypes. Opinions can evolve over time, but labelling an adversary allows people to ignore their views and can contribute to an opinion becoming increasingly static or unresponsive to new information. Labels such as “denier” or “warmist” reduce the need to delve deeper into arguments and rationales of others in the debate and to write off those expressing an opposing point of view. Fourth, labels fail to capture the complexity of individual opinions and rationales. Academics have come up with increasingly detailed taxonomies of climate thinking, yet they do not capture well the arguments and motivations which together make up an opinion. Labels are also failing to capture geographic complexity, as viewpoints on climate change encompass different meanings in different geographical contexts]. We need new ways of framing and talking about climate change.  We need to remember that science “does not provide us with convenient yes/no answers” and being sceptical is part of the scientific process. Removing these antagonistic labels from the debate could encourage all those engaged in this area to think of it less as a polarised debate and move towards a more nuanced and constructive discussion about specific issues of disagreement. The current academic focus on categorising labels about climate change diverts attention away from much-needed research on underlying rationales. Scientists can play an important role in informing and legitimising new policies, therefore it is vital that climate researchers pay attention to their choices of language."
"
Share this...FacebookTwitterClimate sensitivity and the warming pattern
By Die kalte Sonne
(German text translated/edited by P Gosselin)
In March 2018, we reported on a paper that derived the sensitivity of our climate system with the best data available. Lewis/Curry (2018) reached the result: 1.3 °C for doubling of the CO2 in the atmosphere with a rise (Transient Climate Response), long-term equilibrium (ECS) of 1.7 °C (see Table 3 of the paper).
The numbers hardly react sensitively to the choice of (larger) time windows, they fluctuate very little, whether one evaluates 1870…2016 or 1930…2016. There has been a whole series of precursor studies also from other authors who also arrived near these quite small values. Also papers examining historical periods (last glacial maximum to pre-industrial) do not contradict these low figures.
So the much more dramatic sensitivity estimates, especially from GCM model considerations (for General Circulation Models), — 1.86 °C for TCR and 3°C for ECS — are not applicable? “It’s not that simple,” some activists insist because then the low sensitivity of the Earth’s climate would not necessitate urgent action to reduce greenhouse gases.
So how can we save the GCMs from empiricism with their worrisome projections? A key argument so far is this: models predict a different spatial distribution of ocean warming than what we observe:

 

Fig.3: The warming patterns derived by models (top) and the observed patterns. Of particular importance is the fact that the CMIP5 models indicate a rather uniform warming of the tropical Pacific as a result of the (mainly man-made) forcing (hence the model-mean), but the observations show a significantly stronger warming of the western tropical Pacific compared to the eastern one.  The images were generated with the KNMI Climate Explorer.
So it could well be, activists say, that the deviation are just a “whim of nature”, an internal variability, and after the end of this rather random episode, the warming becomes much stronger on a global scale on accordance to the models. There is talk of “trajectories” which were and will be possible, and the observations strongly deviate negatively because they are a random one of the possible warming patterns. In short: “What we have observed so far is not the real reality, but it will certainly get much worse. Believe the climate models!”
2 new papers
Here we present two current papers that provide explanation. To start: The observations of the warming rate are correct, the deviating patterns of the climate models are caused by their inadequacies and these patterns will not change.
In Dong et al (2019), the authors show that if the convective regions with many clouds in the western Pacific warm up more strongly than those with hardly any convection in the eastern Pacific, the overall global warming is much less pronounced.
Let’s take a look at the clouds in the tropical Pacific:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Fig. 4: The convection(CAPE Index) over the tropical Pacific. The west-east gradient can be seen clearly. Source.
Convection in the western tropical Pacific leads to an increased heat radiation into space, which means that the warming there can be reduced much more effectively than would be possible with a stronger warming of the eastern Pacific with less convection, see Fig. 4.
The paper finds:
For the west Pacific patch, warming is communicated to the upper troposphere, which warms the whole troposphere across all latitudes, causing a large increase in outgoing radiation at the TOA. Furthermore, the patch of warming locally decreases tropospheric stability, measured here as estimated inversion strength (EIS), but increases EIS remotely over tropical marine low clouds regions, yielding an increase in global low cloud cover (LCC) which enhances the global SW reflection….The results first highlight the radiative response to surface warming in tropical ascent regions as the dominant control of global TOA radiation change both in the past and in the future. …This surface warming pattern yields a strong global outgoing radiative response at TOA that can efficiently damp the surface heating, therefore producing a very negative global feedback.”
It is therefore a clear physical mechanism that leads to the observed stronger warming of the tropical West Pacific leading to lower global sensitivities (= stronger negative global feedback).
The second paper, Seager et al (2019), deals with the same phenomenon and concludes that the observed pattern is not random, but a direct result of forcing. It states:
The main features of observed tropical Pacific climate change over past decades are consistent with a response to rising CO2, according to fundamental atmosphere and ocean physics….However, the strength of the tropical Pacific influence on global climate implies that past and future trends will diverge from those simulated by coupled climate models that, due to their cold tongue bias (ein Streifen kühleren Wassers in Äquatornähe des Ostpazifiks, d.A.), misrepresent the response of the tropical Pacific to rising CO2.”
Climate models have such large deficits in the depiction of events in the tropical Pacific that they are globally incorrect in determining the response to the forcing (see Fig. 3) and systematically overestimate the sensitivity to the forcing (according to Seager et al, and Dong et al).
So will we read anything about this in the media? A possible headline might be: “Climate models calculate the future too hot! Don’t hold your breath.
PlayStation climatology
We eagerly await to see whether the results of these two important studies will even be included in the IPCC’s forthcoming progress report. Here hundreds of pages dealing with model projections would have to be critically revised. One more reason for us to trust empiricism and “PlayStation climatology”.
But what is to become of the “panic” which Fridays for Future wishes to impose on us? Policymaking is hot because the models are too hot. Which scientists have the courage to be responsible and to enlighten FFF and policymaking?
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOur German skeptic friend Snowfan here keeps us up to date on the latest ODEN “Ship of Fools” attempt to travel across an Arctic that is supposed to be ice-free by now.
The incentive to cross the Arctic passages in the summer is huge. Doing so would mean at least a week of fame with the media blaring out your name along with grossly hyped headlines of an Arctic ice meltdown due to global warming. One of these years, a ship might get lucky and manage to get through the Northwest Passages.

Image from: Ship-Tracker ODEN  Snowfan
And the pressure to do so is enormous because over the last ten years Arctic ice volume has even rebounded slightly and if that trend continues, as some expect, the global warming alarmist may never get another chance to get through. Last year failed.

Mid-summer Arctic ice volume has grown modestly over the past 13 years, thus casting doubt Arctic is melting further. Chart: Kirye.
The latest “Ship of Fools” episode this year is an attempt by the above mentioned Swedish ice breaker ODEN, which hopes to get through. Unfortunately conditions so far this summer have not been as favorable as they hoped, Snowfan reports:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Image: here.
This year Arctic sea ice in the area of interest on July 14 is (unexpectedly) thicker than it was last year at the same time, and a heck of a lot more than what some climate models and Al Gore projected a bit more than 10 years ago:

In Lancaster Sound and the Barrow Strait (eastern access point to the NW-Passage) sea ice in mid July 2019 is up to 3 meters thick, i.e. 2 meters thicker than in mid-July 2018! Source: DMI Arctic Sea Ice Thickness. Image: here.
Also defying the models is the extent of ice cover for July 9 at the Baffin inlets Regent – Boothia. Over the last 50 years, there’s been little trend change:
 

Source: Canadian Ice Service
The latest on ODEN, according to CruiseMapper, is that it is currently well off course. Snowfan writes:
In the night of July 19, 2019, the Ship of Fools has deviated far from its planned route southeast of Coburg Island and is positioned this morning west of this island. We await with suspense to see if the climate fools will overcome the thick ice on July 20, 2019 and arrive on time in Pond Inlet.”
Share this...FacebookTwitter "
nan
"Blind and furious in the smoke, we will seek someone or something to blame for our national fire emergency. We will blame our governments for their inertia on climate change, our firefighters for not burning enough or burning too much and those leftists for their flagrant use of green tape. But there isn’t a single culprit or a simple solution to a problem which has been heading towards catastrophe for decades, if not centuries.  We are all culpable, either directly through our land use practices, or indirectly through the land use practices and emissions that our often-thoughtless consumption necessitates. Like many of my ecologist colleagues, I dread the reaction to these events almost as much as the events themselves. The call for clearing country around infrastructure is already being taken up. And maybe this is part of the solution, but how many wounds can we inflict upon our planet and still expect her to maintain our climate, our air and our water? As a Country Fire Authority volunteer, my mother has been working incredibly hard for some time to plan a buffer zone around Mallacoota that balances the locals’ love for their environment with their need for protection. The plan never had a chance to be enacted. Imagine her heartbreak as she fielded 000 calls in the communications room of the Mallacoota fire station as the houses of her friends were burning. At the end of the smoke and drama that my mother is living through, and after a cold champagne in salute of survival, her mind will once again turn to protecting her community. But I worry that that same community may never again be allowed the space to calmly consider its priorities amid the barking for more clearing and more burning to ensure safe communities. The conversation that we need to have to address this deeply complex problem must be given the time and space it demands and it must be approached with open minds. Most importantly we must remain civil to each other, consider carefully each other’s expertise, experience and values and finally avoid the temptation of accepting poorly considered kneejerk reactions that will inevitably fail our planet, our ecosystems and our communities. We need to acknowledge some truths along the way. Climate change is upon us, we must act to reduce its impact. Equally, we need to comprehend that the impact of climate change will be with us now for decades, even if, as a global community, we immediately begin to take meaningful and substantive action. So, where else must we turn our gaze? Talking to my father recently in a break from his firefighting duties at Gipsy Point, his frustration was palpable. We discussed the inadequacy of land management practices that have contributed to the catastrophe which continues to threaten not only his community and the country of his heart, but also the sacred places of our mob. I’ve heard similar voices of frustration raised before from affected communities when I’ve been deployed to fires including at Wye River in 2015 and this year in south-west Victoria. Are our land management practices failing us so regularly despite the efforts of our firefighters to continually improve their fuel management programs? Perhaps what we lack is not a program of land clearing and ramped up fuel reduction burning. Perhaps what we lack, and desperately need, is a vision for our environment, for the species and ecosystems it will support, and how our communities will sit within these environments. Without this vision I fear fuel reduction burning will simply condemn our landscapes to a patchy state of recovery from a series of wildfires and hazard reduction burns. There’s already a blueprint for how we could remake our landscapes, it’s in our country’s bones. It’s in the stories and sophisticated land management practices of our first peoples. We could raise this vision again, a vision which supported the healthy soils and biodiversity that were inherited by European settlers 232 years ago, a landscape which saw fewer destructive bushfires. It would mean we must have an honest and respectful conversation with the knowledge-holders of Aboriginal communities so that we can all understand the lore by which country was managed. Eight years ago, I started a fire program with colleagues on Cape Otway. The ecosystem we were working with was suffering the stark consequences of neglect, following a contact period which had catastrophic consequences for the Indigenous population. Fortunately, we had a relatively good description of what the environment looked like under the custodianship of the Gadabanud from settler diaries, a lightly wooded rolling dune system with a diverse yet open understorey. We knew that fire had a role to play in restoring this landscape, although the complexity of the knowledge was not available to us. We’ve made many mistakes in attempting to recreate this environment, most often through my failure to account for the attributes of certain plants. But, slowly, what we can see emerging in our landscape through the use of fire, is the structure of an open woodland that is rich in plant species once more. It’s less hazardous now because we’ve changed the fuel structure, although it is certainly still flammable. Most importantly though, this process has given us a glimpse at what this ecosystem has been and could be again. I know this approach won’t be an end to catastrophic bushfires in our rapidly changing climate as it’s not the only piece to the puzzle. However, we do know that through respectful and highly skilled use of fire, this country’s first peoples produced food, fibre and medicine for a large population while protecting communities, totems and places of cultural significance. This was achieved by a society whose term of custodianship straddled periods of significant climatic change, making it an adaptive land management approach that we cannot afford to ignore now. Above all else, this was a knowledge system that provided a vision for our landscapes that doesn’t need revival, simply our attention. Jack Pascoe is the research manager at the Conservation Ecology Centre, a fire practitioner and Yuin man."
"
Share this...FacebookTwitterThe President of the German Bundesamt für Bevölkerungsschutz und Katastrophenhilfe (Federal Office for Civil Protection and Disaster Relief, abbreviated BKK) is calling on citizens, government offices and companies to be prepared for widespread blackouts.

In an interview with German national daily Die Welt, BBK President Christoph Unger warned that in the future Germany faced higher probabilities of natural disasters arising from climate change, such as droughts, heat waves and flooding, but said his greatest concern was a power outage.
“After 24 hours without electricity we would have catastrophic conditions,” Unger told Die Welt.
He was particularly concerned about how the power supply could be switched off by a cyber attack. “We have to prepare ourselves for such a scenario and prepare ourselves for it”.
Unstable grid, more frequent interventions
He then told Die Welt that although the German power supply is relatively stable and secure in a global comparison, “the German Federal Grid Agency is having to intervene more and more frequently in order to compensate for grid fluctuations.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Over the years Germany has added more and more volatile supplies of wind and solar power to feed into its power grid. This has made keeping the frequency within the needed range an increasingly difficult challenge.
“Faced multiple collapses”
For example, the German DWN here reported how in June earlier this year “Europe’s electricity grid faced multiple collapses” and how grid frequency in Germany had “plummeted several times to such an extent that Europe’s entire power grid had been endangered.” Some aluminum mills had to be taken offline.
Keep candles and matches on hand
To prepare for blackouts, Unger told Die Welt that citizens needed to keep “candles and matches” and always have a “batter-powered radio on hand in order to be able to receive news even when the power is out.” He added: “Every household should have a supply of food and drinking water.”
Diesel backup generators to the rescue
Ironically Unger told Die Welt that government offices and companies to ask themselves: “Is there enough diesel fuel on hand to power an emergency back-up generator? Where will the diesel come from when the electricity has not yet returned after two days but the back-up generators have to continue running and diesel can only be pumped from the tank farms with electric pumps?”
Is this the future of the European power supply? Citizens using matches, candles and battery-powered radios to getb through power blackouts and companies and government offices relying on emergency backup diesel generators? Sounds like the 1950s.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Kirye
and Pierre Gosselin
Whenever NASA GISS announces how recent global temperatures are much hotter than, for example, 100 years ago, just how statistically reliable are such statements?
Most will agree, based mainly on sundry observations, that today is indeed warmer than it was when surface temperatures began to be recorded back in 1880. But we will never really know by how much.
Surface station datasets full of gigantic voids
When we look at NASA GISS’s site here, we can see how many surface stations have data going back to earlier years. Today we see that 2089 stations are at work in Version 3 unadjusted data.
Yet, when we go back 100 years (to 1919), we see only 997 of these surface stations have Version 3 unadjusted data that is complete:


Source: NASA GISS
Note how the Version 3 unadjusted datasets going back to 1919 are poorly distributed and sorrowfully lacking over Africa, Canada, the Arctic and all across the Southern Hemisphere. Never mind the oceans.
Only a measly 174 surface stations go back to 1880!
And when we look at the number of stations in Version 3 unadjusted data going back to 1880, ONLY 174 stations actually provide us with a complete thermometer dataset:
giss.nasa.gov/gistemp/station_data_v3/ …


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




As is shown, Version 3 unadjusted data going back to 1880 covers only some parts of the US and Europe. All of Canada and Russia are void of data, and so it is impossible to know what the temperatures there really was.
The same is true for the entire southern hemisphere, let alone the entire globe. The bottom line: There is no way of knowing what the global temperature really was back in the late 19th century and early 20th century.
Japanese expert: data of “no scientific value”
This tells us that global temperature trends since the start of the Industrial Revolutions presented by NASA are fraught with huge uncertainty.
“This is nothing new,” says Japanese climate expert Dr. Mototaka Nakamura in an email to NTZ. “We simply did not have many observing stations in the 1800s and early 1900s. They can produce ‘new data sets’ and claim that they have ‘better data sets’ all day long, but they just can’t make any meaningful difference for periods up to 1980.”
“Not real data”
“These datasets are products of simulation models and data assimilation software, not real data,” Dr. Nakamura added. “This problem has been present in data products produced by all institutions from the beginning – NASA, NOAA, NCEP, ECMWF, UMet, etc.”
“Spatial bias before 1980 cannot be dealt with”
But the data shortcomings get even worse. Dr. Nakamura wrote: “A far more serious issue with calculating ‘the global mean surface temperature trend’ is the acute spatial bias in the observation stations. There is nothing they can do about this either.  No matter what they do with the simulation models and data assimilation programs, this spatial bias before 1980 cannot be dealt with in any meaningful way. Just look at the locations of the observation stations used in GISS products for various years on their page.”
Dr. Nakamura commented earlier here at NTZ: “The global surface mean temperature change data no longer have any scientific value and are nothing except a propaganda tool to the public.”
So how can we be sure about the globe’s temperatures, and thus it’s trends before 1980? You can’t. The real data just aren’t there.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterRecently NTZ published a post on a study which examined Vietnam tropical cyclone activity.
The study found that for Vietnam “none of the meteorological trends such as frequency, central pressure, wind speed, or storm intensity show any significant increase or decrease over the last four decades.”
But such a trend is not only seen for Vietnam, but virtually the entire Pacific. For example Japanese climate blogger Kirye compiled the stats on Japan typhoon landfalls and here we see they have not risen significantly, and the number of typhoons formed has even fallen:

Number of typhoons formed: jma . Number of typhoons landings in Japan: jma
At his latest Saturday Summary, meteorologist Joe Bastardi shows that this year’s hurricane season is off to a slow start as conditions in the main development zone will remain unfavorable for at least another week.
All of this tells us that global warming alarmists’ warnings of more frequent and intense storms have been completely WRONG so far.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Hurricane frequency falling
Now we look further at the statistics for global tropical storm activity from expert Dr. Ryan Maue here:

Also no trend in major hurricanes since 1992. Image: Dr. Ryan Maue
Looking at total global tropical storms, Dr. Maue’s data show no trend in close to 50 years:

The next time someone claims tropical cyclones have gotten worse and more frequent, you might want to tell them to look at the data and to stop parroting alarmist nonsense spread by the media.
Share this...FacebookTwitter "
nan
"The 100 million-and-counting views of Chinese air pollution documentary Under the Dome is dramatic, but shouldn’t come as any surprise in a country where discussion of smog is more commonplace than discussion of the weather.   It is of course hard to ignore air pollution in most Chinese cities once you step outside. Where Los Angeles in the 70s was famous for its brown skyline, resulting from nitrogen dioxide and photochemical smog, China is now renowned for its white haze of fine droplets, formed when particulate matter pollution and water vapour combine and grow.  China isn’t alone in having a problem with air pollution, (go visit New Delhi, Mexico City, Lagos or London), but you simply can’t ignore it when the impacts on visibility are so great. Until relatively recently, reliable data on Chinese air pollution was hard to come by, but much changed in 2009 when the US started measuring certain pollutants at their Embassy in Beijing and placing the information online. Soon afterwards there was a rapid expansion in openness and now anyone, anywhere, can see real–time pollution all over China.  Of course much of this data simply confirms what most residents can tell for themselves – there are good and bad days (more often bad) but the availability of quantitative information does now change peoples behaviour. National acceptance of air pollution as a serious problem, via public dissemination and heated debate, followed by mitigation measures and regulation, is a very well-trodden path that virtually all developed nations have gone through during periods of rapid economic expansion. In this respect the pollution problem now in China is systemically no different to the transition periods that led ultimately to the Clean Air Act in the UK, or the introduction of catalytic converters in the US. The sources of pollution in Beijing are many and varied, but they have much in common with examples from history.  Expanding provision of energy at the lowest possible cost has always been a lever in driving economic growth, and growth in China has been no exception. Its fuel of choice has been coal, and coal used in a somewhat uncontrolled and, until recently, poorly regulated manner.   Increases in transportation infrastructure have also characterised expanding economies; in the 21st century this means private cars, lorries, aircraft and shipping. While there has been moderate progress in reducing emissions on a per-car or per-aircraft basis, this is easily overwhelmed if the absolute numbers of each increase.  Agricultural emissions are a final but often overlooked contribution to pollution, and again China is no exception.  Large populations with growing incomes want feeding, and this drives the increased use of fertilisers for productivity. In the atmosphere ammonia from often remote agriculture is a potent contributor to particulate matter found in cities. There are scant few historical examples of major economic expansion without air pollution as a consequence. In the absence of a really game-changing energy technology or fuel or food source, national strategies need to be designed to transition as quickly as possible through the polluted period, where low cost trumps all other considerations.  This is something that can be see as analogous to the demographic transition that also accompanies economic development. It may be uncomfortable to accept, but the UK probably experienced a transition period of more than 100 years of terrible urban air pollution before the problem was brought under any degree of control. It seems unlikely the government or citizens of China will accept a transition anything like that long. Control of air pollutant emissions from coal-fired power stations are effective in other countries, so there is no reason why strong regulation and enforcement can’t achieve the same in China. Fertilisers and agriculture have proved technically and politically difficult to control in Europe and the US, but the science at least is understood.  There is also much that could be learned from the recent mistakes of others. It would be disappointing if the poor performance of modern diesel engines seen in European cities were allowed to play out again in China, or indeed in other less reported on pollution megacities in India, Africa and South America. Although measurement data is sketchy and incomplete it is reasonable to assume that China is now past its “peak pollution” in absolute terms. The rate of implementation of cleaner technologies is on a scale greater than anything ever attempted before. Things are getting better, but the distance still to travel is pretty vast.   Investing domestically in cleaner power, cleaner transport, and cleaner urban living has a cost, but so does the healthcare and reduced productivity that air pollution induces. Cleaner air investments should be viewed as part of the engine of economic development, rather than the brake."
"
Share this...FacebookTwitterpetunjuk bandarq ialah salah satu tipe permainan judi yg paling tidak sedikit disukai oleh beberapa orang baik dari seluruhnya kalangan belia & pula dewasa. Permainan Judi bandarq ini tidak sedikit memberikan kemenangan sampai bonus jackpot yg lebih akbar dari dana yg kita mainkan. Ini yg jadi argumen penting mengapa permainan Judi bandarkiu tidak sedikit dinikmati oleh seluruh pemain termasuk juga anak-anak remaja sampai orang dewasa. & yg paling menarik dari permainan ini ialah seluruhnya pemain dapat mendapati peluang yg sama mendapati bonus jackpot bila mereka memperoleh kombinasi card special di tiap-tiap putaran. Nah di artikel ini kita dapat sedikit memaparkan menyangkut pedoman main-main bandarq & mendalami jens-jenis card poker di dalamnya. Sebenarnya telah tidak sedikit berita yg serupa seperti ini tapi belum tidak sedikit kabar yg diberikan dengan cara detil pembahasannya. Berikut ini yaitu tata cara utk main-main judi bandarq di yg mudah.
a. Mengenal Permainan bandarkiu
Dalam main-main Judi bandarq sendiri ada beberapa aspek yg mesti kamu kuasai dgn baik biar dapat memperoleh kemenangan bersama langsung & bertahap. perdana yg kamu kuasai ialah jalanya permainan itu sendiri, jangan sampai mengharapkan kamu mampu mendapati kemenangan bila tak mampu menguasai jalannya permainan Judi bandarq tersebut. kamu mesti memang sanggup masuk & tak boleh terhanyut dalam permainan judi poker online. Kendalikan diri kamu & temukan kemenangan. Berikutnya merupakan insting & kecerdasaan kamu, tak tidak sedikit pemain yg mempunyai insting keren terkait bersama card yg ada di tangan mereka, lebih tidak sedikit pemain yg membelanjakan atau ikut taruhan tidak dengan memikirkan analisa card mereka. Itulah yg menjadikan system permainan judi poker susah di tebak walau kamu satu orang pemain profesional sekalipun. Intinnya disini jangan sampai enteng terkecoh atau terpancing lawan main-main buat raise atau all in dalam jumlah agung. konsisten kepada pendirian kamu sendiri & pastikan kemenangan ada dipihak kamu waktu ini juga
.
b. mulai sejak dgn step Awal Bergabung
disaat kamu memutuskan utk bergabung dgn agen judi bandarq, maka elemen mula-mula yg mesti kamu jalankan yakni dgn mengahdiri website judi qiu qiu 99 apalagi dulu. mari kamu laksanakan pendaftaran disana dgn isikan form pendaftaran dengan cara kumplit & valid. janganlah hingga kamu salah isi sebab bakal menghambat proses transaksi kamu sendiri. Pastikan nomer rekening, bank & nama rekening serasi dgn milik kamu pribadi.
c. sejak mulai bersama step Deposit Perdana
Langkah berikutnya sesudah kamu telah sukses menciptakan akun judi bandarq, dilanjutkan bersama melaksanakan deposit pertama kamu serasi bersama biaya yg kamu punya. tiap-tiap member mempunyai wewenang utk lakukan transfer dana dalam jumlah tertentu cocok bersama ketetapan yg diberlakukan di dalam website poker online. Disana kamu mampu menyaksikan ada deposit minimal yg artinya kamu cuma mampu deposit tepat bersama jumlah minimal yg disediakan contohnya saja Rupiah. 15.000, di bawah rupiah. 15.000 deposit kamu tak dapat diproses oleh system & seterusnya ada pula tarik dana maksimal yg sanggup kamu proses paling tak mesti lebih dari 15 ribu. kamu dapat menarik dana segede 30 juta apabila agen judi poker sediakan kebijakan tersebut.
Terimakasih.
Share this...FacebookTwitter "
nan
"Anne Karpf writes about the “unthinking ageism” that she thinks has crept into the climate movement. (Ageism must not pollute the climate movement, Journal, 18 January). As an older, active member of Extinction Rebellion and of Doctors for Extinction Rebellion, this absolutely has not been my experience. Retired colleagues and I have regularly shared ideas and actions with young people and learned together how to take the movement forward. An example: at a recent Reforesting Scotland gathering, one of the workshops was on XR and how a group of 70, mainly young, XR activists had responded to a call for volunteers and joined experienced foresters to plant trees at Gameshope, a Borders Forest Trust rewilding project in the south of Scotland. After the workshop a set of instructions for effective tree planting and care was devised and shared. Energy and expertise is a powerful combination.Dr Lesley MorrisonPeebles, Scottish Borders • I admire Greta Thunberg, I fear enough for our children’s future and have supported every move for an arms-free world. My generation have protested since 1936, when I marched with my father against poverty, the Spanish civil war, and the rise of fascism. We were the politically-aware children of the unemployed, grandchildren of first world war casualties, and very well aware of where fascism leads. Not an age of selfish innocence. Like many women of my age, I spent time at Greenham. Protest was part of our lives. It is disappointing to be judged as a “threat to the young”, as having “had it all”, by a generation who should see us more as the generation of Spirit of ’45 and Cathy Come Home, not Downton Abbey nostalgia freaks. So thanks to extinction rebels, but remember where you come from.Maureen WilskerWitney, Oxfordshire • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
nan
"We write as scientists alarmed that a minister has ignored scientific evidence, relying instead on grossly misleading social media sources. In the House of Commons on 9 January, Foreign and Commonwealth Office minister Heather Wheeler answered a question about the Australian bushfires by stating: “Very regrettably, it is widely reported on social media that 75% of the fires were started by arsonists.” The claim that arson is a primary cause of this season’s bushfires has been comprehensively debunked: fire officers report that the majority of blazes were started by dry lightning storms. Nevertheless, social media is awash with false claims about the role of arson, obscuring the link between climate change and bushfires (Disinformation and lies are spreading faster than Australia’s bushfires, 11 January).  However fires start, they burn more severely because Australia is suffering extreme conditions which are directly linked to anthropogenic climate change: 2019 was the country’s hottest and driest year ever, with the temperature 1.5C above the long-term average. The Australian government was advised in 2008 that the effects of climate change on the fire seasons “should be directly observable by 2020”. We ask that ministers rely on expert advice rather than social media. Beyond the present situation in Australia, it is important to acknowledge the role of climate change in many other circumstances worldwide, including in the UK. As host of this year’s UN climate talks, the UK government is responsible for keeping the Paris agreement on track. It must tell the truth to parliamentarians, the public and Australian politicians about the causes and consequences of climate change.Dr Stuart Capstick Cardiff University, Prof Colin Davis University of Bristol, Dr James Dyke University of Exeter, Prof Stephan Lewandowsky University of Bristol, Prof Richard Pancost University of Bristol, Prof Julia Steinberger University of Leeds • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"More than half of the world’s killer whales are threatened by a group of toxic industrial chemicals that accumulate in their blubber and can be passed on from mother to calf. That’s according to a new study led by scientists in Denmark and published in the journal Science. Killer whale populations found in the most polluted seas around Japan, Brazil, the UK or in the northeast Pacific, the authors report, are “tending toward complete collapse”. Polychlorinated biphenyls (PCBs) are a ghost from the past. These chemicals were produced in immense quantities from the 1930s onwards and were broadly phased out in the 1970s/1980s as environmental concerns grew.  As they were very stable and were unable to conduct an electrical current (and therefore excellent insulators), they were mainly used in the electrical supply industry. These same properties also saw them being used in a whole array of miscellaneous applications including as sealants and additives in construction. It is this chemical stability that means PCBs stubbornly refuse to degrade in the environment and I have spent the past 25 years studying how these and other contaminants end up accumulating in the Arctic, for instance. However, there are two other properties that make these particular chemicals uniquely problematic, unlike, say, common air pollutants or most heavy metals.  The first is that PCBs are semi-volatile, which means that over time they can evaporate into the atmosphere but then later deposit on surfaces when encountering cooler temperatures or with rainfall or attached to particles. Over decades this continued evaporation and deposition (termed “cycling”) has ensured that they’re smeared around the entire planet. PCBs are just as likely to be found deep in the ocean or in Arctic snow as they are in neighbourhood soils, although the concentrations in soil close to “primary sources” such as cities may be orders of magnitude higher. The second problem is that PCBs tend to work their way up the food web, accumulating in ever higher concentrations as tiny animals (and their unwanted chemicals) are eaten by small animals, who are eaten by larger animals (who take on those same chemicals), and so on. This process of “biomagnification” is most evident in marine food webs where fatty tissue like blubber (a home for PCBs) is an important feature of animals at the top of the food web such as killer whales. So, if the chemicals were largely phased out in the early 1980s, why are they continuing to cause a problem? It’s true that background concentrations have declined over the past 20 years or so, based on measurements of PCBs in the air in animals such as seabirds and even in human breastmilk. But the trend varies from place to place and between different species, and there is evidence that climate change is disturbing the “cycling” of these chemicals, potentially slowing the rate of environmental decline. Furthermore, complex foodwebs in northern oceans, particularly around Europe and North America (where most PCBs were produced and used) are undergoing subtle alterations. Predators like sharks, large fish or killer whales are changing their diets and exploiting new prey, which in turn alters their exposure to PCBs and other contaminants. What can be done? Unfortunately, the horse has bolted as such and it would implausible to remove “background levels” of PCBs from the world’s oceans. The key objective now is to maintain surveillance of these chemicals, whether they be in air, water, soil or animals. In most developed countries, end-of-life action ensures that old industrial materials with PCBs are subject to high temperature incineration (an effective way of ensuring complete destruction). Similarly, grossly contaminated industrial sites or dumps are subject to expensive clean-up and incineration activities.  But, while this is effective and safe at a local level, such measures will account for only a very small fraction of the total PCB inventory, most of which is out in the wild. International efforts by organisations like the UN Environment Programme (UNEP) are ensuring that member states are undertaking “stocktaking” activities, containing old storage or dump sites, and undertaking monitoring programmes. This is particularly important across parts of Asia and key states of the former Soviet Union, where PCB production and use was also high. The legacy of PCBs will continue to haunt us for some while to come. Scientists estimate that the final resting place or “sink” for PCBs is likely to be organic rich soils across the Northern Hemisphere or even ocean sediments. However, in the meantime, PCBs continue to cycle around the environment and are still present in mother’s milk. Maternal transfer from adult female to calf is the key exposure route for most marine mammals and this chemical stress (supplemented by an array of chemical pollutants other than PCBs), alongside climate change induced stress, is a major concern."
"Glowing fungi with an on-off system synchronised to their daily rhythms? It sounds implausible but it’s true. Some mushrooms evolved the ability to glow in the dark in order to attract insects to spread their spores, according to new research in the journal Current Biology. Fungi are peculiar beings at the best of times. Once believed to be closely related to plants, they are now understood to be more closely related to animals.  Mushrooms, or fungal fruit bodies – the bit you see above ground – may be familiar to us all as food but in the real world mushroom-forming fungi only produce these fruit bodies under special conditions. The main body of the fungus exists largely out of sight as a colony of white thread-like hyphae growing through a food source such as a piece of wood or leaf litter.  In some instances fungal colonies can be old and very large. A colony of Armillaria solidipes in the US is estimated to cover 9.6km2 and be thousands of years old. Fruit bodies are produced to disperse their sexual progeny as spores. Many fungi shoot spores into the air from the underside of the mushrooms, relying on moving air currents to passively distribute the spores over a wide area.  If the fungus is several metres up the trunk of a tree, this method is ideal. But wind speed is often either minimal or non-existent on the underside of logs or at the ground level in a dense forest or even underground, where truffles are produced.  So if air movement isn’t effective how can spores be dispersed far and wide? One option is through aroma. Truffles, the fruiting body of the Ascomycete fungi, use their smell to attract fungivores such as pigs or squirrels who eat them and leave spores behind in their waste. Stinkhorn mushrooms have a foul-smelling slime which attracts flies and other insects. The flies eat the slime and unwittingly spread the spores elsewhere. Light is also attractive to many insects. Indeed a number of fungi bioluminesce, emitting a pale green light. One of the first mycology texts I read as a teenager devoted a whole chapter to “luminosity”, mentioning various fungi including some honey fungi (Armillaria), Jack O’lantern (Omphalotus olearius, pictured at the top of this article) and a number of Mycena. In the new study, a team of Brazilian and American researchers looked at the pale green light emission from fungi, to assess whether it attracted insects and whether brighter light conferred a selective advantage for spore dispersal. The researchers looked at Neonothopanus gardneri, a particularly intense emitter found at the base of coconut palms in Brazil. It was previously thought their light was emitted continuously as a byproduct of some other round-the-clock metabolic process.  However, the study found the fungus glows only at night, and so is energy efficient; during daytime the light emission would be too faint to be visible. In any case, the best conditions for spore germination in canopy forests are found at night, when it is more humid. If the mushrooms glow only at night then the bioluminescence must serve some purpose. Camera observations showed the glowing fruit bodies became infested by rove beetles. But these beetles may have been attracted by something else – smell, perhaps.  To specifically test the glowing effect, experimental “mushrooms” made from clear acrylic resin were built. They were equipped with a light emitting diode which operated at a similar wavelength to the mushrooms. To the beetles, the light would have looked the same.  The glowing plastic mushrooms attracted these and various other insects sensitive to green light, while fewer were attracted to non-illuminated controls. From this we can conclude that for these fungi there is a selective advantage to glowing in the dark."
"Climate change will have major effects on the ecology and distribution of many animal species. Now new research suggests that rabbits will be particularly hard hit as climatic changes alter their habitat over the coming decades. Rabbits, hares and pikas could become this century’s new climate migrants – with up to two-thirds of species forced to relocate. There are almost certainly going to be extinctions among some of the more sensitive and less adaptable species.   Rabbits and their relatives hares (referred to in North America as jackrabbits) and the lesser known pikas belong to a group of mammals known as lagomorphs – of which there are 87 species worldwide.  Lagomorphs are particularly interesting to ecologists – and those of my colleagues who work in Global Food Security – as they are a major human food resource, valued game species, agricultural pests, model lab animals and key elements in food webs.  You can find rabbits, hares and pikas almost everywhere, across a huge range of environmental conditions. They’re native to all continents except Antarctica, found from the equator to the Arctic, and from sea level to the very top of the Himalayas.  A quarter of lagomorphs are already listed as threatened, and 13 species are endangered or critically endangered. We were particularly interested in how predicted changes in climate would affect this already highly vulnerable group. In our study, colleagues from Queen’s University Belfast and I collated all known records of lagomorph species worldwide. Environmental conditions such as temperature or rainfall were correlated with the sites where each species occurred to establish the suitable habitat within which each can persist. Widely accepted climate models of projected future conditions were then used to extrapolate how suitable habitat would change. The results, published in the open access scientific journal PLOS ONE suggest that two-thirds of all lagomorph species will be affected. Rabbits, hares and jackrabbits are likely to shift towards the poles with little change in the total size of their range – the geographical area in which the species can be found.  Pikas meanwhile, are likely to shift to ever higher altitudes as the lower slopes warm up leading to huge range declines. This is likely to lead to the extinction of some such as Kozlov’s Pika Ochotona koslowi, a mysterious species unique to China.  Of course the animals won’t just remain still while the climate changes around them – moving towards the poles or to higher ground is a standard strategy to track shifts in suitable habitat. Rabbits, hares and jackrabbits can move long distances and can potentially move to cooler conditions without losing too much of their range; the effects of such shifts on ecosystems are largely unknown but likely to cause significant disruption.  The smaller and less bouncy pikas won’t be so lucky. Pikas inhabit generally cooler conditions in the high mountains of the Himalayas or Rockies and will be driven further upwards until no suitable habitat remains. My colleague Neil Reid, a conservation biologist and lagomorph expert at Queen’s, points out that “they will likely be pushed off the top of the mountains, literally, with total extinction the most probable outcome”. Species traits can be useful indicators of potential responses to climate change, yet have rarely been linked to changes in distributions. Smaller-bodied species were more likely to exhibit range contractions and shifts to higher ground, but species capable of having large numbers of offspring were more likely to shift towards the poles.   The effect of climate change on lagomorphs is predicted to be so substantial that almost a third of the Earth’s land area (31.5 million km2) will lose at least one species by 2100. It is predicted that northern China will lose up to ten species, whereas Montana and North Dakota in North America are likely to gain up to five species – climate rabbit refugees perhaps, fleeing the ever-warming southern states and Mexico. Generally, species on islands and mountains will be the hardest hit by changing temperatures.  However predictive models are simplified versions of reality and as such are rough approximations of what seems likely to happen. Those we used did not account for the complexity of ecological systems, such as how species – like plants or predators – interact with lagomorphs.  Moreover, small burrowing species such as the Pygmy rabbit Brachylagus idahoensis may be able to shelter from the effects of climate change, while larger species like the European hare Lepus europaeus may have to adapt to mitigate the effects of warming temperatures – for example in the way that the Antelope jackrabbit Lepus alleni uses its long ears to shed excess heat.  So we have to be careful in the interpretation of our models – but the consistency of the results across all lagomorph species does not paint a good picture of the future for the group. Conservation strategies, such as assisted migration – where humans deliberately move species to areas of more suitable conditions, pre-empting future changes – may be one of the few options to save highly range-restricted species, even if it is highly controversial.  Collection of more species records, particularly for already rare species, as well as targeting data-deficient geographic regions (such as Russia) will be vital in increasing our knowledge of the most threatened lagomorphs and informing future conservation management."
"The amount of material consumed by humanity has passed 100bn tonnes every year, a report has revealed, but the proportion being recycled is falling. The climate and wildlife emergencies are driven by the unsustainable extraction of fossil fuels, metals, building materials and trees. The report’s authors warn that treating the world’s resources as limitless is leading towards global disaster. The materials used by the global economy have quadrupled since 1970, far faster than the population, which has doubled. In the last two years, consumption has jumped by more than 8% but the reuse of resources has fallen from 9.1% to 8.6%. The report, by the Circle Economy thinktank, was launched at the World Economic Forum in Davos. It shows that, on average, every person on Earth uses more than 13 tonnes of materials per year. But the report also found that some nations are making steps towards circular economies in which renewable energy underpins systems where waste and pollution are reduced to zero. “We risk global disaster if we continue to treat the world’s resources as if they are limitless,” said Harald Friedl, the chief executive of Circle Economy. “Governments must urgently adopt circular economy solutions if we want to achieve a high quality of life for close to 10bn people by mid-century without destabilising critical planetary processes.” Marc de Wit, the report’s lead author, said: “We are still fuelling our growth in population and affluence by the extraction of virgin materials. We can’t do this indefinitely – our hunger for virgin material needs to be halted.” The report found that 100.6bn tonnes of materials were consumed in 2017, the latest year for which data is available. Half of the total is sand, clay, gravel and cement used for building, along with the other minerals quarried to produce fertiliser. Coal, oil and gas make up 15% and metal ores 10%. The final quarter are the plants and trees used for food and fuel. The lion’s share of the materials – 40% – is turned into housing. Other major categories include food, transport, healthcare, communications, and consumer goods such as clothes and furniture. Almost a third of the annual materials remain in use after a year, such as buildings and vehicles. But 15% is emitted into the atmosphere as climate-heating gases and nearly a quarter is discarded into the environment, such as plastic in waterways and oceans. A third of the materials is treated as waste, mostly going to landfill and mining spoil heaps. Just 8.6% is recycled. “This report sparks an alarm for all governments,” said Carolina Schmidt, Chile’s environment minister. “We need to deploy all the policies to really catalyse this transformation [to a circular economy].” Cristianne Close of the conservation group WWF said: “The circular economy provides a framework for reducing our impacts, protecting ecosystems and living within the means of one planet.” The report said increasing recycling can make economies more competitive, improve living conditions and help to meet emissions targets and avoid deforestation. It reported that 13 European countries have adopted circular economy roadmaps, including France, Germany and Spain, and that Colombia became the first Latin American country to launch a similar policy in 2019. China’s ban on waste imports aims to encourage domestic recycling, the report said, but has also stimulated the development of circular economy strategies in Australia and other countries which previously exported their waste to China. Janez Potočnik, a former European environment commissioner and the co-chair of the UN Environment Programme international resource panel, said the world needed to learn to do more with less and replace ownership with sharing, as is increasingly being seen with cars."
"The price of beer could double under unchecked climate change, as droughts and extreme temperatures cause barley yields to drop. That’s one conclusion of research we recently published in Nature Plants. We first became curious about barley, and the beer it produces, as this relatively minor crop was clearly affected by climate extremes yet had never caught the attention of climate scientists. And, unlike many other food crops, barley grown for beer is required to meet very specific quality parameters. Malted barley gives beer much of its flavour, yet if it is too hot or there isn’t enough water during critical growing stages, the malt cannot be extracted. This is why we gathered a team of scientists based in China, the UK and the US to assess what extreme drought and heat events may mean for beer supplies and prices. We were interested specifically in what would happen to barley when there was both extreme drought and heat during the growing season, something that will become more common thanks to global warming. We then modelled what this would mean for barley yields in 34 world regions which either produce or drink a lot of beer.  In more optimistic scenarios, where emissions are brought under control and warming is kept at a manageable level (what climate scientists refer to as RCP2.6), droughts and heatwaves might occur together in about 4% of the years. In the worst case scenario, where emissions and temperatures keep increasing, such extremes might occur in 31% of the years. These are global average results, however, which can hide significant regional variation. In affected years, barley yields would drop the most in tropical areas of Central and South America, and in Central Africa, for instance. In the same years, yields in temperate Europe would decrease moderately, or even increase in parts of the US or Russia. But the overall trend is clear: at a global level, barley yields will at best – under the optimistic scenario – decrease by 3%. And in the worst case scenario, yields will fall 17%. We know that climate change will mean less barley – but what about beer? One factor to consider is that barley is mostly used to feed livestock, and beer is ultimately more dispensable than meat. This means declining yields will hit beer production extra hard. Ultimately, our modelling suggests that during the most severe climate events, the price of beer would double and global consumption would decline by 16%, or 29 billion litres. That is roughly equal to the total annual beer consumption of the US. Even under the optimistic scenario of less extreme climate change, beer consumption would still drop by 4%. Again, price and consumption changes would vary widely from country to country, with the greatest price increases being concentrated in relatively affluent and historically beer-loving countries. In Ireland, for example, the price of a beer bottle would double under extreme climate change. In less wealthy countries, people would simply drink less beer under those circumstances. We predict a 32% drop in Argentina, for example. It is possible that more drought- or heat-tolerant barley cultivars may be developed in future, which would reduce the risk of climate change to supplies of beer. But these and other technological developments, or increases in stockpiling (or even prioritising beer over livestock), were beyond the scope of our study. While previous research has looked in detail at what climate change means for essentials like wheat or rice, less attention has been paid to so-called “luxury goods”. In our study, we took beer as one such example, to highlight the ways climate change will affect our lives.  We hope our results might attract further attention from various beer-lovers who actually have the power to do something about global warming. Seeing that climate change is affecting our lives in more ways than we imagined before, they might start to think about further strengthening global efforts to reduce emissions."
"
Share this...FacebookTwitterBy Kirye
and Pierre Gosselin
Recently Japanese scientist Dr. Kiyohiko Ikeda (@IkedaKiyohiko) retweeted about a newspaper book review appearing in the Sankei Shinbum, which reported on how Marc Morano’s best selling “The Politically Incorrect Guide To Climate Change” was hitting the book market in Japan.

今日の産経に、地球温暖化の不都合な真実がありました。いよいよ地球温暖化、CO₂削減とは何だったか、明らかにされています。国連の気候変動サミットも、色あせて、白々しく感じたものでした。風力発電のアホらしさは最初から分かっているのに、なぜ被害を拡大したのか。悪党よ pic.twitter.com/0yFnfS8KXL
— 由良　守生 (@zan4736511) October 8, 2019

Mr. Morano’s Politically Incorrect Guide book had been recently released in the Japanese version, translated from the English by Tadashi Watanabe, Professor Emeritus of Chemistry of the University of Tokyo and Professor of Tokyo University of Science Graduate School.
Mann lost in court
The Sankei Shimbun book review, authored by Shohei Nagatsuji, explains how this summer an event occurred and challenges the foundation on which the existing IPCC bases its CO2 global warming theory, but which went unreported in Japan. This August, the reliability of Dr. Michael Mann’s hockey stick graph was rocked after he had lost a defamation case against a Canadian researcher [Dr. Tim Ball], who had sharply criticized the hockey stick graph.
“Hundreds of factors” behind climate change
The Sankei Shimbun also reports how Mr. Marc Morano’s book -「地球温暖化」の不都合な真実』- presents the criticisms of Prof. Mann and the inside workings of IPCC.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Japanese daily explains how Morano’s book cites scientists who say “temperature is mainly determined by water vapor and clouds, so even if CO2 is doubled or tripled, the situation would be almost the same” and that there are in fact “hundreds of factors contributing to climate change.”

Marc Morano’s best selling “The Politically Incorrect Guide To Climate Change” now in Japanese.
All focus on CO2 is “misplaced”
The Japanese daily also says Mr. Morano’s book shows how scientists from the UK and New Zealand saying that putting all the focus on CO2 is ” misplaced”.
“…amazed at each chapter”
According to the Sankei Shimbun:
We recommend you take this book because it is easy to read. You’ll be amazed at each chapter. It is full of scientific controversies and scandals over global warming that are not well understood in Japan.”
No consensus
The Sankei Shimbun concludes that Mr. Morano’s book provides “an overall picture of the global warming issue” and that it is an issue which “can be viewed from multiple perspectives.”
Overall it’s a very positive, welcome review for Marc Morano’s “The Politically Incorrect Guide to Climate Change” here in Japan. Recently Morano’s book has climbed near the top of the charts for books under Environment.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGulfstream “barely impacted” by Arctic ice melt
By Die kalte Sonne
(German text translated/edited by P Gosselin)

Arctic ice melt barely impacting AMOC. Day After Tomorrow scenario remains fantasy, new study suggests. Figure: R. Curry, http://editors.eol.org/eoearth/wiki/File:OCP07_Fig-6.jpg; CC BY 3.0
Stefan Rahmstorf never tires of claiming the Gulf Stream system (AMOC, Atlantic Meridional Overturning Circulation) is being strongly weakened by the fresh water input of the melting Greenland ice. In his Klimalounge blog at the end of January 2019 he wrote:
 ”The physics behind how global warming and ice melt (both without a doubt caused by man) is slowing down the AMOC is understood …”
Yet, on April 26, 2019, Dukhovskoy et al published a new paper in the JGR Oceans, which concludes that Greenland’s meltwater is having little impact on the AMOC:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Role of Greenland Freshwater Anomaly in the Recent Freshening of the Subpolar North Atlantic 
The cumulative Greenland freshwater flux anomaly has exceeded 5000 km3 since the 1990s. The volume of this surplus fresh water is expected to cause substantial freshening in the North Atlantic. Analysis of hydrographic observations in the subpolar seas reveal freshening signals in the 2010s. The sources of this freshening are yet to be determined. In this study, the relationship between the surplus Greenland freshwater flux and this freshening is tested by analyzing the propagation of the Greenland freshwater anomaly and its impact on salinity in the subpolar North Atlantic based on observational data and numerical experiments with and without the Greenland runoff. A passive tracer is continuously released during the simulations at freshwater sources along the coast of Greenland to track the Greenland freshwater anomaly. Tracer budget analysis shows that 44% of the volume of the Greenland freshwater anomaly is retained in the subpolar North Atlantic by the end of the simulation. This volume is sufficient to cause strong freshening in the subpolar seas if it stays in the upper 50–100 m. However, in the model the anomaly is mixed down to several hundred meters of the water column resulting in smaller magnitudes of freshening compared to the observations. Therefore, the simulations suggest that the accelerated Greenland melting would not be sufficient to cause the observed freshening in the subpolar seas and other sources of fresh water have contributed to the freshening. Impacts on salinity in the subpolar seas of the freshwater transport through Fram Strait and precipitation are discussed.”
In the main text, it is stated:
“This result agrees with the previous study of Saenko et al. (2017), who also show that the GFWA of similar magnitude (and even double of this magnitude) has negligibly small impact on the SPNA thermohaline fields, barely impacting AMOC.”
GFWA means the meltwater anomaly from Greenland and SPNA of subpolar North Atlantic. A study from 2017 finds something similar, which of course does not get mentioned by Rahmstorf in January, 2019. The fresh water from Greenland is mixed down to depths of 1000 m and thus the amount is practically meaningless for the AMOC, the paper finds.
What now?
For years we have been hearing from certain circles of climate research that we are melting the Greenland ice sheet and thus a “Day After Tomorrow” scenario gets conjured up. But a very recent paper finds that this is not the case. And when we report on it, are we thereby questioning the “credibility of climate science”, or are we correctly reflecting the progress made in climate research because the work is getting cited? Climate alarmists are desperately trying to convey the wrong image of a monolithic “climate science”, which in reality does not exist at all.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Jena-Germany based climate science and renewable energies- critical European Institute For Climate and Energy (EIKE) has sent a cease and desist letter to Wikimedia headquarters in San Francisco demanding that the platform remove all the “false content” in the German language entry about the organization.

Slander: Wikipedia’s German site describes EIKE as an organization for “networking and public relations work for the organized climate denier scene”. Image cropped from Wikipedia here.
EIKE is a non-profit association with the statutory purpose of promoting science and research in the field of climate and energy. According to EIKE, “We pursue our statutory association purpose independently of political parties, religious communities, other associations or organizations.”
EIKE claims the German Wikipedia entry about its activities and members has very little to do with the reality and that the content was in large part written to mislead readers rather than inform them and to slander the institute. “The content of the Wikipedia entry is filled with falsehoods which results in casting EIKE in an extremely negative light,” the Jena-Germany based scientific think tank commented by e-mail.
“Almost every single claim made by the Wikipedia entry about EIKE is either maliciously misleading, grossly distorted or just outright false, wrote EIKE Vice President, Michael Limburg in an e-mail.  “The Wikipedia entry was designed to produce a contemptuous image of the organization with the aim discrediting it.” The list of deletions demanded by EIKE is 7-pages long!
“Climate denier scene”
In one example, the Wikipedia entry claims that the EIKE “is described by independent voices from science and media as the center of the politically active and organized scene of climate deniers in Germany” (see image above) and that “its goal is to promote systematic attacks on climate science’s findings.”
“This is absolutely false and malicious,” EIKE responded by e-mail when asked for comment.
In the long grievance to Wikipedia, the attorney representing EIKE wrote that the claim made by the Internet platform’s authors was “made up”, “untrue and unlawful”, adding: “My client does not deny climate change, and their goal is not to systematically attack the findings of climate science.”
Among the many other alleged false statements made at the Wikipedia site was also that EIKE “pretends to be scientific, deliberately disseminates misinformation and tries to influence parties.” In the cease and desist letter, the attorney representing EIKE called that statement “false” and “unlawful”, adding that EIKE is independent of all political parties and that EIKE “conducts its own research on climate and energy and publishes it in scientific journals and at international scientific congresses.”
Renowned speakers at EIKE conferences


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Over the years, EIKE has organized around a dozen international climate and energy conferences, which often feature many renowned, yet dissenting scientists, such as astrophysicists Prof. Nir Shaviv of the University of Jerusalem and Prof. Henrik Svensmark of the Danish National Space Institute (DTU Space) in Copenhagen. Other speakers have included leading oceanographer Prof. Nils-Axel Mörner.
EIKE also notes that the conferences are open to any scientists, and that it is not solely a place where “climate deniers” meet.
Unlawful Holocaust slandering
Under the Wikipedia entry subheading “Grundsätze des Vereins” (principles of the association) it states that EIKE is “an organization of climate deniers” – a claim that is not only false but also “unlawful”, the EIKE attorney wrote. Climate alarmists routinely use the “denier” term in order to slander and equate global warming skeptics to Holocaust deniers.
Big Oil/coal conspiracy
In the Wikipedia entry about EIKE, it is repeatedly suggested EIKE is funded by the oil and coal industry and the Koch Brothers through its links to CFACT, Heartland Institute, and other organizations.
The attorney representing EIKE underscored: “EIKE a scientific institute and think-tank, organized as a non-profit organization, with the sole purpose of presenting facts concerning climate and energy without any ideology. Yet, it is suggested that my client financially represents the interests of the oil and coal industry, which is demonstrably not true.”
In total, EIKE sent a list 7 pages long of false statements and misleading claims to Wikipedia demanding that they be removed.
Intent to unjustly inflict damage to reputation
EIKE has been working for sometime to get the needed corrections implemented at the Wikipedia site, but without success. Officials at EIKE say the falsehoods and deceptive claims platformed by Wikipedia risks inflicting great damage to their reputation and the overall perception among the unknowing public.
EIKE officials recently sent a cease and desist letter to Wikimedia head offices in San Francisco. But according to EIKE, they received a response from Wikimedia that said there were no German speakers there, and so they couldn’t help.
Wikipedia is a worldwide platform whose content is regularly posted in almost every major language worldwide. Over the years it has been sharply accused of poor quality control and political bias, especially concerning hot-button political issues such as climate science.
Share this...FacebookTwitter "
"Sadiq Khan will promise to put London on a par with Scandinavian capitals by making it a carbon-neutral city by 2030 if he is re-elected as mayor of the capital later this year. The Labour politician’s pledge to tackle air pollution forms part of his first major pitch to voters in the upcoming mayoral race, in which he will go up against Conservative, Lib Dem, Green and independent rivals.  Khan’s strategy to go carbon-neutral forms part of his vision for a “green new deal” for London, which he would roll out during a second term. This will involve a 10-point plan that will be outlined in his manifesto before the mayoral election on 7 May. In a speech to the Fabian Society new year conference in central London on Saturday, he is expected to say the 2030 target is essential to prevent the poorest communities being affected by poor air and the thousands of premature deaths in the capital each year. “My pledge to deliver a green new deal for the city with a target for London to be carbon-neutral by 2030 will help tackle the climate emergency and the air pollution crisis. “Some may say that a 2030 target isn’t achievable but I say we can’t afford not to try. This is a matter of social justice because it’s the poorest communities that are being hit hardest,” said Khan, who became the first Muslim mayor of any western capital city when he was elected in 2016. The majority of the biggest political parties in the UK have set ambitions for the country to reach net-zero emissions by particular dates that range from the 2030s through to the 2050s. Despite Labour activists passing a commitment at their autumn party conference to work towards net-zero carbon emissions by 2030, the party ended up softening its pledge for last month’s election after pressure from trade unions and the impact it would have on industrial jobs. Instead they offered to find a “path” to the date of 2030. The Conservatives have a policy of hitting net-zero by 2050 and the Liberal Democrats pledged a date of 2045. The Green party has pledged to go carbon-neutral by 2030. Across Europe, three Nordic cities – Copenhagen, Oslo and Stockholm – have made firm commitments to be carbon-neutral or fossil fuel-free between 2025 and 2030. Bristol has a net-zero target of 2030, as does Edinburgh, but with a backstop date of 2037. Khan has said green commitments will be a dividing line between his campaign and his nearest rival, Conservative Shaun Bailey, who is behind him in the polls. A survey by Queen Mary University of London’s Mile End Institute found Khan was the first preference candidate of 43% of Londoners. Bailey is on 23%. “The election on 7 May is a two-horse race between me and the Tory candidate,” Khan told the Guardian. To achieve a carbon-neutral status for London, he said City Hall would lead the way in implementing tougher environmental standards, moving away from fossil fuels and reducing waste. Public transport will become greener, he said, and he will commit to trying to get billions of pounds worth of government investment. One example to help reduce emissions is retro-fitting houses to make them more energy-efficient."
"The Guardian and Observer 2019 charity appeal has raised more than £1m for its climate emergency campaign in support of projects which aim to plant and protect trees, woodlands and rainforest. More than 13,000 readers donated an average of £75 each to the appeal, which totalled £1,015,000 on Thursday night. The money will be shared between four charities: Woodland Trust, Trees for Life, Trees for Cities and Global Greengrants Fund UK.  The donations will be spent on initiatives promoting social and climate justice through natural climate solutions, from safeguarding rainforests in the Amazon basin to rewilding the Scottish Highlands and greening Britain’s towns, cities and countryside. Katharine Viner, the editor-in-chief of the Guardian said: “It’s wonderful that our annual charity appeal has raised more than £1m for a cause that’s so clearly close to what our readers care about most. “Because of the outstanding generosity shown by Guardian and Observer readers, these inspiring charities will be able to protect and renew forests and green spaces, both across the UK and in the Amazon basin. Thank you to every single reader who donated – your generosity is so important.” Eva Rehse, executive director of Global Greengrants Fund UK, praised readers for what she called a collective act of generosity and solidarity for the planet. “It gives us hope that we can tackle the collective challenge of the climate crisis together,” she said. Steve Micklewright, the chief executive of Trees for Life, said: “A huge Highland thank you to everyone who so generously donated. Thanks to their amazing support, readers will enable Trees for Life to reconnect people with nature through volunteering days and weeks and educational opportunities.” He added: “Change needs to happen at the landscape scale but small actions, such as planting a tree, can make a world of difference.” Hundreds of readers left messages explaining why they had donated. Common themes were frustration with lack of government urgency in tackling climate change, and horror at the bushfires in Australia. Some said they had been inspired by the appeal to plant a tree in their garden. Donor Eileen Dale wrote: “I want to do my small bit to protect the environment, help the survival of species and mitigate the climate crisis for my grandchildren and all their peers around the world.” Another donor, Ruth Baber, wrote: “I [contributed] my winter fuel payment because this is such an important issue. Planting trees with Trees for Life was a transformative week for me. Trees are vital to combat the climate emergency as well as benefiting physical and mental health.” The 2019 Guardian and Observer appeal was the fifth in succession that has raised more than a million pounds. The 2018 appeal for immigration charities which helped uncover the Windrush scandal raised £1.1m. In 2017 £1.7m was raised for youth homelessness, and £2.6m and £1.6m for refugee causes in 2015 and 2016 respectively. The appeal closed at midnight last Sunday. The final total is expected to be slightly higher as a handful of stray cheques come in. The £1,015,000 figure includes estimated gift aid of £168,000. The appeal’s donation handlers, Charities Trust, will be paid a fee amounting to 3% of the gross total."
"Cardiff council is proposing to charge non-residents £2 to drive into the city centre and use the proceeds to improve the creaking public transport system in and around the Welsh capital. Council leaders and public health experts are arguing that a relatively modest congestion charge could help change perceptions of driving without overly penalising those who need to travel by car. The idea was outlined during the unveiling of a £2bn “transport vision” in Cardiff city centre on Wednesday.  Leaders said the 10-year plan would help to tackle the climate emergency, reduce congestion and improve air quality. They claimed imposing a charge on motorists could lead to the same sea change that followed the introduction of charges for single-use plastic bags. The council leader, Labour’s Huw Thomas, said: “The future success of Cardiff hinges on getting transport right in the city. There can’t be anyone who is happy with the current state of affairs, which is why we are bringing forward this ambitious 10-year vision and why we are beginning an honest conversation about how it’s paid for.” Asked if a £2 charge was enough to change behaviour, Thomas said such a charge would break habits and generate significant funding for transport changes without penalising people too much. The council said it would not introduce charges before improvements had been made to public transport, and anticipated that there would be exemptions – for blue badge holders, for example. 1.Our vision for #Cardiff is a city linked by the infrastructure needed to travel by bike, train and rapid bus transport around and across it, and on into the wider city region – it looks like this.#10ThingsAboutCardiffTransport2030🚋 🚌 🚲 pic.twitter.com/Jlyqzuwe5e Caro Wild, the council’s cabinet member for strategic planning and transport, said Stockholm had introduced a modestly priced congestion charge that had successfully changed behaviour. The Labour councillor said: “Cardiff’s current transport network was designed half a century ago for a city of 200,000 people. Today, once commuters, shoppers and visitors are taken into account, our city has a daily population of almost half a million. No wonder our transport network is creaking – it’s no longer fit for purpose. “If you look at it from the point of view of the average Cardiff resident driving within the city to work every day, struggling for their bit of road space with the 80,000 other car commuters from outside the city’s boundaries, then absolutely, traffic congestion, traffic pollution and a public transport system which struggles to adequately serve the people who live and work here are all issues of major concern. “We are living in a world where the climate emergency is changing how we feel about our future. I have become more and more convinced that to undertake the kind of radical change required we will need to investigate bringing in some form of charging mechanism to fund the infrastructure required in the city and the wider region. “One option might be a simple, universal, £2, low-charging system applied to non-Cardiff residents who drive into the city, which could reduce congestion while raising money towards paying for improvements to our transport network. We need to get people out of cars and on to public transport. To do that we need to give them the best public transport options. And to do that we need to raise money to pay for them.” Wild said a congestion charge was not the only option and other possibilities would be looked at over the next year. He said: “No charge will be put in place until that business case is completed and all options have been reviewed.” The white paper unveiled by the council lists a series of projects that could revolutionise public transport options in Cardiff and the region, including: Opening up new tram/train routes and stations. Introducing new park-and-ride sites. Lowering the cost of bus travel significantly. Delivering safer walking and cycling routes. An electric bike pilot scheme. Fiona Kinghorn, the executive director of public health for Cardiff and Vale University Health Board, said: “We fully support the ambition to increase walking and cycling in Cardiff, provide major enhancements to the public transport network and reduce harmful air pollution.”"
"Last month, as I travelled to see family for a very mild Christmas in the UK, I thought about the bushfires simultaneously raging across Australia. They are just one example from a long series of extreme weather events in 2019, including cyclones in India and Bangladesh that displaced more than three million people, Cyclone Idai, which killed more than 1,000 people in southern Africa, floods that displaced tens of thousands of people in Iran, and entire townships laid to waste by Hurricane Dorian in the Bahamas. The year ended with reports of record rates of Arctic ice melt that, through positive feedback effects, are likely to intensify climate heating and impact the future of humanity. In the face of global catastrophe, it’s hard not to feel daunted. What can I, an individual, do to address such a crisis? Understanding that my daily actions are partly responsible for climate change, I feel a gnawing sense of sense of individual guilt.  It’s perhaps not surprising that I feel like this. I was a child of the 1980s and a teenager in the 90s: my formative years were during something like the most individualistic age in history. While I learned times tables at primary school, Margaret Thatcher was telling the nation there was no such thing as society. During my teenage years, product advertising and globalisation brought a new age of hyper-consumerism, as we were bombarded with education programmes to build self-esteem and TV shows such as Big Brother, The X Factor and The Apprentice, which all glorified self-aggrandisement in subtly different ways. Developing human minds are like sponges and ours were submerged in ever more individualistic language. Phrases such as “unique”, “personal”, “self”, “me” and “mine” were used with increasing frequency in lyrics, TV shows and books. This immersion took its toll: analysis of data from almost 80 countries  shows how the majority have shown marked increases in individualistic attitudes over recent decades. Having a strong sense of self can be useful, but excessive individualism has its costs. The more we see ourselves as discrete entities, the more likely we are to feel isolated and lonely and to show “selfish” behaviours. As a consequence, rates of anxiety and depression are rising across the world, while the climate and biodiversity crises deepen ever further. Yet times are changing. In the last decade, we may have seen individualism peak. Scientific discoveries have revealed how the perception of a distinct self is an illusion. Our bodies are made from materials that were once parts of countless other organisms, from ancient plants to dinosaurs. Most of our 37tn cells are directed by a genetic code that is a shared heritage not just of humanity but all of life on Earth. You might think your life experiences define you, but the neural networks in your brain that encode these are changing constantly – you are not even the same person you were when you started reading this article. And the new science of social networks shows how we are linked together so closely that ideas, behaviours and preferences flow between us in a way that makes it unclear where one mind ends and another begins. And people are finding new value in being part of groups, whether it is through activism (Extinction Rebellion, youth strikes, political party memberships) or leisure activities (book clubs, festivals, park runs). New research shows that when people have a broader sense of group identity (for example viewing themselves as global citizens, rather than embracing nationalism), they tend to be more likely to engage in pro-environmental behaviours, such as reducing their carbon emissions, buying sustainably and volunteering. A new age of collectivism seems to be dawning – and not a moment too soon. So what can be done to make people truly embrace being part of a group? In answering this question, it is worth bearing in mind that the evolutionary history of our brains means we are susceptible to certain biases. When populations face shocks such as environmental catastrophe or social unrest, they are more likely to strengthen bonds between their “in-group” members, while caring less about those outside of the group. This is a defence mechanism to help groups pull together and overcome hardship. Social research has shown that it operates at the country level, too – countries facing crises are more likely to show prejudice towards outsiders and elect authoritarian leaders. Environmental catastrophes are only expected to worsen under climate change, which means nationalism could grow purely due to this evolutionary bias. Yet, is this a sensible response? In 2020, we live in a highly globalised world, with cross-border flows of money and people, as well as environmental impacts such as the climate crisis and air pollution. If we bond together within nations but with less regard for the welfare of others beyond those borders, we will end up fouling the global commons, ultimately to our own detriment. Yet there is hope. New research shows how we can escape individualism. Outdoor community activities increase both our psychological connectedness to others and to the natural world. Escape cities to go for a walk with family or friends, or volunteer in a garden or park near you as often as you can. Meditation is proven to alter neural networks in the brain and reduce self-centredness, and solitary activities such as reading and playing computer games have been shown to increase empathy with others. We can all do something small to be part of something bigger and help solve our global problems. Let’s all get on with it. • Tom Oliver is professor of ecology at the University of Reading, and author of The Self Delusion, which will be published on 23 January."
"Last week it was reported that rising ocean temperatures and changing sea currents are causing leatherback turtles’ journeys from nesting to feeding grounds to double in length. After laying their eggs on some beaches, the turtles must move to cooler waters to feed, but higher temperatures mean some are having to swim further to reach suitable areas, according to France’s Hubert Curien Institute.  Pikas, small mammals native to North America, are increasingly moving off high-alpine boulder piles to adjacent forests. A study in the Journal of Mammology notes that the cool, moist, rocky habitat they require is getting hotter, drier, and less snowy. Because they live high in the mountains, when their terrain becomes inhabitable, there’s nowhere left to go. Warmer temperatures are causing monarch butterflies’ southern migrations to be delayed by up to six months. Columbia University’s Earth Institute explains that this is causing migrations to fall out of sync with the bloom time of the nectar-producing plants the monarchs rely on for food, contributing to the 95% decrease in their numbers in the last two decades. Puffins in the Gulf of Maine normally eat white hake and herring, but warmer oceans are causing these fish to move north. The puffins are trying to feed their young butterfish instead, but they are unable to swallow them. Over the past 20 years, conservationists calculate that fledgling survival rates have declined by 2.5% a year. The Scottish Association for Marine Science says that the melting of sea ice is affecting the wider food chain, as zooplankton feed on the algae growing on sea ice. These microscopic creatures are eaten by fish and shrimps, which are eaten by seals, ultimately forming the basis of 70% of polar bears’ diet, according to one science journal."
"
Share this...FacebookTwitterGerman flagship daily Frankfurter Allgemeine Zeitung (FAZ) publisher Holger Steltzner wrote in an online commentary that the rescue of the global climate” has turned into a religious movement for “a large portion of German society”.
In his commentary, Steltzner remarks that even questioning the hundreds of billions spent thus far with hardly any progress in CO2 reductions to show is enough to get yourself branded as a heretic.
Freedom of dissent under attack
The FAZ publisher also questions the branding skeptics of manmade global warming as “climate deniers”, thus comparing them to Holocaust-deniers. He wonders: “Is this just the thoughtless use of language that abuses the historical break with civilization of the Shoah through banalization?”
Dissent over climate science in Germany is harshly scorned and the media and science community do not tolerate it.
In his commentary Steltzner reminds that man is in fact just one component in the complex climate system where huge natural factors are at play, and that the vast majority of skeptics do not even deny the climatic changes taking place today and how they are just as concerned about the environment as anyone else is.
Communist central planning
The trained business finance specialist and FAZ publisher writes that the German Energiewende (transition to renewable energies) has led to “price distortions, threatened grid stability and the writing off of modern power plants” and is accurately characterized as “eco-central planning”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Causing more environmental harm than good
And what is even worse is that the Energiewende is likely causing more environmental harm than good. For example forests are being cleared to make way for the industrialization of the country’s once idyllic landscape, destroying biotopes with it. Stelzner adds that many Germans are filling up their cars with fuel that is 10% bio-fuel – which in turn leads to orangutans being shot dead so hat palm oil plantations can operate in places like Indonesia.
And according to Steltzer: “One fifth of Germany’s agricultural land is used for growing bio fuels.”
Another example of Germans trying to ease their conscience is the consumption of tofu in place of meat. He writes: “But weren’t there rainforests in Brazil, where today one soy plantation follows the next?”
Other examples Steltzner cites are avocado plantations in Mexico or the lithium-ion battery “which is supposed to save the climate, and whose raw material extraction in Africa, Russia or South America is devastating entire regions.”
“Illusion, religious zeal”
Steltzner also comments that it seems that environmental organizations have taken a page from the Vatican playbook, where in the past “believers could even acquire letters of indulgence for deceased people in order to wipe out sin penalties in purgatory.”
“Today the purchase of carbon dioxide certificates protects you from being plagued by a bad conscience while shopping in London,” Steltzner comments.
Though he perceives climate change as a real challenge, Steltzner summarizes by calling on Germany to “abandon the illusion that it can rescue the planet” and that “climate protection must not be driven with religious zeal”.
Share this...FacebookTwitter "
"This is an article from Curious Kids, a series for children of all ages. The Conversation is asking young people to send in questions they’d like an expert to answer. All questions are welcome: find out how to enter at the bottom.  Why do hens still lay eggs when they don’t have a mate? – Finley, age ten; Evie, age eight; and Jonah, age five, Cambridgeshire, UK Thanks for the question Finley, Evie and Jonah. Humans have been looking after chickens for thousands of years – and we have gradually learned what to do to make sure our hens keep laying eggs for us to eat.  For one thing, we have gradually changed hens through breeding, to make sure that they don’t stop laying eggs in the winter (hens used to do this naturally).  We’ve also learned that if we keep taking the eggs away from the hens, they will keep laying them, because of the way their bodies work. But for you to really understand why, I’ll have to explain a bit of biology.  In our world, creatures have many different ways of trying to have babies. But one thing is almost always the same: a special cell from a female (called the egg cell) and a special cell from the male (called a sperm cell) have to join together to make the baby.  Each of these special cells contains half of the instructions to make a new creature (the baby).  Usually, the male makes lots and lots of his special cells, all with tails to help them move. He sends lots of them into the female, in the hope that one will swim all the way to the female egg cell and join with it: this is called “fertilising the egg”.  The female makes very few of her special cells and gives them the size and covering they need to let a male sperm cell join with them to make one fertilised cell. Then, the fertilised egg can use the full set of instructions – half from the egg cell and half from the sperm cell – to start growing into a baby.  In animals like humans, the baby grows a lot inside the female before it is born.  But in birds like chickens, the egg cell is put into a huge package to feed and protect fertilised eggs while they grown into a baby. We call the whole package “the egg”. It takes about a day to wrap all the packaging around the egg cell. Most of the layers around the egg cell are soft, but the final wrapper is the hard shell. The shell takes the longest time to make (about 19 hours). The chicken has a clever way of “lending” hard material (calcium carbonate) from her bones to make the shell. She then has to replace the calcium carbonate in her bones by eating more at the next meal. The female has to be very careful about when she uses her precious eggs cells to try and make a baby. Lots of animals take one egg each month out of the store they have inside their body. Once its out of the store, the egg goes to a part of their body where a sperm could join up with it to fertilise it.  Other creatures, including many kinds of birds, choose a time to release several of their eggs to try and make a group of babies all at once (often called a “litter” for animals and a “clutch” for birds).  The size of a clutch is different for different kinds of bird: for chickens, it is around 12 eggs. In nature, when the female chicken has laid about 12 eggs, she stops releasing egg cells from her body stores. But if humans keep taking the eggs away, the female chicken will keep laying more eggs. When the female releases the egg cell from her body store, she does not know whether a male sperm cell will come and fertilise it or not. But her body still sends them out from the store, just in case there is sperm to fertilise the egg.  In order not to waste eggs, the female of many kinds of creature (ranging from insects, through garden birds to reindeer) stop releasing eggs from their body store for much of the year, to make sure the babies don’t arrive in the winter time when it is difficult to get enough food for them.  As I mentioned before, humans have gradually changed female chickens over many years so that their bodies don’t stop releasing eggs in the winter, but some traditional breeds still do go “off lay”. Hello, curious kids! Have you got a question you’d like an expert to answer? Ask an adult to send your question to us. You can: * Email your question to curiouskids@theconversation.com 

* Tell us on Twitter by tagging @ConversationUK with the hashtag #curiouskids, or

* Message us on Facebook. Please tell us your name, age and which town or city you live in. You can send an audio recording of your question too, if you want. Send as many questions as you like! We won’t be able to answer every question, but we will do our best. More Curious Kids articles, written by academic experts: What’s the history of aircraft squawk codes and how do they work? – Daniel, age 12, Perth, Australia How can chickens run around after their heads have been chopped off? – Gaelle, age four, Bristol, UK Why does English have so many different spelling rules? – Melania, age 12, Strathfield, Australia"
nan
"Australian company bosses are becoming increasingly concerned about the climate crisis and are expecting tough economic times in the year ahead, a new survey shows. Global accounting firm PwC’s annual survey of CEOs shows bosses are preparing to cut jobs and don’t think Australian business and government is doing enough to deal with global heating – a dismal picture that is set to get worse once the effects of the past month’s deadly bushfires take hold.  Economists expect the damage to industries including tourism, agriculture and retail from the unprecedented fires to carve up to 0.2 percentage points from Australia’s already anaemic growth figures. Experts say the damage to the tourism sector is likely to top $1bn, and there is little likelihood that sales figures will show that Christmas revived a retail sector struggling to hold on as consumers who haven’t enjoyed a pay rise for years keep their wallets firmly shut. In September and October, before the bushfires peaked, PwC surveyed 1,600 CEOs around the world, including 117 Australians. Even then, 65% of Australian bosses said climate change was a major threat, up from 60% last year and 43% a decade ago. “The fact that it’s actually now in the top 10 of our CEO survey, not only in Australia but in many other markets, says this is something that’s not going away and it’s a genuine threat to our economy and our communities,” PwC Australia’s head of energy, utilities and resources, Mark Coughlin, said. “We actually just have to get on with it.” The proportion of Australian CEOs expecting global economic output, or gross domestic product, to drop has skyrocketed from 7% two years ago to 59% this year. With confidence that customers will spend thin on the ground, a whopping 77% are planning “operational efficiencies” – corporate code for cuts. This includes a quarter of CEOs who plan to cut jobs, a potential further blow to an economy where the unemployment rate remains stuck above 5%. Economists are pessimistic about the chances of an improvement any time soon, with Deloitte Access Economics predicting GDP growth will remain stuck at 2% for the rest of the financial year – well short of the 2.75% predicted by the Morrison government at the last federal budget and less even than the 2.25% estimate delivered in December. ANZ estimates the bushfires will carve o.1% to 0.2% off GDP growth, but the bank’s chief economist, David Plank, said the full effect wouldn’t be visible until GDP figures for March were released in June. The bushfires are unusual because natural disasters usually have little effect on GDP, which Plank said was a “pretty flawed way of measuring these things”, as it didn’t take into account the losses of forests and animals or people’s homes and businesses. “We basically said it’ll be a larger impact given the sheer size of the event and the global news around it,” he said. He said ANZ credit card data indicated a “quite weak” Christmas shopping season – further bad news for a retail sector rocked by a series of failures, including the collapse last week of fashion chain Jeanswest. Some of the weakness may be due to the rising popularity of Black Friday moving sales forward into November, and some may be due to smoke haze, Plank said. “It’s very hard to disentangle – I don’t think we’ll ever be able to,” he said. Australian Tourism Industry Council executive director Simon Westaway said the bushfires would cost his sector “at least $1bn through the firestorms and down-the-line impacts”. He said there had been an immediate “significant drop in domestic travel to many Australian regions, fire affected or not”. “It has remained hard to get a full estimate but based on the collective insights coming from the major tourism and accomodation bodies it will rise above $1bn, not fully factoring in retail and hospitality spend losses.” The fires also hit farmers hard, forcing them to shoot thousands of injured animals and disrupting the dairy industry in southern NSW. Bega chairman Max Roberts said milk was now getting off dairy farms but getting to and from the company’s processing plant remained difficult because the road south to Victoria remained cut. Trucks bringing supplies in and products out of the factory were detouring through Canberra, he said. “With our current rules on log books it makes a one-day trip into a two-day trip,” he said. “There’s certainly a cost associated with that but it’s not insurmountable.” He said the fires cut all three main highways in the area at the same time – an “unusual” event, even though in the past two out of three have been simultaneously blocked by floods. “It’s an event that will change how we do things,” he said. “I think hopefully the whole debate about how we handle climate will get some sensibility about it.” However, PwC’s survey shows that just 12% of Australian bosses think government and business are working together effectively to deal with climate change risks, a figure that has barely moved in five years. “The public discourse in Australia has been very challenging … around energy, climate, etcetera,” Coughlin said. “That really doesn’t help. When I go to meetings around the globe, particularly in western Europe, climate sciences, risks, opportunities etc has been part of the dialogue for a decade or more. “They’re talking much more about net zero [carbon emissions] where we’re debating the impacts or otherwise.”"
"The electricity sector is experiencing a profound disruptive shock. This is due to technological innovation including the falling costs of renewables and energy storage, along with tougher environmental policies and regulatory reform.  These changes are most apparent in Australia, the EU and parts of North America, where once-powerful utility companies are struggling or restructuring to survive. But, as I’ve looked at in a recent report, decision-makers elsewhere are asking whether these power markets are outliers or if they herald a global shift. Global investment in renewable energy – excluding large hydropower – was just under US$279 billion in 2017, a rise of 2% on the previous year. Wind and solar account for most of this. In fact, as technology and installation becomes cheaper, non-hydro renewables accounted for 61% of all the new installed power capacity (that’s including all fossil fuel, nuclear and hydro) across the world in 2017. If we are to address climate change, such changes must continue. While the construction of wind and solar was initially stimulated by decarbonisation policy, now it is driven by economics. As renewables continue to be deployed, they become ever cheaper to build and install. Solar is already at least as cheap as coal in Germany, Australia, the US, Spain and Italy. By 2021, it is also expected to be cheaper than coal in China. Integrating all this new power may become costly. National power systems have been designed for centralised coal or gas power stations, after all, which can more easily be switched on and off to ensure supply meets demand. Things are much more challenging when renewables are involved, as the sun doesn’t always shine, and the wind doesn’t always blow. Innovations in energy storage and digital technology promise to keep these costs down, but the big traditional utilities are failing to keep pace. This has left new actors free to provide new technologies and business models. Storage is a key technological element of the new system. Fortunately, the development of electric vehicles (EV), to address climate change and localised pollution, is being seen as a key driver of change for transport and power sectors. EV sales are set to increase dramatically, stimulated by recent government targets and policy support, while the prices of lithium-ion batteries decline sharply.  A plethora of large and powerful car manufacturers are getting into electric vehicles, prompted by government sales targets and the speed at which the total cost of owning an EV is approaching that of a traditional petrol car. Honda wants two-thirds of its sales to be electric or hybrid by 2030, BMW is aiming for 15–25% by 2025, while both Volvo and Jaguar Land Rover are targeting 100% by 2020.  Many of these companies are now making use of their manufacturing capabilities and moving into selling home storage units for electricity, which aren’t too different from an electric car’s battery. These storage units mean that people with solar panels will be able to consume more of their own electricity. This is further reducing the market for traditional firms and creating new competitors as some of the world’s largest manufacturing companies enter the power sector for the first time. As in many other sectors, digitalisation is another disruptive change. Smart meters in particular mean energy firms can better monitor and understand their customers, which enables even more flexibility – imagine energy supplies tailored to individual households and times of day.  These increasingly complex electricity systems will rely on machine learning algorithms to know when and where energy will be needed. Internet giants like Google and Amazon are already piloting and exploring the opportunities. Who would bet against Amazon becoming a major power supplier in the next decade? Blockchain technology could also enable a peer to peer energy market, allowing neighbours to sell excess power to one another and potentially further reducing the role of traditional firms. Over the past few years, there have been significant changes in the power sector, resulting in declining profits and the restructuring of traditional utilities. However, looking forward, the electrification of the transport and eventually heat sectors, and increasing digitalisation is likely to lead to far more significant disruption than we have seen to date. This will bring in a whole new set of companies and potentially engage consumers like never before."
"
Share this...FacebookTwitterScientists (Bragato and Holzhauser, 2019) find natural catastrophes like tornadoes and earthquakes and pandemics like plague, cholera, and influenza “concentrate in the periods of ice expansion in Europe” whereas periods of economic expansion and a lower incidence of natural catastrophes and pandemics occur during deglaciation phases, or warm periods. Century-scale cooling can be elicited by volcanism.

Image Source: Bragato and Holzhauser, 2019

Image Source: Bragato and Holzhauser, 2019
The conclusion that volcanism can trigger centuries of global-scale cooling – and that the Little Ice Age cooling was forced by explosive volcanism  – has also been postulated by McGregor et al., 2015.

Image Source: McGregor et al., 2015
Share this...FacebookTwitter "
"
Share this...FacebookTwitterEarlier Arctic warmth unexplained: In Franz Josef Land it was several degrees warmer in early 1930s than today
By Die kalte Sonne
(German text translated/edited by P Gosselin)
In January 2019, a paper by Andrzej Araźny et al appeared in the journal Theoretical and Applied Climatology, in which the researchers evaluated the weather data from four scientific expeditions to the Arctic Franz Josef Land.

Chart Source: A comparison of bioclimatic conditions on Franz Josef Land (the Arctic) between the turn of the nineteenth to twentieth century and present day.
The Araźny team also came across an unusual heat that was registered during a trip in 1930/31 when it was 4.6 °C warmer than the modern average in 1981-2010. The authors explain that there have been two phases of warmth in the Arctic in the last 140 years. The first spanned from 1920-1938 and the second began in the 1980s or 90s. Both heat phases have a similar course, so that the proportion of natural versus anthropogenic climate drives is unclear.
Araźny and colleagues demand that climate models address this question more intensively in order to finally close the large gaps in understanding in the Arctic climate system – also with regard to attribution.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




What follows is the abstract of the study, whose pdf can be downloaded free of charge:

A comparison of bioclimatic conditions on Franz Josef Land (the Arctic) between the turn of the nineteenth to twentieth century and present day
The paper presents the variability of meteorological conditions: air temperature, wind speed and relative air humidity; and biometeorological indices: wind chill temperature, predicted clothing insulation and accepted level of physical activity on Franz Josef Land (in Teplitz Bay and Calm Bay) in the years 1899–1931. It employs meteorological measurements taken during four scientific expeditions to the study area. The analysis mainly covered the period October–April, for which the most complete data set is available. For that period of the year, which includes the part of the year with the Franz Josef Land’s coldest air temperatures, the range and nature of changes in meteorological and biometeorological conditions between historical periods and the modern period (1981–2010) were studied. The data analysis revealed that during the three oldest expeditions (which took place in the years 1899–1914), the biometeorological conditions in the study area were more harsh to humans than in the modern period (1981–2010) or similarly harsh. In contrast, during the 1930/1931 expedition, which represents the Early Twentieth Century Warming (ETCW), conditions were clearly more favourable (including predicted clothing insulation being 0.3 clo lower and 4.0 °C higher wind chill temperature than conditions observed nowadays).”
In the discussion the authors address in detail the Arctic warmth phenomenon of the 1930s:

In approximately the last 140 years, there have been two periods of significant temperature increases in the Arctic. The first began in around 1918–1920 and lasted until 1938 and has been called the ‘1930s warming’ (Bengtsson et al. 2004). Other works have referred to this period as the ‘Early Twentieth Century Warming’ (ETCW, Brönnimann 2009) or the ‘Early Twentieth Century Arctic Warming’ (ETCAW, Wegmann et al. 2017, 2018). Our results confirm the observations for the last expedition from the historical study period in 1930/1931. These years covered the warmest part of the ETCW (Table 3, Fig. 4). In turn, the second increased warming of the Arctic began around 1980 (Johannessen et al. 2004) or according to Przybylak (2007) in about the mid-1990s. Changes in overall atmospheric circulation have long been believed to have been the cause of the ETCW (e.g. Scherhag 1937). As the modern climate warming (since 1975) has progressed in a largely similar manner to the progression of the ETCW (Wood and Overland 2010; Semenov and Latif 2012), there has been renewed interest in the insufficiently well-explained causes of the ETCW using the latest research methods, including, primarily, climate models. An analysis of the literature shows that the cause of such a significant warming in the present period is still not clear. There is even controversy over whether the main factors in the process are natural or anthropogenic, although the decided majority of researchers assign a greater role to natural factors (Bengtsson et al. 2004; Semenov and Latif 2012). It would appear that the greatest differences of opinion on the causes of the ETCW are to be found in works presenting climate models (see, e.g. Shiogama et al. 2006; Suo et al. 2013), which is an excellent illustration of the still insufficient knowledge of the mechanisms governing the Arctic Climate System.”

In the conclusion, the authors compare the warmth of the 1930s to today’s values:
…during the 1930/31 expedition it was 4.6 °C warmer than the years 1981–2010.”
Share this...FacebookTwitter "
"It is perhaps a cruel irony that, on the same day the Intergovernmental Panel on Climate Change released a landmark call for urgent action, Jair Bolsonaro surged to victory in the first round of Brazil’s presidential elections. Although the leader of the far-right Partido Social Liberal did not achieve the 50% of the popular vote required to win outright, and will now have a run-off against Fernando Haddad of the Partido dos Trabalhadores (Workers’ Party), his rise has posed some painful and divisive questions both within Brazil and beyond. Bolsonaro has openly spoken of the need for a military coup and has a record of racist, misogynistic and homophobic views. He is often compared to Donald Trump in the US, and such parallels can also be seen in the protectionist economic doctrine Bolsonaro has adopted in this election, for instance a promise to end the banana trade with Ecuador to protect Brazilian producers. 


      Read more:
      Brazil: can its poorest region call a halt to Jair Bolsonaro's dangerous politics?


 The electoral success of this divisive figure leaves Brazil at a crucial turning point. There have already been numerous analyses of what this could mean for Brazilian politics – but what could it mean for the environment?  Despite Bolsonaro’s campaign being based on personality as much as policy, it is possible to find some relevant promises – and they aren’t good news. For a start, Bolsonaro has previously said that, if elected, he would withdraw Brazil from the 2015 Paris Agreement on climate change, arguing that global warming is nothing more than “greenhouse fables”. Ultimately, his power to reverse the decision is limited, however. This is because the Paris deal was approved via the Brazilian congress, which is currently divided between 30 parties, and Bolsonaro would face the tricky task of convincing a broad church of conservatives. Although Bolsonaro may be unable to withdraw from the Paris framework, his election would still be a direct threat to the regime of environmental protection in Brazil. Bolsonaro’s rise is a symptom of a wider political shift that has seen an alignment between the environmental views of the far right and those of powerful political factions in Brazil.  Although never directly linked, Bolsonaro’s environmental policies would likely be welcomed by the so-called “ruralistas” – a powerful alliance of agribusiness and big landowners within the country’s Senate and Chamber of Deputies. The ruralista faction previously supported the outgoing president Michel Temer and is infamous for its regressive environmental agenda, which seeks to further deforest the Amazon to make way for cattle farms, soy plantations and the mining industry. Bolsonaro has called for the neutering of both Brazil’s environment agency (IBAMA), which monitors deforestation and environmental degradation, and its Chico Mendes Institute which issues fines to negligent parties. This would eliminate any form of oversight of actions that lead to deforestation. Bolsonaro has also threatened to do away with the legislative protections afforded to environmental reserves and indigenous communities. He has previously argued that what he describes as an “indigenous land demarcation industry” must be restricted and reversed, allowing for farms and industry to encroach into previously protected lands. By removing these protective organs from the equation, the message that Bolsonaro is sending is clear: vast swathes of Brazil’s  biologically diverse and ecologically important landscape will be opened up for development and extraction. With the Brazilian soy industry profiting from the current trade war between the US and China, it is highly likely that promises of this potential expansion would be well received. In the run up to this election, figures were released which showed the rate of deforestation in the Brazilian Amazon is continuing to climb. In August 2018, 545km² of forest were cleared – three times more than the area deforested the previous August. The world’s largest rainforest is integral to climate change mitigation, so cutting back on deforestation is an urgent global issue. Brazil, however, is heading in the opposite direction. Any collective relief at the far right not winning the first round outright may be short-lived. While the previous government of Temer rolled back environmental protections, a Bolsonaro government will likely adopt a brazen anti-environmental strategy. The second round of the election is soon to take place. In light of the IPCC’s recent report, there is more riding on it than ever."
"
Share this...FacebookTwitter“Snow in July – this surprised everyone. We remember times when it fell in April or even in May, but not during summer vacation.”
By Kirye
and Pierre
Ice Age now here reported, “snow and record low temperatures” in Poland — in July — earlier this week.
According to Polish sources, there was fresh snow on the highest peaks of the Tatras and the temperature fell below zero (-0.2 degrees).
June mean temperatures see no rise in Canada, Iceland
While Europe saw some record heat in June, temperatures have since fallen considerably, with many regions reporting well-below normal readings.
Elsewhere over the northern hemisphere June temperature trends show a decline over the past two decades or more.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Taken as a whole, 9 temperature stations scattered across Canada show June mean temperatures have not increased in 25 years. Chart: Kirye. Data: http://ds.data.jma.go.jp/…
Two of three stations in Iceland also show no warming. This is hardly what one would expect to find when scrutinizing behind the alarmist headlines and claims coming from global warming media and activists.

2/3 Iceland stations for June show no warming trend since 2000. Chart by Kirye. Data: http://ds.data.jma.go.jp/…
When it’s hot, the activists are so loud. But when cold offsets it all, then suddenly you can hear pins dropping.
As the saying goes regarding climate science: When it’s warm and stormy, it’s climate. But when it’s cool and calm, it’s just weather.
Share this...FacebookTwitter "
"In his discussion of Flybe and HS2 (Growth versus green? The short-term view always prevails, Journal, 16 January), Larry Elliott seems to be tying himself in knots. On the one hand, he rightly claims that it is the better-off who fly intercity in the UK, while on the other hand he suggests that allowing Flybe to go under would hack off a lot of voters, many of whom voted Tory for the first time in December. Frankly, I think it is more likely than not that intercity fliers and the reluctant Tories of the now-collapsed red wall form two mutually exclusive groups. The bottom line is that both bailing out Flybe and pushing through HS2 are appalling options from an environmental perspective. The green way forward is simple and straightforward. Leave Flybe to sink or swim, keep air passenger duty as it is (or preferably hike it further), and scrap HS2. The £100bn or so saved should be diverted to developing railways – and reopening some of those lost to Beeching’s axe – in those parts of the country where improved transport links are needed most.Bill McGuireEmeritus professor of geophysical and climate hazards, University College London  • Larry Elliott’s article is a worrying warning that politicians are very unlikely to do anything to head off the developing climate catastrophe. Perhaps it is time to ditch the facile terminology – green initiatives, wildlife protection, special scientific interest – which give the impression that these considerations are somehow external to our own interests. Perhaps if we started talking about the biosphere of which we are all a part as “the life support system” and the choices politicians make as being between the protection of life and the destruction of life, then the consequences of these choices might be easier for us to grasp.Isabella StoneSheffield  • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitterWhere have all the globe-trotting climate ambulance chasers gone? Well, they’re nowhere to be found in Europe nowadays.
Hat-tip: Snowfan in Germany
The reason is the unusual cold that has swept across a large swath of the continent and which has sent temperatures plummeting to near freezing.

Icebox July: Parts of Central Europe saw ground surface frost yesterday morning. Source: Wetteronline.de
Yesterday morning ground frost hit parts of Belgium, Holland, Germany and the Czech Republic, as the above chart shows. Unsurprisingly, the media have been curiously silent about it.
Record Dutch July low
It has also been reported that a new all-time July low had been recorded in the Netherlands, according to one source here. The online NL Times here reported, “residents of Eastern Netherlands woke up to a frost covered landscape on Thursday” and that in Twente, “a minimum of -1.6 degrees Celsius was measured – a record low for July, according to Weerplaza.”
The cold has now gripped northern Europe for about a week now, as the mornings of July 3 and 4 saw “at times widespread surface frost in Germany” as well.

Surface frost over northern Germany on July 4th. Source: Wetteronline.de
Europe cold summer to persist


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The cold is not expected to subside anytime soon. A recent GFS forecast shows it will likely persist across Northern Europe and most of northern Russia for another 10 days.
So don’t expect to see any global warming ambulance chasers to be found there. They were last sighted in Alaska, and may soon be headed to Iran or the “stans”.

Source: Kachelmannwetter.com.
Early July Arctic ice volume on the rise!
Also early July Arctic sea ice has refused to melt further for 15 years now.

Chart by Kirye. Data source: DMI.
Japanese climate blogger Kirye plotted the data back to 2006, and we see an upward trend for July 8 Arctic sea ice volume:

Chart by Kirye. Data source: DMI.
Growing ice over past 10 years
The rising trend becomes even pronounced when we look at the last 10 years. This ice cold reality flies in the face of all the wild claims of a melting Arctic we often hear in the media.
Share this...FacebookTwitter "
"Imagine never again receiving an energy bill. Instead, you could pay a flat fee for “comfort”, “cleanliness” or “home entertainment” alongside a premium for more energy-demanding TVs, kettles or fridge-freezers. This isn’t the stuff of science fiction – it’s emerging right now. Recent changes in technology and regulation are enabling the development of new ways to provide electricity and gas.  The energy economy is changing fast. By the 2030s, the power sector will have to be substantially decarbonised if the UK is to meet its emissions targets. This means a lot more renewables, which in turn means more intermittent and variable electricity supply.  Related technological developments, for example in solar and storage, and wider developments in IT and data including the roll-out of smart meters, have the potential to transform contemporary systems of provision.   For instance, the capacity to pool and aggregate data about patterns of energy demand may enable the emergence of new business models in which “energy” suppliers also have a role in providing or managing appliances and the forms of heating, lighting, cooling, computing and entertainment that these enable.  Developments such as these call the very identity of “the provider” into question: as small-scale wind and solar power becomes more common, consumers are increasingly also producers. Even when this is not the case, there are various new “non-traditional” market entrants some of whom have new non-traditional ambitions like those of ensuring that energy is more affordable, especially for those on low incomes or the elderly.   An example is the growing interest of public bodies (local authorities, housing associations and the like) in energy generation and supply, with the aim of delivering greater affordability and fairness to consumers. Alternatively, these offerings may be provided to local communities or communities of interest and may bundle basic energy services with additional offerings such as energy efficiency measures. In effect energy supply is being repackaged as a form of service provision. We all pay energy bills and we understand that energy is delivered through wires and pipes into boilers, TVs, kettles and so forth.  However, it is not the energy, as such, that consumers’ value.   In paying energy bills, people are really paying for the services that energy makes possible: for thermal comfort, for entertainment or for a cooked meal. In other words, it is the ability to watch a favourite TV soap (while consuming a favourite TV dinner) and the cosiness of the home that really matters. This isn’t just an academic distinction. Whether energy is seen as a commodity or a service is fast becoming a crucial factor in how the sector is organised and regulated. The rhetoric of consumer “empowerment” in the energy market and the ambition to provide people with more knowledge about their energy use only makes sense if we think of it as a uniform commodity.  By contrast, if we see energy as being embedded in a huge variety of different practices – that is, if we think of energy as something that is in a sense part of writing emails, watching TV, or making dinner – then demand reduction is not about energy as such, it is about changing the details of daily life.  Recognising these differences helps understand otherwise puzzling features like why more and better information about energy use doesn’t automatically translate into energy-saving actions. The commodity-service distinction is also useful in thinking about how relationships between consumers and providers might be configured now and in the future. If we think of energy not as a commodity but as something that is incorporated in the provision of services we should also think of energy providers as service providers. We are already seeing the emergence of Energy Service Companies (ESCos) which guarantee a fixed energy bill as long as the company can install efficiency measures in your home or office. Other providers offer multi-utility tariffs, bundling together rent, water and energy into a single bill.   At the moment it is unclear whether these novel forms of “energy-plus” provision are forerunners of arrangements that are set to become the norm, of if they will remain niche solutions for a few. Whatever else, these moments of flux remind us that energy and energy services are never set in stone."
"
Share this...FacebookTwitterA potential wind turbine installation on the island of Crete may be poised to drive an endangered raptor population to extinction.
Recent studies have found the favored “renewable” energies – wind and solar – are not effective, even counteractive, when it comes to reducing emissions from fossil fuels.
Solar PV installation, for example, results in a net loss of energy, meaning that the net effect of solar energy use is ultimately more dependence on fossil fuels.

Image Source: Ferroni and Hopkirk, 2016
Due especially to its intermittent energy generation, the installation of wind turbines also necessitates eventual growth in fossil fuel energies to back them up (due especially to the frequent occasions when the wind is not blowing).

Image Source: Marques et al., 2018


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Even worse, the installation of wind turbines have been well documented to destroy wildlife habitats (Marques et al., 2019, Millon et al., 2018, Lange et al., 2018, Barré et al., 2018). Frequent soaring species collisions may ultimately lead to widespread extinctions (Naylor, 2018 , Watson et al., 2018, Vasilakis et al., 2017 ) in the coming decades.
Roughly 25% of North American bats are now classified at risk for extinction (Hammerson et al, 2017) in large part due to the explosion of wind turbines across the landscape.
If the expansion of wind turbines continues at its current pace, the hoary bat population is projected to be reduced by 90% (Frick et al., 2017) within the next 50 years.
In a new paper (Xirouchakis et al., 2019), scientists detail the austere short-term mortality risks wind turbines pose upon an endangered griffon vulture on the island of Crete.
Considering the unreliability and counteractive effectiveness of wind turbine use in mitigating fossil fuel dependency, one needs to ask why we are willing to risk the extirpation of rare raptor species for the purpose of expanding “renewable” energies that increasingly seem to do more harm than good.

Image Source: Xirouchakis et al., 2019
“[T]he environmental impact of commercial wind power production on biodiversity has proved to be substantial [3–7]. Wildlife is affected by wind power production through habitat loss, disturbance and displacement and above all by increased collision risk with wind turbines [8–10]. Bird fatalities due to collision with wind turbines have been the most prominent and frequently identified environmental drawback of wind energy development. Bird casualties from collisions can reach up to 40 deaths per turbine per year [11] with large raptors suffering the greatest toll.”
“We evaluated the consequences of wind farm development on the griffon vulture (Gyps fulvus) which was regarded as a suitable model species. Griffons are among the most collision-prone large soaring raptors and perhaps the most frequent victims of turbine blades in the Mediterranean region, i.e. up to 1.88 individuals/ turbine/ year [8]. Furthermore, assuming that the most crucial factor in minimizing the negative impact of wind farms on wildlife should be proper siting, we tried to estimate the potential collision mortality of the species by taking into account the existing and all planned wind energy projects on Crete.”
“Crete holds the last healthy population in the country (ca. 1000 individuals) which constitutes the largest indigenous insular population worldwide.”
“The model predicted that 39% of the griffon colonies which were occupied by more than 15 individuals would account for 62% of the wind farms and vulture interactions and would suffer 65% of the expected mortalities. The overall collision mortality rate was estimated at 0.03 vultures/wind turbine/year producing an annual loss ranging from 3.7% to 11% of the species population. More specifically a total of 990 individuals were estimated to be at threat of striking with turbine blades. The scenario #1 predicted a mean annual mortality of 1.49 ± 1.12 individuals (range = 0.18–4.98) per colony, whereas the overall annual fatality was anticipated at 83.5 griffons.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterCat 5 Hurricane “Dorian” showed a development parallel to a solar storm lasting several days, which reached the earth from 27 August to 4 September 2019.
By Snowfan
The strength of particle radiation of a solar storm is given as a three-hour value in the Kp index, the daily value is called the A index.
The following table shows the development of hurricane DORIAN compared to solar activity in the daily values of the A index.
Source: https://nextgrandminimum.com/
The parallels are astonishing: It would seem DORIAN was “fed” by the strength of the solar storm in its development, especially in its peak around September 1, 2019.
It’s well known, of course: correlation isn’t causation.
So the question arises: How could solar storms influence earthly hurricanes? And the question certainly cannot be vice versa.
A commentator made the following interesting comments on hurricane activity in 2017 (including IRMA), and 2018 in the North Atlantic and a connection of solar activity with regard to changes in the jet stream:
Interesting sequence of events here; July 9/10 we had a sharp ‘Kp’ impact after a prolonged period of quiet.
On July 11th, TS Barry had been activated, by the end of the week we had the Jet Stream phenomenon, first over the pacific then over US states.
The theory is that a burst of ‘Kp’ activity expands upper atmosphere and triggers profile changes which can activate or exacerbate potential or base line activity lower down in the atmosphere.
Science in this area is in its infancy; however a discussion of what is involved can be seen at
https://howtheatmosphereworks.wordpress.com/about/solar-activity-and-surface-climate/storm-analysis/
This is also an impressive parallel development of hurricane “IRMA” (Cat. 5) and the solar storm in September 2017:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





IRMA– Recorded peak intensity and (below) overall progress

 
The influence of solar activity on the Earth’s weather, e.g. sudden stratospheric warming in the winter over the Arctic with violent “Arctic outbreaks” in the mid-latitudes, is already well known.
Why shouldn’t solar activity also have a significant influence on the formation and development of cyclones through solar storms over the stratosphere and the jet stream?
An important and meaningful field of research, in my opinion…, and far more meaningful than the demonization of the life-giving CO2 in our atmosphere, with the aim of pulling money out of people’s pockets with a CO2 tax….
By the way: The solar activity also influences ENSO – NASA sees the globally cooling La Niña from November 2019 on…

The current NASA-ENSO forecast from September 2019 shows globally cooling Lan Niña conditions with SSTA of at least -0.5 K and colder in the relevant Nino area 3.4 as early as October/November 2019. Dr. Horst Malberg describes the relationship between ENSO conditions and sunspot cycles here. Source: NASA-GMAO-ENSO-Model
Snowfan 2015
Share this...FacebookTwitter "
"Britain’s first new deep coalmine in 30 years is unnecessary and incompatible with UK climate ambitions, according to a report. The £165m Woodhouse colliery in Cumbria was given cross party-backing in March 2019, leading to protests from climate campaigners who said the mine would harm the UK’s efforts to reduce CO2 emissions.  Now a report by the independent thinktank the Green Alliance has found the colliery, along the coast from Whitehaven, will hold back the development of low-carbon steelmaking. The report, authored by two university professors who specialise in environmental issues, claims that opening a new coalmine would hinder this strategy by ensuring the continued availability of cheap coal. It also refutes Cumbria county council’s claim that the mine, which aims to process 2.5m tonnes of coking coal a year for the UK and European steel industry, replacing imports from the US, Canada, Russia and Colombia, will be carbon neutral. Prof Rebecca Willis and Mike Berners-Lee from Lancaster University, say the mine would produce 8.4m tonnes of CO2 per year, equivalent to the emissions from more than 1 million households. The UK has set a target to reach net-zero carbon emissions by 2050, and has committed to switch to lower carbon steel production, announcing a clean steel fund in August 2019. But the report says the proposed mine, expected to begin production in two years, subject to environmental certificates, will jeopardise these ambitions. “The proposed mine is clearly incompatible with the UK’s climate ambitions and the need for a clean energy future. The new government has championed its commitment to climate action. It now needs to set out its policy on fossil fuel extraction, making clear that digging more coal out of the ground is no longer acceptable,” Willis said. Recommendations made in the report include using less steel, using recycled steel, improving the efficiency of steel production with conventional blast furnaces, and producing steel with new processes such as renewable energy. Dustin Benton, Green Alliance’s policy director, said: “Clean energy has already made coal obsolete in the power sector. Our previous work shows that UK demand for coking coal would halve if steel producers opted for cheaper, cleaner steel production using today’s technologies. “In addition, innovation in zero carbon steel production means this mine will likely become redundant in the near future, saddling Cumbria with an expensive stranded asset.” Councillors who backed proposals for the undersea mine said it would create vital jobs. It is expected to employ 500 people, with an estimated 2,000 more jobs created in its supply chain. But Berners-Lee, a leading expert in carbon footprinting and the brother of internet pioneer Sir Tim, said the emphasis should be on creating green jobs. “Cumbria’s politicians understandably want to see new jobs on the west coast. But we estimate that the profits from the mine would leave the local area, with only 3% of the turnover spent on salaries,” he said. “We urgently need an active, low-carbon industrial strategy for Cumbria and other local areas, to generate thousands of green jobs rather than hundreds of coal jobs.” The developer West Cumbria Mining has previously revealed that it agreed a deal for a 50MW solar farm nearby to provide about a third of the project’s energy needs, in order to mitigate some of the impact of the plant on the environment. In June, the UK became the first large economy to pass laws to end its contribution to global warming by 2050. The goal requires Britain to reduce greenhouse gas emissions to net zero by 2050, compared with the previous target of at least 80% reduction from 1990 levels. A spokesperson for the Department for Business, Energy and Industrial Strategy said: “We are well on the way to phasing coal out of our energy system by 2025 and last year Great Britain went nearly 4,000 hours without using coal for electricity. Ending our use of it will be a key milestone on our journey to end our contribution to climate change entirely. “Although coal will soon no longer be part of our energy system, there will continue to be domestic demand for coal in industries such as steel, cement and even heritage railways.”  West Cumbria Mining said it did not want to comment on the report."
"Three thousand litres of water – that is the amount needed to produce the food each British person eats every day. This is the opening line of a recent article also published on The Conversation. The piece reports on research published in Nature Sustainability, which investigated the water footprint of diets in three EU countries, considered national and regional differences, and comes to the overall conclusion that a healthy diet that is low in meat would significantly decrease our water footprint. The scientific consensus is that eating less meat is a good way of reducing your carbon footprint (a measure of carbon dioxide released into the atmosphere by a person’s activities) and contribution to climate change. According to the Water Footprint Network, the water footprint of a kilo of beef is 15,415 litres, compared to 322 litres for a kilo of vegetables. When compared to domestic water use (each person in the UK uses about 150 litres of water per day) these numbers seem large and worrying. But the reality is that the concept of footprints cannot be used for water in a way that is environmentally meaningful. The first flaw in the water footprint concept stems from the fact that water is renewable. It can exist in lakes, rivers and the sea, below ground, as vapour in the air, in glaciers, and more. We neither create nor destroy water, it simply moves around the hydrological cycle. Water that we use in the present can also be used in the future. It isn’t going to run out in any permanent sense unless it is irretrievably polluted, or becomes incorporated into a glacier which will exist for millennia to come. So, regardless of how much steak you eat, the world is not going to run out of water. The next problem with the water footprint concept is that it causes us to value water as being equally important wherever it is. But it’s fairly obvious that a thousand litres of freshwater in Wales is not of equal value to a thousand litres of water in a desert.  In addition, there is no clear relationship between the volume of water we use and the environmental impact of using that volume. So, although with carbon emissions we can reliably say that a serving of pulses contributes less to climate change than a serving of beef, we cannot be nearly so confident when comparing the environmental impacts of the water used to produce the two products. Hydrologists express these issues of time and place using diagrams and equations known as water balances. Water exists in stocks, and flows occur between them. Measuring the size of each stock and flow allows us to understand what the consequences might be of changing flow rates into/out of stocks, or diverting flows in some way, with reference to a specific time period. This helps us understand another problem with the water footprint concept. The footprint is defined as the volume withdrawn from a stock, minus the amount that is discharged back into that stock. When rain falls on grassland, much of it is taken up by plant roots, moves upwards through the stem and then evaporates from the leaves. If the grass is eaten by cattle, then the water footprint of the beef includes all this water. But if the rain was to fall on an area of forest rather than grassland, evapotranspiration (the process by which water evaporates from plant leaves and from the ground) would be higher.  Trees take up more water than grass, so trees have a large water footprint. Does this make forests bad? Clearly not. Evapotranspiration is simply a flow within the hydrological cycle, it is no better or worse in environmental terms than the rainwater that flows into streams and rivers.  However, this way of calculating water footprints also means that if a water company withdrew 1,000 litres of water for domestic water use from a river, and then discharged it back into the river after it had undergone sewage treatment, the water footprint is zero. The water has become immediately available again at local level. Evidently, water footprints lack scientific validity, and don’t actually tell us anything very useful about the environmental impact of water use – but what can we do instead? The Alliance for Water Stewardship is promoting a promising initiative that considers industry and location-specific measures, such as whether water is being abstracted from an aquifer (an underground layer of permeable rock that holds water) at an unsustainable rate, whether irrigation schemes are necessary and properly controlled, and how to balance the needs of all water users in the area. However, these schemes are not yet widely adopted, and it remains difficult for consumers to make water conscious choices. There is also a risk of worrying about water at the expense of other environmental issues. The effects of climate change are felt most immediately through water-related events such as droughts and floods, but we would do well to remember that these events are symptoms and it is the cause that we need to address."
"
Share this...FacebookTwitterTwo University of Turku (Finland) physicists have determined a) the climate’s sensitivity to a doubling of CO2 is 0.24°C, b) the human contribution to the warming of the past century is only about 0.01°C, c) the IPCC and climate modeling dramatically overestimate CO2’s climate impact, and d) variations in low cloud cover control the climate.

Cloud cover changes “explain the linear trend of global temperature” since the 1980s
In a new paper, O.M. Povrovsky of the Russian State Hydrometeorological University analyzes satellite-observed cloud cover changes during 1983-2009 and their relation to global temperature change.
Povrovsky found global and regional cloudiness decreased between 2-6% during these decades, and “the correlation coefficient between the global cloud series on the one hand and the global air and ocean surface temperature series on the other hand reaches values (–0.84) — (–0.86).”
Consequently, Povrovsky (2019) concluded changes in cloud cover explain both the increasing global temperature during 1984-2009, but even the interannual variability.

Anthropogenic climate change isn’t supported by experimental evidence
Dr. Jyrki Kauppinen was an expert reviewer for the IPPC’s last climate report (AR5, 2013).
In a comment to the IPCC overseers, Kauppinen strongly suggested the “experimental evidence for the very large sensitivity [to anthropogenic CO2 forcing] presented in the report” is missing (Kauppinen and Malmi, 2019).
In response, the IPCC overseers claimed experimental evidence could be found in the report’s Technical Summary.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




But the Technical Summary merely contained references to computer models and non-validated assumptions. Kauppinen writes:
“We do not consider computational results as experimental evidence. Especially the results obtained by climate models are questionable because the results are conflicting with each other.”
Upon examination of satellite data and cloud cover changes, Dr. Kauppinen concluded the IPCC’s claims of high climate sensitivity to CO2 forcing (2 to 5°C) are about ten times too high, and “the models fail to derive the influences of low cloud cover fraction on the global temperature.”
Evidence for natural climate change supported by satellite observations
When low cloud cover data from satellite observations are considered, a very clear correlation emerges.

As low cloud cover decreases, more solar radiation can be absorbed by the oceans rather than reflected back to space. Thus, decadal-scale decreases in low cloud cover elicit warming.
When cloud cover increases, cooling ensues.
In this manner, Kauppien and Malmi (2019) find “low clouds practically control the global temperature,” which leaves “no room for the contribution of greenhouse gases i.e. anthropogenic forcing.”
In fact, Kauppinen and Malmi boldly conclude that the total warming contribution from anthropogenic CO2 emissions reached only 0.o1°C during the last 100 years, which means “anthropogenic climate change does not exist in practice.”

Kauppinen and Malmi, 2019
No experimental evidence for the
significant anthropogenic climate change
“The IPCC climate sensitivity is about one order of magnitude too high, because a strong negative feedback of the clouds is missing in climate models. If we pay attention to the fact that only a small part of the increased CO2 concentration is anthropogenic, we have to recognize that the anthropogenic climate change does not exist in practice. The major part of the extra CO2 is emitted from oceans [6], according to Henry‘s law. The low clouds practically control the global average temperature. During the last hundred years the temperature is increased about 0.1°C because of CO2. The human contribution was about 0.01°C.”
“We have proven that the GCM-models used in IPCC report AR5 cannot compute correctly the natural component included in the observed global temperature. The reason is that the models fail to derive the influences of low cloud cover fraction on the global temperature. A too small natural component results in a too large portion for the contribution of the greenhouse gases like carbon dioxide. That is why IPCC represents the climate sensitivity more than one order of magnitude larger than our sensitivity 0.24°C. Because the anthropogenic portion in the increased CO2 is less than 10 %, we have practically no anthropogenic climate change. The low clouds control mainly the global temperature.”

Image Source: Kauppinen and Malmi, 2019
Share this...FacebookTwitter "
"It is unlawful for governments to return people to countries where their lives might be threatened by the climate crisis, a landmark ruling by the United Nations human rights committee has found. The judgment – which is the first of its kind – represents a legal “tipping point” and a moment that “opens the doorway” to future protection claims for people whose lives and wellbeing have been threatened due to global heating, experts say. Tens of millions of people are expected to be displaced by global heating in the next decade. The judgment relates to the case of Ioane Teitiota, a man from the Pacific nation of Kiribati, which is considered one of the countries most threatened by rising sea levels. He applied for protection in New Zealand in 2013, claiming his and his family’s lives were at risk. The committee heard evidence of overcrowding on the island of South Tarawa, where Teitiota lived, saying that the population there had increased from 1,641 in 1947 to 50,000 in 2010 due to sea level rising leading to other islands becoming uninhabitable, which had led to violence and social tensions. He also spoke of the lack of fresh water and difficulty growing crops due to salinity of the water table causing serious health issues for his family. He said that as Kiribati was predicted to be uninhabitable in 10 to 15 years, his life was endangered by remaining there. The New Zealand courts rejected Teitiota’s claim for protection. The UN human rights committee upheld New Zealand’s decision on the grounds that while “sea level rise is likely to render the republic of Kiribati uninhabitable … the timeframe of 10 to 15 years, as suggested by [Teitiota], could allow for intervening acts by the republic of Kiribati, with the assistance of the international community, to take affirmative measures to protect and, where necessary, relocate its population”. However experts say the committee’s ruling opens the way for other claims based on the threat to life posed by the climate crisis. The committee ruled that “the effects of climate change in receiving states may expose individuals to a violation of their rights … thereby triggering the non-refoulement obligations of sending states”. “On a personal level for Ioane and his family it is bad news, because obviously it’s decided that his claim that his right to life was threatened in Kiribati wasn’t strong enough,” said Kate Schuetze, Pacific researcher for Amnesty International. “But they said it wasn’t strong enough based on his personal circumstances and the evidence they put before the court and then they made some very strong statements clarifying the roles and responsibilities of states to say … there would be a trigger of international responsibility for other governments not to return people to places where their life is at risk because of climate-induced changes.” While the judgment is not formally binding on countries, it points to legal obligations that countries have under international law. “What’s really important here, and why it’s quite a landmark case, is that the committee recognised that without robust action on climate at some point in the future it could well be that governments will, under international human rights law, be prohibited from sending people to places where their life is at risk or where they would face inhuman or degrading treatment,” said Prof Jane McAdam, director of the Kaldor centre for international refugee law at the University of New South Wales. “Even though in this particular case there was no violation found, it effectively put governments on notice. “There have been cases brought in Australia and New Zealand since the mid-1990s about environmental harm and climate change and to date they’ve all been unsuccessful ... But now we’ve got a very clear, legal authoritative statement now that it’s almost like: watch this space.” Schuetze said there were roughly a dozen cases in the New Zealand court system similar to Teitiota’s, with people, mostly from Tuvalu and Kiribati, claiming the impacts of the climate crisis affected their right to life. “The Pacific Islands will be the canary in the coalmines for climate-induced migrants,” said Schuetze. “The message in this case is clear: Pacific Island states don’t need to be underwater before triggering those human rights obligations … I think we will see those cases start to emerge.” Two of the 18 members of the committee issued dissenting opinions on the case, saying they did not agree with the conclusion that New Zealand was justified in removing Teitiota to Kiribati, with one writing that just because “deaths are not occurring with regularity on account of the conditions … it should not mean that the threshold had been reached”. “The fact that this [difficulty growing crops and accessing safe drinking water] is a reality for many others in the country, does not make it any more dignified for the persons living in such conditions. New Zealand’s action is more like forcing a drowning person back into a sinking vessel, with the ‘justification’ that after all there are other voyagers on board.”"
"Labour’s new animal protection manifesto makes animal protection and wildlife crime a potential, if unlikely, battleground for the next election. Animal crime is an emotive issue, and one on which the main political parties differ significantly.  Labour’s stance to retain the Hunting Act 2004 stands in contrast to the Conservatives’ pledge to revoke the ban on hunting. And Labour’s introduction of the Animal Welfare Act 2006 during the last parliament suggests a positive attitude towards animal welfare.   In its policy statement, the Labour Party identifies that more should be done to end wildlife crime and animal cruelty. These terms are used to refer to a wide range of illegal activities, from the persecution of British animals like birds of prey, to the global trafficking of endangered species and their parts.  Wildlife crime is considered to be one of the most prevalent forms of crime globally. The demand from source countries is a major problem, particularly Chinese demand for prize items like elephant ivory, and Vietnam’s demand for rhino horn.  The 2014 London Conference on illegal wildlife trade concluded that poaching and trafficking require action by source, demand and transit countries. As a major destination for trafficked wildlife, the EU has a role to play in addressing global wildlife crime, and Labour’s policies acknowledge this. Experts in the field have been making these calls for several years.  Criminologists and conservationists also say there is a lack of resources for wildlife law enforcement, as well as a lack of frontline knowledge when it comes to catching traffickers within the UK. It is also an area where corruption and the involvement of organised crime and different types of criminal require a dedicated enforcement approach. There is general political agreement that wildlife crime is important. But in practice, police forces are not required to prioritise it. Despite the efforts of individual police, enforcement officers and NGOs, wildlife crime enforcement remains significantly under-resourced. Criminologists and conservationists have repeatedly identified this fact.  Labour’s basic pledges are sound: it is necessary to combat illegal wildlife crime and prevent the trafficking and poaching of endangered species including elephants, rhino and some sturgeon species.  But these should be criminal justice priorities, not just animal welfare ones. Even if tougher sentences and stricter wildlife laws were introduced, it is unlikely that the number of offences would reduce. In some cases strong penalties already exist, but they are underused: so why would a new regime make any difference?   Instead, an improved enforcement strategy is needed, with increased resources for police and conservation bodies. We also need to reform wildlife crime laws so they are less confusing, and to reduce overlap and address inconsistencies. The House of Commons Environmental Audit Committee addressed part of this issue back in 2012: the committee identified sentencing inconsistency and prosecutors’ lack of expertise as issues in wildlife crime enforcement.  Austerity measures are also a factor. While the UK has an excellent network of police wildlife crime officers, many of them carry out their roles in addition to their “main” duties. Evidence to the government’s committee suggested that, in some areas, wildlife crime enforcement is under threat from police budget cuts. The Law Commission says UK wildlife laws should be reformed and combined; another move that would improve wildlife protection. Indiscriminate methods of killing wildlife like snares should be prohibited, and loopholes should be closed. Some wording in laws means that wildlife can be killed on technicalities when the law is meant to protect it. Phrases like “wilfully” or “intentionally” should be replaced with wording that actually helps investigators where an offence has clearly been committed. They should not have to prove the wildlife knowledge or intentions of the offender.   One of the problems with wildlife laws is that there are too many, providing different levels of protection for animals. This causes confusion both for the public and enforcers. The coalition government’s Red Tape Challenge suggests that there are 159 regulations relating to biodiversity, wildlife management, landscape, countryside and recreation. Wildlife investigators and campaigners often complain about ambiguous wording and different standards of protection across wildlife legislation. Because of this, a high level of legal expertise is often required even at the investigative stage. The Law Commission sought to address this with plans for a more streamlined legal regime. They suggested increased use of civil and administrative penalties, rather than the existing reliance on the criminal law.   Our current wildlife law enforcement regime makes little provision for crime prevention. Its primary function in practice is to detect and apprehend the offender after the offence has been committed. In the case of wildlife, killed as a result of wildlife crime, this is too late.  Labour’s policy suggests that they see animal protection as important.  This is good news. But if this is the case, we need effectively enforced and coherent wildlife laws as part of our criminal justice system.  As the election heats up, it will be interesting to see which of our political parties is willing to name animal protection and wildlife crime as important policing issues. But ultimately, it will be more important to see which party will commit to providing resources to make this a reality."
"A year of extreme weather events and mounting evidence of global heating have catapulted the climate emergency to the top of the list of issues worrying the world’s elite. The World Economic Forum’s annual risks report found that, for the first time in its 15-year history, the environment filled the top five places in the list of concerns likely to have a major impact over the next decade.  Børge Brende, the president of the World Economic Forum, said: “The political landscape is polarised, sea levels are rising and climate fires are burning. This is the year when world leaders must work with all sectors of society to repair and reinvigorate our systems of cooperation, not just for short-term benefit but for tackling our deep-rooted risks.” After a month in which bushfires have raged out of control in Australia, Brende said there was a need for urgent action. “We have only a very small window and if we don’t use that window in the next 10 years we will be moving around the deckchairs on the Titanic.” The WEF report said the retreat from the multilateral approach that helped cope with the 2008 financial crisis made it more difficult to tackle shared global risks. It said the top five risks in terms of likelihood in the next 10 years were: Extreme weather events with major damage to property, infrastructure and loss of human life. Failure of climate-change mitigation and adaptation by governments and businesses. Human-made environmental damage and disasters, including environmental crime, such as oil spills and radioactive contamination. Major biodiversity loss and ecosystem collapse with irreversible consequences for the environment, resulting in severely depleted resources for humankind as well as industries. Major natural disasters such as earthquakes, tsunamis, volcanic eruptions, and geomagnetic storms. The report was released ahead of the WEF’s annual meeting in Davos next week, which will be attended by the chief executives of some of the world’s biggest and powerful companies. Despite the large number of participants flying in to Switzerland by private jet, the WEF said Davos would be a carbon-neutral event. But John Drzik, the chairman of Marsh & McLennan insights, which helped to compile the report, said businesses had to step up their action on global heating. “There is mounting pressure on companies from investors, regulators, customers, and employees to demonstrate their resilience to rising climate volatility. Scientific advances mean that climate risks can now be modelled with greater accuracy and incorporated into risk management and business plans. High-profile events, like recent bushfires in Australia and California, are adding pressure on companies to take action on climate risk at a time when they also face greater geopolitical and cyber risk challenges.” Peter Giger, group chief risk officer of Zurich Insurance Group, which also collaborates in the preparation of the risks report, said there was a pressing need to adapt faster to avoid the worst and irreversible impacts of the climate crisis and to do more to protect the planet’s biodiversity. “Biologically diverse ecosystems capture vast amounts of carbon and provide massive economic benefits that are estimated at $33tn (£25tn) per year – the equivalent to the GDP of the US and China combined. It’s critical that companies and policymakers move faster to transition to a low carbon economy and more sustainable business models. “We are already seeing companies destroyed by failing to align their strategies to shifts in policy and customer preferences. Transitionary risks are real, and everyone must play their part to mitigate them. It’s not just an economic imperative, it is simply the right thing to do,” he said."
nan
"It’s no secret that bee populations are in decline across the UK and Europe. There has also been a fantastic increase in public awareness over the past few years, leading many to set up hives in their gardens and on their roofs. But this might not be as helpful as you may think. The UK is home to around 270 bee species. Most people are familiar with the charismatic bumblebees, but the 250 species of solitary bee remain lesser-known. As the name suggests, they don’t live in hives or colonies, but nest alone in cavities or underground.  Bee species also differ in their foraging preferences, selecting flowers based on their shape, colour and scent. This reflects the co-evolution between plants and pollinators and means that plants with certain floral traits depend on compatible bee species. Those with deep flowers depend on bees with tongues long enough to reach the nectar, for example. So losing the variety of the country’s wild bee community could leave many cultivated and wild plants without effective pollinators. The European honeybee (Apis mellifera) is a social bee species that has been domesticated for crop pollination and honey production. Beekeeping is often promoted as a way to conserve pollinators and, as a result, is on the rise across the UK. It’s great to see people backing the pollinator movement, but managing hives does nothing to protect our wild pollinators. It’s the equivalent of farming chickens to save wild birds.  High numbers of honeybees can actively harm wild bee populations, because they compete directly for nectar and pollen. That’s not a problem when flowers are plentiful, but in environments where resources are limited, wild bees can be outcompeted. A lack of flowers is one of the main factors behind the decline in bee populations. Initiatives such as urban beekeeping put more pressure on wild bees and worsen the decline. Honeybees are extremely efficient at collecting pollen and returning it to their hives, but as a consequence they transfer little to the flowers they visit. They are quantifiably less effective at pollination than wild bees, so changes in foraging patterns also have knock-on consequences for the plant community. When honeybees occur in high numbers, they can push wild bees out of an area,  making it harder for wild plants to reproduce. Honeybees are not a substitute for wild pollinators, so we must protect the entire bee community to achieve good quality pollination. Honeybee hives are regularly traded locally and internationally, allowing the rapid spread of diseases and parasites, such as deformed wing virus and Varroa  mite. These pathogens can spill over from managed hives into wild bumblebee populations and spread between wild bee species when they visit the same flower. Responsible beekeepers should take steps to control pathogen levels within their hives to minimise transmission to wild bees. When considering the evidence, the rise in amateur beekeeping is likely to cause more harm than good. No one will deny the value of our British beekeepers and the wonderful honey they provide, but if your motivation is to save the bees then here are some more effective steps you can take.  Gardens provide essential habitats for bees across the UK, so make sure you are maximising the pollinator potential of your outdoor space. If you don’t have a garden, then check whether your public spaces, parks and road verges are bee friendly and let local councils know how they can improve. Bees need to eat, so fill your garden with flowering plants that are rich in pollen and nectar. Watch out for ornamental hybrids that have been bred to produce showy flowers that contain little or no nectar. Remember that variety is key. Include plants with a wide range of floral shapes and colours to increase the number of bee species attracted to your garden. Wooden decking and concrete paving may be low maintenance, but impenetrable surfaces prevent ground nesting bees from finding a home. Increasing the size of your flowerbeds lets you plant more flowers and creates space for more bees to locate nesting sites. Cavity nesting bees look to nest in masonry or old plant stems, but you can provide them with additional nesting sites by buying or building a “bee hotel”. The EU recently extended its ban on the agricultural use of neonicotinoid pesticides in acknowledgement of the harm they cause to bees. These same chemicals are still found in common garden pesticides, so do your best to minimise their use. Immaculate lawns and flower beds may impress your guests, but the bees won’t thank you. Many of our fast growing “weedy” plants provide rich sources of pollen and nectar, so ditch the weedkiller and let the wild flowers grow. Lazy gardeners who mow their lawn less frequently can also expect to see a rise in bee abundance of up to 30% due to the increase of “weeds” such as dandelion and clover. To do your bit for bee conservation, forget taking up beekeeping, but instead take a science-backed break from mowing your lawn."
"
Share this...FacebookTwitterYou really know that climate activism is going way off the rails when even a leading German socialist thinks the movement is becoming a threat to democracy. Leading German socialist politician Wolfgang Thierse warns of Greta Thunberg’s “anti-democratic”, uncompromising rhetoric. 
Hat-tip Die kalte Sonne
“Anti-democratic affection”
Over the years a number of leading climate scientists and activists have expressed to some degree their frustration with democracy, hinting that the political system which incorporates the will of the common people in government has only gotten in the way of taking action against the “climate crisis”. What is needed, they suggest, is an elite group of Leaders to decide how to properly organize society. The average citizen is too stupid to make the right decisions.
Even some socialists are beginning to worry about the movement. For example German online flagship daily Die Welt here recently reported on how leading SPD politician, former President of the German Bundestag, Wolfgang Thierse sees in the words of climate activist Greta Thunberg an “anti-democratic affection” and thus he “warns against the climate movement”.
“Rigorism in climate debate”
Die Welt writes how Thierse also “warns against rigorism in the climate debate” and statements made by climate activist Greta Thunberg such as “that the climate does not tolerate compromises”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Thierse made the comments to the Berlin “Tagesspiegel” in a video interview.
In Thierse’s view, such statements are “anti-democratic” and urges climate activists to take former German Chancellor Willy Brandt as an example when it comes to convincing the public on policy.
Young people don’t see the complexity
Thierse is not alone. Last month well-known nature filmmaker David Attenborough also told WELT: “The young climate activists see things in black and white, very clearly. They don’t yet know all the buts…”
In other words, the youth are being manipulated.
Attenborough added: “Maybe the young people don’t see the complexity of the problems to be solved and how to deal with them in a reasonable democratic way. Bringing the whole population along democratically is a big problem.”
German political scientist says climate movement like a religion
Also in a recent interview with German DLF here, political scientist Ulrike Ackermann said: “Rescuing the climate is almost like a religion.”  She warned: “It is of no use to paint the world catastrophe on the wall in an alarmism that can only be countered radically.”
Share this...FacebookTwitter "
"Is your employer having the conversation about cutting back on flying? While activist Greta Thunberg’s emotionally charged speeches around the globe have gained headlines so, too, has her decision to shun air travel in favour of train and boat journeys, no matter how arduous. With flying one of the fastest-growing sources of greenhouse gas emissions, more people are following Thunberg’s lead and rethinking the way they travel. But it’s not just about holidays – business trips are a big contributor to the problem, and discussions are taking place at companies up and down the UK about flying less and “clean travel” options.  But with the value of the global business travel market forecast to increase from $1.3tn (£1tn) in 2017 to almost $1.7tn by 2023, according to an Allied Market Research report issued in November 2018, will large numbers of businesses really start to rethink the need to jet across from the UK to New York to set up a deal, or fly from London to Dublin for a meeting? The often exorbitant cost of train travel means that in cold, hard financial terms, it might be difficult to argue against, say, a £40 return flight from London to Edinburgh versus £240 on the train. And what about long-distance commuting to work? This week’s media coverage of airline Flybe’s woes brought a reminder that many of its passengers are weekly commuters hopping on flights to and from mainland Europe. “With more and more companies making their own ‘net zero’ pledges, business travel is bound to come under the spotlight before long,” says Cait Hewitt, deputy director of campaigning organisation Aviation Environment Federation. “We’re starting to get inquiries from the business travel-buying community (corporate travel buyers) to discuss what they should be doing about the impact of climate change on travel.” Some companies have taken action or are working on it, though it is fair to say that when Guardian Money tried to talk to large and medium-sized companies about business flights, many didn’t want to chat. However, some were prepared to spill the beans. London-based Lawson Conner, part of the IQ-EQ group, provides services and software to financial firms, and says it has reduced business flights by 75% over the last two years. “I used to fly quite a lot – I’d probably take about eight flights a month, travelling to Singapore and Hong Kong,” says Gerhard Grueter, co-founder and managing director of Lawson Conner, which employs 50 people in the UK. “That’s now completely cut.” The business has a “one person” international travel policy, where only one member of staff is allowed to attend global business meetings. The reduction in flights has, in part, only been possible because the company has offices around the world. “If clients are being served locally, if someone wants to speak to me, I don’t need to fly to New York – it’s not necessary,” says Grueter, adding: “If I was asked ‘what did you do in your job as a senior member in a firm, about the impact on the environment?’, I want to be able to respond. We have got to act now.” Two years ago, the engineering professional services firm WSP set itself a target in the UK to become carbon neutral by 2025. This involved tackling business flights, which have seen a 9% fall domestically, and a 16% drop overall. In 2018 it introduced an initiative encouraging non-travel and low-carbon alternatives rather than driving and flying, and banned flights under 250 miles. “When our staff book travel online, a pop-up asks whether they need to travel or could they use Skype,” says Claire Gott, UK head of corporate social responsibility (CSR) at WSP. “Also, our admin staff have been trained to challenge any travel. The first choice is by rail.” There’s also an internal carbon levy of £50 a flight on all domestic air travel, to be increased to £200 a trip, with this invested in CSR activities. Sabine Zetteler, owner of communications agency Zetteler, is on a mission to reduce flights taken by her 10-strong company. Zetteler says the London-based business has clients exhibiting all over the world, so in some cases flying can’t be avoided, but for short trips and design fairs, it plans to find more carbon-efficient means. For instance, in April 2019, five of the team travelled by train to Milan Design Week. “It took 12 hours longer and cost a few hundred extra financially, but it was liberating, bonding and important for us to try,” says Zetteler. As for this year, the company plans to visit fewer places and share the carbon offset charge for international meetings that can’t be avoided. Organisations, such as universities, are also looking at what they can do. Sion Pickering, social responsibility and sustainability projects coordinator at Edinburgh University, says business travel accounts for a sizeable proportion of its carbon emissions. “In 2018 during term time, staff and students travelled more than 66m business miles, emitting more than 18,000 tonnes of CO2e (carbon dioxide equivalent),” he explains. “This is approximately 20% of our carbon emissions, and our third highest source after emissions from the electricity and gas we use to heat and power our campuses.” The university has already started discussions about whether the number of travellers can be reduced, and whether additional value can be found by extending trips slightly to combine multiple engagements. “By helping departments to understand how much they travel, we have started to increase awareness,” says Pickering. This year the university plans to introduce a series of measures to reduce emissions from business travel. Some businesses have signed up to Climate Perks, a new scheme that works with climate-conscious employers to offer at least two paid “journey days” per year to staff who travel on holiday by train, coach or boat instead of flying. These are for people to use to travel to and from their holiday destination. More than 30 companies have signed up so far, according to the charity Possible (formerly known as 10:10 Climate Action), which launched the scheme. These are for people to use to travel to and from their holiday destination. Crucially, these days don’t come out of your annual leave allocation – so if, say, you get 25 days’ holiday a year, you get those extra travel days on top of that. More than 30 companies have signed up so far, according to the charity. In return, employers receive accreditation “in recognition of their climate leadership”. “When it comes to cutting plane travel, the solution must be based in behavioural and social change because there is no real technological solution for cutting aviation emissions,” says Emma Kemp at Possible. Although it recently signed up to Climate Perks, the ethical insurer Naturesave launched a similar initiative more than a decade ago for trips to Europe. “In recent years we have seen it grow,” says the marketing manager, Nick Oldridge. “Over the period we have run the policy, a quarter of staff have taken advantage of the benefit each year, resulting in an additional one or two days’ annual leave per person.” While he concedes there is a cost associated with this, there are undoubtable benefits. “Those who use the scheme have reported they enjoyed their holidays more and rediscovered the pleasure of travel,” he says. “They are also proud of being able to demonstrate to their friends and relatives that they have an employer who takes environmental issues seriously.” One employee taking advantage of the scheme is finance manager Abha Wells, who has used it for trips to Scotland and Belgium during the past two years. “Not only was it better for the environment, but we were also able to take our bikes, which made it even better. Now the climate emergency has become so critical, I am planning to take more trips overland using the extra days from our policy.” While carbon offsetting is offered by airlines and others, Cait Hewitt of Aviation Environment Federation says this isn’t the answer to reducing emissions. “Offsetting might look like a cheap and easy response to the climate change impacts of business flights, but while a well-run scheme will do some good elsewhere in the world, it does nothing to solve the problem of aviation emissions.” “There are no green flights on the market today. Rather than offsetting, businesses should look hard at how to cut back on flight numbers, change staff expectations about flying, and then maybe put the money they have saved towards research and development into genuine solutions for zero carbon aviation, whether that’s zero carbon fuel, electric aircraft, or technologies for capturing and locking away CO2 from the air once it’s emitted.” • Think about whether it’s essential to travel. Could you join the meeting by conference or video call? Is there someone who lives or works nearer to the event or meeting who could go? • If you have to go, could you get there by train? Any extra costs compared with flying can sometimes be offset by travelling on an overnight train and avoiding the cost of a hotel room. • If you do fly, travel economy (a business class seat has around three times the CO2 impact compared with economy, as a result of the extra space and weight it occupies, says the Aviation Environment Federation). • Try to choose the most efficient airline for the route. As well as showing you prices, websites such as Skyscanner display which flights are “greener” because they emit less CO2. This calculation is based on aircraft type, capacity and number of stops. • Don’t encourage extra flying by letting staff keep air miles. Find other ways to provide rewards."
nan
"When life on Earth began around 3.6 billion years ago, all organisms were small. Indeed, it took some 2.5 billion years to evolve any organism that grows larger than a single cell.  Since then, things have accelerated a bit and – along with the great diversification of body forms – animals have tended to get bigger. Indeed, the largest animal ever to live, the blue whale, is still very much with us, and has been swimming the world’s oceans for only a couple of million years – a mere blink of the eye in the long, long history of life in the sea. This trend towards larger body sizes through evolutionary time has become known as Cope’s Rule, after the American palaeontologist Edward Drinker Cope. Cope’s rule has been documented or disputed in hundreds of studies of numerous animal lineages over the last century, but a new study in the journal Science provides perhaps the most comprehensive test yet of its existence. The team, led by Noel Heim from Stanford University, delved into the fossil record to compile information on the body sizes of more than 17,000 kinds of marine animals that have existed since the start of the Cambrian period, 542 million years ago. The results are clear: both the average and maximum sizes of marine organisms have increased substantially over this period, whereas the minimum size has remained reasonably constant. To some extent this may seem inevitable: if life starts small, the only way to go is bigger. And although evolutionary biologists are always wary of narratives of “progress”, many innovations in evolution require a large body size – for example, the smallest vertebrates are inevitably larger than the smallest invertebrates, because it takes a certain size of organism to pack in all the stuff that vertebrates have.  Likewise, warm-blooded marine animals like whales can only stave off hypothermia if they are more than about a metre long. So the re-invasion of the seas by the ancestors of today’s marine mammals imposed a new hard boundary on the minimum size within this group, which in turn affects the average size across groups. In the new study, Heim and colleagues tested whether the observed increase in size could be explained by a simple evolutionary random walk, where body size is allowed to change randomly at each branching in the tree of life. They also modified this to impose a minimum possible size, such that the evolution of body sizes proceeded randomly but “bounced back” if a lineage hit this lower size limit.  Neither of these models fitted the observed data well. Instead, they show that only persistent directional selection for larger body sizes – due to the many advantages to being large – can explain the observed trends. Does this mean that sea creatures are all inexorably getting bigger, and will continue to do so until the oceans are full of behemoths? Not really. First, the minimum size has not changed, and – moving for a moment from evolution to ecology – it is well known that most species are small. In the seas this is especially pronounced, because marine food webs are typically highly size structured – that is, big things eat small things. It takes a lot of small fish to meet the energetic demands of a big fish, and so the only way these food webs can work is if small organisms substantially outnumber their larger predators. Second, Heim and colleagues show that most of the overall increase in body size across all marine animals is explained by the evolution of major new groups, with all of the anatomical and physiological innovation that implies. There is rather less of a drive towards larger sizes within any existing group. In fact, many ocean giants are already more or less as big as they could be, given physical and physiological limits.  In their fascinating study Sizing Ocean Giants published in the journal PeerJ earlier this year, marine biologist Craig McClain and colleagues document the factors limiting size in many of the most conspicuous large marine species. These include the risk of tentacle tangling in jellyfish, metabolic constraints on giant clams, physiological limitations of pumping water over gills in large bony fish, or the reliance of blue whales on dense concentrations of their crustacean prey. In the case of most groups of marine animals, then, it is unlikely that significantly larger members will evolve any time soon. So, even if Cope continues to rule unchallenged, a visitor to our future oceans is less likely to find them populated with fish the size of whales and whales the size of supertankers than with some new giants whose blueprints we do not yet know. However, Cope has an important rival now as an evolutionary force, and that is you, me, and everyone who directly or indirectly exploits our seas. The attitude of people down the ages when confronted with large marine creatures is encapsulated by my reaction when I first saw pictures of newly discovered giant deep sea amphipods: “Barbecue!”.  As a species we’ve been pretty effective at removing large animals wherever we roam. As McClain and colleagues say of manta rays (although this is equally applicable to most exploited marine creatures), “In the face of fishing pressure and other anthropogenic threats, it is likely that individuals in many populations may not be near their maximum possible ages or sizes.” In some species, such as plaice and cod, fisheries appear to have driven selection for smaller body sizes, and our evolving understanding of extinction risk in the seas suggests we should not take for granted the continued existence of the ocean’s giants. Of course, we have been around for too short a time to know if human-driven selection will remain a true competitor to Cope’s rule in the longer term. Indeed, as this new research shows, previous mass extinctions have led to sharp increases in body size among survivors. So who knows? Maybe Cope will again rule the waves following the current human-driven extinction crisis."
"Pesticides are intended to be harmful. They kill pests, diseases and weeds. But some also harm humans and wildlife. Pesticides are a huge global business, worth around US$45 billion. Each year, 3.5 billion kilogrammes of pesticides are applied to food crops and their use is growing. Much use of this use is at best ineffective and at worst outright harmful.  In recent research we showed that farmers in Asia and Africa have been able to cut the use of pesticides while boosting crop yields, reducing costs and delivering  healthier profits. Even the landscape surrounding the farms benefits. Each kilogramme of pesticide used in agriculture imposes €3-15 (US$4-19) of external economic costs on the environment, wildlife and human health – money spent by water companies to remove them from drinking water, for instance, or the loss of valuable pollinating insects. Any reduction in use, therefore, saves farmers costs, but also benefits the wider economy too. Cutting out pesticides can be a no-brainer. All pests have some natural predators and parasites and for farmers these are often free. Farmers can build their use into farm management and minimise or even replace synthetic pesticides. This is known as integrated pest management (IPM), an approach focused on manipulating the crop ecosystem rather than simply wiping pests out.  Through these farming strategies crop yields can be increased while reducing pesticide application and costs. Farmers get more and the environment wins too. Other research is increasingly showing that sustainable approaches in agriculture can both increase yields and improve the environment – whether the focus is management of soils, water, trees or livestock. In our research, we analysed 85 IPM projects from 24 countries in Asia and Africa that were implemented over the past 20 years. We wanted to assess their productivity and reliance on pesticides.  Across all the projects we found yields were up by an average of 41% over periods of 1-5 years after project implementation, while pesticide use went down by 69%. This goes against the conventional assumption which states that pesticide use and yields are positively correlated – as one goes up, so does the other. Our results show otherwise. Most cases we assessed fell firmly into the top-left section of the below graph where pesticide use falls and yields increase. The most significant innovation has been the deployment of farmer field schools (FFS) to spread IPM. These outdoor schools, which are run on principles of ecological education and learning through experience, don’t just teach farmers about new technology. They also boost ecological knowledge, problem-solving skills and teach farmers how to use their political strength. FFSs have been set up in 90 countries and there are huge numbers of graduates: 650,000 in Bangladesh, 930,000 in Vietnam and 1.5m in Indonesia. Some 20,000 FFS graduates worldwide are now running schools for other farmers, having graduated from farmer to expert trainer. Across the 24 countries and 85 projects we assessed, various different methods were employed to achieve these results. In the irrigated rice fields of Vietnam’s Mekong Delta, predatory beetles are excellent pest-controllers, but are killed when sprayed. Research showed insecticide applications in the first 40 days of rice planting were counter-productive. Two million farmers therefore adopted a “no early spray” rule, which saved money and reduced pesticide use by more than half. The melon fly is one of Bangladesh’s biggest pests. Rather than just spray the watermelon fields, simple pheromone traps were created using a male-scented lure in a recycled plastic jar or bottle with a small amount of insecticide. The results were spectacular: yields have risen 40-130% within 2 years, while insecticide use fell from 15 sprays per season to zero, meaning a healthy boost in profits. Clever behavioural manipulation can also make some cropped areas unattractive to pests. In Kenya, the push-pull system design – vutu sukumu – means farmers mix maize with legumes and plant grass varieties on field borders. The maize pests are pushed away by natural chemicals released by the legumes, while their predators are pulled in by the natural chemicals produced by the grass borders. As it happens, the mix also suppresses the invasive and parasitic Striga, better known as witchweed. Despite the evidence, many still believe IPM to be too complex for farmers to understand – and explicit national policy support has been relatively rare. In the past 20 years, the only countries that have seen significant falls in pesticide use are 
the UK (down 44%), France (down 38%), Japan (down 32%), and Vietnam (down 24%).   Some pesticide manufacturers have even appropriated the FFS model to promote greater use of their products. There are good reasons for such push-back: in some countries local markets for pesticides have collapsed, such as in East Java in Indonesia.   IPM has remarkable potential but the job is never done, so investment in research and development must continue in the long term. Ecological and economic conditions change; climates change too. Pests, diseases and weeds evolve, new pests and diseases emerge (often because of pesticide overuse) and pests and diseases are easily transported or are carried to new locations, often where natural enemies do not exist.  In just the past few years we have seen the emergence of the banana leaf roller in India and Nepal, the invasive cassava mealybug in south-east Asia, cucumber mosaic virus in Bangladesh, tomato yellow leaf curl virus in West Africa and cassava mosaic virus and brown streak virus in Uganda. Each requires rapid and co-ordinated action. But working with nature’s services – rather than against them – offers new routes to success. We have shown that millions of small farmers across Asia and Africa using IPM packages can deliver substantial reductions in pesticide use coupled with increased yields. Reduced reliance on synthetic pesticides delivers a range of on and off-farm benefits, including savings, improved public health and improved natural capital on and around farms. Yet, IPM, like other forms of sustainable intensification of agriculture, is much more than just a set of technologies. It is knowledge-intensive, builds social capital and so contributes to society too."
"What if you could sit at home and use your smartphone to buy energy directly from the wind farm down the road or the solar panels on the local school roof?  New technologies are about to disrupt the traditional energy market in a big way. After all, you can already control your heating from your phone, set your washing machine going from your tablet, and tell your oven when you want your dinner cooked from your office. We’re not far off the point where you’ll be able to tell your energy company you want to buy solar when it’s sunny and wind when it’s windy. This combination of cheap renewable energy, even on a small scale, with digital technologies presents a massive challenge to those big utilities who have grown used to simply posting you your bill once a quarter. In most countries large utilities control the generation, distribution and sale of energy. In the UK the big six control 95% of the market between them.  Your local solar farm or biogas plant can’t just jump in and compete directly – it has to sell into the grid through a wholesale market. That energy can then change hands multiple times before finally ending up with your supplier and on your bill. The physical electrons on the other hand don’t care who owns them and they go straight out of the solar farm to the closest consumer they can find. Remember from high school electronics? Electricity is lazy. So why can’t you already buy your power from the local wind farm? The owner of the turbines would get a better rate and so would you. After all, fewer middlemen surely means cheaper electricity.  This is indeed the case, until those calm, still evenings of summer when your wind farm isn’t doing so well and you want ice in your drinks. It’s right then that you need an energy company with lots of different types of generation to back you up. Until very recently there hasn’t been a way of getting the benefits of clean, local energy at the same time as keeping the lights on or the mojitos cool. In our research we investigated some new types of energy company that are looking to trade local power, help you reduce your energy bills and plough value from the energy sector back into local communities. Our report shows that a host of innovative business models are emerging in the energy sector that are proving a real challenge to fit into an energy system used to operating big national markets through multinational companies. We found an energy system that is missing the opportunities of local energy supply and has seen new entrants innovate underneath it.  Imagine a version of Uber that dealt with your electricity bill – start-up tech companies are already on the case, offering peer to peer energy platforms. New community enterprises are trialling smart meter installations to get cheaper bills by physically shifting power to cheaper parts of the day. Bigger organisations such as local authorities are setting up full blown energy companies in order to build more local generation and get a fairer deal for their citizens. Fitting all of this innovation into a national system that has to contend with EU regulations as well as keep an energy grid in perfect balance 24 hours a day and seven days a week is no easy task. The government knows this and so does the regulator. Energy secretary Ed Davey has supported the Local Electricity Supply report, and there has recently been an update to the UK’s Community Energy Strategy to help grow these new companies. The regulator Ofgem is curating an open discussion on how non-traditindonal business models might help or hinder the system and impact on consumers. Local energy service companies can help small businesses and households save money. They can plough money back into the local economy that currently leaks out of our cities like heat through an uninsulated loft. More, smaller companies armed with smart technologies and new approaches to energy services could mean a move from the big six to the “little six thousand”."
"Shortly after Hurricane Helene formed off the coast of West Africa on September 7, it did something unusual. Instead of following most hurricanes westward across the Atlantic, Helene turned north towards the UK and Ireland. Now downgraded to an “ex-hurricane”, Storm Helene is nonetheless expected to bring strong winds across much of England and Wales when it hits on September 17. Something similar happened in October 2017 when ex-Hurricane Ophelia turned north and hit the British Isles, causing three deaths and more than 200,000 homes to lose power.  At the time, Ophelia seemed like a very unusual storm due to the direct course it took across the Atlantic. However, two storms of this type in two years naturally raise the question of whether this is the new normal. As the ocean and atmosphere continue to warm, can people in Britain and Ireland expect more rogue, autumnal hurricanes? Broadly speaking, storms generated in the Atlantic fall into two categories. Normally, the storms responsible for poor autumn and winter weather over the British Isles are mid-latitude cyclones. These storms are largely fuelled by the atmospheric instability where cold and warm air masses meet. Many will be familiar with such features in the form of fronts shown in television forecasts.  In contrast, tropical cyclones, including hurricanes, derive most of their energy from the warm ocean waters over which they form. The change of state from water vapour to cloud droplets releases latent heat (energy) and produces deep convective clouds (thunderstorms). When conditions are favourable, a strong low pressure feature develops and helps to transport more fuel (in the form of moist air) into the storm. It is not unusual for tropical cyclones to develop into mid-latitude cyclones (this happens several times a year). In the Atlantic, the transition usually occurs when tropical cyclones have tracked west and gradually curved north into the mid-latitude storm track. However, the direct nature of the route taken by Ophelia and now Helene marks them out as unusual. So, do Ophelia and now Helene suggest a change in Atlantic storm behaviour? To understand this we need to think about how climate change will impact storms both in tropical and temperate regions. There is now a very clear trend of increasing sea surface temperatures, and it might be expected that warmer seas would lead to more frequent or more powerful tropical cyclones. However, it isn’t yet clear if that is the case for Atlantic hurricanes. What is likely is that warming seas will enable tropical storms to form further north, potentially meaning more will reach the polar front and transition into mid-latitude cyclones. It is also possible that tropical storms originating further north could be more influenced by the subtropical jet stream and be prematurely steered northeast towards Europe (as in the cases of Ophelia and Helene). However, it is unclear what effect climate change might have on the location and strength of the polar front and therefore the mid-latitude storm track. This is due to the sometimes opposing effects of climate change in models, such as the either poleward or equatorward shift of the Atlantic storm track. This kind of uncertainty makes it hard to estimate future storm behaviour, especially given weather systems are chaotic and linear changes to things like temperature or pressure do not produce linear effects. What is more certain is that rising sea levels will mean storm surges (abnormally high sea water levels that accompany powerful storms) will have to be less extreme before causing coastal inundation. It is also the case that with temperatures increasing, the atmosphere will be able to hold more water vapour, leading to hurricanes and mid-latitude cyclones that produce heavier rain and make flash flooding more frequent. Scientists still don’t know exactly how a changing climate will affect the weather. But we do know that the increasing occurrence of rare, extreme weather is detectable and we should expect more of it in the future. As yet, whether or not European hurricanes such as Ophelia and Helene will become more common is unknown. However, it is a further reminder of what an extraordinary year 2018 has been for global weather."
"The world’s energy watchdog has warned the oil and gas industry that it risks a public backlash by failing to act on the climate crisis in favour of making short-term profits. The International Energy Agency (IEA) said oil companies must balance their desire for near-term returns and a long-term future by playing a much more significant role in combating the climate crisis. The IEA is preparing to make its most direct call for oil companies to help tackle the climate crisis at the World Economic Forum’s annual meeting in Davos on Tuesday. The oil and gas industry faces “twin threats” to its financial profitability and social acceptability, according to the IEA. “There are already signs of both, whether in financial markets or in the reflexive antipathy towards fossil fuels that is increasingly visible in the public debate, at least in parts of Europe and North America,” it said. Fatih Birol, the IEA’s executive director, said: “No energy company will be unaffected by clean-energy transitions. Every part of the industry needs to consider how to respond. Doing nothing is simply not an option.” The report said that although some oil and gas companies have taken steps to support efforts to combat the climate crisis, the industry as a whole could play a much more significant role. Oil companies could do more now to help shrink the industry’s giant carbon footprint but most companies were yet to play a meaningful role, according to the report. The world’s oil companies have channelled less than 1% of their spending towards alternative energy technologies outside of oil and gas, despite growing calls to reduce greenhouse gas emissions. The leading oil companies spend about 5%, the report said. The IEA has called on the oil industry to use its “extensive knowhow and deep pockets” to help accelerate the development of clean energy and carbon capture technologies that could help absorb the greenhouse gas from factories before they enter the atmosphere. Last week Microsoft announced plans to establish a $1bn (£770m) fund dedicated to “carbon reduction, capture, and removal technologies” and aims to become “carbon negative” by 2030. The IEA report found that the combined spending of large oil and gas companies in projects beyond oil and gas was just over $2bn last year. “Without the industry’s input, these technologies may simply not achieve the scale needed for them to move the dial on emissions,” Birol said. “The first immediate task for all parts of the industry is reducing the carbon footprint of their own operations. As of today, around 15% of global energy-related greenhouse gas emissions come from the process of getting oil and gas out of the ground and to consumers.” Birol said a large part of these emissions could be brought down relatively quickly and easily by investing in technology that can stop methane leaking from fossil fuel projects into the atmosphere. The IEA has faced scathing criticism in the past that it is undermining the global shift from fossil fuels to renewable energy by mapping out influential future energy scenarios – used by governments to help set energy policy – which are not aligned with global climate targets. The IEA has called for a “grand coalition” of policymakers, investors and oil executives to work together to tackle the climate crisis but this is the first report to focus directly on the role for oil and gas companies in the energy transition. In Europe, major oil companies are facing rising public opposition, including a growing number of cultural institutions that have said they will no longer accept financial support from oil and gas companies. Last week the Royal College of General Practitioners cancelled a conference organised by the trade body Oil and Gas UK that was scheduled to take place on its premises later this month because it “conflicts with the college’s longstanding commitment to combat the impact of climate change on the environment and on the health of our patients”."
"
Share this...FacebookTwitterThe 4.6 trillion euro German green energies flop

By Prof. Fritz Vahrenholt and Frank Bosse
(German text translated/edited by P. Gosselin)
The demands for the phasing out of coal, fuel and natural gas are becoming ever more shrill in Germany. At first early this year it began with the bold proposal of the coal commission, half of which was occupied by green activists from the Federal Chancellery, calling on the phase-out of coal by 2038. Then came the demand by Green party leader Robert Habeck and his green friends for the phase-out of the internal combustion engine by 2030. And when it was very dry for four weeks in April, Annalena Baerbock declared a climate crisis and called for doubling the CO2 price and a strong regulatory law!
Now the Friday Children of Lummerland are demanding a CO2 tax of 180 euros per tonne this year, and that we reduce “greenhouse gas emissions to zero” by 2035, i.e. 100% renewable energies.
So far wind and sun cover only 2.5% of Germany’s primary energy needs
So it is worth taking a look at the study of the Academy project “Energy Systems of the Future” of the “Union of the German Academies of Sciences and Humanities” to see what’s ahead of us. All sectors, electricity, transport and heat are considered together. And look: 80% of the energy is produced by fossil fuels, 7.5% by nuclear energy and 13% by renewable energies. Once biomass (including biogas and biofuel) is subtracted from renewable energies, only 1.5% of primary energy is generated by wind power and 1% by photovoltaics (p. 10 of the study).
This is a long way from 100%. The study comes to the conclusion that if one wants to go the way of decarbonization, e.g. by 90% by 2050, then “around 1150 terawatt hours, almost twice as much electricity will be needed than today” will be needed (p. 10) because traffic and heat are also to be powered from electricity.
7-fold increase in wind and sun needed
Since only photovoltaics and wind power are considered, the study concludes:
In this case, the installed capacity of wind power and photovoltaics would have to be increased sevenfold compared to today (with the same energy consumption).”
Today, we (Germany) have around 28,000 wind turbines with an installed capacity of 57,000 megawatts and 46,000 megawatts of photovoltaics. A sevenfold increase in the photovoltaic area would require covering almost all roof-facades and other residential areas possible in Germany. A sevenfold increase in the capacity of the wind turbines would change Germany even if the capacity of the individual turbines were doubled. Every 1.5 kilometres a 200-meter tall 3-5 MW turbine would have to be installed.
Approaching abyss
The study also hints at the abyss that we are approaching in this way.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The dominance of the fluctuating renewable energies requires high flexibility on the electricity generation side and on the consumption side.”
In other words, if nature does not provide enough wind and solar power, you have to do without electricity for a while. It is interesting to note that even in the beautiful new world of decentralized green energy generation, it still wouldn’t be possible to go without large centralized power stations. The study estimates that some 60 – 100,000 megawatts of large-scale power plants, which of course would run on biogas or synthetic methane or hydrogen, would help prevent short-term grid collapses. For comparison: today’s large power plant capacity is 90,000 MW.
Storage absurdly expensive
The study’s claim that batteries could only be one solution for short-term storage is helpful. The prerequisite for long-term storage is the successful development of power-to-gas, that is converting wind power into hydrogen or even methane by electrolysis. This remains absurdly expensive today, but we can already do it. However, the authors warn that in days of a cold, dark lull (no sun and no wind in winter), there could be competition between power to heat (i.e. heat from wind power) and the demand for electricity when supply is scarce. That means one would have to choose between lighting and heating. The car would stop in any case.
The authors also correct the widespread misinterpretation of the car as a power storage device.
The buffer capacity of the electric fleet is in the range of a few hours.“
The 4.6 TRILLION euro power supply
The beautiful new world of the German Greens has a hefty price. In the study, the authors assume 60% CO2 reduction, which should be achieved by 2030. By then it will cost 4 trillion euros in a good 10 years. Today’s energy supply system costs 250 billion euros per year, but that will cost 1.5 trillion more. With 60 to 75% CO2 reduction, the authors expect a further 800 billion euros. From 75 to 85% yet another trillion. From 85 to 90% CO2 reduction will cost another 1.3 trillion euros. So 1.5 trillion euros up to 60%, and another 3.1 trillion euros up to 90% make together 4.6 trillion euros.
German households are to spend €4.6 trillion to avoid 800 million tonnes of CO2. This is the amount of CO2 that China emits additionally every year.
100% renewables would cost 764 euros – monthly!
So that the parents of Fridays for Future understand the 4.6 trillion figure correctly: that’s 153 billion euros a year. With 40 million households in Germany, each household would pay 382 euros per month. And if it goes according to Greta and her followers, namely to reach 100% renewable energies in 15 years, then that would be 764 euros per month – if it does not first come to a collapse of Germany, which would be very likely. That’s 764 euros for a monthly average income in Germany of 1,890 euros. This means that the average household would fall below the defined poverty line.
What a beautiful new world.
Sun and wind to decide when we can move or heat
We (Germans) are not even able even cope with the converting the electricity supply (see the warning of the Federal Network Agency to build reserve power plant capacity of 10,000 megawatts – 10 nuclear power plants – in 2022). Now we are expanding the problem to heat and transportation. All three sectors, which were previously dominated by different energy sources (coal, natural gas, crude oil), are to be made dependent on a single one: electricity from wind and sun. Wind and sun are to decide when we can move our car, how much heat we can use in winter and when the light can be switched on. This is what is best called a sustainable short-circuit.
Irrational rush
And why all this? Because of the climate crisis mentioned earlier, of course. And that’s why blogs like ours are necessary in order to make it clear to all decision-makers: Yes, we must leave the fossil era behind us by the end of this century. But we also have use this time, because the climate sensitivity of CO2 is much lower than the panic-makers and social system changers like to tell us.
Share this...FacebookTwitter "
"Despite the significant risks for human and non-human life, greenhouse gas emissions (GhG) are still rising. Something has to give – and that something would appear more significant than those with the power to stimulate change are willing to admit. The UK government’s Global Calculator is a good example. This recently released tool allows us to model the compatibility of our food, travel, housing and work environment with national targets to limit climate change. The climate secretary, Ed Davey, reckons the calculator shows “everyone in the world can prosper while limiting global temperature rises to two degrees, preventing the most serious impacts of climate change.” Yet even the most ambitious changes the tool advocates deviate little from our current “normal” patterns of behaviour – supposedly “essential” appliances still include tumble driers, while under the “extremely ambitious” scenario, the urban car would still account for 29% of journeys (currently 41.5%) per year. Meat is included as a core component of daily meals, and very few indicators relate to diet. It remains to be seen which government would adopt the “extremely ambitious” changes. This isn’t what a sustainable future looks like. It isn’t even close. Do we really need tumbledried clothes, or to eat meat every day? Transitioning to sustainability will require profound changes in our everyday ways of living, particularly in westernised countries. It requires changes that are much more significant than simply doing the things that we currently do, but more efficiently.   It’s not about driving more efficiently to reduce the GhG emissions of the commute, but perhaps leaving the car at home, cycling to work – or working from home. While tools such as the one above enable people to calculate their carbon footprint, they tell us little about the changes we’d actually need to make, and how these changes would affect our daily lives. Humans are adaptive creatures, able to move homes, jobs, retire or have children – all of which require us to break down and rebuild our existing ways of doing things. Consider how eating practices change with retirement. Many retirees find themselves with the time and desire to begin growing their own food in an allotment or their gardens. Retirement might provide the flexibility to shift energy-intensive cooking and laundry to daylight hours, taking advantage of solar energy. But retirement can also mean being less environmentally sustainable. The significance of food can diminish as a result of children leaving home or the loss of a partner. Ready meals (which are often worse for the environment) might take the place of cooking from scratch. And, as food becomes a leisure activity, this can involve more car journeys. The point is that people can and do make major life transitions, and these moments are big opportunities to go green. But also, that talking about “going green” as a significant change to how we currently live doesn’t have to be as daunting a prospect as it might first seem. So, rather than a Global Calculator that simply tells us whether or not we’re helping fight climate change, we suggest a more useful tool would be one that supports us in making a metaphorical “U-turn”. This tool would guide us through a process of throwing our lives out of kilter, and renegotiating and exploring more sustainable ways of being.  It couldn’t pull any punches. Rather than focusing on “things” and “stuff”, like a more efficient boiler or a washing machine that does eco mode, such a tool would have to be framed in terms of shifting practices – grow and cook more, eat little (or, better still, no) meat, work and travel less, wear more layers to keep warm and rely less on the heating, buy less “stuff”, and so on. But that’s not to say that living sustainably is easy. Significant changes to our lives are difficult and disruptive, even more so when current policies and infrastructures don’t comfortably support them (for example: public transport systems, expectations of appropriate work clothes). And so we should design tools that encourage us to make transitions towards sustainability that are themselves more sustainable. While big changes are needed, we should work towards them in smaller, more manageable steps. But, nonetheless, steps that involve reconsidering practices, not just tweaking them. After all, encouraging someone to think that switching washing machine, or buying a more efficient car is enough, is misleading. Far better to change practices entirely, so that driving less or line drying clothes becomes the new normal."
"In a few densely forested patches of Nigeria and Cameroon there lives a gorilla so rare and so elusive that the best way to study it is through training sniffer dogs to track down its faeces. This is the Cross River gorilla, and there are just 200-300 left in the wild. To find these shy creatures and learn more about them a team of scientists from Germany and the US turned to detection dogs. They have written about their findings in the Royal Society Open Science journal.  Most of us wish our encounters with faeces to be brief before we flush them away, but this is not the case for conservation biologists. The TV series You Are What You Eat hit on a truth: faecal matter is a rich source of information about its depositors. Faeces doesn’t just tell us what the owner has been eating – it also contains DNA, gut parasites, and hormones which can tell us about reproduction and stress levels.  The researchers in this particular study were after gorilla DNA, which can be used to determine the sex and identity of the individual; this information can then be used to estimate population size, the numbers in a social group, how far the group moves around and how closely related the individuals are. In the past wild population sizes were estimated by capturing individual animals, marking them and then after some time trying to recapture them.  It is possible to estimate population size using data gathered this way, but clearly this method is not appropriate for large and endangered species like gorillas.  However, this process can be simulated using the “recapture” of faeces from the same individuals, which is what the scientists did in this study. Gorillas, as you might imagine, create large piles of faeces. But despite their size, finding such deposits in a tropical forest is not an easy task for humans, especially when the gorillas themselves are so shy.  One way to overcome this problem is by using specially trained detector dogs to find the gorillas’ faeces (or scats as we biologists call them). The use of dogs as odour detectors goes back to the 1960s when they were first exploited to detect narcotics, and these days their olfactory abilities are employed to sniff out everything from explosives to cancerous tumours to the floating poop of killer whales. Scientists still debate how good a dog’s sense of smell is.  But research shows that they can detect chemicals in parts per trillion, whereas most chemical sensing machines work in parts per billion. Dogs possess 20 times as many olfactory receptors as humans, and they dedicate 40 times more of their brain to processing smells.  It is said that if their smell was taste they could detect a teaspoon of sugar in the amount of water needed to fill two Olympic swimming pools. They also can detect all the separate components of a smell; their nose can determine the ingredients list of whatever they are sniffing. Moths and bees can also be trained to detect explosives or drugs, while African pouched rats can detect landmines and even tuberculosis better than humans with machines. The advantage dogs have over insects and to an extent rats is their ability to cover large areas in short periods of time. But as with all detection animals the problem is the need for a human handler who often slows the dog down, especially in a mountainous tropical forest. The dogs used in this study were Working Dogs for Conservation flown in from the US . They proved more successful at finding scats than human fieldworkers and they were less biased in site location. Where human fieldworkers tended to look for gorilla nests and then procure scats nearby, dogs would instead scan the whole area.  This meant the dogs found scats belonging to more individual gorillas, which in turn bumped up the estimated population size.  Given sufficient field time the authors believe detection dogs would provide a precise estimate of gorilla population size. However, specially trained dogs and handlers imported from the US meant the cost per scat found was seven times more expensive than those found by human fieldworkers. This pilot study of just a few weeks cost nearly US$100,000.  The authors of this study recognise, despite the cost, the value of using detector dogs in longer term studies of highly endangered species such as Cross River gorillas, especially if dogs are simultaneously searching for scats of several endangered species.  And they suggest the establishment of a local detection dog program. Gorilla-hunting sniffer dogs for Africa? It’s a novel cause – but a worthy one."
nan
"Peat bogs, which cover 3% of the world’s land surface, are special places. While historically often considered as worthless morasses, today they are recognised as beautiful habitats providing environmental benefits from biodiversity to climate regulation. However, they are threatened by drainage, land reclamation for agriculture and peat cutting for fuel, which has significantly reduced the extent and condition of these ecosystems on a global scale. Bogs are fragile and sensitive to change, whether by human hands or by processes such as climate change. A less well known aspect of bogs is their remarkable archaeological potential. In their undisturbed state at least, bogs are anoxic (oxygen-free) environments due to their saturation. These conditions are hostile to the microbes and fungi that would normally decay organic material such as the remains of plants, which are the principal constituents of the peat. The same anoxic conditions also offer protection from decay for organic archaeological remains. The vast majority of objects and structures used by our ancestors were made from organic materials (in particular wood). These are normally lost on dryland archaeological sites but can be preserved in peatlands. The saturated conditions mean that even soft tissue can survive, including both skin and internal organs. Probably the best known archaeological finds are the remains of “bog bodies” such as the famous prehistoric Tollund Man in Denmark, Lindow Man in the UK, or the more recent Irish discoveries of Clonycavan Man, Old Croghan Man and Ireland’s oldest known bog body, Cashel Man, dated to the Bronze Age.   But archaeology is only part of the story these environments have to tell. They are important archives of the past in other ways: the layers of moss and other vegetation that make up peat are themselves immensely valuable as archives of past environments (palaeoenvironments). The manner in which peat accumulates means that the deposits have stratigraphic integrity, meaning that contained within each layer can be found macroscopic and microscopic remains of plants and other organisms that shed light on landscape change and biodiversity on timescales ranging from centuries to millennia. The high organic content of peat means that these records can be dated using the radiocarbon method. The best known such records are probably pollen grains which provide evidence of past vegetation change. But evidence from other organic material can be used to reconstruct other past environmental processes. For example, single-celled organisms called testate amoebae, preserved in sub-fossil form, are highly sensitive to peatland hydrology and have been extensively used in recent years to reconstruct a history of climatic changes. Meanwhile, fossil beetles can tell us how the biodiversity and nutrient status of a peatland has altered over time. The potential of bogs to preserve both environmental and archaeological records means that they can be regarded as archives of “hidden landscapes”. The accumulating peat literally seals and protects evidence of human activity ranging from the macroscopic (in the form of archaeological sites, artefacts and larger plant and animal remains) through to the microscopic (pollen, testate amoebae and other remains) material that provides contextual evidence of environmental processes.  Through detailed integrated analyses these records can provide evidence of past human activity ranging from the everyday exploitation of economic resources of peatlands, through to the ceremonies associated with prehistoric human sacrifice and the deposition of the so-called bog bodies. The associated palaeoenvironmental record can be used to situate these cultural processes within long term patterns of environmental changes. There has been extensive study of the palaeoenvironmental record from bogs and notable archaeological excavations of sites and artefacts, but there have been relatively few concerted attempts to integrate these approaches. In part this is because generating sufficient data to model the development of a bog in four dimensions (the fourth being time) is a formidable research challenge. But some peatlands have seen relatively extensive archaeological and palaeoenvironmental research over the last few decades, providing an excellent starting point. Hatfield and Thorne Moors, situated primarily in South Yorkshire, are two such peatlands. These two largest surviving areas of lowland bog in England are located within a wider lowland region known as the Humberhead Levels. After decades of industrial peat extraction, these bogs are now nature reserves managed by Natural England, and are becoming the “wild” bogs they once were. We are attempting to reconstruct the wildscape and bring the complex histories of this vast and dynamic boggy landscape to life. These moors are just two surviving parts of a once rich mosaic of wetland landscapes. In the past, this landscape was famed for its wildness – a remnant of an extensive complex of mires, rivers, meres and extensive floodplain wetlands.  Antiquarians such as John Leland visited the area in the 16th century, and his descriptions provide a “window onto what must have been a truly fabulous ‘everglades-like’ landscape”, as described by local historian Colin Howes. Now largely drained, tamed and converted to farmland, it’s hard to imagine the vast wetland landscapes that once characterised these areas. Following large-scale land reclamation in the 17th century, many of the traditional practises such as fishing, fowling, grazing and peat-cutting (turbary) rights were no longer available to commoners. Consequently, the connections between people and place became increasingly defined by a new, dryland landscape and disconnected from its former wetlands that were once so central to people’s lives. We are investigating and reconstructing this dynamic and changing wildscape throughout its history, reconnecting communities to these wetland landscapes. Drawing together previous research alongside targeted archaeological fieldwork and palaeoenvironmental analyses, we are combining these with newly available digital data and sophisticated modelling techniques to reconstruct their interwoven landscape and human histories. Together, for the first time, we are beginning to see the complexity of the dynamic and changing landscape that once characterised the Humberhead Levels."
"Last week Greta Thunberg and 20 other young climate activists demanded that world leaders gathering at Davos at the end of the month abandon fossil fuels. While no thinking human being could disagree with them, I find myself increasingly worried about the unthinking ageism that has crept into this movement. “Young people are being let down by old people and those in power,” they declared, as though the fact that the most powerful people are old means that most old people are powerful. Clearly, they aren’t. In reality, swaths of older people have neither money nor influence, and also support the school climate strikes. What’s happening here, I think, is that some young climate activists have adopted the intergenerational unfairness narrative – the one that also blames old people for zero-hours jobs, soaring house prices and pretty much everything else that’s bad, apart from the overconsumption of avocados. It’s the “OK, boomer” retort now applied to the climate, as expressed last month by the singer Billie Eilish: “Hopefully the adults and the old people start listening to us [about climate change]. Old people are gonna die, and don’t really care if we die, but we don’t wanna die yet.” But stereotyping old people as “après moi, le déluge” types who don’t give a fig about what happens to the planet after they leave it is nonsense. The majority of parents and grandparents are deeply concerned about what they leave behind for their families. (And let’s not be parentist about it, as if only those with offspring care about the planet. Indeed, there are plenty of older people who chose not to have children because of their concern for the planet.) The novelist Chimamanda Ngozi Adichie has warned of the dangers of the single story about another person or country, arguing that our lives are made up of many overlapping stories. “The single story creates stereotypes, and the problem with stereotypes is not that they are untrue, but that they are incomplete. They make one story become the only story,” she argued. This is what the youth climate narrative risks doing. Young climate activists have first-hand experience of ageism, having been admonished repeatedly (mostly by – yes! – old, white men) that they’re too young to know what they’re talking about. It would be a pity if they just flipped this over to stereotype older people. Indeed, over-65s grew up in pre-throwaway times and know all about keeping, repairing and reusing; we need those skills now more than ever. They also have the freedom to imagine a better world: as the radical American anti-ageism campaigner Maggie Kuhn pointed out: “We the elders should be society’s futurists … we have nothing to lose.” Of course the single story makes good copy, and some youth climate strikers, such as Jamie Margolin, co-founder of the youth climate justice movement Zero Hour, in her admirable Ted Talk, are much more nuanced in their analysis. In reality, it’s not generations but structures of power and domination, systems of extraction and exploitation of people and planet for profit, that have brought us to this point of peril. Thunberg recognises this when she eloquently attacks the idea of untrammelled economic growth. Polarising old and young isn’t an effective long-term strategy. If climate activism is to stand any chance of succeeding, it needs to be intergenerational and multigenerational, based on the idea of stewardship of the commons – those resources shared by us all that we need to safeguard for future generations. That way we can be sure future generations will actually exist. • Anne Karpf is the author of How to Age, and professor of life writing and culture at London Metropolitan University"
"China’s push for more intense farming has kept its city dwellers well-fed and helped lift millions of rural workers out of poverty. But it has come at a cost. Ecosystems in what should be one of the country’s most fertile region have already been badly damaged – some beyond repair – and the consequences will be felt across the world. This is part of a long-running trade-off between rising levels of food production and a deteriorating environment, revealed in recent research I conducted with colleagues from China and the UK. Yields of crops and fish have risen over the past 60 years at several locations we studied in Anhui, Jiangsu and Shanghai Provinces in eastern China.  But these are parallelled by long-term trends in poorer air and water quality, and reduced soil stability.   You may ask if this a bad thing.  After all, increasing agricultural productivity has been one of the factors responsible for lifting millions of rural Chinese out of poverty.  Does it really matter that the natural environment has taken a bit of a hit? Well yes. For agriculture and aquaculture to be sustainable from one generation to the next, the natural processes that stabilise soils, purify water or store carbon have to be maintained in stable states. These natural processes represent benefits for society, known as ecosystem services.   Throughout the latter half of the last century, these services were being lost relatively slowly through the cumulative, everyday actions of individual farmers. But the problems accelerated in the 1980s when farmers began to use more intensive methods, especially artificial fertilisers – and again after 2004 when subsidies were introduced.  Worryingly, in some localities, the slow deterioration has turned into a rapid downward spiral. Some aquatic ecosystems have dropped over tipping points into new, undesirable states where clear lakes suddenly become dominated by green algae with losses of high-value fish. These new states are not just detrimental to the continued high-level production of crops and fish but are very difficult and expensive to restore.   These natural processes are degraded and destabilised to the point that they cannot be depended upon to support intensive agriculture in the near future.  The whole region is losing its ability to withstand the impact of extreme events, from typhoons to global commodity prices. National policy must prioritise sustainable agriculture. This will mean big changes on the farm: fertiliser and pesticides must be applied in the correct quantities at the right time of the year, cattle slurry and human sewage must be disposed of properly, chemicals getting into streams and rivers must be reduced, and fish feed has to be controlled. Unfortunately, this is easier said than done. Farmers are still generally poor, badly educated and ageing. Good agricultural advice is lacking and big cities still tempt the younger farmers away from their fields. All these factors mean that rapid action is unlikely. The recent introduction of the Land Circulation reform policy, allows farmers to rent their land to larger combines. The policy is designed to overcome the inefficiencies of small farm holdings but it may not be taken up widely in the more marginal landscapes where potential profits are low.   All the evidence points to a need for a significantly improved system of information and technology transfer to individual smallholders, probably involving a more efficient coordination between agencies. But there’s a larger-scale context to this problem that may affect us all.  China’s grain production has risen fivefold since the 1950s, outstripping the pace of population growth. Despite this, the nation is no longer self-sufficient. The shift towards more meat production has placed a demand for soybean and cereal animal feed that can no longer be met internally. In 2012, China imported more than 60% of all the world’s soybeans that were available for export, and cereal imports are also on the up.   Reliance on imports to fill a shortfall in home produce is nothing new. But in China’s case, the additional risk that agriculture is increasingly unsustainable may amplify the demand. The potential scale of demand for imports is bound to have repercussions for global food production and food prices.  Unless reforms are introduced quickly, the rest of the world may well find that they are sharing China’s trade-off with nature – through the weekly shopping bill."
"
Share this...FacebookTwitterThe European Institute for Climate and Energy (EIKE) here presents two charts which I’m featuring today.
They show that the winter temperature trend for Germany over the past 32 years is not cooperating with “experts'” forecasts of rapid warming and snow and ice becoming a thing of the past.
The first chart, using the data from Germany’s DWD national weather service, shows that wintertime mean temperature trend in Germany has not risen in 32 years:

The green trendline shows that although CO2 in the atmosphere globally has increased from about 350 ppm since 1988 to about 412 ppm currently, Germany’s mean winter temperature has fallen a bit.
France winters cooling
The story is true for much of France as well. Japanese blogger Kirye prepared a chart depicting the winter mean temperature of 12 stations across the country using the untampered data available from the Japan Meteorology Agency (JMA):


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Source: http://ds.data.jma.go.jp/tcc/
Germany trending away from droughts
Also the German media are often filled with scare stories telling us we will be seeing increasing number of droughts and dryness, and that last year’s dry summer was just a taste of what is to come.
Yet once again the data contradict all the doomsday drought reports. The long term winter precipitation trend since records began has been upward.

However, we acknowledge the trend has been decreasing (to normal levels) since about 2000. Interestingly German precipitation shows a 40 year cycle, and so likely has nothing to do with CO2.
The annual precipitation trend for Germany has also been upward overall, and it too has been trending downward since about 2000 (during this time sunshine hours have increased):

Share this...FacebookTwitter "
"Our coral reefs are under threat. Around the world, the long-term survival of reefs is in question because of the environmental stress that climate change is placing on them. But some corals appear to be more resilient to this stress than others. Understanding how these corals are different may hold the key to better predicting how reefs will fare in the future, and perhaps even finding ways to help protect them. Tropical coral reefs are probably the most biodiverse ecosystems in the oceans, and support fishing industries and tourism to the value of US$36 billion a year. But when corals are exposed to an environmental stress such as a sharp increase in temperature, the relationship corals have with the various species of microalgae that live inside their tissues can break down. These algae are expelled, leaving the coral devoid of colour and, more importantly, its food source. These “bleached” corals aren’t yet dead and can recover if they regain their algae quickly enough. Otherwise, corals essentially starve to death. Unfortunately for corals, sharp increases in temperature, known as “marine heatwaves”, are expected to become more frequent and severe because of human-caused climate change.  Coral bleaching has received a lot of media attention in recent years, often with dire predictions for the future survival of coral reef ecosystems. But there is hope. Recent research has shown that coral bleaching has long occurred naturally, since well before human industry began warming the climate. Importantly, the corals analysed in this study recovered after each bleaching event, providing hope that corals today could survive even repeated bleaching events. But the study also found that both the percentage of corals bleaching and number of years in a decade that bleaching occurs has been increasing since the 1800s. If this trajectory continues, there may come a time when recovery from bleaching is not possible. Another source of hope are coralliths, free-living mobile corals that are common in many reefs around the world, but whose physiology has only recently been investigated. These corals  are typically found in areas of reef not otherwise considered favourable for coral growth such as rubble patches. It turns out that these species are physiologically different from their stable counterparts and better at responding to acute environmental change. We also know that there are some species of algae that are more resilient to ocean warming. For example, corals that bond with Durusdinium algae are less likely to bleach.  Our knowledge about these kinds of hardy corals is growing, perhaps because their presence on reefs is becoming more obvious as attention over bleaching events increases. But what can we do with this knowledge? One option being trialled on reefs around the world is transplantation. Fragments or larvae of hardy corals are grown in nurseries and then planted out on a reef by divers. The problem is transplantation is incredibly labour intensive and the transplanted corals often don’t survive very long. While it might be option for smaller reefs and for increasing public awareness, transplantation is unlikely to be a feasible way of restoring large reef areas. 


      Read more:
      3D printing coral reefs can create new habitat – but it doesn't tackle human destruction


 Another approach may be to manipulate the strains of algae associated with the corals to make them and the corals more tolerant to the stress of climate change. However, the rate of success of getting corals to take on new types of algae varies, and it’s a difficult job to say the least.  Corals have a long evolutionary history, and even in today’s rapidly changing climate some display a remarkable resilience to environmental stressors such as warming events. This should give us hope for their continued survival. But the greater the warming, the smaller the window of resilience.  Rather than providing a cure to bleaching, these kind of measures to restore coral reefs are dealing with the symptoms. For the long-term survival of coral reefs, we still need to take more action to deal with climate change and limiting the extent of global warming over the next 50 to 100 years."
"
Share this...FacebookTwitterThe West Coast of North America has 20 long-term (90+ years) tide gauges measuring relative sea level changes. The East Coast has 33. Of the 53 total tide gauges, 45% (24) are negatively accelerating, 14 document falling sea levels, and just 11 have sea levels rising more than 3 mm/yr.

Image Source: Boretti, 2019
A cooling/non-warming North America
A few months ago, Gan et al. (2019) reported that the North American continent as a whole (180-0°, 15-60°N) “is one of the major cooling centers” in the Northern Hemisphere, with temperatures dropping after 1998 and no signficant net change since the early 1980s apparent.
Image Source: Gan et al. (2019)
The contiguous United States has even undergone an overall cooling or non-warming trend – especially on the Eastern half – since 1900 (Partridge et al., 2018).

Image Source: Partridge et al., 2018

Image Source: Partridge et al., 2018
U.S. East Coast has been expanding, not shrinking, since 1960
A few months ago Armstrong and Lazarus (2019) indicated “trends in recent rates of shoreline change along the U.S. Atlantic Coast reflect an especially puzzling increase in accretion, not erosion.”
From 1830 to 1956, shorelines eroded at the rapid rate of -55 cm per year on average. Since 1960, the U.S. Atlantic coast has been expanding (accretion) at a rate of +5 cm per year.

Image Source: Armstrong and Lazarus, 2019
12 of 15 Florida Bay islands have also been expanding in size since the 1950s (Zhai et al., 2019).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Image Source: Zhai et al., 2019
New study: 45% of 53 long-term North America tide gauges show negative acceleration
A new paper (Boretti, 2019) utilizes 90+ years of continuous tide gauge data from the Permanent Service for Mean Sea Level (PSMSL) to record the sea level trends from the West Coast (20) and East Coast (33) of North America.
Boretti finds the average sea level change for the 20 West Coast tide gauges amounts to -0.38 mm/yr, whereas the average sea level rise rate is +2.22 mm/yr for the 33 East Coast gauges. Much of the relative differences between the two coasts can be explained by land subsidence (sinking) or uplift (rising).
“Nearly the entire East Coast of the United States, from Massachusetts and parts of Maine to Florida, is known to be affected by subsidence [6–10]. Subsidence is much stronger along the East Coast of the United States and significant only in Southern California along the West Coast, and it increased in intensity since the mid-1900s.”

Image Source: Boretti, 2019
Of the 53 total tide gauges on North America’s East and West coasts, 45% (24) are negatively accelerating, 14 document falling sea levels, and just 11 have sea levels rising more than +3 mm/yr.
The overall acceleration for both the East and West coasts amounts to just +0.0028 mm/yr² and +0.0012 mm/yr², respectively, when using the late 1800s and early 1900s as the starting years.
An analysis by Houston and Dean (2011) showed that when the sea level trend begins in 1930, the U.S. coasts as a whole actually decelerated overall (-0.013 mm/yr²) during 1930-2007.

Image Source: Houston and Dean, 2011
These modest trends would not appear to support the conention that modern sea level changes in this region are rising at alarming rates.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman political analysis and commentary site Freie Welt here has an article on how millions of  Germans are increasingly unable to afford electric power.

Germany’s Energiewende ‘ risks shorting out as millions struggle to pay their electricity bills. Image cropped here.
While a number of commodities such as electronics, electrical goods and computing power across the country – and the globe – have gotten much cheaper over the years due to development, the price of electricity in Germany has “more than doubled since 2000”.
5 million struggling to pay for their power
Almost all of this is due to the Germany’s ‘Energiewende’: the transition to renewable energies and away from nuclear power and fossil fuels like coal.
According to the Freie Welt: “Last year, almost five million people in Germany had problems paying their electricity bills” as some 4.8 million defaulting customers “were threatened” by power companies.
“As a consequence of unpaid bills, almost 344,000 households were temporarily cut off electricity during the same period. This marks new records,” the Freie Welt reports.
“Next increases already in the pipeline”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The situation for Germans will likely get a lot worse before it gets better. Less than a third of the country’s power is supplied by wind and sun, and as that share rises – as is planned – the costs will only continue to climb and make the hardship for the poor even worse.
“Three quarters of the energy suppliers had raised their prices at the beginning of this year again on the average by five per cent,” Writes Freie Welt. “The next increases are already in the pipeline.”
At 29.42 cents a kilowatt-hour, Germans pay among the highest prices in the world.
Further price increases in the medium to long term
According to Valerian Vogel of the utility Verifox: “In view of the major challenges facing the German electricity system, consumers must prepare themselves for further increases in electricity prices in the medium to long term”.
In Germany, the high prices are mostly made up of taxes, levies, grid fees and green energy feed-in tariffs.
In its report, Freie Welt cites figures from the Federal Network Agency, which says wholesales price for electricity are mostly to blame for the excruciatingly painful prices levels. According to the Federal Network Agency, “Last year was around 30 percent higher than the average price for 2017.”
Fridays for Future (unintended) Revolution
Ironically, the Fridays for Future (skip school) movement yesterday issued a call in Berlin for an even more rapid completion of the coal and fossil fuel power phaseout. They demanded that this phaseout be completed by 2030 rather than 2038. The movement, backed by activist scientists, is in fact calling for a revolution.
And a revolution they will get, but very likely not the kind they are bargaining for.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterTenders for new wind energy projects in Germany “have fallen to a new, all-time low”, the online IWR reports here.
After the installation of thousands of megawatts of German wind power capacity led to instability in the power grid, exploding electricity prices and the destruction of natural landscapes and biotopes, protests against wind projects ratcheted up to the point where the government was forced to scale back on subsidies two years ago. The result: investments in wind parks, once seen as the future of Germany’s energy supply, have since collapsed.
The IWR writes: ”
The negative trend in the construction of new wind turbines in Germany, which has persisted for more than a year, is thus intensifying.”
And: “A short- or medium-term change is not to be expected,” the IWR reports.
As of September 1, 2019, the Federal Network Agency (BNetzA) has put out to tender 500 megawatts (MW) of wind power capacity, but so far “only 176 MW could be awarded in permissible bids”.
The grinding halt in wind energy by Germany flies in the face of the country’s commitment to transition over to green energies by 2050. Already experts say Germany will fail to meet its 2020 comitments.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Following the solar energy industry to the graveyard
IWR Director Dr. Norbert Allnoch said: “Politicians are frivolously jeopardizing the economic location of another future-oriented industry, as they did years ago with the solar industry.”
Will the “restart” be enough?
The wind industry is now placing its hopes on a “restart” on green energy investment announced by finance minister Olaf Scholz in his opening speech that kicked off debate in parliament on national spending in 2020. “More of the same will no longer help us,” Scholz said on the German government’s strategy to push climate-friendly activities through support programs and tax rebates.
Climate cabinet to roll out new measures
Major decisions on green energy programs and investments are expected to be announced by the country’s “climate cabinet” on 20 September 20th, but details on wind energy expansion plans remain vague. Currently onshore wind park projects face fierce opposition from hundreds of citizen protest groups and traditional environmentalists who believe the destruction of the German landscape is not an ecological price worth paying
On other fronts, Scholz foresees a pricing system for CO2 and that any measure would need to be financially designed “in a way that works for citizens”.
“We failed to take the necessary decisions in the past decades. There is now no more time to waste,” Scholz said.
Share this...FacebookTwitter "
"Making something illegal will not stop it happening – just look at the trade in endangered animal parts in traditional Chinese medicine.  And in some cases making an activity illegal has made it more desirable, the consumption of bush meat in Africa being a case in point.  The forbidden fruit, or in this case monkey, tastes sweeter. It’s clear that any crackdown on illicit activity needs to address motivations. Foxhunting is a great example. Ten years after hunting with dogs was outlawed in the UK, prime minister David Cameron has promised MPs an open vote on repealing the ban if he wins the general election. Though 80% of England’s population is against it, clearly the rest still want to carry on as before. Perhaps what fox hunting diehards need is an alternative. Not something that simply exists to keep the authorities happy, but a competitive alternative in its own right. Maybe they could look to east Africa for inspiration, where the Maasai people have traded lion hunting for a different sort of competitive thrill-seeking. Addressing fox hunting requires an understanding of its causes. Politics aside, the question is why there is still such a desire to chase and kill foxes with hounds. Fox populations have not exploded since the ban, so there is no argument in terms of pest control. And in any case lamping – the dazzling of a fox with a bright light and then shooting it – when carried out by a trained marksman has been shown to be a much more effective and humane method of control. Fox hunting enthusiasts argue it is part of the nation’s cultural heritage and that the ban is eroding the culture of countryside folk. This argument is used by indigenous people to hunt everything from polar bears to dugongs or whales.  Fox hunters are quick to point out their target is officially classified as a pest not an endangered species.   But culture changes, people say, and fox hunting need not be part of the UK’s social life for ever. Child labour, for instance, was an important part of the industrial revolution in the UK – it’s now long banned, and no one wants to bring back the traditional chimney sweep. The fox hunting lobby isn’t buying into the argument that culture moves on.  They point out that the number of hunts is still the same as before the ban. Of course since the ban they have been able to engage in substitute activities such as trail hunting, the laying down and following of an artificial trail in the pattern that a fox would leave across appropriate terrain.  Thus the hunters have had outlets for their desires. Many people accept that their motivations to hunt are no longer appropriate in a modern society where food is easily available.  Fishermen practice catch and release, and hunters can shoot clay pigeons.  These activities have been turned into games: fishermen can compete in matches or at least tell their tales of the one who got away, whereas clay pigeon shooting is featured in the Olympics. Pride, prizes and prestige can be gained in these sports.  Something that is missing I suspect from trail hunting, which is born out of a stigmatised activity that now has no obvious prize.  In the past, hunts could boast of how many kills they had made in a season. Lions in Africa are another species that soon could be on the endangered species list.  Realising this, the Maasai of Kenya and Tanzania have changed one important part of their cultural heritage.  Traditionally for a man to become a warrior, a leader or at least attract a wife, he needed to go out and kill a lion.  Since 2012 the Maasai have substituted killing lions with the Maasai Olympics where they can run, jump and throw against each other.   The winners gain medals, prizes and prestige – the same honours once gained through lion-killing. This shows culture is not a static thing but it evolves in relation to its environment.  If culture does not evolve then as all things suffering Darwinian forces it will go extinct – the Maasai know this. Maasai men have been killing lions for much longer than people in the UK have been hunting foxes with hounds but have quickly accepted a change in their culture.  Those wishing to repeal the Hunting Act would do well to think about the lessons to be learned from the Maasai.  Even cultural conservation is not preservation – it is about adapting to change in your environment and acting sustainably."
"Much of the Earth was once cloaked in vast forests, from the subarctic snowforests to the Amazon and Congo basins.  As humankind colonised the far corners of our planet, we cleared large areas to harvest wood, make way for farmland, and build towns and cities. The loss of forest has wrought dramatic consequences for biodiversity and is the primary driver of the global extinction crisis. I work in Borneo where huge expanses of tropical forest are cleared to make way for palm oil plantations. The biological cost is the replacement of some 150 forest bird species with a few tens of farmland species. But forest is also frequently retained inside or at the edges of oil palm plantations, and this is a pattern that is replicated globally. The problem, according to new research published in Science Advances, is that the vast majority of remaining forests are fragmented. In other words, remaining forests are increasingly isolated from other forests by a sea of transformed lands, and they are found in ever-smaller sized patches. The shockwaves of loss thus extend far beyond the footprint of deforestation. The team, led by Nick Haddad from North Carolina State University, used the world’s first high-resolution satellite map of tree cover to measure how isolated remaining forests are from a non-forest edge. Edges are created by a plethora of deforesting activities, from roads to cattle pastures and oil wells, as well as by rivers.   They found that more than 70% of remaining forest is within just 1km (about 0.6 miles) of an edge, while a 100 metre stroll from an edge would enable you to reach 20% of global forests. Comparing across regions, the patterns they find are even starker. In Europe and the US, the vast majority of forest is within 1km of an edge – some of the most “remote” areas in these regions are a stones throw from human activity. “Getting away from it all” has never been more challenging.  If you want remote forests on a large scale you’ll have to head to the Amazon, the Congo, or to a lesser degree, central and far eastern Russia, central Borneo and Papua New Guinea. These findings wouldn’t be cause for alarm if wildlife, forests, and the services that they provide humankind such as carbon storage and water, were unaffected by fragmentation. However, by drawing together scientific evidence from seven long-term fragmentation experiments, Haddad and colleagues show that fragmentation reduces biodiversity by up to 75%. This exacerbates the extinction risk of millions of forest species, many of which we still don’t know much about. Forest species struggle to survive at edges because these places are brighter, windier, and hotter than forest interiors. Edges become choked by rampant vines and invaded by disturbance-tolerant, parasitic or invasive species that outcompete the denizens of dark forest interiors. In Borneo, for example, small forest patches house bird communities that are far more similar to those found in the surrounding oil palm than to those of larger forest tracts.   The survival of large, carbon-rich trees – the building blocks of any intact forest ecosystem – is reduced in smaller and more isolated forest fragments.  These patches thus fail to maintain viable populations, which over time are doomed – an “extinction debt” yet to be paid. With so much global forest in close proximity to humans, larger forest animals such as chimpanzees, gorillas, tapirs or curassow birds are being hunted to extinction in individual areas. This shifts animal communities within the forest fragments to one dominated by small-bodied species.  Further, hunters are willing to penetrate forests for several kilometres from edges in search of game, effectively making the truly wild global forest estate yet smaller.  The insidious effects of fragmentation mean that the top conservation priority must be preventing further incursions into dwindling wildernesses. By preventing the first cut we can help to prevent global fragmentation and the further loss of biodiversity. Of course, we should not ignore fragmented regions.  Some of these, including the Brazilian Atlantic forest, Tropical Andes and Himalayas, share a toxic mix of hyperdiversity, endemic species with tiny ranges, and severe fragmentation. The critically-endangered Munchique wood-wren, for instance, exists only in a handful of peaks in the Colombian Andes, but these are now isolated from each other by cattle pastures and roads. Here we must seek to restore forest cover and improve connectivity between larger fragments if we are to prevent extinctions. However, the rapid expansion of human populations, greed, and meat consumption mean that more forest is likely to be lost, even if farm yield and efficiency can be improved to help bridge gaps between current and future demand. The difficult question is where should this expansion happen? Given the severe degradation of small and isolated fragments, perhaps conversion could target some of these patches, coupled with wilderness protection and expansion. Next time I visit my local National Park – the highly fragmented Peak District – I will spare a thought for the species that are being harmed by their habitats being broken up into ever smaller chunks. There are no easy answers to the problems of fragmentation, but our forests urgently need a global management plan."
"Renewable electricity has nearly trebled under this government.  Ed Davey, Liberal Democrat energy and climate change minister, during an environment debate held by the Daily Politics show. Amid the climate of mistrust about claims made by politicians that tends to accompany election campaigns, it is reassuring to report that the evidence supports the minister’s statement. According to official figures on renewable electricity, installed generation capacity in the UK in 2014 was 2.6 times higher than in 2010, while actual generation of renewable electricity was 2.5 times higher. For further detail see the methodology for data collection by the Department of Energy and Climate Change.  As well as electricity generated by onshore and offshore wind, solar photovoltaic, hydro, and shoreline wave/tidal energy, these figures include electricity generated by organic material. This includes landfill gas, sewage sludge, waste, animal biomass (poultry litter, meat and bone), wet biomass waste (such as animal manure and slurry), and plant biomass (including straw and energy crops).  Although most of this involves generating electricity by combustion, which yields CO2 as a byproduct in the same way as fossil fuel combustion, these organic materials decompose naturally to produce CO2 and other greenhouse gases anyway, so using them to generate electricity has little effect on net greenhouse gas emissions. The main growth area was wind, which accounts for about half of Britain’s renewable electricity, followed by photovoltaic and plant biomass. Provisional data shows that renewables contributed a record 19.2% of electricity generation in 2014.  This increase in renewable electricity can be attributed in part to the Renewables Obligation set up by the previous Labour government in 2002, which obliged electricity supply companies to source an increasing proportion of their electricity from renewable sources. However, the Contracts for Difference feed-in tariff system introduced by the coalition for large-scale energy generation – which established a set price that is high enough to enable investors to make a profit – is probably responsible for increasing the rate of growth. Expert studies have shown that feed-in tariffs are more effective than quota systems in encouraging investment in renewable electricity. The flaw in the coalition’s strategy is that while in other countries, electricity supply companies are obliged to buy all the electricity generated by renewable sources at the feed-in tariff price, which is higher than the market price, in Britain, supply companies buy at the market price and the government pays the difference. As a consequence, expansion of renewable electricity is limited not only by investors’ willingness to invest and planning issues, but also by budgetary constraints. As spending cuts are the order of the day, this means that we cannot be sure that the current rate of expansion will be sustained. Ed Davey’s claim that renewable electricity has almost trebled during the coalition’s term of office is accurate, but flaws in Britain’s feed-in tariff system mean that further expansion may be limited. The coalition certainly deserves some credit for its record on creating new sources of renewable electricity, and it is also true that the fear of electoral unpopularity regarding high energy bills has hampered the efficacy of its achievements. These could have been even higher if the energy companies had been required to purchase higher tariff renewable energy from distributed sources. However, when energy for heating and transport (which still depends primarily on fossil fuels) is taken into account, renewables represent only 5% of energy supply in the UK, according to the 2014 Digest of UK Energy Statistics. There is widespread acceptance, including by the UK government, that greenhouse gas emissions need to be reduced to keep global temperatures from rising beyond 2°C.   The Centre for Alternative Technology’s report Zero Carbon Britain suggests that it is helpful to think the world has a finite amount of greenhouse gases it can emit to keep within the 2°C threshold. This is known as the emissions budget. The report predicts the UK’s share of the global emissions budget (offering a 75% chance of keeping below 2°C) at about 10,000 MtCO2e between now and 2050. At the current emission rate the country will produce 16,000 MtCO2e by the middle of the century.  Voters would do well to avoid the rhetoric over renewable electricity and ask which party’s policies are most likely to decarbonise all parts of the country’s energy budget, and how quickly they say they can do this. – Erik Bichard "
"
Share this...FacebookTwitterA German psychiatrist has read the Thunbergs’ book, observed climate movement and finds it’s all about fanaticism: “utopian character of demands”…”inability to engage in dialogue and compromise”.

Image: S. Fischer Verlag
Prof. Dr. med. Dipl.-Psych. Wolfgang Meins, neuropsychologist and professor of psychiatry, penned an article recently published at German libertarian site Achgut.com which looks at Greta Thunberg, her parents and the Green movement she has helped to propel. The title of the article: Greta and her parents – not hysterical, but fanatic. 
Prof. Meins read Thunberg’s German language book: Szenen aus dem Herzen and believes Thunberg and her movement are all about climate fanaticism and not climate hysteria. He also warns that politicians need to sober up and face the fanaticism for what it is.
Rooted in obsessive-compulsive disorder, autism
Meins writes that one special characteristic of fanatics is their “inability to engage in dialogue and compromise,” which leads to the fact that people are declared “external enemies” who are “potentially also fought with aggressive and destructive means.”
Meins attributes Greta Thunberg’s climate fanaticism to an obsessive-compulsive disorder and her autism.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Her disability, Meins writes, is rooted in the fact “that as an Asperger autistic, she tends to focus very strongly on a special field of interest. People with Asperger syndrome show little compassion and interest in other people,” he writes.
This means “you are as good as immune to the suffering of your fellow human beings”. For example, “people who would become unemployed as a result of banning all flights”.
Strongly emotional convictions dominate, permanently determine thinking
Meins writes: “The climate fanatics are united by a superior idea, i.e. strongly emotional convictions that absolutely dominate and permanently determine their thinking, for example: The CO2-induced apocalypse is irrevocably imminent unless we take immediate, radical countermeasures at any cost. In Greta’s case, superior ideas of this kind developed through a small distraction, based on a related theme: During a school lesson in autumn 2014, she sees a film about the pollution of the oceans. She bursts into tears during the film. At noon she sits in the cafeteria in front of her burger, which she does not touch. From then on, if I correctly interpret the mother’s vague statements, she only eats vegan, if anything at all.”
“Elites almost unanimously paying homage to a fanatic”
“The very special thing about Greta and her fans is that they are courted by large parts of the Western elites, and above all German elites. One hardly hears anything critical from these circles at all,” says Meins. “It is probably the first time since the end of the Second World War that these elites almost unanimously pay homage to a fanatic, and often even encourage Greta and her followers.
With regard to the SPD and especially the CDU-related “elite actors”, Meins assumes that “the completely utopian character of demands for a radical change in climate policy, now and immediately, is clear to them. He accuses them of cowardly refusing to “open the door to the fabulous realm of the climate apocalypse”. Their fear of being driven into political suicide due to “argumentative awkwardness, overlooked pitfalls and media that act on this issue” is overwhelming.
“No need to worry about ecodictatory regulations and prohibitions”
Meins writes in his article that “you get to know quite exactly how climate fanatics tick.” He adds: “For example, that one does not have to worry about the political, economic and social consequences of certain drastic or perhaps better: ecodictatory regulations and prohibitions. Why should they? There is no alternative to such measures, because otherwise we will “burn” or otherwise perish.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSatellite observations indicate the Earth has become much greener in recent decades. According to scientists, the overwhelming majority of the “significant increases in tropical forests and the forests of North America, Eurasia, and China” since the early 1990s can be attributed to the combination of CO2 fertilization (56%) and climate change (35%).

Image Source: O’Sullivan et al., 2019
O’Sullivan et al., 2019
“The recent warming hiatus (1998–2013) was identified as a potential key mechanism behind the increased land sink during this period via reduced ecosystem respiration (Ballantyne et al., 2017).”
“At the global scale, simulated NPP [net primary production, greening] increased substantially over the 20th century to present day from 56.2 (mean of 1901–1910) to 66.0 Pg C/year (mean of 2007–2016) with positive contributions from all drivers considered, including rising CO2 concentrations (referred to as CO2 fertilization), nitrogen deposition, climate, and carbon‐nitrogen as well as carbon‐climate synergies. The relative contribution of these drivers to this overall NPP increase amounts to 60% for increased CO2, 15% for nitrogen deposition, 8% for carbon‐nitrogen synergy, 9% for carbon‐climate synergy, and 8% for climate. Both CO2 fertilization and nitrogen deposition individually caused a smooth, transient increase in NPP, in line with the trajectory of the corresponding drivers.”
“[R]esults show a global NPP [net primary production, greening] increase of 3.4 Pg C/year between the early 1990s (mean of 1990–1996) and the end of our study period (2010–2016), with CO2 fertilization and climate being the dominant drivers, accounting for 56% and 35% of the overall change, respectively.”
“Carbon‐climate interactions led to significant increases in tropical forests and the forests of North America, Eurasia, and China.”
A dozen new papers attest to the substantially positive impact that CO2 fertilization and warming has had on the biosphere.
• Due especially to the rise in CO2 concentrations, 52% of the globe’s vegetated lands have shown statistically significant greening/gross primary production trends since 1981, whereas just 12% of vegetated areas have been browning. CO2’s greening effect has been underestimated by 60% with outdated models.

Image Source: Winkler et al., 2019
Winkler et al., 2019
“Historical increase of atmospheric CO2 concentration, from 280 to current 400 ppm, has resulted in enhanced GPP [gross primary production/greening] due to its radiative and physiological effects, which is indirectly evident in amplified seasonal swings of atmospheric CO2 concentration and large scale increase in summer time green leaf area. Thus, these observables, expressed as sensitivities to ambient CO2 concentration, might serve as predictors of changes in GPP and help to reduce uncertainty in multimodel projections of terrestrial carbon cycle entities. This study is focused on the northern high latitudes (NHL, north of 60°N) where significant and linked changes in climate and vegetation have been observed in the past 3–4 decades: 52% of the vegetated lands show statistically significant greening trends over the 36-year record of satellite observations (1981–2016, Methods), while only 12% show browning trends, mostly in the North American boreal forests due to disturbances.”
“Here, we apply the concept of Emergent Constraints (EC) to reduce uncertainty in multi-model projections of GPP using historical simulations and satellite observations of LAI focusing on NHL. We find that the EC estimate [of the effect of CO2 on greening/GPP] is 60% larger than the commonly accepted multi-model mean value, in line with a recent study that assessed the impact of physiological effects of higher CO2 concentration on GPP of northern hemispheric extra-tropical vegetation. Detailed independent analyses of insitu CO2 measurements and atmospheric inversions imbue confidence in our conclusions. Our central finding is, the effect of ambient CO2 concentration on terrestrial photosynthesis is larger than previously thought, and thus, has important implications for future carbon cycle and climate.”
• According to observations, the Earth – especially its dryland regions – has been greening due to climate change (CO2 and temperature rise).
Brandt et al., 2019
“Recent Earth observation studies find a greening of the Earth and in particular in global drylands, which is commonly interpreted as a global increase in net primary production and has been attributed to climate change. Although changes in rainfall, fire regimes, elevated temperatures, atmospheric CO2 and nitrogen depositions are suggested explanations, only few studies provide quantitative evidence on both the biophysical processes (changes in vegetation cover, structure and composition) and controlling factors of long-term dryland vegetation trends.”
Qiu et al., 2019
“Our results show that both net primary production (NPP) and heterotrophic respiration (HR) of northern peatlands increased over the past century in response to CO2 and climate change.”
• The “remarkable” vegetation greening in the Yellow River Basin since 2000 is expected to continue for 73% of the region.

Image Source: Wang et al., 2019
Wang et al., 2019
“Changes in Vegetation Greenness in the Upper and Middle Reaches of the Yellow River Basin over 2000–2015 … In this study, the vegetation dynamic characteristics were analyzed for unconverted forestland, shrubland, grassland, cropland, and converted forestland, shrubland, and grassland from cropland over 2000–2015 in the upper and middle reaches of the Yellow River. … The results obtained were as follows: (1) Vegetation greening was remarkable in the entire study region (0.036 yr−1).”
“Overall greening trend in the upper and middle reaches of the Yellow River indicated great achievements have been obtained since the implementation of the GTGP. Vegetation restoration exerted stronger influences on converted types from cropland than unconverted types. In the future, approximately 73.1% of the study region is expected to continue increasing [greening].”
• Water-use efficiency – the ability for plants to compensate for water loss – has improved directly due to “rising atmospheric CO2 and contemporary climate change.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Cernusak et al., 2019
“Human-caused CO2 emissions over the past century have caused the climate of the Earth to warm and have directly impacted on the functioning of terrestrial plants. We examine the global response of terrestrial gross primary production (GPP) to the historic change in atmospheric CO2. The GPP of the terrestrial biosphere has increased steadily, keeping pace remarkably in proportion to the rise in atmospheric CO2. Water-use efficiency, namely the ratio of CO2 uptake by photosynthesis to water loss by transpiration, has increased as a direct leaf-level effect of rising CO2. This has allowed an increase in global leaf area, which has conspired with stimulation of photosynthesis per unit leaf area to produce a maximal response of the terrestrial biosphere to rising atmospheric CO2 and contemporary climate change.”
• A “large increase” in total biomass and improvement in water use efficiency is assessed for the Amazon region under elevated CO2 (700 ppm). Elevated CO2 “nullified” the effect of drought.
Oliveira and Marenco, 2019
“The large increase in total biomass and the substantial improvement in WUEP [water use efficiency] under eCO2 [elevated CO2, 700 ppm], and the sharp decline in leaf area under water stress widen our knowledge on the physiology of this important species for the forest management of large areas in the Amazon region.”
“Climate models predict an increase in atmospheric CO2 concentration and prolonged droughts in some parts of the Amazon, but the effect of elevated CO2 is still unknown. Two experiments (ambient CO2 ‒ 400 ppm and elevated CO2 ‒ 700 ppm) were conducted to assess the effect of drought (soil at 50% field capacity) on physiological parameters of Carapa. At ambient CO2 concentration, light-saturated net photosynthetic rate (PNsat) was reduced by 33.5% and stomatal conductance (gs) by 46.4% under drought, but the effect of drought on PNsat and gs was nullified at elevated CO2. Total plant biomass and leaf area production were also reduced (42‒47%) by drought. By changing leaf traits, Carapa is able to endure drought, as the consumptive use of water was reduced under drought (32‒40%). The improvement of PNsat under elevated CO2 and water stress and the leaf plasticity of Carapa broaden our understanding of the physiology of Amazonian trees.”
• Plants grown under elevated CO2 have “higher biomass, plant height, and leaf area.” Elevated CO2 “may mitigate the negative effects of water deficit” in soybeans.
Bencke-Malato et al., 2019
“In this study, we evaluated the individual and combinatory effects of E[CO2] [elevated CO2] and water deficit on the physiology and root molecular responses in soybean. Plants growing under E[CO2] [elevated CO2] exhibited increased photosynthesis that resulted in a higher biomass, plant height, and leaf area. E[CO2] decreased the transcripts levels of genes involved in iron uptake and transport, antioxidant activity, secondary metabolism and defense, and stress responses in roots. When plants grown under E[CO2] [elevated CO2] are treated  with instantaneous water deficit, E[CO2] reverted the expression of water deficit-induced genes related to stress, defense, transport and nutrient deficiency. Furthermore, the interaction of both treatments uniquely affected the expression of genes. Both physiological and transcriptomic analyses demonstrated that E[CO2] may mitigate the negative effects of water deficit on the soybean roots.”
• Elevated temperature and CO2 increased maize and soybean yield by 25%-31%.
Qiao et al., 2019
“Maize had 25% yield increase under elevated temperature (eT). Soybean had 31% yield increase under elevated CO2 (eCO2) with eT. Elevated temperature with and without eCO2 increased grain oil concentrations.”
• Rice yield is “significantly higher” with elevated CO2.
Raj et al., 2019
“Climate  change  associated  with  rising  atmospheric  carbon  dioxide  (CO2)  concentration  may  have  impact  on  crop production and soil health. Increase in atmospheric CO2 concentration may enhance crop growth with higher demand for nutrients by the crop. An experiment was conducted during July-October, 2013 using Free Air Carbon Dioxide Enrichment facility at the Indian Agricultural Research Institute, New Delhi to study the impact of elevated CO2 and nitrogen (N) dose on growth, yield and nitrogen uptake in rice crop. Four doses of N, i.e., control, 0.6 g N pot-1 (75% recommended dose of N), 0.8 g N pot-1 (100% recommended dose of N) and 1.0 g N pot-1 (125% recommended dose of N) were applied in both ambient (395 ppm) and elevated CO2 (550±20 ppm)  conditions. Grain and biomass yield of rice was significantly higher under elevated CO2 condition. Plant growth and yield parameters also increased with increased N doses in both elevated and ambient CO2 conditions. Nitrogen concentration of grain and straw decreased under high CO2 level but N uptake increased under elevated CO2 condition. Agronomic efficiency of N was higher under elevated CO2 while recovery efficiency of N remained unaffected. The study showed that although yield of rice increases under elevated CO2 condition, to maintain plant nitrogen concentration, application of additional dose of N is required.”
• Trees “may temporally benefit from warming climate” in Asian boreal forests.
Zhang et al., 2019
“While summer GST [ground surface temperature] had a somewhat consistently positive correlation with tree growth, winter GST has shifted from a negative to a strongly positive correlation with growth in the last decade, coincidental with a sharp increase in winter GST since 2004. Winter GST is also strongly correlated with the rapidly thawing permafrost dynamics. Overall, our results suggest a link between recent changes in the permafrost and shifts in climate‐growth correlations for one of the main boreal tree species. As a result, L. gmelinii has experienced an important increase in radial growth that may indicate that, unlike what has been reported for other boreal species, it may temporally benefit from warming climate in the continuous permafrost region of the Asian boreal forests.”
• Due to climate change, the height growth for oak trees has been “significantly higher” during the last 30-35 years than the decades prior.
Gulyás et al., 2019
“Due to climate change, it is important to know to what extent forests will be impacted by atmospheric changes. This study focuses on the height growth response of sessile oak.”
“The relative top heights of the young stands were significantly higher than of the older stands, which means that the overall growing conditions were better in the last 30-35 years due to atmospheric changes than the mean conditions during the lifetime of old stands.”
Share this...FacebookTwitter "
"Ordinary people from across the UK – potentially including climate deniers – will take part in the first ever citizens’ climate assembly this weekend. Mirroring the model adopted in France by Emmanuel Macron, 110 people from all walks of life will begin deliberations on Saturday to come up with a plan to tackle global heating and meet the government’s target of net-zero emissions by 2050.  The assembly was selected to be a representative sample of the population after a mailout to 30,000 people chosen at random. About 2,000 people responded saying they wanted to be considered for the assembly, and the 110 members were picked by computer. They come from all age brackets and their selection reflects a 2019 Ipsos Mori poll of how concerned the general population is by climate change, where responses ranged from not at all to very concerned. Of the assembly members, three people are not at all concerned, 16 not very concerned, 36 fairly concerned, 54 very concerned, and one did not know, organisers said. The selection process meant those chosen could include climate deniers or sceptics, according to Sarah Allan, the head of engagement at Involve, which is running the assembly along with the Sortition Foundation and the e-democracy project mySociety. “It is really important that it is representative of the UK population,” said Allen. “Those people, just because they’re sceptical of climate change, they’re going to be affected by the steps the government takes to get to net zero by 2050 too and they shouldn’t have their voice denied in that.” The Committee on Climate Change says cutting greenhouse gas emissions to zero by 2050 is necessary, affordable and desirable. Here are some of the actions needed to make that happen: • Petrol and diesel cars banned from sale ideally by 2030 and 2035 at the latest. • Quadrupling clean electricity production from wind, solar and perhaps nuclear, plus batteries to store it and connections to Europe to share the load. • Connection of new homes to the gas grid ending in 2025, with boilers using clean hydrogen or replaced by electric powered heat pumps. Plus, all homes and appliances being highly efficient.   • Beef, lamb and dairy consumption falling by 20%, though this is far lower than other studies recommend and a bigger shift to plant-based diets would make meeting the zero target easier. • A fifth of all farmland – 15% of the UK – being converted to tree planting and growing biofuel crops and restoration of peat bogs. This is vital to take CO2 out of the air to balance unavoidable emissions from cattle and planes. • 1.5bn new trees will be needed, meaning more than 150 football pitches a day of new forests from now to 2050. • Flying would not be banned, but the number of flights will depend on how much airlines can cut emissions with electric planes or biofuels.  The UK climate assembly differs from the French model in that it was commissioned by six select committees, rather than by the prime minister. Their views, which will be produced in a report in the spring, will be considered by the select committees but there is no guarantee any of the proposals will be taken up by government. Allen said it was rare for members of a citizens’ assembly to get locked into dissent. She pointed to the success of the Irish citizens’ assembly in 2016, which helped break the deadlock in the abortion debate. “This climate assembly is going to come up with recommendations that are going to be really invaluable in highlighting public preferences,” she said. Jim Watson, a professor of energy policy at University College London, is one of four experts who will guide the members of the public in their decision-making. He acknowledged the scale of the challenges they faced in finding solutions to reaching net zero by 2050, which he said was “a hell of a job”. As well as four experts to the assembly, a panel of advisers including representatives from the Confederation of British Industry, Trades Union Congress, National Farmers’ Union, environmental NGOs and renewable energy companies have helped provide the questions on which assembly members will be asked to give their views. The key subjects to be considered will include transport, agriculture, domestic energy, and how consumerism is driving global heating. As well as policies such as bringing forward the ban on the sale of petrol and diesel cars from 2040, the panel will consider technological solutions to cutting carbon emissions. Watson said many technological initiatives were surrounded by hype. “It is really important we get across [to the assembly members] not just that the option is x, but what the status of that option is in the world,” he said. The assembly will meet for four weekends. On the third weekend they will begin making decisions about ways to meet the net zero target. A spokeswoman for Extinction Rebellion, which is calling for the government to create and be led by the decisions of a citizens’ assembly on climate, said they welcomed the fact that such assemblies were being used in mainstream politics. “However, because it is not commissioned by the government it is not what we are looking for. We want something with real teeth, that has actual power to influence policy,” she said."
nan
"At current rates of loss to poaching, rhino species will be extinct within our lifetimes. The big problem is demand for their horn from Asia. The market for rhino horn is moving from “traditional” medicine to “investment value” as jewellery and other processed artefacts in the art and antiques market, according to wildlife trade monitors TRAFFIC. South Africa is at the centre of the problem because it has most of the rhino, and because it now, against international opinion, allows legal domestic trading of rhino horn. This has led to rhino horn being worked to disguise it as jewellery and powder, and exported illegally, principally to Vietnam and China. It is getting ever harder for customs officials to recognise illegal wildlife products.  The relationship between smuggling and law enforcement is like an evolutionary arms race in nature, as each innovation by the smugglers is recognised and tackled by law enforcement, so the criminals innovate and switch strategies.  There can be a tendency to retain an old-fashioned stereotype of “the poacher” as a poor local struggling to feed his family, but the reality is that when it comes to high value products such as rhino horn, the players are often well-organised criminal syndicates involved in other unsavoury activities. The link is unsurprising, given the illegal wildlife trafficking industry is estimated to be worth US$23 billion. However, South Africa recently undermined efforts to reduce demand by lifting its ban on the domestic rhino horn trade. This has made life a lot more difficult for law enforcement as a legal trade sends out the message that rhino horn is valuable, and so facilitates an illegal trade. The recent release of a Thai rhino kingpin from a South African jail only six years into a 40-year sentence raises further questions of the country’s commitment to tackling wildlife crime. It’s easy to see why South African game farms would support a legal trade. Rhino horn can be harvested without having to kill the animal, many farms have stockpiles, and farms want to cash in on their stock. Based on the Asian black market value, rhino horn is estimated to be worth US$65,000 per kg. The problem is that rhino horn should not have a value, and indeed has no commercial value outside the illegal trade, driven principally by consumer demand from Asia. The illegal wildlife trade hurts people as well as animals and plants. Poachers, where caught, are jailed or killed, and their families impacted. Wildlife rangers and law enforcement officers also risk their lives. Desperate people part with cash and hope to invest in false medicinal promise provided by charlatans and criminals. Ecotourism potential is eroded by biodiversity loss – with immeasurable future economic costs. Local communities where rhino and other endangered species live are a key, yet historically often overlooked, factor influencing the sustainability of endangered wildlife populations. All too often the benefits of conservation do not go to local indigenous communities. Community empowerment and integration in wildlife conservation will improve local support and ideally reduce the need and cost of high-tech militaristic solutions. Historically, demand for rhino horn was driven by perceived (yet entirely mythical) medicinal benefits. Demand can be reduced, firstly, by ending all legal trade and therefore not giving rhino horn a value. And second, by broadening education programmes to young and old in Asia to inform that rhino horn has no medicinal value. Rhino horn is useless - except to the rhino. Alongside this, we need to reverse the perception that ownership of rhino horn is a positive status symbol. Society needs to value the live rhino in the wild more than its horn, and rhino horn products should be viewed as a badge of shame, not of honour. As conservation biologist Ian Redmond puts it: “Far from being a status enhancing display, use of rhino horn and ivory now says ‘I support organised crime’.” This sort of culture shift requires not only education in the classroom through teachers, but beyond the traditional education system. For instance, TRAFFIC targeted businesses in a three-year demand reduction project in Vietnam, while film star Jackie Chan is facilitating social change across Asia: Demand for product, even with perceived “traditional” motivation, can be reduced: demand for rhino horn dagger-handles from Yemen in the 1970s and 80s, for instance, was effectively closed. We need to do the same again – tackling whatever consumer market stands to gain from rhino horn. However, a hot-off-the-press TRAFFIC report highlights that demand reduction programmes must improve and be evidence-based and targeted in order to be effective. Biodiversity is a global good, and when a species is gone, it is gone forever. The quagga, Tasmanian tiger, passenger pigeon, great auk, dodo, giant tortoises and giant birds – all hunted to extinction. Everyone has a responsibility to contribute to ensuring the rhino does not go the same way. At its simplest, do not support the illegal wildlife trade: do not buy, report suspicions, and spread the word that ownership of rhino horn, elephant ivory, pangolin scales, and other illicit wildlife products is unacceptable. The link between wildlife crime and legal trade has serious implications for conservation. We need to get the message across that consumption and use of rhino horn and illegal wildlife products are bad news for everybody – not just the animals."
nan
"The 2018 summer heatwave in the UK broke records – and it won’t be the last spell of such severe heat. In fact, climate change means that hot summers which would once occur twice a century may soon occur twice a decade. As the population grows and ages, this will lead to more premature heat-related deaths and place extra strain on physical and mental health services. Previous research on resilience to heatwaves, such as the recent report by parliament’s Environmental Audit Committee, a cross-party group of MPs, has focused predominantly on policy, regulation and infrastructure. Such research barely addresses behavioural or social responses that occur during hot weather events and how these can contribute to building resilience.  This is what my own work looks at. In a new book I explore these ideas and assessed how to improve resilience to climate change through communication, collaboration and co-production. So what can the UK do to be better prepared for heatwaves in future? People must be trained to think more carefully about their vulnerabilities and responses to hot weather. Everyone’s experience of hot weather varies, and this is often associated with positive memories of past summers where they’d enjoy the heat, venture outside and make the most of a potentially short-lived summer.  But this often leads to people being more exposed to the effects of the sun, which affects their health and productivity and puts extra strain on hospitals. Hot temperatures also cause roads to melt and train track to buckle, resulting in delays. As hot weather becomes more common, people need to bear these things in mind. While appropriate regulation and policies are important, they must represent how people respond to heatwaves and how their experiences affect their behaviour. This can be incorporated into broader thinking around other topics.  Buildings, for instance, can be insulated to stay warm in the winter yet cool in the summer, but we need to better understand how people behave in buildings during those periods to ensure appropriate use.  And working practices can be adjusted so people can work outside periods of intense heat. People rarely want to stay at home all day, so more water fountains should be provided in public places. British people famously love talking about the weather. But they still need to get better at talking about heatwaves specifically, and how they can become more resilient to them. That means things like sharing whether they’re feeling the load of the hot weather or sharing ways to stay cool.  Better communication will also help people understand who’s doing what during a hot weather event (for example emergency services under extra strain, or bus and train drivers working in tough conditions). Learn from other others. Mediterranean countries, for instance, are used to the hot weather and people there have adopted simple practices to help them cope with the stress: closing shutters during the hot weather, avoiding being outside or on the beach during peak heat temperatures, painting buildings white, staying hydrated and avoiding strenuous activities during hot weather. Countries in northern Europe that are just getting used to severe heatwaves could adopt these practices. Investment should be pro-active, rather than reactive. That means working closely with scientists to anticipate the risks from heatwaves, getting a better understanding of our vulnerabilities and the potential measures we can take.  Ensure buildings (especially hospitals and care homes) and infrastructure are better prepared to withstand hot weather events and that regulation is updated to better reflect this, without which the number of heatwave-related deaths would increase."
"
Share this...FacebookTwitterIt’s unusual to see rationality over climate change in the German media, but sometimes it manages to get through.
In April this year I missed an important podcast interview with one of the world’s most prominent Sahara Desert researchers, geologist Dr. Stefan Kröpelin, by the Düsseldorf-based German daily, Rheinische Post.

Image: University of Cologne 
The two RP hosts conducting the interview seemed to expect Dr. Kröpelin would tell the audience how dire the consequences of man-made global warming are on the Sahara Desert and planet overall.
They didn’t get what they bargained for.
Warming does not lead to desertification
Instead, in the interview, Dr. Kröpelin rejected in very clear terms man’s major climatic impact and that global warming is only negative.
Kröpelin told listeners that history is very clear: When the globe is cold, the deserts expand. And when the globe is warm, deserts become greener and far more fruitful.
Kröpelin is a leading expert
Kröpelin has been studying the Sahara for over 40 years, spending weeks and months each year on site gathering data a reconstructing past climates. Nature described Kröpelin as “one of the most devoted Sahara explorers of our time.”
At about 9 minutes into the interview, he explains how the Sahara was massive in size during the last glacial period, and that about ten thousand years ago it greened up once temperatures shot up early in the Holocene.
When asked (10:15) if he worries that things in the Sahara “will get much worse” due to climate change, Kröpelin tells the host and audience: “First, that is a statement I 100% reject”, adding that localized desertification has more to do with the population growth at the edges of the desert and that the people who live there are cutting down trees and extracting water from the ground.
Rising precipitation, shrinking desert 
Next (12:00), Kröpelin talks about the remote edges of the Sahara where few people live: “Here we signs that precipitation is increasing and that should the trend continue, the desert is going to shrink.” Similarly as it did at the end of the last glacial. “The Sahara changed from a desert to a savannah. These are not model simulations.” He says rather this is” based 100%” on real observations of a wide variety of proxy data taken throughout the region.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The greening of the Sahara “happened not because it got colder, but because it got warmer,” he said.
A third would become livable again
Kröpelin also shocks the host and audience, claiming that even if the climate models were true, which he says he doesn’t believe, “Maybe one third of the African continent will be a livable zone again. That would be an unbelievable advantage for the people in Sub-Saharan Africa. […] I dispute that over the last decades there’s been a climatically controlled increase of the desert.”
“Never been a stable climate”
On the subject of climate-induced human migration, Kröpelin says human migrations due to climate changes have always occurred. In the past sea level changes simply caused the people to step back or forwards a few meters. But today, the problem is that the built infrastructure is unable to move with the changes. “There’s never been a really stable climate.”
“What’s one meter from 4000?”
On sea level rise, Kröpelin plays down the changes that are occurring today, reminding us that the average depth of the ocean is some 4000 meters, noting.  “What’s one meter from 4000 meters of sea depth?”
Climate change “totally exaggerated”
When asked about the climate protests now taking place (21:00), Kröpelin comments: “I would say that today’s handling of climate change is hysterical” and that “we should not be dramatizing.”
The University of Cologne expert geologist says that by only looking at the last few decades, “We can naturally create panic. But I find it totally exaggerated.”
PIK painting “doomsday scenarios”
Kröpelin notes that the claim that global warming is all bad just “isn’t true” and that “the real catastrophe would be a dramatic drop in global temperature” and that “warming is the least of our problems.” He adds: “Climate change is totally exaggerated.”
He sharply criticizes the Potsdam Institute for Climate Impact Research (PIK) for “painting doomsday scenarios” and says the topic has been heated up by politics.
Share this...FacebookTwitter "
"There is no doubt that plastic pollution in oceans is a growing worldwide problem. The internet is full of images of seabirds and other marine animals entangled in plastic waste, and animals starve because their guts are blocked with plastic bags. But the problem goes much deeper than this. Much plastic pollution is in the form of microplastics, tiny fragments less than five micrometres in size and invisible to the naked eye. Our new research shows that these microplastics are even getting into tiny flying insects such as mosquitoes. And this means the plastic can eventually contaminate animals in a more unlikely environment: the air. Microplastics can come from larger plastic items as they break down, but are also released directly into waste water in their millions in the form of tiny beads found in many cosmetic products including face wash and toothpaste (though these are now banned in many countries). Many tiny animals can’t tell the difference between their food and microplastics so end up eating them. Once inside an animal, the plastic can transfer via the food chain into fish and other creatures and eventually become a potential health problem for humans. By studying mosquitoes, we have found a previously unknown way for plastic to pollute the environment and contaminate the food chain. Our new paper, published in Biology Letters, shows for the first time that microplastics can be kept inside a water-dwelling animal as they grow from one life stage to another. Although most microplastic research has focused on the sea, plastic pollution is also a serious problem in freshwater, including rivers and lakes. Much of the freshwater research has concentrated on animals that live in the water throughout their life. But freshwater insects such as mosquitoes start their lives (as eggs) in water and, after several stages, eventually fly away when they grow up.  It occurred to us that aquatic insects might carry plastics out of the water if they were able to keep the plastics in their body through their development. We tested this possibility by feeding microplastics to mosquito larvae in a laboratory setting. We fed the aquatic young in their third larvae stage food with or without microplastic beads. We then took samples of the animals when the larvae shed their skin to become larger fourth-stage larvae, when they transformed into a non-feeding stage called a pupa, and when they emerged from the water as a flying adult. We found the beads in all the life stages, although the numbers went down as the animals developed. We were able to locate and count the microplastic beads because they were fluorescent. We found beads in the gut and in the mosquito version of the kidney, an organ that we know survives the development process intact. This shows that not only do aquatic insects such as mosquitoes eat both sizes of microplastics, they can keep them in their gut and kidney as they develop from a feeding juvenile larva up to a flying adult.  In this way, any flying insect that spends part of its life in water can become a carrier of plastic pollution. And flying insects are eaten in their thousands by predatory insects in the air such as dragonflies as well as by birds and bats.  Our results have important implications since any aquatic insect that can eat microplastics in the water could potentially carry them in their body to their flying stage where they can move the plastics into new food chains. As a result, freshwater plastic pollution is a problem that has implications far beyond those of water quality and eventual marine pollution. Clearly these results raise a number of questions, including what effect microplastics have on the survival and development of mosquitoes through their life stages. And we still need to examine the effect of different types and sizes of plastics on more species to see how widespread an issue this could become."
"The announcement by the shadow business and energy secretary, Rebecca Long-Bailey, that Labour will target “net zero” emissions by 2050 is of course welcome for anyone interested in achieving a low-carbon economy. But the party is plugging in to an existing and growing movement, rather than leading the way. Indeed, several governments, including those of of New Zealand and Sweden have already endorsed zero emissions, along with companies such as Unilever and Tesco, as well as a cross-party group of British MPs. Even the prime minister, Theresa May, recently announced that the UK will join the Carbon Neutral Coalition, hopefully signalling a step towards a net zero target. So, the pledge itself might not be radical, but it will still be difficult for the UK to achieve. Transforming energy systems is technically, socially, economically and politically complex and Labour’s announcement was backed up a briefing on aspects of how it might be achieved. It foresees rapid growth of both offshore and onshore wind, as well as solar power. It will also require a much-needed concerted effort to improve domestic energy efficiency, particularly in the use of heat in our homes. But the briefing only gives a partial picture and the scope and feasibility of the plan is yet to be established, as full details will only be revealed later in the year. The lack of detail raises lots of questions, but one of the most politically interesting is what role new nuclear energy might play in Labour’s vision of a net zero future. Long-Bailey’s speech did not mention it. The background briefing does, but only in passing. And the final, complete report is not yet out. So how much of Labour’s renewables pledge and net zero target depends on new nuclear stations being built? At the heart of this lack of clarity is the split in the Labour Party about nuclear power – and at the heart of that is Jeremy Corbyn. Back in the day – pre-leadership – Corbyn was a high-profile opponent of the nuclear issue on both environmental and proliferation grounds. None of the problems with nuclear waste and plutonium which so concerned him then have been solved, but his approach has shifted, leading to some awkward exchanges as people seek to understand what his views are now. Most notable among these was the painful Copeland by-election in 2017. Copeland is home to Sellafield, the heart of the UK’s nuclear waste industry, and the seat was solidly Labour for decades. Corbyn’s nuclear position was a key focus of by-election campaigning, with the Conservatives highlighting his statements opposing the nuclear industry generally and new nuclear power in particular. Despite a last-minute endorsement from Corbyn for a new nuclear station at Moorside near Sellafield, Labour lost the seat, with a lack of belief from voters on this new nuclear stance widely identified as a reason. Elsewhere in the party, though, nuclear power is seen as an intrinsic part of the UK’s energy future. Long-Bailey is very keen on it, for instance. This side of the debate reflects the accepted political paradigm that achieving climate targets won’t be possible without nuclear power. This view, though, is a paradigm – a recognised and unquestioned way of thinking about what is “acceptable”. It hasn’t really been challenged since new nuclear power was endorsed in the 2008 Nuclear White Paper. Since then the energy world has changed. The cost of renewables has plummeted, storage has emerged as an increasingly viable option for managing the fluctuations in solar and wind power, and increased interconnection between the electricity systems in the UK and Europe are providing new opportunities for balancing power. Coupled with this, the UK’s nuclear plans are floundering because of the high costs associated with new stations. Hinkley Point C requires much higher subsidies than was envisaged in 2008 – and financing of other new projects such as Wylfa and Moorside have led the government to think about measures such as partial nationalisation as a way of managing the construction and financial risks. This isn’t what the White Paper promised. So, when Labour’s energy plan is finally published, the issue will be one of the most fascinating. Will the party endorse new nuclear plants, despite their ever present financial problems? It seems likely that it will, because there has been no detailed examination of the case for new nuclear power for ten years – instead, both the Conservative and Labour have generally accepted that nuclear is necessary in a world of climate change. This is a real shame. One of the opportunities that putting forward a new vision of the UK’s energy systems offered was a new way of thinking about things. From this perspective, just accepting that nuclear power is an inevitable part of the energy future is lazy thinking which fails to recognise the changing energy world. If Labour really want a new, radical energy plan, it needs to reassess the nuclear paradigm."
nan
"Tropical forests are being exposed to unprecedented environmental change, with huge knock-on effects. In the past decade, the carbon absorbed annually by the Amazon rain forest has declined by almost a third. At 6m km2, the Amazon forest covers an area 25 times that of the UK, and spans large parts of nine countries. The region contains a fifth of all species on earth, including more than 15,000 types of tree. Its 300 billion trees store 20% of all the carbon in the Earth’s biomass, and each year they actively cycle 18 billion tonnes of carbon, twice as much as is emitted by all the fossil fuels burnt in the world.   The Amazon Basin is also a hydrological powerhouse. Water vapour from the forest nurtures agriculture to the south, including the biofuel crops which power many of Brazil’s cars and the soybeans which feed increasing numbers of people (and cows) across the planet. What happens to the Amazon thus matters to the world.  As we describe in research published in Nature, the biomass dynamics of apparently intact forests of the Amazon have been changing for decades now with important consequences. There are two competing narratives of how tropical forests should be responding to global changes.  On one hand, there is the theoretical prospect (and some experimental evidence) that more carbon dioxide will be “good” for plants.  Carbon dioxide is the key chemical ingredient in photosynthesis, so more of it should lead to faster growth and thus more opportunities for trees and whole forests to store carbon. In fact almost all global models of vegetation predict faster growth and, for a time at least, greater carbon storage. Arrayed against this has been an opposing expectation, based on the physical climate impacts of the very same increase in atmospheric CO2.  As the tropics warm further, respiration by plants and soil microbes should increase faster than photosynthesis, meaning more carbon is pumped into the air than is captured in the “sink”. More extreme seasons will also mean more droughts, slowing growth and sometimes even killing trees. The work we have led takes a simple approach. With many colleagues, we track the behaviour of individual trees through time across permanent plots distributed right across South America’s rain forests. Together with hundreds of partners in the RAINFOR network, this close-up look at the Amazon ecosystem has been underway since the 1980s, allowing an unprecedented assessment of how tropical forests have changed over the past three decades. Our analysis – based on work across 321 plots, 30 years, eight nations, and involving almost 500 people – first of all confirms earlier results. The Amazon forest has acted as a vast sponge for atmospheric carbon. That is, trees have been growing faster than they have been dying.  The difference – the “sink” – has helped to put a modest brake on the rate of climate change by taking up an additional two billion tonnes of carbon dioxide each year. This extra carbon has been going into ostensibly mature forests, ecosystems which according to classical ecology should be at a dynamic equilibrium and thus close to carbon-neutral. However we also found a long and sustained increase in the rate of trees dying in Amazon forests that are undisturbed by direct human impacts. Tree mortality rates have surged by more than a third since the mid-1980s, while growth rates have stalled over the past decade. This had a significant impact on the Amazon’s capacity to take-up carbon. Recent droughts and unusually high temperatures in the Amazon are almost certainly behind some of this “mortality catch-up”. One major drought in 2005 killed millions of trees. However the data shows tree mortality increases began well before then. Some other, non-climatic mechanism may be killing off Amazonian trees.  The simplest answer is that faster growth, which is consistent with a CO2 stimulation, is now causing trees to also die faster. As the extra carbon feeds through the system, trees not only grow quicker but they also mature earlier. In short, they are living faster, and therefore dying younger. Thus, 30 years of painstakingly monitoring the Amazon has revealed a complex and changing picture. Predictions of a continuing increase of carbon storage in tropical forests may be overly optimistic – these models simply don’t capture the important feed-through effect of faster growth on mortality. As the Amazon forest growth cycle has been accelerating, carbon is moving through it more rapidly. One consequence of the increase in death should be an increase in the amount of necromass – dead wood – on the forest floor. While we haven’t measured these changes directly, our model suggests the amount of dead wood in the Amazon has increased by 30% (more than 3 billion tonnes of carbon) since the 1980s.  Most of this decaying matter is destined to return to the atmosphere sooner rather than later. More than a quarter of current emissions are being taken up by the land sink, mostly by forests. But a key element appears to be saturating. This reminds us that the subsidy from nature is likely to be strictly time-limited, and deeper cuts in emissions will be required to stabilise our climate."
"
Share this...FacebookTwitterClimate poster child Greta’s is sailing across the Atlantic instead of flying – in order to minimize the climate impact.

Teenage climate rescue warrior Greta Thunberg. Image source: Greta’s Twitter site
5 crewmen to fly over to New York
But German online leftist daily TAZ here has uncovered that Greta’s climate publicity jaunt is going to wind up creating a massive carbon stomp, one far greater than anyone would have dared to imagine.
The TAZ writes that Greta would have been far gentler to the climate had she simply taken a commercial airliner. The reason, the TAZ writes, is because a crew of 5 men will have to fly over to New York in order to take the boat back!
This is what Andreas Kling, press spokesman for Thunberg’s skipper Boris Herrmann, told the TAZ on Thursday.
“There’s no other way,” said Kling!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




10 tons instead of 4
Citing carbon emissions calculator site atmosfair, each crewman flying from Hamburg to New York will emit 2 tons of CO2 for the flight, i.e. a total of 10 tons. Had Greta simply taken a roundtrip commercial economy-class flight, she would have wound up emitting less than 4 tons.
The 16-year-old Greta and her father set sail last Wednesday afternoon on board the ocean-going yacht Malizia II with two sailors and a publicity filmmaker.
Hundreds of journalists travel to Plymouth
Moreover, “hundreds of journalists, supporters and spectators” travelled to Plymouth to watch Greta’s departure, thus adding enormously to the carbon emissions that the trip was supposed to reduced. The journalists could have witnessed here departure via live feed or a webcam rather than travelling in automobiles and what not to Plymouth.
Spokesman Kling says now they are considering sending Greta back from New York via cargo container ship.
Gee, cutting back fossil fuels “not easy” after all
Aware that the trip is possibly turning into public relations farce, sailor Herrmann told the TAZ: “The journey symbolizes two things: that it is not easy to replace fossil fuels and that mastering this challenge can be a great adventure”.
 
Share this...FacebookTwitter "
"As a result of membership of the Common Fisheries Policy, we are now allowed to catch less than 20% of the fish that swim in British waters. The other 80% we have given away to the rest of Europe.  Nigel Farage, UKIP leader, on the campaign trail When fact checking this statement, it is first of all worth pointing out that if the UK was allowed to catch 20% of the fish that swim in British waters and the EU took the rest, then there would be no fish left in the sea. In attempting to check the facts behind this assertion, one must assume, therefore, that Nigel Farage is referring to the allocations of fishing quotas which are determined by the EU’s Common Fisheries Policy (CFP). In 2015, the CFP allocated the United Kingdom a total of 612,612 tonnes of quota from more than 100 different fish and shellfish stocks. The total EU quota for these stocks was 2,069,202 tonnes, so the UK was allocated 30% of these fish (and shellfish) quotas.  These figures include various fish which live beyond the boundaries of UK waters, such as Arctic cod and west of Ireland sole. If one considers the 73 different fish stocks which live in UK waters, the total EU quota was 1,920,915 tonnes, of which 585,211 tonnes was allocated to the UK (which also happens to be 30%). Individual quota allocations differ according to stock, as figure one below shows. For example, the UK gets 84% of the North Sea haddock quota, 81% of North Sea monkfish quota and 98% of west of Scotland prawn quota; but only 4% of North Sea sprat quota, 18% of northern hake and 28% of North Sea plaice. Although UK waters are extensive, as the map below shows, the fish stocks which live in our waters are by no means confined to them. Some, like mackerel, make extensive migrations and only pass through our waters for a short period. Others are more sedentary, like prawns which stay close to their burrows in muddy habitats.   Many species live in different places either at different times of the year or in different phases of their life cycle. In the case of North Sea herring for example, most of the juveniles live in the south east corner around the German bight, whereas the adults tend to congregate around the Shetland Isles prior to spawning at various sites along the British coast. North Sea cod are found throughout the North Sea but prefer spawning along the border between UK and Norwegian waters.  So despite the UK having quite extensive waters, fish stocks do not respect political boundaries, and many are mobile at some stage in their life: these fish are exclusive to neither the UK, the EU, nor the bordering Scandinavian states, but are a shared resource. It would be a major undertaking to establish exactly which proportions of each fish stock would occupy any national waters. These are also likely to change throughout the year, and from year to year. The CFP was designed to manage the mobile fishing fleets that pursue these common, mobile resources. Although the majority of fish stocks around the UK are managed under the CFP, some important stocks, mainly local shellfish species such as crabs, lobsters and scallops, are also managed under national jurisdictions and bilateral agreements, for example between the EU and states such as Norway and Iceland.  The status of all stocks is determined by the International Council for the Exploration of the Sea (ICES), the recognised authority that provides scientific advice to managers. This advice is updated annually and, where possible, includes measures of stock status such as the total biomass of adults and the rate of exploitation the stock has been subjected to by the fishery.   Although the CFP is much derided, various reforms have actually resulted in improvements in the status of many fish stocks in the last decade or so: exploitation rates are down, and in most cases, to levels which are sustainable. The ICES advice also includes recommendations for total allowable catches (TACs) for each stock. Each TAC is then considered by the EU and divided into the quotas which are allocated among the member states according to fixed percentages, under allocation keys known as “relative stability”, which are based on historic fishing patterns.    In 2015, the UK was allocated 30% of the EU quota for fishing ground stocks which occur in UK waters. The area of UK waters relative to other member states is certainly high, but the exact proportions depend on the region and which components of member state waters should be considered.   If Farage’s point is that most of the quota for fish stocks that live in UK waters are fished by other member states, then he is correct; but the figure is not 80%, more like 70%. However, these are not “our” fish, the fish that live in UK waters are no more British than they are German, Dutch, Belgian, Irish or Norwegian: they are in fact European. This is a thorough and well-illustrated response which uses the most reliable and up-to-date information available. By demonstrating that the majority of fish in our waters are in fact European rather than British it highlights a key point – even if Britain left the EU we would still need to negotiate quotas which took this into account. There is no guarantee this would ensure any more of the catch. It’s also interesting to look at these figures in terms of value rather than just landings. Three of the top five most valuable UK fisheries are for shellfish: prawns, scallops and crabs. For these more sedentary species we already have almost complete control. Although some fish, such as haddock are mainly eaten in the UK, a lot of shellfish from British waters is exported to EU countries. The vast majority of our scallop catch – the UK’s third most valuable fishery – goes to France and Belgium. Likewise Spain and Portugal take a lot of our crabs and prawns. Let’s concentrate on looking after what we are responsible for, more wisely."
"
Share this...FacebookTwitterNatural variability rules in Antarctica. Scientists identify clouds, wind, and localized solar heating – not CO2 – as the factors driving ice melt. Rising CO2 leads to Antarctic cooling.

Image Source: Lüning et al. 2019
Antarctica rapidly cooling in recent decades
In a review of the scientific literature, Lüning et al. 2019 report Antarctica as a whole has undergone a cooling trend in recent decades.
The Antarctic Peninsula has cooled at a rate of -0.5°C per decade since the late 1990s.
West Antarctica as a whole has “slightly cooled” (or the warming has “plateaued”) over the past two decades.
East Antarctica “has not experienced any significant temperature change since the 1950s” with  ice sheet mass gains and cooling during the past 15 years.
Rising CO2 leads to Antarctic cooling
Antarctica contains about 90% of the world’s ice.
Because the continent averages -28.2°C in summer and -60°C in winter, inducing even partial retreat for an ice sheet that averages 2.3 kilometers in height would require a substantial amount of heat energy.
This effectively rules out a significant human influence.
According to scientists, raising CO2 concentrations does not even lead to warming in Antarctica. Actually, scientists find Antarctica cools in response to rising CO2 concentrations, which means we humans may be contributing more to ice mass gains than to losses.

Image Source: Schmithüsen et al., 2015
Natural variability – clouds, wind, localized solar heating – drive Antarctic ice melt
The surface melting of portions of the West Antarctic Ice Sheet (WAIS) has received quite a bit of attention in media circles, often accompanied by scary warnings of ice sheet collapse and catastrophic sea level rise.
For example, Dr. James Hansen – admitting his doomsday predictions are tendentiously designed to be “persuasive” – has claimed sea levels will rise by 10 feet by 2065 mostly due to Antarctic ice sheet melt.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Image Source: Slate
These harrowing warnings often seem to arise in response to observations of glacier calving events – large glaciers fissuring and breaking off from the ice sheet.
But glaciologists know that calving events are indicative of ice sheet thickening, not thinning. Glaciers calve when the ice accumulation has become so heavy and thick that the base of the ice sheet can no longer bear the load.

Image Source: Christmann et al., 2016
Yes, portions of Antarctica are undergoing ice melt. But ice sheet recession and advancement are both natural. And modern ice melt is well within the range of what occurs naturally for Antarctica.
Indeed, as Jones et al. (2016) conclude, natural variability “overwhelms” any forced response in satellite era trend observations.

Image Source: Jones et al., 2016
In two new papers, scientists identify the natural mechanisms driving the recession of some of West Antarctica’s glaciers in recent decades.
Scott et al. (2019) conclude surface melt is driven by wind currents and downwelling longwave radiation from clouds.
Stewart et al. (2019) find localized solar heating of surface water can explain melting in small portions of the Ross Ice Shelf.
Considering the total Antarctic meltwater contribution to sea level rise may only amount to 0.34 of a centimeter since 1958 (Frederikse et al., 2018), it is quite reasonable to conclude that nothing unusual, unprecedented, or concerning is occurring in Antarctica that could be said to fall outside the range of natural variability.

Image Source: Scott et al. (2019)

Image Source: Stewart et al. (2019)
Share this...FacebookTwitter "
"The Icelandic volcano Eyjafjallajökull made worldwide headlines in 2010 when it erupted ash that was blown towards Europe, so that air traffic was grounded across the continent. More recently, the volcano’s bigger sister and neighbour, Katla, has also been in the news. First the papers said the “giant volcano” was ready to blow, yet within days articles were appearing to say it was all a mistake and the eruption news was premature. What is going on? Over the past 1,100 years, Katla has erupted at least 21 times - an average of around once every 50 years or so. It is exactly a century since the volcano’s last major eruption through the ice, which produced a 14km high column of fragmented volcanic rocks and gas, as well as enormous floods of meltwater, sediment and ice. But this doesn’t mean that another is “due”. Volcanoes don’t erupt to schedule. So why do headlines regularly appear to suggest this is the case? This latest news flurry was triggered by the publication of an academic paper by a team of scientists lead by Evgenia Ilyinskaya at the University of Leeds. They had carried out gas-monitoring surveys at Katla in 2016-17, which showed it emitted much more CO₂ than previously estimated. One of the exciting parts of this research was the recommendation that gas monitoring becomes part of the regular observations of volcanoes that are hidden under glaciers or ice sheets. However, many news outlets incorrectly suggested that the observation of these carbon dioxide emissions meant an eruption was imminent, and sounded the alarm. This sensationalist approach causes more damage beyond merely being incorrect. From a distance, readers and viewers might be interested in the science, the human story, or because even faraway eruptions can have economic or health costs. But for those living in the shadow of the eruption, the immediate impacts are far more pressing, or even life-threatening. Evacuating from a region, moving family and animals, or leaving your house behind all require a degree of certainty that this risk is real and that it should be avoided. To believe a risk is real, information needs to be trusted and thus information providers need to be trustworthy. It should therefore be clear that accurate information is essential. Effective risk communication is needed before, during and after a hazardous event, aiming to prevent and mitigate disaster harm, ensure preparedness and aid recovery. Inaccurate information will of course mean people will have less faith in scientists and news sources next time round. But it can have more immediate effects too. In July 2018, the New York Times reported how exaggerated coverage of the ongoing Kilauea eruption in Hawaii lead to a vastly inflated risk perception which saw tourism bookings decrease, which in turn led to loss of income and fears about job losses. In the worst instances, poor information can cause people to ignore evacuation orders. The risks aren’t easy to communicate. Hazards do not occur in an easy to predict way, they can happen with little warning, and risk assessments virtually always deal in probabilities rather than absolute certainty. Concepts such as 100-year floods are famously challenging to understand or relate to. In addition, risks to people are influenced by factors such as wealth, age, health, physical ability, whether you own a car, or which floor your apartment is on, so they can vary from person to person, house to house.  Communicating this information therefore comes with responsibilities. By crying wolf too many times, even if the warnings aren’t directly from scientists or the authorities, the media can strongly influence risk perception and create a warning fatigue. Journalists and editors must consider the ripple effects from an overly sensational news article, and the potential consequences for lives. It doesn’t take long for inaccurate news to spread and multiply across the internet: see, for example, the volcanologist and science writer Robin Andrews having to call out and correct reporting of the recent earthquake and tsunami in Indonesia which often conflated it with an unrelated volcanic eruption 600 km away on the same island of Sulawesi. The flip side of this is that competent, reliable communications can boost public trust and reduce fear and panic, helping people to take well-informed actions.  The International Journalist’s Network published an article on disaster journalism that presents some useful guidelines, much of which emphasises accuracy. I’d also suggest that journalists checks their facts with the scientists doing the work, or with the local organisation responsible for monitoring the hazard. Journalists should also avoid simplifying the forecasting process too much, ensuring that a possible scenario or timeframe is not presented as something of certainty. Readers should always be referred to a reliable source of further information. These simple measures can be used as a blueprint for strengthening reporting accuracy, and so help regain trust in science communication and the media."
"
Share this...FacebookTwitter
More pain for consumers. Electricity prices in Germany climb to a new high, reaching 30.85 cents (euro) per kilowatt hour. Experts warn transition to green energies may lead to shortages, higher prices.
German online national daily Die Welt here reports on how electricity prices in the country have reached “a new high” and that natural gas prices are high as well.
The German national news daily writes: “Electricity has never been as expensive for private households in Germany as it is this year.”
“Prices have risen to a new high,” Die Welt reports, citing the latest data from German Federal Network Agency.
For the first time, electricity prices for consumers reached 30 cents (euro) per kilowatt-hour, making German electric prices among the highest in the world.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Citing data from the Federal Network Agency, the average price soared to 30.85 cents (euro) per kilowatt hour, which works out to be an increase of almost 3.3 percent compared to just a year earlier. Last year the average price for one kilowatt hour was 29.88 cents.
According to Die Welt: “The Federal Network Agency evaluates the data of well over 1000 electricity suppliers.”
Why is electricity so expensive in Germany?
The Federal Network Agency puts the blame on the electricity wholesalers who, according to Die Welt, “pass on increases to the electricity exchange”.
And an end in the rising price spiral remains elusive, experts warn.
“Wholesale prices for electricity could continue to rise,” Die Welt reports. Large power producers such as RWE, warn that future plant closures due to the transition to green energies and the phasing out of the country’s nuclear power plants will “lead to a shortage”.
Die Welt ends its article: “The largest block on the electricity bill, however, are taxes, levies and allocations, which account for more than half of the total price.” One major price driver are the mandatory, exorbitantly high green energy feed-in tariffs that grid operators are forced to pay.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterClimate disaster? Grain production almost quadrupled worldwide while the population doubled over past 60 years!
Michael Krueger
(Translated/ edited by P Gosselin)
In these times of Fridays for Future led by Greta Thunberg, all experts and self-proclaimed experts are talking about how badly the earth is doing and warning that planet earth is about to collapse unless action is taken immediately. It’s claimed that all experts agree on their vision of the future! Droughts, floods, crop failures and famines threaten – and millions of climate refugees will make their way from south to north.
These are the visions of the “climate impact researchers”. But is that really the case? The opposite is the reality.
Let us first take a look at the grain yield of the most important cereals grown in the world.

Global grain yields per hectare  for the most important grains. Source: Statista
Miracle upon miracle. The grain yields per hectare of corn, rice, wheat and barley have increased strongly over the last 25 years and have not decreased at all, despite all the climate horror claims.
In the case of maize, the yields per hectare have almost doubled. Maize yields have increased by around 80%, rice by around 65%, wheat by around 70% and barley by around 65%.
And this in times when droughts and torrential rains are supposedly reducing the harvest yields?

Global production of maize, rice and wheat. Source: FAOSTAT
If you look at the world harvests of the most important grains, they have also risen sharply over the last 25 years. The amount of maize harvested has roughly doubled, i.e. increased by 100%, the amount of rice harvested by about 75% and the amount of wheat harvested by about 80%.

If we look at global grain production and grain production in selected tropical countries, this has increased sharply since 1960. On average, production has quadrupled!



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Exponential growth since 2000! Source: Worldwatch Institute
And when we look at the world grain production as a whole (wheat, rice and coarse grains), production has quadrupled since 1961!
This means that four times as much grain is harvested in the world as 60 years ago. The world population has only grown from 3 billion to over 7 billion in the same period. So it has only more than doubled a little bit

Maize and wheat yields for Germany and USA. Source: Felde 2009 as to FAOSTAT
The above figure shows how in Germany and the USA yields per hectare of cultivated land have risen sharply since 1960. Maize in Germany by approx. 130% and for wheat in Germany by approx. 120%. This is more than doubling. Maize in the USA has jumped by approx. 110%, for wheat in the USA approx. 75%. So almost doubling.

Grain production in tonnes and yield per hectare. Source: German Federal Office of Statistics
If we look at the development of grain production in Germany since 1950, we can see a significant increase both in the total harvest quantity and in the yields per hectare. The total grain production has increased by about 450%, the grain yield by about 350%.
Wheat yield (top), maize yield Germany (bottom). Source: Prof. F. Isermeyer, FAL Braunschweig
By international standards, wheat yields per hectare of cultivated land have risen worldwide. Germany, in particular, is distinguished in wheat cultivation by high yields per hectare and a strong increase in yields per hectare. The yield per hectare of wheat has more than doubled since 1970 and is four times higher than in other countries.
And maize acreage and maize yields have also grown strongly in Germany. In the last 30 years, the yields per hectare of maize have almost doubled and the area under maize has increased by about 75%.
Good news censored
The question is: Why don’t you hear about it in the media and news? As a rule, there are only reports of failed harvests and famines, but no new record harvests. Perhaps simply because this does not fit into the picture of a climate catastrophe?
Now imagine that the Arctic and Siberia would also become fertile arable land as a result of global warming and that crop yields increased even further as a result. Would that be bad or good?
Share this...FacebookTwitter "
"You never forget the first time you see an iceberg. The horizon of a ship at sea is a two dimensional space and to see a three dimensional piece of ice appear in the ocean is quite something. But, in truth, the first iceberg you see is likely to be small. Most icebergs that make it far enough north from Antarctica to where they are danger to shipping are sometimes many years old and at the end of their lives. They are small fragments of what once left the continent. Once in a while, however, a monster breaks free from the edge of Antarctica and drifts away. Tens of kilometres long these bergs can tower perhaps 100 metres above the sea and reach several hundred more below the surface. These are called tabular icebergs – and while it is rare for humans to see something on such a scale they are part of the normal cycle of glacial ice in Antarctica. Everyone knows Antarctica is an ice-covered continent, but the ice is not static. To a scientist it is a dynamic environment – it’s just a question of the timescale you are looking at. Snow falls on the continent and over time it has built up layers of ice which flow in glaciers towards the coast.  On reaching the sea, these glaciers fracture and release icebergs or form large regions of floating ice known as ice shelves. In a few special places glaciers can extend tens of kilometres into the ocean – giant fingers of ice several hundred metres thick, pointing out into the sea. Just like a wall they shield what is in their lee, and rather than the ocean being covered by drifting sea ice it can remain open throughout the year to form what is called a polynya. The ocean still freezes, but the ice is constantly pushed away by the prevailing winds. Open water throughout winter helps seals and penguins survive, and stimulates phytoplankton production.  A new research article in the journal Nature Communications by a French team working in Antarctica has looked at the history of the polynya in the lee of the Mertz Glacier going back 250 years. This glacier forms one of these fingers of ice reaching out from the continent and the polynya in its lee can be up to 6,000 square kilometres. What they did was take a core sample of sediment from the sea bed in the lee region (the red star in the above images) and look back in time using climate proxies such as the titanium content – which can be considered a proxy for the how much of the sediment comes from the land.  The proxies tell us which species of plankton dominated the region in a particular period: if the sediment is dominated by species which live in open water then they can infer that the polynya existed and so the Mertz Glacier had a long tongue extending north. If the sediment is dominated by species which live in the sea ice, then the polynya and the glacier tongue were absent. It is quite an elegant way to investigate glacier flow.  What they found is that every 70 or so years the Mertz polynya is absent for tens of years. Given that the glacier is advancing about 1 km per year this means a super-iceberg tens of kilometres in length has regularly formed in this region. These days we can see this happen in almost real time through the amazing access we have to satellite imagery and in February 2010 an iceberg containing almost 900 billion tonnes of fresh water broke free. You may think it would drift north, away from the continent, but icebergs this big don’t have an easy path. They crash and bounce along any relatively shallow region of the sea floor and wipe out anything in their way. Most people know trawling harms the sea floor; imagine the trail of damage 900 billion tonnes of ice scraping on the sea floor can leave. Very large icebergs get identifying codes; this one became C28 as it was the 28th large iceberg from this sector of Antarctica. It took two months for C28 to reach the deep water before it shattered into two pieces (C28A and C28B since you ask) both still massive, and both went on to spawn further icebergs as they fractured into ever smaller pieces over the next few years. When still close to shore these giant bergs are bad news for penguins, who suddenly have to travel much further – around the iceberg – to find open sea, and their food. Chicks growing up near a massive iceberg may starve and die and some entire colonies may become unviable. As they drift away these huge icebergs create their own habitat cooling the seas and freshening the waters, and also seeding the oceans with iron which means more algae and plankton at the bottom of the food chain in remote locations such as South Georgia, where icebergs run aground and die.  Over the past 50 or so years the robust cycle of growth and decay in the Mertz glacier has broken down. The researchers think this is due to large-scale changes in the way the wind circulates over Antarctica – the so-called Southern Annular Mode (SAM). Other studies have shown us that the way the SAM has changed over recent decades has an anthropogenic footprint. It seems even in Antarctica we can identify human impacts on climate processes that are likely to have been operating for thousands of years."
"It was more than 100F (38C) in the attic where telephone technician Brent Robinson was working. The 55-year-old, who had worked for 30 years at Verizon, was installing a phone service for a residential customer in Rancho Cucamonga, 40 miles east of Los Angeles in southern California. He had been out for days sick earlier in the week. After he finished the job in Rancho Cucamonga, he collapsed in the car park of a grocery store where he had gone for a cool drink; paramedics could not revive him. Robinson, who died in 2011, is one of dozens of workers who die every year because of heat exposure. In 2018, 60 workers died due to temperature extremes, according to the most recent Bureau of Labor Statistics data on workplace fatalities. Though the climate crisis is creating conditions where workers are facing hotter temperatures on a more frequent basis, there are no federal safety protections for workers in extreme temperatures, and only three states, California, Washington and Minnesota, have heat stress workplace protection standards. The fatality was one of several over that decade suffered by telecommunications technicians on the job. According to the CWA, it was the last fatality since the union began pushing to include heat stress workplace standards in collective bargaining agreements. “Unfortunately these catastrophic events have to occur to get employer’s adequate attention,” said David LeGrande, now retired Occupational Safety & Health Director for the CWA. The CWA represented Robinson at Verizon at the time of the incident, and LeGrande was one of the leads involved with the union’s investigation of Robinson’s death. LeGrande said: “We are, to my knowledge, the first union that has negotiated protective language with employers. That has been carried out on a national basis.” Verizon did not respond to requests for comment. According to projections conducted by the not-for-profit organization Climate Central, the number of dangerous heat days for 133 US cities, will increase from 20 a year on average in 2000 to 58 in 2050. A dangerous heat day is defined as one in which the heat index, accounting for heat and humidity, exceeds 104F (40C). “Climate change means it’s only getting hotter, and workers are at exposure for all kinds of excessive heat,” Judy Chu, a Democratic congresswoman from California, told the Guardian. Earlier this year, she introduced the Asuncion Valdivia Heat Illness and Fatality Prevention Act of 2019, which would direct the Occupational Safety and Health Administration (Osha) to issue and enforce standards to protect workers from heat-related risks on the job. Chu said: “It all started when I was in the California state assembly. The United Farm Workers came to me about the situation with Asuncion Valdivia. He was a farmworker picking grapes for 10 hours straight when he collapsed in 105F temperatures. “Instead of having any kind of proper treatment for him, a supervisor told his son to take him home. They didn’t even call an ambulance. On the way home, the son saw his father foam at the mouth, fall over and die. So the son had to watch his father die of a preventable heat stroke.” In the California state assembly, Chu authored a bill for the California division of Occupational Safety and Health (Cal/Osha) to enforce heat standard protections for outdoor workers, which passed in 2005, making California the first state in the US to mandate employers to provide workers with periods of rest, shade and adequate water while doing outdoor work. In 2015, the state of California settled two lawsuits brought by the United Farm Workers. “Those called for greater protections for all outdoor workers in high heat temperatures and also called for establishing a mechanism where farmworkers can call us directly to report complaints to CalL/Osha,” said Marichel Meija, national field coordinator for the United Farm Workers Foundation. “We now have regular communications with Cal/Osha to ensure situations are investigated.” Now the United Farm Workers and several other organizations are pushing for similar standards to be enforced across the US. According to the Bureau of Labor Statistics, between 1992 and 2016, 783 workers in the US died and more than 69,000 workers suffered serious injuries due to heat exposure on the job, though labor advocates argue the real numbers are even higher due to widespread under-reporting and employers misclassifying worker deaths as non-work-related. “We’ve had issues where workers are not classified as dying because of their job when we know that is the case,” said Rebecca Reindel, senior safety and health specialist at the AFL-CIO union federation. “With heat you’re running into a lot of vulnerable workers, immigrant workers, where employers will pass it off, say something else happened, and no one is following up and that person’s family don’t know their rights to get it classified as a workplace fatality.” As workers in the US are facing workplace environments that are getting hotter, and experiencing extreme temperatures more frequently, critics say the Trump administration has refused to address the problem. In an April 2019 report, the AFL-CIO noted federal Osha’s inspections related to heat declined by 49% under the Trump administration’s first two fiscal years in office. More than 130 organizations petitioned Osha in 2018 to develop federal heat standards, with Chu prompted by the agency’s inaction to introduce legislation in Congress. “This bill would have such a high impact for so many workers forced to work every day in conditions they can’t control,” said Reindel of the AFL-CIO union federation. “It’s a structure to identify the hazards. These programs are really good because workers are part of the process, and when workers are part of the process that’s when you get to the root of the problem.” According to an Osha spokesperson, the agency launches a heat awareness campaign annually the Friday before Memorial Day, has been educating employers and workers about the dangers of working in heat since 2011, and in 2017 helped update an app for heat safety. The agency did not respond to requests for comment on petitions calling the agency to enact federal heat safety standards."
"Greta Thunberg summed up 2019 in five words: “Our house is on fire.” In Australia, this is now literally the case. Wildfires there have been raging for more than a month and now span an area larger than Switzerland. The situation bears all the hallmarks of a hot new world: lives lost, livelihoods ruined and species pushed towards extinction, accompanied by government inaction, industry PR spin, abetting rightwing echo chambers, and taxpayers footing the multibillion-dollar bill. Insanely, the Australian government remains in denial – ignoring the science, downplaying the seriousness and subservient to coal. The fossil fuel industry, meanwhile, is busy greenwashing and gaslighting: Chevron is boasting about its $1m donation – 0.00667% of its annual earnings – to the Australian Red Cross, and Exxon Australia just wants everyone to “Stay safe and have fun”. All this is set to a backdrop of mutually reinforcing rightwing new outlets, online bots and trolls, which are distracting and misinforming the public about the science and politics of climate-catalyzed fires. The charity of everyday people (and some celebrities) rising to meet the disaster has been inspiring and essential. Yet, tragically, it also unintentionally serves to reinforce the false narrative, perpetuated by fossil fuel propagandists, that we are all equally to blame. In reality, today’s climate chaos is big oil’s legacy, not ours. Unlike the rest of us, the fossil fuel industry saw this climate chaos coming, then literally and figuratively added fuel to the fire, doubling down on a business model incompatible with the science of stopping global warming; buying political inaction; and building a global climate denial and delay machine that has confused the public and fomented distrust of science, media and government. In October last year, the US Congress began to investigate this history. Before a packed audience at a congressional subcommittee hearing titled Examining the Oil Industry’s Efforts to Suppress the Truth about Climate Change, the Democratic representative Alexandria Ocasio-Cortez questioned the climate scientist Dr Martin Hoffert about his collaborative research with Exxon in the 1980s. “So in 1982,” she said, referring to a recently uncovered internal company memo containing a graph of global carbon dioxide and temperature levels rising over time, “1982 – seven years before I was even born – Exxon accurately predicted that by this year, 2019, the Earth would hit a carbon dioxide concentration of 415 parts per million and a temperature increase of 1C. Dr Hoffert, is that correct?” “We were excellent scientists,” answered the former New York University physics professor, triggering laughter from the audience. “Yes, you were; yes, you were,” the congresswoman agreed. “So they knew.” This was the first time that Congress – indeed, any legislative body in the world – had heard a firsthand account – from someone who was actually involved in the work – of just how much, and how early, the fossil fuel industry knew of the potential global warming dangers of its products. The event showed how effective such hearings can be. In the space of a couple of hours, expert witness testimony (including by one of us) and thousands of pages of documented evidence entered the congressional record. Masterful questioning helped translate a key whistleblower’s knowledge into a viral C-Span moment. It was just one hearing, but it had the makings of the tobacco industry investigations led by Representative Henry Waxman in the 1990s. He could just as easily have been speaking about fossil fuels when he described the purpose of that congressional oversight: “To build a public record and eventually create enough momentum in Congress and among the American public for legislation.” Our message to Congress after its first foray into investigating fossil fuels is this: keep going. Because big oil is the new big tobacco. Investigative journalism and peer-reviewed research, including our own, clearly demonstrate that the fossil fuel regime has deliberately denied Americans and Congress their right to be accurately informed about the climate crisis, just as tobacco companies misled Americans about the harms of smoking. From strategy to networks to personnel to rhetoric, the fossil fuel regime’s efforts to deny and delay come straight out of big tobacco’s playbook. The historical record is incontrovertible. As we summarize in a recent report, the fossil fuel industry’s own internal documents reveal that it has been studying CO2 pollution for more than 60 years. As early as the 1950s, it knew its products had the potential to change the climate. By the late 1970s and early 80s, Exxon scientists were explicitly aware that burning fossil fuels could lead to what they called “catastrophic” global warming. In 1986, an internal “greenhouse effect working group” at Shell concluded: “The changes in climate … may be the greatest in recorded history.” For all the skeletons we have already found in big oil’s closet, we are still only looking through the keyhole But instead of taking action or warning the public, fossil fuel interests stayed quiet. Then, in the late 1980s and early 90s, when global warming finally caught the world’s attention, the carbon majors sprang to action and took the low road, spending billions of dollars over the next 30 years on advertising and lobbying challenging science, slandering scientists and attacking policies to protect their profits. In so doing, they have undermined – and continue to undermine – Americans’ chances of a just and stable future. Today, the case for subterfuge is so strong that New York, Massachusetts, Rhode Island and 14 US cities and counties have variously sued ExxonMobil and other fossil fuel companies for fraud, damages or denial. Maui and Honolulu have recently added their intentions to file lawsuits. In Australia, there are mounting calls to make polluters, not just taxpayers, pay for wildfire relief and climate mitigation. For all the skeletons we have already found in big oil’s closet, however, we are still only looking through the keyhole. Tracking down a few hundred documents has allowed us to uncover some key cogs in the climate denial machine. Yet it is a sprawling, well-funded, well-oiled network that stretches far beyond ExxonMobil and the Kochs: a labyrinth of people and money connecting fossil fuel companies, utilities, ancillary manufacturers, trade associations, PR firms, advertising agencies, libertarian foundations, thinktanks, legal firms and individuals, all feeding an echo chamber of pundits, astroturf groups, blogs, media and, yes, politicians. Network analysis has identified at least 4,556 individuals and 164 organizations in the global web of denial. We believe the American public deserve to know the truth – and see the receipts – of these dealings that have already led to deaths, destruction and the injustices of a collapsing climate. This is where congressional authority to request documents and, if necessary, issue subpoenas, comes in. Key breakthroughs in tobacco control came as congressional investigations – as well as legal discovery and industry whistleblowers – exposed thousands, and ultimately millions, of damning documents. The tobacco industry was found guilty of racketeering in part because of the ways that individual companies had coordinated with each other and with third-party allies to present false information to consumers. That history is a precedent for Congress to investigate an industry network that has misled the public and policymakers in an effort to deny the dangers of its products and derail regulation. As the congressional scholar Morton Rosenberg recently testified in the Senate: “Congress and its committees have virtually plenary power to compel production of information needed to discharge their legislative functions.” We are not politicians or political strategists, so we do not presume to dictate how Congress exercises its investigatory powers. But as experts in the history of climate denial and global warming politics, it is our opinion that holding the fossil fuel industry accountable would be one of the most impactful ways for Congress – and governments around the world – to combat the climate crisis. Impeachment investigations understandably occupy much attention. Unfortunately, irreversible global warming and the fossil fuel regime underwriting it will be even harder to unseat than a president, and time is not on our side. Geoffrey Supran is a research associate in the department of the history of science at Harvard University, where he investigates the tactics of fossil fuel interests. He previously co-led the fossil fuel divestment campaign at MIT, as well as the first major scientist protests against the Trump administration Naomi Oreskes is professor of the history of science at Harvard University and the co-author, with Erik M Conway, of Merchants of Doubt and The Collapse of Western Civilization"
"In recent decades, environmentalists have grown used to disappointment when big companies and Wall Street pay lip service to concern over the climate crisis. On Tuesday, it looked like something might have changed. The decision by BlackRock – the world’s biggest asset manager – to exit investments that “present a high sustainability-related risk” has been welcomed by environmentalists as a significant moment in the battle to reshape the relationship between money and the climate crisis.  The move is “a remarkable breakthrough”, the leading climate science writer Bill McKibben told the Guardian. “The activists who made this happen get the afternoon off to celebrate. “This is the biggest pot of money in the world and until today, its leaders have refused to acknowledge the biggest thing happening on the planet – the accelerating rise in temperature. So it indicates that the facts on the ground of the climate crisis are so grave that no one can turn away, and that activist pressure has reached a point that even the richest companies are not immune.” In two letters on Monday, the BlackRock boss, Larry Fink, announced: “The evidence on climate risk is compelling investors to reassess core assumptions about modern finance” and henceforth the company would divest $500m from coal-related businesses. The announcement called on “every company, not just energy firms, to rethink their carbon footprints”. BlackRock, which holds $7tn in assets, has come under intense pressure to reform the funds it offers investors. “Awareness is rapidly changing, and I believe we are on the edge of a fundamental reshaping of finance,” Fink wrote, adding that new funds would allow clients to avoid investments in companies that may be adding to climate change. The firm said it doubled to 150 the number of exchange-traded funds it offers that address social, environmental or governance issues. In November, climate activists protested outside BlackRock’s London offices, dumping ashes to signify the Amazon fires while Extinction Rebellion, the global environmental movement, described BlackRock as the world’s top investor in deforestation and coal. Fink himself has received letters from members of Congress urging action, while BlackRock was named as an investor with one of the worst voting records on climate issues by Ceres, a not-for-profit watchdog that pushes financial firms to consider sustainability. The pressure for change has come from within the world of finance as well as outside. Last month, Mark Carney, the outgoing head of the Bank of England, warned that pension funds risk seeing their assets become worthless unless companies rapidly rise to the challenge of the climate crisis. But while some celebrated, others warned that sustainable investing will not be quick or simple for BlackRock. It currently holds a 6.7% stake in ExxonMobil, 6.9% in Chevron, and 6% in the mining company Glencore. Two-thirds of its $7tn in assets are in tracking funds that cannot easily be switched to meet sustainability goals. McKibben, who last year published a devastating report in the New Yorker titled Money Is the Oxygen on Which the Fire of Global Warming Burns and who is part of a campaign to force companies including Goldman Sachs, Chase Bank and BlackRock to reform their investments, said environmentalists would now need to keep the pressure up. “The steps BlackRock is taking are baby steps, and we will have to watch and push hard for them to begin striding at the pace we need to go. But in some sense, the first step is often the hardest,” McKibben said. He urged the company to go further. Its decision to divest $500m from coal-related businesses, for instance, is not the same as divesting from larger and far more polluting oil and gas industries. “Coal is part of the problem, but not the biggest part of the problem – oil and gas are,” McKibben said. “Fink made noises that natural gas is part of the solution but it’s not. That’s old thinking, and we’ll push them hard on that, but at least we’ve reached the point that they’ve realized they have a role in dealing with the climate crisis.” But perhaps the largest change is BlackRock’s apparent willingness to use its considerable shareholder power to demand climate action – a power it has in the past demurred from using in favor of direct company consultations. A report last year by the Washington DC-based Majority Action and the Climate Majority Project claimed that BlackRock had voted overwhelmingly against key climate resolutions at energy companies, including ExxonMobil. Had BlackRock and Vanguard not torpedoed these investor efforts, at least 16 climate-critical shareholder resolutions at S&P 500 companies would have received majority support in 2019, representing a significant corporate shift on climate, the report claimed. “We have the largest investment stewardship team in the industry and engage with companies even in the absence of shareholder proposals,” BlackRock said in a statement to the Guardian at the time. But, it warned, “it would be wrong to equate good governance with voting against management without regard for a proposal’s impact”. In Tuesday’s statement, that position appeared to be shifting from last year when it said that “recent extreme weather events” and “the implications for investment portfolios – stemming from a rising frequency and intensity of such events – have been notoriously hard for investors to grasp”. No longer. Now BlackRock’s CEO writes that company directors should be held accountable “where we feel companies and boards are not producing effective sustainability disclosures or implementing frameworks for managing these issues”. He added that “the company voted against or withheld votes from 4,800 directors at 2,700 different companies” last year. There are still worries for environmentalists. Majority Action’s Eli Kasargod-Staub warned that subtlety in BlackRock’s language calling for companies to improve disclosure on “integrating and reporting on sustainability” is not the same as calling for immediate action. “BlackRock has the power to be going to corporate directors and saying: ‘Either you commit to the science-based targets of the Paris climate agreement and align your operations, governance, political spending, lobby and trade association activities to achieve that target or we will vote against you and your directors,’” Kasargod-Staub said. “But that’s not what BlackRock said – they said they’re calling on companies to enhance their disclosures around climate risks and their plans around those risks,” he added. Kasargod-Staub pointed to this quote from BlackRock, directed at companies it invests in: “This should include your plan for operating under a scenario where the Paris Agreement’s goal of limiting global warming to less than two degrees is fully realized, as expressed by the TCFD [Task Force on Climate-related Financial Disclosures] guidelines.” “Think about how passive that sentence is, then think about the behavior of ExxonMobil or Marathon petroleum, who through their capital expenditures and policy influence have actively undermined our ability to protect long-term investors and meet the goals of the Paris agreement,” said Kasargod-Staub. Whether Blackrock is now going to side with activist resolutions on sustainability remains to be seen during shareholder season, McKibben said, but he warned against expecting a shift by fossil-fuel energy producers to become carbon-neutral. “I don’t think the big oil companies are capable of changing, though I’d like to be proved wrong,” he said. “The job is basically to starve them and reduce their ability to continue expanding.” Still, McKibben said: “For all of us that have been campaigning for years around climate finances, this is an historic moment. From today, it’s going to be harder to go sink of load of money in Exxon, because the biggest financial firm in the world has said, ‘Huh, there’s something to this climate stuff. Better pay attention.’”"
"Britain’s tallest tree is a 200-year-old, 44-metre high beech growing in woods in West Sussex, according to the Tree Register.  Although this incredible beech, found on the National Trust’s Devil’s Dyke estate, is slightly taller than the previous champion – another of this genus in Gloucestershire – these are not actually the tallest living trees in Britain but the tallest native trees – ones known to have been growing in Britain since the last ice age.  If we included all trees – native or those introduced at a later date – there would be others in the running. Currently the tallest tree growing in the UK is a Douglas fir growing in Reelig Glen, near Inverness which measures just over a massive 66 metres. Height, of course, is not the only thing that can make a tree stand out. Other categories competing for most impressive tree include age and mythology. Here are four others that fit the bill. When Nottinghamshire residents go just about anywhere in the world and explain where they live, the immediate response is “Aaah! Robin Hood!”  Famous around the world for harbouring the infamous folk hero, the “Major Oak” is one of Britain’s oldest oak trees. No one is sure exactly how old it is but estimates of 800 to 1,000-years-old mean that it has survived through at least eight centuries of change. The major is a fine example of Quercus robur, or the English Oak, and brings thousands of tourists to Sherwood Forest every year. Sadly visitors can no longer climb inside the tree as it is now fenced off and to prevent them from falling, the massive branches are propped up on large poles.  It is debatable whether Robin and his Merry Men did actually hide inside this tree but keeping things inside it has been recorded several times during its history, initially as the “Cockpen Tree” when it was used to contain birds before a cock fight. It was only named the Major Oak in the late 1700s after Major Hayman Rooke, the local historian who described it. In the 19th century it was known for a while as the “Queen Oak”. Nottinghamshire is also home to the original Bramley apple tree. Bramleys are large, sour apples well known all over the world for their cooking quality, and they all descend from one 200-year-old tree which still exists today. The tree was first grown from a pip in 1809 in a back garden in Southwell by a young local girl called Mary Ann Brailsford. Once the quality of the fruit had been noted in the 1860s the tree was propagated by Merryweather’s Nursery, also in Southwell.  It’s astonishing to imagine that every single Bramley apple tree across the world has been cloned from this original tree (or indeed from a clone of a clone of a clone of this original tree)  originally grown from a pip so many years ago by a little girl. Although the original was grown from seed, new Bramley apple trees are grafted onto another type of apple tree to help reproduce them. Bramleys are also sterile, able to receive pollen but not able to pollinate other Bramleys themselves. This is because they have an extra set of chromosomes, which means they need two other different types of apple tree to pollinate – otherwise their apples won’t grow and swell. We have to move along to Wales to see Britain’s oldest tree, a 5,000-year-old yew growing in St Cynog’s churchyard at Defynnog near Sennybridge, Powys.   It’s not surprising that this is a yew, as these conifers have an amazing ability to regenerate. For centuries yews have been known as the “tree of life” due to their longevity. When the centre dies away and they become hollow, the cylindrical shape of the trunk is actually amazingly strong and is still able to support the massive crown of the tree.  Yew trees have been long associated with churches and graveyards and in ancient legends they were associated with immortality. In Wales the tradition of the yew as such a symbol is linked with ancient Druid beliefs and customs, and was often a meeting place where rituals and festivities took place. Finally, the award for the tree with the widest trunk goes to another English Oak with an amazing 12-metre circumference. This tree is known as the “Majesty” and is growing in Fredville Park, in Kent. Although the tree is completely hollow, the trunk has not split. One journal entry recorded a visit to the tree in 1793: Call on John Plumtree, Esq. of Fredville, who very politely shews us his famous oak, called Majesty - measure this tree; 4 feet from the ground the circumference is 31 feet; it is supposed to contain from 36 to 42 tons of timber. Two branches separated from this tree about four years ago, in a calm day, which contained three tons of timber. Another oak, called Beauty, 14 tons of timber; girt, 4 feet from the ground, 16 feet 4 inches, is 63 feet high, perfectly straight, and a beauty indeed!"
nan
"When the Paris Agreement in December 2015 called for the IPCC to put together a “Special Report” on Global Warming of 1.5°C, scientists knew very little about the exact differences that half a degree makes (1.5°C versus 2°C). Never before have so many independent studies been conducted at such short notice, in order to meet this pressing question of the global climate negotiations community. Is a warming of 2°C above pre-industrial levels sufficiently low a limit to avoid dangerous anthropogenic interference with the climate system, and, if not, can we implement a lower limit?  Many researchers worked tirelessly to get their scientific publications accepted before the cutoff deadline in May 2018. And now we have the assessed result of their studies, summarised in about 30 pages. So what have climate scientists learned? First, nothing fundamentally new or surprising has arisen. I vividly remember being involved in crafting the sentences on climate change impacts at different temperatures in the IPCC’s previous full assessment round, which was finalised in 2014. We concluded that more warming increases the likelihood of “severe, pervasive, and irreversible impact”, that “some risks of climate change are considerable at 1 or 2°C above pre-industrial levels” and that “the overall risks of climate change impacts can be reduced by limiting the rate and magnitude of climate change”. It is important in interpreting the new report that the IPCC has never said that 2°C was “safe”. The 2018 report now puts the particular differences between 1.5°C and 2°C under a magnifying glass. And it comes up with numbers to demonstrate the significant difference between the two, like in a statement that the lower temperature would mean 50% fewer people “exposed to a climate change induced increase in water stress”. I also remember very well that another IPCC contact group that I co-chaired, in Berlin, concluded that reaching a 2°C target would probably entail large-scale afforestation and/or production of bioenergy with carbon dioxide capture and storage (BECCS). In order to reach 1.5°C, no one should be surprised that the need to suck carbon dioxide out of the atmosphere and store it somewhere will only become greater. And indeed the 2018 report confirms that some sort of “carbon dioxide removal” will be necessary. Its use can remain limited, however (without even the need for BECCS) provided that there are fast and significant measures to cut emissions and “lower energy and land demand”. Providing the additional, detailed information to policymakers is all very useful. But what strikes me about this latest report is its tone. For the scientists involved it has become apparent (which they never said in so many words before) that the goalpost should be shifted from 2°C (which was already hard to reach) to 1.5°C (which is much harder to reach). Which leads one to ask: if climate scientists are so adamant about this now, why did they not create the opportunity themselves to issue such a warning before? And why did they wait for global leaders to ask them the question? Politicians have often erroneously pointed to climate science – and the IPCC as its assessor in particular – as having provided the underpinning of the globally agreed target of 2°C. In 2015, the politicians effectively asked scientists to underpin a more stringent target. And they obliged. The scientific community needs to make it as clear as they can that it is not them who have now decided that 1.5°C is “safe”. The IPCC has only provided the evidence base that can inform politicians in their deliberations of whether they indeed wish to stay below that other target in the Paris Agreement, the limit of 1.5°C. In those deliberations, the feasibility of staying below 1.5°C will feature prominently. And here the scientists will find it hard to admit that the scenarios they have conjured up are not at all realistic – they are more like a pipe dream. If they say, for instance, that large-scale carbon capture can be avoided by implementing incredibly fast and deep emission cuts now, they kind of set the world up for having to implement carbon capture anyway, given the difficulties that are involved in fast deep emission cuts worldwide.  The IPCC did not go further than stating that there are some “feasibility and sustainability constraints” related to many of its scenarios. A smart reader will understand that this means that these scenarios are not really feasible, politically and (since politics is fractured) economically."
"
Share this...FacebookTwitterPIK takes a blow: stronger hurricanes cannot be explained by higher CO2
By Die kalte Sonne
(German text translated/edited by P Gosselin)

Image: NASA (public domain)
Whenever the hurricane season in the Caribbean begins, the whole world and the German Potsdam Institute for Climate Impact Research (PIK) wait for a strong storm, as it presents the ideal opportunity to sell climate change, as was the case in September 2017 when Potsdam’s Neueste Nachrichten (PNN) daily reported with reference to the PIK’s Anders Levermann:
Global warming provides energy for stronger tropical storms
According to Potsdam climate researchers, the impact of the current tropical cyclones can be attributed to climate change. Burning coal, oil and gas increases the temperature of the planet and thus provides energy for ever stronger tropical storms, explained Anders Levermann of the Potsdam Institute for Climate Impact Research (PIK). “Unfortunately, physics here is very clear: hurricanes draw their destructive energy from the warmth of the ocean. The water temperatures in the region are too high. Climate change does not cause these storms, but it can “make their consequences worse.”
Will the intensity of hurricanes increase with climate change? Can this be detected today, as Levermann concludes so trivially? This is not the case, say researchers around Lory Trenary from George Mason University in Fairfax, Virginia. They investigated climate models and re-analyses and found no connection with the drive by greenhouse gases, especially CO2.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The long-term trends 1958-2005 were ultimately contradictory and not valid. An attribution of hurricane intensity to climate change is still not possible. In the introduction to their current work, they also mention Levermann’s argument: “Warmer ocean-more severe storms! After a detailed analysis, however, they come to the following conclusion:
These results indicate that currently we cannot attribute changes in North Atlantic hurricane intensity to human related forcings.”
Already in the past there was disagreement among atmospheric researchers about the influence of anthropogenic forcing on hurricane intensity. Levermann did not bother with this last year either, because as a researcher he is undoubtedly informed about the various topics. So the only reason for spreading the false claim remains the climate siren character of the PIK and others.
Here is the abstract from the work of Trenary et al., which appeared in the Geophysical Research Letters on March 4, 2019:
Are mid‐20th century forced changes in North Atlantic hurricane potential intensity detectable?
Abstract: The impact of anthropogenic forcings on tropical North Atlantic hurricane potential intensity (PI) is evaluated in CMIP5 models for the period 1958‐2005. Eleven models are examined, but only seven models have a forced response that is distinguishable from internal variability. The use of discriminant analysis to optimize detectability does not yield a clear, common climate change signal. Of the seven models with a significant response, one has a negative linear trend while two have a positive linear trend. The trend in PI is not even consistent among reanalyses, although this difference is not statistically significant because of large uncertainties. Furthermore, estimates of PI internal variability have significantly different variances among different reanalysis products. These disagreements between models, reanalysis products, and between models and reanalyses, in conjunction with relatively large uncertainties, highlight the difficulty of detecting and attributing observed changes in North Atlantic hurricane potential intensity.
Plain Language Summary: Observed temperature has been steadily increasing over the last century and much of this warming can be attributed to greenhouse gas emissions. Theoretically, the maximum intensity (or potential intensity) a hurricane can achieve depends strongly upon sea surface temperature, with warmer temperatures producing stronger storms. From this perspective, we might expect that the warming surface temperatures are driving observable changes in hurricane intensity. To this end, we analyze climate model experiments to determine if the observed changes in North Atlantic hurricane intensity can be attributed to human related emissions over the period 1958‐2005. Of the eleven models analyzed, we find that only seven predict that hurricane potential intensity has changed in response to greenhouse gas and aerosol emissions. The change in potential intensity differs across models, with one model predicting a decreasing trend in North Atlantic hurricane potential intensity, while two models predict an increasing trend in potential intensity. Different reanalysis datasets are likewise inconsistent. These results indicate that currently we cannot attribute changes in North Atlantic hurricane intensity to human related forcings. It is possible that as greenhouse gas concentrations continue to increase, an unequivocal forced response in North Atlantic potential intensity may emerge in the future.”
Share this...FacebookTwitter "
"Planning permission has been given for what could become the world’s largest offshore wind farm on the Dogger Bank, off England’s east coast. If fully constructed the project will have up to 400 turbines with a total generation capacity of 2.4 GW. That’s enough to power 1.9 million households – more than Manchester and Birmingham combined. So why now? And why so big? It seems the UK government is essentially taking a punt on the future of offshore wind. Investment in a more expensive renewable technology at an earlier stage means a premium is being paid in the hope it will kick-start a whole industry. This would in turn reduce costs, while generating low-carbon electricity out of sight. Dogger Bank, located more than 80 miles off the Yorkshire coast, is indeed far out of sight. It seems a good location for a wind farm. The region was an island during much of the last ice age and today it has shallow water, seabed conditions well-suited to the foundations of wind turbines and of course strong, consistent wind. Its development nevertheless raises a number of technical and logistical challenges, notably linked to the influence of the weather on the maritime supply chain. No wind farm has yet been built that far from land. Furthermore, it still needs to secure contracts for government subsidies. With fewer neighbours to annoy, offshore wind farms are generally less contested than their onshore equivalents. Offshore wind can have nevertheless a detrimental impact on the natural environment, like disturbance to the seabed by laying cables. But it seems there could be an overall positive effect on marine wildlife as the “artificial reef effect” helps fish group together. Electricity generated by onshore wind can now compete on cost with electricity generated with conventional sources such as gas. But offshore projects from the last licensing “round 3” issued in 2010 are often located in large zones far from the coast such as Dogger Bank, which pushes up costs. Nevertheless, prices could easily come down. Indeed, as solar power has recently shown, renewable energy technologies can become dramatically cheaper once they achieve maturity and the technology is scaled up. While long-term projections of future electricity costs are always uncertain,  offshore wind could become cheaper through better technology, economies of scale and through optimised designs becoming standardised. Dogger Bank could be a big part of this – the first of a series of large wind farms which will gain strength in numbers and reduce generating costs. There are many reasons a country might want to reduce reliance on fossil fuels. Energy generated from oil and gas causes air pollution and environmental degradation, while still requiring subsidies just like renewables. As demonstrated by the late economist Shimon Awerbuch, volatile fossil fuel prices on the international market have a detrimental impact on modern economies. More renewables makes sense to mitigate the impact of future international energy crisis. It looks as though offshore wind is now the preferred path for the UK government to meet renewable energy targets. It hopes offshore will provide 8-10% of the UK’s electricity by 2020. Offshore carries a much lower political cost than its onshore equivalent, with wind turbines anywhere near either homes or areas of natural beauty facing very vocal opposition.  From 2030s, it can be expected that the cost per unit for this technology will be cheaper than for so called “clean” coal or “clean” gas generation while generating far less carbon emissions and pollution. But, if the UK is to decrease drastically its dependence on fossils fuels and decarbonise its electricity sector, offshore wind cannot be a substitute to the development of other renewable energy sources and to the systematic implementation of large-scale energy savings programmes."
"The Labour Party’s new plan for a low-carbon Britain breaks new ground. It could offer a lifeline to a clean energy sector hit by the withdrawal of subsidies and, in a radical move, it proposes to put control over energy back in public hands.  It is also timely. The UN Intergovernmental Panel on Climate Change is about to release a special report on the transformative, systemic action needed to keep warming below 1.5℃ (the stated aspiration of the 2015 Paris Agreement), so bold moves are welcome. The report will reinforce the fact that the strategies governments currently have on the table are wholly inadequate and will leave the world on course for warming of 3℃-4℃ with catastrophic consequences. The Labour plan, outlined by the shadow business and energy secretary, Rebecca Long-Bailey, states that by 2030 the party would ensure that 85% of electricity demand is met from renewable and low-carbon sources. The eventual goal is for the UK to get to zero net emissions by 2050.  In his leader’s speech at the party’s recent conference, Jeremy Corbyn said Labour would “kickstart a green jobs revolution” involving 400,000 skilled jobs created by investments in wind, solar, and energy efficiency. Home insulation efforts will be paid for by £12.8 billion set aside from a national transformation fund, in order to address fuel poverty and conserve energy.  These expressions of “green Keynesianism” mark a break with the failure of neoliberal approaches which assume that market and price signals alone can deliver the required changes to the UK’s energy system. In many ways they resuscitate proposals for a Green New Deal that emerged in the wake of the 2008 financial crisis. They send a strong signal to investors about the direction of change – that in future the only viable energy system will be one which is low-carbon. There are ambiguities and potential contradictions here though. The phrase “renewable or low-carbon energy” keeps the door open for the expansion of nuclear, for instance. Trade unions often support an expansion of the nuclear industry because of its potential to generate new jobs and, since becoming leader, Jeremy Corbyn has lent his support to nuclear power. Such proposals remain unpopular with many in the environmental movement, however.  It is also unclear how Labour’s strategy sits with support for other high-carbon infrastructural investments such as the Heathrow airport expansion. Achieving its goals may well also require a suite of other measures including taxes on pollution rather than labour, sharp reductions in fossil fuel subsidies, much stiffer building regulations and fuel efficiency standards for cars, and stronger efforts to drive behavioural change among businesses and citizens – which are not yet on the table. Labour has called its environment policy the “Green Transformation”. Having studied such transformations, I feel that, despite its promise, there is a sense of a missed opportunity with the plan to be more imaginative about energy futures. This might include bolder thinking about decentralised, off-grid, community-owned models of energy provision as well as much more effective strategies to reduce energy demand in the first place.  And there are even greater challenges for the Labour Party. Can it go beyond a paradigm in which, whatever the question, state-led growth is the answer? Could the embrace of the need for green transformations extend to questioning an unflinching commitment to economic growth at all costs? This would mean engaging with ideas which place  well-being and prosperity – not GDP or growth – as the goals to be achieved. This might open the way to seeing radical reductions in the production and consumption of energy as possible and desirable, as well as necessary, to prolong life on a finite planet."
nan
"The lynx: a short-tailed felid weighing up to six times more than your domestic moggy. This large carnivore once roamed the British Isles 1,300 years ago but, due to habitat destruction, overhunting of its prey and purposeful killing by humans, the species was driven to extinction in the UK. Now, there are plans to reintroduce this species to three sites in England and Scotland. But what are the chances of a success? The International Union for Conservation of Nature (IUCN) has strict guidelines for reintroducing species into the wild.  One of the key recommendations they make is that the main causes of the historical decline must be addressed to ensure success of the reintroduction.   In terms of the threats to lynx, we now have stringent land management policies in place so it is unlikely that the cat’s preferred forested habitat will be destroyed.  The previous decline in the prey base (notably deer) is also not a problem today – in fact, many would agree that we have too many deer due to the lack of natural predators. But it is unclear to what extent the last threat – the purposeful killing by humans – is under control. Previous research has noted that the main cause of death among carnivores that have been reintroduced is due to humans. Although attitudes towards carnivores are generally positive in the UK, they become more negative among the people that could be adversely affected by these species and it is these people who have the power to kill. These are the farmers, gamekeepers and hunters (all of whom are allowed to own guns) who will be sharing their land with this species and may be worried about the damage that lynx can cause. The IUCN clearly states: Any translocation will impact and be impacted by human interests. Social, economic and political factors must be integral to translocation feasibility and design. These factors will also influence implementation and often require an effective, multi-disciplinary team, with technical and social expertise representing all interests.   Much research to date has looked into the biological factors surrounding the potential success of reintroducing lynx (eg. here, here and here), but far less attention has been focused on these important social, economic or political aspects. And it is the human dimension that will play a large part in dictating whether this project succeeds or fails. It is therefore worrying that amongst the main proponents of the lynx reintroduction, only one social scientist is listed on its team of experts (the rest being biologists).  This is not uncommon amongst species reintroduction projects: the Scottish Beaver Trial reintroduction team also does not have a social scientist. Given the widespread call among conservationists to include more social science into wildlife management schemes, it is disheartening to see that more is not being done in this country to integrate the human aspects of conservation into environmental projects. Although I cannot deny that the lynx would bring positive effects to this country by reducing deer populations (which might have additional benefits for young trees), we cannot disregard the potential negatives. Lynx can occasionally kill livestock, which could have economic and psychological costs.   The frequency of predation may be low, but this has not stopped the continual persecution of reintroduced predators in other parts of the world, such as the Mexican wolf. Indeed, the reintroduction of lynx in France failed because of hunting.  It is therefore crucial that we do not underestimate the potential for opponents of the lynx reintroduction to negatively impact the success of the project. Research in other areas of Europe has shown that attitudes towards lynx are, in general, positive.  It is likely that this is the case in the UK too, and I am sure that many British people would love to have lynx wandering the countryside again.  Like the Scottish Wildlife Trust, I too feel that we have a moral and ecological case to bring this species back, but until more extensive work is undertaken to address the threat of human persecution, I do not hold out much hope for this felid’s future in the UK."
"A company in Scotland has unveiled what it claims is arguably the world’s most technically advanced indoor farm. Intelligent Growth Solutions’ vertical farm uses artificial intelligence and specially designed power and communication technologies. The firm says this reduces energy costs by 50% and labour costs by 80% when compared to other indoor growing environments, and can produce yields of up to 200% more than that of a traditional greenhouse. Vertical farms like this aim to minimise water use and maximise productivity by growing crops “hydroponically” in small amounts of nutrient-rich water stacked in a climate-controlled building. But it’s important to recognise that the increased productivity of indoor vertical farming comes at the cost of much higher energy usage due to the need for artificial lighting and climate control systems. By 2050, global food production will need to increase by an estimated 70% in developed countries and 100% in developing countries to match current trends in population growth (based on production information from 2005-2007). But in countries that already use the majority of their land for farming, this is easier said than done. The UK, for example, uses 72% of its landmass for agricultural practices but imports nearly half of the food it consumes. To improve domestic food security and prevent natural habitats from being destroyed for new farmland, countries such as the UK need to consider new methods of food production. Urban farming presents a unique opportunity to grow food on already developed land, increase domestic food production and minimise the distance food travels. Since the publication of Dickson Despommier’s 2010 book The Vertical Farm: Feeding the World in the 21st Century, vertical farming has become synonymous with urban farming. Although the agricultural skyscrapers illustrated in Despommier’s book are yet to be realised, the idea of growing food vertically has captured the minds of designers and engineers alike. The energy demand associated with vertical farming, however, is much higher than other methods of food production. For example, lettuces grown in traditionally heated greenhouses in the UK need an estimated 250kWh of energy a year for every square metre of growing area. In comparison, lettuces grown in a purpose built vertical farm need an estimated 3,500kWh a year for each square metre of growing area. Notably, 98% of this energy use is due to artificial lighting and climate control. Even with the reductions promised by Intelligent Growth Solutions, the energy demand associated with most vertical farms would still be very high, which positions vertical farming in a grey area. On the one hand, the world needs to produce more food, and on the other hand, it needs to reduce energy use and the production of greenhouse gases.  But indoor vertical farming isn’t the only way to grow food in cities. A plethora of naturally lit methods also exist, from raised beds in communal gardens to rooftop aquaponic systems that grow food with the help of fish. These methods all require less energy when compared to vertical farming because they don’t need artificial lighting.  When viewing cities from above, it is clear to see just how many flat roofs are left vacant and the agricultural opportunities they represent. In the city of Manchester in the UK, unoccupied flat roofs account for an area of 136 hectares, representing one third of the city’s inner urban area. Gotham Greens in New York and Lufa Farms in Montreal, for example, are both commercial farms that use vacant roof space to grow food in naturally lit hydroponic greenhouses. Given the success of such projects and the area of roof space available, it seems strange that so many companies would skip ahead to methods of food production that still need a lot of costly development, as well as more energy to operate. Although they can’t grow as much food, rooftop greenhouses need at least 70% less energy for each square metre of growing area than artificially lit vertical farms. Having designed and built a rooftop aquaponic system myself in an ex-industrial building in Salford in the UK, I am surprised that more companies are not considering and maximising the opportunities presented by naturally-lit urban environments. If nothing else, I believe we should be exploring the potential of naturally lit environments before we delve into dimly lit buildings where special technologies, artificial lighting and air handling units are needed to produce food. There is little question that vertical farms will play a big role in urban farming and agriculture in the future. But when considering any method of food production, we need to understand the impact and energy use of the practice to ensure it is a sustainable and comprehensive response to global food demands. Vertical farming currently requires a lot of energy, which will hopefully decrease over time as companies like Intelligent Growth Solutions make technical advances. But for the time being, the practice of vertical farming is still a long way from being a sustainable method of agriculture."
"
Share this...FacebookTwitterGreenland’s ice sheet mass losses have significantly decelerated since 2013 – a reversal from the rapid retreat from the 1990s to 2012 driven by cloud forcing and the NAO (Ruan et al., 2019). The post-2013 “relatively stable” ice sheet even gained mass during 2017-’18 (Andersen et al., 2019).

Ruan et al., 2019    
Decelerated Greenland Ice Sheet Melt Driven
by Positive Summer North Atlantic Oscillation
“The GrIS lost mass at a rate of about -102 Gt/yr in early 2003, increased to -393 Gt/yr during 2012-2013, but suddenly reduced to no more than 75 Gt/yr during 2013-2014 (Bevis et al., 2019). It is suggested that this deceleration is due to the increased snowfall accumulation driven by the positive phase of summer North Atlantic Oscillation (sNAO; Folland et al., 2009; Chen et al., 2015).”
“It is shown that the deceleration of GrIS melting since 2013 is due to the reduction in short-wave solar radiation in the presence of increasing total cloud cover, which is driven by a more persistent positive summer North Atlantic Oscillation (sNAO) on the decadal time scale.”
“After an extreme year of the GrIS mass loss in 2012 (Tedsco et al., 2013; Nghiem et al., 2012) the rate of mass loss dramatically decreased since 2013 and has returned to about the same level (or even less) as was observed during 2004-2005. This indicates that the deceleration in GrIS mass loss since 2013 is mostly attributable to a reduction in the total mass loss during the summer season.”
“[T]he total cloud cover decreased with a rate of around 0.5% per year before 2013 in most of Greenland except the northeast area. As a result, the melt-albedo feedback is enhanced (Hofer et al., 2017) and the increased shortwave radiation over the low albedo ablation zone leads to accelerated melt of the GrIS (Box et al., 2012; Van-Angelen et al., 2012; Franco et al., 2013). Since 2013, the total cloud cover over most of southeast Greenland increased at a rate of more than 0.1% per year.”
“The lower SLP over Greenland is also consistent with the dramatic cooling of the northern North Atlantic Ocean during the same period. On the surface, the mean summer sea surface temperature (SST) in the North Atlantic subpolar gyre is more than 2ºC colder than the SST during 2003-2013; in the upper 300m, the volume mean ocean temperature is nearly 1.6ºC less (Fig. 6). The cooling of the ocean is not only helpful for the atmospheric configuration over the Greenland, but also favorable for the reduction of mass loss due to warmer water intrusion into the marine-terminated glaciers, though the latter process explains only around 30-50 Gt of the total mass budget of the GrIS (Zwally et al., 2002; Box et al., 2009; Tedstone et al., 2013).”


Andersen et al., 2019
Update of annual calving front lines for 47 marine
terminating outlet glaciers in Greenland (1999–2018)
“Currently, the mass loss from the Greenland ice sheet is the largest Arctic contributor to global sea-level rise (van den Broeke et al. 2009, 2017; Box et al. 2018).”
“The period 2007–2012 underwent a rapid loss of glacier area, compared to 2013–2018, in which glacier area was relatively stable, associated with a small area change. The year 2017–2018 stands out as the only period with net area gain (+4.1 km2).”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAverting a bloody climate science civil war
It’s time to take the debate away from the extreme factions and to move it to cooler heads, says veteran Swiss meteorologist Jörg Kachelmann
Former German Public television meteorologist Jörg Kachelmann wrote an essay commentary for the Swiss online Die Weltwoche here titled “Tell me where you stand”, where he compares today’s white-hot intolerance seen in climate science to the political intolerance witnessed in former communist East Germany.
“Religious furor”
In East Germany, either you adhered to the state’s hard communist doctrine, or you were the enemy. Such is the atmosphere we see today in climate science. Kachelmann writes: “Again today it’s either-or, and nothing in between.”
“Debates are important, and we must conduct them with arguments and without the religious furor that is being practiced today by both sides.”
The veteran meteorologist describes how on the climate issue “there are two irreconcilable camps”: the climate deniers and climate hysterics – each arrogantly claiming “infallibility”. It is no longer possible to be in between. Even those in between get insulted and attacked equally by both sides.
Natural science at schools have been “almost completely gutted”
While Kachelmann writes “deniers” are mostly older, right wing persons, the alarmists are made up of mostly “ugly young people” who are the products of school systems that have had their “natural science subjects almost completely gutted out”.
“These people don’t need graphs, but rather the godlike feeling of being on the correct side, which is why you don’t have to be so precise with facts,” Kachelmann comments.
“Today, the divining militancy of both sides is preventing a serious debate on priorities,” He says. “The green and brown nuts try to recruit for their political advantage those who have a big opinion on the subject, but no idea about it.”
Academic (green) supremacists
One example of the militant intolerance Kachelmann describes is illustrated by a recent Twitter comment by Potsdam scientist Stefan Rahmstorf, who reacted to German parliamentarian Philipp Lengsfeld, who earlier had tweeted on a “remarkable” statement recently published by 90 leading Italian scientists who challenged the alarmist climate science and claims of consensus.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Lengsfeld wrote:
Remarkable statement by scientists in Italy. For my taste a bit to hard, but so is the climate debate now: Heated.
From this I discovered a new site, by @NoTricksZone – a list of interesting studies. https://twitter.com/notrickszone/status/1146728105761038336?s=21 …”

Beachtenswert ist es vor allem, wenn ein Abgeordneter eine Klimaleugner-Website nicht von ernstzunehmender Wissenschaft unterscheiden kann und auf eine Unterschriftenliste von überwiegend fachfremden und emeritierten Leuten hereinfällt – noch unglaubwürdiger als die Lungenärzte.
— Stefan Rahmstorf (@rahmstorf) July 6, 2019

 
That comment by Lengsfeld was obviously too much for Rahmstorf, who was obviously unnerved that a parliamentarian would make such an observation. He not only attacks Lengsfeld and this site here, but he also insults and slanders the 70 Italian scientists.
His Twitter comment in English:
It is particularly noteworthy when a member of parliament cannot distinguish a climate denier website from serious science and falls for a list of signatures by predominantly unprofessional and emeritus people – even more untrustworthy than the lung physicians.”
In Rahmstorf’s view, anyone who challenges the Potsdam alarmist climate position is an enemy of the climate state, and any scientist who questions the science is equivalent to a tobacco scientist.
Yes, its’ time to move the debate and science over to moderate voices.
Jörg Kachelmann is an entrepreneur and a 40-year veteran meteorologist operating the site: www.kachelmannwetter.com.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThere’s really not any real doubt about it.
Cities, with their millions of tonnes of steel, asphalt and concrete act as ideal heat-absorbing sinks which take a long time to cool down at night. Just drive on a hot summer night through the country side and into a city makes that very clear.
Yet global warming activist scientists don’t like talking about that because it distracts from their flakey CO2 warming claims.
Now a new study looking at the urban heat island (UHI) effect on London titled “How much has urbanisation affected United Kingdom temperatures?” confirms real impact of the urban heat island effect. The study was published in the Atmospheric Science Letters.
Hat-tip: Reader Mary Brown
Here’s the abstract of the study (emphasis added):

That alone accounts for a very large part of the 20th century warming. But the alarmists certainly don’t want to hear it.
Share this...FacebookTwitter "
"A mission to Mars has captured the public’s imagination and the possibility of making that second small step has never seemed so close. Current NASA plans include sending humans to the red planet as early as the 2030s.  Should we ever establish colonies on Mars, we’d need to build power generation engines. This would imply finding energy sources and working substances to convert heat into useful energy. Now, in research published in the journal Nature Communications, my colleagues and I have found a way to make this happen using a substance easily found on the planet: the solid form of carbon dioxide, known as dry ice. We have developed an engine which can harvest energy from dry ice as it turns from solid into gas. For Martian exploration, it could be a game changer. To understand why, let’s go back to Earth for a moment. Here, we use water to turn the energy stored in coal, oil or gas into useful mechanical or electrical energy through what is known as a “heat engine”. In a steam engine, the most common form of heat engine, fuel is used to heat up water which then vapourises into high-pressure steam. This steam then powers a turbine to generate electricity, or a locomotive engine to create motion. Water is an ideal substance to use as it is widely available and cheap, and it is capable of undergoing a phase change (from liquid to vapour) within temperature ranges that are easily achievable with our current technology on Earth.  This whole situation changes dramatically on Mars; although water is still available on the surface of the red planet, it is locked in solid form. Heating it to melting point and then to boiling point to use it as a working substance requires a lot of energy.  However Martian dry ice already exists close to its “sublimation point” – the temperature at which it turns directly from solid to gas. It therefore only takes a relatively small nudge for dry ice to change states. The challenge is to harness the energy released by this change to power a heat engine – or even a whole colony. We turned to a common scientific effect you’ve probably noticed before in your kitchen. When a water droplet is placed on a hot surface held above 100ºC it boils off, creating steam. However when the surface is heated above a certain temperature, known as the Leidenfrost point, the water no longer boils away. Instead, the drop sits on a layer of its own vapour and levitates on top of the surface. This is known as the Leidenfrost effect. This same effect allows dry ice to levitate freely on top of solid surfaces, as it directly changes from solid to vapour and therefore it too is kept afloat by a layer of newly-formed gas. We can put this to use. By placing water droplets and small blocks of dry ice on top of hot, turbine-like surfaces, we have used the Leidenfrost effect to create rotational motion. The turbines channel the released vapour, whose flow in turn drives the levitating surface above to rotate. In a series of experiments, we have shown that carbon dioxide is a viable working substance for heat engines. By channelling the vapour released upon sublimation of dry ice discs on top of turbine-like surfaces, we have been able to use dry ice to power an electrical generator. Crucially, the vapour produced by the dry ice discs generates enough pressure to overcome gravity, lifting the disc off the turbine surface through the Leidenfrost effect. The discs thus become levitating rotors, meaning the engine is extremely low-friction.  You won’t find solid dry ice occurring naturally here on Earth. However satellite images from NASA’s Mars Reconnaissance Orbiter show the situation is very different on the surface of Mars where large gullies can be found, about 2 km in length. These structures are very different from Earth’s water gullies.  Instead of fanning out at their bottom end as you would expect from a gully created by water, Mars’ gullies end in a pit-shaped apron. NASA scientists have recently shown that such shapes might be caused by gliding boulders of solid dry ice, which sublimate (turn to gas) as temperatures rise in the Martian summer. Carbon dioxide thus plays a similar role on Mars to water on Earth. It is a widely available resource which undergoes cyclic phase changes under the natural Martian temperature variations. Perhaps future power stations on Mars will exploit all this CO2 to harvest the energy from the sublimation phase change as dry-ice blocks evaporate, or to channel the chemical energy extracted from other carbon-based sources, such as methane gas. One thing is certain; our future on other planets depends on our ability to adapt our knowledge to the constraints imposed by strange worlds, and to devise creative ways to exploit resources that do not naturally occur here on Earth."
nan
nan
"Europe’s Mediterranean regions have strong sunshine, bright blue seas, beautiful beaches, and pretty holiday houses immersed in pine forests that provide welcome shade. It sounds very inviting, but such a scenario is also perfect for severe wildfires such as the ones that killed 99 people this July in the popular holiday resort of Mati, in Greece. Now, new research in Nature Communications suggests that the summer fire season in Mediterranean Europe is going to get worse. Under the hottest climatic predictions of 3°C warming, the area that is currently burned every year would double. Even more worryingly, 40% more area would be burnt even if the Paris Climate Agreement is fulfilled and warming stays below “only” 1.5°C. So, time for Europeans to start looking for other holiday destinations? Hang on. Let´s look at the new study in more depth first. In this modelling exercise, a team of scientists led by Marco Turco, a fire researcher at the University of Barcelona, predict the area that would burn in future summers in Mediterranean Europe following different degrees of warming. They base their approach on the findings of a recent study from some of the same authors, which looked at Portugal, Spain, southern France, Italy and Greece, and established a direct association between the area burnt in the summer months and summer drought in recent decades (1985-2011). They use that “fire-drought” relationship to estimate the area burnt under the drought conditions forecasted in three different warming scenarios (1.5°C, 2°C and 3°C).  The climate obviously has a direct effect on fires, as hotter conditions lead to drier vegetation more susceptible to burning. But the authors also account for indirect effects such as drier conditions reducing plant growth, meaning there is less vegetation to “fuel” the fires. This “non-stationary” climate-fire modelling is important because if the indirect effects were not considered the predictions of area burnt would be even higher. So, are Turco and co-authors right? Will the future look blacker for the Mediterranean? Will tragic events, like those in Mati, become more frequent? Turco’s predictions, even if in many ways the most advanced to date, still carry a huge uncertainty, but they add to the growing list of studies that forecast more Mediterranean fire activity in future. What their study is unable to predict is the influence of perhaps the most important factor behind the future occurrence of fires, also the very same factor that is responsible for accelerated climate warming: humans.  Humans are the main source of ignition in most of the Mediterranean, and the main modifiers of vegetation cover. Including them (or us) in scientific models of fire is very challenging, and can radically change the results. For example, at the global scale, models that rely on climate change tend to predict a very substantial increase in area burnt – a hotter world means more fires, as you’d expect. But when human effects are incorporated, the estimated total area burnt can actually decrease to levels even below current ones. This is essentially because more and more land worldwide is being urbanised or converted to agriculture, resulting in smaller and more fragmented “wildland” areas that can burn. We still have plenty to worry about, however, as global averages form only a small part of the story. In some parts of the world, such as Canada and the US, the area burned is already on the increase. Meanwhile, some houses are being built further into forests and other flammable vegetation, while other houses are finding themselves now surrounded by vegetation as nearby fields are abandoned and left to nature. Both situations leave more people exposed to fires. In Mediterranean Europe the situation is particularly complex as the ongoing abandonment of traditional land uses is changing the vegetation more dramatically than climate change. Intensely grazed or cultivated land is becoming overgrown with shrubs or replaced with fire-prone forest stands, a trend that makes the landscape more flammable. This, combined with climate warming, can provide the perfect recipe for fire disasters. For example, Greece has seen less than half the area burned so far this summer than the 2008-17 average), but lots of dry vegetation for fuel, strong winds and a high population density combined to cause Greece’s deadliest fire on record. The future of fire in Mediterranean Europe ultimately depends on the decisions we make. That means complying with the Paris Climate Agreement to reduce global warming but also adapting effectively to the increased risk of fire. And this does not necessarily mean suppressing all fires, which is often not possible, but managing the fuel and how we live among it. Policies aimed at removing fire completely from the landscape have long proven to fail, even if many countries still follow them.  Instead we need to create fire-resilient landscapes and fire-resilient societies. A holiday house in the middle of a pine forest may sound idyllic, but it can be a death trap when a fire occurs, and the study by Turco and his co-authors suggests that this will be even more likely in the future."
"
Share this...FacebookTwitterHigh profile German meteorologist Donald Bäcker recently told an audience that there remains great uncertainty as to what is really behind climate change. He told the biggest problem the planet faces is waste, particularly plastic in the oceans.

Hat-tip: Hallolindenlimmer.de
Donald Bäcker regularly gives his weather forecasts on flagship German public television and spoke in an entertaining way before an open-minded and very interested audience in the Ihme Centre in Hanover.
The lecture lasted two hours and the videos posted at Hallolindenlimmer.de show the climate excerpt of it.
Plastic pollution a greater problem
The topic of climate change was emphasized in his lecture under the title: “Is our climate going crazy?” Bäcker rejected climate panic and recommended to the climate striking pupils to go back to school and learn.
His conclusion on the climate debate: “Plastic in the sea is worse”.
On climate he told the audience that it is very difficult to figure out what part man plays and what natural factors play in the complex system of climate.  At the 5:30 mark of the 32-minute video excerpt, he told that rolling back CO2 is not going to save us and that the worst problem is plastics and coping with the population growth.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Too many people living in naturally hazardous areas
Concerning natural disasters hitting populated areas, he tells the audience that it’s not climate change causing the tragedies, but rather people living in hazardous areas.
“Dangerous” to declare climate science settled
He also criticizes the climate discussion and calls the claims that the discussion is over and that CO2 is the main driver today  “dangerous”. Bäcker points out that predictions made by climate scientists in 2000 that Germany would dry out have turned out to be wrong.
At the 14-minute mark he warns that the climate model predictions are lacking in quality and that climate scientists know their predictions will be forgotten 30 to 40 years down the road. He reminds the audience how scientists warned in the 1970s of a coming ice age, which today we know never showed up.
At the 16-minute mark, Bäcker reminds the audience that renewable energies like solar are not what they are cracked up to be, saying that the production of solar modules “is very energy intensive” and more damaging to the environment than we are led to believe.
Today’s climate not unusual
When questioned about the “dramatic” situation in the Arctic, Bäcker remined that this is not an unusual situation in that people once settled in Greenland 1000 years ago and how the climate back then was warmer than it is today.
No consensus
At the 18:00 mark he sharply criticizes the notion that the science is settled and finds it disturbing that people who present alternative explanations get dismissed and labelled as nuts, and shut out by the press. He adds that there is in reality no consensus and there are scientists out there who don’t agree.
Share this...FacebookTwitter "
"The ninth circuit court of appeals ordered dismissal of a lawsuit brought by 21 youth plaintiffs against the federal government over climate crisis, citing concerns about separation of powers. The case was brought against the government in 2015, charging that it sanctioned, permitted and authorized a fossil fuel system that compromised the youth plaintiffs’ civil right to property. It implied a constitutional right to a stable climate, and alleged that the government violated the public trust by failing to protect assets held in trust, notably the atmosphere.  The plaintiffs, now all between the ages of 12 and 23, also asked the US district court of Oregon to order the government to craft a climate remediation plan, one targeting scientifically acceptable standards to stabilize the climate. On Friday, the ninth circuit court found, however, that the court lacked the power to enforce such a plan or climate policy decisions by the government and Congress, concluding “in the end, any plan is only as good as the court’s power to enforce it”. Nevertheless, the court found that the record “conclusively establishes that the federal government has long understood the risks of fossil fuel use and increasing carbon dioxide emissions” and “that the government’s contribution to climate change is not simply a result of inaction”. The court also found that the youth met the requirements for standing in the case and that some of the plaintiffs met the requirements for actual injury. Levi Draheim, a 12-year-old plaintiff from Satellite Beach, Florida, the court found was injured by repeat evacuations from his home during worsening storms. Jaime Butler, 19, was injured by displacement from her home because of water security issues, separating her from relatives in the Navajo Nation, the court also found. The court also found that the plaintiffs proved their injuries were caused by the climate crisis. Two of the three judges balked at the scope of change required to reverse climate breakdown, finding that halting certain programs would not halt the growth of carbon dioxide levels in the atmosphere or injuries to the plaintiffs. “Indeed, the plaintiffs’ experts make plain that reducing the global consequences of climate change demands much more than cessation of the government’s promotion of fossil fuels. Rather, these experts opine that such a result calls for no less than a fundamental transformation of this country’s energy system, if not that of the industrialized world … given the complexity and long-lasting nature of global climate change, the court would be required to supervise the government’s compliance with any suggested plan for many decades.” Kelsey Juliana, the 23-year-old named plaintiff in Juliana v United States and a resident of Eugene, Oregon, said she was “disappointed that these judges would find that federal courts can’t protect America’s youth, even when a constitutional right has been violated”. “Such a holding is contrary to American principles of justice that I have been taught since elementary school,” Juliana added. “This decision gives full, unfettered authority to the legislative and executive branches of government to destroy our country, because we are dealing with a crisis that puts the very existence of our nation in peril.” “We will continue this case because only the courts can help us,” Draheim told the Guardian following the ruling. “We brought this lawsuit to secure our liberties and protect our lives and our homes. Much like the civil rights cases, we firmly believe the courts can vindicate our constitutional rights and we will not stop until we get a decision that says so.” District Judge Josephine L Staton, in a lengthy dissenting opinion, argued that courts do have the authority to protect the young in the face of climate breakdown, and should, given the government’s inaction: “In these proceedings, the government accepts as fact that the United States has reached a tipping point crying out for a concerted response – yet presses ahead toward calamity. It is as if an asteroid were barreling toward Earth and the government decided to shut down our only defenses. Seeking to quash this suit, the government bluntly insists that it has the absolute and unreviewable power to destroy the nation.” The court ordered the case be remanded to the district court and dismissed."
"Almost all of us walk somewhere every day of our lives. According to the UK’s most recent National Travel Survey 22% of all trips are undertaken on foot – and walking continues to be the second-most important form of transport for all journeys after travel by car or van. For short trips of less than a mile, walking is totally dominant accounting for over 78% of all such travel. One third of all trips less than five miles in length are also on foot.  By contrast, cycling accounts for just 1.5% of all journeys. Even if we only look at all trips under five miles, cycling still makes up less than 2% of journeys.  But you wouldn’t get this impression from listening to politicians, reading policy documents, or observing investment in infrastructure. While both cycling and walking improve personal health and the environment, one gets far more attention than the other. The government has just released its response to a major consultation on its “vision for cycling and walking”, for instance. The document’s name? Cycling Delivery Plan. Although walking is given some consideration in the detail of the document, the priority is clear. While cycling is being actively promoted as a healthy and sustainable form of urban transport, walking remains largely neglected in terms of active policy and investment. Look at London’s “cycle superhighways”, for instance, announced earlier this year to much fanfare. These highways follow significant increases in trips by bike in central London following investment in new infrastructure promoted by the London mayor.  Such investment is of course welcome and long overdue, and much remains to be done as cycle infrastructure remains poor in most other parts of the country. But the fact cycling is beginning to be considered an important form of urban transport that needs to be planned for highlights the fact that travel on foot is not given such recognition. It can, of course, be argued that pedestrians do already have their own dedicated infrastructure – in urban areas at least – in the form of pavements, pedestrian zones, and crossings. For the most part we accept these conditions as adequate and do not question how they might be better, however a closer look suggests that this is rarely the case.  In most locations, road space continues to be dominated by, and planned for, motor vehicles and people on foot are crammed on to pavements that are often too narrow. Pedestrians are made to wait for long periods to cross busy roads, exposed to traffic noise and emissions, and then given insufficient time to cross before the lights change to keep the traffic moving.  Poorly placed (and often unnecessary) street furniture, together with inconsiderately (and potentially illegally) parked cars often obstruct the pavement, while pedestrian surfaces are often poorly maintained and rarely cleared of leaves or snow and ice. Try to negotiate the average urban pavement with a child’s buggy or in a wheelchair and the difficulties become all too obvious. Poor pedestrian infrastructure disadvantages all those who do not have access to, or choose not to use, a motor vehicle. We’ve got into this situation because walking is taken for granted. Such a simple activity has been largely ignored in the planning process; it is seen as making few demands on the environment and thus needs only a minimum of facilities. In contrast, because motor vehicles make much greater demands on the environment their needs have been prioritised.  Pedestrians also suffer from being classed as “walkers” – those who walk for pleasure rather than as a means of transport. The cultural dominance and convenience of the motor vehicle has meant that urban space has been disproportionately allocated towards cars and away from pedestrians. When walking for anything other than recreation is increasingly seen as abnormal, cars will always win.  I recently headed some research in four English cities which clearly demonstrated this. As one respondent in Leeds said “you feel unusual walking”. Most respondents enjoyed walking, and did walk sometimes, but they frequently encountered unnecessary difficulties and inconveniences. The problem was summarised neatly by a Lancaster respondent: “That road is awful, the pavement is very narrow, and in autumn it’s covered in leaves so you slip over half the time, it’s terrifying. But by car the road is fine”. Walking is a cheap, simple, healthy and environmentally friendly way of travelling short distances. It is something most people enjoy doing, but our cities are built in ways that often make life difficult and unpleasant for pedestrians.  Walking needs to be taken more seriously as a means of transport (and not only as a form of exercise or leisure) – and should be actively planned for and given priority, as is beginning to happen with cycling. If more people walked and fewer people drove, it would not only benefit personal health but also cities would be more pleasant for all."
"
Share this...FacebookTwitterBy Kirye
and P. Gosselin
We often hear how the climate is changing everywhere, like in California.
Listening to the media we get the impression that the Golden State is drying out and risks burning up, before heavy rains hit. Others claim the state is facing “weather whiplash” because climate change will make the weather more extreme and volatile.
Today we take a look at the precipitation data of 7 stations spread across the state to see what changes have been happening. Used here are the data from the Japan Meteorology Agency (JMA) that cover the last 33 years.

Data: JMA.
As we can see, there has been no trend over the past 30 years. Variability also appears unchanged. California has always been a state characterized by alternating periods of drought and rainfall influenced by oceanic cycles like ENSO. The data show everything is within the normal range.
The real trend is the massive increase in media climate ambulance chasing where every anomaly gets hyped into something much more than it really is.
Share this...FacebookTwitter "
"The native peoples of Loreto, in Peru’s Amazon basin, have just ended a month long occupation of 14 oil wells belonging to the Argentine company Pluspetrol. Negotiations are still underway between the oil company and various other communities, represented by the indigenous association Feconaco. This is not the first time Feconaco has occupied Pluspetrol’s operations. Such actions on the part of indigenous groups are relatively common. Amazonian people don’t appear to have learned direct action from the occupy movement or from Euro-American protest traditions, despite the similar tactics. In the absence of functioning state protection, native people have always had to stand up for themselves.  Last September, for instance, Ka'apor people of northeastern Maranhão in Brazil published photographs of illegal loggers whom they had captured and tied up. They had taken matters into their own hands because the state was not protecting their territory. The pioneers of indigenous direct action were the Kayapó of southern Pará in Brazil, who began monitoring goldmining and later logging in their territory, which senior leaders tolerated and indeed profited from. In the early 1990s, environmental destruction and mercury poisoning led many Kayapó people to support a younger generation of leaders who expelled the miners and loggers from their territory. Images of the Kayapó have since become synonymous with indigenous environmentalism. The relative success of direct action in recent decades contrasts with the often bloody encounters that went before, from which poorly-armed Indians invariably emerged badly.  Indigenous people in the Amazon have been the victims of the mining and energy industries for hundreds of years. The earliest colonists were motivated by greed for gold, and successive waves of exploitation have followed. The violent and coercive labour relations of the rubber boom (which ended a century ago) continue to affect how local people view trade and outsiders. Fur hunters would shoot native people on sight throughout much of the 20th century. A good friend of mine, one of my principal informants in the field, fled Brazil as a child after his family were killed by fur hunters, and came to live with another tribe in the border area between French Guiana and Suriname. Here, and across the Guiana region (the vast area of northeastern Amazonia bordered by the rivers Negro, Orinoco and the lower Amazon), mining for gold, diamonds and other minerals has led to significant social conflicts. The region’s small communities are held together by personal ties of kinship and are highly dependent upon local ecosystems for their livelihoods. This makes them particularly vulnerable to the side-effects of extractive industries such as environmental destruction and pollution of rivers and lakes. But there are also social and medical effects: prostitution, alcoholism, drug addiction and the introduction of new diseases such as HIV. Mining and oil companies generally earn a bad reputation for their Amazon activities, but projects devised in the name of “sustainability” can have a negative impact too. Think in particular of the programme of hydroelectric dams being rolled out across Brazil. Belo Monte, the world’s fourth largest hydroelectric dam, is being built across a southern tributary of the Amazon, for instance. It has already caused the influx of tens of thousands of workers, with severe strain on local social relations. Its impact on a vast ecosystem – a major hydrological basin – will be monumental.  Protests against the Belo Monte dam have failed, as a Brazilian government focused on development ploughed on with its project which is, after all, consistent with the political rhetoric of the “green economy”. Indigenous people are a small section of the electorate, and their voice cuts little sway in the national political scene.  Protests against international private companies can arguably be more effective, in so far as the directors of these companies consider a poor public image to significantly affect their profits. A legal battle raging for nearly two decades between indigenous peoples in Ecuador and the energy giant Chevron, contributed to the corporation earning the title of a Lifetime Award for Shameful Corporate Behaviour by grassroots satirists in Davos earlier this year. Yet the corporate social responsibility activities which result from such pressures all too often seem to be largely cosmetic. Where direct action has succeeded it is largely thanks to the construction of new kinds of alliances between indigenous leaders, progressive and socially oriented NGOs, and independent activists, including some academics. Indigenous people in the Amazon basin have gradually, over the centuries, become more adept at getting organised and speaking the language of power. They’re now a key part of a global indigenous peoples’ movement which can call on an increasing number of activists with training in international law, documentary film making, or indeed anthropology, to assist campaigning efforts. On a smaller scale, communities regularly engage with different projects brought by outsiders, including the “partnerships” proposed by extractive industries.  However, they just as often come to regret their entrance into the relationship. Indigenous people come to realise that their understandings of fair exchanges are not the same, and sometimes not even compatible with those of their interlocutors, whether they be loggers, miners, or people looking for more intangible wealth such as traditional designs, music or ecological knowledge. These experiences show that the conflicts that sometimes arise between native people and outsiders seeking to extract natural resources are not merely conflicts of material interests, and are not structured merely by an imbalance of power. They are on a more fundamental level conflicts of worldviews, of cosmovisiones, as Afro-Colombians sometimes call them.  Indigenous people have made vast efforts to speak across the gap between themselves and others who live and move in the capitalist world. The onus is now on outsiders, including postcolonial states and transnational organisations, to make a corresponding effort."
"SpongeBob SquarePants, perhaps the world’s most famous sponge, is the star of his own cartoon show set in the ocean-floor city of “Bikini Bottom”. In the real world, however, sponges are often perceived as playing only a supporting role to the real reef stars: corals. But new research, published in PeerJ, has once again highlighted sponge-power. These squishy creatures, it is feared, might take over coral reefs if not kept in check by sponge-eating fishes – and overfishing is removing their natural predators. A team of researchers from the University of North Carolina assessed coral reefs in 12 Caribbean countries. They compared sites where fish stocks are depleted due to intensive fishing with more protected sites where fish still exist in greater numbers. Twice as many coral colonies were found in contact with sponges at the overfished sites.  This matters because sponges have been shown to have the potential to kill corals, and corals are among the key organisms in any reef. Their calcium carbonate skeletons lay the foundation of precious and immensely complex ecosystems on which about a third of all marine species depend on. So any threat should be taken very seriously. Increased exposure to often toxic sponges raises concerns that sponges might be able to out-compete corals.  Many sponges contain a complex cocktail of toxic and distasteful compounds, chemical weapons accumulated to defend themselves from being eaten or overgrown by other organisms. This makes them interesting sources for potential new drugs. But in the absence of predators, it appears this arsenal can be also used in an offensive manner against corals to prepare the ground for their own expansion.  Sponges usually adopt a hidden lifestyle underneath boulders and in a reef’s cracks and crevices, at least partly to avoid predators such as parrotfish and angelfish. In fact, previous research using the same endoscopic techniques surgeons use to look inside human bodies demonstrated that the majority of sponge biomass lives not on top of a reef but within it. Apart from these species that make use of existing hollows, the not so dull “boring sponges” even produce acids 
to drill themselves a home.  They aren’t too worried about where they set up their residence, as long as it consists of chalky material. Boring sponges can therefore be not only found in limestone rock but also in various types of animal and plant shells and skeletons, including those of live and dead corals. This is of critical concern since it renders the coral colonies more fragile and vulnerable to damage by strong waves.  There are exceptions to the rule of course, and a number of sponge species form erect structures on the seabed. One of these, the majestic barrel sponge, can grow to a diameter of nearly two metres and can live for up to 2,000 years. Sponges play a vital role in the functioning of coral reef ecosystems. They can filter large quantities of water through their many pores and then squirt it through their bodies, removing tiny plankton creatures and organic compounds for food. It is this porousness which gives sponges the natural and much-appreciated ability to retain large amounts of liquid for cleaning purposes. The waste products of the sponge diet contain nitrogen and phosphorus compounds, which are dearly needed by the bacterial and plant life of the usually nutrient-deprived reefs. Sponges have also found another way of ridding themselves of their waste: by rapidly replicating cells and shedding them in large numbers. These cells are either eaten by other organisms or decompose, again, releasing valuable nitrogen and phosphorous.  Through these mechanisms sponges can supply nutrients that might otherwise not be accessible to the reef creatures or would be lost to the oceans surrounding the reefs. This nutrient cycle has been termed “sponge loop” and helps to explain the Darwin Paradox – the puzzling observation, first noted by the man himself, that coral reefs form these amazingly productive oases in the midst of a nutrient-poor ocean desert. You can have too much of a good thing, however. Excess nutrients introduced in coral reefs through fertilisers, sewage dumping or stirring-up of sediments have the potential to severely disturb their vulnerable ecological balance. Apart from rendering corals more susceptible to bleaching, more nutrients stimulate the production of plankton thereby increasing the availability of food for sponges.  As a consequence, corals may suffer from destabilisation of their skeletons or the reef framework due to boring sponges or potentially increased competition for space, in particular if the affected reefs are overfished.  In the Caribbean, coral cover – the proportion of reef that is live coral rather than sponge or algae – has declined dramatically from more than 50% in the 1970s to around 10% today. Overfishing and die-outs of herbivores, eutrophication and pollution, invasive species, diseases and climate change have taken a heavy toll on these once flourishing reefs.  Despite the differences in sponge-coral contacts reported in the latest study, the coral cover at these overfished and less fished sites hasn’t differed substantially. The battle between sponges and corals is only just unfolding. It is awful to see coral in such a bad state – after all who doesn’t love the image of a pristine, colourful reef, full of amazing fish? – but sponges aren’t the real villains of this recent reef drama. As overfishing has removed many of their natural enemies it appears sponges have been handed an unfair edge over the corals. Once again, fingers point in the direction of us humans."
"
Share this...FacebookTwitterTwo more new papers add to the voluminous paleoclimate evidence that most of the last 10,000 years were much warmer than modern. 
The globe was about 4 to 6°C warmer than it is today between 9000 and 6000 years ago, when CO2 concentrations centered around 265 ppm.

Image Source: ScienceDaily.com
Some regions exceeded the 4 to 6°C global average.
Northeastern China, for example, has been determined to have been between 7-10°C warmer than today during the Early Holocene (Liu et al., 2019, Zheng et al., 2018, Peterse et al., 2014, Jia et al., 2013, Gao et al., 2012).
New paleoclimate evidence even suggests  the 19th century may even have been ~1.7°C warmer on average than the 20th century in this region (Jiang et al., 2019).
Of course, none of these temperature values are consistent with the claim that the Earth’s surface temperatures are significantly determined by changes in atmospheric CO2 concentrations.


Image Source: Liu et al., 2019


Image Source: Zheng et al., 2018



Image Source: Jiang et al., 2019
Share this...FacebookTwitter "
"The Trump administration wants to make it easier for the oil and gas sector to release methane into the air, according to a report in the New York Times. As atmospheric scientists, we are well aware of the dangers this poses for both global climate change and more localised air pollution. Methane is already the second most abundant greenhouse gas that is released from human activities. “Natural gas”, for instance, refers to a mixture dominated by methane. It has become steadily more concentrated in the air since the 18th century, more than doubling from around 750 parts per billion (ppb) to more than 1,850 ppb today. Like carbon dioxide, methane absorbs infrared radiation and warms the atmosphere. Although there is much less methane in the air than CO₂, the strength of that absorption is such that per molecule it is around 25-30 times more potent as a greenhouse gas. It is a complicated gas to predict and manage since it is released from multiple sources. Some are natural processes, such as emissions from wetlands and bogs, methane that bubbles up through the ocean, or even through termite farts. But many different human activities also result in methane being released. Flooded rice paddies produce lots of methane, as do cow and sheep stomachs, while the gas is also released from waste buried in landfills.  The largest anthropogenic source of methane, however, is the extraction and distribution of natural gas. According to the New York Times report, the US Environmental Protection Agency is set to relax a series of rules on methane emissions currently imposed on the US oil and gas industry, including a reduced frequency in checking for leaks and an extended grace period before repairs must be made. Such changes would add to a recent repeal of Obama-era US rules that required waste gas to be captured rather than vented or burned. This comes at a time when America’s methane consumption is increasing, largely because the amount of natural gas (often from fracking) burnt to generate electricity nearly doubled between 2005 and 2015. Global demand also continues to climb while oil and coal consumption have fallen over the past decade. Quantifying emissions of methane from the US oil and gas sector has been a topic of considerable research. Oil and gas producers and distributors make estimates of their emissions based on complex calculations that account for amounts lost during activities such as drilling, venting and flaring, plus any gas that seeps out from the millions of joints, pipes and connectors that make up the natural gas network. These estimates are then supplemented by in-field tests, spot-checking and monitoring for emissions near the source.  Scientists have also measured plumes of natural gas as they waft away from oil and gas installations using aircraft, and have detected methane over large areas from satellites. In general, these sorts of research methods have shown more methane is being emitted than industry-reported figures. Recent increases in emissions arising from US natural gas extraction have been detected far from their sources, inferred from trends in other trace gases. Natural gas is not pure methane – it also contains small amounts of other hydrocarbons, such as ethane or propane. However, unlike methane, these gases have relatively few other anthropogenic sources, so act as excellent tracers of methane from the fossil fuel industry. Observatories as remote as Cape Verde in the tropical North Atlantic or the Jungfraujoch high in the Swiss alps detected an upwards trends in ethane that coincided with the US fracked gas boom, a smoking gun that showed US emissions of methane were growing. Methane and the other hydrocarbons in natural gas, like ethane and propane, also create ozone pollution in the lower atmosphere when mixed with nitrogen oxides from combustion. Ozone harms people by causing the muscles in the airways to constrict, aggravating lung diseases such as asthma, emphysema and chronic bronchitis. It also limits plant growth and reduces crop yields.   High summertime ozone pollution events are an established phenomenon in southern US oil and gas producing regions, but they are now also found during winter in fracking locations in more northern states. While the current proposal for scaling back regulation of methane emissions has been framed, at least for now, as a roll-back of Obama-era climate policy, it has the potential to also increase concentrations of short-lived air pollutants as well.  The US has extensive regulations to control surface ozone pollution at national and state level. This pollution, particularly in national parks, has historically been taken seriously. Any change in industrial policy that may increase the overall amount of natural gas released to air has the potential to lead to degradation in ozone air quality, both in the US and in regions downwind. The extent of the effects could only be calculated using complex atmospheric simulations, but if shown to be significant, any legal challenge to such a change could well be based on likely air quality effects rather than climate change."
nan
"A double bill of plays that premiered 10 years ago and were hailed as the first big theatre productions to tackle the climate crisis head-on are to be updated and revived. The Donmar Warehouse and Theatr Clwyd are to stage Steve Waters’ The Contingency Plan, a pair of plays first performed at the tiny Bush Theatre in west London in 2009.  In his review, the Guardian’s Michael Billington called them an urgent wake-up call, presenting the issues in compelling human terms. He wrote: “We have waited a long time for a play that dealt comprehensively with climate change. Steve Waters has generously provided two.” They were directed by Michael Longhurst and Tamara Harvey, now in charge of the Donmar and Theatr Clwyd respectively and both keen for them to be seen by a wider audience. Longhurst said it felt at the time “that we were breaking through with something, that it was a major piece of work … an epic pair of plays that were really putting the subject on the agenda in an exciting and engaging theatrical form – and doing that possibly for for the first time. I think the credibility of those plays has stood up since.” They have asked Waters to update the works, looking at the science and political context. One of the plays, On the Beach, features a glaciologist who has been studying an iceberg called Pine Island that was then melting swiftly. “It’s gone now, it’s just gone,” Longhurst said. Both theatres will also work with Julie’s Bicycle, a nonprofit organisation that works within the creative industries, to ensure the coproduction is made sustainably. The revival was announced as part of Longhurst’s second season as artistic director of the Donmar. Other productions include Suzan-Lori Parks’ In the Blood and the world premiere of an adaptation by Tim Price of Ruben Östlund’s film Force Majeure, which features skiing and an avalanche. “It feels utterly impossible to put on the stage but that became the appeal of it,” said Longhurst, who will direct. “Ultimately it is a close-up, forensic look at a marriage imploding and it will be brilliant.”"
"
Share this...FacebookTwitterBy Kirye
NASA GISS likes to go back in history and alter the temperature figures from recorded datasets from all around the world, and then declare global warming.
Yet when we examine the (real) unadjusted, unaltered data, we find an entirely different story: In many places there has been little or even no warming over the recent decades. Many locations have seen cooling, in fact.
For example, using the data from the Japan Meteorology Agency (JMA), I checked 12 France stations which have August temperature data going back to 1982. Seven of 12 stations show August temperatures there have not warmed since 1990!

France August temperatures haven’t risen in almost 3 decades. Data source: JMA.
Looking at the 6 stations that have complete data going back to 1996 in the Scandinavian country of Finland, we also see the same story for August:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Three of 6 Finland stations have seen a cooling trend for August since 1996. The warming at the other three are statistically insignificant. Data source: JMA.
In neighboring Sweden we also find 6 stations for which the JMA has almost complete data going back over 2 decades:

Six stations in Sweden show a cooling trend for August since 1995. Data: JMA
These show no warming as well.
So when we look at the untampered data at stations in Europe, we find that there has not been any warming over the past recent decades. The story is the same at many stations scattered around the globe.
NASA GISS claims that warming has occurred because it simply changed the data to make it appear that way. Real data tell a different story.
Share this...FacebookTwitter "
"If you were to visit the English countryside 15 years ago, you would have found nine times as many small farms as you do today – and twice as many different farms in general.   For years, farmers across the UK have received subsidies on a per-hectare basis without any requirement to use that land to actually produce food as part of the European Common Agricultural Policy. This means that wealthy owners of large estates have been given large sums of taxpayer money simply for owning land, without necessarily farming it. It’s a system that has long been criticised – and rightly so. With Brexit looming, the UK government’s Department for Environment, Farming and Rural Affairs (Defra) has recently introduced an Agriculture Bill and draft policies. It proposes paying landowners for delivering environmental benefits such as improved air quality or habitats for wildlife, an approach that has been understandably praised by environmental groups.   But, while this all sounds rather green, there is little evidence that the government will support, let alone require, farms to integrate ecology with food production. It appears that landowners will receive support for either increasing productivity, or improving the environment – but not necessarily both at the same time. This either-or approach could usher in a new era of environmentally destructive “megafarms”. There has been a rapid increase in the number of these farms in recent years – for both animals and crops. Britain’s first intensive poultry farm was approved in 2003 – and there are now more than 1,400 permits for these operations, the largest of which can “process” more than a million chickens per week. Similarly, the number of high-intensity horticulture operations is increasing, with government grants supporting efforts to produce vegetables without soil. Megafarms have been responsible for pollution to rivers and waterways. Animals are often fed with imported corn and soya, the majority of which is genetically modified to withstand high doses of the controversial herbicide glyphosate. Industrial-scale horticulture operations tend to rely on imported minerals for plant feed, use significant amounts of energy for heating and produce a low diversity of crops. Research shows that conservation areas cannot make up for the environmental damage of intensive farms. Even if megafarms were interspersed within vast landscapes of parks and woodlands, it still wouldn’t help. But given the government’s intention to improve the environment, why would this happen? As area-based payments are phased out, Defra expects that many farmers will leave the sector. The assumption is that as farmers exit, land will be freed up for new entrants. But across the UK farm land is now seen as a safe shelter for wealth – recommended by estate agents as a “tax-efficient” investment. This contributes to the high and rising cost of land, arguably more than land-based subsidies. Without addressing this, it is likely that, as farmers leave, land will be bought by investors and by large farm businesses, continuing the current trend of consolidation and rising farmland prices. Young farmers and other new entrants might be desperately needed to reverse the UK’s declining farming population, but they will continue to struggle to get hold of land. One of the main reasons why megafarms have become popular and smaller farms have gone under is because farms only receive a small fraction of the retail value of food. Combined with low agricultural commodity prices, it is nearly impossible for farmers to earn a living from the food they produce. The Agriculture Bill does propose some new powers to collect data about the supply chain, a move which should mean more transparency but which is unlikely to result in farmers receiving significantly more money. If landowners are paid for protecting the environment, but receive little for food production, there is a good chance that farm land will be used for conservation, not farming. Until the UK can restructure its supply chains, it needs to keep supporting farmers to produce food. The alternative is for the country to increase its already high reliance on imports – but research has shown this could undermine food security and safety. To improve productivity, Defra has emphasised automation, drones and “precision farming” in its consultation paper. Yet these technologies favour uniformity and are best suited to high-intensity, large-scale farms that focus on producing one or two foods and use lots of resources. Low-tech practices such as growing different crops in the same space (poly-cropping) or agroforestry can increase yields of diverse foods and regenerate soil, all while minimising harmful inputs. This could help support existing farms which have struggled with long-term soil deterioration and feel “locked-in” to using certain agro-chemicals. But these approaches are knowledge-intensive and take time to implement. Without support for them it is likely that farmers will continue to either leave the business or intensify. The shift towards megafarms is not inevitable or necessary. Defra has included some measures to support ecological and human-scale farming, such as a nod towards reducing pesticide use, and a support for County Farms which can help new entrants. However, much more is needed to ensure that farming and the environment are truly integrated."
"
Share this...FacebookTwitterA significant number of scientists say that the Earth’s climate is in large part impacted by solar activity, and less so by trace gas CO2 concentration. German scientists present new findings showing a link between solar activity and precipitation in Europe.
=================================================
How Changes on the Sun Influences Rain
A balanced level of precipitation provides the basis for a wide range of economic and social activities in Europe. Particularly agriculture, drinking water supply and inland waterway transport are directly affected. However, the amount of rain fluctuates strongly from year to year. While it may pour torrentially in one year, rain may remain absent for weeks in other year. The population is used to this variability and usually knows how to deal with it.
But what is behind the strong changes? A system, or pure atmospheric noise?
The chance discovery by an agricultural scientist from Münster, Germany, now suggests that in certain months that rain over Germany and other parts of Europe follows a pattern that up to now has remained undetected. As part of agricultural consultation, Ludger Laurenz analyzed decades of rainfall records of the weather station in Münster and noticed a constant up and down that followed an 11-year rhythm – especially in February.

Fig. 1. February precipitation in Germany compared to changes in sunspots. Shown is the optimum positive correlation (r = 0.54) with a solar lag of +17 months. Solar cycles are numbered 14–24. The probability that the correlation r = 0.54 is by chance is less than 0.1% (p < 0.001). Source: Science Direct.com. 
After detailed examination it was clear that this rhythm correlated closely with the activity of the sun: the well-documented 11-year sunspot cycle.
Europe data examined
Laurenz next teamed up with two colleagues to examine the extent to which the observed pattern from Münster is reproducible in other parts of Germany and Europe, and whether the phenomenon also exists for the other months of the year. Horst-Joachim Lüdecke from the HTW University of Applied Sciences in Saarland gathered the precipitation data collected in Europe since the beginning of the 20th century. The physicist emeritus then developed a computer algorithm to determine the similarity of changes in rainfall and solar activity. All 39 European countries and every one of the 12 months of the year were quantified over a total of 115 years using mathematical correlations.

Fig. 3. Map showing the 1901–2015 most positive correlation coefficients for February precipitation and sunspots on a country-by-country basis. Pearson r values from Table 1. All maps: Lags are simplified and generally fall within ±10 months of the statistically calculated value (Table S1). Source: Science Direct.com. 
In order to include possible delay effects, the data series of rain and sunspots were systematically checked for shifts. For this purpose, the time series were gradually shifted in time against each other like combs and the respective change of the correlation measure was noted. The multidimensional data obtained in this way were evaluated for systematic trends by geoscientist Sebastian Lüning and visualized cartographically. Lüning is associated with the Swiss Institute of Hydrography, Geoecology and Climate Sciences (IFHGK) and is specialized in the research of solar climate effects.
February northern Europe precipitation linked to solar activity
The mapped out results show that the link between February precipitation and solar activity originally discovered in Münster is valid for large parts of Central and Northern Europe and has very high statistical significance there. Towards southern Europe, however, the correlation weakens significantly.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




4-year shift for February Central Europe precipitation
The statistical investigation was also able to demonstrate systematic phase shifts across the continent. In Germany and neighboring countries, February precipitation was particularly low when the sun was very strong four years earlier. The delay seems to be due to the slow deep circulation of the Atlantic, as earlier work suggests. On the basis of the statistically-empirically determined correlation, February 2018 in Germany with particularly low precipitation can now also be explained, which followed a particularly high intensity peak of solar activity at the beginning of 2014.
Solar signal found in other months
Similar relationships between rainfall and solar activity have been observed in a weakened way in some other months, especially in April, June and July, which account for a large part of the vegetation period in Central Europe. The result was a complex picture of the interplay of sun and rain in Europe, which showed clear trends over 1000 km and varied strongly from month to month.
Mechanism remains unclear
The study thus confirms the concept of a solar participation in the European hydroclimatic development, which had already been indicated by a whole series of local case studies of other authors. However, the exact mechanism by which the solar signal influences precipitation is still largely unclear and requires further research.
Ocean cycles also at play
The solar precipitation effect, which has now been mapped out across Europe for the first time, opens up new possibilities for improved medium-term precipitation forecasts. Agriculture in particular, but also for defense against extreme weather damage in connection with heavy rainfall and droughts, could benefit from this.
The next step in refining the forecasting methodology is a more precise quantification of the effects of Atlantic Ocean cycles, which also play an important role in rainfall, especially in Western Europe.
Original publication:
Laurenz, L., H.-J. Lüdecke, S. Lüning (2019): Influence of solar activity on European rainfall. J. Atmospheric and Solar-Terrestrial Physics, 185: 29-42, doi: 10.1016/j.jastp.2019.01.012
The pdf version can be downloaded free of charge at the following link until early March: https://authors.elsevier.com/a/1YXWZ4sIlkiVhv
Contact:
Prof. Dr. Horst-Joachim Lüdecke
Hochschule HTW des Saarlandes
moluedecke@t-online.de
Dr. habil. Sebastian Lüning
Institut für Hydrographie, Geoökologie und Klimawissenschaften (IFHGK), www.ifhgk.org
luening@ifhgk.org
Tel. 00351-961470494
Share this...FacebookTwitter "
"Jane Shepherdson was once named the most powerful woman in British fashion. As the boss of Topshop when it ruled the high street and delivered £100m in profit a year for Philip Green’s Arcadia retail empire, she was the high priestess of fast fashion. But times have changed: Shepherdson now wants us to ditch the shopping bags and get our style fix by renting everything from dresses to sunglasses and shoes instead. Shepherdson, who revamped the Whistles fashion chain after leaving Topshop in 2006, is now chair of My Wardrobe HQ, a designer fashion rental and resale website, which next month opens a pop-up in London department store Liberty. The tie-up is part of an emerging trend for secondhand and rented clothing which is becoming not only acceptable but desirable. Liberty claims to be the first UK department store to host a peer-to-peer fashion rental pop-up, following a partnership between Nordstrum and Rent the Runway in the US. But the idea is in the same vein as Selfridges hosting pop-ups by fast-growing vintage vendors Depop and Vestiaire Collective and online designer store Farfetch testing Second Life, a handbag resale service. “People are becoming more comfortable with wearing things other people have worn and not necessarily seeing it as second rate,” says Shepherdson. Concerns about the environmental impact of fashion, which contributes more to climate change than the aviation and shipping industries combined, are expected to drive a boom in rentals. The UK market is expected to grow more than fivefold to £2.3bn by 2029 from an estimated £400m last year, according to analysts GlobalData. Peer-to-peer lenders such as My Wardrobe HQ and Hurr, where those with an over-stuffed wardrobe rent out items to those on a budget, are expected to lead the way, outstripping traditional players such as Moss Bros or newer online platforms such as Girl Meets Dress or Hire Street. On My Wardrobe HQ at present, fashion lovers might choose a floral satin dress from The Vampire’s Wife label for £110, a Gucci military coat for £295, a pair of Michael Kors biker boots for £40 or a Herve Leger sequinned bodycon mini for £215. All rentals last a week and customers who fall in the love with their items can buy them outright. Shepherdson says she got into the idea of peer-to-peer rental after taking nearly a year off living out of Airbnb homes in the US after quitting Whistles in 2016. “I came back at the moment when it was suddenly becoming more and more apparent about what a massive polluter fashion is. I thought I’ve filled all my life with making fashion more compelling and there’s some massive back-peddling required.” “I thought about peer-to-peer renting and why couldn’t it be exactly like Airbnb, where people could attract each other and buy into someone’s lifestyle. “I’m not a hypocrite. I want people to enjoy fashion. Rental is a totally guilt-free way to wear the most beautiful dress and it’s not out of reach for people.” A £1,000 dress might rent for £100, which is not exactly cheap, but accessible to anyone who can afford a big night out with cocktails, dinner and a cab home, she says. Shepherdson began by trying to start her own site but then met Sacha Newall and Tina Lake, who founded My Wardrobe HQ in June 2018, combining their experience in online fashion, car sharing, online marketplaces and women’s magazines: “It felt like a business that could scale.” My Wardrobe HQ works by managing the whole rental process, including photography, delivery, cleaning and payment, for its clients. About half the items on offer come from individuals, half from brands.  Shepherdson says she is now in discussions with brands about producing collections specifically for rental. “Why not? It’s obviously a change but it’s just sharing a bit more, making sure you get away from that thing of buying something, wearing it once and moving on.” She says the idea is particularly appropriate for luxury womenswear. Ski-wear, occasion wear, maternity clothing and childrenswear are other areas Shepherdson thinks are ripe for rental. While Shepherdson says it’s unlikely she’ll go back to leading a fashion chain unless it’s one with strong sustainability credentials, she rues the troubles at Topshop and its fellow fast-fashion chains, particularly the loss of good jobs for young women. “It’s sad but there is a certain inevitability to it. Everything has changed, the whole approach to shopping. If you look at the retailers having a difficult time, most are based on bricks and mortar shops. “I still love going shopping but you have to create theatre, something worth coming in for, to get people off the sofa.”"
"
Share this...FacebookTwitterWhat follows is another example of the tricks the mainstream media use to produce fake drama and urgency concerning sea level rise and climate change – namely omissions – and how geologist Sebastian Lüning held their feet to the fire.

Geologist Dr. Sebastian Lüning puts German ARD broadcasting’s feet to the climate fire. Photo. Die kalte Sonne.
Dr. Sebastian Lüning wrote a complaint to German ARD public broadcasting concerning its December 2, 2018, one-sided reporting of the Indian island of Ghoramara and the sea level rise it is allegedly experiencing. The €6.9 billion euro publicly funded, 22,612-employee ARD is the German equivalent to the UK’s BBC.
What follows is the exchange between Lüning and the ARD editorial staff:
======================================
From: Dr. Sebastian Lüning
To: NDR Rundfunkrat
Date: 3 December 2018
Dear Ladies and Gentlemen,
On December 2, 2018, you reported on the Tagesschau.de evening news on the Indian island of Ghoramara, which according to your report is “sinking into the sea” due to climate change.
https://www.tagesschau.de/ausland/indien-klima-ghoramara-101.html
In concrete terms, the report cites rising sea levels as the only cause. This, however, distorts the facts, as the shrinking of the island actually has a number of reasons. Although the globally rising sea level plays a role, other processes are much more important, which your correspondent Bernd Musch-Borowska fails to mention a single word about and thus ultimately over-dramatizes the role of climate change. This is all the more regrettable because the report appeared on the first day of the Katowice Climate Conference and thus casts the technical robustness of your reporting in to doubt.
In view of the enormous importance of climate change in the public debate, you should make additional efforts to avoid such one-sided and technically unbalanced presentations in your program, e.g. by consulting experts before publication.
The island of Ghoramara lies at the mouth of the Ganges. As in many deltas of the earth, strong currents prevail here, which lead to a constant rearrangement of sediment and a systematic shifting of the islands. Similar coastal dynamic processes can be observed in the area of the East Frisian Islands.
The island of Ghoramara and neighboring islands in the Sundarbans have therefore always been exposed to major morphological changes. In addition, there is a rate of subsidence of several millimeters per year, which is also typical for deltas, an amount which even exceeds the global (eustatic) sea-level rise of 2-3 millimeters per year. In addition, the construction of several dams in the catchment area of the Ganges has led to a reduced sediment load in the river and delta, further exacerbating erosion.
Also activities on the island of Ghoramara have made the problem worse. Strong groundwater removal has led to an additional compaction and lowering of the island. In addition, the islanders have removed part of the protective mangrove vegetation in the process of creating additional arable land, leaving the soil vulnerable to erosion during storms.
If you are interested, I would be happy to provide you with the relevant technical literature.
The Tagesschau article falsely suggests that sea-level rise is the main problem for Ghoramara. This is wrong. What is true is that the shrinking of the island of Ghoramara has a variety of causes, which can be divided into 1) natural, 2) non-climatic anthropogenic and 3) climatic anthropogenic causes. I would therefore like to ask you – at the same place as the original report – to list the complete range of causes so as not to provide a basis for accusations of climate dramatization on the occasion of the current climate conference in Katowice.
Best regards,
Dr. habil. Sebastian Lüning
Geoscientist
But the editor-in-chief of ARD, Dr. Kai Gniffke, finally replied evasively on January 4, 2019. The pdf of the reply can be found here. In the reply, the ARD defended its report, writing: “Unfortunately it is not possible to address all backgrounds and developments in daily reporting.”
To which Lüning responded:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




From: Dr. Sebastian Lüning
To: NDR Broadcasting Council [ARD]
Date: 10 January 2019
Dear Dr. Nenz,
Dear Dr. Gniffke,
Thank you for sending the statement. Of course, the answer is not satisfactory, because you reply to my accusation of selective and distorted reporting by claiming that the climate conference and the scarcity of the reporting justify the deliberate omission of important contextual information. The incomplete presentation, however, automatically leads to an artificial dramatization. Ultimately, it is deliberate cherry-picking.
The editorial team is thus in the same line as the former editor of the Süddeutsche Zeitung, Christopher Schrader, who in your program ZAPP openly admitted that in his articles he follows a personal mission and prefers to leave scientific uncertainties unmentioned in order to prevent citizens from becoming unrestful and doubting the energy revolution.
https://www.ndr.de/fernsehen/sendungen/zapp/Von-wegen-Klima-Wissenschaftsjournalisten-wettern,klima302.html
I was also surprised that another mistake had crept into your answer. You wrote that there are “more violent and more frequent storms” in the area of the Indian island of Ghoramara due to climate change. This is also wrong, especially as it is not even claimed in your original article. Studies in the northern Indian Ocean have not found a trend in tropical cyclones for the last three decades. See Hoarau et al. 2012:
https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/joc.2406
It would be really important that you introduce quality assurance measures in your ARD editorial office in the area of climate change reporting in order to avoid such obvious mistakes and distortions. As you may know, this is not the first case. As an example, I would like to mention your reporting on the warming of the North Sea in 2017:
http://www.kaltesonne.de/um-antwort-wird-gebeten-der-fall-nordsee-erwarmung/
For the sake of transparency, I would also like to ask you to allow us to publish your Ghoramara statement on the website www.kaltesonne.de.
Yours sincerely,
Dr. habil. Sebastian Lüning
Again the ARD editors followed by dodging the facts of their poor reporting in a response to Lüning’s message above, even going so far as to deny everything. What follows is their response to Lünings accusations:
From: Dr. Kai Gniffke (Editor-in-Chief ARD-aktuell)
To: Dr. Sebastian Lüning
Date: 25 January 2019
Dear Dr. Lüning,
We regret that our detailed response to your program complaint was not satisfactory from your point of view. As we have already stated in the opinion, we believe that the situation of Ghoramara has been accurately described in the criticized report. In principle, not all aspects of a complex issue can be presented in a single contribution. We understand your comments as a suggestion and have already written that an in-depth consideration, for example in the context of a longer radio feature, is conceivable.
In your reply, you also mentioned our report on the warming of the North Sea in 2017, which you also criticized. We refer you to our corresponding statement, which you had already published on your website. You are also welcome to publish our most recent statement there.
We thank you for your comments and assure you that we will continue to report on climate change and its impacts.
Yours sincerely,
Dr. Kai Gniffke
First Editor-in-Chief ARD-aktuell
Clearly the ARD’s reporting was sloppy and intentionally one-sided with the aim of generating climate urgency. And the reactions by its editors told us us they had no plans to change anything with regards to quality control and its obligations to viewers.
But today, months later, Die kalte Sonne here informs that ARD editor Kai Gniffke has left the ARD. But don’t expect the quality of climate science reporting to improve at ARD any time soon.
Share this...FacebookTwitter "
"Richard Nixon was in the White House, Mao Zedong was running China and Ted Heath was the prime minister of the UK when hand-picked members of the global business, academic and policymaking elite were first invited to a get-together in the Swiss resort of Davos in 1971. This year marks the 50th Davos but there is not exactly a party mood. The World Economic Forum, the body that organises the annual talkfest in the snow, is “committed to improving the state of the world” but in key respects things look worse today than they did at the start of the 70s. Not in every way, obviously. The percentage of the world’s population living in abject poverty has come down sharply, largely because of rapid growth in China and India. The gap between rich and poor within countries has increased over the past five decades but inequality is not the same as destitution. Living standards have risen, whether measured by incomes per head, life expectancy or technical progress. There were no smartphones in 1971 and nor was there an inkling that they would be manufactured in the economic superpower that China has become. Under Mao, China was essentially a peasant economy and the reforms that led to industrialisation and the migration from the country to the cities were still some way off. Nobody had the slightest interest in China’s growth rate or its trade policy. A small group of developed countries – led by the US – accounted for the lion’s share of global GDP and called all the shots. That is no longer the case. By the early 70s, the long period of post second world war growth was coming to an end. The Bretton Woods currency system, held together by the link between the US dollar and gold, would collapse in 1971 as a result of the inflationary strains on the American economy caused by the cost of the Vietnam war and higher domestic spending. The mood music does not seem to have changed all that much. The 2020 Davos takes place amid concern that a crisis is looming. It is more than a decade since the end of the financial crisis of 2007-09 but the recovery has been tepid. Wage growth, investment growth and productivity growth have all been poor. Financial markets look dangerously overvalued. So why is the current state of affairs more troubling than it was in 1971? Well, for a start there seemed a simple – if harsh – way out of the economic problems associated with the end of Bretton Woods. Inflation, according to economists such as Milton Friedman, was caused by profligate governments printing too much money to pay for excessive wage settlements and public spending pledges. The answer was to reduce budget deficits, to rein in the power of organised labour and to give control of interest rates to independent central banks. This was broadly the system in place from the mid-1970s to the moment when everything went pear-shaped in 2008. At that point, there was something of a crash rethink. Interest rates were slashed, central banks pumped money into their economies, budget deficits were allowed to balloon. Yet the strong and sustained recovery that was expected has not happened. The main impact of the extraordinary policy stimulus has been seen in asset prices rather than in the real economy. In the event of another crisis, central banks look to be short of conventional weapons. Tentatively, there are signs that fiscal policy – regulating the economy through tax and public spending – is making a comeback. In Britain, the chancellor, Sajid Javid, says interest rates are going to stay low for years to come, making it possible to borrow cheaply for long-term infrastructure projects. Clearly, the money could be put to good use. The big, inescapable difference between the 1971 Davos and the one this week is the threat posed by the climate emergency. A flick through Fritz Schumacher’s seminal 1973 green text – Small is Beautiful – finds no mention of global heating. It simply was not a political issue back then. Now, of course, it is. Each year the WEF asks a sample of experts and policymakers to list the most likely risks the world will face over the next decade. Unsurprisingly, against a backdrop of droughts, hurricanes, bushfires, melting glaciers and a steady heating of the planet, for the first time the top five threats are all environmental. Klaus Schwab, the founder of Davos and the WEF’s executive chairman, has written to all those attending this year’s event urging them to commit to net zero carbon emissions by 2050. An indication of how successful that appeal will be should come on Tuesday when Donald Trump drops by. What Trump should say – but won’t – is as follows: the US recognises the existential threat posed by global heating. It accepts that multilateral cooperation is needed if the problem is to be tackled before it it is too late. As a businessman, he is aware that no company could hope to survive if it depleted its own capital in the way that humans are consuming natural resources. To that end, the White House is working on an ambitious plan for the climate change summit due to be held in Glasgow at the end of this year. As the world’s biggest economy, the US will commit to stringent emissions targets, commit to renewable energy and bankroll a modern equivalent of the postwar Marshall Plan to help poor countries make the transition to a low-carbon future. Why? Because whereas the threat in 1948 was the spread of communism, now it is the much greater danger that capitalism will eat itself."
"Efforts to reduce levels of one potent greenhouse gas appear to be failing, according to a study. Scientists had expected to find a dramatic reduction in levels of the hydrofluorocarbon HFC-23 in the atmosphere after India and China, two of the main sources, reported in 2017 that they had almost completely eliminated emissions.  But a paper published in the journal Nature Communications says that by 2018 concentrations of the gas – used in fridges and air conditioners – had not fallen but were increasing at a record rate. Matt Rigby, from Bristol University, who co-authored the study and is a member of the Advanced Global Atmospheric Gases Experiment, said academics had hoped to see a big reduction following the reports from India and China. “This potent greenhouse gas has been growing rapidly in the atmosphere for decades now, and these reports suggested that the rise should have almost completely stopped in the space of two or three years. This would have been a big win for climate.” Scientists say the fact they found emissions had risen is a puzzle and could have implications for the Montreal protocol, an international treaty that was designed to protect the stratospheric ozone layer. Kieran Stanley, the lead author of the study, said that although China and India were not yet bound by the agreement, their reported reduction would have put them on course to be consistent with it. “Our study finds that it is very likely that China has not been as successful in reducing HFC-23 emissions as reported,” he said. “However, without additional measurements, we can’t be sure whether India has been able to implement its abatement programme.” HFCs were hailed as an answer to the hole in the ozone layer that appeared over Antarctica in the 1980s because they replaced hundreds of chemical substances widely used in aerosols that depleted the thin layer of ozone that protects Earth from harmful rays from the sun. But in recent years there has been mounting concern at how the potent greenhouse gas was undermining efforts to keep global heating below dangerous levels. Scientists say one tonne of HFC-23 emissions is equivalent to the release of more than 12,000 tonnes of carbon dioxide. Experts estimate that had the HFC-23 emissions reductions been as large as reported, the equivalent of a year’s worth of Spain’s CO2 emissions would have been avoided between 2015 and 2017. • This article was amended on 6 February 2020 because HFC-23 is not used in inhalers, as an earlier version wrongly said. This has been corrected."
"World leaders and business chiefs meeting in Davos this week will be confronted for the first time with an agenda on which the climate and ecological crises take top billing. Financial and economic concerns have been shunted down the list of priorities in favour of five environmental issues: climate breakdown and extreme weather; failure to mitigate or adapt to climate change; human-made pollution; biodiversity loss and ecosystem collapse; and natural disasters such as earthquakes, tsunamis and volcanic eruptions. Green campaigners and social and human rights activists have been raising concerns on all of these for more than two decades, but it seems that finally the world’s powers are paying attention. In some cases it may be too late to act to avoid the consequences of the delay in taking action. Since 2015 when the landmark Paris agreement was signed, greenhouse gas emissions have risen a further 4% and although there are signs the rate of increase may be slowing, that is nowhere near enough. Oceans are at the hottest ever recorded. Last year, ecological scientists said 1 million species were on the brink of extinction. The biomass of wild animals on the planet has fallen by more than 80%, about half of the area of key natural ecosystems has been lost, and insect populations have crashed, according to the report from the UN’s Intergovernmental Science-Policy Platform on Biodiversity and Ecosystems Services. The Intergovernmental Panel on Climate Change said in 2018 that by 2030 the world must be on track or exceeding 1.5C of global heating above pre-industrial levels would be all but inevitable. Warming has already topped 1C and 2019 was the second hottest year on record. As the Davos agenda shows, businesses are taking note. Ashim Paun, the global co-head of environmental, social, and governance research at HSBC, said: “Will 2020 be an inflexion point? Our investor clients increasingly think climate change is absolutely core to their investment processes. So this year we look to major political and policy developments – the details of the EU green deal in March, the outcome of elections, particularly the US where we see the outcome as fairly binary for climate, and whether this year’s climate talks in Glasgow [in November] can regain previous momentum.” There is plenty that all people around the world can do to get involved and shape the direction of this crunch decade. “2019 proved that activism works,” said Richard George, a climate campaigner for Greenpeace. “The amazing contributions from the school strikers and Extinction Rebellion, along with many others, got us a net zero target [in the UK and other countries], and almost universal agreement that not only is climate change happening but action to stop it is both vital and urgent. What we need now is real action to get the carbon out of our energy, transport, food and finance sectors, which means turning up the heat on politicians and corporations. This is the year to do it.” There will be international conferences this year on the climate, the oceans, biodiversity, deforestation and a host of other pressing environmental concerns. Many targets and deadlines for taking action are pegged to 2020, and governments and businesses will have to answer for any failure to meet those goals. The world is changing and leaders in all spheres are recognising that people are no longer willing to passively accept environmental destruction. Here’s what to look out for in 2020. Nearly five years have passed since the signing of the Paris agreement pledging to prevent global heating of more than 2C above pre-industrial levels. Since then, progress has stalled. Last year’s UN climate conference in Madrid ended inconclusively with no agreement on some basic aspects of implementing Paris. More importantly, countries’ commitments on cutting greenhouse gas emissions under the 2015 accord are inadequate to stay within the 2C limit and would lead to a disastrous 3C rise. That makes this year’s climate summit the biggest since Paris. Governments must come to COP26 in Glasgow in November armed with new emissions targets commensurate to the risk of climate breakdown. If Donald Trump is still in power, other countries must press ahead without the US and face down challenges to the Paris accord from Brazil, Saudi Arabia, Russia and others. That will be a massive struggle, and strong clear messages from civil society will be vital to its success. Trump has blasted through federal protections ranging from clean air and water to Alaskan drilling and pipeline construction, and if he wins a second term he is likely to continue on that track. In international terms his influence has been baleful on climate action: he started the formal process to withdraw the US from the Paris climate agreement in 2017, and that decision that will come into effect the day after the presidential election on 3 November. COP26 begins on 9 November and the US delegation will be drawn from the Trump White House whatever the election outcome. British diplomats will be looking to use the supposedly friendly relationship between Trump and Boris Johnson to try to ensure the US does not play a disruptive role. Trump will also preside over the G7 meeting in June, which means environmental issues will be off the agenda. In some previous years, notably 2005-07, the then G8’s focus on the climate proved a valuable spur to progress in the UN climate talks. This year that will be missing. Plastic pollution, overfishing, overheating and acidification from climate change are driving a crisis in the oceans. The World Ocean Summit in early March in Tokyo will set out the latest science on ocean health and present possible solutions. Later that month, from 23 March to 3 April, comes the final scheduled meeting of the UN effort to draft a new global treaty on the seas. IGC4 aims to set out a new legally binding instrument on “the conservation and sustainable use of marine biological diversity in areas beyond national jurisdiction”. Ecosystems around the world, from the Amazon to the Antarctic, are on the verge of collapse owing to human encroachment and exploitation, pollution, water scarcity and the impacts of global heating.  Two meetings will focus attention on the loss of biodiversity and ways to stem further destruction. The World Conservation Congress in mid-June in Marseille is a four-yearly meeting of the International Union for the Conservation of Nature, the organisation that compiles the global red lists of endangered and threatened species. A series of meetings held under the UN convention on biological diversity will culminate in a meeting at Kunming, China, in October where progress – or the lack of it – on protecting wildlife and plants will be assessed. The current global biodiversity action plan runs from 2011 to 2020 and its key aims are likely to be missed. A new action plan for the next decade should be adopted at the Kunming conference. The Paris agreement was not the only major international achievement of 2015: there was also the signing of the UN sustainable development goals, a set of 17 plans to remedy social and environmental ills – including eliminating poverty and hunger, empowering women and girls, improving access to healthcare and education in developing countries, and providing access to clean water and sanitation. Most of the goals are pegged to 2030, and this year is a staging post to assess progress at the UN high-level political forum in New York in July. The last few years have seen a new wave of environmental activism targeting businesses, whether through divestment campaigns aimed at fossil fuel investors, arts sponsorship deals or direct action. That is likely to increase in 2020 as the impact has become clearer. BlackRock made an unprecedented decision last week to start stepping out of investments with a high climate risk, and other funds will come under pressure to follow suit. There are a variety of ways people can make their views known to company boards, from questioning their pension funds to joining protests or even becoming a shareholder. Globalisation has led to a massive increase in carbon from shipping, which now represents 3% of all greenhouse gas emissions but will reach 17% by 2050 if unchecked. But shipping has been deliberately excluded from UN climate negotiations and little progress has been made in the last two decades on cutting greenhouse gases from one of the dirtiest forms of transport. At the International Maritime Organisation meeting in March in London, countries are supposed to come up with a new way forward to fulfil the UN agency’s aims of halving shipping emissions by mid-century – a goal that campaigners say is still inadequate. Last year Extinction Rebellion led effective protests. This year, decisions deferred last year will come back to the agenda. In 2010, companies from around the world joined forces on a target to banish deforestation for palm oil from their supply chains permanently by 2020. That target looks far from being met, but at the Consumer Goods Forum in June in London the signatory companies will have to explain their progress and what they hope to do to improve their performance. Palm oil is one of the biggest drivers of deforestation, particularly in south-east Asia where wildlife ranging from the orangutan to the Sumatran elephant and rhino are being endangered. Consumers have the chance to make their views felt: nobody wants their grocery shopping to contribute to species loss, and there are ways to grow natural resources without causing ecological disaster. It is up to producer companies and retailers to make the difference. The new European commission took office in Brussels late last year with one central promise: a green deal for Europe, by which the whole of the European economy and EU regulations would be overhauled to put environmental protections at the heart of continued prosperity. Clean energy, transport and industry will create new green jobs to replace those lost in polluting industries, and citizens will enjoy cleaner air, water, a healthier natural environment and a stable climate. That is the goal, at least. Living up to that promise will involve hard choices and skilful diplomacy, and in the course of this year the European commission, member states and EU parliament will face a series of key votes and decisions. The EU will also play a leading role in COP26, and the EU-China summit pegged for mid-September in Leipzig in Germany will be key. With the US rejecting the Paris agreement, cooperation between the world’s other biggest emitters will be vital, so the EU must forge a partnership with China or face failure at COP26."
"We applaud the rise in state-sector intake across Oxford University and are glad to see individual colleges praised (Report, 16 January). Perhaps Mansfield College deserves a mention. In a quietly radical fashion, we have led the way in Oxford access for 20 years. Our state intake has been over 80% for 10 years and over 90% since 2016. And more than 90% of our state-sector intake this year is from non-selective schools – a meaningful statistic for Oxford University.Lucinda RumseySenior tutor, Mansfield College, Oxford • Some years ago I attended a clergy conference in Wales, where an American visitor was using air purification processes as analogies for how parish priests should safeguard themselves in particularly toxic situations (Letters, 17 January). “It is vital,” he declared, “to ensure you have quick access to the right sort of scrubbers.” The laughter that followed was memorable.Rev Canon (Retd) Adrian CoppingWoolpit, Suffolk  • In his 1951 revue number Don’t Make Fun of the Festival (Editorial, 16 January), Noel Coward was far from defending the Festival of Britain, but rather, like Evelyn Waugh, caustically attacking it. The song’s final lines are “We believe in the right to strike / But now we’ve bloody well got to like / our own darling Festival of Britain.”Adam PollockGreenwich, London • The headline on Gaby Hinsliff’s article (Journal, 15 January) is “Driving in cities should become as antisocial as smoking”. Surely it already is; the point is for it to be recognised as such.Albert BealeKing’s Cross, London • In St Albans in the 1950s, my sister and I hammered on the back door of the King Harry pub to buy Marmite-flavoured crisps (Letters, 15 January). Our treat of the week.Sue PhillipsSalisbury, Wiltshire • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
nan
"The Black Death struck Europe in 1347, killing 30-50% of the European population in six violent years. It wasn’t a one-off epidemic: it signalled the start of the second plague pandemic in Europe that lasted for hundreds of years and only slowly disappeared from the continent after the Great Plague of London in 1665-1666. These outbreaks were traditionally thought to be caused by rodent reservoirs of infected rats lurking in Europe’s cities, or potentially by rodent reservoirs in the wilderness. But our research, published in the journal PNAS, suggests otherwise.  If the “reservoir” thesis were correct, we would expect plague outbreaks to be associated with local climate fluctuations, through changes in agricultural yields and primary productions in forests, affecting the number of urban and wildlife rodents, resulting in more plague. We found that Europe’s plague outbreaks were indeed associated with climate fluctuations – but in Asia. The Black Death came to Europe from Asia. Historical records tentatively map it back to outbreaks in 1345 in Astrakhan and Sarai, two trade centres located on the Volga river near the Caspian Sea.  Where the Black Death came from before it hit those cities is not known, but by recovering fragments of DNA from the teeth of plague victims in Europe, the closest currently known living relatives of this medieval strain of the plague causing bacteria Yersinia pestis are circulating in marmots and long-tailed ground squirrels in north-west China. Some dominant narratives on the plague are poorly substantiated. One being that medieval plague was transmitted by black or brown rats and their infected fleas jumping to humans. This was indeed how the third plague pandemic in the 19th and 20th centuries was transmitted – but there is poor archaeological evidence there were many rats across much of northern Europe in the Middle Ages aside from small populations of black rats in harbour towns, and no historic records that rats played a role in the disease. “Rodent reservoirs” represent another dominant narrative. The idea is that the disease was introduced in medieval Europe once (the Black Death epidemic) after which it settled into local rats or wildlife rodents, and continued to cause outbreaks in European cities for hundreds of years.  This is the narrative we aimed to substantiate through evidence, but which we ended up challenging. Using tree-ring based climate records from Europe and Asia, we showed that plague reintroductions into European harbours were associated with periods of wet conditions, followed by a drought, across large parts of Central Asia.  These conditions were tough for rodents in the region, traditionally the hosts of the plague bacterium, and their numbers would plummet. Infected fleas would seek new hosts, often latching onto passing human traders or their camels, though we don’t yet know exactly how the plague made the journey westward. What we do know is that, 14-16 years after the rodent-killing drought, we would often find plague reintroduced into Europe.  The chart below shows these climate fluctuations in Central Asia preceded the Black Death in 1347, the Italian plague of 1629, and the Great Plague of Marseille a century later, but notably not the London plague of 1665 or the outbreak in Vienna the following decade. This followed a pattern that we associate with current-day plague outbreaks. What is the implication of such a finding? In terms of our understanding of the past plague pandemics, it provides a different perspective as to how the disease moved across Eurasia, driven by climate events that were and still are frequently occurring.  It implies that there might never have been permanent reservoirs of plague among European rodents. While alpine marmots might have been affected and transmitted plague in medieval Europe, we found no indications that they can form a long-term reservoir, as their cousins in Asia do. Furthermore, the observation that plague disappeared from the European mainland, while outbreaks in the Middle East and northern Africa continued to follow upon climate events in Central Asia strongly suggests that the reason why plague disappeared from Europe should be phrased not in terms of why its reservoirs disappeared, but why the disease could no longer spread efficiently across the continent. It gives historians, epidemiologists and biologists new questions to ask in their quest to reconstruct what exactly happened during one of the most devastating pandemics in human history."
"The world’s climate scientists have spoken: if we want to limit human-induced global warming to 1.5℃ we probably can. But it will be tough, given where we’re starting from. That’s the conclusion of a new report by the UN’s Intergovernmental Panel on Climate Change (IPCC). The focus on 1.5℃ is the result of years of international negotiation. Starting in 1994, a central aim of the UN’s climate change efforts (the Framework Convention on Climate Change, or UNFCCC) was to stabilise greenhouse gas concentrations at a level that would “prevent dangerous anthropogenic interference with the climate system”. Much was written on what this meant, particularly the word “dangerous”.  Negative impacts of climate change occur on a continuum, and defining a point at which climate change becomes dangerous is difficult and contentious. On the other hand, climate change negotiations are difficult without some target to work towards. Fifteen years later, the UNFCCC’s Copenhagen Accord introduced a 2℃ target, and its 2015 Paris Agreement was even more specific: it “aims to strengthen the global response to the threat of climate change … by holding the increase in … temperature to well below 2℃ above pre-industrial levels and pursuing efforts to limit the … increase to 1.5℃”. The IPCC provides scientific advice to the UNFCCC, which makes policy, and the IPCC itself has never stated a temperature target. It does however list climate change risks using five “reasons for concern”. These include impacts such as “unique and threatened ecosystems and cultures” (such as coral reefs) and “extreme weather events”, each of which is rated on a scale from “undetectable” to “very high”. The IPCC’s most recent (2014) Fifth Assessment of the scientific evidence found that at around 1.5℃ warming there was a transition from moderate to high risk for threatened ecosystems and cultures and for extreme weather events. Thus there is consistency between the Paris and IPCC assessments. The Paris Agreement asked the IPCC to report on the impacts of global warming of 1.5℃, and this new publication is the result. Its tone is not “we must avoid 1.5℃ warming”, as you might think from many commentators, but more “if we want to avoid 1.5℃ warming, this is what must be done”. The report contrasts the impact of 1.5℃ and 2℃ warmings, giving information on what would be gained by the extra effort needed to limit warming to 1.5℃. As the IPCC’s reports are largely based on a critical assessment and synthesis of published scientific papers, many of its latest conclusions are unsurprising. There are many well recognised uncertainties in understanding climate change - for instance, even if we set a course aiming to hit 1.5℃ (which is mostly determined by future CO₂ emissions), we could end up hitting, say, 1℃ or 2℃ instead. The report provides uncertainty ranges in its estimates and confidence levels, based on expert judgement. The new report tells us that human activity has already caused about 1℃ of global warming, while at the present rate of warming (0.2℃ per decade) we’ll hit 1.5℃ by about 2040. National pledges made as part of the Paris Agreement still mean we are on course for warming of about 3℃ by 2100, meaning four of the five “reasons for concern” would then be in the high to very-high risk category.  Achieving the 1.5℃ target will require anthropogenic CO₂ emissions to decline by 45% by 2030 (relative to 2010). By 2050, they will need to reach “net zero” - any further CO₂ emissions due to human activity would then have to be matched by deliberate removal of CO₂ already in the atmosphere, including by planting trees. Net zero would have to occur by around 2075 to meet a 2℃ target. Many illustrations are given for the difference between 1.5℃ and 2℃ worlds. At 1.5℃, summertime Arctic sea ice is projected to disappear once per century, compared to once per decade at 2℃; 8% of plants that have been studied would lose half their climatically-suitable area, compared to 16%; sea level rise would be 10cm less (with 10m fewer people impacted at today’s population levels); and while coral reefs might decline by a further 80% at 1.5℃, they could virtually disappear at 2℃. The report identifies various routes by which emissions cuts would limit warming to 1.5℃; each makes assumptions about future changes in, for example, economic strategy, population growth and the rate at which low carbon energy is adopted. The IPCC recognises the challenges are “unprecedented in scale” but notes, for example, “the feasibility of solar energy, wind energy and electricity storage mechanisms have substantially improved over the past few years”. The report is sensitive to the fact that changes required to meet 1.5℃ must be consistent with the UN’s wider sustainable development goals. Limiting climate change will help meet goals associated with health, clean energy, cities and oceans. But there are potential negative impacts on others (poverty, hunger, water, energy access) “if not carefully managed”. So where next? Of course, the conclusions will be widely debated at many levels, but eyes will be on the UNFCCC’s response at its next meeting, in Katowice, Poland, in early December."
"For more than half a century, the indigenous Kaiowá and Guarani people of Brazil have been deprived of their ancestral lands, and consigned to small reserves where it is impossible to maintain their traditional livelihoods. Generations of these indigenous peoples’ lives have been marked by violence and vulnerability as they have tried to reclaim what, according to the Brazilian constitution, is rightfully theirs. And now we have found that increasing globalisation is posing an urgent threat. In March 2018, as part of the Global-Rural research project based at Aberystwyth University, we visited the Kaiowá and Guarani people who live near Dourados, in the southwestern state of Mato Grosso do Sul. We investigated how increasing worldwide intergration is impacting the Brazilian countryside, and explored the ways in which the Kaiowá and Guarani peoples’ lives are being affected by the intensification and expansion of industrialised agriculture production used for foreign markets.  We spoke to indigenous leaders and families based in several Kaiowá and Guarani villages across the municipalities of Juti, Rio Brilhante, Dourados and Caarapó, and found out the devastating consequences of globalisation on their way of life. The first dispossession of Kaiowá and Guarani indigenous lands took place at the end of the 19th century, when the Brazilian government gave five million hectares to the Mate Laranjeira Company. Under the pretext of defending the interests of the native peoples, the state also founded the SPI (Indian Protection Service), which created indigenous land reserves. Different ethnicities (the Kaiowá, Guarani, Terena and others) were forced to live together in these reserves, despite historical hostilities. They were catechised, taught to communicate in Portuguese (and strongly discouraged from using their native languages) and became assimilated as “Brazilians”. There was not enough space in the reserves for the people to continue hunting, and use the local natural resources for their subsistence as they had done traditionally, so they were forced to learn the professions of the non-indigenous. In the 1980s, after the military dictatorship, when Brazil was engaging in a re-democratisation process, the Kaiowá and Guarani found themselves at a crossroads. They would cease to exist if they continued to live on the reserves, or they could leave and reoccupy their ancestral lands to preserve their culture, roots and livelihood. In choosing the latter option, they faced armed ranchers and farmers who would defend private property at any cost. And so began the worst human rights violations and violence against the Kaiowá and Guarani peoples to ever occur.  Though the Brazilian Federal Constitution guaranteed indigenous people the right to the land in 1988, it also established a limit of ten years to demarcate and hand over the land, and compensate farmers. Now, after 30 years, the demarcation process is far from completed.  Since the early 2000s, land reoccupation conflicts have intensified. According to one survey, some 258 Kaiowá and Guarani leaders were murdered in Mato Grosso do Sul between 2003 and 2011. These ongoing violent conflicts, the displacement and the ongoing genocide of the Kaiowá and Guarani have been internationally denounced. Yet, even though it has received global attention, it is still seen as only a local problem. One of the main reasons why the land conflicts haven’t been resolved is down to the value of agribusiness. Farming is championed as the flagship of the Brazilian economy, with increasing portions of lands being used to intensify industrial and mechanised agriculture. In the last ten years, this sector has grown further, along with the exportation of commodities, especially soy. Brazil has been declared a global agribusiness powerhouse, and praised for supplying the “four Fs” – food, feed, fuel and fibre – to the world.  While we were in Brazil, we saw the everyday threats of living in a contested territory surrounded by industrial plantations. We witnessed three occupied villages near Dourados being evicted, to make way for large scale monocultures (where one crop is grown). Though the Kaiowá and Guarani were there protecting their lands with indigenous rituals, they still expected the worst to happen – and so did we. We prepared an escape plan with the people, whereby we researchers would save the children if military troops arrived. Although the eviction was ultimately postponed, this shows how the Kaiowá and Guarani live in constant fear of being removed from their land, of being intoxicated by the contaminated water, air and soil, of been killed.  During our research, we also visited families who had been evicted from reoccupied areas due to agribusiness expansion, and left with no land. Squeezed between sugar cane, soy and corn plantations, they were ousted to the sides of roads.  We spoke to an indigenous leader, who was living at the edge of a road, driven from her indigenous land. She cried over the death of her husband and son, which were due to land conflicts, and lamented the health problems that came from chemicals put by agribusiness on the land. She mentioned that the children specifically had increasingly experienced headaches, stomach problems and sickness, which they believed was due to water contamination – and that some of them had lost their lives. She told us of the challenges to her people’s livelihood and the unbearable situation to which they are now condemned. One of the indigenous leaders claimed “Europeans should know that in the bio-ethanol they are importing from Brazil they will find our blood”.  While, sugar cane, soy and cattle take over the landscape in the southwest of Mato Grosso do Sul, it is impossible to ensure a healthy livelihood for the Kaiowá and Guarani. They have no access to drinkable water, no protection from agro-chemical contamination, and no adequate conditions for planting, hunting or fishing. The conditions are violent and the Kaiowá and Guarani people are in a precarious position. In the name of global development, progress and sustainability, the silent genocide of one of the largest ethnic groups in the country is taking place. “Earth, life, justice and demarcation!” – the cry of the Kaiowá and Guarani people."
"
Share this...FacebookTwitterAs the pressure mounts in Germany to switch off coal power plants and to rapidly transition over to green energies, one gets the feeling that it all has more to do with a desperate, last-ditch effort by the green energy proponents to rescue their pet green project.
Photo right: Energy expert, Dr. Björn Peters. Image: Deutscher Arbeitgeberverband 
Hat-tip: Die kalte Sonne
Recently, Der Spiegel wrote about how Germany’s once highly ballyhooed Energiewende (transition to green energies) has turned out to be a botched project. Then Michael Schellenberger at Forbes commented that the laws of physics tell us it was never meant to work in the first place.
Behind closed doors, no one in Berlin believes in it
Now, just days ago, energy expert Dr. Björn Peters wrote at the German Association of Employers site that the Energiewende has deteriorated to the point that: “No specialist politician in Berlin believes in the success of the Energiewende any more. Whoever you ask, everyone says this only behind closed doors and thinks that if you go to the press with it you can only lose against the ‘green’ media mainstream.”
Peters warns that what is needed in Germany is a good dose of reality and “a fresh start on energy policy.”
Advantages of fossil fuels “too great”
The German expert writes that despite the hundreds of billions of euros committed to green energies, “chemical energy from coal, oil and gas supplies about four fifths of primary energy worldwide and also in Germany and thus represents the present energy supply”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And although at some point, the reserves will be exhausted, and alternatives will need to be found, but “for the time being, chemical energy sources are irreplaceable and will remain so for several decades to come. Their advantages are too great.”
Peters reminds that “petroleum-based fuels have the invaluable advantage of high energy density. At over 10 kWh/kg – a hundred times higher than batteries – they are the only energy sources that can reliably supply cars on overland journeys, trucks and ships with energy.”
Yet, Peters agrees that alternatives need to be sought out ultimately because traditional fossil fuels are limited in their supply and burning them entails questions concerning their impact on health.
Nuclear technology as the solution
In his opinion piece, Peters advocates nuclear power as the alternative, writing: “If now the chemical energy sources cause too much damage to humans and nature and will run out in the foreseeable future, and the surrounding renewable energies cannot provide a comprehensive energy supply, only nuclear energy sources remain. Physics does not permit other energy sources. From these we can show that they have the potential to deliver clean and highly concentrated energy forever. Of particular importance is the fact that nuclear energy can provide energy for all applications that human civilization needs, i.e. not only electrical energy but also for heating, transport and industrial process energy.”
Peters also notes that there are “candidates for a modern energy supply by means of nuclear energy”, with the most promising being the dual fluid reactor as it is inherently safe because the physical processes prevent it from getting out of control and it is emissions-free.
Sun and wind inadequate
In Peters view, it’s been shown on multiple occasions that energies from the sun, wind and biomass are not yet suitable for powering entire modern societies.
The German energy expert criticizes Germany and the EU’s narrow focus “on promoting only a few power generation technologies” while ignoring more comprehensive energy supply concepts.
He warns: “In the end, even the German public will not be able to avoid the banal physical reality: Without nuclear energy sources, it will not be possible to abandon chemical energy sources due to the pitfalls of renewable energies. A new start in energy policy is therefore urgently needed.”
Share this...FacebookTwitter "
"The solar eclipse due to cover much of Europe on March 20 will be the continent’s first for 16 years. Back in 1999, as people stopped staring at the sun and got back on with their day they caused a power surge which still stands as a UK record – greater than anything after a football match or royal wedding.  At the time, solar power made up just 0.1% of all Europe’s electricity produced from renewables. Since then it has increased to at least 5% as countries subsidise renewables to meet EU targets. The installed capacity of solar power in continental Europe is expected to reach 90 GW this year, comparable to 150 coal fired plants. Under clear skies, regulators expect some 35 GW of solar energy to fade away with the eclipse before being re-injected into Europe’s electrical system. This is a big test for solar power. It’s the first time when such an event could have a significant impact on those European countries with lots of solar panels such as Germany (with 44% of continental Europe’s installed capacity), Italy, Spain and France. Much more, European grid integration means everyone could be affected. Keeping the grid stable during the eclipse is the main concern for power utilities. The electrical grids of continental Europe are linked together in what’s called the European synchronous area, allowing countries to juggle excess energy between them to meet demand. Grid regulators will have to coordinate across regions to manage the solar drop off along and demand, all in real time.   According to ENTSOE, Europe’s association of national grid operators, around 50% of the lost power will come from Germany and 21% from Italy. The grid will be losing 0.4 GW/minute at the start of the eclipse and gaining 0.7 GW/minute as the sun returns.  This is a huge amount of electricity generation to come online at once. The European power system will need to adapt in real time, with countries helping each other by providing the necessary reserves of coal, gas and hydropower to keep things running. Electric grids operate on the principle that demand and supply need to be carefully balanced. In continental Europe, grids are connected as one synchronous network. The normal operating frequency is 50 Hz, with two statutory limits, the upper limit, which is 50.5 and the lower limit which is 49.5. Above the upper limit, the generators will trip, while below the lower limit demand will disconnect completely, that means power won’t reach end users and blackouts will happen.  Think of it like driving a car with a target speed of 50 miles/hr (+/-0.5mph). The accelerator is generation, the forces dragging on the car represent the demand. Keeping the frequency at 50Hz means maintaining secure operation of the system, quality of supply and operate economically. Despite the impact on solar energy the eclipse’s most significant effect on the power grid will actually be as a result of human behaviour. During the 1999 eclipse in the UK, people stopped working to enjoy the phenomenon, as highlighted in this graph by Solar Power Portal. The 3 GW surge was greater than the 2.8 GW surge after England played Germany in the 1990 world cup semi-final, or the 2.4 GW surge after the 2011 royal wedding. Something similar will happen this time round. There will be a drop in demand before maximum eclipse, and increased demand after as people come back inside, turn on the tv and fire up the kettle.  In this time the system will have to adapt to the changing load and this could be a challenge. Planning is critical, as you can’t just instantly increase electricity generation. But electricity surges happen from time to time – the 2014 World Cup provides a recent example – and grid coordinators have contingency measures in place to balance supply and demand. The solar eclipse on Friday is a good test for the future, when even more electricity will be produced from renewables like solar and wind, which are more volatile and dispersed generation. Germany, Italy and the US are among the countries where solar will make up a large proportion of overall power. In such situations, even cloudy weather will create a big decrease in production.  If you want to look at what happened during the eclipse, then BM reports provides near real time and historic data on the UK’s national grid balancing system – electricity generation, system prices, warnings, frequency, wind forecasts, market activity, and so on. So, while most people will spend Friday morning observing at the sun with their pinhole cameras, I’ll be keeping one eye on the grid."
"When Theresa May became the “Brexit prime minister” in July 2016 it took her less than 24 hours to dissolve the Department of Energy and Climate Change. The message could not have been clearer: Brexit first, and climate change would have to wait. May, although historically noncommittal on the subject of climate regulation, was probably not acting on a disbelief in the threat of climate change. The far more concerning motivation was the simple preoccupation with another political concern. Throughout May’s tenure it has become all too clear that the UK government is fixated on Brexit, along with the country’s media and almost everybody else. Climate change has been continually pushed out of the headlines by yet another Brexit blooper, which has serious implications for the UK’s international policy. The Paris Agreement intends to keep global temperature increases at below 2℃ above pre-industrial levels. It is premised on the notion that states set their own nationally determined contributions (NDCs), essentially setting out how much carbon they themselves will cut to help achieve the overall objective – the agreement is therefore based not on obligation but discretion. States are not legally obliged to act on the Paris Agreement in any specific way. Instead, the design and submission of NDCs is directly linked to the determination of the incumbent government. In the case of the UK, a state submersed in Brexit, the reality is a complete failure to draft its own contribution. Members of the European Union decide their international climate policy collectively, of course. This means that, for the time being, the UK is able to rely on commitments made by the EU which, although not hugely ambitious, would allow the UK to engage in EU carbon off-setting and technology transfer initiatives to provide overall NDCs for the bloc. In March 2019 this option will cease to exist and the UK will become a climate laggard without an NDC. In the absence of the Department of Energy and Climate Change the UK Committee on Climate Change has stepped into the role of dispenser of information to the government. The committee is chaired by Lord Deben (John Gummer), a long-time advocate for climate policy, and produces independent reports offering critiques of the current and longer term climate objectives and the means in which to achieve them. However, the committee is not able to force the government into action and is instead limited to an advisory role. In October 2016 it released a 60 page report detailing various shortcomings of the current strategies and the high likelihood of unsuccessfully meeting emission reduction targets by 2030. Yet its recommendation was for the government not to alter its existing targets. This timidity gave further ammunition to critics who have questioned whether the committee is truly independent. The government promptly absorbed these recommendations and carried on with its Brexit obsession without hesitation or adjustment to its climate strategy. Thus the committee is not able to provide the same kind of leadership as a full departmental minister. Climate change as a priority has therefore lost a great deal of momentum at the hands of a Brexit-focused government. The Paris Agreement has 197 signatories, and at most Brexit will have a direct impact on 28 of those – the remaining EU members. Brexit is certainly a UK problem, probably an EU problem, but unlikely a global problem. Yet what it represents is the inherent flaw in electoral democracy. Governments have become increasingly short term species with one eye on the next election, a philosophy embodied by May’s time in Downing Street. By relegating all other issues she has made her pitch for continued leadership entirely dependent on the outcome of Brexit. The result of this is almost complete frustration of the UK’s climate policy. But every state will suffer its own Brexit moment in one form or another. If we do not learn to frame climate change as a non-political issue it will always be subject to challenge. Brexit has not killed the Paris Climate Agreement but the electoral system of democracy just might."
"As the planet warms, species are moving further north to climate zones which are closer in temperature to what they originally evolved in. The oceans have absorbed most of this temperature increase, and so many marine species, including commercially fished scallops, are under particular stress to migrate northwards to cooler waters.  In the face of this disruption, legal boundaries for fishing fleets could become increasingly irrelevant. As the fish stocks they once contained move out, conflict is likely to arise between countries exploiting neighbouring fishing grounds. As a result, the ongoing “scallop war”, which has seen tense physical confrontations between French and British scallop fishers over access to these prized molluscs, may be a taste of worse to come. The habitat ranges and migration patterns of commercial species in the ocean have been carefully studied throughout history, so that fishing fleets can exploit them more efficiently. This understanding has informed the division of fishing grounds according to who has the right to harvest them. French scallop fishers were incensed over their British counterparts’ alleged pillaging of scallop stocks, as smaller British boats aren’t bound by a French law that prohibits dredging in the Baie de Seine from October 1 through May 15, to allow scallop populations to recover. While on the surface it might seem that these skirmishes are anchored to specific circumstances – potentially inflamed by existing tensions around Brexit – they highlight the enormous difficulties in clearly mapping and enforcing legal boundaries around natural habitats that are changing rapidly. These disputes over resources such as food will become more frequent and intense as climate change alters the habitats and material conditions of life on Earth. 


      Read more:
      'Scallop wars' between Britain and France are just a pre-Brexit skirmish


 Managing marine resources like fish has always been tricky. Each species responds differently to changes and pressures in its environment, making it difficult for anyone to predict exactly where they will be, when or how far they will migrate, and how many remain. Climate change has introduced new uncertainty.  The effects of rising temperatures, though variable across species, have already begun to alter the sizes, distribution, and food web interactions of marine organisms. Warming seas have led to an overall northward movement for many species, some at a pace of 2.2 kilometres per year. This includes commercial species such as the Atlantic cod, a trend that is observable among land-based animals as well. More carbon dioxide in the atmosphere means more of it dissolves in the ocean, making seawater more acidic. This process, known as ocean acidification, is making it difficult for species such as scallops to grow their tough calcium-carbonate shells, threatening their growth and survival.  On top of all of this, we’re taking from the ocean more than it can replenish. Currently over 90% of large commercial fish species such as tuna and cod have already been caught, and over 70% of the world’s fisheries range from “significantly depleted” to “fully exploited”. Species unable to adapt to this pressure are likely to decline or even disappear.  If the scallop wars end soon, climate change will continue to disrupt marine ecosystems and render political boundaries increasingly outdated. We will need to have a radical rethink of who should have rights to what, who is to have the authority in managing important areas and resources, and what constitutes a truly sustainable harvest.    Greater communication and collaboration between fishers, policymakers, researchers and the wider public will become essential for navigating the troubled waters ahead.  Perhaps it is also time to take the interests of other species into consideration in this process, by viewing the natural world and non-human life as more than mere resources or a backdrop to the unfolding human drama."
"
Share this...FacebookTwitterkebenaran teranyar berkaitan Permainan Bandarq! Bandarq merupakan game terkenal yg dimainkan oleh tidak sedikit orang di semua dunia. Dibuat sudah menciptakan aku polar oleh kemajuan tehnologi. Bandarq menawari jumlahnya opsi pembayaran, maka kamu mampu percaya bahwa kamu dapat memperoleh kemenangan bersama serentak & mudah.
kamu bisa pilih utk tentukan kemenangan di bank kamu. Atau mampu serta dalam wujud token yg sanggup kamu pakai di situs-situs. Inilah argumen kenapa tidak sedikit orang pilih Bandarq & memainkan permainan yg sudah mereka sediakan.
Ada tidak sedikit kasino di internet disaat ini, yg membuatnya susah utk menemukan yg serasi utk kamu & biaya kamu. sesudah kamu mengunduh penerapan Bandarq & menciptakan akun buat kamu sendiri, tinggal mengawali & menyaksikan game mana yg yakni pilihan sesuai utk Anda.
kamu kemungkinan mau main-main poker reguler kalau ini yaitu permainan yg biasa kamu sukai & gemar main-main, atau kamu kemungkinan mau cobalah poker domino baru utk kamu sendiri. bandarq mempunyai tidak sedikit pilihan utk pemain.
Permainan ini mempunyai keseluruhan dua puluh delapan card. tiap-tiap card mempunyai poin yg tidak serupa. Di tiap-tiap putaran permainan, masing-masing pemain mulai sejak dgn empat card. sesudah kompetisi berhenti, juara jadi pemain bersama poin paling signifikan.
Itu mampu gampang atau susah. Ini tergantung terhadap gimana seorang melihatnya & memainkannya. tidak sedikit orang sudah cobalah peruntungan di game ini. Beberapa sudah sukses sementara yg lain kalah. menjadi apa yg menciptakan kamu menang atau kalah dalam game ini?
Sudahkah kamu main online & kehilangan sebahagian gede duit kamu dalam perjudian ini? kenapa kamu kalah? jikalau tak, ini yaitu beberapa petunjuk yg bakal meringankan kamu utk membunuh dalam perjudian ini.
mulai sejak bersama Game Gratis
Iya nih. jangan sampai sempat terburu-buru bertaruh dgn duit hasil jerih payah kamu kalau kamu belum menguasai seni permainan. Ada tidak sedikit web online yg dapat kamu memberi peluang ini. Mereka bebas. kenapa tak mengahdiri mereka? tak dapat menghabiskan tidak sedikit disaat Anda.
Apa bukti teranyar dari Permainan Bandarq?
tetapi, kamu mesti lumayan bersabar. jangan sampai terburu-buru. Luangkan saat kamu buat menuntut ilmu & menghindari menciptakan kesalahan. main-main game cuma-cuma ini bakal menopang menciptakan kamu pintar maka waktu kamu mulai sejak main-main game nyata, kamu sanggup bersama gampang menang. kenapa tak cobalah web free hri ini?
terus Fokus
umumnya orang kalah dalam permainan ini sebab kurangnya perhatian & fokus yg dimanfaatkan. kala kamu memutuskan utk memainkan game ini dengan cara online, kamu mampu memainkannya di mana saja. kamu cuma butuh koneksi internet yg serentak & andal.
Tolong janganlah sempat memainkannya di daerah di mana ada tidak sedikit nada & ganjalan. jenguk ruangan yg dingin & mulailah main-main. hunian, kereta api, & kafe kemungkinan bukan lokasi paling baik lantaran tidak sedikit kebisingan di sekitarnya.
type nada ini menciptakan kamu kehilangan fokus. dgn begitu, kamu tak dapat berada dalam posisi buat memantau lawan kamu. bila kamu bakal memainkan game ini, saksikan utk menghindari risiko taruhan Anda.
Lihatlah aktivitas Lawan Anda
dimanfaatkan konsentrasi kala kamu tak main. Ini berikan kamu peluang sempurna buat menonton wajah lawan kamu. Bisakah kamu membaca langkah kemudian yg paling barangkali? Ini teramat mutlak. Ini meningkatkan kesempatan kamu utk menang. Apa yg dilakukan lawan diwaktu mereka bermain?
bagaimanakah bersama disaat mereka tak main-main? teramat gampang utk memastikan apa yg dapat berjalan bersama paling menyaksikan ini. lihat Ini Erat.
seandainya kamu satu orang Pemula, senantiasa pakai Tabel Kecil
janganlah serakah diwaktu main Bandarq. menggali ilmu yakni satu buah proses. janganlah sempat membawa risiko berfokus terhadap tabel yg lebih akbar. bisa jadi akbar kamu dapat kalah. Dianjurkan utk menempel terhadap meja mungil. Ini dapat menciptakan lawan kamu nyaris mustahil utk mengalahkan Anda.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAn empirical analysis using 2005-2015 data from 15 EU countries indicates that as more renewable energies (i.e., solar PV) are deployed, energy costs increase, household poverty risks rise, and incomes decline.


Image Source: Pereira et al., 2019
In contrast to the negative consequences of switching from fossil fuels to renewables, Dr. Tadesse Weldu Teklu affirms “CO2 emission (energy consumption) is directly correlated to economic prosperity and industrialization.”  
Therefore, least developed countries (LDCs) such as Ethiopia should “increase her CO2 emission per capita as much as possible” to escape from the renewables-centered “poverty trap” foisted upon them by “Earth-friendly” wealthy countries.  
Besides,  fossil fuel consumption will inevitably continue to grow and maintain a similar share to today’s (~80%) by 2040 despite symbolic “destined to fail” Paris agreement gestures.


 

Image(s) Source: Teklu, 2018
Share this...FacebookTwitter "
"The decision by counter-terrorism police to place Extinction Rebellion (XR) on a list of extremist groups was an abuse of the tools available to them (Starmer: police ‘completely wrong’ to label XR extremist, 14 January). This abuse amounts to an admission that the police do not know how to deal with XR. They are familiar with capturing those who avoid arrest. But many in XR welcome arrest as a way of highlighting the climate emergency. I was arrested during the October rebellion last year. As I was leaving Wood Green station, I overheard two police officers talking. One said to the other: “There must be a better way. They are doing this because they believe in it, and we are doing this because it’s our job. There must be a better way.” He was right. A better way is needed – and not one that involves further abuse of police powers. That better way requires the government to listen to XR, and to act on the climate crisis. Until that happens, the police will struggle.Nigel HarveySt Albans, Hertfordshire  • I agree with Les Knight (I want humans to go extinct, Experience, Weekend, 11 January). Planet Earth is suffering from an infestation of human beings. Nor do I want us to colonise another planet. We have plundered the one we are already on. If we colonised another we’d simply carry our polluting ways there too.Donald PelmearLondon • Apocalyptic views have been held, for differing reasons, by many individuals over the centuries. Les Knight’s are a present-day extreme version. Why characterise them as an “experience”? They appear to have nothing to do with lived experience but rather with an ingrained attitude of mind whose deep-seated origins remain opaque.Gillian TindallLondon • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"There have been many proposed solutions to the climate crisis – from outright bans on fossil fuels to planting 2 billion trees – but Jonathan Safran Foer’s antidote to global devastation strikes me as the neatest and most achievable. It could sound like something written by a prophet in stone: Eat No Meat Before Sundown. But Safran Foer, in his brilliant book, We Are the Weather, insists on couching it in far more conversational terms: we need to make a “collective act to eat differently”, he says, and one straightforward way is to aim to eat no animal products before dinner. This idea for a roughly two-third shift in animal consumption comes armed with unarguable statistics about its positive effect in reversing climate trends, including the killer pay-off: “If cows were a country they would rank third in greenhouse gas emissions, after China and the United States.”  I meet Safran Foer in London in the autumn, while Extinction Rebellion are glueing themselves to corporate buildings. He has chosen to eat at Nopi, Ottolenghi’s brasserie outpost off London’s Regent Street, not least because in Safran Foer’s decade of campaigning against factory farming (his 2009 book Eating Animals was the starting point) the chef has become a good friend and ally. We order sharing plates including cauliflower and green bean fritters, hispi cabbage and tofu mayonnaise, chickpeas with sumac feta and – ignoring any potential for caricature – talk first about the protests and their effect. There has, Safran Foer says, been nothing remotely like them in the US, but he is not convinced they are effective. “I saw a protester asked on the news, ‘What is the point?’” he says. “The reply was the obvious one: ‘We wouldn’t be talking about it now, if this were not happening.’ But is that exactly a point? You can imagine ways in which it could be a bad thing if it becomes too divisive, or is seen as just a liberal concern.” One theme of his book is that human beings cannot hold potential apocalypse in their minds for very long: “We are good at things like calculating the path of a hurricane,” he writes, “and bad at things like deciding to get out of its way.” He uses at one point the analogy of his grandmother’s family in 1930s Poland to examine human reaction to the psychology of existential threat. His grandmother heard what was happening in Germany and – partly through luck and circumstance – decided to emigrate. All her relations heard the same news and were paralysed by it, or had other concerns. He fears that is the effect of a lot of well-intentioned hand-wringing about the planet, the virtue-signalling threats of doom. The scale overwhelms us, and we do nothing. “I don’t understand why the Extinction movement isn’t concretising. Why it isn’t issuing specific ideas,” he says. “They are awfully vague and unrealistic. Why not say: ‘Here’s a thing we can all do to help this month?’ And do that every month. I feel then that an awful lot of people would start to give it a shot.” His informed suggestion about daytime veganism is a case in point. But even then, and in his book, he cautions against being too shrill. One of the most persuasive adopters of his plan in the US has been the chef Samin Nosrat, bestselling author of Salt, Fat, Acid, Heat. “The way Samin talks about it is climate leadership, for me,” Safran Foer says. “She doesn’t ask anyone else to do it. She says: ‘I might not be consistent with it, it is going to be a big change. But knowing what I know, this is what I feel I should do.’ When people lecture me on their own ethical accomplishment, I find that extremely annoying and certainly not inspiring. But if somebody says, ‘I want to try this, I fear I might fail,’ people start to think, ‘Well, you know, I could try that too.’” Safran Foer is upfront about his own lapses in the book. He confesses even to one or two fast-food burger moments when tired or emotional or lazy. That seemed to me quite a brave thing to do, but also a persuasive one. “It felt like an embarrassing thing to write,” he says. “But I have definitely had meat. And I have often wanted it. These days I find cooking vegetarian quite easy. But veganism is much more difficult. I mean I wrote the book, so I had to do it. But it was still like, ‘Oh shit, this is difficult.’” He thinks that above all we need to get away from thinking in binary terms. “If someone says to me, you know, I couldn’t give up chicken, or cheese, or burrata, that’s fine, just eat much less of it, or only eat it for dinner. The goal is not to perfect a virtuous identity for yourself. The goal is to reduce the amount of carbon in the atmosphere.” Safran Foer first found a global audience as a wunderkind novelist. His book Everything is Illuminated, a fictional personal journey into Holocaust history, earned him an eye-watering publisher’s advance and universal critical acclaim. It came out when he was only 25. He followed it with another chunky bestseller, Extremely Loud and Incredibly Close, which offered a child’s eye view on the 9/11 attacks, and became a film starring Tom Hanks. In his two polemical books, he uses a pared-down version of that hyper-intelligent novelist’s voice, but retains a genius for a compelling story and a telling detail. He understands that the best of the latter are often the most simple. One thing that struck him when he started to share a platform with distinguished climate scientists was that they were all, to a woman and man, vegetarian. “They just took that as read,” he says, “in the same way they would never drive an SUV. The funny thing was that it was too obvious to them almost to mention.” Another telling revelation, he says, struck him when Eating Animals came out. He imagined it would likely be loved by animal rights protesters and hated by farmers. In fact, he had the opposite experience. “Farmers I spoke to welcomed the book. They despise factory farming more than anyone. The whole model of industrial agriculture obviously seeks to remove farmers from the process. Sustainable farming offers them a future.” The protesters, meanwhile, found plenty to protest about in Safran Foer’s human and realistic tone, because that is what they do. We dig into our sharing plates, Safran Foer doing his best to avoid the rule-breaking components of our order, yogurt and feta. “This is part of my difficulty right here,” he says, of a slightly awkward interaction with the waiter when he suggested he would rather not have dairy. “I still don’t quite know how to have the conversation about these things. I know how well they source things here. And I don’t like that feeling of sounding judgmental. There is nothing I like less than going to dinner at a friend’s house having forgotten to tell them.” What will he do? “It depends. If they have gone to a lot of effort sometimes I might not say, just because in the scheme of things one dinner obviously doesn’t matter.” In all of this, he suggests, we put too much emphasis on motivation and not enough on action. An honest commitment to try to change habits is always far more effective than hard-and-fast denial, but deciding what is possible is the first step. He tells a story of a couple he met at a reading he gave; when he came to sign their copy of his book he saw that the title page was covered in writing. “They told me that they were about to get married, and decided to have a plan for the future. The plan involved trying to eat vegetarian except at dinner. Vegan two days a week. Have no more than two kids. And to drive no more than 1,500 miles a year. That struck me as a good way of looking at it.” Safran Foer went home that evening and wrote his own plan. It involved among other things a commitment not to fly for vacations as well as one to try to stick to his diet. “Everyone might think about a plan,” he says. And what better moment to adopt one than new year 2020? We Are the Weather is out now (Hamish Hamilton, £16.99). To order a copy, go to guardianbookshop.com"
"This is an article from Curious Kids, a series for children of all ages. The Conversation is asking young people to send in questions they’d like an expert to answer. All questions are welcome: find out how to enter at the bottom.  We have eyes on the front of our heads so we can see where we are going, but birds’ eyes are on the side so how do they see where they’re going? – Thomas and Luke, age six, Sussex, UK Dear Thomas and Luke, Thanks for your question. First of all, I should mention that not all birds have their eyes on the sides of their heads. Pigeons and parrots do, but other birds, such as owls, have large eyes placed close together at the front of their heads – a bit like ours.  Whether they have eyes at the front or on the sides of their heads, all birds can still see straight ahead. But that doesn’t mean all birds see things in the same way. In fact, where a bird’s eyes are on its head can tell us a lot about how it sees the world.  Having two eyes means animals can see a three dimensional image of what’s around them. So they can perceive the height, width and depth of an object, as well as how far away it is.  Where a bird’s eyes are on its head affects its field of vision – that’s how much it can see in front and to the side at any one time. Think about how far you can see to either side without turning your head: these are the limits of your own field of vision.  Because owls have eyes at the front of their heads, they have a smaller field of vision – around 150 degrees for a barn owl (though they can turn their heads very far to look around).  Parrots, pigeons and other birds with eyes on the sides of their heads have a much bigger field of vision, of about 300 degrees. Amazingly, this means that they can see in front and a long way to the side, at the same time.  Where the eyes are placed decides how a bird views its surroundings using different types of vision. Binocular vision means both eyes focus on the same object at the same time, and eye movement is coordinated – this is the kind of vision that predatory birds such as owls rely on most.  Monocular vision means each eye is focused on a different object at any particular moment, and this is normal for parrots and pigeons. Having different kinds of vision helps different kinds of birds survive in the wild. For parrots and pigeons, having eyes on the sides of their heads is a huge advantage. Having a wider field of vision with only a small blind spot behind them lets these birds see where they are going, while also keeping an eye out for predators which might be trying to sneak up on them.  For predatory raptors such as barn owls, having forward-facing eyes helps them to see depth and distance much more clearly, since both eyes can focus on the same object at the same time. This is perfect for spotting and catching small prey such as field mice.  So though it might seem like birds with eyes on the side of their heads can’t see where they are going, they can see forward and sideways at the same time, and in fact can see much more than those with eyes facing forwards.  Hello, curious kids! Have you got a question you’d like an expert to answer? Ask an adult to send your question to us. You can: * Email your question to curiouskids@theconversation.com 

* Tell us on Twitter by tagging @ConversationUK with the hashtag #curiouskids, or

* Message us on Facebook. Please tell us your name, age and which town or city you live in. You can send an audio recording of your question too, if you want. Send as many questions as you like! We won’t be able to answer every question, but we will do our best. More Curious Kids articles, written by academic experts: How does gravity pull things down to Earth? – Gabriel, age 4, Stewartby, UK What sea creature can attack and win over a blue whale? – Drake, age seven, Sydney, Australia What is fire? – Lyra, age seven, Oxford, UK"
"The prime minister says the Coalition is acting on emissions, meeting its targets and doing more than Labor did when in power. What’s the reality? No. National emissions peaked in 2007, the last year of the Howard government, came down each year under the Rudd and Gillard Labor governments, and have flatlined since the Coalition was elected in 2013. This graph by Nick Evershed, Guardian Australia’s data and interactive editor, sets it out clearly. (Specifically, that they are on average 50m tonnes less each year under the Coalition than Labor.) This was not correct until last year, when the government released revised historic emissions data (as explained here). Since then, Morrison’s claim is roughly accurate. But it is a meaningless statistic – a clear case of nonsense framing to mask what is happening. Labor can’t be held responsible for the historically high emissions level it inherited when it came to office, and pollution fell about 14% in the nearly six years Kevin Rudd and Julia Gillard were prime minister. The ALP can’t take all the credit for the decline. The millennium drought, the global financial crisis and a high Australian dollar all had some impact. But government policies, including the carbon price scheme introduced in partnership with the Greens and independents, had some effect. Emissions reductions stopped under the Coalition about the time the carbon price scheme was repealed in 2014. The most recent quarterly greenhouse data found rising pollution in most parts of the economy were offset by a significant fall in emissions from agriculture due to drought and floods – a shift that has nothing to do with the government. This is where we risk getting buried in numbers, but bear with me. It makes sense for governments to set emissions targets. How else to assess whether countries are playing their part in addressing a dramatically escalating global problem? But the most important initial question about a government target, before asking whether it will be met, is whether it addresses the problem faced. As far back as 1990, the Coalition went to an election under Andrew Peacock promising to cut emissions 20% by 2000. But Australia’s first target under the Kyoto protocol, the initial climate pact signed in 1997, allowed it to increase emissions by 8% above 1990 levels by the years 2008-2012. Put another way, the Howard government adopted a goal that allowed it to emit even more heat-trapping gas as part of an agreement under which developed countries were supposed to be cutting pollution. As has been well ventilated, it was no accident that 1990 was chosen as the baseline year. There was a hell of a lot of land-clearing and deforestation that year, releasing a stack of carbon dioxide. As the graph above shows, emissions plummeted after 1990, largely because land management in Queensland changed. It meant Australia had set itself a target that allowed it to not just increase pollution by 8%, but dramatically ramp up emissions from fossil fuels and other industry. As this graph shows, that’s what happened. It leaves out emissions of what is known as LULUCF (land use, land use change and forestry) – which are important, but have been used to muddy the picture – to show Australian pollution from electricity, industry, transport, agriculture and waste is up about 30% over three decades. So, yes, Australia “beat” its first Kyoto target. If it had used any year after 1991 as the baseline it wouldn’t have. And fossil fuel emissions – the primary driver of the climate crisis – have continued to rise. Australia’s 2020 target is usually described as a 5% cut below 2000 levels by 2020. As analysts and politicians have pointed out, it is neither meeting nor beating that goal. Government data shows emissions are expected to be just 0.3% lower this year than at the turn of the millennium. Again, the wonders of greenhouse accounting. As the ANU economist Stephen Howes explains, Australia’s 2020 target was expressed in more than one way. It was also listed with the UN as a 0.5% cut below 1990 emissions levels – that baseline year again – for the average of the years 2013 and 2020. Under that complicated formulation, Australia will technically beat its 2020 target. But it will still be putting the same amount of heat-trapping gas into the atmosphere this year as it was 20 years ago. Not much. The Department of the Environment and Energy projects that pollution will be only 4% lower in 2030 than today. It expects that despite assuming that, due to the falling cost of solar panels and some state-based targets, renewable energy will rise to provide 51% of electricity in the national grid by then (a level that the government opposed as damaging to the economy at last year’s election). If the department projections are correct, it means we will not have made a 5% emissions cut below 2000 levels by 2030, let alone 2020. That, despite Morrison claiming it will be met “in a canter”, the government is not on track to meet that either. Before getting to the specifics, it is worth considering what was agreed in Paris, and what it means for Australia. The headline goal of the 2015 pact was to limit global warming to “well below” 2C above pre-industrial levels and trying to keep it as close to 1.5C as possible. Scientists say that means net zero emissions by about 2050. That this is the implicit target of the Paris agreement is now broadly accepted across the engaged community. More than 70 countries say they are working towards that goal. In Australia, a coalition of groups including the Business Council of Australia, the Australian Industry Group, the National Farmers Federation and the Australian Energy Council issued a statement in December saying the country should adopting policies that put it on a path to net zero national emissions. Every state, whether run by the Coalition or Labor, has a net zero emissions goal. The Morrison government doesn’t. Asked by 3AW’s Neil Mitchell on Monday about a suggestion federal Labor would recommit to net zero emissions by 2050, the prime minister said he had “no idea what the Labor party is talking about”. Pressed further, he acknowledged the government promised at last year’s Pacific Islands Forum, where Australia faced sustained criticism from island nations for its support of the coal industry, that it would consider it. But he stressed he was concerned that “it wouldn’t be a good thing” and did not think it should be adopted unless it was clear what it would mean for jobs. Australia disregarded scientific advice in setting its initial, medium-term target under the Paris agreement. The then Abbott government was advised by the Climate Change Authority that Australia’s part under a meaningful global pact would be equivalent to a cut of between 45-63% below 2005 levels by 2030. It instead opted for a 26-28% reduction over that timeframe. Again, there was some fudging. Rather than stick with 1990 or 2000, the government opted for a baseline year that – as emissions were substantially higher in 2005 than in 2000 – made the proposed cut appear larger. If the government had stuck with 2000 as the baseline, its Paris target would be a 16-18% cut. Department data suggests national emissions are expected to instead be 16% below 2005 levels by 2030, well short of the minimum 26% goal. The government plans to make up the difference through another accounting measure: claiming credit for “beating” or, as it now describes it, “overachieving” its Kyoto targets. Using what are known as Kyoto “carryover credits” is politically and legally contentious, and opposed by many countries at climate talks. Critics say Australia is still trying to claim credit for a 30-year-old land-clearing loophole that it used against targets that were already far lower than what scientists said was necessary. Not so far. The government’s main climate policy remains the $2bn climate solutions fund, under which taxpayers pay businesses and land-owners to limit pollution, mostly by planting or protecting vegetation. Recent evidence suggests it is struggling to find people to sign up. In October, the government quietly commissioned a review of the policy in what was seen as an acknowledgement that it was not delivering what was needed. The Coalition supports some energy projects, particularly pumped hydro storage, and is promising a long-delayed electric vehicle strategy and a “technology investment roadmap”. Morrison says Australia is leading the world on renewable energy, and emissions from the electricity sector have fallen while those from other sectors increase. But spending on clean power fell 56% last year, and the government has rejected calls for an overarching policy to drive private investment. Australia is responsible for about 1.3% of pollution, but has only 0.3% of the global population. It is one of the top 20 emitting nations, releasing more than G7 members Britain, France and Italy. It is also the third biggest exporter of fossil fuels and aims to expand the trade. Several analyses have found that, even by the inadequate standard of international action to address the climate crisis, Australia is performing poorly. Science and policy body Climate Analytics says it is expected to fall even further behind because, unlike comparable countries, it has no plan to introduce an effective national emissions reduction policy."
"More than half of all Australians have been directly affected by the summer’s bushfire crisis, including millions suffering health effects, according to a new survey from the Australia Institute. As fire crews in New South Wales and Victoria prepare for the return of severe fire conditions later this week, the survey of more than 1,000 people found 57% of Australians were directly affected in some way by the fires over the past three months.  About a quarter of those surveyed (26%) reported illness or health effects as a result of smoke haze, while a third (33%) reported a change to routine – such as not jogging outside – as a result of the conditions. About 15% said they had been forced to change or cancel holiday or travel plans, while 12% said regular places of business or leisure were closed as a result of the disruption. The number of people reporting negative health impacts has been extrapolated in the nationally representative survey to represent about 5.1 million Australian adults. The number of people reporting poor health as a result of the fires was highest in NSW, where 35% of those surveyed saying they had suffered illness such as breathing or respiratory problems because of the smoke. In Victoria, the figure was 29%, but the survey was taken from 8-12 January, before the hazardous levels of smoke haze hit Melbourne the following week. With 9% of respondents saying they had missed work because of the fires or smoke, the Australia Institute is estimating that at least 1.8 million work days were lost as a result, based on the assumption of one day off for each worker affected. Using Australian Bureau of Statistics labour figures, the survey estimated disruption of the workforce to have cost more than $1.3bn in lost economic production, which it says is a “conservative” estimate. “In many areas, including in large cities, workplaces closed for many days and in some cases for a week or more,” the survey said. “If we assume an average of two days of lost production on average, the estimate of lost production doubles to $2.6bn.” The research also showed a correlation between those directly affected by the fires and concern about the impacts of climate change. People who had been impacted by the fires were much more likely to be “very concerned” about climate change (58%) than those not impacted (32%). Those directly affected were also more likely (68%) to say Australia is experiencing “a lot” of climate change impacts, compared with those not affected (42%). The findings also showed greater concern for Australia’s forests and wildlife and government inaction among this group. Only about a third of all surveyed said they believed the federal Coalition had done a “good job managing the crisis”. Tom Swann, senior researcher at the Australia Institute, said the findings underscored the extent of the “vast” social, economic and medical impacts of Australia’s “national climate disaster”. “This research suggests that, as Australians face the escalating impacts of climate change in their own lives, calls for policies that reduce carbon emissions will continue to grow,” Swann said. “Even looking simply at lost work days, the bill is in the billions of dollars. The broader impacts and recovery efforts will cost many billions more and take many years. “That is why it is so concerning that rising emissions threaten to make events like this even more common in the future.” Swann said the findings should give extra impetus to the organisation’s call for a levy on fossil fuel producers to help pay for the escalating cost of natural disasters. “Establishing a National Climate Disaster Fund would move some of the financial burden of these events from the households, businesses and taxpayers that are currently forced to pick up the tab,” he said."
"
Share this...FacebookTwitterAt the latest Saturday Summary at Weatherbell Analytics, Joe Bastardi, a well-known 40-year veteran of meteorology, looks at tornadoes and hurricanes.
Although many meteorologists and climatologists confirm that there is no data suggesting global warming is causing more frequent and intense tornado and hurricane activity, there is a small but influential alarmist group who claim otherwise. And it’s no surprise who the click-baiting media parrot at maximum volume.
Landfalling hurricanes downward trend
At the 5:45 mark, Joe presents a chart depicting the frequency of US landfalling hurricanes since 1900:

Thank you global warming!
As the chart above shows, hurricane frequency has declined while global temperatures have risen over the same period, which leads Joe to comment that we “have been fed a bill of goods by people who use the weather as weapons.”
By “people” here, he means the climate-ambulance chasing media, scientists and public figures who seize upon every weather anomaly and claim it’s a sign of manmade global warming.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Also the former veteran AccuWeather meteorologist points out that the alarmists like to forget that there was a record setting 10-year hiatus for major hurricanes striking the U.S from 2005 to 2015. Here he suggests that the warming of the past 117 years may in fact be contributing to the downward trend.
Tornado activity on the decline
Next at the 10:10 mark of the Saturday Summary, Joe looks at tornado activity. Data here as well show that tornado activity has been declining rather than picking up, which is what the climate alarm-heads like to suggest is the case:

Chart: NOAA
As the NOAA chart clearly shows, tornado activity has fallen over the past 50 years. Here as well Bastardi says we’ve “been sold a bill of goods” concerning claims that climate is making tornadoes worse.
And so far 2019 has seen below average tornado activity as well:

Image cropped from April 13, 2019 Weatherbell Saturday Summary.
Share this...FacebookTwitter "
"In my time I have seen some pretty strange things parading as art – I still vividly remember the sawn-up sharks and cows in Damien Hirst’s Sensation Exhibition.  Beauty and art I guess is in the eye of the beholder.  What I consider to be art you may well think of as a pile of rubbish, and indeed it may actually be someone’s junk. Anthropologists consider art to be a uniquely human activity in which a person produces something for the aesthetic appreciation of others.  But human motives are seldom so simple. Modern-day artists are very aware of the commercial value of their product and of the fringe benefits of being successful artists such as fame and attracting members of the opposite or same sex. Art I suspect was never just for aesthetic appreciation. This anthropologic definition of art seems to exclude the possibility that animals can be artists. For example, we might find male birds of paradise extremely beautiful but this is not art.  Bird song is often described as music and the displays of some animals are described as dance.  But do they qualify as art? Although the song of many birds is improved by practice during the animal’s lifetime it is largely innate – the animal is not composing on a blank slate. And the same seems to apply to animal dances or constructions.   The intricately designed nests of the weaverbird would seem to be a work of art but is nothing more than an evolutionary pre-programmed design – and, of course, it was designed to hold eggs not for artistic appreciation.   Our descriptions suggest artistic qualities in these animals, but the reality suggests something much simpler. The dulcet tunes of my voice may sound beautiful to some, but they are the result of my environment and not any artistic composition. There are, however, cases of artistic creation in the animal kingdom that may meet the anthropologist’s requirements for something to be considered art.  One such case is the song of the male lyrebird from central Australia.   The lyrebird does not learn its song from his father as is the case with most bird species. Instead it samples the song of birds from its habitat and puts these samples together in a continuous sequence, just as a DJ might rearrange snippets and loops of old records into a new song.   The aim of the male lyrebird is to create music that will attract females, which also seems to work for human musicians. When in captivity it has even been known for these birds to sample the sounds of human activity such as chainsaws cutting down trees or even human music played by loggers. Thus, the bird is producing non-innate “music” for the appreciation of others, in this case females of the same species. Studies have shown that most bird song cannot be considered music, innately produced or not, because it does not follow human musical scales. I personally find this a weak argument as there are a great number of musical scales used by humans. What is noise to me maybe music to you. Male bowerbirds make and decorate what is essentially a twig sculpture – bower – to impress females. Females pass by, inspecting these works of art – and the males stand in front of them hawking their artistic prowess.   Male bowerbirds use visual illusions that mess with perspective, just like the artist MC Escher. They create a courtyard of objects in front of their bower, the largest objects being placed further away creating a forced perspective that they are larger than they really are. If the female is impressed by the male’s artistic talents then she will mate with him. The theory being that great male artists possess good genes, which the female’s offspring will inherit. Once mated, the female will leave the male and head off to make her nest and rear her offspring alone. There are of course captive animal artists such as pet cats or zoo-housed chimpanzees who are provided by humans with an opportunity to express themselves artistically. They may produce works like Jackson Pollock – but this is an induced, not a spontaneous activity and it is not clear if there is any artistic intent.  Although the famous sign language chimpanzee Washoe would sometimes describe what her paintings represented. Bower and lyrebirds provide just two animal examples from the wild of work that can be considered art in light of the human definition of the subject.  Personally, I believe there are many more artists to be discovered in the animal kingdom.   But I, for one, would question this division between things that are beautiful or artistic. Surely what is important is that there is an aesthetic appreciation of them: whether they are a beautiful mountain that has been sculpted by glaciers, a sculpture made by bowerbirds or Michelangelo’s David.  Personally, I appreciate the beauty in all three of these examples because they elicit in me the same emotional response of being in awe."
"Leatherback turtles are making exhausting journeys, in some cases nearly twice as long as usual, from nesting to feeding grounds, because of rising ocean temperatures and changing sea currents. After nesting, turtles must move to cooler waters to feed, but higher temperatures mean some are having to swim further to reach suitable areas, according to research from Greenpeace and the French Institut Pluridisciplinaire Hubert Curien, part of the Centre National de la Recherche Scientifique.  The researchers tagged 10 nesting female leatherback turtles last year on the Yalimapo and Remire-Montjoly beaches of French Guiana, and then tracked their migration through the north Atlantic. Some of the turtles were found to have swum as far as Nova Scotia in north-east Canada and to France to find new feeding grounds for the jellyfish which form their main diet. Though small in scale, the research provides an insight into how some marine species are being forced to adapt to the warming oceans. This week scientists warned that ocean temperatures had reached record levels with the last five years, which were the five hottest on record. Warming oceans pose clear dangers to human life as they lead to more intense storms and rising sea levels, but the impact of the increasing frequency of heatwaves at sea on marine species is much less studied. There is evidence that some species, including commercially important fish such as cod, are migrating towards the poles in search of cooler waters, but more research is needed for a fuller picture. In another stark example of the dangers to marine life from human actions, one turtle followed was found dead on a beach in Suriname only 120km (74 miles) from the starting point, drowned after having become enmeshed in a discarded fishing net.  Estimates say more than half of all sea turtles have ingested plastic. The animals also face threats from overfishing, though they are mainly bycatch rather than targets. The beaches of French Guiana were once abundant turtle nesting grounds, but now the eggs laid there are only a small fraction of those laid 30 years ago. Last year, the complete absence of leatherback turtles from a beach in a nature reserve in Nicaragua also raised alarm. “Sea turtles survived the extinction of the dinosaurs, but they might not survive us,” said Will McCallum, a campaigner at Greenpeace. “Human activity has put such severe pressure on sea turtle populations around the world that six out of the seven species are threatened with extinction. Without urgent action the situation will only get worse.”"
"The world’s ocean contains trillions of plastic fragments coming from packaging, fishing gear and other synthetic objects that break down at sea over time.  Most of what is known about these ocean plastics comes from surface net sampling, where the top 15cm of water is filtered to collect particles larger than 0.3mm.  Now we have published the first ever high-resolution depth profiles of ocean plastics in the journal Biogeosciences and data repository Figshare. Most of the submerged plastics were very small – less than 1 mm across. Previous studies had noticed that tiny plastics were missing from the oceans. We show that at least a fraction of this missing plastic is still adrift at sea, but at depths greater than the surface layer that is usually sampled by scientists. A better characterisation of the vertical distribution of marine plastic pollution will improve predictions of plastic loads, particle sizes, and ecological impacts in the world’s oceans. Buoyant plastics can be pushed underwater by the turbulence created by wind and waves. Models predict that the number of plastic particles decreases abruptly over the first few meters of the water column. However, until now, no subsurface measurements existed to test this prediction. We developed a new device that collects samples from the sea surface at 50cm intervals, down to a depth of 5 meters. This device was used to sample one of the world’s major plastic pollution hotspots: the North Atlantic “garbage patch”. Buoyant plastics were concentrated at the sea surface, with both numerical and mass concentrations decreasing exponentially with water depth. Nevertheless, under stronger winds this decrease was less abrupt. Our results match relatively well with those predicted by scientific models. The speed in which buoyant plastics return to the sea surface after being pushed into deeper waters by turbulence is an important parameter for predicting the depth profiles of marine plastic pollution. We found that smaller plastics present lower rising speeds, being therefore more susceptible to transport into deeper layers. Even under light wind conditions, many of the tiniest plastics were still hidden underwater. This indicates that previous studies using surface-only samples are biased towards larger plastic pieces.  Two major studies last year headed by ocean scientists 
Andres Cózar and Marcus Eriksen both concluded that there are major losses of small plastics from oceans. We show that at least a fraction of this “missing” plastic is just under the sea surface. More at-sea and experimental work is required to further quantify this effect and develop models capable of estimating depth-integrated size distribution of buoyant plastics drifting at sea. Samples of ocean plastics from below the surface are still very scarce. Further multi-level sampling is extremely important to help us estimate how much plastic is actually in our oceans, and understand its ecological impacts. Knowing how deep plastics go will help determine the chance of animals inhabiting different depths to encounter and interact with plastic items. For instance, sea birds, turtles, and mammals, which breathe air and use the sea surface for daily activities, present high rates of plastic ingestion and entanglement. Ocean plastics are also enhancing ocean drift opportunities and causing damage to biota and habitats. Plastic items harbour organisms such as microbes, invertebrates and fish, which can disperse across oceans and potentially invade non-native habitats. We emphasise that estimates on the amounts and impacts of plastic pollution across the oceans, both in coastal and oceanic environments, are urgently required. Such research is crucial to better inform those aiming to reduce the flow of plastics entering this environment, and develop mitigation strategies for this worldwide problem."
"
Share this...FacebookTwitterGeographers from FAU investigating glaciers in South America in more detail than ever
If you compare historical photos of glaciers with those taken more recently, you can see that where there was formerly ice there is now very often nothing but rock. Geographers, however, are less interested in the area covered by a glacier, and more interested in its mass. Researchers from FAU have now investigated all glacial areas in South America in more detail than ever before, from the tropical areas of Venezuela to the subpolar regions of Tierra del Fuego.
Their two major findings are that the highest rate of mass loss is in the Patagonian ice sheet, and that the glaciers in the tropics have lost considerably less mass than previously projected, although this is not the good news which it might appear at first sight. The researchers’ findings have been published in the journal Nature Climate Change.*
Surveying glaciers is nothing new. There are two methods which are used particularly often. In the first method, researchers take several measurements directly at a glacier and project the results for entire regions. This is particularly problematic when it comes to large glacial areas such as the large ice fields in Patagonia, as barely any in situ measurements are available for these areas.
The other option is to take gravimetric measurements using satellites. Scientists base their measurements on the fact that gravity on Earth changes depending not only on the location but also over time. It is influenced by aspects such as the composition of the Earth’s surface, mountain ranges, movements in the core, plate movements – and, of interest for our context, when glaciers lose mass. One disadvantage of this method is that when only small areas are covered by glaciers, as is the case in the South American tropics, the satellite only receives a weak signal and the measurement is significantly less accurate.
One method for measuring all glaciers
Geographers from FAU specialising in both climatology and remote sensing and spatial information, led by Prof. Dr. Matthias Braun and Dr. Tobias Sauter, also used satellite data for surveying South American glaciers, but they focused on calculating elevation levels instead of basing their results on gravimetric measurements. Two radar satellites from the German Aerospace Center (DLR) have been orbiting the Earth since 2010. The aim of the TanDEM-X-mission was to obtain a three dimensional image of the Earth, which is not only of a consistent quality but also more accurate than anything that has gone before.
Differences in elevation were recorded down to the last metre. The researchers from FAU used data collected between 2011 and 2015 and compared them with measurements from the Shuttle Radar Topography Mission of 2000. Using a complex method which involved making various corrections and calculating possible error margins, they compared the data to calculate the changes in elevation in the glacial regions of South America, thus obtaining an accurate picture of the changes in glacial mass.
Their method was unusual in that they were able to use one uniform method to record all glacial areas in the region. In addition, the method even provided accurate data for individual glaciers. Comparing the measurements from both space missions allowed the researchers to gain detailed insights into the situation throughout South America. For the first time, researchers succeeded in analysing the large Patagonian ice fields separately from the surrounding, smaller glaciers.
Entire glaciers have vanished
The greatest loss of mass, both relatively and in comparison to the other South American glaciers, was found in both inland ice fields in Patagonia, two regions with an area of approximately 18,000 square kilometres, roughly equivalent to the Rhineland-Palatinate region in Germany.
Slower rate of mass loss in tropics


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The second important fact revealed by the research is that the mass of glaciers in the tropical regions of South America – in Venezuela, Columbia, Ecuador, Peru and Bolivia – is changing at a considerably slower rate than previously supposed. Projections to date calculated that the 2900 glaciers there were losing approximately 6 gigatonnes of mass per year. The geographers from FAU have discovered, however, that they are only losing 0.55 gigatonnes per year, approximately 10 percent of the estimates to date.
This result is important, as glaciers are an important source of water in the dry period: when no rain falls and the temperatures reach their highest level, glacier melt water is used as drinking water, for irrigation and hydro power. People in these regions therefore have to know to what extent the glaciers are changing, and need quantitative data not only with respect to area but also in terms of their volume and mass.
In some areas such as the Central Andes in Chile and Argentina or the Cordillera Real in Bolivia, experts are even of the opinion that the maximum amount of water available from glacial melt has already been exceeded. This is an indication that glaciers are irrevocably on the retreat and will vanish entirely in the foreseeable future. In future, these areas will have less water available during the dry season.
The survey, however, also revealed that some areas have hardly experienced any change at all, such as the Andes in northern Chile and Argentina as well as in southern Bolivia at the latitude of the Atacama desert.
The researchers from Erlangen now hope that their study will be included in the next report of the Intergovernmental Panel on Climate Change (IPCC). After all, melted glacier ice is contributing to the rise in sea levels and the huge ice fields in Patagonia are particularly relevant. Glaciers are also used as an indicator for climate change in other respects as well.
The geographers from FAU now want to extend their analyses to cover other regions and investigate how the situation develops over a longer period of time. At present, the global terrain model from the TanDEM-X mission is currently being updated. Researchers hope to be able to benefit from these data in future. They are also relying on further national missions which are in the pipeline such as the Tandem-L satellites, which would make it possible for such measurements to be repeated more frequently.
* https://doi.org/10.1038/s41558-018-0375-7
Further information:
Prof. Dr. Matthias Braun
Phone + 49 9131 85-22015
matthias.h.braun@fau.de
=========================================================
Hat-tip: Die kalte Sonne.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA new paper just appeared in the journal of Atmospheric Research titled: “Climate classifications from regional and global climate models: Performances for present climate estimates and expected changes in the future at high spatial resolution“.
Hat tip: Reader Mary Brown

Though the title itself reveals little about the quality of the performance of models, the study suggests that models still have a long way to go before really being useful for policymakers to go by.
The study concludes, “The modeling of precipitation remains the Achilles’ heel of models and thus of multidimensional indices, which are very sensitive to this variable.”
Well, just about every major climate index is directly related to precipitation. Thus if the models cannot get precipitation right, then everything else will also be wrong – or at least so far off the mark as to be useless.
The plea for us to worship crude models
“Nonetheless”, the authors write, “the role of models as privileged tools to advance our scientific knowledge of the Earth’s system remains undisputed.”
In other words, even though the models don’t work, and thus cannot be relied on at all by policymakers, we should still worship them!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Models as snake oil
Climate scientists have a long history of making the public think their models are pretty darn good, and that only a teeny weeny bit more tweaking is all that is needed. In reality, however, climate models are still only at the very embryonic stages of development and nowhere near suitable for performing the tasks that would make them of any use for the long term.
The climate system, which includes the atmosphere, extraterrestrial systems, tectonic activity and our great oceans, is just too poorly understood and so absolutely impossible to accurately model with any degree of certainty. There are still so many huge data holes that need to be filled.
Any scientist who claims otherwise should be put away for fraud, or in the least dismissed as an outright quack.
New data get ignored
What’s especially sad is that many of these gaping holes are gradually being filled, but unfortunately these data contradict the CO2 hypothesis of the alarmist scientists – and so they just ignore them.
The result: their models will remain a sham.
What follows is the paper’s abstract:
Climate classifications based on temperature and precipitation measurements are increasingly being used for environmental and climate change studies. Using three classification methods (Köppen, Extended Köppen, and Holdridge) and one observational dataset for present climate (CRU, Climate Research Unit), we show that GCMs have bridged the gap that led to the emergence of RCMs thirty years ago, as GCMs can now provide global climate classifications whose accuracy and precision are comparable to those of regional outputs of the RCMs. Projections of high-resolution GCMs for future climates under the assumptions of three Representative Concentration Pathways (RCP26, RCP45 and RCP85) can therefore be used as a primary source for climate change and global warming studies at high resolution. This paper provides comprehensive, model-derived climate classifications for the entire planet, using RCMs and two GCMs for present and future climate-change scenarios, and discusses how well the models actually represent the climates of the world when compared with reference, ground validation data. It turns out that both GCMs and RCMs appear still limited to provide practical estimates of the world climates even for present climate conditions. The modeling of precipitation remains the Achilles’ heel of models and thus of multidimensional indices, which are very sensitive to this variable. The conclusion is that model outputs at regional scale need to be taken with extreme caution without venturing into informing policies presenting potentially large societal impacts. Nonetheless, the role of models as privileged tools to advance our scientific knowledge of the Earth’s system remains undisputed.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn most scientific fields, hypotheses that fail to be verified by real-world observations 85% to 100% of the time are rejected immediately.
In Consensus Climate Science, when 126 of 126, 111 of 114, 42 of 49… modeled projections are wrong, or when the opposite sign of the modeled trend is observed, the climate models are still regarded as mechanistically correct, especially with regard to the CO2 climate influence.
Those who disagree are dismissed as “denialists”.


Image Source: Tabari and Willems, 2018

For 2019, the opposite-sign, contradicted-by-observations models continue to be highlighted in the scientific literature.
At what point will Consensus Climate Science actually question if the greenhouse gas forcings the models are predicated on need reconsideration?
Connolly et al., 2019
“Observed changes in Northern Hemisphere snow cover from satellite records were compared to those predicted by all available Coupled Model Intercomparison Project Phase 5 (“CMIP5”) climate models over the duration of the satellite’s records, i.e., 1967–2018. A total of 196 climate model runs were analyzed (taken from 24 climate models). Separate analyses were conducted for the annual averages and for each of the seasons (winter, spring, summer, and autumn/fall). A longer record (1922–2018) for the spring season which combines ground-based measurements with satellite measurements was also compared to the model outputs. The climate models were found to poorly explain the observed trends. While the models suggest snow cover should have steadily decreased for all four seasons, only spring and summer exhibited a long-term decrease, and the pattern of the observed decreases for these seasons was quite different from the modelled predictions. Moreover, the observed trends for autumn and winter suggest a long-term increase, although these trends were not statistically significant.”

He and Yang, 2019


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“However, three combined gridded observational datasets, four reanalysis datasets, and most of the CMIP5 models cannot capture extreme precipitation exceeding 150 mm day−1, and all underestimate extreme precipitation frequency. The observed spatial distribution of extreme precipitation exhibits two maximum centers, located over the lower-middle reach of Yangtze River basin and the deep South China region, respectively. Combined gridded observations and JRA-55 capture these two centers, but ERA-Interim, MERRA, and CFSR and almost all CMIP5 models fail to capture them. The percentage of extreme rainfall in the total rainfall amount is generally underestimated by 25%–75% in all CMIP5 models.”
Bishop et al., 2019
“Atmospheric models forced by observed SSTs and fully coupled models forced by historical anthropogenic forcing do not robustly simulate twentieth-century fall wetting in the SE-Gulf. SST-forced atmospheric models do simulate an intensified anticyclonic low-level circulation around the NASH, but the modeled intensification occurred farther west than observed. CMIP5 analyses suggest an increased likelihood of positive SE-Gulf fall precipitation trends given historical and future GHG forcing. Nevertheless, individual model simulations (both SST forced and fully coupled) only very rarely produce the observed magnitude of the SE-Gulf fall precipitation trend.”
Chung et al., 2019
“Here, by conducting a comprehensive analysis based on multiple independent observational records, including satellite observations along with a large ensemble of model simulations, we objectively determine the relative contributions of internal variability and anthropogenic warming to the emergence of long-term PWC [Pacific Walker Circulation] trends. Our analysis shows that the satellite-observed changes differ considerably from the model ensemble-mean changes, but they also indicate substantially weaker strengthening than implied by the reanalyses. Furthermore, some ensemble members are found to reproduce the observed changes in the tropical Pacific. These findings clearly reveal a dominant role of internal variability on the recent strengthening of the PWC [Pacific Walker Circulation].”
Zhang et al., 2019
“Observed Southern Ocean surface cooling and sea-ice expansion over the past several decades are inconsistent with many historical simulations from climate models. Here we show that natural multidecadal variability involving Southern Ocean convection may have contributed strongly to the observed temperature and sea-ice trends.”


Share this...FacebookTwitter "
"Coral reefs are vanishing from the world’s oceans. At least three quarters of these tropical marine habitats are severely threatened globally and in 2016 alone, the Great Barrier Reef lost up to 30% of its coral cover. But could modern technology simply create more reef? It may sound fantastical, but scientists are working on 3D printing new reef habitats to replace those lost from climate change, overfishing and pollution.  Coral reefs are important ecosystems for people in tropical countries as the sea life which lives on them is a major source of food and income. They also protect shorelines from erosion and storms.  Unfortunately, overfishing, pollution and climate change have changed how most coral reefs look and function. Corals are particularly sensitive to small increases in sea temperature and so highly vulnerable to global warming. Since the 1980s, many reefs have suffered large-scale coral die-offs as a consequence of high temperatures. When corals die, the hard structure of the reef still remains behind and can be colonised by new corals. But this process of recovery can take a long time, particularly if the environmental problems have not been effectively managed. This means there is actually plenty of existing reef structure, but much of what is left is now devoid of corals. Corals are a bit like trees in a forest – they create most of the complex structure that provides a habitat for a diverse range of species.  Most efforts to manage impacts on coral reef ecosystems have focused on establishing and setting up marine protected areas (MPAs), which are regions of the ocean where fishing and other activities are restricted or banned. At least a third of coral reefs are already inside MPAs and, if effectively managed, these provide huge benefits including protecting fish and other vulnerable species, limiting other practices that cause pollution or direct damage.  However, in some cases, even well managed and protected reefs show little recovery due to a poor supply of new corals. These arrive as small larvae carried by currents and use the reef to settle and metamorphose. Sometimes the reef surface has been reduced to rubble and is no longer stable enough to support growing corals, usually due to dynamite fishing or ship groundings. Reefs within protected areas are also not shielded from the effects of global climate change.  To address this, researchers have looked at how to restore degraded reefs, either by directly planting corals onto reefs, or more rarely, repairing or replacing parts of the reef with human-made structures. Restoring the reef’s function as a habitat for wildlife has been attempted in numerous places around the world, often with limited success and usually at very small scales of tens to hundreds of square metres. In many cases, restoration efforts fail to deliver results because the factors that caused a decline in the first place have not been adequately managed. In other cases, the reasons for restoration are not carefully thought through, making it hard to judge if a project has been successful or not.  Recently, one the largest 3D printed coral reef was deployed at a site in the Maldives, as a way of creating new reef habitat, using a new technology called Modular Artificial Reef Structures or MARS for short. MARS consist of lattices that have been 3D printed in ceramic material and designed to be deployed from small boats and pieced together by divers. The idea is that they can be used together with coral farming – where coral is cultivated for commercial purposes or reef restoration – to create new reef habitat in areas that have been degraded or where there were no corals to begin with, such as sandy bottoms.  The potential benefit of modular structures like MARS is that they don’t require heavy-duty machinery to deploy (for example, cranes and barges are needed to deploy large concrete structures), so can be used in remote locations to create artificial reefs at lower cost. Another advantage is that 3D printing technology allows you to make structures that actually look like reefs and have complex structures to create a range of habitat types for fish, corals and other reef organisms. The system can also be tailored depending on the specific restoration goal in a given location. Each of the units is 3D printed and moulded, with hollow pieces filled with marine concrete and steel reinforcement to aid durability.  The surface design allows for corals to be easily transplanted using epoxy or a similar adhesive and the surface is chemically inert, so it is thought not to harm newly-attached corals and coral settlers.  Artificial reef structures such as these may create value at small scales by providing high value dive sites to tourists when natural dive sites have been degraded. They also provide a way of involving tourists and volunteers in conservation efforts if they can be engaged as volunteers to help construct reefs and transplant corals. Much of the value of reefs comes from them having live corals, for example, many tourists prefer to see living rather than dead corals. Living corals continue to build reef. So without sufficient numbers of living corals, the actual reef structure will eventually erode over time and will not grow to keep up with sea level rises. Reefs need growing, healthy corals to continue to function and protect coastlines. So merely increasing the amount of reef structure available for coral growth will not in itself solve the problem of natural reef decline.  Another big concern with using artificial structures as a restoration tool is that they are very expensive and may therefore divert funds from existing proven conservation techniques (for example, policing within marine protected areas). It should also be mentioned that artificial reefs may not necessarily have the same levels and types of biodiversity as natural reefs. The biggest problem with artificial reefs, however, is that these methods cannot be scaled up to anything like that required to counter the current degradation on reefs.  This does not mean that 3D printed reefs cannot be beneficial in coral management as any restoration activity can provide an opportunity to engage the public to learn more about the difficulties facing coral reefs. However, the only way to tackle reef decline in the long term, is to deal head on with its main causes: climate change, pollution and destructive fishing practices."
"Donald Trump told the world’s business leaders to stop listening to “prophets of doom” as he used a keynote speech at the World Economic Forum to attack the teenage activist Greta Thunberg over her climate crisis warnings. The US president hailed America’s growth record and compared campaigners against global heating with those who feared a population explosion in the 1960s and mass starvation in the 1970s. On an opening day in Switzerland dominated by the climate emergency, Thunberg scoffed at Trump’s claim that his backing for a new initiative to plant 1tn trees showed his concern for the environment. Davos is a Swiss ski resort now more famous for hosting the annual four-day conference for the World Economic Forum. For participants it is a festival of networking. Getting an invitation is a sign you have made it – and the elaborate system of badges reveals your place in the Davos hierarchy. The meeting is sponsored by a huge number of international banks and corporations. For critics, “Davos man” is shorthand for the globe-trotting elite, disconnected from their home countries after spending too much time in the club-class lounge. Others just wonder if it is all a big waste of time.  The 2020 meeting is being advertised as focusing on seven themes: Fairer economies, better business, healthy futures, future of work, tech for good, beyond geopolitics and how to save the planet. Young climate activists and school strikers from around the world will be present at the event to put pressure on world leaders over that last theme.  “Our house is still on fire. Your inaction is fuelling the flames by the hour,” Thunberg said. “And we’re asking you to act as if you love your children more than anything else.” The US president and Thunberg did not meet face to face at the WEF, but Trump left few in doubt about who he was referring to as he defended his record since entering the White House three years ago. “This is not a time for pessimism,” he said. “This is a time for optimism. To embrace the possibilities of tomorrow, we must reject the perennial prophets of doom and their predictions of the apocalypse. They are the heirs of yesterday’s foolish fortune tellers. “They want to see us do badly, but we don’t let that happen. They predicted an overpopulation crisis in the 1960s, mass starvation in the 70s, and an end of oil in the 1990s. These alarmists always demand the same thing: absolute power to dominate, transform and control every aspect of our lives. We will never let radical socialists destroy our economy, wreck our country or eradicate our liberty.” He said he was “a big believer in the environment” in a speech that ensured he was absent from Washington as impeachment hearings took place on Capitol Hill. “The environment to me is very important,” he said. He made no mention of the climate emergency but backed the plan – launched in Davos – to capture carbon by planting trees on a mass scale in the coming years. “What I want is the cleanest water and the cleanest air,” he said. Environmentalists were unimpressed by a speech in which Trump boasted that his support for the coal and oil industries meant the US was self-sufficient in energy. Thunberg said: “Planting trees is good, of course, but it’s nowhere near enough, and it cannot replace real mitigation and re-wilding nature. We don’t need to lower emissions. Emissions need to stop.” Thunberg had three demands for her Davos audience: The halt of all investment in fossil fuel exploration and extraction by companies, banks, institutions and governments. An immediate end to all fossil fuel subsidies. An immediate exit from fossil fuel investments. “We don’t want it done in 2050, 2030, or even 2021, we want it done now,” Thunberg said. “You might think we’re naive, but if you won’t do it, you must explain to your children why you’ve given up on the Paris agreement goals, and knowingly created a climate crisis,” she said. She then added that the right, the left, and the centre of politics had all failed the sustainability test. “No political ideology or economic structure has managed to tackle the climate and environmental emergency and create a cohesive and sustainable world.” Jennifer Morgan, Greenpeace’s executive director, said: “The 1tn trees initiative didn’t make up for the lack of a wider attack on the climate emergency, and Trump had failed to appreciate the scale of the crisis. “To assume you can have a great, profitable America, and happy Americans without understanding the risk to Americans from climate change is astounding. It just demonstrates the level of denial, and the capture of this government by the coal, oil and gas industries.” Trump said the American dream was back, “bigger, better and stronger” than before, adding that the benefits of growth were going primarily to low-income workers rather than the better off. Trump added that 7m jobs had been created and 12,000 factories opened during his presidency. Many of the president’s claims were rejected by the Columbia University economics professor Joseph Stiglitz. “Research shows that Trump normally tells five or six lies a day. He far exceeded that today,” he said, noting that growth had been faster under Barack Obama than it was currently under Trump, and that life expectancy had fallen every year of his presidency. Although the US economy grew far more rapidly in previous decades than it has since he was elected in November 2016, Trump said: “I’m proud to say that the US is in an economic boom, the likes of which the world has never seen before.” The main hall in Davos, together with an overspill room, were packed to hear the president, although there were some titters as he ran through a litany of boasts. “I hold up the American model as an example to the world,” Trump said, contrasting his record with that of his predecessor, Obama. The US was “thriving, flourishing and winning” unprecedentedly, he added, citing trade deals signed last week with China and Mexico-Canada as models for the 21st century. “I am looking forward to a tremendous new trade deal with the UK,” Trump said, noting that Britain had a “wonderful new prime minister” in Boris Johnson, who was keen on a deal. The president said the economic boom had happened despite the US Federal Reserve, which “raised rates too fast and cut them too slowly”."
"Ministers have been urged to step in to help families whose homes are at imminent risk of collapsing into the sea on the fastest-eroding coastline in northern Europe. Residents in the Yorkshire village of Skipsea were told this week that more than 20 homes were at risk of falling into the North Sea in the next 12 months, with hundreds vulnerable in the coming decades. Parts of the 52-mile east Yorkshire coast are disappearing much faster than forecast. Rising sea levels and more frequent storms brought on by the global climate emergency have accelerated the erosion. Councillors will this week urge ministers to treat coastal erosion as a natural catastrophe like flooding, saying that there is a lack of national guidance and funding to help tackle the issue. Jane Evison, a councillor on East Riding council, said families whose homes were at imminent risk of sliding into the sea were liable to pay the full cost of demolishing their property and for their relocation. The Department for Environment, Food and Rural Affairs (Defra) provides up to £6,000 in retrospective funding towards the cost of demolishing each property, but Evison said the total bill was at least double that. “The’ve lost their home and the legal responsibility is on them – they don’t have that sort of money,” she said. “At the moment the only funding we have available to us is from Defra [but] it doesn’t cover the cost at all, and then the council is making up the remainder of what it costs.” Evison said ministers should treat coastal erosion like flooding, where significantly larger pots of funding are made available to local authorities, homeowners and businesses to cover the bill for damage. She said: “We know sea levels are rising. It’s going to accelerate. It’s an act of nature we have no control over. We think it isn’t a special case – it’s the same as flooding – so we should be able to bid for genuine costs to help keep people safe.” A council report, due to be discussed on Wednesday, found that some parts of the picturesque Yorkshire coastline were disappearing at more than double the average speed. On one two-mile stretch south of Withernsea, near Hull, 10 metres were lost in nine months last year, compared with a yearly average of four metres. The report states: “This erosion rate is expected to increase in future due to sea level rise and more frequent storm events linked to climate change, which will put even greater pressure on both the coast and council resources. “Despite this, there remains a lack of national policy guidance and funding mechanisms for adaptive management in locations where defences cannot be constructed or maintained.” Prof Mike Elliott, who co-authored an academic report on coastal erosion, said the government was wary of “opening the floodgates” to potentially thousands of compensation claims for people living on the eroding east coast, which stretches from Bridlington to the white cliffs of Dover. A Defra spokesman said it was investing £1.2bn in coastal defences to protect 170,000 properties by 2021 and that it was working with local authorities on a £23m five-year scheme to monitor the erosion."
"
Share this...FacebookTwitterThe Post-1998 Hiatus
Plods On…Regionally

Image Source: Gan et al., 2019
North America (180-0°N, 15-60°N) has been characterized as a “major cooling center” by the authors of a new paper (Gan et al., 2019) published in Earth and Space Science.
The continent warmed from 1982-1998, but a cooling trend since 1998 has nearly wiped out all the previous warming.
Overall, there has been no significant temperature change in North America since 1982.
The warming and cooling trends, especially the daily temperature minimum (Tmin), are well-correlated (r=0.71) with the path of the Atlantic Multidecadal Oscillation (AMO) during 1950-2014, leading the authors to conclude that the temperature trends over this 32-year period are “a result of” natural changes in the AMO.

Gan et al., 2019
The Key Role of Atlantic Multidecadal Oscillation
in Minimum Temperature Over North America
During Global Warming Slowdown
“Daily Minimum temperature (Tmin) is an important variable in both global and regional climate changes, and its variability can greatly affect the ecological system. In the early 21st century, warming slowdown is seen over the North Hemisphere and North America is one of the major cooling centers.”
“In this study, we found that Tmin experienced an obvious decline in North America during warming slowdown period. Such Tmin decline is closely related to the Atlantic Multidecadal Oscillation (AMO), the correlation between the decadal components of Tmin and AMO reached 0.71 during 1950-2014.”
“According to composite analysis, the AMO on the positive (negative) phase takes two low-pressure (high-pressure) systems in the northeastern Pacific and the North Atlantic at night, accompanied by cyclonic (anticyclonic) circulations and warm (cold) advection in North America. Therefore, the analyses conclude that the Tmin decline during warming slowdown period is a result of the synchronous decrease of the AMO. The results emphasize the key role of AMO on the decadal variation of Tmin in North America.”

Image Source: Gan et al., 2019

Another new paper renews the global warming “hiatus” debate and documents a 21st century cooling trend in northern China that also effectively snuffs out the previous decades of warming for the region.

Li et al., 2019
Satellite-based regional warming
hiatus in China and its implication
“Global warming ‘stalled’ or ‘paused’ for the period 1998–2012, as claimed by the Intergovernmental Panel on Climate Change (IPCC) Fifth Assessment Report (AR5) (IPCC, 2013). However, the early drafts of IPCC AR5 have no detailed explanation for this “hiatus” since 111 of 114 climate models in the CMIP5 earth system model did not verify this phenomenon. … In 2017, after a wave of scientific publications and public debate, the climate models as reported in IPCC remain debates, including definitions of “hiatus” and datasets (Medhaug et al., 2017).”

Image Source: Li et al., 2019
“The slowdown in global warming since 1998, often termed the global warming hiatus. Reconciling the “hiatus” is a main focus in the 2013 climate change conference. Accurately characterizing the spatiotemporal trends in surface air temperature (SAT) is helps to better understand the “hiatus” during the period. This article presents a satellite-based regional warming simulation to diagnose the “hiatus” for 2001–2015 in China. Results show that the rapid warming is mainly in western and southern China, such as Yunnan (mean ± standard deviation: 0.39 ± 0.26 °C (10 yr)−1 ), Tibet (0.22 ± 0.25 °C (10 yr)−1), Taiwan (0.21 ± 0.25 °C (10 yr)−1), and Sichuan (0.19± 0.25 °C (10 yr)−1). On the contrary, there is a cooling trend by 0.29 ± 0.26 °C (10 yr)−1 in northern China during the recent 15 yr, where a warming rate about 0.38 ± 0.11 °C (10 yr)−1 happened for 1960–2000. Overall, satellite simulation shows that the warming rate is reduced to −0.02 °C (10 yr)−1. The changes in underlying surface, Earth’s orbit, solar radiation and atmospheric counter radiation (USEOSRACR) cause China’s temperature rise about 0.02 °C (10 yr)−1. A combination of greenhouse gases (GHGs) and other natural forcing (ONAT, predominately volcanic activity, and atmosphere and ocean circulation) explain another part of temperature trend by approximately −0.04 °C (10 yr)−1. We conclude that there is a regional warming hiatus, a pause or a slowdown in China, and imply that GHGs-induced warming is suppressed by ONAT [other natural forcing] in the early 21st century.”

Image Source: Li et al., 2019
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIs Greenland’s Ice Disappearing?

Image Source: AVweb, August 2018 
I. Emergency Landing In 1942
In July, 1942, a squadron of six U.S. P-38 fighter planes and two B-17 bombers embarked on a flight mission to England when they were suddenly bombarded by severe weather.
All 8 planes were consequently forced to emergency-land on the southeastern corner of the Greenland ice sheet, about 29 kilometers from the coastal edge.
While all 25 of the occupants were ultimately rescued, the 8 planes had to be abandoned atop the surface of Greenland as it existed in 1942.  Eventually the planes were buried beneath decades of ice and snow accumulation.
II. The first “Lost Squadron” plane rescued in 1992…buried under 268 feet of ice
Over the course of the next several decades, nostalgic interest in a search-and-recovery effort grew.  After all, the Lost Squadron planes were effectively new when they were abandoned and, if preserved well enough, they could potentially be restored to flying condition .
The first several attempts to locate the planes during the 1980s were unsuccessful, as the search crews had underestimated how deep beneath the surface the planes were after 40-plus years of ice sheet growth.  It ultimately took 12 tries before the first plane was spotted.
In 1988 the search crews were finally able to pinpoint the location of a P-38 that was ultimately named “Glacier Girl”.   She was buried 260 feet (79.2 meters) below the surface of the ice sheet as it existed in 1988.
By 1992 the 260-foot depth had grown to 268 feet (81.7 meters), and “Glacier Girl” was slowly (piece-by-piece) retrieved from the ice.
III. Another Lost Squadron plane was found in mid-2018…buried under 340 feet of ice
Accompanied by far less fanfare, another Lost Squadron P-38 was located in 2018 using drone technology.
This plane was found buried under another 72 feet – 21.9 meters – of ice relative to the 1992 recovery site for the first P-38 rescue (340 feet versus 268 feet).
IV. Potential implications and Greenland observations
• Greenland’s interior ice is melting more slowly now than 95% of the last 9,000 years

Image Source: MacGregor et al., 2016 and AAAS press release
• An anthropogenic influence on Greenland’s ice melt is too small to be detected

Image Source: Haine, 2016


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




• The Greenland Ice Sheet surface area is larger now than 95% of the last 8,000 years

Image Source: Briner et al., 2016

• Greenland hasn’t warmed overall since the 1920s and 1930s

Image Source: Hanna et al., 2011
“The annual whole [Greenland] ice sheet 1919–32 warming trend is 33% greater in magnitude than the 1994–2007 warming.”   (Box et al., 2009)
• Greenland ice melt has added just 1.5 cm to sea levels since 1900 – with no contribution during 1940-2000

Image Source: Fettweis et al ., 2017
• Greenland has been cooling during the last decade

“Here we quantify trends in satellite-derived land surface temperatures and modelled air temperatures, validated against observations, across the entire ice-free Greenland. … Warming trends observed from 1986–2016 across the ice-free Greenland is mainly related to warming in the 1990’s. The most recent and detailed trends based on MODIS (2001–2015) shows contrasting trends across Greenland, and if any general trend it is mostly a cooling. The MODIS dataset provides a unique detailed picture of spatiotemporally distributed changes during the last 15 years. … Figure 3 shows that on an annual basis, less than 36% of the ice-free Greenland has experienced a significant trend and, if any, a cooling is observed during the last 15 years (<0.15 °C change per year).” (Westergaard-Nielsen et al., 2018)

“For the most recent 10 years (2005 to 2015), apart from the anomalously warm year of 2010, mean annual temperatures at the Summit exhibit a slightly decreasing trend in accordance with northern North Atlantic-wide cooling.  The Summit temperatures are well correlated with southwest coastal records (Ilulissat, Kangerlussuaq, Nuuk, and Qaqortoq).” (Kobashi et al., 2017)
• Greenland was much warmer than today throughout most of the last 10,000 years

Image Source: Kobashi et al., 2017
“Greenland temperature reached the Holocene thermal maximum with the warmest decades occurring during the Holocene (2.9 °C warmer than the recent decades) at 7960 ± 30 years B.P.”  (Kobashi et al., 2017)

Image Source: McFarlin et al., 2018
Share this...FacebookTwitter "
"The search for alternative energy sources in the age of climate change has overlooked tidal energy: a vast and unexploited worldwide resource.  For three decades now, tidal lagoon schemes have been recommended as an economically and environmentally attractive alternative to tidal barrages. More recently, two proposals for tidal lagoons in Swansea Bay, Wales have emerged and there have been several reports documenting how such a project there could have the potential to harness significant energy resources.  Tidal energy involves constructing a barrage, a dam or some other sort of barrier to harvest power from the height difference between high and low tides. The power is generated by running the water through turbines, found within the barrier. The technology used is very similar to that found in hydropower schemes, however unlike rivers tidal currents run in two directions. Where a tidal barrage blocks off an entire estuary, a tidal lagoon instead impounds an artificially created area of the sea or estuary. A lagoon doesn’t necessarily have to be connected to the shore – it could even sit out in the ocean.  As the tide goes out the lagoon remains closed, and full. It then opens the flood gates to let the water out until water levels on each side of the lagoon wall are even. When the tide comes in the process is reversed.  It’s tough to estimate exactly how much tidal power can be exploited, but the UK may have close to half of Europe’s total. And few potential sites worldwide are as close to electricity users and the transmission grid as those in the UK.  Swansea Bay is located in the Bristol Channel on the South Wales coastline. As part of the Severn Estuary it experiences one of the world’s largest tidal ranges, often reaching 10m.  A tidal lagoon has been mooted in the bay before, back in 2004, but the latest proposals are on a grander scale. The structure shown below would cover 11.5 km2, cost £913m to construct, and would be capable of generating 495 GWh per year – enough energy to power 155,000 homes. The Swansea Bay scheme demonstrates a renewed interest in tidal power, which has many advantages compared to other renewable sources. It is well documented that increasing integration of volatile, unpredictable sources of renewable energy such as wind and solar power jeopardises the stability of the power grid. In order for the grid to remain stable the power generated at any instance has to match demand, therefore it is important that the transmission network contains power sources that are immediately available. While the sun may stop shining, and the wind can drop, the tides remain predictable – an obvious advantage for tidal power and a great help for National Grid forecasters. Yet improvements are still needed. The upfront costs remain high, and there are some ecological implications. Experiences with artificially closed compounds have demonstrated that the costs of managing an artificial tidal basin (for example in the case of La Rance, Brittany, and Cardiff Bay), Wales are high and need careful monitoring and planning.  Turbines can become more efficient, perhaps learning from the wind industry about aspects such as varying the speed of turbines. We need to develop better 3D modelling to get a better sense of how the tides ebb and flow, and how turbines perform under turbulence. But there are important positives that should lead to more tidal power. The re-opening of dams and barriers, often built between the 1950s and 1970s can have great ecological benefits for the water bodies behind them due to a creation of a gradient that is beneficial to aquatic ecology (brackish water) and an increased oxygen content; in such instances, tidal technology can also be used as a tool for water quantity management, while generating power.  They can actually improve some ecosystems and have additional societal benefits besides renewable energy such as flood defence, environmental and ecological water quality improvement, fisheries and even tourism functions.  New technologies are being developed that would allow energy to be harvested from new areas, where the difference between high and low tides are measured in centimetres rather than metres. All this make an investment in a tidal lagoon for Swansea Bay seem like a strong investment in the future."
"A video recently doing the rounds on Facebook included a segment from the BBC comedy quiz show QI. The video asks which of avocados, almonds, melon, kiwi or butternut squash are suitable for vegans. The answer, at least according to QI, is none of them.  Commercial farming of those vegetables, at least in some parts of the world, often involves migratory beekeeping. In places such as California, there are not enough local bees or other pollinating insects to pollinate the massive almond orchards. Bee hives are transported on the back of large trucks between farms – they might go from almond orchards in one part of the US then on to avocado orchards in another, and later to sunflower fields in time for summer. Vegans avoid animal products. For strict vegans this means avoiding honey because of the exploitation of bees. That seems to imply that vegans should also avoid vegetables like avocados that involve exploiting bees in their production. Is that right? Should vegans forego their avocado on toast? The revelation that avocados might not be “vegan-friendly” could seem to be a reductio ad absurdum of the ethical vegan argument. Some people might point to this and claim that those who are vegan but still consume avocados (or almonds and the like) are hypocrites. Alternatively, this sort of news might lead some people to throw up their hands at the impossibility of living a truly vegan diet, and so to give up. Pass me the foie gras someone … However, one initial defence for vegans is that this is only a problem for certain vegetables that are produced commercially on a large scale and which are dependent on migratory beekeeping. In places such as the UK, this practice is still (as far as I can tell) uncommon. Locally sourced butternut squash would probably be fine (although you could never guarantee a bee kept in a hive hadn’t pollinated a crop), while avocados and almonds (including most almond milk) sourced from California might be a problem. Another answer might depend on someone’s view about the moral status of insects. Commercial beekeeping may injure or kill bees. Transporting bees to pollinate crops appears to negatively affect their health and lifespan. But some may question whether bees are capable of suffering in the same way as animals, while others may wonder whether bees are self-aware – whether they have a desire to continue to live. If they do not, some philosophers argue that they would not be harmed by being killed (others, such as Gary Francione, would beg to differ).  The more important general response is that whether or not migratory beekeeping is a problem depends on your ethical rationale for being vegan. Some vegans have a non-consequentialist justification for being vegan – they wish to avoid acting immorally through their diet. This could be based on something like the Kantian rule of avoiding using another sentient being as a means to an end. Or they may have a rights-based view, according to which animals (including bees) are rights holders. Any amount of rights violation is wrong under this view – it is simply not ethically permissible to use bees as slaves. Other vegans choose not to eat meat or other animal products for consequentialist reasons – they wish to minimise animal suffering and killing. This ethical argument might also have trouble with migratory beekeeping. While the amount of suffering experienced by an individual bee is probably small, this would be magnified by the very large number of insects potentially affected (31 billion honeybees in the Californian almond orchards alone). A vegan who chooses to eat almonds or avocados is not doing what would most reduce animal suffering. However, a different, (perhaps more practical) ethical rationale that might underlie a decision to go vegan is the wish to reduce the animal suffering and killing  and environmental impact involved in food production. Migratory beekeeping also has negative environmental effects, for example, through the spread of disease and effect on native honeybee populations  Taking this view, dietary choices that reduce animal exploitation are still valuable even if some animal exploitation would still occur. After all, there is a need to draw a line somewhere. When we make choices about our diet, we a need to balance the effort we expend against the impact on our daily life. The same applies when we make choices about how much we should donate to charity, or how much effort we should make to reduce water consumption, energy use, or CO₂ emissions. One ethical theory for how resources should be distributed is sometimes called “sufficientarianism”. Briefly, it is the idea that resources should be shared out in a way that is not perfectly equal, and may not maximise happiness, but at least ensures that everyone has a basic minimum – has enough. In another area of ethics, there is sometimes discussion of the idea that the aim of parenting is not to be the perfect parent (we all fail at that), but to be a “good enough” parent. Taking a similar “sufficientarian” approach to the ethics of avoiding animal products, the aim is not to be absolutely vegan, or maximally vegan, but to be sufficiently vegan – to make as much effort as feasible to reduce harm to animals for the sake of our diet – we could call this a “vegantarian” diet. For some people this may mean choosing to avoid Californian avocados, but others may find their personal ethical balance at a different point. What is more, accepting and embracing all these variations may provide room for more people to adopt or sustain a vegan lifestyle.  Pass me the avo on toast, someone."
"Would the prime minister rule out protecting Australians from terrorism if it cost a single job? Would he promise that no nurse, teacher or other public servant would be sacked in pursuit of a budget surplus? Of course not. But when it comes to preventing dangerous climate change, the government whose policies closed the entire Australian car industry claims that every job is sacred. Yeah, right. The one thing we can say with certainty about the coal industry is that, regardless of climate policy, automation will decimate coal communities in the coming decade. The coal companies sacked around half their workforce in the late 80s – the minute new technology let them – and the coal industry is gearing up to do it again. Adani promised its proposed Queensland coalmine would be automated “from pit to port” and the rest of the industry is publicly preparing for the same goal.  But while #ScottyFromMarketing loves to position himself as defending coal workers from climate activists, he is strategically silent when it comes to protecting those same coal workers from the ravages of automation. If the Coalition wanted to protect the jobs of those who currently work in the coal industry, they would ban the introduction of robot-driven trucks and trains in existing mines and ban the construction of new, highly automated mines in regions that have never mined coal. But they won’t, because supporting the coal industry has nothing to do with protecting the jobs of existing coal workers. Coal is about symbolism and the symbiotic relationship between the Coalition and the coal industry. Fresh from doing nothing to prepare for the worst bushfires Australia has ever seen, Scott Morrison’s latest inactivity revolves around doing nothing to prevent our already changed climate from heatingup even more. Now that pretending there’s doubt about the science of climate change doesn’t cut it, our spin-doctor-in-chief has moved on to feigning concern with the economy as his latest excuse for climate inaction. The prime minister is under mounting pressure to match the net-zero emission targets for 2050 that’s supported by all Australian states (including New South Wales, Tasmania and South Australia, with Liberal governments). And while he might not hold a hose when the bushfires are raging, there’s no doubt Morrison knows how to put a fire hose on his colleagues. Step one is, of course, to shoot the messenger. While it’s usually scientists or environmentalists that cop abuse for speaking up against the federal government’s love affair with coal, Morrison didn’t miss a beat when he set out to mock and belittle the NSW environment minister, Matt Kean. Practice makes perfect. Step two is to pull out the straw man. Shutting the coal industry down overnight would be reckless and cause lots of pain for no real gain. The fact that no one, ever, has called for the shutdown of the coal industry overnight makes it a particularly hard fight to lose. But it distracts journalists for just long enough to move things along to step 3. Econobabble. If we know one thing about the economy it’s that it changes so frequently and so unexpectedly that it is literally impossible to predict. But even though no economist can accurately predict what the exchange rate or unemployment rate will be in three years’ time, Australian governments have become expert in worrying about what the economy will look like in 30 years’ time. It doesn’t matter whether it’s tax cuts, penalty rate cuts or climate policy. Australian politicians love to talk in detail about what the impact of their policies will be in 30 years’ time, rather than talk at all about the problems they are ignoring today. Peter Costello started it with his ridiculous fear campaign about “the costs of ageing”, but the Coalition, under Abbott and Morrison, plumbed new depths with their fear campaign aimed at anyone trying to save the planet. Saying that you accept the science of climate change but think preventing it is a bit expensive is like saying you accept the science of immunisation but then decide to only inoculate one of your three kids. Climate science told us long ago that our bushfires, hail storms, floods and cyclones were going to get a lot worse if we kept burning so much coal, oil and gas. Economics has told us all along that prevention is cheaper than cure, and that the removal of fossil fuel subsidies and the introduction of a carbon price would be good for the overall economy, good for the budget and good for the climate. But just as we replaced real science with climate denial, we have replaced real economics with dodgy forecasts and bizarre criteria like protecting every coal job for the next 30 years. Less than a year ago, Morrison promised the budget would be in surplus, wage growth would pick up and the economy would grow strongly. They were wrong about these things, not because they are stupid, but because no one knows what will happen to the economy in a year’s time – let alone in decades to come. Which brings me back to that fire hose Morrison is trying to put on his Liberal colleagues who believe it makes more sense to try and prevent climate change than to use a term in government blaming others for it. When pushed on setting more ambitious emission reduction target, Morrison mounted his high horse to declare: “What troubles me is that there are plenty of people at the moment who will go out and make a glib promise about that and they can’t look Australians in the eye and tell them what it will mean for their electricity prices, what it will mean for their jobs.” Whether because of privatisation, outsourcing, offshoring, technological change, policy change or just plain bad luck, we should always be generous in helping people when they’re forced to make a new start. But promising that our country won’t tackle climate change unless every single coal worker’s job is safe is not generous. It’s a cruel hoax designed to conceal climate inaction. No one job is worth saving at the expense of dangerous climate change. Not even Scott Morrison’s. • Richard Denniss is chief economist at the Australia Institute"
nan
"
Share this...FacebookTwitterSome critics have slammed Germany’s decision to exit coal power by the year 2038. For example the Wall Street Journal here called Germany’s energy policy “the world’s dumbest” (it is).
Yet, we need to remind ourselves that many in Germany had been calling for an exit within 10 years, or even sooner. For political leaders, however, shutting down what today is still Germany’s backbone of power supply so quickly would mean economic and political suicide. So the decision to push everything off to 2038 was yet again the German government punting the ball down the field, and leaving the messy issue to the next generation of leaders.
The government is not taking action; it’s avoiding it.
Keep in mind that a lot can happen between now and 2038. It’s entirely reasonable to expect that other forms of cleaner energy sources will be developed – 20 years is a long time. And climate can change rapidly, as a number of scientists are warning of cooling ahead.
Under the bottom line, it’s comforting that the Germans have given themselves the extra time, especially amid so many claiming that green technology is already available. Obviously it really isn’t.
World Future Council sees more coal burning
Even hardcore green energy groups are realizing they’ve been had and are beginning to voice their dissatisfaction with the new government-set 2038 coal exit target, for example the Hamburg-based, planet-rescuing World Future Council, Because of the deal, it expects coal CO2 emissions to climb by 16%!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




What follows is their recent press release (my emphasis added):
===============================================
Despite capacity reductions, coal-fired power generation and CO2 emissions can increase by up to 16 percent
Hamburg, February 7, 2019 – Dr. Matthias Kroll, Chief Economist of the Hamburg-based World Future Council, has recalculated the effects of the so-called “coal compromise” on the climate, with the result that coal-fired power generation could even increase by 2030 despite capacity reductions. The reason for this is the increase in the base load on the remaining coal-fired power plants due to the nuclear phase-out.
“The improvements suggested in the coal compromise for climate protection on the way to the 1.5°C target are a deceptive package,” says Kroll.  The main criticism of the coal compromise to date has been the very late phase-out date of 2038.
However, the current compromise conceals yet another problem that has been lost in the debate so far: “For climate protection, it is not decisive how much power plant capacity is shut down, but how much electricity generation with coal actually decreases,” Kroll continues. “In the current model, I see a bottom line increase in electricity production from coal of around 16 percent. The situation is similar with CO2 emissions. Germany must take its foot off the brake and significantly push ahead with the expansion of renewable energies, the associated storage systems (‘power to gas’) and the construction of new natural gas power plants. Otherwise CO2 emissions will increase and not decrease.”
Although about 12 GW of the currently existing 42 GW coal-fired power plant are to be shut down by the end of 2022, it has to be expected that the planned remaining 15 GW of lignite and stone coal each will produce more electricity and CO2 emissions than today. The reason for this is the significantly increasing utilisation of the remaining coal-fired power plants, as it must be assumed that they will take over the last 9.5 GW of nuclear base load that will be eliminated.
While coal-fired power plants today are only used very irregularly because they are increasingly being forced out of the grid by wind and photovoltaic power, they can largely run at their maximum load. In terms of figures, this will amount to an increase of up to 16 percent in coal-fired electricity and the associated CO2 emissions compared with 2018. To ensure that the essential phase-out of nuclear power does not lead to a permanent increase in coal-fired power generation, the remaining 30 GW of coal-fired power from 2022 must be further reduced rapidly.
“It is questionable how Germany intends to achieve the 1.5°C target it has contractually agreed to in the Paris Agreement if CO2 emissions from coal-fired power generation are even higher than current levels for another decade, even though the reduction to zero is necessary,” criticises Kroll.
Share this...FacebookTwitter "
"Australia’s unprecedented bushfire crisis has unfolded in waves across the spring and summer, demanding coverage across many months that has encompassed a vast geographical area and has tried to make sense of dozens of interrelated narratives, from the personal stories of individuals caught in the disaster to the devastation of wildlife, social media misinformation and the overarching relevance of the climate crisis. The key vehicle for delivering the news on the bushfires has been our daily live blog. Our first day of live coverage, incredibly, was on 10 September, months before the normal onset of the bushfire season, when fires raced through parts of northern New South Wales and southern Queensland. Since early November we have covered the fires live on 32 days, including continuously from 16 December to Christmas Eve, and again from 30 December to 11 January, often for more than 12 hours a day. But of course an event of this size and drama cannot be covered solely from the office. The logistical challenges of putting reporters and photographers into fire zones hundreds of kilometres from their Sydney or Melbourne bases have been huge. The safety of our journalists has always been our priority, but inevitably in a situation where the demands on them are extreme and communications often impaired, there have been anxious moments. We have been rewarded by extraordinary dispatches, telling the stories of places whose names have sadly become synonymous with disaster: Balmoral, Cobargo, East Gippsland. In other towns, such as Mallacoota and Malua Bay, we have been able to reconstruct the terrifying events there through the accounts of residents both in print and audio. The crisis came at what is usually the quietest news time of the year, when many staff are on leave. Many gave up their summer breaks to work long hours on our coverage. Some were themselves caught up in the fires while on holiday, able to report on a harrowing experience only when communications were restored. Reporting events on this scale has been challenging enough, but putting them in the context both of Australian domestic politics and the wider question of climate change has put even greater demands on our reporters and opinion writers. From the start we have been at pains to keep the climate crisis at the forefront of our coverage, by explaining the science and holding the government to account for its response. The photographer Chris Hopkins and I drove from Melbourne to Bairnsdale, Victoria on Monday 30 December, the day after emergency services took the unprecedented step of advising everybody in the far-east wedge of the state to get out. Under a bridge on the eastern side of Bairnsdale, next to a sign that said “no camping”, we found evacuees such as 77-year-old Marilyn Withers, whose face was red from the 43C heat. That night the temporary campground under the bridge swelled to the hundreds, including many who had fled with just the clothes on their backs and who were now sleeping in their cars. The discount department store sold out of tents that night, we were told. Many people had not intended to flee, but changed their minds when they saw the size and speed of the smoke column. It looked like a moving volcano. We watched from a pie-and-sandwich shop on the edge of town alongside Alan and Jenny Blair, who had made a last-minute decision to leave their six-hectare property at Wy Yung. While we spoke the wind was roaring in from the north-west, pushing the fire towards Wy Yung and Bairnsdale. At 5pm, the wind changed, sparing the Blairs’ home but devastating the villages of Clifton Creek, Sarsfield, and Bruthen, taking 43 houses and a school. The next morning at the official evacuation centre it was easy to spot those whose houses had been lost. They walked around white-faced, desperate to talk to someone but wary of the notebook. I made friends with the animals: 250 horses held safe in the saleyards, countless dogs, five chickens laying eggs in the back of a Landrover. Shellshocked humans who did not want to talk about how they were doing told me about how their pets were faring, and then their kids, and then finally themselves. Everyone who stayed to defend their property told us they would never do that again. I grew up in the shadow of bushfires, on the other side of the Victorian alps. When a woman told me the church where her family was buried had burned down, I told her my family’s church had burned too, in another bushfire. It feels inevitable now that if you live in Australia some part of your life will burn down. It’s just a matter of when. My first fire callout this season was to the well-heeled Sydney suburb of Turramurra in November, where no property was lost, houses were doused in the delightfully coloured pink fire retardant and some departing firefighters handed us ice creams on their way out. My most recent was to the area around Nowra, south of Sydney, and the NSW southern highlands in January, where houses were lost and fires created their own lightning storms. In between, I went to the Mount Gospers fire twice and the Green Wattle Creek fire as it hit Balmoral again and again over consecutive days. Reporting on the fires requires a lot of driving, instinct and guesswork. There is often more information in the newsroom than on the ground, and we relied a lot on firefighters, the fire and traffic apps and radio broadcasts. I also received text updates on wind and weather changes from my dad, who can read charts better than I can. We would find crews, conduct interviews, take photos and get advice about where we could see firefighting efforts without getting in the way or getting too reckless. Then we’d park the car for half an hour, file to Guardian Australia’s live blog or the news desk, and do it all again somewhere else. In Kurrajong Heights, photographer Jessica Hromas and I met a strike team waiting for a fire to come up from the gorge and into the suburbs. A firefighter told us where to park our car – facing out and with doors unlocked – and said he’d give us a radio so he could tell us when to escape. Again and again I saw the short-lived relief in people’s faces as a wind change saved their home, before they realised it meant someone else would likely lose theirs. From a personal point of view, it has been heartbreaking. The scale of the disaster, the fear and anger and sense of powerlessness on the ground is palpable, and it’s the moments that are hard to write about in the usual news style that I will remember the longest: The sound of thunder in Nowra rolling overhead from dirty brown clouds, knowing it was one of three storms generated by a nearby fire. The feeling of guilt having firefighters check on our welfare and make sure we weren’t hungry. The steely bravery on the face of a 12-year-old kid who wasn’t evacuated before the roads closed and was now helping their mum put out spot fires in the backyard. The overwhelming desire to hug interview subjects, either because they’d just gone through something horrific or they’d just done something extraordinarily selfless, and because this isn’t just a news story, this is home. There has been a lot of anger and politics swirling around Australia’s bushfires, as well as a lot of facts – some relevant, some not, and some fake. As an environment reporter, one of my main roles during the bushfire crisis has been to get into that swirling mess and come out with something that gives people a clear picture of what’s going on. So while some of my colleagues have been delivering blistering and heart-wrenching narratives from the fire grounds, I’ve been knee deep in academic papers about bushfires, and conversations about the Forest Fire Danger Index and the Indian Ocean dipole. I have been talking to ecologists to work out what the environmental impact of these fires will be – the answer is unfolding, but the experts say they’ll be amazed if we don’t see species becoming extinct. We’d had warnings this bushfire season was going to be bad – rainfall had been at record low levels in many areas, and temperatures at record highs. As the fires took hold in NSW and continued in Queensland, a blame game emerged. These fires had little to do with the climate crisis, some were saying, but were down to “greenies” and their “policies” to stop hazard-reduction burning in forests and national parks. Australia has plenty of academic expertise on bushfires because it’s part of our lived experience. One of the first people I spoke to, Prof Ross Bradstock, gave an almighty sigh when I called him up to ask if this really was all the fault of the Greens. This was “conspiracy stuff”, he said, an accusation that almost always came up after major bushfires. I later took a further look at hazard-reduction techniques and their limitations. I tried never to leave the climate question unanswered. I’ve spoken to I don’t know how many experts in their field over the last few months. I’ve disturbed conservationists and scientists on their holidays. One ecologist on Kangaroo Island was telling me what was going on while she and her children evacuated her house from the threat of a fire. The climate crisis comes up in every conversation. "
"It’s the most famous taxi in the world and a British icon, rivalling the Queen and red pillar boxes for global recognition. Now there’s a battle to make London’s black cabs greener. Geely, the Chinese automaker that owns the London Taxi Company, is investing £250m in a zero-emission capable version of the world-famous black cab to be built in Coventry. British firm Metrocab based in nearby Tamworth has also developed an eco-friendly version of the London cab. Meanwhile Shenzen-based BYD has signed a deal to provide electric cars for London chauffeuring firm Thriev. It’s no surprise these innovations are happening in London as the city has taken increasingly aggressive steps to combat poor air quality. Since 2008 London has hosted one of the largest low emission zones (LEZ) in the world and an ultra-low emission zone (ULEZ) has now been announced that will come into force in central London in 2020, with proposed regulations on new taxi purchases as early as 2018. On the face of it, electric vehicles (EVs) are the perfect fit for taxis. Taxi firms differ from private consumers as the vehicles can be in almost continuous use, so running and operational costs are much more important than initial purchase price. Wherever electricity is significantly cheaper than petrol, cab companies are able to absorb the higher costs of EVs. Research by Coventry University on small car fleets supports the evidence from a growing number of EV taxi firms that higher levels of vehicle usage can quickly translate into savings. Electric vehicles are also more reliable than their conventionally fuelled equivalents as EVs have fewer moving parts – which is a big advantage when temporarily losing a cab means an immediate loss of revenue. Low or zero tailpipe emissions may not always be a big draw for individual passengers, but they can be enough to win corporate and government clients keen to burnish their environmental credentials. Finally, larger firms can enter the electric vehicle market on a trial basis, supplementing their fleet without the risk of disruption that individual buyers might experience if going electric proves to be not to their liking. Yet technical challenges remain. Taxis aren’t public transport. They don’t follow set routes, might not own their own specialist infrastructure and are less likely to have set idling times. As such, limited range, charging time and availability are all more significant impediments for cab firms. The new model proposed by the London Taxi Company would overcome this challenge by operating a hybrid engine capable of running on electricity in the ultra-low emissions zone and petrol outside it. Metrocab’s solution is to use a petrol range extender to boost battery life. At the same time, firms such as Thriev have sought to roll out their own charging infrastructure to reduce charge times down to half an hour. Yet clearly doubts linger – and it is telling that while Nissan decided to suspend its petrol-based version of the black cab (also assembled in the West Midlands) in light of the ULEZ announcement, they have not announced plans to introduce an electric version. As David Bailey at Aston Business School observes, the current market leader in electric vehicles appears to be adopting a wait-and-see approach, to see how the market develops. After all there is still quite a bit of scope for change – and by 2018 a range of hydrogen fuel cell vehicles will provide a faster fuelling, if more expensive, alternative. These concerns are real, but so are the opportunities for manufacturers. London’s ultra-low emissions zone announcement represents the next step in a trend towards city-level polluter-pays policies. Europe already has well over 100 low emission zones. Paris, for instance, already operates a very visible electric vehicle sharing scheme and a ban of diesel vehicles has been mooted for 2020. In Beijing, new emission limits are being considered, while an entire zero-emission city is being built in Dongtan, an island near Shanghai.  Global warming may be low on the priority list for national governments, but for city authorities the impact of emission on air quality is often an immediate and pressing concern. Manufacturers that are able to make a success of the London ULEZ  may find a queue of emerging-market megacities considering similar regulations. In this context, it is no coincidence that two Chinese car-makers are leading the race. Electric taxis are more common in Chinese cities, in large part due to the high costs of liquefied natural gas as an alternative fuel. Chinese automakers have also struggled to establish their brands in Europe and America, but in the taxi market they are more able to compete on specifications.  Geely’s investment in LTC could be a masterstroke. In one leap, Geely acquires a globally recognised design icon, a relatively protected launch market in the form of the London black cab trade and access to significant research and development resources in the West Midlands. Geely already produces a version of the London cab in Shanghai and has a stated interest in pushing exports for the updated electric model. All of which is good news for the UK. The ultra-low emissions zone both improves health in the capital and injects life into the emerging electric taxi sector where the country has historic design advantages. This demonstrates the strength of coupling forward-looking environmental policies with regional R&D investments in niche sectors. Whether or not this outcome is design or a happy coincidence will surely not trouble the prime minister as he touts the deal on the campaign trail."
"Conflict between humans and elephants has reached a crisis point in Kenya. As the elephants have begun to regularly raid farms in search of food, it has become not uncommon for local people to attack and kill them in retaliation. Between 2013 and 2016, 1,700 crop raiding incidents, 40 human deaths and 300 injuries caused by wildlife were reported in the Kajiado district alone.  The problem has come as vast parts of Kenya that are home to elephants have been subject to intensive agricultural development in the past few decades. The Maasai people who tend to the land are switching from their traditional nomadic lifestyle to seek a more permanent livelihood. But these lands have also been used by elephants and other wildlife for many generations, providing them with food, water and space for migration.   Tensions are running high, but a controversial solution is being put in place: electrified fencing.  In the 2016 Netflix documentary The Ivory Game, filmed in Kenya’s Kajiado district, the following exchange was caught on camera, between a group of Maasai people and Craig Millar, head of security at non-profit conservation foundation Big Life: Farmer 1: You see this maize? It is for my children, not for elephants … we don’t want to see elephants on our farms. Millar: And what do you think is the solution? Farmer 1: The solution is to kill them!  Farmer 2: A fence. Electrification. Millar: I agree, but … it is expensive. We will ask countries in Europe for help … everybody will have to contribute something. You will have to protect the fence once it is erected. Farmer 1: We’ll take care of it. If you are lying about the fence, the elephants will be in danger. The elephants will die. When the documentary was filmed, an electrified fence was believed to be the only solution to the conflict. So, with support from international investors, work in the borderlands between Kenya and Tanzania was started in 2016 and the foundation has reported that the 50km of fence built to date has already reduced elephant crop raids by more than 90%.  Unfortunately, this is not the only human-elephant conflict hotspot in the country. Kenya is experiencing rapid economic and industrial growth, and small-scale agriculture developments are spreading across Maasai lands, causing more and more problems. Fencing is one of the most commonly used conservation tools in the world. And Big Life’s electrified fence is a great example of how fast and effective it can be. But fencing can have long-term consequences for animals – it can disturb wildlife migration routes, disrupt gene transfer through mating and alter population dynamics.  The possible costs to animals are unknown. South Africa is the only African country that legally requires an environmental impact assessment to be done prior to building fences. Generally speaking, there is no straightforward international policy or legal guidelines for fence planning. In most countries, fences are built in a random and uncontrolled way. But fencing can be an effective tool for conservation – in Australia, fencing is commonly used to save native mammals from introduced carnivores, while in Namibia fencing protects cattle from cheetahs and lions.  In our recently published paper we looked at how an electrified fence being built around crop fields in southern Kenya is affecting major elephant migration pathways. We used GPS collars on 12 elephants from the area where the fence was to be built, and tracked their movement and behaviour. All the elephants were from different families and were collared in various locations.  After two years of data collection we used the information to map where and how the elephants spent their time in the study area. We reconstructed their movement paths and built a connectivity model, highlighting the most important migration routes between large national parks.  After validating our model, we included the fence plan and recalculated, to estimate if the fence would change the elephants’ free movement between parks. The results showed that local managers were right: fencing did not disturb migration corridors nor diminish connectivity between the national parks.  But more detailed examination gave us some food for thought. Areas with limited amounts of the resources that elephants need (wetlands, floodplains and conservancies) are predicted to be more intensively used after fencing because the elephants will no longer have access to their usual grounds – and this may lead to overgrazing and habitat destruction. In addition, fences will not stop elephants from moving – so the conflict will basically be shifted to unfenced areas. These results raise a reasonable question: how much more land will have to be fenced to resolve human-wildlife conflicts? Besides high costs and difficulties in maintenance, the more land is fenced the less habitat remains for elephants. Long-term aerial monitoring in the Amboseli Ecosystem (an 5,700km² conservation area near the Tanzania-Kenya border) confirms that habitat loss to agriculture will become a bigger threat to elephants than illegal poaching in the near future. There is no simple solution here. The benefits of electrified fencing are undeniable, but lack of understanding of the long-term consequences for wildlife is worrying. We recommend that integrated impact assessments – as we did during our study – are made prior to fencing become international policy.  Another approach could be using fences only as a temporary tool for mitigating critical conflicts and considering alternative management approaches – such as fencing which contains beehives, to deter elephants but not restrict their movement – to solve the problem in the long run."
"Three thousand litres of water – that is the amount needed to produce the food each British person eats every day. This is according to a new study into the “water footprint” of diets in Western Europe, conducted by the European Commission and published in Nature Sustainability. The term “carbon footprint”, which accounts for all the emissions of CO₂ associated with the manufacture or production of an item, has become commonplace in recent years. Similarly, the “water footprint” of food can be calculated using information on the amount of water required during cultivation and processing.  The authors of this new study, led by EC scientist Davy Vanham, first gathered existing data on the water footprint of various foods and drinks. They then combined this with census information for regions within the UK, France and Germany, and knowledge of local eating habits, to calculate how much water is used to feed people in each region and how that could be reduced. Considering the record-breaking heatwave and drought across Europe in summer 2018, their insight may have arrived just in time. Of the three countries studied, the UK has the smallest average water footprint at 2,757 litres per person per day, in Germany the average is 2,929 and in France it’s 3,861 (for reference, people in the US use more than 9,000 litres per day). One of the standout reasons for the difference between these countries is that the French drink more wine, compared to the Germans and the British who prefer beer, which has a smaller water footprint.  Another feature of this study is the focus on smaller regions which reveals large differences within these countries. A common theme is that rural areas have higher water footprints than cities, mainly due to differences in diet. People in London, for example, eat less red meat than other regions. This is why the UK’s highest footprints (still less than France’s smallest footprint) are found in the south-west, North Yorkshire and Lincolnshire.  In Germany and France this trend manifests as a distinct north-south divide, with the French wine growing regions in the south-west using up to 5,000 litres per person per day. According to the study, another cause of differences within each country is the make up of regional populations. In London, the amount of wine consumed is closely related to the level of education of residents. In other words, water footprint increases with education. But what does all this mean? Well, 3,000 litres a day adds up to more than a million litres per year – or enough water to fill your local swimming pool three times over. More importantly, a higher water footprint is associated with an unhealthy diet, largely due to meat requiring a lot more water than vegetables or fruit. In all three countries, people “eat too much sugar, oils and fats, (red) meat as well as milk and cheese combined,” write Vanham and colleagues, and in France and Germany “people do not eat enough fruit and vegetables.” Eating less meat through adopting a “healthy meat” diet could reduce water footprint by up to 35%, the authors say. An even greater saving can be made if meat is replaced by fish, lowering water footprint by 55%, but interestingly moving completely to a vegetarian diet makes around the same savings. Making such changes will not only save water, but will have the additional benefit of improving diet in countries where more than a third of people are overweight and around a quarter obese. Convincing people to make such a change to their eating habits will not be simple. A number of suggestions are put forward in the study, including punitive measures for “unhealthy” foods, such as a sugar tax. However, such approaches are controversial, with considerable evidence suggesting that they are harmful to low income families. A more subtle approach would be to change the layout of supermarkets, “nudging” shoppers towards more healthy purchases.  Finally, the authors acknowledge that education of the population in dietary matters will be key. But, as their own analysis shows, more education is associated with higher wine consumption, which increases the water footprint."
"African elephants are in serious danger. The magnificent creatures are found in 37 countries – and most of these populations are threatened by poaching. The problem is that protecting elephants isn’t cheap and conservationists struggle to fund their work.  In Africa, budgets are tight and governments have bigger priorities such as funding health and education. At an international level public sympathy for elephants rarely translates into cash, so donor funding is normally short-term and unpredictable. This is why many African governments stockpiled ivory that was confiscated from poachers or came from elephants that died of natural causes before selling their ivory legally and using the money to pay for conservation work. This last happened in 2008 but several African countries are stockpiling more of their ivory for the future. Many countries outside Africa – prominent among them China – have markets for antique and legally stockpiled ivory. So the sale of ivory can provide a reliable source of funding for elephant conservation. But outside Africa this trade is often passionately opposed. This partly comes from lack of awareness – many people think all ivory comes from poaching, whereas some comes from elephant deaths and herd conservation and management. Many people are also uneasy about the idea of making money from wildlife and are particularly uncomfortable when it involves animals as majestic as elephants. This is one reason why in the last year several countries have destroyed their ivory stockpiles in the hope it will discourage trade and reduce poaching. In contrast, countries such as Botswana and South Africa, which have large and growing elephant populations, continue to store theirs. A more specific issue has come to light, however. We now have good evidence that the trade is being undermined by corruption. Poached ivory is being laundered as legal ivory and park staff, customs officials and politicians have been implicated. Some conservationists argue this corruption can’t be tackled and have called for a complete trade ban. The fact that people are exposing these examples of corruption is a great step forward. This is because conservationists are generally wary of publicising the problem. However, together with colleagues, I recently argued that we should not single out the ivory trade. Corruption could be undermining every aspect of elephant conservation and we have no evidence that this trade is more affected. Successful elephant conservation is based on funding park management, enforcing laws and sharing benefits with local people. All of these can be undermined by bribery, cronyism and embezzlement. This is illustrated by a 2010 study that looked at how well African national parks protected their wildlife. It showed that all animals are in decline in the more corrupt countries, including lower-profile species such as antelopes and zebras. This suggests elephant numbers would be dropping anyway in these countries, independent of international wildlife trade policy. Fortunately, evidence from business and anti-poverty projects does show that corruption can be tackled. An important first step is breaking up the problem into specific issues, such as embezzlement of national park budgets or bribery of police to turn a blind eye to poaching. This makes the task less daunting, changing the idea that corruption is a huge, unsolvable problem. Many of these problems can then be reduced by adopting good business practice. These include commonsense actions such as checking project bank accounts and sacking rule-breakers. Another approach is to focus on where conservation groups have the most influence. Police and customs officials put most of their efforts into stopping crimes against people, not animals. So it makes sense for conservationists to try and stop elephants being poached in the first place. Increasing success on the ground ensures healthy elephant populations and local people’s support for their conservation. It also tackles the problem of ivory laundering at source. All of this suggests we can tackle corruption in elephant conservation but need to change how conservationists deal with the problem. A good start would be following the example of anti-poverty groups, such as CAFOD, Tearfund and Christian Aid. They recognised that corporate bribery was stopping them achieving their goals and took action. This is why they played an active role in publicising the problem and supporting new anti-corruption initiatives, such as the recent UK Bribery Act. Just as importantly, the international community needs to consider corruption when developing elephant conservation strategies. At the moment, it takes a crisis before new policies and projects are developed. These initiatives then focus on countries with the biggest poaching problems and assume more money and stricter laws will help. But such policies actually play into the hands of corrupt officials. It is much easier to steal money in a crisis and stricter laws just create more opportunities for bribery. Burning ivory reduces the supply and could increase prices on the black market. So unless corruption is tackled, investing in elephant poaching hot-spots will be a short-term solution at best. Instead, we need projects to understand and tackle corruption. We should learn from countries with successful elephant conservation policies and give them a greater voice in international debates. Finally, we should discuss corruption more openly and use our head as well as our heart when trying to save Africa’s elephants."
"For those who long to live by the sea, the thought of gently breaking waves and waking by the beach sums up the irresistible charm of coastal life. But not, perhaps, in the Yorkshire village of Skipsea. Residents in the tiny seaside parish were warned this week that a large number of homes are at “imminent risk” of tumbling into the North Sea within 12 months because of the rapid erosion of the East Yorkshire coast.  For decades the picturesque seaside from Bridlington to Withernsea has been a haven for holidaymakers from across the country. But it is quickly becoming known for another reason: it is the fastest-eroding coastline in northern Europe. Figures published this week showed that parts of the coast were disappearing far faster than first thought. A combination of stormy weather and rising sea levels caused more than 10 metres of cliff to disappear from a 2-mile stretch of coast in just nine months last year, compared with the annual average of 4 metres. In just six months, three strips of coastline lost nearly double what they expected to lose in a year. On Green Lane, residents are on the frontline of this unwinnable war with nature. “You can get up one morning and open your curtains and you’ve lost your fence, or your garden’s gone,” said Carly Davis, 30, whose rented chalet is one of more than 20 home at imminent risk of being swallowed by the sea in the next year. Davis, not her real name, points to the half-missing fence at the foot of her garden and the wet clay cliff, freshly-exposed by the waves. All along her street, huge chunks are missing from gardens and the cliff is just 9 metres from some people’s back doors. The main road that once led to their street now ends precipitously at the cliff edge. A bright red sign warns: “Danger. Cliffs subject to coastal erosion. DO NOT PROCEED.” Davis moved into her rented home only two months ago so she could live next to her friends. Her son, 12, loves his seafront bedroom but they know it is not a forever home. “You sit here and the waves hit your window and you think: it’s getting close. You go check it for fresh soil all the time and you think: how long have I actually got left?” Looking out to sea, she mused: “It’s a monster, that thing, but then again it’s beautiful. You see the sunset and you think it’s gorgeous, then you hear the crashing waves and you think it’s a monster – it’s a destroyer.” An abandoned amusement arcade stands at the end of Davis’s street, opposite a large hole where Skipsea beach social club served seaside drinkers for 80 years before it was demolished last year. There is no longer public access to the beach, though hardy residents have been known to clamber down ladders from their gardens in summer. The erosion of Yorkshire’s soft clay coast is not a new phenomenon: about 30 villages have been lost to the sea since the Middle Ages. The steady nibbling away began about 10,000 years ago, at the end of the last ice age, but the global climate emergency has accelerated the process. Rising sea levels and more frequent volatile storms have seen huge chunks of land disappear in the past 20 years. “You would have to be Donald Trump to say climate change isn’t happening,” said David Elvidge, who will chair an East Riding council meeting next week to discuss measures to protect homeowners. “There have been occasions on certain areas of the coast where a bad storm has taken in a single night what you would expect to go in three or four years.” The average annual erosion rate remains about 2 metres a year for the whole 52-mile coastline. In Skipsea, there is anger that neighbouring towns and villages have been protected by sea defences but their parish, with its population of about 700, has not. Sea defences are decided on a cost-benefit analysis, with large urban areas and important industries prioritised over farmland and individual houses. On that basis, Skipsea must brave the waves. “There’s half a mile of land gone in 20 years,” said John Keay, 64, serving afternoon pints at the village’s newly-built social club half a mile inland. “You wouldn’t mind if they were trying to slow the erosion down but they’re not – they’re just letting it go. My argument is how far do you want it to go?” Some residents on Green Lane feel the council has not done enough to protect them from erosion or help them to move nearby. As it stands, they will also have to pay thousands of pounds towards the cost of demolishing their homes. Some have already chosen to leave but many of those who remain were too angry and upset to talk to journalists this week. One 80-year-old man, whose wife died recently, said he had lived in his seaside bungalow for 25 years and could not imagine moving. “I’m losing my home. It’s been like this for seven years. I’m at my rock’s end with it,” he said. Another woman added: “I am really furious but I don’t want to talk. They have big meetings and get some money but nothing ever comes to us.” As the tide moves towards her garden, Davis vowed to stay put for as long as she could: “The view, the community and the friends – we’re all a big family down here and we help each other. But you see people leaving and we’re getting less and less and less.”"
"
Share this...FacebookTwitterNo Reason For Panic: The Oscillating Gulf Stream
By Die kalte Sonne
(German text translated/edited by P Gosselin)

Image: NASA JPL (public domain)
The Gulf Stream provides heating for Western Europe. Some climate activists paint horror scenarios on the wall that the Gulf Stream is slowing down or even stopping due to climate change – with fatal consequences for Europe. However, other scientists see no evidence of this in the hard data. You can find more on this discussion at our DkS archive.
Today’s blog post: What’s new on the Gulf Stream?
In February 2019, Lozier et al. reported in Science that the models did not even correctly quantify the most important drives of the Gulf Stream. The dominant factor is not the Labrador Sea east of Canada, but the Arctic Ocean east of Greenland. See also report in The Daily Caller.
The Gulf Stream is apparently not as vulnerable to climate change as we thought. ScienceNews on 31 January 2019:
Climate change might not slow ocean circulation as much as thought
New findings from an international ocean observing network are calling into question the long-standing idea that global warming might slow down a big chunk of the ocean’s “conveyor belt.” The first 21 months of data from sensors moored across much of the North Atlantic are giving new insight into what controls the strength of the Atlantic Meridional Overturning Circulation, a system of currents that redistributes heat around much of the Western Hemisphere.
Researchers had thought the strength of that circulation, known by the acronym AMOC, was largely influenced by the sinking of cold freshwater in the Labrador Sea, between Greenland and Canada. And climate simulations suggest that the sea’s deepwater formation might slow as the world continues to warm — which also could slow down the entire Atlantic current system and possibly make temperatures on land in the northeastern United States and the United Kingdom plunge. That concept inspired the (otherwise unrealistic) 2004 climate apocalypse film The Day After Tomorrow.
Read more at ScienceNews
This MDR report from July 2018 also deals with fundamental problems of understanding:
Does a weak Gulf Stream deliver heat to us?
A new study is causing uproar and a lot of criticism. It deals with the Gulf Stream. So far it has been said: If it becomes weaker and possibly fails to appear at all, then it gets cold. A research team from China and the USA now claims the opposite. They say that a weakening Gulf Stream is heating up the global temperature once again.”.
Rad more at MDR.
Also see the articles on the study in Die Welt. Backers of the tough IPCC line were horrified. Alarmist site Klimareporter does not like the study at all and calls it “provocative“. Also the climate alarmist SZ daily was also dissatisfied. It is best to have the results explained directly by the authors without filtering. What follows is the accompanying press release from the University of Washington dated 18 July 2018:
Atlantic Ocean circulation is not collapsing – but as it shifts gears, global warming will reaccelerate
A huge circulation pattern in the Atlantic Ocean took a starring role in the 2004 movie “The Day After Tomorrow.” In that fictional tale the global oceanic current suddenly stops and New York City freezes over. While many aspects of the movie are unrealistic, oceanographers are concerned about the long-term stability of the Atlantic Ocean circulation, and previous studies show that it has slowed dramatically in the past decade. New research from the University of Washington and the Ocean University of China finds the slowdown is not caused by global warming but is part of regular, decades-long cycle that will affect temperatures in coming decades. The paper [Chen & Tung 2018] was published July 18 [2018] in Nature.
“Climate scientists have expected the Atlantic overturning circulation to decline long-term under global warming, but we only have direct measurements of its strength since April 2004. And the decline measured since then is 10 times larger than expected,” said corresponding author Ka-Kit Tung, a UW professor of applied mathematics with an adjunct appointment in atmospheric sciences.
“Many have focused on the fact that it’s declining very rapidly, and that if the trend continues it will go past a tipping point, bringing a catastrophe such as an ice age. It turns out that none of that is going to happen in the near future. The fast response may instead be part of a natural cycle and there are signs that the decline is already ending.”
The results have implications for surface warming. The current’s speed determines how much surface heat gets transferred to the deeper ocean, and a quicker circulation would send more heat to the deep Atlantic. If the current slows down, then it will store less heat, and Earth will be likely to see air temperatures rise more quickly than the rate since 2000.
“The global climate models can project what’s going to happen long-term if carbon dioxide increases by a certain amount, but they currently lack the capability to predict surface warming in the next few decades, which requires a knowledge of how much the excess heat trapped by greenhouse gases is being absorbed by the oceans,” Tung said.
The Atlantic Meridional Overturning Circulation, or AMOC, is a conveyor belt that brings surface water northward in the Atlantic; from there, the heavier salty water sinks and returns at depth from the Labrador and Nordic seas, near the North Pole, all the way south to the Southern Ocean. Most people are interested in what happens at the surface — the Gulf Stream and associated Atlantic currents carry warmer water north, bringing mild temperatures to Western Europe.
But the new paper argues that the most important step, from a climate perspective, is what happens next. In the North Atlantic, the saltier water from the tropics sinks almost a mile (1,500 meters). As it does, it carries heat down with it away from the surface.
Changes in the strength of the AMOC affect how much heat leaves our atmosphere. The new study uses a combination of data from Argo floats, ship-based temperature measurements, tidal records, satellite images of sea-surface height that can show bulges of warm water, and recent high-tech tracking of the AMOC itself to suggest that its strength fluctuates as part of a roughly 60- to 70-year, self-reinforcing cycle.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




When the current is faster, more of the warm, salty tropical water travels to the North Atlantic. Over years this causes more glaciers to melt, and eventually the freshwater makes the surface water lighter and less likely to sink, slowing the current.
When the AMOC is in a slow phase, the North Atlantic becomes cooler, ice melt slows, and eventually the freshwater melt source dries up and the heavier saltier water can plunge down again, which speeds up the whole circulation.
The new study argues that this current is not collapsing, but is just transitioning from its fast phase to its slower phase – and that this has implications for heating at the surface.
From 1975 to 1998, the AMOC was in a slow phase. As greenhouse gases were accumulating in the atmosphere, Earth experienced distinct warming at the surface. From about 2000 until now, the AMOC has been in its faster phase, and the increased heat plunging in the North Atlantic has been removing excess heat from the Earth’s surface and storing it deep in the ocean. “We have about one cycle of observations at depth, so we do not know if it’s periodic, but based on the surface phenomena we think it’s very likely that it’s periodic,” Tung said.
The new paper supports the authors’ previous research showing that since 2000, during which observations show a slowdown in surface warming, heat has accumulated deep in the Atlantic Ocean. The new study shows this is the same period when Atlantic overturning circulation was in its fast phase.
Recent measurements of density in the Labrador Sea suggest the cycle is beginning to shift, Tung said. That means that in coming years the AMOC will no longer be sending more of the excess heat trapped by greenhouse gases deep into the North Atlantic. “The good news is the indicators show that this slowdown of the Atlantic overturning circulation is ending, and so we shouldn’t be alarmed that this current will collapse any time soon,” Tung said. “The bad news is that surface temperatures are likely to start rising more quickly in the coming decades.”
The first author is Xianyao Chen at the Ocean University of China and Qingdao National Laboratory of Marine Science and Technology. The study was funded by the U.S. National Science Foundation, the Natural Science Foundation of China, the National Key Basic Research Program of China and a Frederic and Julia Wan Endowed Professorship.

 
Figure: The top panel shows global average surface temperature changes since 1950, with two periods of slower change and a period of rapid warming from 1975 to 2000. The lower panels show the strength of the Atlantic overturning circulation. The blue (and, on the right, purple) curve is the salinity north of 45N, an indirect measure, or proxy, for the AMOC strength. The green curve is an established proxy of AMOC.Ka-Kit Tung/University of Washington.”
Die Welt reported on July 21, 2019:
Deep temperatures have been measured in the North Atlantic since the 1940s,” reports Professor Monika Rhein of the University of Bremen. These temperatures are an indirect indication of the strength of the Gulf Stream. “These measured data show strong fluctuations, but no trend in any direction,” says the oceanographer, summing up the long series of measurements. A decrease in the Gulf Stream has therefore not yet been observed.”
The German Climate Consortium published a Brochure on the Gulf Stream in July 2018.
Thibodeau et al. 2018 2018 analyzed oxygen isotopes of foraminifera of a Northwest Atlantic sediment core and found that the attenuation of the Gulf Stream (AMOC) in the 20th century led to a Gulf Stream minimum in the 1970s. The Gulf Stream was also particularly weak during the Little Ice Age, a natural cold phase. See also report in the Daily Mail.
McCarthy et al. 2018 found that a part of the Gulf Stream variability was related to the NAO ocean cycle.
Yan et al. 2018 complained that climate models represented the strong Gulf Stream variability only in a diminished form, an important inadequacy of model simulations.
Todd et al. 2018 short-term changes of the Gulf Stream after powerful hurricanes.
Good et al. 2018:
The observed AMOC overturning has decreased from 2004–2014, but it is unclear at this stage whether this is forced or is internal variability.
Lique & Thomas 2018 warned that the Gulf Stream could change over time. Report on this at Scinexx:

North Atlantic: climate change shifts the circulation
Sinking zones of the Atlantic circulation could shift considerably
Shifted engine of circulation: Climate change could not only weaken the Atlantic circulation flow, but could also shift it, as a simulation now suggests. The large sink zones of warm water would no longer lie off Greenland, as they do today, but in the Arctic Ocean and the subtropical Atlantic. This, however, could have a strong influence on the current – and also alter the heat exchange and the buffer effect of the ocean, as the researchers report in the journal “Nature Climate Change”.
Read more at Scinexx.
Share this...FacebookTwitter "
"They are the answer to the classic quiz question: “What is the most deadly animal on earth?” By the time contestants have debated the demerits of tigers, cobras and great white sharks scores of victims of the real worst killer will have died and other people will have been infected by the diseases it spreads. The mosquito goes about its deadly business every day, moving infections around that kill hundreds of thousands of humans every year.  It increasingly seems nowhere is safe – experts have warned mosquitoes could bring malaria and dengue fever to the UK within decades. There is nothing good to be said for mosquitoes. Scientists willingly concede that their eradication would bring significant benefits for humanity with no obvious downsides. What good mosquitoes might do, mostly through sheer weight of numbers as food for other creatures or as amateurish pollinators, are roles readily filled by alternative species. As the famous and charming folk song has it: “All God’s creatures got a place in the choir”, some singing higher, some lower and some just clapping their paws. However the lyrics do not suggest that any of the choir are sneaking off for a clandestine blood meal, infecting millions of people with malaria, yellow fever, dengue fever, west Nile virus and a host of other less familiar dreads.  Even the most generous explanations of the mosquito’s place in the world is that it is here to remind us of our fall from grace. Instead of trying to invent a place for the mosquito in a supposed natural balance that is a cosy but flawed version of the natural world, perhaps it is better to see these insects as the Gothic fly in the ointment they so clearly are. The mosquito has replaced many of the old monsters and demons of earlier folklore in our imaginations.   Mosquito natural history is a perfect mixture of monstrous traits. They are associated with swamps and miasmas, those eerie and uncertain places of which humanity is wary. Even before we understood the role of these blood-sucking flies in transmitting disease, humanity had a sense that there was something carried in the filthy swampland air that brought disease and that these places were best avoided.  Swamps and fens are odd places, neither land nor water, but perfect mosquito habitat. In the UK some of the earliest surveys of ponds and wetlands in East Anglia were driven by the desire to find the mosquitoes’ lair, in the very same swamps where once saints and heroic warriors had ventured to confront fiends. Mosquitoes are also creatures of the night. The fall of darkness has always been a threat to us light-loving primates, not just at a basic biological level as our senses falter but also in religion and custom. Mosquitoes awake with the failing light, able to find their victims when we can only hear their whine.  Above all they suck blood in order to reproduce, or at least the females do, which only fuels the religious constructions of why humankind is plagued by them.  We no longer have the Saxon hero Beowulf to confront the monsters in their water lair, but instead Bill Gates has malaria and its mosquito vectors in his well resourced sights: the rational world of science and technology pitted against a blood sucking foe from the twilight. It is the classic struggle. Meantime mosquitoes have made some advances of their own. In the UK headlines warn us of a “plague”, that a “killer mosquito lurks in Britain” which will “threaten to terrorise the UK” . Malaria had been indigenous to the country since at least Roman times, notably around the coastal marshes of the Thames estuary, the same marshes from which the terrifying convict Magwitch looms at the start of Charles Dickens’ Great Expectations, in classic swamp monster style. However by the early 20th century the disease had been eradicated.   It is those same marshes that now seem to be home for a bridgehead of invasive mosquito species new to the UK, moving north from the continent. They include the Asian Tiger mosquito, a vector for west Nile virus. This mosquito is a miniature cantilevered marvel of black and white, drawn straight from the pages of a Victorian gothic fantasy. The killer swarms rising from their swamp lairs show no signs of retreat."
"It started in Sweden, where the term flygskam (flight shame) was coined in 2018 to describe the unease about flying experienced by environmentally conscious travellers. The hashtag #jagstannarpåmarken (which translates as #stayontheground) came into use around the same time, as groups sprang up to share tips. Other wealthy countries are not immune from such trends: a recent survey of 6,000 people in Germany, France, the UK and the US found 21% had cut back. Such a shift in attitudes makes it all the more disturbing that members of the current government, including the health secretary, Matt Hancock, have yet to catch up. Asked twice on the radio this week whether people should reduce the number of flights they take, the minister said they should not.  The Swedish activist Greta Thunberg has probably done more than anyone else to promote the idea that flying should, wherever possible, be avoided. In August she went to New York on a zero-emissions sailing boat. In Sweden last year, air passenger numbers fell by 5% as rail numbers went up. The German Green party (which topped 20% and doubled its seats in last year’s European elections) aims to make domestic flights obsolete. With new research showing 2019 was the second-hottest year on record on the planet’s surface, and the hottest-ever for the oceans, it is increasingly difficult to understand why any rational person would not be behind all and any measures designed to reduce carbon emissions. Evidence of the growing danger extends from the devastation caused by the Australian bushfires to this week’s report that up to 1 million seabirds were killed in less than a year by a “hot blob” in the Pacific Ocean. This context made it particularly troubling to hear a senior UK government minister, and one generally considered to be on the moderate wing of his party, blithely deny that reducing flights is a good idea. Just as bad was the fact that his remarks came only hours after the announcement of a tax holiday and review of air passenger duty as part of a rescue deal to save the regional airline Flybe. Mr Hancock’s comment that “we should use technology to reduce carbon emissions” could be dismissed as naive if it was not so irresponsible. Electric flight is in its infancy and, while there have been significant gains in fuel efficiency, zero-carbon flight remains a remote prospect. Projections of future emissions consistently expect aviation to be responsible for an increasing share of the total, although the industry complains that it is unfairly singled out given that the current figure is 2.5%. The UK, however, is a special case. Aviation is responsible for 7% of emissions now and is expected to overtake all other sources by 2050. Britons are the most frequent flyers to international destinations in the world, although a small minority are responsible for the vast majority of flights; by contrast, 48% reported in a recent government survey that they had not flown at all in the previous year. The US, meanwhile, has by far the heaviest air traffic (including domestic flights) overall, with the International Air Transport Association predicting that China will overtake it in about five years’ time – and global air traffic expected to double to around 8.2bn passengers annually by 2037. No one wants remote locations such as some of those served by Flybe to be cut off, which is why the handful of routes deemed socially necessary are exempt from European state aid rules. But ministers should promote alternatives wherever possible. Hinting at a reduction in flight taxes when rail fares are rising by 2.7% sends the wrong message. Individuals altering their habits, even in large numbers, will not avert disaster. In a sense the opposite is true: collective action by whole countries, led by governments, to push entire economies into a clean era is the answer. But “flight shame”, along with movements to restrict other carbon-intensive forms of consumption, is still a force for good. The point is not to show that you are better than other people, or to displace anxiety from the public realm into the private one. It is to show the world’s leaders, in business and politics, that we get it: life must change. • This article’s headline was amended on 18 January 2020 to better reflect the content of the article. The text was amended on 21 January to correct a reference to global air traffic potentially reaching “8.2bn flights” by 2037; the predicted figure relates to the number of air passengers, not flights."
"Images of the crumbling fabric and antiquated network of environmental services, including the mechanical ventilation and air-conditioning system in the Palace of Westminster, suggest that the building may have had its day. Yet appearances may be deceptive.  A research project that I’ve been leading since 2012 has shown that the palace is actually a highly innovative building. The striking skyline of Gothic towers and turrets is the outcome of Victorian technical achievement and architectural design, and the stack system which provided ventilation for the debating chambers for more than 90 years is one that is now being widely considered as a model for low-energy, sustainable ventilation in large public buildings.  Victorian engineers and scientists were confronted with the challenge of resolving the two parallel (and, at times, competing) agendas of a flamboyant Gothic scheme and the problem of ventilating such a large building in the days before mechanical ventilation and air conditioning.  Since Christopher Wren remodelled the interior of St Stephen’s chapel for the House of Commons in the 17th century, the issue of air quality and temperature in the debating chamber had been a major concern. Overcrowding and candle lighting made the space difficult to keep cool and adequately ventilated. A fire in 1834 gave the opportunity to rebuild the palace – and an architectural design by Charles Barry and Augustus Welby Pugin was selected in January 1836, four years before the government decided on a stack ventilation system. It was a Scottish physician, David Boswell Reid, who presented a series of diagrams outlining what he considered the ideal ventilation system. Reid’s vision was a centralised system that would serve the entire palace, in which all of the fresh air was introduced through air shafts inside the Clock and Victoria towers. The air would be supplied to the different rooms via the basement with the aid of steam-powered fans.  The towers were part of Barry’s original architectural plans, but a third tower, known as the Central Tower, was added to function as a stack through which the building’s hot air could be exhausted. The stack effect was to be enhanced by waste heat from gas and smoke fumes, at times boosted with the aid of coke fires.  Reid tested his design in a model debating chamber at his laboratory in Edinburgh and, from autumn 1836, was able test his system in two chambers built as temporary accommodation for parliament. Members were directly involved in evaluating and refining the system, which included a sophisticated climate control strategy that created individually controlled micro-climates in different parts of the chamber. After four years of experimentation, Reid was finally employed to develop the stack ventilation system for the actual palace. But applying his system to the existing architectural design posed insurmountable difficulties and in 1846 the centralised scheme was abandoned. A simpler system using local turrets was adopted instead. Reid’s responsibility for the ventilation became confined to the House of Commons – while the architect, assisted by Michael Faraday and his engineers, took on the ventilation system for the House of Lords. Between 1847 and 1860 numerous local turrets were gradually introduced across the palace to serve individual sections.  The Central Tower was reduced in size and the striking skyline of turrets that contribute to the palace’s distinctive Gothic character, evolved in response to this decentralised approach. The original drawings and sketches also illustrate that the tiered outline of the turrets fulfilled functional requirements and that the stacks had sophisticated mechanical details such as storm guards and wind-sensitive louvres. Pugin and Barry subsequently gave the exterior of these utilitarian structures the appearance of elegant Gothic spires. The general principle behind the system was simple but its day-to-day operation involved a complex process: continuous monitoring of weather conditions, indoor climate and occupation levels and user experience. This was done entirely manually in a strict operational regime.  To maintain comfortable conditions the system had to respond to changes in the weather and fluctuations in the number of MPs, but also to highly subjective factors, such as the perception of temperature, humidity or air currents that members encountered inside the debating chamber. The monitoring system involved collecting and processing user feedback, alongside measurements. During every sitting the speaker or the sergeant-at-arms reviewed feedback from MPs, passed to them by messengers and, if necessary, gave orders to make ad-hoc adjustments to the climate conditions or the ventilation rate.  Although the speaker and many members knew that it would be impossible to achieve a full consensus on comfort, dissatisfied MPs frequently put pressure on attendants and engineers by demanding adjustments. In 1852, and again in 1854, the MPs appointed a select committee to review the design and management of the ventilation.  Reid’s original system was replaced with a new system after merely two years due to sustained pressure. He was never given enough time to fully complete his system, let alone demonstrate its full capabilities.  A new system by the physician Goldsworthy Gurney was adopted and in the House of Commons revealed significant improvements in temperature and air quality, but more importantly it received approval from MPs and a similar system was adopted in the House of Lords. No fewer than ten select committees were appointed over a 90-year period to specifically coordinate continuing scientific evaluations and performance.  The House of Commons was completely destroyed by the German Luftwaffe in 1941. The last, most systematic and comprehensive scientific evaluation before this historic system was destroyed was undertaken between 1902 and 1931. This included chemical and pathological examinations of the air, physiological studies, and investigations into improving air flow. In 1944, a special select committee recommended a modern system with air conditioning to replace the original Victorian system, which it dismissed as “antiquated” and “ineffective”. The new system was instead described as the “best which modern science can devise”. On several occasions between 1941 and 1943 Winston Churchill spoke passionately that the “traditional character” of the original debating chamber should be restored, yet advocated embracing modern technical solutions for the ventilation. Over the past seven decades we have experienced yet another change of attitude, and the forthcoming refurbishment opens up the opportunity to revisit the potential of the historic system. Stack ventilation is now touted for creating sustainable systems in large public buildings. There are numerous modern examples, including UCL’s Schools of Eastern European and Slavonic Studies or Cambridge’s Department of Mathematical Sciences.  Commons speaker John Bercow recently said that refurbishment required an approach through which the “Victorian legacy can be rendered practical for contemporary representation”. Detailed studies of the performance of the historic system that I’ve carried out suggests that that past could potentially inform the current renovation in a sustainable manner."
"
Share this...FacebookTwitterAmazing: A proxy study of Laos finds natural variability in hydrometeorology, a little Ice Age, and other substantial climate changes in the pre-greenhouse gas era.
Who would have thought! (sarcasm)
Hat-tip: NTZ reader Mary Brown.


University of California Irvine researcher Jessica Wang and her team of researchers find plenty of natural climate variability in Southeast Asia over the past 2000 years and a positive correlation with solar activity. Photo credit: Jessica K. Wang.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In a recently published paper published by a team lead by Jessica Wang of the Department of Earth System Science, University of California Irvine titled: “Hydroclimatic variability in Southeast Asia over the past two millennia,” in the journal of Earth and Planetary Science Letters, Wang et al found good evidence of a positive correlation with solar activity since 1200 CE, “contrary to the findings in previous studies”.

Wang is developing high-resolution and precisely dated stalagmite stable isotope records (of C and O) to evaluate past hydroclimate variability. She and her team of researchers compare the new records with regional tree-ring records and stalagmite records from the broader Asian monsoon region to better understand regional hydroclimate dynamics.

The researchers use global climate model simulations to better understand the role external forcings (i.e., solar activity) have on precipitation variability over the last two millennia.
What follows is the paper’s abstract:
The spatiotemporal variability of the Asian Monsoon (AM) over the last two millennia has been attributed to a combination of external solar and volcanic forcing and/or internal coupled atmosphere-ocean dynamics, but the relative importance of these mechanisms remains unresolved. The present knowledge of multidecadal to centennial-scale AM variability over Mainland Southeast Asia is not well-constrained, despite substantial progress in understanding seasonal to decadal variability from tree ring records. Here we present the first high-resolution stable isotope (δ13C and δ18O) speleothem record from northern Laos spanning the Common Era (∼50 BCE to 1880 CE). The δ13C record reveals substantial centennial-scale fluctuations primarily driven by local water balance. Notably, the driest period at our site occurred from ∼1280 to 1430 CE, during the time of the Angkor droughts, supporting previous findings that this megadrought likely impacted much of Mainland Southeast Asia. In contrast, variations in stalagmite δ18O reflect changes in rainfall upstream from our study site. Interestingly, the δ18O record exhibits a positive correlation with solar activity that persists after 1200 CE, contrary to the findings in previous studies. Solar-forced climate model simulations reveal that these δ18O variations may be driven by solar-forced changes in upstream rainout over the tropical Indian Ocean, which modify the δ18O of moisture transported to our study site without necessarily affecting local rainfall amount. We conclude that future rainfall changes in Mainland Southeast Asia are likely to be superimposed on multidecadal to centennial-scale variations in background climate driven primarily by internal climate variability, whereas solar forcing may impact upstream rainout over the Indian Ocean.”

Yet another paper showing that climate variability was common over the past 2000 years without added CO2 from man.
Confirmed by 100s of studies
Alarmists may wish to dismiss these findings, but Wang’s results are in line with those of hundreds of other studies.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterLaurent Alexandre: “Greta Thunberg instrumentalized by militant extremists“
In a stinging commentary at Le Figaro here, Dr. Laurent Alexandre, surgeon-urologist, a graduate of Sciences Po, HEC and ENA, and co-founder of the Doctissimo website, asserts that teenage Nobel Prize nominee Greta Thunberg is being shamelessly exploited and “is playing into the hands of economic interests for whom climate protection is of little importance”.

Dr. Laurent Alexandre. Image: https://twitter.com/dr_l_alexandre?lang=de
The French physician blasts the instrumentalization of the special child as “irresponsible” and that “revealing her neuropsychiatric state to the media should be a crime.”
“Substitute for the Marxist dictatorship” and “liberticidal agenda” 
Laurent Alexandre first comments that “the young people who follow Greta Thunberg are the useful idiots of the green dictatorship” much in the same way Lenin called left-wing bourgeois “useful idiots of the revolution” and that the failures of all Marxist models have “left the anti-liberals in turmoil.”
He writes that ecology today serves as “the ideal instrument to propose a new utopia that is a substitute for the Marxist dictatorship”. He adds: “By exploiting the youth, we are imposing a liberticidal agenda in the name of good feelings.”
Targets reachable only possible through a green dictatorship
Alexandre comments that Thunberg and the leftists are demanding that “we reduce our energy consumption by at least to a fourth, and believes that “imposing such a step backwards can only be achieved through the green dictatorship.”
The French physician even characterizes the militant activists as the “Khmer greens” and “green ayatollahs”, and reminds readers that the measures that are demanded by the greens will likely end up leading to more CO2 emissions rather than less because they are also demanding the shut down of nuclear power. If the nuclear power plants in France were to be shut down, fossil plants would need to be on standby and spring into action on sunless, windless days.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Shamefully manipulated victim”

Alexandre implies that Greta Thunberg is unwittingly promoting “the interests of China and Russia” and that her demands would make us “highly dependent on rare metals needed for wind, solar and storage installations, of which China has a near-monopoly.”


The French urologist and book author describes Ms. Thunberg as “a shamefully manipulated victim” who needs to be protected, but adds that her radical ideas “must be attacked relentlessly”.
Criminal child abuse?

The tragedy of Greta Thunberg, Alexandre comments, is that “the child is all the more manipulable as her parents have made her disability public (which is irresponsible on their part)” and that as a doctor he believes that “revealing the neuropsychiatric state of minor children to the media should be a crime!”
He concludes:
We have known since Hans Asperger’s description of the syndrome in 1941 that Asperger’s children are sometimes brilliant but always fragile; instrumentalizing them is a moral fault.”
Movement of “deadly utopias”
Finally, Alexandre comments that following the green path will backfire because it would “aggravate global warming, increase the waste of public money, lead to a regressive green dictatorship and put us at the mercy of China and Russia. All liberal democrats, all Raymond Aron’s heirs, must combat the deadly utopias it conveys.”

 

Share this...FacebookTwitter "
"
Share this...FacebookTwitterOnline German business daily Handelsblatt here reported last month that leading German energy expert Jens Koeppen of Angela Merkel’s CDU party is calling for “drastic” permitting rules when it comes to installing wind turbines.

Wind turbine towers over German landscape. Photo: P Gosselin
The proposed rules would make a number of proposed wind projects impossible.
Currently a work group that is focused on acceptance and made up of members from the coalition parties is trying to figure out a way to get around the rapidly growing protests against more wind turbines, whose erection are deforesting and industrializing large swaths of Germany’s idyllic landscape. 
Traditional environmentalists and conservationists are livid over the environmental destruction and health risks posed by wind parks. 
Protests have become formidable, and as reported yesterday here, Germany’s expansion of wind energy has literally ground to a halt as a result and has thus angered climate protection alarmists and Big Wind lobbyists.
The Handelsblatt writes citizens are tenaciously fighting the installation of 200-meter tall turbines, even doing so in court, and explains how one CDU-politician is calling for a nationwide wind turbine setback rule based on the one used in the southern state of Bavaria.
Bavarian 10H rule has effectively stopped new wind projects


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Bavarian 10H rule forbids the installation of any wind turbine within a distance equaling 10 times the height of the turbine from any residential area. That means no 200-meter tall turbine can be built within 2 kilometers from a residential area. In Bavaria that rule has literally ended the installation of new wind turbines.
Koeppen told the Handelsblatt that “the citizens must be taken seriously” or else “no progress will be made”.
Currently there’s a wave of lawsuits challenging wind park proposals across the country.
Communities risk being surrounded and plagued
The German UBA Office of Environment, however, warns that even a distance of 1000 meters would reduce the area wind turbines by up to 50% in some places.
Citizens are also very concerned about the health impacts from infrasound generated by wind turbines, which experts claimed can have an impact 10 kilometers away.
Once peaceful communities now find themselves divided
Wind energy has not only divided the environmentalists, but also disturbed the tranquility and harmony once found in many idyllic communities across the country.
Politicians as well are divided. The conservatives in the CDU aim to assure adequate setbacks for wind parks near communities. The socialists in the SPD, on the other hand, wish to relax the rules and thus clear the way for more wind park installation near communities.
Share this...FacebookTwitter "
"The Guardian’s Leave It In the Ground campaign names and shames the Wellcome Trust and the Gates Foundation for not divesting their holdings in fossil fuel companies.  Editor Alan Rusbridger launched the project by declaring the case for the divestment of fossil fuel investment is overwhelming both on moral and financial grounds.   While this campaign and those against Harvard, Oxford, Sydney and other universities are great at generating publicity – the Wellcome Trust announced it had already sold off its £94m investment in ExxonMobil – they may be doing more harm than good.  The tactics applied harken back to the anti-apartheid boycotts of the 1960s-1980s in the hope that the campaigns will ultimately filter through to the money making parts of the fossil fuel industry. Yet none of the arguments for fossil fuel divestment appear to understand the nature and importance of ownership in modern shareholder societies.  One of the hallmarks of investing in a company is that share ownership confers the legal right of proportional ownership.  Legally, any individual holding a specific ownership share can bring issues to the company and has proportional rights to vote on all motions put to the ownership either by the board or shareholders. While corporations have to engage in conversations and negotiations with a multitude of “stakeholders”, it is only those who possess ownership rights that they are, in practice, accountable to in a fiduciary sense.  Shareholders determine the composition of the board, and the value of their investment will be influenced directly by what the board and senior management do. Those behind divestment campaigns have lost sight of the fact that investment can imply control.  Significant ownership shares, or coalitions of ownership shares, can be turned into activist voting blocks and also ensure that specific ownership interests get seats on the board.  For example, investor Dan Loeb used his fund’s position in Yahoo! to force a change of CEO while also gaining a seat on its board.  Groups such as Domini Social Investments are quite enthusiastic about their effective use of an activist investor approach to inducing corporate change.  On average they put a dozen proposals to shareholders of major corporations such as Apple, Energen and Pepsico a year, addressing issues ranging from methane emissions to political contributions and the role pesticides in the decline in the number of honeybees. Investment can influence corporate actions, which is why pension funds and institutional investors want to hold significant shares in key companies. The greater the investment, the more likely it is that the company’s management must take the viewpoint of the investor seriously, as in the Yahoo! case.  Divestment does little more on this dimension other than to turn an inside voice that can demand that a company listen into an outside voice that a company can easily ignore. Divestment does not destroy value – it simply transfers it to another set of owners who are not so morally outraged and are willing to pick up the shares set aside, at a slight bargain.  As the outraged owners are being replaced by less moral types, the likelihood that inside pressure can be brought to bear declines.  Hence, if the point of the divestment campaigners is to publicly shame the fossil fuel companies and put pressure on them to change their strategies, the campaign is doomed to fail.  Rather than the board and management having to suffer owners who are concerned about the moral direction of the company, they are now happily accountable to owners who are less likely to care about such things. Divestment campaigners seem to believe their investment goes to the company – that somehow this divestment starves the company of the ability to invest, or raises the cost of capital and debt.  In fact, buying shares does nothing to alter the cash flows available to that company for future investment.  The only time the company receives funds is when it issues new shares, and divestment will have no influence on this. Indeed, most major energy firms have not had new share offerings in decades.  Hence the conclusion that such divestment would reduce the investment capital available to fossil fuel companies has no basis in either financial reality or fact.   One response to this last general point is that while divestment will not hurt large companies, it will restrict investment in smaller fossil fuel and mining companies.  In reality this also makes no sense.   First, the groups that would divest are not so rich that they can move financial markets with their divestment alone or even in concert with others.  For example, while Harvard has lots of money in its endowment (US$36 billion) it still won’t change the price of oil or the value of oil companies. The university’s endowment pales in comparison to Bridgewater Associates (a hedge fund with US$169 billion under management) and most major pension funds and sovereign wealth funds, the majority of whom are unlikely to jump on the divestment bandwagon.  Harvard might divest, only to leave the investment to be picked up easily by investors from China, Qatar, or Indonesia.  Second, even if small companies did suffer through divestment there is nothing to stop the larger fossil fuel firms simply using their cash flow and borrowing capabilities to purchase their now cheaper and more vulnerable rivals.  So rather than divestment hurting the large amoral multinational fossil fuel companies and its remaining investors, it provides an opportunity for them to control and consolidate the industry further, potentially reaping more dividends from the act of consolidation.   If the divested funds were used to purchase shares in “alternative energy” companies all that would be happening is that the shares of those companies would be changing hands. Again, this share investment would not add to the cash flows or available investment capital of these companies unless the redirected investment went into new share offerings. Divestment campaigns can no doubt make people feel good about themselves and the actions they are taking to make the world a better place.  They can also put pressure on organisations who don’t have active ownership structures but instead view themselves as accountable to a range of people who act as if they have ownership rights – think of universities and their faculty, students and alumni.  All of this is noble.   However, such campaigns may be inferior to a more activist alternative, which is to either increase the investment or to work to pool the investments of like-minded shareholder groups so as to form ownership blocks that can demand changes in the board, management and strategy. In the end, it may be that moral outrage is not as effective as capitalism because one of the points of capitalism is to separate ownership from management while allowing owners control over managers.   One can express moral outrage about short-term shareholder capitalism but shares do not care who owns them and it is the job of the shareholder as owner to ensure that the company is run according to their wishes.  If the divestment advocates want companies to operate according to different precepts, perhaps more active ownership control would achieve their goals more quickly and effectively."
"Mongolia is hoping a massive dam on its largest river could provide much needed power and water for the country’s booming mining industry. However environmental groups are concerned that the hydroelectric power plant and a related pipeline project will do immeasurable environmental damage to oldest and deepest freshwater body in the world: Lake Baikal. As Baikal sits just over the border in Russia, Mongolia risks seriously annoying its northern neighbour at at time when the lake is already experiencing problems with invasive algae along its coasts, unregulated mining and a water level which just passed a “critically low” point. The Shuren Hydropower Plant, planned on the Selenga River in northern Mongolia, was first proposed in 2013 and is currently the subject of a World Bank-funded environmental and social impact assessment. In tandem, Mongolia is also considering building one of the world’s largest pipelines to transport water from the Orkhon River, one of the Selenga’s tributaries, to supply the miners in the Gobi desert 1,000km away. The impact of these projects will be most keenly felt downstream in Lake Baikal. The lake formed in a tectonic rift zone more than 25m years ago in southern Siberia. With a maximum depth of almost 1,700m, Baikal contains 20% of the world’s unfrozen freshwater.  Due to it’s great age, depth and remote location, more than 2,500 species have been documented in the lake, of which more than 75% are believed to be endemic and are found nowhere else in the world – from the microscopic plants that provide the lake with most of its energy to one of the world’s few truly freshwater seals, the nerpa or Pusa sibirica. Because of its unique characteristics and biodiversity, Lake Baikal was made a UNESCO World Heritage Site in 1996. By far the largest and most important of the 350-plus rivers that flow into Lake Baikal is the Selenga River, which contributes almost 50% of the lake’s water. The Selenga and its tributaries cover a vast area, much of it in northern Mongolia, and the catchment of Lake Baikal is bigger than Spain. The river enters Lake Baikal through the Selenga Delta, a wetland of internationally recognised importance.   The delta is crucial to the health of Lake Baikal. Its shallow waters are a key spawning ground for Baikal’s many endemic fish and is on the migratory route for millions of birds every year. It also filters out impurities flowing through the river before they reach the lake. The Shuren dam isn’t the only threat to the delta, but it may be the most important. The Selenga is already very polluted; mining for gold and other minerals in northern Mongolia has resulted in elevated levels of heavy metals in the water. Sewage and waste-water treatment plants along its banks are often old, leading to elevated concentrations of nutrients and other contaminants.  However, actually disrupting the river flow into the Selenga delta and Lake Baikal has the potential to cause untold damage to the lake and its life. Any lowering of the delta’s shallow waters will disrupt the spawning grounds of many endemic fish species – and other species, including birds and aquatic insects will lose their homes.  Biodiversity loss has the potential to degrade Baikal’s unique ecosystems, resulting in severe economic implications for local and regional economies. Such is the concern that several environmental NGOs such as Rivers Without Boundaries and academics from Mongolia and Russia have lodged a request for the World Bank to be investigated as they claim the bank is disregarding its own regulations by funding an assessment for a project on a unique river system that is home to endangered species. The Russian Security Council, which advises the president on national security issues, has also voiced its concern. But Russia cannot be let off the hook either. In the early 1950s, a hydroelectric dam was built in the city of Irkutsk on the Angara River, Lake Baikal’s only outflow. On completion, the water levels of Lake Baikal increased by more than a metre, flooding almost 150,000ha of land, displacing 15,000 people and disrupting the Selenga delta spawning grounds. More recently, the Irkutsk dam has been implicated (along with lower than expected rainfall) in contributing to some of Lake Baikal’s lowest water levels for several decades. But these problems may pale into insignificance if the Shuren Hydropower Plant and the Orkhon-Gobi Water Diversion schemes in Mongolia get the green light."
nan
"Rachel Connolly is right to demand that the Labour leadership candidates address the climate crisis (The nuclear button? There really are more pressing issues, Journal, 8 January). But suggesting we remove nuclear weapons from the conversation ignores how intertwined these two existential threats are. Generations of climate scientists have documented that a nuclear war could cause drastic climatic disturbances and global famine. Last year scientists found that the use of a few hundred weapons (less than 10% of today’s global nuclear arsenals) could nearly stop all rain over India and central China, and reduce global precipitation globally by 15%-30%. It would take over a decade to return to rainfall levels before the nuclear war.  Nuclear weapons destroy the climate even when they are not used. Nuclear weapons facilities – not unlike the oil and gas companies exacerbating the climate crisis – have contaminated land and water around the world with waste that will last far beyond even our grandchildren’s lifetimes. Climate change could actually make nuclear war more likely. Increased resource scarcity increases the chance of conflict, according to a growing body of research. The unacceptable humanitarian and environmental consequences of nuclear weapons and the ever-growing risk of nuclear use led 122 countries to vote to ban them in 2017. Today the UN treaty on the prohibition of nuclear weapons has 34 ratified states and 80 signatories – and counting. So perhaps, as Rachel suggests, we should not be asking whether candidates would push the button to launch nuclear weapons. Instead we should join the world’s majority of countries and ask when they will take the nuclear button off the table for good.Alicia Sanders-ZakreInternational Campaign to Abolish Nuclear Weapons • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitterNow in English…
An eye-opener book by Japanese MIT climate scientist now partly available in English at Kindle.

MIT climate scientist Dr. Mototaka Nakamura’s writes global warming data are “untrustworthy”, “falsified”.  Image: http://iprc.soest.hawaii.edu/
Not long ago we reported on a recently released book authored by Dr. Mototaka Nakamura, a scientist who received his doctorate from MIT and worked at NASA: “Confessions of a climate scientist The global warming hypothesis is an unproven hypothesis“.
After that post, I personally urged Dr. Nakamura to write the book in English.
Today I am very pleased to announce that a newly released Kindle version is now available with the important parts in English. You can download it for free for a limited time.
Please do download it! The English parts are within the Japanese text.
“Untrustworthy” and “falsified” data


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the book Dr. Nakamura writes how in the 1980s he became “seriously concerned about the predicted ‘catastrophic global warming due to the increasing carbon dioxide in the atmosphere'” and how the issue motivated him to study the atmospheric and oceanic sciences at the North Carolina State University and the Massachusetts Institute of Technology and to become a climate scientist.
Ironically, rather than finding any robust scientific basis underpinning the hypothesis, Dr. Nakamura wound discovering just how “untrustworthy” and “falsified”  the data behind global warming really are.
“We also do not know for certain how the earth’ s climate has changed in the past 100 years or longer, although we do know well how regional climate has changed in limited regions, such as Europe, North America, and some parts of Asia,” he writes. “A quasi-global observation system has been operating only for 50 years or so, since the advent of artificial satellite observation. Temperature data before then were collected over extremely small (with respect to the earth’ s entire surface area) areas and, thus, have severe spatial bias.”
Confident other scientists will speak up on “fraudulent claims”
On whether other scientists will speak up, Nakamura wrote that he is confident that “some honest and courageous true climate scientists will continue to publicly point out the made by the ‘mainstream climate science community'”.
As an expert, Dr. Nakamura also believes that the climate simulation models used for climate change predictions have two “serious flaws” among many. One “fatally serious flaw” is the oceanic component of the models and the “grossly oversimplified and problematic representations of the atmospheric water vapor”.
Nothing except a propaganda tool
Dr. Nakamura concludes that the “global surface mean temperature change data no longer have any scientific value and are nothing except a propaganda tool to the public.”
Share this...FacebookTwitter "
nan
"The least surprising development in the Flybe saga was Willie Walsh throwing a tantrum. The rescue of the struggling regional airline is “a blatant misuse of public funds”, thundered the boss of IAG, owner of British Airways, as he made an official complaint to the European commission. That’s the same IAG, note, that enjoys a feather-bedded life thanks to its control of 56% of the landing slots at Heathrow, the most capacity-constrained airport in Europe. BA doesn’t get a leg-up via grubby Flybe-style negotiations with ministers but, if the airline industry wasn’t so riddled with politics, and if flag-carriers didn’t enjoy such lobbying power, IAG’s share of landing slots at Heathrow would have been capped at 30% a long time ago.  The continued existence of Flybe maddens Walsh for a couple of reasons, one suspects. First, it is partly owned by the hated Virgin Atlantic. Second, Flybe indirectly secured a few slots at Heathrow via the fallout from BA’s takeover of British Midland in 2012; the competition authorities, in a rare act of resistance, took the view that BA was big enough already at London’s main airport and domestic consumers would benefit from greater choice. Walsh is not a voice of impartiality on Flybe. None of which is to deny that there are big questions to be answered about the rescue package. The Virgin-led Connect consortium has yet to explain how much money it has invested since it bought the assets for a mere £2.8m less than a year ago, and why crisis has arrived so soon. Making money from regional aviation is hard, as evidenced by Flybe’s many problems over the years, but that’s a reason to have a better plan B than begging for a deferral of an Air Passenger Duty (APD) bill and a short-term loan. It may be that the Connect crew is dysfunctional. Virgin Atlantic, 49%-owned by US carrier Delta, is mostly interested in delivering passengers to Heathrow and Manchester for transatlantic flights. Stobart would like more flights out of its Southend airport. Cyrus Capital, an obscure US investment firm, may have viewed the Flybe takeover as a short-term punt that could be abandoned if it threatened to become expensive. Those caricatures may be exaggerated, but the government is taking a risk in backing, even for a while, a consortium that looks fundamentally unstable. The fact that a review of APD has suddenly been thrown into the mix says this is a case of policymaking on the hoof. Yet it’s hard to say definitively that the government has done the wrong thing. If the aim is to ensure that Flybe survives until the peak summer season, that’s not so silly. The approach buys time to develop a coherent strategy. By contrast, the instant demise of Flybe would have been followed, almost certainly, by crises at several regional airports. The government’s ability to implement any policy would have evaporated. What would a sensible strategy look like? Well, there’s certainly a case for redesigning APD as a tax on emissions, rather than being a per-passenger charge. A straightforward reduction in APD – in other words, a pro-flying bung at a cost to the public purse – would make a mockery of the UK’s carbon-reduction ambitions. As for regional connectivity, the important thing is that the government doesn’t become beholden to Flybe’s unreliable owners. If it is really essential (a debate in itself) to run uncommercial flights between regions, let operators pitch for low-margin management contracts. Flybe doesn’t have to get the gig. Most of all, though, make the current help for Flybe transparent. A short-term sticking plaster could be a pragmatic fudge, whatever Walsh says, especially if it means Flybe is more likely to pay its APD liability in full. But any deal that underwrites the current owners would be completely unacceptable. “The government has not given any state aid to Flybe,” says the business department. Let us hope that statement is true. And, if it is, make sure it stays true. Still on aviation matters, here comes the World Economic Forum to claim that its Davos shindig will be a carbon-neutral event this year. Maybe it will be, but it’s safe to assume that many of the big-name participants from business, banking and politics will arrive in Switzerland via private jet. It happens every time, and instantly undermines all the worthy speeches about tackling the climate emergency. The aim this year, by the way, is to produce a manifesto for “a cohesive and sustainable world”. Of course it is."
"Giant sequoia trees, the largest living organisms on the planet – some more than three millennia old – have started dying from beetle attacks linked to the climate emergency, the preliminary findings of a new study have revealed. The deaths of the trees, some of which lived through the rise and fall of hundreds of empires, caliphates and kingdoms – not to mention the inauguration of every US president – have shocked researchers in their speed and novelty.   In Sequoia and Kings Canyon national parks in the Sierra Nevada, California, 28 giant sequoias have died from a seemingly deadly interaction between bark beetles, drought and fire damage since 2014, according to a joint National Park Service and US Geological Survey study that will be published later this year. Beetle attacks appear to have killed the trees in previously unseen ways, claiming mature standing giant sequoia trees known as monarchs. In addition to the beetle attacks, high-severity fires strengthened by drought and decades of natural wildfire suppression have killed 12 giant sequoias since 2015 in the national parks. The deaths have challenged age-old assumptions about the tree, which only grows on the western slopes of the Sierra Nevada and is fabled for its near-indestructibility, attracting visitors from across the world. “It’s unheard of. It’s never happened before,” said Dr Christy Brigham, chief of resource management and science for Sequoia and Kings Canyon national parks, who oversees the welfare of ecosystems in the parks. “You think giant sequoias don’t die in fire, you think giant sequoias can’t be killed by insects. That’s not true any more.”  According to more than 100 years of records preceding California’s 2012-16 drought, sequoia trees either died by falling over or suffering near total crown scorch in wildfires, never while standing upright. But since the historically hot and dry drought, researchers have recorded trees dying “from the top down” with the notable presence of bark beetles in their crown.  Although the number of trees that have died is a small proportion of the approximately 6,000 sequoias in the park, Dr Nathan Stephenson, the US Geological Survey forest ecologist who conducted the research, said he expected more to succumb to beetle attacks if, as expected, droughts become more severe and frequent in the future due to the climate crisis. “I don’t expect a threshold to be passed, at least in my lifetime, when there’s suddenly gigantic outbreaks taking out whole groves of giant sequoias. I suspect it will be [beetles continuing to hit] the most stressed sequoias but they will be doing more sequoias, because there will be more stressed sequoias.” Stephenson said while there were no beetle attacks marked in park records, he suspected it might have happened before “deep in history”, but more needed to be done to understand what the insects were doing to the trees. Climate crisis contingency plans for giant sequoia tree deaths and high severity wildfires made for the 2050s are being enacted now, the National Park Service said. Ecologists are considering taking measures such as planting seedlings at higher elevations outside the areas sequoia trees usually grow and increasing prescribed burns to thin the forest as much as possible. Fire is vital to ecosystems in the Sierra Nevada mountains, clearing the forest floor and allowing new seedlings to establish themselves. The sequoia tree needs slow burning fire to reproduce, but decades of fire suppression has meant that burns have not taken place in some parts of the forest for over a century. As a result, the buildup of fuel in the forest means that when fires do take place, they are more intense than usual, killing sequoia trees in the process. “For the sequoias that died in fires, it’s a combination of past management practices plus the hotter drought that ganged up to kill so many,” Stephenson explained. “Sequoias have died in past fires when it hasn’t been an extreme hot drought, but it was fewer. Again, it might be a warning shot across the bow that if it continues to warm as projected, you might get more severe, longer-lasting, hotter droughts and sequoias will be exposed to those kinds of wildfires.” Tens of millions of trees have died across the US, ravaged by pests, wildfires and the effects of the climate crisis, research in August found. In February 2019, the US Forest Service announced 18m trees had died since 2017 in California, bringing the total to more than 147m for the years since the drought began in 2010. Find more age of extinction coverage here, and follow biodiversity reporters Phoebe Weston and Patrick Greenfield on Twitter for all the latest news and features"
"
Share this...FacebookTwitterYesterday the online Hamburg Abendblatt published an interview with Prof. Fritz Vahrenholt on the recent climate demonstrations and alarmism. Vahrenholt calls the demonstrations and demands “over-the-top”, and a real threat to the economy. He says the climate models are unreliable and predictions of great warming “absurd”.

Co-founder of Germany’s modern environmental movement, Prof. Fritz Vahrenholt. Image: GWPF
Vehrenholt is one of founders of Germany’s modern environmental movement, the founder of the country’s largest renewable energy company, Innogy and a member of Germany’s SPD socialist parties. Lately the retired professor has become renegade among his peers by criticizing the “over-the-top climate debate” and warning against “hasty reforms”.
Atmosphere of fear and hysteria
Vahrenholt tells the Abendblatt the climate debate has become hysterical and that in fact “we don’t have a climate emergency.” He adds: “If Greta Thunberg’s demands are implemented, global prosperity and development will be massively endangered.”
Vahrenholt is one of the more prominent signatories of the letter to the UN: “There is no climate emergency.”
In the interview with the Abendblatt, Vahrenholt rejects Thunberg’s  bleak world view, noting that human society has markedly improved on almost every front over the recent decades.
“The number of hungry people in the world has halved, life expectancy has doubled, and infant mortality has been reduced to tenths. These successes have been largely due to the supply of energy for electricity, heat, transport and nutrition,” said Vahrenholt.
When asked why so few German scientists (12) signed letter to the UN, Vahrenholt told the Abendblatt: “People no longer dare to express themselves differently.”
The German chemistry professor says spreading panic and fear is “irresponsible” and that we should: “Stop scaring the children – they are already getting delusions.”
Climate models still unreliable


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Vahrenholt then tells the Abendblatt that “we have until the end of the century” to tackle greenhouse emissions – and not 12 years –  and that the situation is nowhere near as serious as the alarmist voices claim it is. Moreover, Vahrenholt reminds that the models still – which serve as the basis for the panic – have a long way to go before being reliable: “Many climate models have been shown to show too much warming and cannot reproduce the fluctuations of the past because they know only one factor: CO2.”
Later in the interview he asks: “What are we to think of models that neither reproduce the Little Ice Age nor the Medieval Warm Period – when it was about as warm as it is today?” In other words: If they don’t even work for the past, then they are completely unreliable for the future.
CO2 greens the planet
Vahrenholt reminds the Abendblatt that the added CO2 has in fact made the planet greener because of the boosted photosynthesis.
Only small number of scientists say man is 100% responsible
When asked about the 97% consensus, Vahrenholt tells the Hamburg-based daily that very few scientists deny CO2 has a warming effect, but adds: “Only a small minority believe that climate change is 100 percent man-made, and the vast majority believe in several causes.”
Green movement a real economic threat
Vahrenholt agrees that we have to reduce emissions, “but not commit suicide.”
The retired German professor advises against a hasty shutdown of coal energy, and warns it would lead to far greater poverty, even in prosperous Germany: “If we get out of coal and the combustion engine by 2030, then what will become of this country?

The retired professor also rejects the claims he turned his back on environmental protection, rather he has “stayed true to the cause”.
Schellnhuber’s 6°C warming a scandal, absurd
Near the end of the interview, Vahrenholt tells the Abendblatt he thinks the globe will warm about 1.5° by 2100, i.e. the low end of the IPCC’s 1.5 – 4.5°C projected range. He characterizes Prof. Hans-Joachim Schellnhuber’s 6°C rise – and the applause it always gets – as a “scandal” and being “absurd”.

Share this...FacebookTwitter "
"One weekend during the fiercely hot summer of 2018, when every single fan in Sweden had sold out, my boyfriend and I decided to get out of Stockholm and go camping. When we arrived at the campsite, we were asked not to smoke, and told firmly that no fires of any kind could be lit, owing to the forest fires that had been raging from the Arctic Circle to the Baltic Sea. Later that day, we received emergency notifications on our phones. Several more fires had broken out all over the country. I slept uneasily that night – and not only because I was on a yoga mat besieged by midges. It was my first experience of living with the climate crisis as a low-level but present danger.  This unease is now very familiar to most of us, and has been heightened by what we’re seeing in Australia. Since the fire season began there, in the middle of last year, 29 people have died, along with more than a billion animals, and an area comparable in size to the whole of England has been ablaze. It’s a vicious reminder that, for all the sophistication of the modern world, something as primitive as fire can still bring us to our knees. As shocking as the scale of the destruction has been, though, it’s easy to see it on our computer screens here on the other side of the world, in the middle of a British winter, and feel disconnected from it. We accept that the climate emergency is now truly upon us yet still feel that it’s mostly happening to other people, elsewhere. But wildfires are increasingly a problem for everyone, including in the UK. Last August, there were almost five times as many of them around the world as there had been the previous August. In the EU, the number of wildfires in the first half of 2019 was three times the annual average for the previous decade. And while they used to be a serious problem only in hotter, southern European countries such as Portugal and Spain, now northern Europe is in trouble too. The Swedish fires of 2018 were by far the most severe in the country’s history, burning an area almost twice as large as the worst previous wildfire, in 2014. In the UK, 2018 and 2019 were the worst two years on record for wildfires, particularly on moors in the north-west of England and parts of Scotland. One fire last year, at Marsden Moor in Yorkshire, destroyed almost three square miles of land. The damage is on a very different scale to the almost 30,000 square miles that have burned in Australia, of course, but this is still a development we can’t afford to ignore. Aside from all the more immediate effects – the threat to humans, livestock and wildlife – the recent increase in wildfires has been linked to severe air quality problems. People living up to 62 miles (100km) downwind of fires in the Pennines in 2018 were exposed to toxic fumes. And as there is no sign of cooler weather in the years ahead, it is reasonable to expect more fires in 2020. The EU has now established a fleet of firefighting planes, and the European Forest Institute has warned that unless we take steps to protect the countryside – for instance, by planting less-flammable species and creating barriers to the spread of flames – emergency services won’t be able to prevent the rapid spread and firestorms that have characterised the Australian crisis. This isn’t all because of the climate crisis – changes to land use and increased urbanisation over several decades are also factors. Weather patterns are noisy data, and it’s difficult to attribute any single wildfire to the climate crisis. The scientific consensus, however, is that it is increasing the intensity and frequency of fire-conducive weather across the world. Even those fires that are eventually linked to human error, like a still-lit disposable barbecue, are increasingly likely due to warming temperatures. Hotter summers mean more barbecues lit in the first place. The climate crisis is going to change the way we behave in every aspect of our lives. And with the probability of another summer of extreme weather coming, we will need to adapt to new dangers that won’t just be on the other side of the planet but, quite literally, in our own backyards. It’s not at all clear that we’re ready for what might be coming. There is still a cognitive jump yet to be made when those of us in Europe read about the fires in Australia, from mourning the destruction there to recognising that we face some version of the same threat. When we look at Australia, we’re not looking at the future that might await Europe. That future is already here. • Imogen West-Knights is a writer and freelance journalist"
"
Share this...FacebookTwitterScientists have found sea levels on India’s eastern coast were still 1-1.5 m higher than today as recently as 500 to 300 years ago and 3-4 m higher than today between 6000 to 4000 years ago. Seas rose and fell by multiple meters (-5 m to +3 m) within 1250 years until as recently as 4000 to 2000 years ago.
A new paper (Loveson and Nigam, 2019) reveals sea levels were still rising at a rate of 2.2 meters per century between 8100 and 7200 years ago, reaching a highstand of 4 meters above today’s sea level 6050 years ago.
For the next several millennia sea levels rapidly rose and fell within a range 6 meters – between 4 meters above to -2 meters below present levels.
A drop in sea level at one point reached an amplitude of -5 meters in just 1250 years (4350 to 3100 years ago) followed by 3 meters of sea level rise within 1200 years (3100 to 1900 years ago).
As recently as about 300 years ago mean sea level on India’s eastern shore was still about 1 meter higher than today.

Image Source: Loveson and Nigam, 2019

Evidence there were sea port towns along India’s west coast that are presently located much further inland suggest sea levels were 2-3 m higher prior to 2500 years ago.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




At the time of the 43 AD Roman invasion of Britain, the ocean shoreline, or beach, was located 2 miles (3.22 kilometers) from today’s shore.

Image Source: BBC
A new paper (Makwana et al., 2019) indicates there were sea port settlements that are today located “far inland” compared to where they were about 2500 years ago.
The scientists suggest sea levels may have been at least 2 meters higher than today at that time.
A visual example of how 2-meters-higher sea levels could have “submerged” the coast of western India is provided.

Image Source: Makwana et al., 2019
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman climate scientist Professor Werner Kirstein was interviewed by alternative media outlet NuoViso,  and since the video was released early this month on Youtube, it has been viewed over 130,000, times.

Politics commissioning reports for money
In the interview Professor Kirstein tells moderator Robert Stein that CO2 emissions have no effect on the climate and that “politicians commission climate scientists to produce expert reports for money.”
“Public is being deceived”
Prof. Kirstein talks about the “conscious deception” of the public and how all research projects and publications by “climate scientists” only have the goal of confirming “man-made climate change” and that different scientific views are not welcome.
According to Kirstein, the public is being deceived with the false information and that the aim of politics is to find a way to collect further taxes and to collect levies.
“We currently see this with the climate tax, which is to be introduced soon,” Kirstein says.
Movement back to feudalism
In the interview Kirstein also says that in Germany it gets down to ideologues pursuing an ideological transformation. He says: “I say this a bit exaggerated: We are to become a society of craftsmen and farmers like under feudal rule. Above are the feudals and below are the peasants who pay taxes. Industry is a detrimental thing that destroys the environment.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Doomsday scenarios are “false”
The now retired professor calls the doomsday scenario in which the polar caps melt due to the CO2 greenhouse effect and floods and climate refugee flows occur worldwide, false.
“Even if all CO2 emissions in Germany were stopped, the effect would still be zero. We have no influence on climate change,” he says.
Mann’s hockey stick “a fake”, Gore “a profiteer”

Kirstein also sharply criticizes the IPCC and Prof. Michael E. Mann, telling Stein: “The purpose of the IPCC report is to deceive people,” and that Mann’s famous curve in the shape of a hockey stick chart and the graphics “are fake.”
Kirstein also blasted Al Gore, calling him a “profiteer” of the spreading global warming hysteria.
Warming has been natural, “All this is normal”
“In truth, it was very warm in the 12th century in the Middle Ages. And about 150 years ago a small ice age came to an end, both were suppressed in Michael Mann’s curve,” Kirstein said. He calls the rise in temperature after the Little Ice Age a natural “reheating”.
Kirstein also says the assumption that the glaciers have declined due to global warming is also wrong.
“Glaciers come and glaciers go. But that also varies from region to region,” the expert says. “That is why the ice would increase at the South Pole and some glaciers would melt at the North Pole. All this is normal.”

Share this...FacebookTwitter "
"Four years ago a viral campaign wooed the world with a promise of fighting climate change and jump-starting the economy by replacing tarmac on the world’s roads with solar panels. The bold idea has undergone some road testing since then. The first results from preliminary studies have recently come out, and they’re a bit underwhelming. A solar panel lying under a road is at a number of disadvantages. As it’s not at the optimum tilt angle, it’s going to produce less power and it’s going to be more prone to shading, which is a problem as shade over just 5% of the surface of a panel can reduce power generation by 50%. The panels are also likely to be covered by dirt and dust, and would need far thicker glass than conventional panels to withstand the weight of traffic, which will further limit the light they absorb.  


      Read more:
      Solar freakin' roadways? Why the future of this technology may not be so bright


 Unable to benefit from air circulation, its inevitable these panels will heat up more than a rooftop solar panel too. For every 1°C over optimum temperature you lose 0.5% of energy efficiency.  As a result a significant drop in performance for a solar road, compared to rooftop solar panels, has to be expected. The question is by how much and what is the economic cost? One of the first solar roads to be installed is in Tourouvre-au-Perche, France. This has a maximum power output of 420 kW, covers 2,800 m² and cost €5m to install. This implies a cost of €11,905 (£10,624) per installed kW.   While the road is supposed to generate 800 kilowatt hours per day (kWh/day), some recently released data indicates a yield closer to 409 kWh/day, or 150,000 kWh/yr. For an idea of how much this is, the average UK home uses around 10 kWh/day. The road’s capacity factor – which measures the efficiency of the technology by dividing its average power output by its potential maximum power output – is just 4%. In contrast, the Cestas solar plant near Bordeaux, which features rows of solar panels carefully angled towards the sun, has a maximum power output of 300,000 kW and a capacity factor of 14%. And at a cost of €360m (£321m), or €1,200 (£1,070) per installed kW, one-tenth the cost of our solar roadway, it generates three times more power.  In America, a company called Solar Roadways has developed a smart highway with solar panels, including sensors and LED lights to display traffic warnings about any upcoming hazards, such as a deer. It also has heating pads to melt snow in winter.  Several of their SR3 panels have been installed in a small section of pavement in Sandypoint, Idaho. This is 13.9 m² in area, with an installed capacity of 1.529 KW. The installation cost is given as $48,734 (about £37,482), which implies a cost per installed kW of €27,500 (£24,542), more than 20 times higher than the Cestas powerplant. Solar Roadway’s own estimates are that the LED lights would consume 106 MWh per lane mile, with the panels generating 415 MWh – so more than 25% of the useful power is consumed by the LEDs. This would reduce performance even further. The heating plates are also quoted as drawing 2.28 MW per lane mile, so running them for just six days would cancel out any net gain from the solar panels. And this is before we look at the actual data from the Sandypoint installation, which generated 52.397 kWh in 6 months, or 104.8 kWh over a year. From this we can estimate a capacity factor of just 0.782%, which is 20 times less efficient than the Cestas power plant.  That said, it should be pointed out that this panel is in a town square. If there is one thing we can conclude, it’s that a section of pavement surrounded by buildings in a snowy northern town is not the best place to locate a solar installation. However, perhaps there’s a bigger point – solar roads on city streets are just not a great idea. Roads don’t actually represent as large an area as we assume. The UK department of transport gives a breakdown of the length of the UK’s different road types.  Assuming we can clad these in solar panels, four lanes of every motorway, two lanes on the A & B roads and half a lane for C & U roads (a lot are single track roads and just won’t be suitable) we come up with a surface area of 2 billion m².  Which sounds like a lot, until you realise that buildings in the UK’s urban areas occupy an area of 17.6 billion m². So just covering a fraction of the UK’s rooftops with solar panels would immediately yield more power than putting them on roads. That’s quite apart from the benefits that a more elevated position would yield for greater power generation.  All of this suggests that only a small fraction of the road network would actually be suitable. And, given the relatively small size of the road network, solar roads could only ever become a niche source of power and never the shortcut to our future energy supply."
"Falling ocean oxygen levels due to rising temperatures and influence from human activities such as agrochemical use is an increasingly widespread problem. Considering that the sea floors have taken more than 1,000 years to recover from past eras of low oxygen, according to a recent University of California study, this is a serious problem. Ocean regions with low oxygen levels have a huge impact on aquatic organisms and can even destroy entire ecosystems. Areas of extremely low oxygen, known as oxygen minimum zones or “dead zones”, are estimated to constitute 10% and rising of the world’s ocean. This expansion has been attributed to a warming climate, which increases water temperature, changes ocean circulation, and decreases the solubility of oxygen in sea water. At the same time fertiliser and pesticide run-off from farming and other human activities leads to rising levels of nutrients such as nitrogen and phosphorous reaching the sea.  Together, these two processes speed up the release of chemicals from ocean sediments and promote algal blooms. Subsequent algal death and decay result in increased consumption of oxygen in the water. The result is that other aquatic species such as invertebrates on the seafloor and fish suffocate for lack of oxygen. Due to circulation and runoff effects, dead zones are especially severe around large cities on the western continental coasts such as the coast of Peru, and within enclosed or semi-enclosed regions like the Baltic Sea or Gulf of Mexico. What effects will these changes have? We don’t yet know how great the effects of human-caused climate change will be, nor how much can be done to try and mitigate the effects on the environment. Even if oceanic oxygen levels rise again, will the world’s ocean ecosystems be able to recover?  The University of California study, published in the Proceedings of the National Academy of Sciences, studies fossils of over 5,400 sea animals including seed shrimps, molluscs, and brittle stars in order to try and answer this question. By examining seafloor sediments the researchers assessed how global warming affected sealife during the transition from the last ice age to the more-recent interglacial period, between 17,000-3,000 years ago. What the study found was that within only 130 years the oceans underwent devastating changes that led to complete collapse of invertebrates on the seafloor. More worryingly, the fossil records show that ecosystem recovery took at least 1,000 years. So the current growth of dead zones could leave drastic and long-lasting changes to marine life biodiversity. Climate change caused by human activity has already caused significant environmental damage over a relatively short time – the vast increase in pollution, ocean acidification, overfishing and deforestation in just the last 50-100 years, for example. However long it takes us to reverse the effects of global warming, if indeed we can, it will likely take ocean ecosystems many orders of magnitude longer to recover. Though microscopic organisms residing in the ocean and on the seafloor might seem to have little relevance to us, even small changes in ocean ecosystems can have enormous effects on the entire ocean food chain, from the smallest bacteria to the largest fish. Any impact on the creatures higher up in the food chain will have a massive impact on the human communities that rely on them economically and as a food source. Studies have shown that populations of mid-water fish such as Pacific hake decreased by up to 60% during periods of low oxygen off the coast of Southern California.  Conversely, numbers of Humboldt squid, which are more tolerant of low-oxygen waters, have increased significantly in the same location. Even the fish that can survive in dead zones are not faring well: large numbers of female Atlantic Croaker have been found to be growing testes-like organs instead of ovaries, a sexual deformation which causes infertility. Any shifts in ecosystem biodiversity can lead to a vicious feedback loop: dead zone seafloors turn into biodiversity deserts, where little but methane- and hydrogen sulphide-producing bacteria survive. Paired with changes in nutrient cycling which result in the release of nitrogen gas, levels of greenhouse gases being released from the ocean to the atmosphere increase and contribute to further global warming. To prevent the possibility of a 1,000-year (or longer) recovery period from a dead zone seafloor, we need to be much more aware of how the various environmental aspects are connected. An understanding of how de-oxygenation has affected the ocean in the past and how our actions are affecting the ocean in the present is critical to either preventing a recurrence or at least minimising effects of what we have already done."
"In April 2005, a fire burnt much of Victoria’s beloved national park at Wilsons Promontory leading to the evacuation of holidaymakers from Tidal River. The fire was the result of a fuel reduction burn, which escaped 10 days after it was lit when the weather became hot and windy. I remember it well as I was Victoria’s environment minister at the time, responsible for the park and the burn. The then premier Steve Bracks was one of the campers evacuated.  In 2015 a fuel reduction burn at Lancefield in Victoria escaped, causing a fire that destroyed six homes and caused a great deal of anguish for the local community. There have been many such instances of fuel reduction burns escaping and causing damage in different parts of Australia. The risk of putting fire in the landscape for fuel reduction is real. For years, elements of the media have promoted the idea that “greenies” and environmentalists have prevented fuel reduction burning. This particularly suits those with an agenda to deny climate change as it simultaneously advances the culture war against environmentalists and draws attention away from the need to take action on climate change. As environment minister, I don’t recall ever being influenced or lobbied by environmentalists or “greens” to stop fuel reduction burns. What does stand in the way of planned burns is climate change: higher temperatures, dryer fuel and strong winds in autumn and spring making it unsafe to burn. A shorter timeframe for safe burning – not “debate by environmentalists” – is the overwhelming factor. Much attention has been given to the recommendation of the Victorian Bushfires Royal Commission to implement a program of planned burning based on an annual target of 5% of public land – 390,000 hectares for Victoria. The former Victorian premier Jeff Kennett and others have criticised the Victorian government for not achieving this target. However, these criticisms not only ignore the climate-related difficulties with planned burning, they also fail to take account of the expert advice received in the years since the royal commission reported. The weather-related difficulties in achieving a hectare-based target were born out in 2014, the last year of the Napthine Coalition government, when only 82,022 hectares were burnt despite the government’s commitment to the 5% target. Kennett’s government itself could manage only 40,000 hectares of planned burning in 1997-98 and I had the same experience myself when I was minister in the very dry and hot 2006 year. The royal commission itself acknowledged that planned burning is risky and only available in limited timeframes. The royal commission also recommended that the Victorian government appoint an independent person to monitor the implementation of its recommendations. The former police chief commissioner Neil Comrie was appointed to the role and in his reports in 2012 and 2013 recommended that the planned burning target of 5% be replaced. Comrie concluded that the 5% was not “achievable, affordable or sustainable” and recommended that it be replaced by a risk-based approach with a primary focus on human life and safety. Following Comrie’s reports, the Inspector General of Emergency Management recommended a change from a hectare-based target for planned burns to a risk reduction target. A group of fire experts from around the country reviewed this recommendation and backed the changed approach because it focuses on the areas of highest risk rather than on burning broad acres for the sake of meeting a target. The risk-based approach also creates incentives to pursue alternative forms of risk reduction such as mowing and slashing when planned burning is not possible. In 2016, the Victorian government agreed to adopt this new approach, which means that fuel reduction is now done in a way to maximise the reduction in risk to people and their homes rather than simply burning as many hectares as possible. Fuel reduction burns are now carefully planned using computer-based fire models that indicate where the burning is likely to be most effective. The target is to reduce the risk that homes will be lost by 30%, which experts advised is the right level across the state. Planned burns cannot guarantee that homes will be saved. They are most effective when the fire is at ground level, but they are of limited effect on the most dangerous fire weather days when a fire can race across tree crowns or across already burnt areas. Fuel reduction burns should be part of the toolkit that our firefighting agencies have to tackle the ever-growing risk of bushfire. They should not be used as a weapon in the culture wars in order to divert attention from the need to act on climate change. John Thwaites is the chair of Monash Sustainable Development Institute and ClimateWorks Australia and a former deputy premier and environment minister in Victoria"
"Switching from fossil fuels to renewable energy is an important and necessary step towards averting climate change. However, in our efforts to go green, we also need to be mindful of other consequences, both intended and unintended – and that includes how a mass deployment of renewable technology might affect its surrounding climate.  What if the Sahara desert was turned into a giant solar and wind farm, for instance? This is the topic of new research published in Science by Yan Li and colleagues. They found that all those hypothetical wind turbines and solar panels would make their immediate surroundings both warmer and rainier, and could turn parts of the Sahara green for the first time in at least 4,500 years.  The scientists behind the research looked at the maximum amount of solar and wind energy that could be generated in the Sahara desert and the transition region to its south, the Sahel. The two regions were picked as they are relatively plausible sites for such an enormous roll-out of renewable energy, being fairly near to substantial demand from Europe and the Middle East, while having limited other demands on the land. Both have substantial potential resources of wind and solar energy. Li and colleagues also suggest that The Sahel, in particular, could also benefit from economic development and more energy for desalination, providing water for cities and agriculture.  As the two regions are so large, the solar and wind farms that were simulated in this study are the size of entire countries – 38 times larger than the UK. They would be vastly bigger than any existing solar and wind farms, and could provide up to four times as much energy as is currently consumed globally.  This would prompt quite significant changes in the local environment – massive wind farms would raise temperatures by around 2℃ for instance, similar to the amount of global warming we are concerned about. Solar would cause a smaller temperature change, around 1℃.  Precipitation increases of 0.25 mm per day associated with wind farms sound more modest, yet this would be almost double the previous amount of rainfall. Again, the effect associated with solar parks was smaller – an increase of 0.13 mm/day – but still significant when added up over a year.  Wind farms largely cause temperature increases because their turbine blades bring warmer air down to the surface, especially at night. This has been observed in field studies and using remote sensing. They have also been shown to increase moisture in the air. Solar panels mean more solar radiation is absorbed and less of the sun’s energy is reflected back into space. This causes the land surface to warm up. Several studies have shown this, including one which showed that the effect of warming caused by fossil fuels, via carbon emissions, was 30 times greater than the warming caused by solar photovoltaics absorbing more solar radiation. However, temperature effects may vary within the solar park and with season. In the Sahara simulation, extra rainfall happens because wind turbines represent an obstacle to free-flowing air, slowing it down and reducing the effect of the Earth spinning on air flow. This lowers the air pressure, and the difference in pressure between the Sahara and surrounding areas causes wind to flow there. When the air meets, or converges, in the Sahara it has nowhere else to go but up. As the air rises, water vapour in it condenses and rain drops form.  For solar, the process is slightly different: warmer air, heated by the panels, simply rises. However, this also promotes low pressure, causing air to flow there, converge and rise.  More rainfall also means more vegetation. This increases surface roughness, as with wind turbines, and causes more solar radiation to be absorbed, as with solar panels. This reinforcing cycle is known as a “climate feedback” and incorporating these vegetation feedbacks is a novel aspect of the research by Li and colleagues. Not quite. Decisions aren’t made in response to environmental impacts alone – if this was the case we’d have already ditched fossil fuels. It’s certainly true that developing a mega renewable energy site across the Sahara and the Sahel would be a game-changer, but there are lots of other factors to consider first.  These areas may be sparsely populated but people do live there, their livelihoods are there, and the landscapes are of cultural value to them. Can the land really be “grabbed” to supply energy to Europe and the Middle East? Coherent and stable energy policies are challenging enough within an individual nation, let alone between nations with all the potential political implications and energy security issues. Though mass amounts of cheap Saharan energy sounds like a great thing, it is not clear it would be a secure enough investment for the economics to add up. It’s also hard to tell what this would mean for desertification, which is caused by poor land management, such as overgrazing, as well as by the climate. The changes to rainfall looked at in this study are regional, not global, and once the wind and solar farms were taken away their effects would disappear and the land could revert back to its previous state. Overall, this is an interesting and important piece of research, highlighting the need to be mindful of unintended consequences, be these positive or negative, of the energy transition. Integrating these findings with other social, economic, environmental and technical considerations is essential to ensure we don’t leap from the frying pan into the fire."
"One of the UK’s flagship sustainability policies is in big trouble. Less than a year from now, the theory goes, all new homes will be “zero-carbon”. The reality is rather different. Economic meltdown, a housing crisis, pressure from developers and poorly designed legislation have all combined to leave the country way behind schedule. The policy dates back to 2006, when the Labour administration introduced stringent sustainability legislation. All new homes, they said, would be “zero-carbon” by 2016. The provision of solar panels (and other renewable energy technologies) and better energy efficiency would balance out emissions from heating, lighting and use of appliances leaving net emissions at zero.  To achieve this, building regulations were to be progressively tightened in the run up to 2016 and a Zero Carbon Hub would be formed to knock together the heads of house builders, NGOs and bureaucrats.  At the time this target was hailed as world leading and on some level the policy has been a success. By December 2014 some 33,000 homes had been built to sustainable standards, according to one measure. However, we need to look at the bigger picture. Fast forward a decade or so and under the Conservative-led coalition government the agenda has spluttered from problem to problem. The reforms to building regulations have been delayed and are not achieving the kinds of levels envisaged. The latest were introduced a year late and only achieved a 33% improvement in energy performance, against a promised 44%. This leaves a big gap between where we are now and the next iteration, which is supposed to achieve “zero-carbon”. More worryingly, despite six years of negotiations it still isn’t clear how “zero-carbon” will be defined. What we do know is that zero-carbon is likely to be anything but.  The definition of emissions, for example, was weakened in the 2011 budget. It now includes emissions from heating and lighting but it wont include those from “unregulated energy” – that is, energy used by appliances within the home.  Emission reductions won’t even have to be achieved in the house itself. “Allowable solutions” have been introduced instead, a level of emissions above which developers can pay into a fund for low-carbon infrastructure to be built elsewhere as a way to “off-set” carbon.  Precisely at what level these allowable solutions will kick in is not clear, nor how the fund will work in reality. What is clear is that developments of fewer than ten houses (which comprise the vast majority of house-building) will be exempt from allowable solutions. Tellingly, the WWF left the Zero-Carbon Hub in protest against what it saw as a “watering down” of policy. With so many details still to be decided, it is unsurprising that there is little confidence that the 2016 target will be met. This is not necessarily the coalition’s fault however. In many ways it is the result of inherent contradictions within the policy. The underlying rhetoric has been that technology – solar panels, heat pumps, insulation and so on – will do all of the hard work and consumers need not worry themselves about how they engage with and run their homes.  But who pays for this technology? Government figures show that complying with the 2010 sustainable building regulations meant a 5% increase in real production costs compared to 2006. Complying with 2013 regulations would see that figure rise to 9%. Want to build to the strictest zero-carbon standards? That’s a 50% increase. Labour never adequately addressed the question of “who pays”, sowing the seeds for today’s problems.  More often than not it has been housing developers who have had to shoulder the costs because there has never been a significant enough “price premium” attached to sustainable homes.  These costs would come down as technologies and expertise became more widespread, but the 2008 credit crisis and the increased politicisation of housing affordability and supply changed things. These sustainability requirements had the potential to hinder the construction of new housing, so developers were vocal in their opposition. The coalition has been more sympathetic to developers than other parties may have been. Yet in many ways these policy reforms were inevitable. While it would be nice to say that the government should force increased costs on builders, the reality is very different as the government must consider whether environmental policy will jeopardise housing supply. In the midst of a financial crisis, the industry couldn’t afford the costs associated with the initial zero-carbon proposals. In many ways this watering down could have been avoided if the initial policy had more of a focus on giving home owners an incentive to be greener. The challenge for the next administration is finding a way to encourage developers to build the homes we desperately need while sharing sustainability demands between both buyers and builders. We need homes, but we owe it to future generations to make them green."
"
Share this...FacebookTwitterNDR north German television recently broadcast a report about the protests against a planned windpark near the German village of Kreien, some 200 km east of Hamburg.

White tail eagles being chased away from nest by loudspeakers in order to clear the way for permitting 14 wind turbines over 200 meters tall in Northern Germany. Image cropped: juvenile white-tailed eagle, Christoph Müller (www.christophmueller.org) – CC BY 4.0
One local resident told NDR television the area is already packed with 178 turbines, and that the plans to build 14 new over 200-meter tall behemoths are no longer welcome. The resident had noticed something very peculiar: a loudspeaker system that had been installed in the area of the planned project (see video, 0:20 mark).
Apparently the speaker system had been put in place to scare away white tail eagles that might get the idea to nest atop an adjacent nesting mast just meters away. The mast had been provided earlier for the purpose of providing a nesting place for the endangered bird species. White tail eagles nesting there would mean a sure stop of the project, and shooing them away would ensure the go-ahead for the wind project.
The sound of barking hounds


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Eagles entering the area and looking to establish a nest there would be scared away by the sound of barking dogs blaring from the speaker (2:40). The result: keeping the nest empty and thus a free path for the construction of the wind park by wind project company UKA Nord.
Residents in the area have reacted angrily at the prospect of yet even more giant wind turbines getting erected in their area, and especially at the tactics used by UKA Nord to ward off potential nesting birds.
One local mayor described the loudspeaker measure as “unbelievable”.
Climate protection before habitat protection?
When asked to comment by NDR, windpark builder UKA Nord replied by text message claiming that the nesting mast was not “to protect birds” but instead was “a pure measure to prevent the expansion of wind energy, which is necessary for climate protection.”
Moreover, the written UKA Nord statement appealed to the local policymakers “to live up to their responsibility for transition to green energies and climate protection and strive for a constructive cooperation.”
At the 3:30 mark of the report, citizens are shown banding together to organize a citizen’s group against the project. So far they have seen some success. The UKA Nord has since turned off the speaker system and it’s been decided to dismantle it. Yet, plans for the construction of the park still have not been halted.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA new paper finds the performance of test-taking (cognitive, decision-making) “astronaut-like” subjects exposed to 5000 ppm CO2 was “similar to or exceeded” the performance of those exposed to baseline (600 ppm). This study follows up on a 2018 paper that determined submariners exposed to 15000 ppm CO2 performed just as well as subjects exposed to 600 ppm.
Those of us who own CO2 monitors know that indoor (bedroom) CO2 concentrations typically vary between about 600 ppm during the day and 1000 ppm overnight – the latter earning a frowny face air quality rating.


CO2 is a cognitively-impairing toxin?
In recent years there has been a push to create the impression carbon dioxide is a pollutant, or toxin. Consequently, there have been a few studies suggesting exposure to higher CO2 concentrations (~1500 to 2500 ppm) severely impair human cognitive and decision-making performance (Satish et al., 2012, Allen et al., 2016).
If true, this would be rather problematic for elementary school children, as they are routinely exposed to CO2 concentrations ranging between about 1500 and 3000 ppm in their classrooms (Corsi et al., 2002).
Driving alone in one’s vehicle could mean exposure to “3700 ppm … above outdoor [CO2] concentrations” (Satish et al, 2012), or about 4100 ppm.
This elevated-CO2-is-toxic-to-brain-functioning paradigm suggests the world’s highways are teeming with cognitively-impaired drivers.
2 new studies show elevated CO2 has no effect on cognitive performance
The results from a 2018 study (Rodeheffer et al., 2018) measuring the cognitive and decision-making performances of submariners exposed to elevated CO2 undermined the attempts to portray CO2 as a brain-function-impairing toxin.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the study, subjects were exposed to 3 CO2 conditions: 600, 2500, and 15000 ppm.
The results indicated there were “no significant differences” in how the subjects performed for any of the CO2 exposure levels.

Image Source: Rodeheffer et al., 2018
A new study (Scully et al., 2019) assessing the capacity of elevated CO2 exposure to affect cognitive and decision-making performance appends the Rodeheffer et al. (2018) results.
This time, “astronaut-like” subjects were exposed to four CO2 gradients: 600, 1200, 2500, and 5000 ppm.
The results indicated there were “no clear dose-response patterns” evident for any of the exposure conditions.
In fact, the performance of subjects exposed to 5000 ppm slightly exceeded the performance of subjects exposed to 600 ppm CO2.
These results suggest the elevated-CO2-is-toxic-to-brain-functioning paradigm is not supported by real-world experiments.

Image Source: Scully et al., 2019
Share this...FacebookTwitter "
"Greta Thunberg has challenged political leaders and the media to listen to the science as she warned time was running out to tackle global heating. Speaking on a panel of young environmentalists in Davos, Thunberg said the increase in global temperature could not be kept below 1.5C if the world continued to use up its limited carbon budget at its current rate. “With today’s emissions levels, the remaining budget is gone in less than eight years. These aren’t anyone’s views, this is the science,” Thunberg said, citing a 2018 Intergovernmental Panel on Climate Change (IPCC) report. “I know you don’t want to report this or talk about this but I will keep repeating the numbers until you do.” The 2018 IPCC report said that the world had a limit of 420 gigatons of carbon to emit if there was to be a 67% chance of keeping the increase in global temperatures to 1.5 degrees. Thunberg said that was now down to 340 gigatons. There was an assumption, she said, that “future generations will somehow suck hundreds of billions of tonnes of CO2 out of the atmosphere, even though such technology doesn’t exist yet”. Davos is a Swiss ski resort now more famous for hosting the annual four-day conference for the World Economic Forum. For participants it is a festival of networking. Getting an invitation is a sign you have made it – and the elaborate system of badges reveals your place in the Davos hierarchy. The meeting is sponsored by a huge number of international banks and corporations. For critics, “Davos man” is shorthand for the globe-trotting elite, disconnected from their home countries after spending too much time in the club-class lounge. Others just wonder if it is all a big waste of time.  The 2020 meeting is being advertised as focusing on seven themes: Fairer economies, better business, healthy futures, future of work, tech for good, beyond geopolitics and how to save the planet. Young climate activists and school strikers from around the world will be present at the event to put pressure on world leaders over that last theme.  The IPCC forecasts did not include feedback loops or possible tipping points that might make the need for action even more urgent, the Swedish activist said; rich countries needed to get their emissions down rapidly and then help poor countries to make the necessary changes. “Even with a 1C increase people are dying of climate change. Every fraction of a degree matters.” Thunberg was speaking hours before Donald Trump – a global heating sceptic – was due to make a keynote address to the World Economic Forum. She said people were more aware of the problem, thanks to the efforts of young people: “It feels like the climate and environment is a hot topic now. But from another perspective virtually nothing has been done. Without treating this as a real crisis we cannot solve it.” After a year in which her first appearance at Davos catapulted her to international fame, Thunberg said she could not complain about her voice being heard. “I’m being heard all the time. But the science and the voice of young people are not at the centre of the conversation and they need to be. This is about us and future generations.”"
"
Share this...FacebookTwitterNoTricksZone contributor Kirye provides us with a unique look at climate and energy developments in Japan.
===============================================
World may get another climate realist leader
By Kirye
As the working class struggles economically, signs of profound anti-establishment shifts are emerging in Japan, spurred on by a new political leader who is a climate and energy realist.
Rising Japanese political star Taro Yamamoto aims to shake up Japan’s crusty establishment down to the core. Image: Twitter here.
Growing poverty in Japan
In the House of Councillors election held on July 21, 2019, I voted for the recently founded Reiwa Shinsengumi party led by Taro Yamamoto . Why? According to the Ministry of Health, Labour and Welfare (MHLW), 57.7% of families, 81％ of single mothers and 1 of 7 children feel impoverished. These are shockingly dismal social and economic indicators for one the richest countries on the planet.
Part of this is due to an increased tax burden that have made people unhappy and poorer while the super rich profit from tax cuts. Moreover, Japanese finance minister Tarō Asō suggested that Japan could even learn from constitutional changes made by the Nazi party! Japanese president Shinzo Abe spends time on the golf course.
In contrast Taro Yamamoto, leader of the newly minted Reiwa Shinsengumi party, helps out at soup kitchens and fights for Japan’s many forgotten citizens.
Enough is enough – historic election result
Today there’s finally a growing feeling among the Japanese citizenry that the country is in need of toppling establishment structures and bringing in a new president and political party who work for justice, life and on behalf of the poor.
In the recent Upper House election, Mr. Yamamoto hauled in 992,267 votes, and so was the candidate with the highest number of votes in history in proportional representation. Now the Reiwa Shinsengumi has gone from a political group to political party, and is becoming more famous as many Japanese media are reporting on the phenomenon.
Energy and climate realist


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




When it comes to energy, party leader Yamamoto wants to use natural gas thermal power as a main energy supply, and to end the use of nuclear power (Japan is an earthquake country, so his ideas are valid).
On climate, I personally have never heard Mr. Yamamoto mention that CO2 is bad, despite so many Japanese people having been brainwashed by the media into believing we have to cut CO2 emissions. Many Japanese have never even heard of Climategate. Where does he stand on climate?

Yamaoto at JAJ press conference.
To find out, last Wednesday I took part in a press conference held by the Journalists Association of Japan and had the opportunity to tell Mr. Yamamoto the real story of how CO2 is not climate’s main driver (1:34:34 mark and 1:38:00). In summary I told him: Just this year alone, almost 200 new papers which do not support the anthropogenic global warming theory have been published so far. Last year the number of skeptic papers was 504. Moreover, NASA’s website shows only 166 stations have data that go back to 1880, and less than 1000 stations have the data from January, 1919.
I also told Mr. Yamamoto how distinguished Japanese climate scientist Dr. Mototaka Nakamura, who used to work for NASA, reminds us that only 5% of Earth’s surface has been adequately measured by thermometer over past 100 years and how the surface temperatures have been substantially affected by the urban heat island effect. Also how the real world’s temperature remains a far cry from the IPCC’s prediction.
He answered:  “In a sense it is wonderful if the fact spreads abroad and that it is controversial.”
He added:
Some people say that warming is not good, and are criticizing me because I aim breaking with nuclear power generation and I am pushing the generation of thermal power.”
This is a fresh perspective that has long been lacking in Japan, and so Mr. Yamamoto could act as a figure for changing public perception on the issues of climate and energy. Eventually the facts will win out because the sham cannot hide reality for long.
Growing roster of worldwide climate realist leaders – alarmists in panic
Already a number of worldwide leaders have expressed strong doubts on CO2 being the dangerous climate driver, for example US President Donald Trump, Russia President Vladimir Putin, Prime Minister Scott Morrison of Australia and the UK’s Boris Johnson. Others include Eastern European leaders, Italy’s Matteo Salvini and Brazil’s Jair Bolsonaro. The momentum is real. So it’s little wonder global warming alarmists are becoming increasingly spooked and hysterical.
Some people believe that Mr. Yamamoto will be the next President of Japan, and I hope so. If it becomes reality, the world will be adding yet another climate realist to the growing roster of climate-realist leaders.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterYet another scientific paper presents evidence that the Arctic region was warmer than recent decades during the 1930s, leading scientists to conclude there is “still-insufficient knowledge of the mechanisms governing the Arctic Climate System.”

Image Source: Araźny et al., 2019

Araźny et al., 2019
A comparison of bioclimatic conditions on
Franz Josef Land (the Arctic) between the
turn of the 19th to 20th century and present day
“Air temperature in 1899–1914 during three expeditions was 1.8–4.6 °C lower than the modern period in winter (Oct–Apr). However, during the 1930/31 expedition it was 4.6 °C warmer than the years 1981–2010. Our results relate to what has been called the ‘1930s warming’, referred to by various authors in the literature as the ETCW or the ETCAW.”
“In individual months, the highest negative anomalies were identified in Calm Bay (hereafter CB) in January 1914 (− 7.4 °C) and in February 1900 (− 6.8 °C). In contrast, during the 1930/31 expedition, it was 4.6 °C warmer than the present day in CB [Calm Bay]. Such a high thermal anomaly was influenced by a warm autumn and winter, especially February 1931, when the average monthly temperature was 10.7 °C higher than in the modern period.”
“In approximately the last 140 years, there have been two periods of significant temperature increases in the Arctic. The first began in around 1918–1920 and lasted until 1938 and has been called the ‘1930s warming’ (Bengtsson et al. 2004). Other works have referred to this period as the ‘Early Twentieth Century Warming’ (ETCW, Brönnimann 2009) or the ‘Early Twentieth Century Arctic Warming’ (ETCAW, Wegmann et al. 2017, 2018). Our results confirm the observations for the last expedition from the historical study period in 1930/1931. These years covered the warmest part of the ETCW.  In turn, the second increased warming of the Arctic began around 1980 (Johannessen et al. 2004) or according to Przybylak (2007) in about the mid-1990s. Changes in overall atmospheric circulation have long been believed to have been the cause of the ETCW (e.g. Scherhag 1937). As the modern climate warming (since 1975) has progressed in a largely similar manner to the progression of the ETCW (Wood and Overland 2010; Semenov and Latif 2012), there has been renewed interest in the insufficiently well-explained causes of the ETCW using the latest research methods, including, primarily, climate models. An analysis of the literature shows that the cause of such a significant warming in the present period is still not clear. There is even controversy over whether the main factors in the process are natural or anthropogenic, although the decided majority of researchers assign a greater role to natural factors (Bengtsson et al. 2004; Semenov and Latif 2012). It would appear that the greatest differences of opinion on the causes of the ETCW are to be found in works presenting climate models (see, e.g. Shiogama et al. 2006; Suo et al. 2013), which is an excellent illustration of the still-insufficient knowledge of the mechanisms governing the Arctic Climate System.”

Image Source: Araźny et al., 2019

Another new paper indicates that West Greenland retreat rates were much higher “(400-800 m/yr)” during the 1930s and 1940s than “after 2000 (>200 m/yr)”.
Vermassen  et al., 2019
A reconstruction of warm water inflow to Upernavik Isstrøm
since AD 1925 and its relation to glacier retreat
“A link between the physical oceanography of West Greenland and Atlantic SSTs has indeed been suggested previously: a positive phase of the AMO [Atlantic Multidecadal Oscillation] is related to an increase of warm Atlantic waters flowing towards and along the SE and W Greenland shelf (Drinkwater et al., 2014; Lloyd et al., 2011). Our data indeed supports that the AMO influences bottom water temperature variability along the West Greenland shelf and shows that this influence is strong within Upernavik Fjord.
“Despite differences in the timing and magnitude of the retreat of the different glaciers, they broadly share the same retreat history. High retreat rates occurred between the mid ‘30s and mid ‘40s (400-800 m/yr), moderate retreat rates between 1965-1985 (~200 m/yr, except for Upernavik) and high retreat rates again after 2000 (>200 m/yr).”
“[O]ur study shows that while warming of ocean waters in Upernavik fjord likely contributed to the retreat phases during the 1930s and early 2000s, ocean warming is not a prerequisite for retreat of Upernavik Isstrøm.”
“This is important since it implies that the future potential oceanic forcing of Upernavik Isstrøm will depend on changes related to circulation in the North Atlantic (i.e. the AMO). Since the meridional overturning circulation strength and associated heat transport is currently declining, (Frajka-Williams et al., 2017), this may lead to cooling bottom waters during the next decade in Upernavik Fjord and most likely also other fjords in West-Greenland.”

Image Source: Vermassen  et al., 2019
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBefore people jump into a debate about weather with veteran Swiss meteorologist Jörg Kachelmann, they’d first better make sure that they really paid close attention at school and did their science homework.
In an debate at Twitter, the high-profile, seasoned meteorologist inadvertently exposed a shocking lack of comprehension of fundamental physics by some of Germany’s top climate officials, among them renewable energy expert Prof Volker Quaschning.
Hat-tip: Axel Bojanowski
High temperatures do not cause droughts
The Twitter exchange was unleashed by Kachelmann blasting the recent junk-science-driven media hype over another year of potential drought over Central Europe, and especially the false claim made by Prof. Quaschning that higher temperatures lead to more drought and forest fires. Kachelmann called this claim: false and “complete nonsense.” Kachelmann recently explained in a t-online article he penned:
Heat does not cause forest fires and is completely irrelevant. Forest fires are caused by the fact that it is dry longer, and then some fools – intentionally or not – throw something burning into the area, or park a very hot car over dry high grass and then drive away. The temperature on the day of the outbreak of forest fires does not matter.”
It’s the moisture, stupid
In other words, Kachelmann, dumps cold water on Quaschning’s claim that higher temperature is the factor behind drought and thus forest fires and Biblical-scale misery of the sort prophesized by Green fanatics. Kachelmann explains that temperature has nothing to do with the risk level of fire, and that the factor behind it is air moisture.
Shockingly, this fundamental physics law seemed to be unknown to “top scientists” such as Quaschning and others.
The FridaysFor Future activist and “renewable energy expert” Prof. Volker Quaschning kept insisting that temperature determined how dry soil would become, tweeting to Kachelmann: “Physics: More heat = more evaporation = drier ground = high forest fire risk = more forest fires. To shore this up he dragged Stefan Rahmstorf in to his side.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Confused about water vapor
Next, scientist Stefanie here tweeted a chart showing how much water a kg of air could hold versus temperature with the aim of showing Kachelmann he was wrong and that it was all about temperature:

Water vapor in grams per kilogram of air versus air temperature. Source here.
But this backfired on Stefanie when Kachelmann correctly demonstrated she did not understand the chart at all and that she had no idea what she was talking about.
That these climate experts would not know that water vapor in the air is the driving factor behind drought makes one wonder what faulty physics may have gotten applied to the climate models.
Throughout the entire thread there are attempts by the climate “experts” to assert their “academic authority”.
Other readers noted, for example, that despite extremely high temperatures in jungles, raging forest fires don’t break out in them. It’s not because of the temperature, but because of the moisture.
Climate alarmism becoming a sect
If any trend is emerging, it is that Kachelmann, a believer in man-made warming, is tiring of the fanaticism on both sides. He recently tweeted:
But unfortunately you can only stay in the sect if you join in the chattering of all the nonsense and depart from the grounds of science because of the purpose of saving the world allows all nonsense. Green and browns are outbidding each other in terms of lack of seriousness. It is getting very wretched.”
Share this...FacebookTwitter "
"Let’s not beat about the bushfires. It’s not the impacts of climate breakdown on our ecosystems or the world’s poorest in the global south that worries Larry Fink, the CEO of that financial behemoth BlackRock. No, what really worries him and his shadow banking peers is the “fundamental reshaping of finance” threatened by climate protesters, and what this means for his company’s interests. Fink made headlines this week with his annual letter to CEOs, which put the climate emergency front and centre. Acknowledging the risks that it poses to markets, and announcing that his fund will no longer invest in companies that generate more than 25% of their revenue from thermal coal production, his letter was hailed as a landmark move. But, before we get too laudatory, it’s worth asking: what is BlackRock?  The US company is the world’s biggest asset management fund. 63% of the staggering $7tn financial assets it manages originates in the Americas and 29% in Europe. In the UK (as far as we know) BlackRock manages £16.5bn of local government pensions, as well as at least £3.8bn of Transport for London’s pension fund. BlackRock’s management of our savings takes place largely in a globalised sphere known as the shadow banking sector. In the past, most savings were placed in carefully regulated high-street banks and other savings institutions. Today, many of these functions have migrated toward shadow banking. This sector is made up of institutions (including pension funds, insurance companies and hedge funds) that use securities (a tradeable bundle of debt or equities) as collateral in a modern form of credit creation. BlackRock, backed by $7tn of the world’s savings, also provides traditional banking services across the international financial system. Asset management funds such as BlackRock operate beyond democratic borders and are not subject to the same regulatory oversight as traditional banks. In his letter, Fink acknowledges that “the money [BlackRock] manages is not [its] own”. “Last September,” he continues, “when millions of people took to the streets to demand action on climate change, many of them emphasised the significant and lasting impact that it will have on economic growth and prosperity – a risk that markets to date have been slower to reflect. But awareness is rapidly changing, and I believe we are on the edge of a fundamental reshaping of finance.” But the “shape of finance”, especially in the shadow sector, remains essentially the same: it spews out massive quantities of credit – forms of new money – much of it aimed at speculative activity. The Financial Stability Board reckons that at the end of 2017 shadow banks generated $184tr in financial assets. This money is then used to invest in the real economy of consumption and production – and in the fossil fuel sector. As Bill McKibben, leader of the campaign group, 350.org, writes, without asset management companies such as BlackRock, “fossil-fuel companies would almost literally run out of gas”; what’s more, the company is the “world’s largest investor” in coal, oil and gas companies, and in those “driving deforestation”. While it is significant that Fink has publicly acknowledged the risks that climate breakdown poses to his and other companies, that is surely not the only point. The real concern is that the world’s politicians and regulators have allowed this behemoth to scoop up our savings, while turning a blind eye to how those savings are managed. This, in turn, has fuelled the creation of vast amounts of credit and debt, which has made the global financial system unstable and fragile. The shadow banking sector is much, much larger than it was after the Lehman Brothers collapse – a collapse precipitated in part by Lehman’s activities in the shadows. If we are to save the planet, then we must begin by switching off the giant tap of unregulated credit. Fink is right: a “fundamental reshaping of finance” is what climate protesters want as the order of the day. But self-regulated divestment is not enough. The “reshaping” needs to be democratically enforced and accountable. We must ensure that companies such as BlackRock are brought back down to Earth and properly regulated by public authority. We have to do this if we are to redirect investment into the transformation of economies away from their addiction to fossil fuels and into more sustainable transport, energy and land-use systems. • Ann Pettifor is director of Prime: Policy Research in Macroeconomics and a fellow of the New Economics Foundation • This article was amended on 17 January 2020 to clarify that 63% of the assets managed by BlackRock originates in the Americas and 29% in Europe, rather than BlackRock managing about 60% of the savings of all Americans, and about 30% of the savings of Europeans"
"New details of a nightmare period on Earth with surface conditions as frigid as present-day central Antarctica at the equator have been revealed thanks to the publication of a study of ancient glacier water. The research, by an international team led by Daniel Herwartz, is published in the journal Proceedings of the National Academy of Sciences and shows that even tropical regions were once covered in snow and ice. In the most recent ice age, the last glacial advance (ending about 12,000 years ago) ice sheets extended across Europe at the latitude of southernmost England and reached south of the Great Lakes in North America. Beyond lay tundra, woolly mammoths and so on – but the equatorial belt of tropical rainforest was still there. Much more drastic situations occurred far earlier in Earth’s history however, and it is these that are supported by the new study. The periods have been dubbed “Snowball Earth”. This term first rose to prominence in the 1990s on the back of decades of geological observations of rocks deposited by glaciers, on land and at sea, during much of the period lasting from about 720m to 630m years ago at locations from across the globe which – at the time – were on the equator or no more than 40 degrees from it.  This was not easy for geologists to establish, because organisms that would leave large, easily recognisable fossils (so useful for relative dating) had not yet evolved. Moreover, the distribution of continents was different and has to be deduced by measuring traces of the Earth’s magnetic field captured into the rocks when they formed (paleomagnetism). Over the period in question, a single super-continent known as Rodinia was beginning to break apart, but still straddled the equator. Why the climate should ever veer so extremely as to become caught in Snowball Earth conditions is a complex matter. On the one hand the Sun was 20-30% fainter than it is now, and thus provided less heat. However, the ancient atmosphere had much more carbon dioxide in it than now, so there would have been a more effective “greenhouse effect” to trap heat and keep the planet warm.  Changes in the Earth’s orbit, or in the tilt of its axis, might have tipped the balance – these are the likely cause of more recent glaciations – but it is possible that full Snowball Earth conditions can be initiated only when a super-continent lies across the equator. As land reflects more solar heat than the oceans, equatorial Rodinia maximised the amount of heat bounced back into space rather than absorbed into the seas and kept on Earth. Snowball Earth conditions gripped Rodinia at least twice, in an older episode known as the Surtian and in a younger episode known as the Marinoan. Herwartz and his team studied rock samples from the Dabie-Sulu belt in modern day eastern China. Back in Surtian and Marinoan times this region was between 15 and 35 degrees north, the same sort of latitude as present-day Mexico, India or the Sahara.  The team also studied rocks from a much older proposed Snowball Earth episode, about 2.2 billion years ago, sampled in Karelia, in present-day northwest Russia close to the border with Finland. These too were at a low latitude at the time in question. 
0 The researchers’ key innovation was to analyse oxygen left behind by ancient glacial water as it reacted with rocks to form new minerals. They used this to work out the prevailing surface temperatures. Oxygen comes in three stable forms, or “isotopes”. Nearly 99.8% of oxygen atoms are oxygen-16 (made of 8 protons and 8 neutrons). Most of the remainder is oxygen-18 (8 protons and 10 neutrons), but there are also traces of oxygen-17 (8 protons and 9 neutrons).  A water molecule containing a heavier isotope of oxygen has the same chemical properties as a water molecule containing the lighter oxygen-16 but will evaporate less readily and condense more quickly. This means that the oceans lose water molecules containing oxygen-16 at a faster rate, and rain (or snow) falling far from the ocean will be poorer than average in the heaver isotopes. The ratios of the different oxygen isotopes in the recent geological past can be used as a proxy for global temperature, or to estimate how much water from the oceans has been removed and stored in glaciers. It is far from simple to get at the information locked in ancient rocks of the kind studied by Herwartz’s team, but by including the extremely rare oxygen-17 isotope in their study, they were able to show that both of the heavier isotopes must have been rarer than expected in the glacial water that had reacted with the rock. The difference in the depletion of oxygen-17 compared to the depletion in oxygen-18 enabled them to demonstrate likely mean annual surface temperatures of as much as 40°C below zero. Such low temperatures imply that the oceans would have been deeply frozen too, supporting the full Snowball Earth model. But if the land where the rocks originated was so cold because it was several kilometres above sea level, the possibility that the planet was more of a Slushball Earth, with open seawater near the equator, cannot entirely be ruled out."
"What are the consequences of a second term of Donald Trump? To even consider the question sends the left-leaning mind into a paroxysm. Everything from nuclear war to the utter collapse of American democracy looms large in the imaginations of otherwise sober-minded people.  In truth, the damage may be less immediately obvious. Life, in many ways, would go on. But the planet we inhabit will continue to heat up, and the most powerful government on Earth would be doing everything it can to further destabilize the environment around us. Just after the new year, the Trump administration announced it planned to radically revise the National Environmental Policy Act, a landmark measure that forced federal infrastructure projects to take into account their impact on the environment. Under the rewritten rules, builders of highways, pipelines, and other major infrastructure projects would no longer have to consider climate change when assessing their impact. It is, without question, one of the most grievous blows Trump has inflicted since taking office three years ago. It follows more than 100 environmental rollbacks, including relaxing rules limiting emissions from coal plants and weakening protections for endangered species. Fossil fuel projects like the Keystone XL oil pipeline would have free rein, undaunted by court challenges that ruled the Trump administration didn’t properly consider climate change when analyzing the pipeline’s impact. The new rules would dramatically narrow which projects would require environmental review, with many infrastructure initiatives sailing through the approval process without having to disclose plans to discharge waste, cut trees or increase air pollution. The new rule would no longer require agencies to consider the “cumulative” consequences of new infrastructure, a requirement interpreted as a mandate to study the effects of ruinous greenhouse gas emission and rising sea levels. The act currently requires the federal government to prepare detailed analyses of projects that could have major environmental effects. It was a Republican, Richard Nixon, who enacted the law in 1970 after the heavily polluted Cuyahoga River caught fire and a tanker spilled 3m gallons of crude off the coast of California. Though Nixon was a perpetual villain for leftists of the era, he created the Environmental Protection Agency, developing the crucial regulations under attack today. Even conservatives at the time acknowledged that the government had a role to play in being stewards of the environment we all share. We are in a new, terrifying age. Trump’s Republican party is far more savagely conservative than any version that came before it. It’s important to understand that the shredding of environmental regulations is not something that would have been unique to a Trump presidency, unlike his Twitter inanities or nonstop campaign rallies. The Koch brothers and other billionaire funders of the Republican party have been dreaming of the day they could again control the executive branch to pursue an agenda of environmental destruction.Trump presides over a party that denies the existence of climate change, that rejects science itself. There are few equivalents elsewhere. Even Boris Johnson’s Conservatives acknowledge there is a climate crisis afoot. But had Ted Cruz or Marco Rubio won the presidency in 2016, the assault on the EPA would have commenced as expeditiously as it is now. Perhaps they, like Trump, would have named a coal lobbyist to lead the agency. Four years of damage can be undone. Eight is far more difficult. The Democrats running for president, and the millions who will go to the polls this fall, must understand the planetary stakes. A functioning EPA is essential to reversing the worst effects of climate change, which are very likely to be felt at the cataclysmic rate the planet is warming. If Trump has eight years in power, fossil companies will have carte blanche to profit off environmental destruction for a very significant amount of time. The next Democratic president will not only have to undo Trump’s damage but rapidly play catch-up as the world races to secure a future for the human race. The doomsday clock is ticking."
"
Share this...FacebookTwitterA new paper appearing in the journal Urban Climate titled “Statistics on typhoon landfalls in Vietnam: Can recent increases in economic damage be attributed to storm trends?“, authored by Hiroshi Takagi, shows that tropical storm claims often made by climate alarmists are more fiction than fact. 

Tropical storm. Image: NASA
The paper concludes “it is reasonable to attribute the expansion of disaster-related economic damage to economic development and the fundamental volatility of typhoons.”
Hat-tip: reader Mary Brown
It also concludes:  “None of the meteorological trends such as frequency, central pressure, wind speed, or storm intensity show any significant increase or decrease over the last four decades.”
What follows is the paper’s abstract:


The Emergency Events Database (EM-DAT) indicates that the economic damage associated with storms has been rapidly growing in Vietnam. By contrast, the fatality rate due to storm-relevant disasters has been declining in recent decades. This study investigates whether typhoon trends have affected these outcomes. Best track data from the Japan Meteorological Agency (JMA) were examined to estimate central pressure and wind speed when typhoons made landfall. From 1977 to 2017, typhoons with wind speeds above 20 knots struck the country 105 times. A statistical analysis, which defined a storm’s intensity using principal component analysis (PCA), revealed that Typhoon Doksuri in 2017 was the strongest among the collection, followed by Cecil in 1985, Xangsane in 2006, and Damrey in 2017. The worst storm in history, Typhoon Linda in 1997, claimed over 3500 lives in southern Vietnam, but was only ranked 37th, demonstrating that typhoon intensity is not always the determining factor of fatalities.
Moreover, the analysis of variance (ANOVA) illustrates that none of the meteorological trends such as frequency, central pressure, wind speed, or storm intensity show any significant increase or decrease over the last four decades. However, landfall frequency has risen significantly, particularly in the northernmost part of the country where two large cities, Hanoi and Hai Phong, are located. A strong correlation was found between intensity and recent economic damage (r = 0.80) based on the proposed index of positive annual landfall storm intensity (PALSI). Given all of these factors, it is reasonable to attribute the expansion of disaster-related economic damage to economic development and the fundamental volatility of typhoons.”

Share this...FacebookTwitter "
"Scott Morrison needs to take action on global heating or he will become a “climate change casualty”, a former Victorian Labor premier, Steve Bracks, said. Bracks, who is chair of the $55bn industry superannuation fund Cbus, said the fires that have raged Australia have galvanised community support for action and he called on the Morrison government to put a price on carbon.  “It’s really in a sad position in Australia where we’re seeing effectively corporate Australia, industries, the financial sector and business who are leading on climate change and the government’s not,” he told Guardian Australia. The fires, which have burned more than 10m hectares, killed 28 people and covered Sydney and Melbourne with hazardous smoke, “made a world of difference” to public feeling about global heating. “People’s experiences are so important so I think there is a great appetite now for effective climate action in Australia, and even the prime minister I think is sort of starting to recognise that and move in that direction, and that’s a good thing,” he said.  “If he doesn’t do that I think he’ll be another climate change casualty in Australia.” Bracks said Cbus had focused on environmental, social and governance issues for about 10 years under its chief executive, David Atkin, who announced his retirement on Wednesday. Under Atkin’s leadership, Cbus has grown from an organisation with about $12bn under management that was, he said, something of a cottage industry, to one of the nation’s biggest funds. Atkin, who will step down in six months after almost 13 years in the job, said the fires had changed public sentiment on the climate. “There’s nothing like seeing the physical consequences – you can see it in Melbourne, there’s smoke everywhere,” he said. Super funds had “a really important role to play” in combating global heating. “We’re looking for companies that we invest in who have thought carefully about this, have done their scenario testing, understand what their footprint is from a carbon perspective and are changing their business models to ensure that they can be successful in the future,” he said. “We will not support companies, as investors, if we think that they are being too short term or aren’t taking that issue seriously enough.” Cbus and other industry funds are always under pressure from activist organisations to dump their shares in fossil fuel companies and other big emitters. But Atkin said refusing to invest in an industry category was the wrong approach and Cbus looked to invest in companies with a strategy to decarbonise operations. “We are not investing in companies we don’t have confidence in all the time,” he said.  “We do not have the dinosaurs in our portfolio because we’ve already made that call. We think they’re going to lose us money, not make us money.” Bracks said: “All the companies we invest in understand they have to have a long-term sustainable future and they have to assess the risk of climate change within that. “They know that there will be some stranded assets – particularly in energy generation – if we don’t get the right economic settings for investment in generation in the future, and so they’re really taking the lead and doing the work that the government should be doing.”  As well as pushing corporate Australia to take environmental, social and governance issues more seriously, including by serving as a member of a string of investor groups, Atkin also piloted Cbus through two royal commissions. The trade union royal commission, set up by the then prime minister, Tony Abbott, after the 2013 election criticised Cbus and Atkin over the leak of personal information about fund members to the construction union – before itself giving confidential Cbus documents to other parties. But Cbus skated through 2018’s banking royal commission after counsel assisting, Michael Hodge, QC, decided not to call any witnesses from the fund. Instead Hodge and the commissioner, Kenneth Hayne, held hearings that demolished the reputations of the for-profit sector – an outcome that embarrassed the government, which had included superannuation in the inquiry’s terms of reference in a bid to embarrass industry funds over their links to the unions. “We were to be called and they did not call us in the end and they were quite satisfied with the procedures we had in place, and that’s a good thing,” Bracks said. “So we take that as a seal of approval, but more than that the royal commission as it turns out was a great boon for industry funds, and certainly in our fund we had something like $1bn of net inflows extra compared to the previous year over the period of the royal commission.”"
"The speed with which the conservative side of politics and the media has gone from assuring us climate change was not a problem, so we don’t need to worry about reducing emissions, to asserting that climate change is a problem, but we still don’t need to worry about reducing emissions, is breathtaking. Literally, given the levels of smoke still around. You don’t get a cookie for saying you think climate change is real.  I’m sorry, you don’t. All you get is the capacity to say you have reached 1990 levels of comprehension – as that was when the first IPCC report was issued. You don’t get a prize for spending 30 years doing all you can to halt, undermine and dismantle action to reduce emissions, only to now say: “Hey, climate change is real.” Consider that the Sydney Morning Herald this week ran a front page story headlined “Minister slams climate debate”, with the lead that “Australia’s bushfire crisis has prompted a blunt warning from Science Minister Karen Andrews to those she says are wasting time arguing about whether climate change is real”. Oh good, that’s all sorted then. But when you read on, you see nothing in her statement suggest one iota of a shift in the government’s position on emissions. She told the Herald: “My starting position in the discussion tomorrow will be that the climate has changed and it continues to change. We need to focus on the steps to adapt and mitigate the impact of those changes.” The important point is she desires to mitigate the impact of the change, not to mitigate the actual change. Right now the government is indulging in the equivalent of responding to polio by promising to invest in more iron lungs. And bizarrely, it is getting credit for it. Adaptation is not mitigation. What is being said now is no different to what was said by Tony Abbott back when he was prime minister. In 2015, Abbott told parliament: “As far as the government is concerned, climate change is real. Mankind makes a contribution, and it is important to have strong and effective action to deal with it. “We have met and beaten our Kyoto targets ... We are on track to meet and beat our current commitments to reduce emissions by 2020 by 13 per cent on 2005 levels.” He then concluded: “I’m not going to put someone’s job at risk, a region’s, town’s future at risk, I’m not going to put up electricity prices to do it, I’m not going to put a tax on them to do it. I’m going to achieve it in the way we’ve met our Kyoto 2020 targets, meet and beat, and we’ve done that through better technology, through the policies we’ve put through the emissions reduction fund, and we’re going to continue to do that because it is really important.” Oh sorry, that wasn’t Abbott, that was Scott Morrison in his interview with David Speers last Sunday. If you can discern any difference in language between what Morrison is now saying and what Abbott said in 2015, then your level of reading between the lines has become so great you are seeing things that are not there. Just because we all desire the Coalition to do something on climate change doesn’t actually mean they will. And their actions over the past decade mean they have not earned the benefit of doubt, rather they have earned our total scepticism. The same goes for the conservative media. This week the NT News was getting praise for its front page, in which it stated: “What Australian needs now is real, affordable solutions – not armies of keyboard warriors.” But aside from the pretty random sideswipe at keyboard warriors, the statement is the perfect representation of meaningless dribble designed to sound like a bold stance. You know what is a real and affordable solution? Putting a price on carbon. And yet in the NT News editorial, the word emissions was not even mentioned, and I am prepared to bet my superannuation fund they would not suggest a price on carbon was an affordable solution. Similarly the Daily Telegraph’s editorial on Thursday on “Moving climate debate forward” praised the government’s policy and demanded the ALP come clean with how much theirs would cost. Give me strength. It seems that moving forward is reenacting the exact same coverage that occurred during the last election. You can’t say you agree with the science on climate change and then completely disregard the science that calls for the need to reduce emission by 45% from  2010 levels as soon as possible and to get to zero net emissions by at least 2050. Saying you agree with the science of climate change but that you believe the government’s current plan is adequate is like saying you agree with vaccination, but you chose to only get one of your three kids immunised because, heck, that is more affordable. The cheapest way to deal with the cost of climate change is to reduce our emissions and prevent, as much as is possible, further increases in global temperatures. Dealing with climate change will be tough – people will lose jobs, the prices of some things will rise, but the cost of inaction is going to be much greater and more damaging – both to our economy and to our society. Fortunately, the path to a vibrant emissions-free economy remains, and as Ross Garnaut has pointed out, such a shift will be extremely beneficial for our economy if we act now. Indeed perhaps the most frustrating thing about the past decade is that not only have we have wasted a chance to reduce emissions, we have forgone the opportunity to set up our economy for the next 100 years. Do not fall for the government’s spin. The need for action on climate change is the need to reduce emissions and to also take a leading role in that fight on the international stage. So when you hear someone in government say they believe in climate change, ask what they are doing about reducing emissions; everything else is spin."
"Imagine if more than a quarter of a century ago, the bushwalker David Noble had not stumbled across the stand of Wollemi pines and they had remained undiscovered. The trees survive in three stands in just one remote canyon in a massive wilderness to Sydney’s north-west. Until they were found, they were a species clinging to the edge of the precipice of extinction – just one disaster away from vanishing. A quarter of a century for a species with a lineage going back to the age of dinosaurs is not even a fraction of a millionth of a blip. And given the monumental effort that has gone into saving this desperately endangered wild population it is highly likely that had they not been found in 1994, then the past few months would have seen them wiped out without anyone ever knowing they still existed. The miracle of their discovery has become the miracle that has saved them – for now. I remember the day in a Sydney newsroom almost 20 years ago when an editor at the paper where I worked at the time heard that I was writing a book about the Wollemi pines. Even though the trees’ discovery in 1994 made news on front pages around the world, my boss walked over to my desk, looked me in the eye and said: “No one is going to read a fucking book about a tree.” Implicit in what he said was that no one cared about Wollemi pines enough to read a book about them. How wrong he was, was demonstrated this week as dramatic news emerged that the trees had been saved from the firestorm of the vast Gospers Mountain fire and people rejoiced. To see the photos of the ribbon of green of the Wollemi pines, surrounded by the charred towering clifftops and ridgelines, was a rare moment of joy and relief for a community that has watched so much destroyed during the past few months. When I visited the canyon in 1997 I was taken in by helicopter wearing a blindfold and then abseiled into a deep and dark prehistoric environment that was absolutely soaked and waterlogged. At the time it seemed impossible that such a place would ever burn. Now it seems impossible that it didn’t. The Wollemi pine has been a story that has captured people’s imaginations. It is a tale of high adventure and academic excellence. First, there was a dramatic canyoning exploration trip that led to its discovery, then scientific detective work to determine exactly what that 40-metre-tall tree found by Noble actually was, followed by the quest to understand how it survived unnoticed, so close to Sydney. Perhaps the significance of the discovery was best captured by a quote given to me by the then director of the Royal Botanic Gardens, Carrick Chambers, on the day the discovery was announced: “This is the equivalent of finding a small dinosaur alive on Earth.” What Chambers was alluding to and that most people don’t realise is that Wollemi pines are time travellers from a different Australia, from a warmer and wetter planet. Their history stretches back more than 100m years and they have survived natural climate change that has seen temperatures swing dramatically and sea levels rise and fall by hundreds of metres, multiple times. The trees tell the story of almost unimaginably deep time. Once, instead of gum trees, Gondwana – of which Australia was a small part – was covered in immense forests of Wollemi pines and their close relatives. These ancient trees deposited so much pollen that it is still found as fossils around the southern hemisphere, retrieved by geologists who find evidence of the trees in cores, from places like Bass Strait, that are kilometres thick. Then, 10m years ago, the trees begin to vanish from the fossil pollen record and two million years ago they disappeared altogether, indicating that the climate had shifted in a way that made their widespread survival untenable. Since then, as the planet shifted towards icier, colder, drier conditions, any surviving populations of the trees would have slowly shrunk, become separated and forced to retreat into the last refuges of wet deep rainforest canyons. After people arrived in Australia and widespread burning was practised, their fate was sealed to imprisonment in a single deep gorge. It is hard, after this week, to consider the remaining original Wollemi pines as wild. Only intensive water-bombing, the installation of emergency irrigation and the intervention of determined firefighting has allowed them to survive until the next threat. The trees are now dependent on us for their survival. And it’s not just our efforts to protect the canyon where they survive, it is also about the research that has seen millions of trees cultivated and sold commercially around the world. It is about the creation of back-up populations in other similar canyons in the greater Blue Mountains. It is also about the ongoing effort to keep the location of the trees secret and protected from fungal pathogens. The fact that out of this catastrophe, Wollemi pines have become a symbol of survival and all that is good about what we can do when we are determined to protect something, shows that all is not lost as human-made climate change tightens its grip. James Woodford is the author of The Wollemi Pine: The Incredible Discovery of a Living Fossil from the Age of the Dinosaurs, Text Publishing"
nan
"We are all too familiar with images of flooding in low lying areas after heavy rainfall or houses destroyed by coastal erosion after a storm. For an increasing number of people, coastal flooding and erosion is a real threat to property, the local economy and, in some cases, life. Hurricane Florence, for example, is forcing more than a million people on the US East Coast to flee from their homes. Coasts support important industries (such as ports and tourism) and their populations are growing faster than inland areas. But coastal areas are also particularly sensitive to impacts of climate change, which are likely to increase the extent, intensity and frequency of coastal flooding and erosion. So not only have we occupied areas that naturally flood and erode from time to time, we have changed the environment in ways that increase coastal flooding and erosion risk. And we continue to do so, sometimes with serious legal consequences. Meanwhile, public policies have not been very effective in managing this predicament.  Traditional hard engineering approaches of coastal protection (such as groynes, revetments and seawalls) are known to cause detrimental effects, which in the longer term can aggravate the problem they were supposed to solve. The impact of Hurricane Katrina in New Orleans was a stark reminder that engineering structures are not effective against all events at all times. They are built based on trade-offs between the level of protection needed and the costs of construction and maintenance.  Soft engineering, such as beach nourishment (where sediment, usually sand, is added to the shore), can offer a level of protection and beach amenity – but these reduce through time, as erosion continues. Meanwhile, “protection” gives a false sense of safety and enables occupation of risk areas, increasing the number of people and assets in risk areas. Climate change has forced a paradigm shift in the way coastal flooding and erosion risks are managed. In areas of lower risk, adaptation plans are being devised, often with provisions to make properties and infrastructure more resilient. Adaptation may involve requiring raised foundations in flood-prone areas or the installation of mitigating measures, such as sustainable drainage systems. Building codes may also be established to make structures more disaster-proof and to control the types of constructions within risk zones.  But such adaptation options are often of limited use or unsuitable for high-risk areas. In such areas relocation is the only safe climate-proof response.  Planning for relocation is problematic. There are large uncertainties concerning the predictions of climate change impacts – and this makes planning a difficult task. Uncertainty is not an easy concept to incorporate in planning and coastal management. In some places, effects of sea level rise are already evident, but it’s still difficult to be sure how fast and how much it will rise.  Similarly, there is still great uncertainty about when and where the next “super storm” will happen and how intense it will be. Inevitably, areas that have already been affected by flooding or erosion will be affected again – the question is when and how badly. Despite these issues, relocation is increasingly being adopted as a strategy. There have been some successes at the local level. One such example is the Twin Streams project in Auckland (New Zealand), where relocation (through the purchase of 81 properties) has provided space to create community gardens and cycleways where 800,000 native vegetation plants were planted. This was made possible by engaging over 60,000 volunteer hours.  Although not on the coast, the town of Kiruna in Sweden shows that, when risks are high, forward thinking and long-term planning can make large-scale relocation possible. Kiruna is at risk of ground collapse due to mining. Over a 20-year period, more than 18,000 residents will be relocated to a new city centre 3km away. The layout of the new city centre has been designed to be more sustainable, energy efficient and have better options for cultural activities and socialising. Local residents were engaged and helped identifying 21 heritage buildings they want relocated to the new area. The French, meanwhile, have instigated the first ever national strategy focused on relocation from high-risk areas. French policy places a duty on local authorities to develop plans by 2020, identifying the areas at serious risk of coastal flooding or erosion, what needs to be relocated and how (including sources of funding). Five pilot areas have been selected to test how the strategy might be implemented at the local level. Two of these areas have contrasting approaches and outcomes. In Lacanau (a top surfing stop in the Bay of Biscay) coastal erosion threatens the tourism-based economy. Although public opposition was initially high, the development of a local plan has generally been positive, mainly due to the inclusive community involvement in the project. A local committee was created to act as a consultation body and decisions were informed by open discussions based on clear communication of technical, legal, financial and sociological issues. In Ault (northern France) the experience was less positive. the risk reduction plan identified a high-risk zone within 70 metres of the cliff edge. It was decided that no new construction would be allowed here and restrictions to improvements on the existing 240 houses were imposed. This would force relocation if the properties were damaged by flooding or erosion. In May 2018 a residents group won a court case which considered the plan illegal, lifting the restrictions imposed on renovation of existing properties until a new plan is drafted. These examples demonstrate that engaging with local communities from the inception of any such project is essential. Unfortunately, people instinctively resist change – and relocation is a complete shift from the centuries-old approach of fixing coastlines and fighting against coastal dynamics. Our current legal and management frameworks are too geared up for maintaining the status quo. Funding and legal aid to support purchase of properties and removal of infrastructure that are not imminently deemed inhabitable are limited. But open and inclusive debate about the need for relocation and the consequences and benefits of it can change people’s perceptions. The “Nimby” (not in my backyard) attitude is strong in coastal communities, but can subside after personal experiences of severe flooding or erosion. The environment around us is changing and we cannot continue living the way we did in the past. Prevention is always less costly and more effective than remediation, particularly when involving people’s safety. The earlier we accept the need to change, the less damaged is the legacy we leave to the next generations."
nan
"
Share this...FacebookTwitterA commentary at flagship German online daily FAZ looked at a recent study by the German Umweltbundesamt – UBA – (Federal Environment Agency) which examined the per capita consumption of natural resources by different population groups.
Not surprisingly, high income groups were found to own a large number of cars and live in large homes with energy-guzzling appliances – thus making this group of people large consumers of energy.
Frequent flier climate activists
Also the study found that the “urban, academic young classes who tend towards voting for the Greens have far above-average CO2 emissions per capita” and these emissions “are not offset by them buying vegetables from the local region in the organic shop”.
The FAZ writes that the study found that this particular class — who are worried about the CO2 emissions and the climate — have “an above-average number of frequent flyers” and like to take long-haul flights to distant places like “New Zealand or Canada to admire nature”.
The UBA study also found that traditional working classes (whose lifestyles the Greens often complain about) in fact are energy modest and fly less frequently.
Here the FAZ concludes:
The bottom line of the study was that those with a ‘positive environmental attitude’ had the highest actual energy consumption and CO2 emissions.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Al Gore: “a hypocrite and a Pharisee”
The FAZ also mentions former Vice President Al Gore’s film “An Inconvenient Truth”, where he “praised his ‘CO2-neutral lifestyle’ and claimed he compensated for his air travel. But later it was exposed how Gore’s 10,000 square foot mansion in Tennessee consumed “about twenty times as much energy as the house of an average American family”.
“The green-preaching politician was a hypocrite and a Pharisee,” the FAZ commented over Gore.
Back to extreme poverty
The FAZ commentary also wrote about the “Fridays for Future” movement. Here the involved activists are calling on society to wean itself off fossil fuels. This for example could be done by enacting a high CO2 tax, they claim. However the FAZ comments that this would lead to “a sharp rise in energy costs, which would be difficult for low-income groups to bear” and that “millions of poor people in other parts of the world, such as Africa, would be pushed below the absolute poverty line.”
High energy tax “a death sentence”
According to the FAZ: “To put it bluntly, the path naively advocated by some well-off activists could, in extreme cases, be the death sentence for the poor in developing countries whose future well-being and survival they are supposed to be fighting for.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSince the 1980s, deaths attributable to excessive heat have declined, whereas deaths attributable to cold weather have not.

Image Source: The Guardian
Rising energy poverty with wind and solar energy penetration
Heating a home in the United Kingdom became 63% more expensive in the last decade, and electricity prices have risen by 80% in Germany since 2000. These developments can be traced to the increasing reliance on wind and solar energy in these developed countries (Lomborg, 2014).

Image Source: Lomborg, 2014
Significantly due to California’s heavy emphasis on wind and solar energy penetration, Californians’ electricity prices rose 5 times more than the other states between 2011 and 2017 (EnvironmentalProgress.org).
Californians pay 60% more for electricity than the rest of the country.

Image Source: EnvironmentalProgress.org
Cold weather is 20 times more deadly than hot weather
A 2015 study analyzing 74 million deaths from 384 locations across the world (1985 and 2012) revealed that cold weather killed 20 times more people than hot weather did (7.29% of mortalities due cold vs. 0.42% of mortalities attributed to heat).
A new paper (Sera et al., 2019) analyzes atrributable mortality trends in urban areas – 340 cities in 22 countries – and found there was a similar (but less pronounced) discrepancy between attributable cold deaths and heat deaths (6.05% vs. 0.56%) during 1985-2014 for the world’s cities.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Heat-related deaths are “low and non-significant” relative to exposure to cold weather in SW China according to another new paper (Deng et al., 2019).

Image Source: Deng et al., 2019
Cold weather death rates are increasing as heat deaths are declining
Two new papers (Díaz et al., 2019, Cheng et al., 2019) indicate that from Spain to Australia, heat-related mortality has been decreasing whereas cold-related deaths have risen in recent decades.
Vicedo-Cabrera et al., 2018 found heat-related deaths declined in 7 out of 10 countries studied since 1985 and no trends in cold-weather deaths.
It is likely that the rise in both energy prices and energy poverty have heavily contributed to the higher incidence of cold-related mortality in recent decades.

Image Source: Díaz et al., 2019

Image Source: Cheng et al., 2019

Image Source: Vicedo-Cabrera et al., 2018
Share this...FacebookTwitter "
nan
"Despite the dramatic news coverage of oil spills and other big pollution disasters in our seas and oceans, most environmental pollution is caused by much smaller incidents that are often invisible, persistent, and far more difficult to track. While animals and plants caught up in these disasters are easily identified as stressed or physically affected by the pollution, with smaller incidents, organisms might look and behave perfectly normal. Only over time does the chronic exposure to low-level pollution take its toll. By the time this becomes obvious, often it is too late to do anything to save a particular population, whose decline might have knock-on effects on the surrounding environment, often with socio-economic consequences. So there is not only a moral responsibility to look after the environment, but also a strong financial incentive, because many jobs and livelihoods depend on a healthy environment and its ecosystems. Biomarkers of exposure provide a tool to identify pollution events early on, often at levels that are not detectable by conventional methods. Loosely defined as measurable effects (endpoints) in organisms, providing evidence of exposure to pollutants, biomarkers lead to establishing the cause and giving the necessary data to inform any policy decisions that need to be taken. Such biomarkers exist in a number of biological areas. They can be purely biochemical, manifesting themselves as damages to DNA, alterations to the activity of enzymes involved in metabolism, structural damage to cells and their subsequent ability to perform properly, as well as more obvious pathological, reproductive or behavioural disorders. However, this requires intimate knowledge of the species and the relevant environmental variables, including how these may influence the respective biomarkers. The latest Intergovernmental Panel on Climate Change (IPCC) reports on climate change show that the upper 75 metres of the world’s oceans have been warming at a rate of 0.11°C per decade since at least 1971 and the uptake of CO2 caused by human pollution has depressed pH (acidity level) by -0.0014 to -0.0024 per year, and is predicted to continue. These changes are likely to affect biomarkers on three levels. First of all, commonly used organisms may no longer be available, as they migrate further north in search of cooler water. And they may then be replaced by invasive species from warmer waters that are not be as sensitive to pollution and therefore not as useful as biomarker organisms. Changing migratory patterns may increase the transport of contaminants in the bodies of organisms in significant quantities to other, previously clean locations, in some cases even becoming more important than wind or water-driven methods. Second, the fate and behaviour of contaminants in the environment, particularly their persistence, their ability to be taken up by organisms and how they behave once absorbed, is strongly driven by environmental factors such as salinity, pH and temperature – and these are all subject to change under climate change scenarios. This means, organisms may be more or less susceptible to pollutants; the degree of change will depend on the specific pollutants and the organism species involved. Last of all, organisms unable to migrate will experience increased stress owing to changes in temperature, salinity and pH which may mean they may no longer be sensitive enough for the biomarker task.  A major focus of research in my lab is working towards re-evaluating these biomarkers in several mainstream organisms and assessing the potential of new, better-adapted organisms. The main aim of this work is to future proof our tools for detecting pollution in the marine environment in order to maintain the ecosystem we all depend on. The evidence for climate change driven by pollution caused by humans is overwhelming and it is clear it is affecting the marine environment. As a result, some commonly used biomarker species and endpoints may need to be re-evaluated and adapted for this changing environment if they are to be used in future as early warning systems for pollution."
"
Share this...FacebookTwitterYet another region of the globe has not warmed (net) for the last 333 years.
The authors of a new study (Jiao et al., 2019) point out that temperature changes in the Tianshan mountains are “mainly influenced by the solar activity via the mean minimum temperature within approximately 11-year periods.”
Despite some warming since the 1950s, the authors do not maintain CO2 changes were an influencing climate factor in the 1680-2012 reconstruction.
The 1708-1801 period is shown to be about 1-2°C warmer than the the 1950-2012 period.

Jiao et al., 2019
“Regional climate change is affected by large-scale climate-forcing factors, such as solar activity and atmospheric–oceanic variability (Fang et al., 2010; Linderholm et al., 2015; Rydval et al., 2017). On the one hand, based on the MTM analysis results, the temperature changes in the study area are mainly influenced by the solar activity via the mean minimum temperature within approximately 11-year periods (Li et al., 2006; Wang et al., 2015). The tree-ring chronology was developed by samples of Schrenk spruce collected from the National Nature Reserve of the Western Tianshan Mountains. The mean minimum temperature in the growing season is the main and stable limiting climate factor. Therefore, the mean minimum temperature series in the growing season during 1680–2012 was reconstructed based on the STD chronology.”
“In the past 333 years, the mean minimum temperature has roughly experienced three relatively cold periods and relatively warm stages (relatively cold periods: 1680–1707, 1802–1911 and 1935–1997; relatively warm periods: 1708–1801, 1912–1934 and 1998–2012). By analyzing similar trends in regional temperature changes in our reconstruction series with drought events, large volcanic eruptions and other reconstruction series around the study regions in Xinjiang and even large-scale regions, we found that the mean minimum temperature of the reconstruction was accurate and reliant. Moreover, the mean minimum temperature was influenced by solar activity (sunspots) and large-scale atmospheric–oceanic fluctuations (NAO, WPO, ENSO, TBO) based on the MTM and spatial correlation analysis.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWell, wouldn’t you know it!  There he is again – behind another multi-million-dollar money-making scheme.
Al Gore is standing to rake in millions from a World Resources Institute meat consumption reduction report, one that will certainly help boost profits for the meat substitute manufacturers – in which Gore just happens to be a big stakeholder!

Al Gore has ties to meat consumption reduction report while holding huge stake in substitute meat company. Image: cropped here M4GW.
CNN recently reported here on the just published report from the global research nonprofit World Resources Institute. The 568-page report dubbed “Creating a Sustainable Food Future” recommends, among other actions, eating far less beef in order to rescue the planet.
Gore hack is WRI co-chair
But according to S___  at a thread at Twitter (see below), the WRI’s Co-Chair is David Blood. “David Blood is former Goldman Sachs’ Asset Management head who founded Generation Investment Management with Al Gore, yes that Al Gore,” S___writes under point no. 3.

1) So I was curious why there was this sudden push to cut meat, particularly beef consumption, it seemed to come out of nowhere, so I did a little research, a thread: https://t.co/8baJfISZ7c
— S____ (@_S70DD) August 4, 2019


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





So the report is now looking more and more like a junk-science-based instrument designed to boost the plant-based substitute meat industry, which include major companies such as Beyond Meat.
Kleiner Perkins: biggest Beyond Meat investor
Generation Investment Management is connected to Kleiner Perkins, where former Vice President Al Gore is one of its partners and advisors.
Who’s Kleiner Perkins? It turns out they are Beyond Meat’s biggest investor, according to bizjournals.com here. Beyond Meat is a Los Angeles-based producer of plant-based meat substitutes founded in 2009 by Ethan Brown. The company went public in May and just weeks later the more than quadrupled in there value.
Yes, Al Gore, partner and advisor to Kleiner Perkins, Beyond Meat’s big investor, stands to haul in millions, should governments move to restrict real meat consumption and force citizens to swallow the dubious substitutes and fakes.
If taken seriously, the World Research Institute Report, backed by Gore hacks, will help move the transition over to substitute meats far more quickly.
According to S___:
All these “We need to cut beef consumption to save the planet” stories originate from the World Resources Institute whose co-chair is a partner in the firm that collaborates w/ the main investor in @BeyondMeat and his co-founder is a partner in the main investor.”
Another dubious money making scheme that reeks of ethics violations and that needs to be investigated.
Share this...FacebookTwitter "
nan
"Following the 2015 Paris Agreement to hold the global increase in climate to below 2℃ above pre-industrial levels, the UN’s Intergovernmental Panel on Climate Change (IPCC) was asked to produce a report on the impacts of global warming of 1.5℃. The report focuses on what must be done if we want to avoid warming above 1.5℃, and the difference between 1.5℃ and 2℃ warming. The general message is that the ecological and social impacts of 1.5℃ are significantly more manageable than 2℃ – half a degree of warming is a big deal.  The IPCC thinks we still have a chance of keeping warming to 1.5℃. But current nationally determined pledges to take action to reduce warming, when combined, are emphatically “not on track to limit global warming to 1.5°C above pre-industrial levels”. The window of opportunity is small and shrinking – perhaps 12 years before a 1.5℃ target is unattainable, assuming in the meantime there is concerted global action to rapidly scale back carbon emissions. Without that action “researchers find very few (if any) ways to reduce emissions after 2030 sufficiently quickly to limit warming to 1.5°C”. The report is also pretty explicit in claiming that “unprecedented changes” are required to limit warming to 1.5℃. The language is dry and technical, so it’s easy to be lulled into a techno-fix mindset. For example, the required “system transitions” can be “enabled” by “an increase of adaptation and mitigation investments, policy instruments, the acceleration of technological innovation and behaviour changes”. But look closer, and in an important sense, the IPCC report is all about change and upheaval, especially for the well-off citizens of the developed nations. But it is change on a scale we have never experienced before: “There is no historical precedent for the scale of the necessary transitions, in particular in a socially and economically sustainable way.” We appear to stand at a crossroads. And according to Debra Roberts, co-chair of the IPCC Working Group that produced the report, the stakes could not be higher:  The decisions we make today are critical in ensuring a safe and sustainable world for everyone, both now and in the future … The next few years are probably the most important in our history. So can the report and its coverage actually contribute towards making the changes it implicitly demands of us urgent and extensive? Perhaps, but first we need to think a little more about the kind of change that is required. What tends to happen with this kind of information is that it gets translated into a checklist of things we can do to make a difference – as individuals. Those of us in affluent, “developed” societies – because those are the people to whom such lists are exclusively directed – can read the lists, think about what we can or already do individually, commit ourselves mentally to others, then park it and get on with our individual lives, busy, distracted, but doing our bit, and striving or hoping to do more.  Clearly, this is not enough. The need for this latest IPCC report is evidence of that. For some time now, many environmental activists and commentators have pointed out the limitations of individual behaviour and lifestyle change as the primary means of “making a difference”, and instead direct us towards “collective action”. As climate scientist Michael E Mann pronounces, the “single biggest way to have impact on climate change and other environmental crises is through collective pressure on policymakers to act in our interest rather than special interests”. There’s no doubt this is a key point. Change, of the speed and scope required, cannot rely on easily packaged discrete, simple, individual change checklists. We need to shift the story away from the individual towards what we can achieve together.  But where does that leave us – me and you – in terms of what to do? “Collective action” can feel alien, remote, even scary when it’s not already woven into our everyday lives. There’s a danger that we end up caught between the call to “act collectively” (which is difficult, uncertain) and individually (low-impact, compromised). To bridge this gap, we need to start by addressing the issue at the in-between level - with our family, friends, and the spaces and places of civil society. These, after all, are the spaces where climate change has a tendency to disappear once the headlines move on again.  We settle back into “socially generated silence” or “socially organised denial” around the issue. “What can we do about climate change” is a tangible taboo we politely talk around; not despite, but precisely because, of the reminders of scale of the problem we are exposed to. But this is also the space where we can make the first mundane and tentative steps towards something as grand as “collective action”. And there are some historical precedents here, even if they don’t match the scale of the global warming challenge.  The women’s suffrage and abolitionist movements, for example, were built on countless individual “choices” but not “behaviour and lifestyles changes” of the kind we associate with checklists. These movements depended on people starting (awkward) conversations in everyday settings. Collective action is here interlinked with individual choice – choosing to talk, perhaps through awkwardness and embarrassment at first, learning, voting, writing, protesting, divesting and investing, taking a stand and seeking out others to do it with; coming together, to demand societal and cultural change. This isn’t romantic – as the long grind that marked these movements attests, often in the face of virulent opposition. Collective action in response to climate change does depend on changes in individual choices and actions, then, but not those we tend to find on “how to make a difference” checklists. Let’s live without them, and start talking."
"The European shale gas boom has not materialised in the way that some were predicting. We are a far cry from the situation a few years ago, where interest in fracking in Europe was gathering pace on the back of the successes in North America.  The UK appeared to be leading the way, with drilling activities in north-west and south-east England. Companies started snapping up exploration licences right across the continent, and prospects from Scandinavia to the Urals found themselves being eagerly appraised. So what’s happened, and what do the prospects for Europe look like now? Of the countries in mainland western Europe, France has the most potential for unconventional hydrocarbons. The shales of the Paris Basin are thought to have major shale gas and minor shale oil potential, while the Jurassic shales in the south-east of the country may also have some shale gas potential. But a fracking moratorium has been in place since 2011, and was upheld in 2013. For the present, therefore, France ne frac pas. Germany, like France, has not permitted fracking since 2011. But unlike France, it does not have huge quantities of prospective shale. Most of the potential interest in fracking is for gas from low permeability sandstones and coal beds, and there have been moves recently to permit fracking at depths of more than 3,000 metres. The only other mainland western European country with significant shale gas potential is the Netherlands. There is considerable public opposition, however, particularly with conventional gas extraction having been linked to subsidence and induced seismicity in the Groningen area. No fracking for shale gas has been permitted so far. Shale gas in Europe by country With large areas of apparently prospective shale and a government supportive of fracking, Poland looked to be the frontrunner of the European shale gas boom. The reality has been rather more sobering, however.  Many boreholes have been drilled, few have produced the results that were hoped for, and most of the major companies have now withdrawn from the country. Polish shale gas may still prove to be viable in the long-term, but abundant shales and an enthusiastic political leadership do not guarantee fracking success. Ukraine was also seen as a major exploration target, with prospects for shale gas in both the west and east of the country. Exploration began in both areas, but subsequent political upheavals and the violent conflict in the Donetsk region have ensured that fracking has not taken off and has little likelihood of doing so in the near future. The prospective shales of western Ukraine continue into Romania and Bulgaria. Romania saw some exploration for shale gas by Chevron, but poor results and environmental protests saw the company pull out of the country in early 2015. Bulgaria, meanwhile, placed a moratorium on fracking in 2012. Hungary and the Lithuania-Kaliningrad region of the Baltic are also thought to have unconventional hydrocarbon potential, but little exploration activity has taken place. Shale oil in Europe by country The only Scandinavian country where shales have proven of interest is Denmark, where the US Geological Survey suggested that there were 2.5tn cubic feet (tcf) of onshore gas resources in the Alum Shale.  The government issued a moratorium on fracking in 2012, but Total was allowed to continue with exploration in Jutland and Zealand, with plans to carry out test drilling this spring. There have been reports that the government may consider lifting the moratorium if Total decides to go ahead with fracking on the back of good results.  The geology in southern Europe is tectonically complex. There are few shale basins, so the region has seen very limited interest in fracking. The Jurassic shales of the Basque-Cantabrian basin of northwest Spain are considered to have some potential for shale gas, and some exploration has begun there. It is clear there are very few European countries in which fracking is likely to happen any time soon, if at all. Many apparently prospective European shales have turned out to be more geologically complicated than expected.  This is related to the fact that although shale is a very common rock, it has not been a common subject of research – at least until recently. Much remains to be understood about how shales form, how they vary, and how they behave when fracked.  Environmental and political concerns have also come to the fore more than might have been anticipated, while the oil-price slump has made all efforts look much more expensive than they did a year ago.  For the companies concerned, this has changed the economics – particularly where the geology has proven complex. Europe’s shales were always going to be different to those of North America. To major companies, they now look a great deal less enticing.  Nonetheless, it is crucial that fracking research continues. A good understanding of shale geology is still in its infancy. If fracking is to take place anywhere in Europe, baseline environmental information from potential fracking sites needs to be collected, analysed, and made publicly available, along with long-term monitoring data.  Shale scientists must also develop meaningful dialogues with the public, explaining what we know and don’t know about the possible risks. The Research Fracking in Europe (ReFINE) project is involved in this work, looking at things like how far hydraulic fractures go, how large an earthquake fracking can cause, and the likelihood of leaks from shale-gas wells.  Meanwhile the EU announced several weeks ago that it was awarding €12m (£8.6m) to researchers looking at the environmental impact of fracking, and the risks of chemicals and gases being dispersed below the ground. Europe might never lead the world in fracking, but it can lead the world in fracking research."
"A little bit of bread and no cheese. This short phrase may conjure bucolic scenes of the British summertime in your head, or it may just remind you of what you need to grab from the shops on your way home.  If you fall into the former camp, you’re probably familiar with the song of the yellowhammer, a sparrow-sized bird recently thrust into our news cycle as the namesake of the Brexit no-deal contingency plan – “Operation Yellowhammer”.  The yellowhammer’s tune is believed to sound like someone saying “A little bit of bread and no cheese”. When naming their preparations for stockpiling food and other essentials, the UK government evoked the yellowhammer’s report of a bare kitchen cupboard.  But there’s more to the yellowhammer than the tune it sings. The fortunes of this plucky bird have their own complicated history with the EU. 

A male yellowhammer delivering its famous mnemonic.
 Yellowhammers (Emberiza citronella) are found in open habitats, particularly heathland and agricultural landscapes scattered with hedgerows throughout the UK and Europe.  They are a species of “bunting”, a seed-eating group of birds restricted to Europe, Africa and Asia. Recently, however, they were found to be more closely related to the sparrows and tanagers of the Americas than the sparrows and finches of Europe that they visibly resemble. The common name “yellowhammer”, or “yellow yorlin” as traditionally known in Scotland, refers to the male of the species, with its gaudy, canary yellow head and upper breast set against its brown-streaked body. By comparison, the female sports a rather drab off-yellow head and breast. Males are particularly noticeable during the spring and summer because of the stamina with which they sing their nasal songs, from the tops of small bushes and trees. Their conspicuousness explains the yellowhammer’s place in the folklore of rural idylls, inspiring poems by Thomas Hardy and Robbie Burns. In “Rural the place, with cart ruts by dyke side”, the poet John Clare wrote of the habits of the yellowhammer: Close to a hill of ants where Cowslips bloom And shed o'er meadows far their sweet perfume. In early spring, when winds blow chilly cold, The Yellowhammer, trailing grass will come, To fix a place and choose an early home, With Yellow breast and head of solid gold. As John Clare noted, yellowhammers begin nest building in early April, laying their eggs in nests low to or on the ground between mid-April and July. Their clutches are small – typically three to four eggs which vary in colour from light blue to reddish-brown. The surface of these eggs is covered by fine, ink-like squiggles, earning the bird another traditional name: “scribble lark”. Yellowhammers are resident in the UK, although they disperse away from breeding territories in the autumn and winter where they frequently form large flocks with other ground feeding birds in search of seed. Despite this, British birds are generally quite sedentary. Roughly 70% of British yellowhammers spend winter in habitats within five kilometres of their breeding territories. Adult yellowhammers typically live for three years, although research on individually marked birds has found the oldest to reach the impressive age of nearly 12 years old.  The simple, wheezing song of the yellowhammer has frequently cropped up in popular culture, even being credited with inspiring the opening “Fate at the door” motifs of Beethoven’s 5th Symphony. While Enid Blyton popularised the mnemonic “A little bit of bread and no cheese” as a familiar sound of the British countryside in her books and poems, it has in recent decades become notable by its absence. Yellowhammers are “red-listed” as a species of the highest conservation concern in the UK, as populations have declined by over 50% since the mid-1980s. Like many farmland birds, their decline is attributed to intensive farming practices brought about under the EU’s Common Agricultural Policy (CAP), which prioritised making the land as productive as possible. For example, a switch from spring to autumn crop sowing has reduced seed-rich foraging habitats that yellowhammers need to survive the winter, significantly affecting local populations.  However, a reform of the CAP in the mid-2000s brought in environmental stewardship schemes, which sought to restore and protect important habitats through environmentally sensitive farming. These schemes remain an important part of the UK’s efforts to halt the decline of farmland birds like yellowhammers. Agricultural subsidies, on a level with the CAP, have been guaranteed post-Brexit until 2022. However, it was recently announced that these payments will face a major shake-up from 2021, including a shift to prioritising habitat for wildlife and improved flood defences over the quantity of land farmed. Many have hailed this plan for ensuring that environmental protection in agriculture remains as part of a “green Brexit”, although as yet the amount of money farmers will receive from the public purse remains undisclosed.  Only time will tell, then, if Brexit spells fate at the door, or leaving with a little bit of bread, but no cheese for yellowhammers and beyond.  Five eggs, pen-scribbled o'er with ink their shells, Resembling writing scrawls which fancy reads As nature’s poesy and pastoral spells — They are the yellowhammer’s and she dwells Most poet-like where brooks and flowery weeds As sweet as Castaly to fancy seems And that old molehill like as Parnass’ hill On which her partner haply sits and dreams O'er all her joys of song—so leave it still A happy home of sunshine, flowers and streams. – The Yellowhammer’s Nest by John Clare."
"Prince William recently spoke at one of the largest illegal wildlife summits ever held in London. He said, “Poaching is an economic crime against ordinary people and their futures.” The quote could have been better. Poachers, after all, are merely the corner boys of the global illegal wildlife trade, the ones who benefit least financially and risk most, usually their lives. They’re ordinary people too, and vilifying them is not getting to the heart of the issue.  William had travelled to Tanzania, Kenya and Namibia in September and October this year, to learn about conservation, and a video of his trip to Tanzania was presented to the attendees. It did not go down well with various NGOs and campaigners who accused the video of promoting a “white saviour” image, given that only one African, a student, spoke to the camera, while the rest of the interviewees were international participants. Certainly, the team making the video could have better selected the participants and had a wider range of people speak. But that would be putting a sticking plaster over a very serious wound. There are fundamental issues at the heart of conservation, which as a movement was built on inequality and can also perpetuate that same inequality.  In the Guardian’s reporting of the Prince William incident, Dr Mordecai Ogada, director of Conservation Solutions Afrika, said: Conservation even now, nearly 55 years after Kenya got independence, is still the one arena where Prince William can waltz in to Kenya and tell us he wants us to do this, that or the other … He couldn’t do that in education, banking or other fields, but conservation still has that romantic, Out of Africa feel about it. This is the bigger issue we should be having a conversation about. Why, decades after the independence of many countries in the Global South, does conservation still have this (neo-)colonial undertone? In conservation, history is always present. Across the Global South, researchers like me often work in post-colonial landscapes, areas marked by evictions, forced settlement of herders, the fencing of large swathes of land for private use, or other access restrictions. This, understandably, can foster resentment, disenfranchisement and anger in people living in those regions.  I’ve looked at elephants in South Africa’s Kruger National Park, for instance, where the very name “Kruger” is divisive given he was an Afrikaner leader with a dubious relationship to conservation. There, the government has settled land claims of people who were dispossessed from the park land – for example, in 2016, six communities received 84m rand (£4.5m). Rates of visiting the park are still recovering from the fact that generations of South Africans who were classified as “non-white” were denied access to large sections of national parks under apartheid. I recently attended a session on human and wildlife “conflict” and coexistence in southern India. I realised this wasn’t a simple north-south issue. A lot of my Indian colleagues had also been trained under our current ideas about anthropogenic activities threatening biodiversity. This concept can risk bleeding into a perception of humans themselves being the threat. For example, an article in Nature on future threats to biodiversity and paths to prevent them takes on the distinctly misanthropic and negative “humans are killing the planet and all its inhabitants” when reported in the New York Post. At the same meeting, I heard sentiments way too close for comfort to the “noble savage” trope about communities, in this case local ethnic minorities, who live alongside wildlife. I was disappointed that we seemed to reduce people to bad guys, victims, or romanticise them even though conservation paradigms have supposedly shifted to centring, or at least considering people. As we talked about low-paid immigrant workers on tea plantations, I noticed there weren’t any representatives present. This risks them being “othered” and the psychological distance creating a space for us to accept them facing risks, like being killed by an elephant as they walked to work. I talked to a journalist colleague in Johannesburg and she shared a similar sentiment, the world wants wildlife stories about a collectively imagined “wild Africa”, not human stories. Because the human stories are complex, less palatable, and potentially threatening to biodiversity. And it’s a shame because Johannesburg is such a vibrant hub of entrepreneurship and creativity. We should be leaping onto that for conservation and collaborating, not seeing it as the opposition. I am not naïve enough to think that the global distributions of funding and biodiversity map onto each other. In fact, it’s no coincidence that richer countries have lost most of their large mammals in favour of agricultural, industrial and urban development. But how can we manage the funding and conservation efforts without perpetuating the “white saviour” issue?  The answer to me is clear. Conservation can’t be the preserve of people who can afford international travel and to take unpaid internships. We can make choices about communication, participation, training, educating, hiring, salaries, promotion and project leadership (let’s not trap people in assistant positions) and focus on diversity in those. The opening to every conservation text book reads like the fall from the garden of Eden and we have to turn that around; people (and not just white people) are the opportunity. Skills in spatial analysis, human behaviour, modelling data are vital to a vibrant and technology-driven approach to conservation and these are marketable skills. We need to capture this exceptional human talent, make sure a wide range of people have access to funding and ensure people feel heard in conservation so they choose to make it their career. There are already some incredible leaders and people sharing platforms, and hopefully Prince William will do that in his next speech."
"Museums, archaeological sites and historical buildings are rarely included in conversations about climate change, which tend to focus on the wider impact and global threats to our contemporary world. Yet these threats impact everything, from local cultural practices to iconic sites of outstanding universal value. In light of this, it’s worth exploring the relationship between our heritage and the changing global climate in more detail. More powerful storms, flooding, desertification and even the melting of permafrost are already destroying important sites at an alarming rate. While we race to preserve or record these places before they are lost forever, it is also the case that some sites – especially those that are or have been highly adaptable and flexible – can also be assets in understanding adaptation strategies more generally.  These questions are currently being explored by an expert working group, which we are part of. Our aim is to unpack the intersection between our changing climate and the world’s cultural heritage, specifically world heritage sites. Building on the Paris Agreement, which notes the importance of traditional and indigenous knowledge when thinking about adaptation strategies, we are exploring how global heritage can be used not only to stress urgency about the dangers and risks of climate change, but also as an asset to enforce community resilience and develop adaptation strategies for the future. Take Russia’s Treasures of the Pazyryk Culture. Located in the Altai mountains, this landscape of burial mounds (kurgans) and rock carvings derive from the Scythian nomadic culture of 2,500 years ago. A few of the two- to four-metre tall stone mounds have been excavated in the past. They reveal an incredible array of artefacts, complex funerary practices, and (most famously) tattooed individuals – all preserved due to the sub-zero conditions. The melting of permafrost due to rising temperatures is expected to significantly impact frozen tombs at the site by the middle of this century. The chemical and biological deterioration of the organic and inorganic contents, previously inhibited by the freezing conditions, is likely to accelerate rapidly, while associated ground movement could cause structural damage to the tombs themselves. The threat to these tombs from rising temperatures has been met with efforts to survey and protect them. While many indigenous people and heritage conservators aim to preserve the burials without disturbing them, it is not yet clear if this can be achieved. Elsewhere, rising sea waters and erosion are having a similarly disastrous impact. The Ruins of Kilwa Kisiwani in Tanzania, for example, are at considerable risk from the impact of increased surf, exacerbated by the loss of mangrove forestry on the island.  This site was founded in the ninth century and became a major trading centre by the 13th century. It was inscribed as a UNESCO world heritage site in 1981 as an exceptional testimony to the expansion of Swahili coastal culture, and to the spread of Islam in Africa in this period. Ongoing efforts are being made here to strengthen the sea wall protecting the site, and to encourage alternate land use strategies to increase natural protection. The area’s iconic heritage is helping to deliver important messages concerning climate change.  In Easter Island, meanwhile, rising sea levels and increasing storm surges are eroding the platforms (ahu) upon which famous statues (moai) are stood. Almost all of these statues are on the coast. It is very clear that climate change is having an adverse and worsening impact on these sites. This damage will destroy parts of the archaeological resource, including subsurface archaeological deposits that are particularly under-researched. The loss of these statues could have a significant negative impact on the tourism economy of Easter Island, affecting the livelihoods and resilience of the islanders. But we can learn a lot from some communities’ response to threat at such sites in the study of climate change resilience. While increased flooding and extreme weather conditions represent a considerable challenge globally, coastal and river communities have been living with (and adapting to) similar events for centuries.  A good example of this localised adaptation can be found on the river island of Majuli in the Brahmaputra River in Assam, India. Majuli is a landscape of both natural and cultural significance. The island is also home to over 30 ancient monasteries, known as sattras, which are repositories of both tangible and intangible culture.  Here, annual flooding has led to significant erosion of the river and the displacement of communities, many of which live outside of the protective levees constructed in recent years. Over hundreds of years, communities on Majuli have developed modular and portable building techniques using local materials including building on stilts. The river and its annual flooding have become part of the everyday experience of living on Majuli and is a part of the local worldview.  More permanent structures of the sattras are not immune to the impacts of the river and some have been moved up to five times over the last 300 years. These places and their associated cultural heritage have evolved to be portable, a valuable skill in a landscape which changes regularly.  It should be stressed that, even with these adaptations, the current pace of climate change is unprecedented and its impact on river and coastal communities will be disastrous. Yet, by better understanding places like Majuli, we will learn much about resilience and adaptation to the inevitable impacts of climate change."
"
Share this...FacebookTwitterDuring the Mid-Holocene, when CO2 concentrations were stable and low (270 ppm), Antarctica’s massive Ross Ice Shelf naturally collapsed, adding the meltwater equivalent of 3-4 meters to sea levels.
Because CO2 concentrations changed very modestly during the pre-industrial Holocene (approximately ~25 ppm in 10,000 years), climate models that are predicated on the assumption that CO2 concentration changes drive ocean temperatures, ice sheet melt, and sea level rise necessarily simulate a very stable Holocene climate.
In contrast, changes in ocean temperatures, ice sheet melt, and sea level rise rates were far more abrupt and variable during the Holocene than during the last 100 years.
Modern ocean changes are barely detectable in the context of natural variability

Image Source(s): Rosenthal et al., 2013; Climate Audit
The temperatures of the global ocean have changed by just 0.1°C in the last 50 years, and just 0.02°C during 1994-2013.
According to Levitus et al. (2012), the global ocean’s 0-2000 m layer warmed by 0.09°C during 1955-2010, while the 0-700 m layer warmed by 0.18°C during that span.
In the context of the Pacific Ocean’s 0-700 m temperature changes during the last two millennia (Rosenthal et al. 2013), that 0.18°C change in 55 years is barely detectable.
Mid-Holocene centennial-scale sea level fluctuations were much higher than today’s
During the Early Holocene, when continental ice sheets were still in the process of melting, sea levels rose at rates that ranged between 10 to 60 mm/yr, or 1 to 6 meters per century (Ivanovic et al., 2017; Zecchin et al., 2015; Hodgson et al., 2016).
During the Mid- to Late-Holocene, when relative sea level was about 2 meters higher than today’s levels, sea levels rose and fell at rates of a half-meter to a meter per century, with 13 mm/yr reached on decadal timescales.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Image Source: Meltzner et al., 2017

Image Source: Mörner et al., 2011
In contrast, the modern record indicates that sea levels only rose at a rate of 1.5 mm/yr during 1958-2014, or about 0.15 of a meter (6 inches) per century.

Image Source: Frederikse et al., 2018
Widespread collapse of ice sheets from 5000-1500 years ago
A new paper (Yokoyama et al. [2019]) suggests that the Antarctic (and/or Greenland) ice sheets melted to such an extent around 5000 years ago that they added between 3 and 4 meters to sea levels.
The Ross Ice Shelf (Antarctica) underwent “widespread collapse” during this period (Yokoyama et al., 2016), subjected to rates of retreat and sub-ice shelf water temperatures much higher than present.
These melting events occurred while CO2 concentrations were a low and quiescent 270 ppm.

Image Source: Yokoyama et al., 2019

Image Source: Yokoyama et al., 2016

Image Source: Yokoyama et al., 2016
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHysteria and insults get refuted
Australia’s election results are in, and once again major media are in state of shock.
The New York Times here for example called it a “stunning win” and claimed it was “propelled by a populist wave” that resembled “the force that has upended politics in the United States, Britain and beyond.”
The UK Guardian went on calling the result of the “climate change election” a “major upset”, complaining that in fact “the climate lost.”
The climate skeptic, German-language Ruhrkultour here commented that citizens have grown increasingly tired of the “climate hysteria”, and that this ultimately “cost Labour the election victory”.
Crosshairs on democracy
Now that the dust begins to settle, the search for answers begins in earnest. But as was the case in 2016 in the aftermath of Donald Trump’s stunning victory, don’t expect the losing side to acknowledge the truth and reality.
Rather look for them to search out a scapegoat. Expect them to even start criticizing democracy and blaming “misled voters”, who were deceived by fake news and populist disinformation campaigns. There will be more loud calls for even greater crackdowns on Internet social media platforms.
“Hope you die!”
The real reason for the loss by Labour is the towering arrogance that left of centre parties have been putting on display lately. Nothing illustrates this better than two tweets recently appearing:
Here’s the first by Australian academic, Daniel Best via Not Suit:

The salt is real. See as what a leftie socialist really wants of those that don't agree.
Agree or die.Convert or die. https://t.co/F38TZgpXew pic.twitter.com/V1irBDTLnR
— Not Suit (@Suitologist) May 19, 2019



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In other words it’s: “Vote for us, or eff yourself and die!”
That’s appalling. And these people think it’s “populism” or the “Russians” behind their losses? Try infantilism, and people being turned off by it.
Threats and insults
If these planet rescuers want to start winning elections again, they need to realize it’s their tantrummy, 6-year old attitude that’s turning everyone off. People are sick of — and frankly appalled — by all their phony “expertise”, bullcrap “consensus” claims, emotional hysteria and fake “climate crisis”. Never mind all the insults.
Yet, The Guardian pledges to get even more shrill about climate and use even bigger bogus threats.
Insulting the elderly
And here’s the second reaction, this one concerning the upcoming EU elections, by Matt Kelly


Source: Telegraph, via Twitter. Read story here.
So Mr. Kelly thinks the elderly are just disgusting incontinents who need constant cleaning up and cannot vote correctly.

Well, people are tired of being threatened and insulted into voting a certain way, and it’s people like Kelly and Best who are disgusting. This is the real reason why people aren’t voting for them.
Wishing us dead
And each time after they lose, none of us of course ends up dying and so in a tantrum they wish us all dead. Thankfully the majority of voters have been able to see through the infantile behavior.
In a way, The Guardian’s latest move ought to be welcome. It will only play into the hands of us “populists” and “deplorables” and ensure us more election victories ahead.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe German automobile industry today continues to be the real engine driving the country’s economy, but that may dramatically change for the worse – soon – according to economists Matthias Weik and Marc Friedrich in a commentary at the online news portal of the Deutsche Mittelstands Nachrichten (German Midsize Companies News – DMN).
The two authors focus on the economic direction of the German economy and how it is seriously threatened by the country’s obsession with climate protection and how policymakers are neglecting its key industry: automobiles.
Weik and Friedrich say that German policymakers are naive, and are in the process of ruining the German economy in their panic to rescue the planet from an alleged climate meltdown.
“Everybody is talking about the climate, yet no one is talking about the economic climate,” Weik and Friedrich say.
“Hard as nails” recession threatens Germany


The two economists warn of a coming recession, one that will be “hard as nails” as the ecological activist onslaught on German industry picks up.
According to the Weik and Friedrich, already “the seasonally adjusted and real order intake of German industry fell by 8.6 percent compared to the same month last year! For the tenth month in a row it is going down!”
“Companies such as Deutsche Bank, BASF, Bayer, Siemens, Thyssen, Ford have begun “massive job cuts or announced plans to do so”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The two authors say that new buzzwords, such as “unemployment” and “layoffs”, will soon be dominating the media and that “no one will talk about the shortage of skilled workers any more, let alone climate change”.
Climate activist policymakers “negligently gamble away” prosperity 
They write that the outlook for Germany’s key industry, automobiles, “is pitch-black” as the assault against the internal combustion engine continues unrelentingly.
The authors write: “If we actually continue to destroy our car industry – which accounts for 21 percent of our GDP – then everyone must be aware of the consequences.”
These consequences would mean economic shock waves not only for Germany, but also for Europe which massively relies on revenues generated by the German automotive industry, the authors explain.


Weik and Friedrich write that Germany’s policies “negligently gamble away” prosperity and that the “coming climate change in the economy will nip all irrelevant sham debates in the bud.”
“People in the streets”…”different demonstrations on Fridays”
They add: “The heated discussions and hysteria are a sign of the famous late Roman decadence and a warning sign of the crash. For many who demonstrate today, there will be no jobs in Germany tomorrow.”
Weik and Friedrich warn that as the “economic climate changes drastically and more and more people are standing in the streets without work […] we will see completely different demonstrations on Fridays. But then it will be too late.”

Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn a new study, scientists report that about  17,000 to 20,000 years ago, when CO2 levels hovered near 190 ppm, “summer temperatures were higher here [North Slope, Alaska] than they are today” (Kuzmina et al., 2019).

Image Source: Guthrie and Stoker, 1990 and The New York Times
In the modern climate, North Slope, Alaska (north of the Arctic circle) has a mossy tundra terrain and an absence of trees.
About 8,000 to 9,000 years ago, with CO2 levels lingering around 260 ppm, this region was imbued with both trees and animal species that today live many 100s of km south (Kuzmina et al., 2019).
Even during the Last Glacial Maximum (LGM) 17,000 to 20,000 years ago, when CO2 levels hovered near 190 ppm, “summer temperatures were higher here than they are today” (Kuzmina et al., 2019).

Image Source: Kuzmina et al., 2019
During the LGM, horses were the most common large animal living in this region of the Arctic, followed by bison. Horses had a “substantial dietary volume” of dried grasses year-round, even in winter (Guthrie and Stoker, 1990).
Even though CO2 concentrations have reached 410 ppm today, 220 ppm higher than during the LGM, Northern Alaska is too snow-covered and frigid for horses to occupy this region now.
As Guthrie and Stoker, 1990 conclude, the Arctic is presently “no place for horses” because there is too little for them to eat, and the food there is to eat is “deeply buried by snow”.

Image Source: Guthrie and Stoker, 1990
Share this...FacebookTwitter "
"Time is divided by geologists according to marked shifts in the Earth’s state. Human activity has clearly altered the land surface, oceans and atmosphere, and re-ordered life on Earth. This suggests that the planet has entered a new human-dominated geological epoch, called the Anthropocene.  However there has been significant scientific debate concerning exactly when this epoch began. We argue, in a new paper in Nature, that the Anthropocene began with the irreversible exchange of species between the New and Old Worlds following the 1492 arrival of Europeans in the Americas. The resulting global networks of trade led to a rapid, repeated, cross-ocean exchange of species, which is without precedent in Earth’s history. It provides an unambiguous event after which the impacts of human activity became global and set Earth on a new trajectory. Defining the beginning of the Anthropocene as a formal geologic unit of time requires two requirements to be met. First, that there is evidence of long-term changes to the Earth as a global system. Second, that there is a marker of a global event that can be dated in layers of rock, sediment from the ocean floor, or ancient glacier ice. This marker is called a Global Stratotype Section and Point (GSSP), also known as a “golden spike”. GSSPs have been used to define geological time for the past 600m years.  In our research we found that most previously proposed Anthropocene start dates, including the earliest detectable human impacts through farming and historic events such as the start of the industrial revolution, should be rejected. They are not based on a globally synchronous markers and may not be permanent changes that could still be seen in a few million years – the time span of a typical epoch. We found only two GSSP dates that fit. There was the 1610 Orbis (Latin for “world”) spike, when the impacts of the collision of the New and Old Worlds a century earlier were first felt globally. The species exchange between the Old and New Worlds is noted in the fossil record at this time, coupled with a marked drop in atmospheric carbon dioxide, centred on 1610. Then there was the 1964 Bomb Spike, the peak in radionuclide fallout from nuclear weapons testing, which is coincident with the acceleration of very recent global environmental changes.  While both GSSP dates appear to adhere to the criteria for the beginning of the Anthropocene, we suggest that overall, 1610 is the strongest contender. A drop in CO2, centred on 1610, was a result of European arrival in the Americas. This arrival led to the deaths of around 50m indigenous people, most within a few decades of the 16th century and mostly due to smallpox. The resulting near-cessation of farming across a continent and re-growth of Latin American forests and other vegetation removed enough carbon dioxide from the atmosphere to produce a pronounced dip in CO2 seen in Antarctic ice core records.   The decline in carbon dioxide fits the formal requirement of a dated global environmental change that is captured and preserved in natural material. The irreversible exchange of species fits the other requirement of evidence of long-lasting changes to the Earth. For example, fossil pollen of maize, a Latin American species, first appears in marine sediment in Europe in 1600, becoming common over subsequent centuries. In geological terms the 1610 drop in atmospheric carbon dioxide is also associated with the coolest period of the Little Ice Age – a period between about 1300 and 1870 when North America and Europe experienced colder winters – when many changes occurred in geological deposits worldwide. The boundary therefore also marks Earth’s last globally synchronous cool moment before the onset of the long-term global warmth of the Anthropocene. The second possible starting point which we and other research groups have identified is the 1964 peak in radionuclide fallout.  The advantage of this GSSP is that it is recorded in many geological deposits worldwide and it coincides with the huge acceleration of human impacts starting in the 1950s that continues to the present. Yet, from a geological perspective, there is one key disadvantage of this date: while nuclear weapons could dramatically alter the planet’s environment, so far they haven’t. The radioactive fallout from bomb tests is a very good marker, but is not itself an Earth-changing event leading to long-lasting changes. The start of the industrial revolution has commonly been suggested as the beginning of the Anthropocene. It is a clear turning point in human history and the rise of atmospheric carbon dioxide from fossil fuel use is a critically important long-term global environmental change.  However, there is a lack of a suitable golden spike at this time because most impacts were local – while smog soon covered towns in the north of England, most of the rest of the world continued largely untouched. Meanwhile the global exponential rise in carbon dioxide is too smooth an increase to form a marker.   We could instead date the Anthropocene from a hand-picked year, not tied to a specific event in the fossil or atmospheric record, but tied instead to broad change in the Earth as a system – this is how geologists date eras beyond 600m years ago where well-preserved rock sections and specific events are hard to find. However picking the year 1760 or 1800, or when ever, is fraught with difficulty as any date chosen would be open to challenge as being arbitrary. Nonetheless, the collision of the Old and New Worlds is linked to the industrial revolution. Europe’s annexing of the Americas provided major new imports of agricultural commodities, thereby freeing Western European labour from the land – this, alongside coal, was one of two essential precursors to the industrial revolution. So dating the Anthropocene to 1610, some 150 years prior to the beginning of the industrial revolution, is consistent with the material causes of that turning point in human history. Formally ratifying the Anthropocene as an epoch requires the agreement of a series of geological committees. If it is adopted, we consider it a defining moment for humans, a time that has fundamentally changed our relationship with our environment.   Embracing the Anthropocene essentially reverses 500 years of scientific discoveries that have moved humans to a position of increasing insignificance, from the 16th-century Copernican revolution and the modern understanding that our sun is one of 1024 stars in the universe, to the 19th-century Darwinian revolution that established humans as merely a twig on the tree of life with no special origin.  A 21st-century adoption of the Anthropocene reverses this insignificance: humans are not passive observers of Earth but central to it, where the future of the only place where life is known to exist is being determined by our actions. A more widespread recognition that human actions are driving far reaching changes to the life-supporting infrastructure of Earth will have implications for our philosophical, social, economic and political views of our environment. But we should not despair. The power that humans wield is unlike any other force of nature, it is reflexive and therefore can be used, withdrawn or modified. The first stage of course is recognising it."
"Trees do a lot more for us than you probably think. Their roots prevent soil from eroding, their canopies provide shade and their leaves decompose into nutrients for crops, which feed livestock. Trees provide homes for a diverse range of wildlife and tree crops, such as coffee, rubber, and hardwoods, support countless livelihoods and entire economies. Trees also mark boundaries and hold immense spiritual, cultural and social value for smallholder communities around the world. In the 1980s, charities proposed planting more trees to halt “desertification” in the Sahara Desert. This involved “afforestation” – planting trees where they had not grown for a while and “reforestation” – replacing recently lost tree cover. Today the idea is growing strong, and an array of private companies from adult website Pornhub (yes, Pornhub) to clothing brand Ten Tree are using trees as a marketing tool. 


      Read more:
      Pornhub has planted a few more trees, but don't pretend it's being responsible


 Businesses can offset their environmental impact by planting trees or supporting other forms of habitat restoration, so as to “pay off” the damage they cause locally. As climate change escalates, trees are in vogue for their potential to soak up the carbon dioxide we keep putting in the atmosphere.  The United Nations (UN) has even adopted a scheme for offering local communities and governments some sort of financial payout for saving trees from deforestation. This “economy of repair” has been adopted by some of the largest companies in their commitments to corporate social responsibility. One such programme is the Green Belt Movement – a Kenyan conservation NGO started by the late professor and Nobel Prize recipient Wangari Maathai.  Maathai’s original mission was to empower local people, particularly women, to overcome inequality through leading forest restoration and resisting the expanding Sahara Desert. Despite the involvement of charities and businesses, research has suggested that in programmes like these, it is farmers and local people, not companies, which make the biggest contributions to planting new trees. Since local people also inherit responsibility for them, it’s important that projects devised by outside parties are planned and executed wisely, and in the community’s interest. 


      Read more:
      Africa's got plans for a Great Green Wall: why the idea needs a rethink


 While some may argue that tree planting is a win-win for the environment whoever does it, offsetting is just another way of corporate greenwashing. Environmental damage in one place cannot somehow be fixed by repairing habitats elsewhere, sometimes on the other side of the world. Here are some of the ways in which indiscriminate tree planting can cause more harm than good. Diverse forests are often cleared for agricultural production or industrial use, and replaced by uniform stands of the same species selected because of their ability to grow fast.  Tropical forests in some cases take up to 65 years to regrow and their diversity cannot be replicated by a monoculture of reforested plots. Reforestation and afforestation schemes must decide which species are appropriate to plant – native or exotic, multi-purpose or fast growing, naturally regenerating forests or managed plantations. Sometimes the wrong species are selected and Eucalyptus (Eucalyptus globulus) is one such poor choice. Eucalyptus is usually chosen because it is fast growing and economically valuable. Yet, it is exotic to many places it is now planted and requires lots of water, which drains the water table and competes with native crops. In Europe, replacing broad-leafed native oak trees with faster growing conifers has meant that forest cover on the continent is 10% greater than it was before the industrial revolution. However, the new trees are not as good at trapping carbon but do trap heat more efficiently, contributing to global warming. Clearly, tree planting without due caution can do more harm than good. Tree species take a long time to grow and need continual care. However, tree planting schemes usually “plant and go” –- meaning they do not put resources into managing the trees after they are placed into the ground. Young trees are particularly vulnerable to disease and competition for light and nutrients and if not cared for, will eventually die. Trees planted by states or private donors may choose sites without consulting local communities, ignoring any of their customary land rights and management regimes. This locally-owned land may be in fallow or have different economic, cultural or spiritual uses. Blundering into planting in these places may exacerbate tensions over land tenure, spreading disinterest in tree care and stewardship. Dispossessed locals may move to existing forests and clear land for food production. Tenure rights over trees are also not always owned by whole households either, but divided between gender. Planting trees and asking questions later may sow tensions over land ownership for long after the project departs. It’s no surprise that trees are on the green economy agenda, but this does not necessarily mean that planting them is “green” or helpful for social harmony. Allowing trees to regrow naturally is not always effective either, as trees are unlikely to survive on their own. Community involvement is therefore crucial.  This means real consultation over site and species selection, property rights over the trees, their products, and the land they grow in and who takes on the labour to keep the trees alive after they are planted. If companies are serious about planting trees then they need to care about the communities that live with them and not just their own reputations."
"
Share this...FacebookTwitterFor those serious about taking concerted action to combat climate change, implications from a 2018 study suggest that the widespread abandonment of  smartphone use — which is collectively on track to add 125 megatons of CO2 equivalent per year by 2020 — may be key to preventing the planet’s catastrophic demise.

Image Source (adapted): Press-Herald
Most people haven’t considered their smartphones to be significant contributors to global CO2 emissions.
But they are.  And they are poised to become one of the more prominent obstacles to global efforts to reduce CO2 emissions in the coming decades.
The unsustainable expansion of smartphone emissions
A recent analysis by Belkhir and Elmeligi (2018) determined that the greenhouse gas emissions from the Information and Communication Industry (ICT) – smartphones and mobile devices, prominently – will grow from 1% of total global emissions in 2007 to 14% by 2040. That’s more than half of today’s relative contribution from the globe’s entire transportation sector.
In 2010, smartphone use added 17 megatons of CO2 equivalent (17 MT-CO2-e) to annual global emissions. By next year (2020), smartphone emissions are expected to reach 125 MT-CO2-e/year – a 730% explosion in just 10 years.
Last year (2018), there were 2.5 billion smartphone users.  Belkhir and Elmeligi suggest that if there aren’t serious efforts to reduce or eliminate smartphone use in the near future, the number of smartphone units across the globe may reach 8.7 billion by 2040.
This is unsustainable, dramatically undermining global efforts to reduce CO2 emissions.

Image Source: The Conversation
Protesters demand climate action


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This past weekend, climate change protesters took to the streets across the world by the hundreds of thousands.
Many of these protesters were children and youth.  They decided to skip school last Friday to demonstrate just how deeply concerned they are about the Earth’s climate.
There is little these young people can do to save the planet from extinction as far as directly influencing government policy.
However, there is something that they – and we – can do that would make a difference in reducing our CO2 emissions impact: give up our smartphones.
Permanently.
And encourage all our friends and family members to do the same.
Widespread smartphone renunciation would be a symbolic testament to our commitment to rescuing the planet from the oncoming climate catastrophe.
It’s not too late…yet.  Shall we begin?

Image Source: Belkhir and Elmeligi, 2018
Share this...FacebookTwitter "
nan
nan
"
Share this...FacebookTwitterHigher frequencies of drought and extreme rainfall are assumed to be associated with modern climate change. But long-term studies in both hemispheres indicate extreme precipitation patterns were more common prior to the 20th and 21st centuries. Natural variability dominates precipitation patterns so thoroughly that an anthropogenic signal cannot be detected in observed records.
Internal climate variability (ICV) masks detection of an anthropogenic influence in extreme rainfall patterns (Bhatia and Ganguly, 2019).

Image Source: Bhatia and Ganguly, 2019
Contrary to modeled expectations, there has been no “coherent picture” of an increase in extreme precipitation on a global scale in recent decades (Tabari and Willems, 2018).

Image Source: Tabari and Willems, 2018
There has been “little unequivocal evidence” of an acceleration of the hydrological cycle on a global scale in recent decades. Instead, recent trends are “caused by internal climate variability” (Miralles et al., 2016).

Image Source: Miralles et al., 2016
“No evidence was found for changes in extreme precipitation attributable to climate change in the available observed record” (van der Wiel et a., 2016).

Image Source: van der Wiel et a., 2016
“Natural variability appears to dominate current observed trends” in precipitation extremes (Kendon et al., 2018).

Image Source: Kendon et al., 2018
Since 1983, there has been no increasing or decreasing trends in precipitation detected on a global scale (Nguyen et al., 2018).


Image Source: Nguyen et al., 2018
There have been “no significant trends” in extreme precipitation (floods or droughts) on the East and West US coasts observed in the last 145 years. Further, “significant drought conditions that were common prior to 1900 have not been experienced by the present population“(Christy, 2019).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Image Source: Christy, 2019
There are “no significant annual trends” in extreme precipitation in central China (Yellow River region). Actually, warming “would bring less extreme heavy precipitation” (Jiang et al., 2019).

Image Source: Jiang et al., 2019
Not warm, but “cold tropical Pacific Ocean conditions are the principal driver of pan-[continental United States] droughts” (Baek et al., 2019).

Image Source: Baek et al., 2019
For Antarctica as a whole, “there has been no significant change in the precipitation from EPEs [extreme precipitation events] over the period considered here [1979-2016]” (Turner et al., 2019).

Image Source: Turner et al., 2019
An intensification of the hydrological cycle – the wet-gets-wetter-dry-gets-drier paradigm – was more evident prior to the 20th century according to Northern Hemisphere proxy evidence over the last 1200 years (Ljungqvist et al., 2016).

Image Source: Ljungqvist et al., 2016
Megadroughts and flood events “were more severe, extensive, and prolonged over Northern Hemisphere land areas before the 20th century” (Cook et al., 2015).

Image Source: Cook et al., 2015
For the Southern Hemisphere (Australia), extreme patterns in drought and flood events were “signficantly longer and more frequent” prior to 1900 (Tozer et al., 2016).

Image Source:   Tozer et al., 2016
Extreme daily rainfall events were “more extreme [during 1839-1899] than anything in the modern record” for the Australian cities of Melbourne, Sydney, and Adelaide (Ashcroft et al., 2019).

Image Source: Ashcroft et al., 2019
Share this...FacebookTwitter "
"It’s all very well choosing not to eat genetically modified (GM) food, or even banning it entirely, but what if you then rear your cows on GM soya? Can you really maintain a consistent moral objection?  This is the dilemma many European countries are faced with now the EU has proposed measures that will further de-harmonise rules on genetically modified organisms (GMOs). The latest proposal would allow member states to “opt-out” from the use of GM food and animal feed, thereby mirroring legislation passed earlier this year that allowed members to opt-out from GM cultivation.  The official aim is to allow member states to impose restrictions on GM food and feed “in respect of democratic choice and in the interest of consistency”. But countries expecting to pick and choose from different GMOs, whether crops, food or feed, will find their freedom heavily constrained. Any GM restrictions must still comply with EU law. This firstly requires that any measures be necessary to protect a “relevant legitimate objective”. Worries over the environment or public health don’t count – in theory these are dealt with under the initial authorisation process. This leaves objectives such as public morality, consumer protection or agricultural policy (preventing contamination between GM and non-GM crops, or having to change farms to use for GM crops). Even then, there must still be no arbitrary discrimination or disguised protectionism.  Consider the example of Ireland and Italy: two green, agricultural nations who may shortly be faced with serious headaches. Both have mixed feelings regarding GMOs and both have interests in prohibiting certain products, but crucially not all.  In particular, a substantial proportion of animal feed used in both Italy and Ireland is of GM origin. A 2010 report indicated that more than 90% of protein feed for livestock in Ireland contained EU-authorised GM varieties – mostly soya, maize, cotton and rapeseed. As imported feed is vital to keep Ireland’s cows and sheep well fed, and since it’s tough to guarantee zero contamination by GM sources, the country supported an amendment to EU legislation allowing for temporary tolerances of unauthorised GM feed at a level of 0.1%. Even if they would avoid GM feed in neutral circumstances, the market has created a high level of dependency by national producers on GM feed. This adds to a dilemma surrounding specific products produced nationally with GM counterparts produced outside the EU.  Rapeseed is an important crop in Ireland, for instance, just as it is in the UK. Although GM rapeseed is not currently authorised for cultivation in the EU, GM rapeseed food and animal feed grown elsewhere, mostly in Canada, is authorised.  Italy is Europe’s main producer of soybeans. As with rapeseed, you can’t grow GM soya in the EU, but GM soya products are authorised if imported, with the main suppliers based in America, Brazil and Argentina. Therefore European producers (all non-GM) are in competition with those beyond the EU, both GM and non-GM.  While Ireland and Italy depend on imported GM rapeseed and soya feed too much to impose restrictions, the two nations might be tempted to give their national producers a helping hand by attempting to prohibit GM rapeseed and soya food products. Yet if either were to prohibit these GM foods and not others, irrespective of any legitimate objective claimed, it would indicate “arbitrary discrimination” – whether direct or indirect. What of a general ban on GM food, based on consumer protection or public morality? Consumer protection won’t work. Shoppers could be sufficiently protected by labelling, which is already required (even if not considered full and accurate information).  Public morality might justify such restrictions, but if purely on GM food this would appear hypocritical. If public morality justifies a national ban on GM food, why is no such ban required for GM feed and GM crops also? Especially when the GM feed or crops lead eventually to food.  That just leaves environmental and health protection that could justify restricting one GM food and not another, or GM food generally and not feed or crops. However both are expressly excluded under the EU’s proposed legislation. Consequently, Ireland and Italy may be able to impose unilateral restrictions on GM crops, food or feed for a range of legitimate objectives. They could indeed be truly “GM-free”. However, if you claim public morality justifies prohibiting GM crops or food, you cannot then backflip and still permit GM feed.  Restrictions on cultivation might be permitted without restrictions on other GM products, but this is due to it also promoting separate objectives such as protection of traditional farming or producer choice. For the measures to be acceptable, they must be consistent."
"
Share this...FacebookTwitterAt Twitter NoTricksZone’s contributor Kenneth Richard posted this paper appearing in the Journal Science in 2011.
The papers find that “summer temperatures during the HTM in North Greenland were 2° to 4°C warmer in this part of the Arctic.

Atmospheric CO2 concentrations back then of course were much lower than the historically very modest 410 ppm we have today.
Share this...FacebookTwitter "
"Residents are struggling with the aftermath of Hurricane Florence, a record-breaking storm that has hit the US east coast and led to at least 32 deaths, floods and damaged homes. Meanwhile, Typhoon Mangkhut has been ravaging southern China. More than three million people were evacuated. In the last few years, AI has become ever more powerful. It can diagnose diseases, book restaurants, fake presidential speeches, and even compose hit music and produce trailers for horror movies. So in this new era of “big data” and “artificial intelligence”, do we have new tools to protect our society and manage the damage of such storms? AI demonstrated a superior ability to understand certain situations in 2016, when the programme AlphaGo beat Lee Sedol, 18-time world champion, at the game Go, the most sophisticated game in history. But is this superior capability seen elsewhere, too? Could, for example, AI understand, predict and manage natural disasters – such as floods – better than humans can? A computer game and a flood are obviously two very different things. But AI is catching up humans in understanding “things”. For example, researchers recently demonstrated that AI could help diagnose breast tumours from the medical imaging. And more preliminary research is showing that AI could definitely help us monitor floods and could perhaps even deliver more accurate early warning messages in the near future. In a recently published paper, I describe how I used two of the most popular AI techniques to monitor tweets and photos streamed from Twitter and a mobile app called MyCoast. These AI-based algorithms can identify the location mentioned in a tweet about flooding and describe the content of the photos to recognise flood scenes through intensive training with “worked examples”, photos manually labelled by humans using keywords. After such training, the trained AI could make a prediction about whether a new photo is a flood scene or not.  Diagnosing breast tumours and identifying floods is, of course, something that humans can do. But AI can up the potential of such human capability by a major scale. An AI programme, for example, can read thousands of tweets and photos in seconds. In addition, AI does not tire – its judgement is kept at the same level all the time. In comparison, human judgements are subjective, changing due to decreasing concentration and fluctuating emotions. So yes, AI is much more powerful than humans in these aspects, especially in terms of speed and volume. So should we be worried about this power? Many argue that we should worry about AI using natural disasters to destroy human society, as imagined in the recent movie Geostorm. Technology tycoon Elon Musk has also spoken of AI posing an “existential risk” to humans. But it is important to note that AI cannot compete with humans, at least in the foreseeable future, in many other areas. First, AI is a mimicking algorithm of human judgements. AI is better than humans in terms of speed and volume, but not in terms of quality. This is especially true of flood monitoring. My research demonstrated that AI could make mistakes in recognising flood scenes. However, this situation might change in the future, as it did in the case of the game Go. As more training datasets become available, the accuracy and reliability of AI’s predictions will be further improved. Second, AI is still weak when it comes to prediction. Although these algorithms can make acceptable forecasts within the scope of the past, predictions become wild when they go beyond the parameters of the training data. Say you are given a series of points to connect with a line. It’s relatively easy to guess what lies between the points as the guess cannot be absurdly wrong (assuming the data is not fluctuating too much). But it will be far more difficult to guess the point beyond the most right and the most left points because there is no evidence as to how they will change.  In terms of flood-monitoring, then, it is difficult to predict long-term flood  trends based on the past training datasets because climate change is fundamentally changing the trend of many hydrological factors. We have no acceptable training data in this case. But the most fundamental difference between AI and humans, I think, is the difference in consciousness, or more specifically, motivation. So far, AI will do whatever the users ask, but it cannot come up with an idea of its own. My two-year-old daughter can easily exceed AI when she says “I want that candy”. She can even improvise by saying repeatedly “I want want that candy” to emphasise her demand. I cannot imagine an AI algorithm that could do anything even close to that. At the end of the day, we need creative solutions, and AI is not capable of providing them. AI, then, is currently merely a tool to scale up human’s “understanding” and maybe “prediction”. It has a long way to go before it catches up with human thinking, creativity and motivation."
"Scott Morrison has issued an extraordinary rebuke of the New South Wales environment minister, Matt Kean, for suggesting federal Liberals are pushing the government to increase its ambition on emissions reduction. Asked about Kean’s call for the federal government to abandon its use of Kyoto carryover credits to meet its 2030 emissions target, Morrison told ABC’s AM that “Matt Kean doesn’t know what he’s talking about, he doesn’t know what’s going on in the federal cabinet [and] most of the federal cabinet wouldn’t even know who Matt Kean was”.  “We are dealing with our climate policies in the same way as we took them to the election … we will meet and beat our emission reduction targets,” Morrison said. At a press conference in Canberra, Morrison told reporters he did not regret the remarks. Morrison said although the government will review the possibility of reaching zero emissions by 2050, in line with its Pacific Island Forum commitment, it would not adopt the target if it “didn’t know the cost”. The treasurer Josh Frydenberg backed Morrison’s position, by saying Kean was “wrong” to say cabinet ministers want the government to do more on climate change. After an unprecedented summer season of bushfires which Kean and even Morrison himself have conceded is caused in part by climate change, the federal government is under pressure to do more to fight global heating. At the 2019 election a record number of voters nominated climate change or the environment as their top concern. Morrison has suggested the Coalition could go “even further” than the target of 26-28% emissions reduction by 2030, which was met with a chorus of approval from moderate Liberals but sparked warnings of negative consequences for Morrison by conservative Liberals and Nationals MPs. On Monday, Morrison denied that federal Liberals were pushing to increase emissions reduction ambition, telling broadcaster Sabra Lane that “what is being suggested by your question is that there are others [who want a stronger policy] – that just isn’t the case”. “The government is completely united on focusing on the challenge of the response to the current bushfire crisis and meeting and beating our emissions reduction targets and taking our climate policies forward over the next term of government.” Morrison said the government was still aiming for a 26% emission reduction, and noted that while the government had a target, “I can’t say that for everyone else” – a reference to the fact Labor will announce its target closer to the next election. Morrison ruled out a carbon tax, increasing electricity prices and “[wiping] out resource industries”. Morrison told 3AW Radio he had “no idea” if Labor will aim for zero carbon emissions by 2050 but acknowledged that “we undertook to look at that through the Pacific Islands Forum commitment I gave last year”. “But we need to understand what that means – I mean, people can say that, but what does that mean for jobs? Now I can’t answer that question right now … But I’m concerned it wouldn’t be a good thing. “People who make these commitments need to be able to tell people what it will cost them.” The Pacific Island Forum’s communique committed Australia and other Pacific countries to produce a 2050 strategy by 2020 which “may include commitments and strategies to achieve net zero carbon by 2050”. The federal Liberal MPs pushing for change include Katie Allen, who has said the government is “starting to move in the right direction but we have a lot more to do”, and Dave Sharma and Tim Wilson, who both welcomed Morrison’s comments last week on the need to “evolve” policy. On Sunday Anthony Albanese promised that Labor would “take climate change seriously” and have a “very strong” policy that aimed to be “as ambitious as possible” but did not commit to outbid the Coalition because he hoped the Morrison government would take action before the next election. Albanese confirmed that a 45% reduction target by 2030 is no longer Labor policy and described it as a “mistake” that Labor automatically maintained that target from the 2016 to 2019 election without further shadow cabinet reconsideration."
nan
"Hundreds of thousands of native fish are estimated to have died in northern New South Wales after rains washed ash and sludge from bushfires into the Macleay River. Parts of the Macleay River – favoured by recreational fishers – have been turned into what locals described as “runny cake mix” that stank of rotting vegetation and dead fish. One freshwater ecologist told Guardian Australia the impact of the fish kill might be felt for decades to come, with long-lived species like Australian bass hit hard. The NSW Department of Primary Industries has been receiving reports of “hundreds of thousands” of fish dead in the river since December 2019. Locals say rain in the past 10 days has seen more ash and mud from the parched and burned landscape running into the river. The disaster on the Macleay River is one of eight fish kills reported to the department this year, with the cause of most linked to lack of rainfall. Larry Newberry, a recreational fisher from Frederickton, near Kempsey, said he drove 100km to George’s Creek to survey the river last weekend. “I would say from what I’ve seen I would not be surprised that it’s wiped out every fish in at least 100 kilometres of the river,” he said. “The stench was overwhelming – it stank that much it made you heave. It’s the dead fish, the rotting vegetation and the ash from the fires and maybe the fire retardant. It is just like brown sludge. “I’ve been fishing the river for 50 years and I have seen fish kills before, but nothing of this magnitude. This will be happening in every east coast river that’s been hit by bushfires.” Newberry was critical of commercial fishing operations that had been catching Australian bass, and also the primary industry department for what he called its lack of response. Species seen dead and reported to Guardian Australia were Australian bass, eels, bullhead mullet, yellow-eye mullet, herring, gudgeons and catfish. Upstream from Kempsey at the town of Bellbrook, residents have been using pumps and hoses borrowed from firefighters to try and oxygenate the water. Newberry said he admired the efforts but feared it was “like pissing into a 40 kilometre an hour nor’easter”. James Pritchard, a founder of the Bellbrook Social Fishing Club, said rain on Thursday evening had raised the level of the river, but had “brought tonnes and tonnes of debris and dirt with it”. He said: “There’s more ash in the river now than I’ve ever seen before. The top of the river is covered in ash. The water looks like a runny cake mix. It’s terrible. “The river is finished for generations – I won’t see this come back in my lifetime. To say I’m fucking gutted isn’t the word.” Aboriginal elders relied on a healthy river for food and to teach culture, he said, and this would devastate those efforts. “This is so wrong. The DPI knew this was going to happen and they’ve put nothing in place,” he said. Prof Lee Baumgartner, a freshwater ecologist at Charles Sturt University, said the fish would have suffocated.  Adding ash and nutrients to the water promotes bacteria, which in turn removes oxygen from the water. And if the water becomes sludgy, fish are not able to pass enough water over their gills to extract oxygen. Even though efforts to oxygenate the water might seem futile, he said even one saved mature female bass could then go on to spawn and lay hundreds and thousands of eggs. He said there was a precedent for understanding the long-term impacts of an event such as this: major bushfires in 1939 had caused ash to run into the Lachlan River, and “the fish never recovered”. He said: “I think we’ll see more of these events as it rains. These things can have decades of impact. It can be really terrible.” The department’s “fish kills” page also has reports of hundreds of dead fish at Tilba Lake on the south coast of NSW, where soot had been reported on the banks, alongside dead bream, flathead, mullet, eels and blue swimmer crabs. Drought had also likely caused the death of thousands of fish in the Hastings River near Port Macquarie, the page reports. A NSW DPI statement said its fisheries department “continues to investigate a fish kill event on the Macleay River”. The statement said: “The suspected cause of the incident is poor water quality leading to low dissolved oxygen. Rainfall events are adding ash from the extensive bushfires throughout the region into local catchments, as well as other organic matter and sediment. This can cause rapid drops to oxygen levels in the water. “Fisheries staff have conducted numerous field assessments and the main species affected have been Australian bass, freshwater mullet and eel-tailed catfish. The number of fish impacted is estimated to be in the hundreds of thousands.” Community members were encouraged to report fish deaths or observations to the Fishers Watch hotline on 1800 043 536."
