"
Share this...FacebookTwitterExperts are finding out wind turbines are not only an inefficient way to produce electricity, but that they are also wrecking the environment, natural habitats and even the climate.

German meteorologist Dr. Karsten Brandt warns wind turbines are altering local climates. Image: Donnerwetter.de.
So far we know wind parks:

Are an erratic source of power
Have high maintenance costs
Involve recycling problems
Blight the natural landscape
Are a hazard to birds and wildlife
Result in deforestation and wrecked biotopes
Make people seriously sick (infrasound), and
Interfere with weather radars.

And according to one German prominent meteorologist, Dr. Karsten Brandt of Donnerwetter.de,  wind turbines are now even putting the brakes on wind speeds and even altering local climates.
How an environmentalist could support this form of energy is becoming increasingly mind-boggling. Hat-tip Die kalte Sonne here. The Donnerwetter.de press release follows:
Less and less wind due to more and more wind turbines?
An ever weaker wind is blowing across Germany. For example in the 1960s annual wind speeds of 3.7 meters per second were measured in Osnabrück, but now it’s only 3.2 m/s. That’s a drop of over 13 percent. Almost all weather stations in the country which were analyzed by the Bonn-based meteorologists at donnerwetter.de found that the trend looks similar. 
Wind speed has decreased “very significantly”
“In most places, the mean wind speed has decreased very significantly,” says Dr. Karsten Brandt. And he has a suspicion: “We believe that in the last 15 years more and more massive wind turbines have influenced the wind speed.”
The trend of ever decreasing winds was not observed out on the open sea, however. To the contrary: On the islands of Norderney or Helgoland the wind has in fact increased slightly over the past 20-30 years. Yet in northern Germany, just inland from the coast, i.e. just after the first wind rotors, the donnerwetter.de meteorologists found a decline in the average annual wind speed: from 3.8 – 3.9 m/s to less than 3.5 m/s.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Of course, the increase in building construction and especially high-rise buildings in Germany has had a slight braking effect,” admits Brandt. “The braking effect of wind turbines should, however, exceed this.”
Confirmed by other studies

A variety of studies support the meteorologists’ assumption. “Danish research has shown that air flow is weaker than before the turbines even 14 kilometers downstream from a wind farm,” says Dr. Brandt. 
This is an effect that the operators of such parks are concerned about. If a new turbine park is built in front of an existing park in the main wind direction, the losses could be over 50 percent, American studies have shown.
In northern Germany, there is now one wind turbine every 10 square kilometers. According to the donnerwetter.de meteorologists, the North German air flow is generating so much energy that a weaker north wind is now arriving at the north German interior. The situation is similar with westerlies, which are weakened by wind turbines in the Netherlands and Belgium. 
Wind park warming…”more heat inland”!
According to Dr. Brandt: “The weaker wind ensures less air exchange. This in turn drives up pollutant concentration in our air. Especially in the summer months, the lack of wind means more heat inland and less land-sea-wind circulation. In addition, the air is heated by the generators, as further studies have shown.” 
“Think again before further developing wind energy”

So far the wind has been considered as an almost inexhaustible source of energy – albeit being incalculable and poorly predictable. The fact that you can extract some of your energy from the wind turbines was seen as a pioneering achievement. 
“But the fact that man takes so much energy from the wind”, the climatologist concludes, “and considering the consequences, we should probably think again before further developing wind energy.”

Share this...FacebookTwitter "
"
Share this...FacebookTwitter

Within the last few years, over 30 papers have been added to our compilation of scientific papers that find the climate’s sensitivity to CO2 concentration changes is low to negligible.
Link: 85 Scientific Papers – Low CO2 Climate Sensitivity
A few of the papers published in 2018 that were added to the list are provided below.

Fleming, 2018


“The results of this review point to the extreme value of  CO2 to all life forms, but no role of  CO2 in any significant change of the Earth’s climate. … Many believe and/or support the notion that the Earth’s atmosphere is a ‘greenhouse’ with CO2 as the primary “greenhouse” gas warming Earth. That this concept seems acceptable is understandable—the modern heating of the Earth’s atmosphere began at the end of the Little Ice Age in 1850. The industrial revolution took hold about the same time. It would be natural to believe that these two events could be the reason for the rise in temperature. There is now a much clearer picture of an alternative reason for why the Earth’s surface temperature has risen since 1850.”


“There is no correlation of CO2 with temperature in any historical data set that was reviewed. The climate-change cooling over the 1940–1975 time period of the Modern Warming period was shown to be influenced by a combination of solar factors. The cause of the Medieval Warm Period and the Little Ice Age climate changes was the solar magnetic field and cosmic ray connection. When the solar magnetic field is strong, it acts as a barrier to cosmic rays entering the Earth’s atmosphere, clouds decrease and the Earth warms. Conversely when the solar magnetic field is weak, there is no barrier to cosmic rays—they greatly increase large areas of low-level clouds, increasing the Earth’s albedo and the planet cools. The factors that affect these climate changes were reviewed in “Solar magnetic field/cosmic ray factors affecting climate change” section. The calculations of “H2O and CO2 in the radiation package” section revealed that there is no net impact of CO2 on the net heating of the atmosphere. The received heat is simply redistributed within the atmospheric column. This result is consistent and explains the lack of CO2 correlations with observations in the past. The current Modern Warming will continue until the solar magnetic field decreases in strength. If one adds the 350-year cycle from the McCracken result to the center of the Maunder Minimum which was centered in 1680, one would have a Grand Minimum centered in the year 2030.”



Smirnov, 2018  


“From this, it follows for the change of the global temperature as a result at doubling of the concentration of atmospheric CO2 molecules [is] ∆T = (0.4 ± 0.1) K, where the error accounts for the accuracy of used values, whereas the result depends on processes included in the above scheme. Indeed, we assume the atmospheric and Earth’s albedo, as well as another interaction of solar radiation with the atmosphere and Earth, to be unvaried in the course of the change of the concentration of CO2 molecules, and also the content of atmospheric water is conserved. Because anthropogenic fluxes of carbon dioxide in the atmosphere resulted from combustion of fossil fuels is about 5% [Kaufman, 2007], the contribution of the human activity to ECS (the temperature change as a result of doubling of the atmospheric carbon dioxide amount) is ∆T = 0.02 K, i.e. injections of carbon dioxide in the atmosphere as a result of combustion of fossil fuels is not important for the greenhouse effect.”



Davis et al., 2018


“[T]he contemporary global warming increase of ~0.8 °C recorded since 1850 has been attributed widely to anthropogenic emissions of carbon dioxide (CO2) into the atmosphere. Recent research has shown, however, that the concentration of CO2 in the atmosphere has been decoupled from global temperature for the last 425 million years [Davis, 2017] owing to well-established diminishing returns in marginal radiative forcing (ΔRF) as atmospheric CO2 concentration increases. Marginal forcing of temperature from increasing CO2 emissions declined by half from 1850 to 1980, and by nearly two-thirds from 1850 to 1999 [Davis, 2017]. Changes in atmospheric CO2 therefore affect global temperature weakly at most.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Holmes, 2018 


“Calculate for a doubling of CO2 from the pre-industrial level of 0.03% [300 ppm]: [formula found in text] Calculated temperature after doubling of CO2 to 0.06% [600 ppm] ≈ 288.11 K. Climate sensitivity to CO2 is ≈ 288.14 – 288.11 ≈ – 0.03 K.”


“The change would in fact be extremely small and difficult to estimate exactly, but would be of the order -0.03°C. That is, a hundred times smaller than the ‘likely’ climate sensitivity of 3°C cited in the IPCC’s reports, and also probably of the opposite sign [cooling]. Even that small number would likely be a maximum change, since if fossil fuels are burned to create the emitted CO2, then atmospheric O2 will also be consumed, reducing that gas in the atmosphere – and offsetting any temperature change generated by the extra CO2. This climate sensitivity is already so low that it would be impossible to detect or measure in the real atmosphere, even before any allowance is made for the consumption of atmospheric O2.”



Allmendinger, 2018


“Knowledge about thermal radiation of the atmosphere is rich in hypotheses and theories but poor in empiric evidence. Thereby, the Stefan-Boltzmann relation is of central importance in atmosphere physics, and holds the status of a natural law. However, its empirical foundation is little, tracing back to experiments made by Dulong and Petit two hundred years ago. … For studying the pressure dependency, the experiments were carried out at locations with different altitudes. For the so-called atmospheric emission constant A an approximate value of 22 Wm−2 bar−1 K−0.5 was found. In the non-steady-state, the total thermal emission power of the soil is given by the difference between its blackbody radiation and the counter-radiation of the atmosphere. This relation explains to a considerable part the fact that on mountains the atmospheric temperature is lower than on lowlands, in spite of the enhanced sunlight intensity. Thereto, the so-called greenhouse gases such as carbon-dioxide do not have any influence.”


“While a theoretical calculation of such an absorption coefficient was not feasible, at least a principal explanation may be given: There is no good reason to assume that absorbed IR-radiation will be entirely transformed into heat. Instead, it is conceivable that a part of it is re-emitted, i.e. to say in all directions, before having induced a temperature enhancement.”


“This approach contradicts in many ways the conventional greenhouse theory: Firstly, the boundary processes at the Earth surface and at the lowest layer of the atmosphere are predominant, while the conventional greenhouse theory regards the whole atmosphere; and secondly—even more crucial—the radiation budget is solely determined by the air conditions of the atmosphere such as pressure and temperature while so-called ‘greenhouse gases’ such as carbon-dioxide do not have the slightest influence on the climate. Besides, the atmosphere cannot really be compared to a greenhouse, not least due to the absence of a glass-roof which absorbs IR-radiation, and which inhibits considerable air convection.”



Laubereau and Iglev, 2018


“Using a simple 1-dimensional model the global warming of the surface is computed that is generated by the increase of GHG and the albedo change. A modest effect by the GHG of 0.08 K is calculated for the period 1880 to 1955 with a further increase by 0.18 K for 1955 to 2015. A larger contribution of 0.55 ± 0.05 K is estimated for the melting of polar sea ice (MSI) in the latter period, i.e. it notably exceeds that of the GHG and may be compared with the observed global temperature rise of 1.0 ± 0.1 K during the past 60 years.”


“In conclusion we wish to say that we have performed a study of the infrared properties of carbon dioxide, methane, dinitrogen-oxide and water to estimate their contribution to the global warming in 1880 – 2015. Our results suggest that the IR properties of the CO2 are responsible for ~ 20% of the mean temperature increase of the surface [during 1880-2015] and notably less for CH4 and N2O.”



Liu and Chen, 2018


“CO2 and temperature records at Mauna Loa, Hawaii, and other observation stations show that the correlation between CO2 and temperature is not significant. These stations are located away from big cities, and in various latitudes and hemispheres. But the correlation is significant in global mean data. Over the last five decades, CO2 has grown at an accelerating rate with no corresponding rise in temperature in the stations. This discrepancy indicates that CO2 probably is not the driving force of temperature change globally but only locally(mainly in big cities). We suggest that the Earth’s atmospheric concentration of CO2 is too low to drive global temperature change.”


“Our empirical perception of the global warming record is due to the urban heat island effect: temperature rises in areas with rising population density and rising industrial activity. This effect mainly occurs in the areas with high population and intense human activities, and is not representative of global warming. Regions far from cities, such as the Mauna Loa highland, show no evident warming trend. The global monthly mean temperature calculated by record data, widely used by academic researchers, shows R~2=0.765, a high degree of correlation with CO2. However, the R~2 shows much less significance (mean R~2=0.024) if calculated by each record for 188 selected stations over the world. This test suggests that the inflated high correlation between CO2 and temperature (mean R~2=0.765-0.024=0.741) used in reports from the Intergovernmental Panel on Climate Change (IPCC) was very likely produced during data correction and processing. This untrue global monthly mean temperature has created a picture: human emission drives global warming.”
Share this...FacebookTwitter "
"It’s not surprising that the government’s recent white paper was controversial. “Taking back control” of UK regulation was one of the main objectives of the Leave campaign. But the white paper suggests that the UK will maintain the EU’s approach to a huge range of environmental, consumer protection and food safety regulation, by maintaining a “common rule book” with the EU for trade in goods. Or does it? According to the government, this “common rule book” only applies to rules that must be checked at the border. It isn’t obvious which rules apply. Speaking to the Environmental Audit Committee, the environment secretary, Michael Gove, recently concluded that while the UK will share food and animal and plant health regulation, it will go its own way on many issues, including “the way in which our food is grown”.  His comment seems to deny that much of EU agrifood regulation deals precisely with the process by which food is grown. This includes what pesticides can be used, and in what quantities, prohibitions on the use of hormones in farm animals, and so on. The white paper suggests some areas where the UK and EU could recognise that their regulation is “equivalent”, including organic labels. While this may seem like a technical distinction, in fact it is quite a central debate between the EU (which says the UK must follow its approach exactly) and the UK (which has argued that as long as its outcomes are equivalent, it should be able to go its own way).  So what on first glance seems like broad regulatory harmonisation is, upon further inspection, unclear in terms of its scope and coverage. The UK is clearly trying to maintain some wiggle room. In terms of non-goods related environmental legislation, such as rules for air pollution, species protection and habitat preservation, the white paper does not call for a common rulebook. Instead the UK government states that it won’t lower standards, and also commits to uphold international standards and agreements. This may sound inspiring, but in fact such commitments, known as “non-regression” clauses, are included in most EU free trade agreements – and have been widely criticised for doing precisely nothing. The government’s white paper states that its EU trade relationship will most closely approximate an “association agreement”. These vary widely – but by means of contrast, the EU-Ukraine DCFTA agreement, sometimes held up as a potential model for the UK-EU relationship, also contains commitments to harmonise with a broad range of environmental regulation. These don’t just include those that are related to trade in goods, but also air quality, climate change, public participation in environmental decision making, and environmental impact assessment. Of course, it’s fine for the UK to go its own way on environmental legislation, as long as it is able to maintain – or even improve, as Gove has suggested – EU levels of protection. And the UK government, at least initially, will adopt EU environmental laws, in the process of “transposing” them into domestic law. But this process is far from automatic, as the UK must replace the many monitoring and enforcement functions that the EU currently undertakes. There are ongoing consultations about how to replace these functions with a UK “environmental watchdog”. But fines for noncompliance, something that the EU employs, seem to be off the table in the discussion of options for the UK’s environmental watchdog. This raises concerns about whether the UK will have an equivalent ability to uphold environmental rules. Also, EU environmental principles, unlike the legislation, will not be “transposed” through the Withdrawal Bill. Upcoming environmental legislation is meant to address this deficit with a general statement of environmental principles and their interpretation and application. But it’s possible that these commitments may be “lighter” than those provided in the EU – simply requiring that the UK government consider them rather than requiring all legislation to be based on them. The precautionary principle is a good example to consider. It justifies a conservative approach to assessing risk on the basis that there may not yet be enough conclusive scientific evidence to establish environmental harm. The precautionary principle forms the basis of a number of EU bans or restrictions on US products. Donald Trump’s disparaging comments about the prospects for a UK-US trade deal under the white paper model reflect the US administration’s position that the UK should move toward its approach to regulatory approvals in areas such as GMOs, food additives, chemical washes for meats (including the infamous “chlorinated chicken”), which it describes as “science-based”.  Furthering this concern, the white paper confirms that the UK will pursue membership of the CPTPP trade agreement, a signed, but not-yet ratified, trade agreement between Australia, Brunei, Canada, Chile, Japan, Malaysia, Mexico, New Zealand, Peru, Singapore and Vietnam. However, the CPTPP’s “regulatory coherence” chapter arguably goes against the EU’s “precautionary” approach in this area. So what can we expect of the UK’s sustainability in the future? A lot seems to hang on trusting Gove’s assertion that the UK would only ever want to raise its standards. The UK is facing external pressures from the US, India and other countries to relax consumer protection standards. On top of this, there is a strong domestic lobby, led now by David Davis, the former Brexit secretary, arguing that the UK should not dampen its international competitiveness with pesky EU environmental standards.  The recent rebellion on the Customs Bill does not undermine the UK’s commitment to a “common rule book” with the EU. But in light of international pressures, as well as the prospect of weakening UK environmental monitoring and enforcement, Gove’s promises form a pretty shaky foundation for UK environmental standards."
"
Share this...FacebookTwitterUnmasking Marcott’s “Uptick”

20th century “uptick” from Marcott et al., 2013, RealClimate.org  
Almost immediately after it was introduced to the public, the lead author of Marcott et al. (2013) squelched the narrative that said the hockey-stick-shaped reconstruction he and his colleagues produced is a robust representation of modern global-scale temperature changes.
In an interview with Marcott published by RealClimate.org, it was acknowledged that the “uptick” does not represent a global-scale reconstruction, as it is based on only a few proxy records and lacks statistical significance. 

Despite this admitted lack of supporting evidence for the 20th century’s “uptick”, the Marcott et al. (2013) “hockey stick”-shaped graph has nonetheless been unskeptically cited by other authors nearly 700 times. 
Marcott’s compilation of 73 reconstructions
The same “73 globally distributed” proxy temperature records used to manufacture the Marcott et al. (2013) “hockey stick”-shaped graph above were featured two years earlier in Shaun Marcott’s Oregon State University doctoral dissertation.  
Marcott, 2011  “Late Pleistocene and Holocene Glacier and Climate Change”
One may view the graphical representations of all 73 proxy temperature records used for the 2013 “uptick” on pages 200-203 of Marcott’s 2011 paper (above link, about three-fourths of the way down). 
Interestingly, a majority of the graphs do not have temperatures extending to the right Y axis, indicating that most of the 73 proxy records do not encompass the modern era and preclude analysis of the relative temperature differences between the past and present.
In fact, just 32 of the 73 graphs have overall trend lines that extend to “0 yrs BP” in the Marcott dissertation paper.  The rest end somewhere in the Late Holocene (or earlier).  The 32 reconstructions that do extend all the way to the right Y axis are shown below.


Same data, contradictory results 
As even a cursory glance at the 32 reconstructions illustrates, Marcott’s 2011 paper showed no 20th century temperature “uptick” after a modest overall Holocene cooling trend.
A compilation of all 73 Holocene temperature trends for the past 11,300 years is presented in one compressed graph on page 204.  Notice that the large amplitude of variations involving temperature changes of several degrees Celsius shown in the proxy reconstructions has been replaced by much smaller variable ranges (tenths of a degree). 

In contrast, the 2013 paper — utilizing the very same 73 temperature reconstructions — depicts the explosive temperature rise during modern times popularized by climate activists. 

This glaring contradiction between Marcott’s 2011 and 2013 papers was pointed out by Professor Paul Matthews in a comment published by the journal Science.

Image Source: Science
Marcott’s selected reconstructions indicate 2°C warmer temps during the Early- to Mid-Holocene
Interestingly, the temperature reconstructions Marcott used to produce both his 2011 Ph.D thesis and his 2013 Science paper show that (a) Early- to Mid-Holocene temperatures were, on average, more than 2°C warmer than today, and (b) they varied throughout the Holocene by multiple degrees Celsius instead of by just the tenths-of-a-degree shown in both the 2011 and 2013 papers. 
Of the 32 reconstructions extending to the Y axis in Marcott’s papers, 25 clearly define the modern or present temperature relative to the past.  The other 7 did not have modern or present temperature values that were clearly defined in the body of the paper.   In the 25 reconstructions that did allow comparison, the compiled peak Holocene temperatures were determined to be 2.3°C warmer than today on average. 
This result wholly contradicts the claims of Marcott’s 2013 paper.
Examples of the warmer-than-today records
Perhaps Marcott did not look closely enough at the content of each paper he referenced.  Had he done so, he may have noticed that Rodrigues et al., 2009 indicate the “at present” temperature in the Iberian region is 15°C, which is about 1°C colder than it was during the Little Ice Age (16°C) and 4°C colder than the peak Holocene temperature. 

Isono et al. (2009) report that the “present” temperature is 16.7°C, but the peak Holocene temperature was 21.4°C, meaning that North Pacific temperatures were approaching 5°C warmer about 7,000 or 8,000 years ago.

Even a graph that initially appears to support a sharp rise in temperature during modern times (an “uptick”) like Nielsen et al. (2010) actually asserts the Holocene peak was  4°C warmer than the modern average in the body of the paper itself.

As mentioned, some graphs are identified as not clearly defining the modern temperature values.  However, as Bendle and Rosell-Mele, 2007 point out, the amplitude of past temperature changes could reach as high as 10°C within a matter of centuries.  This would appear to contradict the contention that Holocene temperature variability was much less pronounced (a few tenths of a degree spanning millennia).

Of note, none of the reconstructions analyzed support the contention that modern temperatures are unusually high or unprecedented.  
If the paleoclimate evidence doesn’t support a recent pronounced “uptick”, where does it come from?
To summarize, the proxy evidence from the peer-reviewed scientific papers that Marcott derived his global temperature data set compilation wholly contradicts Marcott’s apparent attempt to construct a Mann-like Holocene-length “hockey stick” temperature record.  
Marcott himself has acknowledged that the 20th century “uptick” is based on only “a few” reconstructions that are neither globally representative or statistically robust.  This begs the questions:
1. What data set is used to justify the depiction of a pronounced temperature “uptick”? 
2. Has the “uptick” been fabricated?
3. On what basis did the journal Science publish the 2013 version of a paper that is contradicted by an earlier work by the same author? 
The list of Marcott’s graphs
Below is the table of contents for the 32 referenced reconstructions extending to the right Y axis.  The warmer-than-now temperature value is emboldened on the right.  This list is followed by the pictorial representations of the Marcott-selected reconstructions and excerpts from the papers.  
Sachs, 2007 – Northwest Atlantic SSTs: +4.5°C, +9.5°C, +7.0°C = +7.0°C Rodrigues et al., 2009 – Iberian Shelf: +4.0°CBarrows et al., 2009 – New Zealand: +2.1°CBendle and Rosell-Mele, 2007 – North Icelandic Shelf: not clearly definedBarron et al., 2003 – Northern California: +1.3°C   Isono et al., 2009 – North Pacific: +4.7°CLarocque and Hall, 2004 – Northern Sweden: +2.1°C, +3.0°CEmeis et al., 2003 – NW Europe: +4.0°CKim et al., 2002 – Eastern Atlantic: +2.6°CKurek et al., 2009 – Yukon Territory: +2.0°CPelejero et al., 1999 – South China Sea: +0.25°CMcGlone et al., 2010 – Southern Ocean: +2.0°C, not clearly definedThornalley et al., 2009 – Subpolar North Atlantic: not clearly definedDeMenocal et al., 2000 – NW Africa: MWP “marginally warmer than present”Linsley et al., 2010 – Western Pacific: +0.5°C, +0.5°C Stott et al., 2004 – Western Tropical Pacific: +0.5°C, +0.5°CClegg et al., 2010 – Alaska: +1.0°CNielsen et al., 2010 – South Atlantic/Southern Ocean: +4.0°CFarmer et al., 2005 – South Africa: +1.5°CWeijers et al., 2007 – Tropical Africa: +1.3°CCastañeda et al., 2010 – Eastern Mediterranean: +1.5°CWeldeab et al., 2006 – Western Tropical Atlantic: +1.2°CBenway et al., 2006 – Eastern Pacific Warm Pool: not clearly definedHuguet et al., 2006 – Arabian Sea: +5.3°C , not clearly definedSchefuß et al., 2005 – Central Africa: not clearly definedSeppä and Birks, 2001 – Fennoscandia: +1.7°CSeppä et al., 2005 – Sweden: +2.5°C 

Holocene peak (+4.5°C, +9.5°C, +7°C) +7.0°C warmer than present
Sachs, 2007   Sachs, J. P. (2007). Cooling of Northwest Atlantic slope waters during the Holocene. Geophysical Research Letters 34, L03609, doi:10.1029/2006GL028495.


Holocene peak +4.0°C warmer than present 
Rodrigues et al., 2009   Rodrigues, T., Grimalt, J. O., Abrantes, F. G., Flores, J. A., and Lebreiro, S. M. (2009). Holocene interdependences of changes in sea surface temperature, productivity, and fluvial inputs in the Iberian continental shelf (Tagus mud patch). Geochemistry, Geophysics, and Geosystems 10, Q07U06, doi:10.1029/2008GC002367.


Holocene peak +2.1°C warmer than present
Barrows et al., 2007   Barrows, T. T., Lehman, S. J., Fifield, L. K., and De Deckker, P. (2007). Absence of Cooling in New Zealand and the Adjacent Ocean During the Younger Dryas Chronozone. Science 318, 86-89.



Holocene peak vs. present not clearly defined, warm/cool amplitudes of 10°C
Bendle and Rosell-Mele, 2007   Bendle, J. A. P., and Rosell-Mele, A. (2007). High-resolution alkenone sea surface temperature variability on the North Icelandic Shelf: implications for Nordic Seas palaeoclimatic development during the Holocene. The Holocene 17, 9-24.


Holocene peak +1.3°C warmer than present
Barron et al., 2003   Barron,  J. A., Heusser, L., Herbert, T., and Lyle, M. (2003). High resolution climatic evolution of coastal northern California during the past 16,000 years. Paleoceanography 18, 20-1 to 20-14



Holocene peak +4.7°C warmer than present
Isono et al., 2009   Isono, G., Yamamoto, M., Irino, T., Oba, T., Murayama, M., Nakamura, T., and Kawahata, H. (2010). The 1500-year climate oscillation in the midlatitude North Pacific during the Holocene. Geology 37, 591-594


Holocene peak +2.1°C and +3.0°C warmer than present
Larocque and Hall, 2004   Larocque, I., and Hall, R. I. (2004). Holocene temperature estimates and chironomid community composition in the Abisko Valley, northern Sweden. Quaternary Science Review 23, 2453-2465.


Holocene peak +4.0°C warmer than present


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Emeis et al., 2003   Emeis, K. C., Struck, U., Blanz, T., Kohly, A., and Woß, M. (2003). Salinity changes in the central Baltic Sea (NW Europe) over the last 10 000 years. The Holocene 13, 411-421.


Holocene peak +2.6°C warmer than present
Kim et al., 2002   Kim, J.-H., Schneider, R. R., Muller, P. J., and Wefer, G. (2002). Interhemispheric comparison of deglacial sea-surface temperature patterns in Atlantic eastern boundary currents. Earth and Planetary Science Letters 194, 383-393.


Holocene peak +2.0°C warmer than present
Kurek et al., 2009   Kurek, J., Cwynar, L., and Vermaire, J. C. (2009). A late Quaternary paleotemperature record from Hanging Lake, northern Yukon Territory, eastern Beringia. Quaternary Research 72, 246-257.


Holocene peak +0.25°C warmer than present
Pelejero et al., 1999   Pelejero, C., Grimalt, J., Heilig, S., Kienast, M., and Wang, L. (1999). High resolution UK37 temperature reconstructions in the South China Sea over the past 220 kyr. Paleoceanography 14, 224-231.


Holocene peak +2.0°C warmer than present (bottom), not clearly defined (top)
McGlone et al., 2010   McGlone, M. S., Turney, C. S. M., Wilmshurst, J. M., Renwick, J., and Pahnke, K. (2010). Divergent trends in land and ocean temperature in the Southern Ocean over the past 18,000 years. Nature Geoscience 3, 622-626.


Holocene peak not clearly defined
Thornalley et al., 2009   Thornalley, D. J. R., Elderfield, H., and McCave, I. N. (2009). Holocene oscillations in temperature and salinity of the surface subpolar North Atlantic. Nature 457.


Holocene peak not clearly defined, MWP “marginally warmer than present”
deMenocal et al., 2000   deMenocal, P., Ortiz, J., Guilderson, T., and Sarnthein, M. (2000). Coherent Highand Low-Latitude climate variability during the Holocene warm period. Science 288, 2198-2202. [Northwest Africa]


Holocene peak +0.5°C warmer than present (2 reconstructions)
Linsley et al., 2010   Linsley, B. K., Rosenthal, Y., and Oppo, D. W. (2010). Holocene evolution of the Indonesian throughflow and the western Pacific warm pool. Nature Geoscience 3, 578-583.                                        


Holocene peak +0.5°C warmer than present (2 reconstructions)
Stott et al., 2004   Stott, L., Cannariato, K., Thunell, R., Haug, G.H., Koutavas, A. and Lund, S. (2004)  Decline of surface temperature and salinity in the western tropical Pacific Ocean in the Holocene epoch.  Nature 431.


Holocene peak +1.0°C warmer than present
Clegg et al., 2010   Clegg, B. F., Clarke, G. H., Chipman, M. L., Chou, M., I.R., W., Tinner, W., and Hu, F. S. (2010). Six millennia of summer temperature variation based on midge analysis of lake sediments from Alaska. Quaternary Science Review, doi:10.1016/j.quascirev.2010.08.001.


Holocene peak +4.0°C warmer than present
Nielsen et al., 2010   Nielsen, S. H. H., Koç, N., and Crosta, X. (2010). Holocene climate in the Atlantic sector of the Southern Ocean: Controlled by insolation or oceanic circulation? Geology 32, 317-320.


Holocene peak +1.5°C warmer than present
Farmer et al., 2005   Farmer, E. C., deMendocal, P. B., and Marchitto, T. M. (2005). Holocene and deglacial ocean temperature variability in the Benguela upwelling region: Implications for low-latitude atmospheric circulation. Paleoceanography 20, doi:10.1029/2004PA001049.


Holocene peak +1.3°C warmer than present
Weijers et al., 2007   Weijers, J. W. H., Schefuß, E., Schouten, S., and Damste, J. S. D. (2007). Coupled Thermal and Hydrological Evolution of Tropical Africa over the Last Deglaciation. Science 315, 1701-1704.


Holocene peak +1.5°C warmer than present
Castañeda et al., 2010   Castañeda, I. S., Schefuß, E., Pätzold, J., Damste, J. S. D., Weldeab, S., and Schouten, S. (2010). Millennial‐scale sea surface temperature changes in the eastern Mediterranean (Nile River Delta region) over the last 27,000 years. Paleoceanography 25, PA1208, doi:10.1029/2009PA001740.


Holocene peak +1.2°C warmer than present
Weldeab et al., 2006   Weldeab, S., Schneider, R. R., and Kölling, M. (2006). Deglacial sea surface temperature and salinity increase in the western tropical Atlantic in synchrony with high latitude climate instabilities. Earth and Planetary Science Letters 241, 699-706.


Holocene peak not clearly defined
Benway et al., 2006   Benway, H. M., Mix, A. C., Haley, B. A., and Klinkhammer, G. P. (2006). Eastern Pacific Warm Pool paleosalinity and climate variability: 0 – 30 kyr. Paleoceanography 21, PA3008, doi:10.1029/2005PA001208


Holocene peak +5.3°C warmer than present (top), not clearly defined (bottom)
Huguet et al., 2006   Huguet, C., Kim, J.-H., Damsté, J. S. S., and Schouten, S. (2006). Reconstruction of sea surface temperature variations in the Arabian Sea over the last 23 kyr using organic proxies (TEX86 and UK37). Paleoceanography 21, doi:10.1029/2005PA001215.


Holocene peak not clearly defined
Schefuß et al., 2005    Schefuß, E., Schouten, S., and Schneider, R. R. (2005). Climatic controls on central African hydrology during the past 20,000 years. Nature 437, 1003-1006.


Holocene peak +1.7°C warmer than present
Seppä and Birks, 2001   Seppä, H., and Birks, H. J. B. (2001). July mean temperature and annual precipitation trends during the Holocene in the Fennoscandian tree-line area: pollen-based climate reconstructions. The Holocene 11, 527-539.


Holocene peak +2.5ºC warmer than present
Seppä et al. 2005      Seppä, H., Hammarlund, D., and Antonsson, K. (2005). Low-frequency and high-frequency changes in temperature and effective humidity during the Holocene in south-central Sweden: implications for atmospheric and oceanic forcings of climate. Climate Dynamics 25, 285-297.

Share this...FacebookTwitter "
"Sign up for updates on America’s public lands. Under this administration, nothing is sacred as we watch the nation’s crown jewels being recut for the rings of robber barons. For more than 100 years, professional management of our national parks has been respected under both Democratic and Republican administrations. Yes, they have different priorities, the Democrats often expanding the system and the Republicans historically focused on building facilities in the parks for expanding visitation. But the career public servants of the National Park Service (NPS), charged with stewarding America’s most important places, such as the Grand Canyon, Yellowstone and the Statue of Liberty, were left to do their jobs. Even in the dark days of interior secretaries James Watt and Gail Norton, both former attorneys with the anti-environmental Mountain States Legal Foundation, the National Park Service (NPS) was generally left untouched, perhaps because they recognized that some institutions have too much public support or their mission too patriotic to be tossed under the proverbial bus. This time is different and we should know, as Jon, one of this story’s authors, worked for the last 10 interior secretaries as a career NPS manager, and ultimately led the agency under Barack Obama, and Destry, Jon’s brother and co-author, has worked with the past 12 NPS directors as a conservation advocate. The change began within 24 hours of the inauguration when Donald Trump complained that the NPS was reporting smaller crowds on the National Mall than Obama had drawn. Perhaps this is when the NPS wound up on the list of transgressors. Soon the interior secretary, Ryan Zinke, attempted to double the entrance fees, rescinded climate policies and moved seasoned senior national park superintendents around to force their retirements. After Zinke’s abrupt resignation, secretary David Bernhardt populated too much of the department’s political leadership with unconfirmed, anti-public land sycophants, and announced a reorganization to install his own lieutenants to oversee super regions, realigning NPS from seven regions to twelve in the name of greater efficiency. Next came the proclamation that career staff in Washington would be sent to the field to be closer to the people they serve, but in reality, to be out of the way and no longer an impediment to his agenda. Then came the decisions to leave the parks open to impacts during the unfortunate government shutdown, illegally misuse entrance fees, open park trails to e-bikes, suppress climate science, kill wolf pups and bear cubs in their dens to enhance “sport hunting”, privatize campgrounds, and issue muzzle memos to park managers. With a waiver of environmental laws, bulldozers are plowing ancient cacti in national parks along the southern border in order to build a wall. Senior career park managers are likely to be replaced with unqualified political hacks. These are not random actions. This is a systematic dismantling of a beloved institution, like pulling blocks from a Jenga tower, until it collapses. You ask, why on earth would someone want to do that to the popular National Park Service, the subject of one of Ken Burns’ acclaimed documentaries and often called “America’s best idea”? Because if you want to drill, mine and exploit the public estate for the benefit of the industry, the last thing you want is a popular and respected agency’s voice raising alarms on behalf of conservation and historic preservation. Because if you want the public to ignore the science of climate change, the last thing you want are trusted park rangers speaking the truth to park visitors. Because if you want to get the federal government small enough (in the words of Grover Norquist) to “drown it in a bathtub”, the last thing you want is a government agency with high popular appeal that needs to grow rather than shrink. It is clear that this administration cannot be trusted with the keys to the vault of our most precious places that define us as a nation, such as Mount Rushmore or Yosemite national park. When this nightmare ends, and we begin to rebuild, we suggest it is time for Congress to consider making the National Park Service an independent institution, more akin to the Smithsonian, and no longer subject to the vicissitudes of a hostile political agenda in a Department of the Interior dominated by extractive industries and anti-public land crusaders. Brothers Jonathan and Destry Jarvis have spent a combined 87 years in the conservation of parks and public lands. Jonathan was the 18th director of the NPS and served in the agency for 40 years. Destry has spent 47 years as an advocate for national parks working for several non-governmental organizations and in the private sector. The opinions expressed here are those of the authors. For more information about how this project is supported, click here."
"
Share this...FacebookTwitterGerman ZDF public television recently broadcast a report showing how electric cars are a far cry from being what they are all cracked up to be by green activists.

Northern Chilean desert being ruined by widespread lithium mining. Image cropped from ZDF documentary: Die Schattenseiten der E-Mobilität
The report titled: “Batteries in twilight – The dark side of e-mobility” shows how the mining of raw materials needed for producing the massive automobile batteries is highly destructive to the environment. For example, two thirds of the cobalt currently comes from the Congo, where the mining rights have been acquired by China. Other materials needed include manganese, lithium and graphite.
Every electric car battery needs about 20 – 30 kg of lithium.
The mining of the raw materials often takes place in third world countries where workers are forced to work under horrendous conditions and no regard is given to protecting the environment. When it comes to “going green”, it seems everything flies out the window.
Immense water consumption
The report shows that one source of the lithium is the desert of northern Chile. Everyday at the mine shown some 21 million liters of ground water get pumped to the surface, where it evaporates and a sludge with 6% lithium content gets shipped to processing plants. The operations are transforming the Chilean desert landscape into a vast industrial wasteland.
Precious vegetation shriveling up
The Chilean lithium mining operations are pumping out what little precious groundwater that remains and ruining the living basis of the local population. What little vegetation there was to begin with is now dying due to falling water tables. Overall, mining operations are expected to expand four-fold within the next decade and the mining companies profit while the local citizens lose their livelihoods.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Car companies turning a blind eye
The automotive companies, the buyers of the lithium batteries insist that they have strict requirements in the sourcing of their products and make sure it is done in a sustainable way. Obviously they are having little effect.
Congolese slave labor for China
Today’s batteries for e-cars also require approx. 10 – 15 kg of cobalt, where two thirds of which comes from authoritarian Republic of the Congo. The mining rights are owned by Chinese companies. Here as well the benefits of the mining operations do not find their way to the local residents, who are forced live under horrendous conditions.
Privately operated local companies are not allowed, unless the authorities are paid bribes to look the other way. In these rogue operations, work conditions are primitive and extremely dangerous. The ZDF reports that some 20% of Congolese cobalt is extracted in this manner. Profits do not find their way down to the miners.
Child labor
Meanwhile the ground around the mining villages are now perforated with vertical shafts that pose a constant danger to children who risk falling into them. Work conditions for the miners themselves is extremely dangerous. The money they earn is not enough to provide for their families. Children are forced to work and do not go to school.
Chinese companies control most of the lithium supply chain, ZDF reports, and miners are cheated by them. The valuable raw material makes its way to China, where it gets processed for the manufacture electric batteries, according to Dr. Mathias John of Amnesty International. Congolese cobalt likely is contained in the car batteries of German electric cars.
German automakers such as Mercedes insist that they make effort to ensure that their supply chains “exclusively process cobalt from industrial mines that have the proper sustainability standards.”
As electric cars begin to flood global markets, the environmental and social destruction of third world countries where the precious minerals are mined will reach ghastly proportions. The promised green utopia will remain a an illusion.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterCNN and the Guardian just reported on a new study suggesting meat is bad for human health (even though humans and their ancestors have been eating and thriving on it for some 3 million years).
The authors also suggest that the healthy alternative is the vegan diet!
Meat tax “could save 220,000 lives per year”?
The team of scientists led by Dr. Marco Springmann who authored the new study published in the journal Public Library of Science ONE claim that a global meat tax “could save 220,000 lives and cut health care bills by $41 billion” a year.
The study’s authors assert that meat consumption increases risk of heart disease, cancer, stroke and diabetes, and is even “carcinogenic when eaten in processed forms, including sausages, bacon and beef jerky” and thus comparable to “cigarettes and alcohol”.


Dr. Marco Springmann is from the Nuffield Department of Population Health at Oxford University.
Springmann also claims: “Consuming red and processed meat not only affects your health but also the economy at large” due to “illness and care for family members who suffer with chronic disease.”
“Based on weak epidemiology”…”literally fake science”
However, since the paper was published, there’s been a hailstorm of criticism.
For example science journalist and the author of Big Fat Surprise, Nina Teicholz, tweeted that the results and recommendations made by Springmann are based on lousy science and “should never be used as a foundation for policy.”. At Twitter she wrote:


This is all based on weak epidemiology, the kind of science meant to generate hypotheses, not test them. This is, literally, fake science that should never be used as a foundation for policy. @cnn reporter should know better https://t.co/GATSRaluOk
— Nina Teicholz (@bigfatsurprise) November 8, 2018



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Lead author a vegan and climate activist!
Not only is the science dubious, but it turns out that the lead author of the paper itself is a vegan, and has also fallen for the junk science behind climate change!
Reader Simon Dwinder discovered the link:

""In his own case, it seemed a no-brainer to become a vegan ten years ago, when he realised that it is demonstrably healthier and better for the planet""https://t.co/9jpWWS4Lzd
— Simon Dwinder #StandUp4Brexit (@Sidwinder75) November 8, 2018

And (leftist) reader tlcoles November 8, 2018 added:


So the CNN article should have read “Ateam of researchers led by Dr. Marco Springmann, a vegan at the Nuffield Department of Population Health at Oxford University, produces science to declare meat bad…again.” 😂

The meaty, high-(good)fat diet worked fantastically for me
Personally 5 years ago I made the switch to the high fat, low junk-carb diet, eating plenty of butter, eggs, meat, nuts, cheese etc. and wound up losing 20 pounds and seeing my health return with full power. I no longer have to take any prescription medicines at all.
Vegan diet harbors huge health risks
Moreover, anyone doing the least amount of research will quickly discover that the vegan diet in many cases is a slow and tortuous suicide. Just ask KasumiKriss, who stopped being a vegan after four years and saw her health improve dramatically.
Other reading:
– Vegans and vegetarians more mentally unstable
– Meat scare “intimidation of the public”
– The sick kids of vegans 


Share this...FacebookTwitter "
"The government is fighting to keep secret draft versions of its strategy for helping the Pacific deal with climate change, prompting concerns it may be hiding changes that weakened the final report. The Department of Foreign Affairs and Trade released its climate change action strategy in November, detailing how the foreign aid program would be used to help developing nations – particularly those in the Pacific – deal with global heating. The department’s draft report had languished in the office of the foreign minister, Marise Payne, for nine months, and the delays had frustrated foreign aid groups, particularly given Pacific nations have identified climate change as the region’s single biggest threat. Seeking to understand whether the minister’s office influenced the final version, the Greens senator Mehreen Faruqi lodged a freedom of information request for the draft copy, which the department gave to the minister’s office in February last year. But the government is now refusing to release the draft, arguing it is not in the public interest and would “undermine the value and authority of the final climate change strategy”. The department is relying on exemptions in the FOI act that block the release of “deliberative matter” – material that has been used in the making of decisions. “I consider that there is no identifiable benefit or public interest to release this type of draft information,” the department’s decision-maker said. “Release of the deliberations that form part of the drafting process would undermine the value and authority of the final Climate Change Action Strategy. I therefore consider that it would not be in the public interest to release the draft Climate Change Action Strategy.” Payne was previously questioned about delays to the release of the final report during Senate estimates, following reports her office had sat on it for months. She said the release of the final report was delayed because changes were required to “better reflect our international climate change engagement prior to the Paris Agreement coming into effect in 2020, particularly noting – for those who are oblivious – that we have just had a federal election”. “The government wants to take the opportunity to make sure that strategies such as this and other relevant documentation are contemporary and are relevant to the changes in our commitments, which will be seen under the Paris Agreement,” Payne said in July. But Faruqi said the refusal to release the draft version “absolutely smacks of a cover-up”. She said the argument that there was no public interest in its release “makes no sense” and raised suspicion about efforts to keep it secret. “This strategy appears to have sat on the foreign minister’s desk for almost nine months and we simply don’t know how it was altered in that time,” she said. “The public has a right to know whether the government politically interfered to water down the strategy.” A department spokeswoman said the draft strategy was updated during the nine months to better reflect new government initiatives, including the announcement of $500m for climate and disaster resilience in the Pacific and $140m for a fund to mobilise the private sector on climate change. “An early draft of the Strategy was sent to the Foreign Minister’s Office in February 2019,” she said. “After the Government went into caretaker mode and the election was held, the Morrison Government made a number of decisions to build climate resilience and mitigation through the Pacific Step-up. The Strategy therefore needed to take these new initiatives into account.” Other changes between the draft and the final version included a stronger focus on social inclusion, updates to climate finance data, updated source references, and the addition of “more current case studies”, the spokeswoman said. Pacific nations have previously expressed frustration at Australia’s intransigence on climate change. During last year’s Pacific Islands Forum, Australia attempted to distance itself from language calling for urgent action on climate change, putting it at odds with other nations. It was successful in removing almost all references to coal and had worked hard to soften the language on climate change. The foreign affairs department has been approached for a response."
"
Share this...FacebookTwitterIt is often claimed that modern day sea ice changes are “unprecedented”, alarming, and well outside the range of natural variability.  Yet scientists are increasingly finding that biomarker proxies used to reconstruct both Arctic and Antarctic sea ice conditions since the Early Holocene reveal that today’s sea ice changes are not only not unusual, there is more extensive Arctic and Antarctic sea ice during recent decades than there has been for nearly all of the last 10,000 years.

Antarctic Sea Ice Extent
In the Southern Ocean surrounding Antarctica, the sea surface temperatures have been cooling since 1979.

Image Source: Jones et al., 2016

Image Source: Fan et al., 2014
Purich et al., 2018     “Observed Southern Ocean changes over recent decades include a surface freshening (Durack and Wijffels 2010; Durack et al. 2012; de Lavergne et al. 2014), surface cooling (Fan et al. 2014; Marshall et al. 2014; Armour et al. 2016; Purich et al. 2016a) and circumpolar increase in Antarctic sea ice (Cavalieri and Parkinson 2008; Comiso and Nishio 2008; Parkinson and Cavalieri 2012).”

Image Source: Purich et al., 2018
The decline in Southern Ocean temperatures has coincided with an increase in Antarctic sea extent since 1979.

Image Source: Jones et al., 2016
Comiso et al., 2017     “The Antarctic sea ice extent has been slowly increasing contrary to expected trends due to global warming and results from coupled climate models. After a record high extent in 2012 the extent was even higher in 2014 when the magnitude exceeded 20 × 106 km2 for the first time during the satellite era. … [T]he trend in sea ice cover is strongly influenced by the trend in surface temperature [cooling].”

Image Source: Comiso et al., 2017
In contrast to the post-1970s cooling and sea ice advance, Antarctica warmed and sea ice declined during the 1950s to 1980s.
Antarctica warming rapidly, 1950s-1980s
IPCC (2001):    “Another analysis of a 21-station data set from Antarctica by Comiso (1999) found a warming trend equivalent to 1.25°C per century for a 45-year record beginning in the 1950s but a slight cooling trend from 1979 to 1998. The slight cooling trend for this later 20-year period also was confirmed via analysis of surface temperatures over the whole continent, as inferred from satellite data.”
Fan et al., 2014:  “[S]ea surface temperatures and surface air temperatures decreased during 1979–2011, consistent with the expansion of Antarctic sea ice. In contrast, the Southern Ocean and coastal Antarctica warmed during 1950–1978.”
Declining Antarctic sea ice concentrations, 1950s-1980s
Sinclair et al., 2014     “We present the first proxy record of sea-ice area (SIA) in the Ross Sea, Antarctica, from a 130 year coastal ice-core record. High-resolution deuterium excess data show prevailing stable SIA [sea ice area] from the 1880s until the 1950s, a 2–5% reduction from the mid-1950s to the early-1990s, and a 5% increase after 1993.”
Miles et al., 2013     “Despite large fluctuations between glaciers—linked to their size—three epochal patterns emerged: 63 per cent of glaciers retreated from 1974 to 1990, 72 per cent advanced from 1990 to 2000, and 58 per cent advanced from 2000 to 2010.  … Indeed, several studies report increasing sea-ice concentrations in the study region from approximately 1980 to 2010, which is consistent with the predominance of glacier advance since 1990, when above-average sea-ice and fast-ice concentrations could have suppressed calving by increasing back-pressure on glacier termini. In contrast, reduced sea ice concentrations from the 1950s to the mid 1970s are consistent with glacier retreat during the 1960s and 1970s, when air temperatures were also increasing along the Pacific coast.”
Antarctic sea ice conditions were similar to today’s during 1897-1917.
Edinburgh and Day, 2016     “In stark contrast to the sharp decline in Arctic sea ice, there has been a steady increase in ice extent around Antarctica during the last three decades, especially in the Weddell and Ross seas. In general, climate models do not to capture this trend … This comparison shows that the summer sea ice edge was between 1.0 and 1.7° further north in the Weddell Sea during this period but that ice conditions were surprisingly comparable to the present day [during 1897-1917] in other sectors.”
(press release)     “We know that sea ice in the Antarctic has increased slightly over the past 30 years, since satellite observations began. Scientists have been grappling to understand this trend in the context of global warming, but these new findings suggest it may not be anything new. … The new study published in The Cryosphere is the first to shed light on sea ice extent in the period prior to the 1930s, and suggests the [sea ice] levels in the early 1900s were in fact similar to today“
New paper finds Antarctic (Peninsula) sea ice more extensive today than possibly any time in the last 10,000 years.
Belt, 2018     “Exceptionally, Massé et al. (2011) observed a general decline in sedimentary IPSO25 concentration in a short offshore transect from East Antarctica; a trend shown subsequently to be quite general for various other Antarctic regions (Belt et al., 2016). In the latter study, it was suggested that the origin of this trend might be found in the preferred habitat of the known source of IPSO25 (B. adeliensis), which has a tendency to proliferate in platelet ice, found most commonly in near-shore locations covered by fast ice (Medlin, 1990). As such, it was hypothesised that higher concentrations of IPSO25 might be found in locations proximal to ice shelves, since their basal melt acts as the major driver for platelet ice formation (Jefferies et al., 1993). Re-examination of some palaeo sea ice records based on IPSO25 added further credibility to this suggestion (Fig. 6), and Smik et al. (2016a) also identified highest concentrations of IPSO25 in near-shore surface waters soon after spring sea ice melt.”


Arctic Sea Ice Extent
“Extensive modern sea ice conditions” during spring (80% concentrations), but “consistently low” and “marginal” (<10%) sea ice conditions from 10,500 to 1,500 years before present.
Köseoğlu et al., 2018     “The core 70 site is characterised by extensive modern sea ice conditions (≈80% SpSIC [Spring Sea Ice Concentration]) and the downcore record represents a gradual evolution of sea ice cover in the northern Barents Sea from ice-free conditions during the early Holocene to prolonged seasonal sea ice presence prevalent in the region today. The primarily insolation-controlled southward expansion of sea ice cover previously inferred for the core site throughout the Holocene (Belt et al., 2015; Berben et al., 2017) is reflected in the CT model assessment. Consistent with the onset of the Holocene Thermal Maximum and the resulting proximity of the annual maximum sea ice edge to the core site between ca. 9.5–8.5 cal kyr BP evident from low PIIIIP25-derived SpSIC (ca. 5–15%), the CT model predicts mostly marginal sea ice conditions during this interval. … From ca. 10.0–1.5 cal kyr BP, ice-free conditions characterised the core 11 site, as evidenced by consistently low SpSIC (ca. <10%) and marginal sea ice conditions predicted by the CT model, and further supported by an enhancement of AW [Arctic Water] inflow to the core site from ca. 9.8 cal kyr BP (Groot et al., 2014).”

“Lower than modern” sea ice conditions between 2,200 and 1,200 years before present.  Little Ice Age sea ice conditions “possible similar to conditions as observed today”.
Kolling et al., 2018     “Our biomarker record indicates that Disko Bugt [West Greenland] experienced a gradual expansion of seasonal sea ice during the last 2.2 kyr. Maximum sea ice extent was reached during the Little Ice Age around 0.2 kyr BP. Superimposed on this longer term trend, we find short-term oscillations in open water primary production and terrigenous input, which may be related to the Atlantic Multidecadal Oscillation and solar activity changes as potential climatic trigger mechanisms.  The period between 2.2 and 1.2 kyr BP, with lower than modern sea ice conditions in Disko Bugt (Fig. 6b), coincides with generally warm conditions over the Greenland Ice Sheet.”
“During the last 0.1 kyr, all biomarker concentrations showed an increase, brassicasterol and HBI III reach maximum values in the uppermost sample (80 µg/gTOC and 1.8 µg/gTOC, respectively; Fig. 3b, d).
“[During the Little Ice Age (0.7–0.2 kyr BP)] our biomarker record supports harsher sea ice conditions, possibly similar to conditions as observed today (Fig. 6b), indicated by strong increased in IP25 concentration and the PDIP25 index (Fig. 4c, d). …  A self-amplifying system may have caused the environmental changes observed in Disko Bugt area as follows: solar triggered Arctic sea ice melt [Ruzmaikin et al., 2004] increases freshwater supply towards the North Atlantic causing a reduction in sub-polar gyre activity and AMO [Holland et al., 2001, Schmith et al., 2003] as described by Sha et al. [2016]. This may in turn cause distinct changes in WGC composition and meltwater supply from the Greenland Ice Sheet that affects phytoplankton blooms in West Greenland.
“We find that the Disko Bugt area was influenced by seasonal sea ice over the last 2.2 kyr BP. The overall sea ice trend indicates a development from a reduced sea ice cover during early spring, with sea ice algae productivity hampered by light availability to a gradual extend of the sea ice season from 1.2 kyr BP onwards. This change in sea ice extend is parallel to decreasing Northern Hemisphere atmospheric temperatures and culminates in the Little Ice Age around 0.2 kyr. We assume that modern conditions, with sea ice present until late spring and the presence of a stable ice edge at Disko Bugt, established around that time [~200 years ago].”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->







Other Arctic reconstructions indicate more extensive sea ice conditions exist today than most of the Holocene.

Image Source:  Yamamoto et al., 2017

Image Source: Perner et al., 2018
Nothing unusual or unprecedented: ‘Internal variability’ or natural cycles responsible for half of the Arctic sea ice loss since 1979.
Yu and Zhong, 2018    “The underlying physical mechanisms for the Arctic warming and accelerated sea ice retreat are not fully understood. In this study, we apply a relatively novel statistical method called Self-Organizing Maps (SOM) to examine the trend and variability of autumn Arctic sea ice in the past three decades and their relationships to large-scale atmospheric circulation changes. Our results show that the anomalous autumn the Arctic Dipole (AD) (Node 1) and the Arctic Oscillation (AO) (Node 9) could explain in a statistical sense as much as 50% of autumn sea ice decline between 1979 and 2016. The Arctic atmospheric circulation anomalies associated with anomalous sea surface temperature patterns over the North Pacific and North Atlantic influence Arctic sea ice primarily through anomalous temperature and water vapour advection and associated radiative feedback. … We investigate the potential mechanisms for the autumn arctic sea ice decline for the period 1979-2016 using the SOM method. Our results show that more than half of the autumn Arctic sea ice loss may be associated with the changes in the temperature and water vapour transport and the associated water vapour radiation feedback resulting from anomalous atmospheric circulations linked to SST anomalies over the North Pacific and North Atlantic. …  [T]he results here help advance the knowledge about the relatively large contributions from the decadal-scale natural climate variability to Arctic climate change…”

Image: https://www.nature.com/articles/s41598-018-22854-0

Image: http://www.nature.com/nature/journal/v509/n7499/full/nature13260.htm

Image: https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2011GL048008

Image: https://www.nature.com/articles/nclimate3241

Image: http://www.pnas.org/content/112/15/4570.full

Image: https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2005GL023429
Graph
Share this...FacebookTwitter "
"Rupert Murdoch’s son has strongly criticised his family’s news outlets for downplaying the impact of the climate crisis, as bushfires continue to burn in Australia. James Murdoch and his wife, Kathryn, issued a rare joint statement directly criticising his father’s businesses for their “ongoing denial” on the issue, which has been reflected in the family’s newspapers repeatedly casting doubt on the link between the climate emergency and the bushfires.  “Kathryn and James’s views on climate are well-established and their frustration with some of the News Corp and Fox coverage of the topic is also well-known,” a spokesperson for the couple said, confirming a report in the Daily Beast. “They are particularly disappointed with the ongoing denial among the news outlets in Australia given obvious evidence to the contrary.” James Murdoch was most recently the chief executive of the family’s 21st Century Fox entertainment business, leaving when it merged with Disney. He is making media investments through his own Lupa Systems company but continues to sit on the board of the family’s newspaper business, News Corp, which also owns the Times and the Sun. The bushfires have focused attention on the likes of Andrew Bolt, a political commentator for News Corp’s Australian newspapers who is known for promoting the views of climate science deniers, and for his own attacks on “alarmists” and his derision of climate change science. He also has a programme on the Murdoch-owned Sky News Australia, where he has criticised the “constant stream of propaganda” on the public broadcaster ABC about the role of the climate crisis in the bushfires. “Politicians who should do better are out there feeding the fear and misinformation,” he said in a recent broadcast criticising politicians who said carbon emissions needed to be cut to avoid future fires. “As if that would stop a fire. You’d have to be a child like Greta Thunberg to believe that fairytale.” US viewers have also heard commentary from Fox News presenters such as Laura Ingraham, who has said that “celebrities in the media have been pressing the narrative that the wildfires in Australia are caused by climate change”, before introducing guests who cast doubt on this interpretation. James Murdoch’s criticism sheds light on the family’s internal rifts, amid speculation over his 88-year-old father’s succession plans. James’s older brother Lachlan is still actively involved in the family businesses as the US-based chairman and chief executive of the slimmed-down Fox Corporation, which owns Fox News. Last year, Rupert Murdoch told shareholders “there are no climate change deniers” around his company and said his business was early to commit to “science-based targets to limit climate change” and was working to reduce its climate emissions. However, he has been publicly critical about the “alarmist” approach to the issue. In 2015, he used his Twitter account to describe himself as a “climate change sceptic not a denier”. A climate change skeptic not a denier. Sept UN meets in NY with endless alarmist nonsense from u know whom! Pessimists always seen as sages Lachlan Murdoch, Rupert Murdoch and News Corp have all separately donated millions of dollars to bushfire recovery efforts in recent days, although the Daily Beast claimed the donations were made after it requested comment about James Murdoch’s statement. James Murdoch has a long history of advocacy on environmental issues, inviting the former US vice-president Al Gore to present a version of his An Inconvenient Truth slideshow to Fox executives in 2006. At the time he was the heir apparent to the media empire and had been trusted with running BSkyB in London, where he would push environmental issues to the fore, working on ways to reduce the power used by Sky’s set-top boxes and insisting on using hybrid taxis long before such things were standard corporate behaviour. Since stepping back from day-to-day roles with the family business at the end of 2018, the multibillionaire has made clear he feels uncomfortable about much of Fox News’ output and was unsuccessful in an attempt to cash-in his stock completely and make a clean break with the company – an effort that failed after Lachlan declined to buy him out. Kathryn Murdoch has already set out the couple’s vision, telling the New York Times last year that she was increasingly focused on the issue of global heating: “There hasn’t been a Republican answer on climate change. There’s just been denial and walking away from the problem. There needs to be one.” She said she was particularly moved to act after seeing Al Gore’s speech at the Fox event in 2006: “I decided to switch everything I was doing. I wanted to be able to look my children in the eye and say ‘I did everything I could.’”"
"
Share this...FacebookTwitterRapid sea level rise was supposed
to shrink Earth’s coasts. It hasn’t.

Image Source: Mörner, 2018
“Over the past decades, atoll islands exhibited no widespread sign of physical destabilization in the face of sea-level rise. 88.6% of islands were either stable or increased in area, while only 11.4% contracted. It is noteworthy that no island larger than 10 ha decreased in size. These results show that atoll and island areal stability is a global trend, whatever the rate of sea-level rise.”- Duvat, 2019

Image Sources: Donchyts et al., 2016 and BBC (press release)
I. Despite sea level rise, “the coasts are growing all over the world”
Sea levels aren’t rising fast enough to deleteriously affect coastal areas on a net global scale.
Satellite observations indicate there has been 13,565 km2 of net growth in land area across the globe’s coasts between 1985-2015.
In other words, the Earth’s coasts gained more land area than were lost to rising sea levels.
“Earth’s surface gained 115,000 km2 of water and 173,000 km2 of land over the past 30 years, including 20,135 km2 of water and 33,700 km2 of land in coastal areas.” (Donchyts et al., 2016)
As a visual example, Ahmed et al. (2018) find that Bangladesh’s coastal land area grew by 7.9 km2 per year during 1985-2015.
“This paper draws upon the application of GIS and remote sensing techniques to investigate the dynamic nature and management aspects of land in the coastal areas of Bangladesh. … This research reveals that the rate of accretion [coastal land growth] in the study area is slightly higher than the rate of erosion. Overall land dynamics indicate a net gain of 237 km2 (7.9 km2annual average) of land in the area for the whole period from 1985 to 2015.”  (Ahmed et al., 2018)

Image Source: Ahmed et al., 2018
II. Even with ~4 mm yr−1 local sea level rise, Pacific islands grew in size during 1971-2014
Between 1958-2014, the globe’s sea levels rose at a rate of about 1.4 mm yr−1 , or 14 centimeters (5.5 inches) per century (Frederikse et al., 2018).
Ice melt from Greenland and Antarctica contributed a grand total of 1.5 cm of the 7.9 cm (3.1 inches) of sea level rise during those 56 years.
“The global-mean sea level reconstruction shows a trend of 1.5 ± 0.2 mm yr−1 over 1958–2014 (1σ), compared to 1.3 ± 0.1 mm yr−1 for the sum of contributors.” (Frederikse et al., 2018)
However, there are regions of the world where sea levels are rising at rates two or three times the global average.  Tuvalu, representing over 100 islands located in the central west Pacific, has  undergone “twice the global average” rate of sea level rise (~3.90 ± 0.4 mm yr−1) since the 1970s.
It would be expected that such high rates of local sea level change would result in shrinking island coasts and overall land area during this period.
But the opposite has occurred.  There has been a net increase in the coastal land area of Tuvalu between 1971-2014 in 8 of 9 atolls.
“We specifically examine spatial differences in island behaviour, of all 101 islands in Tuvalu, over the past four decades (1971–2014), a period in which local sea level has risen at twice the global average. Surprisingly, we show that all islands have changed and that the dominant mode of change has been island expansion, which has increased the land area of the nation.”
“Using remotely sensed data, change is analysed over the past four decades, a period when local sea level has risen at twice the global average (~3.90 ± 0.4 mm yr−1). Results highlight a net increase in land area in Tuvalu of 73.5 ha (2.9%), despite sea-level rise, and land area increase in eight of nine atolls.” (Kench et al., 2018)
III. The stability or coastal net growth of islands in recent decades to century “is a global trend”
Coastal stability and expansion for atoll and island land area is not just a regional trend, but a global one.
A comprehensive (709 islands) review of coastal changes that have been observed in the last decades to century (Duvat, 2019) reveals that no atoll island destabilization has occurred due to the effects of rising sea levels.
In fact, 88.6% of the globe’s islands have coasts that are either stable or expanding in size.
Further, not a single island larger than 10 hectares [1 ha = 10,000 square m, or 2.5 acres] has decreased in size in recent decades.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




None of these observed trends affirm the popularized claim that modern sea level rise is currently threatening the globe’s coasts.

Duvat, 2019
A global assessment of atoll island
planform changes over the past decades

Image Source: Duvat, 2019
“This review first confirms that over the past decades to century, atoll islands exhibited no widespread sign of physical destabilization by sea level rise. The global sample considered in this paper, which includes 30 atolls and 709 islands, reveals that atolls did not lose land area, and that 73.1% of islands were stable in land area, including most settled islands, while 15.5% of islands increased and 11.4% decreased in size. Atoll and island areal stability can therefore be considered as a global trend.”
“Importantly, islands located in ocean regions affected by rapid sea-level rise showed neither contraction nor marked shoreline retreat, which indicates that they may not be affected yet by the presumably negative, that is, erosive, impact of sea-level rise.”
“It is noteworthy that no island larger than 10 ha decreased in size, making this value a relevant threshold to define atoll island areal stability.”
“[A]mong the 27 islands having a land area lying between 100 and 200 ha (9 in French Polynesia, 6 in the Marshall Islands, 6 in Kiribati, 5 in Tuvalu and 1 in the Federated States of Micronesia), only 3 increased in area, while 24 were stable.”
“The great majority of Pacific islands showed positional stability, as illustrated by the Tuamotu atolls, where 85–100% of islands were stable, depending on atolls (Duvat & Pillet, 2017; Duvat, Salvat, et al., 2017).”
“Importantly, the reanalysis of available data on atoll island planform change indicates that over the past decades to century, no island larger than 10 ha and only 4 out of the 334 islands larger than 5 ha (i.e., 1.2%) underwent a reduction in size.”

IV. Sea level rise is not the coastal threat that natural geological processes are
Rapid sea level rise rates due to global warming are not the threat to coastal communities and wildlife that they have often been claimed to be.  What is?  Natural geological/crustal changes, or vertical land movement.
Tied to the Earth’s gravitational attraction and shifting plates, geologic subsidence (land sinking) or uplift (land rising) processes are far more of a determinant of coastal structure and positioning than the rather small (by comparison) seawater volume changes in the world’s ocean basins.  This is why sea level rise (or fall) rates are local, not global, as they vary quite dramatically across the world.
Along the coast of Juneau, Alaska, for example, the land surface has been rapidly rising due to gravitational uplift for many decades.  Consequently, relative sea levels are plummeting in this region at a rate of over -13 mm yr−1 (minus-5 inches per decade) according to NOAA.

The opposite is occurring along the U.S. Gulf coast (Grand Isle, Louisiana), where the land area is sinking and thus sea levels are rising at a rate of over +9 mm yr−1.

Scientists have concluded that “sea level rise is not the primary factor controlling the shoreline changes” in regions where sea levels are rapidly rising (Testut et al., 2016).   Even localized rates of sea level rise as high as 5 mm yr−1 are not rapid enough to overcome the much more pronounced geologic changes (accretion and uplift).
“We show that Grande Glorieuse Island has increased in area by 7.5 ha between 1989 and 2003, predominantly as a result of shoreline accretion [growth]: accretion occurred over 47% of shoreline length, whereas 26% was stable and 28% was eroded. Topographic transects and field observations show that the accretion is due to sediment transfer from the reef outer slopes to the reef flat and then to the beach. This accretion occurred in a context of sea level rise: sea level has risen by about 6 cm in the last twenty years and the island height is probably stable or very slowly subsiding. This island expansion during a period of rising sea level demonstrates that sea level rise is not the primary factor controlling the shoreline changes. This paper highlights the key role of non-climate factors in changes in island area, especially sediment availability and transport.”  (Testut et al., 2016)
V. Vertical motions of the Earth’s crust exert “dominant control” over relative sea level
Along the eastern coast of the U.S., Piecuch and colleagues (2018) find that the “dominant control” over the disparate rates of sea level rise during the modern era has been exerted by “vertical motions of the Earth’s crust”, not climate.
“Here we analyse instrumental data and proxy reconstructions using probabilistic methods to show that vertical motions of Earth’s crust exerted the dominant control on regional spatial differences in relative sea-level trends along the US East Coast during 1900–2017, explaining most of the large-scale spatial variance. … Rates of coastal subsidence caused by ongoing relaxation of the peripheral forebulge associated with the last deglaciation are strongest near North Carolina, Maryland and Virginia [locations where the sea level rise rates are highest]. Our results indicate that the majority of large-scale spatial variation in long-term rates of relative sea-level rise on the US East Coast is due to geological processes that will persist at similar rates for centuries. … We note that negative VLM [vertical land motion] reflects subsidence and hence contributes to sea-level rise. Correspondingly, the most negative VLM [vertical land motion] rate (−2.5 ± 0.6 mm yr−1) is likely (P = 0.75) to occur in the states that host the maximum sea-level rise, North Carolina or Virginia, whereas the most positive rate of VLM (0.7 ± 0.8 mm yr−1) is very likely (P = 0.90) to occur in Maine.” (Piecuch et al., 2018)
Pfeffer and colleagues (2017) assessed 849 coastal sites and determined that geophysical processes, or vertical land motion (VLM) trends (ranging from −13 to +16 mm yr−1 ), “have been recognized as a dominant component of the total relative sea-level variations observed at coasts” at locations throughout the globe.
“VLMs contribute actively to the sea-level changes felt by coastal populations, as they can amplify, diminish or counteract the effects of climate-induced signals (e.g. Pfeffer & Allemand 2016). In many cases, for example, Torres Islands (Ballu et al. 2011), western Tropical Pacific (Becker et al. 2012), southern Europe (Woppelmann & Marcos ¨ 2012) or Indian Ocean (Palanisamy et al. 2014), VLMs [vertical land motions] have been recognized as a dominant component of the total relative sea-level variations observed at coasts. … VLMs are estimated at 258 GPS stations and 591 tide gauges, for a total of 849 coastal sites. Trend values range from −13 to +16 mm yr−1 (Fig. 3a). A strong spatial variability in VLM is observed at all scales, including locally, which is evidenced for example by the dense instrumental network in Japan. High rates of crustal uplift are observed at high latitudes, while subsidence of coastal areas is more often observed at medium latitudes (e.g. the East American coast).” (Pfeffer et al., 2017)

VI. Meter-scale sea level rise is “related to geologic events only”, not climate change
In a 2018 paper published in the journal Geoscience Frontiers, geophysicist and tectonics expert Dr. Aftab Khan asserts that “both regional and local sea-level rise and fall in meter-scale is related to the geologic events only and not related to global warming and/or polar ice melt.”
Very high rates of land subsidence and uplift persist today.  Vertical land motions as profound as ±10 to 30 mm yr−1 have been observed by geologists – easily overwhelming even the highest measured relative sea level changes.
The conclusion that rapid and high-amplitude (i.e., meters-per-century) sea level changes occur primarily as a consequence of natural geologic processes effectively leaves no room for global warming and/or polar ice melt to significantly contribute to the alarming meters-per-century sea level rise projected to engulf the Earth’s coasts by the end of the century.
Modeled predictions of multiple meters of sea level rise by 2100 (for example, 2.6 meters of global sea level rise by 2100 according to authors like Dr. Michael Mann and Dr. Richard Alley in Garner et al. 2017) are dismissed as “highly erroneous” by Dr. Khan.
Suggestions of a controlling anthropogenic influence on coastal and shoreline changes — the scariest aspect of climate modeling predictions — may therefore be significantly undermined by real-world scientific observations.

Khan, 2018
Why would sea-level rise for global
warming and polar ice-melt?
“Geophysical shape of the earth is the fundamental component of the global sea level distribution. Global warming and ice-melt, although a reality, would not contribute to sea-level rise. Gravitational attraction of the earth plays a dominant role against sea level rise.”
“Geological processes are responsible of two types of major movements of the crustal block viz., uplift and subsidence. Hence, the relation of sea level and crustal motion is attributed to sea level drops when there is an uplift while it rises when there is subsidence.”
“Snay et al. (2016) have found large residual vertical velocities [land uplift], some with values exceeding 30 mm/yr, in southeastern Alaska. The uplift occurring here is due to present-day melting of glaciers and ice fields formed during the Little Ice Age glacial advance that occurred between 1550 A.D. and 1850 A.D.”
“Johansson et al. (2002) conducted research on a project BIFROST (Baseline Inferences for Fennoscandian Rebound Observations, Sea-level, and Tectonics) that combines networks of continuously operating GPS receivers in Sweden and Finland to measure ongoing crustal deformation due to glacial isostatic adjustment (GIA). They have found the maximum observed uplift rate 10 mm/yr for Fennoscandian region analyzing data between August 1993 and May 2000. Sella et al. (2007) and Lidberg et al. (2010) suggested that postglacial rebound continues today albeit very slowly wherein the land beneath the former ice sheets around Hudson Bay and central Scandinavia, is still rising by over a centimeter a year, while those regions which had bulged upwards around the ice sheet are subsiding such as the Baltic states and much of the eastern seaboard of North America.”
“Transgression commences when continental block undergoes subsidence with respect to continental shelf and abyssal plain, while regression occurs when this process is reverse i.e., when continental block is uplifted with respect to continental shelf and abyssal plain. Prograding delta system in low lying areas and other geologic events may cause local/relative sea-level fall as new sedimentary deposition advances as accretion pushing sea further down the coast irrespective of global warming and polar ice-melt.”
“Hence, both regional and local sea-level rise and fall in meter-scale is related to the geologic events only and not related to global warming and/or polar ice melt.”
“Prediction of 4–6.6 ft sea level rise in the next 91 years between 2009 and 2100 is highly erroneous.”
Share this...FacebookTwitter "
"The next four years are going to be anomalously warm – even on top of regular climate change. That’s according to new research my colleague Sybren Drijfhout and I have just published.  We developed a new prediction system we call PROCAST (PROabilistic foreCAST), and used it to predict the natural variability of the climate system. This refers to how the climate varies naturally from warm to cool phases that last a few years at a time, and is separate from the long-term trend of anthropogenic global warming. PROCAST predicts a warm phase for the next few years. Our work, published in Nature Communications, is important as such forecasts help predict the chances of events like heatwaves or cold snaps months in advance, and it is now well established that anomalous climatic events have a direct human impact. For example, heatwaves lead to excess deaths in only a few weeks. During the 2003 European heatwave, a long drought caused UK wheat production to drop by 12%.  Tougher winters, meanwhile, can worsen respiratory infections, increasing pressure on health services and the supply of drugs. Indeed, consumption of flu vaccines can vary significantly depending on the weather conditions. In the UK, snowy conditions in winter 2010 were estimated to have cost the economy £690m a day, while natural gas consumption increased massively. Predicting these extreme climatic events up to a season in advance is therefore a priority, in order to allow early adaptation and cost-effective mitigation. Scientists have made some important breakthroughs in understanding and modelling the climate system, yet these have not yet been transferred into an ability to predict the climate from year to year. This inability has its roots in the deterministic chaos of the climate system, which has been popularised by the idea of the “butterfly effect” where the tiniest error in the estimation of the current weather might have significant consequences later. Despite these difficulties, major research centres and national meteorological services have embraced this challenge and a significant effort is currently going toward developing accurate predictions of year to year climate variations. At the core of this development each group and centre relies on its individual state-of-the-art climate model used to propagate into the future the current climate state. Unfortunately, because climate models are not perfect, we are still not able to efficiently predict the climate a few years in advance. This is where PROCAST comes in. Instead of relying on a single climate model, we combined a range of different climate models used in the context of the Coupled Model Intercomparison Project phase 5 (CMIP5). PROCAST can be quickly trained to build on the work already done by these models, which are already completed and freely available.  This has two obvious advantages. First, it removes any dependence on a single, possibly biased, model. But it also dramatically improves the speed of the predictions – a forecast that previously took a supercomputer an entire week now can be done on a laptop in a few hundredths of a second. To check if our predictions are accurate and reliable, we conducted a series of a posteriori predictions, or “hindcasts”. We found our system was both accurate (able to predict what actually happened in the future) and reliable (on average, it did not predict events that did not occur). Our study shows that, on top of the forced warming from climate change, natural variability will induce an anomalously warm phase of more than 0.02℃ for 2018, more than 0.03℃ for 2018-2019, and more than 0.01℃ for 2018-2022. These numbers, which can look unfamiliarly small, are in fact comparable in intensity to the typical rate of global warming experienced each year if averaged it over the past century (around 1℃ over 100 years roughly equals 0.01℃ every year). However it is important to acknowledge that the method does not only predict one given value, but a probability. This means that warm years are more likely than cold years for the period 2018-2022. Indeed our research showed that over the next two years it is 64% likely to be anomalously warm. In addition, over the course of the next five years PROCAST predicts a relative decrease in the likelihood of extreme cold years."
"
Share this...FacebookTwitterStefan Rahmstorf caught redhanded manipulating temperature charts
By Michael Krueger
(Text translated/edited by P. Gosselin)

Three days ago, climate researcher Stefan Rahmstorf published an article at his KlimaLounge blog on the hearing of Jewish climate scientist Nir Shaviv in the German Bundestag concerning the Climate Change Conference in Katowice.
Accuses Shaviv of presenting “outlandish theories”
 There he describes Shaviv as a “climate skeptic” with outlandish theories and who is courted by the fossil lobby and AfD Party. During the hearing, the German Left party even accused Shaviv of obviously being paid to publish climate-denialism. Stefan Rahmstorf went even further, claiming, “This is a targeted misleading of the layperson audience”. 
Just who is misleading whom, I would like to pursue here. 
The conflict between Jewish climate scientist Nir Shaviv and Stefan Rahmstorf dates back to 2003, when Stefan Rahmstorf wrote the following e-mail to his colleagues:
I feel another recent paper may require a similar scientific response, the one by Shaviv & Veizer (attached). …This paper got big media coverage here in Germany and I guess it is set to become a climate skeptics classic: …”
Since then, Shaviv has fallen out of favor with Stefan Rahmstorf.
Dissenters get labelled as right wingers
In the comment area of Mr. Rahmstorf’s article, some commentators — who were immediately labelled by other commenters as right wing spectrum — criticized that NASA’s temperature curve in Figure 5 was truncated in 2016, exactly when the last El-Nino pushed up the global temperature. Mr. Rahmstorf vehemently rejected the criticism.
In the article Mr. Rahmstorf refers to a link on how to create your own widget according to Figure 5, here the link. There the year 2017 is included and the curve is not cut off at 2016. Between 2016 and 2017 the global temperature dropped by 0.1°C, and in 2018 by a further 0.1°C.
Hide the decline
In the year 2016 we were at +1°C temperature anomaly according to NASA (a new record!), but today in the year 2018 only at 0.8°C. Mr. Rahmstorf obviously wanted to hide this by cleverly truncating at 2016, probably with the hope his lay public would not notice it?
Mr. Rahmstorf first showed the following Figure 5 in the article, which was truncated at 2016:

When the “deception” was discovered, he quickly changed Figure 5, without comment, and recorded the year 2017. Now the chart looks like this:

The year 2018 is still missing, which is currently only 0.8°C above the mean just before the end of the year, i.e. 0.1°C lower than 2017.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Poor correlation
With the chart he also tries to give the impression that there is a close relationship between CO2 rise and temperature rise. If one looks at the correlation coefficients, i.e. whether there is a linear relationship between CO2 and temperature rise, one can immediately see that between 1880-1970/80 there is only a moderate correlation between CO2 and temperature. It is around 0.6. A value of zero means no correlation, 1 means a perfect correlation. Only between 1980 and today does the correlation increase to around 0.9.
Thus one can say that actually only since 1980 does a good correlation exist.
To be correct, it has to be taken into account that other climatic factors also contribute to the rise in temperature and not just CO2 alone. In addition, in the recent geological past (around the last 1 million years), as evidenced by ice cores in the Antarctic and Arctic, it is always the temperature that has risen and then followed by CO2. 
So it may well be that even today the temperature increase precedes the CO2 increase and the CO2 increase is partly due to temperature, e.g. because less CO2 can be stored in warm seas. (Half of the CO2 remains in the air, the other half goes into the ocean). 
Natural factors kept hidden
Of course, Mr. Rahmstorf does not mention this in his article, in the belief nobody would notice. Or in other words, it’s about “deliberately misleading the lay audience”, and here not by Mr. Shaviv.
Mr. Rahmstorf’s supporters in the comments section obviously do not care whether Mr. Rahmstorf uses the methods which he accuses others of using. It is about deliberately discrediting others who have a different opinion and not of having a debate at factual level. The climate activists consider themselves scientifically and politically legitimized to force their policy on the opponents of opinion, and to do so by using smearing and violence if necessary. Sometimes a Jewish scientist gets placed in the “right-wing corner” and persons with a different opinion placed with the right wing AfD. The ends justify the means.
More misleading claims by Rahmstorf
In the following I would like to briefly go into further “deceptions” in Mr. Rahmstorf’s article. He writes:
30 years ago, in 1988, the American climate researcher James Hansen famously declared in the US Senate that the long predicted warming was now there and recognizable in the data.”
But Hansen was completely wrong with his 1988 scenarios, as we know today. See the following figure:

Furthermore ,Stefan Rahmstorf defends the hockey stick curve of his friend Michael Mann from 1998/99.
Busted hockey stick chart
Recent reconstructions would still show the same result. It should be noted that Mann’s 1998/99 hockey stick was truncated in 1980 because the proxy data showed no increase at the end of the time series. His colleague Briffa even truncated the chart in 1960. Used in place of the proxy data were weather data/temperatures from weather stations showing much larger rises than the proxy data averaged.
What follows is the the Briffa version where the proxy data are cut off at 1960 and replaced by data from weather stations and with the proxy data (green) up until the present.

The same was done with the more recent “reconstructions” mentioned by Mr. Rahmstorf.
When Mr. Rahmstorf was asked, he replied, claiming “these are well-known ‘talking points’ of the ‘climate sceptics’, and almost everything is wrong or misleading.”
Original article in German at Science Skeptical here.
Share this...FacebookTwitter "
"In 2019, millions of Californians experienced a wildfire safety blackout, some for nearly a week at a time, as the troubled utility company Pacific Gas & Electric and other investor-owned utilities grappled with replacing one devastating disaster with another, comparatively manageable one. 2019 was not an anomaly, but the beginning of a new way of life for many California residents. While “de-energization” for fire safety has been state policy for more than a decade, it had never before been used on such a mass scale. According to utility experts, politicians and PG&E, customers can expect many more years of blackouts to come, as fire risk in California’s hills only increases.  “Wildfire blackouts could be California’s new normal for the next 10 to 30 years, or even longer,” the Senate energy committee chair, Lisa Murkowski, told a hearing on utility and fire safety in December. In stark contrast to recent years past, California’s 2019 wildfire season was relatively mild: just 732 structures destroyed, compared with the tens of thousands and dozens killed in 2017 and 2018. The crisis of 2019’s fire season was less the fires themselves, and more the actions taken that were meant to prevent fires from igniting in the first place. Intended as a measure of last resort, California power utilities conducted nine public safety power shutoffs in the fall of 2019 in an effort to reduce wildfire risk in hot, windy weather conditions – and to reduce liability costs to utilities. Those costs following deadly wildfires in 2017 and 2018 fires linked to equipment belonging to PG&E, drove the company to file for bankruptcy in 2019, and to reconsider how to manage the grid during future fire weather events. Bill Johnson, PG&E’s CEO, has at different times claimed his utility – the largest in the state – would resort to blackouts for the next three, five or 10 years. The southern California investor-owned utility San Diego Gas and Electric “is the poster child for safety”, said Michael Wara, the director of the climate and energy policy program at Stanford’s Woods Institute for the Environment. SDG&E has been de-energizing its lines during fire weather events for more than a decade. “Why is it that PG&E thinks it’s going to be able to replicate what San Diego’s done and do even better over a larger area in less time? It’s not impossible, but it’s an enormously challenging task,” said Wara. PG&E’s post-de-energization reports to the state utilities commission showed a number of hazards after each event, from damaged lines and conductors to fallen trees. After its largest shutoff at the end of October, the utility noted more than 100 individual hazards. “Would every piece of system damage that they noted have caused a fire? Probably not. But some of them probably would have,” said Wara. “[Public safety power shutoff policy] is so unpopular, and it impacts so many people, I worry we will be pushed to be overly optimistic about other potential avenues for creating safety.”  Despite the widespread shutoffs, PG&E equipment was still tied to igniting several fires in the fall of 2019, including the Kincade fire in Sonoma county, which destroyed 352 structures and burned more than 77,000 acres. “It’s not clear to me that the system is that much safer than 2017,” Wara said. “The safety that we had this season and the absence of fires during these dangerous wind events was due to the fact that the wires weren’t hot.” Fire risk in the California hills will rise precipitously through the middle of the century, according to a 2018 report for California’s Fourth Climate Change Assessment, with big new hazards in areas where high voltage transmission lines run through the mountains and connect California to clean energy out of state. In the face of that rising danger, the public safety power shutoff is a utility’s fastest and cheapest means of reducing fire risk. “I want to assure you that we do not expect an annual repeat of what we went through this fall. We are working hard now to narrow the scope and duration of future safety shutoffs and minimize their customer impact as much as possible,” Johnson told the Senate hearing. But he also took credit for the less destructive 2019 fire season: “PG&E’s [public safety power shutoff] program achieved its singular goal: there was no loss of life during wildfires in 2019.” Not everyone in California is convinced that success is PG&E’s to claim. Will Abrams and his family lost their home in the 2017 Tubbs fire that destroyed more than 5,600 structures and killed 22 people. They were forced to evacuate again from the 2019 Kincade fire. “The fact that our firefighters went in and did an amazing job, learned from prior fires and got these more under control shouldn’t be a PG&E victory lap,” said Abrams. “I would argue that the shutoffs provide a disincentive for other mitigation. Because if you can just pull the power, you don’t have to do the vegetation management and the microgrids and all the other stuff you need to do.” All of that “other stuff” is enormously expensive and labor-intensive and will take years to complete. And the costs of installing stronger poles and trimming trees will not just be borne by the company’s profits. CEO Johnson has said ratepayers will not be on the hook for the costs associated with the company’s bankruptcy, but they will have to foot some of the bill for grid upgrades and maintenance. Customers saw their rates increase again on 1 January, though not as much as the utility would have liked. PG&E customers already pay some of the highest prices in the country for power, and those prices will only increase.  PG&E expects to reinforce 7,100 miles of line in fire risky areas in the next 12 to 14 years. To date, the utility has completed just 129 miles. To some, PG&E’s bankruptcy initially seemed like an opportunity to restructure the troubled utility in favor of creating a more reliable and resilient grid to weather future climate change – one that wouldn’t necessitate extensive annual blackouts. “This bankruptcy represents a closing window of opportunity to change course so that not only is PG&E a proven safe and reliable provider of energy but so the state has a way forward to address wildfires and climate change,” said Abrams, who has filed motions in the case advocating for more significant restructuring and transparency in the process. But the California governor, Gavin Newsom, rejected PG&E’s plan to leave bankruptcy, calling it “woefully short” of reorganizing the company “to provide safe, reliable, and affordable service to its customers”. In 2018, the state legislature passed a bill aimed at heading off that bankruptcy but providing new funding sources for fire-burdened utilities and requiring new wildfire safety plans – which ultimately included de-energization. In 2019, at Newsom’s urging, the legislature passed new legislation that created a wildfire liabilities fund, and placed a June deadline for PG&E to leave bankruptcy. Critics argued that both bills were essentially bailouts for investor-owned utilities. “I voted no on both of them – I thought that they shifted financial responsibility on to Californians and neglected to raise public safety to the paramount priority,” said assembly member Marc Levine. “De-energization was a massive failure.” While California’s fires have been orders of magnitude more destructive than the blackouts, they touch just a fraction of the millions who had their lights turned off in 2019 – making de-energization a hotter problem for politicians and PG&E to solve.They have just a few months before the next fire season begins. Three new pieces of legislation introduced in the state legislature’s first week back in 2020 aimed at addressing a troubled PG&E, regardless of the bankruptcy’s resolution. A new proposal from Levine would install a public administrator from the state regulatory commission for a period of six months to oversee all the functions of a floundering investor-owned utility. “We need to stop treating PG&E like a business to keep solvent and more like a convicted felon that needs to be held accountable,” said Levine.  Assembly member Kansen Chu authored two bills directly aimed at de-energization which would authorize state regulators to determine if utilities should compensate customers after each power shutoff, and require utilities to support customers who rely on power for medical needs. “There’s so much ageing infrastructure, but that’s not going to be fixed very soon,” Chu said. “In the meantime I want them to be more responsible and more careful with their shutoffs because the first shut off was a disaster.” But leaving the power on in the meantime, said Chu, “is probably more devastating”."
"Thousands of climate protesters flooded the streets of Australian state capitals on Friday night as fire authorities warned of another dangerous night ahead in four states. Firefighters in New South Wales, Victoria, South Australia and Western Australia continued to battle fires, with gusty winds expected to create hazardous firefighting conditions late into the night.  A male firefighter in his 20s suffered burns to his face, ears and hands in the Snowy Valley region where fierce winds were pushing the fires in different direction. Temperatures reached above 40C in some parts of NSW during the day, and strong south-westerly winds with gusts of up to 90km/h were expected to move up the coast later in the night, the Bureau of Meteorology said. “The change is critical,” the BoM’s Graham Reader said. “The winds really peak around the change and the directions shift is very sharp and particularly gusty.” The change was not expected to reach Sydney until early on Saturday morning. By 8pm on Friday, fire authorities in NSW and Victoria had started to issue emergency warnings as southerly winds fanned the fires. In Victoria, 21 fires were burning out of control by late afternoon, with more than 1.3m hectares burned so far this bushfire season. On Friday afternoon the state’s premier, Daniel Andrews, said 286 residential properties had been damaged or destroyed in the state. Andrews praised the response of Victorians to evacuation orders and other warnings. “People have, by and large, followed the advice given, and that is one of the reasons why I’m able to say to you tonight, despite this unprecedented fire activity, we have nobody who is unaccounted for, we have no further people that have died, and we have no further communities that have been cut off.” But he warned that “all of those things can change” and urged the public to remain vigilant. People living in the state’s alpine region were told they had until 7.50pm on Friday to safely evacuate. “Evacuation after this time is considered life threatening,” an emergency warning said. Relief centres were set up in Bonegilla, Myrtleford and Wangaratta for evacuees. In the alpine towns of Bright and Harrietville, authorities had placed satellite phones, baby formula, food, nappies and torches in containers in case the two areas were cut off. State authorities were concerned fires in the north of Victoria could merge with others burning near the NSW border. In NSW, where 66 of the 137 fires burning were not contained, the Rural Fire Service warned the forecast wind change “could cause erratic fire behaviour over many firegrounds”. Conditions in several areas of the Snowy Mountains, and in the southern highlands around Bundanoon, were particularly challenging. Conditions in the state were expected to ease on Saturday. In Western Australia, a fire jumped one of the the main freeways south of Perth, threatening lives and homes just 30km south of the city centre. Residents were told to immediately head south if they could. Fires in South Australia had burned through more than a third of Kangaroo Island, killing two people and injuring 22 fire personnel. The town of Parndana in the centre of the island was again spared on Friday after being threatened twice by flames. In the evening more than 10,000 climate change protesters filled the streets in Sydney, Melbourne, Brisbane, Adelaide and Canberra, with anger directed towards the Australian prime minister, Scott Morrison. Sydney protester Ambrose Hayes, 14, said people were “fed up” with Morrison, who she said was not acting on the climate crisis. Morrison rejected criticism of his government’s climate record in a series of interviews on Thursday and Friday. Conceding climate change had played a role in the fires, he told one radio station his government did not want “job-destroying, economy-destroying, economy-wrecking targets and goals” on climate change. Can barely capture the whole crowd.Huge climate/bushfires/dump ScoMo protest outside Sydney town hall.Has shut down George and Park Street intersection. #SackScoMo #AustraliaFires pic.twitter.com/KYK12k7e94 He said any such efforts to cut emissions “won’t change the fact that there have been bushfires or anything like that in Australia”. In a conference call with MPs, Morrison banned backbench MPs from doing international media, after Liberal MP Craig Kelly caused an outcry by denying the link between climate change and bushfires on the UK’s Good Morning Britain show. On Friday it emerged a senior News Corp employee had accused the company of “misinformation” and diverting attention from climate change during the bushfire crisis in an all-staff email addressed to the company’s executive chairman. The email accused News Corp papers, including the Australian, the Daily Telegraph and the Herald Sun, of misrepresenting facts and spreading misinformation to focus on arson as the cause of the bushfires, rather than climate change. The company defended its coverage and said the employee, Emily Townsend, had submitted her resignation in December. The Bureau of Meteorology confirmed on Thursday that 2019 was the country’s hottest since records began in 1910. The year was also been the country’s driest since rainfall records began in 1900. The bureau said 2019 had also been the worst year for the Forest Fire Danger Index – a metric used to assess the risk of dangerous bushfire weather. That record goes back to 1950."
"We will likely never know how life on Earth started. Perhaps in a shallow sunlit pool. Or in the crushing ocean depths miles beneath the surface near fissures in the Earth’s crust that spewed out hot mineral-rich soup. While there is good evidence for life at least 3.7 billion years ago, we don’t know precisely when it started.  But these passing aeons have produced something perhaps even more remarkable: life has persisted. Despite massive asteroid impacts, cataclysmic volcano activity and extreme climate change, life has managed to not just cling on to our rocky world but to thrive.  How did this happen? Research we recently published with colleagues in Trends in Ecology and Evolution offers an important part of the answer, providing a new explanation for the Gaia hypothesis. Developed by scientist and inventor James Lovelock, and microbiologist Lynn Margulis, the Gaia hypothesis originally proposed that life, through its interactions with the Earth’s crust, oceans, and atmosphere, produced a stabilising effect on conditions on the surface of the planet – in particular the composition of the atmosphere and the climate. With such a self-regulating process in place, life has been able to survive under conditions which would have wiped it out on non-regulating planets. Lovelock formulated the Gaia hypothesis while working for NASA in the 1960s. He recognised that life has not been a passive passenger on Earth. Rather it has profoundly remodelled the planet, creating new rocks such as limestone, affecting the atmosphere by producing oxygen, and driving the cycles of elements such as nitrogen, phosphorus and carbon. Human-produced climate change, which is largely a consequence of us burning fossil fuels and so releasing carbon dioxide, is just the latest way life affects the Earth system.  While it is now accepted that life is a powerful force on the planet, the Gaia hypothesis remains controversial. Despite evidence that surface temperatures have, bar a few notable exceptions, remained within the range required for widespread liquid water, many scientists attribute this simply to good luck. If the Earth had descended completely into an ice house or hot house (think Mars or Venus) then life would have become extinct and we would not be here to wonder about how it had persisted for so long. This is a form of anthropic selection argument that says there is nothing to explain. Clearly, life on Earth has been lucky. In the first instance, the Earth is within the habitable zone – it orbits the sun at a distance that produces surface temperatures required for liquid water. There are alternative and perhaps more exotic forms of life in the universe, but life as we know it requires water. Life has also been lucky to avoid very large asteroid impacts. A lump of rock significantly larger than the one that lead to the demise of the dinosaurs some 66m years ago could have completely sterilised the Earth. But what if life had been able to push down on one side of the scales of fortune? What if life in some sense made its own luck by reducing the impacts of planetary-scale disturbances? This leads to the central outstanding issue in the Gaia hypothesis: how is planetary self-regulation meant to work?  While natural selection is a powerful explanatory mechanism that can account for much of the change we observe in species over time, we have been lacking a theory that could explain how the living and non-living elements of a planet produce self-regulation. Consequently the Gaia hypothesis has typically been considered as interesting but speculative – and not grounded in any testable theory. We think there is finally an explanation for the Gaia hypothesis. The mechanism is based on “sequential selection”, a concept first suggested by climate scientist Richard Betts in the early 2000s. In principle it’s very simple. As life emerges on a planet it begins to affect environmental conditions, and this can organise into stabilising states which act like a thermostat and tend to persist, or destabilising runaway states such as the snowball Earth events that nearly extinguished the beginnings of complex life more than 600m years ago.  If it stabilises then the scene is set for further biological evolution that will in time reconfigure the set of interactions between life and planet. A famous example is the origin of oxygen-producing photosynthesis around 3 billion years ago, in a world previously devoid of oxygen. If these newer interactions are stabilising, then the planetary-system continues to self-regulate. But new interactions can also produce disruptions and runaway feedbacks. In the case of photosynthesis it led to an abrupt rise in atmospheric oxygen levels in the “Great Oxidation Event” around 2.3 billion years ago. This was one of the rare periods in Earth’s history where the change was so pronounced it probably wiped out much of the incumbent biosphere, effectively rebooting the system. The chances of life and environment spontaneously organising into self-regulating states may be much higher than you would expect. If fact, given sufficient biodiversity, it may be extremely likely. But there is a limit to this stability. Push the system too far and it may go beyond a tipping point and rapidly collapse to a new and potentially very different state. This isn’t a purely theoretical exercise, as we think we may able to test the theory in a number of different ways. At the smallest scale that would involve experiments with diverse bacterial colonies. On a much larger scale it would involve searching for other biospheres around other stars which we could use to estimate the total number of biospheres in the universe – and so not only how likely it is for life to emerge, but also to persist. The relevance of our findings to current concerns over climate change has not escaped us. Whatever humans do life will carry on in one way or another. But if we continue to emit greenhouse gasses and so change the atmosphere, then we risk producing dangerous and potentially runaway climate change. This could eventually stop human civilisation affecting the atmosphere, if only because there will not be any human civilisation left. Gaian self-regulation may be very effective. But there is no evidence that it prefers one form of life over another. Countless species have emerged and then disappeared from the Earth over the past 3.7 billion years. We have no reason to think that Homo sapiens are any different in that respect. This article was updated on July 10 to add the reference to Richard Betts."
"A new scientific paper proposing a scenario of unstoppable climate change has gone viral, thanks to its evocative description of a “Hothouse Earth”. Much of the media coverage suggests that we face an imminent and unavoidable extreme climate catastrophe. But as a climate scientist who has carried out similar research myself, I am aware that this latest work is a lot more nuanced than the headlines imply. So what does the hothouse paper actually say, and how did the authors draw their conclusions? First, it’s important to note that the paper is a “perspective” piece – an essay based on knowledge of the scientific literature, rather than new modelling or data analysis. Leading Earth System scientist Will Steffen and his 15 co-authors draw on a diverse set of literature to paint a picture of how a chain of self-reinforcing changes might potentially be initiated, eventually leading to very large climate warming and sea level rise.  One example would be the thawing of Arctic permafrost, which releases methane into the atmosphere. As methane is a greenhouse gas, this means the Earth retains more heat, causing more permafrost to thaw, and so on. Other possible self-reinforcing processes include the large-scale die-back of forests, the melting of sea ice, or the loss of ice sheets on land. Steffen and colleagues introduce the term “Hothouse Earth” to emphasise that these extreme conditions would be outside those that have occurred over the past few hundred thousand years, which have been cycles of ice ages with milder periods in between. They also present an alternative scenario of a “Stabilised Earth” where these changes are not triggered, and the climate remains similar to now. The authors make the case that there is a level of global warming which is a critical threshold between these two scenarios. Beyond this point, the Earth System might conceivably become set on a pathway that makes the extreme “hothouse” conditions inevitable in the long term. They argue – or perhaps speculate – that the process of irreversible self-reinforcing changes could in theory start at levels of global warming as low as 2°C above pre-industrial levels, which could be reached around the middle of this century (we are already at around 1°C). They also acknowledge large uncertainty in this estimate, and say that it represents a “risk averse approach”. A key point is that, even if the self-perpetuating changes do begin within a few decades, the process would take a long time to fully kick in – centuries or millennia. Steffen and colleagues support their suggestion of a threshold at 2°C through reference to previously-published scientific work. These include other review papers which themselves drew on wider literature, and an “expert elicitation” study in which scientists were asked to estimate the levels of global warming at which “tipping points” for these key climate processes might be passed (I was one of those consulted). The authors argue that 2°C can still be avoided if humanity takes concerted action to reduce its warming effect on the climate. In a similar way that the “Hothouse Earth” scenario involves huge changes in the climate system with multiple effects of one process leading to another, the concerted global action to avoid 2°C would, they suggest, also involve huge changes in the human system, again with several fundamental steps leading from one change to another. Personally, I found this an interesting and important think piece that was well worth reading. But since this is not actually new research, why is it getting so much coverage? I suspect that one reason is the use of the vivid “Hothouse Earth” term at a time when everyone’s talking about heatwaves. Another is that it’s clearly a dramatic narrative, and not surprisingly this has led to some sensationalist articles. With some exceptions, much of the highest-profile coverage of the essay presents the scenario as definite and imminent. The impression is given that 2°C is a definite “point of no return”, and that beyond that the “hothouse” scenario will rapidly arrive. Many articles ignore the caveats that the 2°C threshold is extremely uncertain, and that even if it were correct, the extreme conditions would not occur for centuries or millennia. Some articles do however emphasise the more tentative nature of the work, and some push back against this overselling of the doomsday scenario, arguing that provoking fear or despair is counterproductive.  One thing that strikes me about the scientific literature on “tipping points” is that there are a lot of review papers like this that end up citing the same studies and each other – indeed, my colleagues and I wrote one a while ago. There is a great deal of interesting, insightful research going on using theoretical methods and calculations with large approximations. However, we have yet to see an equivalent level of research in the highly-complex Earth System Models which generate the kind of detailed climate projections used for addressing policy-relevant questions by the Intergovernmental Panel on Climate Change (IPCC). Steffen and colleagues have made a good start at addressing such questions, going as far as they can on the basis of the existing literature, but their essay should motivate new research to help narrow down the huge uncertainties. This will help us see better whether “Hothouse Earth” is our destiny, or mere speculation. In the meantime, awareness of the risks – however tentative – can still help us decide how to manage our impact on the global climate."
"
Share this...FacebookTwitter406 Guinea Delegates Make Junket To Katowice Climate Conference
By Die kalte Sonne(German text translated/edited by P. Gosselin)
The climate conference in Katowice is in full swing and a variety of carbon-saving initiatives are being discussed: eating less meat, less heating and less air travel. In the latter case, of course, the conference itself is taking on great proportions of absurdity.
It would have been easy to turn the conference into an internet meeting with live streaming and online commenting. But then the long wonderful “business trip”  with all its receptions, daily allowances and pre-Christmas meetings with fellow climate rescuers would have been missed. This time more than 22,000 participants have made their way to Poland, most comfortably by plane. The largest delegations to the Climate Conference came from Africa.
Guinea is sending 406 delegates this year, the Democratic Republic of Congo is there with 237 participants, and the Ivory Coast is sending 191 compatriots to Poland. The list of participants is available on the homepage of the conference as a pdf and is 1084 pages long.
The list of delegates from Guinea starts on page 239 and goes to page 273. There are 406 names on it. In the previous year in Bonn the group from Guinea was even larger, 86 participants more, with a delegation size of close to 500 people.
The Ivory Coast has also “severely restricted” participation this year. At the COP23 in Bonn, the country was present with 492 participants. Maybe Bonn was a more attractive destination than Katowice? Eco-business.com has compiled the numbers of climate conferences in recent years in an Excel spreadsheet, which is available here.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The obvious question: what is supposed to be the task of all these delegates? And who will pay for the travel costs? Let’s start with the first question, the role of the delegates. Here we can really only speculate, since we do not know the individual daily program of the participants. A look at the affiliation of the participants gives a first idea. Among other things, there are several employees of the Friedrich Ebert Foundation from Guinea.
There are also journalists, a large number of NGO employees, representatives of the water authority, etc. It remains unclear who really provides added value here, and who is only traveling as a tourist or on a daily travel allowance. Incidentally, this does not only apply to Guinea, but to all delegates.
Is Question 2 maybe easier to answer? Who pays the travel expenses and daily allowances? On the website of the Bonn COP23 we get some information on this:

Daily subsistence allowance disbursement and travelDelegates from Parties eligible for funding are kindly requested to contact the daily subsistence allowance (DSA) office located in the temporary structure in the foyer of the main building of the World Conference Center Bonn as of Monday, 30 April 2018. Delegates attending the pre-sessional meetings of the regional groups are invited to come to the DSA office in room H-030 in the Altes Abgeordnetenhochhaus building on the United Nations Campus from Tuesday, 24 April to Friday, 27 April. Please bring your passport, electronic flight ticket confirmation and boarding pass(es). After receiving clearance from the DSA office, delegates can proceed to the bank to collect their DSA.”

So there is a group of participants who are eligible for flight, accommodation and daily allowance. All you have to do is go to a booth at the conference with your passport and plane tickets, and then there’s cash from the bank. It can be assumed that the participants of most African countries are fully financed by the UN.
In view of the good daily allowances and travel opportunity, the incentive to participate in the climate conferences is great. The COP24 has its own website for ‘Funded Delegates Accommodation’. The minimum stay in Katowice is 12 days. What is the usual UN daily allowance? According to the ICSC website, Poland receives $194 per day outside Warsaw. For a stay of 12 days, that’s $2,328 per person. In Bonn, it was $272 per day in the previous year. This may explain the slight decline in the number of interested parties this year.
Is COP24 really only about climate?
Share this...FacebookTwitter "
"
Share this...FacebookTwitter• CO2 emissions from termites are more than double human emissions from fossil fuels.


Image sources:  New York Times, 1982,   Zimmerman et al., 1982

• Termite populations have been observed expanding rapidly in recent decades.


Image Source: Grace, 2006

Image Source: Buczkowski and Bertelsmeier, 2017

• CO2 emissions from soil is 9 times greater than human CO2 emissions.


Image: press release for Carey et al., 2017

• Deserts are shrinking as the Earth greens and soil area expands.

Venter et al., 2018      “Over the past three decades, 7.5 million km2 (55%) of non-forest biomes in sub-Saharan Africa underwent significant net gains in woody plant cover. This is more than triple the 2.2 million km2 (16%) significant decrease in woody plant cover, confirming local-scale studies indicating increases in WPE [woody plant encroachment] over the last century. … These results confirm global greening trends, thereby bringing into question widely held theories about declining terrestrial carbon balances and desert expansion.”
Munier et al., 2018     “On average, all vegetation types have experienced greening over the last two decades at rates ranging from 0.026 m2m−2yr−1 for winter crops to 0.042 m2m−2yr−1 for coniferous forests. Coniferous forests are mainly greening in temperate regions and show the largest area affected by high positive trends. By contrast, grasslands are greening at a moderate average rate, but since they cover almost half of the total vegetated area, the grassland area affected by high trend values is greater than for any other vegetation type but coniferous forests. … In the tropical zone, evergreen forests and grasslands are rapidly greening (see Table 4), which seems to be related to rising CO2 in the atmosphere [Zhu et al., 2016]. On the contrary, in high latitudes of the Northern Hemisphere where coniferous forests are dominating, Zhu, Z. et al. [2016] suggested that changes in the vegetation dynamics are mainly driven by climate change.”
Brandt et al., 2017     “Here we used a passive microwave Earth observation data set to document two different trends in land area with woody cover for 1992–2011: 36% of the land area (6,870,000 km2) had an increase in woody cover largely in drylands, and 11% had a decrease (2,150,000 km2), mostly in humid zones. Increases in woody cover were associated with low population growth, and were driven by increases in CO2 in the humid zones and by increases in precipitation in drylands, whereas decreases in woody cover were associated with high population growth.”
Bastin et al., 2017     “We show that in 2015, 1327 million hectares of drylands had more than 10% tree-cover, and 1079 million hectares comprised forest. Our estimate is 40 to 47% higher than previous estimates, corresponding to 467 million hectares of forest that have never been reported before. This increases current estimates of global forest cover by at least 9%.”

Question
If termite populations and soil-terrain area have been rapidly
growing in recent decades, and these sources emit 2 and 9 times
more CO2 into the atmosphere than humans do via fossil fuel
combustion respectively, why is it assumed that an increase in
human CO2 emission is 100% responsible for the increase in
atmospheric CO2 concentration?
Share this...FacebookTwitter "
"The scientists responsible for the “doomsday clock” moved it 30 seconds closer to midnight – the symbolic point of total catastrophe for humanity and the planet – at the beginning of 2018. The minute hand now hovers ominously at two minutes to 12, the closest point it has ever been (matching the previous peak of 1953 – the height of the Cold War).  This judgement is a reflection of the multiple threats we face as a species, the most urgent being nuclear war and climate change. The former has loomed over humanity for decades. But the latter emergency has only become apparent relatively recently (to the extent that some people and powers even deny that it is a problem). Yet the scientific consensus is clear and alarming. Unless we manage to limit global warming this century to 2°C, then we are in devastating, civilisation threatening trouble.  We’ll need many things to help combat this emergency: technological innovation and scientific and engineering advances which allow us to harness renewable energies. It will also require new patterns of working and living in more sustainable ways. And I think we will also need something that is both subtler and yet perhaps more profound than these revolutions: a new vision of nature itself. Over the past few centuries, various perspectives on nature have dominated public discourse – generally to the detriment of the environment. The first is the view that humankind has “dominion” over the Earth – that we rule over the planet in some consequential sense. This in itself is not necessarily problematic. It is conceivable that this could be aligned with an ethos of responsible and careful stewardship. But this “dominion” perspective has been widely allied with a mechanistic view of nature that views it as devoid of any intrinsic worth, identity, and purpose beyond its instrumental value to human beings.  The result is a dominant ideology which regards the natural world primarily as a resource that humans are free to plunder at will. This perspective has surely played a pivotal role in our planetary emergency.  But although much damage has already been done, I still believe we could redeem ourselves and set our relationship on a better path if we could develop an alternative vision – of which many can be found across human history and culture.  I’ve recently encountered a wealth of these through my research, which focuses on “untranslatable” words which relate to well-being. Such words are significant, as they represent ideas and practices which have been overlooked or under-appreciated in one’s own culture or time period, but have been recognised by another culture or era. These include visions of nature which have long been neglected in favour of the dominant ideology outlined above. A case in point is the idea of “natura naturans”. Albert Einstein was once asked whether he believed in God, and replied: “I believe in Spinoza’s God, who reveals himself in the orderly harmony of what exists – not in a God who concerns himself with the fates and actions of human beings.”  Baruch Spinoza, born in Amsterdam in 1632, was a pioneer of rationalism and helped lay the foundations for the Enlightenment. He was a controversial figure in his day – with his works placed on the Catholic Church’s List of Prohibited Books – mainly because he was accused by critics of promulgating atheism.  But his philosophy was more nuanced than simply being a direct rejection of the sacred. Rather, he is now seen as one of the first modern advocates of a perspective known as pantheism. This is the idea that God and the cosmos are indivisible – one and the same. To explain this idea, he deployed the Latin phrase “natura naturans” – nature naturing. God is the dynamic process and manifestation of creation itself, nature unfurling in all its glory. Since then, many thinkers have aligned themselves with a pantheistic perspective, even if many have dispensed with the notion of a theistic deity. In this modern sense of the term, the cosmos itself is regarded as sacred or precious in some way, as per Einstein’s reference to “the orderly harmony of what exists”.  Many contemporary scientists and philosophers share this view. They may not believe in God, per se, but the awe the universe inspires in them does appear to come close to religious devotion. For instance, the prominent atheist Richard Dawkins has spoken approvingly of “Einstein’s God”, which he describes as “the laws of nature which are so deeply mysterious that they inspire a feeling of reverence”.  This vision of nature as sacred – which seems to have the potential to appeal to all people, religious and nonreligious alike – may be just what is needed if we are to preserve this planet, our one and only home in the cosmos."
"
Share this...FacebookTwitterJochem Marotzke, Director of Germany’s Max Planck Institute for Meteorology (MPIM), says we would have to wait 20 years before seeing any impact on climate from CO2 reductions, based on model simulations. Climate variability prevails… 
=====================================================
Reduction of CO2 emissions possibly would have no effect on climate over the coming 20 years


By Die kalte Sonne
(German text translated/edited by P Gosselin)
Jochem Marotzke, director of Germany’s Max Planck Institute for Meteorology (MPIM), wondered whether CO2 savings could really have a direct influence on the temperature in the near future. In a new paper (Marotzke 2018), the Hamburg-based climate researcher simulates the temperature profile of the 2030s predicted by climate models and uses once again a conventional emission profile (Scenario RCP 4.5), and once a politically reduced emission scenario. 
Conclusion: Most likely, there would probably be no difference as natural climate variability prevails over these time scales. The paper was published in WIRE’s Climate Change and can be downloaded free of charge as a pdf:

Quantifying the irreducible uncertainty in near‐term climate projections
If the Paris agreement at the Conference of Parties 21 is implemented very effectively, greenhouse‐gas emissions might decrease after year 2020. Whether this would lead to identifiable near‐term responses in “iconic” climate quantities of wide scientific and public interest is unclear, because the climate response would be obscured by quasi‐random internal variability. I define the climate response as an increase or decrease in a linear climate trend over the period 2021–2035, compared to 2006–2020, and establish the probability of such a trend change being caused by an assumed policy shift toward emissions reductions after 2020. I quantify the irreducible uncertainty in projecting such a trend change through very large (100‐member) ensembles of the state‐of‐the‐art climate model MPI‐ESM‐LR. Trends in global‐mean surface temperature (GMST) are higher over the period 2021–2035 than over 2006–2020 in one‐third of all realizations in the mitigation scenario RCP2.6, interpreted as implementing the Paris agreement, compared to around one‐half in the no‐mitigation scenario RCP4.5. Mitigation is sufficient to cause a GMST trend reduction with a probability of 0.40 and necessary with a probability of 0.33. Trend increases in Arctic September sea‐ice area and the Atlantic meridional overturning circulation are caused by the emissions reductions with a probability of only around 0.1. By contrast, emissions reductions are necessary for a trend decrease in upper‐ocean heat content with a probability of over one‐half. Some iconic climate quantities might thus by year 2035 exhibit an identifiable response to a successful Paris agreement but sometimes with low probability, creating a substantial communication challenge.”

In the conclusion, there are some even clearer statements. Marotzke warns that even painful efforts to reduce CO2 in the next two decades could have little impact on the climate:
My thought experiment demonstrates that it is crucial to have realistic expectations of the efficacy of climate policy in the near‐term: Even if greenhouse‐gas emissions begin to decline after year 2020, the probability is substantial that the response of iconic climate quantities to this decline will not have emerged by year 2035.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Science communication challenge
With 90% probability, the Arctic Sea Ice (SIA) and the Gulf Stream (AMOC) will not respond to changes in CO2 emissions in the 2030s. Marotzke already sees a great communication challenge for the scientists, similar to the unexpected hiatus of recent years.

The major advance brought about by my analysis lies in the ability to quantify the degree of irreducible uncertainty about whether the assumed emissions reduction will cause the desired climate response over a given timescale. The probability of this response occurring depends on the quantity in question but also on the type of causation; for the time horizon out to 2035 the probability lies here in the range between a bit under 0.1 for causation both sufficient and necessary for SIA and AMOC and a bit above one‐half for necessary causation for ocean heat content.
Communicating these probabilities will be nontrivial but will be aided by the precise definitions and meanings underlying them (Hannart et al., 2016; Pearl, 2000). The communication challenge (Deser et al., 2012) furthermore supports the notion that the recent hiatus was not a distraction to the scientific community (Lewandowsky, Risbey, & Oreskes, 2016) but instead provided an opportunity to communicate the role of internal variability (Fyfe et al., 2016) to an audience that might otherwise be disinclined to engage in this discourse.”


The climate sciences continue to navigate in difficult waters. The natural variability causes them huge problems because it has been neglected in the models.
Alarmist dreams
Marotzke still dreams that nature only produces noise (“quasi-random internal variability”). However, the day will surely come when he will also acknowledge the systematic effect of natural climate factors such as ocean cycles and solar activity fluctuations. Perhaps he should start to take an interest in paleoclimatology, which is leaving him in the dust…


Share this...FacebookTwitter "
nan
"There are few dams in the world that capture the imagination as much as Belo Monte, built on the “Big Bend” of the Xingu river in the Brazilian Amazon. Its construction has involved an army of 25,000 workers working round the clock since 2011 to excavate over 240m cubic metres of soil and rock, pour three million cubic metres of concrete, and divert 80% of the river’s flow through 24 turbines. Costing R$30 billion (£5.8 billion), Belo Monte is important not only for the scale of its construction but also the scope of opposition to it. The project was first proposed in the 1970s, and ever since then, local indigenous communities, civil society and even global celebrities have engaged in numerous acts of direct and indirect action against it.  While previous incarnations had been cancelled, Belo Monte is now in the final stages of construction and already provides 11,233 megawatts of energy to 60m Brazilians across the country. When complete, it will be the largest hydroelectric power plant in the Amazon and the fourth largest in the world.  The dam is to be operated by the Norte Energia consortium (formed of a number of state electrical utilities) and is heavily funded by the Brazilian state development bank, BNDES. The project’s supporters, including the governments of the Partido dos Trabalhadores (Workers’ Party) that held office between 2003 and 2011, have justified its construction on environmental grounds. They describe Belo Monte as a “sustainable” project, linking it to wider policies of climate change mitigation and a transition away from fossil fuels. The assertions of the sustainability of hydropower are not only seen in Brazil but can be found across the globe – with large dams presented as part of wider sustainable development agendas. With hydropower representing 16.4% of total global installed energy capacity, hydroelectric dams are a significant part of efforts to reduce carbon emissions. More than 2,000 such projects are currently funded via the Clean Development Mechanism of the 1997 Kyoto Protocol – second only to wind power by number of individual projects.  While this provides mega-dams with an environmental seal of approval, it overlooks their numerous impacts. As a result, dams funded by the CDM are contested across the globe, with popular opposition movements highlighting the impacts of these projects and challenging their asserted sustainability. Those standing against Belo Monte have highlighted its social and environmental impacts. An influx of 100,000 construction and service workers has transformed the nearby city of Altamira, for instance. Hundreds of workers – unable to find employment – took to sleeping on the streets. Drug traffickers also moved in and crime and violence soared in the city. The murder rate in Altamira increased by 147% during the years of Belo Monte construction, with it becoming the deadliest city on earth in 2015.  In 2013, police raided a building near the construction site to find 15 women, held against their will and forced into sex work. Researchers later found that the peak hours of visits to their building – and others – coincided with the payday of those working on Belo Monte. In light of this social trauma, opposition actors gave the project a new moniker: Belo Monstro, meaning “Beautiful Monster”. The construction of Belo Monte is further linked to increasing patterns of deforestation in the region. In 2011, deforestation in Brazil was highest in the area around Belo Monte, with the dam not only deforesting the immediate area but stimulating further encroachment.  In building roads to carry both people and equipment, the project has opened up the wider area of rainforest to encroachment and illegal deforestation. Greenpeace has linked illegal deforestation in indigenous reserves – more than 200km away – to the construction of the project, with the wood later sold to those building the dam.  Brazil’s past success in reversing deforestation rates became a key part of the country’s environmental movement. Yet recently deforestation has increased once again, leading to widespread international criticism. With increasing awareness of the problem, the links between hydropower and the loss of the Amazon rainforest challenge the continued viability of Belo Monte and similar projects. While the Clean Development Mechanism focuses on the reduction of carbon emissions, it overlooks other greenhouse gases emitted by hydropower. Large dams effectively emit significant quantities of methane for instance, released by the decomposition of plants and trees below the reservoir’s surface. While methane does not stay in the atmosphere for as long as carbon dioxide (only persisting for up to 12 years), its warming potential is far higher. Belo Monte has been linked to these methane emissions by numerous opposition actors. Further research has found that the vegetation rotting in the reservoirs of dams across the globe may emit a million tonnes of greenhouse gases per year. As a result, it is claimed that these projects are – in fact – making a net contribution to climate change.  Far from providing a sustainable, renewable energy solution in a climate-changed world, Belo Monte is instead cast as exacerbating the problem that it is meant to solve. Belo Monte is just one of many dams across the globe that have been justified – and funded – as sustainable pursuits. Yet, this conflates the ends with the means. Hydroelectricity may appear relatively “clean” but the process in which a mega-dam is built is far from it. The environmental credentials of these projects remain contested, with Belo Monte providing just one example of how the sustainability label may finally be slipping."
"
Share this...FacebookTwitterImpressive Cold Grips As Planet Continues Its Warming Pause
By SnowFan
(Translated/summarized by P Gosselin)
The continuing global cooling and the start of the grand minimum require new targets in climate policy and a complete withdrawal from the previous warming madness.
After a complete failure by the IPCC climate models and the crazy assignment of CO2 as a pollutant, scientific reason must once again return to the climate discussion.
Neither did the sea ice in the Arctic disappear in the summer of 2016 as it was often predicted by nutty scientists (even by NASA, who wrote that Arctic summers would be ice-free by 2013), nor have global temperatures risen by an significance over the past 20 years, thus contradicting the projections of IPCC models.

The chart above depicts in orange the range of the IPCC projections for the deviation of global mean temperature since 1990. The mean IPCC projection was +0.75°C of warming. Satellite measurements by UAH and RSS (blue line) show only an increase of 0.34°C. The models have been completely wrong. Source: When will “The Pause” in global temperature return? 
Moreover, the ice mass at both poles and Greenland have grown over the past years. Also the facts surrounding the increasingly cooler Antarctic are presented by a recent study.
An extreme record value of almost -100°C was measured in 2004, but kept quiet in order not to dísturb the quasi religious fairy tale of manmade “global warming”.
1988 Maldives predictions an epic blunder


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This is also one reason why sea level rise has increased less than originally projected and why the 1988 prophesy that all 1196 Maldives islands would sink underwater within 30 years have turned out to be preposterous. Not a single island has gone under!
“Missed It By That Much”
On September 26, 1988, “experts” announced all of the 1196 Maldives islands would be underwater. In 2018 – 30 years later – we see this has ended up being an epic blunder.

Source: Real Climate
In fact, one recent paper found, for example, that the South Sea Tuvalu islands have grown, the shaming climate scientists!
Time for competent and honest institutions
The time has arrived where government offices, authorities, weather services, media headquarters and educational institutes become staffed by educated and independent persons who are able to see the reality in the interrelationships of weather and climate and report them in an unfalsified manner.
It’s the sun, water, clouds, vapor, ice, snow that determined the weather of our planet, and not life-sustaining trace gas CO2, which makes up only 0.04%of our atmosphere.
Anyone who vilifies trace gas CO2 as a pollutant conducts him/herself in a manner that is hostile to life and is thus not suited to be a scientist, teacher, professor, journalist or politician!
Share this...FacebookTwitter "
"
Share this...FacebookTwitterClimate modeler Jochem Marotzke: more time to decarbonize, earlier climate models were too sensitive 
=========================================================
Correction (12 November 2018): Dr. Lüning writes that he had to modify his post on Marotzke a bit. “Marotzke did not mean CO2 climate sensitivity but that more CO2 is buffered, adding less to the atmosphere.” However, the goalposts still have been moved back and we still get 10 more years. 
==========================================================
Hat-tip: Sebastian Lüning and Fritz Vahrenholt
On October 5, 2018, German national weekly Spiegel here presented a noteworthy interview with Germany’s top climate modeler, Jochem Marotzke, director of the Max Planck Institute for Meteorology in Hamburg.

Top German climate modeler, Jochem Marotzke, Director of the Hamburg-based Max Planck Institute for Meteorology. Image: Max Planck Institute for Meteorology.
Spiegel wrote in its sub headline:

Unexpected extra time in the climate scenario: ‘Our reprieve has been extended by about ten years’ Physicist and climate researcher Jochem Marotzke explains why humanity has more time to stop global warming than previously thought.”

Or in other words, German skeptics Dr. Sebastian Lüning and Prof. Fritz Vahrenholt write at their Die kalte Sonne blog, “the sensitivity of CO2 was obviously overestimated.”
Yes, the climate goalposts just got moved back once again.
Earlier skeptic claims of overly sensitive models now spot on
More than 6 years ago in 2012, Lüning and Vahrenholt had already pointed out the problem of over-sensitive models in their book “Die kalte Sonne” – a claim that Marotzke back then said was “completely outlandish”.
Naturally today Lüning and Vahrenholt find themselves somewhat vindicated, and are confident more vindication is on the way as the reality of climate change becomes increasingly known.
We can emit “at least twice as much”
In the Spiegel interview, conducted editor Olaf Stamp, Marotzke was asked about how much CO2 we could still add to the atmosphere:
MAROTZKE: […] According to the latest climate scenarios, the amount of CO2 that we may emit is far greater than previously assumed – a fundamental point.
SPIEGEL: So we’ve been given amore time to reduce CO2 emissions?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




MAROTZKE: Exactly. That’s what today’s improved models show. Our remaining CO2 budget for the 1.5°C target is in fact at least twice as much as previously thought: almost 1 trillion tonnes. Thus our reprieve has been extended about 10 years. Of course, it makes a huge difference if we have to bring the emissions of greenhouse gases down to zero in 15 years or 25 years. I assume that this will be the key message in the special report.”
And, according to Marotzke:
Our earlier models are too sensitive in one crucial place […]”
Here the Hamburg-based Max Planck Institute for Meteorology director is talking about CO2 climate sensitivity. And Lüning and Vahrenholt write: ” And when Marotzke says this, then it has real weight.”
IPCC Report politicized, “long deviated from the scientific basis”
In the Spiegel interview, which took place three days before the IPCC report was released, Marotzke suspected that the 1.5-degree report of the IPCC was to play down the danger of climate change. But when the report came out, it conveyed the opposite, namely worsened climate warnings. 
This, according to Lüning and Vahrenholt, “is an indication that it is more a political report than a scientific account. Apparently the IPCC report authors, handpicked by politics, have already long deviated from the scientific basis.” 
1.5°C target ” came as a surprise to us climatologists”
When asked by Spiegel why the 1.5°C target was used instead of 2°C:
SPIEGEL: Why was the limit lowered from 2 degrees to 1.5 degrees? 
MAROTZKE: That came as a surprise to us climatologists as well. Especially the West Pacific island states insisted on 1.5 degrees at the Paris negotiations because they would be threatened by the rise of the sea level already at 2 degrees. However in most parts of the world, especially in Europe, we do not expect much difference between a 1.5-degree world and a 2-degree world.”
Politics overruling science
“Once again, political motives were more important than science,” Lüning and Vahrenholt write in response to Marotzke’s comments. 
“Curiously enough, the Pacific Islanders also ignore the fact that they live on growing coral islands, which have already withstood much stronger sea-level rise rates in the transition from the last ice age to today’s interglacial. One has to assume that, above all, this should accelerate the path to the international coffers for climate compensation payments,” say skeptics Lüning and Vahrenholt. 
The whole Spiegel interview is behind a paywall at spiegel.de.
Rejects claims of tipping points taking place
Marotzke also explained that signs of the alleged tipping points coming from the Potsdam Institute were rather weak. He also flat out rejected the tipping points of a stalling Gulf Stream and melting West Antarctic.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterYesterday we wrote about a study that told us the data do not support that weather blockings are occurring more often than they used to. Some alarmist media and scientists have claimed that the heavy snowfalls in the Alps are happening due to manmade global warming.
Swiss meteorologist: Such snowfalls “nothing unique” for Alps
Yesterday one of Europe’s most high profile meteorologists, Jörg Kachelmann, penned an opinion piece at t-online.de reminding the public that heavy snow events in the Alps, such as the one we are now experiencing, are in fact nothing unique and that it is not a catastrophe.
In the days ahead, many parts of the Alps are expecting up to another meter of new snow, yet, according to Kachelmann, this should not pose any problems to buildings and structures – if their construction indeed adhered to the applicable building codes.
“Nothing to do with climate change”
Kachelmann adds later in his t-online piece: “1. The snowfalls are nothing unique so far for the Alps. 2. They have nothing to do with climate change.”
The veteran Swiss meteorologist adds that the heavy snow in the Alps “are making people happy because they ensure the ski season will extend until Easter.”
Snow is in fact welcome
Moreover, they are good for the glaciers, and will help relieve the drought conditions seen in Europe last year. The Swiss meteorologist adds:
They [the snowfalls] are making the media happy as well because weather catastrophes get many clicks. However, the current weather situation is not a catastrophe. Human lives (except in the mentioned 0.1 percent problem) are only in danger if people behave inappropriately.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Kachelmann also thinks the media overhype now taking place may be unnecessarily scaring people away from booking ski trips to the Alps, a region where massive amounts of snow are common.
Models suggest severe winter conditions
Meanwhile, German meteorologist Dominik Jung of wetter.net reported that a Russian “Beast from the East” looks to be in the works for Europe for the weeks ahead:

According to Jung, who cites US and European weather models, beginning January 20 much greater cold will be invading large parts of Europe. And by January 25, the cold conditions could deepen and become extreme.
Northern hemisphere “under the gun”
Also at Weatherbell, 40-year meteorologist Joe Bastardi backs Jung’s projected development, presenting a frigid chart at yesterday’s Daily Summary that shows the forecast 11-16 days out:

Cold to grip Europe, North America and Asia in the weeks ahead, models suggest.
Joe says:
Once this gets here, until March, these areas and these areas, are under the gun. Repetitive snow threats and bitter cold relative to averages, and it’s coming at the coldest time of the year.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterLeft-leaning filmmaker German-Dutch filmmaker Martin Poels has produced some 50 films over the past 15 years. 

German-Dutch film maker Martin Poels has come under attack for questioning climate dogma. Image cropped here.
His most recent film is titled Paradogma – a personal journey why true liberty needs heretics, It focusses on current controversial debates such as climate change, and how dissenters are being silenced.
Martin Poels recently wrote: “People who dare to question important themes today, are often silenced or labeled as suspicious and dangerous and that we now find ourselves “in a new era where world views clash and free speech crumbles under pressure to conform.”
German liberty under threat
And because Poels has been critical concerning the state of the climate debate, he has been threatened and marginalized. 
German mainstream media has silenced the film, and anonymous threats have been launched against Poels, which show that the topic of climate and energy has become type of religion.
And anyone who questions this religion gets shut out of the public discussion forum.
Nevertheless journalist Jörg Rehmann spoke with Poels after the screening of his film in Brussels at the end of last year:

According to the interview:
Since Martin Poels has become critical about the contradictions of climate science, he has been blocked out by the German media and threatened by green lobbyists and at times called a Nazi.”
In the interview he begins by stating that because the film looks at climate and energy, it is a difficult topic because of the deep political dogma that it involves. “But the biggest problem,” Poels said, “Is that the media refuses to report on it.”
Climate: “forged” consensus that must not be disturbed
Poels mentions that they were successful, however, getting the film shown in 100 cinemas. Overall he calls the subject of climate in Germany a dogma that it is very difficult to criticize. He calls climate consensus something that was forged, and not something that is to be disturbed.
Hostile Greenpeace?
The filmmaker speaks of having received threats from organizations, such as Greenpeace, so much so that he became afraid. He said: “I got a call warning that I should better stop the film, before you really get problems.” He says the call was anonymous, but his understanding was that it came from Greenpeace.
Next Poels describes how some people reacted when the film was shown. He said: “Sometimes there were people who got really aggressive in their talk against me”.
“Shameful” media


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




He then calls the German publicly funded media’s role in the climate topic “shameful”, as it is clear that the green energy issue is not a topic that is to be questioned nor discussed.
Either you’re with us, or against us
Poels also notes that the topic of green energies can be discussed and criticizesd in Holland, but that it Germany the issue of green energies has become very sensitive and criticism is not welcome “because rescuing the climate is good, and when you criticize it, it means you no longer want to save the planet.” It’s: either you’re with us, or against us. Poels calls this radical mindset “nonsense”.
Corrupted by business interests
Poels sees green energies as desirable, but currently he believes they are a social injustice, as the rich benefit and the poor have to bear the costs. Moreover, they are harming the environment more than they are helping.
The flim also shows that the science is long from being settled, thus contradicting claims often made by alarmist scientists and the media. Poels believes that the science has been corrupted in part by lobbyists “where the target is no longer the target, and that business has become the target itself.” He adds:
For me, that’s one explanation why we are not allowed to discuss it. Because it criticizes not only climate change, but the business behind it.”
Biased media has abandoned its job
For Poels, this corruption by self interest is simply being neglected by the German public media: “There are simply rules within the media that say to talk about climate change uncritically – only positively. That’s a law within the media business.”
In total, Poels believes German journalism has long abandoned it’s neutrality on the topic of climate change and green energies. “It’s only politics.” He comments further:
Not only the science is politicized, but so are the media.”
German media “really frightening”
Poels then says the media are more open in the Netherlands, but finds the situation in Berlin “really frightening”. He agrees that in Germany it’s enough to express skepticism on climate science in order to be labelled a fringe right winger.
He finds it ironic that the media often accuse climate skeptics of conspiracy theories, but at the same time subscribe to the conspiracy theory that oil companies helped fund his film.
Academic arrogance
In the area of academia, Poels says overall the film has been received positively and openly by most students, but that professors have composed themselves arrogantly and simply dismiss the film’s content offhand after viewing it. One example, Poels cites, is how one professor simply dismissed a critical student – who had challenged the professor – as “a student who still had a lot to learn”.
Energiewende at a dead-end
In summary Poels agrees that the German Energiewende has reached a dead-end and that the establishment is no longer capable of learning lessons.
Historically, that all sounds familiar.
Share this...FacebookTwitter "
nan
"The unusually hot summer of 2018 has proved challenging for farmers across the UK. Among other things, the scorching weather and lack of rain has damaged crops, and the grass used to feed farm animals too. Unfortunately the unusual may become more usual as the effects of climate change are felt more frequently across the world. The high ambient temperatures and humidity seen this year, as well as extreme weather conditions such as flooding, are a significant challenge to the future of farming.  Pasture-based systems of dairy production, which are very common in the UK, are particularly sensitive to environmental factors. In fact, dairy cows are more likely to be vulnerable to the effects of climate change than cows that are housed, because housing provides shelter and technological options to mitigate the extremes of weather.   For our recent study, our team looked at how climate change might impact UK milk production, given what we already knew about how it affects dairy cows. In particular, we wanted to quantify the effects of heat stress on milk production.  Heat stress in cows occurs when ambient temperature and humidity go above animal specific thresholds. These thresholds are estimated by the temperature humidity index (THI). At present, the current British temperature and humidity is considered moderate on this scale, but is expected to get worse. It is open to debate, and depends on the cattle themselves, but generally a THI of more than 70 is regarded to be the point when heat stress becomes a problem and less milk is produced. Using 11 different climate projection models, and 18 different milk production models, we estimated potential milk loss from UK dairy cows as climate conditions change during the 21st century. Given this information, our final climate projection analysis suggests that average ambient temperatures in the UK will increase by up to about 3.5℃ by the end of the century. This means that THIs during the summer, in some parts of the country, will lead to significant heat stress for cows if nothing is done to alleviate the hot weather’s effects.  Lactating cows initially respond to mild heat stress by sweating, panting, drinking more, and seeking shade when possible. At higher temperatures cows eat less feed, which leads to a fall in milk production. In south-east England – the region with the highest incidence of heat stress – the average annual milk losses due to heat stress is projected to exceed 170kg/cow. Cows in the UK currently produce an average of about 7,500kg of milk each year so these future losses would be about 2.4% of their production.  However, climate change projections also suggest the UK would experience more heatwaves, and these would lead to even greater losses of milk. For example, the hottest area (south-east England) in the hottest year in the 2090s is predicted to result in an annual milk loss exceeding 1,300kg/cow, which is about 18.6% of annual milk yield.  In economic terms, south-west England is expected to be the region most vulnerable to climate change because it is characterised by a high dairy herd density, and so potentially a high level of heat stress-related milk loss. In the absence of mitigation measures, the estimated heat stress-related annual income loss for this region by the end of this century may reach £13.4m in average years, and £33.8m in extreme years. However, by the end of the century we predict dairy cattle in large portions of Scotland and Northern Ireland could experience the same level of heat stress as cattle in southern England today.  These predictions assume that nothing is done to mitigate the problems of heat stress. But there are many parts of the world that are already much hotter than the UK where milk is produced, and much is known about what can be done to protect the welfare of the animals and minimise economic losses from heat stress. These range from simple adaptations, such as the providing shade, to installing fans and water misting systems.  Cattle breeding for increased heat tolerance is another potential, which could be beneficial for maintaining pasture-based systems. In addition, changing the location of farming operations is another practice used to address economic challenges worldwide. Even though there is little indication that movement of dairy farming operations is a feasible strategy to decrease the risks of environmental challenges in the UK, regions with little or no prediction of conditions leading to heat stress (for example some parts of Scotland) may become increasingly important for UK dairy farms that depend on the availability of pasture. In any case, we estimate that by 2100, heat stress-related annual income losses of average size dairy farms in the most affected regions may vary between £2,000-£6,000 and £6,000-£14,000 (in today’s value), in average and extreme years respectively. Armed with these figures, farmers need to begin planning for a hotter UK using cheaper, longer-term options such as planting trees or installing shaded areas."
"Scientists have for the first time created hybrid embryos with DNA from the nearly-extinct northern white rhinoceros, an advance that could ultimately lead to the first resurrection of a mega-mammal. But while this scientific achievement could provide a new way to produce future generations of endangered or extinct animals, applying this approach to the white rhino does not meet with universal approval among conservationists. The international team of researchers, led by Professor Thomas Hildebrandt from the Leibniz Institute for Zoo and Wildlife Research, have used an existing assisted reproduction technology developed for horses, and applied it to the white rhino. Eggs and sperm from northern white rhino are in short supply, due to the rarity of the subspecies. So the team also used material from southern white rhino, successfully fertilising southern eggs with sperm from both northern and southern subspecies, proving that the process works. Only seven out of 314 fertilised eggs developed into embryos – a roughly 2% success rate – but the research demonstrated three important steps. First, that rhino eggs can be captured from live females. Second, that they can be fertilised using IVF and developed to the “blastocyst” early embryonic stage (ready for transfer to a surrogate female) – and that this can be done as a hybrid of southern and northern rhino. And third, that the resulting embryos can be frozen without damage. This process is technically very challenging. A special device was developed to enable the operators to extract oocytes (unfertilised eggs) from the ovaries of anaesthetised female southern white rhino from a number of European zoos. This is a three-person job requiring a steady hand that can guide a needle of just over 1 millimetre in diameter and almost 1 metre in length into the reproductive system via the rectum to capture the eggs. The next step will be to transfer three of the embryos that have been frozen to the uterus of surrogate southern white rhino for gestation and birth. This final step toward the birth of a calf containing northern white rhino DNA is no small step, as artificial insemination in rhino has rarely been attempted. San Diego Zoo is currently evaluating six surrogacy candidates, and has already successfully artificially inseminated one with southern white rhino sperm. The four other embryos produced were used to evaluate the potential for creating sperm and eggs from the genetic material of northern white rhino whose sex cells are not already available. While this only worked for southern white rhino embryos and not the hybrids, it did demonstrate the method could be successful. As the first demonstration of this process working for rhino, the research is significant, impressive and exciting. It offers a possibility to rescue the genes of a subspecies that, following the death of the last male northern white rhino earlier this year, is now represented by just two elderly females. And if the method works for the rhino, it should be possible to extend it to other endangered large mammals. The key question of whether scientists can produce pure northern white rhino embryos using this technique remains unanswered. But, even if it is possible, what would be the point? Ultimately, to be useful, these manipulative techniques need to increase the chance of survival of endangered (wild) animal populations. Otherwise, artificially engineered fertilisation and the management of genes has little value for nature conservation. To my mind, the time to save the northern white rhino has passed. If we could not save it when it was here (the last wild northern white rhino is thought to have disappeared around 2006) it seems unlikely we could conserve a resurrected wild population now or in the foreseeable future. The purpose of simply preserving the subspecies’ genes in a new hybrid rhino (in captivity), and whether it would be worth all the effort, is unclear. Recent research by Dr Tate Tunstall of the San Diego Zoo Institute for Conservation Research and colleagues indicates that there may be enough genetic diversity in the frozen northern white rhino material (from only 12 individuals) to provide a suitably diverse founder population for resurrection. They also showed that the genetic differences between the northern and southern subspecies may be the result of evolutionary adaptations to different habitats. An alternative strategy to resurrection would be to secure a safe habitat in the former northern white rhino’s range of central East Africa, populate it with southern white rhino and let natural selection run its course. The introduced rhino population would be expected to evolve over generations to adapt to their new environment and fill the ecological role left vacant by the northern white rhino. There are already southern white rhino currently living and breeding in Uganda at the Ziwa Sanctuary. Restoration ecologists have similarly replaced extinct giant tortoises with related species in a process called taxon substitution. Taxon substitution using the southern white rhino would be simpler and more cost-effective than manipulating genes and introducing manufactured hybrids, and would likely have a higher probability of success. I am concerned that new technologies, such as the creation of these hybrid rhino embryos, are distracting us from on-the-ground conservation and dealing with the root causes of endangerment. There is a growing pervasive psychology that we need to preserve genes for some utopian future. The desperate logic of mixing subspecies and applying assisted reproduction technology is also being discussed regarding the Sumatran rhino. Saving bits of dead animal now to bring back species (or subspecies) in the future perpetuates the delusion that everything will be okay at some point. We need action now. Jurassic Park-esque scientific advances will only work if we save habitats, stop pollution, constrain invasive species, reverse climate change and halt poaching. Otherwise, I fear that we will still be loading samples onto the frozen ark as the lights go off on an otherwise empty Planet Earth."
"
Share this...FacebookTwitterPeople familiar with the chaos that is weather will agree that seasonal forecasts based merely on computer simulations are highly speculative and involve much guesswork. The quality of their output leaves little to be desired.
As much as some of these forecasts may be presented with authoritative tones, in the end they all come with a fine print disclaimer concerning certainty, and so they are nothing one can take to the bank.
The average of a series of WAGs
Even the most powerful super-computers using conventional simulations struggle to predict the weather 10 days out, let alone what an entire a winter will be like in terms of temperature and precipitation. The simulations used by the US weather agencies, for example, simply perform a number of data crunching runs — each using different start conditions — to generate  a set of scenarios (i.e. wild-ass guesses) and then average them out to create an “ensemble”. Under the bottom line, the ensemble is based on a set of wild ass guesses, and so is correspondingly unreliable.
Woefully uncertain
Not surprisingly, Germany’s flagship daily Frankfurter Allgemeine Zeitung (FAZ) also finds that the ensembles leave very little to be desired and point out that the seasonal forecasts issued by weather agencies such as the NOAA are hugely uncertain, and that clearly the computer simulation methodology is in dire need of improvement.
Even farmers seem to have greater success.
So what can be done to improve forecasting performance?
The FAZ writes that a whole new methodology has been developed by German scientists and that this new methodology promises to vastly improve seasonal forecasts. The FAZ writes that earlier this year a study by the University of Hamburg was published in the Geophysical Research Letters. The press release announced: “Possible for the first time: reliable three-month forecasts for European winters“.
80% winter season accuracy


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to the FAZ, oceanographer Dr. Mikhail Dobrynin of the Hamburg University Institute of Oceanography, Center for Earth System Research and Sustainability and his colleagues have developed a method that works with 80% success rate. Instead of solely relying on a super computer crunching data using a variety of start conditions and then averaging them out, Dobrynin says their method relies also on “teleconnections”, i.e. finding “signals amid the chaos“.
The FAZ reports that for winter forecasts, Dr. Dobrynin has identified four factors: “the snow depth in Siberia, Arctic polar vortex, extent of Arctic sea ice and the Atlantic ocean temperature”, which allow “the path of certain air masses going to Europe to be predicted”. The most critical of these is the snow cover over Siberia in fall.

The NAO index is one key factor in seasonal winter forecasts for Europe. Source: Geophysical Research Letters.
The scientists say that conditions in different geographical regions over the Atlantic “can act as a switch that steers winter weather in Europe” and that focusing on how these interact and behave can allow greatly improved forecasting.
According to the conclusion of the study, the method shows vastly improved performance:

For the real forecast test from 2001 to 2017 the prediction skill of the winter NAO is increased from 0.42 for the full ensemble mean to 0.86 for the subsampled ensemble mean. As a result of a better representation of the winter NAO, the prediction skill for the winter surface temperature, total precipitation, and SLP is improved for considerable parts of the NH.”

NOAA forecasts “hardly better” than guessing
The FAZ writes that “without considering teleconnections, winter in Europe has been virtually unpredictable”. 
Dr. Mikhail Dobrynin added that results of forecasts made by the NOAA “were hardly better” than if they had guessed. The new method should thus improve the winter season forecasts considerably. However, he warns that the uncertainty will always exist and we must remain wary of any predictions dealing with seasonal weather.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Kirye
Increasing CO2 in the atmosphere is supposed to be trapping heat and thus warming the global temperature.
But when we look at the Japan Meteorological Agency (JMA) statistics from my home country of Japan, one does not find any such warming over the recent decades.
I looked at the number of so-called cold days in Tokyo, i.e. days on which the thermometer dropped to 0°C and colder. Surprisingly over the past 30 years the trend has been more cold days, and not less:

Data source: JMA
Next I looked at the rural station of Miyama near Kyoto. This station shows a decreasing number of cold days trend since the data there began:

Data source: JMA
However, when we look at the past 34 years, a period when experts said in the late 1980s we’d see great warming, the opposite has in fact occurred:

Data source: JMA
The number of cold days at Miyama has since been on the rise. And if I started the chart at 1989 (30 years), the upward trend would be even more impressive.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Now moving far north to Hokkaido to the station of Suttsu, we also find the trend is the same over the past 30 years: we are seeing more cold days, and not less as we’d expect from a warming planet:

Data source: JMA
Moving to Kochu Prefecture to Murotomisaki station, here as well we find no downward trend for cold days. Cold days are on the rise:

Data source: JMA
Also the station of Tottori has been seeing an upward trend in the number of cold days over the past 30 years:

Data source: JMA.
90% no warming!
Of course over the past 200 years there has been a long term warming as the planet climbed out of the Little Ice Age. But overall over the past 3 decades, Japan has been seeing an increase in cold days. This should not come as a surprise because recently we found out that 90% of all rural sited stations in Japan have shown no warming trend, or even cooling, over the past 20 years.
The data show here has been no warming in Japan, and leaders need to finally acknowledge this.
Obviously natural factors are overwhelming CO2’s (modest) greenhouse effect.
Share this...FacebookTwitter "
"As Australia’s unprecedented bushfire season continues to unfold, competing arguments have been made about the principal causes of the human and environmental tragedy – particularly around the role of climate change. The prime minister, Scott Morrison, has acknowledged that climate change has had an influence on the fires and has defended his government’s climate record. But Morrison has also said that “job-destroying, economy-destroying, economy-wrecking targets and goals” on climate change “won’t change the fact that there have been bushfires or anything like that in Australia”. Backbench MP Craig Kelly denied any link between climate change and bushfires in a combative interview on British TV. Conservative media have concentrated on other factors, such as the amount of hazard reduction burning carried out, or the activities of arsonists – a claim shown to have been inflated and misrepresented. Bushfire experts say that in normal years hazard reduction is a way to control the behaviour of fires, but the changing climate is making it harder to carry out prescribed burns and, according to fire chiefs, it is not a “panacea” for extreme bushfires. Here is what we know about the long-term influences on the bushfire catastrophe. Extreme heat and dryness are two important influencers of fire and, on both measures, 2019 was remarkable for Australia. Australia experienced its hottest year on record in 2019, with average temperatures 1.52C above the 1961-1990 average. Our second hottest year was 2013, followed by 2005, 2018 and 2017. New South Wales – one state hard hit by the bushfires – broke its record by a greater margin, with temperatures 1.95C above average, beating the previous record year, 2018, by 0.27C. At a very basic level, rising levels of greenhouse gases in the atmosphere change the Earth’s radiation balance, allowing less heat to escape. Australia also had its driest ever year in 2019, with rainfall 40% lower than average, based on records going back to 1900. NSW also had its driest year. A visualisation from Prof Nerilie Abram, a climate scientist at the Australian National University, examines hot and dry years in Australia since 1910 and how they correlate with major bushfires. Fire authorities and the Bureau of Meteorology look at the risk of bushfires using the forest fire danger index, a combined measure of temperature, humidity, wind speed and the dryness, but not the amount, of fuel on the ground. Australia’s 2019 spring months of September, October and November were the worst  on a record going back to 1950 for bushfire risk. There have been two other meteorological patterns that helped generate the extreme conditions Australia has been experiencing, and both these “modes of variability” were in “phases” that made conditions worse. The Indian Ocean dipole was in a “positive phase”, meaning the Indian Ocean off Australia’s north-west was cooler than normal and the west of the ocean was warmer. Positive dipole events draw moisture away from Australia and tend to deliver less rainfall. But there is evidence that the extra greenhouse gases in the atmosphere are also impacting the dipole and another phenomenon, known as the southern annular mode (SAM). A 2009 study found that positive dipole events “precondition” the south of the country for dangerous bushfire seasons and that these events were becoming more common. A 2018 study in the journal Nature Communications found the number of extreme positive dipole events goes up as climate heating continues. At 1.5C of global warming, the frequency of extreme positive dipole events doubles compared with the pre-industrial period. The southern annular mode was in a “negative phase” as the bushfires took hold in November and December. This phase was generated by a sudden warming event in the stratosphere above Antarctica. This caused westerly winds to track further north, blowing hot air across the continent into fire-prone areas, further fanning flames. Abram’s own research has found that the SAM is being pushed towards more positive phases which, when they occur in Australia’s winter, tend to dry the continent. Prof Matt England, of the University of New South Wales Climate Change Research Centre, said: “These modes of variability are not changing in a way that’s good for south-east Australia. “We know with certainty that we are stacking the dice for the chances of these extreme drought years because of the changes in the modes.” Scientists have already detected a trend towards more dangerous fire weather in Australia. A 2017 study of 67 years of FFDI data found a “clear trend toward more dangerous conditions during spring and summer in southern Australia, including increased frequency and magnitude of extremes, as well as indicating an earlier start to the fire season”. That trend continued in 2019, which was the riskiest year for bushfires on a record going back to 1950. A study of Queensland’s historic 2018 bushfire season found the extreme temperatures that coincided with the fires were four times more likely because of human-caused climate change. In advice issued in November 2019, Australia’s National Environmental Science Program was unambiguous. “Human-caused climate change has resulted in more dangerous weather conditions for bushfires in recent decades for many regions of Australia. “Observations show a trend towards more dangerous conditions during summer and an earlier start to the fire season, particularly in parts of southern and eastern Australia. “These trends are very likely to increase into the future, with climate models showing more dangerous weather conditions for bushfires throughout Australia due to increasing greenhouse gas emissions.” Despite such unequivocal statements, Scott Morrison has been irritated that interviewers have asked about his government’s record on climate change, saying it was “just ridiculous” to link “any one emissions reduction policy to any of these fires”. Morrison’s argument that no emissions reduction policy can be tied to individual events is spurious, as the same argument could be put for any and all efforts to reduce emissions anywhere in the world, at any time. Scientists also believe that 2019 was a “standout” year in Australia for the formation of extreme bushfires that became “coupled” with the atmosphere, generating their own lightning and gusty, violent and unpredictable winds. Rainfall is replaced with blackened hail and embers that can be shot out over distances of 30km. Another study has found that global heating will create more favourable conditions for these “pyroCB” storms to form in Australia. Climate studies show that conditions in Australia for extreme bushfires will only get worse as more greenhouse gases are added to the atmosphere. On Friday afternoon the president of the Australian Academy of Science, Prof John Shine, said Australia would need to further improve its climate modelling ability and understanding of fire behaviour to mitigate against the extreme events that would become more frequent and intense because of climate change. “Australia must take stronger action as part of the worldwide commitment to limit global warming to 1.5° C above the long-term average to reduce the worst impacts of climate change,” he said. England said: “We are loading the dice for more and more of these summers. But we have had knowledge of this for some time. “What we have seen in Australia this year will just be a normal summer if we warmed the planet by 3C. And an extreme summer would be even worse than we’ve seen now.” Abram said: “Even from my perspective, I am surprised by just how bad 1C of warming is looking. “It’s worrying that we are talking about this as a new normal, because we are actually on an upward trajectory. Currently the pledges in the Paris agreement are not enough to limit us to 1.5C – we are looking more like 3C.”"
"Today the student movement made history by announcing that more than half of UK universities have committed to divest from fossil fuel companies. Since 2012, students have campaigned to marginalise companies like Shell and BP which profit from climate breakdown. The campaign, supported by the National Union of Students,People & Planet and Students Organising for Sustainability UK, has shown the power of students taking collective action. The University of Glasgow was the first UK university to divest in October 2014, and was soon followed by major divestments after sustained campaigns at institutions including Warwick, Sheffield, King’s College London, Edinburgh and Durham. The 50% mark was reached when the University of York became the 77th UK university to divest.  As we celebrate this moment, we should also reflect on how it has taken us so long to get here. We should ask why globally important universities including Oxford and Cambridge still refuse to move their money out of all fossil fuels. Despite growing declarations of climate emergency, 50% of UK universities remain invested in the principle profiteers of the climate crisis. At a time when Australia burns in the bushfire crisis and climate deniers remain in positions of power across the globe, this lack of action is unforgivable. The social licence of the fossil fuel industry has already been significantly damaged. We’ll now use this moment as a springboard to continue campaigning until the whole university sector has divested and the fossil fuel industry can no longer operate. The need to keep up the pressure on these companies couldn’t be clearer. Indigenous and frontline communities are still fighting for their rights in response to the way these transnational corporations operate in their communities. The First Nations continue their decades-long resistance against tar sands expansion in Canada, while the Movement for the Survival of the Ogoni People in the Niger Delta are still fighting Shell’s business model which, we believe, causes dispossession and destruction across the region. Our solidarity with impacted communities is crucial. The support for fossil fuel imperialism by the UK government underlines our imperative to act here too. In Argentina, bilateral trade agreements with the UK support the business ventures of companies like BP. Here, BP operates through its part-ownership of Pan American Energy (PAE) and is involved with the exploitation of Vaca Muerta, one of the world’s largest shale oil and gas reserves. Multinational oil companies are acting in violation of the rights of the Mapuche indigenous people, who have not given consent for the extraction that destroys their ancestral home to take place. The government remains an active participant in the exploitative business models of oil companies overseas. This is particularly concerning at a time when new fossil fuel infrastructure needed to stop being built by 2017 to remain within the 1.5 degree parameter the Paris Agreement identified as a limit. As students and universities we can keep the pressure on by ensuring civil society is fully divested from the fossil fuel industry. Universities are meant for the public good and so must lead the way in displaying how the UK takes responsibility for our actions in the world. They should be at the forefront of making the links between the struggles for climate justice and other social justice issues. The universities that have divested should use that commitment as a platform to intervene in the fight against land dispossession by fossil fuel companies and struggles against racist, forced deportations. At their roots are a system built on exploitation, dispossession, empire, imperialism and colonialism. The fossil fuel industry and its partners in corporate crime will continue to increase their resistance to all those fighting it. In light of that, so must we. Zamzam Ibrahim is the president of the National Union of Students"
"As fires rage across Australia, floods wash away villages and temperatures break records, scientists are wheeled out and asked by journalists is this climate change? The answer is always fudged, along the lines of “individual events cannot be put down to climate change, this is just an extreme of weather, only further research can tell if there is a connection.” This proper and natural scientific caution has been reinforced by decades of attacks by the fossil fuel lobby, plus threats to remove grants and university tenure. The same cautious approach has also infected science journalists who repeat the same formula.  But this mantra “It’s weather not climate” can now be discarded because Swiss scientists have shown that windstorms, floods, droughts and heat waves – events as short as a single day – can be placed firmly at the door of global heating. The weather will go on varying wildly from day to day but the Swiss have been able to prove that these swings are made worse by extra temperature and moisture in the atmosphere. In other words every extreme has been made greater by man-made climate change. Let us hope that every climate scientist and journalist reads the Swiss paper and when asked the question “Is this global heating?” now just says “yes.” "
"This is an article from Curious Kids, a series for children of all ages. The Conversation is asking young people to send in questions they’d like an expert to answer. All questions are welcome. Skip to the bottom to see how to enter.  How do the clouds stay up in the sky? – Samson, age four, London, UK. Thanks for the question, Samson. Believe it or not, I once weighed a cloud and not many people can say they have done that! My scientist friends and I flew up into the sky in a giant airship, and went all the way through a fluffy, white cloud. Actually, it was very wet up there, because clouds are made up of billions of tiny water droplets.  As we flew through the cloud, we used lasers and other special scientific devices to measure how big the cloud was, and count how many tiny droplets of water were in it. Then, we did some maths and found that this cloud – which was actually pretty small, for a cloud – weighed four tonnes. That’s the same as two elephants! So, you’re right to wonder how such a heavy thing can stay up in the sky.  There are three pieces to this puzzle, and the first one is gravity. Like everything on this planet, the tiny droplets that make up a cloud are drawn towards the Earth by gravity. But these droplets are so small that it’s hard for them to push past all the air beneath them. This means that they don’t fall very fast at all – in fact, only about one centimetre per second. And any wind blowing upwards can carry the droplets back up.  To fit the second piece of the puzzle, we’ll need to learn some proper chemistry; not too much, though, just enough for our story. Let me introduce the periodic table: a map of all the elements that we humans know about. Elements are the building blocks of all things – just like the smallest pieces of Lego, which you use to build bigger and more complex objects.  The periodic table is organised so that the lightest element of each row is always on the left. Hydrogen is the lightest of all elements, so you’ll find it at the top left. As you move along each row from left to right, the elements get heavier and heavier.  Click here for a larger, interactive version. Dry air is mostly made up of two gases, nitrogen and oxygen, plus a little bit of argon and tiny amounts of other gases. For now, we can just focus on nitrogen and oxygen. As you can see on the periodic table, the weight of a single nitrogen atom is 14, while oxygen weighs almost 16.  But neither nitrogen nor oxygen atoms like to be alone, so they almost always go in pairs – two atoms in a molecule, like two peas in a pod. Because of this, a nitrogen molecule usually weighs 28, and an oxygen molecule weighs 32.  As soon as we add water (H₂O) to the air, things get interesting. A water molecule is made up of two hydrogen atoms and one oxygen atom. Remember how hydrogen is the lightest element? Well, a single water molecule weighs just 18. So it’s actually lighter than a molecule of nitrogen or oxygen. That’s why moist air is lighter than dry air.  The next piece of the puzzle is temperature. As a rule, warm air rises up, while cold air sinks down. When water in the air is warmer, it’s more likely to be a gas. When it’s cooler, it prefers to take a liquid form, such as cloud droplets, rain, hail or snow.  As warm, moist air rises, it gets cooler and cooler. And as it cools, more tiny water droplets form. You might expect the water droplets just to fall down as rain, but instead, something fun happens. You know how sweat cools our skin when it dries and changes from liquid into gas? Well, when gas turns into liquid, the exact opposite happens: it actually gives off heat.  This means that the cloud droplets are now surrounded by a tiny blanket of warm air. And what does warm air do? It rises! Not very far, though, because the air will cool again as it goes up. Now our puzzle is complete: clouds are made up of tiny droplets of water, which are hardly affected by gravity, embedded in moist air, which is lighter than dry air. And they’re surrounded by tiny warm blankets of air, which lift them up towards the sky. That’s how clouds weighing billions of tonnes can stay afloat up in the sky.  


      Read more:
      Curious Kids: Why do you have to wear a helmet in space?


 Hello, curious kids! Have you got a question you’d like an expert to answer? Ask an adult to send your question to us. You can: * Email your question to curiouskids@theconversation.com 

* Tell us on Twitter by tagging @ConversationUK with the hashtag #curiouskids, or

* Message us on Facebook. Please tell us your name, age and which town or city you live in. You can send an audio recording of your question too, if you want. Send as many questions as you like! We won’t be able to answer every question, but we will do our best. This article has been updated to reflect the effects of air resistance and gravity on cloud droplets more accurately."
"Vanguard, the world’s second largest asset manager, has refused to sign up to a group of major investors demanding that polluters respond to the climate crisis, despite its rival BlackRock relenting to pressure to do so. The US investment manager’s decision leaves it increasingly isolated after BlackRock last week joined Climate Action 100+ (CA100+), a group of asset managers that pushes the largest fossil fuel producers to show how they will meet carbon dioxide reduction targets.  CA100+ counts among its members asset managers controlling more than $40tn, giving it clout to push large oil companies and other fossil fuel extractors to address climate issues. Last year, it forced British oil multinational BP to describe how its strategy aligned with goals laid out at the 2015 Paris climate summit. Vanguard on Monday revealed that its assets under management surpassed $6tn during 2019, after a net gain of $230bn in new investments, much of it in passive investments that track stock market indices, giving it large stakes in many fossil fuel companies. It has also gained regulatory approval to launch a new UK investment advice service, adding to the funds service that it started offering in the UK in 2017. Vanguard chief executive Tim Buckley has repeatedly insisted that it will focus on engaging with companies rather than voting for action. “We have to make sure we’re talking to companies on how they are dealing with and addressing these issues, but not crossing the line and telling them what to do,” he said in an interview with the Financial Times published on Sunday. Jeanne Martin, campaign manager at ShareAction, highlighted the voting records of both BlackRock and Vanguard. Both investors opposed more than 80% of climate-related shareholder motions at fossil fuel companies between 2015 and 2019, according to Guardian analysis of data provided by Proxy Insight – far higher than many counterparts. Martin said: “Following BlackRock’s move to join CA100+, the spotlight is now firmly on Vanguard. The fact they aren’t already a member is telling of their approach to climate engagement.”  A Vanguard spokeswoman said the company had no plans to join Climate Action 100+. Another spokeswoman later said the company continued “to evaluate how our alignment with this organisation could benefit Vanguard’s investors”. The second spokeswoman said that Vanguard was taking action to address climate change, including taking part in emissions disclosure initiatives. The spokeswoman said: “While voting at shareholder meetings is important, it is only one part of the larger corporate governance process. Vanguard is pursuing an active engagement strategy that focuses on boards’ climate governance and oversight of climate risk or climate strategies, and on comparable and investor-relevant disclosures.”"
"Every August, London Zoo weighs and measures every one of its 19,000 animals. It’s a great PR move for the zoo, guaranteeing lots of friendly coverage of photogenic animals on scales or next to tape measures, at a time when many politicians and journalists have clocked off for the summer. But, as a wildlife conservation researcher and a former zookeeper, I have seen exactly how these sorts of annual “weigh-ins” also helped the animals themselves. Recording the weights and size of animals in a zoo directly benefits their welfare, and could potentially help in the global conservation of their wild counterparts. Monitoring the health of the animals in your charge is a large part of what being a keeper is all about. You do this by getting to know the individuals and noting any changes in their behaviour each day as you would your own pet. You even assess their droppings, looking at colour and solidity – which made for interesting conversation on morning coffee breaks.  Although these observations are useful, they can be a bit subjective. By taking measurements such as weight you immediately have something a bit more concrete that can be used to evaluate well-being and review the effectiveness of husbandry methods. Also, giving the correct dosage of food supplements or medicines often requires you to know the weight of an animal. Small creatures like snakes or lizards can be put into a pillow case and weighed using hanging scales. A trained handler can even hold venomous snake species such as a black mamba against a tape measure.  However larger mammals are a bit trickier. Whether it is a lemur or rhino, it often involves time, effort and patience to train one to walk onto a set of scales. Usually there is some form of food reward to help entice them onto the scales in the first place and then to keep them stationary long enough for a reading. For the most dangerous mammals of all, like the African leopards I worked with, zookeepers have to either target train them with food (using a stick with meat on the end) or wait until there is a reason to sedate them then weigh them. If you think this sounds difficult, it is nothing compared to the challenges faced out in the wild. There, this kind of information is usually only gathered when the species is specifically being studied and only then typically when the animal is under sedation for research purposes (for instance to fit a GPS tracking collar).  Often the species that are being studied have been officially assessed as threatened with extinction, based on population numbers and trends, types of threat and conservation effort. Although populations need to be monitored directly over time to check for increases or decreases, they can also be modelled based on basic information such as weight, life expectancy and breeding rates to give an idea of what the population is likely to do under different circumstances. In the region of 25% of known animalshave been classified, however for all taxa (mammals, reptiles, birds and so on) there are species that have not been classified due to insufficient data. Many of these fall into the less “charismatic” categories such as amphibians, crustaceans or fish. For example it is thought 23% of assessed amphibians have not been classified while up to half of amphibian species are potentially threatened with extinction. There are even gaps in our knowledge of mammals, 14% of which have not been classified.  How can scientists fill in those gaps? I attended a conference recently where a speaker was discussing the potential for utilising the data gathered by zoos to produce models for the species with missing data and assess how vulnerable they might be to climate change, habitat loss and other threats.  And zoos have a lot of data: of all the thousands of threatened land vertebrate species – everything from tigers or lemurs to colourful snakes or tiny frogs – around one in seven have some individuals held in captivity somewhere. Zoos really can fill an important role and have an impact. This knowledge in turn could then be used to highlight where conservation efforts and often limited funding should be focused, to increase the survival chances of more threatened species out in the wild."
"This is an article from Curious Kids, a series for children of all ages. The Conversation is asking young people to send in questions they’d like an expert to answer. All questions are welcome: find details on how to enter at the bottom.  We live in Deal, Kent and can see the coast of France from here. The waves lap towards us onto the shore on our side of the Channel, but they also lap towards the people on the opposite shore in Calais. Is there a place in the middle where the waves change direction? – Sebastian, age 12, Kent, UK Well done for noticing this, Sebastian. This is very true, the waves lap towards England on one shore, and also lap towards France across the Channel. This happens for a few reasons. First, waves are created by the wind. When the wind blows across the surface of the water, it pushes the tiny particles of water on top of the ocean away from it. Over time, the energy from the wind moving along these particles causes waves to form. The blowing wind keeps pushing the energy along the water, driving the waves away from the place where they began.  The same thing happens when you blow really hard across a basin full of water: the waves you have created travel away from the source (your breath) – not just forwards, but in all directions. Now, if the planet had no land and we lived in a waterworld, the waves would carry on travelling around the globe without anything to stop them. But in reality, we have land such as England and France getting in the way of the waves.  So, as the wind blows through the English Channel – in whichever direction – it pushes the waves away from it, towards both England and France. There’s another force which causes the waves to lap against both shores. The ground at the bottom of the sea – also known as the “sea bed” – rises from the middle of the channel, like a valley, all the way up to give us the lovely beaches we have on both the coasts.  As the waves get closer to the land, the sea bed also rises towards the shore, causing the waves to slow down. And when they slow down, they get closer together. Think of it like this: when the traffic slows down on the motorway, the distance between the cars gets smaller and smaller as drivers all press on the brakes. In exactly the same way, the distance between one wave and the next – what scientists call the “wavelength” – gets squashed as the waves slow down.  But even when the waves slow down, they still contain all that energy they got from the wind. So, as the wavelength becomes shorter, and the waves have to go slower, they put that energy into growing taller instead.  You will be able to see this when you look out to sea: the waves coming towards the shore get taller and taller, until they’re so tall and close together that they start “breaking”. White foam forms on the top of each wave, and splash! They crash on the shore, transferring all the energy they’ve been carrying onto the land.  This breaking happens at the coastline, both here in England and also in France. If the wind is strong enough, the westward moving waves produced in the English Channel may one day even make it all the way to America. Waves break along every coastline in the world.  Hello, curious kids! Have you got a question you’d like an expert to answer? Ask an adult to send your question to us. You can: * Email your question to curiouskids@theconversation.com 

* Tell us on Twitter by tagging @ConversationUK with the hashtag #curiouskids, or

* Message us on Facebook. Please tell us your name, age and which town or city you live in. You can send an audio recording of your question too, if you want. Send as many questions as you like! We won’t be able to answer every question, but we will do our best. More Curious Kids articles, written by academic experts: What is fire? – Lyra, age seven, Oxford, UK
*_  How do SIM cards make a phone work? – Leo, age five, Sydney, Australia What’s it like to be a fighter pilot? – Torben, age eight, Sussex, UK"
"The whale shark is the largest fish in the world, but much of its lifecycle remains shrouded in mystery. These gentle giants gather in just a handful of places around the globe – something which has long baffled scientists – but our new research has started to explain why. Better understanding of whale shark movements could help prevent further population loss in a species that has already experienced a 63% population decline over the past 75 years. When swimming solo, the whale shark, which can grow up to 18.8 metres in length and 34 tons in weight, travels all over the world. Recently, a group of scientists tracked the remarkable journey of one whale shark across the Pacific from Panama to the Philippines. At more than 12,000 miles it proved to be one of the longest migrations ever recorded. Yet whale sharks are known to come together at just a few specific locations around the world. Anything from ten to 500 whale sharks may gather at any one time in areas off the coasts of Australia, Belize, the Maldives, Mexico and more. Approximately 20 hotspots have been identified – mere pinpricks in the vastness of the world’s oceans – but we don’t know what exactly attracts the whale sharks to them. In some cases the sites are linked to a specific biological phenomenon – such as the spawning of land crabs at Christmas Island in the Indian Ocean, which provides whale sharks with the seasonal equivalent of a Christmas feast. Our new research aimed to discover whether there was something else that united the places where these giants of the ocean hang out. The physical features of these spots – known as their bathymetry – have been shown to influence gathering points in other marine species. So in collaboration with the Maldives Whale Shark Research Programme, we decided to investigate whether it drives whale shark gatherings in the same way. Our new global study shows that whale sharks congregate in specific areas of shallow water, next to steep slopes that quickly give way to areas much deeper water (usually between 200 metres and 1,000 metres). We identified three main reasons. First, the deep water is used by whale sharks for feeding. Studies have shown the sharks diving to depths of almost 2 kilometres (1,928 metres to be precise) to feed on zooplankton and squid. Second, the steep slopes are known to bring nutrients up to the surface from the deep, which in turn increases the abundance of plankton and attracts large numbers of filter feeding species. And finally, in shallow water, as well as feeding on coral and fish spawn, the sharks are able to thermoregulate, warming themselves back up after their dives into deep water which gets as cold as 4℃. If you’ve ever seen or swum with a whale shark, it was most likely in one of these relatively shallow aggregation areas. Knowing where these hotspots are has provided local communities with a windfall from ecotourism. In the Maldives alone, economic benefits from whale shark-related activities were estimated at US$9.4m per year. Whale sharks are worth a lot more alive than dead – and with many of these meeting points in developing countries, the income is invaluable.  But with the increasing pressures of tourism comes new dangers for the sharks. Crowds of snorkelers and tourist vessels are increasingly disturbing the whale shark’s waters, and – more worryingly – risk potentially fatal strikes by boats. To protect these beautiful creatures and continue to reap the rewards of ecotourism, we recommend that marine protected areas should be set up around whale shark gatherings and codes of practice be followed when interacting with them. These discoveries have narrowed down some of the key reasons why whale sharks congregate where they do, but many mysteries remain. Do individuals travel between these hotspots? Coastal gatherings are predominately made up of immature male sharks, usually still just four or five metres long. So where are all the girls? And where do whale sharks mate and give birth? Mating and pupping have never been seen in the wild – but, intriguingly, up to 90% of the whale sharks passing through the Galapagos marine reserve are female and thought to be pregnant. Could this be a key labour ward for the world’s whale sharks? Last year a BBC film crew at the Galapagos attempted to follow a pregnant female in a submersible to watch it give birth, but to no avail. That’s one secret that the depths are keeping for now."
"This is an article from Curious Kids, a series for children of all ages. The Conversation is asking young people to send in questions they’d like an expert to answer. All questions are welcome: find details on how to enter at the bottom.  What is fire? – Lyra, age seven, Oxford, UK Thanks for the question, Lyra. Basically, fire is light and heat that comes from a special kind of chemical reaction, which humans figured out how to make hundreds of thousands of years ago.  To understand how that reaction works, there are a few things that we need to learn about the world around us. Everything that you see and touch is made up of tiny things called atoms. You can think of atoms as really, really small bits of Lego – so small you can’t even see them.  Atoms join together to form molecules, and molecules join together to form the objects we can see and feel in everyday life. For example, wood is mainly made of a type of molecule called cellulose  and each molecule of cellulose is made of atoms called carbon, oxygen and hydrogen. Now, to see how the chemical reaction works, let’s imagine that you’re living in a cave 400,000 years ago, and that you’re one of the very first people to use fire.  You’re hungry and you want to cook an animal that you caught earlier in the day. On your way back to the cave, you collected some twigs and sticks for your fire. But there’s two other things you need before you can light the fire. You need oxygen – but luckily there’s plenty of that in the air (though you wouldn’t have known about it at the time). And you’ll need some heat to start things burning. Of course, matches haven’t been invented yet, so instead you quickly rub two sticks together. The rubbing causes friction, which heats up the sticks – like when you rub your hands together fast to warm them up. This heat causes all the molecules in the wood to jiggle around.  When a part of a stick gets hot enough, the molecules are moving about so much they start to break apart. This is when you start to see smoke. The smoke is all those broken up molecules escaping from the wood as gases. But you haven’t made fire yet – you need things to get even hotter! So you keep rubbing the sticks together really hard. Eventually, the gas molecules from the wood get so hot they bash into oxygen in the air and join together. When they do that, they make new molecules called water and carbon dioxide. At the same time, they also make heat and light. Well done, you’ve made a flame! You can stop rubbing the sticks together now.  As you put more twigs on your small fire, the heat carries on breaking down the molecules in the wood, and making more gases. These gases catch fire as well. But something else needs to happen before your fire can really grow. When the gases leave the wood you get left with charcoal. Then, as your fire gets even hotter, the charcoal also starts to combine with more oxygen, making even more heat and light. Now things are hot enough to start cooking. You make your meal, and after a while you run out of fuel for your fire. All the wood and charcoal burns away leaving ash. This is the stuff in the wood that doesn’t burn. Without the light and heat from the fire, there’s nothing to do but go to sleep – but at least you’re not hungry anymore.  Hello, curious kids! Have you got a question you’d like an expert to answer? Ask an adult to send your question to us. You can: * Email your question to curiouskids@theconversation.com 

* Tell us on Twitter by tagging @ConversationUK with the hashtag #curiouskids, or

* Message us on Facebook. Please tell us your name, age and which town or city you live in. You can send an audio recording of your question too, if you want. Send as many questions as you like! We won’t be able to answer every question, but we will do our best. More Curious Kids articles, written by academic experts: How do SIM cards make a phone work? – Leo, age 5, Sydney What’s it like to be a fighter pilot? – Torben, age eight, Sussex, UK If an insect is flying in a car while it is moving, does the insect have to move at the same speed? – Sarah, age 12, Strathfield, Australia"
"The climate is changing – and so are our seas. Warming sea temperatures have resulted in British cod moving north, benefiting Iceland. The English Channel has warmed during the last half century and the grey Atlantic triggerfish is now a year-round, rather than just a summer, resident in the waters off Cornwall and Dorset. Along the south coast of England there has also been an eastward shift in the distribution of “warm” Atlantic barnacles, which are now displacing the “cold” North Sea species. But bigger fish, including sharks, are changing their range, too. An excellent recent paper revealed how temperature changes the occurrence and activity of roaming apex predators. It said that the redistribution of species is one of the most pervasive impacts of anthropogenic climate warming.  This detailed study of Australian tiger sharks suggested that an increase in water temperature of 1-2°C will lead to them being seen off New South Wales all year round (at the moment, they tend only to visit the region in summer). And as this species is responsible for a large proportion of the shark bites on humans this raises the issue of whether control measures, such as shark nets, should be deployed to protect Australian bathers. Some sharks will follow the warmer water and their prey into UK waters, too. I have examined the known ranges of sharks and if water temperatures rise the following large species found off the coasts of Spain and Portugal may join the 40 species that are already in UK waters: great hammerhead, blacktip shark, sand tiger, bigeye thresher, longfin mako, bronze whaler, oceanic whitetip shark, silky shark, dusky shark, and goblin shark.  Indeed, one of these species has already visited British waters. The first bigeye thresher was caught off the UK near Newlyn, Cornwall in 1995. But while the potential number of shark species around the UK may increase in the next few decades, the overall number of sharks (especially the larger ones) will fall thanks to global overfishing. In fact, one report estimated that 100m sharks are killed each year, many for shark fin soup. Most of the larger sharks are recorded on the IUCN Red List – which monitors endangered species – as “vulnerable” to or “near threatened” with extinction. Basically, we are killing sharks faster than they can reproduce. A typical female shark reaches maturity at ten-years-old and will produce less than ten young. Contrast this with a cod, which can reach maturity at a year old and produce over a million eggs each year. As well as overfishing, sharks are also vulnerable to pollution. Most people are aware of the problems of waste plastics in the ocean. As the plastics break down into smaller and smaller particles, their ability to absorb pollutants increases and their incorporation into the ocean food chain becomes more likely. Sharks as top predators will take on the pollutants from everything that they have eaten, putting their health in peril. Of course, if more large shark species are likely to come to British waters, many will wonder whether great whites will be among them. There is considerable debate over whether they have already visited – and I see no reason why not. They can live in large numbers in colder waters than the UK off South Africa and there’s a plentiful supply of one of their favourite foods – seals – along the Cornish coast, as well as around Scotland and other parts of the country. The only argument against there being great whites in British waters is that their numbers worldwide are declining (they are now protected in several countries) so the chances of seeing one in this region fall every year. In March 2015, the conservation research organisation OCEARCH tagged a 14ft (4.4 metre) great white shark off Jacksonville, Florida and nicknamed her Lydia. She swam over 30,000km, including meanderings along the east coast of the US – before striking out for Europe. A year later, when she crossed the mid-Atlantic Ridge and came within a few hundred miles of Ireland, the media became very excited. The Mirror announced Great White shark ‘just days away from Cornwall’ after scientists track it swimming across Atlantic. Sadly, satellite contact was lost soon after that so we don’t know whether she made it. But this, and my recent suggestion that there may soon be more shark species around the UK, attracted a flurry of media attention – much of it overblown. While I was careful not to predict an influx of great white sharks, the type of headline used by The Daily Mail was almost inevitable: Eleven terrifying shark species, including great whites and hammerheads, are ditching warmer waters and heading to British shores. Thankfully, a more measured response was made subsequently by The Guardian: “Warmer seas will not lure great white sharks to UK, experts say.” There seems to be an almost inevitable need to use the cliche “killer sharks” in press stories about sharks. But the number of human fatalities resulting from shark attacks is tiny compared to other causes – even vending machines are deadlier.  Britain’s largest shark is the basking shark, which can grow up to eight metres in length but eats nothing bigger than plankton. Nevertheless, it is a summer, silly season necessity to print a photo of a basking shark fin and claim it’s a “killer” great white. Perhaps the best overview of the popular press view of sharks is expressed by Private Eye. While we continue to demonise sharks as mindless killers their wholesale slaughter goes unchallenged, until one day soon they will become extinct and shark natural history films will be reclassified as just history. So when we hear that more new species may start visiting the UK, it should trigger efforts to protect them, not just another wave of hysteria."
"
Share this...FacebookTwitterDespite the warm year seen in Central Europe so far this year, and all the claims that it’s due to climate warming, the globe in fact has shown it’s been cooling off, or at least not warming at all.
Hat-tip: Schneefan
UAH satellite measurements of temperature at 1500 m altitude in October 2018 came in at an anomaly of + 0.22°C with respect to the WMO climate mean from 1981-2010. That’s four tenths of a degree less than October, 2017.
So far 2018 is the third year in a row that the globe has cooled off from it’s El Nino peak set in 2015. Especially large parts of North America have seen a cold October, as an NCEP/NCAR reanalysis shows:
Arctic stable over past decade
And despite earlier predictions of an ice-free late summer Arctic made by alarmist climate scientists years ago, Arctic sea ice has in fact stabilized over the past 10 years. This year the  Northwest passage was closed the entire year.
Arctic sea ice extent has exploded since early November, gaining over 200,000 km² daily on average, as depicted by the following Alfred Wegener Institute (AWI) chart:

Hudson Bay freeze-up earlier than average for 2nd year
The surprising ice burst contradicts claims that polar bears have been in trouble. Polar bear biologist and expert Dr. Susan Crockford reports here:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This is the second year in a row that freeze-up of Western Hudson Bay ice has come earlier than average” and that “it’s unlikely that a strong wind will again blow the newly-formed ice offshore (as happened earlier this year) because the ice is more extensive.”
According to Dr. Crockford: “Ice has been developing rapidly over the last couple of days.”
The Canadian Ice Service chart for 10 November shows the ice very clearly:

Winter hitting northern hemisphere earlier
In October, snow cover over North America stood at 9.7 million square kilometers, which is some 1.7 million square kilometers over the mean of the past 50 years.

Source: Rutgers University Global Snow Lab
The October snow cover trend is also the same story for the entire northern Hemisphere, hat-tip: Kirye:

Source: Rutgers University Global Snow Lab
Share this...FacebookTwitter "
"Three decades from now, several crucial elements of the Antarctic Treaty will come up for possible renewal, plunging the future of the continent into uncertainty. For six decades, the treaty has been the cornerstone of governance for our most southerly, harshest and most pristine continent. It has fostered scientific research, promoted international cooperation, ensured non-militarisation, suspended territorial claims and strengthened environmental protections. Its guardians are the Antarctic Treaty Consultative Parties (ATCPs) – chief among them the US, UK, Australia, New Zealand, Russia, Norway, Germany, Chile and Argentina. Out in the field, a new generation of robots and drones are peering under ice shelves, probing the ocean depths and monitoring glaciers, ushering in the age of the “Smart Antarctic”. The ice sheets aren’t exactly flourishing – the Antarctic continent has lost three trillion tonnes of the stuff since 1992 – but scientific research is thriving. For many polar researcher this is a reason for optimism – but in the political arena, the horizon is darkening. As it stands, the Antarctic Treaty acts as a safeguard for Antarctic science: an international bulwark against commercial or political interference. But as the years tick by, the treaty – and the cooperation that accompanies it – could begin to quietly fracture or even disintegrate completely. In 1998, seven years after it was first signed into the treaty, the Protocol on Environmental Protection came into effect. Its purpose was to “enhance protection of the Antarctic environment and dependent and associated ecosytems” – a noble if poorly defined pledge that has proven difficult to uphold. But, tucked away among the acronyms and technical terminology, Article Seven of the Protocol consisted of a single important sentence, easily missed by the careless reader: “any activity relating to mineral resources, other than scientific research, shall be prohibited”. Simple and to the point. Antarctica’s natural resources, whatever they may be, are to remain pristine and untouched. At least for now.  Article 25 carries a caveat: “If, after the expiration of 50 years”, it reads “any of the Antarctic Treaty Consultative Parties so requests, a conference shall be held as soon as practicable to review the operation of this Protocol”. In other words, 30 years from now in 2048, the ATCPs could reject anti-mining regulation and start stripping Antarctica of its mineral resources, diverting the continent towards a radically different future. Many consider this undesirable, unworkable and unthinkable, but long-time observers know that the uncharted waters of polar politics can constantly surprise. In fact, the “unthinkable” has already been thought – and half-acted upon. In the 1980s, the ATCPs drew up an international mining framework called the Convention on the Regulation of Antarctic Resource Activities, which sought to regulate any possible future resource extraction. It established property rights and gave special privileges to seven claimant states – including the UK. The framework would not function today – China and India would certainly demand far-reaching revisions – but in the 1980s it was only when France and Australia pulled out and started championing the current protocols that the convention was shelved. Indeed, a number of states might now have issues with the treaty. Much of the governance set down by the Antarctic Treaty still dates from when it was first negotiated in the late 1950s, in a very different political, technological, legal and environmental climate. It only involved 12 states and was concluded long before China became a polar superpower. The Antarctic ice sheets were considered stable – and there was still a great deal of mystery surrounding what lay beneath them. There was little to no tourism – now it’s the biggest industry operating in Antarctica.  Fast forward to 2048: the Antarctic is melting, plastics are found in the ice, and foreign species (including yet more humans) dot the continent. Drones and other automated vehicles are routinely used and the polar summer is a hive of activity, with thousands of tourists mobbing every penguin colony. Commercial fishing thrives in the Southern Ocean and permanent settlements spring up on the Antarctic peninsula and surrounding islands. The profits available from biological harvesting have made the extremes of Antarctic living a reality. Indeed, major polar operators such as China and the US only continue to support the mining ban because their energy needs can be satisfied elsewhere. At present ACTPs are focusing on improving cold weather technology and gaining confidence in Antarctic conditions, but it might not be long until they have the capability and incentive to do more. China is already using underwater vehicles to search for gas hydrates and metallic nodules in the South China Sea. Ominously, underwater mining and deep-sea energy prospecting seem set to be growth industries over the coming decades. So what could change between now and 2048? Possibly little: the ATCPs might decide to keep the Protocol and continue to prohibit mining. Or they might not.  The recent announcement of a marine protected area in the Ross Sea was a good sign for conservationists, but it required a great deal of tough negotiation. This “general protection zone” forbids fishing completely, and joins an existing “special research zone”, which permits limited fishing of for toothfish and krill. These will come up for review in 2047 and 2052, adding another dimension to what could become a period of unparalled change for polar governance. If the ATCPs decide to question the provisions of the Protocol, automated mining could begin soon after. Those in favour might argue that the Antarctic environment is continuing to degrade in a way that no amount of regional management can halt. Or they might put forward the view that the need for new sources of protein outweighs the “restrictive” conservation measures. Either way, the “special” qualities of Antarctica might not carry quite the same emotive weight in the future.   After 2048, Antarctica could be carved up between nations like every other land mass and surrounding ocean, and slowly relieved of its resources. Those who care about the future of Antarctica must keep a close eye on the continent and its surrounding seas, or risk losing them to drones, drills and desperate politicians."
"
Share this...FacebookTwitterNinety-nine percent of the Earth’s atmosphere is made up of two gases: (78%) nitrogen (N2) and (21%) oxygen (O2). Neither is considered an IR-absorbing/re-emitting greenhouse gas (GHG) like (0.041%) carbon dioxide (CO2) or (0.00018%) methane (CH4). 
Utilizing real-world Raman spectrometer data, an independent researcher from Sweden has found both N2 and O2 do indeed absorb radiation, or function as GHGs. If true, the CO2-is-a-special-heat-trapping-gas conceptualization effectively collapses.

Image Source: ResearchGate
A new paper entitled “Quantum Mechanics and Raman Spectroscopy Refute Greenhouse Theory” has recently been made available online.
Written by Blair D Macdonald, an independent researcher specializing in fractral geometry and quantum mechanics, the analysis utilizes real-world IR spectral measurements from a Raman spectrometer (laser).
Concisely, Macdonald has determined that CO2 is no more “special” a gas absorber and re-emmitter of radiation than nitrogen or oxygen, even though the latter are not considered greenhouse gases.
What follows is but a tiny snapshot of some key points from this comprehensively-sourced paper.
Note: It would be advisable that interested readers – especially those who are rightly skeptical of iconoclastic analyses like these – should read the text in some detail before commenting.  Turning the spotlight on papers that question conventional wisdom is primarily intended to elicit open-minded discussion.  It is not intended to convey we have arrived at a definitive conclusion about the authenticities of the CO2 greenhouse effect.

Macdonald, 2018
Quantum Mechanics and Raman Spectroscopy 
Refute Greenhouse Theory
Abstract:  “Greenhouse theory’s premise, nitrogen and oxygen are not greenhouse gases as they do not emit and absorb infrared radiation, presents a paradox; it contradicts both quantum mechanics and thermodynamics – where all matter above absolute 0° Kelvin radiates IR photons.  It was hypothesized these gases do radiate at quantum mechanics predicted spectra, and these spectra are observed by IR spectroscopy’s complement instrument, Raman spectroscopy; and N2 spectra can be demonstrated to absorb IR radiation by experiment, and application o the N2-CO2 laser.  It was found the gases do possess quantum predicted emission spectra at 2338 cm−¹ and 1156 cm−¹ respectively, both well within the IR range of the EMS, and are only observed – and their temperatures accurately measured – by Raman spectrometers.  Raman spectrometers measure, more accurately, the Keeling curve, and have application with meteorological Lidars and planetary atmospheric analysis.  The N2-CO2 Laser showed – contrary to current greenhouse theory – N2 absorbs electrons or (IR) photons at its – metastable ‘long-lasting’ – spectra mode.  It was argued atmospheric CO2, as a law, is heated by the same mechanism as the N2-CO2 laser: nitrogen (first) and the entire atmosphere absorbs IR radiation directly from the Sun, just as it heats water on the ocean surface.  With these findings, greenhouse theory is wrong – all gases are GHGs [greenhouse gases] – and needs review.”

 

 

Image(s) Source: Macdonald, 2018
Share this...FacebookTwitter "
"The BuzzFeed video, “Bacon lovers meet baby pigs” is amusing to watch. With 14,493,383 views, you may have seen it. It depicts several young men and women waiting blissfully to be delivered a plate of mouthwatering bacon, only to be handed instead a cute baby pig. Gasp! The participants react with high-pitched squeals of glee as they embrace a piglet, before looks of bemusement emerge in the realisation that their love for bacon and affection for the piglet [don’t mix]. One woman exclaims, “I’m never going to have bacon ever again.” A male respondent jokes, “I mean, he does look delicious, let’s be honest.”  The video is entertaining. But it also reflects a subtle truth about the relationship men and women have to meat: the two sexes often differently resolve the tension caused when thinking about the slaughter of animals. 


      Read more:
      Why don't we feel more guilty about eating animals?


 Many studies show that men tend to enjoy meat more than women, and consume it more. For example, a 2014 Faunalytics study found that females disproportionately outnumbered men among both current (74%) and former (69%) vegetarians and vegans in the US. Women are more likely than men to reject meat for reasons related to its appearance, taste, health, weight loss, environmental concerns, and animal welfare. Men, by contrast, identify a lot with meat, perhaps because of historical associations between meat and masculinity.  Women who do eat meat often use somewhat different strategies than men to avoid guilt over eating animals. The psychologist Hank Rothgerber has shown for example that men, as a group, tend to endorse human domination beliefs and pro-meat justifications for the slaughter of farmed animals. That is, they’re more likely to agree with statements like, “humans are at the top of the food chain and meant to eat animals”, or “meat tastes too good to worry about what all the critics say”. In one study based on a 1-9 scale of agreement, where nine meant “strongly agree,” men averaged almost six compared to around 4.5 for women on measures of pro-meat and hierarchical justifications. These pro-meat beliefs help neutralise any notion that eating meat is problematic.  Rothgerber found that women on the other hand are more likely to engage in less overt strategies to reduce the cognitive dissonance, such as avoiding thoughts about the suffering of animals when eating meat (on the same scale of agreement, where nine meant they strongly try to avoid such thoughts, women average around nine while men register 5.5). These indirect strategies are useful, but they are more fragile. When confronted with the reality of animal slaughter (perhaps through sympathetic movies such as Earthlings or Okja) it may be more difficult for women to avoid sympathising with the animals they find on their plates.   Women’s sympathies towards animals are on sharp display when contrasting men and women’s responses to baby animals. Baby animals, like human babies, are particularly vulnerable and dependent on the care of their parents for survival. They also display stereotypically “cute” features – large head, round face, large eyes and chubby cheeks – that we associate with human infants, what ethologist Konrad Lorenz termed Kindchenschema, or “baby schema”.  Research shows that both men and women can detect cute features in baby faces. But women, especially women high in maternal tendencies, find images of cute babies particularly emotionally rewarding.  Because of their mixed opinions about meat, and women’s emotional attunement to baby features, my colleagues Neil McLatchie, Cecilie Olesen and I wondered whether women might find meat particularly distasteful when it comes from a baby animal. Might women show greater tenderness towards a piglet than their adult counterpart, an adult pig? And might this lead women to reject meat, even when the end product looks the same for both animals? We wondered the same about men, but we did not expect them to show much movement in their appetite towards meat on account of their more positive relationship with meat. Across three studies, we presented 781 American men and women with either images of baby animals – from baby cows and kangaroos to baby pigs and lambs – or their adult counterparts. We paired the animal images with a meat dish (the precise dish varied between studies). In each study, the meat product was always the same image regardless of whether the animal was an adult or baby. Participants rated their appetite for the dish on a 0-100 scale (from Not at all to Extremely appetising) and made ratings of how cute the animal was or how tender it made them feel.  Women consistently found the meat dish less appetising when it came from a baby animal than when from an adult. Looking across the three studies, they tended to rate the meat dish on average 14 points less appetising on the 0-100 scale. This was partly explained by their greater feelings of tenderness towards the baby animal. Results for men were less conclusive. Their appetite for the dish was largely unaffected by the “babyness” of the animal (across the studies, on average, about four points less appetising when it was a baby). Interestingly, we observed these gender differences despite establishing beforehand that both men and women rated baby farm animals (chicks, piglets, calves, lambs) as highly worthy of their moral concern. Men seemed better able to separate their appraisals of baby animals from their appetite for meat.  Of course, our studies did not investigate whether men and women went on to reduce their meat consumption, as we did not follow them into their homes or kitchens. What our research does suggest is that appeals to care-taking emotions, which are so important for how we treat members of our own species, might be beneficial for getting people to rethink their relationship to meat. This seems especially true for women. Indeed, vegetarian strategists and animal advocacy groups identified this baby-tenderness effect long ago. The next time you pick up a leaflet from an animal welfare group like Viva! or PETA, pay attention to the animal images you see. More than likely most of them will be of baby animals."
nan
"Pollutants in rivers and other water bodies are a serious problem for marine life as well as human health. However, removing them from the water can be a costly process, often requiring energy from fossil fuels, which adds to both operating costs and environmental damage. Consequently, using plants to remove pollutants – a process known as phytoremediation – has become increasingly attractive around the world.  Not only is phytoremediation more environmentally friendly than conventional methods, it is cheaper too. It involves using photosynthesising organisms to remove pollutants – for example, heavy metals like lead – from water. It is thought that the mechanism of removal involves a combination of adsorption (whereby pollutants stick to the surface of roots) and absorption (whereby they’re taken up by the plants’ transport system) of metals via the plant roots.  Our research team has recently been investigating how phytoremediation could help clean up rivers in Britain. Though phytoremediation has been used in the country previously, this time we have been specifically using water hyacinth. This tropical plant is not native to the UK, and is actually classed as an invasive species. It has been used for phytoremediation before, but we were the first to use it in a temperate Northern hemisphere river, far removed from its native habitat, originally in South America. What we found was remarkable. The water hyacinth was able to remove highly toxic elements from river water. We introduced the plant to the Nant-Y-Fendrod stream, a tributary of the River Tawe, in Swansea. This waterway is located in an area which was the heart of global copper production during the 19th and 20th centuries. As a consequence, it has been heavily polluted by millions of tonnes of copper and zinc smelting waste. Despite previous efforts to remediate the land using conventional approaches, such as the removal of contaminated soil, considerable contamination of heavy metals remains, affecting the stream’s water quality. In fact, pollution is so bad that it fails to meet EU water quality standards. 


      Read more:
      Four simple ways you can reduce pollution in your local river


 We constructed two purpose-built treatment pods to contain the plants in the river, preventing them from escaping but allowing the water to move in and out of them. We used 25 plants in each pod, covering around one square metre. This equated to approximately 10% of the width of the channel. The content of heavy metals in the river water was determined – using inductively coupled plasma mass spectrometry – prior to plant introduction, within the treatment pods, and downstream on an hourly basis for a period of seven hours. We found that the water hyacinth was able to remove many different heavy metals – including cadmium, zinc, arsenic, lead, chromium, aluminium, copper, manganese and nickel – from the stream’s water. The speed of this metal removal was fast. Our tests demonstrated more than 60% of the aluminium and zinc polluting the water which went into the the pods was removed within just seven hours. Such a high speed of removal is consistent with the reputation of water hyacinth as the fastest growing aquatic plant in the world.  To date, most research work on the water hyacinth plant has originated from developing countries. But given the effects of climate change on the distribution of all kinds of species, researchers from developed countries urgently need to play a greater role in exploring its control, management and effective utilisation.  One particular area of research that still needs to be explored is dealing with the water hyacinth after it has adsorbed/absorbed pollutants. There are several possible solutions, such as recovery of the metals it has adsorped/absorbed for industrial use, and using the plant biomass for bioenergy production or fertilisers. Another option is to find a way to live with what is the world’s most prolific aquatic plant, instead of eradicating it – which has so far been unsuccessful.    The plant has a prolific growth rate and, as climate change affects the range of all kinds of species, it will likely spread into new regions. This means that it may no longer be a problem solely linked with poorer countries in Africa, Asia and South America, where it clogs up rivers, lakes and canals causing huge economic burdens.  Though there are disadvantages to phytoremediation – including that it takes time for the plant to trap the pollutant, and that it must carefully be managed to stop it blocking waterways entirely – our research has shown how nature can help heal the damage caused by industry."
"The mahseers are an iconic group of fish found throughout the fast-flowing rivers of South and South-East Asia. Characterised by their large scales, attractive appearance and potentially vast size, the mahseers have long been afforded saintly status as “God’s fishes”. They are also known to anglers as some of the world’s hardest fighting freshwater game fish, earning them the reputation of “tigers of the water”. But despite lots of interest in mahseers, their future is under serious threat as their rivers become polluted and blocked by hydropower dams in order to support a rapidly growing human population. Those fish that do survive are vulnerable to illegal “dynamite fishing” in which a blast kills or injures all aquatic life, allowing poachers to harvest anything that floats to the surface.  Of the 18 currently valid species of mahseer, the official IUCN Red List of Threatened Species currently lists four as endangered, one as vulnerable, and one as near threatened. The rest either lack enough data to reach a conclusion or haven’t been evaluated. Recent research published by colleagues and I in PLOS ONE focused on the hump-backed mahseer, the largest and most endangered of all mahseers. The fish was once common throughout the Cauvery river and its various tributaries in southern India, but it is now limited to just a handful of small isolated populations. Weighing as much as a small adult human (55kg), this freshwater giant qualifies as megafauna, yet bizarrely it has remained a taxonomic enigma without a valid scientific name. Until now. Colleagues and I discovered that the hump-backed mahseer is actually the same species as Tor remadevii: a mahseer that previously lacked a common name. Scientists first described Tor remadevii as a new species in 2007, based on a small sample of juvenile fish from the most southerly tributary of the Cauvery catchment in the state of Kerala. Little did they realise that the small fish they had discovered from this remote sub-catchment was the same as the monster mahseer found in the upper and middle reaches of the main river Cauvery.   The hump-backed mahseer was first brought to the attention of the world’s anglers in Henry Sullivan Thomas’s 1873 classic, The Rod in India. During British rule, several huge specimens were recorded, including the still-standing world rod-caught record, a 120lb (54kg) monster captured in 1946 by a taxidermist from Mysore known as de Wet Van Ingen. Indian independence followed soon after, and the mahseer was largely forgotten by the outside world, with many believing the fish had been dynamited to extinction. That was until 1977, when the Trans World Fishing Team – comprised of three Englishmen –travelled to India and spent several months exploring the country’s rivers before reaching the Cauvery. There they found the hump-backed mahseer very much alive, and realised their sporting dreams by recording individual catches up to 92lbs (42kg). This reignited global interest, and catch-and-release anglers from around the world flocked to the River Cauvery in search of the legendary fish. Local villagers found employment as angling guides, cooks or drivers, some of them rehabilitated poachers who realised that a live mahseer had renewable value, unlike the single value of a dead one at market. Patrols were set up to protect the species 24/7, allowing the ecology of the river to flourish.  But all was not what it seemed. Since their establishment in the 1970s, the angling camps had been collecting invaluable data which shed new light on the situation. When colleagues and I analysed these detailed catch records, we realised the hump-backed mahseer had almost disappeared. Although overall mahseer stocks were rising, the humpback itself was being rapidly replaced by a non-native and highly invasive species of mahseer, which had been deliberately introduced to the River Cauvery to boost stocks in the late 1970s. This led us to publish a paper in 2015, outlining the threat of imminent extinction facing the hump-backed mahseer. The hump-backed mahseer has been known around the world by its common name, but confusion over its scientific name has prevented its inclusion in the IUCN Red List of threatened species. Given the fish is on the edge of extinction, it proved a significant challenge finding wild specimens from which to collect the DNA and associated evidence required to support a formal taxonomic clarification. Only after three years of expeditions was our team finally successful in finding a small population of humpbacks in a remote jungle section of the River Moyar, a tributary of the Cauvery. The paper we recently published fixes the scientific name as Tor remadevii and should see the iconic species assessed as “critically endangered” in the next update of the Red List. The significance of the research published will afford this iconic fish the recognition and legislative protection it so urgently requires to develop robust conservation planning.  However, in the long term, the fish’s future rests in the hands of the three Indian states with stakes in the highly-contested Cauvery river system – Tamil Nadu, Kerala, and Karnataka. One hope is that the humpback mahseer will become a unifying force and bring these states together to protect the rich biodiversity and natural function of the Cauvery from further decay, allowing the river to continue to support the many millions of people who depend on it."
"The devastating floods in the Indian state of Kerala are a stark reminder of the vulnerability of the world’s most densely populated regions to weather and climate phenomena. In addition to the tragic loss of several hundred lives, widespread floods driven by unusually high and persistent monsoon rains have severely impacted the region’s fragile infrastructure and displaced more than a million people. Only in recent days has the Indian government been able to understand the full extent of an estimated US$3 billion worth of damage. It is now typical that the aftermath of severe weather events is marked by questions about the role played by human-induced climate change. More precisely, scientists aim to provide a timely statement about the extent to which global warming has changed the likelihood of a certain weather-related hazard. The practice of attributing an event to climate change has become a regular activity and is being tackled with a growing number of methodologies. Improvements in the computer models used to make climate predictions means that attribution information can often be made available immediately after, and sometimes even during, the event. For instance, reports declaring this summer’s heatwave across Northern Europe to be at least twice as likely as a result of climate change were circulated while many citizens continued to experience the scorching temperatures. Being able to communicate this information while the event is still firmly in the consciousness of the general public is potentially very powerful in changing the opinions of those resistant to climate action News of the worsening situation in Kerala is an opportunity to consider why understanding the effect of climate change is more difficult for some events than for others. For example, the links between global warming and temperature extremes are reasonably well understood. It should come as little surprise that a warmer world will bring more severe summer heatwaves and more frequent mild winters. When it comes to rainfall, however, things are a bit more complicated.  Unlike temperature, rainfall varies hugely in space and time. Even the most sophisticated climate models struggle to simulate physical processes such as convection and evaporation that drive rainfall activity. On top of that, global warming is not expected to change the frequency and intensity of rainfall extremes in the same way in all parts of the world. On a global scale, an increase in the most severe rainfall events is anticipated given the atmosphere’s capacity to hold around 7% more water per °C rise in temperature, as described by the Clausius–Clapeyron relation. But when we get to the regional scale, this relationship becomes somewhat distorted by the response of rainfall to meteorological phenomena such as tropical cyclones, thunderstorms and, in the case of the Kerala event, monsoons. So, how should an extreme rainfall event be defined? By the amount of rain that fell or by the weather patterns that caused it? The choice to focus solely on the rainfall itself is particularly relevant for flooding events. Though accusations of poor decision-making and mismanagement of water resources are beginning to appear in the Kerala aftermath, the floods simply would not have occurred without a significant amount of rain. Few of those suffering lost homes and livelihoods are likely to care much about where the rain came from or the intricacies of the weather conditions that led to it. But to understand as much as possible we must consider the individual responses of weather phenomena to a changing climate. Different approaches tackle the problem in different ways – and may produce conflicting results. Even in the absence of a significant trend in the highest rainfall totals, a climate change signature may still exist in the form of rising temperatures in the oceans where the moisture that fed the rainfall originated. Disentangling these contributory factors takes time. In comparison to droughts and heatwaves, short-term hazards such as floods do not usually give us much chance to report concrete findings while the media and general public are still engaged in the event. In-depth studies may not publish their results for many months, sometimes even years after the event in question. Many of these issues are not exclusive to extreme rainfall. The excellent US National Academies report on Attribution of Extreme Weather Events in the Context of Climate Change describes the shortcomings in our efforts to attribute a variety of extremes. But for rainfall in particular there is a discrepancy between what we understand about the general effect of global warming and our rather lesser ability to quantify the climate change fingerprint on specific events.  While this is a cause for concern, the opportunity for improvement should be the focus of our attempts to make attribution a more effective vehicle for communicating climate risk."
"
Share this...FacebookTwitterSchneefan (Snow Fan) at German skeptic site wobleibtdieerderwaermung.de here recently posted an overview of Arctic sea ice. This summer as well has Arctic sea ice refused to obey all the claims of melting.

Source: DMI plot sea ice cover.
Sea ice increase accelerating
The above chart shows August mean Arctic sea ice area in million square meters from 1979 to 2018 (red curve). There’s been a positive linear trend since 2007.
Moreover, the upward linear trend has even sharpened since 2012 (green lines) since Al Gore and Peter Wadhams made their absurd projections there would be an ice-free Arctic by now.
Kirye at KiryeNet here shows that current Arctic sea ice volume for mid September remains at the center of the pack, and thus no sign of short-term dwindling Arctic sea ice:

Chart: KiryeNet
The Northwest Passage this year as well was continuously blocked by ice and thus impassable for the entire year.
Yacht ignored warnings, got crushed
But some refused to believe the ice was not melting. For example German Yacht Online here reported how a crew on the yacht “Anahita” had ignored warnings of the Canadian Coast Guard and tried to cross the Passage. By late August the yacht ended up getting crushed by sea ice and sank within minutes. The 2-man crew was forced to escape on the ice by foot and were later airlifted to safety by helicopter.
According to Yacht online: “The ‘Anahita’ was one of a dozen other yachts on the way from the east to the west through the Northwest Passage. However this summer the sea ice in the Arctic remained tenacious.”
Ship of Fools II


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Also a group of publicity seeking climate activists on Russian ice breaker/expedition ship ‘Akademik Ioffe’ were forced to move their starting point about 1000 km to the south to Kugaaruk. Just hours after starting on August 24, 2018, the vessel “ran aground on an uncharted shoal” and all passengers had to be rescued.
The trip was supposed to focus the world’s attention on global warming and “disappearing” Arctic sea ice. However, the expedition ended up being an embarrassment and ironically showed the opposite: the Arctic still had quite some ways to go before becoming ice-free.

The conditions the Northwest Passage Project crew were hoping for, but never became the case. Ice breaker/expedition ship Akademik Ioffe. Photo: The Northwest Passage Project
All passengers on the Akademik Ioffe were safely transferred to shore and returned home, the site informs.
“Uncharted geologic feature”
According to the website, the expedition was abandoned because the Akademik Ioffe needed repair after it had run aground and been refloated.
The expedition itself insisted the mission was not curtailed due to ice conditions and instead blamed “an uncharted geologic feature”. But why would a ship need to enter an uncharted area? Maybe because ice was blocking the usual route?
Today “Akademik Ioffe“ is back on the way to Les Mechins, Quebec from Kugaaruk and the expedition is postponed to summer 2019.

Chart: Marine Tracker.
Share this...FacebookTwitter "
"Whether commanding the attention of rock star Neil Young or apparently being supported by the former head of Greenpeace, genetically modified food is almost always in the news – and often in a negative light. GM divides opinion, and even individual people can find themselves pulled in two different ways. On the one hand it is a largely new technology and new tech often brings prosperity, solves problems and offers hope for the future. But this also makes it a step into the unknown and people are frightened of what they do not know, or what cannot be known.  In a study recently published in the journal Appetite, colleagues and I examined why some people reject GM technology. We were neither arguing for nor against GM, but rather we wanted to look at the characteristics which determine people’s views.  Specifically, we examined attitudes in the EU to two different types of genetic modifications made to apples. Both involve the introduction of genes to make them resistant to mildew and scab. The first is a gene that exists naturally in wild/crab apples. This is an example of what is called “cisgenesis”. In the second one the gene is from another species such as a bacterium or animal, and is an example of “transgenesis”. As an idea of the gains available from this process, the production of a new apple cultivar may take 50 years or more. Gene transfer technologies can substantially shorten this. At the same time they may introduce characteristics from totally alien species which is virtually impossible to do naturally. This may then introduce many desirable qualities into the apple – for instance, in the hypothetical case we are analysing, the apples were made more resistant to disease. We found people’s attitudes tend to be driven by their fears of risk, and their hopes of gain, with hopes being more important for cisgenesis (introduced genes from other apples) and the former for transgenesis (genes from other species).  But quite separate to risk and gain are perceptions that the technologies are “not natural”. Evidently people are disturbed when science takes us away from what they see as the laws of nature. People are also concerned about environmental impact. Our data is based on a Eurobarometer survey carried out in 2010 of 15,650 people from around the EU. In general people seem to be more hesitant about transgenesis, than cisgenesis (apple to apple gene transfer). Thus 57.1% of respondents wished to see cisgenesis encouraged compared to just 31.4% for transgenesis. Clearly people are more worried about having animal genes in their apples, compared to genes from wild apples. Attitudes are not spread randomly across the population. Rather there are systematically different views dependent on gender, level of education, home background, whether in a village or a large town and across different countries.  Men are significantly more likely to support cisgenesis, for example, as are better educated and more prosperous people. Religion is also important and Muslims, Catholics and Orthodox Christians are significantly less approving than the general population.  People are more united in their disapproval of transgenesis (adding genes from other species). But, again, more educated people tend to be more approving as do men and the more prosperous, while older people tend to be more wary. Finally, for both technologies studying science, or having a father who studied science, impacted favourably on attitudes. Some figures show the impact of religion: compared to the 31.4% who approved of transgenesis overall, just 23.3% of Orthodox Christians did so. The situation is reversed for cisgenesis with 57.1% approving overall, but Greek Orthodox Christians now more supportive with 60.9% approving. It is now Muslims who are substantially less supportive with only 40.6% approving.  This is an example of how religious diversity leads to differing opinions on new technologies. Thus if a government wishes to encourage GM technology, it might give some thought to opening up dialogue with religious leaders. The EU is one of the world’s toughest places to gain approval for GM crops, in part because of these concerns expressed by its citizens. This has resulted in the EU falling behind other countries.  The more positive attitudes of scientists and better educated people may suggest wariness of GM foods is simply driven by ignorance. Increasing knowledge and understanding would help reduce this, but there may be limits – in reality few of us are fully able to evaluate the relevant technical arguments. Hence we tend to rely on the opinions of those we trust, religious leaders in some cases, experts, scientists and governments in others. The evidence is that people are more supportive and less concerned with cisgenesis than transgenesis. This perhaps makes sense as many in the sample perceived apples crossed with genes from other apples as more “natural” than apples crossed with something else. If from the outset these had been separately labelled, then it is possible the EU would have been quicker to give the green light to cisgenesis.  On the other hand treating them all as one and the same increases the possibility that the green light will eventually be given to all GM products, cisgenesis and transgenesis alike. It is an example of the dangers of placing disparate technologies in a single basket and saying: take it or leave it."
"
Share this...FacebookTwitterThe European Institute for Climate and Energy (EIKE) here posted a video of excerpts of a German Parliamentary hearing on climate change in the German Federal Parliament featuring Potsdam Institute for Climate Impact Research (PIK) scientist Anders Levermann and atmospheric physicist Prof. Nir Shaviv of Hebrew University in Jerusalem.
The hearing was to look into the controversy of climate change, with the AfD opposition party casting doubt on the German government’s long-held alarmist position.
In total the hearing lasted some 2 hours, but EIKE has fortunately provided a condensed 16-minute version featuring the main points.

As expected Levermann of the alarmist and activist PIK claimed that the physics of global warming were “rock solid” and that a doubling of CO2 would undoubtedly lead to 3°C of warming. He tried to claim the science was settled.
No proof…dubious hockey stick
At the 1:40 mark, Shaviv responded by saying there was “no scientific proof that showed CO2 has a large impact on climate” and that the arguments used by the IPCC to claim otherwise “are faulty”.
He says we know today that the hockey stick chart was “dubious science”.
IPCC ignores the sun
Shaviv also told the members of the German Parliament that the IPCC refuses to acknowledge the sun’s powerful role on driving climate and sea level rise rate. “The sun has contributed to more than half the warming.”
At the 3:40 mark Shaviv states that CO2 climate sensitivity is in fact only 1 – 1.5°C for a doubling of CO2, far less than the figure suggested by the PIK’s Levermann.
Models are faulty
Levermann then bluntly responded (5:05) with an insult, calling Shaviv’s non-alarmist claims “nonsense”.
But Shaviv fired back (6:10), reminding that there’s much scientific literature supporting the sun is a major driver and that the IPCC climate models are faulty and lopsided.
At the 7-minute mark Levermann claims the global temperature rose 0.2°C over the past 2 decades “in just a short” time, but not mentioning the natural oceanic El Nino event being at play. He then claimed they had already refuted all the points made by skeptics.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




From 15.0°C in 1850 to 14.8 today?
An interesting moment came at the 8-minute mark when one Parliamentarian asked Levermann which pre-industrial reference temperature the IPCC was working with. Parliamentarian Dr. Kraft asked Levermann what exactly was the global temperature before industrialization some 150 years ago. According to Levermann, it was “in the area of 15°C”, thus implying today’s global temperature is over 16°C. At this point Parliamentarian Hilse (8:40) noted that “the WMO, NASA and the NOAA gave 14.8°C as the global mean temperature in 2016”. According to Parliamentarian Hilse:
So, Herr Levermann, if what you say is right, then it means the temperature has fallen 0.2°C.”
Levermann then told the Parliamentarians that the fact that CO2 causes warming was as sure as gravity making objects fall, and called everything said by Shaviv “all shit” (9:30).
CO2 sensitivity rapidly declining
At the 9:50 mark Levermann clarifies that a doubling of CO2 itself leads to only 1.1°C of warming, but that the added warming will result from the water vapor feedback. He insists there is little uncertainty here. Yet EIKE points out at the 10:35 mark that the IPCC range in fact contains a high degree of uncertainty: 1.5° C to 4.5°C and that there is nothing certain about the science at all.
Recently scientists have been walking back CO2’s warming effect, EIKE shows:

EIKE presents the above chart to show how leading scientists have been ratcheting down their estimates of CO2 climate sensitivity over the years, which today is well below Levermann’s claims of 3.0°C for a doubling. Image cropped at 13:12.
Strangely at the 11:15 mark, the PIK scientist claims that the CO2 molecule is V-shaped. Yet, it is known that it is a straight molecule (11:50).
Shaviv: “No proof that large CO2 changes lead to large temperature changes”
In the end Shaviv disputes Levermann’s claim that the science is “rock solid”, noting that the models neglect factors such as clouds and that there are a number of studies showing that CO2’s impact on temperature is far more modest.
Shaviv summarizes:
There’s no proof that large changes in CO2 would lead to large temperature changes.”
Overall, EIKE called the debate before the Parliamentary Committee a “debacle for the climate alarmists”.
Share this...FacebookTwitter "
"The Victorian government has announced a two-year inquiry into the bushfire crisis, ahead of the mooted federal royal commission which has met resistance from some states. On Tuesday the Victorian premier, Daniel Andrews, announced the inspector-general of emergency management, Tony Pearce, will receive $2.55m for extra staff to review recent bushfires in the state, including in the Gippsland region and the dramatic evacuation of Mallacoota. The inquiry will report by mid 2020 on preparedness and firefighting efforts – ahead of the next fire season – with a second report on relief and recovery due in 2021. The intervention comes as Melbourne suffers from very poor to hazardous smoke conditions – at one point overnight reaching the worst air quality in the world. On Sunday Scott Morrison said that a national inquiry – most likely a royal commission – would be “necessary” to examine the bushfires and he intended to take a proposal to cabinet for endorsement in coming weeks after agreement with the states. The Western Australian government has dissented from the call for a royal commission. On Monday the WA emergency services minister Francis Logan said: “I would prefer – given the royal commissions that are under way at the moment and it takes a huge amount of time in doing royal commissions … I’d prefer personally to see a thorough investigation, not necessarily a royal commission into it.” The New South Wales premier, Gladys Berejiklian, has already announced that state will hold a separate inquiry. Andrews told reporters in Melbourne that Morrison was “still working through the type of inquiry he prefers” and a proposal was yet to go to cabinet. “It is unclear to me – and that’s not a criticism it just isn’t settled yet – whether this would be an inquiry into how the national effort can be as best coordinated as possible or whether it is an inquiry into the event more broadly,” he said. Andrews said he had told Morrison about Victoria’s plans and Morrison had given a commitment to consult on the terms and scope of a national inquiry. Andrews praised Pearce, who he said had the “experience, the understanding and the status in our emergency services system” to conduct the Victorian state inquiry. Later on Tuesday Morrison told reporters in Canberra that a national inquiry had never been intended to replace state inquiries and any suggestion they were in conflict was “false”. Morrison clarified that a national inquiry would examine the preparation and response to bushfires, the scope of federal power including when it can initiate defence force action rather than simply respond to state requests, and “resilience and adaptation” to climate change. Bernard Teague, a retired Victorian supreme court judge who conducted the Black Saturday royal commission, said a national royal commission would be ideal if the federal and state governments could agree about the terms of reference and who would conduct it. “If that’s not possible … then it may be scaled down to have appropriate inquiries in the relevant jurisdictions,” he told Radio National. Teague said the hurdles to setting up a royal commission in the right way were “substantial” and it was therefore “not particularly likely”. Teague said it is clear climate change has a major impact on bushfires but an inquiry could consider “taking more appropriate action into the future” to combat it. The business community will meet in Canberra on Tuesday and is expected to push for the extension of recovery grants to those directly affected by bushfires in Victoria as well as government support for “exceptional circumstances” faced by businesses indirectly affected by the national crisis, to be paid for from a $2bn federal recovery fund. The Victorian emergency services minister, Lisa Neville, announced further measures to assist in the cleanup in the state, where 353 residential properties have been damaged by the fires, including the suspension of the landfill levy."
"
Share this...FacebookTwitterDaniel Wetzel at German national daily Die Welt here recently commented that limiting the warming to 1.5°C warming is utopian. That’s of course, assuming the man-made global warming theory is correct to begin with.
According Wetzel, time theoretically ran out long ago.
Wetzel wrote that despite all the controversy surrounding the IPCC report, one thing is clear: “It’s going to take trillions for the 1.5°C target . And without many veggie days, it’s not going to happen.”
The green urgency for a state of emergency
Even before the report was released to the public, environmentalists and climate activists had already made up their minds that humanity had one last chance to avert calamity. Profound wide-scale action would need to be taken. Green politicians and environmental activists are now demanding a declaration of a state of emergency, it seems. Theoretically however, the window in fact closed weeks ago.
Misrepresenting the report

For Germany, green-colored or shaded politicians and activists said the report confirms that Germany must exit coal power by 2025 at the latest. But Wetzel comments that many special interests are framing the report as something that it really isn’t:


Every lobbyist is taking out of the UN climate report what what appeals to them, and leave everything else aside.”
Clock stuck at 5 to 12, in fact ran out weeks ago


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Wetzel comments that the urgent claims made by the Greens that there is still a small window of opportunity is “surprising” because according to the Mercator Research Institute’s (MCC) “CO2 countdown clock“, time already ran out 30 days ago even for the mid range scenarios, meaning there wasn’t supposed to any more CO2 emissions at all. But Wetzel writes:
In the latest climate report, suddenly there’s 300 gigatonnes more. […] Indeed on in this manner does the world gain 7.5 years time for CO2 reductions, says Oliver Geden, a lead author for the next UN report.”
He cites Chapter C1.4, footnote no. 14 of the report.
A TRILLION dollars a year
According to Wetzel, the UN report also notes that between 900 billion and 1.8 trillion dollars would need to be invested every year from 2015 – 2050 to revamp the global energy system. This is a figure that even the richest nations are going run from.
Currently Germany’s Energiewende alone is costing Germany 34 billion euros annually. Worse, there’s been no CO2 reduction in Germany in close to a decade. That’s some 300 billion euros for zero result. Wetzel adds that Germany has already reached its threshold of financial pain as electricity prices have soared to among the highest worldwide.
Wetzel points out severe “limitations in nutrition are needed”
The Die Welt economics journalist also writes that the German Greens forget to tell the public that it would be necessary to “commit some 8 million square kilometers of agricultural area to growing energy plants in order to reach the 1.5°C warming target.”
Moreover reaching the target would also require going much more without meat, whose production is energy and CO2 intensive. Overall, Wetzel writes, reaching the 1.5°C target “collides with the fight against poverty and hunger” and , if the theory is true, there’s no chance of reaching the 1.5°C target.
 



Share this...FacebookTwitter "
"The birth of industrial civilisation in the 18th century meant humans could extract, transport, and process ever more of nature’s bounty, permanently affecting natural cycles. As we navigate the Anthropocene, the much-debated geological epoch that recognises the geological and ecological impact of the industrial age, there are several environmental disasters and crimes that should be taught in schools to educate young people about the human impact on our shared planet. In choosing a list of five, I have confined my choices to the 1960s and beyond as popular environmental alarmism was born in the decade of cultural revolution that questioned the conventional wisdom of Western civilisation.  This was the first major oil spill of the post-Second World War era. When the SS Torrey Canyon was shipwrecked on a reef off the coast of Cornwall, England, spilling 875,000 barrels of crude oil into the sea, a national event sparked an international debate about the impact of transporting oil, the size of tankers (which had grown dramatically since 1945), and the use of untested chemicals to break down the spilled oil.  Millions of litres of the detergent BP 1002 were sprayed into the sea, but it failed to break down the oil and caused more long term damage to birds and the marine environment.  Torrey Canyon was one of the first televised environmental disasters. Images broadcast around the world helped fuel the fledgling environmental movement and highlighted the vulnerability of marine ecosystems, the role of chemicals, and the dangers of a new global economy based on consumerism and fossil fuels. One of the most significant environmental disasters in American history happened in the city of Niagara Falls, upstate New York. Between 1942 and 1953 the Hooker Chemical Company used the city’s “Love Canal” to dump 21,000 tonnes of toxic chemicals, including 12 carcinogens. It then sold the land to the Niagara Falls School Board for US$1. By 1978, the chemical pollution had caused residents surrounding Love Canal to suffer from birth defects, miscarriages and cancer rates far in excess of national averages.  A popular resident’s protest, driven by local mother-turned-activist Lois Gibbs, forced the American government to act and prompted a national debate about chemical waste disposal sites. President Jimmy Carter declared a state of emergency, 700 families were eventually moved away from the site, and the Environment Protection Agency’s Superfund was established in 1980 to clear up chemical waste sites, oil spills, and natural disasters.  One community’s suffering and protest provided the legal framework to challenge polluters and command the American state to fund the clean up of environmental disasters. Operation Ranch Hand was part of an American herbicidal warfare programme during the Vietnam War, which sought to remove the strategic cover the forest canopy provided for the Viet Cong. Three US administrations – the governments of Lyndon Johnson, John F. Kennedy, and Richard Nixon – sprayed 72m litres of defoliants and herbicides, primarily “Agent Orange” to kill Vietnam’s forests and poison its rice paddies.  The US was condemned internationally and accused of breaking the Geneva Convention which banned the uses of chemical weapons on humans. Though it defended itself by stating that humans were not directly targeted, America’s actions were described as “ecocide” by Swedish prime minister Olof Palme at the UN’s first environment summit in 1972. Operation Ranch Hand should be taught in schools as it initiated discussions about the targeting of the natural environment in warfare, ecocide as the fifth “crime against the peace”, and whether nature should be bestowed with its own legal rights. In March 2011, a strong earthquake off the coast of Japan resulted in the largest nuclear disaster since Chernobyl in 1986. A tsunami unleashed by the quake overwhelmed the Fukushima nuclear plant’s safety systems, disabling the emergency generators and preventing the reactors from being cooled. As a result, reactors one, two, and three suffered meltdowns.  Despite no deaths being directly attributed to the nuclear meltdown, unlike at Chernobyl, it is estimated that the radiation from the many dump sites will last for 300 years. Teaching about the Fukushima disaster in schools encourages children to consider the fuels of the future as we come to legislate for the roles of solar, tidal, wind, and non-renewable energies. With a growing global population and energy demands, how we produce energy and maintain the health of the natural world is a central question for the 21st century. Palm oil is derived from the palm fruit which originates in West Africa but is now largely cultivated in Malaysia and Indonesia. It is found in cosmetics, cleaning products, shampoos and all kinds of food from frozen pizzas to peanut butter.  Yet palm oil is also a leading cause of deforestation and biodiversity loss. The World Wildlife Fund estimates that 300 football pitches are deforested every hour to make way for plantations, while species such as the orangutan are being driven towards extinction as their habitats disappear.  It is important to teach about the impact of palm oil production because it forces us to confront the very foundations of our relationship with nature. It is a case study of an unsustainable economic system that elevates short term economic gain at an ecological cost. A discussion about palm oil is a discussion about the future of life on this planet."
"The UK and Ireland have been experiencing a prolonged hot and dry spell since June, with the first half of summer being the UK’s driest on record. The lack of rainfall has led to hosepipe bans in Northern Ireland and the north-west of England, while the weather is also playing havoc with farming. A shortage of lettuce and broccoli is expected in the next few months, and grass isn’t growing fast enough to feed Ireland’s sheep and cattle through the winter. The hot and dry weather is associated with a high pressure weather system situated over the UK. The high pressure means that the storms the UK occasionally gets at this time of year are being steered much further northwards towards Iceland. While the UK and Ireland have been wilting in the sunshine, Reykjavík has recorded its wettest (May) and cloudiest (June) months on record.  This high pressure system is unusually persistent and has been building up over Europe throughout spring and early summer. In April it was over Central Europe and in May shifted northwards towards Scandinavia. Subsequently it was the hottest April and May in Germany and the hottest May in Denmark since observations began in the 1880s. But why has it been so dry and warm? Here is a shortlist of candidates that could be playing a role – or not – in this unusual summer: Let’s start with the obvious: temperatures are increasing globally due to the burning of fossil fuels, which is increasing concentrations of atmospheric carbon dioxide. The global rise in temperatures means that heatwaves are occurring against a warmer background and so are more likely to become extreme. The past few years have seen some record-breaking temperatures in Europe, for example the 2015 heatwave and the 2017 “Lucifer” heatwave in Central Europe. Unusually warm summer temperatures have also been recorded elsewhere, for example in Canada and Japan, and climate change is very likely to have played a role in the UK and Ireland as well. Temperatures over the North Atlantic Ocean can play a role in setting the position of a narrow band of strong wind in the upper atmosphere known as the jet stream. The position of the jet stream in turn has a profound impact on the weather experienced in the UK and Ireland.  The jet stream can affect weather in Europe. This summer, ocean temperatures have been relatively warm between the Gulf of Mexico and North Africa while temperatures south of Greenland have been unusually cold. This is thought to have pushed the jet stream further northwards, sending bad weather towards Iceland while allowing areas of high pressure to linger over Europe. Every few years, ocean temperatures in the tropical Pacific swing between being relatively warm (known as El Niño) and cool (La Niña). Since October 2017 the area has been in a La Niña phase. This is sometimes associated with cold winters in north-western Europe (for example the winter of 2010-11 and the recent “Beast from the East” cold spell in March 2018). However, La Niña cannot really be blamed here – this year’s event had started to weaken around April and had almost gone by June when the UK’s current dry spell began.  The above factors influence the type of weather the UK and Ireland will get but, within these broad possibilities, good or bad luck also plays a role. This is especially the case for very unusual weather such as the current hot and dry spell. This summer is no different and the hot and dry weather is partly due a combination of Atlantic temperatures, climate change and annual weather patters. Should weather patterns continue as they are then 2018 may turn out to be as hot and dry as the extreme summer of 1976. This raises the question of how predictable it is. The science of forecasting the weather a few months ahead is still in its infancy, and such “seasonal forecasts” are subject to lots of uncertainty. However, the UK Met Office did predict back in early June that there was an increased probability of a drier and warmer summer. While meteorologists are not yet able to predict prolonged hot and dry spells months in advance there were useful indicators of an increased chance of extreme weather. Advancing the science of seasonal forecasting requires a deeper understanding of the different factors than can influence the weather, from ocean temperatures and jet streams through to changes in Arctic sea ice. As part of the UK Drought and Water Scarcity programme research institutions in the UK are being funded to further our knowledge of these influences and to better understand how the UK can respond to and mitigate the impacts of prolonged dry weather."
nan
nan
"The heat in the world’s oceans reached a new record level in 2019, showing “irrefutable and accelerating” heating of the planet. The world’s oceans are the clearest measure of the climate emergency because they absorb more than 90% of the heat trapped by the greenhouse gases emitted by fossil fuel burning, forest destruction and other human activities. The new analysis shows the past five years are the top five warmest years recorded in the ocean and the past 10 years are also the top 10 years on record. The amount of heat being added to the oceans is equivalent to every person on the planet running 100 microwave ovens all day and all night. Hotter oceans lead to more severe storms and disrupt the water cycle, meaning more floods, droughts and wildfires, as well as an inexorable rise in sea level. Higher temperatures are also harming life in the seas, with the number of marine heatwaves increasing sharply. The most common measure of global heating is the average surface air temperature, as this is where people live. But natural climate phenomena such as El Niño events mean this can be quite variable from year to year. “The oceans are really what tells you how fast the Earth is warming,” said Prof John Abraham at the University of St Thomas, in Minnesota, US, and one of the team behind the new analysis. “Using the oceans, we see a continued, uninterrupted and accelerating warming rate of planet Earth. This is dire news.” “We found that 2019 was not only the warmest year on record, it displayed the largest single-year increase of the entire decade, a sobering reminder that human-caused heating of our planet continues unabated,” said Prof Michael Mann, at Penn State University, US, and another team member. The analysis, published in the journal Advances In Atmospheric Sciences, uses ocean data from every available source. Most data is from the 3,800 free-drifting Argo floats dispersed across the oceans, but also from torpedo-like bathythermographs dropped from ships in the past. The results show heat increasing at an accelerating rate as greenhouse gases accumulate in the atmosphere. The rate from 1987 to 2019 is four and a half times faster than that from 1955 to 1986. The vast majority of oceans regions are showing an increase in thermal energy. This energy drives bigger storms and more extreme weather, said Abraham: “When the world and the oceans heat up, it changes the way rain falls and evaporates. There’s a general rule of thumb that drier areas are going to become drier and wetter areas are going to become wetter, and rainfall will happen in bigger downbursts.” Hotter oceans also expand and melt ice, causing sea levels to rise. The past 10 years also show the highest sea level measured in records dating back to 1900. Scientists expect about one metre of sea level rise by the end of the century, enough to displace 150 million people worldwide. Dan Smale, at the Marine Biological Association in the UK, and not part of the analysis team, said the methods used are state of the art and the data is the best available. “For me, the take-home message is that the heat content of the upper layers of the global ocean, particularly to 300 metre depth, is rapidly increasing, and will continue to increase as the oceans suck up more heat from the atmosphere,” he said. “The upper layers of the ocean are vital for marine biodiversity, as they support some of the most productive and rich ecosystems on Earth, and warming of this magnitude will dramatically impact on marine life,” Smale said. The new analysis assesses the heat in the top 2,000m of the ocean, as that is where most of the data is collected. It is also where the vast majority of the heat accumulates and where most marine life lives. The analysis method was developed by researchers at the Chinese Academy of Sciences in Beijing and uses statistical methods to interpolate heat levels in the few places where there was no data, such as under the Arctic ice cap. An independent analysis of the same data by the US National Oceanographic and Atmospheric Administration shows that same increasing heat trend. Reliable ocean heat measurements stretch back to the middle of the 20th century. But Abraham said: “Even before that, we know the oceans were not hotter.” “The data we have is irrefutable, but we still have hope because humans can still take action,” he said. “We just haven’t taken meaningful action yet.”"
"Should we give up having children to save the planet? Recent news articles and scientific papers have once again raised concerns about “overpopulation” and the environmental implications of having too many humans on Earth. Many people consider bringing fewer children into the world to be the logical solution. If you read the comments section of these articles, you’ll find out what anyone who’s been in a conversation about overpopulation knows: such exchanges are polarised, emotionally loaded and conflict ridden.  Regardless of whether you think that overpopulation is the defining issue of our time, don’t think it is a real problem, or lie somewhere in between, it’s absolutely crucial we can have these conversations without further polarising the debate. In a recent comment in Environmental Research Letters, we offer three tips for having conversations about overpopulation in a more ethical, thoughtful and sensitive way. An individual person (or a couple) acting by themselves can only do so much. It can seem like the most impactful action one can take is to have fewer children, but our capacity to act collectively can have far greater impacts than any one (or two) people can alone. Environmental problems are so large that they are hard for us to wrap our minds around. When people are encouraged to think about these problems as individuals, it can cause them to go into denial about how much impact they can genuinely have. But research has shown that highlighting a collective responsibility for addressing environmental issues actually leads to a greater desire to act. Often recommendations for how to be more environmentally friendly are targeted at things you do in your personal life: recycle more, eat less meat, fly less, and so on. However, businesses, universities, hospitals, churches and charities all have big environmental footprints, too. In fact, these are usually much larger than any one individual’s footprint. Therefore, individuals acting professionally within these organisations can substantially reduce their environmental impact. For example, the head of purchasing of a large organisation may be able to make bigger reductions in their organisation’s carbon emissions through changing purchasing guidelines than they could ever make by having fewer children. So organisations, or people working on behalf of organisations with big environmental footprints, are often much more strategic actors to target when striving towards larger-scale pro-environmental changes. When we’re talking about population as an environmental issue, it’s important to remember that it’s not the number of people per se but rather the consumption habits that lead to environmental degradation. Seven billion Americans using as much water, plastic, petrol and meat as they do now, would be a global disaster. In many countries, however, individuals use a fraction of the average American, and Eritrea has the smallest per capita ecological footprint of all. So few children are being born in most developed countries that without immigration, populations would be declining. For example, in Canada, the fertility rate was 1.6 children per woman in 2011 (well below the replacement rate of 2.1). So if you think about it, the real environmental impact here has to do with how much people are consuming – and this varies widely both between and within countries. Suggestions to have fewer children are very closely linked to the idea of birth control. Birth control has an ugly history and its knock-on effects can still be seen in China and South Korea today. In these countries, birth control led to the abortion of many female embryos as families preferred to have boys for several cultural reasons. However, today these countries face the problem of having more men than women of childbearing age which is one reason behind the trafficking of young women from other countries, such as Vietnam. Against this backdrop, in 2012, the United Nations Population Fund declared family planning a human right. But still about 12% of women aged 15–49 globally don’t have access to family planning. This is a modern-day human rights violation happening right now. This is why, when the suggestion of addressing environmental issues by having fewer children comes up, the conversation often switches to overpopulation and becomes fraught. Overpopulation is usually seen as a problem that puts future generations at risk. Therefore when it is raised in conversations about family planning, it’s read as a value statement: my children’s rights being violated in future are more important than the rights of those being violated now. This may not be your intended message, so be clear: should women have the right to choose when and how many children they have? An expanding human population is a collective challenge which incorporates values, emotions, different worldviews, and the alignment of different interests. So next time you find yourself wading into an exchange about overpopulation, be clear about your underlying assumptions. This is a conversation with many layers and we need to approach it with open minds, sensitivity, tact and compassion."
"When Scott Morrison thanked governments of the world for their assistance with Australia’s bushfire crisis, he particularly singled out “the loving response from our Pacific family”. Across the Pacific region – a collection of developing and least developed nations that are themselves almost uniquely at risk from climate-induced catastrophes – the response to the Australian bushfires has been immediate and generous, but it also reveals something of the problematic fraternity that Australia has with the rest of the region.  Governments from all over the Pacific have offered support. A hundred Papua New Guinean defence personnel, mostly engineers, will fly to Australia to help with firefighting efforts, and Fijian defence personnel will also be coming to assist. Vanuatu’s government has pledged $250,000. A PNG politician urged people to donate to relief efforts, pledging 50,000 kina (A$20,000) himself. And then there are the small gestures: a coffee shop in Fiji donated all of its sales on Monday – F$3,000 (A$2,000) – to bushfire relief; a group of Red Cross volunteers in Vanuatu walked down the street collecting donations, carrying a sign reading: “Give hope to Australian bush fire survivors”. Giro Imbu, 35, organised a similar donation drive in Lae, Papua New Guinea’s second-largest city, after seeing images of the bushfires on television. Imbu led a group of young people who walked through the city’s settlements on Thursday and Friday collecting donations. On their first day they received 1,000 kina. “We see the environment was really devastated, we see the plants being destroyed, we see a lot of the countrymen losing their lives in the fire,” Imbu said. “We’re not very educated, but it has given us a drive … we want to help.” Vanuatu Choir, who were displaced from Batlow while working to pick fruit, perform hymns at the Wagga multi-faith service for those affected by bushfires. #nswfires pic.twitter.com/F99RplyT5y To put all of this in context, in 2017 Vanuatu’s GDP per capita was just under US$3,000, Papua New Guinea’s was about US$2,500, Australia’s was close to US$55,000. The minimum wage in PNG is 3.50 kina (A$1.50) an hour. As Morrison noted at his press conference – speaking about Vanuatu’s pledge of $250,000 – “it might not sound like a lot in terms of the tremendous assistance provided by many other countries, but from them, that was a gift from the heart”. The heartfelt response of Pacific nations to Australia during this time is in part a reciprocation of the assistance Pacific countries receive from Australia when crises befall them. As James Marape, the prime minister of Papua New Guinea, noted in his statement about the fires: “Australia is the closest friend of PNG and is always the first in PNG in our times of adversities.” After Cyclone Pam devastated Vanuatu in 2015, Australia committed $50m in support for early and long-term recovery. After Cyclone Winston caused damage in Fiji amounting to about 30% of its GDP in 2016, Australia stepped in with $35m for recovery efforts. Morrison also reminded the world of Australia’s generosity as he was thanking Pacific countries for theirs, saying: “[Pacific leaders] know how Australia has been faithful to them in their hours of need, and they just in their own way are trying to extend that in the best way they possibly can.” But Australia’s generosity also puts Pacific countries in a tight spot. Pacific leaders have to walk a difficult line: keeping Australia and its financial support on side, particularly as they face the prospect of increased climate-related natural disasters in their countries, while wanting to challenge Australia on its climate policies. Pacific leaders are among the most outspoken and effective climate leaders the world has. We know they are angry at Australia’s refusal to transition away from coal, as well as Australia’s use of carryover credits to meet Paris targets. We know, in the words of the former prime minister of Tuvalu, , Enele Sopoaga, that they see Australia as trying to save its economy, while they are working to save their people. We know that they knowAustralia is not doing enough to tackle the climate crisis – the same climate crisis that is seeing their islands suffer rising sea levels, increasingly frequent devastating cyclones, salinity of the water table, erosion of their islands; that same climate crisis that threatens to make Australia’s current devastating fire season the norm for our future. And yet, still, they are there to offer us help. When asked whether he thought it was odd for people in a much poorer country like Papua New Guinea to be raising money for people in a wealthier one, Imbu, who organised the Lae fundraiser, said: “We live in an environment where the richest are getting richer and the poorest getting poorer, but as human beings we have this hardware, we try to help.” Pacific nations deserve all the thanks Morrison has given them, but to survive, they need much more from him."
"Large numbers of species are at risk of global extinction from climate change. As a result, some governments are trying include wildlife in their plans for how to adapt the management of natural landscapes to a warming world. The problem is we still know very little about the sorts of environments that could help wildlife survive adverse climate shifts. But we do know that, during the Ice Age, pockets of warmer conditions protected species such as red squirrels and even red deer from the extreme cold. So, could modern versions of these “refugia”: locally cool habitats such as bogs, alpine environments or shaded valleys give species what they need to survive today’s warming? Using 5m records of plants and insects collected by citizen scientists in England, my colleagues and I looked for signs that refugia are protecting species today. We found that quite a number of sites around the country are already beginning to act as refugia. This was particularly the case in areas where the landscape is hilly or steep, where the local climate conditions (microclimate) vary more often. We estimate that these areas of variable microclimate have reduced the risk of extinction for insects and plants that are particularly sensitive to warming by an average of 9% and 22% respectively. Incorporating these key wildlife areas into our plans for climate change could help save more species and local populations from extinction. Our research indicates that inside these refugia the microclimate can vary over very short distances. This can be as little as few hundred metres across a shaded valley. But a variable microclimate can also develop in hummocky terrain, which has lots of slopes facing different ways – both towards and away from the sun. These local differences can be as much as 7°C during the hottest parts of the day. For some species, that can be the difference between extinction or survival. A surprising aspect to the work was that the refugia we found weren’t necessarily forming in the coolest parts of the landscape. Instead, they formed in those areas that had the most variable microclimate. It is therefore quite possible that there are lots of alternative habitats for threatened species close to where they already live. This would mean that the species that live in these refugia wouldn’t have to move far to make use of them. This could be particularly important for plants and, as we already know, they can’t shift their geographical range as quickly as animals in response to warming. But we found that animals also benefit from refugia and, in most cases, animal species will be able to make use of numerous alternative thermal habitats within the lifetime of an individual. So how can we protect refugia from climate change, to make sure they are available for wildlife to use in the future? In some ways, the areas we’ve identified are quite different to the expansive, continuous areas of habitat that we currently prioritise for wildlife conservation, such as large areas of moorland or bog. But there is certainly some overlap with areas we have already protected for wildlife. This is particularly the case within the UK’s network of Sites of Specific Scientific Interest (SSSIs), the highest category of legal protection we can give to parts of the landscape.  So at least we won’t be starting from scratch when we adapt our conservation plans to the huge challenge of climate change. But some important sites for refugia lie outside these networks, and we should aim to protect as many of these as we can. In regions with fewer, naturally occurring refugia – flatter, often low-lying areas such as the east of England – we might even want to be more radical and consider using mechanical diggers to create hummocky terrain from scratch. This might sound expensive, but becomes far more attractive if it can be done where there is building or engineering work already going on, as the equipment and expertise will already be available and on site. For example, we could add the creation of refugia to plans for new housing developments. There are particular wildlife benefits to be had where digging exposes more alkali minerals such as as chalk to the air. This allows rarer, specialist plants and animals to move in and make use of the unusual soil conditions that arise. As the world warms up, much of our wildlife is facing a future of warming temperatures in landscapes which, thanks to human activity, are already hostile to many species. Refugia won’t “save” species from climate change, but finding and protecting the sorts of areas that give our flora and fauna the best chance of survival seems like a first and perhaps obvious step towards a more integrated approach to managing our environment. This would help us to safeguard its value as the provider of the food we eat, the water we drink and the natural landscapes we enjoy."
"Fields of sunflowers are now a common – and beautiful – sight all over the world. They have inspired artists from Van Gogh to Klimt, and continue to do so in the age of Instagram, if the recent selfie craze is anything to go by and as one Canadian sunflower farm discovered. It was forced to shut after thousands of tourists seeking the perfect selfie caused chaos. An astonishing 7,000 vehicles caused a traffic jam stretching over four kilometers. But when sunflowers were introduced to Europe from the Americas in the early 16th century they were little more than garden novelties. The 16th-century English herbalist, John Gerard, was disappointed that the sunflowers in his Holborn garden in London were only 4.3 metres tall (those of his European competitors reached 7.3 metres). Today, sunflowers, with their massive, yellow flower heads are among the most recognisable plants on the planet. The growth in their prevalence – and that of sunflower selfie snaps – is largely due to their ballooning use for oil. Over the last 60 years, changes to our diets and industrial needs mean the area of global oil crop production has more than doubled. Four oil crops consume most of this land: oil palm, soya, rape and sunflower. Sunflowers have two main commercial uses, oil and confectionery (for direct seed consumption). Oil varieties of the flower have small, black, oil-rich seeds with thin hulls, which are pressed to produce an edible, almost tasteless, pale oil, rich in unsaturated fatty acids (especially oleic acid and linoleic acid). The oil is popular for cooking, margarine manufacture and even bio-diesel production. Leftovers from oil extraction are used to make high-protein animal feed. Confectionery types, on the other hand, have large, striped, oil-poor seeds with thick hulls. Both oil and confectionery types are the results of centuries of careful selection and breeding from wild plants. In North America, the sunflower’s native continent, the harvest contributes little to global production; peak production happened in the late 1970s only to fall dramatically in the 1980s. Today, most sunflowers are grown in the former Soviet Union.   The annual sunflower, a member of a genus of about 50 species from the Americas, was domesticated in North America about 5,000 years ago. Native North American uses of sunflower ranged from food and medicine, through a fibre and dye plant to a source of musical instruments and bird snares.  Commercial interest in sunflowers as an oil crop was slow to develop across most of Europe and North America. In contrast, Russians were using sunflowers as an oil crop by the late 18th century, perhaps because the Russian Orthodox Church did not prohibit the oil’s use during Lent. By the end of the 19th century, Russians had selected highly productive oil and confectionery varieties, which were re-imported to North America in the baggage of Russian immigrants. During the early 20th century, the Soviet plant breeder Vasilii Stephanovich Pustovoit began selecting sunflowers for oil content. In 1913 seeds contained approximately 30% oil, by the late 1950s seeds contained approximately 50% oil. Much of the change was achieved by breeding for thin hulls surrounding the kernels. By the 1960s, Western commercial sunflower oil production was based on the Soviet sunflower variety “Peredovik”. 


      Read more:
      The flower breeders who sold X-ray lilies and atomic marigolds


 Soviet sunflower seeds even got mixed up with the Cold War – high-quality seeds surreptitiously moved among Soviet and American plant breeders. Soviet sunflower breeders used naturally occurring variation within the annual sunflower to make commercial progress. But by the mid 20th century, North American breeders were taking a different approach, crossing wild and cultivated sunflower species to exploit the yield advantages associated with hybrid vigour. Today, most commercial sunflower farmers grow hybrid sunflower seed. Hybrid sunflower seed can be made by slowly, meticulously and expensively emasculating individual flowers to create females, which are then pollinated by hand. Alternatively, mutant sunflowers, incapable of producing fertile pollen, are used as female parents in hybrid crosses. Insects are essential for producing the vast quantities of the hybrid sunflower seed planted each year, since pollen must be transferred from male-fertile to male-sterile plants. Without insects, hybrid sunflower seed production would be uneconomic. But once in the farmer’s field, the sunflower crop does not rely on insects: crop seeds are produced by flowers that are fertilised with their own pollen. But new seeds will have to be purchased for the next season. Sunflower breeding continues in earnest today. New demands are placed on breeders by the environments in which farmers want to grow sunflowers and by consumers in the ways they want to use the harvest. Height, for example, is something every child wants their sunflower to achieve. But to the farmer, tall sunflowers must be avoided. Energy used to push up stems cannot be used to make seeds. And heavy rains and strong winds will knock over tall, top-heavy plants.  The dramatic changes of form and use of sunflowers over the last century show what can be achieved by breeders if suitable genetic resources are available. If we continue to adapt sunflowers to our needs as climates change, we must ensure diverse genes are conserved for future generations – ensuring those sunflower fields remain on offer as the perfect place to take a picture.  


      Read more:
      After Svalbard: why safety of world seed vaults is crucial to future food security


"
"
Share this...FacebookTwitterBy  Kirye 

The media, alarmist scientists and many leading policymakers often tell the public “the Arctic is rapidly melting”. And if a poll were done today, a vast majority of the people in Japan and elsewhere would say this is true. Unfortunately they have become the victims of “fake news”.


Luckily we have some hard data from the Arctic. And if one looks at them, it is true that sea ice has seen a declining trend – if we go back 40 years.
Yet, if we look at the past 12 years, we see that the trend for minimum has stopped, and one could argue even reversed:




Chart: By Kirye


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The above Arctic sea ice volume chart, which relies on data from the Danish Meteorological Institute (DMI), shows that there has even been a modest increase in the minimum sea ice volume recorded every late summer.  
Overall, Arctic volume has been stable, slightly on the rise over the past 12 years, as the full year data from the DMI show:
Yet, the media constantly falsely report that the Arctic sea ice is still melting away rapidly (it isn’t), and many have even made the alarms louder.
Sloppy, misleading media
Unfortunately the media have been sloppy, lazy and misleading in their reporting of what is really happening at the poles of the Earth. If they did their homework, they’d realize their shrill headlines are inappropriate and outdated.
In early September NoTricksZone’s author Kenneth Richard presented a number of papers, where he wrote:

An accumulating collection of “headlines” taken from the 2018 scientific literature is indicating the Arctic region is no longer experiencing accelerated mass ice sheet/glacier loss, warming, or sea ice declines.”

Disservice to the public
Why the media, IPCC and many policymakers ignore this remains a mystery. It’s a disservice to the public and taxpayers who have entrusted them to conduct policymaking responsibly and honestly.
P. Gosselin contributed to this article.Share this...FacebookTwitter "
"In the middle of the last century, mass-produced, disposable plastic waste started washing up on shorelines, and to be found in the middle of the oceans. This has since become an increasingly serious problem, spreading globally to even the most remote places on Earth. Just a few decades later, in the 1970s, scientists found the same problem was occurring at a much less visible, microscopic level, with microplastics.  These particles of plastic are between 0.05mm and 5mm in size. Larger pieces of plastic can be broken down into microplastics but these tiny bits of plastic also come from deliberate additions to all sorts of products, from toothpaste to washing power.  Now, with major global sampling efforts, it has become clear that microplastics are dispersing all over the world – in the water column, sediments, and marine animal diets – even reaching as far south as the pristine environments of Antarctica. While this plastic problem has become more prevalent, one of the most pristine ecosystems on Earth, the fjords of the Western Antarctic Peninsula, have been revealed by retreating glaciers. Tucked between islands and the mainland, the coast along the Western Antarctic Peninsula has long, narrow inlets created by glaciers. During the last 50 years, these fjords have physically changed, due to reduced sea ice cover and because nearly 90% of glaciers have retreated in this region. These processes have exposed the ocean floor of many of the fjords for the first time.  The potential for microplastics to impact this environment and its marine life is huge – and we’re now working to figure out the depth of the effect that microplastic pollution is having on the newly colonised habitats. Any microplastics recovered in the Southern Ocean, particularly in newly formed ecosystems, raise alarm. They not only indicate that the area has been affected, but that plastic pollution is increasingly ubiquitous too. In November 2017, our multidisciplinary UK-Chile-US-Canada research team – known as ICEBERGS – joined the RRS James Clark Ross (an ice strengthened research ship) and headed to Antarctica’s northernmost fjords. Our goal was, and still is, to gain a better understanding of how the environment and organisms evolve in newly emerging and colonising habitats in Antarctica. We are particularly interested in the marine ecosystems on the ocean floor, so have been looking at areas such as Marian Cove and Börgen Bay on the Western Antarctic Peninsula, where communities have only developed in the last few decades – due to the retreating glaciers. Thriving marine ecosystems can act as climate regulators. When ice retreats, new, pristine fjordic habitats are revealed and phytoplankton blooms occur. These help to counteract climate change because they take carbon dioxide gas out of the atmosphere. New productive seabed habitat also becomes available for the diverse shallow water fauna that eat this algae, and store the carbon long term. Not counteracting climate change, however, is the fact that new open water absorbs heat faster, in contrast to ice that would have reflected it.  The animals colonising the exposed fjords face challenging conditions. The sediment and fresh water flowing in the glacier melt runoff make it very difficult for many organisms to survive. And, if exposed to them, microplastics can be a serious concern for many marine animals, especially filter-feeding organisms (for example krill, and other zooplankton). As these creatures filter water to obtain food, they may ingest microplastics which can clog and block their feeding appendages, limiting food intake. Ingested microplastics may be transferred to the circulatory system too, which can cause an increased immune response.  Microplastics may also bring in new bacteria and chemical pollutants attached to them too. So, because many filter-feeding organisms support the entire food web, any impact on them should be expected to have cascading effects on the ecosystem. In newly revealed habitats, creatures are less likely to have been impacted by marine pollutants previously so they can help us learn about more recent changes in an environment. To our knowledge, microplastics have not been found in the Antarctic fjords before now, but our preliminary results have already found an alarmingly high presence – similar to those found in the open water of the Atlantic and Pacific Oceans, near big civilisations. These results came from samples taken directly from the fjords, and we are now looking further at the evidence of how micro-organisms are being affected by microplastics. During the next two Antarctic summers, we will be collecting more geophysical, physical oceanographic, sedimentological and biological data from these pristine sites in the same locations, so we can compare the changes over time in the habitats that colonise new ocean floor in Antarctic fjords.  Only after such rigorous data collection and analysis will we be able to tell the true impact of microplastics on pristine environments. Until then, we can all do our bit to cut down on potential pollution and protect what may very well be the last pristine environments on Earth."
"Elegant science can arise from ugly facts. This is the thought that springs first to mind as we read a new study in Nature about how a single invasive species – the black rat Rattus rattus – can deeply impact not just the landscape it overruns, but fundamentally alter the wider marine realm that surrounds it. The elegance springs from the exploitation of chance patterns of invasion. The researchers behind the study, led by marine biologist Nick Graham of Lancaster University, looked at the Chagos Archipelago, a remote group of coral atolls in the Indian Ocean. Some of the small islands that make up the archipelago are rat-infested and some are rat-free, a result of different patterns of human habitation in the 18th and 19th centuries.  Graham and colleagues found that the difference between the islands is now startling and has no need to be teased apart by sophisticated statistical techniques. Those islands with rats have something like one or two seabirds per hectare, while those without rats have 1,000 or more in the same area.  On rat-free islands, the seabirds range far and wide across the oceans to feed, and then deposit much of the resulting nitrogen and phosphorus-rich excrement on their home island. These nutrients are then washed into the shallow waters of the surrounding coral reef lagoons, where they support a complex food web that ultimately maintains large fish stocks. The fish in turn then graze the reefs and keep a healthy balance between seaweed and the island-building corals.  Next to the rat-infested islands, however, the researchers showed the fish populations are smaller, grow more slowly and eat less than half as much seaweed. These reefs, therefore, are more prone to be smothered by seaweed, and to have less healthy corals. This general phenomenon is not new. On the Chagos Islands it is a few centuries old, but elsewhere it can range back thousands of years – humans have long been migrating, taking rats and other fellow invaders such as pigs, rabbits and cats with them to cause comparable ecological havoc.  The trick here, as the authors underlined, has not been in finding evidence of human impact, for that is now nigh-well pervasive, but in finding some examples of something approaching a natural baseline – those islands that are still rat-free – which can allow the scale of that impact to be assessed. Given this history, the Chagos Archipelago story is not, technically, part of the Anthropocene – for the current best estimate for a beginning of this putative, still informal, geological epoch is somewhere in the mid-20th century. But it does illuminate the extent of – and the likely fallout from – the yet greater changes associated with more recent human impacts, when the scale and speed of biological invasions continued and indeed accelerated. Since the mid-20th century, most of the lakes and waterways of North America, for instance, have been the scene of a blitzkrieg by the zebra mussel, a native shellfish of Asia. The invasive zebra mussels of the River Thames of London, meanwhile, have seen their short-lived grip on the river prised from them by the yet more prolific Asian clam which, in the space of little more than a decade, has become a dominant species in the river.  San Francisco was once known for hippies with flowers in their hair, but its surrounding bay is also home to some less benign visitors, including vast numbers of the Amur River clam from across the Pacific, and the shipworm (actually a burrowing mollusc), which on its arrival managed to bore its way through numerous wooden piers and wharfs. Meanwhile, on the other side of the world in the East African savannah, there are a plethora of invading plants including the aptly named “devil weed” and “famine weed”, which spreads rapidly and can wipe out entire harvests. Teasing out the ecological ripple effects of these newer and more numerous examples of the Anthropocene will be harder than in the finely-worked Chagos Islands study of Nick Graham and co. The natural ecological baseline is now yet more distant, while other effects – from pollution, urbanisation, agriculture, and climate change – are also intensifying. Amid a thickening tangle of environmental forcing factors, it is becoming harder to precisely link cause and effect. It is clear, though, that the Earth system is now on a new trajectory, of the Anthropocene, following the relative stability of the Holocene. This new story of rats and reefs underlines how far-reaching these changes are likely to be. 


      Read more:
      Dawn of the Anthropocene: five ways we know humans have triggered a new geological epoch


"
"Chirp, chirp! To make this familiar summer sound, the male cricket holds his nerve and “stridulates” – rubbing his back legs together in order to entice a female. He knows this makes him vulnerable. What a female cricket can find, so too can the predators and parasites that wish to consume or infect him.  Hiding in the vegetation, he is also surrounded by a silent audience of other males. Those “sneakier” males do not sing themselves, but will try to intercept females as they approach a singing rival. It is this dramatic scene that plays out as we hear the crickets and grasshoppers calling on warm evenings. Or at least it did. Because the crooning of the crickets has quietened in recent years and may be becoming a thing of the past. There is strong evidence that large numbers of crickets and grasshoppers (known, along with mantises, earwigs and cockroaches as the “Orthoptera”) are declining across Europe. A 2017 review of European species showed that over 30% of the 1,000 European species were in decline while only 3% were increasing. As with many insects, we simply don’t know what is happening to most of the rest.  The problem is that recent work has suggested that all insect species, including Orthoptera, are declining – the so-called “insect Armageddon”. A 2017 study found that the abundance of flying insects has plunged by 75% over the past 25 years. One member of the study team, Professor Dave Goulson of Sussex University, said at the time: “Insects make up about two-thirds of all life on Earth [but] there has been some kind of horrific decline.”  He added: “We appear to be making vast tracts of land inhospitable to most forms of life, and are currently on course for ecological Armageddon. If we lose the insects then everything is going to collapse.” Among the species threatened is the delightfully-named “wart-biter” – so-called because of an 18th century Swedish practice of using the strong jaws of the cricket to remove warts from the skin. The wart-biter is now the focus of conservation efforts, including reintroductions into sites from which it has been lost. But this kind of intensive conservation simply is not possible for all species. The reasons behind the decline in crickets and grasshoppers are the standard fare. The loss, damage and fragmentation of habitats, largely as a result of increasing farming and urbanisation, as well as increasing rates of fires such as those that the world is experiencing in 2018. Crickets are often held to be indicators of good quality natural habitat, so their decline mirrors the ongoing decline in the wider natural world.  Anybody who has spent any time in the world’s most natural places will know that natural “soundscapes” are neither peaceful nor serene – they are as noisy and busy as any urban high street. The crickets are just one part of the larger soundscape that provides the musical accompaniment to nature’s play. Depending on where you live, you might hear bird song, flowing water, the buzzing of bees, the roar of tigers, the rustle of leaves, or the calling of frogs.  In 1962, Rachel Carson famously wrote about the “Silent Spring” caused by the effects of agricultural pesticides on songbirds. Now we are beginning to appreciate that other components of the natural world are falling silent. This is why some scientists are turning to “soundscape ecology” or “ecoacoustics” as a tool to understand the changing natural world.  This new scientific field gives conservation biologists another tool – an ecological stethoscope with which to listen for subtle changes in the environment. But in order to protect the soundscape we need to protect the landscape. At a time when land is at a premium for food production, housing and industry, we need to make space for nature."
nan
"
Share this...FacebookTwitterAlmost daily the CO2 Science site brings reports on the impact of climate change on the living world. Hat-tip: Die kalte Sonne here

Recently, CO2 Science brought up a paper in Nature Communications.
Using satellite images, Venter et al. 2018 found an eight percent increase in woody vegetation in sub-Saharan Africa over the last three decades, underscoring the global “greening trend”.

Recent study by Venter et al finds that the Sahara has shrunk by 8% over the past three decades. NASA image, public domain.
According to Wikipedia, the Sahara covers a vast area of some 9.2 million square kilometers. Eight percent of that translates into more than 700,000 square kilometers. That’s an area that’s almost as big as Germany and France combined! This is profound.
In other words, it’s well over 10,000 Manhattans!
If the added green area were effectively used for agriculture, it could produce enough food to feed the African continent. Unfortunately, this is a fact that the doomsday-obsessed media, activists and ruling politicians fear will become publicly known. They instead would prefer that the globe returns to a climate of the 1980s, when drought and famine ravaged the vast North African region.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to the recent study, the cause was a decline in vegetation fires in a warmer and more humid climate. Abstract:
Drivers of woody plant encroachment over Africa
While global deforestation induced by human land use has been quantified, the drivers and extent of simultaneous woody plant encroachment (WPE) into open areas are only regionally known. WPE has important consequences for ecosystem functioning, global carbon balances and human economies. Here we report, using high-resolution satellite imagery, that woody vegetation cover over sub-Saharan Africa increased by 8% over the past three decades and that a diversity of drivers, other than CO2, were able to explain 78% of the spatial variation in this trend. A decline in burned area along with warmer, wetter climates drove WPE, although this has been mitigated in areas with high population growth rates, and high and low extremes of herbivory, specifically browsers. These results confirm global greening trends, thereby bringing into question widely held theories about declining terrestrial carbon balances and desert expansion. Importantly, while global drivers such as climate and CO2 may enhance the risk of WPE, managing fire and herbivory at the local scale provides tools to mitigate continental WPE.
Read more at CO2 Science.
Another element that is unmentioned is the fertilization effect of the added CO2 into the atmosphere surely provides.
Relotian media
This is positive news that no one will find in the Relotian mainstream media, which are fixated on purveying propaganda, falsehoods, half truths and censorship with the aim of distorting public opinion and vigorously marginalizing dissenting views.
Also (thanks to readers:
– https://journals.ametsoc.org/doi/abs/10.1175/JCLI-D-17-0236.1
– https://www.nasa.gov/feature/goddard/2016/carbon-dioxide-fertilization-greening-earth
– http://journals.ametsoc.org/D-17-0236.1
– http://www.mdpi.com/htm
– http://www.mdpi.com/2072-4292/10/3/424/htm

Share this...FacebookTwitter "
"Watching animals in their natural habitat may seem harmless, but it can have serious consequences for the conservation status of wildlife. More than 1,400 species listed as Endangered and Critically Endangered by the International Union for the Conservation of Nature are threatened by tourism. This can be a consequence of habitat destruction caused by tourism development or disturbance caused by tourists.  The golden-capped fruit bat, for example, is an endangered species that is endemic to the Philippines. One of the major threats it faces is disturbance at the roost site caused by tourists. Not only can this disturbance stress the animals, it can also lead to the abandonment of pups. Together with other threats, such as deforestation, this disturbance contributes to pushing this and other species towards extinction. Nature tourism can be a primary source of income for entire communities or even countries. For example, in 2010 nature tourism in Scotland was worth £1.4 billion and generated 39,000 jobs. £127m of that is attributable to wildlife watching alone.  Consequently, we need to find ways to manage these activities so that the targeted wildlife can continue to thrive and the businesses that depend on it can remain economically viable. This is not an easy task.  The first obstacle is a lack of data. It is difficult and expensive to “track” people during their recreational activities, especially over large areas and long periods of time. Surveys allow experts to ask people about their recreational activities, but they are expensive to run and the response rate can be poor.  Here’s where social media can come to the rescue. Platforms such as Facebook and Twitter have billions of users, who share large amounts of information about their activities.  Flickr is a photo-sharing website that has been active since 2004. Most of the photographs uploaded onto Flickr have a time stamp indicating when the photo was taken. Some of them have geographical coordinates indicating where the photo was taken, too. Users can also add text to their photos, which gives an indication of their content.  Wildlife watching, and nature recreation in general, is closely associated with photography, making Flickr an ideal source of information to quantify these activities on a large scale and in fine detail.  As ideal as this may sound, however, Flickr data would be useless for conservation purposes if it didn’t reflect patterns of actual visitation. To address this, my co-authors and I compared the distribution in space and time of Flickr photographs to spatial and temporal trends from visitor statistics obtained from surveys.  We found that the monthly numbers of visitors to the Cairngorms National Park in Scotland obtained through surveys corresponded to the monthly numbers of people taking photographs in the Cairngorms National Park and sharing them on Flickr. Since not all tourists are social media users, there are fewer Flickr users than visitors, but the trends showed by the two datasets are very similar.  We found the same correspondence between the spatial distribution of geotagged Flickr photographs of wildlife taken in Scotland and the spatial patterns of wildlife watching activities according to an online Scotland-wide survey. Moreover, this relationship was true down to an area as small as 10km. All the data used in this study are publicly available and were downloaded following the terms and conditions of the data provider (in this case Flickr). We did not use the actual photographs but only the data associated with them, which was completely anonymised so as to avoid any privacy issues. By mapping where the most Flickr nature photographs were taken, we could then identify some of the most popular wildlife watching destinations in Scotland – and thus where certain species might face added pressure from tourism. Chanonry Point in the Moray Firth, for example, was identified as a hotspot for Flickr photographs of dolphins – and the beach is indeed one of the best locations in the UK to watch bottlenose dolphins from land, as is Aberdeen, which was also a hotspot for Flickr images of the mammals.  Meanwhile, a map of Flickr photographs of seals showed, among other locations, Forvie Nature Reserve in Aberdeenshire as a hotspot. This is an official seal haul-out site (a site on land where seals come ashore for resting, moulting or breeding) that now holds more than 1,000 grey seals.  Now we know that these areas are home to large numbers of animals and attract significant numbers of people eager to view them – so it is important to monitor these sites to avoid impacts on the wildlife. The first obstacle on the path to managing nature tourism sustainably can be overcome by harnessing the power of the internet and social media. We can use this data to identify areas where wildlife is under strong pressure from recreational activities and intervene, perhaps preventing any significant impacts on the wildlife. We can also investigate whether nature recreation is helping countries to achieve biodiversity and sustainability targets, such as the United Nations Sustainable Development Goals. For example, we can look for associations between nature tourism growth and progress towards biodiversity and sustainability goals in different countries. Wildlife watching is always an exciting experience and I want the next generations to be able to enjoy it. In order to preserve the wildlife and the industry that relies on it, we need to put more effort into designing effective management strategies that will lead to sustainable nature tourism. Social media could be an effective way to do this."
"The saying goes that the Taj Mahal is pinkish in the morning, milky white in the evening, and golden when the moon shines. Though this may once have been true for the famously pristine marble monument, a mixture of pollution and poor management has now burdened the Taj with a 24-hour layer of yellowy-brown. Condemning the “lethargy” of restoration efforts, India’s Supreme Court recently told the government to restore the Taj  or demolish it. Located in Agra, in the northern Indian state of Uttar Pradesh, the Taj Mahal is one of the most iconically beautiful buildings in the world. Built by Mughal Emperor Shah Jahan as a testament to his grief, following the death of his first wife Mumtaz Mahal, Rabindranath Tagore called it “a tear running down the cheek of time”. The Taj was constructed of translucent white marble, brought to Agra from the north-west Indian region of Rajasthan. It was then inlaid with semiprecious stones, including jasper, jade, turquoise, lapis lazuli, sapphire and carnelian. The whole riverside complex, including the gardens and surrounding sandstone walls, was finished in 1653. Over the last four centuries the Taj has aged and darkened as a result of natural oxidation processes – the marble equivalent of rust – but it has been given no help by its hostile surroundings. It has been drenched in acid rain, coated in soot from industrial and domestic chimneys, and eroded by atmospheric pollutants. Air pollution in Indian cities is legendary, and Agra is no exception. As in many Asian cities, increasing car ownership has caused traffic to surge, while dirty air seeps from Agra’s oil refinery and tannery chimneys. These pollutants – sulphur dioxide, Nox gases, and mainly carbon-based particulates – have steadily weathered and eroded the Taj’s brilliant white façade, giving it a yellow sheen. Despite the establishment of a 4,000 square mile protective area around the site, (the Taj Trapezium Zone), within which emissions are supposedly strictly controlled, photographs show a marked deterioration in the Taj’s condition over the last few years.  Legal emission limits have been long contested by developers, and are widely ignored. Smoky funeral pyres are lit, and piles of rubbish are regularly burned very close to the buildings. Pollution from the Yamuna River presents a further challenge. Untreated sewage and industrial waste pours in from the city, creating nutrient-rich waters. These nutrients are then picked up by the wind and deposited in the Taj’s increasingly porous stonework, allowing river-derived microorganisms to thrive on its surfaces, colouring them green.  Allegedly, excrement from the many insects that thrive in the contaminated river water has hastened the damage, but the effect is surely negligible compared to that of fossil fuel-derived sulphur dioxide and nitrogen dioxide. Since 1998, a range of Indian research institutes have explored restoration methods, and millions have been spent trying to reverse the discolouration. One attempt involved smothering the Taj with damp clay poultices similar to face packs. It was hoped they would draw the damaging acids out of the surface layers of marble, but, if anything, they seem to have made the situation worse. In London, some 50 years after the completion of the Taj Mahal, Sir Christopher Wren designed a structure of comparable ambition. St Paul’s Cathedral was finished around 1711, a resting place for the nation’s great and good, and was built from the light-coloured, calcerous rock, Portland Stone. St Paul’s has suffered many of the same problems as the Taj Mahal – acid rain, soot, atmospheric pollutants, darkening with age. But after 40 years of monitoring by teams of university geographers, employing scientific techniques such as repeated observation with microerosion meters, the extent of the weathering is far better understood Older British readers may recall the infamous smogs that engulfed Britain’s cities in the 1940s and 50s. Four hundred years of coal-powered domestic heating, and latterly the fumes emanating from vehicles and coal-fired power stations, allowed sulphur dioxide and fine particles of carbon to reach toxic levels in London’s air. On cold, still autumn evenings, dense chemical smog can do as much damage to calcerous or chalky stone as it can to people’s lungs. Combined with rainfall it creates weak sulphuric or nitric acid, which over centuries can erode calcareous stone. When St. Paul’s was closely examined in the 1980s, some of the parapets and carvings had crumbled away completely leaving stone surfaces held together by black sooty crusts, hiding the voids beneath.  The worst excesses of soot and sulphur dioxide have been curbed by environmental legislation, though the atmospheric nitrogen produced by traffic, particularly diesel vehicles, still causes problems. Like Agra, London regularly breaks the World Health Organisation limits on air pollution.  However, the rate of weathering on St Paul’s seems to have halved with the fall in atmospheric sulphur dioxide. Concerns remain over microflora growing on stone surfaces, but sensitive cleaning and the odd replacement stone have largely protected Wren’s legacy. It remains to be seen whether the Taj can be similarly restored. The Taj Mahal is a wonder of the modern world, but this national and international treasure needs swift and decisive action if it is not to lose its legendary lustre."
"Moderate Liberals have seized on Scott Morrison’s apparent shift on climate change policy to argue the government will do more to cut emissions, as some conservatives push back against any “symbolism” that could damage the economy. In a sign of the challenge facing the prime minister as he seeks to “evolve” climate change policy, government MPs have split over the prime minister’s comments on the weekend that the Coalition wanted to reduce emissions “even further” than current commitments.  While saying Australia’s 2030 emission reduction targets remain government policy, Morrison said he wanted to do “better” and would only rely on the use of carryover credits from the Kyoto protocol if needed. Australia is the only country relying on carryover credits to meet its Paris 2030 target of 26% to 28% of 2005 levels by 2030, which critics say do not represent the cuts required to limit global warming to as close to 1.5C as possible. Katie Allen, the Liberal MP for the Victorian seat of Higgins, welcomed Morrison’s remarks, telling her constituents that she would be a “strong voice” in the party room for stronger action on climate change. “I’m excited we are starting to move in the right direction – but we have a lot more to do,” Allen told her supporters on Facebook. “I have been and will continue to be a strong voice for Climate Action inside the tents.” When asked if she supported the aim of net zero emissions by 2050 and lifting “clean energy ambitions” in line with the global efforts to keep the world below 1.5C warming, Allen said she agreed more needed to be done. “I’m working on influencing that agenda. We need to have higher ambitions to lead the world in renewables – not just to drive down our own emissions but help other countries with theirs,” Allen said. “We have a diplomatic strength that should be used to help strengthen the global agenda on climate action.” The self-styled modern Liberal MP Tim Wilson also endorsed Morrison’s comments, saying the commitment at the last election to “cut emissions, but not jobs” was a baseline for action. “The prime minister has rightly identified there’ll be more evolution of policy to cut emissions, but not jobs, and I look forward to contributing to that important evolution,” Wilson told Guardian Australia. Dave Sharma, the MP for Malcolm Turnbull’s former seat of Wentworth, said he was “pleased to hear” Morrison’s comments on the importance of responding to climate change and promoted the government’s plan to “continue to evolve our policies with a view to reducing our emissions further”. Does climate change cause bushfires? The link between rising greenhouse gas emissions and increased bushfire risk is complex but, according to major science agencies, clear. Climate change does not create bushfires, but it can and does make them worse. A number of factors contribute to bushfire risk, including temperature, fuel load, dryness, wind speed and humidity.  What is the evidence on rising temperatures?  The Bureau of Meteorology and the CSIRO say Australia has warmed by 1C since 1910 and temperatures will increase in the future. The Intergovernmental Panel on Climate Change says it is extremely likely increased atmospheric concentrations of greenhouse gases since the mid-20th century is the main reason it is getting hotter. The Bushfire and Natural Hazards research centre says the variability of normal events sits on top of that. Warmer weather increases the number of days each year on which there is high or extreme bushfire risk. What other effects do carbon emissions have? Dry fuel load - the amount of forest and scrub available to burn - has been linked to rising emissions. Under the right conditions, carbon dioxide acts as a kind of fertiliser that increases plant growth.  So is climate change making everything dryer?  Dryness is more complicated. Complex computer models have not found a consistent climate change signal linked to rising CO2 in the decline in rain that has produced the current eastern Australian drought. But higher temperatures accelerate evaporation. They also extend the growing season for vegetation in many regions, leading to greater transpiration (the process by which water is drawn from the soil and evaporated from plant leaves and flowers). The result is that soils, vegetation and the air may be drier than they would have been with the same amount of rainfall in the past. What do recent weather patterns show? The year coming into the 2019-20 summer has been unusually warm and dry for large parts of Australia. Above average temperatures now occur most years and 2019 has been the fifth driest start to the year on record, and the driest since 1970. Is arson a factor in this year's extreme bushfires? Not a significant one. Two pieces of disinformation, that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush have spread across social media. They have found their way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. Another moderate Liberal, Jason Falinski, said the party would continue to “drive responsible policy on climate change”. “We need practical and sensible policy here and seek ambitious action globally,” he said. But as moderates welcomed the shift, conservative MPs were warning against a change in policy. The Queensland Nationals MP Llew O’Brien told the Courier Mail that if Australia went beyond its current commitments, it would be “pure symbolism at the expense of the economy”. The former Nationals leader Barnaby Joyce also issued a thinly veiled warning that the government risked a backlash in the bush if it moved to ramp up emission reduction targets. “To the person in the weatherboard and iron, the solution is not: you’ll lose your job and we’ll put up your power prices, because that is not a solution, that is another problem,” Joyce told Guardian Australia. Joyce said the royal commission into the bushfires needed to be “absolutely pragmatic” in its focus, looking at how to prevent a repeat of the crisis without straying to “global” issues. “If it goes off on a path of a macro global view, it will not ultimately bring people together, it will tear people apart,” he said. “Global outcomes must be managed globally.” The divide comes as Morrison insists the role of climate change is “not in dispute” within his ranks, despite several MPs denying the role of a warmer planet as an underlying cause of the severe bushfire season. The Nationals MP George Christensen was the latest to promote his view that climate change was not a factor, telling his supporters on Facebook that climate change is not “a bogey man who can go around lighting bushfires”. “I post this because those who are politicising this tragedy by pushing their extreme green political agenda while the fires still burn absolutely disgust me,” he said. The Liberal MP Craig Kelly last week caused a storm of controversy after appearing on UK television to argue that there was “no link” between climate change and Australia’s drought. Following the appearance, Morrison told his MPs that backbenchers should not do any international media interviews."
"
Share this...FacebookTwitterA new paper documents “remarkably different” land temperatures from one instrumental data set to another. In some regions there is as much as an 0.8°C conflict in recorded temperature anomalies for CRU, NASA, BEST, and NOAA. The relative temperature trend differences can reach 90% when comparing instrumental records. Consequently, the uncertainty in instrumental temperature trends — “0.097–0.305°C per decade for recent decades (i.e., 1981–2017)” —  is as large or larger than the alleged overall warming trend itself for this period.

In a just-published audit of the IPCC-preferred HadCRUT temperature data set, Dr. John McClean identified 70 problems that seriously compromise the reliability and accuracy of this IPCC-preferred instrumental record dating back to 1850.
Joanne Nova provides a summary of the main points from the paper, McLean’s Ph.D thesis.



McLean found freakishly improbable data, and systematic adjustment errors , large gaps where there is no data, location errors, Fahrenheit temperatures reported as Celsius, and spelling errors.


Almost no quality control checks have been done: outliers that are obvious mistakes have not been corrected – one town in Columbia spent three months in 1978 at an average daily temperature of over 80 degrees C.  One town in Romania stepped out from summer in 1953 straight into a month of Spring at minus 46°C. These are supposedly “average” temperatures for a full month at a time. St Kitts, a Caribbean island, was recorded at 0°C for a whole month, and twice!


Temperatures for the entire Southern Hemisphere in 1850 and for the next three years are calculated from just one site in Indonesia and some random ships.


Sea surface temperatures represent 70% of the Earth’s surface, but some measurements come from ships which are logged at locations 100km inland. Others are in harbors which are hardly representative of the open ocean.



Are Any Of The Temperature Data Sets Reliable? 
A new paper published in the Journal of Geophysical Research reveals that the recorded land temperature data from the four most commonly-referenced instrumental data sets — CRU, NASA, BEST, and NOAA — are “remarkably different” from one another.
In fact, the authors find that “for some areas, different data sets produce conflicting results of whether warming exists” due especially to variations in the use of “infilling techniques” — adding artificial temperatures to areas where there are no real-world measurements.
One data set trend can be “nearly 90%” different than another data set trend, which ratchets up the uncertainty to levels that undermine confidence in the overall reliability of the instrumental record.
Excerpts from the paper’s abstract and discussion/conclusion are provided below.


Rao et al., 2018
Land Surface Air Temperature Data Are Considerably Different
Among BEST‐LAND, CRU‐TEM4v, NASA‐GISS, and NOAA‐NCEI
“Several groups routinely produce gridded land surface air temperature (LSAT) data sets using station measurements to assess the status and impact of climate change. The Intergovernmental Panel on Climate Change Fifth Assessment Report suggests that estimated global and hemispheric mean LSAT trends of different data sets are consistent. However, less attention has been paid to the intercomparison at local/regional scales, which is important for local/regional studies. In this study we comprehensively compare four data sets at different spatial and temporal scales, including Berkley Earth Surface Temperature land surface air temperature data set (BEST‐LAND), Climate Research Unit Temperature Data Set version 4 (CRU‐TEM4v), National Aeronautics and Space Administration Goddard Institute for Space Studies data (NASA‐GISS), and data provided by National Oceanic and Atmospheric Administration National Center for Environmental Information (NOAA‐NCEI). The mean LSAT [land surface air temperature] anomalies are remarkably different because of the data coverage differences, with the magnitude nearly 0.4°C for the global and Northern Hemisphere and 0.6°C for the Southern Hemisphere.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“This study additionally finds that on the regional scale, northern high latitudes, southern middle‐to‐high latitudes, and the equator show the largest differences nearly 0.8°C.”
“These differences cause notable differences for the trend calculation at regional scales. At the local scale, four data sets show significant variations over South America, Africa, Maritime Continent, central Australia, and Antarctica, which leads to remarkable differences in the local trend analysis. For some areas, different data sets produce conflicting results of whether warming exists.”
“Our analysis shows that the differences across scales are associated with the availability of stations and the use of infilling techniques. Our results suggest that conventional LSAT data sets using only station observations have large uncertainties across scales, especially over station‐sparse areas.”
“The relative difference of trends estimated from different data sets can reach nearly 90% for different regions and time periods. CRU-TEM4v generally appears to have the largest grid box scale differences, while NASA-GISS has the smallest differences compared to BEST-LAND.”
“The uncertainty of the LSAT [land surface air temperature] trend estimation caused by the data set differences (i.e., RMSD) ranges from 0.035 to 0.086°C per decade for the long-term trend (i.e., 1901–2017) to 0.097–0.305°C per decade for recent decades (i.e., 1981–2017).”
“In developing future LSAT data sets, the data uncertainty caused by limited and unevenly distributed station observations must be reduced.”

Image Source: Rao et al., 2018
Share this...FacebookTwitter "
"Global engineering company Siemens will not pull out of a contract at the new Adani coalmine in Australia, rejecting calls from climate campaigners including Greta Thunberg. President and CEO of Siemens, Joe Kaeser, announced Monday that after reviewing the rail signalling contract the company had “a legally binding and enforceable fiduciary responsibility.”  He said: “While I do have a lot of empathy for environmental matters, I do need to balance different interests of different stakeholders, as long as they have lawful legitimation for what they do.” He said the company, based in Germany, “should have been wiser about this project beforehand” and claimed had it been his own company, he may have “acted differently”. He added that the company “fundamentally shares the goal of making fossil fuels redundant to our economies over time”. Campaigners said the decision was “shameful” and would damage its reputation and undermine its own climate policies. Siemens says it is one of the first companies to have pledged to be carbon neutral by 2030. The decision on the contract, reportedly worth $30m, comes as Australia is in the grip of an unprecedented bushfire crisis that has claimed at least 27 lives, destroyed more than 2,000 homes and likely pushed several species towards extinction, scorching millions of hectares of unique habitat and killing more than a billion animals. Explaining his decision, Kaeser said he was assured by a December 2019 letter from Resources Minister Matt Canavan that the mine, in Queensland’s Galilee Basin, had passed all legal obstacles. Just finished our extraordinary Managing Board Meeting. We evaluated all options and concluded: We need to fulfil our contractual obligations. Also, we will establish an effective Sustainability Board to better manage environmental care in the future. https://t.co/uPgjPgwFrr Canavan wrote to Kaeser in December with a plea “not to be intimidated by the noisy anti-coal minority targeting the Adani Carmichael mine project and companies providing services to it.” He wrote: “If the protestors achieve their goals of ending coalmining by bullying companies into submission, the result would be millions more people without a home, without access to electricity and without as much hope as they otherwise could have.” In the statement, he said the project was also “approved” by the indigenous Wangan and Jagalingou people which was “very important to us”. That approval is strongly disputed by a group of Wangan and Jagalingou people. Adani took court action to prevent that group, led by Adrian Burragubba, from setting up camp on the land. The Queensland Government in 2019 extinguished native title over Wangan and Jagalingou to enable the mining project to proceed. Kaeser said he was personally “moved” by messages from Australians who had “described that their homes and their country is burning and suffering from these terrible fires”. The Adani coalmine will extract an initial 10m tonnes of thermal coal per year from a site 300km inland and transport it along a railway line to Adani’s Abbot Point Port for export. Kaeser said there were competitors to the railway signalling contract the company signed on 10 December 2019, which meant “whether or not Siemens provides the signaling, the project will still go ahead”. Last week Swedish climate activist Greta Thunberg said Siemens had “the power to stop, delay or at least interrupt the building of the huge Adani coalmine in Australia” and people should push the company “to make the only right decision”. It seems that @SiemensDE have the power to stop, delay or at least interrupt the building of the huge Adani coal mine in Australia. On Monday they will announce their decision. Please help pushing them to make the only right decision. #StopAdani Greens leader Richard Di Natale had also written to Siemens, and warned the company risked “reputational damage” over the deal. Galilee Blockade spokesperson Ben Pennings said: “Siemens has just trashed their billion dollar reputation for a $30m contract. Their reckless indifference to the suffering of Australians will be judged harshly, now and in the history books.” “Siemens’ expertise is vital to the Adani coal railway and there is too much at stake to give up. Citizens will escalate their protests until Siemens listens to the science and choose the right side of history. “Adani will never have social licence to build a new thermal coalmine in Australia. Our challenge is to turn this discontent into civil disobedience powerful enough to overcome any government repression.” Australian Conservation Foundation senior campaigner Christian Slattery said the Siemens announcement, “while bushfires rage in Australia, is nothing short of shameful”. He said: “The company has shown its true colours with this decision. It has a climate change policy, but it is hollow and empty. Sadly, Siemens has shown it is no better than the fossil fuel companies it works with.” The Galilee Basin has been identified as one of the largest untapped sources of coal in the world, and campaigners and scientists have warned the Adani mine will open the way to several other coal mining projects in the region. Slattery added: “If constructed, the infrastructure for Adani’s mine will open the Galilee Basin to one of the largest expansions of thermal coal mining on the planet. “Siemens claims to support the Paris Agreement, but now it is committed to work on one of the world’s biggest carbon bombs.” “The unfolding bushfire crisis in Australia, which has killed at least 28 people and more than one billion native animals is a terrifying foretaste of the climate change future if more coal mines are dug.” An Adani spokesperson said: “We are pleased to be working with Siemens as the company is known for its exceptional experience in building rail signalling infrastructure around the world. “With construction of the Carmichael Project well and truly under way we have repeatedly demonstrated that we will not be intimidated or deterred from delivering on our promises to regional Queenslanders, Australians and people in developing nations who desperately need affordable energy to help lift them out of poverty.”"
"
Share this...FacebookTwitterAs Germany moves to phase out coal power, more focus is being placed on relying on wind energy to fill in the gap.
Recently German business daily Handelsblatt here reported that despite the country adding more wind energy capacity, “the latest figures show that only a little wind power is available at any time.”
According to the German BWE wind energy group, 29,900 wind turbines are currently operating in the country with a total capcity of 56,000 megawatts. Wind energy makes up 18.8% of the country’s power supply.
Glaring weaknesses
But the Handelsblatt reports there are “glaring weaknesses” and that wind turbines cannot be relied on to deliver steady power when it’s needed.
According to Oliver Then, Managing Director of the VGB PowerTech Association, citing recent research results which the Handelsblatt has obtained: “The actual production figures show that the readily available wind power capacity in Germany is less than one percent of installed capacity.”
Back up absolutely necessary
According to the Handelsblatt, VGB PowerTech evaluated 2016 data from a number of European countries, and reports that the message is clear:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Even if the expansion of wind power progresses rapidly, there will always have to be back-up capacity, for example in the form of fossil power plants.” 
VGB Director Oliver Then says that as more and more green energies get fed in, the less gas and fossil fuels plants operate, and thus making them no longer profitable. Yet they remain absolutely essential to keep the grid stable.
Can rely on neighboring countries?
Proponents of green energies who support a rapid fossil fuel phaseout insist that it can be done, and that Germany would only need to rely increasingly on a power supply from neighboring countries. When the wind is not blowing in Germany, power could be imported from another country where the wind is blowing.
But VGB Director Oliver Then says the data do not support this claim in any way, adding, “Power production is strongly synchronous over great distances.”
This means that if wind lacks in Germany, it often lacks in Poland as well and so neighbors cannot be relied on to provide electricity.
Pump storage not feasible
Pump storage as a way to store energy is also not feasible says Then, saying it would need to be increased 1000 fold, which would entail enormous costs. Then notes that periods of no wind extending two weeks are not uncommon in Germany.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterEarlier this year in Ljubljana, Slovenia, acoustics and health expert Dr. Mariana Alves Pereira explained the impacts low frequency infrasound can have on health. It’s far from pretty.
Infrasound is very low frequency (<20 Hz) and is below the threshold of human hearing. It is sensed by the human ear only as pressure waves.
Hat tip: Reader Jim Feasel
Dr. Alves Pereira has a Masters in Biomedical Engineering and a PhD in Environmental Sciences.

“It’s a problem to human health”
In her presentation she explains to the audience that because infrasound is of very low frequency, the wavelengths are very long and thus can easily penetrate thick barriers and into buildings. “This is why it’s a problem to human health.” The waves travel kilometers and are difficult to shield against.
Governments rely on inadequate measurements
The acoustic expert also describes why the dBA scale is inadequate for measuring infrasound and thus are irrelevant for their evaluation.
At the 12:30 mark she uses the example of a mink farm in Denmark located near a wind park and so is thus subjected to “acoustic pollution” from the wind turbines. Here she demonstrates how woefully inadequate the methods and measurements often used by permitting authorities for assessing acoustic pollution really are.
Neurological and cardiovascular damage


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Later she illustrates how damaging infrasound can be to human health. For example aviation workers have a risk of epilepsy (a neurological problem) that is some 50 times higher than average (22:00) for the occupation and how workers had tumors, and cardiovascular disease from abnormal tissue growth caused by infrasound exposure.
At 33:09 mark, Dr. Alves Pereira presents the clinical stages of vibroacoustic disease for occupational exposures. Workers exposed to infrasound more than 10 years developed severe health damage, e.g. psychiatric disturbances, severe joint and muscle pain, blood in the urine or decreased vision, among others.
Horses near wind turbines developed “boxy foot”
At the 43:00 mark, Dr. Alves Pereira explains how at first they were skeptical of claims made by patients that infrasound had made them sick while at home. In 2000 her team began to look at the claims and found that non-occupational residents who were subjected long-term to infrasound indeed got sick.
At the 48:08 mark, Dr. Alves Pereira turns her attention to wind turbines.
In one example, in Portugal 4 wind turbines were installed within 800 meters of a home and began operation in November, 2006. Five months later in March 2007 the family members in the home were suffering serious health issues and the boy’s performance at school crashed. His energy had been sapped. The horses the family owned developed “boxy foot”.
Moreover, the previously mentioned mink farm in Denamrk suddenly saw hundreds of aborted fetuses (53:30), all caused by infrasound from the nearby wind turbines, experts suspect.
Post traumatic stress syndrome
At the 56:00 mark, Dr. Alves Pereira shows a home in Germany surrounded on two sides by wind turbines located less than 2000 meters away. When the family moved into the home, there had been only two turbines, but then came dozens of new turbines. The family was forced to convert into a bunker in a desparate attempt to shield themselves.
In Ireland a 9-year old child developed epilepsy and the 19-year old brother wound up with post-traumatic stress syndrome (PTSD) – as did the worker at the mink farm in Denmark. The house in Ireland had to be abandoned.
Dr. Alves Pereira sums up: “I know it’s kind of depressing, but these are the scientific facts what we have over 30 years of research.”
Share this...FacebookTwitter "
"If global temperatures are allowed to rise by 2℃, we face creating a “Hothouse Earth” that would shift the planet to an irreversible state, a recent research paper warns. This has provoked a global frenzy in social, news and print media reminiscent of the planetary emergency professed by Al Gore a decade ago. Only this time climate scientists, and not politicians, are the ones causing the storm.  The research is compelling, but the arguments are hardly new. We’ve long known that Earth systems require extensive human intervention, that nature will not redress the balance itself. We already know of the planetary boundaries and, thanks to our unsustainable practices, how crossing certain thresholds of natural resources (fresh water, land use, and biodiversity loss) and environmental variables (atmospheric aerosols, biochemical flows and ozone depletion) could lead to tipping the Earth’s systems out of balance. Nonetheless, the idea of Hothouse Earth has taken off. This is a good thing in terms of raising awareness and triggering global concerns and subsequent actions for integrated climate governance. But such accounts often fail to consider the political climate of the day. 


      Read more:
      Hothouse Earth: here's what the science actually does – and doesn't – say


 Ongoing austerity measures in the aftermath of the 2007-08 financial meltdown mean that states are divesting from their responsibilities on welfare, making way for supposedly “caring” forms of market-based mechanisms. Short-term policies of “doing more with less” have also affected civil society as many organisations that rely on government funding are either disappearing or struggling to sustain their causes.  Meanwhile, this research could not have come at any better (or worse) time with the prolonged spells of heatwaves around the world. And studies suggest that public perceptions of environmental hazards fluctuate with the proximities and experiences of climatic events.  But if not carefully interpreted, claims of doom and gloom scenarios can polarise public and political opinions. Much scientific research of this ilk, and certainly the vast majority of the media coverage about it, fails to appreciate the potential of individual people in tackling environmental issues. The same is true of many politicians, who consider environmental sustainability too serious a task to be trusted to people.  As a result, communities - although recognised as vulnerable to the effects of disappearing forests, warming oceans and melting ice sheets - remain absent from the decision-making processes and the proposed solutions. But community-based actions can be incredibly powerful, when harnessed.  There are various meaningful actions and initiatives that can be spearheaded by people in their communities. And in this time of political disengagement from the issue, it’s more important than ever that we do so. While 1% of us may be able to consider their options for relocating to more hospitable places on Earth (Silicon valley billionaires are buying up property in New Zealand), or relatively less hospitable locations on the moon and Mars, the others will have to do something, now.  Among the steps that can be taken immediately, you could consider: Not just attitudes and behaviours, we need to reconsider how we live our everyday lives. As we become more knowledgeable about the state of nature in our surroundings with deteriorating air, soil and water conditions, we need to think about changing the way we our families and our friends are contributing to the environment. Opt for an organic or vegetarian diet, support Fairtrade, and purchase locally sourced goods where you can. Growing fruit or vegetables in your front or back gardens, or in pots indoors, will not only liven up your living space and provide you with fresh, local produce. The increased photosynthesis increases carbon sink and contributes to reducing greenhouse gases. Even more so, do it as a community. Many local authorities are now encourage the greening of the abandoned lands and derelict areas.  Or better still, start one. Transition Network is a good example of actions based on voluntary individual and collective participation. It began as a permaculture movement to reduce fossil fuels dependence, growing own food, sourcing locally, and promoting social inclusion. Today it is one of the largest community-based networks, with presence all over the world. Many towns and cities are now promoting different kinds of bike ride or sharing schemes. Sustainable transport solutions can help decrease car dependence besides reducing carbon footprint. Citizen science is increasingly becoming a valuable way of community-sourced and voluntary participation and research in all scientific disciplines. Contributions from everyday lives of citizens help scientists get out of their silos and find better solutions to complex and wicked problems. Most of the political parties on a broad range of spectrum now understand and support the need for sustainable and healthy lifestyles to make our places better in social, economic and environmental terms. But political agendas are a reflection of what people demand. And what better way to empower ourselves than to use our voting rights responsibly? Local and national governments are committed to improving the environment. Many towns and cities have signed up for the Covenant of Mayors, voluntarily agreeing to reduce emissions and using sustainable energy sources. Surprisingly, not many countries have sufficient legal structures in place for climate action. Among national strategies, the Well-being of Future Generations Act in Wales is often quoted as an exemplar of good policy and practice."
"
Share this...FacebookTwitterThe weather models are all now pointing to wintry weather pushing into Europe next week, after a year of near record warm temperatures. Is a cold winter in store?
German skeptic weather and climate blogger Schneefan (Snow Fan) here writes that the winter most likely will be starting early this year, but it remains a question if the colder, more wintery conditions will persist throughout the winter.
The current low solar activity favors it will, as studies show Europe’s winters turn harsher when solar activity is quiet. Over the past few days, the models have been in agreement in showing that cold wintry weather is approaching in the days ahead.
Schneefan writes that the big 3 weather models ECMWF (Europe), GFS (USA) and GEM (Canada) have all been projecting the same development:

Shown above are the prognoses dated 10 November, 2018, from ECMWF (Europe), GFS (USA) and GEM (Canada) for the 20th of November. Source: Wetterzentrale
Yesterday the three models forecast the following for November 19:

Source: Wetterzentrale
The stratospheric models from ECMWF und GFS also point to an early wintery weather pattern change, with a large trough extending over the entire Mediterranean and an extensive high over Scandinavia and Northern Russia:

Comparison of the ECMWF (150 hPa, 14 km altitude) and GFS (100 hPa, about 16 km altitude) prognoses November 20. This unusual large weather pattern signifies a change in the wind patterns and favor cold Russian air moving over Europe . If the models are right, it would mean an early start for winter in Europe. Source: ECMWF and GFS.
WO/GFS already foresees frost for Eastern Europe this weekend:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





 

Snow is also forecast to spread across large regions of eastern Europe early next week:



Large parts of Germany and Europe could see snow cover at the end of November:

Schneefan writes that the conditions could be similar to those seen in the winters of 2005/06 and 2010/11. One reason, Schneefan writes:
We now find ourselves in a multiple-year solar minimum of weak solar cycles that is the weakest in the last  200 years.
Just recently the GFS06 showing a northern position (Greenland/Atlantic blocking) and further massive winter invasions from the north on November 29, 2018.

So while Europe may be enjoying agreeable mild weather for now, models show that it may very well end abruptly. Preparations for winter should be done over the coming days.
Global warming eliminating snow and ice remains a myth. Soon expect to hear warmist scientists claim the cold is due to the warming causing polar vortices. Don’t buy the nonsense. It’s BS science.
The truth is that this is just winter as usual, and the climate has not really changed that much.
Share this...FacebookTwitter "
"There is still time to donate to the Observer and Guardian climate emergency charity appeal, which has raised more than £875,000 for projects designed to plant, protect and renew trees, woodlands and forests. More than 11,000 readers have so far given to the appeal, which promotes environmental and social justice through natural climate solutions, from safeguarding rainforests in the Amazon basin to rewilding the Scottish Highlands and greening Britain’s towns, cities and countryside. The appeal closes at midnight on Sunday 12 January.  The four charities supported through the appeal are: Woodland Trust, Trees for Life, Trees for Cities and Global Greengrants Fund UK. David Elliott, chief executive of Trees for Cities, said: “We are inspired and humbled by the amazing level of engagement that readers have shown for this appeal. Their support will significantly help our organisations create a landscape shift – in more than one sense – that is so urgently and vitally needed. Restoring and protecting our natural environment is one of the most effective actions we can take to push back against the escalating impacts of the climate crisis.” Cristina Orpheo, of Global Greengrants Fund’s local partner in Brazil, CASA Socio-Environmental Fund, said: “Many thanks to all who responded to the Guardian and Observer charity appeal. The funds designated for Global Greengrants Fund and its partners will be used to support traditional communities and improve their living conditions so that they have a better chance of promoting the preservation and protection of this great biome for future generations.” Scores of donors have left online messages explaining why they gave to the appeal. Many said it was to signal their frustration with governments’ failure to take the climate crisis seriously, and the slow institutional political response to what they considered to be the most important issue facing the planet. One reader said: “At a time that feels very bleak, these projects not only offer some comfort, but powerful examples of how we can overcome our individual despair and seek to build a better future together.” • The appeal ends at midnight on Sunday 12 January. Readers can donate online here or send a cheque (payable to the Guardian and Observer charity appeal 2019) to: The Guardian and Observer charity appeal 2019, Charities Trust, Suite 20-22, Century Building, Tower Street, Liverpool L3 4BJ."
"Comparisons have been made between summer 2018 and Britain’s record breaking heatwave of 1976, which is often hailed as being unprecedented for how hot and dry it was. June 2018 has not only been the hottest since 1976, it is one of the driest on record. For those that love the summer sunshine and see rain as the source of a washed out BBQ, this is welcome news. But 1976 was also famous for the drought that left fields brown and made life extremely difficult for farmers, ultimately affecting the country’s food supply. A closer look at the conditions in 1976 shows why farmers (and shoppers) today are likely to be better off in the face of a prolonged, extremely hot and dry summer. Certainly, widespread reports of crops wilting in the heat has raised concerns that there could be widespread food shortages. For example, vegetables like broccoli, cauliflowers and notably salad crops like lettuces have already been affected. There are also fears that there may be a shortage of potatoes (and in turn crisps) due to a combination of the cold weather that affected Britain earlier in the year and the current heatwave.  June 1976 brought vegetable shortages and astronomically high prices for some items, particularly for potatoes. The year is also remembered because the Labour government at the time was forced to introduce food subsidies in a desperate attempt to keep down the cost of living. Official files held at The National Archives, contemporary reports and the farming press reveal the devastating impact the drought had on agricultural production, as well as the extent to which shortages led to a rapid increase in prices.  Potatoes are shallow-rooted plants which are sensitive to even small deficiencies of water in the root zone. When moisture stress occurs, as evidenced by the wilting of the leaves, the growth rate is significantly reduced, which in turn affects both their quality and yield. In the 1970s, unlike today, irrigation was limited to a small number of farmers. Potato crops were therefore subject to severe water shortages, which led to very slow growth, particularly for those crops being grown on more drought-prone lighter soils. So, while the dry winter of 1975-76 had enabled potatoes and horticultural crops to be planted early, the ground was already suffering from a moisture deficit. In 1976 although many food prices rose significantly, the increases were dwarfed by the exponential rise in the price of potatoes, with production down by approximately 40%. Given the relatively constant demand for potatoes by mid to late winter, prices were six times higher than what they were in a normal season. But price hikes of this magnitude are less likely to occur today. British consumers are not as dependent on potatoes as a staple item of their diet as they were in the 1970s due to the availability of alternative starchy foods like pasta and rice. Today farmers are better able to irrigate their crops, enabling them to mitigate some of the worst effects of the present exceptionally dry conditions. There are still issues of concern, though. Notably that in 2018 many main crop potatoes were planted late because of the cold, wet spring. Nonetheless, it is highly likely that the unprecedented price rises experienced following the 1976 drought will not be repeated. When the drought finally ended at the end of August 1976, September turned out to be abnormally wet, with high rainfall continuing throughout the autumn. This was significant in how it affected the crops when the rain finally came. The onset of rain led to a secondary growth of potatoes. The existing potatoes, instead of being able to use the moisture to grow, produced small new potatoes of their own.  The wet autumn of 1976 not only delayed the harvesting of the potato crops, but meant much of the crop went into store wet and ill-suited for long term keeping. It was the combination of factors taking place in the autumn which led to the later high prices for potatoes. In spite of the present drought, it is highly unlikely that the shortages will be as bad as those that occurred in the 1976. It is probable that even if the present dry hot weather continues it will not produce a repeat quite of the magnitude of the food price hikes which occurred in 1976. These reflected not only the impact of the west European drought but also international factors, in particular an El Niño induced reduction in world food production. This is not to say that food prices, particularly for potatoes, will not be affected. But the significance of the price rises will likely be considerably less than in 1976. Nevertheless, based on the experiences of 1976, the price rises may not be confined to a single year – it all depends on how the weather changes in the months to come."
"
Share this...FacebookTwitterRecently we’ve been hearing about how cold it’s been over much of North America, for example how Houston saw its earliest snowfall on record!
Well, it appears that the early wintry conditions are getting set to take even stronger hold over the Northern Hemisphere.
Yesterday at Weatherbell’s Daily Update, veteran meteorologist Joe Bastardi showed how some 90% of North America has been well below normal temperature-wise so far this month:

Source: Weatherbell Daily Update.
In Europe, the continent has experienced a very warm summer and fall so far, but that is about to change rather dramatically — should the latest computer model generated weather forecasts pan out, and which they are expected to do.
Snow is forecast to cover much of the US and all of Canada by early next month:

Source: Weatherbell Daily Update.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Russian beast from the east
Joe says at the Daily Summary that Europe should expect “brutal cold” at the end of the current month. At the end of the video he says:
“Boy, we’ve got some interesting things going on in Europe. […] Wicked cold coming into Europe.”

Source: Weatherbell Daily Update.
Also Japanese skeptic blogger Kirye at Twitter sent me chart showing Arctic sea ice volume is back up to normal after having been a bit below normal over the past couple of months.

Source: Kirye.
Once again expect another rollout of the scientifically bogus explanation of a Arctic-warming-induced perturbed jet stream causing all the cold. Just keep in mind this is barely a hypothesis that has no data to back it up and that it mostly relies on phony models created by climate activists.
Although the globe may have warmed about half a degree, much of the Northern Hemisphere land mass will continue to see cold snows winters like it did 50 years ago. The earlier idiotic alarmist predictions are proving to be merely fantasy visions of hysterical minds.
Share this...FacebookTwitter "
nan
"When Sudan the white rhino was put down by his carers earlier this year, it confirmed the extinction of one of the savannah’s most iconic subspecies. Despite decades of effort from conservationists, including a fake Tinder profile for the animal dubbed “the most eligible bachelor in the world”, Sudan proved an unwilling mate and died – the last male of his kind. His daughter and granddaughter remain – but, barring some miraculously successful IVF, it is only a matter of time. The northern white rhino will surely be mourned, as would other stalwarts of picture books, documentaries and soft toy collections. But what about species of which of which we are less fond – or perhaps even entirely unaware? Would we grieve for obscure frogs, bothersome beetles or unsightly fungi? Extinction is, after all, inevitable in the natural world - some have even called it the “engine of evolution”. So should extinction matter to us? First of all, there are strong practical arguments against biodiversity loss. Variation, from individual genes to species, gives ecosystems resilience in the face of change. Ecosystems, in turn, hold the planet steady and provide services essential to human welfare. Forests and wetlands prevent pollutants entering our water supplies, mangroves provide coastal defence by reducing storm surges, and green spaces in urban areas lower city-dwellers’ rates of mental illness. A continued loss of biodiversity will disrupt these services even further. Seen in this light, the environmental damage caused by resource extraction and the vast changes that humans have wrought on the landscape seem extremely high risk. The world has never before experienced these disturbances all at the same time, and it is quite a gamble to assume that we can so damage our planet while at the same time maintaining the seven billion humans that live on it. Although the unregulated plundering of the Earth’s natural resources should certainly worry those brave enough to examine the evidence, it is worth specifying that extinction is an issue in its own right. Some environmental damage can be reversed, some failing ecosystems can be revived. Extinction is irrevocably final.  Studies of threatened species indicate that, by looking at their characteristics, we can predict how likely a species is to become extinct. Animals with larger bodies, for example, are more extinction-prone than those of smaller stature – and the same holds true for species at the top of the food chain. For plants, growing epiphytically (on another plant but not as a parasite) leaves them at greater risk, as does being late blooming. This means that extinction does not occur randomly across an ecosystem, but disproportionately effects similar species that perform similar functions. Given that ecosystems rely on particular groups of organisms for particular roles, such as pollination or seed dispersal, the loss of one such group could cause considerable disruption. Imagine a disease that only killed medical professionals – it would be far more devastating for society than one which killed similar numbers of people at random. This non-random pattern extends to the evolutionary “tree-of-life”. Some closely related groups of species are restricted to the same threatened locations (such as lemurs in Madagscar) or share vulnerable characteristics (such as carnivores), meaning that the evolutionary tree could lose entire branches rather than an even scattering of leaves. Some species with few close relatives, such as the aye-aye or tuatara, are also at higher risk. Their loss would disproportionately affect the shape of the tree, not to mention erasing their weird and wonderful natural history stories. The most regular counter argument contends that we should not worry about extinction, because it is a “natural process”. First of all, so is death, but it does not follow that we meekly surrender to it (especially not prematurely or at the hands of another). But secondly, fossil records show that current extinction levels are around 1,000 times the natural background rate. They are exacerbated by habitat loss, hunting, climate change and the introduction of invasive species and diseases. Amphibians seem particularly sensitive to environmental change, with estimated extinction rates up to 45,000 times their natural speed. Most of these extinctions are unrecorded, so we do not even know what species we are losing. But does it really matter that the world contains fewer types of frog? Let’s take a hypothetical small, brown African frog that becomes extinct because toxic waste pollutes its stream. The frog has never been described by science, so no one is the wiser about its loss. Putting aside disaster movie-level ecosystem collapse as a result of ongoing mass extinction, the frog’s intrinsic value is a matter of opinion. It evolved over millions of years to be adapted for its particular niche – to us, the authors, the loss of that perfectly balanced individuality makes the world a lesser place.  But it is easy to moralise about biodiversity when you don’t have to live alongside it. One person’s marvel of nature might be another person’s torment – an orangutan raiding a poor farmer’s crops, or a leopard snatching a shepherd’s livestock. Pathogens are also part of life’s rich tapestry, but how many of us mourn the eradication of smallpox? So how far should our aversion to extinction extend? We cannot answer this question – but like all good philosophical conundrums it belongs to everyone, to be debated in schools, cafes, bars and market places across the world. We may not all agree, but extinction is broadening its reach, so consensus and urgent action are needed if we hope to control it."
"
Share this...FacebookTwitterMojib Latif: three statements, three times totally off the mark
By Die kalte Sonne
(German text translated by P Gosselin)
At the end of the year, it’s usual to take a look back. That’s what we wish to do at this blog.
Leading German climate scientist Mojib Latif made three historical statements in 2012 that are worth remembering. How much truth was there in his statements of that time?
STATEMENT 1:
Mojib Latif on December 4, 2012 in the talkshow “Pelzig hält sich”:
I want to say one thing again. I would be glad if it were the sun. Then we really could do nothing. Yes. But it is not that. If you look at the sun’s radiation, the sun has been weaker for 50 years. And how is a weakening sun supposed to cause massive warming?”
False. The sun has actually become stronger in the last 50 years when one considers the total solar irradiance (TSI – white curve in the diagram), which also includes cosmic rays and the solar magnetic field.

Figure: Development of solar activity over the past 400 years. White curve shows total solar irradiance (TSI), yellow peaks mark sunspots. Source:    PAGES2K website, downloaded in 2016.
———–
STATEMENT 2:
Mojib Latif on December 4, 2012, in the talkshow “Pelzig hält sich“:
Yes, you can quantify everything. That is, of course, a plain lie if it is claimed that we do not take the sun into account. There is no climate model that does not take the sun into account. I do not think we are fools. This somehow gives the impression that we are the biggest idiots of all time. It’s not like that.”
False, Mr. Latif. A look at the radiation drive in the 5th IPCC Climate Report is enough to see that the sun plays almost no role in the models. CO2: 1.68 W/m2, sun: 0.05 W/m2. The sun is made practically as a non-factor in this.

Figure: Radiation as a driver among the individual climate factors according to the 5th IPCC report. The sun plays practically no role in the IPCC.
———–


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




STATEMENT 3:
Mojib Latif in an interview with the Neuen Osnabrücker Zeitung (NOZ) on September 12, 2012:
NOZ: Mr. Latif, does the sun more likely to contribute to global warming or the greenhouse gas carbon dioxide, CO2?
LATIF: It’s a mix of both. It is clear that man has been responsible for more than half of the rise in temperature since the beginning of industrialization.”
Just before that in the Austrian daily Austrian daily ‘Die Presse‘ (DP) on February 9, 2012, he said the following:
DIE PRESSE: Back to the previous warming, 0.8 degrees for 100 years. For [Fritz] Vahrenholt, half comes from the sun. And at the IPCC everything comes from CO2?
LATIF: No, the IPCC never said that. It is very careful and says that about half of the warming is anthropogenic.
DIE PRESSE: Then it says the same as Vahrenholt?
LATIF: Yes, that’s what drives me crazy: An exaggerated threat is built up and then torn up with great relish.”
Again Latif is wrong. Here it’s enough to just look at the Special report of the IPCC concerning the 1.5°C target:
Reflecting the long-term warming trend since pre-industrial times, the observed mean global surface temperature in the decade 2006-2015 was 0.87 °C (probably between 0.75 °C and 0.99 °C) higher than the average for the period 1850-1900 (very high confidence).
Estimated anthropogenic global warming is consistent with the extent of observed warming within ±20% (likely range).”
In other words: According to the IPCC, the total warming observed over the last 150 years is anthropogenic.
———–
Three Latif statements, three times over the line.
Is Latif’s criticism of the Die kalte Sonne book still valid under these circumstances? We would like to talk to Mojib Latif about it personally. After his earlier refusal, is he now perhaps ready for discussion? We hope for good climatic developments in 2019.
We wish all Die kalte Sonne blog readers – and of course Mr. Latif – a Happy New Year!
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn the first 9½ months of 2018,  368 scientific papers have been published that cast doubt on the position that anthropogenic CO2 emissions function as the climate’s fundamental control knob…or that otherwise serve to question the efficacy of climate models or the related “consensus” positions commonly endorsed by policymakers and mainstream media sources.

These 368 new papers affirm the position that there are significant limitations and uncertainties inherent in our understanding of climate and climate changes, emphasizing that climate science is not settled.
More specifically, the papers in this compilation support these four main skeptical positions — categorized here as N(1) – N(4) — which question climate alarm.
N(1) Natural mechanisms play well more than a negligible role (as claimed by the IPCC) in the net changes in the climate system, which includes temperature variations, precipitation patterns, weather events, etc., and the influence of increased CO2 concentrations on climatic changes are less pronounced than currently imagined.
N(2) The warming/sea levels/glacier and sea ice retreat/hurricane and drought intensities…experienced during the modern era are neither unprecedented or remarkable, nor do they fall outside the range of natural variability.
N(3) The computer climate models are neither reliable or consistently accurate, and projections of future climate states are little more than speculation as the uncertainty and error ranges are enormous in a non-linear climate system.
N(4) Current emissions-mitigation policies, especially related to the advocacy for renewables, are often ineffective and even harmful to the environment, whereas elevated CO2 and a warmer climate provide unheralded benefits to the biosphere (i.e., a greener planet and enhanced crop yields).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In sharp contrast to the above, the corresponding “consensus” positions that these papers do not support are:
A(1) Close to or over 100% (110%) of the warming since 1950 has been caused by increases in anthropogenic CO2 emissions, leaving natural attribution at something close to 0%.
RealClimate.org: “The best estimate of the warming due to anthropogenic forcings (ANT) is the orange bar (noting the 1𝛔 uncertainties). Reading off the graph, it is 0.7±0.2ºC (5-95%) with the observed warming 0.65±0.06 (5-95%). The attribution then follows as having a mean of ~110%, with a 5-95% range of 80–130%. This easily justifies the IPCC claims of having a mean near 100%, and a very low likelihood of the attribution being less than 50% (p < 0.0001!).”
A(2) Modern warming, glacier and sea ice recession, sea level rise, drought and hurricane intensities…are all occurring at unprecedentedly high and rapid rates, and the effects are globally synchronous (not just regional)…and thus dangerous consequences to the global biosphere and human civilizations loom in the near future as a consequence of anthropogenic influences.
A(3) The climate models are reliable and accurate, and the scientific understanding of the effects of both natural forcing factors (solar activity, clouds, water vapor, etc.) and CO2 concentration changes on climate is “settled enough“, which means that “the time for debate has ended“.
A(4) The proposed solutions to mitigate the dangerous consequences described in N(4) – namely, wind and solar expansion – are safe, effective, and environmentally-friendly.
To reiterate, the 368 papers compiled in 2018 thus far support the N(1)-N(4) positions, and they undermine or at least do not support the “consensus” A(1)-A(4) positions.  The papers do not do more than that.   In other words, it is not accurate to claim these papers prove that anthropogenic global warming (AGW) positions are invalid, or that AGW claims have now been “debunked”.
Below are the three links to the list of  2018 papers amassed as of the 15th of October, 2018, as well as the guideline for the lists’ categorization.
Finally, a sampling of some of the new papers is also included below.
Skeptic Papers 2018 (1)
Skeptic Papers 2018 (2)
Skeptic Papers 2018 (3)

Part 1. Natural Climate Change Observation, Reconstruction
Warming Since Mid/Late 20th Century? (30)
A Warmer Past: Non-Hockey Stick Reconstructions (58)
Lack Of Anthropogenic/CO2 Signal In Sea Level Rise (12)
Sea Levels Multiple Meters Higher 4,000-7,000 Years Ago (12)
A Model-Defying Cryosphere, Polar Ice (25)
Mass Extinction Events Caused By Glaciation, Sea Level Fall (3)
Antarctic Ice Melting In High Geothermal Heat Flux Areas (2)
Abrupt, Degrees-Per-Decade Natural Global Warming (5)
Part 2. Natural Mechanisms Of Weather, Climate Change  
Solar Influence On Climate (78)
ENSO, NAO, AMO, PDO Climate Influence (19)
Modern Climate In Phase With Natural Variability (8)
Cloud/Aerosol Climate Influence (4)
Volcanic/Tectonic Climate Influence (2)
The CO2 Greenhouse Effect – Climate Driver? (9)
Part 3. Unsettled Science, Failed Climate Modeling

Climate Model Unreliability/Biases/Errors and the Pause (19)
Urban Heat Island: Raising Surface Temperatures Artificially (3)
Failing Renewable Energy, Climate Policies (11)
Wind Power Harming The Environment, Biosphere (10)
Elevated CO2: Greens Planet, Higher Crop Yields (7)
Warming Beneficial, Does Not Harm Humans, Wildlife (7)
Warming, Acidification Not Harming Oceanic Biosphere (7)
Coral Bleaching A Natural, Non-Anthropogenic Phenomenon (2)
No Increasing Trends In Intense Hurricanes (6)
No Increasing Trend In Drought/Flood Frequency, Severity (6)
Natural CO2 Emissions A Net Source, Not A Net Sink (5)
Global Fire Frequency Declining As CO2 Rises (2)
CO2 Change Lags Temperature Change By 1000+ Years (3)
Miscellaneous (12)
Scientists: We Don’t Understand (1)

Non-Hockey Sticks: A Few Thousand Years Ago It Was 1-3°C Warmer Than Today
Papadomanolaki et al., 2018  (Baltic Sea)  A large fraction of the Baltic Proper became hypoxic again between 1.4 and 0.7 ka BP, during the Medieval Climate Anomaly (MCA), when mean air temperatures were 0.9–1.4 °C higher than temperatures recorded in the period 1961–1990 (e.g. Mann et al., 2009; Jilbert and Slomp, 2013).
Leonard et al., 2018  (Great Barrier Reef, Australia)  Coral derived sea surface temperature (SST-Sr/Ca) reconstructions demonstrate conditions ∼1 ◦C warmer than present at ∼6200 (recalibrated 14C) and 4700 yr BP, with a suggested increase in salinity range (δ18O) associated with amplified seasonal flood events, suggestive of La Niña (Gagan et al., 1998; Roche et al., 2014).
Suvorov and Kitov, 2018  (Eastern Sayan, Siberia)  The authors examined the variability of activity of modern glaciation and variation of natural conditions of the periglacial zone on climate and on dendrochronological data. Results of larch and Siberian stone pine growth data were revealed at the higher border of forest communities. …  It is believed that the temperature could be 3.5 °C warmer at the Holocene optimum than at the present time (Vaganov and Shiyatov 2005). … Since 2000, there has been growth of trees instability associated with a decrease in average monthly summer temperatures. …  Since the beginning of 2000, decrease in summer temperatures was marked.
Lozhkin et al., 2018  (East Siberia)  The postglacial occurrence of relatively warm/dry and warm/wet intervals is consistent with results of a regional climate‐model simulation that indicates warmer than present temperatures and decreased effective moisture at 11 000 cal. a BP and persistence of warm conditions but with greater moisture and longer growing season at 6000 cal. a BP.
Smith, 2018  (Greenland Ice Sheet)     To project how much sea level will rise in response to ongoing climate warming, one of the things we need to know is how sensitive the rate of Greenland Ice Sheet melting is to rising temperatures. McFarlin et al. present results from a set of sediment cores from a small nonglacial lake in the highlands of northwest Greenland, which contain deposits from the Holocene and the Last Interglacial (LIG). They found midge assemblages indicating peak July temperatures that were 4.0° to 7.0°C warmer than modern temperatures during the early Holocene and at least 5.5° to 8.5°C warmer during the LIG. This perspective of extreme warming suggests that even larger changes than predicted for this region over the —–coming century may be in store.
Kullman, 2018  (Scandes, Northern Sweden)     The present paper reports results from an extensive project aiming at improved understanding of postglacial subalpine/alpine vegetation, treeline, glacier and climate history in the Scandes of northern Sweden. The main methodology is analyses of mega fossil tree remnants, i.e. trunks, roots and cones, recently exposed at the fringe of receding glaciers and snow/ice patches. This approach has a spatial resolution and accuracy, which exceeds any other option for tree cover reconstruction in high-altitude mountain landscapes. …  All recovered tree specimens originate from exceptionally high elevations, about 600-700 m atop of modern treeline positions. … Conservatively drawing on the latter figure and a summer temperature lapse rate of 0.6 °C per 100 m elevation (Laaksonen 1976), could a priori mean that, summer temperatures were at least 4.2 °C warmer than present around 9500 year before present. However, glacio-isostatic land uplift by at least 100 m since that time (Möller 1987; Påsse & Anderson 2005) implies that this figure has to be reduced to 3.6 °C higher than present-day levels, i.e. first decades of the 21st century. Evidently, this was the warmth peak of the Holocene, hitherto. This inference concurs with paleoclimatic reconstructions from Europe and Greenland (Korhola et al. 2002; Bigler et al. 2003; Paus 2013; Luoto et al. 2014; Väliranta et al. 2015).
Borisova, 2018  (central East European Plain)     Paleobotanical assemblages from peat, lake, and archaeological deposits reveal that during the Middle Holocene (MH; ca. 9.0 to 4.7 kyr BP), the central East European Plain was occupied by highly productive and diverse mixed-oak forests, along with mire, meadow, and riverine communities. Climatic reconstructions based on modern analogues of fossil pollen and plant macrofossil assemblages indicate that throughout the MH [Middle Holocene] mean annual precipitation was at near present levels (~600 mm) and July temperatures were similar to those of today (~17°C). However, differences in the Fossil Floras (FFs) suggest changes in winter conditions though the MH [Middle Holocene, 9.0 to 4.7 kyr BP], with January temperatures higher than the present-day value of -10°C by 2°C in the Early Atlantic, 6°C in the Middle Atlantic, and 3°C in the Late Atlantic-Early Subboreal. The annual frost-free period was 15 days longer than today in the Early Atlantic, about one month longer in the Late Atlantic, and became close to present by the beginning of the Subboreal. The combination of warm winters with diverse and productive vegetation communities provided an environment that was more hospitable than that of today for Late Mesolithic and Neolithic societies.
McFarlin et al., 2018    (Greenland)  Early Holocene peak warmth has been quantified at only a few sites, and terrestrial sedimentary records of prior interglacials are exceptionally rare due to glacial erosion during the last glacial period. Here, we discuss findings from a lacustrine archive that records both the Holocene and the Last Interglacial (LIG) from Greenland, allowing for direct comparison between two interglacials. Sedimentary chironomid assemblages indicate peak July temperatures [Greenland] 4.0 to 7.0 °C warmer than modern during the Early Holocene maximum [10,000 to 8,000 years ago] in summer insolation. Chaoborus and chironomids in LIG sediments indicate July temperatures at least 5.5 to 8.5 °C warmer than modern.
Bartels et al., 2018  (North Atlantic Region)     During summer, AW [Atlantic Water] rises up to waterdepths as shallow as ~55 m. … Summer surface temperatures [1955-2012] range between up to 3°C at the northern mouth and <-1.5 °C at the southern mouth of the Hinlopen Strait, while winter surface temperatures vary between 0.5 and <~1.5°C (averaged, 1955–2012; Locarnini et al. 2013). … Increased summer insolation probably amplified the surface melting of the glaciers resulting in enhanced meltwater production and in a very high accumulation of finegrained sediments within the fjord […].  In addition, during the mild early Holocene conditions, summer sea-surface temperatures probably reaching 8–10°C [~5 – 9.5°C warmer than 1955-2012] (indicated by M. edulis findings as discussed in Hansen et al. 2011) may have contributed to reducing the number of glaciers that entered the fjord directly as tidewater glaciers and thus causing a diminished IRD input. These comparably warm surface temperatures most likely resulted in a reduced sea ice cover during summer, which is also reflected in the sea-ice biomarker data exhibiting lowest IP25 values during the early Holocene. … [G]lacier advances are most likely caused by atmospheric cooling as indicated, e.g. by d18O values from the Greenland NGRIP ice-core (Rasmussen et al.  2014a), by data from peats and permafrost soils on Spitsbergen (e.g. Humlum et al. 2003; Humlum 2005; Jaworski 2016), and by evidence that solar activity reduced around 2.7 ka, contributing to a cooling in both hemispheres (van Geel et al. 1999, 2000). … In lake sediments from northwestern Spitsbergen a temperature drop of ~6°C is recorded between c. 7.8 and c. 7 ka [-0.8°C per century], which has been connected to a stronger influence of Arctic Water and expanding sea ice (van der Bilt et al. 2018).
Street-Perrot et al., 2018  (Estonia)     Estimates of summer temperatures in Estonia based on rapidly responding proxies such as aquatic macrofossils (Valiranta et al., 2015) and chironomids (Heiri et al., 2014) suggest conditions 2 °C warmer than today during the early Holocene.
Pozachenuk, 2018 (Western Russia)  Mass peat accumulation in the territory of Vyatka region began only in the first half of the Atlantic Holocene period. The maximum warming corresponds to the second half of at (climatic optimum Holocene), when the average temperatures of January and July exceeded modern 2-3˚C. at this time in the region formed coniferous-broad-leaved forests of complex composition, with a slight presence of broad-leaved species (Qercus, Tilia, Ulmus) and Corulus. Siberian element of flora-fir on the territory of Vyatka region appeared only in the Subatlantic period of Holocene, most likely due to climatic conditions.
Kolaczek et al., 2018 (Southeastern Poland)    The reconstruction of the mean July temperature based on Chironomidae revealed the exceptionally high rate of warming during the period of ca. 11,490–11,460 cal. BP (at least 1 °C per decade) up to values > 2 °C than modern ones. … Between ca. 11,490 and 11,460 cal. BP, the strongest warming trend in the Early Holocene MJT was registered, that is from 15 to 20.7°C (0.19°C yr1, 1.9°C/decade). Then, ca. 11,450 cal. BP, the temperature decreased to 18.3°C and up to ca. 10,560 cal. BP MJT fluctuated between 17  and 19°C. The climate of the area [today] is classified as cold temperate with mean annual air temperature of 8.2°C  and mean annual precipitation 620 mm. A mean temperature of the warmest month, i.e. July, is +18.2°C [today], whereas a mean temperature of the coldest month, i.e. January, is -3.6°C.
Ruskeeniemi et al., 2018  (Greenland Ice Sheet)     Towards the Holocene Climatic Optimum, temperatures steadily increased and were 2.5°C higher than at present during 8000-5000 cal years BP. It is suggested that the GrIS started to re-advance after 4400 cal years BP due to cooling, with 0.5°C lower temperatures than at present around 2000 years BP. Within the LIA, Dahl-Jensen et al. (1998) identified two cold periods at 1550 AD and 1850 AD, with temperatures respectively 0.5°C and 0.7°C below the present values. At around 1930 AD, the temperatures reached a maximum and have slightly decreased thereafter.
The CO2 Greenhouse Effect: Climate Driver?
Davis et al., 2018     [T]he contemporary global warming increase of ~0.8 °C recorded since 1850 has been attributed widely to anthropogenic emissions of carbon dioxide (CO2) into the atmosphere. Recent research has shown, however, that the concentration of CO2 in the atmosphere has been decoupled from global temperature for the last 425 million years [Davis, 2017] owing to well-established diminishing returns in marginal radiative forcing (ΔRF) as atmospheric CO2 concentration increases. Marginal forcing of temperature from increasing CO2 emissions declined by half from 1850 to 1980, and by nearly two-thirds from 1850 to 1999 [Davis, 2017]. Changes in atmospheric CO2 therefore affect global temperature weakly at most. The anthropogenic global warming (AGW) hypothesis has been embraced partly because “…there is no convincing alternative explanation…” [USGCRP, 2017] (p. 12). …  The ACO [Antarctic Centennial Oscillation] provides a possible [natural] alternative explanation in the form of a natural climate cycle that arises in Antarctica, propagates northward to influence global temperature, and peaks on a predictable centennial timetable. … The period and amplitude of ACOs oscillate in phase with glacial cycles and related surface insolation associated with planetary orbital forces. We conclude that the ACO: encompasses at least the EAP; is the proximate source of D-O oscillations in the Northern Hemisphere; therefore affects global temperature; propagates with increased velocity as temperature increases; doubled in intensity over geologic time; is modulated by global temperature variations associated with planetary orbital cycles; and is the probable paleoclimate precursor of the contemporary Antarctic Oscillation (AAO). Properties of the ACO/AAO are capable of explaining the current global warming signal.
Smirnov, 2018     From this, it follows for the change of the global temperature as a result at doubling of the concentration of atmospheric CO2 molecules [is] ∆T = (0.4 ± 0.1) K, where the error accounts for the accuracy of used values, whereas the result depends on processes included in the above scheme. Indeed, we assume the atmospheric and Earth’s albedo, as well as another interaction of solar radiation with the atmosphere and Earth, to be unvaried in the course of the change of the concentration of CO2 molecules, and also the content of atmospheric water is conserved. Because anthropogenic fluxes of carbon dioxide in the atmosphere resulted from combustion of fossil fuels is about 5% [Kaufman, 2007], the contribution of the human activity to ECS (the temperature change as a result of doubling of the atmospheric carbon dioxide amount) is ∆T = 0.02 K, i.e. injections of carbon dioxide in the atmosphere as a result of combustion of fossil fuels is not important for the greenhouse effect.
Fleming, 2018     This manuscript will review the essence of the role of  CO2 in the Earth’s atmosphere. The logic of  CO2 involvement in changing the climate will be investigated from every perspective: reviewing the historical data record, examining in further detail the twentieth-century data record, and evaluating the radiation role of  CO2 in the atmosphere—calculating and integrating the Schwarzschild radiation equation with a full complement of  CO2 absorption coeﬃcients. A review of the new theory of climate change—due to the Sun’s magnetic ﬁeld interacting with cosmic rays, is provided. The application of this new theory is applied to climate-change events within the latter part of the Earth’s interglacial period. … The results of this review point to the extreme value of  CO2 to all life forms, but no role of  CO2 in any signiﬁcant change of the Earth’s climate. … The results of this review point to the extreme value of  CO2 to all life forms, but no role of  CO2 in any significant change of the Earth’s climate. … Many believe and/or support the notion that the Earth’s atmosphere is a “greenhouse” with CO2 as the primary “greenhouse” gas warming Earth. That this concept seems acceptable is understandable—the modern heating of the Earth’s atmosphere began at the end of the Little Ice Age in 1850. The industrial revolution took hold about the same time. It would be natural to believe that these two events could be the reason for the rise in temperature. There is now a much clearer picture of an alternative reason for why the Earth’s surface temperature has risen since 1850. … There is no correlation of CO2 with temperature in any historical data set that was reviewed. The climate-change cooling over the 1940–1975 time period of the Modern Warming period was shown to be influenced by a combination of solar factors. The cause of the Medieval Warm Period and the Little Ice Age climate changes was the solar magnetic field and cosmic ray connection. When the solar magnetic field is strong, it acts as a barrier to cosmic rays entering the Earth’s atmosphere, clouds decrease and the Earth warms. Conversely when the solar magnetic field is weak, there is no barrier to cosmic rays—they greatly increase large areas of low-level clouds, increasing the Earth’s albedo and the planet cools. The factors that affect these climate changes were reviewed in “Solar magnetic field/cosmic ray factors affecting climate change” section. The calculations of “H2O and CO2 in the radiation package” section revealed that there is no net impact of CO2 on the net heating of the atmosphere. The received heat is simply redistributed within the atmospheric column. This result is consistent and explains the lack of CO2 correlations with observations in the past. The current Modern Warming will continue until the solar magnetic field decreases in strength. If one adds the 350-year cycle from the McCracken result to the center of the Maunder Minimum which was centered in 1680, one would have a Grand Minimum centered in the year 2030.
Holmes, 2018     In short, there is unlikely to be any significant net warming from the greenhouse effect on any planetary body in the parts of atmospheres which are >10kPa. Instead, it is proposed that the residual temperature difference between the effective temperature and the measured near-surface temperature, is a thermal enhancement caused by gravitationally-induced adiabatic auto compression, powered by convection. A new null hypothesis of global warming or climate change is therefore proposed and argued for; one which does not include any anomalous or net warming from greenhouse gases in the tropospheric atmospheres of any planetary body. … A decline of 6% in lower tropospheric tropical cloud cover (15°N–15°S) occurred 1984 – 2000 according to the international satellite cloud climatology project’s data [29]. These years are contained well with the 1975-2000 period of warming, and an observed 0.4°C rise in global temperatures occurred over the same period. Scatter diagrams [55] of low cloud cover vs global surface air temperatures indicate that a 1% fall in low clouds equates to a 0.07°C rise in surface air temperatures – hence this change in cloudiness accounts for the entire observed rise in global temperatures during the 1975-2000 period, leaving no room for any effect from growing greenhouse gases.
Ollila, 2018         The temperature effects of the water and CO2 are based on spectral analysis calculations, which show that water is 11.8 times stronger a GH gas than CO2 in the present climate. … There are essential features in the long-term trends of temperature and TPW [total precipitable water], which are calculated and depicted as mean values 11 years running. The temperature has increased about 0.4°C since 1979 and has now paused at this level. The long-term trend of TPW effects shows that it has slightly decreased during the temperature-increasing period from 1979 to 2000. This means that the absolute water amount in the atmosphere does not follow the temperature increase, but is practically constant, reacting only very slightly to the long-term trends of temperature changes. The assumption that relative humidity is constant and that it amplifies the GH gas changes over the longer periods by doubling the warming effects finds no grounds based on the behavior of the TWP [total precipitable water] trend. The positive water feedback exists only during the short-term ENSO events (≤4 years). … The validity of the IPCC model can be tested against the observed temperature. It turns out that the IPCC-calculated temperature increase for 2016 is 1.27°C, which is 49 per cent higher than the observed 0.85°C. This validity test means that the IPCC climate forcing model using the radiative forcing value of CO2 is too sensitive for CO2 increase, and the CS [climate sensitivity] parameter, including the positive water feedback doubling the GH gas effects, does not exist. … The CO2 emissions from 2000 onward represent about one-third of the total emissions since 1750, but the temperature has not increased, and it has paused at the present level. This is worthy proof that the IPCC’s climate model has overestimated human-induced causes and has probably underestimated natural causes like the sun’s activity changes, considering the historical temperatures during the past 2000 years. … The RF [radiative forcing] value for the CO2 concentration of 560 ppm is 2.16 Wm−2 according to equation (3), which is 42 per cent smaller than 3.7 Wm−2 used by the IPCC. The same study of Ollila (2014) shows that the CS [climate sensitivity] parameter λ is 0.27 K/(Wm−2), which means that there is no water feedback. Using this λ value, equation (3) gives a TCS [transient climate sensitivity] value of 0.6°C only. This same result is also reported by Harde (2014) using the spectral analysis method. …There are both theoretical- and measurement-based studies showing results that can be explained only by the fact that there is no positive water feedback. This result reduces the CS [climate sensitivity] by 50 per cent. Some research studies show that the RF [radiative forcing] value of carbon dioxide is considerably smaller than the commonly used RF value, according to the equation of Myhre et al. (1998). Because of these two causes, the critical studies show a TCS [transient climate sensitivity] of about 0.6°C instead of 1.9°C by the IPCC, a 200 per cent difference.
Liu and Chen, 2018     CO2 and temperature records at Mauna Loa, Hawaii, and other observation stations show that the correlation between CO2 and temperature is not significant. These stations are located away from big cities, and in various latitudes and hemispheres. But the correlation is significant in global mean data. Over the last five decades, CO2 has grown at an accelerating rate with no corresponding rise in temperature in the stations. This discrepancy indicates that CO2 probably is not the driving force of temperature change globally but only locally(mainly in big cities). We suggest that the Earth’s atmospheric concentration of CO2 is too low to drive global temperature change. Our empirical perception of the global warming record is due to the urban heat island effect: temperature rises in areas with rising population density and rising industrial activity. This effect mainly occurs in the areas with high population and intense human activities, and is not representative of global warming. Regions far from cities, such as the Mauna Loa highland, show no evident warming trend. The global monthly mean temperature calculated by record data, widely used by academic researchers, shows R~2=0.765, a high degree of correlation with CO2. However, the R~2 shows much less significance (mean R~2=0.024) if calculated by each record for 188 selected stations over the world. This test suggests that the inflated high correlation between CO2 and temperature(mean R~2=0.765-0.024=0.741) used in reports from the Intergovernmental Panel on Climate Change(IPCC) was very likely produced during data correction and processing. This untrue global monthly mean temperature has created a picture: human emission drives global warming.
Laubereau and Iglev, 2018     Using a simple 1-dimensional model the global warming of the surface is computed that is generated by the increase of GHG and the albedo change. A modest effect by the GHG of 0.08 K is calculated for the period 1880 to 1955 with a further increase by 0.18 K for 1955 to 2015. A larger contribution of 0.55 ± 0.05 K is estimated for the melting of polar sea ice (MSI) in the latter period, i.e. it notably exceeds that of the GHG and may be compared with the observed global temperature rise of 1.0 ± 0.1 K during the past 60 years. … In conclusion we wish to say that we have performed a study of the infrared properties of carbon dioxide, methane, dinitrogen-oxide and water to estimate their contribution to the global warming in 1880 – 2015. Our results suggest that the IR properties of the CO2 are responsible for ~ 20% of the mean temperature increase of the surface and notably less for CH4 and N2O.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Swiss online Basel BAZ news site reported yesterday how the Yellow Vest fossil fuel tax protests have spread across Belgium and into the Netherlands, and so threaten to become a European phenomenon.
Previously it was thought that a move away from fossil fuels and higher taxes on them were the will of the people in Europe, and so citizens would readily accept higher taxes on them in order to get society to adopt the lean green energy diet. However that has suddenly turned out to be a gross misinterpretation by policymakers and activists.
Climate activists speechless – devastating signal
As the Yellow Vest protests intensify and spread, activists and delegates in Poland find themselves speechless as the begin to realize that a comprehensive transitioning over to green energies is not going to happen any time soon because their proposals are unmistakably generating anger. The signal to the world from France could not be more devastating to the climate protection movement.
The French have sent a loud and clear message.
The BAZ writes that the European governments are so spooked by the anger that in Brussels institutions such as the EU Commission, the EU Counsel and the EU Parliament had to be completely sealed off because of the demonstration. Police arrested some 100 protesters early as a preventive measure to keep the protest from escalating out of control.
Fuel taxes hurt the poor
Also police in the Netherlands sealed off Den Haag against protesters. The BAZ reported:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Several hundred people on Saturday also protested at the Yellow Vest demonstrations in the Netherlands against what they saw as the growing gap between rich and poor.”
Egregious arrogance, hypocrisy
One reason for the elevated level of anger is the arrogance and hypocrisy EU policymakers exhibit as they rush to impose green energies onto their population. While Eurocrats jet-set from one rescue-conference to another and lead the life of luxury on the taxpayers’ dime, they demand citizens tighten their energy and financial belts and go without.
One egregious example of such arrogance comes from the United States.  The Washington Examiner here reports how Vermont Senator Bernie Sanders spent $300,000 on private jet flights (in a single month!)while demanding citizens refrain from using fossil fuels and forgo their already modest lifestyles. The Examiner writes:
While private jets are a common tool for political campaigners, the same day the massive check was written to a private jet company, Sanders issued a call to arms to take on greenhouse gas emissions.”
Meanwhile President Donald Trump wondered if it was not time “to end the ridiculous and extremely expensive Paris Agreement.”

Since the protests began, France has decided to put off the high taxes on diesel and gasoline fuel for the time being. Expect other European countries to crank down their fuel tax rhetoric as a result.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAlthough resistance to littering the landscape with industrial wind turbines continues to grow strongly and the power grid is becoming ever more unstable, the German government refuses to back off its expansion of wind and solar energy.

Protests groups reach over 1000 in number as wind turbine litter the German landscape. Photo: Windwahn.
Jonas Herrmann of the Swiss NZZ here comments how Germany “is struggling with its wind turbines”.
It started 28 years ago, when the German government enacted a law that forced power companies to buy up any green power produced, pay exorbitant prices for it and feed it into the power grid whether it was needed or not. Over time the installation of solar panels and wind turbines exploded and today many parts of the countryside have become littered with unsightly wind parks.
Ruined landscape, yet a long way to go
Yet, Germany today remains far away from supplying its energy needs through “green” sources.
The NZZ comments: “The landscape has changed in many places as a result. A longer drive through Germany inevitably leads past dozens of wind turbines.”
Moreover, every community has been impacted, Nikolai Ziegler, says the chairman of resistance group Vernunftkraft, which is the major umbrella association of wind power opponents. According to Ziegler: “In Germany there are more than 1000 citizens’ initiatives that are mobilizing against wind energy” and that these groups are getting involved in politics.
Wind and sun will never be able to do the job


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Not only are wind turbines ruining Germany’s idyllic landscape, but the NZZ writes that much of the resistance is also based on wind energy’s technical unreliability as a power supply. The Herrmann at NZZ cites engineering expert Dr. Detlef Ahlborn, who says wind energy is too erratic and thus unreliable.
According to the NZZ;
With the umbrella organization Vernunftkraft, everyone is convinced that wind and solar energy will never be able to ensure a secure power supply.”
Proponents in denial
This is a claim that the German government and green energy proponents refuse to acknowledge. Proponents in Germany believe that the problems with green energies will somehow go away and the supply will miraculously somehow smooth out if more and more volatile wind and sun capacity gets installed.
Critics like Nikolai Ziegler also criticize that there really hasn’t even been any real Energiewende (transition the green energies) so far because electricity is only one fifth of Germany’s total energy demand. Green energies provide only one third of that one measly fifth, and so “it’s relatively meaningless”.
The NZZ notes that “most of the leaders of the protest group Vernunftkraft are “male in the second half of their lives” who “are united by their anger at wind energy”, but adds most have a background in natural science almost half of them are professors.
“Path to the unknown”
Vernunftkraft is calling for an end to green energy subsidies, a stop to the construction of additional wind turbines and instead greater investment in gas-fired power plants
The NZZ writes:
However, a political majority is not in sight. Although the AfD and parts of the FDP [parties] believe the Energiewende is a mistake, the German government can hardly prevent a further expansion of renewable energies. Germany is thus still on the path to the unknown with the Energiewende.”
Share this...FacebookTwitter "
nan
"The government’s current energy policies have led to a sharp decline in the number of new onshore windfarms, raising fears that the UK may fall short of the renewable energy it needs to generate to meet its climate targets. Industry data shows the ­rollout of new onshore windfarms fell dramatically after the ­government scrapped subsidy schemes four years ago. According to official data from the Renewable UK trade association, 23 new onshore windfarms began generating clean electricity for the UK last year, but all but one of them had secured support from subsidy schemes before they were closed.  Last year’s total was a fraction of the 2014 peak when more than 400 new onshore wind projects began generating clean power for the first time. The 2019 figures are also well below the average set over the last decade of 208 new projects a year.  Renewable UK warned that the UK risked falling short of its aim of reducing carbon emissions to net zero by 2050 as the pipeline of projects that clinched support before the schemes were closed begins to run dry. Rebecca Williams, a director at Renewable UK, said the figures showed that the government’s current approach was falling short on the clean electricity needed to meet the UK’s legally binding climate targets. “This is a flashing red warning light on our net zero dashboard and we urgently need a new strategy from government,” she said. The findings are likely to increase pressure on the government to reverse the block on government support for new onshore windfarms, put in place by the former Tory prime minister David Cameron in 2016. The current energy policy blocks onshore wind developers from competing for support contracts, and has caused the rollout of new onshore wind capacity to fall to 629 megawatts (MW) last year, or a quarter of the onshore wind growth recorded two years ago. The government’s official climate adviser, the Committee on Climate Change, has suggested that the UK’s onshore wind capacity should increase by almost threefold in the next 15 years to meet climate goals at low cost. This would require the UK to grow its onshore wind capacity from 13,000 MW now to 35,000 MW by 2035, or an average of more that 1,400MW a year. The sole addition to the UK’s fleet of onshore wind farms under the government’s current energy policy last year – the Withernwick II project, in the East Riding of Yorkshire – has a capacity of 8MW, with just four turbines. “Onshore wind is one of the cheapest low carbon technologies in the UK, quick to build, and it’s hugely popular as the government’s own opinion polls show 78% of people support it,” Williams said. “As ministers get down to work at the start of a new decade, we need to see new policies which support the full range of clean power sources to transform our energy system.” ScottishPower, a major developer of renewable energy, has started planning for a major expansion of onshore windfarm projects across Scotland in anticipation of a government U-turn on support for wind power projects. Lindsay McQuade, the chief executive of ScottishPower Renewables, told the Guardian late last year that “if the commitment of net zero is to be a reality, I expect to see support from government to match it”."
nan
"The nuclear industry provides about 15% of the UK’s electricity, makes a vital contribution to the country’s carbon cutting ambitions and is a remarkably safe form of energy with no major accidents since the Windscale Fire in 1957. But despite all this, it still seems to suffer from disinterest and distrust from the public and these factors continue to dominate the nuclear narrative. The industry is green, safe and has the potential to create many high-tech jobs. Why then is the nuclear industry so often seen as a guilty secret rather than a national treasure, with most of the public opting for ignorance or ambivalence? Perhaps one reason the public has so far failed to embrace nuclear power is that people feel excluded from the journey it is taking and lack any influence over how new nuclear solutions might emerge. It is high time the industry found a way to make its case and forge its future, hand in hand with the British public. So here are a few thoughts on why this is so important and how, over time, it might be achieved. Nuclear power is making a key contribution towards the government’s Clean Growth Strategy which aims to reduce carbon emissions. Within this strategy, the government has committed to supporting the replacement of existing reactors as they come to the end of their lives. This has resulted in huge multi-billion pound projects at Hinkley Point in Somerset, Wylfa on Anglesey and Moorside in west Cumbria.   But all of these projects (particularly Hinkley Point) continue to attract significant controversy around affordability – a debate which does nothing to promote long-term public confidence.  To guard against nuclear accidents like Fukushima and Chernobyl – and in an attempt to make the public feel safe – the nuclear industry has always looked to shield, protect and distance society from risk. It has sought to offer reassurance through the power of its own expertise and the promise of strict control. Of course, telling the public they don’t need to worry about something they can’t hope to fully understand – and traditionally associate with cataclysmic destruction – is virtually guaranteed to get their palms sweating. So, for many, nuclear investment has never risen above the status of a reluctant distress purchase, and is often better not contemplated at all  In reality, the UK’s nuclear energy story encompasses all the features necessary to capture the public’s attention and hold onto it. It’s an amazing technical concept and a high stakes journey of risk and reward with the future of the planet as the prize. If the industry wants to truly engage, then surely it needs to find new ways to invite people along for the ride. One new approach to public consultation uses so called “hybrid forums”. These forums bring together scientists and a diverse range of concerned stakeholders (such as local citizens, pressure groups and academic experts). These forums are convened to let problems emerge and to create a vision of the future that is common to everyone.  One example of a hybrid forum took place to address chronic flooding problems in North Yorkshire. The forum enabled everyone who took part to share their knowledge and expertise and alight on the radical alternative solution of gradually arresting the flow of floodwater, rather than providing expensive defences in the area itself. Today’s nuclear grand challenges – like providing affordable nuclear power stations and disposing of nuclear waste – are “social” problems with resolutions which lie in creating and maintaining public support over many years. This is a common feature which makes them well suited to such a hybrid approach. The hunt is already on for a volunteer host community for a Geological Disposal Facility (GDF) for the underground disposal of radioactive waste. Volunteer communities are compensated for hosting the facility through community investment funding. With a GDF, radioactive waste would be put hundreds of metres underground. This is internationally recognised as the safest long-term solution to nuclear waste disposal. Having one in the UK will create jobs and guarantee investment for whichever community takes it on. There is also growing interest in Small Modular Reactors or SMRs. These are lower cost, factory-built units that provide localised power. Widespread adoption of SMRs as a more affordable alternative to large scale plants would mean many new nuclear sites would need to be established – many in urban areas. This, again, requires long-term public support.   SMRs have generated government and industry interest internationally because designers have suggested they may offer lower investment risk, cost less and offer greater compatibility with the electricity network. The University of Manchester has set up The Beam Nuclear and Social Research Network to investigate the social challenges bound up in the UK’s nuclear future. We want to tackle all these questions head-on and bring fresh insights. But the ultimate test will be whether these insights can be made to resonate within the industry itself. The nuclear debate must be expanded and enriched for the benefit of everyone. I hope that our research will help the general public to think more passionately about what the UK’s nuclear future could be like and whether current nuclear policy is taking us there."
"Greta Thunberg and fellow youth climate campaigners are demanding that global leaders immediately end the “madness” of huge ongoing investments in fossil fuel exploration and enormous subsidies for coal, oil and gas use. The 21 young activists are also calling on the political and business leaders who will be attending the World Economic Forum in Davos to ensure investment funds dump their holdings in fossil fuel companies.  “Anything less would be a betrayal against life itself,” said Thunberg and colleagues in an article in the Guardian. “Today’s business as usual is turning into a crime against humanity. We demand that you play your part in putting an end to this madness.” The burning of fossil fuels is the biggest driver of the climate emergency. Scientists predict catastrophic impacts unless deep cuts in emissions are made rapidly, but global emissions are still rising. “Young people are being let down by older generations and those in power,” the climate strikers said. “To some it may seem like we are asking for a lot. But this is just the very minimum effort needed to start the rapid sustainable transition.” Much of the world’s existing coal, oil and gas reserves must be kept in the ground to avoid the worst impacts of global heating. But investment in fossil fuel exploration and extraction remains high. Since the Paris climate agreement in 2015, the world’s largest investment banks have provided more than $700bn (£535bn) to fossil fuel companies to develop new projects, with the total investment estimated to be trillions of dollars. Fossil fuel companies argue that their products will be used for many years to come and that they have a pivotal role in shifting the energy system to zero emissions. But their investments in green energy are tiny compared with those in fossil fuels. Subsidies for fossil fuels also remain high despite a G20 pledge in 2009 to eliminate them. The IMF estimates such subsidies run at $10m a minute, or $5.2tn a year. “The fact that [ending investment and subsidies] hasn’t been done already is, quite frankly, a disgrace,” said Thunberg and colleagues. Investors managing funds totalling $12tn have already divested from coal, oil and gas, but the climate activists demand that “all companies, banks, institutions and governments immediately and completely divest from fossil fuels”. Mark Carney, the governor of the Bank of England, said in December that the financial sector was not cutting investments in oil and gas companies rapidly enough and warned that assets in the sector could end up “worthless”. He said in October that companies and industries not moving towards zero-carbon emissions would be punished by investors and go bankrupt. “It ought to be in every company and stakeholder’s interest to make sure that the planet they live on will thrive,” said the climate strikers, who come from nations across the world, including the US, Australia, Brazil, Russia, India and Nigeria. “But history has not shown the corporate world’s willingness to hold themselves accountable. So it falls on us, the children, to do that.” The agenda for the 50th annual meeting of the World Economic Forum, which begins on 20 January in Switzerland, lists four “urgent and important” global issues. The first is “how to address the urgent climate and environmental challenges that are harming our ecology and economy”. The climate strikers said: “The world’s leaders should invest their money in existing sustainable technologies, research and in restoring nature. Short-term profit should not trump long-term stability of life.”"
"Surprise will have been many people’s understandable reaction to learning that Extinction Rebellion, the environmentalist network, was listed by British counter-terrorism police alongside violent neo-Nazi and Islamist groups in a guide to “extremist ideologies”. The document, issued to schools, included instructions to look out for those who use “strong or emotive terms” when discussing climate change or pollution. Since 2015, teachers have been under a statutory duty to refer students suspected of extremist sympathies to the anti-terror Prevent programme, with education now the main source of referrals (in 2017-18 these included 2009 children under 15). A suggestion that participation “in planned school walkouts” could be grounds for suspicion is particularly egregious, given that the school strike movement’s stated aim is for governments to act on climate scientists’ warnings. But what is particularly dispiriting about this ill-judged document is that the bracketing of green groups with terrorists is far from a one-off. Instead, and as numerous activists spied on by police in the past know (including an unknown number of women tricked into sexual relationships by officers), the treatment of environmentalists as dangerous subversives is consistent with longstanding attitudes to green issues at the highest levels of the British state.  Such views do not have a monopoly. Sir Peter Fahy, the former police chief who led Prevent from 2010 to 2015, has criticised the approach to Extinction Rebellion as counterproductive. But at a time when public concern about the climate emergency in many countries has never been higher, with bushfires ravaging Australia and new analysis showing record rises in ocean temperatures, the decision of the home secretary, Priti Patel, to highlight alleged “security risks” from green groups when asked about the issue is grounds for alarm. Climate policymaking is a global challenge and the stakes in 2020 could not be higher. If legally binding cuts on greenhouse gas emissions are not agreed at a crunch round of UN talks in December, then the world will be in a very dark place indeed (experts say emissions must be reduced by 7.6% per year for a decade if we are to avoid the most destructive scenarios). With that summit due to be held in Glasgow, the UK government has a vital role to play. But so does civil society, including activist groups such as Extinction Rebellion. The litany of failures of climate policy so far suggests that unless millions of people exert pressure on their leaders, governments will fail to take the necessary steps. In this context, it is a grotesque distortion of reality to suggest that young people who join peaceful climate protests bear any resemblance to terrorists. Fossil fuel companies, and asset managers such as Vanguard that consistently oppose climate resolutions, show far greater recklessness with regard to human life. Extinction Rebellion’s founders may declare support for alternatives to capitalism, but their grasp of climate science belongs not beyond the pale, but in the mainstream. Of course, the police must prepare for the disruption caused by civil disobedience. Such actions do not command universal support and in some cases are planned to maximise pressure on police resources. But none of this has anything to do with counter-terrorism. The government’s delayed review of Prevent must now take place, with a thorough examination of this episode as part of its remit, and clear advice as to how those affected can seek redress."
nan
"It’s too early to say whether the prime minister, Scott Morrison, is speaking with a forked tongue when he says the government will “evolve” its climate change policy. What appeared on Sunday to be a shift in rhetoric on the government’s emission reduction targets may be meaningful – or it may yet prove to be deliberately duplicitous.  Morrison is clearly under pressure on the government’s unambitious climate change policy, an issue that may have remained conceptual for some if not for the horror bushfire crisis that has laid bare the consequences of a warmer planet. For months, the prime minister has refused to yield on calls for more ambitious action, saying the government was doing enough and would “meet and beat” its Paris target of reducing emissions by 26% to 28% of 2005 levels by 2030. But as the cries for action have become louder – including from a group of former fire chiefs who have clearly linked the fire crisis to the effects of climate change in Australia – Morrison is detecting the whiff of backlash. Despite his ill-judged family holiday to Hawaii, and what was arguably a tardy national response to the fires, Morrison is not politically naive. He knows that the political pressure over climate change is only becoming more intense, and will be most profoundly felt in inner-city seats held by moderate Liberals, particularly in Sydney, Melbourne and Brisbane. Like a verbal Rorschach test, Morrison’s media appearances on Sunday were open to interpretation, but designed to give the government wriggle room. A conservative Queenslander who works in a coal seat? Morrison wants you to hear the message that he won’t be changing course. But a moderate Liberal in Victoria? Morrison’s message for you is he plans to “go further” on emissions reduction. Does climate change cause bushfires? The link between rising greenhouse gas emissions and increased bushfire risk is complex but, according to major science agencies, clear. Climate change does not create bushfires, but it can and does make them worse. A number of factors contribute to bushfire risk, including temperature, fuel load, dryness, wind speed and humidity.  What is the evidence on rising temperatures?  The Bureau of Meteorology and the CSIRO say Australia has warmed by 1C since 1910 and temperatures will increase in the future. The Intergovernmental Panel on Climate Change says it is extremely likely increased atmospheric concentrations of greenhouse gases since the mid-20th century is the main reason it is getting hotter. The Bushfire and Natural Hazards research centre says the variability of normal events sits on top of that. Warmer weather increases the number of days each year on which there is high or extreme bushfire risk. What other effects do carbon emissions have? Dry fuel load - the amount of forest and scrub available to burn - has been linked to rising emissions. Under the right conditions, carbon dioxide acts as a kind of fertiliser that increases plant growth.  So is climate change making everything dryer?  Dryness is more complicated. Complex computer models have not found a consistent climate change signal linked to rising CO2 in the decline in rain that has produced the current eastern Australian drought. But higher temperatures accelerate evaporation. They also extend the growing season for vegetation in many regions, leading to greater transpiration (the process by which water is drawn from the soil and evaporated from plant leaves and flowers). The result is that soils, vegetation and the air may be drier than they would have been with the same amount of rainfall in the past. What do recent weather patterns show? The year coming into the 2019-20 summer has been unusually warm and dry for large parts of Australia. Above average temperatures now occur most years and 2019 has been the fifth driest start to the year on record, and the driest since 1970. Is arson a factor in this year's extreme bushfires? Not a significant one. Two pieces of disinformation, that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush have spread across social media. They have found their way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. Morrison’s allegiance to the party’s centre-right faction has given him more rhetorical flexibility in his response to climate change than conservative MPs ever allowed his predecessor, Malcolm Turnbull. But conservatives will become suspicious – and unruly – if the man they believe to be one of their own actually wants to back up this latest change in rhetoric with action or substantial policy change. On the other flank of the party, there is an emerging view – from a clutch of at least a dozen MPs – that climate anxiety can no longer be ignored. These MPs will be demanding more. Moderates are hoping that Sunday’s rhetorical shift is the first sign of a pivot – that of a pragmatic prime minister attempting to turn around the Queen Mary. But conservatives will be hoping that Morrison is all talk, no action. Morrison has been attempting to paper over the cracks within his partyroom by insisting that there is “no dispute” within the coalition that climate change is linked to the bushfire crisis, despite abundant evidence to the contrary. It was no accident that Morrison told his MPs last week in a phone hook-up to shut their collective trap on climate change policy until after the fires abated. Climate change policy has dogged the conservative side of politics for more than a decade, and there is no reason to expect that Morrison will be left off the hook. But he is not Tony Abbott, and nor is he Malcolm Turnbull; he carries none of the ideological baggage of his predecessors. This could prove a great strength for Morrison as he seeks to navigate a new policy path through such politically dangerous territory. Shifting course is, as the prime minister said on Sunday, “a challenging task”. But it’s now clear that the status quo is untenable."
"In late 2019, before the bushfires hit crisis level, concern about climate change in Australia was at record levels. Since then at least 27 people have lost their lives, millions of animals have died and the navy has been called in to evacuate beaches. The devastating impacts of climate change are tragically becoming real for many. And many, from bushfire survivors to business leaders to firefighters, are calling for action. As a result, we are in a moment where the opportunity to implement effective and long-lasting policy to lower Australia’s climate pollution could finally be within reach. Indeed, the independent MP Zali Steggall has announced her intention to introduce a climate bill into federal parliament in March. Meanwhile the New South Wales energy minister, Matt Kean, has asked the state’s chief scientist to identify opportunities for NSW to lead on climate action. Even the NSW Young Liberals have put forward a plan to act on climate.  To grasp this opportunity we must learn critical lessons from the past. This is not the first time that public support for climate action has been sky high, nor the first time that political opportunity for far-reaching policy has presented itself. In 2007 Kevin Rudd was elected with a huge mandate to act on climate. In 2011 the Gillard government, with support of the crossbench, implemented the extremely effective clean energy future package. And last year people across the country worked tirelessly to make the federal election a climate election. In all three of these cases, we lost in the how – how should Australia go about acting on climate? In the first instance, we lost momentum for action because we could not agree on the effectiveness of a policy – would the carbon pollution reduction scheme with its 5% emissions reduction target be a springboard for further action, or lock in rights to pollute for our biggest emitters? In the second case, climate deniers such as Tony Abbott weaponised the carbon price policy for political ends, running the extremely effective “Axe the tax” scare campaign. Furthermore, the carbon price was for many Australians an abstract policy idea disconnected from their lives but perceived to be hurting their hip pockets. In the third, a poll by the Australia Institute found that there was simply not enough awareness of the differences between the two main parties’ energy and climate policies. With renewable energy booming, the federal Coalition was able to paint itself has having a reasonable and sensible climate policy, even though it has anything but. I raise these painful moments in history not to rehash the past but rather to see what we can learn for the future. Because we need to recognise that from public policy and political perspective, climate change is hard – the causes (burning fossil fuels and reducing carbon sinks) are distant from the impacts geographically and temporarily. Its solutions practically are many and the policies needed often complex. Not to mention the fact that Australia has a powerful fossil fuel lobby and, in each of these moments, it took advantage of the disagreement, disconnection and lack of understanding to good effect. Looking forward, we are now presented with both a policy challenge and communications challenges. First, can those who care about climate unite behind practical solutions and policy options that will be: effective at lowering emissions; connect with real people’s lives; and are easy and compelling for the average person to understand? Second, can we communicate a set of success measures against which everyday Australians can judge the effectiveness of a policy or a government on climate? I propose five tests or questions that could help us meet these policy and communications challenges: Is carbon pollution going down in real terms? Can the government point to real-world action and policies that are being implemented now, this year, to lower emissions that are commensurate with the scale of the problem? Does the government have a plan to fully decarbonise every sector of the economy – electricity, transport, industry, buildings, agriculture and land use? And ones that address the biggest opportunities and threats, for example a renewable export plan and a bushfire plan? Do these plans deliver co-benefits in each sector that make people’s lives better? For example, creating new jobs, new industries, healthier and more liveable? homes, less traffic congestion, lower electricity bills and less air pollution. Is the government or policy reducing and removing support for fossil fuels and/or other causes of climate change? If the answer is no to these questions, the policy isn’t working, the government isn’t acting on climate, it’s unlikely to be popular and thus long-lasting and it isn’t fulfilling our obligations under the Paris agreement. The basic idea that underpins these tests is that actually to address climate change we need a plan, or in reality multiple plans. For too long, climate policy insiders and commentators have been obsessed with carbon pricing. Carbon prices, like other policies can be well designed and effective, or badly designed and ineffective. But whether a carbon price is well designed or not, it’s only one tool in the policy toolkit for decarbonising Australia. Other tools include regulatory changes, investment in research and development, new standards, support for new markets and so forth. A plan is needed for each sector of the Australian economy that brings together these different policy levers or tools and different actors to do the hard work of decarbonisation. Work, that the climate science says is urgently required but, if done right, could lead to a better, more prosperous Australia. The good news is we are starting to see different organisations calling for a plan. For example, WWF-Australia is calling for a climate plan and have done the research needed to communicate it to mainstream Australia. Farmers for Climate Action are calling for the development of a climate and agriculture strategy. The Climate and Health Alliance is advocating for a climate and health plan. While, Renew, the Australian Council of Social Service, the Energy Efficiency Council and many others are working on a plan for existing buildings that is starting to gain traction. The good news is all of these organisations are building diverse coalitions, talking about the non-environmental benefits that can be delivered by acting on climate in their respective sectors. Australian’s trust in its political leadership is at an all-time low, perhaps this is a moment that leaders across all states and territories to redeem our faith in politics and end the climate wars, with the humble task of drawing up a plan. Nicky Ison is the energy transition manager at WWF-Australia and a research associate at the Institute for Sustainable Futures at the University of Technology Sydney"
nan
"The huge moorland fires at Saddleworth and Winter Hill in northwest England have shown just how serious a problem wildfires can be in the UK. Now the fires are out, it is time to look at how such catastrophes can be prevented in the future and why this critical environmental issue needs to be on the political agenda.  Our research has shown how informal local and national partnerships helped keep the flames under some form of control and can reduce the risk of future fires on this scale. But the government needs to support these partnerships and see wildfire as more than a fire service problem. Climate change will make such fires more common so the country must be ready. Managing moorland wildfire risk is not just about putting out fires. It is also about reducing the risk of fires starting and spreading. This involves the cooperation of many diverse interest groups, so fire and rescue services work collaboratively with other stakeholders such as mountain rescue groups, local councils, police forces and government agencies. As the Scottish government wildfire manual (section 8A.20) acknowledges, it would be impossible for fire and rescue services to attempt to address the risks in isolation.   Fire crosses property and administrative boundaries so cooperation between agencies and interest groups is vital. Informal partnerships have developed to coordinate efforts. Local fire groups have formed to share expertise and firefighting equipment. The Peak District Fire Operations Group (FOG was one of the first. It is six local fire services, three water companies, amenity groups and other landowners working together to prevent and prepare for wildfires. There are now at least 20 such groups across the UK, spurred by bad fire seasons in 2003, 2006 and 2011. These collaborations, championed by Northumberland Fire and Rescue Service among others, have changed the approach to fighting UK wildfires. 


      Read more:
      How climate change is increasing the risk of wildfires


 Fire groups train together and share resources. Standard gauge hoses now mean that fire brigades can join them together in a “water relay” to reach remote fires. The Peak District group includes Pennine helicopters – seen on the news dumping water on the moorland fires in Lancashire and Greater Manchester. The Lancashire FOG uses the Bay Search and Rescue’s large all-terrain vehicle – normally used to traverse Morecambe Bay’s sands – to ferry people and heavy equipment across soft peat moorland. Bolton Mountain Rescue served as tactical lookouts, spotting flare-ups at the Winter Hill fire. Land managers provide all-terrain vehicles and “fogging units” with fine sprays to wet vegetation, while countryside rangers and landowners bring local knowledge of the terrain.  Formal multi-agency working is also required at major incidents, including help from other emergency services, the military and utility companies. There is no separate national fire service for wildfires. Instead, the UK’s 54 fire services help each other, so wildfire training is vital for all crews.  Saddleworth Moor fire crews had help from a Wildfire Tactical Advisor, one of a new national “flying squad” of specially trained regional officers, recently set up by the National Fire Chiefs Council Wildfire Group.  The England and Wales Wildfire Forum and its Scottish equivalent share good practice nationally and raise awareness of wildfire issues. Although unfunded, they have become the “go-to” bodies for government on wildfire issues.   They collaborate with UK wildfire researchers to match practitioners’ needs with wildfire research expertise, although many research gaps still remain. Critically, the UK does not have a suitable fire danger rating system to predict when and where wildfires will occur and their impacts.  


      Read more:
      A high-adrenaline job: 5 questions answered about fighting wildfires


 Key fire service personnel in the UK have also gained valuable skills through international collaboration – for example, with the Pau Costa Foundation in Catalonia and the US’s Prescribed Fire Training Exchange (TREX). They learned how to predict wildfire behaviour by reading the landscape. Fire travels faster upwards on sunlit slopes and with the wind. Crews now use this knowledge in what is called indirect attack – this involves “starving” strategic locations in the fire’s path of fuel by mechanical clearing or controlled “defensive burning”. A more robust planning and prevention approach to wildfire has evolved over the last 20 years, thanks to these informal local and national partnerships and international training. But the UK’s wildfire problem has only recently been recognised by national policy. Major fires in 2011 were a catalyst for severe wildfire to be included in the National Risk Register. The Natural Hazard Partnership now includes wildfire in its daily hazard assessments.  


      Read more:
      How the land recovers from wildfires – an expert's view


 Local and national partnerships have proved an effective response, despite stretched resources, and deserve government support. Without these bottom-up initiatives, fire crews fighting the blazes on Saddleworth Moor and Winter Hill would have had an even more arduous task.   Wildfire is more than just a fire service issue. Any change in land use or land management which affects ignition sources (people) or fuel (vegetation) can also change wildfire risk, whether deliberately or unintentionally. Either way, planning ahead to manage wildfire risk should be firmly on the political agenda."
"
Share this...FacebookTwitterThere are large regions of the globe where observations indicate there has been no warming (even cooling) during the last decades to century. Climate models rooted in the assumption that fossil fuel emissions drive dangerous warming dismiss these modeling failures and project temperature increases of 3° – 10°C by 2100 for these same regions anyway. 

Four decades of Southern Ocean cooling
After warming from the 1940s to the mid-1970s, the Southern Ocean has been cooling since the late-1970s, which has consequently resulted in an increase in sea ice extent (Fan et al., 2014; Purich et al., 2018; Latif et al., 2017; Turney et al., 2017 ).
In their paper entitled “Natural variability of Southern Ocean convection as a driver of observed climate trends”, Zhang et al. (2019) suggest that the Southern Ocean cooling was driven by natural processes.
Zhang et al., 2019
“Observed Southern Ocean surface cooling and sea-ice expansion over the past several decades are inconsistent with many historical simulations from climate models. Here we show that natural multidecadal variability involving Southern Ocean convection may have contributed strongly to the observed temperature and sea-ice trends.”

Climate models, in contrast, had projected a rapid warming and significant decreases in sea ice extent during the last few decades.

Image(s) Source: Zhang et al., 2019
The East-Central U.S. has been cooling (about -0.6°C) since the 1950s
Partridge et al., 2018
“We present a novel approach to characterize the spatiotemporal evolution of regional cooling across the eastern U.S. (commonly called the U.S. warming hole), by defining a spatially explicit boundary around the region of most persistent cooling. The warming hole emerges after a regime shift in 1958 where annual maximum (Tmax) and minimum (Tmin) temperatures decreased by 0.46°C and 0.83°C respectively.”

Image Source: Partridge et al., 2018
Alter et al., 2017
“From 1910- 1949 (pre-agricultural development, pre-DEV) to 1970-2009 (full agricultural development, full-DEV), the central United States experienced large-scale increases in rainfall of up to 35% and decreases in surface air temperature of up to 1°C during the boreal summer months of July and August … which conflicts with expectations from climate change projections for the end of the 21st century (i.e., warming and decreasing rainfall) (Melillo et al., 2014).”

Image Source: Alter et al., 2017
Climate models project 3°C – 10°C warming in the Midwest (U.S.) by 2100
Even though climate models failed to simulate the last 50 to 100 years of temperatures for this region, hindcasting a dramatic warming instead of the observed cooling, the projections for 2100 are still predicated on CO2 emission scenarios (RCP4.5, RCP8.5) as the determinant of regional surface temperatures.  Consequently, the regional models project a warming of 3°C – 10°C over the next 80 years.
Hamlet et al., 2019
“For the two most widely used greenhouse gas concentration scenarios, Representative Concentration Pathways (RCP) 4.5 and 8.5 (Moss et al. 2008) (representing “medium” and “high” twenty-first century greenhouse gas concentration trajectories respectively), the Midwestern United States is projected to experience profound changes in climate by 2100, especially for (T). Projections for annual mean T over the Midwestern United States from 31 global climate models (GCMs) for the RCP8.5 scenario show an ensemble mean increase in T of about 6.5 °C (11.7 °F) by 2100 relative to the historical 1971–2000 baseline (Fig. S1) (Byun and Hamlet 2018). The projected change in the annual ensemble mean T for RCP4.5 over the Midwestern United States is about 3.3 °C (5.9 °F) by 2100 relative to the 1971–2000 baseline. The upper tail of the annual mean T distribution, represented by the 97.5th percentile of the 31 GCM projections for RCP8.5 (i.e., a “worst-case” scenario), is nearly 10 °C (18 °F) warmer than the historical baseline by 2100.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Image(s) Source: Hamlet et al., 2019
The North Atlantic hasn’t warmed since the 1800s
Grieman et al., 2018

Image Source: Grieman et al., 2018
Birkel et al., 2018

Image Source: Birkel et al., 2018

Reverdin et al., 2018


Image Source: Reverdin et al., 2018


Climate models project 3°C warming in the North Atlantic by 2100

Gervais et al., 2018
“Recent studies have documented the development of a warming deficit in North Atlantic sea surface temperatures (SST) both in observations of the current climate (Rahmstorf et al. 2015; Drijfhout et al. 2012) and in future climate simulations (Drijfhout et al. 2012; Marshall et al. 2015; Woollings et al. 2012). This “North Atlantic warming hole” (NAWH) is characterized in the observed record as a region south of Greenland with negative trends in SSTs of 0.8 K century-1 (Rahmstorf et al. 2015). In fully coupled global climate model (GCM) future simulations, the NAWH is seen as a significant deficit in warming within the North Atlantic subpolar gyre (Marshall et al. 2015; Winton et al. 2013; Gervais et al. 2016).  This local reduction in future warming is communicated to the overlying atmosphere and may impact atmospheric circulation (Gervais et al. 2016), including the North Atlantic storm track (Woollings et al. 2012).”

Image Source: Gervais et al., 2018
Hansen (2013): CO2 emissions will cause 20°C of global warming by ~2130
Back in 1989, Dr. James Hansen, the former head of NASA, predicted that New York City’s West Side Highway would be underwater within 20 years due to rapid global warming and the consequent rising sea levels.
A glance at a 2018 image of the West Side Highway  indicates that it is still very much above water, no lower than its position in 1936.
A few decades later (2012), Hansen was the lead author of a paper published by The Royal Society (2013) that indicated ever-growing fossil fuel emissions would lead to a nearly five-fold rise in atmospheric CO2 concentrations (to 1,400 ppm) within 118 years.
He then projected this CO2 increase and presumed 9 W m-2 forcing would cause a global surface temperature warming of 20°C by about 2130, with 30°C warming at the poles.

Image Source: Hansen et al., 2013
Hansen et al., 2013
“Let us now verify that our assumed fossil fuel climate forcing of 9 W m−2 is feasible. If we assume that fossil fuel emissions increase by 3% per year, typical of the past decade and of the entire period since 1950, cumulative fossil fuel emissions will reach 10 000 Gt C in 118 years [2012 + 118 years = ~2130 C.E.] … [T]he fossil fuel source required to yield a 9 W m−2 forcing may be closer to 5000 Gt C, rather than 10 000 Gt C.”
“9 W m−2 forcing requires approximately 4.8×CO2 [1400 ppm] … Our calculated global warming in this case is 16°C, with warming at the poles approximately 30°C. Calculated warming over land areas averages approximately 20°C. … Such temperatures would eliminate grain production in almost all agricultural regions in the world. Increased stratospheric water vapour would diminish the stratospheric ozone layer. More ominously, global warming of that magnitude would make most of the planet uninhabitable by humans.”
“Given the 20°C warming we find with 4.8×CO2 [1400 ppm], it is clear that such a climate forcing would produce intolerable climatic conditions even if the true climate sensitivity is significantly less than the Russell sensitivity, or, if the Russell sensitivity is accurate, the CO2 amount required to produce intolerable conditions for humans is less than 4.8×CO2 [1400 ppm].”
“Are there sufficient fossil fuel reserves to yield 5000–10 000 Gt C? Recent updates of potential reserves, including unconventional fossil fuels (such as tar sands, tar shale and hydrofracking-derived shale gas) in addition to conventional oil, gas and coal, suggest that 5×CO2 (1400 ppm) is indeed feasible.”
Given the documented modeled forecast failures and lack of extreme or dangerous warming in recent decades, is there good reason to assume that Hansen’s prediction of a 20°C warming over the next 110 years will be realized?
At what point do modeling failures lead to a reconsideration of the forcing mechanisms?
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman climate skeptic Snowfan here reports that Germany’s DWD National Weather Service has been caught deliberately spreading climate alarmism ahead of the COP24 using “fake news” in its press release of December 3, 2018, where it announced:
2018 could be the warmest and driest year since 1881.“
Snowfan replied on December 9th that 2018 could not be “the driest year” because the German Weather Service knew plenty of precipitation was in the pipeline for December, 2018.
As Snowfan shows, the old record of 555.1 mm/m² of mean precipitation across Germany was set way back in 1959, (see chart below).

Germany’s mean annual precipitation since 1881. The green line shows how Germany’s mean precipitation has increased over the past decades. The 1981-2010 mean is close to 820 liters/sq m.
By the end of November 2018, an average amount of 482.3 mm/m² of precipitation had fallen in 2018 through November. As of December 8, 2018, an average of about 518 mm had fallen across the country.
Then on the 11th of December, Snowfan noted that the GFS forecast for precipitation in Germany up to Christmas day showed yet more rain on the way:

Defying the the GFS forecasts, the DWD went ahead and “expected” less than 30 liters/sqm of precipitation to fall across Germany by the end of the month. The purposely very low expectation of course allowed DWD to issue an alarmist press release warning that 2018 could set an all-time record for the driest year ever.
On December 11, Snowfan pointed out that this was not going to happen, and called the DWD claims “ridiculous nonsense”, adding:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




1. The year 2018 in Germany cannot be the driest year since 1881, the positive linear trend of precipitation in Germany since 1881 (green line in the DWD graph above) will remain.
2. In the last week of the completely senseless 24th World Climate Change Conference (COP24) in Poland’s largest coal mining district in Katowice, December 2-14, snow will fall heavily over the last week to cool the overheated climate brains.”
Today Snowfan writes that as of December 16, 2018, already about 81% of December’s mean precipitation has fallen so far.
On the DWD’s panic forecast of possibly the driest year on record issued on December 3, before COP24, Snowfan concludes:
There was no basis for it, there is none, and there isn’t going to be any ‘DWD 2018 driest year since since recordings began in 1881!'”
Currently only 15 l/m² are missing until the end of the month. According to a very recent outlook by the GFS, plenty more rain is forecast for Germany for the rest of December:

1959 was the record driest year ever, and will remain Germany’s record driest year until further notice – no matter what the DWD may insist.
Snowfan adds:
The DWD thus knew before the December 3, 2018 press release of the climate fairy tale of the driest year ever, and that there would be more heavy rainfall in Germany by the end of the year.
Could one call a deliberate climate false story a climate lie? Does the DWD German Weather Service, with an annual budget of about 347 million euros in 2018, have the state contract to organize climate alarm by repeatedly deliberately spreading climate lies?”
 
Share this...FacebookTwitter "
"Every school in New Zealand will this year have access to materials about the climate crisis written by the country’s leading science agencies – including tools for students to plan their own activism, and to process their feelings of “eco-anxiety” over global heating. The curriculum will put New Zealand at the forefront of climate change education worldwide; governments in neighbouring Australia and the United Kingdom have both faced criticism for lack of cohesive teaching on the climate crisis. The New Zealand scheme, which will be offered to all schools that teach 11 to 15 year-old students, will not be compulsory, the government said. “One of the pieces of feedback we’ve got from teachers around the country is that they’re really crying out for something like this, because kids are already in the conversation about climate change,” said James Shaw, New Zealand’s climate change minister and co-leader of the left-leaning Green Party. “They’re seeing stuff on social media on a daily basis and none of it’s good news, and the sense of powerlessness that comes from that is extremely distressing.” Hundreds of thousands of school and university students around the world, including in New Zealand, walked out of their classes for a series of climate strikes during 2019, a year when scientists warned that climate change was an “existential threat to civilisation”. Young people feel betrayed and abandoned by older generations over their lack of action on the climate issue, and worry about it has increasingly sparked anxiety and depression, a group of British psychologists warned in September. A pilot of the New Zealand scheme, which ran in one school in the city of Christchurch in 2018, had led to the introduction of materials for the national roll-out that helped students process their emotions about the climate issue, Shaw told The Guardian. “Being in the conversation itself causes stress,” he said. By necessity, he added, students would “delve into the bad news” of the science explaining the climate crisis. But the resources had been bolstered with “quite an emphasis on talking through with students how they’re feeling about it,” he said. Materials created for teachers that were provided to the Guardian suggest students keep a “feelings thermometer” to track their emotions, learn how to change defeatist self-talk, and consider how their feelings could generate action and response. “It helps kids to see that it is a fixable problem and people are working on it, and there is something they can foresee for themselves in terms of their own futures,” said Shaw. Another tool in the curriculum helps students create and carry out an action plan on a particular environmental issue – such as creating an edible garden. The curriculum included text, video, and advice for teachers, the education minister Chris Hipkins said in a statement. “It explains the role science plays in understanding climate change, aids understanding of both the response to it and its impacts – globally, nationally and locally – and explores opportunities to contribute to reducing and adapting to it impact on everyday life,” he added. While the Paris climate agreement, signed in 2015, urges signatory countries to implement climate education, many countries who made the pledge have not fulfilled it, including New Zealand’s nearest neighbour Australia, according to the science publication The Conversation. While some parts of Britain have enacted their own climate literacy plans, there is not a nationwide curriculum to teach it. The Labour party urged such a policy last May. Italy will this year become the first country in the world to make sustainability and the climate crisis compulsory subjects for students, with material integrated into regular lessons, such as mathematics and geography."
nan
"The palm oil industry is no stranger to controversy. While the world has come to learn of the environmental issues linked to the oil’s production, claims have arisen that countless rural communities have been affected by land grabs by companies seeking to expand their production. That began to change in 2001, however, when World Wildlife Fund started to explore setting up a Roundtable on Sustainable Palm Oil (RPSO). By 2004, the roundtable had been formally established as a not for profit group, bringing together several types of industry stakeholder, including civil society organisations (CSOs) to represent the interests of rural communities on whose land large companies are growing oil palm. All members now work together to agree and develop a set of environmental and social criteria, and achieve a sustainable palm oil certification. As of May 2018, 3.57m hectares of land had been certified under the scheme, and the 3,920 members produced 19% of global palm oil (12.2m tonnes). While global data on the impact of RSPO certification on land grabbing episodes are hard to find, a 2018 report suggested that it had contributed to a 33% reduction in deforestation between 2001 and 2015 in Indonesia alone. However, these stats are now set to change following palm oil giant Golden Veroleum Liberia’s (GVL) withdrawal from the RSPO. The Singapore-based developer is one of Liberia’s largest investors who, according to its RSPO profile, is “committed to the sustainable development of palm oil in Liberia. This means protecting the environment and working harmoniously with local communities”. GVL’s leaving was triggered by the RSPO’s decision to sanction several member organisations – including GVL – who had been accused of violating the body’s key principle of free prior informed consent. The main purpose of this is to “ensure that RSPO-certified sustainable palm oil comes from areas without land conflicts or … grabs”.  GVL began operations in Liberia in 2010, amid hopes that it would boost local employment. It was awarded 220,000 hectares of land by the Liberian government for the cultivation of oil palm.  But soon after the company began operations, the people of the Butaw region became concerned that it was clearing sacred sites and protected forests, and encroaching on land without the free prior informed consent of the people. The forests near GVL’s Liberian plantations are also heavily populated with chimpanzees, leopards, pygmy hippopotamus and forest elephants which are significant not only to the local ecosystem but globally. Complaints were made to the RSPO in October 2012 by several CSOs, which even went so far as accusing GVL of negotiating deals with communities during Liberia’s Ebola outbreak. They argued that communities were desperate for income during the crisis and were easily coerced into signing their land away.  After years of back and forth, RSPO sanctioned GVL in February 2018, ordering the company to stop clearing new lands. A subsequent appeal was rejected and so GVL withdrew. The problem here is that if it is so easy for a company like GVL to leave the RSPO, what’s to stop others from doing it too? Their leaving could very well be the start of multiple large stakeholders in the palm oil industry going back on their social and environmental agreements. Numerous CSOs have tested the RSPO’s ability to sanction members over the years, with mixed results. In 2010, a complaint was brought against Sime Darby by the Forest People Programme. This subsequently forced the company to set up a sustainable partnership initiative with local communities affected by land grabs and Liberian environmental groups. The aim was to work together on guidelines for how the company could expand its operations.  However, my own recent conversations with Liberian government officials have revealed that both the company and government felt the RSPO intervention actually harmed the company’s ability to expand. Another case brought against Sime Darby has resulted in the complainant bringing action against the RSPO itself for its failure to make a decision. With such mixed results, it is almost surprising that no members have left the RSPO until now.  GVL has said that its leaving does not represent a “weakening of their commitment” to sustainable palm oil production. And it has even announced its own new sustainability action plan. All good in theory, but the RSPO was there to hold companies to account, and to give the people a way of making sure that global organisations cannot take their land. Although RSPO membership and adherence to its principles is voluntary, it has been a buffer, stopping large oil palm giants from potentially aligning with corrupt political elites in low income countries. It has stopped – to a certain extent – the erosion of the rights of poverty stricken rural communities, who may have the land beneath their feet taken away, or their local environment destroyed. The fact that any company could get away with a crime they had been accused of without any punishment – even when they held RSPO membership – makes one wonder what they may be able to get away with now that they are not bound by RSPO principles."
"Australia’s Great Barrier Reef made headlines in 2016 for all the wrong reasons. Part of the world’s largest coral reef had been turned almost white by warm seas and other stressors. The shocking sight drew worldwide attention to the process of coral “bleaching”. Bleaching occurs when water temperatures and other stressors are too extreme and disrupt the symbiotic relationship between the coral and the single-celled colourful algae which live inside them, causing the algae to be expelled and the white coral skeleton to become visible. Coral – technically an animal not a plant – can survive bleaching, but it is a sign of extreme stress and in the worst cases bleaching can cause the catastrophic loss of large areas of coral reefs. This is what happened with the Great Barrier Reef in 1998, 2002, 2016 and 2017. We know about those recent events as they have been widely observed and studied, but prior to the 1970s we have little understanding of coral bleaching due to scant observational records. This could mean that bleaching didn’t happen, happened very infrequently, that we didn’t know how to recognise it, or that we were not looking for it in the right places.  To better assess the survival chances of the Great Barrier and other coral reefs, we wanted longer-term records to help us understand how and why coral reefs end up bleaching in response to environmental change over the centuries. This in turn would give us a better sense of their ability to cope with recent rapid changes. Fortunately for us, coral colonies can live for hundreds of years keeping very good archives of their environment during that time. This is because, like trees, they have annual growth bands. The width, density and chemistry of the bands provides information on past growth rates, sea temperature and runoff from land during storms. To access those bands, scientists can drill out a long and thin “core”, removing a part of the skeleton without killing the coral itself. These cores can then be X–rayed or chemically analysed to understand the history of the coral – and its environment.  The Great Barrier Reef benefits from a wealth of cores extracted by scientists over the past four decades, giving a unique opportunity to understand patterns in past growth and bleaching, which can be identified from groups of successively very small bands in the coral skeleton. This new approach to reconstructing bleaching has allowed us to look back beyond the observational record, to reconstruct 400 years of bleaching along the Great Barrier Reef. We found that widespread bleaching had been occurring there since at least the 1600s. However, there has been a 10% increase in the proportion of corals affected since the late 1700s. Centuries ago, widespread bleaching was probably caused primarily by fluctuations in temperature. More recently, warm oceans have likely been compounded by other, human-induced, stressors including pollution or sediment and fertilisers washed into the ocean. Over the past 400 years, the time span covered by our cores, Great Barrier Reef corals have shown evidence that they can recover from widespread bleaching events. However, since the 1800s, both the number of such events and the number of corals involved have increased, indicating they may not be able to cope well with sustained increases in temperature, and are possibly reaching a tipping point. Future studies would benefit from longer cores, allowing us to look further back in time. Importantly, this 400-year record now allows us to identify that corals are moving out of a period during which they could cope with environmental change into one where they appear to be increasingly struggling. In the face of rapid and complex environmental change, coral reefs are not certain to survive."
"We have just entered a new decade, a decade where every month and every day will be absolutely crucial in deciding what the future will look like. Towards the end of January, chief executives, investors and policymakers will gather in Davos for the 50th anniversary of the World Economic Forum.  Young climate activists and school strikers from around the world will be present to put pressure on these leaders. We demand that at this year’s forum, participants from all companies, banks, institutions and governments immediately halt all investments in fossil fuel exploration and extraction, immediately end all fossil fuel subsidies and immediately and completely divest from fossil fuels. We don’t want these things done by 2050, 2030 or even 2021, we want this done now – as in right now. We understand and know very well that the world is complicated and that what we are asking for may not be easy. But the climate crisis is also extremely complicated, and this is an emergency. In an emergency you step out of your comfort zone and make decisions that may not be very comfortable or pleasant. And let’s be clear – there is nothing easy, comfortable or pleasant about the climate and environmental emergency. Davos is a Swiss ski resort now more famous for hosting the annual
four-day conference for the World Economic Forum. For participants it is
a festival of networking. Getting an invitation is a sign you have made
it – and the elaborate system of badges reveals your place in the Davos hierarchy. The meeting is sponsored by a huge number of international banks and corporations. For critics, “Davos man” is shorthand for the globe-trotting elite,
disconnected from their home countries after spending too much time in
the club-class lounge. Others just wonder if it is all a big waste of time.  The 2020 meeting is being advertised as focusing on seven themes: Fairer economies, better business, healthy futures, future of work, tech for good, beyond geopolitics and how to save the planet. Young climate activists and school strikers from around the world will be present at the event to put pressure on world leaders over that last theme.  Young people are being let down by older generations and those in power. To some it may seem like we are asking for a lot. But this is just the very minimum of effort needed to start the rapid sustainable transition. The fact that this still – in 2020 – hasn’t been done already is, quite frankly, a disgrace. Yet, since the 2015 Paris agreement, 33 major global banks have collectively poured $1.9tn (£1.5tn) into fossil fuels, according to Rainforest Action’s report. The IMF concluded that in 2017 alone, the world spent $5.2tn subsidising fossil fuels. This has to stop. The world of finance has a responsibility to the planet, the people and all other species living on it. In fact, it ought to be in every company and stakeholder’s interest to make sure the planet they live on will thrive. But history has not shown the corporate world’s willingness to hold themselves accountable. So it falls on us, the children, to do that. We call upon the world’s leaders to stop investing in the fossil fuel economy that is at the very heart of this planetary crisis. Instead, they should invest their money in existing sustainable technologies, research and in restoring nature. Short-term profit should not trump long-term stability of life. The theme of this year’s gathering in Davos is “stakeholders for a cohesive and sustainable world”. According to the forum’s website, leaders will meet to discuss ideas and improve our global progress on climate change. Our request to them is perhaps not so far-fetched considering that they say they understand and prioritise this emergency. Anything less than immediately ceasing these investments in the fossil fuel industry would be a betrayal of life itself. Today’s business as usual is turning into a crime against humanity. We demand that leaders play their part in putting an end to this madness. Our future is at stake, let that be their investment. • Greta Thunberg is a 17-year-old environmental campaigner from Stockholm, Sweden. This article was co-written with youth climate activists Jean Hinchliffe, Australia; Danielle Ferreira de Assis, Brazil; Joel Enrique Peña Panichine, Chile; Robin Jullian, France; Luisa Neubauer, Germany; Licipriya Kangujam, India; David Wicker, Italy; Julia Haddad, Lebanon; Oladosu Adenike, Nigeria; Iqbal Badruddin, Pakistan; Arshak Makichyan, Russia; Holly Gillibrand, Scotland; Alejandro Martínez, Spain; Isabelle Axelsson, Sweden; Sophia Axelsson, Sweden; Ell Jarl, Sweden; Mina Pohankova, Sweden; Linus Dolder, Switzerland; Vanessa Nakate, Uganda; Tokata Iron Eyes, USA"
nan
"The UK has a rich history of marine biology, with famous scientists such as Charles Darwin who did pioneering work in the field, and strong research institutions with international expertise in marine sciences. So, surely then, scientists must know everything there is to know about the country’s coasts and rockpools? Unfortunately not. While there are scientific names for the overwhelming majority of marine species on the country’s shores, we don’t necessarily know everything about the organisms themselves – or what lives inside them.  Back in 2012, researchers looked at how much was known about the biology of marine species around Britain and Ireland’s coasts, and concluded that there were considerable gaps in scientific knowledge. This extensive review of biological data looked at almost 1,000 species, including 148 species of fish and over 800 species of invertebrates such as worms, crustaceans, sponges, sea urchins and starfish. They looked at eight types of biological traits that may be known for each – including diet, growth, dispersion and reproduction – and found that information for all eight traits was only known for 9% of the species. While 20% of the species had no biological traits recorded at all. Despite researchers working hard, very few of these gaps have been filled in the six years since that paper was published. This missing information is critical to safeguard and conserve the waters which surround the UK. Scientists can’t properly determine the effects of, say, climate change or pollution on marine life if the factors which determine things like the timing of their reproduction aren’t known. 


      Read more:
      Octopuses: How citizen scientists are uncovering their secrets


 And when we talk of creatures that live around the country’s shores, we can’t ignore the species that live on or inside them. Take parasites, for example. Trematodes, nematodes, microsporidians, paramyxeans, gregarines and protists aren’t household names in the kingdom of life. However, the typical animals that might be found around UK shores (crabs, worms, oysters and starfish) are home to multiple species of parasites. Some of these parasites are also home to parasites themselves (known as “hyperparasitism”). Parasites are considered the most abundant and diverse creatures on the planet, and they play an incredibly important role in how wildlife interact with ecosystems. Though microscopic, parasites can affect how fast organisms can grow or mature, make them exert abnormal behaviours, and influence where they live too.  They can even feminise their hosts, changing some crustaceans from male to female. Some time ago we discovered a microsporidian parasite was the cause of feminisation in the shrimp-like amphipod (Echinogammarus marinus). And we recently found out that two parasites combined, or possibly another new species of parasites (a paramyxean), might be involved in the feminisation too.  This amphipod also turned out to be host to an undescribed species of trematode parasite that can change its behaviour, making it more attracted to light – a consequence of which is that it’s more likely to get eaten, completing the parasites’ lifecycle. In just one quite common species we have found multiple undescribed species of parasites. Given the thousands of marine species around British and Irish shores, it is highly conceivable that there are many new discoveries like ours to be made. But more importantly, we must get to know the biology of known marine life and their parasites if we wish to understand how ecosystems function, the human impacts, and safeguard the environment’s future.  As the world has focused on unlocking human genomes, the costs of rapidly mapping the genetic blueprints of wildlife have fallen dramatically. Scientists have the tools at their disposal, to analyse the genes of animals that live on UK shores, and the organisms that live inside them. Each marine species is an island, home to multiple others, and only if we start to disentangle their genetic codes can we begin to understand to truly understand what life is like on the UK’s oceanic doorstep."
"Japanese knotweed, a widespread invasive non-native species in the UK, is seldom out of the news and can strike fear into the hearts of anyone who finds it growing on their property, house owner or developer alike. It is a tall, herbaceous and fast-growing plant that reduces biodiversity and can increase the risk of flooding.  Japanese knotweed – Fallopia japonica – is associated with a significant economic burden in the UK. Recently, a court in Wales ruled that homeowners were entitled to claim damages from Network Rail because rhizomes (the plant’s underground shoots) had extended below their properties. Japanese knotweed is subject to various legislation and mortgage lenders often require that an insurance-backed management plan for the plant is in place when it is present on or near a property before agreeing to a mortgage. The presence of the species can also result in a reduction of a property’s value. Japanese knotweed’s often quoted abilities to grow through concrete, damage buildings and extend destructive rhizomes seven metres from the above ground portion of the plant are among the most feared features of the plant. But it is exactly these supposed abilities that our new research challenges. I teamed up with lead author Mark Fennell and co-author Max Wade, both members of the environment and ground engineering team at global services firm AECOM, to present the most comprehensive study to date assessing the ability of Japanese knotweed to cause damage to built structures compared to other plants. What we found is at odds with what is currently accepted and may help to alleviate fears that the plant can grow through concrete or cause major structural damage to buildings. There are three primary ways plants can damage buildings: indirect damage though subsidence or heave; direct damage though collapse and impact; and direct damage through the accumulated pressure of plant growth. We assessed the evidence that Japanese knotweed can cause each of these types of damage and how the possibility of Japanese knotweed causing damage in these ways compares to other plants. A detailed survey of the literature revealed that indirect damage caused by plants is only possible on shrinkable clay soils, a type of soil that is not particularly common in the UK. Even where the most shrinkable soils are found, the biology and size of Japanese knotweed makes it less likely to facilitate this type of damage than large trees. This means that the risk of Japanese knotweed causing damage by modifying soil water content is extremely remote and only relevant in areas with exactly the right type of soil. Our next step was to conduct a survey of members of the Property Care Association and Royal Institution of Chartered Surveyors who have been involved in property surveys and treating or removing Japanese knotweed in the UK. Respondents were asked to report whether they had observed damage to buildings occurring with Japanese knotweed. Only between 2% and 6% of respondents reported any co-occurrence of Japanese knotweed and structural damage to buildings. Our paper also concluded that where Japanese knotweed is associated with damage, it is likely that the plants will have exacerbated existing damage, rather than being the initial cause of the damage.  Further to this, we asked respondents to report the lateral extension of underground shoots in cases where they had undertaken full excavations of Japanese knotweed. This allowed us to test the “seven-metre rule” commonly used to denote whether Japanese knotweed is likely to pose a threat to buildings.  We found that smaller stands of Japanese knotweed (less than four square metres in area) generally had rhizomes no longer than two metres and not beyond four, while 75% of larger stands had rhizomes extending no further than 2.5 metres. We received only one report of rhizomes over four metres in length. This shows that the fear of Japanese knotweed commonly having seven-metre rhizomes is unfounded and the use of the seven-metre rule is not robust for determining the likely lateral extent of these underground shoots. We then assessed 68 abandoned properties on three streets in northern England with a significant Japanese knotweed infestation, to determine whether these houses had damage caused by the presence of the plant. Many properties had Japanese knotweed present or nearby but we found no evidence to suggest that the dilapidation of the properties was caused by the plant. In fact, the other plants – particularly some woody trees – were visually associated with more damage. This area represented a near worst case scenario for houses that had been left to the mercy of Japanese knotweed and still we found no evidence for the plant causing damage. Overall, our study found no support for the commonly suggested ideas that Japanese knotweed routinely damages buildings and that its influence extends seven metres from plants above ground. Nor did we find evidence that it poses a major risk to built structures. Japanese knotweed remains a serious threat to Britain’s biodiversity, ecosystems and the amenity value of land, but these very real threats should not be confused with what our research shows to be myth more than fact. Japanese knotweed is no more of a risk to solidly built homes and buildings than many plants and less so than many woody species, particularly some large trees. 


      Read more:
      We've found the best way to control Japanese knotweed


 Our research highlights that the key to tackling invasive species lies in developing a detailed understanding of their biology and further highlights the ongoing need for new research and knowledge to help us to understand and, hopefully, address the emerging challenges presented by invasive non-native species."
"Not so long ago, one of the reigning cliches around the subject of climate crisis was that it was a “looming catastrophe”. The situation was urgent, yes, and catastrophe was more or less imminent, but when people talked about it they mostly stuck to the future tense. It’s hard to identify the precise moment when the crisis moved from the horizon of popular imagination to the immediate foreground, but the spectacle in recent weeks of a continent in flames feels like a clear indication that the time of looming has ended and the catastrophe proper has commenced. The other day I messaged an Australian friend, a volunteer firefighter in Melbourne who had spent the week between Christmas and new year in East Gippsland, where thousands of people have been evacuated from their homes. After informing me she was home and safe, and requesting that I arrange for some Irish rain to be redirected down there, she sent me a photo she had taken on the job: an image of a narrow dusty road leading toward low hills dotted with trees, behind which the sky itself was a vast inferno of dark smoke and glowing flame. I stared at her photo for a long time, and kept returning to it all that day.  There was something both bizarre and instructive about the image, the way in which the gentle bucolic scene in the foreground was juxtaposed surreally against the literally hellish sky behind it. It made me think of René Magritte’s Empire of Light series of paintings, in which scenes of a residential street at night are presided over by a bright, daylit sky. It also made me think of what life is basically like now: a calm foreground with an inferno on the horizon. And it struck me that this would be a thing that would happen at the end of the world. People would point their phones at the fire in the sky, and they would send photos to their friends in other places. “This is what the apocalypse looks like here,” they would say. “How is it where you are?” There would be a great storm of content and engagement, and then there would be nothing at all. One thing that is often remarked about climate crisis is that the subject is characterised by a strange form of cognitive dissonance. You read about the melting ice caps, the rising temperatures, the mass extinctions, and you understand intellectually that something truly terrible is happening. It doesn’t feel like that on the nerve endings, though. On the nerve endings, it feels like an unseasonably warm day in January. But what is happening in Australia, and the images that are emerging from the fires, feels like a closing of the gap between the scientific evidence and the field of immediate perception. A little boy in a facemask in a small boat at sea, his hand on the outboard tiller, the sky behind him an incandescent haze. Two horses in silhouette against a burning forest. Crowds of masked people taking refuge on a beach. That same beach littered with the corpses of tropical birds. A kangaroo burned alive, trapped by a barbed wire fence. All these scenes suffused with a malignant red glow, as though put through an Instagram filter named “Inferno”. It looks like a film. It looks like a video game. It looks like what we have always imagined the end of the world would look like. In East Gippsland, where my friend had been dispatched to fight the fires after Christmas, the situation was so severe that the government issued an emergency warning telling the remaining residents that it was too late to evacuate. “You are in danger,” read the warning, “and need to act immediately to survive.” Here on the other side of the world, thousands of miles from the immediate peril of the fires, it’s impossible not to read this as a warning about the broader climate emergency. It’s the message we’ve been hearing from scientists and activists for decades. And it is undoubtedly the message of those apocalyptic images from Australia, bathed in the crimson radiance of catastrophe. If God himself were to materialise and deliver this message, it could not be any clearer, any more urgent. You may recall, in fact, that it was by means of a burning bush that God announced it was time to lead the Israelites out of Egypt. Yet the most disturbing thing about the images of the fires is not that they might signal the end of the world, but that they might signal how the world will continue. That we might just get used to large parts of the planet being on fire, and even larger parts of it being underwater. And more disturbing still, that we might harden our hearts against the people who live and die in the floods and the fires.  Because when I look at the images of those Australians crowded on the beaches, fleeing the smoke and the flames, there is a kind of double exposure effect, whereby I see the ghostly image of those other refugees who have come by boat to Australia from places where they were no longer safe, only to be held indefinitely and in appalling conditions on offshore detention facilities in the South Pacific. In the rest of the world, their suffering has been mostly ignored. These people know better than anyone what an apocalypse looks like. It’s not the melting of the ice-caps or the burning of the forests that seem to me to be the real apocalyptic scenario, but rather the slow atrophying of our moral imaginations; not the inferno itself, but the indifference of those of us who are not yet on fire. In this sense above all we are in danger, and we need to act immediately to survive. • Mark O’Connell is a writer based in Dublin. His book Notes from an Apocalypse will be published in April"
"Lies have spread faster than grassfire during Australia’s unprecedented national emergency. They’ve ranged from the exaggerated to the outrageous.  One conspiracy bizarrely claims bushfires have been lit to clear a path for high-speed rail down Australia’s east coast. Others baselessly claim Islamic State is instructing its followers to wage war on the country with fire, that Chinese billionaires are using lasers to clear the path for new cities, or that eco-terrorists are trying to spur action on climate change by manufacturing a catastrophe. Accompanying these laughable mistruths, though, are more dangerous distortions. They are the ones being used to deflect from climate change’s role in creating longer, more severe fire seasons. Two pieces of disinformation stand out from the rest: that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush. Disinformation has spread across social media, finding its way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists like Alex Jones. Esteemed climate change expert professor Will Steffen, a member of Australia’s Climate Council and the inaugural director of Australian National University’s Climate Change Institute, is concerned at how disinformation has spread with such ease. “In my mind, I think it’s a serious issue and it is potentially very dangerous,” Steffen told the Guardian. “That’s because the bushfire situation is very dangerous … the evidence is overwhelming that climate change is playing a prominent role in worsening bushfire conditions across Australia. “People who are for whatever reason trying to put out false or extremely misleading information are actually doing a huge disservice to the risk to human life in the future, the risk to property, the risk to the natural world, and indeed the risk to economy.” Digital rights experts say the disinformation is yet more evidence that social media platforms are failing in their duty to act responsibly. “We need to see social media platforms playing a greater role in responding to the disinformation being shared on their platforms about the bushfires,” Digital Rights Watch chair Tim Singleton Norton said. “This needs to happen in tandem with effective government oversight, transparency, and accountability measures, as well as public education campaigns that give people the tools to identify misinformation.” Hazard reduction is absolutely an important factor when it comes to fire management ... but it is not the panacea There are nuggets of truth in some of the disinformation. Arson has always been a serious problem in Australia, particularly at times of heightened fire danger. Arsonists have been responsible for some of Australia’s worst bushfires, including a blaze during the horrific 2009 Black Saturday fires that killed 10 people, and arson is a common cause of ignition. New South Wales police say they have charged 24 people for lighting bushfires since November. This time around, though, the role of arson has been grossly exaggerated. Suggestions of an arson epidemic began to ferment on social media at the height of the crisis around New Year’s Day. On Twitter, much of the disinformation centred around the #arsonemergency hashtag. Queensland University of Technology senior lecturer Timothy Graham, an expert in social media analysis, took a sample of tweets from the hashtag and analysed them for characteristics typically associated with bots and trolls. His findings suggested a clear “disinformation campaign”. “Australia suddenly appears to be getting swamped by mis/disinformation as a result of this environmental catastrophe, and we are suffering the consequences in terms of hyped up polarisation and an increased difficulty and inability for citizens to discern truth,” Graham told the Guardian. Claims of an arson emergency were spurred along by some mainstream outlets. Channel 7, a major commercial television network, tweeted that police were “now working on the premise arson is to blame for much of the devastation caused this bushfire season”. The tweet neither reflected what police had said or what Channel 7 had itself reported in its news story. A story in the Murdoch-owned national broadsheet, The Australian, also falsely claimed that 183 arsonists had been arrested in the “current bushfire season”. That piece also went global. It was tweeted by Donald Trump Jr and followed up by InfoWars, a right-wing US website, which stated: “Authorities in Australia have arrested close to 200 people for deliberately starting the bushfires that have devastated the country, yet the media and celebrities continue to blame ‘climate change’ for the disaster.” The number was a gross exaggeration. It was arrived at by counting a range of bushfire-related offences other than arson – including contraventions of fire bans, for example – and used annual figures, not those for the current fire season, which began in September. The Australian subsequently updated its story. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. That claim was running hot on social media, and was given credibility by figures like federal Nationals MP Barnaby Joyce, a prominent Australian politician, who said “green caveats” were stopping firefighters from reducing fuel loads. This is at complete odds with statements by the RFS commissioner, Shane Fitzsimmons, who said the single biggest barrier to hazard reduction is the increasingly hot and dry weather and the “shrinking window of opportunity” within which managed burns could safely take place. Fitzsimmons said hazard reduction is also of little utility in fires as intense as those experienced in NSW this season. “Hazard reduction is absolutely an important factor when it comes to fire management and managing fire in the landscape but it is not the panacea,” Fitzsimmons said on Wednesday. Comments like Fitzsimmons’ have done little to stop the idea taking hold. Prime minister Scott Morrison has nominated the lack of hazard reduction work as a key issue he wants to investigate after the current crisis. At the same time, Morrison has demonstrated little appetite for strengthening climate action."
"
Share this...FacebookTwitterAuthors of a new paper published in the journal Science (Gebbie and Huybers, 2019) insist “the deep ocean ultimately plays a leading role in the planetary heat budget.” The global deep ocean has much less heat today than it had during both the Medieval Warm Period and the Little Ice Age.

Image Source: Gebbie and Huybers, 2019
A Bottom-Up Heat Flux?
The deep ocean may warm hundreds (to thousands) of years before hemispheric surface temperatures and CO2 concentrations do (Stott et al., 2007).
Image Source: Stott et al., 2007
This bottom-up hemispheric-scale heat flux – independent of CO2-forcing – may occur for land area as well.
“The increase of carbon dioxide concentrations occurred 2–3 thousands of years later than the heat flux increase and synchronously with temperature response.”  (Demezhko and Gornostaeva, 2015)
“GST [ground surface temperature] and SHF [surface heat flux] histories differ substantially in shape and chronology. Heat flux changes ahead of temperature changes by 500–1000 years.” (Demezhko et al., 2017)
 “During the Last Glacial Maximum 26–19 thousand years ago (ka), a vast ice sheet stretched over North America [Clark et al., 2009]. In subsequent millennia, as climate warmed and this ice sheet decayed, large volumes of meltwater flooded to the oceans [Tarasov and Peltier, 2006; Wickert, 2016]. This period, known as the ‘last deglaciation’, included episodes of abrupt climate change, such as the Bølling warming [~14.7–14.5 ka], when Northern Hemisphere temperatures increased by 4–5°C in just a few decades [Lea et al., 2003; Buizert et al., 2014], coinciding with a 12–22 m sea level rise in less than 340 years [5.3 meters per century] (Meltwater Pulse 1a (MWP1a)) [Deschamps et al., 2012].” (Ivanovic et al., 2017)
Deep ocean heat leads surface temperature change yet today?
A new paper indicates that the deep ocean in the Pacific has continued cooling in recent decades, extending the long-term cooling trend that commenced after the warmer-than-today Medieval Warm Period ended.
Other authors (Wunsch and Heimbach, 2014) have also documented a global-scale deep ocean (below 2,000 meters) cooling trend within the last few decades.
“About 52% of the ocean lies below 2000 m and about 18% below 3600 m. … A very weak long-term [1993-2011] cooling is seen over the bulk of the rest of the ocean below that depth [2,000 meters] including the entirety of the Pacific and Indian Oceans, along with the eastern Atlantic basin.”  (Wunsch and Heimbach, 2014)

Image Source: (Wunsch and Heimbach, 2014)
Little Ice Age conditions may still dominate in the deep ocean despite the dramatic rise in CO2 concentrations during the last few hundred years — from about 280 ppm during the late 1700s to well over 400 ppm today.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The global ocean below 2000 meters may actually be colder today than during the 18th century.

Gebbie and Huybers, 2019
The Little Ice Age and 20th-century deep Pacific cooling
“The ongoing deep Pacific is cooling, which revises Earth’s overall heat budget since 1750 downward by 35%.”
“In the deep Pacific, we find basin-wide cooling ranging from 0.02° to 0.08°C at depths between 1600 and 2800 m that is also statistically significant. The basic pattern of Atlantic warming and deep-Pacific cooling diagnosed from the observations is consistent with our model results, although the observations indicate stronger cooling trends in the Pacific.” 
“These basin-wide average trends are used to relax the assumption of globally uniform changes in surface conditions and to constrain regional temperature histories for 14 distinct regions over the Common Era by a control theory method. The result, referred to as OPT-0015, fits the observed vertical structure of Pacific cooling and Atlantic warming. Global surface changes still explain the basic Atlantic-Pacific difference in OPT-0015, but greater Southern Ocean cooling between 600 and 1600 CE leads to greater rates of cooling in the deep Pacific over recent centuries.”
“OPT-0015 indicates that the upper 2000 m of the ocean has been gaining heat since the 1700s, but that one-fourth of this heat uptake was mined from the deeper ocean. This upper-lower distinction is most pronounced in the Pacific since 1750, where cooling below 2000 m offsets more than one-third of the heat gain above 2000 m.”
“Finally, we note that OPT-0015 indicates that ocean heat content was larger during the Medieval Warm Period than at present, not because surface temperature was greater, but because the deep ocean had a longer time to adjust to surface anomalies. Over multicentennial time scales, changes in upper and deep ocean heat content have similar ranges, underscoring how the deep ocean ultimately plays a leading role in the planetary heat budget.”


Image Source: Gebbie and Huybers, 2019

A lack of long-term CO2→OHC correlation 
It may be worth a closer look at the graph of global ocean heat content (OHC, 0 m-bottom) during the last 2,000 years from Gebbie and Huybers (2019).

Image Source (bottom graph, heavily annotated): Gebbie and Huybers, 2019
It is interesting to note the multiple centennial-scale warming and cooling trends during the last two millennia that exceed the rate and amplitude of the ocean heat changes that have occurred since 1950, or since atmospheric CO2 concentrations began rising dramatically.
For example, despite the very modest  associated changes in atmospheric CO2 concentrations (< 5 ppm), it appears that both the 1850-1875 and 1925-1945 global warming periods in the 0-700 m layer exceeded the rate and amplitude of the heat content changes since 1950.
As the global oceans rapidly warmed and cooled in the centuries preceding modern times (i.e., the Medieval Warm Period and Little Ice Age), the corresponding CO2 concentrations were remarkably stable, neither rising with the warming or falling with the cooling.
Considering 93% of the Earth’s heat changes are expressed in the global ocean, and that just 1% of global warming is said to be reflected in surface air temperatures (IPCC, 2013), the lack of conspicuous correlation between ocean heat content and CO2 during the last 2,000 years would seem to undermine claims that atmospheric CO2 concentration changes drive zero-to-bottom global ocean warming.
Share this...FacebookTwitter "
"Smoke from this season’s bushfires has turned the sun red, the moon orange and the sky an insipid grey. It has obscured iconic views tourists flock to see. Far more than an aesthetic problem, it has forced business shutdowns, triggered health problems and kept children indoors for weeks. City dwellers in south-east Australia have been forced to take a crash course in the finer points of air pollution. We’ve learned about the dangers of inhaling tiny PM2.5 particles (those 2.5 microns or fewer in diameter). We’ve learned that only a close-fitting P2 mask will do much to protect us. Still, we wear disposable paper masks and hold handkerchiefs to our faces, hoping any amount of filtering is helpful. Even for an historian of air pollution like me, this situation is a shock. It is not the first time Australia’s major cities have been shrouded in bushfire smoke. But the terrible air quality is unmatched in terms of severity, duration and extent. Historically, air pollution from smoke was considered outside human control and not subject to regulation. But these bushfires are clearly linked to global warming, for which government, corporations and individuals are responsible. It’s time to rethink the way we protect air quality. In recent weeks, apps such as AirVisual have confirmed what we city dwellers can already see and smell: since the fires on the north coast of New South Wales began in late October, our air quality has plummeted. The NSW government’s Air Quality Index data has shown that since late October, days when the index was higher than 100 – signalling exposure is unhealthy – have outnumbered clear days in Sydney, Newcastle and the Illawarra. Index readings above 2,550 have been recorded in Sydney, while the Monash monitoring site in Canberra reached a choking 5,185 at 8pm on New Year’s Day. Bushfire smoke has affected the cities of NSW and the Australian Capital Territory in the past. In late January 1926, when Canberra was just emerging as a city, a thick haze of smoke sat over the site. Fires came within metres of Yarralumla, the residence which, the following year, would become home to the governor general. In several years in the mid-1930s, bushfires burning to the north of Sydney left the city air thick with smoke. In October 1936, bushfire smoke forced a motor liner arriving from Hong Kong to warily enter the harbour sounding its siren, because it was invisible to signallers on South Head. A New Zealand pilot, flying into Sydney from Longreach the following month, had to fly blind in “great clouds of dense smoke” covering much of NSW. In 1939, Canberra was covered by what the visiting writer HG Wells described as a “streaming smoke curtain”. In the summer of 1944, Sydney was again enveloped in a smoke haze, this time from fires in the Blue Mountains and (later Royal) national park in November. Photographs published at the time show the Sydney Harbour Bridge barely visible through dust and smoke at midday. The ongoing fires were blamed for an increase in diseases of the ears, nose and throat, and for cases of influenza and pneumonia, leading to a shortage of hospital beds. In November 1951, all of NSW was said to be blacked out by bushfire smoke. In Sydney on the worst days, records show all four of the city’s airfields were closed because of “smoke-fog”. In each of these episodes, bushfire smoke disrupted transport, commerce, health and the enjoyment of the urban environment. But even as other forms of air pollution began to be regulated, smoke from bushfires escaped legislative attention. What was understood as air pollution were the unwanted byproducts of industrial processes, whereas bushfire smoke was viewed as natural. In NSW in 1866, an act based on British legislation restricted smoke from mills, distilleries and gas works. Further limitations on smoke production in built-up areas were included in later acts governing public health (1902), motor traffic (1909) and local government (1919). After the second world war Newcastle, the site of the country’s largest concentration of coal-burning heavy industry, began to pay closer attention to managing air quality. This pioneering work was given added urgency after 4,000 people died in heavy London smog in 1952. In 1958, a NSW parliamentary committee delivered a report into smoke abatement. It did not mention recent issues with bushfire smoke, and also dismissed the impact of domestically produced smoke. The subsequent 1961 Clean Air Act focused on air pollution from industry, transport and power generation. Air pollution legislation continued to evolve in following decades, targeting motor vehicle emissions in the 1970s, backyard burning of waste in the 1980s, and wood fires used to heat homes in the 1990s. These measures have been successful. A 2006 study found that between 1998 and 2003, on the limited occasions when standards for PM10 in six Australian cities were exceeded, the main sources were not industry or transport, but dust storms and bushfires (with the exception of Launceston, where heating fires were the main contributor). Today, bushfire smoke is excluded from air quality regulations, despite its obvious role in pollution. It is still considered natural and beyond human control. However, the link between the current fires and human-caused climate change, long predicted by climate scientists, suggests this exemption is no longer valid. As the Australian National University’s Tom Griffiths has written, the current fires in some ways repeat patterns of the past. But “the smoke is worse, more widespread and more enduring”. When Australia begins the recovery from these fires, our business-as-usual approach requires a rethink. Measures to protect air quality should be a major part of this. It is time that corporations, governments and societies which contribute to global heating be held to account for more frequent, intense and widespread bushfires, and the smoke which billows from them. Nancy Cushing is an associate professor at the University of Newcastle This piece was originally published in the Conversation"
"I recently flew to Florida to visit family. My round-trip economy seat emitted roughly two tonnes of carbon dioxide, according to one carbon offsetting website. By contrast, the average person in Britain is responsible for roughly seven tonnes for the entire year, already quite high by global standards. This makes me a climate change villain. Dumping such huge amounts of carbon into the atmosphere seems clearly morally wrong, because of the harm this will cause others. But carbon offsets let me fly with a clear conscience – for now. When I buy an offset, carbon emissions are reduced elsewhere, cancelling out those from my flight. It might involve planting or preserving trees, or installing cheap and efficient stoves. Offsetting my Florida trip cost £13 – a couple of drinks in the departures lounge. Convenient. But perhaps too easy? Offsetting clearly raises the scientific question of whether a purchase will really reduce global carbon emissions. This is difficult and controversial stuff, better suited to climate scientists and economists. Philosophers, by contrast, deal in hypotheticals. So let’s assume that offsetting “works” and it cancels out my flight emissions. Does that make the flight morally OK? Many people remain suspicious. The writer and environmentalist George Monbiot famously compared carbon offsetting to the sale of medieval Catholic indulgences, where the rich could buy themselves out of sin. Monbiot writes that from sellers of offsets, “you can now buy complacency, political apathy and self-satisfaction”. But I think he is wrong. In moral philosophy, so-called “consequentialist” theories say that when it comes to the rightness or wrongness of some action, the consequences are all that matter. If any ethical theory vindicates offsetting, it is this. Consequentialism has problems as a general moral theory. For example, it might license horribly unjust actions now, such as killing one innocent person because their organs will save the lives of five seriously ill people. Consequentialism cares only about the “total”, which seems wrong in the case of human lives: five saved lives don’t normally outweigh one murder.  Those who benefit from the offset might not be the same people harmed by the flight, but when it comes to climate, we should care (at least a bit) about the total amount of carbon in the air. So a focus on total emissions does seem at least partly correct about the environment. Another ethical worry is that offsets are only cheap because few people buy them. For instance, one cheap method of offsetting is to replace inefficient stoves in the developing world. This saves lots of carbon for little money. However these savings can’t go on forever, and when eventually the last stove is replaced, the schemes will get more expensive. In the philosophical jargon, cheap offsetting depends on “partial compliance”. But this is not always a problem: it’s not a moral problem for voting that if everybody voted, the queue at the polling station would be longer. Rising prices lead to a second worry. As philosopher Kai Spiekermann has noted, the robustness of the motivation to offset is a little dubious. Maybe I’ll pay the £13 now, but what about £200? What if I can’t afford that – will I really give up flying altogether? I’m not sure. But I think this problem is irrelevant to my Florida flights. If offset prices go up, and in a decade I fly without offsetting, then that will be morally wrong. Perhaps it will also show that my motivation this year wasn’t very robust. But it won’t show that this year’s flight-and-offset package was wrong. By analogy: suppose that you stop giving to charity when the economy crashes. This might show that your donations during the good times were not backed by very robust moral motivation – you only helped when it didn’t sting too much. That’s not great. But it doesn’t mean that your donations during the good times were morally wrong. Wouldn’t it be better if we all give up flying because of climate change, rather than fly and offset? Even defenders of offsetting often say this. But flying brings real benefits, even if only to a fraction of humanity. If we can get those benefits without harming the environment, then that’s a good consequence, which counts for something morally. Even thinking about offsetting can be beneficial. Spend some time with a carbon offset calculator, and you will likely face some uncomfortable truths. Rich people (in global terms) like travel, and one such truth is that there’s no carbon-friendly way to cross the ocean. Last year, my family took the boat from Southampton to New York for a close friend’s wedding, partly for climate reasons, and partly to avoid a flight with a toddler. We were dismayed to learn that the cruise ship was probably worse for the environment than flying would have been. As with tipping in American restaurants, a good slogan might be: “If you can’t afford the offset, then you can’t afford the flight.” But many people who oppose tipping on moral grounds don’t stop dining out. They just stop tipping, which is the worst of both worlds. Don’t be like that. So assuming, as I have been, that offsetting does work, stop worrying about the climate impacts of flying, if you can afford to offset – and actually do so."
"
Share this...FacebookTwitterA retired German climate scientist says the IPCC has ventured into “the red rev range of ideology and reality loss”, and adds there is no stringent scientific proof of CO2’s influence on climate
At the European Institute for Climate and Energy (EIKE), a German climate scientist, wonders if the IPCC and German media have lost their grip on reality as they place the blame for global warming on human CO2 emissions.
Prof. Dr. Horst-Joachim Lüdecke writes that the IPCC is in the “red rev range of ideology and reality loss” as the German media and politicians renew their calls to drastically cut back CO2 emissions in order to keep the planet from “dangerously overheating”.
The German climate scientist, however, says CO2’s impact on the climate are exorbitantly overblown.
Germany’s share of global CO2 negligible
First Prof. Lüdecke reminds that Germany’s share of global CO2 emissions is so puny that any reductions efforts by the country will have no detectable effect on global temperatures, and cites a Report of the PBL Netherlands Environmental Assessment Agency.
In the report’s Fig. 2.3 we see:
&amp;lt;img class=”alignnone size-medium wp-image-49858″ src=”https://www.eike-klima-energie.eu/wp-content/uploads/2018/10/pbl-2017-640×412.jpg” alt=”” width=”640″ height=”412″ srcset=”https://www.eike-klima-energie.eu/wp-content/uploads/2018/10/pbl-2017-640×412.jpg 640w, https://www.eike-klima-energie.eu/wp-content/uploads/2018/10/pbl-2017-768×494.jpg 768w, https://www.eike-klima-energie.eu/wp-content/uploads/2018/10/pbl-2017-1024×658.jpg 1024w, https://www.eike-klima-energie.eu/wp-content/uploads/2018/10/pbl-2017.jpg 1213w” sizes=”(max-width: 640px) 100vw, 640px” /&amp;gt;


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Image (Fig. 2.3): Emissions of climate gases worldwide (here)
As the chart shows, the European Union share of global emissions is only 9%. At 2.5%, Germany is a mere fraction of that.
“Already we see that our share globally is negligible,” Lüdecke writes.
“Fictional” damage
Lüdecke also doubts the large role CO2 is claimed to have on climate, and characterizes the notion the climate is somehow damaged by human CO2 as “fictional”.
“No stringent proof” manmade CO2 influences climate
The retired German professor also says that according to the scientific literature: “To date, there is no stringent proof that the anthropogenic, i.e. human-made (!) CO2 has exerted any influence on the climate which is clearly traceable to this source.”
Lüdecke adds that the temperature increase seen at the end of the 20th century is well within the range of natural variability and is not unusual and that, if anything, CO2 is good for the planet.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe European Institute for Climate and Energy (EIKE) posted a video of prominent German geologist Dr. Stefan Kröpelin, who in a presentation late last year in Munich called the notion of CO2-induced climate tipping points scientifically outlandish.
He also called the prospect of the Sahara spreading into Europe preposterous. 
EIKE recently wrote an article on the presentation and posted the presentation (in German). The article follows in English (headings added):
==========================================
The Green Past of the Sahara
Stefan Kröpelin geographer and geologist who, after his training at the Free University of Berlin, has been working at the Institute for Prehistory and Early History in Cologne since 1995. He is one of the most renowned expedition researchers in the field of “Climate, Cultural, and Landscape Change in Arid Africa,” and is best known for his scientific travels to Sudan and Chad. In his career he has undertaken about 60 expeditions, which have been presented in numerous popular science TV programs.
Sahara once a paradise
In his lecture, Dr. Kröpelin first gave an overview of the Eastern Sahara located in Sudan, Chad, Libya and Egypt. The region is the driest place on planet Earth today. But thanks to natural climate change over the millennia, this has not always been the case. On the contrary: if you think of the Hungarian researcher László Almásy, known from the book and film “The English Patient”, who discovered “swimmers” on cave paintings in Eastern Sahara as early as the 1930s, you know that the area was once a paradise.
Explorer Kröpelin was able to confirm Almásy’s assumptions through his work – and even add an almost unbelievable fact.
Higher temperatures 7500 years ago
The paradisiacal humid conditions in the east of the Sahara prevailed between about 8,500 and 5,300 B.C., i.e. after the last Ice Age and at the beginning of the Neolithic, when higher temperatures led to frequent rainfalls, and thus raised the groundwater level considerably, and allowed surface waters and rich vegetation.
As a result of the gradual drying up of the region over the last 7,000 years, the human inhabitants migrated south to present-day Sudan or later to Egypt, where they founded the Earth’s first advanced culture on the Nile with its fertile floods.

Video of Dr. Stefan’s lecture on the slow drying up of the Sahara on the occasion of the 12th IKEK in Düsseldorf in November, 2018
Cooling means a drying Sahara


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The slow drying out of the Sahara was caused by a successive cooling of the climate, analogous to the formation of savannahs through warming. Interestingly, today’s Sahara desert does not have the dimensions it had during the maximum of the last ice age about 20,000 years ago. At that time, the desert extended hundreds of kilometres further south into today’s Sahel zone.
Lake sediment, cave paintings unlock secrets of the past
How could Dr. Kröpelin reconstruct climate events in North Africa over the millennia? What natural climate indicators does the region offer?
One of the best sources of climate data are the deposits at the bottom of the largest lake in the Sahara, Lake Yoa in the oasis of Ounianga in north-eastern Chad, from which as much water evaporates every day as the city of Cologne consumes every day.
The loss is compensated by the abundant fossil groundwater resources. But it is not only hidden data deep in the ground that are suitable for precisely reconstructing the past of the climate in the last decades – the human settlement of the region and its legacies are also a reliable climate indicator. Particularly impressive in this context are the aforementioned cave paintings, which were able to withstand the sandstorms and the heat surprisingly well. These prehistoric works of art were not made in a short time, but over thousands of years. The depicted objects like the floating people or cattle herds stand for different phases of the colonization.
“Tipping Point” catastrophe theory contradicted

The proven gradualness of climate change at that time contradicts the “Tipping Point” catastrophe theory, which predicts a “climate collapse” with drastic changes in the environment in only one human generation. In fact, Kröpelin’s research shows that climate change in the Sahara has been so slow that people have hardly noticed anything about it during their lifetime.
Stefan Kröpelin also refers in this context to the political use of the current climate catastrophe theory, which is even misused for mass immigration policy.
The exponential increase in the world population over the next 50 years is the real problem facing our civilization.
A Sahara reconstructed timeline follows:


Cropped from video here posted above. EIKE
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterInnovation Award for Climate-Friendly Methane Cracking

Producing Hydrogen from Natural Gas without Emissions: German Gas Industry Honors a Process Developed by Researchers from Karlsruhe and Potsdam – KIT Spin-Off Ineratec Receives Special Award for Innovative Startups

The experimental reactor for methane cracking is part of the liquid metal laboratory at KIT (Photo: Amadeus Bramsiepe, KIT)
Generating energy from natural gas without climate-damaging CO2 emissions – that’s the promise of a new technology developed in a joint research project by scientists at Karlsruhe Institute of Technology (KIT) and the Institute for Advanced Sustainability Studies (IASS) in Potsdam. Natural gas, which mainly consists of methane, is converted into hydrogen and fixed carbon. For their work, the researchers have now received the German Gas Industry Innovation Award. KIT was also honored with a new special award for the most innovative startup which was presented to Ineratec, a spin-off of the research university.

“The German Gas Industry Innovation Award for the new methane cracking process is testament to the innovative spirit of our scientists,” says the President of KIT, Professor Holger Hanselka.
“The option of using fossil natural gas in a climate-friendly way in the future can make a major contribution to curb CO2 emissions. I am very pleased that we, as the research university in the Helmholtz Association, can make this important contribution to climate protection together with our partners.” The award was presented to the research team consisting of scientists from KIT and IASS on November 22 in Berlin. The research team also won an additional award voted for by the attendees at the ceremony. The event was held under the auspices of the Federal Minister of Education and Research, Anja Karliczek.
 
 The winners of the 2018 German Gas Industry Innovation Award from KIT and IASS in Potsdam (Photo: Claudius Pflug)
The new process makes it possible to use natural gas in a climate-friendly manner. “Instead of directly burning natural gas, which mainly consists of methane, we break it up into its components hydrogen and carbon,” says Dr Stefan Stückrad who has co-managed the research project at IASS. The hydrogen produced in methane cracking can be used as an energy source in fuel cell vehicles as well as for generating electricity and heat.
Applications in the chemical industry are also possible. “So far, hydrogen for the chemical industry has mainly been produced from natural gas by steam methane reforming. During this process, considerable amounts of carbon dioxide are released,” says Stückrad. In addition to hydrogen, very pure powdery carbon is created as a by-product during cracking, the importance of which is constantly increasing as an industrial raw material. For example, it is used in the production of elastomers, lightweight materials, printing inks and batteries.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Methane cracking is not a new idea as such and has previously been analyzed in experiments with gas phase reactors. “Conventional methods proved unsuitable for application at an industrial scale, though,” says Professor Thomas Wetzel from the Institute of Thermal Process Engineering (TVT) at KIT. “The carbon produced during cracking was deposited on the heated reactor walls as a solid layer, blocking the reactors in a short space of time. Other approaches on the basis of arc- or plasma-based reactors weren’t very successful either.” The research project from IASS and KIT has therefore chosen a fundamentally different approach for continuous pyrolytic methane cracking.
The basic idea is to use molten tin as a heat transfer and liquid medium in a bubble column reactor. Here, KIT scientists have applied their expertise in liquid metal research and technology. In the Innovation Award winning process, methane gas is continuously fed into a liquid metal column from the bottom, which is kept at a temperature of up to 1,200 degrees Celsius, and rises as a bubble swarm. The gas in the bubbles very quickly reaches the reaction temperature so that pyrolysis reaction takes place. “The bubbles open up on the surface of the liquid tin and release the gaseous hydrogen and carbon,” says Wetzel. “The carbon occurs as micro-granular powder that is easy to separate from the gas stream and easy to handle.”
The new technology is now for the first time enabling continuous operation of a reactor for methane cracking. A conversion rate as high as 78 percent has been proven on a laboratory scale. The groups of scientists are currently working on further optimizing and scaling the process to pilot level.
Producing synthetic fuels from renewable energy sources inexpensively is also an important element for the energy transformation. Huge systems are required to produce synthetic gasoline, kerosene, diesel and natural gas. Ineratec, a KIT spin-off, builds chemical reactors that are so compact that the assembled system fits in a shipping container and can be used anywhere. At the 2018 German Gas Industry Innovation Award ceremony the young company was honored with a special award for the most innovative startup.
The German Gas Industry Innovation Award
Every two years, the associations of the German gas industry present the German Gas Industry Innovation Award organized by the Association for the Efficient and Environmentally Friendly Use of Energy (ASUE). Award partners of ASUE are the German Technical and Scientific Association for Gas and Water (DVGW), the Association of the German Energy and Water Industry (BDEW) as well as the Zukunft Erdgas industry initiative. The awards are presented in four categories; the project from KIT and IASS on methane cracking was a winner in the “Research & Development” category. INERATEC was honored with a new special award for innovative startups.
Detailed caption: The experimental reactor for methane cracking is a 1.2-meter-high device made from quartz and stainless steel which contains molten tin. In the reactor, cracking takes place in methane bubbles as they rise up. The reactor is part of KALLA (KArlsruhe Liquid Metal LAboratory) where various technologies for the use of liquid metals are developed. (Photo: Amadeus Bramsiepe, KIT)
More about the KIT Energy Center: http://www.energie.kit.edu 
Hat-tip: Die kalte Sonne.

Share this...FacebookTwitter "
nan
nan
nan
"The apocalyptic images of desolate, scorched landscapes following the wildfires in Greater Manchester and Lancashire are hard to reconcile with the lush, picturesque moorland scenery that had existed just days before. While the fight to extinguish these fires continues – and may do so for weeks – our thoughts turn to the recovery of the affected area that now exceeds 2,000 hectares in size. Words that have been used to describe the burnt areas in the media include “devastated”, “ravaged” and “barren” – but is this really the case? The question now is whether our moorlands, which are home to many rare and endangered species and play an important role in carbon and water storage, will be able to recover from this “relentless destruction”. The full scale of the impact to wildlife and the moorland habitat will not be known until the blaze is out but some of the immediate effects are clear. Animals that could escape the flames, such as deer and mountain hares, have moved to more hospitable landscapes. But those with more limited mobility, for example small mammals, reptiles, amphibians and insects, may not have been so fortunate.  The timing has been particularly crucial for species of ground-nesting birds, such as skylarks, meadow pipits, curlews and short-eared owls, whose nests and young are at risk of being burned. For plants, all vegetation above the ground will have been scorched and many seeds and root systems will have been destroyed by the heat. The fire may also be having effects on the soil – there have been reports of smouldering peat fires. Severe fire can act as a steriliser, essentially resetting the successional clock (how an ecosystem progressively changes over time) in an area by reducing complex and established communities of fungi, microbes, plants and animals to bare soil. At extremes it can also heat and damage the soil’s structure and community of organisms, which may trigger irreversible erosion. Of particular concern in these current fires is the burning and resultant loss of peat and its associated vegetation, which not only releases large quantities of greenhouse gases and accumulated pollutants (such as heavy metals) but also takes a long time to recover – peat forms at a rate of 0.5 to 1mm per year. As a consequence, the complex web of interactions between moorland species of vegetation is likely to take a long time to rebuild following such a severe fire, with some species possibly becoming locally extinct. The influence of fire can also expand beyond the burnt area. Peatlands occur mainly in upland areas covering the headwaters of most major British rivers and, as such, fires can cause large amounts of organic carbon to be deposited into rivers. This may have significant negative effects on river inhabitants. Much of the scientific literature on the ecological effects of moorland fires focuses on small-scale, controlled fires. Such fires have been used to manage moorland for grouse shooting and may also be an effective conservation tool. For example, studies from five Peak District moors demonstrate that controlled fires are important in maintaining plant diversity.  The lack of controlled burning in the affected areas is suggested as a contributing factor to the scale and intensity of the wildfires with fuel loads having built up over time. The effects of severe, uncontrolled wildfires are less well understood but there is growing evidence that they can have very serious ecological consequences.  But we must not to quickly write off the resilience of our moorland wildlife in the face of these fires. The earliest evidence of wildfires comes from 420m years ago and since then many species of plants and animals have developed ways to survive, regenerate and even take advantage of fire. Some species, such as pine and banksia trees, have gone so far as to become completely dependent upon fire to release their seeds and fulfil their life cycle. In addition to natural fires, species from the moorlands of northern Europe have experienced frequent controlled burns for over 150 years. Moorland plants possess an array of strategies to persist through fire including re-sprouting from protected buds (for example, purple moor grass) and underground structures called rhizomes (such as bilberry), or regenerating from seeds (heather).  These survival mechanisms may come as a direct result of these human-driven management strategies. For example, heather seeds from fire managed heathlands germinate more quickly when exposed to smoke in comparison to those from other infrequently burnt habitats. As a result they are better able to make the most of the bare, nutrient-rich soil exposed by the fire. So the recovery of moorland vegetation on scorched land may be quicker particularly if assisted by patches of unburned vegetation. It is the severity of these fires, which is yet unknown, that will be decisive to their ecological impact. Importantly, with upland fires becoming more frequent under climate change, we must find a management solution, such as the use of regular burns to control fuel loads, that reduces the impact of wildfires and preserves these internationally important ecosystems."
"The “most realistic” plant-based steak to date has been revealed, mimicking the texture and appearance of a real cut of meat. The fake steak’s ingredients include pea, seaweed and beetroot juice, which are extruded into fine fibres to recreate muscle tissue. Its producer, the Spanish company Novameat, says the steak will be available in some restaurants in Spain and Italy this year before scaling up in 2021.  The enormous impact of cattle and other livestock on the environment has led a swathe of companies to create plant-based alternatives to meat, with the Beyond Meat burger and Greggs sausage roll among the vegan successes. But recreating the texture of whole cuts of meat is far more challenging than ground meat. “I started with steak I think because it is the holy grail of plant-based meat,” said Giuseppe Scionti, founder of Novameat. “It is the most difficult.” The company unveiled a 3D-printed steak in 2018, but the new steak has both the firm, fibrous texture and meaty appearance of a real steak, he said, making it the “most realistic” to date. The company is still experimenting with the taste, but Scionti said the company’ can use the ingredients already used to create convincing beefy burgers from plants. He expects a final formulation in the next few months. The key to the new steak is patented micro-extrusion technology that produces fibres between 100 and 500 microns in diameter. This allows the complex structure of real meat to be replicated, with muscle fibres and fat entwined. Existing extrusion technology produces much larger fibres. The 50g steak produced cost $1.50 (£1.15) to make, similar in price to current supermarket steak in the UK. But Scionti said the cost will drop when the process is scaled up. The company plans to commission a pilot plant in 2021 which can produce 50kg of steak per hour. But to reach a mass market, the company plans to licence its technology to existing food manufacturers who can develop their own recipes. Some plant-based alternatives to meat have been criticised for being as high in fat and salt as the food they are intended to replace. Scionti said plant-based alternatives do not contain cholesterol or the hormones and antibiotics often found in real meat. In future, he said, beneficial ingredients such as omega-3 fatty acids could be added. Novameat is not alone in developing plant-based steaks, with Israel-based Redefine Meat being a leading competitor. Unlike Novameat’s product, the Israeli company’s meat has been publicly tasted, receiving positive feedback, but the firm has not yet revealed a textured steak. Others include Atlast Food, which is using a fungus fibres to create textures similar to meat, and Emergy Foods. Another Israeli company, Aleph Farms, has produced a steak from real beef cells cultured in a laboratory, which, the firm says, will have a much lower environmental footprint than real meat. There is definitely a role for technology that can structure both plant-based and lab-grown meat into more complex products, said Rosie Wardle, at the Jeremy Coller foundation and advisor for CPT Capital, which has invested in Redfine Meat. “I’ve eaten early versions of the Redefine products and they were truly delicious,” she said. Novameat has attracted investment from New Crop Capital, a firm that also invests in some of the best known plant-based and lab-grown meat companies, including Beyond Meat, Memphis Meat and Mosa Meat. David Welch, at the Good Food Institute, which works with scientists and entrepreneurs to create alternatives to animal products, said: “To meet the growing global demand for meat with more sustainable plant-based products, we need to deliver the taste, texture, and appearance that meat eaters want.” He said new technologies such as Novameat’s bioprinting are useful: “They give plant-based meat manufacturers a wider array of tools to mimic all types of meat and seafood.” Scionti said the company aims to produce pork and salmon in the future. Recent scientific studies have found that huge reduction in meat-eating in rich nations is essential to cut greenhouse gas emissions and fight the climate crisis. “We believe it is important to provide an alternative,” said Scionti, who spent a decade researching tissue engineering at the Polytechnic University of Catalonia in Barcelona and other institutions. “This will help in the long term to decrease the need for land, water, energy and, of course, reduce the emissions coming from animal agriculture. “We want to be better than the other companies,” he said. “But we are all in the same boat. We want to be remembered for doing something good at this moment when the planet needs alternatives to meat. ”"
"In a globalised world, we routinely move enormous quantities of food around the planet in trade and for aid. Many countries, including the UK, would struggle to feed their populations without food imports. Most people are used to being able to buy a wide range of produce which domestic farmers would struggle – or find impossible – to grow. A typical example is the banana, once a prized exotic novelty, but now a staple in many country’s supermarkets. Bananas are one of the most widely grown, traded and eaten of all the crops – an essential and much-loved part of the diet for many people around the world. Modern bananas are sterile, containing only tiny residual seeds, so new banana plants are propagated from cuttings. The sterile domesticated banana is the result of ancient cross-breeding between wild species. In contrast, wild bananas are packed full of bullet-like seeds and contain very little edible fruit. Wild bananas can be found in the wet hot forests of New Guinea and South and Southeast Asia, but for many years the origin of domesticated bananas was a complete mystery. Finding ancient evidence for soft, sappy plants like bananas is extremely difficult at the best of times. The problem is worse in the tropical forests, because of the rapid decay of organic matter in the heat and humidity. The answer was to use phytoliths, a technique first experimentally used in the late 1950s and adopted by archaeologists in the 1970s. These are tiny, complex-shaped particles of silica laid down in plant cells. Silica is an extremely durable mineral, and silica phytoliths have been shown to survive for millions of years in suitable circumstances. Phytoliths have provided an exciting tool for archaeologists and palaeobotanists exploring the origin and history of tropical plants. Some phytoliths of domesticated bananas are distinctive, and therefore give us a tool to chart their appearance in ancient sediments. We have known for some time that phytoliths of cultivated bananas appear at Kuk Swamp in Papua New Guinea around 6,800 years ago. But how they spread into the wider world has not been clear, and has led to much debate. Later finds include those from Munsa, Uganda 5,250 years ago, and Kot Diji in Pakistan, 4,250 years ago. But the status of these finds as domesticated bananas has been disputed. We have been investigating ancient tropical forest use in Sri Lanka and Borneo for the best part of 20 years. Now, in Fahien Cave in Sri Lanka, in deposits about 6,000 years old, we have discovered phytoliths identical with those from cultivated bananas. The first people for whom we have evidence arrived at Fahien Cave perhaps as early as 46,000 years ago and used it for shelter regularly but intermittently thereafter.  Phytolith evidence tells us that from the beginning they were eating and using a variety of wild plants, including breadfruit, durians, canarium nuts, species of palm and bamboo – and wild bananas. Even today, the leaves, flowers, fruits, stems and rhizomes of the two wild banana species on Sri Lanka are still used. Ethnographic observations suggest uses as diverse as plates, food wrapping, medicines, stimulants, textiles, clothing, packaging, paper-making, crafts, ornaments and also in ceremonial, magic and ritual activities.  But after the earliest appearance of the phytoliths of domesticated bananas, about 6,000 years ago, we found that phytoliths of wild bananas declined sharply. Less than 1,000 years separates the first certain appearance of phytoliths of cultivated bananas at Kuk Swamp, the earliest example of domesticated bananas anyone has discovered, and the first appearance of phytoliths of domesticated plants in Sri Lanka. Only dispersal by sea, carried perhaps by migrating people, is likely to have been rapid enough to bring domesticated bananas to Sri Lanka an estimated 800 years after their first certain appearance in Papua New Guinea. It is possible that they were then spread into South Asia and Africa from Sri Lanka, or that bananas reached them directly, during the same migration. Ancient DNA studies suggest that movement of populations and interconnection between distant peoples in the ancient world was remarkably common. These early travellers seem, on several occasions, to have carried food plants with them, especially starchy staple crops. For instance, in an earlier paper, we suggested the carriage of swamp sago from New Guinea to Borneo about 10,000 years ago. This would have required a sea voyage of more than 2,000km, but the durable seeds of this important food plant could have been carried easily.  However, because domesticated bananas are sterile, reproduction has to be vegetative, so cuttings or whole plants must have been carried. The transport of banana plants or cuttings between Papua New Guinea and Sri Lanka would have been fraught with difficulty, as it most likely happened in open canoes – an amazing feat, even if the journey took many voyages over many years. These heroic journeys also occurred on land. For instance Martin Jones’ FOGLIP Project has charted the spread of millets, wheat and barley across Asia from the sixth millennium BC. The ancient dispersal of manioc from central South America to Mexico and of maize in the opposite direction has also been suggested.  What does all this indicate? Global connections and exchange may be perceived as part of the modern world – but it is becoming increasingly apparent that these tendencies are deeply rooted in our prehistory."
"
Share this...FacebookTwitter“Extreme sea level rise warnings based on predictions by never validated models, or speculations, that are defocusing coastal management from every other relevant situation, should be discharged.” — Parker, 2018


Parker, 2018
Sea level oscillations in Japan and China since the start of
the 20th century and consequences for coastal management
“Regionally, the sea levels in the PRD [Pearl River Delta, China] region and Japan show no significant acceleration from 1900 to present, but only oscillations. This result is consistent with the other coastal area of the world where long-term tide gauges are located. Policy making, and management, should therefore focus on adaptive measures linked to the monitoring by tide gauges and Global Navigation Satellite System (GNSS) of relative sea level rise and land subsidence. Extreme sea level rise warnings based on predictions by never validated models, or speculations, that are defocusing coastal management from every other relevant situation, should be discharged.”
“[T]he long-term tide gauges of the world show no significant sign of sea level acceleration since the start of the 20th century.”
“Ocean and coastal management in the area should be based on the accurate monitoring of the relative sea level rise and the subsidence of the land by coupled tide gauge and Global Navigation Satellite System measurements, rather than models’ predictions and speculations defocusing coastal management from more relevant situations than the non-existent threat of extreme sea level rise.”

Share this...FacebookTwitter "
"The impact of climate change over the past five months across Australia has caused climate change deniers within the media and governments to quickly update their tactics to a new, sinister position. Gone are the plans to just keep lying for the next decade that activists such as Greta Thunberg are predicting that the world is going to end in 2030, or to continue to flub and fudge the science – no real warming since 1998, 2005, 2010, 2016! Solar activity! Volcanoes! Greenland! Now of course the feculent minds of columnists and government MPs will continue to spout these lies – when has reality ever been an impediment to their effluent-driven utterances? But the months of fires across southern Queensland, northern New South Wales, the horrors of Gippsland, the NSW south coast and Kangaroo Island over Christmas and new year, the smoke haze across Sydney and Canberra and now Melbourne, has shifted forwards their timetable of obfuscation. Five months ago they could still get away with wheeling out the “now is not the time” line, or to confidently state that you cannot link this bushfire to climate change. But now such lines are greeted with universal scorn. Last year was the hottest and driest calendar year in Australia’s recorded history. That created the conditions for the fires, and they do not exist without climate change. At this point any climate change denier with access to a social media account will tell you that rainfall has actually increased over the past century in Australia. That is true, and also utterly irrelevant and designed to mislead. Climate change impacts have only really taken off since the late 1960s and early 70s, and not surprisingly, given the size and differing climates of Australia, the impact on rainfall has varied. Over the past 50 years the trend rate of rainfall in northern Australia has barely changed – if anything, it has risen a bit (great if you like rain and you live in Broome) but in south-eastern Australia the trend is clearly falling: So now that they are unable to say “now is not the time”, they have adapted. Rather than suggest no connection with climate change, they have shifted to arguing there is no connection between any particular climate change policy and bushfires. Scott Morrison argued last week on ABC’s 7.30: “You cannot link any individual single emissions reduction policy of a country – whether it’s Australia or anyone else – to any specific fire event. I mean, that’s just absurd.” Nothing Scott Morrison has said suggests any change in policy that will actually involve emissions reductions Yes, it is absurd, because no one is actually arguing that. But the prime minister is very good at defeating arguments no one is making. He is also very good at giving false hope. Right now columnists and journalists are writing articles expressing belief that maybe Morrison is about to shift the government’s climate change policy. Perhaps he will, but I have seen Charlie Brown try to kick this football before and I remain unpersuaded because I have listened to what the prime minister himself has said just this past week. Three times David Speers asked him on Sunday if the government would increase its emissions targets. Morrison responded with: “Well, the cabinet and the government will continue to evolve our policies.” Then he added: “What I’m saying is I’m not going to put someone’s job at risk, a region’s, town’s future at risk.” And finally: “What I’m saying is we want to reduce emissions and do the best job we possibly can and get better and better and better at it.” What he is saying is “no”. Nothing he has said suggests any change in policy that will actually involve emissions reductions. Instead he has quickly adopted the new go-to response of climate change deniers – that of the need to adapt and “improve resilience”. What does that mean? It means the next step in climate change denial – a step I joked grimly last month was not far away. Alas, it is no longer a joke. The new argument is that, yes climate change is probably to blame, but we can’t do anything about it, and anyway it’s too late now, so let’s “adapt”. And what does that adaptation involve? According to Morrison: “Building dams is key to that. Native vegetation management is key to that. Land clearing is key to that.” In other words doing the very things conservatives have been desirous of for the past century – building dams, reducing national parks and increasing land clearing. They will hand out grants to organisations and areas most electorally beneficial and all the while trumpet that they are dealing with the issue in a practical way, unlike the opposition which, they argue, will be trying to kill jobs. Conservatives hate dealing with the actual source of problems – they much prefer handing out the graft; which is appropriate when you realise climate change denialism is the biggest con in political and media history. And of course emissions will rise while they suggest they are actually being reduced. The line from Morrison is that we will “meet and beat” our Paris emissions reductions targets. The current figures from his own government show that rather than reduce emissions in 2030 by 26% below 2005 levels, we are on track to cut them by just 16%. But the real problem – one that needs much more attention than interviewers now give it – is the 26% target itself has no basis in science as being anywhere near enough to keep temperatures below 1.5C. The Intergovernmental Panel on Climate Change reported in 2018 that to keep global temperatures from rising above 1.5C, C02 emissions needed to “decline by about 45% from 2010 levels by 2030, reaching net zero around 2050”. Forty-five per cent, not 26%. And that is a 45% reduction of actual emissions, not including farcical “land use” figures. When we exclude land use, our 26% target really becomes closer to 15%. Morrison boasting that Australia will meet and beat its target is like someone boasting that they are beating their target of 10 minutes of exercise a day, and hoping everyone ignores that doctors recommended 30 minutes. A 45% cut of real emissions is well below what the government is targeting and miles below our current projections: The reality is, even while including land use, we are still well short of where we need to be: And so we enter the next stage of climate change politics – a subtle and sinister shift – the talk will be about practical measures of adaptation rather than of reducing emissions: gone will be direct action, in its place will be “direct adaptation”. It is a stage that, if successful, will signal the end for our planet. Greg Jericho writes on economics for Guardian Australia"
"
Share this...FacebookTwitterThe non-falsifiable climate catastrophe: No matter if it’s hot or cold – it always has got to be global warming
By Die kalte Sonne
(Text translated by P Gosselin)
The Central European heat summer of 2018 was a feeding frenzy for the followers of the climate disaster. The media turned it into sensational news and clearly saw climate change at work.
And then came the winter. In the US, this year (2018) saw one of the coldest Thanksgiving holidays of the past 100 years. That did not suit the PIK at all. Quickly there was a press release (22/11/2018) that blamed the cold spell on global warming:
Winter weather extremes in the US and Europe: messing with giant airstreams in the stratosphere
Over Thanksgiving, arctic air masses are predicted to bring record-cold temperatures and frigid winds to the Northeast of the United States. Driver for such winter weather extremes is often the stratospheric polar vortex, a band of fast moving winds 30 kilometers above the ground. In winter, when the polar vortex is disturbed by upward-blowing air masses, this can bring cold spells over Northeastern America or Eurasia, a new study now shows. And paradox as it might seem, climate change might further disrupt the complex dynamics in the atmosphere – bringing us not only more hot extremes in summer but potentially also cold spells in winter.”
Read more here.
No matter if it’s hot or cold, it always has to be global warming. The crazy world of climate alarm. If one follows this logic, there is no single weather condition that could refute the concept. The climate catastrophe model can not be falsified, no matter what the weather. This indeed breaks an important principle of science. 
But to ensure the well-being of mankind, scientific sacrifices must be made. With autocratic climate rule breaking all the laws of science is standard procedure.
Share this...FacebookTwitter "
"A staggering 235m items of unwanted clothing were forecast to be dumped in UK landfill in 2017, while the average American is estimated to bin 81lb (37kg) of used clothing annually. Overconsumption and the inevitable disposal of unwanted clothing has become a worrying global problem – and in many cases, this clothing is unnecessarily thrown away. Instead, it could be repaired or recycled. Filling landfill with clothing and textiles costs the UK alone an estimated £82m every year. But on the flip side, the consumption of clothing is hugely important to the economies of many countries, too. Research from The British Fashion Council, for example, found that fashion contributes £28 billion directly to the UK economy – and globally, it is a US$2.4 trillion industry.  Despite this, materialistic values and a widespread desire for having new things, twinned with fashion’s premise to create – and sell – different styles, has reduced the functional value of clothing, making it easily disposable. A staggering 100 billion items of clothing are being produced annually, and 50% of fast fashion pieces are disposed of within a year.  In fact, recent figures show that one rubbish truck of textiles is thrown away every second globally. Little wonder, then, that fashion has been dubbed “incredibly wasteful” – even by insiders.  Fashion and sustainability have historically had an uncomfortable relationship. The 2013 Rana Plaza disaster in Bangladesh, along with growing concerns over sweatshop labour, have seen fashion companies overhaul their social and environmental impacts. Consumers, meanwhile, have grown increasingly concerned about where and how garments are made. But while fashion takes strides to become ethical, there are still serious concerns over its environmental impact and contribution to climate change. Fashion is deemed to be one of the world’s most polluting industries – from toxic chemical use to water pollution and waste. Some 35% of the global total of microfibres in the oceans comes from clothes and textiles, meaning fashion is a major contributor to this pollution. By 2050, it is anticipated, the fashion industry will use up 25% of the world’s carbon budget.  So what’s the solution? A circular economy seeks to move beyond fashion’s linear model of take, make and waste, to close the loop, designing out waste and minimising environmental impacts. While fashion brands work to limit their polluting practices through the creation of organic, environmentally conscious collections, there is still a need to limit the sheer volume of waste that fashion creates.  Recycling has become an important initiative to address this. H&M, for example, has a successful garment collection scheme, repurposing their consumers’ unwanted clothing. Other brands, meanwhile, are using recycled materials to create clothing. Outdoor clothing brand Patagonia has made polyester fleece out of recycled plastic bottles.   While recycling could achieve circulatory by designing out waste, it is problematic environmentally. Recycling is energy intensive and may require use of further virgin materials. Additionally, while it resolves some of fashion’s sustainability issues, it does not adequately address the problem that consumers buy too much, and that the average number of times a garment is worn has declined by 36% since 2000. We must reconsider how fashion is sold, encouraging consumers to waste less, and ensure that garments have a longer life span. WRAP, the UK’s resource efficiency agency, has identified leasing as an innovative business model that gives clothes a longer service life, while reducing material use and carbon dioxide emissions. A recent survey conducted by Westfield Shopping Centre in London also proposed that clothing rental would become a key future trend.  The possible value of the clothing rental market in the UK is predicted to be £923m and the model is already well-established for certain items, such as dinner jackets and wedding suits for men. Despite this, there are currently just a handful of fashion companies that have adopted a leasing model. At Mud Jeans, for example, consumers can lease a pair of organic jeans, and after a year can keep, swap or return them. Girls Meets Dress, meanwhile, was founded in the UK in 2009, under the ethos that in a sharing economy ownership will become obsolete. In America, Rent the Runway has become a significant player in the fashion industry. These companies are built on change, but undoubtedly they face the challenges of the traditional sales-driven fashion system, along with consumer hesitation.   Our research has explored the potential for clothing rental among consumers. While we found there were opportunities certainly at the luxury end of the market, there was a definite resistance to rental of lower priced items, which were just too easy to buy.  If consumers are to engage, rentals need to be convenient, cheap, accessible and fulfil the desire for having something new. Consumers are open to change and leasing could help achieve a more circular fashion industry. However, there are issues to consider from transportation through to dry cleaning impacts. Clothing rental has the potential to reduce waste and increase the lifespan of garments, but to achieve a more sustainable industry a systemic change in business practice and consumer behaviour is needed."
"
Share this...FacebookTwitterProposed wind turbines in Switzerland’s Linth region have been rejected by local communities, the media report. Parts of Switzerland want no part of blighting their landscape in the name of environmental protection.
Hit-tip: a reader from Switzerland
Little wonder!
Here’s what wind energy opposition organization Linth Gegenwind (Linth Headwind) shows what the otherwise idyllic Swiss landscape would end looking like by 2040 if the projects went ahead.






An artist’s depiction of what the Linth region would look like by 2040 if proposed wind projects were approved. Sanity appears to have returned. Image: Linth Gegenwind.
Wind energy is losing its luster for many reasons, but among them is the obvious industrial blight to the landscape they cause.
Wind turbines in Bilten rejected
In the latest step to protect the landscape from industrialization, Swiss SRF public broadcasting here reported on November 6 that the up to 5 controversial wind turbines, which had been planned to be erected in the middle of a “densely residential area”, were rejected on the grounds they would lead to “landscape blighting”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The SRF quotes local Glarner government councilman Kaspar Becker:
We have come to the conclusion that it is not necessarily clever to pursue such things in densely populated areas.”
In response, wind energy opposition site Linth Gegenwind writes: “Common sense has prevailed!”
Honegg-Oberfeld wind park flat out rejected
Also recently the Swiss online appenzell24.ch has reported that the proposed Honegg-Oberfeld wind park was outright rejected.
On November 6, 2018, Appenzell24 wrote the local commission decided against the Honegg-Oberfeld district as a wind power location. Thus no wind farm can be built there.
On this, wind energy protest organization Linth Gegenwind writes at its website:
The reason is, above all, protection of the landscape. During the consultation process there were 60 in favor and 500 against the planned wind farm. Opponents also include Appenzell Ausserrhoden, St. Gallen, the state of Vorarlberg and the community presidents’ conference Ausserrhoden.”
According to the Appenzell24.ch, the 5 wind turbines with a hub height of 135 meters, would have resulted in “massive disadvantages for the landscape’s appearance”, according to opponents. 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWe’re seeing lots of headlines about heavy snowfalls and cold temperatures gripping Eastern and Southern Europe. Not surprisingly some activist scientists are blaming manmade global warming.

Expected snow depths by January 15. Chart: WXCharts.EU.
Junk theory: Global warming causing more snow extremes
Yet global warming logically isn’t supposed to be directly causing massive snow and bitter cold, and so there has to be some explanation for the unexpected cold and snowy weather. So to explain its all, a gaggle of activist scientists have concocted a theory that claims “unprecedented” Arctic sea ice loss over the past two decades has led to an increase in blocking over North America and Europe [e.g., Liu et al., 2012; Francis and Vavrus, 2012] and so is indirectly causing lots of snow and cold.
These desparate scientists then hope that the public and media will be gullible enough to buy into it.
Blocking is strongly tied to weather extremes in the midlatitudes (e.g., cold snaps, heat waves) and can persist for days to weeks [e.g., Black et al., 2004; Dole et al., 2011], so more blocking could mean more weather extremes as Arctic sea ice continues to decline (Note: Arctic sea ice in fact hasn’t declined in more than 10 years).
Analyses: no data to support the theory
However, a recent paper authored by Elisabeth A. Barnes, Department of Atmospheric Science, Colorado State University, says the data to support this just aren’t there.
The paper’s abstract:
Observed blocking trends are diagnosed to test the hypothesis that recent Arctic warming and sea ice loss has increased the likelihood of blocking over the Northern Hemisphere. To ensure robust results, we diagnose blocking using three unique blocking identification methods from the literature, each applied to four different reanalyses. No clear hemispheric increase in blocking is found for any blocking index, and while seasonal increases and decreases are found for specific isolated regions and time periods, there is no instance where all three methods agree on a robust trend. Blocking is shown to exhibit large interannual and decadal variability, highlighting the difficulty in separating any potentially forced response from natural variability.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The results of the analyses are summed up in the following charts of the paper’s Figure 3:

Time series of blocking frequencies for the three indices and four reanalyses for (a, c, and e) Asia in DJF and (b, d, and f) the North Atlantic in JJA. Trends significantly different from zero at 95% confidence are denoted by asterisks in the legend of each panel for Asia (1990–2012) and the North Atlantic (1980–2012). Filled circles (stars) denote the seasons following the 5 highest (lowest) years of September Arctic sea ice extent over the trend period. Blocking frequencies are averaged between 40° and 80°N for the 2‐D indices. Chart: Barnes et al (2014)
Not supported by observations
The findings reiterate those of Barnes [2013], The 2014 paper concludes that “the link between recent Arctic warming and increased Northern Hemisphere blocking is currently not supported by observations.”
Blocking events well within historical observed range
The paper adds:
While Arctic sea ice experienced unprecedented losses in recent years, blocking frequencies in these years do not appear exceptional, falling well within their historically observed range.”
In other words, the theory that global warming is causing more extremes due to melting Arctic sea ice is just plain crap. There’s no data to support it. It’s just a hypothesis – one that was rolled out in a desperate attempt to explain events that weren’t supposed to happen.
Correspondence to: Elisabeth A. Barnes:
eabarnes@atmos.colostate.edu
Search for more papers by this author
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Kyoji Kimoto
kyoji@mirane.co.jp
1. Warmer period of the 1930s
In 1998 D. Dahl-Jensen et al. pointed out in the journal Science that the 1930s is 0.5°K warmer than the present time based on a bore-hole study of Greenland ice sheet.
The following data support D. Dahl-Jensen’s findings, from Soon 2012.

Also heat waves were far worse across the USA in the 1930s:

More heat waves in the 1930s.
The strongest hurricane was the Labor Day hurricane, which hit in 1935. Hurricane Irma and Harvey had much higher central pressure at landfall. (U.S .National Hurricane Center):

Strongest hurricane occurred in the 1930s.
2. Arctic temperature and sea ice extent
Parts of the Arctic were warmer in the 1930s:

Source: Real Climate Science.
Arctic sea ice levels were just as low in the 1930s as they are today:

Read more here.
3. NASA & NOAA altered the data
The climatic data above can be understood with solar activity change (aa Index) and ocean oscillation (Pacific Decadal Oscillation Index), see the 2 charts that follow.

(Archibald)
The Pacific Decadal Oscillation (PDO) index was also in its warm phase during the 1930s:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




PDO index was positive from1925 to1945. Data: Japan Meteorological Agency.
In summary, increasing solar activity with positive PDO index caused the warmer period of the 1930s. However, NASA and NOAA have made data tampering to stress recent warming.
Recent temperature data shows strong influence of ocean oscillation (El Nino) and no relation with CO2 increase as follows:

Source: Climate4you
4. MWP & LIA caused by changes in solar activity
Solar activity proxies show the MWP & the LIA in Japan and China as follows:

Chart above: Kitagawa, H. & Matsumoto, E., Geophysical Research Letters, Vol. 22, 2155-2158, 1995
 

Graphic above: Quansheng GE. et al., Advances in atmospheric sciences, Vol. 34, 941-951, 2017.
There are hundreds of other proxies worldwide that support solar activity as the main climate driver.
5. Sea level rise
Almost 25-years of meticulous data gathered by the Australian Bureau of Meteorology displays no discernible sea-level rise for Solomon Islands and Nauru. See the two graphs that follow:


Source: WUWT.
6. El Nino linked to solar activity
A publication by Njau (2006) showed El Nino starts at the year of sunspot minimum or maximum, thus showing that solar activity has a major impact on oceanic oscillations, which in turn powerfully impact weather and climate.
7. Extreme weather and solar activity
Bucha (1988) showed decreased solar activity causes meandering of jet stream which produces extreme weather in broad area. Since 2006 decreased solar activity has been causing heat waves, wildfires and heavy rainfall and snowfall all over the world.

Bucha (1988)
Share this...FacebookTwitter "
"A heatwave has hit the UK, largely due to a flow of very warm air from southern Europe, and in particular the Iberian peninsula. Temperatures are expected to rise into the mid-30s Celsius. The media has picked up on the term “Spanish plume” to describe the current weather setup but it’s a phrase often misused. So what exactly is a “Spanish plume” and are we actually experiencing one? The origins of the term aren’t completely clear, although a 1968 paper on severe convective storms can probably claim the first usage. Regardless, by the 1980s the phrase “Spanish plume” was certainly in widespread use among UK weather forecasters, so the headlines over the past few days aren’t referring to anything new. As the Met Office pointed out last summer, a Spanish plume is a catchy name for a rather complex set of circumstances. It does indeed involve a flow of hot dry air from the Iberian peninsula across western France and into the UK.  But this in itself isn’t enough to constitute a Spanish plume in the full meteorological sense. To make a true Spanish plume, it’s crucial what happens to this hot dry air as it tracks northwards and how it interacts with air flowing from other directions. During the summer months, the air over Spain can become very hot if it is able to sit over the elevated plateau in the centre of the Iberian peninsula for several days. It will also be very dry as there isn’t a source of moisture near the surface. As an example, the air near Madrid at midnight on June 30 (Sunday night) had a relative humidity of only 24% (which is very dry) and a temperature of 38°C. Also important to note is that Madrid sits at about 600 metres above sea level. As this very hot dry air moves north on southerly winds it passes above the Bay of Biscay and western France where the air near the surface is still very warm but much moister; at midnight on June 30, it was 23°C in Bordeaux but relative humidity was 61%. The combination of these two air masses on top of each other, with warm and moist air near the surface and hot and dry air above, can be very unstable. In order to release this instability, the whole column of air, with the warm moist air near the surface and the hot dry air aloft, to be lifted in the vertical. Once this occurs then clouds, rain and potentially thunderstorms can form very rapidly. This can indeed happen as the air flows northwards, with the air being lifted not directly vertically but on a rather gentle upwards slope as it moves north and runs into the colder, denser air of northern France and the UK. This combination of circumstances can occur when there is a slow moving depression situated over the Atlantic to the west of the UK, with high pressure over central Europe. On some occasions this lifting can lead to the rapid development of intense thunderstorms over northwest Europe or the UK. A true Spanish plume occurs when all these circumstances conspire together to lead to intense storms. Such storms are being forecast – so it looks like the UK is indeed currently experiencing a true Spanish plume. These events are typically well-forecast several days ahead, as they evolve rather slowly, although it is usually more difficult to pinpoint exactly where any thunderstorms may actually occur. A Spanish plume will usually occur at least once a year over the summer period and sometimes much more frequently.  Some of the heaviest rain that has fallen in the UK, such as the 279mm that fell on Martinstown, Devon in July 1955 and for many years held the UK record for the most rain in one day, was caused by the Spanish plume scenario. However it’s important to realise that not every UK heatwave or summer thunderstorm is down to a Spanish plume."
"Carmakers could pull models from the UK, the automotive industry has warned, as Britain’s taste for polluting vehicles clashes with the difficulty of meeting post-Brexit carbon dioxide limits. Under new EU rules, average carbon dioxide emissions of almost all cars sold in 2020 and 2021 across the single market, including the UK, must fall below 95g a kilometre, with heavy fines for carmakers that miss individual targets designed to meet the goal. The heavier, fuel-inefficient SUVs favoured by Britons have been offset by the smaller, less polluting cars preferred in countries such as Italy. But after Brexit, when the UK plans to copy EU rules, this will no longer be the case, making a UK-only limit harder to hit. Mike Hawes, the chief executive of the Society of Motor Manufacturers and Traders (SMMT), the car industry lobby group, said: “[Carmakers] will have to look at their model mix … you’ve got to see whether that’s economic. The fines are going to be severe and all of them will do everything they can to avoid that. “It could be that you see a reduction in consumer choice through the removal of higher-emitting vehicles from not just the top end, but particular segments.” While having to pull models from sale would be a blow to the car industry, the rules could prove to be environmentally effective if they reduce sales of the most polluting models. Cars account for just over 18% of UK emissions, according to government figures, and action in the transport sector is considered crucial to cutting emissions to 51% of 1990 levels by 2025 and to reach net zero by 2050. Mel Evans, a climate campaigner for Greenpeace UK, said: “Carmakers are not obliged to aggressively market heavy, polluting cars. They know that we are in a climate emergency and yet keep accelerating towards the cliff edge, because bigger, dirtier cars have higher profit margins. And because they use more petrol and diesel, the oil companies cash in as well. “To address the climate crisis, manufacturers need to U-turn on petrol and diesel, stop spending millions drumming up demand for their dirtiest cars, and focus on electric vehicles for a post-oil world.”  The carbon dioxide emissions of cars sold to British consumers rose for the third year in a row in 2019, underlining the scale of the challenge for the industry as it tries to meet the new EU limits. However, the prospect of an imminent Brexit at the end of January will force carmakers to make choices before the end of 2020, when the implementation period is scheduled to end and the UK-only limits kick in. That could include choosing to sell electric cars in the EU rather than the UK if they judge Europe to be a more important market. Carmakers are rushing to bring to market new electric cars with zero exhaust  emissions – including Volkswagen’s ID.3, Vauxhall’s Corsa-e and an electric Fiat 500 – this year, but production will initially be limited as factories gear up. At the same time, they are keen to hang on to their profitable but polluting sales of internal combustion engines. Carmakers breaching their individual CO2 targets will pay fines of €95 (£83) for every gram they are over their limit, multiplied by the number of cars sold that year. Average UK emissions were 127.9g a kilometre in 2019, the SMMT said, 35% above the 95g target for 2020 and 2021. The UK is planning to adopt the EU fine structure after Brexit. Al Bedwell, an analyst at the car consultancy LMC Automotive, said he expected some higher-polluting models to be withdrawn from sale across both the EU and the UK in the next two years. However, he said major efforts to increase sales of battery electric vehicles (BEVs) might not work in the absence of consumer demand. “You can’t suddenly create a perfect environment to sell enough BEVs to make the problem go away,” he said. The Department for Transport said: “Our priority is to protect everyone from unsafe vehicles, including those that are damaging our environment, which is why we continue to work with industry to improve the emissions standards of all vehicles. “We have set out bold plans for driving down CO2 emissions and committed in our ‘Road to Zero’ strategy to pursue vehicle emissions regulation that is at least as ambitious as the current arrangements as we leave the EU.”"
"
Share this...FacebookTwitter[The most notable part of the documentary is the interview with Freeman Dyson, from 1:09:00 – 1:14:00]
In his new documentary “The Uncertainty has Settled“, Dutch filmmaker Marijn Poels focuses on climate science and politics and found that the issue is in fact as controversial and as UNSETTLED as any issue could possibly get.
The science climate change is far from settled and is in fact unsettled.

The production of the film took Poels to a variety of locations from Manhattan to the Austrian Alps.
The first part of the film depicts the plight of farmers in former East Germany (Saxony Anhalt), who are struggling to practice their livelihoods under the heavy burden of German agricultural regulation and market distortion that result from bureaucrats having decided that 0.01% of our atmosphere (man-emitted CO2) is a monumental problem.
That’s the narrative the media and leading politicians keep ramming. But a number of skeptics doubt it, and so Poels investigates if this doubt is just right wind politics or if there is something really behind it.
In the end he finds that the science is fully in dispute.
Belief we can stop climate change “enormously egocentric”
At the 38:00 Poels says that the [alarmist] Potsdam Institute refused to grant him an interview and so he set out for Hamburg to meet with climate scientist Hans von Storch, who is in the warmist camp.
Von Storch confirms that climate change is real, man-made and is a problem that needs to be dealt with seriously. But he adds that the claim that we can “rescue” the climate is “nonsense” and characterizes the claim the individual can play a role on controlling climate as “enormously egocentric”. Later in the film (1:04:45) von Storch says he doesn’t see climate change as a danger, but as “a challenge” that he is not afraid of.
CO2 as a climate driver “complete, delusional nonsense”
Next astrophysicist Piers Corbyn tells Poels that the amount of man-made Co2 in the atmosphere is like a “tiny blob of birdshit” and calls the claim that this is causing the climate to change “complete, delusional nonsense”. Corbyn also believes the globe will see continued cooling until about 2035. He calls the datasets showing warming “frauds”.
Freeman Dyson: 
Climate models “very dangerous game”…”they’re wrong”
Next Poels makes his way to Princeton where he meets with “living legend” Princeton physicist Freeman Dyson, one of the leading skeptic voices on man-made climate change.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Dyson has harsh, critical words for climate science and the models they rely on (1:10:30). He calls the science of climate modeling a “very dangerous game”, adding:
When you work with a computer model for years and years and years – always improving the model – in the end you end up believing it. […] It’s very difficult to remain objective.”
Models “wrong”…”disagree with observations”
On why we should not trust the models, Dyson says flat out: “Because they’re wrong. It’s very simple. They’re wrong.” Dyson says they “disagree with observations”. He then commented on modeling scientists:
Those people don’t look at observations. They are in a world of their own.”
“Scaring the public”
The 93-year old Princeton professor also notes that although the models are “very good tools for understanding climate”, they are a “very bad tool for predicting climate” and that these scientists “live by scaring the public”.
Climate theories are “very confused”
Dyson continues:
Unfortunately the thing has become so political it’s no longer science when you have strong political dogmas, as you say, on both sides.”
Overall Dyson advises that we need to believe the observations and pointed out that “the theories of climate are very confused.”
Herd, tribal mentality
He also told Poels a large sociological part of the problem is that climate scientists have in large part gotten caught in herd and tribal mentality.
It’s still more important to belong to the tribe than to it is to speak the truth.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAccording to a recent paper by Choujun Zhan et al, extreme precipitation events have declined over 90% of China.
Hat-tip: reader Mary Brown
Image right: Journal of Atmospheric and Solar-Terrestrial Physics
According to the paper’s abstract, a newly developed dataset containing daily precipitation in China at 0.5° intervals of longitude and latitude over the period 1961 to 2011 was statistically analyzed.
The authors found “the probability of rainy days has decreased over time for over 90% the surface area of China, and that the extreme precipitation and annual precipitation have decreased for most of the area in China.”
The results contradict the often made alarmist claim of more frequent and extreme weather events due to global warming.
Australia: “no trend in one day precipitation extremes”
In a recent paper titled “Variability and long-term change in Australian temperature and precipitation extremes“, the authors found that although in Australia minimum temperatures have increased, but maximum temperatures not so much, there was no trend in one day precipitation extremes.
The authors summarized in the paper’s abstract:

Daily precipitation extremes rarely exhibit long-term change over the century but are strongly modulated by the El Niño Southern Oscillation (ENSO). The relative importance of long-term change and climate variability therefore depends on the variable or index.
We conclude that in assessing the likelihood of climate hazards, one needs to consider the modulation of climate extremes due to both long-term change and climate variability. Our findings imply that when planning for adaptation, different emphasis needs to be given to changing temperature and precipitation extremes.”

Share this...FacebookTwitter "
"A coalition of Scottish conservation groups has called for legally enforceable culls of deer to be imposed on private landowners and stalking estates, while raising the prospect of local communities becoming more involved in shooting and killing deer for food. The report, published by Scottish Environment Link (SEL), which includes the John Muir Trust, the National Trust for Scotland, RSPB Scotland and the Scottish Wildlife Trust, argues that a dramatic reduction in the country’s wild deer population is needed to tackle accelerating climate and biodiversity crises.  The report says deer can cause significant damage to emerging woodlands through grazing, and that they trample fragile peatlands, which are key to carbon absorption. Scotland’s deer population produces 5,500 tonnes of methane each year, the equivalent of 137,500 tonnes of CO2. The report also argues that more active culling could reduce accidents on rural roads. With no existing natural predators, the red deer population reached a peak of 400,000 in 2010. Deer management groups, often on sporting estates, kill certain numbers, but SEL wants the Scottish government to set and enforce higher targets.  Higher cull targets could involve other people in the deer management, they say. Noting that “for centuries, red deer stalking in Scotland has relied on paying clients and guests of private landowners, supplemented by professional stalkers”, the report suggests that in other parts of Europe communities are more involved in deer control. “In Norway, for example, over half a million people – almost 10% of the population – are registered hunters. Hunting on state land is considered a communal source of sustainable food, and local people have priority use. Game meat is an important part of Norwegian food culture, rather than a byproduct of trophy hunting, as is often the case here.” SEL argues that a similar culture could be encouraged in Scotland, moving away from the kind of management that focuses on “wealthy clients seeking a pair of antlers”, which necessitates a much higher deer population and resultant environmental damage. The report was published before the release of findings by the independent deer working group, set up by the Scottish government in 2017 to consider changes for management of the species. Mike Daniels, head of land management at the John Muir Trust, said: “We believe there is a growing appetite for change in how Scotland’s uplands are managed into the 2020s and beyond, and delivering sustainable deer management is a critical component.”"
"The new record represents the most stark demonstration that global heating is unequivocally real and driving the climate crisis. With emissions still rising every year, more heat is being trapped by greenhouse gases, and the ocean data is crystal clear: an unrelenting and accelerating rise for at least the past half century. Lijing Cheng, at the Chinese Academy of Sciences, said: “There are no reasonable alternatives aside from the human emissions of heat-trapping gases to explain this.” We live on the surface of the Earth, and so air temperature is the most common heat measurement. But two-thirds of the planet’s area is ocean and water can absorb far more heat than air. As a result, just 4% of the heat trapped by greenhouse gases warms the air and land. So to really see what is happening with global heating, you need to look at the oceans. Here, the signal is unmistakable, with every year in the past decade recording hotter oceans that the year before, bar one. In contrast, air temperature is more affected by the natural variation that overlies human-caused global heating. The hottest year for air temperature to date is 2016, thanks to an El Niño event, though 2019 may slot in at number two when the final data is available. The oceans and atmosphere are inextricably linked. Changing ocean heat means changing rains, and that means more floods in some places and more droughts and wildfires in others. Furthermore, hotter oceans mean more sea level rise, threatening cities from Shanghai to Miami and Rio de Janeiro to Alexandria. Hotter oceans also supercharge storms, with Kevin Trenberth at the US National Center for Atmospheric Research noting that a hotspot in the Gulf of Mexico in 2017 spawned Hurricane Harvey. That led to 82 deaths and caused about $108bn in damage. In 2018, a hotspot in the Atlantic Ocean near the Carolinas led to Hurricane Florence. Many coral reefs are already suffering from bleaching. But the increasing number of ocean heatwaves are affecting all life. For example, the hot “blob” seen in the North Pacific from 2013 to 2015 caused a major loss of marine life, from plankton and fish – including 100 million cod – to marine mammals such as whales. No, but it might lead to some. Climate tipping points are reached when particular impacts of global heating become unstoppable, such as the runaway loss of ice sheets or forests, or the release of the potent greenhouse gas methane from melting tundra. Some scientists think the world may already have crossed a series of tipping points. If so, the buildup of heat graphically demonstrated in the oceans shows why. Yes. The way to end global heating and tackle the climate emergency is to stop emitting greenhouse gases. Most importantly that means a rapid end to fossil fuel burning, plus the protection and regeneration of forests and cutting down emissions from farming, in particular from cattle. There is no time to lose."
"The leader of Germany’s Friday for Future climate protests has said she turned down a seat on the board of Siemens’ new energy business amid growing anger over its role in a controversial coalmining project in Australia as she feared she would lose the right to criticise the company. Luisa Neubauer, 23, the German face of the campaign group inspired by Swedish activist Greta Thunberg, who has campaigned alongside her, said on Monday the position would jeopardise her independence if she had taken up the offer from its chief executive, Joe Kaeser, made at a meeting in Berlin on Friday.  The two met as protests by Fridays for Future and Extinction Rebellion were held in 40 cities across Germany, including outside Siemens’ Munich headquarters, against a central Queensland coalmine that will open up one of the world’s biggest untouched coal basins. Neubauer had hoped to persuade Kaeser to withdraw from the project, for which Siemens has won an €18m contract to provide the rail infrastructure. At the meeting in Berlin, Neubauer was offered a position by Kaeser in either the supervisory board or leadership council of Siemens Energy, a spin-off business which hopes to head a new generation of energy-efficient technology. It is due to split from the main company in the spring and to go public in September on Germany’s Dax index. She said on Monday she had turned down the offer. “If I were to take it up, I would be obliged to represent the company’s interests and could never be an independent critic of Siemens,” she explained. “That is not compatible with my role as [a] climate activist.” The Carmichael mine was approved by the Austalian government in June and will be run by the Indian company Adani. It has become a cause for climate protesters who disapprove of a project which will contribute to global heating – especially at a time when large parts of Australia are already being wracked by bushfires blamed on the climate crisis. Kaeser, who has made much of the company’s pledge to become carbon neutral by 2030, last month tweeted his recognition of the activists’ complaints about the mine, promising he would “diligently look into the matter” and “get back” to the protesters. He pointed out a decision would “not be easy” due to the various interest groups involved, including shareholders, customers and the public. But on Sunday, following an extraordinary meeting of Siemens management, Kaeser announced the company was to go ahead with the project as it was legally obliged to remain committed to it, adding that at the same time it would become increasingly watchful of environmental concerns. “We have evaluated all the options and have concluded that we must fulfil our contractual obligations,” he tweeted. He promised the company would improve its future management of “protecting the environment” by establishing what he called “an effective Sustainability Board”. Activists say the coalmine project will produce an annual 27.5m  tonnes of coal and will contribute to global heating. They also point to the vast amounts of water it will require, as well as destruction of habitat and the need to transport the coal via the Great Barrier Reef, the largest coral reef in the world. The Australian Conservation Foundation called the decision “disastrous”, and pledged to continue its protests against the mine. It added: “With this decision, the company is showing its true face ... its climate change strategies have been revealed to be meaningless and hollow.” Neubauer has referred to the Siemens’ project as an “inexcusable mistake”. She told the news agency DPA: “We asked Kaeser to do everything possible to stop the Adani mine. Instead he will now profit from this disastrous project. “This is so last century, and Joe Kaeser is making an unforgivable mistake,” she added, emphasising that Siemens’ decision threatened climate goals to reduce the rise in global warming by two degrees."
"Atop Mount Lico in northern Mozambique is a site that few have had the pleasure of seeing – a hidden rainforest, protected by a steep circle of rock. Though the mountain was known to locals, the forest itself remained a secret until six years ago, when Julian Bayliss spotted it on satellite imagery. It wasn’t until last year, however, that he revealed his discovery, at the Oxford Nature Festival. We recently visited the 700 metre-high mountaintop rainforest in an expedition organised by Bayliss, in collaboration with Mozambique’s Natural History Museum and National Herbarium. As far as anyone knew (including the locals), we would be the first people to set foot there (spoiler: we weren’t). Since the rainforest’s discovery, Lico has received worldwide attention. That it captured the public’s imagination speaks volumes about how rare such places are. Humans are nothing if not adventurous, pushing our range boundaries like no other species can. But when almost every corner of the planet now shows signs of human activity, how do conservation scientists justify visiting and publicising these last bastions of untrodden nature?  From our perspective, the answer depends on what expeditions like this can teach us about the natural world, our place in it, and how to shepherd the wildest of places through the Anthropocene. Standing back and crossing our collective fingers is not always a winning strategy. This expedition formed part of a long-standing research programme into these mountains, that aims to provide evidence to legally protect Mozambique’s mountain forests. Currently none of northern Mozambique’s mountains are formally protected, either nationally or internationally. Finding new species is one way to highlight the importance of such sites and justify their protection. As well as exploring Mount Lico, the expedition was the first to undertake a biological survey of nearby Mount Socone. Every bit as majestic and species rich as the iconic Lico, Socone highlights the threat faced by many forests in Mozambique, Africa and elsewhere. Globally, one football pitch worth of forest is lost every second, driving countless species to extinction. The removal of trees from mountain slopes also leads to soil erosion, flooding in the wet season and water shortages in the dry season. On our first day on Socone, we set out to locate the middle of the forest using a satellite image and GPS. However, the difference between what this image was telling us and what we could see was vast. As we walked towards what the image showed as the heart of lush rainforest, we could see the warm glow of the African sun. Soon enough, we emerged from beneath the canopy and into newly established farmland. Without the protective cover of the forest, heavy rains will pound these exposed mountain soils, fresh cuts will need to be made, and so the cycle repeats. Media attention on neighbouring Lico, and the new species descriptions coming out of both sites, help to bring these conservation and livelihood issues to the world’s attention. Our brief footsteps on Lico will soon be overgrown, and the plants and animals that live there will continue to be protected by the same towering cliffs (more than 125 metres high) that have saved them up to now (without the help of world-class climbers, our expedition would not have been possible). But the impact of people goes far beyond where we have actually managed to set foot. Since the industrial revolution, humans have increased the amount of carbon dioxide in the atmosphere to levels higher than at any time in the past 400,000 years, increasing temperatures and changing weather patterns. Despite being situated on a fortress of rock, Lico’s forest is vulnerable to climate change, like every other ecosystem on the planet. The contrast between protection from direct human activities but exposure to climate change means that Lico has a lot to teach us. Most forests experience both of these processes simultaneously, and so it is difficult to unravel their relative and interacting impacts. Through the data collected on Lico, Socone and other forests worldwide, we gain a greater understanding of how human disturbance affects the ability of forests to respond to environmental change. Lico is a rare data point on this map: millennia of climate change and ecological response, played out in the absence of direct human disturbance. Reconstructing this history meant digging a two metre-deep pit in the forest, so that we could sample the layers of soil in the order that they accumulated. We tried to minimise any lasting effects on the forest (the hole was filled and topsoil replaced) but nonetheless, reasonable objections can be made against our disturbing this previously pristine site. What we gained were a series of time capsules: each little tin of soil contains information on the plants that grew, the fires that burned and the water that flowed, data that will be shared in open access repositories, allowing people worldwide to investigate this unique site without the need for further disturbance. What we learn from Lico will help the world understand how forests might be affected by future changes in climate. So were we really the first humans on Lico? Well, not quite. To everyone’s surprise, we found ancient pots, ceremonially placed near the source of a stream that flows to a waterfall down the side of the cliff. Were these placed there during a time of drought, as the waterfall ran dry and the crops failed?  Archaeologists and climate scientists are investigating. Given the pots pre-date local knowledge, the incredible inaccessibility and lack of any other signs of human activity, Lico’s forest remains one of the least disturbed on the planet. One thing’s for sure though – humans really do get everywhere."
"
Share this...FacebookTwitter“A number of biases internal and external to the scientific community contribute to perpetuating the perception of ocean calamities in the absence of robust evidence.”  – Duarte et al., 2015

Image Source: Larcombe and Ridd, 2018
Within a matter of days after the press release for a newly published Nature paper spewed the usual it’s-worse-than-we-thought headlines throughout the alarmosphere (Washington Post, BBC, New York Times), the paper’s results were assessed to have “major problems” by an author of multiple CO2 climate sensitivity papers (Lewis and Curry, 2015, 2018).
A glaring miscalculation was quickly spotted that changed not only the results, but consequently undermined the conclusion that estimates of climate sensitivity to doubled CO2 may be too low.
And yet the paper was able to pass through peer review anyway.
Dr. Michael Mann’s error-riddled 2016 paper
A few years ago Dr. Michael Mann was the lead author of an embarrassingly non-scientific paper fraught with glaring methodological and statistical errors.
A post-publication reviewer (statistician Dr. William Briggs) wrote in his point-by-point critique of the paper that “Mann’s errors are in no way unique or rare; indeed, they are banal and ubiquitous.”
Despite the glaring errors, the paper made it through peer-review and was published in Nature‘s Scientific Reports journal anyway.
“Hoax” papers can get published in 70% of peer-reviewed journals
Analyses indicate that “fake peer review” often goes undetected, and as many as 7 of 10 peer-reviewed journals are apt to publish a deliberately-written “hoax” paper.
“Any reviewer with more than a high-school knowledge of chemistry and the ability to understand a basic data plot should have spotted the paper’s shortcomings immediately. Its experiments are so hopelessly flawed that the results are meaningless. … The hoax paper was accepted by a whopping 157 of the journals and rejected by only 98. Of the 106 journals that did conduct peer review, 70% accepted the paper…”  (Murphy, 2017  The Failure of Peer Review)
A new paper cites analyses that find half of peer-reviewed science results are flawed, not replicable


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Earlier this year, a review paper (Larcombe and Ridd, 2018) published in the journal Marine Pollution Bulletin delivered a stinging rebuke to the modern version of science’s disturbing lack of replicability and verifiability.

Image Source: Larcombe and Ridd, 2018
The authors go on to detail a large volume of examples when peer-review failed to detect errors in Great Barrier Reef (GBR) coral research.
Confirmation bias appears to permeate the peer-reviewed literature, slanted in the direction of finding evidence for catastrophic decline in coral health.  This isn’t the first time that marine research has been called out for overselling calamity (see Cressey, 2015, “Ocean ‘calamities’ oversold, say researchers – Team calls for more scepticism in marine research.”) and falling “into a mode of groupthink that can damage the credibility of the ocean sciences”.
As just a single example among the many provided, Larcombe and Ridd reviewed the De’ath et al. (2009) study in which an “unprecedented” decline in GBR corals was alleged to have occurred between 1990-2005.
After a reanalysis of the measurements and methods used, Larcombe and Ridd used corrected data to show there has actually been “a small increase in the growth rate” of corals since the early 1900s (see below image) instead of the dramatic decline after the 1990s documented in the peer-reviewed paper.
These errors slipped past the reviewers’ notice too.   The publication of flawed results has seemingly become so common that it’s no longer even surprising.
“This paper [De’ath et al. (2009): Declining coral calcification on the Great Barrier Reef.] studied 328 corals on the GBR, and indicated a 14% reduction in growth rates between 1990 and 2005. It stated that the corals of the GBR are declining “at a rate unprecedented in coral records reaching back 400 years”. Subsequent reanalysis of the data indicated that the apparent recent reduction in growth rate was caused by a) problems with the physical measurements of calcification, which systematically biased recent growth bands to give lower growth rates (D’Olivio et al., 2013; Ridd et al., 2013), and b) an unjustified assumption that coral growth rate does not change with the age of the coral (Ridd et al., 2013). With these taken into account, the dramatic fall in growth rate after 1990 is no longer evident, and a small increase in growth rates since the early 1900’s appears (Fig. 6). Further, D’Olivio et al. (2013), working on a different set of GBR corals, showed an increase in coral calcification rates on middle and outer shelf reefs, which together represent 99% of GBR corals, of 10% for the period ~1950 to ~2005, but a decrease of 5% per decade between 1930 and 2008 on inner-shelf reefs, which represent only 1% of GBR corals. Therefore, it would be hard to glean from these datasets that there is a documented decline in coral ‘growth’ parameters, and even harder to attribute change to a particular cause.”

Image Source: Larcombe and Ridd, 2018
Share this...FacebookTwitter "
"Rising temperatures caused by global heating are likely to increase deaths from road crashes, violence, suicides and drowning, according to new research, and will affect young people most. Deaths from injuries have long been known to be seasonal and the new analysis uses data on nearly 6m deaths in the US to calculate the impacts of a 2C rise in temperature, the main target set by the world’s nations. The scientists calculated that this increase would result in about 2,100 more fatal injuries every year in the US alone. People tend to go outside more and drink more alcohol on hotter days, while higher temperatures are known to increase rates of violence and suicide. The analysis did show a small reduction in the number of deaths related to falls among elderly people, probably because there is less ice in winter. Previous research on the impact of the climate emergency on health has focused on chronic diseases such as heart failure and infectious diseases including malaria. But deaths from injuries currently make up about 10% of all fatalities around the world and the impact of global heating on this had been little studied until now. The scientists say young people play vital roles in supporting societies and economies and that measures to tackle deaths from injury must be a public health priority. “Our results show how much climate change can affect young people,” said Prof Majid Ezzati of Imperial College London. “We need to respond to this threat with better preparedness in terms of emergency services, social support and health warnings.” Injury deaths were expected to increase in all nations as temperatures rose, he said, although local factors would influence the extent of the increase – for example, the standard of road safety or level of gun control. The world is currently on track for a 3-4C temperature rise, suggesting the increase in injury deaths could be even higher. The research, published in the journal Nature Medicine, is based on data on recorded deaths from injuries in every county in the mainland US between 1980 to 2017. It also used temperature data to find the months when the average temperature was 2C higher than usual. This enabled the researchers to account for the fact that people adapt to normal local conditions but are affected by unusual temperatures. Comparing the data allowed the scientists to estimate the annual increase in deaths that would result from a 2C rise. Men are already much more likely than women to die from injuries and the researchers found that 84% of the additional deaths were among men. The most affected age group was 15-34. Road crashes accounted for 42% of the extra deaths and suicide 30%. Deaths from violence and from drowning both made up about 14% of the total. Drownings increase in hot weather as more people swim. “There is a long history of work that shows injuries are fundamentally seasonal,” said Ezzati. “Some of this is obvious – people drown more in summer. We also know that warmth influences both our physiology and our behaviour.” The reasons deaths from suicide and violent assault increase in hot weather are not fully understood. But the researchers said it was possible that people spending more time outdoors had a higher risk of confrontations. People also tend to be more agitated in hot weather, and may drink more alcohol, which could lead to more assaults. Previous research indicates that high temperatures are associated with higher levels of mental distress, especially in young people. Injuries already kill more that 5 million people a year, more than HIV/Aids, tuberculosis and malaria combined, and such deaths are rising. Policies to tackle the climate emergency should include measures to combat deaths from injuries, said Shanthi Ameratunga and Alistair Woodward of the University of Auckland, New Zealand, in an accompanying commentary on the research. “The need to address this major public health problem is particularly urgent in low- and middle-income countries that experience over 80% of the global injury burden and are generally more vulnerable to the effects of extreme weather,” they said. “The public health community tend to forget that injury deaths are actually a pretty big factor [in overall mortality],” said Ezzati. “The emphasis on young people is an important aspect of the story, as they are educationally and economically active.”"
"Garden frogs and toads are in decline. The latest data from RSPB Garden Birdwatch reveals that we are seeing one-third fewer toads and 17% fewer frogs compared to 2014. Many people forget that our gardens can be important havens for wildlife. But with ponds drying up, amphibians are losing out.  We should be worried about these declines. Frogs and toads may not be our most glamorous garden inhabitants, but they offer an important opportunity to connect with wildlife within a domestic environment. As RSPB conservation scientist Dr Daniel Hayhow says:  Most people remember seeing tadpoles at the local pond or a toad emerging from under a rock while they were growing up. These first experiences with nature stay with us forever. Unfortunately, the sights and sounds of wildlife that were once common to us are sadly becoming more mysterious. These early connections with wildlife are being lost, leading to concerns that some children may be suffering from nature deficit disorder which can affect their mood and attention. Research shows that children are more familiar with Pokémon characters than they are with our native wildlife. We need to find more ways to encourage interactions with nature. Ponds, even small ones, are a great way of doing this.  Population declines in amphibians is caused by the reduction of garden ponds, and the reduced numbers of ponds in the wider countryside. We lost 50% of our ponds in the UK over the 20th century, and many that are left are in a poor condition because of pollution and lack of management.  Frogs and toads need clean ponds in which to breed, but outside the breeding season you’ll find them in tall grass and log piles. The fashion of keeping our gardens meticulously neat and tidy is leaving our wildlife with nowhere to hide. Amphibians also provide a very useful pest control service (they love eating slugs and snails) so encouraging them into gardens could bring many benefits.  So how do we help? The Freshwater Habitats Trust is leading the Million Ponds Project with the aim of creating networks of ponds. You don’t need to rebuild your garden to get involved, as even a small outside tub can be enough to provide a suitable habitat for amphibians.  If you are feeling more generous, then creating a larger pond can be a fun project – especially with children. Once put in, it will only take a matter of days before something decides to make it their home. It will usually be invertebrates and plants to begin with, but it won’t take long for it to be found by a nearby frog or toad population.  Another benefit of gardening with wildlife in mind, is that often it means that you need to do less work. Mowing your lawn less frequently provides a great habitat for wildlife. And creating a log pile, putting up nest boxes for birds or putting in a hole in your fence to allow access for hedgehogs, are all low-effort activities which are highly effective.  There are even ways to get involved if you do not have a garden. You can become a local “toad patroller”, helping toads to navigate roads safely as they migrate to their breeding ponds. Or you could become a citizen scientist by reporting whenever you see a frog or toad through Amphibian and Reptile Conservation, and taking part in the RSPB’s Wild Challenge.  Gardens in the UK might account for less than 2% of our total land use, but 83% of people live in urban areas. Small adjustments in gardens could lead to big changes in frog and toad populations – which would be good news for them, and provide gardeners young and old with a boost at the same time."
"The now recalled guidance issued by counter-terror police that placed Extinction Rebellion alongside the likes of jihadists and neo-Nazis emerged at a problematic time for the government’s flagship anti-radicalisation programme, Prevent. The voluntary initiative is supposed to be under independent review after years of concerns about its impact on certain communities and on freedom of expression.  But just under a year after the review was announced by the Home Office, its chair, Lord Carlile, was forced to step down after a legal challenge to his appointment was brought on grounds of his partiality. The review was set to report back in August this year, but is currently without a leader and the clock is ticking. The criticism that prompted the review focused around three key themes: first, that the way the strategy is applied fosters discrimination against people of Muslim faith or background; second, its effectiveness (the last set of official figures revealed that still only one in 10 of referrals goes on to receive specialist support); and finally, that it inhibits legitimate expression. The last point is particularly pertinent given the fact that Extinction Rebellion and the environmental issues for which it campaigns were included on a list of “extremist ideologies”, which was then sent out to public sector partners, including teachers, who are under a legal obligation to refer the slightest suspicion that a person is vulnerable to said ideologies. Among evidence that a person may be vulnerable to Extinction Rebellion’s alleged extremist beliefs was speaking in “strong or emotive terms about environmental issues like climate change, ecology, species extinction, fracking, airport expansion or pollution”. Given the growing awareness of the climate emergency across the world – arguably due in part to the actions of Extinction Rebellion – this would make hundreds of thousands of people extremists. School strikers were singled out in the guidance – last year thousands of UK pupils, and millions worldwide, walked out of school in protest at government inaction on the climate crisis. The activist Greta Thunberg is a leading proponent of school strikes. This would have placed teachers – obliged to refer under the statutory duty, perhaps the most controversial element of the Prevent programme – under further pressure. The education sector is already the greatest single source of referrals to Prevent. Counter-terror police have been at pains to emphasise that Extinction Rebellion are not considered to be extremists and that the document was drawn up in error. Action has been taken to recall the document, but only after police were approached by the Guardian. It is also likely that the document, dated November last year, has been in circulation for around two months, and police chiefs are unable to say how many individuals and organisations received it. But there has already been at least one publicised case of an individual being referred to Prevent over their associations with Extinction Rebellion – Lyn Jenkins, a 69-year-old retired doctor, was referred by his NHS trust after telling them he wanted to be arrested during Extinction Rebellion protests. Prevent practitioners within police forces log every Prevent referral on a giant case management database – a database that the police insist was not a secret before the Guardian covered it last year, despite revealing that they do not inform individuals they are being listed on the database, pointing critics to a handful of buried references in highly obscure civil service documents online. For those concerned that they may have been referred to Prevent for their fears – and actions taken to address them – over the climate emergency, individuals are able to contact their relevant police force, ask if their details are held on the Prevent case management database, and then request that they be removed."
"The Indian state of Kerala has been devastated by severe floods. More than 350 people have died, while more than a million have been evacuated to over 4,000 relief camps. Tens of thousands remain stranded.  The crisis is a timely reminder that climate change is expected to increase the frequency and magnitude of severe flooding across the world. Although no single flood can be linked directly to climate change, basic physics attests to the fact that a warmer world and atmosphere will hold more water, which will result in more intense and extreme rainfall. The monsoon season usually brings heavy rains but this year Kerala has seen 42% more rain than would be expected, with more than 2,300mm of rain across the region since the beginning of June, and over 700mm in August alone. These are similar levels seen during Hurricane Harvey, that hit Houston in August 2017, when more than 1,500mm of rain fell during one storm. Tropical cyclones and hurricanes, such as Harvey, are expected to increase in strength by up to 10% with a 2℃ rise in global temperature. Under climate change the probability of such extreme rainfall is also predicted to grow by up to sixfold towards the end of the century. The rivers and drainage systems of Kerala have been unable to cope with such large volumes of water and this has resulted in flash flooding.  Much of that water would normally be slowed down by trees or other natural obstacles. Yet over the past 40 years Kerala has lost nearly half its forest cover, an area of 9,000 km², just under the size of Greater London, while the state’s urban areas keep growing. This means that less rainfall is being intercepted, and more water is rapidly running into overflowing streams and rivers.  One of the most striking things from the videos and images emerging from the area is the brown colour of the flood waters and the extreme damage caused by landslides. Our recent research has shown that geomorphology – the processes of erosion and deposition that shape the Earth’s surface – is sensitive to rainfall intensity, so more frequent and more extreme floods mean more rapid changes across our landscapes. The floods have been described as “the worst in 100 years” by Kerala state’s chief minister. Similar descriptions are often used to try and define the magnitudes of a flood, such as a “one-in-100 year flood event”, despite it being widely recognised that such descriptions are ineffective for communicating flood risk. Our ways of thinking about probability and the risk of flooding, as well as measuring its magnitude, are in desperate need of updating. The 100-year flood, the flood that has a 1% chance of occurring in any given year, does not register in public consciousness.  A different way of thinking about it is that a 100-year flood at a given location has close to a one in four chance of occurring within the term of a 25-year mortgage. A 25% chance your house will flood before you’ve finished paying for it is far more relatable and more likely to get people to consider and engage with their own individual risk. Likewise, governments, both regional and national, along with agencies and first responders, need to develop improved flood maps and update them to incorporate uncertainty. Alongside this, we need more effective communication and public engagement to develop flood risk literacy – long term this will help improve policy decisions. The UK’s 25-year environment plan is a step in that direction. Most critically we have to accept that, with the changing climate and changing patterns of rainfall, the behaviour of rivers will also shift. All our assessments of flood risk currently assume a static, steady-state system where rivers respond in the same way they have in the past. An increase in rainfall, and in particularly extreme events, will cause our landscapes to adjust. Rivers and their basins will become more dynamic and prone to change.  How quickly rivers change, and how quickly we respond with urban drainage and flood mitigation measures, will play a significant role in our evolving flood risk. Layered on this will be how rapidly societies, and their governments, begin to adopt more resilient ways of living with water.  Flooding is a challenge across individual, local, regional and global scales, and is set to increase in the future and its impacts will become more damaging. We need solutions across each of these scales to improve individual and societal resilience – so when flooding does occur it isn’t the disaster we are currently witnessing unfold in Kerala."
"Mansour Rajeb is wrapping a plastic protective sheet around the branch of a date palm in his oasis near the village of Bchelli, in southern Tunisia. Tying it up, he lingers. “I’m worried,” he says. “The quality is getting worse. The dates are getting drier.” Like thousands of farmers across the region, the effects of the climate crisis and water scarcity are threatening his livelihood. “When the quality is poor, we receive lower prices. I’m earning less. This year, I’ll earn a third of last year, which was an average year.” On the road out of Bchelli, a gust of wind makes the sand rise like steam. Beyond the palm trees lies desert, a flat, barren terrain of scrub, rock and sand. Communities have survived here for thousands of years, but the changing environment may soon make it uninhabitable. Overall, temperatures here have risen by about 1C (1.8F) since 1988, according to data collected by the meteorological office in Tozeur, the capital of the region’s western district.  “Temperatures used to peak in August and then fall, but now the heat persists until October,” says Taieb Foudhaili of South Organic, a date exporting company based in Kebili. Given this pattern of warming, humidity levels are falling and the plants adapt by releasing water. The result, says Foudhaili, is a drier, poorer product. His company must now do more sorting to maintain quality standards. Global heating has also created shorter periods during which date palms can flower and pollinate, according to Nabila el-Kadri, an agronomist based in Kebili. As a consequence, Kadri has observed a decline in the productivity of dates per hectare. But it is not just rising temperatures causing anxiety. Over recent decades, and particularly after Tunisia’s 2011 revolution, unlawful plantations have spread like blots across the white landscape. The state has failed to exert proper controls. There are now 38,000 declared hectares (93,860 acres) of palm tree across the Kebili region, though Kadri believes the real figure could be as high as 50,000 hectares. More than half of the country’s dates are produced here. After olive production, dates are Tunisia’s second most valuable agricultural export, generating more than $200m (£154m) a year.  A consequence is growing water scarcity: date palms are thirsty. On each plantation, Kadri estimates there are between 100 and 140 palm trees per hectare, with each tree requiring roughly 20–25,000 cubic metres of water each year. Neither natural springs nor groundwater can meet this demand. Farmers are resorting to drilling and pumping water from aquifers. There are now about 30,000 wells across the country, some hundreds of metres deep. As many as half of these were drilled illegally, according to a 2017 report by Tunisia’s Ministry of Agriculture, and less than half of the water from wells is not renewable. Water levels are being increasingly overexploited across southern Tunisia.  “If we keep creating these new oases, with thousands of hectares of new trees, then over 10 to 15 years we won’t have any water left,” says Kadri. Some are already suffering. Rajeb says he has farmer friends who have already sold their trees in the new, poorly irrigated oases, because their crop was “so feeble”. Kadri says it is only a matter of time before date production as a whole will have to migrate north to Gafsa. Ultimately, the problems of global heating and water scarcity facing Tunisia’s date farmers arise from a similar myopia: a common failure to see things holistically. “We are only thinking about the product,” says Foudhaili, “when we should be thinking about the air, the tree and the soil. We need to change the way we think.” Many of Tunisia’s modern palm plantations are monocultures, producing the valuable Deglet Noor variety of date and little else. When this crop fails, farmers have little to fall back on. Lying in the shade of a palm tree in Chebika, 71-year-old Younes Belgasim is a figure of hope. His oasis is thriving. He is one of an estimated 18,000 people benefiting from a $5.7m World Bank project that launched in 2014. The project provided him with seeds for vegetables and fruit trees, helped him improve his land’s soil and irrigation, and allowed him to erect better fencing to protect his plot from local wild boars. The initiative supported Belgasim to restore a “three-level” system of inter-cropping. On his oasis, the date palms give shade to vines, banana, pomegranate and fig trees, while vegetables and wild grasses grow beneath. This system demands more from farmers, and it may deliver less immediate commercial payoff than date production. Both factors may deter farmers looking to earn their revenue in one date harvest season. But while some inter-cropping farmers in the oases say the system can demand more water, they also report that it maintains humidity levels, improves the soil quality and strengthens biodiversity. It also diversifies farmers’ assets. These successes suggest ecosystem-based farming can be a win-win: protecting farmers from climate, economic or disease-related shocks, while also preserving the natural environment. For this reason, Belgasim is more relaxed about the future. “It is getting hotter,” he says, “but I’m not worried about climate change.”"
"
Share this...FacebookTwitterDespite sea level rise, Tuvalu Islands surface area has grown 3% over the past decades
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
The South Sea islands are sinking. Send us money and visas for Australia and USA fast! That’s the underlying message of many media reports on the problem of sea level rise and their effects on the Pacific Coral Islands. Here science simply gets cast aside.
Since coral islands are made up of living organisms that have always lived just below the sea level, the islands “float” like ships on the surface of the ocean. When sea level goes up, so do the corals. This is already something you learn in geography lessons at school.
Paul Kench and his colleagues have now measured the shorelines of all 101 islands of Tuvalu for the last 40 years using satellite imagery. The result: The land area grew by just under 3% during this period, despite a fairly strong regional sea-level rise of 4 mm per year. Here is the abstract of the work that appeared in February 2018 in Nature Communications:
Patterns of island change and persistence offer alternate adaptation pathways for atoll nations
Sea-level rise and climatic change threaten the existence of atoll nations. Inundation and erosion are expected to render islands uninhabitable over the next century, forcing human migration. Here we present analysis of shoreline change in all 101 islands in the Pacific atoll nation of Tuvalu. Using remotely sensed data, change is analysed over the past four decades, a period when local sea level has risen at twice the global average (~3.90 ± 0.4 mm.yr−1). Results highlight a net increase in land area in Tuvalu of 73.5 ha (2.9%), despite sea-level rise, and land area increase in eight of nine atolls. Island change has lacked uniformity with 74% increasing and 27% decreasing in size. Results challenge perceptions of island loss, showing islands are dynamic features that will persist as sites for habitation over the next century, presenting alternate opportunities for adaptation that embrace the heterogeneity of island types and their dynamics.”

Source: Nature Communications
The discussion part of the paper states:
Results challenge existing narratives of island loss showing that island expansion has been the most common physical alteration throughout Tuvalu over the past four decades. Of significance, documented increases in island area over this period have occurred as the sea level has been rising.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe days of unlimited speed on Germany’s famed autobahns are indisputably coming to an end – probably soon. And thank God!
Hat-tip: achgut.com.
The online Mitteldeutche Zeitung MZ) here reports the Evangelical Church in Central Germany (EKM) is pushing to impose a speed limit on German autobahns, the motorways where drivers  in certain stretches are free to drive as fast as they dare.

The days of no speed limit on Germany’s famed autobahns are about to end. Photo: Darkone, CC BY-SA 2.5, (Wikipedia)
Quoting Christian Fuhrmann of the EKM, the MZ reports that cars should she limited to 130 km/hr and the Church will mobilize to send a public petition to the German Bundestag.
The MZ adds that the petition will be launched on Ash Wednesday and 50,000 signatures are needed.
According to the MZ: “The Central German Church covers large parts of Saxony-Anhalt and Thuringia and has about 700,000 members.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Church’s main reason for limiting the speed of cars to 130 km/hr on the autobahn is to reduce greenhouse gas emissions and exhaust fumes, which the Church says would translate to an emissions reduction of 2 – 2.5%. Also the high speeds and associated braking leads to more fine particle emissions from tire abrasion on asphalt surfaces, as well as more noise.
“A Confession to the Creator”
The MZ also reports that potential CO2 savings could be 2 million tonnes annually. Currently Germany emits some 900 million tonnes of CO2 equivalent gases annually.
The MZ adds:
“We see a world responsibility for ourselves, assigned by God,” said state bishop Ilse Junkermann. Mankind is destroying the foundations of life. The fight against it is “a confession to the Creator”.
Makes sense from safety alone
Personally I support a 130 km/hr limit, but not because of the silly climate reasons. Overall a limit is far safer, and some studies show it would likely improve over traffic flow efficiency and help reduce long traffic jams, which often result from messy car accidents. In the end less traffic jams means reaching your destination just as quickly as you would madly driving at breakneck speeds.
Also an autobahn speed limit could mean lower maintenance costs because the surface specifications for unevenness could be relaxed a bit. Any unevenness really becomes a factor when a vehicle is flying at 280 km/hr. With speeds at 130 km/hr, road crews would not have to be sent out to “repair” the road, which in turn means lane closures and again more traffic obstruction and slowdown.
One compromise could be to tolerate speeds of 160 km/hr (100 mph) during times and areas of light traffic.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe year 2018 could mark the beginning of the end of climate change alarmist reporting.  Projections of catastrophic melting of the ice sheets and sea level rise swallowing up the Earth’s coasts are increasingly undermined by observations. 

Extensive glacier and ice sheet melt resulting in an accelerated sea level rise threatening the world’s population centers living along the coasts is indeed the most legitimate threat posed by a global-scale warming trend.
Alarming sea level rise predictions abound.   Several meters of sea level rise due to catastrophic melting of the Greenland and Antarctic ice sheets have been predicted based on anthropogenic CO2 emissions scenarios.
For example, claims that we shall experience 260 centimeters (2.6 meters) of global sea level rise by 2100 unless we dramatically curtail our fossil fuel consumption have been published by authors like Dr. Michael Mann and Dr. Richard Alley (Garner et al. 2017).  These same authors even suggest seas will rise by 17.5 meters in the next 180 years (Mörner et al., 2018).

Image Source: Mörner et al., 2018
Despite the hackneyed practice of reporting “staggering” ice sheet melt for both Greenland and Antarctica in recent decades, the two polar ice sheets combined to add just 1.5 centimeters to sea level rise between 1958 and 2014 (graph from Frederikse et al., 2018) as global sea levels only rose by “1.5 ± 0.2 mm yr−1 over 1958–2014 (1σ)” or “1.3 ± 0.1 mm yr−1 for the sum of contributors”.
That’s about 7.8 centimeters (3.1 inches) of global sea level change in 56 years.
Even more significantly, satellite observations all across the globe show that the coasts of islands and sandy beaches and continents have not only not been shrinking for the last several decades, they’ve been stable to growing on net.  Along the world’s coasts, there is today more land area above sea level than there was in the mid-1980s (Donchyts et al., 2016), leaving scientists “surprised”.
“We expected that the coast would start to retreat due to sea level rise, but the most surprising thing is that the coasts are growing all over the world,” said Dr Baart.  “We’re were able to create more land than sea level rise was taking.”  (BBC press release for Donchyts et al., 2016)
Dr. Nils-Axel Mörner – a world-renown sea level expert who headed the Department of Paleogeophysics & Geodynamics at Stockholm University – and 3 other co-authors have concluded that sea level rise projections of 2.6 m by 2100 and 17.5 m by 2300 are “deeply flawed” and “not rooted in facts” (Mörner et al., 2018).
What follows is a very abbreviated summary of the dozens of alarmism-quelling papers published in 2018 pertaining to ice sheet melt, sea level rise, and coastal expansion.

Mörner et al., 2018
Estimating Future Sea Level Changes, Assessing Coastal
Hazards, Avoiding Misguiding Exaggerations, and
Recommending Present Coastal Management
“Tide-gauges offer records of the relative changes in sea level. Out of a total of about 2300 stations (PSMSL), “a global set of ~300 tide gauges that serves as the backbone of the global in situ sea level network” in the Global Sea Level Observing System (GLOSS). There is no objective, straightforward solution for estimating a global mean value. The University of Colorado chose 184 global tide-gauge records. Their rate of distribution has a marked peak in the zone from ±0.0 to +2.0 mm/yr with a mean value at +1.14 mm/yr. Because the majority of stations used include a component of regional subsidence and local sediment compaction, the true mean sea level value should be <+1.14 mm/yr. … Satellite altimetry is a new and important tool, which reconstructs the entire ocean surface changes. But nowhere do the measurements agree with coastal observations. Satellite altimetry exceeds tide-gauge records by about 300%. There have even been accusations of data manipulation [Mörner, 2018].”
“Garner et al. (2017) propose SLR of up to 2.6 m by 2100, 10.5 m by 2200, and 17.5 m by 2300 (Fig. 1). These SLRs are far greater than those that occurred during catastrophic melting of immense ice sheets at the end of the Pleistocene, so the question arises, where will all the water come from to produce these very large SLRs? Melting of small, temperate, alpine glaciers wouldn’t produce anywhere near the SLRs projected by Garner et al., so the only possible sources of water are the Antarctic and Greenland ice sheets. The projections of Garner et al. of SLR of 7–8 m per century would require about seven times the end of the Pleistocene SLR when immense ice sheets were collapsing under warming of up to 20 °F in less than a century. To get these huge SLRs would require melting of an immense amount of ice from the Antarctic ice sheet. The average winter temperature in Antarctica is about –55 °F and temperatures have reached as low as 135 °F, so any significant melting of the Antarctic ice sheet would require 55° + 32° = 87 °F of warming just to get to the freezing point plus another 10 degrees or so to melt much ice. So Antarctica would have to warm up by 90–100 °F to melt enough ice to substantially raise sea level.”
“Hazard prediction is important, but the essence of science is the testing of predictions by comparison with observational facts. Without that validation, predictions are really just idle speculations. The future sea level values given by Garner et al. [2017] are deeply flawed and therefore misleading for coastal planning. They must be rejected as nonsense. Sea level research has its own well established means of recording past and present sea level changes and from those data to estimate likely sea level changes in the future. There are also physical frames to consider, some of which are absolute and must not be violated. … [T]he values given by Garner et al. [2017] violate not only physical laws but also accepted scientific knowledge of glaciology. Therefore, their values must not be considered in coastal planning. We also question the reviewing process.”
“Is Greenland warming and the ice sheet melting away? Chylek et al. [2004] analyzed temperature histories of coastal stations in southern and central Greenland having almost uninterrupted temperature records between 1950 and 2000 and found that coastal Greenland’s peak temperatures occurred between 1930 and 1940, after which subsequent decrease in temperature was so substantial and sustained that current coastal temperatures “are about 1°C below their 1940 values.” At the summit of the Greenland Ice Sheet, the summer average temperature has decreased at the rate of 2.2 °C per decade since the beginning of measurements in 1987. Two weather stations, Godthab Nuu and Angmagssalik, on opposite coasts of Greenland, have the longest records, dating back more than a century. Both show similar annual temperature patterns–strong warming in the 1920 and 1930s followed by cooling from 1950 to 1980 and warming from 1980 to 2005. The significance of these recent temperature records is that they show that temperatures in the past several decades have not exceeded those of the 1930s and Greenland temperatures have fluctuated normally in step with global temperatures changes [Easterbrook, 2016].”
“Satellite and surface temperature records and sea surface temperatures show that both the East Antarctic Ice Sheet and the West Antarctic Ice Sheet are cooling, not warming. Satellite and surface temperature measurements show that the East Antarctic Ice Sheet is cooling, not warming, and glacial ice is increasing, not melting. Satellite and surface temperature measurements of the southern polar area show no warming over the past 37 years. Growth of the Antarctic ice sheets means sea level rise is not being caused by melting of polar ice and, in fact, is slightly lowering the rate of rise. Satellite Antarctic temperature records show 0.02 °C/decade cooling since 1979. The Southern Ocean around Antarctica has been getting sharply colder since 2006. Antarctic sea ice is increasing, reaching all-time highs. Surface temperatures at 13 stations show the Antarctic Peninsula has been sharply cooling since 2000. This indicates that the hypothetical “enhanced Antarctic Ice Sheet contribution” of Garner et al. [2017] is a serious mistake (Fig. 1) not anchored in facts.”



2. Ice melt from Greenland, Antarctica added just 1.5 cm to sea levels since 1958 
“For the first time, it is shown that for most basins the reconstructed sea level trend and acceleration can be explained by the sum of contributors, as well as a large part of the decadal variability. The global-mean sea level reconstruction shows a trend of 1.5 ± 0.2 mm yr−1 over 1958–2014 (1σ), compared to 1.3 ± 0.1 mm yr−1for the sum of contributors.” (Frederikse et al.,2018)


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





 
3. Ice mass gains in the rapidly-cooling Antarctic Peninsula since 2009  
“Two small glaciers on James Ross Island, the north-eastern Antarctic Peninsula, experienced surface mass gain between 2009 and 2015 as revealed by field measurements. A positive cumulative surface mass balance of 0.57 ± 0.67 and 0.11 ± 0.37 m w.e. was observed during the 2009–2015 period on Whisky Glacier and Davies Dome, respectively. …  Ambrožová and Láska (2016) reported a significant decrease (0.03–0.15°C a−1 [-0.3 to -1.5°C per decade]) in the temperature along the AP [Antarctic Peninsula] over the 2005–15 period with the most prominent cooling at the Bibby Hill station on JRI [James Ross Island]. … The cumulative mass gain of the glaciers around the northern AP [Antarctic Peninsula] indicates a regional change from a predominantly negative surface mass balance in the first decade of the 21st century to a positive balance over the 2009–15 period. The change in the glacier mass balance follows a significant decrease in the warming rates reported from the northern AP [Antarctic Peninsula] since the end of the 20th century. The mass gain is also consistent with the regional trend of climate cooling on the eastern side of the AP [Antarctic Peninsula].”   (Engel et al., 2018)

4. Collapse of Larsen C glaciers would add 0.25 to 0.42 of a cm to sea levels
“Here we apply numerical ice-sheet models of varying complexity to show that the centennial sea-level commitment of Larsen C embayment glaciers following immediate shelf collapse is low ( < 2.5 mm to 2100,  < 4.2 mm to 2300) [0.25 to 0.42 of a cm added to sea levels by 2100/2300 with Larsen C collapse]. Despite its large size, Larsen C does not provide strong buttressing forces to upstream basins and its collapse does not result in large additional discharge from its tributary glaciers in any of our model scenarios. In contrast, the response of inland glaciers to a collapse of the George VI Ice Shelf may add up to 8mm to global sea levels by 2100 and 22mm by 2300 [0.8 cm to 2.2 cm] due in part to the mechanism of marine ice sheet instability. Our results demonstrate the varying and relative importance to sea level of the large Antarctic Peninsula ice shelves considered to present a risk of collapse.” (Schannwell et al., 2018)
5. East Antarctica is gaining mass – it takes “millions of years” for “even partial retreat” 
“The East Antarctic ice sheet may be gaining mass in the current, warming climate. The palaeoclimate record shows, however, that it has retreated during previous episodes of prolonged warmth. … In terms of immediate sea-level rise, it is reassuring that it seems to require prolonged periods of lasting hundreds of thousands to millions of years to induce even partial retreat.” (Nature Geoscience, 2018)
6. No glacier-melt trend for Antarctica’s largest sea level rise contributor in 70 years
“Pine Island Glacier is the largest current Antarctic contributor to sea level rise. Its ice loss has substantially increased over the last 25 years through thinning, acceleration and grounding line retreat. However, the calving line positions of the stabilizing ice shelf did not show any trend within the observational record (last 70 years) until calving in 2015 led to unprecedented retreat and changed alignment of the calving front. … Despite the thinning and flow acceleration of PIG [Pine Island Glacier], and sustained, rapid thinning of the ice shelf over at least the past 25 years the position of the ice front had not shown any clear trend over 68 years of observations prior to 2015 (Bindschadler, 2002;MacGregor et al., 2012;Rignot, 2002).”  (Arndt et al., 2018)
7. East Antarctica gaining mass…projections due to ice sheet melt “overestimated”
“East Antarctic Ice Sheet (EAIS) mass balance is largely driven by snowfall. Recently, increased snowfall in Queen Maud Land led to years of EAIS mass gain. It is difficult to determine whether these years of enhanced snowfall are anomalous or part of a longer-term trend, reducing our ability to assess the mitigating impact of snowfall on sea-level rise. We determine that the recent snowfall increases in western Queen Maud Land (QML) are part of a long-term trend (+5.2±3.7% decade-1) and are unprecedented over the past two millennia. Warming between 1998 and 2016 is significant and rapid (+1.1±0.7 °C decade-1). Using these observations, we determine that the current accumulation and temperature increases in QML from an ensemble of global climate simulations are too low, which suggests that projections of the QML [Queen Maud Land] contribution to sea-level rise are potentially overestimated with a reduced mitigating impact of enhanced snowfall in a warming world.”  (Medley et al., 2018)
8. Globally, 73.1% of island coasts are stable, 15.5% are growing, and 11.4% are shrinking 
“This review first confirms that over the past decades to century, atoll islands exhibited no widespread sign of physical destabilization by sea-level rise. The global sample considered in this paper, which includes 30 atolls and 709 islands, reveals that atolls did not lose land area, and that 73.1% of islands were stable in land area, including most settled islands, while 15.5% of islands increased and 11.4% decreased in size. Atoll and island areal stability can therefore be considered as a global trend. Importantly, islands located in ocean regions affected by rapid sea-level rise showed neither contraction nor marked shoreline retreat, which indicates that they may not be affected yet by the presumably negative, that is, erosive, impact of sea-level rise. .. These results show that atoll and island areal stability is a global trend, whatever the rate of sea-level rise. Tuvaluan atolls affected by rapid sea-level rise (5.1 mm/yr; Becker et al., 2012) did not exhibit a distinct behavior compared to atolls located in areas showing lower sea-level rise rates, for example, the Federated States of Micronesia or Tuamotu atolls.”  (Duvat et al., 2018)
9. Since 1984, 48% of the globe’s shorelines have been stable, 28% are growing, and 24% are shrinking
“The application of an automated shoreline detection method to the sandy shorelines thus identified resulted in a global dataset of shoreline change rates for the 33 year period 1984–2016. Analysis of the satellite derived shoreline data indicates that 24% of the world’s sandy beaches are eroding at rates exceeding 0.5 m/yr, while 28% are accreting and 48% are stable. …. Erosion rates exceed 5 m/yr along 4% of the sandy shoreline and are greater than 10 m/yr for 2% of the global sandy shoreline. On the other hand, about 8% of the world’s sandy beaches experience significant accretion (>3 m/yr), while 6% (3%) are accreting more than 5 m/yr (10 m/yr). … Taking a continental perspective, Australia and Africa are the only continents for which net erosion (−0.20 m/yr and −0.07 m/yr respectively) is found, with all other continents showing net accretion.”  (Luijendijk et al., 2018)

10. “Despite sea-level rise” there has been a “land area increase in eight of nine atolls” since 1971
“We specifically examine spatial differences in island behaviour, of all 101 islands in Tuvalu, over the past four decades (1971–2014), a period in which local sea level has risen at twice the global average (Supplementary Note 2). Surprisingly, we show that all islands have changed and that the dominant mode of change has been island expansion, which has increased the land area of the nation. … Using remotely sensed data, change is analysed over the past four decades, a period when local sea level has risen at twice the global average [<2 mm/yr-1] (~3.90 ± 0.4 mm.yr−1). Results highlight a net increase in land area in Tuvalu of 73.5 ha (2.9%), despite sea-level rise, and land area increase in eight of nine atolls.”  (Kench et al., 2018)

11. Bangladesh coastal land area has expanded by 7.9 km2 per year during 1985-2015
“This paper draws upon the application of GIS and remote sensing techniques to investigate the dynamic nature and management aspects of land in the coastal areas of Bangladesh. … This research reveals that the rate of accretion [coastal land growth] in the study area is slightly higher than the rate of erosion. Overall land dynamics indicate a net gain of 237 km2 (7.9 km2annual average) of land in the area for the whole period from 1985 to 2015.”  (Ahmed et al., 2018)
12. 54% of ‘vulnerable’ SW Pacific Islands studied had shorelines that expanded from 2005-2015
“Summary: Atoll islands are low-lying accumulations of reef-derived sediment that provide the only habitable land in Tuvalu, and are considered vulnerable to the myriad possible impacts of climate change, especially sea-level rise. This study examines the shoreline change of twenty-eight islands in Funafuti Atoll between 2005 and 2015 … Most of the islands remained stable, experiencing slight accretion or erosion or a combination of both over time. The total net land area of the islands increased by 1.55 ha (0.55%) between 2005 and 2010, and it has decreased by 1.90 ha (0.68%) between 2010 and 2015, resulting in a net decrease by 0.35 ha (0.13%). … Results indicate a 0.13% (0.35 ha) decrease in net island area over the study time period, with 13 islands decreasing in area and 15 islands increasing in area.  Substantial decreases in island area occurred on the islands of Fuagea, Tefala and Vasafua, which coincides with the timing of Cyclone Pam in March, 2015.”  (Hisabayashi et al., 2018 )
Share this...FacebookTwitter "
"Nearly five billion people worldwide will use a smartphone by 2020. Each device is made up of numerous precious metals and many of the key technological features wouldn’t be possible without them. Some, like gold, will be familiar. Others, such as terbium, are less well-known. Mining these metals is a vital activity that underpins the modern global economy. But the environmental cost can be enormous and is probably far greater than you realise. Let’s walk through some of the key metals in smartphones, what they do, and the environmental cost of getting them out of the ground. Iron (20%), aluminium (14%) and copper (7%) are the three most common metals by weight in your average smartphone. Iron is used in speakers and microphones and in stainless steel frames. Aluminium is used as a lightweight alternative to stainless steel and also in the manufacture of the strong glass used in smartphone screens. Copper is used in electric wiring.  However, enormous volumes of solid and liquid waste (termed mine “tailings”) are produced when extracting these metals from the earth. Typically, mine tailings are stored in vast impoundment structures that can be several square kilometres in area. Recent catastrophic mine tailings spills highlight the danger of improper construction methods and lax safety monitoring. The largest spill on record occurred in November 2015 when a dam collapsed at an iron ore mine in Minas Gerais, Brazil, releasing approximately 33m cubic metres (enough to fill 23,000 Olympic swimming pools) of iron-rich waste into the River Doce. The waste inundated local villages killing 19 people and travelled 650km until it reached the Atlantic Ocean 17 days later. This was just one of 40 mine tailings spills that have occurred in the past decade and the long-term ecological and human health impacts remain largely unknown. One thing is clear though – as our thirst for technology increases, mine tailings dams are increasing in number and size, and so is their risk of failure. Gold and tin are common in smartphones. But mining of these metals is responsible for ecological devastation from the Peruvian Amazon to the tropical islands of Indonesia.  Gold in smartphones is used primarily to make connectors and wires but gold mining is a major cause of deforestation in the Amazon. Furthermore, extraction of gold from the earth generates waste rich in cyanide and mercury – two highly toxic substances that can contaminate drinking water and fish, with serious implications for human health.  Tin is used for soldering in electronics. Indium-tin oxide is applied to smartphone screens as a thin, transparent and conductive coating that gives touchscreen functionality. The seas surrounding Indonesia’s Bangka and Belitung Islands supplies about a third of the world’s supply. However, large-scale dredging of the seabed for the tin-rich sand has destroyed the precious coral ecosystem while the decline of the fishing industry has led to economic and social problems. What makes your smartphone smart? That’ll be the rare earth elements – a group of 17 metals with weird names like praseodymium that are mined mostly in China, Russia and Australia.  Often dubbed “technology metals”, rare earths are fundamental to smartphone design and function. Crystal clear smartphone speakers, microphones and phone vibration are possible due to small yet powerful motors and magnets manufactured using neodymium, dysprosium and praseodymium. Terbium and dysprosium are also used to produce the vibrant colours of a smartphone screen. Extracting rare earths is a difficult and dirty business, typically involving the use of sulphuric and hydrofluoric acids and the production of vast amounts of highly toxic waste. Perhaps the most disturbing and thought provoking example of the environmental cost of our smartphone thirst is the “world’s tech waste lake” in Baotou, China. Created in 1958, this artificial lake collects the toxic sludge from rare earth processing operations.   The valuable metals used to manufacture smartphones are a finite resource. Recent estimates indicate we will run out of some rare earths in the next 20 to 50 years, which makes you wonder if smartphones will still be around then. Reducing the environmental impact of smartphone use requires manufacturers to increase product lifetimes, make recycling more straightforward and be open about where they source their metals and the environmental impact. Around the world mining companies have made huge strides in practising more sustainable mining. But we as consumers also need to consider smartphones as less of a throwaway item and more of a precious resource that carries an enormous environmental burden."
"Due to the uncertainty of Brexit, property prices and the cost of living are on the increase while household salaries have remained the same. Home extensions and improvements therefore remain an attractive, financially viable alternative to relocating and buying a new property. Many homeowners are captivated by television DIY programmes, but are seldom aware of all of the potential pitfalls of engaging builders, the contract, and the quality standards required (for both materials and workmanship). Although most DIY programmes offer some important information, it’s easy to overlook these during the excitement – and stress – of getting the work done. “Jerry building” is a commonly used term to describe cowboy or fly-by-night operators who provide ridiculously cheap estimates and cash in hand offers that are difficult to refuse. Homeowners are seduced by the cheap price without much thought for the potential risks when construction work begins. Trying to address time-consuming and costly mistakes can then become a major problem. The flipside of this is that others are put off hiring anyone to do their work altogether. Brian Berry, chief executive of the Federation of Master Builders (FMB), recently stated that: A third of home owners are so anxious about the possibility of choosing a bad builder, they don’t commission any building work whatsoever. This means that the UK economy could be missing out on £10 billion of activity every year. The latest research undertaken by FMB reveals that, on average, homeowners “would spend £40,000 on major home improvement projects over the next five years if they could be guaranteed a positive experience”. So how can you achieve this? The following tips will help you find a bona fide builder at a reasonable rate. Check whether the builder is a member of a credible trade body, such as the Federation of Master Builders, the National Federation of Builders, and/or the Guild of Builders and Contractors. Members of these bodies are bound by a code of conduct. Ask about the builder’s experience and qualifications – it’s not enough that they have professional-looking letterheads and business cards. Do not hesitate to check their recent jobs – and speak to past and current clients if necessary. Don’t be shy. Professional builders won’t mind you conducting these checks. They realise how important it is for you to trust them and appreciate that their work is to a high standard. Only cowboy builders will be defensive and try to stop you looking too closely at their track record. Although there are several online websites – such as Rated People, My Builder, Trust a Trader and Find a Trade – that provide ratings for builders and local tradespeople, don’t rely on them too much. Due diligence is still required. Many builders offer insurance-backed warranties for their work. This may involve a small additional cost but does provide extra protection for you, the customer. But check the cost and the level of cover provided before you accept. Ask the builder who the insurance is provided by, and whether they are an established insurer. All of this will put you in a better situation if something goes badly wrong. Make a list of your requirements, and ensure the plans are in line with local planning permission guidelines and building regulations. If the job involves work to a wall you share with a neighbouring property, it may be subject to the Party Wall Act. Identify clearly what additional works are required – for example, rewiring, window replacements and decoration. Ask for a detailed breakdown of the estimate (item by item) and check how long  the estimate is valid for and how long the construction work will last. You can then draw up a contract using standard forms prepared by the trade bodies mentioned above. This should include an agreed contract duration (a start and completion date) and the key phases during the work. Rather than paying hefty deposits or for everything in one go, agree to make staged payments as each of these phases is completed – if you’re not sure how this works, seek advice from the Royal Institution of Chartered Surveyors who will put you in touch with local surveyors. This is critical. Many builders tend to front load the payments rather than spreading the cost across the duration of the contract, which makes it far harder for you to seek redress if anything goes wrong. Peace of mind is worth a little extra cost. Before releasing any stage payments, check with an appointed building regulations inspector that all works comply with building regulations. And ensure everything is in writing and above board. If someone is prepared to cheat on their taxes, are you sure they won’t cheat on you? An invoice and proper paperwork proves a relationship and, if a dispute follows, it can be helpful. Without it, how can you even prove your builder was doing the work? You can further strengthen your position by taking regular photographs of the works and keeping a log of their activities on a daily/weekly basis. And hold back a final payment until the work is complete, warranties and guarantees have been issued to you, and the job has been certified as completed by your building regulations inspector. If you’ve followed these simple tips, you can then sit back, relax and enjoy your new home."
"Wildfires, drought and extreme heat have been the talk of the town and country across Europe this summer. Attention has now turned to Portugal and Spain, where temperatures at the weekend reached more than 46℃ in some parts of both countries – close to the all-time European record of 48℃, set in Greece in 1977. Records aside, the obvious question is what is causing the current Iberian heatwave and whether this might be a harbinger of the future. A number of factors can be identified. These include unusually warm sea surface temperatures in the North Atlantic, a wandering jet stream and associated “blocking” pattern of high pressure, a very dry land surface, and climate change.  The anomalous size and position of warm water areas in the North Atlantic this summer have shifted the so-called “polar front” northwards. This is the point where warm air from the south meets cold polar air, and any movement in the front will affect the distribution of high and low atmospheric pressure right across the Atlantic. This in turn influences the flow of westerly winds across the Atlantic and over Western and Southern Europe, especially the thin and fast “jet stream” in the upper atmosphere. This summer, an area of persistent high pressure or “blocking” has become established over Western Europe and the eastern parts of the Atlantic. Such blocking causes the jet stream to appear “lazy” and wander much further north and south than its average position.  The upshot of all of this is that atmospheric blocking and a very snake-like jet stream prevents low pressure systems, and the “bad” weather they bring, from heading eastwards across Western and Southern Europe. In such a situation, the usual fluctuations between good, and not so good, summer weather are largely put on hold. Instead, as Portugal, Spain and much of Europe have experienced, clear skies, lots of heat, and very dry surface conditions become the norm.  In certain circumstances, persistent blocking can even draw in very warm air from elsewhere. This is what happened in Portugal and Spain,  after intense heat caused an area of low pressure to form over Iberia. This “heat low” created the conditions for the flow of hot dry air from the Saraha Desert. Currently life in Portugal and Spain is not just in an oven, but more like a convection oven. Heatwaves in Portugal and Spain are not uncommon because this type of extreme weather is characteristic of the hot and dry summers in the Mediterranean climate region. Yet there is convincing observational evidence that heatwaves are happening more frequently across the Iberian Peninsula. Logically the question arises as to what extent the current heat is associated with climate change.  Although answering this question thoroughly would involve undertaking some well-designed climate modelling experiments, it’s safe to say that there is indeed a fair chance the current heatwave is associated with climate change. That is because heatwaves are now happening on a background of rising global temperatures so the base level of background temperature on which extremes are occurring has lifted somewhat compared to pre-industrial levels. And what of the question on everyone’s parched lips: are the current extremes the “new norm”? The short answer is no, not right now, as extremes of over 46℃ still constitute rare events. However, analyses of the pronounced 2003 European heat wave, which affected both Portugal and Spain, indicate that the very similar extremes of August 2003 could be fairly normal by the 2040s. This of course raises questions as to the habitability of places that already possess harsh summer climates. Most likely their sustainability will depend on the extent to which traditional climate adaptation strategies related to building and lifestyles can be pushed to the limit to cope with a new climate future typified by summers with temperatures in and over the mid 40s and how flexible people and businesses might be to the idea of going elsewhere or literally underground during summer."
