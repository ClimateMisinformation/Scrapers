"Exposure to air pollution has a staggering effect on human health.  It is thought to cause around 7m premature deaths each year worldwide, with around 40,000 occurring in Britain.  These premature deaths can occur through air pollution increasing the likelihood of heart disease and stroke, or through exacerbating existing lung diseases such as chronic obstructive pulmonary disease (COPD) or asthma. My colleagues and I recently showed that air pollution particles can even damage the immune system. Governments can of course take action, regulating sources of pollution such as car exhausts, factories or wood fires, or implementing less obvious measures such as strategic tree planting. Indeed a new EU report says member states need to take more effective action to improve air quality and make the public aware of the problem.  However, there may be another issue in terms of how we actually measure air pollution, and what it means for human health. Air pollution is frequently underestimated, either through monitoring in the wrong places, or through limitations of the detection methods. However, research presented by Jacqueline Hamilton at the British Science Festival suggests that we need to look in much greater detail at the causes of air pollution in the environment.   Hamilton, an atmospheric chemist based at the University of York, is an expert in detecting the compounds that can contribute to the formation of some of the most damaging particles in air pollution. She says that rather than looking at particulate air pollution in isolation, we need to look at some of the substances that can generate air pollution particles, which she calls “missing emissions”.  One key pollutant, which Hamilton terms “large hydrocarbons”, may be causing more of a problem than has been realised. These substances contain high numbers of carbon atoms, and are found in higher concentrations in diesel than in petrol. Large hydrocarbons can be released into the air by vehicles which use diesel as a fuel. While new cars have low hydrocarbon emissions levels, older cars, as well as buses and taxis, can release high concentrations of diesel hydrocarbons from their exhausts.  The key issue is that while they are not particularly toxic in themselves, large hydrocarbons can actually react with other substances in the air to generate damaging nano-sized particles, what we normally think of as “particulate air pollution”. These particles have been shown to be extremely toxic to human health.  While there have been successful efforts to reduce the hydrocarbons that are emitted into the environment, we have previously known very little about how large hydrocarbons are released as they are so difficult to detect. Hamilton, however, has been able to use new high resolution “chromatography” technology that hasn’t been used before to detect emissions from diesel engines. She used this technique to measure a busy traffic area in London and identify the composition of all the hydrocarbons released. She found extremely high concentrations of large hydrocarbons. In fact, her data suggests that using current models, some hydrocarbon components of diesel emissions, such as those with 12 and 13 carbon atoms, may be underestimated by a factor of at least 70.  This is a concern, as there is very little monitoring of large hydrocarbons in terms of air quality. There is a well established network of over 300 air sampling units distributed throughout the UK which continually measure the nitrogen dioxide and particle concentrations in the air we breathe. However, there are only four monitoring sites that can measure hydrocarbons.   I spoke with Hamilton and she said that it was critical for more research to be performed to understand the chemistry of large hydrocarbons. This is essential if they are to be incorporated into the air quality models used by the government to understand air pollution exposure. She noted that it was still unclear how driving conditions could contribute to large hydrocarbon release from diesel vehicles, and that more work in the lab, and in the field, is urgently needed. The UK government has recently closed its consultation on its 2018 clean air strategy and the outcomes are due to be published in March 2019. Until then, it is clear that we need to continue to take action on both the known, and the “missing emissions” if we are to reduce the number of deaths attributed to air pollution."
"Zones of ocean known as Marine Protected Areas (MPAs) are all the rage. They have no single or agreed definition, but essentially they are areas of sea in which human activity is restricted or prohibited in order to preserve and protect marine habitat and species. They may be small coastal areas or very large offshore expanses of ocean. MPAs are established by local or national governments in order to address actual or potential threats to the marine environment, to create “blue corridors” and to safeguard the breeding and feeding grounds of various marine species. The thrust for large-scale MPAs is driven by global targets tied to international obligations under the Convention on Biodiversity 1992. Currently the global target is to protect 10% of the world’s oceans by 2020. But in September, at a side event to the United National General Assembly, the UK environment minister, Michael Gove, proposed that the global target be increased to 30% by 2030. This is not a new idea but it is a big ask, given the current conservative estimate that only around 3% of the world’s oceans are protected. The strongest advocates and lobbyists for large-scale MPAs are conservation charities, research institutes and individuals who catch the attention of the media, such as WWF,
National Geographic’s Pristine Seas Initiative, Pew Trusts, and the DiCaprio Foundation. Arguments are made that the most effective MPAs cover large areas (including reefs and the breeding and feeding grounds of open-ocean species such as sardines or tuna), in which all extractive marine activity by humans, such as fishing or mining, is prohibited, and which are maintained as no-take areas for an extended period of time. The case for creating such protected areas seems like an obvious win in environmental terms. But the science supporting such arguments is inconclusive and mixed, not least owing to lack of sufficient data, especially studies that take a longer-term view. Very large MPAs are also difficult to patrol, despite promises of using satellite and drone technology. Some appear to be little more than “paper parks”, protected in name only with overfishing and so on still happening. The oceans are regarded as part of the “global commons” and the heritage of mankind. And indeed they should be treated as such. But in the “blue” credentials race between nations seeking to declare ever bigger MPAs, there are a number of real political problems. Large-scale MPAs tend to be declared in areas where there is least likely to be major opposition, especially from fishers. Overseas dependencies and territories are particularly popular. It is much easier to declare large no-take marine protected areas around remote island overseas territories with small, economically dependent, politically weak, communities than coastal areas where articulate, well-resourced commercial interests voice opposition. The UK, for example, has declared large MPAs around the British Indian Ocean Territory and Pitcairn and it is proposing to do so around Ascension Island, South Georgia, St Helena and Tristan da Cunha. It has pledged to safeguard over 4m square kilometres of ocean around the territories by 2021.  While there may well be noble environmental reasons for doing this, there can also be significant political effects. A 2010 Wikileaks cable suggested that one motivation behind the MPA around the Chagos islands was to prevent resettlement of locals to their homeland. The locals sued the UK government – and although the UK’s Supreme Court has since rejected that this was a motivation, resettlement clearly remains an issue and was referred to by the International Court of Justice in the request for an opinion by the United Nations General Assembly. The UK is not alone. France, has declared a large MPA around New Caledonia; the US around Hawaii; and Chile around Rapa Nui Rahui (Easter Island). The largest protected areas are all in such distant waters. The legal procedure for declaring an MPA, meanwhile, often skips full democratic debate. In some cases they can be achieved by presidential fiat or executive order. All this means that those whose livelihoods are likely to be impacted by restrictions or prohibitions on human activity in an MPA may have little or no involvement in the decision-making process. Meanwhile, there is often no guarantee that promises made about the benefits of the MPA to local inhabitants – such as employment in eco-tourism, better fish size, large catches in the longer term, or profitable visits by teams of researchers and scientists – are delivered. Linked to this is the fact that the management of MPAs is not always representative. Local or indigenous people have been known to be marginalised. Management is sometimes dominated by the organisations that lobbied for the creation of the MPA is the first place. For example, where resources are limited, NGOs or researchers funded by these NGOs are often relied on. MPAs are also sometimes used as a trade-off by small states surrounded by large seas to reduce their financial burdens and attract inward investment as well as international approbation. An example is in the Seychelles, where a US$22m national debt owed to overseas lenders was traded to a US-based NGO (The Nature Conservancy) in return for an undertaking that future repayments by Seychelles will be paid into a trust fund directed at the conservation of two extensive MPAs. Taking steps to address concerns about our shared marine resources is of course commendable. But “ocean grabbing” through the declaration of MPAs is a worry, especially if nations agree the higher target to be achieved in a fixed time. Already there are calls by those urging caution for advocates and lobbyists to adopt ethical guidelines and suggestions for better and more equitable models of management. In some cases these are being heeded. Nevertheless, the targeting of small island states and the role of charitable organisations in what are, ultimately, political decisions, needs to be questioned. This article was edited on October 23 to clarify certain points."
nan
"All across the world, we hear uplifting stories that reflect the fast changes in the energy scene. The developed world is consuming less energy than ten years ago. Carbon prices are at the highest level in a decade. Costa Rica now generates more than 99% of its electricity from renewables. Yet the Paris climate targets seem in jeopardy and most forecasts say not enough is being done. Why? In truth, nearly nobody is doing enough to cut emissions by the 11-19 gigatonnes thought necessary to restrict the increase in the world’s temperature to 1.5℃ by 2050. While Europe has done so much in the past and has an 18% renewables share of electricity generation, now it is stalling. Donald Trump has taken the US out of Paris and is trying to revive the coal industry, while taxing imported solar panels. The developing world, which tends to be more heavily reliant on fossil fuels to produce power, will have taken note. This matters, because energy demand from non-OECD countries is currently around 60% of the world total. Consumption is still rising fast, with growing numbers of connected homes a key factor. Electricity generation by source, 2017 It is difficult to generalise, however. China has invested massively in renewable energy – US$127 billion (£99 billion) in 2017 alone, which is head and shoulders above any other country. The new solar capacity China installed during that year equates to several Hinkley Point nuclear power plants. With heavy government support, China has made excellent progress reducing energy consumption per unit of GDP, and an even better job at reducing carbon emissions per unit of GDP.  India is further behind. Where China announced that every household had access to electricity in 2015, India is still going through a major electrification push. It has doubled the proportion of homes connected to over 80% since the turn of the century, though millions of homes still don’t have electricity.  India’s electricity system relies primarily on cheap domestic coal, accounting for about three quarters of consumption. India is therefore heavily relying on coal to fuel its economic growth, and the electrification push is rapidly driving up demand – putting further stress on the power grid, too. China had an even greater dependency on coal a few years ago; now it is more like two thirds for electricity and 60% for energy overall.  India/China growth rates 2011-2017 But if India has more work to do, there are signs it is moving in the right direction. Investment in renewable power did finally top that of fossil fuel generation last year, and the country recently earned praise for its efforts in this area.  In sharp contrast to these countries, Russia has a Soviet legacy of full electrification. Yet power generation from renewables last year, excluding hydro-electricity, was only 0.1% of total output. Russia is instead pushing for more nuclear power, which is unpopular in the West. On the other hand, its coal dependency for electricity is in the low teens; most Russian power comes from gas.  Meanwhile, Africa, the Middle East and Southeast Asia have all seen strong increases in power generation and CO₂ emissions over the past decade. Recent data also contains stark warnings for the future: Indonesia, Pakistan and the Philippines all increased CO₂ emissions above 5% in 2017, mostly through significant increases in coal-fired electricity output. Many developing countries have resisted pressure from the West to decarbonise in the past, arguing Western industrialisation caused most of the problem in the first place, and it will be even harder to persuade them in the current climate. So it is important to realise it is not purely a straight choice between cheaper fossil fuel power and renewables (or nuclear): additional options often get overlooked.  Coal’s share of global electricity production is the same as 20 years ago. Yet newer plants have at least made generation more efficient. Between 1997 and 2016, fuel savings in power generation were 8% for coal and 16% for natural gas. Coal plants in developing countries are approaching the efficiency levels of the developed world, while gas plants have seen improvements worldwide.  We are also underplaying an opportunity with gas. When you compare new gas and coal plants, the carbon emissions from gas are between 50% and 60% lower per unit of power output. In this respect, the fact that gas-fired electricity output has almost tripled in the last 20 years is to be welcomed. Persuade some countries to switch future plants from coal to gas and you make a big difference to emissions. Methane emissions are a controversial downside, but there is still a case for gas.  Share of global electricity generation by fuel  Yes, replacing fossil generation plants with renewables is a quicker way to decarbonise electricity, but we need to be realistic. This will involve building a phenomenal amount of capacity – and we’re moving too slowly. Global investment in renewables actually fell last year. To turn this around, reducing costs is vitally important, as is carbon pricing – the UK is a prime example of how this can effectively remove coal from the energy mix. Nonetheless, scores of new fossil-powered plants are in the offing worldwide, and developing nations in particular are just not going to build enough renewables to reach the Paris targets. By 2040, renewables are still forecast to have a smaller share of power generation than oil, gas or coal. Carbon capture and storage is also growing too slowly. It is important to emphasise that electricity is not the only issue – it only accounts for about 40% of the increase in final consumption up to 2040. Another understated challenge, for example, is the growing use of oil in transport. Yet if there is an electric car revolution, a substantial share of that demand will shift into electricity – and it will only be as clean as its source.  But given the reality of where the world, particularly the developing world, is heading, we should only expect so much of renewables. We must also focus on plant efficiency and encouraging switching from coal to gas-fired power. I am not saying this will make the Paris targets achievable, but it will get us closer than being dogmatic about renewables. We need to recognise where we are and tackle carbon emissions from all possible ends."
"
Share this...FacebookTwitterA modest long-term (1800s-present) declining trend in ocean pH values predominantly occurred prior to 1930, or before anthropogenic CO2 emissions began rising precipitously. Since 1930, seawater pH trends have risen slightly, meaning sharply rising CO2 has been coincident with less, not more, ocean “acidification”.

Image Source (lower graph): Wei et al., 2015
Is “acidification” occurring too rapidly for species to adapt?
Scientists (Wei et al., 2015) estimate that the ocean’s global mean surface pH may have declined (i.e., become less alkaline and thus more “acidic”) by -0.07 to -0.08 in the last 200 years — from ~8.12 during pre-industrial times to 8.04 to 8.05 today.
It is commonly claimed that this long-term decline in pH, or “acidification”, is occurring far too rapidly for the oceanic biosphere to adapt.  Consequently, there are alarmist claims that the pH changes in the last few hundred years are so extreme they will lead to a mass extinction event.

Image Source: Wei et al., 2015
A pH change of -0.07-0.08 over 200 years is an overall long-term pH change rate of about -0.0003 per year.
By way of comparison, from one season to the next, or over the course of less than 6 months, pH levels naturally change by ±0.15 pH units, or twice the overall rate of the last 200 years. 
On a per-decade scale, the changes are even more pronounced.  Oceanic pH values naturally fluctuate up and down by up to 0.6 U within a span of a decade, with an overall range between 7.66 and 8.40.  This is decadal rate of pH change is larger than the overall 200-year trend (0.07-0.08) by a factor of 8.

Image Source: Wei et al., 2015
If the oceanic biosphere was incapable of adapting to the modern rate of long-term change (-0.07-0.08/200 years), or to the frequently-realized seawater “acidic” values of 7.7 or 7.8, one would think this vulnerability would have been observed at some point in the last 200 years.
Reconsidering the “acidification” starting point
Many of the highly cited pH trend studies choose a starting point from the recent decades rather than from a long-term record.  Dore et al. (2009), for example, chose 1988.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Using recent decades has the effect of illustrating that rapid pH decline, or “acidification”, coincides with dramatically rising CO2 emissions.  This is the intended representation, of course, because it is assumed that we humans are responsible for “acidifying” the oceans.

Image Source: Wei et al., 2015
What if we choose 1930 as the “acidification” starting point?
If CO2 emissions predominantly drive trends in oceanic pH, the correlation between pH decline and an explosive rise in emissions could presumably be established beginning around the 1930s, or when CO2 emissions began to rise dramatically.
Interestingly, an entirely different pattern emerges if we use 1930 rather than more recent decades as the starting point for pH trend detection.
Namely, the long-term decline in pH can mostly be found in the decades prior to the 1930s, or when steep increases in CO2 emissions were not occurring.
The post-1930s period even suggests a slightly rising pH trend.
In other words, after CO2 emissions began rising precipitously in the 1930s, the oceans have become less “acidic”.
This determination would appear to undermine the claim that human activity, and not natural variation, is what drives the long-term declining trend (0.07 to 0.08) in oceanic pH.



Image(s) Source (lower graph): Wei et al., 2015
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThere has been a flurry of major May cold weather and snow reports coming in from a variety of regions across the globe, leaving global warming alarmists speechless.
Australia in ice box
For example, weather site electroverse.net here just reported on how the entire Australian land mass is getting walloped by extreme cold as the winter season begins there.
“It’s a cold snap affecting the whole country, it’s a big one,” says Bureau of Meteorology (BOM) forecaster Sarah Scully. Temperatures would be 10C below normal “even in the Northern Territory and Queensland.”
German mountain peak sees 6 meters of snow – in May!
Much of Europe has also been seeing unusually cold temperatures as well. Germany’s highest peak, Zugspitze, recently saw snow pile up to 6 meters – in May.
“That’s “the most in 20 years,” reported Michael Krueger of Science Skeptical.
“Very remarkable” snow in Corsica
Dalmatia, Croatia has seen “its coldest May start since records began and a “very rare and very remarkable” just blanketed the Mediterranean island of Corsica.
“Very Rare and Very Remarkable” May Snowfall Blankets the Mediterranean Island of Corsica

New England: “Been brutal”…can’t remember such “delayed” spring
In North America in New England on May 13th, Vermont, New Hampshire and Maine were forecast to get snow, and not just dustings, but real cover.
Vermont-resident and NTZ reader Indomitable Snowman PhD wrote by e-mail 2 days ago: “It’s been brutal.  I can’t remember a ‘spring’ – ever – that has been this slow and delayed.  The grass is starting to turn green, but there is barely a hint of leaves on the trees.”
“Huge piles of snow” linger
Indomitable Snowman Phd – also a pilot – also described how he had just flown some friends up to Quebec City on May 12th and how on the way up they could see “there was still some snow in the forest and in the ditches”:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Snow still remains on the ground in mid-May over southern Quebec, Canada. Photo: Indomitable Snowman PhD.
And upon landing at CYQB (Quebec City airport), he wrote: “There were still huge piles of snow on the grass between the taxiways and behind the perimeter fence from the dumping of snow during the winter”. See photo:

Piles of winter snow remain at Quebec City airport in mid-May, with bare trees in background. Photo: Indomitable Snowman PhD.
On the way back, inbound to Burlington, Vermont, they flew past Mount Mansfield. What follows is footage shot BEFORE more snow fell the very next night (May 13-14):

https://notrickszone.com/wp-content/uploads/2019/05/KBTV-ILS33.mp4


Footage by Indomitable Snowman PhD.
As the footage shows, one might think it’s February over Vermont, and not mid-May!
By the early morning of May 14, the National Weather Service (NWS) in Vermont reported snowfalls of 3.5 inches in Danville, 2.3 inches in Williamstown, 2.5 inches in Plainfield and 2 inches in Marshfield. Mount Washington in New Hampshire even saw a foot of new snow. Mid-May!
Major Greenland glacier “slams on the brakes”
A sign that the globe, or at least a major part of the Arctic (a claimed “climate canary in a coal mine”) has been seeing a major warming slowdown is that European satellites have been showing how a mighty Greenland glacier has “slammed on the brakes”. The Global Warming Policy Foundation site reports:


In the 2000s, Jakobshavn Isbrae was the fastest flowing ice stream on the island, travelling at 17km a year. […] But now it’s all change. Jakobshavn is travelling much more slowly, and its trunk has even begun to thicken and lengthen.”


 


Share this...FacebookTwitter "
"Think of rainforests and the picture is inevitably one of a dark and forbidding realm where life is abundant, yet alarmingly cryptic. Rather than the sense of space offered by long, iconic grassland vistas, distance is compressed into tangled webs of foliage, veiling both predators and prey. Diffuse and difficult to access proteins, carbohydrates and fats increase the chances of encountering an array of lurking dangers. For these reasons, it has long been thought that humans were only able to colonise rainforests in the last few thousand years, after the development of agriculture. In fact, we still have no clear idea when humans first began to inhabit rainforests. But mounting evidence is deconstructing the idea that rainforests – that is, forests requiring between 2,500 and 4,500 mm of rain a year – were hostile “green deserts” to early hunter gatherers.  In South Asia, there is now compelling archaeological evidence that Homo sapiens rapidly adapted to life in rainforests. At Niah Cave in Borneo, toxic plants obtained from nearby rainforest habitats were being processed as far back as 45,000 years ago, soon after people were first documented in this region. In Sri Lanka, there is evidence for direct reliance on rainforest resources at least 36,000 years ago. And a paper published in Nature last year reported the presence of humans in a rainforest environment on Sumatra dating back to a staggering 70,000 years ago. If early humans could adapt to the rainforests of South Asia, then perhaps they also did so much earlier in Africa at the inception of our species. While this is not a new suggestion, we now know that our species first arose in Africa more than 300,000 years ago, leaving plenty of time for our ancestors to adapt to varied habitats.  But finding conclusive evidence for rainforest habitation is difficult. Rainforests are very challenging fieldwork environments, not least because the warm and wet conditions mean that very little of the archaeological record survives the test of time.  In addition, Africa’s rainforest ecologies are fragile, sustained by annual levels of rainfall that are at the lowest limit of what is required to maintain a rainforest. This means that there were frequent episodes of rainforest fragmentation in prehistory, making it difficult to establish the environmental context of past human habitation in regions that are forested today. With the exception of a few dedicated individuals, Africa’s rainforests have barely been explored for their potential role in human evolution. Despite the many problems described above, there are tantalising suggestions that humans used and perhaps lived in African rainforests far before the development of agriculture some 8,000-9,000 years ago. It is also becoming apparent that this line of research has growing implications for how we understand our evolutionary history. Rigorous ethnographic studies have demonstrated that the availability of wild plant foods have been considerably underestimated in Africa’s rainforests, and there is some evidence supporting the ancient exploitation of such resources. An ancient hominin tooth from Central Africa indicates that our hominin ancestors were already living in mixed environments at the edges of forests around 2.5m years ago. Composite foraging tools argued to be forest adapted may have appeared as early as 265,000 years ago and have been found across vast regions of modern rainforest. And new evidence published this year shows that humans were exploiting mixed tropical forest/grassland environments in Kenya up to 78,000 years ago.  Later human fossils dating to around 22,000 years ago from the Democratic Republic of Congo and 12,000 years ago in southern Nigeria feature enough distinctive morphological features to suggest that the populations they belonged to did not often mix with others from elsewhere in Africa. Specifically, these fossils bear more physical similarities to people living between 100,000-300,000 years ago than their contemporaries. It’s possible that they were separated because they had adapted to life in very different environments. My fieldwork in tropical West Africa has also uncovered striking cultural similarities. Some groups living here up to 12,000 years ago were making stone tools that were more typical of people living in similarly earlier time periods. This is not akin to findings from elsewhere which emphasise the late presence of a single artefact form in an otherwise “advanced” tool kit. My findings from Senegal could easily be transplanted to a situation 50,000 or 100,000 years earlier, and they would not look out of place. Why were people here maintaining such ancient material cultural traditions when populations elsewhere had begun to experiment with agriculture? Did they choose to sustain strong cultural boundaries? Or were they cut off, either by distance or some other factor? While we are still working to establish the environmental context of these sites, it seems plausible that regions of dense forest may have played an important role in separating – and hence diversifying – early Homo sapiens populations. Such regions represented discrete human habitats, heralding the beginnings of our adaptability or “ecological modernity” and adding to the gamut of processes driving the significant physical variation of early members of our species. Indeed, such processes of diversification may even have been the cauldron of our biological plasticity and behavioural flexibility, as I argue in a recent paper. The plot thickens further at this point. It seems that our species shared Africa with other, more genetically divergent hominins such as Homo heidelbergensis, Homo naledi and perhaps other as yet undiscovered species. There are even suggestions that there may have been gene flow between Homo sapiens and one or more such hominins. If proved, the shifting patchwork of Africa’s diverse environments – including rainforests – may therefore also have played a role in facilitating the late persistence of such species and subsequent episodes of gene flow with Homo sapiens. It’s possible that the last groups of species such as Homo heidelbergensis hid out in forests. Given the extraordinary discoveries of the last decade, it is certainly wise to keep an open mind and shy away from overly dogmatic assertions about human evolution. This is particularly the case when so little is known about vast swathes of Africa, whose rainforest regions alone cover 2.2m square miles. The only inescapable fact is that there is a lot yet to be discovered."
nan
"In an editorial on Saturday, the Weekend Australian defended the News Corp paper’s climate coverage in response to criticism that it had underplayed the bushfire crisis and chosen to highlight concerns about arsonists and hazard reduction rather than explain the climate change drivers of the horrendous season. The editorial said: “In our coverage, the Australian’s journalists report facts about how to tackle bushfires and about how to deal with the impact of climate change. Second, we host debates reflecting the political division that exists in Australia about how to address climate change without destroying our economy.”  It said its coverage of the bushfires had been “wilfully and ineptly misrepresented by the New York Times and Guardian Australia as climate denial”. The Australian newspaper’s editorials, like its news stories, accept the basic premise that humans cause climate change and that action should be taken. The newspaper also covers diligently the news around the climate policy debate and the implications of climate change for business. But its defence of its bushfire coverage ignores its prolonged willingness to expose readers to a regular diet of misrepresentations on climate change science on its opinion page, as well as outright denial of the breadth of science linking fossil fuel burning to dangerous climate change. In November, as the bushfire crisis was unfolding, News Corp’s executive chairman, Rupert Murdoch, told his annual general meeting: “There are no climate change deniers around, I can assure you.” The next day the Australian ran a column from the mining industry figure and geologist Prof Ian Plimer, who wrote: “It has never been shown that human emissions of carbon dioxide drive global warming.” The organisation Climate Feedback asks climate scientists to fact-check articles and opinion columns. Like three previous Plimer columns, the group gave the article its lowest rank for scientific credibility, saying it was “a mixture of misdirection, misleading claims and outright falsehoods”. Last month, two days after the Bureau of Meteorology declared that 17 December 2019 had been Australia’s hottest day on record, the Australian published a story quoting a long-time critic and climate science “sceptic” questioning the bureau’s methodology. The story quoted “climate scientist” Dr Jennifer Marohasy but did not mention that Marohasy works at the Institute of Public Affairs, a Melbourne thinktank heavily financed by the mining billionaire Gina Rinehart and known for promoting climate science denial. The story reported Marohasy’s criticisms of a widely used technique known as homogenisation that corrects for known errors in data, even though the data used to calculate the hottest day record is not homogenised. The Australian has a long history in this space. There have been lots (understatement alert) examples of climate science denial at The Australian over the years. I have written about lots of them. A thread.  In 2009 it published a column that dismissed climate science as a “fraud” pushed by “warmaholics”. In response, an exasperated Dr Michael Coughlan, then chief climatologist at the Bureau of Meteorology, said: “The Australian clearly has an editorial policy. “No matter how many times the scientific community refutes these arguments, they persist in putting them out – to the point where we believe there’s little to be gained in the use of our time in responding.” In 2013 a study of News Corp’s coverage of climate change found it was a dominant voice in the country’s media on the subject. The Australian wrote more on it than any other outlet, and almost half its comment pieces expressed doubt about the science, including 100% of seven editorials analysed. Only 18% of news stories expressed doubt, the study said. In 2013 the newspaper ran a front page story with the headline “Sea rise ‘not linked to warming’ ”, based on a study which it later admitted it had “misinterpreted”. The same year it ran a news story claiming that “experts” were worried about a coming ice age. The article relied on five-year-old quotes lifted from a blog by a group that has claimed carbon dioxide is a “coolant” and not a greenhouse gas. The Australian has also published stories sympathetic to claims that wind turbines make people sick. In 2012 the Australian Press Council upheld a complaint against the newspaper after it ran an article by a British climate science denier, James Delingpole, in which he quoted an anonymous sheep farmer who had compared the wind energy industry to a paedophile ring. After the press council’s judgment, Delingpole returned in the Australian to say he stood by “every word” of his story “especially the bit about paedophiles”. One of the Australian’s most flagrant and regular deniers has been Maurice Newman, the former ABC chairman and adviser to Tony Abbott who believes climate scientists are part of a global socialist plot. “The scientific delusion, the religion behind the climate crusade, is crumbling,” Newman has written. On checking one column, a scientist Newman had quoted to back his argument that global cooling was on the way said the claims were “scientifically ludicrous”. As recently as last week Newman referred to “the media left, Hollywood and the rest of the global warming cult”, comparing them to “ancient druids”. Even while covering the topic of hazard reduction, the Australian has turned to climate science deniers. On New Year’s Eve it ran an opinion column by Viv Forbes that advocated a revival of traditional fire management techniques, while blaming the intensity of the fires on a lack of hazard reduction and the creation of national parks. The column did not mention climate change. Forbes spent more than 40 years in the coal industry – a connection not disclosed in the column – and leads a project against the Paris climate agreement that says fossil fuel emissions are not changing the climate, and that increasing concentrations of CO2 are “improving the environment, not harming it”."
"Sea levels are rising and climate fires are burning. Unless the world acts urgently to combat the climate crisis, it will be too late to do anything other than shuffle around the deckchairs on the Titanic. So says the World Economic Forum, the body that organises the global elite’s annual shindig in the Swiss ski resort of Davos. Each year the WEF asks experts what are likely to be the greatest threats over the next decade; this year, for the first time, the top five risks all related to the environment.  Let’s park the cynicism for a minute. Yes, to be sure, there’s something nauseating about billionaires flying in from around the planet in their private jets to tell the rest of us we need to do more to reduce our carbon footprint. That said, the WEF report suggests it is a dangerous fallacy to assume that new ways of doing things can be phased in slowly over the next 20 or 30 years. Yet the political incentives to put off action for another day are strong. Governments in democracies have regular elections to fight, and they have seen what happened to Emmanuel Macron’s popularity after his attempt to raise fuel duty prompted the yellow vest protests. In Britain there are pressures on ministers to agree measures to boost growth that would be counter-productive from a climate emergency perspective. The battle to save the airline Flybe from collapse and the looming decision over the high-speed rail line HS2 illustrate the dilemma for a government that claims to want to tackle climate change and Britain’s glaring regional economic imbalances. If ministers had decided not to support Flybe earlier this week, Europe’s biggest regional airline would have seen planes grounded and 2,000 jobs put at risk. The chancellor, Sajid Javid, has said he will consider scrapping air passenger duty (APT) on domestic flights as part of his March budget. Would tossing this particular lifeline to Flybe allow Boris Johnson to escape the charge that he is a southern toff who is not remotely serious about levelling up the regions? Yes, it would. Would it be consistent with the aim of tackling the climate emergency? Not remotely. The best tax systems are those that penalise things a country wants less of while encouraging things it wants more of. Scrapping APT would do the opposite: indeed it would be both environmentally damaging and regressive, since it is the better-off – on average – who fly intercity in the UK. APT is not the world’s best-designed green tax, but at least it recognises that there are hidden costs to air travel, and that those doing the polluting should pay. Scrapping the £13 charge on domestic flights would, according to the basic laws of economics, encourage more people to fly. On the other hand, allowing Flybe to go to the wall would hack off a lot of voters, many of whom have just broken the habit of a lifetime and voted Tory. One alternative to flying is to take the train, yet the decision over whether to give approval to the high-speed link between London and the north of England presents another tough choice. Until now, the case against HS2 has primarily been about its cost to the taxpayer, and there is certainly reason to be worried on this score: the costs have spiralled since it was first mooted. An initial £34bn price tag now stands at £88bn, according to the latest estimate. At the outset, taxpayers were supposed to get £2.30 back in economic benefits for every £1 spent. That is now down to between £1.30 and £1.50 for every pound invested, a figure that relies on no further cost rise and much higher train frequency than on other high-speed lines – both heroic assumptions. But HS2 also has an environmental cost. A detailed report into its impact on wildlife says it will irreparably damage five internationally protected sites, almost 700 local wildlife sites, more than 100 ancient woodlands and 33 legally protected sites of special scientific interest. An HS2 spokesperson says the data is not new, and that the line will provide a cleaner and greener way to travel. But, increasingly, HS2 looks an enormously expensive way of adding some extra capacity to the rail network. Critics say there are less environmentally damaging and cheaper alternatives that would generate greater economic benefits to the UK in general and the regions in particular. They are right, and it is really quite scandalous that there has not been more careful consideration of whether the cash for the project (which will almost certainly end up costing more than £100bn) could be better spent. Ministers will probably give it the go-ahead anyway. Johnson has been something of an HS2 sceptic, but does he want his first big post-election domestic decision to be the abandonment of a project supported by Labour councils in the north, especially given that a third runway at Heathrow is going ahead? It would seem that, once again, infrastructure spending was being concentrated in the prosperous part of the country. The political optics would not be good. In their different ways, the cases of Flybe and HS2 tell us much about modern Britain. When it comes to making decisions, the short term triumphs over the long term every time, especially when a powerful corporate lobby gets to work. Ministers say they see no contradiction between a growing economy and protecting the environment, and proudly boast that they are pledged to make Britain a net zero-carbon economy. But that happy day is not planned to arrive until 2050. If the rest of the world follows Britain’s example, that will be a couple of decades too late. • Larry Elliott is the Guardian’s economics editor"
"The cold, remote Arctic Ocean and its surrounding marginal seas have experienced climate change at a rate not seen at lower latitudes. Warming air, land and sea temperatures, and large declines in seasonal Arctic sea ice cover are all symptoms of the changing Arctic climate. Although these changes are occurring in relatively remote locations, there is growing evidence to link Arctic sea ice retreat to increasingly erratic weather patterns over the northern hemisphere. As sea ice declines, areas of open water increase, allowing the ocean to lose more heat to the atmosphere. Heat lost from the ocean to the atmosphere reduces the atmospheric pressure which provides more energy to storms and increases their cloud content through evaporation.  Water flowing north from the Atlantic Ocean provides a major source of heat to the Arctic Ocean and surrounding continental shelf seas. While the Atlantic Water (the particular water mass in the Arctic ocean) carries enough heat to melt all the floating Arctic sea ice in less than five years, it is currently insulated from the surface by a lighter, fresher layer of water over most of the central Arctic Ocean.  However, this paradigm appears to be changing. North of Svalbard, Atlantic Water heat has been mixed up towards the surface, resulting in increased surface heat lost to the atmosphere over the ever greater area of open ocean. This change has recently been shown to enhance the rate of sea ice loss eastwards.  A key Arctic region for Atlantic Water heat exchange with the atmosphere is the Barents Sea. Atlantic Water flowing east through the Barents Sea Opening – between Bear Island, and northern Norway – remains exposed to the atmosphere as it circulates through the central Barents Sea. It gradually cools and becomes fresher (due to sea ice melting) as it moves eastwards to the Kara Sea.  In the Barents Sea, sea ice forms every autumn and melts in late spring/summer. In the northern part of the sea, a north-south change from cold to warm sea surface temperatures signals the presence of the Polar Front, which separates cold Arctic water from the warm Atlantic water. The meeting of the two water masses, its location and the temperature difference across it reflects changes in Barents Sea circulation. During years with low seasonal sea ice concentrations (when there’s more heat loss from more exposed open water), the north-south differences in atmospheric temperatures across the Barents Sea are reduced. These conditions have been linked to wintertime cyclones travelling further south into western Europe, instead of their tendency to move eastwards towards Siberia, as well as more frequent cold winter extremes at middle latitudes. For our recent study, we looked at satellite measurements of sea ice and sea surface temperature, to determine how ocean and ice conditions have evolved between 1985 and the end of 2016. We found that prior to 2005, sea ice extended south of the Polar Front every winter, but that since 2005 this has not been the case.  At the same time, the sea surface temperature difference across the Polar Front has increased, with southern temperatures increasing at a faster rate than those to the north. The average between 1985 and 2004 was -1.2°C in the north and 1.5°C in the south, while between 2005 and 2016 it was -0.6°C in the north and 2.6°C in the south. Clearly, from 2005 the Barents Sea has become too warm for sea ice to exist south of the Polar Front. The question then is why is the Barents Sea getting warmer? Long-term oceanographic measurements of water temperature and salinity near the Barents Sea Opening have shown that inflowing Atlantic Water temperatures have increased over the last 30 years, with what appears to be a small but persistent rise around 2005 – likely to be due to upstream changes in the North Atlantic sources (though it must be noted that our study did not explore this question). An impact of the warmer water entering the Barents Sea is a warmer atmosphere, which in turn insulates the warmer surface water allowing the Atlantic Water heat to penetrate further to the north, preventing winter sea ice formation and import (that is sea ice that has formed farther north that has drifted southwards) to the region south of the Polar Front.     We believe that this represents a long-term shift in the climate of the Barents Sea, a region already identified as influential on lower-latitude European weather. Furthermore, we believe that the 2005 regime shift we observed over the Barents Sea may have contributed to the increasingly frequent extreme weather events experienced over Europe in the past decade or so."
nan
"
Share this...FacebookTwitterBy Kirye

 
 
 
 
 
Since the global warming scare started some 30 years ago, Japan’s winters in fact have have not been warming – but rather many areas show the opposite is happening: cooling.
January in Japan no warming in over 30 years
For Japan as a whole, the entire country has not seen any rise in January mean temperature over the past 30 years, according to data from the Japan Meteorological Agency (JMA):

As the chart above shows, if anything, Japan mean January temperature has been falling a bit, thus contrdicting the warming claims of climate alarmists.
Cooling Kyoto
January in Kyoto has been cooling over the past 30 years, as the following chart shows, even as atmospheric CO2 concentrations have risen from about 350 ppm back in 1985 to over 410 ppm today:

No trend at Naze in 33 years
The same is true for the south Japan station of Naze:

Naze has seen slight January cooling over the 33 years – not warming!
Wintry Hokkaido stays that way
In northern Japan, the month of January has also gotten slightly colder over the past 30 years, as shown by measurements taken at the Suttsu station in Hokkaido:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





 
Overall, January today in Suttsu is at about the same level as it was more than 100 years ago.
Same is true at Okinawa
Moving far south to the Nago station in Okinawa, here as well we see that January mean tenmperatures have been cooling, and not warming like climate activists insisted it would.
Japan refuses to cooperate with the global warming “science”:

By now many people should be awaiting an explanation as to why the trend has behaved the opposite of what has been predicted for decades by CO2 global warming scientists.
Cooling near Nagasaki
The trend for January at the Sasebo station near Nagasaki over the past 32 years has also seen a steady linear decline:

How can anyone in the Japanese media be speaking about rapid warming over the recent years? Much of the climate news in Japan are of poor quality, unfortunately, as they continue to make people believe it’s warming when it is in fact not.
Japan’s winters have seen no trend 
Okay, the charts show trends for the month of January, the dead of winter. So what about the complete winter in Japan from December through February? Here as well we see no warming at all across Japan:

The untampered data from the Japan Meteorological Agency (JMA) shows the Japan’s winters have not warmed at all in over three decades.
Typhoons have also become less frequent
In general many other factors have not cooperated with the many predictions made by global warming scientists. One important example is typhoons, which we were told would become more frequent and intense. But here’s the typhoon data from the JMA:

Also there’s been no real trend in the number of typhoon landfalls hitting Japan.
In summary, lots of hype about warming in Japan, yet the data haven’t shown it in over 3 decades.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman climate skepticism may have awakened, and ironically it may in large part be an unintended consequence of the “Greta demonstrations”. Germans may be finally getting fed up with the hysteria that has emptied out schools and turned into an ambush on their industrial jobs.
German geologist Dr. Sebastian Lüning, who together with Prof. Fritz Vahrenholt runs German climate skeptic site Die kalte Sonne, was recently interviewed by the conservative Junge Freiheit TV in Berlin (In German).

While the mainstream media focus almost exclusively on the ultra-alarmist climate scenarios, Lüning takes a far more moderate, non-alarmist view of climate and  man’s impact on it.
In Lüning’s view, natural factors play an as big, or even bigger. role on climate than humans do.
Recent warming “not unusual”
In the interview, Lüning explains how the assumptions made by the CO2 alarmists fall apart when tested against the observations of the past. The experienced German geologist explains why the modern 20th century warming is nothing unusual and that the same has already occurred numerous times over the past 10,000 years.
Start of industrialization coincided with end of Little Ice Age
One problem, Lüning says, is that scientists like to begin their temperature charts right before industrialization began in earnest, which happens to coincide near the temperature low point of the Holocene. He says that the term “pre-industrial” has been the source of “lots of confusion”.

Medieval and Roman times were warmer. Image: Die kalte Sonne
Natural factors at work
Lüning reminds listeners that the question concerning how much of the recent warming can be attributed to man is still being hotly debated, and that we know that natural factors have always been in the driver’s seat in the past. Personally Lüning believes that the real figure is closer to 50-50, with a likelihood that natural factors are a bit more than half.
He thinks the CO2-based climate models so far have been unable to explain the climate variability of the past, but that those based on natural factors and the past changes are far better.
97% consensus claim very misleading
On the claims that there is a 97% consensus among climate scientists that man is now driving the climate, the geologist – who is also co-author  of the book: The Neglected Sun – says that claim is totally misleading:
The study is often cited, but unfortunately misunderstood. If you look closely at the study, then you quickly see that it has to do with a completely different question. That Co2 drives warming, most people – even the large majority skeptics – concede CO2 warms, but it gets down to the question of how much. […] All those who think it’s just a little bit get also lumped into the 97%. I’m in the 97%. Donald Trump is a part of the 97%, as he recently said that it is possible that CO2 warms.”
Preindustrial global temperature much worse
Next Junge Freiheit (JF TV)  asks if a one-degree temperature rise would be so bad. “Is today’s temperature worse than the level of 1850?”
Lüning replies, reminding us that 1850 was the Little Ice Age and how it was “really a difficult time”. Lüning added:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




We had crop failures. We had cold. We had disease. We really should appreciate that we no longer live in the Little Ice Age because that one degree of warming was urgently needed. No one would want to go back to this cold period.”
Concerning another 1°C of warming ahead, he says that it would not be only bad news. “There would be winners and there would be losers.” He points out that especially Canada and Siberia would profit.
Emotionalized – kids should return to school, learn fundamentals
Lüning is also critical of the “Greta demonstrations” which he says “have moved the discussion from a factual one to one that is emotional”. He adds: “It’s good that the youth are getting involved, but they should return to school and learn physics, chemistry and geography and all the fundamentals of climate science.”
Strongly filtered press
Lüning also sharply criticizes the press, saying the issue has been “strongly filtered”:
Everything that is negative gets sold as headlines. And things like it’s been cooling for the last 3 years naturally get no headlines. What gets reported is very selective.”
Lüning calls the media “filtering” a fundamental problem that should not be happening in the 21st century.
Published literature far more balanced than media
When asked if the the published science is as imbalanced as the media, Lüning responds: “Not at all.” He says a new (non-alarming study) comes out almost daily, but the media refuse to report on it and instead they “prefer to report on alarmist ones, particularly from an institute located close to Berlin.”
Catastrophe very unlikely
Finally, when asked if we need to worry about the planet going under, as many projections range from manageable to catastrophic conditions ahead:
I see very many indications showing that it’s going be at the lower end of the range, towards manageable. That doesn’t mean we don’t need to do anything. But we don’t need to be preparing for the worst case scenario.”
In Lüning’s view, the path is very long and it should be taken one step at a time. He also tells JF-TV that climate science is still poorly understood and that more research needs to be done. He sees no need to hysterically put the entire economic system in question.
Viral: Nearing 50,000 views in just 2 days
On a positive note, since the JF-TV interview was released on Youtube just 2 days ago, it has been viewed already almost 50,000 times. For a German climate skeptic video, this is nothing short of phenomenal!
Perhaps in Germany it’s one thing to protest climate change, but maybe people are now getting fed up with kids not going to school and instead irrationally turning the discussion into a hysteria.
I asked Dr. Lüning what he thought about the video getting so many views. His reply by email:
People want to see a more balanced climate discussion, involving all views, not just the most extreme alarm scenarios.”
Germans are also starting to get fed up with the onslaught on their industry and jobs.
Share this...FacebookTwitter "
"James Murdoch claims he has never watched Succession, the drama series that documents the professional and personal rebellions of a billionaire media family suspiciously similar to his own. But his comments attacking the family business’s record on climate crisis coverage – which blindsided other parts of the family – suggest he may have picked up a few pointers from the HBO show. The declaration that he and his wife, Kathryn, felt “frustration with some of the News Corp and Fox coverage” of the climate crisis, particularly the “ongoing denial among the news outlets in Australia, given obvious evidence to the contrary”, focused an awkward light on the family’s businesses – but could help James differentiate himself from his father, Rupert, and brother, Lachlan.  His statement raised eyebrows, not least because until 18 months ago James was at least nominally responsible for Fox News output as boss of its parent company. He is also still a director of News Corp, which owns the family’s newspaper interests. Peter Barnes, a board member, said the board had yet to discuss the comments. But making a public stand on the issue has also helped the 47-year-old make clear to the wider world that he is heading in a different direction from the family business, as he looks to make investments in media companies with a more liberal standpoint. He has already donated to the US presidential campaign of Democratic candidate Pete Buttigieg, joined the board of Elon Musk’s Tesla, and made clear he wants to distance himself from the conservative outlets associated with his surname. Alice Enders, of media analysts Enders, suggested Murdoch had always had a genuine and sincere concern about environmental issues throughout his career: “He and his wife believe in this so fundamentally and so strongly. They obviously believe that the media has a very important role in this.” She added: “It’s very unusual to decide that the public domain is the best place to air a difference of views.” The move caps a long journey for an individual who has often seemed uneasy with his enormous privilege, without ever rejecting it. After dropping out of Harvard in the mid-90s and working as a cartoonist, he helped to run the pioneering New York hip-hop record label Rawkus Records, providing funding for the operation. According to one person who visited the offices in this period, the twentysomething had “pierced ears and eyebrow, dyed hair, a goatee, and a poster of Chairman Mao on his wall in New York”, apparently rebelling against his family while also using its funds to subsidise his interests. After exiting the music industry – having sold a majority stake in Rawkus to his father – he was brought into the family business, having a brief stint advising on internet investments during the dotcom boom, followed by a spell running Asian pay-TV operator Star. But he shocked the British media scene when he was appointed as chief executive of BSkyB, a listed FTSE 100 company, at the age of 30. It was during this time that he became increasingly concerned about climate change, inviting former US vice-president Al Gore to give a talk on the topic, and was an early convert to making businesses carbon neutral. Following a stint at the European arm of News Corp – where he was in charge as the phone-hacking scandal ravaged its newspapers and forced the closure of the News of the World – he became chief executive of 21st Century Fox until it was sold to Disney at the end of 2018. While there had been suggestions that James – until recently seen as the heir apparent – would join the combined behemoth, he instead walked away with billions of dollars. In the process, he left his brother in charge of a new, much smaller, Fox Corporation, which controls a group of television channels including Donald Trump’s favourite outlet, Fox News. Enders said that Murdoch’s approach to the environment contrasted with his father’s focus on profits at all costs. While it would be hard for the likes of Fox News to U-turn on the issue of the climate crisis, she suggested it could encourage journalists within the organisation to voice their concerns about coverage: “There’s a lot of people who are going to be standing up at News Corp meetings making these points.” Individuals who have worked with Murdoch at BSkyB insist that his commitment to environmental issues is sincere, while also pointing to the influence of his wife, Kathryn, who put her name to the joint statement. In recent days she has used Twitter to share links to stories about investment company BlackRock putting climate change at the centre of its investment strategy and a story in the Murdoch-owned New York Post suggesting conservatives have answers to climate change. She also linked to an article in Vice – an outlet in which James’s company recently bought a minority stake – blaming the bosses of large fossil fuel producers for the bushfires in Australia. The piece is withering about claims that arsonists are responsible for the natural disaster unfolding in Australia, mocking “Rupert Murdoch’s rightwing media outlets” for spreading such claims, which have “been given a huge platform in the US by Donald Trump Jr and Sean Hannity” – critiquing both the president’s son and one of Fox News’s most prominent hosts. On Wednesday it appeared that at least one part of Rupert Murdoch’s newspaper empire was listening. The Northern Territory News – one of the company’s most rambunctious tabloids – ran a front-page editorial breaking with the party line of many other Murdoch outlets: “Now is not the time to play the blame game,” its front page declared. “Now is the time to discuss climate change.”"
"It comes as quite a shock when the ground beneath your feet, your house or your field suddenly disappears leaving a hole. This hole may be tens of metres or more deep, and it will eventually lead into a cavity which may extend downwards for hundreds of metres below the ground.  We call these sinkholes, and they are a global problem. Sometimes sinkholes are a purely natural phenomenon, but they may also be associated with previous industrial activities, most commonly mining. So how do scientists like us detect a sinkhole before they appear at the surface? The geology of the rocks beneath you is a clue to the possibility of sinkholes. Limestone is prone to dissolution by groundwater which can, over time, create enormous networks of underground caves known as karst. These can collapse downwards due to gravity, leading to great surface depressions and subsidence damage and even the complete loss of houses. Poorly mapped and recorded historic mine workings in coal, salt, potash, tin and copper often leave voids in the ground. These voids may eventually come to the surface over time as the roof progressively collapses. These collapses can be gradual, or can happen suddenly, with surface depressions appearing overnight without warning. Such rapid events are often associated with changes in groundwater or during excessive rainfall events. In a region where all of the surface rocks are limestone, such as Florida or large parts of China, it is difficult to avoid the risk which these pose as there is often little prior warning.  In densely populated areas, such as the UK, a lack of available land is leading to brownfield sites being utilised, often without adequate prior knowledge or ground investigation. Compensation is available for some kinds of collapse, such as coal mining liabilities which are covered by The Coal Authority, but many of the other causes are seen by insurers as “Acts of God” and cover is expensive or difficult to obtain. We have both worked on the problem of sinkholes everywhere from gold mines in Australia to the Middle East, particularly in Kuwait and the Dead Sea, and the Bahamas. We’ve also been all over the UK and Ireland, looking at mining cavities in South Wales, Yorkshire and the Potteries, and collapses from medieval robbing of chalk for mortar beneath a major road near London.  Over the years, we have become experts in measuring the Earth’s gravity at ultra-high precision to a few parts in a billion. This is known as microgravity. We can use this to detect a cavity, or even a partially-filled area with less density than the surrounding rocks, long before any collapse reaches the surface.  Often, we are called in after the first collapse has occurred to detect all of the other potential sinkholes nearby. Developers need to start thinking about this kind of work before building commences. An additional innovation we have developed is to carry out what are known as 4-D, time-varying, repeated microgravity surveys at intervals of months to years. This enables us to detect changes in gravity, which suggest that the cavities are propagating towards the surface and potentially becoming unstable. We have been observing a problematic section of the Trent and Mersey Canal in Cheshire since 2002 and have repeated readings on more or less an annual basis. Over this period, the microgravity results suggest increasing anomalies and that the underlying salt mines which were the reason why the canals were constructed in the first place are becoming less stable. This may be due to leakage from the canals themselves or more frequent intense rainfall as the climate changes.  A recent collapse of a section of the same canal nearby at Middlewich, which caused great disruption and almost led to loss of life, has brought our work into sharp focus.  The proposed route of Phase 2 of HS2 is planned to cross a significant portion of this Cheshire Salt Field where subsidence is very common and the engineering challenges for this high-speed line will be considerable. We have contributed to a new Channel 5 series on sinkholes that has covered this issue and our work in some depth. We hope to be able to give guidance on how the area should be fixed and where this technique might be utilised to map other vulnerable areas along this network of waterways. After all, it is possible to do something about sinkholes – if they can be detected in time."
"
Share this...FacebookTwitterAccording to German online business daily Handelsblatt here, German electricity are set to get significantly more expensive in 2019 due to the power grid becoming 8 percent more expensive to use.  This will make already painfully high electricity prices even more excruciating. 

The Handelsblatt cites calculations by German think tank “Agora Energiewende”, which reports that revenues for the network operators total 24 billion euros this year.
According to Agora, “Costs previously referred to as grid costs are expected to rise by a total of six to eight percent.” For household customers the grid already amounted to 7.17 cents per kilowatt hour in 2018, which compared to 6.79 cents per kilowatt hour levied for the renewable energy feed in tariffs. This year it was 6.41 cents.
According to the Handelsblatt, “The EEG levy and grid fees thus add up to amounts of over 50 billion euros” annually. The rising grid fees are due to “massive investment in grid expansion to integrate renewable energies into the grid”. And because Germany’s Energiewende (transition to green energies) still finds itself in the early stages, the costs are projected to keep rising.
In Germany, electricity prices of around 30 cents per kilowatt hour for private consumers are among the most expensive worldwide, and are in fact “the highest in Europe” Handelsblatt reports.
What is especially warped about Germany’s electricity market is that one kilowatt-hour of electricity “is available in wholesale for less than five cents”, reports the Handelsblatt. This shows how grotesquely distorted the price structure has become since renewable energies have been mandated and nuclear power plants taken offline. .
The high end-user prices have become a huge burden on private individuals and energy intensive companies alike. German think tank Agora is demanding reforms and more transparency in the country’s murky electricity pricing structure.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Kirye
Correction: 7 of 9 stations show no warming (not 8 of 9).
April data have been coming in, and they show that warming has been missing at many sub-Arctic stations over the past decades.
Canada cooling
Looking at 9 stations in Canada, where data from the Japan Meteorology Agency (JMA) are mostly complete, we see that the month of April hasn’t warmed at all despite all the hollering about a “climate warming crisis”.

Data source: JMA
In reality, the data show for April temperatures at 7 out of 9 Canada stations have been declining over the past 30-plus years!
Sweden no April warming in 2 decades
Next we look at data from 6 stations in the Nordic country of Sweden:

Data: JMA.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In Sweden, using stations with good data availability, we see that as a whole there has been no real April warming trend over the past 2 decades.
Irish spring is cooling
The same is true for the North Atlantic island of Ireland:

Data source: JMA
 
In fact, 5 of the 7 stations examined in Ireland have seen April cooling since 1993, a time when all the global warming hype was just getting started in earnest.
No warming at Antarctic station in 50 years
Finally. we move to the other end of the globe, Antarctica, and look at a plot of the annual data from the Japanese Showa research station:

Data source: JMA.
In an alleged time of “rapid warming”, nothing of the sort is actually happening. The Showa station, founded in 1957, in fact shows there hasn’t been any warming there in 50 years!
Share this...FacebookTwitter "
"From an unmanned submersible, protected by a casing of stainless steel almost an inch thick and a window made from super strong sapphire crystal, we can observe the life that thrives at our planet’s most extreme and darkest depths. Thanks to technology and sheer material strength, we can temporarily trespass into this high pressure environment. But in stark contrast to the robust deep sea imaging equipment we rely on, the creatures our camera records look extremely fragile.  Four-and-a-half miles beneath our research vessel, which was floating on the surface of the Pacific Ocean, we captured footage of several previously undiscovered species of hadal snailfish. With delicate fins and transparent, gelatinous bodies, they are some of this environment’s most enigmatic inhabitants, fish that – at first glance – look like they should be incapable of surviving under such enormous pressures. And yet, it appears they are thriving in this strange world. In spring, a team of 40 scientists from 17 different nations conducted an expedition to the Atacama Trench, which runs along the west coast of South America. We were there to find a particular snailfish.  On a previous expedition, our principal investigator (Alan Jamieson) had photographed a snailfish with long, wing-like fins at a depth of 7,000 metres. Only one species, Notoliparis antonbruuni was known to inhabit this area at such a depth. It had been described from a single specimen, so badly damaged that we are not able to use it to identify our images of living animals. We wanted to find this elusive winged snailfish again to learn more about it and observe it in its natural habitat. These hadal snailfish tend to live at depths between 7,000 and 8,200 metres (“hadal” simply means anywhere below 6,000 metres), but their apparent rarity is perhaps misunderstood. Because of their extreme habitat (at least for humans), they are difficult to observe rather than actually “rare” as we know it. And with the right equipment and opportunity, we were confident, after ten years of study, that we knew where and how to find them.   The Atacama Trench is part of the Peru-Chile subduction zone, a large 590,000 square kilometre area where one tectonic plate is being forced under another and the ocean floor quickly plunges to more than 8,000 metres. Its volume is almost the same as the neighbouring Andes mountain range, which the tectonic subduction zone also creates, and exploring it is no easy feat. We deployed our freefalling cameras 27 times – from the relative shallows at 2,500 metres to the trench’s deepest point, Richard’s Deep, at just over 8,000 metres. This enabled us to take more than 100 hours of video and 11,000 photographs at the seabed – and the results did not disappoint. The snailfish we were looking for made an appearance – and it wasn’t alone. Two other previously unknown hadal snailfish species were present in the footage. In fact, all three species appeared in the same shot on one occasion. Out of necessity, they were given quick, stand-in names: we called them the “purple”, the “pink” and the “blue” Atacama snailfishes. The “blue” appeared to be the “winged” species Jamieson had recorded previously. Its long trailing fins and prominent snout resembled the Ethereal snailfish we had recorded on another expedition to the Mariana Trench, far away on the other side of the Pacific.  The “pink” species, meanwhile, was more robust and was closer in appearance to the Mariana snailfish (Pseudoliparis swirei) that we described in 2017 and which also inhabits the Mariana Trench. To see these two species – with such different body plans – sharing a trench again got us thinking: they must be doing something different to one another down there to both carve themselves a niche. The third species, a small purple fish, looked more like the snailfish we would expect to see on the shallower abyssal plains – at a depth of around 3,500 metres. But one of these purple snailfish, just 9cm long, followed its invertebrate prey into one of our traps. This small fragile fish is currently the only physical specimen of the new species and should eventually allow us to give it a formal scientific name. And while we much prefer our video of the living animal, only a physical specimen can be deposited in a museum and used to formally describe a new species. Once on the surface, we photographed this specimen while it was suspended in chilled seawater – its body is simply too fragile to support itself in air and we didn’t want it to suffer the same fate as the poor blobfish, which, for the record, really aren’t that sad-looking (their jelly-like bodies just collapse when exposed at the surface). Over the following months, we then put the specimen through several stages of preservation to avoid shrinking its largely gelatinous body. So that scientists (and the interested public) don’t have to fight over access to a single, fragile specimen, it was also CT scanned at the Natural History Museum, London, creating a detailed 3D digital model of it, inside and out. Such digital back ups are gaining traction in science – take the Scan All Fishes project, for example. And disasters like the recent fire at Brazil’s National Museum, which will have wiped out many unique specimens, also show why they are so important. But what have we discovered about these mysterious creatures? First, as fish approach the absolute extremes of the environmental conditions that they can cope with, they do not simply eke out an existence but thrive. It is also emerging that some trenches support not only a single specialist species but multiple species with body plans that hint at different lifestyles within the trench.  Second, the snailfish family (Liparidae) is not only the absolute winner of the deepest fish award (having been found in multiple other trenches), but species are living in trenches that at times are over 10,000km apart and entirely isolated from one another. Incredibly, snailfish exist at these extreme depths, wherever these extreme depths are, and in numbers never thought possible. And the snailfish is just one story that emerged from our expedition. Over the coming months, we will continue to process the huge amount of data we collected, the most we have ever gathered on a single voyage. Our assessment of the large mobile animals we filmed will feed into the project’s larger goal to understand the biological and chemical processes within the trench as a whole."
"
Share this...FacebookTwitterThe publisher of conservative Swiss weekly “Weltwoche” and SVP National Council member Roger Köppel commented in an interview with the Baseler Zeitung (BaZ) on children skipping school to demonstrate for climate, and the climate movement in general.

Weltwoche publisher Roger Köppel. Image: https://twitter.com/KoeppelRoger
In the interview Köppel called the climate movement a “political mass trance that that is currently rolling over us” and that children have been prompted to skip school and protest an “infantilization” of politics.
In the interview, Köppel notes that the planet has warmed “only one degree since 1860” and that this increase is nothing unusual in a historical context.
“Dangerous” state intervention


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




When the BAZ points out that his opinion is more one from the fringes, Köppel dismisses it, telling the “Evangelium of climate prophets” is being challenged by renowned scientists like Richard Lindzen “while policymaking is already convinced that this climate hysteria is to be understood as absolute truth.”
He tells the BaZ that “it is dangerous that the state is massively intervening in our economy and energy supply.”
“State collective much more dangerous”
Later in the interview Köppel calls the belief that man has the main control over climate “presumption, religious delusion and self-denial.” When asked whether or not the state indeed should take action with regards to the “climate crisis”, Köppel replied “no”  and added: “The state climate collective is much more dangerous than climate change.”
“Dangerously one-sided” debate needs to be countered
So aggressive were the questions posed by the BaZ that Köppel asked: “Stop with this CO2 demonization”, telling the BAZ: “We have a hype about the climate. I’m talking about a new solar religion, a kind of political trance. It is the duty of citizens to take countermeasures. The debate is dangerously one-sided.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAnother new paper published in Paleoceanography and Paleoclimatology casts further doubt on the paradigm that says CO2 has historically been a temperature driver.
Evidence from the tropical Atlantic indicates today’s regional temperatures (15.5°C) are 7.5°C colder than a peak temperatures (23°C) between 15,000 to 10,000 years ago, when CO2 hovered around 220 ppm.


Image Source: Reißig et al., 2019
“[T]he Tobago Basin core 235 subSSTMg/Ca record is highly variable and ranges from ~13-23°C, which is approximately three times as much as at Beata Ridge.. In Tobago Basin, the subSSTMg/Ca decrease by ~2°C from 30 ka BP (18°C) to the onset of HS1 (16°C). Within HS1, the subSSTMg/Ca increase continuously by 2°C, while at ~15.5 ka it rises abruptly by ~6°C up to maximum temperatures of 23°C. The abrupt subSST rise is delayed too the reconstructed SST rise at the beginning of HS1 by Bahr et al. (2018) (Fig. S7). Subsequently, subSSTMg/Ca scatters around 20°C until the beginning of the Bølling-Allerød (B/A). During the B/A and the YD the subSSTMg/Ca remains higher than ~19°C, abruptly increases up to ~22°C at mid YD, while steadily decreasing afterwards reaching modern values of ~15.5°C in the mid Holocene. Lowest subSSTMg/Ca of ~13°C are observed after ~7 ka BP. On average, the LGM subSSTMg/Ca are warmer by ~2.5°C than during the Holocene.”
“[T]he subsurface temperature variability is a robust climate signal in the tropical W Atlantic. Both records show an increase of ~5°C in subSSTMg/Ca from the LGM to the early YD and a subSSTMg/Ca decrease by ~7-8°C during the Holocene suggesting that both sediment cores are influenced by the same oceanographic changes. Notably, the mid Holocene subSSTMg/Ca in Tobago and Bonaire Basins remain cooler by ~1.5°C and ~3°C, respectively, than during the LGM.”
“At Tobago Basin and Bonaire Basin, the deglaciation is characterized by abrupt rises in subSSTMg/Ca by ~5.5°C at the end of HS1 and by ~6°C at the middle of the YD to peak values of up to ~23°C and ~22°C, respectively, accompanied by changes towards saline conditions (mean δ18Osw-ivf of ~2.25‰ and ~2‰, respectively (Fig. 3). These highly variable changes occur within less than 400 years.”
“In contrast to modern conditions Tobago Basin core 235 was influenced by a warm water mass between 30-10 ka BP, indicated by elevated subSSTMg/Ca (~2.5°C warmer than the modern conditions).”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe German language Epoch Times here reports how the entire editorial board at the Wall Street Journal (WSJ) commented how the “German government under Angela Merkel was running the “world’s dumbest energy policy”.
“Devastating comment”
After having wasted billions of euros on renewable energies, saddling consumers with ultra high power prices, shutting down nuclear power plants, Germany has just decided to shut down its coal power plants by the year 2038. The Journal writes on the move to exit coal:
Having wasted uncountable billions of euros on renewables and inflicted some of Europe’s highest energy prices on German households and businesses, now Berlin is promising to kill the one reliable power source Germany has left.”
The Epoch Times calls the Wall Street Journal commentary “a devastating comment on the conduct of political decision-makers in a country that is not geopolitically considered an explicit opponent of the US.”
Even exceeds Europe’s “stupid environmental policy”
The Epoch Times, along with the Wall Street Journal, also says that “although stupid environmental policy is routine throughout Europe, with reference to the fuel taxes of French President Emmanuel Macron, who had triggered the protests of the yellow vests, the looming German renunciation of coal, however, would easily exceed even this standard.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Last reliable source will be shut down
“After the leadership in Berlin had already wasted countless billions of euros on renewable energies and had imposed the highest energy prices on European households and companies, Germany was now also offering the prospect of the end for the only reliable source of energy left to the country,” The Epoch Times wrote.
The Epoch Times also questions Berlin’s move with regards to pollution, writing that if the government complains that it is unduly polluting the environment, then it must ask itself why it had been “making the wrong political decisions for more than a decade” since it decided to burn more coal in lieu of the nuclear power plants which were shut down in 2011 in the wake of the Fukushima accident.
Green folly, dangerously dependent
And as Germany pushes to complete its Nord Stream 2 monster pipeline for delivering gas from Russia, the WSJ believes that Germany is dangerously making itself energy dependent on foreign countries. Just the compensation that has to be paid to coal power plants operators for the early shutdown will cost consumers 40 billon euros, the Epoch Times writes.
The WSJ does not think Chancellor Merkel will come to her senses, but hopes her successor Annegret Kramp Karrenbauer will. The WSJ adds:
Her successor will have the opportunity to name Ms Merkel’s green folly, and Germany’s troubled electricity customers should hope that this is the case.” &amp;amp;amp;amp;lt;img class=”wort-pixel” src=”https://vg06.met.vgwort.de/na/408ebf488a494fa392946e22f769ddd4″ alt=”” width=”1″ height=”1″ /&amp;amp;amp;amp;gt;&amp;lt;span id=”mce_marker” data-mce-type=”bookmark” data-mce-fragment=”1″&amp;gt;​&amp;lt;/span&amp;gt;
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAlarmists say that sea levels are rising rapidly, and unless we act now to take over the climate using the secret man-made CO2 reduction method, soon New York and even Cologne, Germany, will end up in water. At least that’s the alarmist scenario that the Truth Media like to tell us about.
However, a number of studies and tide gauge data tell us a very different story. Hat-tip: reader Mary Brown.
The latest study titled: Holocene sea-level change and evolution of a mixed coral reef and mangrove system at Iriomote Island, southwest Japan, by Yamano et al tells us that sea levels were more than 1 meter higher 5100 to 3600 years ago than they are today they, or 0.4 meters when corrected for tectonics.

The paper’s abstract follows:
Exposed fossil microatolls and core samples from a coral reef and a mangrove forest at the Yutsun River mouth, Iriomote Island, southwest Japan, reveal the internal structure and temporal changes in the sedimentary processes of a mixed reef–mangrove system. Evidence from the core samples and fossil microatolls suggests sea level reached its present position before 5100 cal yr B.P., and a relative sea-level highstand of 1.1–1.2 m above the present sea level occurred from 5100 to 3600 cal yr B.P. This was followed by a gradual fall in relative sea level. The tectonically corrected sea-level curve indicates a stable sea level after 5100 cal yr BP., with a sea-level highstand of up to 0.4 m between 5100 and 3600 cal yr B.P.
A nearshore reef dominated by massive Porites and arborescent Acropora initially developed at 6500–3900 cal yr B.P. Reef development was potentially terminated by relative sea-level fall and sediment discharge from the Yutsun River that affected the backreef environment. An offshore coral reef reached present-day sea level by 1000 cal yr B.P., forming a wave break that enabled the foundation of mangrove forest on the fringing reef after ∼1000 cal yr B.P. The reef development was significantly delayed compared with other coral reefs in the region with similar medium-to high-energy conditions, but it provided a calm environment in the backreef area that allowed the development of mangroves. These features demonstrate the chronology and causal relationship between coral reef and mangrove development under the influence of Holocene sea-level change and river discharge.”

The peer-reviewed study is yet more cold water on the heated alarmist claims of a rapidly accelerating sea level rise.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




NOAA: tide gauges measure only 1.7 – 1.8 mm
Tide gauges are also showing a much slower sea level rise. Just recently the NOAA here announced that had adjusted its tide gauge data for 2018 and now says the average global sea level rise rate is only 1.7-1.8 mm/yr, as opposed to satellite data which show a rise of over 3 mm per year.
Naturally, the tide gauge data are more crucial because they measure sea level rise at the coast where people actually live.
According to sunshinehours.net:
That’s a measly 5.6 inches by 2100. 
The map of relative sea level trends provides an overview of variations in the rates of local sea level change at long-term tide stations (based on a minimum of 30 years of data in order to account for long-term sea level variations and reduce errors in computing sea level trends based on monthly mean sea level).
The variations in sea level trends seen here primarily reflect differences in rates and sources of vertical land motion.
Areas experiencing little-to-no change in relative sea level are illustrated in green, including stations consistent with average global sea level rise rate of 1.7-1.8 mm/yr. These are stations not experiencing significant vertical land motion.“
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAccording to the calculations of Dr. James Hansen, the radiative influence derived from the increase in CO2 during the last deglaciation was so negligible that it equated to “a third of energy required to power a honey bee in flight” (Ellis and Palmer, 2016).

Image Source: Ellis and Palmer, 2016
Between about 22,000 and 17,000 thousand years ago, Earth’s sea levels were about 120 meters lower than they are now because much of the Earth’s seawater was locked up in kilometers-thick continental ice sheets.
Then, about 14,500 years ago, nearly the entire Northern Hemisphere abruptly warmed up by about 4-5°C within a span of about 20-30 years as sea levels rose at rates between 3 and 6 meters per century (Ivanovic et al., 2017).  Northern Hemisphere sea surface temperatures warmed by 3°C in less than 90 years during this time.

Image Source: Ivanovic et al., 2017
The last ice age ends and the Holocene begins
The Earth cooled and warmed and cooled and warmed for the next 3,000 years, during which time there was a gradual overall increase in global temperature of about 5-6°C superimposed on the abrupt decadal- and centennial-scale climate undulations.
By 11,700 years ago, when Greenland warmed up by 10°C within about 50 years (Steffensen et al., 2008), the last ice age glacial period ended and the Holocene interglacial warmth we now enjoy officially commenced.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Image Source: Muschitiello et al., 2019
The honey bee-sized magnitude of CO2’s influence during the last deglaciation
There are many adherents to the Shakun et al. (2012)-endorsed position that “increasing CO2 concentrations is an explanation for much of the temperature change at the end of the most recent ice age.”
And yet one has to wonder how this conclusion could have been reached when the explosive warmings of degrees-per-decade occurred without any clearly detectable changes in CO2.
Not only that, but as Ellis and Palmer (2016) point out, Dr. James Hansen’s calculations of CO2’s radiative influence during the ~5,000 years of the Pleistocene-to-Holocene 5-6°C deglaciation suggest a 0.006 W/m² per decade CO2 forcing during this period, which is “about a third of the energy required to power a honey bee in flight.”

Image Source: Ellis and Palmer, 2016
With this vanishingly small forcing magnitude, why is it nonetheless thought that CO2 is a macro-level driver of Earth’s temperatures and a determinant of deglaciation transitions?
Share this...FacebookTwitter "
"
Share this...FacebookTwitterDuring the last few hundred years, species extinctions primarily occurred due to habitat loss and predator introduction on islands.  Extinctions have not been linked to a warming climate or higher CO2 levels.  In fact, since the 1870s, species extinction rates have been plummeting.

Image Sources: Loehle & Eschenbach (2012), BBC, Wrightstone, 2019
In the past it has been widely reported that high and abruptly changing CO2 concentrations led to climate conditions that were “too hot for complex life to survive” on the planet.
More recently, though, scientists have determined that the opposite may have been true: mass extinction events occurred during periods of global cooling, expansive ice sheet growth, and marine-habitat-destroying sea level drops of more than 100 meters.
In fact, of the 5 previous mass extinctions, volcanism-induced glaciation is thought to be responsible for the 1st, 3rd, and 4th events, with the 2nd unknown and the 5th from an aseteroid impact.  None of these explanations have ties to CO2 concentrations or sudden warming.

Images Source: Jones et al., 2017, Phys.Org

Image Source: Creveling et al., 2018

Image Source: Isozaki and Servais, 2018

Image Source: Wu et al., 2014

Image Source: Kani et al., 2018
As suggeted above, scientists usually attribute the mass extinction cooling events to the same mechanism previously thought to cause sudden-onset warming: widespread volcanic eruptions.
More volcanism means more sulfate aerosols blocking out solar heat from penetrating into the ocean.  With “repeated clusters” of volcanic events gradually accumulating over time, decades to centuries of cooling can ensue.

Image Source: McGregor et al., 2015

Image Source: UPI.com
New (2019) research suggests that the global cooling extinction events could have been triggered by a solar-astronomical influence.
Again, this suggests no clear link between mass extinctions and CO2-induced or sudden-onset warming events.

Image Source: Isozaki, 2019

Image Source: Fang et al., 2018
Share this...FacebookTwitter "
"The international community has widely acknowledged the severe threats posed by the impacts of climate change to a series of human rights, including the rights to life, health, and an adequate standard of living. But a stark gap has emerged between this acknowledgement in global climate policy – evidenced by a non-binding clause in the preamble of the Paris Agreement – and their actions to meet promised targets. How can we hold governments accountable to their human rights duties? A Dutch case recently upheld by the appeals court might hold the answer. In June 2015, The Hague District Court and a group of 886 concerned citizens, united by the environmental interest group Urgenda Foundation, made history. This, the first successful climate change case brought on human rights and civil law grounds, saw the Dutch government ordered to reduce their greenhouse gas emissions by a minimum of 25% on 1990 levels by the year 2020.  Three years on – against a backdrop of intense scrutiny and after an appeal lodged by the government – The Hague Court of Appeal upheld this decision on October 9. Indeed, it has gone significantly further in affirming the duties of care owed by the state to its people. The court considered the weight of the scientific evidence presented by the Intergovernmental Panel on Climate Change (IPCC) and the recommendations of successive UN conferences to reach an informed conclusion on the required mitigation targets commensurate with the prevention of dangerous climate change.  Significantly, the judges reached this decision by applying the European Convention on Human Rights: the right to private and family life and the right to life more broadly. As such, this case reaffirms the existence of obligations on the part of the state to take concrete measures to prevent the infringement of these rights where the authorities are aware of the existence of a real and imminent threat.  These obligations were held to extend to industrial activities which threaten the rights of people within the state’s jurisdiction. Based on an analysis of the scientific evidence, the court concluded that climate change presents a real and imminent threat to the enjoyment of citizens’ rights as spelled out in the EU convention. They ruled that a 25% emissions reduction is the minimum required to fulfil the government’s duty of care. The Urgenda appeal decision was handed down too early for the findings of the most recent IPCC report on global warming of 1.5ºC, which was published the day before the ruling, to be integrated into the judges’ reasoning. But these findings will significantly strengthen the evidential basis of future claims. The IPCC report outlines the stark increase in the risks to human health, food and water security, and livelihoods associated with 2ºC of warming, when compared to 1.5ºC. The evidence presented on human health, including the increased risk of heat-related morbidity and mortality, projected with “very high confidence”, is particularly striking. The climate is currently 1ºC warmer than pre-industrial levels, and with the planet projected to reach 1.5ºC as early as 2030 if current trends continue, the alarm on the imminence of the threat to human rights has been sounded.  No legally binding human rights provisions or remedies are provided within the international climate change regime. And so we must turn to the courts to clarify state duties. The Urgenda case sets an encouraging precedent. And there are many more examples of rights-based claims being brought against governments in Belgium, Canada, Colombia, the UK, and even against the EU institutions. This marks a sea change in the use of human rights to hold policymakers to account for their inaction on climate change.  In the face of the severity and imminence of the environmental risks we face, the approach to human rights protection adopted by the Urgenda judges is crucial. If courts focus on the imminent risks to human life and health, cases brought forward by particularly climate-vulnerable groups should be prioritised. Individuals most at risk from rising temperatures and extreme weather events – including those whose livelihoods, socio-economic status, and geographic susceptibility result in them being disproportionately affected – would have the strongest claims. Civil society organisations have a crucial role to play in facilitating access to justice for such individuals, for whom entrenched structural barriers often mean that individual access to the courts remains out of reach. To effectively accommodate climate risks of this nature the existing legal doctrine will need to be adapted, bringing together environmental principles and human rights. The role of the courts themselves is being called into question by climate litigation: the separation of powers between policymakers and the judiciary is embedded in legal systems around the globe, yet the protection of fundamental rights is intended to transcend this divide. It is the duty of the courts to act as a check on executive action and, in this case, inaction, where the enjoyment of rights is in jeopardy.  Never before has the role of the courts been so significant in influencing the path of global policy. In the face of inadequately ambitious action by policy-makers, civil society movements and the courts are the agents of change securing climate action."
"The global food system has a lot to answer for. It is a major driver of climate change, thanks to everything from deforestation to cows burping. Food production also transforms biodiverse landscapes into fields inhabited by a single crop or animal. It depletes valuable freshwater resources, and even pollutes ecosystems when fertilisers and manure washed into streams and rivers. The planet can only take so much of this stress. Staying within its environmental limits will require a global shift towards healthy and more plant-based diets, halving food loss and waste, and improving farming practices and technologies. That’s what a team of international researchers and I found in a new study published in the journal Nature. The global food system has fundamentally altered our planet and the resource base humanity depends on. Food production is responsible for about a quarter of all greenhouse gas emissions and therefore is a major driver of climate change. Agriculture occupies more than a third of the Earth’s land surface and has led to reductions in forest cover and loss of biodiversity. Farming also uses more than two thirds of all freshwater resources, and the over-application of fertilisers in some regions has led to “dead zones” in oceans. Without concerted action, we estimated that the environmental pressure of the food system could increase by 50-90% by 2050 as a result of population growth and the continued Westernisation of diets. At that point, those environmental pressures would exceed key planetary boundaries that define a safe operating space for humanity. Crossing planetary boundaries would increase the risk of destabilising essential ecosystems. Among others, it could lead to dangerous levels of climate change with higher occurrences of extreme weather events; affect the regulatory function of forest ecosystems and biodiversity; result in disruptions of water flows with impacts on the global hydrological cycle; and pollute water bodies such that it would lead to more oxygen-depleted dead zones in oceans. Fortunately, such a situation can be avoided. We combined detailed environmental accounts with a model of the global food system that tracks the production and consumption of food across the world. With this model, we analysed several options that could keep the food system within environmental limits. Here is what we found: Climate change cannot be sufficiently mitigated without people eating a lot less meat. Adopting healthy and more plant-based diets globally could reduce the greenhouse gas emissions of the food system by more than half, and also reduce other environmental impacts, such as those from fertiliser application and the use of cropland and freshwater, by a tenth to a quarter. In addition to dietary changes, improving management practices and technologies in agriculture is required to limit pressures on agricultural land, freshwater extraction, and fertiliser use. Increasing agricultural yields from existing cropland, balancing application and recycling of fertilisers, and improving water management, could, along with other measures, reduce those impacts by around half. Finally, halving food loss and waste could, if achieved globally, reduce environmental impact of food production by up to a sixth. Many of the solutions we analysed are already being implemented in some parts of the world, but it will need strong global coordination and rapid uptake to make their effects felt. Take the necessary improvements to farming technologies and management practices, for instance. That would require a lot more investment in research and public infrastructure, it would need the right incentive schemes for farmers to ensure they don’t miss out financially, and things like fertiliser use and water quality would need much stronger regulation. Tackling food loss and waste will require measures across the entire food chain, from storage and transport, through food packaging and labelling, to changes in legislation and business behaviour that promote zero-waste supply chains. When it comes to diets, comprehensive policy and business approaches are essential to make serious changes possible and attractive for a large number of people. Important aspects include school and workplace programmes, economic incentives and labelling, and aligning national dietary guidelines with the current scientific evidence on healthy eating and the environmental impacts of our diet. As an individual, you can help by adopting a healthier diet with less meat. You can call on business to reduce waste across their supply chain and offer more plant-based food options. And you can hold politicians to account by demanding strong regulation of environmental resource use and pollution."
nan
"Sir David Attenborough has said it is “palpable nonsense” to suggest that Australia’s bushfire crisis has nothing to do with climate changeas he warned “the moment of crisis” has arrived. The 93-year-old British naturalist made the direct link between the ongoing bushfires and climate change during an interview with the BBC published on Thursday.  “As I speak, south-east Australia is on fire. Why? Because the temperatures of the Earth are increasing,” he said. “We have been putting things off year after year. We’ve been raising targets, saying ‘oh well, if we do it in the next 20 years …’ the moment of crisis has come.” More than 10.7m hectares of land have burnt so far in the Australian bushfires, including 80% of the Blue Mountains, and 50% of the Gondwana world heritage rainforests. While Australian prime minister, Scott Morrison, has talked down suggestions there are climate change deniers in his party, several Australian government MPs have continued to downplay the role of global heating on the bushfire crisis, and Morrison has attempted to pivot the debate from acting on climate change to resilience and adaptation. Attenborough said the world can no longer prevaricate and delay decisions, and the change needed to be made not by appealing to optimism but by highlighting it is a life or death decision. “This is not just having nice little debates and arguments and then coming away with a compromise. This is an urgent problem that has to be solved,” Attenborough said. “And what is more is that we know how to do it, that’s the paradoxical thing, that we are refusing to take steps that we know have to be taken. “And every year that passes makes those steps more and more difficult to achieve.” He said China needed to step forward and announce it is curbing carbon output because of climate change, and everyone else would “fall into line”. “That would be the big change that one could hope would happen.” He said the public mood had already shifted. “People can see the problem, particularly young people can see the problem, and that must force governments to take action.”"
"Some of the biggest companies in the world are funding climate misinformation by advertising on YouTube, according to a study from activist group Avaaz. The group found that more than 100 brands had adverts running on YouTube videos on the site that were actively promoting climate misinformation. The brands, including Samsung, L’Oreal and Decathlon, were unaware that their adverts were being played before and during the videos.  “This is not about free speech, this is about the free advertising YouTube is giving to factually inaccurate videos that risk confusing people about one of the biggest crises of our time,” said Julie Deruy, a senior campaigner at the group. “YouTube should not feature, suggest, promote, advertise or lead users to misinformation.” For the report, Avaaz examined videos pushed to users when they search “global warming”, “climate change”, or “climate manipulation” on the site, focusing particularly on those giving high prominence by YouTube’s recommendation algorithms. It found that 16 of the top 100 videos on the first term contained misinformation, as did eight of the videos found under “climate change” and 21 of those under “climate manipulation”. “YouTube has previously taken welcome steps to protect its users from anti-vaccine and conspiracy theories,” Avaaz argued, “but has not acted with equal force against broader misinformation and disinformation content, including climate misinformation.” The group called on YouTube to implement new policies to prevent the further spread of climate misinformation on its platform. It said the site should: Include climate misinformation in its “borderline content” policy, which limits the algorithmic distribution of videos that do not reach the bar required to fully remove them from the site. Demonetise misinformation, “ensuring such content does not include advertising and is not financially incentivised. YouTube should start immediately with the option for advertisers to exclude their ads from videos with climate misinformation.” Work with independent fact-checkers to inform users who have seen or interacted with verifiably false or misleading information. Provide transparency to researchers by releasing data showing how many views are driven to misinformation by its own recommendation algorithms. In a statement, YouTube said Avaaz’s report had its own transparency problems. “We can’t speak to Avaaz’s methodology or results, and our recommendations systems are not designed to filter or demote videos or channels based on specific perspectives. YouTube has strict ad policies that govern where ads are allowed to appear and we give advertisers tools to opt out of content that doesn’t align with their brand. We’ve also significantly invested in reducing recommendations of borderline content and harmful misinformation, and raising up authoritative voices on YouTube. “In 2019 alone, the consumption on authoritative news publishers’ channels grew by 60%. As our systems appear to have done in the majority of cases in this report, we prioritise authoritative voices for millions of news and information queries, and surface information panels on topics prone to misinformation – including climate change – to provide users with context alongside their content. We continue to expand these efforts to more topics and countries.” A L’Oréal spokeswoman said: “The information promoted by these videos is in direct contradiction with L’Oréal’s commitments and the work we have been carrying out for many years to protect the environment. We are collaborating with YouTube teams asking them to use all the technological means at their disposal to better inform the platform’s users about the nature of these videos and to limit their impact.”"
nan
"Scallop fishing attracts controversy. Dredgers scrape scallops out of the hollows they make for themselves in the seabed, and in the process disturb seaweed and other sea life that lives fixed to the bed. Even among senior marine scientists there is disagreement as to whether it is possible to do this sustainably. Most agree that certain vulnerable habitats such as seagrass and maerl beds should never be dredged, but that in some other areas dredging may be no worse than the disturbance from storms or currents. Scallops are also valuable – only mackerel and prawn fisheries are worth more to the UK. All this has led to battles between British and French ships over access to fishing grounds in the Bay of Seine off the coast of Normandy in northern France. The most recent conflict in the so-called “scallop wars” saw 40 small French boats try to chase off five larger British boats. Stones were thrown and boats collided, but there were no injuries or sinkings. Though what they were doing was totally legal in this case, the nomadic fleet of large British vessels doesn’t always help itself. Several high profile cases have found against them for fishing where they should not in UK and French waters, not keeping accurate records, landing bycatch species they don’t have quota for, or as in the case of Honeybourne III, which took a starring role in the recent altercation, landing undersize scallops.  The UK’s scallop fishers have also not made many friends among lobster/crab fishermen. A minority of scallop boats spark annual protests by Yorkshire fishermen as they tow away any lobster and crab pots that lie in their path.  The scallop wars have two underlying, root causes. The first is that there are two groups of fishermen, targeting the same species in the same area but under different rules. A local regulation prohibits French boats from targeting scallops in the Bay of Seine until October 1 each year. But this French regulation does not apply to British boats.  In previous years the French fishermen have persuaded the larger UK boats to stay away until October by transferring extra European fishing allocation to them, so they can fish in other areas. This year, with Brexit looming, and after increased numbers of British boats fished the area in 2017, this “gentleman’s agreement” broke down. Although it is legal for boats from Britain, Ireland and other countries to fish in the area before October, it must be incredibly frustrating for the French fishermen. Over a decade ago France instigated highly progressive management measures for its scallop fishery, including limits on licences, reductions in boat and gear size, time restrictions, and increases in dredge mesh size. It was tough on French fishermen at the time, but as one French fisheries scientist once told us: “No pain, no gain.”  Now scallop stocks in the Bay of Seine are at near record levels, but vessels from other countries are catching them before the French are even allowed to go fishing themselves. In comparison, although there are now efforts to improve the sustainability of the scallop fishery around the UK, catch rates are declining, while the the number of scallop fishing boats has increased from 135 a decade ago to more than 200. The second root cause is that nomadic boats from the UK and other countries have no links to the local community that depends upon the scallops in the Bay of Seine. Small boats, such as the French use, have a limited range and depend entirely on what they can catch in the area. In such situations where there are extensive kin ties and shared communities, fishermen are much more likely to develop informal agreements with regard to who fishes where. Of course, such tensions work both ways. For many years the French trawled for sea bass in the English channel, disadvantaging UK fishers who were banned due to concerns they would catch too many dolphins by mistake. The French fishery was only stopped by the EU when sea bass stocks collapsed. Neither side has come out of this well. What the UK boats did by fishing in the Bay of Seine may have been legal, and the French response overly aggressive, but they would have known they were asking for trouble and their own retaliation was over the top – and possibly illegal. As Barry Deas, chair of the national representative body of fishermen pointed out, this is just a skirmish before the battle of Brexit. Ships from elsewhere in the EU take more fish from UK waters than the British fleet does and many in the fishing community would like to see reform that addresses what they see as an injustice. The problem is that most fish are not scallops, which rarely move, but instead undergo annual migrations across international boundaries. Therefore preventing fishing in one area may not necessarily reduce access to stocks.  In the absence of robust international agreements that manage stocks rather than areas, and respect the fact that fish do not care about human boundaries, the North Sea could become the new Mediterranean, where poor regulation and disagreement between EU and non-EU states has resulted in a steady decline in stocks. On top of the regular movements of fish, the North Sea fisheries will be challenged by climate change induced movement of fish out of UK waters (something that is already evident with mackerel). In the face of Brexit we should be aiming to improve international relations, not damage them. Otherwise fish stocks and the wider marine environment are likely to suffer most – at which point everyone loses."
"
Share this...FacebookTwitterOver the course of a 12 hour period on a cloudless day, 500 Wm-2 of solar energy pummels past the ocean surface to depths of 20 or more meters, warming up the first 2 meters of the ocean by 2.0 K.

Image Source: Fairall et al., 1996
In contrast, the infrared radiation absorbed and re-emitted in all directions by CO2 molecules cannot penetrate past the ocean’s 0.1 to 1 mm “thick” skin layer.

Image Source: Skeptical Science blog
Clouds and Ocean Domination
How much solar radiation is absorbed by the Earth system’s heat reservoir – the oceans, where 93% of the globe’s heat energy resides – is significantly determined by changes in decadal-scale cloud cover.
Direct short wave and long wave (i.e., “greenhouse effect”) forcing from the reduction or increase in cloud cover dominates as the modulator of Earth’s energy budget changes.
CO2’s influence is minimal and easily overwhelmed in these processes, as “the greenhouse effect of clouds may be larger than that resulting from a hundredfold increase in the CO2 concentration of the atmosphere.”


Image Source: Ramanathan et al., 1989, Wielicki et al., 2002
Satellite observations of decadal-scale cloud cover changes indicate that between the 1980s and 2000s about 3 to 6-7 Wm-2 of direct short wave forcing was additionally absorbed by the Earth’s oceans.  This may account for the warming trend in recent decades.

Image Source(s): Ogurtsov et al., 2012 , Pinker et al., 2005, Goode and Palle, 2007
CO2’s Honey Bee-Sized Contribution
According to a widely cited analysis of the CO2 radiative contribution to the Earth’s greenhouse effect, there was a 0.2 Wm-2 per decade forcing associated with a CO2 change of 22 ppm during 2000 to 2010.
The seasonal mean range for DWLWR (downwelling long wave radiation) reaches amplitudes of ~30 Wm-2 over the course of months.  This range is more than a 100 times larger than the entire DWLWR CO2 forcing contribution over 11 years.

Image Source: Feldman et al., 2015, Okulaer, 2015
CO2 concentration changes are registered in parts per million (ppm, 0.000001).  This means that for the 100 ppm rise in CO2 from the last glacial period to the warm interglacial we enjoy now (from ~180 ppm to ~280 ppm), the gaseous representation of CO2 in the atmosphere rose from <2 parts in 10,000 parts to <3 parts in 10,000 parts.
Since it took about 5,000 years for CO2 to rise by 1 part in 10,000 parts, this is the forcing equivalent of 0.006 Wm-2 per decade using the calculations of Dr. James Hansen (and the IPCC).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




A CO2 forcing of 0.006 Wm-2 per decade is “about a third of the energy required to power a honey bee in flight.”
Image Source: Hansen et al., 2012 and  Ellis and Palmer, 2016
Uncertainty, Errors 10-100 Times Larger Than CO2 Forcing
According to the Intergovernmental Panel on Climate Change (IPCC), uncertainty in the factors influencing the ocean heat flux reach amplitudes of 20 Wm-2.  This uncertainty is more than 10 times larger than the entire forcing contribution from CO2 since 1900 (<2 Wm-2).
“Unfortunately, the total surface heat and water fluxes … are not well observed. The uncertainty in the observational estimate is large – of the order of tens of watts per square metre for the heat flux, even in the zonal mean.” – IPCC AR4 (2007)

Image Source: IPCC AR5 (2013)
The IPCC also identifies error ranges for long wave (LW) forcing that range between 5-15 Wm-2.

Image Source: IPCC AR4 (2007)
The Earth’s energy budget is assumed to be imbalanced, as more energy is said to be absorbed by the system than leaving it.
During 2000-2010, Earth’s energy imbalance was believed to be 0.6 Wm-2. The uncertainty range for this value was ±17 Wm-2, meaning the energy imbalance could have ranged anywhere from -16.4 Wm-2 to +17.6 Wm-2, which is more than ten times larger than “the changes to the net surface fluxes associated with increasing greenhouse gases in the atmosphere.”

Image Source: Stephens et al., 2012
The ARGO data measuring ocean heat content launched in the early 2000s, but the coverage still leaves much of the non-uniformly warming and cooling regions of the ocean unsampled.  Sampling errors can range anywhere from 10 to 200 Wm-2.

Image Source: Hadfield et al., 2007
Renowned Climate Scientists Ask A Never-Answered Question
In late 2013, five American Physical Sociey (APS) climate scientists published a framing document designed to re-examine the physical basis for the IPCC’s “consensus” position(s) on climate change.
Using the IPCC’s acknowledgement of ocean data uncertainty and low confidence that an anthropogenic signal can be detected amid the noise of natural variability, a cogent question was posed pertaining to the claims of certainty that humans exert fundamental control over the the climate of the Earth system.
The question has never been answered.

Image Source: American Physical Society
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWorld leading sea level expert Prof. em. Nils Axel Mörner presents some stark examples that show how the IPCC and climate activists are wildly exaggerating their claims of rapid sea level rise.
================================================
12th IKEK: Nils Axel Mörner – the Kattegat and others among test areas for sea level
Prof. em. Nils Axel Mörner auf der 12. IKEK München, Bild EIKE
By EIKE
Mörner studied the Kattegat Sea between Denmark and Sweden. In this region sea level has not increased as announced by climate alarmists, but instead decreased. The actual oceanic increase in the past 125 years can be estimated as modest at 0.9 mm per year.   
Stockholm’s tide record is the second longest in Europe; the mean long-term change in sea level is a decline of 3.8 mm per year. The country itself is rising 4.9 mm per year due to the post-glacial rise of the continental landmass. The difference of 1.1 mm per year is the true oceanic component.
Nova Scotia: sea level 700mm higher back in 16th century
In addition to European locations, Mörner also looks at the Indian Ocean and the Pacific. He has just returned from the Ouvéa area off Nova Scotia. In the 17th century, the sea level was 70 cm higher, as confirmed by immutable geomorphological facts. 
At that time, the “Little Ice Age” with larger glaciers prevailed in the Alps (as Professor Patzelt showed). How could more liquid water be present at the equatorial area at the same time?
 

Video of the lecture (in English!)  by Prof. em. Axel Mörner at the 12th IKEK in Munich. 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The phenomenon thus proves that the IPCC is wrong. 
In warm times, the sea level does not rise globally. The reason for this is the so-called rotational eustasy of the planet: In the north, the volume of water increases a bit, at the equator it remains about the same. 
Sea level at Fiji Islands, Maldives, Goa has dropped since 1950s
Also other islands or coastal regions show a sea level change, such as the island Ouvéa, also the Fiji Islands, the Maldives and Goa in India. Here, too, the oceans sank around 1700, rose around 1800 and sank again after 1950.  
Solar driven
Global sea level changes followed the moon’s tidal super cycles, which in turn stem from the large solar cycles. The sun also affects the Gulf Stream in the North Atlantic, which brings warmth to Western and Northern Europe. At maximum solar activity, the Gulf Stream flows northeast and sea level rises. During a solar minimum, the Gulf Stream flows from east to southeast and sea level drops to the north.
“CO2 no factor”
Mörner emphasized that the solar cycles and gravity of our neighboring planets, the solar wind and the moon, determined our climate and our environment. The carbon dioxide greenhouse effect has no place. 
IPCC climate science in part “anti-scientific nonsense”
With his presentation in Munich, the speaker wanted to send a message to the world climate conference COP24 in Katowice / Poland, which took place shortly after the EIKE conference. That message is: “Some of their statements fall into the area of ​​anti-scientific nonsense. The polar ice does not melt so quickly and the sea level does not rise in a short time. ” 
Mörner recommends observing physical laws and the evidence from nature for the procedure of determining sea level.
Share this...FacebookTwitter "
"Harvard law students have disrupted a recruiting event for Paul Weiss, the law firm representing ExxonMobil in climate lawsuits, in an escalation the protesters hope will open a new front in climate activism in the legal world.  The oil giant is facing a series of lawsuits in the US related to claims that it knew petroleum products were heating the planet and sought to persuade the public otherwise. The students say Paul Weiss has cultivated a reputation as a liberal corporate law firm, despite representing oil companies, tobacco and big banks. Ted Wells Jr, a partner at the New York firm, is a prominent Democratic donor. During a reception at an upscale restaurant in Cambridge, Massachusetts, a group of students unfurled a banner reading “#DropExxon” and began chanting over a speaker from the firm that they wouldn’t work for Paul Weiss as long as the firm worked for Exxon. They live-streamed the event. The protest follows another demonstration at the Harvard-Yale football game in November, when students from both universities swarmed the field at half-time. The protesters say they want to bring accountability to the legal world, where attorneys traditionally have been expected to accept that all entities deserve representation regardless of their deeds. The action is especially jarring because the field’s culture dictates professionalism. Organizer Aaron Regunberg said the protest action will be a shock to the Harvard Law School community, where students are taught that their job requires them to remain neutral about the actions of clients. “But if you don’t start these conversations – if you don’t start forcing people to reckon with the reality of what the work that Paul Weiss is doing for Exxon, for example, means – then there’s never going to be any change,” Regunberg said. “And it’s clear from the science that we have just a few years left to address climate change.” Asked how he would explain his participation to future employers, Regunberg said: “I went to law school because I believe in the power of our legal system to be a force for good, and using aggressive tactics to enable corporate polluters to literally continue lighting our future on fire to me is the antithesis of what lawyers should do.” Paul Weiss successfully defended Exxon against a lawsuit from New York’s attorney general alleging the company misled investors about climate regulation risks. The publication Law.com named the firm’s lawyers “litigators of the week”, for delivering a “cool win” for Exxon in the $1.6bn suit. The firm has also initiated suits against the state government officials bringing cases against Exxon, accusing the top lawyers in Massachusetts and New York of an alleged illegal conspiracy. One judge dismissed those allegations, writing that the relief Exxon sought was an “extraordinary” attempt to “to stop state officials from conducting duly-authorized investigations into potential fraud”, based on “extremely thin allegations and speculative inferences” that are altogether “implausible”. The Guardian has contacted Paul Weiss for comment."
"
Share this...FacebookTwitterRecord cold temperatures, transportation disrupted, fire extinguishers freeze as “coldest air mass ever” sweeps over Japan’s northern island of Hokkaido.
By Kirye

 
 
 
 
As the Asahi Shimbun here reports, Japan’s northernmost main island of Hokkaido has been gripped by a deep freeze with the temperature plunging to -31.8°C in Rikubetsu on February 9.

Chart: Japan Meteorology Agency (JMA)
Three other observation stations in Hokkaido “also reported temperatures below minus 30 degrees,” the Japanese online daily reports.
10 stations set new record lows
In total yesterday, February 9, in Hokkaido Prefecture, 10 stations saw their temperatures reach record lows:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Image from the Japan Meteorology Agency (JMA)
Although some media outlets are claiming the record cold is due to a phenomenon that is often implied as being new and caused by global warming, it is in reality what people simply used to call a plain old ‘cold wave’.
The NOAA reports here that the “polar vortex” is in fact nothing new at all, and that the term had been used already 166 years ago, back in 1853!
Global warming causing “coldest ever” air masses?
The Japan Times here reported that it was “the coldest air mass ever recorded” to hit Hokkaido”.
How can global warming be causing record cold air masses? Air masses are supposed to be getting warmer, and not colder. Climate scientists are desperately scrambling to explain the inconvenient cold events.
Referring to the Japan Meteorology Agency (JMA), The Japan Times have written: “The agency said a cold air mass with a temperature of minus 24.4, the lowest seen since it began compiling such data in 1957, was hovering about 1,500 meters above Sapporo, which saw the mercury drop to minus 12.5 in the morning.”
Frozen fire extinguishers at nuclear power plant!
The cold is so severe that it even froze a fire extinguisher system at a nuclear power plant in Hokkaido, “due to a record cold weather,” reported the NHK World here.
Meanwhile further south in Tokyo, snow fell yesterday. The forecast is calling for cold conditions to grip Japan in the days ahead.
============================================
Pierre contributed to this article.
Share this...FacebookTwitter "
nan
nan
"
Share this...FacebookTwitterpetunjuk bandarq ialah salah satu tipe permainan judi yg paling tidak sedikit disukai oleh beberapa orang baik dari seluruhnya kalangan belia & pula dewasa. Permainan Judi bandarq ini tidak sedikit memberikan kemenangan sampai bonus jackpot yg lebih akbar dari dana yg kita mainkan. Ini yg jadi argumen penting mengapa permainan Judi bandarkiu tidak sedikit dinikmati oleh seluruh pemain termasuk juga anak-anak remaja sampai orang dewasa. & yg paling menarik dari permainan ini ialah seluruhnya pemain dapat mendapati peluang yg sama mendapati bonus jackpot bila mereka memperoleh kombinasi card special di tiap-tiap putaran. Nah di artikel ini kita dapat sedikit memaparkan menyangkut pedoman main-main bandarq & mendalami jens-jenis card poker di dalamnya. Sebenarnya telah tidak sedikit berita yg serupa seperti ini tapi belum tidak sedikit kabar yg diberikan dengan cara detil pembahasannya. Berikut ini yaitu tata cara utk main-main judi bandarq di yg mudah.
a. Mengenal Permainan bandarkiu
Dalam main-main Judi bandarq sendiri ada beberapa aspek yg mesti kamu kuasai dgn baik biar dapat memperoleh kemenangan bersama langsung & bertahap. perdana yg kamu kuasai ialah jalanya permainan itu sendiri, jangan sampai mengharapkan kamu mampu mendapati kemenangan bila tak mampu menguasai jalannya permainan Judi bandarq tersebut. kamu mesti memang sanggup masuk & tak boleh terhanyut dalam permainan judi poker online. Kendalikan diri kamu & temukan kemenangan. Berikutnya merupakan insting & kecerdasaan kamu, tak tidak sedikit pemain yg mempunyai insting keren terkait bersama card yg ada di tangan mereka, lebih tidak sedikit pemain yg membelanjakan atau ikut taruhan tidak dengan memikirkan analisa card mereka. Itulah yg menjadikan system permainan judi poker susah di tebak walau kamu satu orang pemain profesional sekalipun. Intinnya disini jangan sampai enteng terkecoh atau terpancing lawan main-main buat raise atau all in dalam jumlah agung. konsisten kepada pendirian kamu sendiri & pastikan kemenangan ada dipihak kamu waktu ini juga
.
b. mulai sejak dgn step Awal Bergabung
disaat kamu memutuskan utk bergabung dgn agen judi bandarq, maka elemen mula-mula yg mesti kamu jalankan yakni dgn mengahdiri website judi qiu qiu 99 apalagi dulu. mari kamu laksanakan pendaftaran disana dgn isikan form pendaftaran dengan cara kumplit & valid. janganlah hingga kamu salah isi sebab bakal menghambat proses transaksi kamu sendiri. Pastikan nomer rekening, bank & nama rekening serasi dgn milik kamu pribadi.
c. sejak mulai bersama step Deposit Perdana
Langkah berikutnya sesudah kamu telah sukses menciptakan akun judi bandarq, dilanjutkan bersama melaksanakan deposit pertama kamu serasi bersama biaya yg kamu punya. tiap-tiap member mempunyai wewenang utk lakukan transfer dana dalam jumlah tertentu cocok bersama ketetapan yg diberlakukan di dalam website poker online. Disana kamu mampu menyaksikan ada deposit minimal yg artinya kamu cuma mampu deposit tepat bersama jumlah minimal yg disediakan contohnya saja Rupiah. 15.000, di bawah rupiah. 15.000 deposit kamu tak dapat diproses oleh system & seterusnya ada pula tarik dana maksimal yg sanggup kamu proses paling tak mesti lebih dari 15 ribu. kamu dapat menarik dana segede 30 juta apabila agen judi poker sediakan kebijakan tersebut.
Terimakasih.
Share this...FacebookTwitter "
nan
"We write as scientists alarmed that a minister has ignored scientific evidence, relying instead on grossly misleading social media sources. In the House of Commons on 9 January, Foreign and Commonwealth Office minister Heather Wheeler answered a question about the Australian bushfires by stating: “Very regrettably, it is widely reported on social media that 75% of the fires were started by arsonists.” The claim that arson is a primary cause of this season’s bushfires has been comprehensively debunked: fire officers report that the majority of blazes were started by dry lightning storms. Nevertheless, social media is awash with false claims about the role of arson, obscuring the link between climate change and bushfires (Disinformation and lies are spreading faster than Australia’s bushfires, 11 January).  However fires start, they burn more severely because Australia is suffering extreme conditions which are directly linked to anthropogenic climate change: 2019 was the country’s hottest and driest year ever, with the temperature 1.5C above the long-term average. The Australian government was advised in 2008 that the effects of climate change on the fire seasons “should be directly observable by 2020”. We ask that ministers rely on expert advice rather than social media. Beyond the present situation in Australia, it is important to acknowledge the role of climate change in many other circumstances worldwide, including in the UK. As host of this year’s UN climate talks, the UK government is responsible for keeping the Paris agreement on track. It must tell the truth to parliamentarians, the public and Australian politicians about the causes and consequences of climate change.Dr Stuart Capstick Cardiff University, Prof Colin Davis University of Bristol, Dr James Dyke University of Exeter, Prof Stephan Lewandowsky University of Bristol, Prof Richard Pancost University of Bristol, Prof Julia Steinberger University of Leeds • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"More than half of the world’s killer whales are threatened by a group of toxic industrial chemicals that accumulate in their blubber and can be passed on from mother to calf. That’s according to a new study led by scientists in Denmark and published in the journal Science. Killer whale populations found in the most polluted seas around Japan, Brazil, the UK or in the northeast Pacific, the authors report, are “tending toward complete collapse”. Polychlorinated biphenyls (PCBs) are a ghost from the past. These chemicals were produced in immense quantities from the 1930s onwards and were broadly phased out in the 1970s/1980s as environmental concerns grew.  As they were very stable and were unable to conduct an electrical current (and therefore excellent insulators), they were mainly used in the electrical supply industry. These same properties also saw them being used in a whole array of miscellaneous applications including as sealants and additives in construction. It is this chemical stability that means PCBs stubbornly refuse to degrade in the environment and I have spent the past 25 years studying how these and other contaminants end up accumulating in the Arctic, for instance. However, there are two other properties that make these particular chemicals uniquely problematic, unlike, say, common air pollutants or most heavy metals.  The first is that PCBs are semi-volatile, which means that over time they can evaporate into the atmosphere but then later deposit on surfaces when encountering cooler temperatures or with rainfall or attached to particles. Over decades this continued evaporation and deposition (termed “cycling”) has ensured that they’re smeared around the entire planet. PCBs are just as likely to be found deep in the ocean or in Arctic snow as they are in neighbourhood soils, although the concentrations in soil close to “primary sources” such as cities may be orders of magnitude higher. The second problem is that PCBs tend to work their way up the food web, accumulating in ever higher concentrations as tiny animals (and their unwanted chemicals) are eaten by small animals, who are eaten by larger animals (who take on those same chemicals), and so on. This process of “biomagnification” is most evident in marine food webs where fatty tissue like blubber (a home for PCBs) is an important feature of animals at the top of the food web such as killer whales. So, if the chemicals were largely phased out in the early 1980s, why are they continuing to cause a problem? It’s true that background concentrations have declined over the past 20 years or so, based on measurements of PCBs in the air in animals such as seabirds and even in human breastmilk. But the trend varies from place to place and between different species, and there is evidence that climate change is disturbing the “cycling” of these chemicals, potentially slowing the rate of environmental decline. Furthermore, complex foodwebs in northern oceans, particularly around Europe and North America (where most PCBs were produced and used) are undergoing subtle alterations. Predators like sharks, large fish or killer whales are changing their diets and exploiting new prey, which in turn alters their exposure to PCBs and other contaminants. What can be done? Unfortunately, the horse has bolted as such and it would implausible to remove “background levels” of PCBs from the world’s oceans. The key objective now is to maintain surveillance of these chemicals, whether they be in air, water, soil or animals. In most developed countries, end-of-life action ensures that old industrial materials with PCBs are subject to high temperature incineration (an effective way of ensuring complete destruction). Similarly, grossly contaminated industrial sites or dumps are subject to expensive clean-up and incineration activities.  But, while this is effective and safe at a local level, such measures will account for only a very small fraction of the total PCB inventory, most of which is out in the wild. International efforts by organisations like the UN Environment Programme (UNEP) are ensuring that member states are undertaking “stocktaking” activities, containing old storage or dump sites, and undertaking monitoring programmes. This is particularly important across parts of Asia and key states of the former Soviet Union, where PCB production and use was also high. The legacy of PCBs will continue to haunt us for some while to come. Scientists estimate that the final resting place or “sink” for PCBs is likely to be organic rich soils across the Northern Hemisphere or even ocean sediments. However, in the meantime, PCBs continue to cycle around the environment and are still present in mother’s milk. Maternal transfer from adult female to calf is the key exposure route for most marine mammals and this chemical stress (supplemented by an array of chemical pollutants other than PCBs), alongside climate change induced stress, is a major concern."
"The price of beer could double under unchecked climate change, as droughts and extreme temperatures cause barley yields to drop. That’s one conclusion of research we recently published in Nature Plants. We first became curious about barley, and the beer it produces, as this relatively minor crop was clearly affected by climate extremes yet had never caught the attention of climate scientists. And, unlike many other food crops, barley grown for beer is required to meet very specific quality parameters. Malted barley gives beer much of its flavour, yet if it is too hot or there isn’t enough water during critical growing stages, the malt cannot be extracted. This is why we gathered a team of scientists based in China, the UK and the US to assess what extreme drought and heat events may mean for beer supplies and prices. We were interested specifically in what would happen to barley when there was both extreme drought and heat during the growing season, something that will become more common thanks to global warming. We then modelled what this would mean for barley yields in 34 world regions which either produce or drink a lot of beer.  In more optimistic scenarios, where emissions are brought under control and warming is kept at a manageable level (what climate scientists refer to as RCP2.6), droughts and heatwaves might occur together in about 4% of the years. In the worst case scenario, where emissions and temperatures keep increasing, such extremes might occur in 31% of the years. These are global average results, however, which can hide significant regional variation. In affected years, barley yields would drop the most in tropical areas of Central and South America, and in Central Africa, for instance. In the same years, yields in temperate Europe would decrease moderately, or even increase in parts of the US or Russia. But the overall trend is clear: at a global level, barley yields will at best – under the optimistic scenario – decrease by 3%. And in the worst case scenario, yields will fall 17%. We know that climate change will mean less barley – but what about beer? One factor to consider is that barley is mostly used to feed livestock, and beer is ultimately more dispensable than meat. This means declining yields will hit beer production extra hard. Ultimately, our modelling suggests that during the most severe climate events, the price of beer would double and global consumption would decline by 16%, or 29 billion litres. That is roughly equal to the total annual beer consumption of the US. Even under the optimistic scenario of less extreme climate change, beer consumption would still drop by 4%. Again, price and consumption changes would vary widely from country to country, with the greatest price increases being concentrated in relatively affluent and historically beer-loving countries. In Ireland, for example, the price of a beer bottle would double under extreme climate change. In less wealthy countries, people would simply drink less beer under those circumstances. We predict a 32% drop in Argentina, for example. It is possible that more drought- or heat-tolerant barley cultivars may be developed in future, which would reduce the risk of climate change to supplies of beer. But these and other technological developments, or increases in stockpiling (or even prioritising beer over livestock), were beyond the scope of our study. While previous research has looked in detail at what climate change means for essentials like wheat or rice, less attention has been paid to so-called “luxury goods”. In our study, we took beer as one such example, to highlight the ways climate change will affect our lives.  We hope our results might attract further attention from various beer-lovers who actually have the power to do something about global warming. Seeing that climate change is affecting our lives in more ways than we imagined before, they might start to think about further strengthening global efforts to reduce emissions."
"
Share this...FacebookTwitterGulfstream “barely impacted” by Arctic ice melt
By Die kalte Sonne
(German text translated/edited by P Gosselin)

Arctic ice melt barely impacting AMOC. Day After Tomorrow scenario remains fantasy, new study suggests. Figure: R. Curry, http://editors.eol.org/eoearth/wiki/File:OCP07_Fig-6.jpg; CC BY 3.0
Stefan Rahmstorf never tires of claiming the Gulf Stream system (AMOC, Atlantic Meridional Overturning Circulation) is being strongly weakened by the fresh water input of the melting Greenland ice. In his Klimalounge blog at the end of January 2019 he wrote:
 ”The physics behind how global warming and ice melt (both without a doubt caused by man) is slowing down the AMOC is understood …”
Yet, on April 26, 2019, Dukhovskoy et al published a new paper in the JGR Oceans, which concludes that Greenland’s meltwater is having little impact on the AMOC:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Role of Greenland Freshwater Anomaly in the Recent Freshening of the Subpolar North Atlantic 
The cumulative Greenland freshwater flux anomaly has exceeded 5000 km3 since the 1990s. The volume of this surplus fresh water is expected to cause substantial freshening in the North Atlantic. Analysis of hydrographic observations in the subpolar seas reveal freshening signals in the 2010s. The sources of this freshening are yet to be determined. In this study, the relationship between the surplus Greenland freshwater flux and this freshening is tested by analyzing the propagation of the Greenland freshwater anomaly and its impact on salinity in the subpolar North Atlantic based on observational data and numerical experiments with and without the Greenland runoff. A passive tracer is continuously released during the simulations at freshwater sources along the coast of Greenland to track the Greenland freshwater anomaly. Tracer budget analysis shows that 44% of the volume of the Greenland freshwater anomaly is retained in the subpolar North Atlantic by the end of the simulation. This volume is sufficient to cause strong freshening in the subpolar seas if it stays in the upper 50–100 m. However, in the model the anomaly is mixed down to several hundred meters of the water column resulting in smaller magnitudes of freshening compared to the observations. Therefore, the simulations suggest that the accelerated Greenland melting would not be sufficient to cause the observed freshening in the subpolar seas and other sources of fresh water have contributed to the freshening. Impacts on salinity in the subpolar seas of the freshwater transport through Fram Strait and precipitation are discussed.”
In the main text, it is stated:
“This result agrees with the previous study of Saenko et al. (2017), who also show that the GFWA of similar magnitude (and even double of this magnitude) has negligibly small impact on the SPNA thermohaline fields, barely impacting AMOC.”
GFWA means the meltwater anomaly from Greenland and SPNA of subpolar North Atlantic. A study from 2017 finds something similar, which of course does not get mentioned by Rahmstorf in January, 2019. The fresh water from Greenland is mixed down to depths of 1000 m and thus the amount is practically meaningless for the AMOC, the paper finds.
What now?
For years we have been hearing from certain circles of climate research that we are melting the Greenland ice sheet and thus a “Day After Tomorrow” scenario gets conjured up. But a very recent paper finds that this is not the case. And when we report on it, are we thereby questioning the “credibility of climate science”, or are we correctly reflecting the progress made in climate research because the work is getting cited? Climate alarmists are desperately trying to convey the wrong image of a monolithic “climate science”, which in reality does not exist at all.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Jena-Germany based climate science and renewable energies- critical European Institute For Climate and Energy (EIKE) has sent a cease and desist letter to Wikimedia headquarters in San Francisco demanding that the platform remove all the “false content” in the German language entry about the organization.

Slander: Wikipedia’s German site describes EIKE as an organization for “networking and public relations work for the organized climate denier scene”. Image cropped from Wikipedia here.
EIKE is a non-profit association with the statutory purpose of promoting science and research in the field of climate and energy. According to EIKE, “We pursue our statutory association purpose independently of political parties, religious communities, other associations or organizations.”
EIKE claims the German Wikipedia entry about its activities and members has very little to do with the reality and that the content was in large part written to mislead readers rather than inform them and to slander the institute. “The content of the Wikipedia entry is filled with falsehoods which results in casting EIKE in an extremely negative light,” the Jena-Germany based scientific think tank commented by e-mail.
“Almost every single claim made by the Wikipedia entry about EIKE is either maliciously misleading, grossly distorted or just outright false, wrote EIKE Vice President, Michael Limburg in an e-mail.  “The Wikipedia entry was designed to produce a contemptuous image of the organization with the aim discrediting it.” The list of deletions demanded by EIKE is 7-pages long!
“Climate denier scene”
In one example, the Wikipedia entry claims that the EIKE “is described by independent voices from science and media as the center of the politically active and organized scene of climate deniers in Germany” (see image above) and that “its goal is to promote systematic attacks on climate science’s findings.”
“This is absolutely false and malicious,” EIKE responded by e-mail when asked for comment.
In the long grievance to Wikipedia, the attorney representing EIKE wrote that the claim made by the Internet platform’s authors was “made up”, “untrue and unlawful”, adding: “My client does not deny climate change, and their goal is not to systematically attack the findings of climate science.”
Among the many other alleged false statements made at the Wikipedia site was also that EIKE “pretends to be scientific, deliberately disseminates misinformation and tries to influence parties.” In the cease and desist letter, the attorney representing EIKE called that statement “false” and “unlawful”, adding that EIKE is independent of all political parties and that EIKE “conducts its own research on climate and energy and publishes it in scientific journals and at international scientific congresses.”
Renowned speakers at EIKE conferences


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Over the years, EIKE has organized around a dozen international climate and energy conferences, which often feature many renowned, yet dissenting scientists, such as astrophysicists Prof. Nir Shaviv of the University of Jerusalem and Prof. Henrik Svensmark of the Danish National Space Institute (DTU Space) in Copenhagen. Other speakers have included leading oceanographer Prof. Nils-Axel Mörner.
EIKE also notes that the conferences are open to any scientists, and that it is not solely a place where “climate deniers” meet.
Unlawful Holocaust slandering
Under the Wikipedia entry subheading “Grundsätze des Vereins” (principles of the association) it states that EIKE is “an organization of climate deniers” – a claim that is not only false but also “unlawful”, the EIKE attorney wrote. Climate alarmists routinely use the “denier” term in order to slander and equate global warming skeptics to Holocaust deniers.
Big Oil/coal conspiracy
In the Wikipedia entry about EIKE, it is repeatedly suggested EIKE is funded by the oil and coal industry and the Koch Brothers through its links to CFACT, Heartland Institute, and other organizations.
The attorney representing EIKE underscored: “EIKE a scientific institute and think-tank, organized as a non-profit organization, with the sole purpose of presenting facts concerning climate and energy without any ideology. Yet, it is suggested that my client financially represents the interests of the oil and coal industry, which is demonstrably not true.”
In total, EIKE sent a list 7 pages long of false statements and misleading claims to Wikipedia demanding that they be removed.
Intent to unjustly inflict damage to reputation
EIKE has been working for sometime to get the needed corrections implemented at the Wikipedia site, but without success. Officials at EIKE say the falsehoods and deceptive claims platformed by Wikipedia risks inflicting great damage to their reputation and the overall perception among the unknowing public.
EIKE officials recently sent a cease and desist letter to Wikimedia head offices in San Francisco. But according to EIKE, they received a response from Wikimedia that said there were no German speakers there, and so they couldn’t help.
Wikipedia is a worldwide platform whose content is regularly posted in almost every major language worldwide. Over the years it has been sharply accused of poor quality control and political bias, especially concerning hot-button political issues such as climate science.
Share this...FacebookTwitter "
"Sadiq Khan will promise to put London on a par with Scandinavian capitals by making it a carbon-neutral city by 2030 if he is re-elected as mayor of the capital later this year. The Labour politician’s pledge to tackle air pollution forms part of his first major pitch to voters in the upcoming mayoral race, in which he will go up against Conservative, Lib Dem, Green and independent rivals.  Khan’s strategy to go carbon-neutral forms part of his vision for a “green new deal” for London, which he would roll out during a second term. This will involve a 10-point plan that will be outlined in his manifesto before the mayoral election on 7 May. In a speech to the Fabian Society new year conference in central London on Saturday, he is expected to say the 2030 target is essential to prevent the poorest communities being affected by poor air and the thousands of premature deaths in the capital each year. “My pledge to deliver a green new deal for the city with a target for London to be carbon-neutral by 2030 will help tackle the climate emergency and the air pollution crisis. “Some may say that a 2030 target isn’t achievable but I say we can’t afford not to try. This is a matter of social justice because it’s the poorest communities that are being hit hardest,” said Khan, who became the first Muslim mayor of any western capital city when he was elected in 2016. The majority of the biggest political parties in the UK have set ambitions for the country to reach net-zero emissions by particular dates that range from the 2030s through to the 2050s. Despite Labour activists passing a commitment at their autumn party conference to work towards net-zero carbon emissions by 2030, the party ended up softening its pledge for last month’s election after pressure from trade unions and the impact it would have on industrial jobs. Instead they offered to find a “path” to the date of 2030. The Conservatives have a policy of hitting net-zero by 2050 and the Liberal Democrats pledged a date of 2045. The Green party has pledged to go carbon-neutral by 2030. Across Europe, three Nordic cities – Copenhagen, Oslo and Stockholm – have made firm commitments to be carbon-neutral or fossil fuel-free between 2025 and 2030. Bristol has a net-zero target of 2030, as does Edinburgh, but with a backstop date of 2037. Khan has said green commitments will be a dividing line between his campaign and his nearest rival, Conservative Shaun Bailey, who is behind him in the polls. A survey by Queen Mary University of London’s Mile End Institute found Khan was the first preference candidate of 43% of Londoners. Bailey is on 23%. “The election on 7 May is a two-horse race between me and the Tory candidate,” Khan told the Guardian. To achieve a carbon-neutral status for London, he said City Hall would lead the way in implementing tougher environmental standards, moving away from fossil fuels and reducing waste. Public transport will become greener, he said, and he will commit to trying to get billions of pounds worth of government investment. One example to help reduce emissions is retro-fitting houses to make them more energy-efficient."
"The Guardian and Observer 2019 charity appeal has raised more than £1m for its climate emergency campaign in support of projects which aim to plant and protect trees, woodlands and rainforest. More than 13,000 readers donated an average of £75 each to the appeal, which totalled £1,015,000 on Thursday night. The money will be shared between four charities: Woodland Trust, Trees for Life, Trees for Cities and Global Greengrants Fund UK.  The donations will be spent on initiatives promoting social and climate justice through natural climate solutions, from safeguarding rainforests in the Amazon basin to rewilding the Scottish Highlands and greening Britain’s towns, cities and countryside. Katharine Viner, the editor-in-chief of the Guardian said: “It’s wonderful that our annual charity appeal has raised more than £1m for a cause that’s so clearly close to what our readers care about most. “Because of the outstanding generosity shown by Guardian and Observer readers, these inspiring charities will be able to protect and renew forests and green spaces, both across the UK and in the Amazon basin. Thank you to every single reader who donated – your generosity is so important.” Eva Rehse, executive director of Global Greengrants Fund UK, praised readers for what she called a collective act of generosity and solidarity for the planet. “It gives us hope that we can tackle the collective challenge of the climate crisis together,” she said. Steve Micklewright, the chief executive of Trees for Life, said: “A huge Highland thank you to everyone who so generously donated. Thanks to their amazing support, readers will enable Trees for Life to reconnect people with nature through volunteering days and weeks and educational opportunities.” He added: “Change needs to happen at the landscape scale but small actions, such as planting a tree, can make a world of difference.” Hundreds of readers left messages explaining why they had donated. Common themes were frustration with lack of government urgency in tackling climate change, and horror at the bushfires in Australia. Some said they had been inspired by the appeal to plant a tree in their garden. Donor Eileen Dale wrote: “I want to do my small bit to protect the environment, help the survival of species and mitigate the climate crisis for my grandchildren and all their peers around the world.” Another donor, Ruth Baber, wrote: “I [contributed] my winter fuel payment because this is such an important issue. Planting trees with Trees for Life was a transformative week for me. Trees are vital to combat the climate emergency as well as benefiting physical and mental health.” The 2019 Guardian and Observer appeal was the fifth in succession that has raised more than a million pounds. The 2018 appeal for immigration charities which helped uncover the Windrush scandal raised £1.1m. In 2017 £1.7m was raised for youth homelessness, and £2.6m and £1.6m for refugee causes in 2015 and 2016 respectively. The appeal closed at midnight last Sunday. The final total is expected to be slightly higher as a handful of stray cheques come in. The £1,015,000 figure includes estimated gift aid of £168,000. The appeal’s donation handlers, Charities Trust, will be paid a fee amounting to 3% of the gross total."
"Cardiff council is proposing to charge non-residents £2 to drive into the city centre and use the proceeds to improve the creaking public transport system in and around the Welsh capital. Council leaders and public health experts are arguing that a relatively modest congestion charge could help change perceptions of driving without overly penalising those who need to travel by car. The idea was outlined during the unveiling of a £2bn “transport vision” in Cardiff city centre on Wednesday.  Leaders said the 10-year plan would help to tackle the climate emergency, reduce congestion and improve air quality. They claimed imposing a charge on motorists could lead to the same sea change that followed the introduction of charges for single-use plastic bags. The council leader, Labour’s Huw Thomas, said: “The future success of Cardiff hinges on getting transport right in the city. There can’t be anyone who is happy with the current state of affairs, which is why we are bringing forward this ambitious 10-year vision and why we are beginning an honest conversation about how it’s paid for.” Asked if a £2 charge was enough to change behaviour, Thomas said such a charge would break habits and generate significant funding for transport changes without penalising people too much. The council said it would not introduce charges before improvements had been made to public transport, and anticipated that there would be exemptions – for blue badge holders, for example. 1.Our vision for #Cardiff is a city linked by the infrastructure needed to travel by bike, train and rapid bus transport around and across it, and on into the wider city region – it looks like this.#10ThingsAboutCardiffTransport2030🚋 🚌 🚲 pic.twitter.com/Jlyqzuwe5e Caro Wild, the council’s cabinet member for strategic planning and transport, said Stockholm had introduced a modestly priced congestion charge that had successfully changed behaviour. The Labour councillor said: “Cardiff’s current transport network was designed half a century ago for a city of 200,000 people. Today, once commuters, shoppers and visitors are taken into account, our city has a daily population of almost half a million. No wonder our transport network is creaking – it’s no longer fit for purpose. “If you look at it from the point of view of the average Cardiff resident driving within the city to work every day, struggling for their bit of road space with the 80,000 other car commuters from outside the city’s boundaries, then absolutely, traffic congestion, traffic pollution and a public transport system which struggles to adequately serve the people who live and work here are all issues of major concern. “We are living in a world where the climate emergency is changing how we feel about our future. I have become more and more convinced that to undertake the kind of radical change required we will need to investigate bringing in some form of charging mechanism to fund the infrastructure required in the city and the wider region. “One option might be a simple, universal, £2, low-charging system applied to non-Cardiff residents who drive into the city, which could reduce congestion while raising money towards paying for improvements to our transport network. We need to get people out of cars and on to public transport. To do that we need to give them the best public transport options. And to do that we need to raise money to pay for them.” Wild said a congestion charge was not the only option and other possibilities would be looked at over the next year. He said: “No charge will be put in place until that business case is completed and all options have been reviewed.” The white paper unveiled by the council lists a series of projects that could revolutionise public transport options in Cardiff and the region, including: Opening up new tram/train routes and stations. Introducing new park-and-ride sites. Lowering the cost of bus travel significantly. Delivering safer walking and cycling routes. An electric bike pilot scheme. Fiona Kinghorn, the executive director of public health for Cardiff and Vale University Health Board, said: “We fully support the ambition to increase walking and cycling in Cardiff, provide major enhancements to the public transport network and reduce harmful air pollution.”"
"
Share this...FacebookTwitterGerman flagship daily Frankfurter Allgemeine Zeitung (FAZ) publisher Holger Steltzner wrote in an online commentary that the rescue of the global climate” has turned into a religious movement for “a large portion of German society”.
In his commentary, Steltzner remarks that even questioning the hundreds of billions spent thus far with hardly any progress in CO2 reductions to show is enough to get yourself branded as a heretic.
Freedom of dissent under attack
The FAZ publisher also questions the branding skeptics of manmade global warming as “climate deniers”, thus comparing them to Holocaust-deniers. He wonders: “Is this just the thoughtless use of language that abuses the historical break with civilization of the Shoah through banalization?”
Dissent over climate science in Germany is harshly scorned and the media and science community do not tolerate it.
In his commentary Steltzner reminds that man is in fact just one component in the complex climate system where huge natural factors are at play, and that the vast majority of skeptics do not even deny the climatic changes taking place today and how they are just as concerned about the environment as anyone else is.
Communist central planning
The trained business finance specialist and FAZ publisher writes that the German Energiewende (transition to renewable energies) has led to “price distortions, threatened grid stability and the writing off of modern power plants” and is accurately characterized as “eco-central planning”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Causing more environmental harm than good
And what is even worse is that the Energiewende is likely causing more environmental harm than good. For example forests are being cleared to make way for the industrialization of the country’s once idyllic landscape, destroying biotopes with it. Stelzner adds that many Germans are filling up their cars with fuel that is 10% bio-fuel – which in turn leads to orangutans being shot dead so hat palm oil plantations can operate in places like Indonesia.
And according to Steltzer: “One fifth of Germany’s agricultural land is used for growing bio fuels.”
Another example of Germans trying to ease their conscience is the consumption of tofu in place of meat. He writes: “But weren’t there rainforests in Brazil, where today one soy plantation follows the next?”
Other examples Steltzner cites are avocado plantations in Mexico or the lithium-ion battery “which is supposed to save the climate, and whose raw material extraction in Africa, Russia or South America is devastating entire regions.”
“Illusion, religious zeal”
Steltzner also comments that it seems that environmental organizations have taken a page from the Vatican playbook, where in the past “believers could even acquire letters of indulgence for deceased people in order to wipe out sin penalties in purgatory.”
“Today the purchase of carbon dioxide certificates protects you from being plagued by a bad conscience while shopping in London,” Steltzner comments.
Though he perceives climate change as a real challenge, Steltzner summarizes by calling on Germany to “abandon the illusion that it can rescue the planet” and that “climate protection must not be driven with religious zeal”.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAccording to a new paper (Oliver and Terry, 2019) published in Palaeogeography, Palaeoclimatology, Palaeoecology, oyster remains have been found encrusted in rock 2.5 to 3.8 meters above the present mean sea level.  This fossilized evidence dates to ~6000 to years ago, a period when the Earth’s surface temperatures were 4-6°C warmer than they are today.

Image(s) Source: Oliver and Terry, 2019
The evidence provided by Oliver and Terry (2019) will be added the to growing list of more than 80 scientific papers indicating sea levels from locations throughout the world were meters higher than they are today just a few thousand years ago.
80+ Papers: Mid-Holocene Sea Levels
Were Multiple Meters Higher Than Today

Oliver and Terry, 2019
Relative sea-level highstands in Thailand since the
Mid-Holocene based on 14C rock oyster chronology
• “~6000 cal yr B.P. old oysters can be found from between 3.8 ± 0.1 m to 2.5 ± 0.1 m above present day mean sea level. … Dead (fossil) oysters were collected from between 1 and 3 m above the centre of the live oyster band in a more sheltered cleft inside the notch. The oldest sample with an age of 5270–4950 cal yr B.P. was collected at an elevation of 3.01 ± 0.1 m above the apex of the notch. The ages decrease with elevation down to 920–710 cal yr B.P. at 1.03 m.”
• “In all the sites, the 14C age of the dead oysters inside the notches increases with increasing elevation above present day MSL. Clearly, relative sea level was 2 to 3 m higher than present between 6000 and 3000 B.P. and has steadily fallen since.” 
• “There was a progressive warming from ~13,500 years ago to a peak at 6500 ± 200 years ago followed by a cooling of −2.6 °C to the present day.” 
• “Generally, there is a ~1 m wide live oyster band (with modern 14C ages) in the apex of the sea notch that corresponds to the present day MSL. 14C ages of dead oysters are systematically older higher up the sea notch and reach a maximum 14C cal yr B.P. age of 6513–6390 cal yr B.P. at an elevation of 2.5 ± 0.1 m above present day MSL in an exposed site at West Railay Beach. Consequently, relative sea levels must have been higher in the mid Holocene than they are now.”
• “[A]t a more sheltered site inside a bay on Ko Pha Nak, the highest preserved oyster shell is at 3.2 ± 0.1 m above MSL and has a younger 14C calibrated age of 5845–5605 cal yr B.P. Furthermore, oysters from 3.8 ± 0.1 m above present day MSL, encrusted on a stalactite in a cave at West Railay Beach has a 14C calibrated age of 6176–6041 cal yr B.P.”


Image(s) Source: Oliver and Terry, 2019
Share this...FacebookTwitter "
"This is an article from Curious Kids, a series for children of all ages. The Conversation is asking young people to send in questions they’d like an expert to answer. All questions are welcome: find out how to enter at the bottom.  Why do hens still lay eggs when they don’t have a mate? – Finley, age ten; Evie, age eight; and Jonah, age five, Cambridgeshire, UK Thanks for the question Finley, Evie and Jonah. Humans have been looking after chickens for thousands of years – and we have gradually learned what to do to make sure our hens keep laying eggs for us to eat.  For one thing, we have gradually changed hens through breeding, to make sure that they don’t stop laying eggs in the winter (hens used to do this naturally).  We’ve also learned that if we keep taking the eggs away from the hens, they will keep laying them, because of the way their bodies work. But for you to really understand why, I’ll have to explain a bit of biology.  In our world, creatures have many different ways of trying to have babies. But one thing is almost always the same: a special cell from a female (called the egg cell) and a special cell from the male (called a sperm cell) have to join together to make the baby.  Each of these special cells contains half of the instructions to make a new creature (the baby).  Usually, the male makes lots and lots of his special cells, all with tails to help them move. He sends lots of them into the female, in the hope that one will swim all the way to the female egg cell and join with it: this is called “fertilising the egg”.  The female makes very few of her special cells and gives them the size and covering they need to let a male sperm cell join with them to make one fertilised cell. Then, the fertilised egg can use the full set of instructions – half from the egg cell and half from the sperm cell – to start growing into a baby.  In animals like humans, the baby grows a lot inside the female before it is born.  But in birds like chickens, the egg cell is put into a huge package to feed and protect fertilised eggs while they grown into a baby. We call the whole package “the egg”. It takes about a day to wrap all the packaging around the egg cell. Most of the layers around the egg cell are soft, but the final wrapper is the hard shell. The shell takes the longest time to make (about 19 hours). The chicken has a clever way of “lending” hard material (calcium carbonate) from her bones to make the shell. She then has to replace the calcium carbonate in her bones by eating more at the next meal. The female has to be very careful about when she uses her precious eggs cells to try and make a baby. Lots of animals take one egg each month out of the store they have inside their body. Once its out of the store, the egg goes to a part of their body where a sperm could join up with it to fertilise it.  Other creatures, including many kinds of birds, choose a time to release several of their eggs to try and make a group of babies all at once (often called a “litter” for animals and a “clutch” for birds).  The size of a clutch is different for different kinds of bird: for chickens, it is around 12 eggs. In nature, when the female chicken has laid about 12 eggs, she stops releasing egg cells from her body stores. But if humans keep taking the eggs away, the female chicken will keep laying more eggs. When the female releases the egg cell from her body store, she does not know whether a male sperm cell will come and fertilise it or not. But her body still sends them out from the store, just in case there is sperm to fertilise the egg.  In order not to waste eggs, the female of many kinds of creature (ranging from insects, through garden birds to reindeer) stop releasing eggs from their body store for much of the year, to make sure the babies don’t arrive in the winter time when it is difficult to get enough food for them.  As I mentioned before, humans have gradually changed female chickens over many years so that their bodies don’t stop releasing eggs in the winter, but some traditional breeds still do go “off lay”. Hello, curious kids! Have you got a question you’d like an expert to answer? Ask an adult to send your question to us. You can: * Email your question to curiouskids@theconversation.com 

* Tell us on Twitter by tagging @ConversationUK with the hashtag #curiouskids, or

* Message us on Facebook. Please tell us your name, age and which town or city you live in. You can send an audio recording of your question too, if you want. Send as many questions as you like! We won’t be able to answer every question, but we will do our best. More Curious Kids articles, written by academic experts: What’s the history of aircraft squawk codes and how do they work? – Daniel, age 12, Perth, Australia How can chickens run around after their heads have been chopped off? – Gaelle, age four, Bristol, UK Why does English have so many different spelling rules? – Melania, age 12, Strathfield, Australia"
nan
"The electricity sector is experiencing a profound disruptive shock. This is due to technological innovation including the falling costs of renewables and energy storage, along with tougher environmental policies and regulatory reform.  These changes are most apparent in Australia, the EU and parts of North America, where once-powerful utility companies are struggling or restructuring to survive. But, as I’ve looked at in a recent report, decision-makers elsewhere are asking whether these power markets are outliers or if they herald a global shift. Global investment in renewable energy – excluding large hydropower – was just under US$279 billion in 2017, a rise of 2% on the previous year. Wind and solar account for most of this. In fact, as technology and installation becomes cheaper, non-hydro renewables accounted for 61% of all the new installed power capacity (that’s including all fossil fuel, nuclear and hydro) across the world in 2017. If we are to address climate change, such changes must continue. While the construction of wind and solar was initially stimulated by decarbonisation policy, now it is driven by economics. As renewables continue to be deployed, they become ever cheaper to build and install. Solar is already at least as cheap as coal in Germany, Australia, the US, Spain and Italy. By 2021, it is also expected to be cheaper than coal in China. Integrating all this new power may become costly. National power systems have been designed for centralised coal or gas power stations, after all, which can more easily be switched on and off to ensure supply meets demand. Things are much more challenging when renewables are involved, as the sun doesn’t always shine, and the wind doesn’t always blow. Innovations in energy storage and digital technology promise to keep these costs down, but the big traditional utilities are failing to keep pace. This has left new actors free to provide new technologies and business models. Storage is a key technological element of the new system. Fortunately, the development of electric vehicles (EV), to address climate change and localised pollution, is being seen as a key driver of change for transport and power sectors. EV sales are set to increase dramatically, stimulated by recent government targets and policy support, while the prices of lithium-ion batteries decline sharply.  A plethora of large and powerful car manufacturers are getting into electric vehicles, prompted by government sales targets and the speed at which the total cost of owning an EV is approaching that of a traditional petrol car. Honda wants two-thirds of its sales to be electric or hybrid by 2030, BMW is aiming for 15–25% by 2025, while both Volvo and Jaguar Land Rover are targeting 100% by 2020.  Many of these companies are now making use of their manufacturing capabilities and moving into selling home storage units for electricity, which aren’t too different from an electric car’s battery. These storage units mean that people with solar panels will be able to consume more of their own electricity. This is further reducing the market for traditional firms and creating new competitors as some of the world’s largest manufacturing companies enter the power sector for the first time. As in many other sectors, digitalisation is another disruptive change. Smart meters in particular mean energy firms can better monitor and understand their customers, which enables even more flexibility – imagine energy supplies tailored to individual households and times of day.  These increasingly complex electricity systems will rely on machine learning algorithms to know when and where energy will be needed. Internet giants like Google and Amazon are already piloting and exploring the opportunities. Who would bet against Amazon becoming a major power supplier in the next decade? Blockchain technology could also enable a peer to peer energy market, allowing neighbours to sell excess power to one another and potentially further reducing the role of traditional firms. Over the past few years, there have been significant changes in the power sector, resulting in declining profits and the restructuring of traditional utilities. However, looking forward, the electrification of the transport and eventually heat sectors, and increasing digitalisation is likely to lead to far more significant disruption than we have seen to date. This will bring in a whole new set of companies and potentially engage consumers like never before."
"
Share this...FacebookTwitterEarlier Arctic warmth unexplained: In Franz Josef Land it was several degrees warmer in early 1930s than today
By Die kalte Sonne
(German text translated/edited by P Gosselin)
In January 2019, a paper by Andrzej Araźny et al appeared in the journal Theoretical and Applied Climatology, in which the researchers evaluated the weather data from four scientific expeditions to the Arctic Franz Josef Land.

Chart Source: A comparison of bioclimatic conditions on Franz Josef Land (the Arctic) between the turn of the nineteenth to twentieth century and present day.
The Araźny team also came across an unusual heat that was registered during a trip in 1930/31 when it was 4.6 °C warmer than the modern average in 1981-2010. The authors explain that there have been two phases of warmth in the Arctic in the last 140 years. The first spanned from 1920-1938 and the second began in the 1980s or 90s. Both heat phases have a similar course, so that the proportion of natural versus anthropogenic climate drives is unclear.
Araźny and colleagues demand that climate models address this question more intensively in order to finally close the large gaps in understanding in the Arctic climate system – also with regard to attribution.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




What follows is the abstract of the study, whose pdf can be downloaded free of charge:

A comparison of bioclimatic conditions on Franz Josef Land (the Arctic) between the turn of the nineteenth to twentieth century and present day
The paper presents the variability of meteorological conditions: air temperature, wind speed and relative air humidity; and biometeorological indices: wind chill temperature, predicted clothing insulation and accepted level of physical activity on Franz Josef Land (in Teplitz Bay and Calm Bay) in the years 1899–1931. It employs meteorological measurements taken during four scientific expeditions to the study area. The analysis mainly covered the period October–April, for which the most complete data set is available. For that period of the year, which includes the part of the year with the Franz Josef Land’s coldest air temperatures, the range and nature of changes in meteorological and biometeorological conditions between historical periods and the modern period (1981–2010) were studied. The data analysis revealed that during the three oldest expeditions (which took place in the years 1899–1914), the biometeorological conditions in the study area were more harsh to humans than in the modern period (1981–2010) or similarly harsh. In contrast, during the 1930/1931 expedition, which represents the Early Twentieth Century Warming (ETCW), conditions were clearly more favourable (including predicted clothing insulation being 0.3 clo lower and 4.0 °C higher wind chill temperature than conditions observed nowadays).”
In the discussion the authors address in detail the Arctic warmth phenomenon of the 1930s:

In approximately the last 140 years, there have been two periods of significant temperature increases in the Arctic. The first began in around 1918–1920 and lasted until 1938 and has been called the ‘1930s warming’ (Bengtsson et al. 2004). Other works have referred to this period as the ‘Early Twentieth Century Warming’ (ETCW, Brönnimann 2009) or the ‘Early Twentieth Century Arctic Warming’ (ETCAW, Wegmann et al. 2017, 2018). Our results confirm the observations for the last expedition from the historical study period in 1930/1931. These years covered the warmest part of the ETCW (Table 3, Fig. 4). In turn, the second increased warming of the Arctic began around 1980 (Johannessen et al. 2004) or according to Przybylak (2007) in about the mid-1990s. Changes in overall atmospheric circulation have long been believed to have been the cause of the ETCW (e.g. Scherhag 1937). As the modern climate warming (since 1975) has progressed in a largely similar manner to the progression of the ETCW (Wood and Overland 2010; Semenov and Latif 2012), there has been renewed interest in the insufficiently well-explained causes of the ETCW using the latest research methods, including, primarily, climate models. An analysis of the literature shows that the cause of such a significant warming in the present period is still not clear. There is even controversy over whether the main factors in the process are natural or anthropogenic, although the decided majority of researchers assign a greater role to natural factors (Bengtsson et al. 2004; Semenov and Latif 2012). It would appear that the greatest differences of opinion on the causes of the ETCW are to be found in works presenting climate models (see, e.g. Shiogama et al. 2006; Suo et al. 2013), which is an excellent illustration of the still insufficient knowledge of the mechanisms governing the Arctic Climate System.”

In the conclusion, the authors compare the warmth of the 1930s to today’s values:
…during the 1930/31 expedition it was 4.6 °C warmer than the years 1981–2010.”
Share this...FacebookTwitter "
"It is perhaps a cruel irony that, on the same day the Intergovernmental Panel on Climate Change released a landmark call for urgent action, Jair Bolsonaro surged to victory in the first round of Brazil’s presidential elections. Although the leader of the far-right Partido Social Liberal did not achieve the 50% of the popular vote required to win outright, and will now have a run-off against Fernando Haddad of the Partido dos Trabalhadores (Workers’ Party), his rise has posed some painful and divisive questions both within Brazil and beyond. Bolsonaro has openly spoken of the need for a military coup and has a record of racist, misogynistic and homophobic views. He is often compared to Donald Trump in the US, and such parallels can also be seen in the protectionist economic doctrine Bolsonaro has adopted in this election, for instance a promise to end the banana trade with Ecuador to protect Brazilian producers. 


      Read more:
      Brazil: can its poorest region call a halt to Jair Bolsonaro's dangerous politics?


 The electoral success of this divisive figure leaves Brazil at a crucial turning point. There have already been numerous analyses of what this could mean for Brazilian politics – but what could it mean for the environment?  Despite Bolsonaro’s campaign being based on personality as much as policy, it is possible to find some relevant promises – and they aren’t good news. For a start, Bolsonaro has previously said that, if elected, he would withdraw Brazil from the 2015 Paris Agreement on climate change, arguing that global warming is nothing more than “greenhouse fables”. Ultimately, his power to reverse the decision is limited, however. This is because the Paris deal was approved via the Brazilian congress, which is currently divided between 30 parties, and Bolsonaro would face the tricky task of convincing a broad church of conservatives. Although Bolsonaro may be unable to withdraw from the Paris framework, his election would still be a direct threat to the regime of environmental protection in Brazil. Bolsonaro’s rise is a symptom of a wider political shift that has seen an alignment between the environmental views of the far right and those of powerful political factions in Brazil.  Although never directly linked, Bolsonaro’s environmental policies would likely be welcomed by the so-called “ruralistas” – a powerful alliance of agribusiness and big landowners within the country’s Senate and Chamber of Deputies. The ruralista faction previously supported the outgoing president Michel Temer and is infamous for its regressive environmental agenda, which seeks to further deforest the Amazon to make way for cattle farms, soy plantations and the mining industry. Bolsonaro has called for the neutering of both Brazil’s environment agency (IBAMA), which monitors deforestation and environmental degradation, and its Chico Mendes Institute which issues fines to negligent parties. This would eliminate any form of oversight of actions that lead to deforestation. Bolsonaro has also threatened to do away with the legislative protections afforded to environmental reserves and indigenous communities. He has previously argued that what he describes as an “indigenous land demarcation industry” must be restricted and reversed, allowing for farms and industry to encroach into previously protected lands. By removing these protective organs from the equation, the message that Bolsonaro is sending is clear: vast swathes of Brazil’s  biologically diverse and ecologically important landscape will be opened up for development and extraction. With the Brazilian soy industry profiting from the current trade war between the US and China, it is highly likely that promises of this potential expansion would be well received. In the run up to this election, figures were released which showed the rate of deforestation in the Brazilian Amazon is continuing to climb. In August 2018, 545km² of forest were cleared – three times more than the area deforested the previous August. The world’s largest rainforest is integral to climate change mitigation, so cutting back on deforestation is an urgent global issue. Brazil, however, is heading in the opposite direction. Any collective relief at the far right not winning the first round outright may be short-lived. While the previous government of Temer rolled back environmental protections, a Bolsonaro government will likely adopt a brazen anti-environmental strategy. The second round of the election is soon to take place. In light of the IPCC’s recent report, there is more riding on it than ever."
"
Share this...FacebookTwitterA potential wind turbine installation on the island of Crete may be poised to drive an endangered raptor population to extinction.
Recent studies have found the favored “renewable” energies – wind and solar – are not effective, even counteractive, when it comes to reducing emissions from fossil fuels.
Solar PV installation, for example, results in a net loss of energy, meaning that the net effect of solar energy use is ultimately more dependence on fossil fuels.

Image Source: Ferroni and Hopkirk, 2016
Due especially to its intermittent energy generation, the installation of wind turbines also necessitates eventual growth in fossil fuel energies to back them up (due especially to the frequent occasions when the wind is not blowing).

Image Source: Marques et al., 2018


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Even worse, the installation of wind turbines have been well documented to destroy wildlife habitats (Marques et al., 2019, Millon et al., 2018, Lange et al., 2018, Barré et al., 2018). Frequent soaring species collisions may ultimately lead to widespread extinctions (Naylor, 2018 , Watson et al., 2018, Vasilakis et al., 2017 ) in the coming decades.
Roughly 25% of North American bats are now classified at risk for extinction (Hammerson et al, 2017) in large part due to the explosion of wind turbines across the landscape.
If the expansion of wind turbines continues at its current pace, the hoary bat population is projected to be reduced by 90% (Frick et al., 2017) within the next 50 years.
In a new paper (Xirouchakis et al., 2019), scientists detail the austere short-term mortality risks wind turbines pose upon an endangered griffon vulture on the island of Crete.
Considering the unreliability and counteractive effectiveness of wind turbine use in mitigating fossil fuel dependency, one needs to ask why we are willing to risk the extirpation of rare raptor species for the purpose of expanding “renewable” energies that increasingly seem to do more harm than good.

Image Source: Xirouchakis et al., 2019
“[T]he environmental impact of commercial wind power production on biodiversity has proved to be substantial [3–7]. Wildlife is affected by wind power production through habitat loss, disturbance and displacement and above all by increased collision risk with wind turbines [8–10]. Bird fatalities due to collision with wind turbines have been the most prominent and frequently identified environmental drawback of wind energy development. Bird casualties from collisions can reach up to 40 deaths per turbine per year [11] with large raptors suffering the greatest toll.”
“We evaluated the consequences of wind farm development on the griffon vulture (Gyps fulvus) which was regarded as a suitable model species. Griffons are among the most collision-prone large soaring raptors and perhaps the most frequent victims of turbine blades in the Mediterranean region, i.e. up to 1.88 individuals/ turbine/ year [8]. Furthermore, assuming that the most crucial factor in minimizing the negative impact of wind farms on wildlife should be proper siting, we tried to estimate the potential collision mortality of the species by taking into account the existing and all planned wind energy projects on Crete.”
“Crete holds the last healthy population in the country (ca. 1000 individuals) which constitutes the largest indigenous insular population worldwide.”
“The model predicted that 39% of the griffon colonies which were occupied by more than 15 individuals would account for 62% of the wind farms and vulture interactions and would suffer 65% of the expected mortalities. The overall collision mortality rate was estimated at 0.03 vultures/wind turbine/year producing an annual loss ranging from 3.7% to 11% of the species population. More specifically a total of 990 individuals were estimated to be at threat of striking with turbine blades. The scenario #1 predicted a mean annual mortality of 1.49 ± 1.12 individuals (range = 0.18–4.98) per colony, whereas the overall annual fatality was anticipated at 83.5 griffons.”
Share this...FacebookTwitter "
"Britain’s first new deep coalmine in 30 years is unnecessary and incompatible with UK climate ambitions, according to a report. The £165m Woodhouse colliery in Cumbria was given cross party-backing in March 2019, leading to protests from climate campaigners who said the mine would harm the UK’s efforts to reduce CO2 emissions.  Now a report by the independent thinktank the Green Alliance has found the colliery, along the coast from Whitehaven, will hold back the development of low-carbon steelmaking. The report, authored by two university professors who specialise in environmental issues, claims that opening a new coalmine would hinder this strategy by ensuring the continued availability of cheap coal. It also refutes Cumbria county council’s claim that the mine, which aims to process 2.5m tonnes of coking coal a year for the UK and European steel industry, replacing imports from the US, Canada, Russia and Colombia, will be carbon neutral. Prof Rebecca Willis and Mike Berners-Lee from Lancaster University, say the mine would produce 8.4m tonnes of CO2 per year, equivalent to the emissions from more than 1 million households. The UK has set a target to reach net-zero carbon emissions by 2050, and has committed to switch to lower carbon steel production, announcing a clean steel fund in August 2019. But the report says the proposed mine, expected to begin production in two years, subject to environmental certificates, will jeopardise these ambitions. “The proposed mine is clearly incompatible with the UK’s climate ambitions and the need for a clean energy future. The new government has championed its commitment to climate action. It now needs to set out its policy on fossil fuel extraction, making clear that digging more coal out of the ground is no longer acceptable,” Willis said. Recommendations made in the report include using less steel, using recycled steel, improving the efficiency of steel production with conventional blast furnaces, and producing steel with new processes such as renewable energy. Dustin Benton, Green Alliance’s policy director, said: “Clean energy has already made coal obsolete in the power sector. Our previous work shows that UK demand for coking coal would halve if steel producers opted for cheaper, cleaner steel production using today’s technologies. “In addition, innovation in zero carbon steel production means this mine will likely become redundant in the near future, saddling Cumbria with an expensive stranded asset.” Councillors who backed proposals for the undersea mine said it would create vital jobs. It is expected to employ 500 people, with an estimated 2,000 more jobs created in its supply chain. But Berners-Lee, a leading expert in carbon footprinting and the brother of internet pioneer Sir Tim, said the emphasis should be on creating green jobs. “Cumbria’s politicians understandably want to see new jobs on the west coast. But we estimate that the profits from the mine would leave the local area, with only 3% of the turnover spent on salaries,” he said. “We urgently need an active, low-carbon industrial strategy for Cumbria and other local areas, to generate thousands of green jobs rather than hundreds of coal jobs.” The developer West Cumbria Mining has previously revealed that it agreed a deal for a 50MW solar farm nearby to provide about a third of the project’s energy needs, in order to mitigate some of the impact of the plant on the environment. In June, the UK became the first large economy to pass laws to end its contribution to global warming by 2050. The goal requires Britain to reduce greenhouse gas emissions to net zero by 2050, compared with the previous target of at least 80% reduction from 1990 levels. A spokesperson for the Department for Business, Energy and Industrial Strategy said: “We are well on the way to phasing coal out of our energy system by 2025 and last year Great Britain went nearly 4,000 hours without using coal for electricity. Ending our use of it will be a key milestone on our journey to end our contribution to climate change entirely. “Although coal will soon no longer be part of our energy system, there will continue to be domestic demand for coal in industries such as steel, cement and even heritage railways.”  West Cumbria Mining said it did not want to comment on the report."
"Three thousand litres of water – that is the amount needed to produce the food each British person eats every day. This is the opening line of a recent article also published on The Conversation. The piece reports on research published in Nature Sustainability, which investigated the water footprint of diets in three EU countries, considered national and regional differences, and comes to the overall conclusion that a healthy diet that is low in meat would significantly decrease our water footprint. The scientific consensus is that eating less meat is a good way of reducing your carbon footprint (a measure of carbon dioxide released into the atmosphere by a person’s activities) and contribution to climate change. According to the Water Footprint Network, the water footprint of a kilo of beef is 15,415 litres, compared to 322 litres for a kilo of vegetables. When compared to domestic water use (each person in the UK uses about 150 litres of water per day) these numbers seem large and worrying. But the reality is that the concept of footprints cannot be used for water in a way that is environmentally meaningful. The first flaw in the water footprint concept stems from the fact that water is renewable. It can exist in lakes, rivers and the sea, below ground, as vapour in the air, in glaciers, and more. We neither create nor destroy water, it simply moves around the hydrological cycle. Water that we use in the present can also be used in the future. It isn’t going to run out in any permanent sense unless it is irretrievably polluted, or becomes incorporated into a glacier which will exist for millennia to come. So, regardless of how much steak you eat, the world is not going to run out of water. The next problem with the water footprint concept is that it causes us to value water as being equally important wherever it is. But it’s fairly obvious that a thousand litres of freshwater in Wales is not of equal value to a thousand litres of water in a desert.  In addition, there is no clear relationship between the volume of water we use and the environmental impact of using that volume. So, although with carbon emissions we can reliably say that a serving of pulses contributes less to climate change than a serving of beef, we cannot be nearly so confident when comparing the environmental impacts of the water used to produce the two products. Hydrologists express these issues of time and place using diagrams and equations known as water balances. Water exists in stocks, and flows occur between them. Measuring the size of each stock and flow allows us to understand what the consequences might be of changing flow rates into/out of stocks, or diverting flows in some way, with reference to a specific time period. This helps us understand another problem with the water footprint concept. The footprint is defined as the volume withdrawn from a stock, minus the amount that is discharged back into that stock. When rain falls on grassland, much of it is taken up by plant roots, moves upwards through the stem and then evaporates from the leaves. If the grass is eaten by cattle, then the water footprint of the beef includes all this water. But if the rain was to fall on an area of forest rather than grassland, evapotranspiration (the process by which water evaporates from plant leaves and from the ground) would be higher.  Trees take up more water than grass, so trees have a large water footprint. Does this make forests bad? Clearly not. Evapotranspiration is simply a flow within the hydrological cycle, it is no better or worse in environmental terms than the rainwater that flows into streams and rivers.  However, this way of calculating water footprints also means that if a water company withdrew 1,000 litres of water for domestic water use from a river, and then discharged it back into the river after it had undergone sewage treatment, the water footprint is zero. The water has become immediately available again at local level. Evidently, water footprints lack scientific validity, and don’t actually tell us anything very useful about the environmental impact of water use – but what can we do instead? The Alliance for Water Stewardship is promoting a promising initiative that considers industry and location-specific measures, such as whether water is being abstracted from an aquifer (an underground layer of permeable rock that holds water) at an unsustainable rate, whether irrigation schemes are necessary and properly controlled, and how to balance the needs of all water users in the area. However, these schemes are not yet widely adopted, and it remains difficult for consumers to make water conscious choices. There is also a risk of worrying about water at the expense of other environmental issues. The effects of climate change are felt most immediately through water-related events such as droughts and floods, but we would do well to remember that these events are symptoms and it is the cause that we need to address."
"A year of extreme weather events and mounting evidence of global heating have catapulted the climate emergency to the top of the list of issues worrying the world’s elite. The World Economic Forum’s annual risks report found that, for the first time in its 15-year history, the environment filled the top five places in the list of concerns likely to have a major impact over the next decade.  Børge Brende, the president of the World Economic Forum, said: “The political landscape is polarised, sea levels are rising and climate fires are burning. This is the year when world leaders must work with all sectors of society to repair and reinvigorate our systems of cooperation, not just for short-term benefit but for tackling our deep-rooted risks.” After a month in which bushfires have raged out of control in Australia, Brende said there was a need for urgent action. “We have only a very small window and if we don’t use that window in the next 10 years we will be moving around the deckchairs on the Titanic.” The WEF report said the retreat from the multilateral approach that helped cope with the 2008 financial crisis made it more difficult to tackle shared global risks. It said the top five risks in terms of likelihood in the next 10 years were: Extreme weather events with major damage to property, infrastructure and loss of human life. Failure of climate-change mitigation and adaptation by governments and businesses. Human-made environmental damage and disasters, including environmental crime, such as oil spills and radioactive contamination. Major biodiversity loss and ecosystem collapse with irreversible consequences for the environment, resulting in severely depleted resources for humankind as well as industries. Major natural disasters such as earthquakes, tsunamis, volcanic eruptions, and geomagnetic storms. The report was released ahead of the WEF’s annual meeting in Davos next week, which will be attended by the chief executives of some of the world’s biggest and powerful companies. Despite the large number of participants flying in to Switzerland by private jet, the WEF said Davos would be a carbon-neutral event. But John Drzik, the chairman of Marsh & McLennan insights, which helped to compile the report, said businesses had to step up their action on global heating. “There is mounting pressure on companies from investors, regulators, customers, and employees to demonstrate their resilience to rising climate volatility. Scientific advances mean that climate risks can now be modelled with greater accuracy and incorporated into risk management and business plans. High-profile events, like recent bushfires in Australia and California, are adding pressure on companies to take action on climate risk at a time when they also face greater geopolitical and cyber risk challenges.” Peter Giger, group chief risk officer of Zurich Insurance Group, which also collaborates in the preparation of the risks report, said there was a pressing need to adapt faster to avoid the worst and irreversible impacts of the climate crisis and to do more to protect the planet’s biodiversity. “Biologically diverse ecosystems capture vast amounts of carbon and provide massive economic benefits that are estimated at $33tn (£25tn) per year – the equivalent to the GDP of the US and China combined. It’s critical that companies and policymakers move faster to transition to a low carbon economy and more sustainable business models. “We are already seeing companies destroyed by failing to align their strategies to shifts in policy and customer preferences. Transitionary risks are real, and everyone must play their part to mitigate them. It’s not just an economic imperative, it is simply the right thing to do,” he said."
nan
"It’s no secret that bee populations are in decline across the UK and Europe. There has also been a fantastic increase in public awareness over the past few years, leading many to set up hives in their gardens and on their roofs. But this might not be as helpful as you may think. The UK is home to around 270 bee species. Most people are familiar with the charismatic bumblebees, but the 250 species of solitary bee remain lesser-known. As the name suggests, they don’t live in hives or colonies, but nest alone in cavities or underground.  Bee species also differ in their foraging preferences, selecting flowers based on their shape, colour and scent. This reflects the co-evolution between plants and pollinators and means that plants with certain floral traits depend on compatible bee species. Those with deep flowers depend on bees with tongues long enough to reach the nectar, for example. So losing the variety of the country’s wild bee community could leave many cultivated and wild plants without effective pollinators. The European honeybee (Apis mellifera) is a social bee species that has been domesticated for crop pollination and honey production. Beekeeping is often promoted as a way to conserve pollinators and, as a result, is on the rise across the UK. It’s great to see people backing the pollinator movement, but managing hives does nothing to protect our wild pollinators. It’s the equivalent of farming chickens to save wild birds.  High numbers of honeybees can actively harm wild bee populations, because they compete directly for nectar and pollen. That’s not a problem when flowers are plentiful, but in environments where resources are limited, wild bees can be outcompeted. A lack of flowers is one of the main factors behind the decline in bee populations. Initiatives such as urban beekeeping put more pressure on wild bees and worsen the decline. Honeybees are extremely efficient at collecting pollen and returning it to their hives, but as a consequence they transfer little to the flowers they visit. They are quantifiably less effective at pollination than wild bees, so changes in foraging patterns also have knock-on consequences for the plant community. When honeybees occur in high numbers, they can push wild bees out of an area,  making it harder for wild plants to reproduce. Honeybees are not a substitute for wild pollinators, so we must protect the entire bee community to achieve good quality pollination. Honeybee hives are regularly traded locally and internationally, allowing the rapid spread of diseases and parasites, such as deformed wing virus and Varroa  mite. These pathogens can spill over from managed hives into wild bumblebee populations and spread between wild bee species when they visit the same flower. Responsible beekeepers should take steps to control pathogen levels within their hives to minimise transmission to wild bees. When considering the evidence, the rise in amateur beekeeping is likely to cause more harm than good. No one will deny the value of our British beekeepers and the wonderful honey they provide, but if your motivation is to save the bees then here are some more effective steps you can take.  Gardens provide essential habitats for bees across the UK, so make sure you are maximising the pollinator potential of your outdoor space. If you don’t have a garden, then check whether your public spaces, parks and road verges are bee friendly and let local councils know how they can improve. Bees need to eat, so fill your garden with flowering plants that are rich in pollen and nectar. Watch out for ornamental hybrids that have been bred to produce showy flowers that contain little or no nectar. Remember that variety is key. Include plants with a wide range of floral shapes and colours to increase the number of bee species attracted to your garden. Wooden decking and concrete paving may be low maintenance, but impenetrable surfaces prevent ground nesting bees from finding a home. Increasing the size of your flowerbeds lets you plant more flowers and creates space for more bees to locate nesting sites. Cavity nesting bees look to nest in masonry or old plant stems, but you can provide them with additional nesting sites by buying or building a “bee hotel”. The EU recently extended its ban on the agricultural use of neonicotinoid pesticides in acknowledgement of the harm they cause to bees. These same chemicals are still found in common garden pesticides, so do your best to minimise their use. Immaculate lawns and flower beds may impress your guests, but the bees won’t thank you. Many of our fast growing “weedy” plants provide rich sources of pollen and nectar, so ditch the weedkiller and let the wild flowers grow. Lazy gardeners who mow their lawn less frequently can also expect to see a rise in bee abundance of up to 30% due to the increase of “weeds” such as dandelion and clover. To do your bit for bee conservation, forget taking up beekeeping, but instead take a science-backed break from mowing your lawn."
"Is your employer having the conversation about cutting back on flying? While activist Greta Thunberg’s emotionally charged speeches around the globe have gained headlines so, too, has her decision to shun air travel in favour of train and boat journeys, no matter how arduous. With flying one of the fastest-growing sources of greenhouse gas emissions, more people are following Thunberg’s lead and rethinking the way they travel. But it’s not just about holidays – business trips are a big contributor to the problem, and discussions are taking place at companies up and down the UK about flying less and “clean travel” options.  But with the value of the global business travel market forecast to increase from $1.3tn (£1tn) in 2017 to almost $1.7tn by 2023, according to an Allied Market Research report issued in November 2018, will large numbers of businesses really start to rethink the need to jet across from the UK to New York to set up a deal, or fly from London to Dublin for a meeting? The often exorbitant cost of train travel means that in cold, hard financial terms, it might be difficult to argue against, say, a £40 return flight from London to Edinburgh versus £240 on the train. And what about long-distance commuting to work? This week’s media coverage of airline Flybe’s woes brought a reminder that many of its passengers are weekly commuters hopping on flights to and from mainland Europe. “With more and more companies making their own ‘net zero’ pledges, business travel is bound to come under the spotlight before long,” says Cait Hewitt, deputy director of campaigning organisation Aviation Environment Federation. “We’re starting to get inquiries from the business travel-buying community (corporate travel buyers) to discuss what they should be doing about the impact of climate change on travel.” Some companies have taken action or are working on it, though it is fair to say that when Guardian Money tried to talk to large and medium-sized companies about business flights, many didn’t want to chat. However, some were prepared to spill the beans. London-based Lawson Conner, part of the IQ-EQ group, provides services and software to financial firms, and says it has reduced business flights by 75% over the last two years. “I used to fly quite a lot – I’d probably take about eight flights a month, travelling to Singapore and Hong Kong,” says Gerhard Grueter, co-founder and managing director of Lawson Conner, which employs 50 people in the UK. “That’s now completely cut.” The business has a “one person” international travel policy, where only one member of staff is allowed to attend global business meetings. The reduction in flights has, in part, only been possible because the company has offices around the world. “If clients are being served locally, if someone wants to speak to me, I don’t need to fly to New York – it’s not necessary,” says Grueter, adding: “If I was asked ‘what did you do in your job as a senior member in a firm, about the impact on the environment?’, I want to be able to respond. We have got to act now.” Two years ago, the engineering professional services firm WSP set itself a target in the UK to become carbon neutral by 2025. This involved tackling business flights, which have seen a 9% fall domestically, and a 16% drop overall. In 2018 it introduced an initiative encouraging non-travel and low-carbon alternatives rather than driving and flying, and banned flights under 250 miles. “When our staff book travel online, a pop-up asks whether they need to travel or could they use Skype,” says Claire Gott, UK head of corporate social responsibility (CSR) at WSP. “Also, our admin staff have been trained to challenge any travel. The first choice is by rail.” There’s also an internal carbon levy of £50 a flight on all domestic air travel, to be increased to £200 a trip, with this invested in CSR activities. Sabine Zetteler, owner of communications agency Zetteler, is on a mission to reduce flights taken by her 10-strong company. Zetteler says the London-based business has clients exhibiting all over the world, so in some cases flying can’t be avoided, but for short trips and design fairs, it plans to find more carbon-efficient means. For instance, in April 2019, five of the team travelled by train to Milan Design Week. “It took 12 hours longer and cost a few hundred extra financially, but it was liberating, bonding and important for us to try,” says Zetteler. As for this year, the company plans to visit fewer places and share the carbon offset charge for international meetings that can’t be avoided. Organisations, such as universities, are also looking at what they can do. Sion Pickering, social responsibility and sustainability projects coordinator at Edinburgh University, says business travel accounts for a sizeable proportion of its carbon emissions. “In 2018 during term time, staff and students travelled more than 66m business miles, emitting more than 18,000 tonnes of CO2e (carbon dioxide equivalent),” he explains. “This is approximately 20% of our carbon emissions, and our third highest source after emissions from the electricity and gas we use to heat and power our campuses.” The university has already started discussions about whether the number of travellers can be reduced, and whether additional value can be found by extending trips slightly to combine multiple engagements. “By helping departments to understand how much they travel, we have started to increase awareness,” says Pickering. This year the university plans to introduce a series of measures to reduce emissions from business travel. Some businesses have signed up to Climate Perks, a new scheme that works with climate-conscious employers to offer at least two paid “journey days” per year to staff who travel on holiday by train, coach or boat instead of flying. These are for people to use to travel to and from their holiday destination. More than 30 companies have signed up so far, according to the charity Possible (formerly known as 10:10 Climate Action), which launched the scheme. These are for people to use to travel to and from their holiday destination. Crucially, these days don’t come out of your annual leave allocation – so if, say, you get 25 days’ holiday a year, you get those extra travel days on top of that. More than 30 companies have signed up so far, according to the charity. In return, employers receive accreditation “in recognition of their climate leadership”. “When it comes to cutting plane travel, the solution must be based in behavioural and social change because there is no real technological solution for cutting aviation emissions,” says Emma Kemp at Possible. Although it recently signed up to Climate Perks, the ethical insurer Naturesave launched a similar initiative more than a decade ago for trips to Europe. “In recent years we have seen it grow,” says the marketing manager, Nick Oldridge. “Over the period we have run the policy, a quarter of staff have taken advantage of the benefit each year, resulting in an additional one or two days’ annual leave per person.” While he concedes there is a cost associated with this, there are undoubtable benefits. “Those who use the scheme have reported they enjoyed their holidays more and rediscovered the pleasure of travel,” he says. “They are also proud of being able to demonstrate to their friends and relatives that they have an employer who takes environmental issues seriously.” One employee taking advantage of the scheme is finance manager Abha Wells, who has used it for trips to Scotland and Belgium during the past two years. “Not only was it better for the environment, but we were also able to take our bikes, which made it even better. Now the climate emergency has become so critical, I am planning to take more trips overland using the extra days from our policy.” While carbon offsetting is offered by airlines and others, Cait Hewitt of Aviation Environment Federation says this isn’t the answer to reducing emissions. “Offsetting might look like a cheap and easy response to the climate change impacts of business flights, but while a well-run scheme will do some good elsewhere in the world, it does nothing to solve the problem of aviation emissions.” “There are no green flights on the market today. Rather than offsetting, businesses should look hard at how to cut back on flight numbers, change staff expectations about flying, and then maybe put the money they have saved towards research and development into genuine solutions for zero carbon aviation, whether that’s zero carbon fuel, electric aircraft, or technologies for capturing and locking away CO2 from the air once it’s emitted.” • Think about whether it’s essential to travel. Could you join the meeting by conference or video call? Is there someone who lives or works nearer to the event or meeting who could go? • If you have to go, could you get there by train? Any extra costs compared with flying can sometimes be offset by travelling on an overnight train and avoiding the cost of a hotel room. • If you do fly, travel economy (a business class seat has around three times the CO2 impact compared with economy, as a result of the extra space and weight it occupies, says the Aviation Environment Federation). • Try to choose the most efficient airline for the route. As well as showing you prices, websites such as Skyscanner display which flights are “greener” because they emit less CO2. This calculation is based on aircraft type, capacity and number of stops. • Don’t encourage extra flying by letting staff keep air miles. Find other ways to provide rewards."
nan
"Shortly after Hurricane Helene formed off the coast of West Africa on September 7, it did something unusual. Instead of following most hurricanes westward across the Atlantic, Helene turned north towards the UK and Ireland. Now downgraded to an “ex-hurricane”, Storm Helene is nonetheless expected to bring strong winds across much of England and Wales when it hits on September 17. Something similar happened in October 2017 when ex-Hurricane Ophelia turned north and hit the British Isles, causing three deaths and more than 200,000 homes to lose power.  At the time, Ophelia seemed like a very unusual storm due to the direct course it took across the Atlantic. However, two storms of this type in two years naturally raise the question of whether this is the new normal. As the ocean and atmosphere continue to warm, can people in Britain and Ireland expect more rogue, autumnal hurricanes? Broadly speaking, storms generated in the Atlantic fall into two categories. Normally, the storms responsible for poor autumn and winter weather over the British Isles are mid-latitude cyclones. These storms are largely fuelled by the atmospheric instability where cold and warm air masses meet. Many will be familiar with such features in the form of fronts shown in television forecasts.  In contrast, tropical cyclones, including hurricanes, derive most of their energy from the warm ocean waters over which they form. The change of state from water vapour to cloud droplets releases latent heat (energy) and produces deep convective clouds (thunderstorms). When conditions are favourable, a strong low pressure feature develops and helps to transport more fuel (in the form of moist air) into the storm. It is not unusual for tropical cyclones to develop into mid-latitude cyclones (this happens several times a year). In the Atlantic, the transition usually occurs when tropical cyclones have tracked west and gradually curved north into the mid-latitude storm track. However, the direct nature of the route taken by Ophelia and now Helene marks them out as unusual. So, do Ophelia and now Helene suggest a change in Atlantic storm behaviour? To understand this we need to think about how climate change will impact storms both in tropical and temperate regions. There is now a very clear trend of increasing sea surface temperatures, and it might be expected that warmer seas would lead to more frequent or more powerful tropical cyclones. However, it isn’t yet clear if that is the case for Atlantic hurricanes. What is likely is that warming seas will enable tropical storms to form further north, potentially meaning more will reach the polar front and transition into mid-latitude cyclones. It is also possible that tropical storms originating further north could be more influenced by the subtropical jet stream and be prematurely steered northeast towards Europe (as in the cases of Ophelia and Helene). However, it is unclear what effect climate change might have on the location and strength of the polar front and therefore the mid-latitude storm track. This is due to the sometimes opposing effects of climate change in models, such as the either poleward or equatorward shift of the Atlantic storm track. This kind of uncertainty makes it hard to estimate future storm behaviour, especially given weather systems are chaotic and linear changes to things like temperature or pressure do not produce linear effects. What is more certain is that rising sea levels will mean storm surges (abnormally high sea water levels that accompany powerful storms) will have to be less extreme before causing coastal inundation. It is also the case that with temperatures increasing, the atmosphere will be able to hold more water vapour, leading to hurricanes and mid-latitude cyclones that produce heavier rain and make flash flooding more frequent. Scientists still don’t know exactly how a changing climate will affect the weather. But we do know that the increasing occurrence of rare, extreme weather is detectable and we should expect more of it in the future. As yet, whether or not European hurricanes such as Ophelia and Helene will become more common is unknown. However, it is a further reminder of what an extraordinary year 2018 has been for global weather."
"
Share this...FacebookTwitterThe 4.6 trillion euro German green energies flop

By Prof. Fritz Vahrenholt and Frank Bosse
(German text translated/edited by P. Gosselin)
The demands for the phasing out of coal, fuel and natural gas are becoming ever more shrill in Germany. At first early this year it began with the bold proposal of the coal commission, half of which was occupied by green activists from the Federal Chancellery, calling on the phase-out of coal by 2038. Then came the demand by Green party leader Robert Habeck and his green friends for the phase-out of the internal combustion engine by 2030. And when it was very dry for four weeks in April, Annalena Baerbock declared a climate crisis and called for doubling the CO2 price and a strong regulatory law!
Now the Friday Children of Lummerland are demanding a CO2 tax of 180 euros per tonne this year, and that we reduce “greenhouse gas emissions to zero” by 2035, i.e. 100% renewable energies.
So far wind and sun cover only 2.5% of Germany’s primary energy needs
So it is worth taking a look at the study of the Academy project “Energy Systems of the Future” of the “Union of the German Academies of Sciences and Humanities” to see what’s ahead of us. All sectors, electricity, transport and heat are considered together. And look: 80% of the energy is produced by fossil fuels, 7.5% by nuclear energy and 13% by renewable energies. Once biomass (including biogas and biofuel) is subtracted from renewable energies, only 1.5% of primary energy is generated by wind power and 1% by photovoltaics (p. 10 of the study).
This is a long way from 100%. The study comes to the conclusion that if one wants to go the way of decarbonization, e.g. by 90% by 2050, then “around 1150 terawatt hours, almost twice as much electricity will be needed than today” will be needed (p. 10) because traffic and heat are also to be powered from electricity.
7-fold increase in wind and sun needed
Since only photovoltaics and wind power are considered, the study concludes:
In this case, the installed capacity of wind power and photovoltaics would have to be increased sevenfold compared to today (with the same energy consumption).”
Today, we (Germany) have around 28,000 wind turbines with an installed capacity of 57,000 megawatts and 46,000 megawatts of photovoltaics. A sevenfold increase in the photovoltaic area would require covering almost all roof-facades and other residential areas possible in Germany. A sevenfold increase in the capacity of the wind turbines would change Germany even if the capacity of the individual turbines were doubled. Every 1.5 kilometres a 200-meter tall 3-5 MW turbine would have to be installed.
Approaching abyss
The study also hints at the abyss that we are approaching in this way.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The dominance of the fluctuating renewable energies requires high flexibility on the electricity generation side and on the consumption side.”
In other words, if nature does not provide enough wind and solar power, you have to do without electricity for a while. It is interesting to note that even in the beautiful new world of decentralized green energy generation, it still wouldn’t be possible to go without large centralized power stations. The study estimates that some 60 – 100,000 megawatts of large-scale power plants, which of course would run on biogas or synthetic methane or hydrogen, would help prevent short-term grid collapses. For comparison: today’s large power plant capacity is 90,000 MW.
Storage absurdly expensive
The study’s claim that batteries could only be one solution for short-term storage is helpful. The prerequisite for long-term storage is the successful development of power-to-gas, that is converting wind power into hydrogen or even methane by electrolysis. This remains absurdly expensive today, but we can already do it. However, the authors warn that in days of a cold, dark lull (no sun and no wind in winter), there could be competition between power to heat (i.e. heat from wind power) and the demand for electricity when supply is scarce. That means one would have to choose between lighting and heating. The car would stop in any case.
The authors also correct the widespread misinterpretation of the car as a power storage device.
The buffer capacity of the electric fleet is in the range of a few hours.“
The 4.6 TRILLION euro power supply
The beautiful new world of the German Greens has a hefty price. In the study, the authors assume 60% CO2 reduction, which should be achieved by 2030. By then it will cost 4 trillion euros in a good 10 years. Today’s energy supply system costs 250 billion euros per year, but that will cost 1.5 trillion more. With 60 to 75% CO2 reduction, the authors expect a further 800 billion euros. From 75 to 85% yet another trillion. From 85 to 90% CO2 reduction will cost another 1.3 trillion euros. So 1.5 trillion euros up to 60%, and another 3.1 trillion euros up to 90% make together 4.6 trillion euros.
German households are to spend €4.6 trillion to avoid 800 million tonnes of CO2. This is the amount of CO2 that China emits additionally every year.
100% renewables would cost 764 euros – monthly!
So that the parents of Fridays for Future understand the 4.6 trillion figure correctly: that’s 153 billion euros a year. With 40 million households in Germany, each household would pay 382 euros per month. And if it goes according to Greta and her followers, namely to reach 100% renewable energies in 15 years, then that would be 764 euros per month – if it does not first come to a collapse of Germany, which would be very likely. That’s 764 euros for a monthly average income in Germany of 1,890 euros. This means that the average household would fall below the defined poverty line.
What a beautiful new world.
Sun and wind to decide when we can move or heat
We (Germans) are not even able even cope with the converting the electricity supply (see the warning of the Federal Network Agency to build reserve power plant capacity of 10,000 megawatts – 10 nuclear power plants – in 2022). Now we are expanding the problem to heat and transportation. All three sectors, which were previously dominated by different energy sources (coal, natural gas, crude oil), are to be made dependent on a single one: electricity from wind and sun. Wind and sun are to decide when we can move our car, how much heat we can use in winter and when the light can be switched on. This is what is best called a sustainable short-circuit.
Irrational rush
And why all this? Because of the climate crisis mentioned earlier, of course. And that’s why blogs like ours are necessary in order to make it clear to all decision-makers: Yes, we must leave the fossil era behind us by the end of this century. But we also have use this time, because the climate sensitivity of CO2 is much lower than the panic-makers and social system changers like to tell us.
Share this...FacebookTwitter "
"Peat bogs, which cover 3% of the world’s land surface, are special places. While historically often considered as worthless morasses, today they are recognised as beautiful habitats providing environmental benefits from biodiversity to climate regulation. However, they are threatened by drainage, land reclamation for agriculture and peat cutting for fuel, which has significantly reduced the extent and condition of these ecosystems on a global scale. Bogs are fragile and sensitive to change, whether by human hands or by processes such as climate change. A less well known aspect of bogs is their remarkable archaeological potential. In their undisturbed state at least, bogs are anoxic (oxygen-free) environments due to their saturation. These conditions are hostile to the microbes and fungi that would normally decay organic material such as the remains of plants, which are the principal constituents of the peat. The same anoxic conditions also offer protection from decay for organic archaeological remains. The vast majority of objects and structures used by our ancestors were made from organic materials (in particular wood). These are normally lost on dryland archaeological sites but can be preserved in peatlands. The saturated conditions mean that even soft tissue can survive, including both skin and internal organs. Probably the best known archaeological finds are the remains of “bog bodies” such as the famous prehistoric Tollund Man in Denmark, Lindow Man in the UK, or the more recent Irish discoveries of Clonycavan Man, Old Croghan Man and Ireland’s oldest known bog body, Cashel Man, dated to the Bronze Age.   But archaeology is only part of the story these environments have to tell. They are important archives of the past in other ways: the layers of moss and other vegetation that make up peat are themselves immensely valuable as archives of past environments (palaeoenvironments). The manner in which peat accumulates means that the deposits have stratigraphic integrity, meaning that contained within each layer can be found macroscopic and microscopic remains of plants and other organisms that shed light on landscape change and biodiversity on timescales ranging from centuries to millennia. The high organic content of peat means that these records can be dated using the radiocarbon method. The best known such records are probably pollen grains which provide evidence of past vegetation change. But evidence from other organic material can be used to reconstruct other past environmental processes. For example, single-celled organisms called testate amoebae, preserved in sub-fossil form, are highly sensitive to peatland hydrology and have been extensively used in recent years to reconstruct a history of climatic changes. Meanwhile, fossil beetles can tell us how the biodiversity and nutrient status of a peatland has altered over time. The potential of bogs to preserve both environmental and archaeological records means that they can be regarded as archives of “hidden landscapes”. The accumulating peat literally seals and protects evidence of human activity ranging from the macroscopic (in the form of archaeological sites, artefacts and larger plant and animal remains) through to the microscopic (pollen, testate amoebae and other remains) material that provides contextual evidence of environmental processes.  Through detailed integrated analyses these records can provide evidence of past human activity ranging from the everyday exploitation of economic resources of peatlands, through to the ceremonies associated with prehistoric human sacrifice and the deposition of the so-called bog bodies. The associated palaeoenvironmental record can be used to situate these cultural processes within long term patterns of environmental changes. There has been extensive study of the palaeoenvironmental record from bogs and notable archaeological excavations of sites and artefacts, but there have been relatively few concerted attempts to integrate these approaches. In part this is because generating sufficient data to model the development of a bog in four dimensions (the fourth being time) is a formidable research challenge. But some peatlands have seen relatively extensive archaeological and palaeoenvironmental research over the last few decades, providing an excellent starting point. Hatfield and Thorne Moors, situated primarily in South Yorkshire, are two such peatlands. These two largest surviving areas of lowland bog in England are located within a wider lowland region known as the Humberhead Levels. After decades of industrial peat extraction, these bogs are now nature reserves managed by Natural England, and are becoming the “wild” bogs they once were. We are attempting to reconstruct the wildscape and bring the complex histories of this vast and dynamic boggy landscape to life. These moors are just two surviving parts of a once rich mosaic of wetland landscapes. In the past, this landscape was famed for its wildness – a remnant of an extensive complex of mires, rivers, meres and extensive floodplain wetlands.  Antiquarians such as John Leland visited the area in the 16th century, and his descriptions provide a “window onto what must have been a truly fabulous ‘everglades-like’ landscape”, as described by local historian Colin Howes. Now largely drained, tamed and converted to farmland, it’s hard to imagine the vast wetland landscapes that once characterised these areas. Following large-scale land reclamation in the 17th century, many of the traditional practises such as fishing, fowling, grazing and peat-cutting (turbary) rights were no longer available to commoners. Consequently, the connections between people and place became increasingly defined by a new, dryland landscape and disconnected from its former wetlands that were once so central to people’s lives. We are investigating and reconstructing this dynamic and changing wildscape throughout its history, reconnecting communities to these wetland landscapes. Drawing together previous research alongside targeted archaeological fieldwork and palaeoenvironmental analyses, we are combining these with newly available digital data and sophisticated modelling techniques to reconstruct their interwoven landscape and human histories. Together, for the first time, we are beginning to see the complexity of the dynamic and changing landscape that once characterised the Humberhead Levels."
"Last week Greta Thunberg and 20 other young climate activists demanded that world leaders gathering at Davos at the end of the month abandon fossil fuels. While no thinking human being could disagree with them, I find myself increasingly worried about the unthinking ageism that has crept into this movement. “Young people are being let down by old people and those in power,” they declared, as though the fact that the most powerful people are old means that most old people are powerful. Clearly, they aren’t. In reality, swaths of older people have neither money nor influence, and also support the school climate strikes. What’s happening here, I think, is that some young climate activists have adopted the intergenerational unfairness narrative – the one that also blames old people for zero-hours jobs, soaring house prices and pretty much everything else that’s bad, apart from the overconsumption of avocados. It’s the “OK, boomer” retort now applied to the climate, as expressed last month by the singer Billie Eilish: “Hopefully the adults and the old people start listening to us [about climate change]. Old people are gonna die, and don’t really care if we die, but we don’t wanna die yet.” But stereotyping old people as “après moi, le déluge” types who don’t give a fig about what happens to the planet after they leave it is nonsense. The majority of parents and grandparents are deeply concerned about what they leave behind for their families. (And let’s not be parentist about it, as if only those with offspring care about the planet. Indeed, there are plenty of older people who chose not to have children because of their concern for the planet.) The novelist Chimamanda Ngozi Adichie has warned of the dangers of the single story about another person or country, arguing that our lives are made up of many overlapping stories. “The single story creates stereotypes, and the problem with stereotypes is not that they are untrue, but that they are incomplete. They make one story become the only story,” she argued. This is what the youth climate narrative risks doing. Young climate activists have first-hand experience of ageism, having been admonished repeatedly (mostly by – yes! – old, white men) that they’re too young to know what they’re talking about. It would be a pity if they just flipped this over to stereotype older people. Indeed, over-65s grew up in pre-throwaway times and know all about keeping, repairing and reusing; we need those skills now more than ever. They also have the freedom to imagine a better world: as the radical American anti-ageism campaigner Maggie Kuhn pointed out: “We the elders should be society’s futurists … we have nothing to lose.” Of course the single story makes good copy, and some youth climate strikers, such as Jamie Margolin, co-founder of the youth climate justice movement Zero Hour, in her admirable Ted Talk, are much more nuanced in their analysis. In reality, it’s not generations but structures of power and domination, systems of extraction and exploitation of people and planet for profit, that have brought us to this point of peril. Thunberg recognises this when she eloquently attacks the idea of untrammelled economic growth. Polarising old and young isn’t an effective long-term strategy. If climate activism is to stand any chance of succeeding, it needs to be intergenerational and multigenerational, based on the idea of stewardship of the commons – those resources shared by us all that we need to safeguard for future generations. That way we can be sure future generations will actually exist. • Anne Karpf is the author of How to Age, and professor of life writing and culture at London Metropolitan University"
"
Share this...FacebookTwitterThe European Institute for Climate and Energy (EIKE) here presents two charts which I’m featuring today.
They show that the winter temperature trend for Germany over the past 32 years is not cooperating with “experts'” forecasts of rapid warming and snow and ice becoming a thing of the past.
The first chart, using the data from Germany’s DWD national weather service, shows that wintertime mean temperature trend in Germany has not risen in 32 years:

The green trendline shows that although CO2 in the atmosphere globally has increased from about 350 ppm since 1988 to about 412 ppm currently, Germany’s mean winter temperature has fallen a bit.
France winters cooling
The story is true for much of France as well. Japanese blogger Kirye prepared a chart depicting the winter mean temperature of 12 stations across the country using the untampered data available from the Japan Meteorology Agency (JMA):


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Source: http://ds.data.jma.go.jp/tcc/
Germany trending away from droughts
Also the German media are often filled with scare stories telling us we will be seeing increasing number of droughts and dryness, and that last year’s dry summer was just a taste of what is to come.
Yet once again the data contradict all the doomsday drought reports. The long term winter precipitation trend since records began has been upward.

However, we acknowledge the trend has been decreasing (to normal levels) since about 2000. Interestingly German precipitation shows a 40 year cycle, and so likely has nothing to do with CO2.
The annual precipitation trend for Germany has also been upward overall, and it too has been trending downward since about 2000 (during this time sunshine hours have increased):

Share this...FacebookTwitter "
"Our coral reefs are under threat. Around the world, the long-term survival of reefs is in question because of the environmental stress that climate change is placing on them. But some corals appear to be more resilient to this stress than others. Understanding how these corals are different may hold the key to better predicting how reefs will fare in the future, and perhaps even finding ways to help protect them. Tropical coral reefs are probably the most biodiverse ecosystems in the oceans, and support fishing industries and tourism to the value of US$36 billion a year. But when corals are exposed to an environmental stress such as a sharp increase in temperature, the relationship corals have with the various species of microalgae that live inside their tissues can break down. These algae are expelled, leaving the coral devoid of colour and, more importantly, its food source. These “bleached” corals aren’t yet dead and can recover if they regain their algae quickly enough. Otherwise, corals essentially starve to death. Unfortunately for corals, sharp increases in temperature, known as “marine heatwaves”, are expected to become more frequent and severe because of human-caused climate change.  Coral bleaching has received a lot of media attention in recent years, often with dire predictions for the future survival of coral reef ecosystems. But there is hope. Recent research has shown that coral bleaching has long occurred naturally, since well before human industry began warming the climate. Importantly, the corals analysed in this study recovered after each bleaching event, providing hope that corals today could survive even repeated bleaching events. But the study also found that both the percentage of corals bleaching and number of years in a decade that bleaching occurs has been increasing since the 1800s. If this trajectory continues, there may come a time when recovery from bleaching is not possible. Another source of hope are coralliths, free-living mobile corals that are common in many reefs around the world, but whose physiology has only recently been investigated. These corals  are typically found in areas of reef not otherwise considered favourable for coral growth such as rubble patches. It turns out that these species are physiologically different from their stable counterparts and better at responding to acute environmental change. We also know that there are some species of algae that are more resilient to ocean warming. For example, corals that bond with Durusdinium algae are less likely to bleach.  Our knowledge about these kinds of hardy corals is growing, perhaps because their presence on reefs is becoming more obvious as attention over bleaching events increases. But what can we do with this knowledge? One option being trialled on reefs around the world is transplantation. Fragments or larvae of hardy corals are grown in nurseries and then planted out on a reef by divers. The problem is transplantation is incredibly labour intensive and the transplanted corals often don’t survive very long. While it might be option for smaller reefs and for increasing public awareness, transplantation is unlikely to be a feasible way of restoring large reef areas. 


      Read more:
      3D printing coral reefs can create new habitat – but it doesn't tackle human destruction


 Another approach may be to manipulate the strains of algae associated with the corals to make them and the corals more tolerant to the stress of climate change. However, the rate of success of getting corals to take on new types of algae varies, and it’s a difficult job to say the least.  Corals have a long evolutionary history, and even in today’s rapidly changing climate some display a remarkable resilience to environmental stressors such as warming events. This should give us hope for their continued survival. But the greater the warming, the smaller the window of resilience.  Rather than providing a cure to bleaching, these kind of measures to restore coral reefs are dealing with the symptoms. For the long-term survival of coral reefs, we still need to take more action to deal with climate change and limiting the extent of global warming over the next 50 to 100 years."
"
Share this...FacebookTwitterGerman political analysis and commentary site Freie Welt here has an article on how millions of  Germans are increasingly unable to afford electric power.

Germany’s Energiewende ‘ risks shorting out as millions struggle to pay their electricity bills. Image cropped here.
While a number of commodities such as electronics, electrical goods and computing power across the country – and the globe – have gotten much cheaper over the years due to development, the price of electricity in Germany has “more than doubled since 2000”.
5 million struggling to pay for their power
Almost all of this is due to the Germany’s ‘Energiewende’: the transition to renewable energies and away from nuclear power and fossil fuels like coal.
According to the Freie Welt: “Last year, almost five million people in Germany had problems paying their electricity bills” as some 4.8 million defaulting customers “were threatened” by power companies.
“As a consequence of unpaid bills, almost 344,000 households were temporarily cut off electricity during the same period. This marks new records,” the Freie Welt reports.
“Next increases already in the pipeline”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The situation for Germans will likely get a lot worse before it gets better. Less than a third of the country’s power is supplied by wind and sun, and as that share rises – as is planned – the costs will only continue to climb and make the hardship for the poor even worse.
“Three quarters of the energy suppliers had raised their prices at the beginning of this year again on the average by five per cent,” Writes Freie Welt. “The next increases are already in the pipeline.”
At 29.42 cents a kilowatt-hour, Germans pay among the highest prices in the world.
Further price increases in the medium to long term
According to Valerian Vogel of the utility Verifox: “In view of the major challenges facing the German electricity system, consumers must prepare themselves for further increases in electricity prices in the medium to long term”.
In Germany, the high prices are mostly made up of taxes, levies, grid fees and green energy feed-in tariffs.
In its report, Freie Welt cites figures from the Federal Network Agency, which says wholesales price for electricity are mostly to blame for the excruciatingly painful prices levels. According to the Federal Network Agency, “Last year was around 30 percent higher than the average price for 2017.”
Fridays for Future (unintended) Revolution
Ironically, the Fridays for Future (skip school) movement yesterday issued a call in Berlin for an even more rapid completion of the coal and fossil fuel power phaseout. They demanded that this phaseout be completed by 2030 rather than 2038. The movement, backed by activist scientists, is in fact calling for a revolution.
And a revolution they will get, but very likely not the kind they are bargaining for.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA German psychiatrist has read the Thunbergs’ book, observed climate movement and finds it’s all about fanaticism: “utopian character of demands”…”inability to engage in dialogue and compromise”.

Image: S. Fischer Verlag
Prof. Dr. med. Dipl.-Psych. Wolfgang Meins, neuropsychologist and professor of psychiatry, penned an article recently published at German libertarian site Achgut.com which looks at Greta Thunberg, her parents and the Green movement she has helped to propel. The title of the article: Greta and her parents – not hysterical, but fanatic. 
Prof. Meins read Thunberg’s German language book: Szenen aus dem Herzen and believes Thunberg and her movement are all about climate fanaticism and not climate hysteria. He also warns that politicians need to sober up and face the fanaticism for what it is.
Rooted in obsessive-compulsive disorder, autism
Meins writes that one special characteristic of fanatics is their “inability to engage in dialogue and compromise,” which leads to the fact that people are declared “external enemies” who are “potentially also fought with aggressive and destructive means.”
Meins attributes Greta Thunberg’s climate fanaticism to an obsessive-compulsive disorder and her autism.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Her disability, Meins writes, is rooted in the fact “that as an Asperger autistic, she tends to focus very strongly on a special field of interest. People with Asperger syndrome show little compassion and interest in other people,” he writes.
This means “you are as good as immune to the suffering of your fellow human beings”. For example, “people who would become unemployed as a result of banning all flights”.
Strongly emotional convictions dominate, permanently determine thinking
Meins writes: “The climate fanatics are united by a superior idea, i.e. strongly emotional convictions that absolutely dominate and permanently determine their thinking, for example: The CO2-induced apocalypse is irrevocably imminent unless we take immediate, radical countermeasures at any cost. In Greta’s case, superior ideas of this kind developed through a small distraction, based on a related theme: During a school lesson in autumn 2014, she sees a film about the pollution of the oceans. She bursts into tears during the film. At noon she sits in the cafeteria in front of her burger, which she does not touch. From then on, if I correctly interpret the mother’s vague statements, she only eats vegan, if anything at all.”
“Elites almost unanimously paying homage to a fanatic”
“The very special thing about Greta and her fans is that they are courted by large parts of the Western elites, and above all German elites. One hardly hears anything critical from these circles at all,” says Meins. “It is probably the first time since the end of the Second World War that these elites almost unanimously pay homage to a fanatic, and often even encourage Greta and her followers.
With regard to the SPD and especially the CDU-related “elite actors”, Meins assumes that “the completely utopian character of demands for a radical change in climate policy, now and immediately, is clear to them. He accuses them of cowardly refusing to “open the door to the fabulous realm of the climate apocalypse”. Their fear of being driven into political suicide due to “argumentative awkwardness, overlooked pitfalls and media that act on this issue” is overwhelming.
“No need to worry about ecodictatory regulations and prohibitions”
Meins writes in his article that “you get to know quite exactly how climate fanatics tick.” He adds: “For example, that one does not have to worry about the political, economic and social consequences of certain drastic or perhaps better: ecodictatory regulations and prohibitions. Why should they? There is no alternative to such measures, because otherwise we will “burn” or otherwise perish.”
Share this...FacebookTwitter "
nan
"At current rates of loss to poaching, rhino species will be extinct within our lifetimes. The big problem is demand for their horn from Asia. The market for rhino horn is moving from “traditional” medicine to “investment value” as jewellery and other processed artefacts in the art and antiques market, according to wildlife trade monitors TRAFFIC. South Africa is at the centre of the problem because it has most of the rhino, and because it now, against international opinion, allows legal domestic trading of rhino horn. This has led to rhino horn being worked to disguise it as jewellery and powder, and exported illegally, principally to Vietnam and China. It is getting ever harder for customs officials to recognise illegal wildlife products.  The relationship between smuggling and law enforcement is like an evolutionary arms race in nature, as each innovation by the smugglers is recognised and tackled by law enforcement, so the criminals innovate and switch strategies.  There can be a tendency to retain an old-fashioned stereotype of “the poacher” as a poor local struggling to feed his family, but the reality is that when it comes to high value products such as rhino horn, the players are often well-organised criminal syndicates involved in other unsavoury activities. The link is unsurprising, given the illegal wildlife trafficking industry is estimated to be worth US$23 billion. However, South Africa recently undermined efforts to reduce demand by lifting its ban on the domestic rhino horn trade. This has made life a lot more difficult for law enforcement as a legal trade sends out the message that rhino horn is valuable, and so facilitates an illegal trade. The recent release of a Thai rhino kingpin from a South African jail only six years into a 40-year sentence raises further questions of the country’s commitment to tackling wildlife crime. It’s easy to see why South African game farms would support a legal trade. Rhino horn can be harvested without having to kill the animal, many farms have stockpiles, and farms want to cash in on their stock. Based on the Asian black market value, rhino horn is estimated to be worth US$65,000 per kg. The problem is that rhino horn should not have a value, and indeed has no commercial value outside the illegal trade, driven principally by consumer demand from Asia. The illegal wildlife trade hurts people as well as animals and plants. Poachers, where caught, are jailed or killed, and their families impacted. Wildlife rangers and law enforcement officers also risk their lives. Desperate people part with cash and hope to invest in false medicinal promise provided by charlatans and criminals. Ecotourism potential is eroded by biodiversity loss – with immeasurable future economic costs. Local communities where rhino and other endangered species live are a key, yet historically often overlooked, factor influencing the sustainability of endangered wildlife populations. All too often the benefits of conservation do not go to local indigenous communities. Community empowerment and integration in wildlife conservation will improve local support and ideally reduce the need and cost of high-tech militaristic solutions. Historically, demand for rhino horn was driven by perceived (yet entirely mythical) medicinal benefits. Demand can be reduced, firstly, by ending all legal trade and therefore not giving rhino horn a value. And second, by broadening education programmes to young and old in Asia to inform that rhino horn has no medicinal value. Rhino horn is useless - except to the rhino. Alongside this, we need to reverse the perception that ownership of rhino horn is a positive status symbol. Society needs to value the live rhino in the wild more than its horn, and rhino horn products should be viewed as a badge of shame, not of honour. As conservation biologist Ian Redmond puts it: “Far from being a status enhancing display, use of rhino horn and ivory now says ‘I support organised crime’.” This sort of culture shift requires not only education in the classroom through teachers, but beyond the traditional education system. For instance, TRAFFIC targeted businesses in a three-year demand reduction project in Vietnam, while film star Jackie Chan is facilitating social change across Asia: Demand for product, even with perceived “traditional” motivation, can be reduced: demand for rhino horn dagger-handles from Yemen in the 1970s and 80s, for instance, was effectively closed. We need to do the same again – tackling whatever consumer market stands to gain from rhino horn. However, a hot-off-the-press TRAFFIC report highlights that demand reduction programmes must improve and be evidence-based and targeted in order to be effective. Biodiversity is a global good, and when a species is gone, it is gone forever. The quagga, Tasmanian tiger, passenger pigeon, great auk, dodo, giant tortoises and giant birds – all hunted to extinction. Everyone has a responsibility to contribute to ensuring the rhino does not go the same way. At its simplest, do not support the illegal wildlife trade: do not buy, report suspicions, and spread the word that ownership of rhino horn, elephant ivory, pangolin scales, and other illicit wildlife products is unacceptable. The link between wildlife crime and legal trade has serious implications for conservation. We need to get the message across that consumption and use of rhino horn and illegal wildlife products are bad news for everybody – not just the animals."
"The 2018 summer heatwave in the UK broke records – and it won’t be the last spell of such severe heat. In fact, climate change means that hot summers which would once occur twice a century may soon occur twice a decade. As the population grows and ages, this will lead to more premature heat-related deaths and place extra strain on physical and mental health services. Previous research on resilience to heatwaves, such as the recent report by parliament’s Environmental Audit Committee, a cross-party group of MPs, has focused predominantly on policy, regulation and infrastructure. Such research barely addresses behavioural or social responses that occur during hot weather events and how these can contribute to building resilience.  This is what my own work looks at. In a new book I explore these ideas and assessed how to improve resilience to climate change through communication, collaboration and co-production. So what can the UK do to be better prepared for heatwaves in future? People must be trained to think more carefully about their vulnerabilities and responses to hot weather. Everyone’s experience of hot weather varies, and this is often associated with positive memories of past summers where they’d enjoy the heat, venture outside and make the most of a potentially short-lived summer.  But this often leads to people being more exposed to the effects of the sun, which affects their health and productivity and puts extra strain on hospitals. Hot temperatures also cause roads to melt and train track to buckle, resulting in delays. As hot weather becomes more common, people need to bear these things in mind. While appropriate regulation and policies are important, they must represent how people respond to heatwaves and how their experiences affect their behaviour. This can be incorporated into broader thinking around other topics.  Buildings, for instance, can be insulated to stay warm in the winter yet cool in the summer, but we need to better understand how people behave in buildings during those periods to ensure appropriate use.  And working practices can be adjusted so people can work outside periods of intense heat. People rarely want to stay at home all day, so more water fountains should be provided in public places. British people famously love talking about the weather. But they still need to get better at talking about heatwaves specifically, and how they can become more resilient to them. That means things like sharing whether they’re feeling the load of the hot weather or sharing ways to stay cool.  Better communication will also help people understand who’s doing what during a hot weather event (for example emergency services under extra strain, or bus and train drivers working in tough conditions). Learn from other others. Mediterranean countries, for instance, are used to the hot weather and people there have adopted simple practices to help them cope with the stress: closing shutters during the hot weather, avoiding being outside or on the beach during peak heat temperatures, painting buildings white, staying hydrated and avoiding strenuous activities during hot weather. Countries in northern Europe that are just getting used to severe heatwaves could adopt these practices. Investment should be pro-active, rather than reactive. That means working closely with scientists to anticipate the risks from heatwaves, getting a better understanding of our vulnerabilities and the potential measures we can take.  Ensure buildings (especially hospitals and care homes) and infrastructure are better prepared to withstand hot weather events and that regulation is updated to better reflect this, without which the number of heatwave-related deaths would increase."
"There is no doubt that plastic pollution in oceans is a growing worldwide problem. The internet is full of images of seabirds and other marine animals entangled in plastic waste, and animals starve because their guts are blocked with plastic bags. But the problem goes much deeper than this. Much plastic pollution is in the form of microplastics, tiny fragments less than five micrometres in size and invisible to the naked eye. Our new research shows that these microplastics are even getting into tiny flying insects such as mosquitoes. And this means the plastic can eventually contaminate animals in a more unlikely environment: the air. Microplastics can come from larger plastic items as they break down, but are also released directly into waste water in their millions in the form of tiny beads found in many cosmetic products including face wash and toothpaste (though these are now banned in many countries). Many tiny animals can’t tell the difference between their food and microplastics so end up eating them. Once inside an animal, the plastic can transfer via the food chain into fish and other creatures and eventually become a potential health problem for humans. By studying mosquitoes, we have found a previously unknown way for plastic to pollute the environment and contaminate the food chain. Our new paper, published in Biology Letters, shows for the first time that microplastics can be kept inside a water-dwelling animal as they grow from one life stage to another. Although most microplastic research has focused on the sea, plastic pollution is also a serious problem in freshwater, including rivers and lakes. Much of the freshwater research has concentrated on animals that live in the water throughout their life. But freshwater insects such as mosquitoes start their lives (as eggs) in water and, after several stages, eventually fly away when they grow up.  It occurred to us that aquatic insects might carry plastics out of the water if they were able to keep the plastics in their body through their development. We tested this possibility by feeding microplastics to mosquito larvae in a laboratory setting. We fed the aquatic young in their third larvae stage food with or without microplastic beads. We then took samples of the animals when the larvae shed their skin to become larger fourth-stage larvae, when they transformed into a non-feeding stage called a pupa, and when they emerged from the water as a flying adult. We found the beads in all the life stages, although the numbers went down as the animals developed. We were able to locate and count the microplastic beads because they were fluorescent. We found beads in the gut and in the mosquito version of the kidney, an organ that we know survives the development process intact. This shows that not only do aquatic insects such as mosquitoes eat both sizes of microplastics, they can keep them in their gut and kidney as they develop from a feeding juvenile larva up to a flying adult.  In this way, any flying insect that spends part of its life in water can become a carrier of plastic pollution. And flying insects are eaten in their thousands by predatory insects in the air such as dragonflies as well as by birds and bats.  Our results have important implications since any aquatic insect that can eat microplastics in the water could potentially carry them in their body to their flying stage where they can move the plastics into new food chains. As a result, freshwater plastic pollution is a problem that has implications far beyond those of water quality and eventual marine pollution. Clearly these results raise a number of questions, including what effect microplastics have on the survival and development of mosquitoes through their life stages. And we still need to examine the effect of different types and sizes of plastics on more species to see how widespread an issue this could become."
"The announcement by the shadow business and energy secretary, Rebecca Long-Bailey, that Labour will target “net zero” emissions by 2050 is of course welcome for anyone interested in achieving a low-carbon economy. But the party is plugging in to an existing and growing movement, rather than leading the way. Indeed, several governments, including those of of New Zealand and Sweden have already endorsed zero emissions, along with companies such as Unilever and Tesco, as well as a cross-party group of British MPs. Even the prime minister, Theresa May, recently announced that the UK will join the Carbon Neutral Coalition, hopefully signalling a step towards a net zero target. So, the pledge itself might not be radical, but it will still be difficult for the UK to achieve. Transforming energy systems is technically, socially, economically and politically complex and Labour’s announcement was backed up a briefing on aspects of how it might be achieved. It foresees rapid growth of both offshore and onshore wind, as well as solar power. It will also require a much-needed concerted effort to improve domestic energy efficiency, particularly in the use of heat in our homes. But the briefing only gives a partial picture and the scope and feasibility of the plan is yet to be established, as full details will only be revealed later in the year. The lack of detail raises lots of questions, but one of the most politically interesting is what role new nuclear energy might play in Labour’s vision of a net zero future. Long-Bailey’s speech did not mention it. The background briefing does, but only in passing. And the final, complete report is not yet out. So how much of Labour’s renewables pledge and net zero target depends on new nuclear stations being built? At the heart of this lack of clarity is the split in the Labour Party about nuclear power – and at the heart of that is Jeremy Corbyn. Back in the day – pre-leadership – Corbyn was a high-profile opponent of the nuclear issue on both environmental and proliferation grounds. None of the problems with nuclear waste and plutonium which so concerned him then have been solved, but his approach has shifted, leading to some awkward exchanges as people seek to understand what his views are now. Most notable among these was the painful Copeland by-election in 2017. Copeland is home to Sellafield, the heart of the UK’s nuclear waste industry, and the seat was solidly Labour for decades. Corbyn’s nuclear position was a key focus of by-election campaigning, with the Conservatives highlighting his statements opposing the nuclear industry generally and new nuclear power in particular. Despite a last-minute endorsement from Corbyn for a new nuclear station at Moorside near Sellafield, Labour lost the seat, with a lack of belief from voters on this new nuclear stance widely identified as a reason. Elsewhere in the party, though, nuclear power is seen as an intrinsic part of the UK’s energy future. Long-Bailey is very keen on it, for instance. This side of the debate reflects the accepted political paradigm that achieving climate targets won’t be possible without nuclear power. This view, though, is a paradigm – a recognised and unquestioned way of thinking about what is “acceptable”. It hasn’t really been challenged since new nuclear power was endorsed in the 2008 Nuclear White Paper. Since then the energy world has changed. The cost of renewables has plummeted, storage has emerged as an increasingly viable option for managing the fluctuations in solar and wind power, and increased interconnection between the electricity systems in the UK and Europe are providing new opportunities for balancing power. Coupled with this, the UK’s nuclear plans are floundering because of the high costs associated with new stations. Hinkley Point C requires much higher subsidies than was envisaged in 2008 – and financing of other new projects such as Wylfa and Moorside have led the government to think about measures such as partial nationalisation as a way of managing the construction and financial risks. This isn’t what the White Paper promised. So, when Labour’s energy plan is finally published, the issue will be one of the most fascinating. Will the party endorse new nuclear plants, despite their ever present financial problems? It seems likely that it will, because there has been no detailed examination of the case for new nuclear power for ten years – instead, both the Conservative and Labour have generally accepted that nuclear is necessary in a world of climate change. This is a real shame. One of the opportunities that putting forward a new vision of the UK’s energy systems offered was a new way of thinking about things. From this perspective, just accepting that nuclear power is an inevitable part of the energy future is lazy thinking which fails to recognise the changing energy world. If Labour really want a new, radical energy plan, it needs to reassess the nuclear paradigm."
"The Icelandic volcano Eyjafjallajökull made worldwide headlines in 2010 when it erupted ash that was blown towards Europe, so that air traffic was grounded across the continent. More recently, the volcano’s bigger sister and neighbour, Katla, has also been in the news. First the papers said the “giant volcano” was ready to blow, yet within days articles were appearing to say it was all a mistake and the eruption news was premature. What is going on? Over the past 1,100 years, Katla has erupted at least 21 times - an average of around once every 50 years or so. It is exactly a century since the volcano’s last major eruption through the ice, which produced a 14km high column of fragmented volcanic rocks and gas, as well as enormous floods of meltwater, sediment and ice. But this doesn’t mean that another is “due”. Volcanoes don’t erupt to schedule. So why do headlines regularly appear to suggest this is the case? This latest news flurry was triggered by the publication of an academic paper by a team of scientists lead by Evgenia Ilyinskaya at the University of Leeds. They had carried out gas-monitoring surveys at Katla in 2016-17, which showed it emitted much more CO₂ than previously estimated. One of the exciting parts of this research was the recommendation that gas monitoring becomes part of the regular observations of volcanoes that are hidden under glaciers or ice sheets. However, many news outlets incorrectly suggested that the observation of these carbon dioxide emissions meant an eruption was imminent, and sounded the alarm. This sensationalist approach causes more damage beyond merely being incorrect. From a distance, readers and viewers might be interested in the science, the human story, or because even faraway eruptions can have economic or health costs. But for those living in the shadow of the eruption, the immediate impacts are far more pressing, or even life-threatening. Evacuating from a region, moving family and animals, or leaving your house behind all require a degree of certainty that this risk is real and that it should be avoided. To believe a risk is real, information needs to be trusted and thus information providers need to be trustworthy. It should therefore be clear that accurate information is essential. Effective risk communication is needed before, during and after a hazardous event, aiming to prevent and mitigate disaster harm, ensure preparedness and aid recovery. Inaccurate information will of course mean people will have less faith in scientists and news sources next time round. But it can have more immediate effects too. In July 2018, the New York Times reported how exaggerated coverage of the ongoing Kilauea eruption in Hawaii lead to a vastly inflated risk perception which saw tourism bookings decrease, which in turn led to loss of income and fears about job losses. In the worst instances, poor information can cause people to ignore evacuation orders. The risks aren’t easy to communicate. Hazards do not occur in an easy to predict way, they can happen with little warning, and risk assessments virtually always deal in probabilities rather than absolute certainty. Concepts such as 100-year floods are famously challenging to understand or relate to. In addition, risks to people are influenced by factors such as wealth, age, health, physical ability, whether you own a car, or which floor your apartment is on, so they can vary from person to person, house to house.  Communicating this information therefore comes with responsibilities. By crying wolf too many times, even if the warnings aren’t directly from scientists or the authorities, the media can strongly influence risk perception and create a warning fatigue. Journalists and editors must consider the ripple effects from an overly sensational news article, and the potential consequences for lives. It doesn’t take long for inaccurate news to spread and multiply across the internet: see, for example, the volcanologist and science writer Robin Andrews having to call out and correct reporting of the recent earthquake and tsunami in Indonesia which often conflated it with an unrelated volcanic eruption 600 km away on the same island of Sulawesi. The flip side of this is that competent, reliable communications can boost public trust and reduce fear and panic, helping people to take well-informed actions.  The International Journalist’s Network published an article on disaster journalism that presents some useful guidelines, much of which emphasises accuracy. I’d also suggest that journalists checks their facts with the scientists doing the work, or with the local organisation responsible for monitoring the hazard. Journalists should also avoid simplifying the forecasting process too much, ensuring that a possible scenario or timeframe is not presented as something of certainty. Readers should always be referred to a reliable source of further information. These simple measures can be used as a blueprint for strengthening reporting accuracy, and so help regain trust in science communication and the media."
"
Share this...FacebookTwitterClimate disaster? Grain production almost quadrupled worldwide while the population doubled over past 60 years!
Michael Krueger
(Translated/ edited by P Gosselin)
In these times of Fridays for Future led by Greta Thunberg, all experts and self-proclaimed experts are talking about how badly the earth is doing and warning that planet earth is about to collapse unless action is taken immediately. It’s claimed that all experts agree on their vision of the future! Droughts, floods, crop failures and famines threaten – and millions of climate refugees will make their way from south to north.
These are the visions of the “climate impact researchers”. But is that really the case? The opposite is the reality.
Let us first take a look at the grain yield of the most important cereals grown in the world.

Global grain yields per hectare  for the most important grains. Source: Statista
Miracle upon miracle. The grain yields per hectare of corn, rice, wheat and barley have increased strongly over the last 25 years and have not decreased at all, despite all the climate horror claims.
In the case of maize, the yields per hectare have almost doubled. Maize yields have increased by around 80%, rice by around 65%, wheat by around 70% and barley by around 65%.
And this in times when droughts and torrential rains are supposedly reducing the harvest yields?

Global production of maize, rice and wheat. Source: FAOSTAT
If you look at the world harvests of the most important grains, they have also risen sharply over the last 25 years. The amount of maize harvested has roughly doubled, i.e. increased by 100%, the amount of rice harvested by about 75% and the amount of wheat harvested by about 80%.

If we look at global grain production and grain production in selected tropical countries, this has increased sharply since 1960. On average, production has quadrupled!



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Exponential growth since 2000! Source: Worldwatch Institute
And when we look at the world grain production as a whole (wheat, rice and coarse grains), production has quadrupled since 1961!
This means that four times as much grain is harvested in the world as 60 years ago. The world population has only grown from 3 billion to over 7 billion in the same period. So it has only more than doubled a little bit

Maize and wheat yields for Germany and USA. Source: Felde 2009 as to FAOSTAT
The above figure shows how in Germany and the USA yields per hectare of cultivated land have risen sharply since 1960. Maize in Germany by approx. 130% and for wheat in Germany by approx. 120%. This is more than doubling. Maize in the USA has jumped by approx. 110%, for wheat in the USA approx. 75%. So almost doubling.

Grain production in tonnes and yield per hectare. Source: German Federal Office of Statistics
If we look at the development of grain production in Germany since 1950, we can see a significant increase both in the total harvest quantity and in the yields per hectare. The total grain production has increased by about 450%, the grain yield by about 350%.
Wheat yield (top), maize yield Germany (bottom). Source: Prof. F. Isermeyer, FAL Braunschweig
By international standards, wheat yields per hectare of cultivated land have risen worldwide. Germany, in particular, is distinguished in wheat cultivation by high yields per hectare and a strong increase in yields per hectare. The yield per hectare of wheat has more than doubled since 1970 and is four times higher than in other countries.
And maize acreage and maize yields have also grown strongly in Germany. In the last 30 years, the yields per hectare of maize have almost doubled and the area under maize has increased by about 75%.
Good news censored
The question is: Why don’t you hear about it in the media and news? As a rule, there are only reports of failed harvests and famines, but no new record harvests. Perhaps simply because this does not fit into the picture of a climate catastrophe?
Now imagine that the Arctic and Siberia would also become fertile arable land as a result of global warming and that crop yields increased even further as a result. Would that be bad or good?
Share this...FacebookTwitter "
"In recent decades, environmentalists have grown used to disappointment when big companies and Wall Street pay lip service to concern over the climate crisis. On Tuesday, it looked like something might have changed. The decision by BlackRock – the world’s biggest asset manager – to exit investments that “present a high sustainability-related risk” has been welcomed by environmentalists as a significant moment in the battle to reshape the relationship between money and the climate crisis.  The move is “a remarkable breakthrough”, the leading climate science writer Bill McKibben told the Guardian. “The activists who made this happen get the afternoon off to celebrate. “This is the biggest pot of money in the world and until today, its leaders have refused to acknowledge the biggest thing happening on the planet – the accelerating rise in temperature. So it indicates that the facts on the ground of the climate crisis are so grave that no one can turn away, and that activist pressure has reached a point that even the richest companies are not immune.” In two letters on Monday, the BlackRock boss, Larry Fink, announced: “The evidence on climate risk is compelling investors to reassess core assumptions about modern finance” and henceforth the company would divest $500m from coal-related businesses. The announcement called on “every company, not just energy firms, to rethink their carbon footprints”. BlackRock, which holds $7tn in assets, has come under intense pressure to reform the funds it offers investors. “Awareness is rapidly changing, and I believe we are on the edge of a fundamental reshaping of finance,” Fink wrote, adding that new funds would allow clients to avoid investments in companies that may be adding to climate change. The firm said it doubled to 150 the number of exchange-traded funds it offers that address social, environmental or governance issues. In November, climate activists protested outside BlackRock’s London offices, dumping ashes to signify the Amazon fires while Extinction Rebellion, the global environmental movement, described BlackRock as the world’s top investor in deforestation and coal. Fink himself has received letters from members of Congress urging action, while BlackRock was named as an investor with one of the worst voting records on climate issues by Ceres, a not-for-profit watchdog that pushes financial firms to consider sustainability. The pressure for change has come from within the world of finance as well as outside. Last month, Mark Carney, the outgoing head of the Bank of England, warned that pension funds risk seeing their assets become worthless unless companies rapidly rise to the challenge of the climate crisis. But while some celebrated, others warned that sustainable investing will not be quick or simple for BlackRock. It currently holds a 6.7% stake in ExxonMobil, 6.9% in Chevron, and 6% in the mining company Glencore. Two-thirds of its $7tn in assets are in tracking funds that cannot easily be switched to meet sustainability goals. McKibben, who last year published a devastating report in the New Yorker titled Money Is the Oxygen on Which the Fire of Global Warming Burns and who is part of a campaign to force companies including Goldman Sachs, Chase Bank and BlackRock to reform their investments, said environmentalists would now need to keep the pressure up. “The steps BlackRock is taking are baby steps, and we will have to watch and push hard for them to begin striding at the pace we need to go. But in some sense, the first step is often the hardest,” McKibben said. He urged the company to go further. Its decision to divest $500m from coal-related businesses, for instance, is not the same as divesting from larger and far more polluting oil and gas industries. “Coal is part of the problem, but not the biggest part of the problem – oil and gas are,” McKibben said. “Fink made noises that natural gas is part of the solution but it’s not. That’s old thinking, and we’ll push them hard on that, but at least we’ve reached the point that they’ve realized they have a role in dealing with the climate crisis.” But perhaps the largest change is BlackRock’s apparent willingness to use its considerable shareholder power to demand climate action – a power it has in the past demurred from using in favor of direct company consultations. A report last year by the Washington DC-based Majority Action and the Climate Majority Project claimed that BlackRock had voted overwhelmingly against key climate resolutions at energy companies, including ExxonMobil. Had BlackRock and Vanguard not torpedoed these investor efforts, at least 16 climate-critical shareholder resolutions at S&P 500 companies would have received majority support in 2019, representing a significant corporate shift on climate, the report claimed. “We have the largest investment stewardship team in the industry and engage with companies even in the absence of shareholder proposals,” BlackRock said in a statement to the Guardian at the time. But, it warned, “it would be wrong to equate good governance with voting against management without regard for a proposal’s impact”. In Tuesday’s statement, that position appeared to be shifting from last year when it said that “recent extreme weather events” and “the implications for investment portfolios – stemming from a rising frequency and intensity of such events – have been notoriously hard for investors to grasp”. No longer. Now BlackRock’s CEO writes that company directors should be held accountable “where we feel companies and boards are not producing effective sustainability disclosures or implementing frameworks for managing these issues”. He added that “the company voted against or withheld votes from 4,800 directors at 2,700 different companies” last year. There are still worries for environmentalists. Majority Action’s Eli Kasargod-Staub warned that subtlety in BlackRock’s language calling for companies to improve disclosure on “integrating and reporting on sustainability” is not the same as calling for immediate action. “BlackRock has the power to be going to corporate directors and saying: ‘Either you commit to the science-based targets of the Paris climate agreement and align your operations, governance, political spending, lobby and trade association activities to achieve that target or we will vote against you and your directors,’” Kasargod-Staub said. “But that’s not what BlackRock said – they said they’re calling on companies to enhance their disclosures around climate risks and their plans around those risks,” he added. Kasargod-Staub pointed to this quote from BlackRock, directed at companies it invests in: “This should include your plan for operating under a scenario where the Paris Agreement’s goal of limiting global warming to less than two degrees is fully realized, as expressed by the TCFD [Task Force on Climate-related Financial Disclosures] guidelines.” “Think about how passive that sentence is, then think about the behavior of ExxonMobil or Marathon petroleum, who through their capital expenditures and policy influence have actively undermined our ability to protect long-term investors and meet the goals of the Paris agreement,” said Kasargod-Staub. Whether Blackrock is now going to side with activist resolutions on sustainability remains to be seen during shareholder season, McKibben said, but he warned against expecting a shift by fossil-fuel energy producers to become carbon-neutral. “I don’t think the big oil companies are capable of changing, though I’d like to be proved wrong,” he said. “The job is basically to starve them and reduce their ability to continue expanding.” Still, McKibben said: “For all of us that have been campaigning for years around climate finances, this is an historic moment. From today, it’s going to be harder to go sink of load of money in Exxon, because the biggest financial firm in the world has said, ‘Huh, there’s something to this climate stuff. Better pay attention.’”"
nan
"When the Paris Agreement in December 2015 called for the IPCC to put together a “Special Report” on Global Warming of 1.5°C, scientists knew very little about the exact differences that half a degree makes (1.5°C versus 2°C). Never before have so many independent studies been conducted at such short notice, in order to meet this pressing question of the global climate negotiations community. Is a warming of 2°C above pre-industrial levels sufficiently low a limit to avoid dangerous anthropogenic interference with the climate system, and, if not, can we implement a lower limit?  Many researchers worked tirelessly to get their scientific publications accepted before the cutoff deadline in May 2018. And now we have the assessed result of their studies, summarised in about 30 pages. So what have climate scientists learned? First, nothing fundamentally new or surprising has arisen. I vividly remember being involved in crafting the sentences on climate change impacts at different temperatures in the IPCC’s previous full assessment round, which was finalised in 2014. We concluded that more warming increases the likelihood of “severe, pervasive, and irreversible impact”, that “some risks of climate change are considerable at 1 or 2°C above pre-industrial levels” and that “the overall risks of climate change impacts can be reduced by limiting the rate and magnitude of climate change”. It is important in interpreting the new report that the IPCC has never said that 2°C was “safe”. The 2018 report now puts the particular differences between 1.5°C and 2°C under a magnifying glass. And it comes up with numbers to demonstrate the significant difference between the two, like in a statement that the lower temperature would mean 50% fewer people “exposed to a climate change induced increase in water stress”. I also remember very well that another IPCC contact group that I co-chaired, in Berlin, concluded that reaching a 2°C target would probably entail large-scale afforestation and/or production of bioenergy with carbon dioxide capture and storage (BECCS). In order to reach 1.5°C, no one should be surprised that the need to suck carbon dioxide out of the atmosphere and store it somewhere will only become greater. And indeed the 2018 report confirms that some sort of “carbon dioxide removal” will be necessary. Its use can remain limited, however (without even the need for BECCS) provided that there are fast and significant measures to cut emissions and “lower energy and land demand”. Providing the additional, detailed information to policymakers is all very useful. But what strikes me about this latest report is its tone. For the scientists involved it has become apparent (which they never said in so many words before) that the goalpost should be shifted from 2°C (which was already hard to reach) to 1.5°C (which is much harder to reach). Which leads one to ask: if climate scientists are so adamant about this now, why did they not create the opportunity themselves to issue such a warning before? And why did they wait for global leaders to ask them the question? Politicians have often erroneously pointed to climate science – and the IPCC as its assessor in particular – as having provided the underpinning of the globally agreed target of 2°C. In 2015, the politicians effectively asked scientists to underpin a more stringent target. And they obliged. The scientific community needs to make it as clear as they can that it is not them who have now decided that 1.5°C is “safe”. The IPCC has only provided the evidence base that can inform politicians in their deliberations of whether they indeed wish to stay below that other target in the Paris Agreement, the limit of 1.5°C. In those deliberations, the feasibility of staying below 1.5°C will feature prominently. And here the scientists will find it hard to admit that the scenarios they have conjured up are not at all realistic – they are more like a pipe dream. If they say, for instance, that large-scale carbon capture can be avoided by implementing incredibly fast and deep emission cuts now, they kind of set the world up for having to implement carbon capture anyway, given the difficulties that are involved in fast deep emission cuts worldwide.  The IPCC did not go further than stating that there are some “feasibility and sustainability constraints” related to many of its scenarios. A smart reader will understand that this means that these scenarios are not really feasible, politically and (since politics is fractured) economically."
"
Share this...FacebookTwitterPIK takes a blow: stronger hurricanes cannot be explained by higher CO2
By Die kalte Sonne
(German text translated/edited by P Gosselin)

Image: NASA (public domain)
Whenever the hurricane season in the Caribbean begins, the whole world and the German Potsdam Institute for Climate Impact Research (PIK) wait for a strong storm, as it presents the ideal opportunity to sell climate change, as was the case in September 2017 when Potsdam’s Neueste Nachrichten (PNN) daily reported with reference to the PIK’s Anders Levermann:
Global warming provides energy for stronger tropical storms
According to Potsdam climate researchers, the impact of the current tropical cyclones can be attributed to climate change. Burning coal, oil and gas increases the temperature of the planet and thus provides energy for ever stronger tropical storms, explained Anders Levermann of the Potsdam Institute for Climate Impact Research (PIK). “Unfortunately, physics here is very clear: hurricanes draw their destructive energy from the warmth of the ocean. The water temperatures in the region are too high. Climate change does not cause these storms, but it can “make their consequences worse.”
Will the intensity of hurricanes increase with climate change? Can this be detected today, as Levermann concludes so trivially? This is not the case, say researchers around Lory Trenary from George Mason University in Fairfax, Virginia. They investigated climate models and re-analyses and found no connection with the drive by greenhouse gases, especially CO2.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The long-term trends 1958-2005 were ultimately contradictory and not valid. An attribution of hurricane intensity to climate change is still not possible. In the introduction to their current work, they also mention Levermann’s argument: “Warmer ocean-more severe storms! After a detailed analysis, however, they come to the following conclusion:
These results indicate that currently we cannot attribute changes in North Atlantic hurricane intensity to human related forcings.”
Already in the past there was disagreement among atmospheric researchers about the influence of anthropogenic forcing on hurricane intensity. Levermann did not bother with this last year either, because as a researcher he is undoubtedly informed about the various topics. So the only reason for spreading the false claim remains the climate siren character of the PIK and others.
Here is the abstract from the work of Trenary et al., which appeared in the Geophysical Research Letters on March 4, 2019:
Are mid‐20th century forced changes in North Atlantic hurricane potential intensity detectable?
Abstract: The impact of anthropogenic forcings on tropical North Atlantic hurricane potential intensity (PI) is evaluated in CMIP5 models for the period 1958‐2005. Eleven models are examined, but only seven models have a forced response that is distinguishable from internal variability. The use of discriminant analysis to optimize detectability does not yield a clear, common climate change signal. Of the seven models with a significant response, one has a negative linear trend while two have a positive linear trend. The trend in PI is not even consistent among reanalyses, although this difference is not statistically significant because of large uncertainties. Furthermore, estimates of PI internal variability have significantly different variances among different reanalysis products. These disagreements between models, reanalysis products, and between models and reanalyses, in conjunction with relatively large uncertainties, highlight the difficulty of detecting and attributing observed changes in North Atlantic hurricane potential intensity.
Plain Language Summary: Observed temperature has been steadily increasing over the last century and much of this warming can be attributed to greenhouse gas emissions. Theoretically, the maximum intensity (or potential intensity) a hurricane can achieve depends strongly upon sea surface temperature, with warmer temperatures producing stronger storms. From this perspective, we might expect that the warming surface temperatures are driving observable changes in hurricane intensity. To this end, we analyze climate model experiments to determine if the observed changes in North Atlantic hurricane intensity can be attributed to human related emissions over the period 1958‐2005. Of the eleven models analyzed, we find that only seven predict that hurricane potential intensity has changed in response to greenhouse gas and aerosol emissions. The change in potential intensity differs across models, with one model predicting a decreasing trend in North Atlantic hurricane potential intensity, while two models predict an increasing trend in potential intensity. Different reanalysis datasets are likewise inconsistent. These results indicate that currently we cannot attribute changes in North Atlantic hurricane intensity to human related forcings. It is possible that as greenhouse gas concentrations continue to increase, an unequivocal forced response in North Atlantic potential intensity may emerge in the future.”
Share this...FacebookTwitter "
"The Labour Party’s new plan for a low-carbon Britain breaks new ground. It could offer a lifeline to a clean energy sector hit by the withdrawal of subsidies and, in a radical move, it proposes to put control over energy back in public hands.  It is also timely. The UN Intergovernmental Panel on Climate Change is about to release a special report on the transformative, systemic action needed to keep warming below 1.5℃ (the stated aspiration of the 2015 Paris Agreement), so bold moves are welcome. The report will reinforce the fact that the strategies governments currently have on the table are wholly inadequate and will leave the world on course for warming of 3℃-4℃ with catastrophic consequences. The Labour plan, outlined by the shadow business and energy secretary, Rebecca Long-Bailey, states that by 2030 the party would ensure that 85% of electricity demand is met from renewable and low-carbon sources. The eventual goal is for the UK to get to zero net emissions by 2050.  In his leader’s speech at the party’s recent conference, Jeremy Corbyn said Labour would “kickstart a green jobs revolution” involving 400,000 skilled jobs created by investments in wind, solar, and energy efficiency. Home insulation efforts will be paid for by £12.8 billion set aside from a national transformation fund, in order to address fuel poverty and conserve energy.  These expressions of “green Keynesianism” mark a break with the failure of neoliberal approaches which assume that market and price signals alone can deliver the required changes to the UK’s energy system. In many ways they resuscitate proposals for a Green New Deal that emerged in the wake of the 2008 financial crisis. They send a strong signal to investors about the direction of change – that in future the only viable energy system will be one which is low-carbon. There are ambiguities and potential contradictions here though. The phrase “renewable or low-carbon energy” keeps the door open for the expansion of nuclear, for instance. Trade unions often support an expansion of the nuclear industry because of its potential to generate new jobs and, since becoming leader, Jeremy Corbyn has lent his support to nuclear power. Such proposals remain unpopular with many in the environmental movement, however.  It is also unclear how Labour’s strategy sits with support for other high-carbon infrastructural investments such as the Heathrow airport expansion. Achieving its goals may well also require a suite of other measures including taxes on pollution rather than labour, sharp reductions in fossil fuel subsidies, much stiffer building regulations and fuel efficiency standards for cars, and stronger efforts to drive behavioural change among businesses and citizens – which are not yet on the table. Labour has called its environment policy the “Green Transformation”. Having studied such transformations, I feel that, despite its promise, there is a sense of a missed opportunity with the plan to be more imaginative about energy futures. This might include bolder thinking about decentralised, off-grid, community-owned models of energy provision as well as much more effective strategies to reduce energy demand in the first place.  And there are even greater challenges for the Labour Party. Can it go beyond a paradigm in which, whatever the question, state-led growth is the answer? Could the embrace of the need for green transformations extend to questioning an unflinching commitment to economic growth at all costs? This would mean engaging with ideas which place  well-being and prosperity – not GDP or growth – as the goals to be achieved. This might open the way to seeing radical reductions in the production and consumption of energy as possible and desirable, as well as necessary, to prolong life on a finite planet."
nan
"A company in Scotland has unveiled what it claims is arguably the world’s most technically advanced indoor farm. Intelligent Growth Solutions’ vertical farm uses artificial intelligence and specially designed power and communication technologies. The firm says this reduces energy costs by 50% and labour costs by 80% when compared to other indoor growing environments, and can produce yields of up to 200% more than that of a traditional greenhouse. Vertical farms like this aim to minimise water use and maximise productivity by growing crops “hydroponically” in small amounts of nutrient-rich water stacked in a climate-controlled building. But it’s important to recognise that the increased productivity of indoor vertical farming comes at the cost of much higher energy usage due to the need for artificial lighting and climate control systems. By 2050, global food production will need to increase by an estimated 70% in developed countries and 100% in developing countries to match current trends in population growth (based on production information from 2005-2007). But in countries that already use the majority of their land for farming, this is easier said than done. The UK, for example, uses 72% of its landmass for agricultural practices but imports nearly half of the food it consumes. To improve domestic food security and prevent natural habitats from being destroyed for new farmland, countries such as the UK need to consider new methods of food production. Urban farming presents a unique opportunity to grow food on already developed land, increase domestic food production and minimise the distance food travels. Since the publication of Dickson Despommier’s 2010 book The Vertical Farm: Feeding the World in the 21st Century, vertical farming has become synonymous with urban farming. Although the agricultural skyscrapers illustrated in Despommier’s book are yet to be realised, the idea of growing food vertically has captured the minds of designers and engineers alike. The energy demand associated with vertical farming, however, is much higher than other methods of food production. For example, lettuces grown in traditionally heated greenhouses in the UK need an estimated 250kWh of energy a year for every square metre of growing area. In comparison, lettuces grown in a purpose built vertical farm need an estimated 3,500kWh a year for each square metre of growing area. Notably, 98% of this energy use is due to artificial lighting and climate control. Even with the reductions promised by Intelligent Growth Solutions, the energy demand associated with most vertical farms would still be very high, which positions vertical farming in a grey area. On the one hand, the world needs to produce more food, and on the other hand, it needs to reduce energy use and the production of greenhouse gases.  But indoor vertical farming isn’t the only way to grow food in cities. A plethora of naturally lit methods also exist, from raised beds in communal gardens to rooftop aquaponic systems that grow food with the help of fish. These methods all require less energy when compared to vertical farming because they don’t need artificial lighting.  When viewing cities from above, it is clear to see just how many flat roofs are left vacant and the agricultural opportunities they represent. In the city of Manchester in the UK, unoccupied flat roofs account for an area of 136 hectares, representing one third of the city’s inner urban area. Gotham Greens in New York and Lufa Farms in Montreal, for example, are both commercial farms that use vacant roof space to grow food in naturally lit hydroponic greenhouses. Given the success of such projects and the area of roof space available, it seems strange that so many companies would skip ahead to methods of food production that still need a lot of costly development, as well as more energy to operate. Although they can’t grow as much food, rooftop greenhouses need at least 70% less energy for each square metre of growing area than artificially lit vertical farms. Having designed and built a rooftop aquaponic system myself in an ex-industrial building in Salford in the UK, I am surprised that more companies are not considering and maximising the opportunities presented by naturally-lit urban environments. If nothing else, I believe we should be exploring the potential of naturally lit environments before we delve into dimly lit buildings where special technologies, artificial lighting and air handling units are needed to produce food. There is little question that vertical farms will play a big role in urban farming and agriculture in the future. But when considering any method of food production, we need to understand the impact and energy use of the practice to ensure it is a sustainable and comprehensive response to global food demands. Vertical farming currently requires a lot of energy, which will hopefully decrease over time as companies like Intelligent Growth Solutions make technical advances. But for the time being, the practice of vertical farming is still a long way from being a sustainable method of agriculture."
"
Share this...FacebookTwitterThere’s really not any real doubt about it.
Cities, with their millions of tonnes of steel, asphalt and concrete act as ideal heat-absorbing sinks which take a long time to cool down at night. Just drive on a hot summer night through the country side and into a city makes that very clear.
Yet global warming activist scientists don’t like talking about that because it distracts from their flakey CO2 warming claims.
Now a new study looking at the urban heat island (UHI) effect on London titled “How much has urbanisation affected United Kingdom temperatures?” confirms real impact of the urban heat island effect. The study was published in the Atmospheric Science Letters.
Hat-tip: Reader Mary Brown
Here’s the abstract of the study (emphasis added):

That alone accounts for a very large part of the 20th century warming. But the alarmists certainly don’t want to hear it.
Share this...FacebookTwitter "
nan
"Europe’s Mediterranean regions have strong sunshine, bright blue seas, beautiful beaches, and pretty holiday houses immersed in pine forests that provide welcome shade. It sounds very inviting, but such a scenario is also perfect for severe wildfires such as the ones that killed 99 people this July in the popular holiday resort of Mati, in Greece. Now, new research in Nature Communications suggests that the summer fire season in Mediterranean Europe is going to get worse. Under the hottest climatic predictions of 3°C warming, the area that is currently burned every year would double. Even more worryingly, 40% more area would be burnt even if the Paris Climate Agreement is fulfilled and warming stays below “only” 1.5°C. So, time for Europeans to start looking for other holiday destinations? Hang on. Let´s look at the new study in more depth first. In this modelling exercise, a team of scientists led by Marco Turco, a fire researcher at the University of Barcelona, predict the area that would burn in future summers in Mediterranean Europe following different degrees of warming. They base their approach on the findings of a recent study from some of the same authors, which looked at Portugal, Spain, southern France, Italy and Greece, and established a direct association between the area burnt in the summer months and summer drought in recent decades (1985-2011). They use that “fire-drought” relationship to estimate the area burnt under the drought conditions forecasted in three different warming scenarios (1.5°C, 2°C and 3°C).  The climate obviously has a direct effect on fires, as hotter conditions lead to drier vegetation more susceptible to burning. But the authors also account for indirect effects such as drier conditions reducing plant growth, meaning there is less vegetation to “fuel” the fires. This “non-stationary” climate-fire modelling is important because if the indirect effects were not considered the predictions of area burnt would be even higher. So, are Turco and co-authors right? Will the future look blacker for the Mediterranean? Will tragic events, like those in Mati, become more frequent? Turco’s predictions, even if in many ways the most advanced to date, still carry a huge uncertainty, but they add to the growing list of studies that forecast more Mediterranean fire activity in future. What their study is unable to predict is the influence of perhaps the most important factor behind the future occurrence of fires, also the very same factor that is responsible for accelerated climate warming: humans.  Humans are the main source of ignition in most of the Mediterranean, and the main modifiers of vegetation cover. Including them (or us) in scientific models of fire is very challenging, and can radically change the results. For example, at the global scale, models that rely on climate change tend to predict a very substantial increase in area burnt – a hotter world means more fires, as you’d expect. But when human effects are incorporated, the estimated total area burnt can actually decrease to levels even below current ones. This is essentially because more and more land worldwide is being urbanised or converted to agriculture, resulting in smaller and more fragmented “wildland” areas that can burn. We still have plenty to worry about, however, as global averages form only a small part of the story. In some parts of the world, such as Canada and the US, the area burned is already on the increase. Meanwhile, some houses are being built further into forests and other flammable vegetation, while other houses are finding themselves now surrounded by vegetation as nearby fields are abandoned and left to nature. Both situations leave more people exposed to fires. In Mediterranean Europe the situation is particularly complex as the ongoing abandonment of traditional land uses is changing the vegetation more dramatically than climate change. Intensely grazed or cultivated land is becoming overgrown with shrubs or replaced with fire-prone forest stands, a trend that makes the landscape more flammable. This, combined with climate warming, can provide the perfect recipe for fire disasters. For example, Greece has seen less than half the area burned so far this summer than the 2008-17 average), but lots of dry vegetation for fuel, strong winds and a high population density combined to cause Greece’s deadliest fire on record. The future of fire in Mediterranean Europe ultimately depends on the decisions we make. That means complying with the Paris Climate Agreement to reduce global warming but also adapting effectively to the increased risk of fire. And this does not necessarily mean suppressing all fires, which is often not possible, but managing the fuel and how we live among it. Policies aimed at removing fire completely from the landscape have long proven to fail, even if many countries still follow them.  Instead we need to create fire-resilient landscapes and fire-resilient societies. A holiday house in the middle of a pine forest may sound idyllic, but it can be a death trap when a fire occurs, and the study by Turco and his co-authors suggests that this will be even more likely in the future."
"
Share this...FacebookTwitterHigh profile German meteorologist Donald Bäcker recently told an audience that there remains great uncertainty as to what is really behind climate change. He told the biggest problem the planet faces is waste, particularly plastic in the oceans.

Hat-tip: Hallolindenlimmer.de
Donald Bäcker regularly gives his weather forecasts on flagship German public television and spoke in an entertaining way before an open-minded and very interested audience in the Ihme Centre in Hanover.
The lecture lasted two hours and the videos posted at Hallolindenlimmer.de show the climate excerpt of it.
Plastic pollution a greater problem
The topic of climate change was emphasized in his lecture under the title: “Is our climate going crazy?” Bäcker rejected climate panic and recommended to the climate striking pupils to go back to school and learn.
His conclusion on the climate debate: “Plastic in the sea is worse”.
On climate he told the audience that it is very difficult to figure out what part man plays and what natural factors play in the complex system of climate.  At the 5:30 mark of the 32-minute video excerpt, he told that rolling back CO2 is not going to save us and that the worst problem is plastics and coping with the population growth.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Too many people living in naturally hazardous areas
Concerning natural disasters hitting populated areas, he tells the audience that it’s not climate change causing the tragedies, but rather people living in hazardous areas.
“Dangerous” to declare climate science settled
He also criticizes the climate discussion and calls the claims that the discussion is over and that CO2 is the main driver today  “dangerous”. Bäcker points out that predictions made by climate scientists in 2000 that Germany would dry out have turned out to be wrong.
At the 14-minute mark he warns that the climate model predictions are lacking in quality and that climate scientists know their predictions will be forgotten 30 to 40 years down the road. He reminds the audience how scientists warned in the 1970s of a coming ice age, which today we know never showed up.
At the 16-minute mark, Bäcker reminds the audience that renewable energies like solar are not what they are cracked up to be, saying that the production of solar modules “is very energy intensive” and more damaging to the environment than we are led to believe.
Today’s climate not unusual
When questioned about the “dramatic” situation in the Arctic, Bäcker remined that this is not an unusual situation in that people once settled in Greenland 1000 years ago and how the climate back then was warmer than it is today.
No consensus
At the 18:00 mark he sharply criticizes the notion that the science is settled and finds it disturbing that people who present alternative explanations get dismissed and labelled as nuts, and shut out by the press. He adds that there is in reality no consensus and there are scientists out there who don’t agree.
Share this...FacebookTwitter "
"The ninth circuit court of appeals ordered dismissal of a lawsuit brought by 21 youth plaintiffs against the federal government over climate crisis, citing concerns about separation of powers. The case was brought against the government in 2015, charging that it sanctioned, permitted and authorized a fossil fuel system that compromised the youth plaintiffs’ civil right to property. It implied a constitutional right to a stable climate, and alleged that the government violated the public trust by failing to protect assets held in trust, notably the atmosphere.  The plaintiffs, now all between the ages of 12 and 23, also asked the US district court of Oregon to order the government to craft a climate remediation plan, one targeting scientifically acceptable standards to stabilize the climate. On Friday, the ninth circuit court found, however, that the court lacked the power to enforce such a plan or climate policy decisions by the government and Congress, concluding “in the end, any plan is only as good as the court’s power to enforce it”. Nevertheless, the court found that the record “conclusively establishes that the federal government has long understood the risks of fossil fuel use and increasing carbon dioxide emissions” and “that the government’s contribution to climate change is not simply a result of inaction”. The court also found that the youth met the requirements for standing in the case and that some of the plaintiffs met the requirements for actual injury. Levi Draheim, a 12-year-old plaintiff from Satellite Beach, Florida, the court found was injured by repeat evacuations from his home during worsening storms. Jaime Butler, 19, was injured by displacement from her home because of water security issues, separating her from relatives in the Navajo Nation, the court also found. The court also found that the plaintiffs proved their injuries were caused by the climate crisis. Two of the three judges balked at the scope of change required to reverse climate breakdown, finding that halting certain programs would not halt the growth of carbon dioxide levels in the atmosphere or injuries to the plaintiffs. “Indeed, the plaintiffs’ experts make plain that reducing the global consequences of climate change demands much more than cessation of the government’s promotion of fossil fuels. Rather, these experts opine that such a result calls for no less than a fundamental transformation of this country’s energy system, if not that of the industrialized world … given the complexity and long-lasting nature of global climate change, the court would be required to supervise the government’s compliance with any suggested plan for many decades.” Kelsey Juliana, the 23-year-old named plaintiff in Juliana v United States and a resident of Eugene, Oregon, said she was “disappointed that these judges would find that federal courts can’t protect America’s youth, even when a constitutional right has been violated”. “Such a holding is contrary to American principles of justice that I have been taught since elementary school,” Juliana added. “This decision gives full, unfettered authority to the legislative and executive branches of government to destroy our country, because we are dealing with a crisis that puts the very existence of our nation in peril.” “We will continue this case because only the courts can help us,” Draheim told the Guardian following the ruling. “We brought this lawsuit to secure our liberties and protect our lives and our homes. Much like the civil rights cases, we firmly believe the courts can vindicate our constitutional rights and we will not stop until we get a decision that says so.” District Judge Josephine L Staton, in a lengthy dissenting opinion, argued that courts do have the authority to protect the young in the face of climate breakdown, and should, given the government’s inaction: “In these proceedings, the government accepts as fact that the United States has reached a tipping point crying out for a concerted response – yet presses ahead toward calamity. It is as if an asteroid were barreling toward Earth and the government decided to shut down our only defenses. Seeking to quash this suit, the government bluntly insists that it has the absolute and unreviewable power to destroy the nation.” The court ordered the case be remanded to the district court and dismissed."
"
Share this...FacebookTwitterBy Kirye
and P. Gosselin
We often hear how the climate is changing everywhere, like in California.
Listening to the media we get the impression that the Golden State is drying out and risks burning up, before heavy rains hit. Others claim the state is facing “weather whiplash” because climate change will make the weather more extreme and volatile.
Today we take a look at the precipitation data of 7 stations spread across the state to see what changes have been happening. Used here are the data from the Japan Meteorology Agency (JMA) that cover the last 33 years.

Data: JMA.
As we can see, there has been no trend over the past 30 years. Variability also appears unchanged. California has always been a state characterized by alternating periods of drought and rainfall influenced by oceanic cycles like ENSO. The data show everything is within the normal range.
The real trend is the massive increase in media climate ambulance chasing where every anomaly gets hyped into something much more than it really is.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterTwo more new papers add to the voluminous paleoclimate evidence that most of the last 10,000 years were much warmer than modern. 
The globe was about 4 to 6°C warmer than it is today between 9000 and 6000 years ago, when CO2 concentrations centered around 265 ppm.

Image Source: ScienceDaily.com
Some regions exceeded the 4 to 6°C global average.
Northeastern China, for example, has been determined to have been between 7-10°C warmer than today during the Early Holocene (Liu et al., 2019, Zheng et al., 2018, Peterse et al., 2014, Jia et al., 2013, Gao et al., 2012).
New paleoclimate evidence even suggests  the 19th century may even have been ~1.7°C warmer on average than the 20th century in this region (Jiang et al., 2019).
Of course, none of these temperature values are consistent with the claim that the Earth’s surface temperatures are significantly determined by changes in atmospheric CO2 concentrations.


Image Source: Liu et al., 2019


Image Source: Zheng et al., 2018



Image Source: Jiang et al., 2019
Share this...FacebookTwitter "
"The Trump administration wants to make it easier for the oil and gas sector to release methane into the air, according to a report in the New York Times. As atmospheric scientists, we are well aware of the dangers this poses for both global climate change and more localised air pollution. Methane is already the second most abundant greenhouse gas that is released from human activities. “Natural gas”, for instance, refers to a mixture dominated by methane. It has become steadily more concentrated in the air since the 18th century, more than doubling from around 750 parts per billion (ppb) to more than 1,850 ppb today. Like carbon dioxide, methane absorbs infrared radiation and warms the atmosphere. Although there is much less methane in the air than CO₂, the strength of that absorption is such that per molecule it is around 25-30 times more potent as a greenhouse gas. It is a complicated gas to predict and manage since it is released from multiple sources. Some are natural processes, such as emissions from wetlands and bogs, methane that bubbles up through the ocean, or even through termite farts. But many different human activities also result in methane being released. Flooded rice paddies produce lots of methane, as do cow and sheep stomachs, while the gas is also released from waste buried in landfills.  The largest anthropogenic source of methane, however, is the extraction and distribution of natural gas. According to the New York Times report, the US Environmental Protection Agency is set to relax a series of rules on methane emissions currently imposed on the US oil and gas industry, including a reduced frequency in checking for leaks and an extended grace period before repairs must be made. Such changes would add to a recent repeal of Obama-era US rules that required waste gas to be captured rather than vented or burned. This comes at a time when America’s methane consumption is increasing, largely because the amount of natural gas (often from fracking) burnt to generate electricity nearly doubled between 2005 and 2015. Global demand also continues to climb while oil and coal consumption have fallen over the past decade. Quantifying emissions of methane from the US oil and gas sector has been a topic of considerable research. Oil and gas producers and distributors make estimates of their emissions based on complex calculations that account for amounts lost during activities such as drilling, venting and flaring, plus any gas that seeps out from the millions of joints, pipes and connectors that make up the natural gas network. These estimates are then supplemented by in-field tests, spot-checking and monitoring for emissions near the source.  Scientists have also measured plumes of natural gas as they waft away from oil and gas installations using aircraft, and have detected methane over large areas from satellites. In general, these sorts of research methods have shown more methane is being emitted than industry-reported figures. Recent increases in emissions arising from US natural gas extraction have been detected far from their sources, inferred from trends in other trace gases. Natural gas is not pure methane – it also contains small amounts of other hydrocarbons, such as ethane or propane. However, unlike methane, these gases have relatively few other anthropogenic sources, so act as excellent tracers of methane from the fossil fuel industry. Observatories as remote as Cape Verde in the tropical North Atlantic or the Jungfraujoch high in the Swiss alps detected an upwards trends in ethane that coincided with the US fracked gas boom, a smoking gun that showed US emissions of methane were growing. Methane and the other hydrocarbons in natural gas, like ethane and propane, also create ozone pollution in the lower atmosphere when mixed with nitrogen oxides from combustion. Ozone harms people by causing the muscles in the airways to constrict, aggravating lung diseases such as asthma, emphysema and chronic bronchitis. It also limits plant growth and reduces crop yields.   High summertime ozone pollution events are an established phenomenon in southern US oil and gas producing regions, but they are now also found during winter in fracking locations in more northern states. While the current proposal for scaling back regulation of methane emissions has been framed, at least for now, as a roll-back of Obama-era climate policy, it has the potential to also increase concentrations of short-lived air pollutants as well.  The US has extensive regulations to control surface ozone pollution at national and state level. This pollution, particularly in national parks, has historically been taken seriously. Any change in industrial policy that may increase the overall amount of natural gas released to air has the potential to lead to degradation in ozone air quality, both in the US and in regions downwind. The extent of the effects could only be calculated using complex atmospheric simulations, but if shown to be significant, any legal challenge to such a change could well be based on likely air quality effects rather than climate change."
"If you were to visit the English countryside 15 years ago, you would have found nine times as many small farms as you do today – and twice as many different farms in general.   For years, farmers across the UK have received subsidies on a per-hectare basis without any requirement to use that land to actually produce food as part of the European Common Agricultural Policy. This means that wealthy owners of large estates have been given large sums of taxpayer money simply for owning land, without necessarily farming it. It’s a system that has long been criticised – and rightly so. With Brexit looming, the UK government’s Department for Environment, Farming and Rural Affairs (Defra) has recently introduced an Agriculture Bill and draft policies. It proposes paying landowners for delivering environmental benefits such as improved air quality or habitats for wildlife, an approach that has been understandably praised by environmental groups.   But, while this all sounds rather green, there is little evidence that the government will support, let alone require, farms to integrate ecology with food production. It appears that landowners will receive support for either increasing productivity, or improving the environment – but not necessarily both at the same time. This either-or approach could usher in a new era of environmentally destructive “megafarms”. There has been a rapid increase in the number of these farms in recent years – for both animals and crops. Britain’s first intensive poultry farm was approved in 2003 – and there are now more than 1,400 permits for these operations, the largest of which can “process” more than a million chickens per week. Similarly, the number of high-intensity horticulture operations is increasing, with government grants supporting efforts to produce vegetables without soil. Megafarms have been responsible for pollution to rivers and waterways. Animals are often fed with imported corn and soya, the majority of which is genetically modified to withstand high doses of the controversial herbicide glyphosate. Industrial-scale horticulture operations tend to rely on imported minerals for plant feed, use significant amounts of energy for heating and produce a low diversity of crops. Research shows that conservation areas cannot make up for the environmental damage of intensive farms. Even if megafarms were interspersed within vast landscapes of parks and woodlands, it still wouldn’t help. But given the government’s intention to improve the environment, why would this happen? As area-based payments are phased out, Defra expects that many farmers will leave the sector. The assumption is that as farmers exit, land will be freed up for new entrants. But across the UK farm land is now seen as a safe shelter for wealth – recommended by estate agents as a “tax-efficient” investment. This contributes to the high and rising cost of land, arguably more than land-based subsidies. Without addressing this, it is likely that, as farmers leave, land will be bought by investors and by large farm businesses, continuing the current trend of consolidation and rising farmland prices. Young farmers and other new entrants might be desperately needed to reverse the UK’s declining farming population, but they will continue to struggle to get hold of land. One of the main reasons why megafarms have become popular and smaller farms have gone under is because farms only receive a small fraction of the retail value of food. Combined with low agricultural commodity prices, it is nearly impossible for farmers to earn a living from the food they produce. The Agriculture Bill does propose some new powers to collect data about the supply chain, a move which should mean more transparency but which is unlikely to result in farmers receiving significantly more money. If landowners are paid for protecting the environment, but receive little for food production, there is a good chance that farm land will be used for conservation, not farming. Until the UK can restructure its supply chains, it needs to keep supporting farmers to produce food. The alternative is for the country to increase its already high reliance on imports – but research has shown this could undermine food security and safety. To improve productivity, Defra has emphasised automation, drones and “precision farming” in its consultation paper. Yet these technologies favour uniformity and are best suited to high-intensity, large-scale farms that focus on producing one or two foods and use lots of resources. Low-tech practices such as growing different crops in the same space (poly-cropping) or agroforestry can increase yields of diverse foods and regenerate soil, all while minimising harmful inputs. This could help support existing farms which have struggled with long-term soil deterioration and feel “locked-in” to using certain agro-chemicals. But these approaches are knowledge-intensive and take time to implement. Without support for them it is likely that farmers will continue to either leave the business or intensify. The shift towards megafarms is not inevitable or necessary. Defra has included some measures to support ecological and human-scale farming, such as a nod towards reducing pesticide use, and a support for County Farms which can help new entrants. However, much more is needed to ensure that farming and the environment are truly integrated."
"
Share this...FacebookTwitterA significant number of scientists say that the Earth’s climate is in large part impacted by solar activity, and less so by trace gas CO2 concentration. German scientists present new findings showing a link between solar activity and precipitation in Europe.
=================================================
How Changes on the Sun Influences Rain
A balanced level of precipitation provides the basis for a wide range of economic and social activities in Europe. Particularly agriculture, drinking water supply and inland waterway transport are directly affected. However, the amount of rain fluctuates strongly from year to year. While it may pour torrentially in one year, rain may remain absent for weeks in other year. The population is used to this variability and usually knows how to deal with it.
But what is behind the strong changes? A system, or pure atmospheric noise?
The chance discovery by an agricultural scientist from Münster, Germany, now suggests that in certain months that rain over Germany and other parts of Europe follows a pattern that up to now has remained undetected. As part of agricultural consultation, Ludger Laurenz analyzed decades of rainfall records of the weather station in Münster and noticed a constant up and down that followed an 11-year rhythm – especially in February.

Fig. 1. February precipitation in Germany compared to changes in sunspots. Shown is the optimum positive correlation (r = 0.54) with a solar lag of +17 months. Solar cycles are numbered 14–24. The probability that the correlation r = 0.54 is by chance is less than 0.1% (p < 0.001). Source: Science Direct.com. 
After detailed examination it was clear that this rhythm correlated closely with the activity of the sun: the well-documented 11-year sunspot cycle.
Europe data examined
Laurenz next teamed up with two colleagues to examine the extent to which the observed pattern from Münster is reproducible in other parts of Germany and Europe, and whether the phenomenon also exists for the other months of the year. Horst-Joachim Lüdecke from the HTW University of Applied Sciences in Saarland gathered the precipitation data collected in Europe since the beginning of the 20th century. The physicist emeritus then developed a computer algorithm to determine the similarity of changes in rainfall and solar activity. All 39 European countries and every one of the 12 months of the year were quantified over a total of 115 years using mathematical correlations.

Fig. 3. Map showing the 1901–2015 most positive correlation coefficients for February precipitation and sunspots on a country-by-country basis. Pearson r values from Table 1. All maps: Lags are simplified and generally fall within ±10 months of the statistically calculated value (Table S1). Source: Science Direct.com. 
In order to include possible delay effects, the data series of rain and sunspots were systematically checked for shifts. For this purpose, the time series were gradually shifted in time against each other like combs and the respective change of the correlation measure was noted. The multidimensional data obtained in this way were evaluated for systematic trends by geoscientist Sebastian Lüning and visualized cartographically. Lüning is associated with the Swiss Institute of Hydrography, Geoecology and Climate Sciences (IFHGK) and is specialized in the research of solar climate effects.
February northern Europe precipitation linked to solar activity
The mapped out results show that the link between February precipitation and solar activity originally discovered in Münster is valid for large parts of Central and Northern Europe and has very high statistical significance there. Towards southern Europe, however, the correlation weakens significantly.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




4-year shift for February Central Europe precipitation
The statistical investigation was also able to demonstrate systematic phase shifts across the continent. In Germany and neighboring countries, February precipitation was particularly low when the sun was very strong four years earlier. The delay seems to be due to the slow deep circulation of the Atlantic, as earlier work suggests. On the basis of the statistically-empirically determined correlation, February 2018 in Germany with particularly low precipitation can now also be explained, which followed a particularly high intensity peak of solar activity at the beginning of 2014.
Solar signal found in other months
Similar relationships between rainfall and solar activity have been observed in a weakened way in some other months, especially in April, June and July, which account for a large part of the vegetation period in Central Europe. The result was a complex picture of the interplay of sun and rain in Europe, which showed clear trends over 1000 km and varied strongly from month to month.
Mechanism remains unclear
The study thus confirms the concept of a solar participation in the European hydroclimatic development, which had already been indicated by a whole series of local case studies of other authors. However, the exact mechanism by which the solar signal influences precipitation is still largely unclear and requires further research.
Ocean cycles also at play
The solar precipitation effect, which has now been mapped out across Europe for the first time, opens up new possibilities for improved medium-term precipitation forecasts. Agriculture in particular, but also for defense against extreme weather damage in connection with heavy rainfall and droughts, could benefit from this.
The next step in refining the forecasting methodology is a more precise quantification of the effects of Atlantic Ocean cycles, which also play an important role in rainfall, especially in Western Europe.
Original publication:
Laurenz, L., H.-J. Lüdecke, S. Lüning (2019): Influence of solar activity on European rainfall. J. Atmospheric and Solar-Terrestrial Physics, 185: 29-42, doi: 10.1016/j.jastp.2019.01.012
The pdf version can be downloaded free of charge at the following link until early March: https://authors.elsevier.com/a/1YXWZ4sIlkiVhv
Contact:
Prof. Dr. Horst-Joachim Lüdecke
Hochschule HTW des Saarlandes
moluedecke@t-online.de
Dr. habil. Sebastian Lüning
Institut für Hydrographie, Geoökologie und Klimawissenschaften (IFHGK), www.ifhgk.org
luening@ifhgk.org
Tel. 00351-961470494
Share this...FacebookTwitter "
"Jane Shepherdson was once named the most powerful woman in British fashion. As the boss of Topshop when it ruled the high street and delivered £100m in profit a year for Philip Green’s Arcadia retail empire, she was the high priestess of fast fashion. But times have changed: Shepherdson now wants us to ditch the shopping bags and get our style fix by renting everything from dresses to sunglasses and shoes instead. Shepherdson, who revamped the Whistles fashion chain after leaving Topshop in 2006, is now chair of My Wardrobe HQ, a designer fashion rental and resale website, which next month opens a pop-up in London department store Liberty. The tie-up is part of an emerging trend for secondhand and rented clothing which is becoming not only acceptable but desirable. Liberty claims to be the first UK department store to host a peer-to-peer fashion rental pop-up, following a partnership between Nordstrum and Rent the Runway in the US. But the idea is in the same vein as Selfridges hosting pop-ups by fast-growing vintage vendors Depop and Vestiaire Collective and online designer store Farfetch testing Second Life, a handbag resale service. “People are becoming more comfortable with wearing things other people have worn and not necessarily seeing it as second rate,” says Shepherdson. Concerns about the environmental impact of fashion, which contributes more to climate change than the aviation and shipping industries combined, are expected to drive a boom in rentals. The UK market is expected to grow more than fivefold to £2.3bn by 2029 from an estimated £400m last year, according to analysts GlobalData. Peer-to-peer lenders such as My Wardrobe HQ and Hurr, where those with an over-stuffed wardrobe rent out items to those on a budget, are expected to lead the way, outstripping traditional players such as Moss Bros or newer online platforms such as Girl Meets Dress or Hire Street. On My Wardrobe HQ at present, fashion lovers might choose a floral satin dress from The Vampire’s Wife label for £110, a Gucci military coat for £295, a pair of Michael Kors biker boots for £40 or a Herve Leger sequinned bodycon mini for £215. All rentals last a week and customers who fall in the love with their items can buy them outright. Shepherdson says she got into the idea of peer-to-peer rental after taking nearly a year off living out of Airbnb homes in the US after quitting Whistles in 2016. “I came back at the moment when it was suddenly becoming more and more apparent about what a massive polluter fashion is. I thought I’ve filled all my life with making fashion more compelling and there’s some massive back-peddling required.” “I thought about peer-to-peer renting and why couldn’t it be exactly like Airbnb, where people could attract each other and buy into someone’s lifestyle. “I’m not a hypocrite. I want people to enjoy fashion. Rental is a totally guilt-free way to wear the most beautiful dress and it’s not out of reach for people.” A £1,000 dress might rent for £100, which is not exactly cheap, but accessible to anyone who can afford a big night out with cocktails, dinner and a cab home, she says. Shepherdson began by trying to start her own site but then met Sacha Newall and Tina Lake, who founded My Wardrobe HQ in June 2018, combining their experience in online fashion, car sharing, online marketplaces and women’s magazines: “It felt like a business that could scale.” My Wardrobe HQ works by managing the whole rental process, including photography, delivery, cleaning and payment, for its clients. About half the items on offer come from individuals, half from brands.  Shepherdson says she is now in discussions with brands about producing collections specifically for rental. “Why not? It’s obviously a change but it’s just sharing a bit more, making sure you get away from that thing of buying something, wearing it once and moving on.” She says the idea is particularly appropriate for luxury womenswear. Ski-wear, occasion wear, maternity clothing and childrenswear are other areas Shepherdson thinks are ripe for rental. While Shepherdson says it’s unlikely she’ll go back to leading a fashion chain unless it’s one with strong sustainability credentials, she rues the troubles at Topshop and its fellow fast-fashion chains, particularly the loss of good jobs for young women. “It’s sad but there is a certain inevitability to it. Everything has changed, the whole approach to shopping. If you look at the retailers having a difficult time, most are based on bricks and mortar shops. “I still love going shopping but you have to create theatre, something worth coming in for, to get people off the sofa.”"
"We applaud the rise in state-sector intake across Oxford University and are glad to see individual colleges praised (Report, 16 January). Perhaps Mansfield College deserves a mention. In a quietly radical fashion, we have led the way in Oxford access for 20 years. Our state intake has been over 80% for 10 years and over 90% since 2016. And more than 90% of our state-sector intake this year is from non-selective schools – a meaningful statistic for Oxford University.Lucinda RumseySenior tutor, Mansfield College, Oxford • Some years ago I attended a clergy conference in Wales, where an American visitor was using air purification processes as analogies for how parish priests should safeguard themselves in particularly toxic situations (Letters, 17 January). “It is vital,” he declared, “to ensure you have quick access to the right sort of scrubbers.” The laughter that followed was memorable.Rev Canon (Retd) Adrian CoppingWoolpit, Suffolk  • In his 1951 revue number Don’t Make Fun of the Festival (Editorial, 16 January), Noel Coward was far from defending the Festival of Britain, but rather, like Evelyn Waugh, caustically attacking it. The song’s final lines are “We believe in the right to strike / But now we’ve bloody well got to like / our own darling Festival of Britain.”Adam PollockGreenwich, London • The headline on Gaby Hinsliff’s article (Journal, 15 January) is “Driving in cities should become as antisocial as smoking”. Surely it already is; the point is for it to be recognised as such.Albert BealeKing’s Cross, London • In St Albans in the 1950s, my sister and I hammered on the back door of the King Harry pub to buy Marmite-flavoured crisps (Letters, 15 January). Our treat of the week.Sue PhillipsSalisbury, Wiltshire • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
nan
"The world’s climate scientists have spoken: if we want to limit human-induced global warming to 1.5℃ we probably can. But it will be tough, given where we’re starting from. That’s the conclusion of a new report by the UN’s Intergovernmental Panel on Climate Change (IPCC). The focus on 1.5℃ is the result of years of international negotiation. Starting in 1994, a central aim of the UN’s climate change efforts (the Framework Convention on Climate Change, or UNFCCC) was to stabilise greenhouse gas concentrations at a level that would “prevent dangerous anthropogenic interference with the climate system”. Much was written on what this meant, particularly the word “dangerous”.  Negative impacts of climate change occur on a continuum, and defining a point at which climate change becomes dangerous is difficult and contentious. On the other hand, climate change negotiations are difficult without some target to work towards. Fifteen years later, the UNFCCC’s Copenhagen Accord introduced a 2℃ target, and its 2015 Paris Agreement was even more specific: it “aims to strengthen the global response to the threat of climate change … by holding the increase in … temperature to well below 2℃ above pre-industrial levels and pursuing efforts to limit the … increase to 1.5℃”. The IPCC provides scientific advice to the UNFCCC, which makes policy, and the IPCC itself has never stated a temperature target. It does however list climate change risks using five “reasons for concern”. These include impacts such as “unique and threatened ecosystems and cultures” (such as coral reefs) and “extreme weather events”, each of which is rated on a scale from “undetectable” to “very high”. The IPCC’s most recent (2014) Fifth Assessment of the scientific evidence found that at around 1.5℃ warming there was a transition from moderate to high risk for threatened ecosystems and cultures and for extreme weather events. Thus there is consistency between the Paris and IPCC assessments. The Paris Agreement asked the IPCC to report on the impacts of global warming of 1.5℃, and this new publication is the result. Its tone is not “we must avoid 1.5℃ warming”, as you might think from many commentators, but more “if we want to avoid 1.5℃ warming, this is what must be done”. The report contrasts the impact of 1.5℃ and 2℃ warmings, giving information on what would be gained by the extra effort needed to limit warming to 1.5℃. As the IPCC’s reports are largely based on a critical assessment and synthesis of published scientific papers, many of its latest conclusions are unsurprising. There are many well recognised uncertainties in understanding climate change - for instance, even if we set a course aiming to hit 1.5℃ (which is mostly determined by future CO₂ emissions), we could end up hitting, say, 1℃ or 2℃ instead. The report provides uncertainty ranges in its estimates and confidence levels, based on expert judgement. The new report tells us that human activity has already caused about 1℃ of global warming, while at the present rate of warming (0.2℃ per decade) we’ll hit 1.5℃ by about 2040. National pledges made as part of the Paris Agreement still mean we are on course for warming of about 3℃ by 2100, meaning four of the five “reasons for concern” would then be in the high to very-high risk category.  Achieving the 1.5℃ target will require anthropogenic CO₂ emissions to decline by 45% by 2030 (relative to 2010). By 2050, they will need to reach “net zero” - any further CO₂ emissions due to human activity would then have to be matched by deliberate removal of CO₂ already in the atmosphere, including by planting trees. Net zero would have to occur by around 2075 to meet a 2℃ target. Many illustrations are given for the difference between 1.5℃ and 2℃ worlds. At 1.5℃, summertime Arctic sea ice is projected to disappear once per century, compared to once per decade at 2℃; 8% of plants that have been studied would lose half their climatically-suitable area, compared to 16%; sea level rise would be 10cm less (with 10m fewer people impacted at today’s population levels); and while coral reefs might decline by a further 80% at 1.5℃, they could virtually disappear at 2℃. The report identifies various routes by which emissions cuts would limit warming to 1.5℃; each makes assumptions about future changes in, for example, economic strategy, population growth and the rate at which low carbon energy is adopted. The IPCC recognises the challenges are “unprecedented in scale” but notes, for example, “the feasibility of solar energy, wind energy and electricity storage mechanisms have substantially improved over the past few years”. The report is sensitive to the fact that changes required to meet 1.5℃ must be consistent with the UN’s wider sustainable development goals. Limiting climate change will help meet goals associated with health, clean energy, cities and oceans. But there are potential negative impacts on others (poverty, hunger, water, energy access) “if not carefully managed”. So where next? Of course, the conclusions will be widely debated at many levels, but eyes will be on the UNFCCC’s response at its next meeting, in Katowice, Poland, in early December."
"For more than half a century, the indigenous Kaiowá and Guarani people of Brazil have been deprived of their ancestral lands, and consigned to small reserves where it is impossible to maintain their traditional livelihoods. Generations of these indigenous peoples’ lives have been marked by violence and vulnerability as they have tried to reclaim what, according to the Brazilian constitution, is rightfully theirs. And now we have found that increasing globalisation is posing an urgent threat. In March 2018, as part of the Global-Rural research project based at Aberystwyth University, we visited the Kaiowá and Guarani people who live near Dourados, in the southwestern state of Mato Grosso do Sul. We investigated how increasing worldwide intergration is impacting the Brazilian countryside, and explored the ways in which the Kaiowá and Guarani peoples’ lives are being affected by the intensification and expansion of industrialised agriculture production used for foreign markets.  We spoke to indigenous leaders and families based in several Kaiowá and Guarani villages across the municipalities of Juti, Rio Brilhante, Dourados and Caarapó, and found out the devastating consequences of globalisation on their way of life. The first dispossession of Kaiowá and Guarani indigenous lands took place at the end of the 19th century, when the Brazilian government gave five million hectares to the Mate Laranjeira Company. Under the pretext of defending the interests of the native peoples, the state also founded the SPI (Indian Protection Service), which created indigenous land reserves. Different ethnicities (the Kaiowá, Guarani, Terena and others) were forced to live together in these reserves, despite historical hostilities. They were catechised, taught to communicate in Portuguese (and strongly discouraged from using their native languages) and became assimilated as “Brazilians”. There was not enough space in the reserves for the people to continue hunting, and use the local natural resources for their subsistence as they had done traditionally, so they were forced to learn the professions of the non-indigenous. In the 1980s, after the military dictatorship, when Brazil was engaging in a re-democratisation process, the Kaiowá and Guarani found themselves at a crossroads. They would cease to exist if they continued to live on the reserves, or they could leave and reoccupy their ancestral lands to preserve their culture, roots and livelihood. In choosing the latter option, they faced armed ranchers and farmers who would defend private property at any cost. And so began the worst human rights violations and violence against the Kaiowá and Guarani peoples to ever occur.  Though the Brazilian Federal Constitution guaranteed indigenous people the right to the land in 1988, it also established a limit of ten years to demarcate and hand over the land, and compensate farmers. Now, after 30 years, the demarcation process is far from completed.  Since the early 2000s, land reoccupation conflicts have intensified. According to one survey, some 258 Kaiowá and Guarani leaders were murdered in Mato Grosso do Sul between 2003 and 2011. These ongoing violent conflicts, the displacement and the ongoing genocide of the Kaiowá and Guarani have been internationally denounced. Yet, even though it has received global attention, it is still seen as only a local problem. One of the main reasons why the land conflicts haven’t been resolved is down to the value of agribusiness. Farming is championed as the flagship of the Brazilian economy, with increasing portions of lands being used to intensify industrial and mechanised agriculture. In the last ten years, this sector has grown further, along with the exportation of commodities, especially soy. Brazil has been declared a global agribusiness powerhouse, and praised for supplying the “four Fs” – food, feed, fuel and fibre – to the world.  While we were in Brazil, we saw the everyday threats of living in a contested territory surrounded by industrial plantations. We witnessed three occupied villages near Dourados being evicted, to make way for large scale monocultures (where one crop is grown). Though the Kaiowá and Guarani were there protecting their lands with indigenous rituals, they still expected the worst to happen – and so did we. We prepared an escape plan with the people, whereby we researchers would save the children if military troops arrived. Although the eviction was ultimately postponed, this shows how the Kaiowá and Guarani live in constant fear of being removed from their land, of being intoxicated by the contaminated water, air and soil, of been killed.  During our research, we also visited families who had been evicted from reoccupied areas due to agribusiness expansion, and left with no land. Squeezed between sugar cane, soy and corn plantations, they were ousted to the sides of roads.  We spoke to an indigenous leader, who was living at the edge of a road, driven from her indigenous land. She cried over the death of her husband and son, which were due to land conflicts, and lamented the health problems that came from chemicals put by agribusiness on the land. She mentioned that the children specifically had increasingly experienced headaches, stomach problems and sickness, which they believed was due to water contamination – and that some of them had lost their lives. She told us of the challenges to her people’s livelihood and the unbearable situation to which they are now condemned. One of the indigenous leaders claimed “Europeans should know that in the bio-ethanol they are importing from Brazil they will find our blood”.  While, sugar cane, soy and cattle take over the landscape in the southwest of Mato Grosso do Sul, it is impossible to ensure a healthy livelihood for the Kaiowá and Guarani. They have no access to drinkable water, no protection from agro-chemical contamination, and no adequate conditions for planting, hunting or fishing. The conditions are violent and the Kaiowá and Guarani people are in a precarious position. In the name of global development, progress and sustainability, the silent genocide of one of the largest ethnic groups in the country is taking place. “Earth, life, justice and demarcation!” – the cry of the Kaiowá and Guarani people."
"
Share this...FacebookTwitterAs the pressure mounts in Germany to switch off coal power plants and to rapidly transition over to green energies, one gets the feeling that it all has more to do with a desperate, last-ditch effort by the green energy proponents to rescue their pet green project.
Photo right: Energy expert, Dr. Björn Peters. Image: Deutscher Arbeitgeberverband 
Hat-tip: Die kalte Sonne
Recently, Der Spiegel wrote about how Germany’s once highly ballyhooed Energiewende (transition to green energies) has turned out to be a botched project. Then Michael Schellenberger at Forbes commented that the laws of physics tell us it was never meant to work in the first place.
Behind closed doors, no one in Berlin believes in it
Now, just days ago, energy expert Dr. Björn Peters wrote at the German Association of Employers site that the Energiewende has deteriorated to the point that: “No specialist politician in Berlin believes in the success of the Energiewende any more. Whoever you ask, everyone says this only behind closed doors and thinks that if you go to the press with it you can only lose against the ‘green’ media mainstream.”
Peters warns that what is needed in Germany is a good dose of reality and “a fresh start on energy policy.”
Advantages of fossil fuels “too great”
The German expert writes that despite the hundreds of billions of euros committed to green energies, “chemical energy from coal, oil and gas supplies about four fifths of primary energy worldwide and also in Germany and thus represents the present energy supply”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And although at some point, the reserves will be exhausted, and alternatives will need to be found, but “for the time being, chemical energy sources are irreplaceable and will remain so for several decades to come. Their advantages are too great.”
Peters reminds that “petroleum-based fuels have the invaluable advantage of high energy density. At over 10 kWh/kg – a hundred times higher than batteries – they are the only energy sources that can reliably supply cars on overland journeys, trucks and ships with energy.”
Yet, Peters agrees that alternatives need to be sought out ultimately because traditional fossil fuels are limited in their supply and burning them entails questions concerning their impact on health.
Nuclear technology as the solution
In his opinion piece, Peters advocates nuclear power as the alternative, writing: “If now the chemical energy sources cause too much damage to humans and nature and will run out in the foreseeable future, and the surrounding renewable energies cannot provide a comprehensive energy supply, only nuclear energy sources remain. Physics does not permit other energy sources. From these we can show that they have the potential to deliver clean and highly concentrated energy forever. Of particular importance is the fact that nuclear energy can provide energy for all applications that human civilization needs, i.e. not only electrical energy but also for heating, transport and industrial process energy.”
Peters also notes that there are “candidates for a modern energy supply by means of nuclear energy”, with the most promising being the dual fluid reactor as it is inherently safe because the physical processes prevent it from getting out of control and it is emissions-free.
Sun and wind inadequate
In Peters view, it’s been shown on multiple occasions that energies from the sun, wind and biomass are not yet suitable for powering entire modern societies.
The German energy expert criticizes Germany and the EU’s narrow focus “on promoting only a few power generation technologies” while ignoring more comprehensive energy supply concepts.
He warns: “In the end, even the German public will not be able to avoid the banal physical reality: Without nuclear energy sources, it will not be possible to abandon chemical energy sources due to the pitfalls of renewable energies. A new start in energy policy is therefore urgently needed.”
Share this...FacebookTwitter "
"When Theresa May became the “Brexit prime minister” in July 2016 it took her less than 24 hours to dissolve the Department of Energy and Climate Change. The message could not have been clearer: Brexit first, and climate change would have to wait. May, although historically noncommittal on the subject of climate regulation, was probably not acting on a disbelief in the threat of climate change. The far more concerning motivation was the simple preoccupation with another political concern. Throughout May’s tenure it has become all too clear that the UK government is fixated on Brexit, along with the country’s media and almost everybody else. Climate change has been continually pushed out of the headlines by yet another Brexit blooper, which has serious implications for the UK’s international policy. The Paris Agreement intends to keep global temperature increases at below 2℃ above pre-industrial levels. It is premised on the notion that states set their own nationally determined contributions (NDCs), essentially setting out how much carbon they themselves will cut to help achieve the overall objective – the agreement is therefore based not on obligation but discretion. States are not legally obliged to act on the Paris Agreement in any specific way. Instead, the design and submission of NDCs is directly linked to the determination of the incumbent government. In the case of the UK, a state submersed in Brexit, the reality is a complete failure to draft its own contribution. Members of the European Union decide their international climate policy collectively, of course. This means that, for the time being, the UK is able to rely on commitments made by the EU which, although not hugely ambitious, would allow the UK to engage in EU carbon off-setting and technology transfer initiatives to provide overall NDCs for the bloc. In March 2019 this option will cease to exist and the UK will become a climate laggard without an NDC. In the absence of the Department of Energy and Climate Change the UK Committee on Climate Change has stepped into the role of dispenser of information to the government. The committee is chaired by Lord Deben (John Gummer), a long-time advocate for climate policy, and produces independent reports offering critiques of the current and longer term climate objectives and the means in which to achieve them. However, the committee is not able to force the government into action and is instead limited to an advisory role. In October 2016 it released a 60 page report detailing various shortcomings of the current strategies and the high likelihood of unsuccessfully meeting emission reduction targets by 2030. Yet its recommendation was for the government not to alter its existing targets. This timidity gave further ammunition to critics who have questioned whether the committee is truly independent. The government promptly absorbed these recommendations and carried on with its Brexit obsession without hesitation or adjustment to its climate strategy. Thus the committee is not able to provide the same kind of leadership as a full departmental minister. Climate change as a priority has therefore lost a great deal of momentum at the hands of a Brexit-focused government. The Paris Agreement has 197 signatories, and at most Brexit will have a direct impact on 28 of those – the remaining EU members. Brexit is certainly a UK problem, probably an EU problem, but unlikely a global problem. Yet what it represents is the inherent flaw in electoral democracy. Governments have become increasingly short term species with one eye on the next election, a philosophy embodied by May’s time in Downing Street. By relegating all other issues she has made her pitch for continued leadership entirely dependent on the outcome of Brexit. The result of this is almost complete frustration of the UK’s climate policy. But every state will suffer its own Brexit moment in one form or another. If we do not learn to frame climate change as a non-political issue it will always be subject to challenge. Brexit has not killed the Paris Climate Agreement but the electoral system of democracy just might."
"As the planet warms, species are moving further north to climate zones which are closer in temperature to what they originally evolved in. The oceans have absorbed most of this temperature increase, and so many marine species, including commercially fished scallops, are under particular stress to migrate northwards to cooler waters.  In the face of this disruption, legal boundaries for fishing fleets could become increasingly irrelevant. As the fish stocks they once contained move out, conflict is likely to arise between countries exploiting neighbouring fishing grounds. As a result, the ongoing “scallop war”, which has seen tense physical confrontations between French and British scallop fishers over access to these prized molluscs, may be a taste of worse to come. The habitat ranges and migration patterns of commercial species in the ocean have been carefully studied throughout history, so that fishing fleets can exploit them more efficiently. This understanding has informed the division of fishing grounds according to who has the right to harvest them. French scallop fishers were incensed over their British counterparts’ alleged pillaging of scallop stocks, as smaller British boats aren’t bound by a French law that prohibits dredging in the Baie de Seine from October 1 through May 15, to allow scallop populations to recover. While on the surface it might seem that these skirmishes are anchored to specific circumstances – potentially inflamed by existing tensions around Brexit – they highlight the enormous difficulties in clearly mapping and enforcing legal boundaries around natural habitats that are changing rapidly. These disputes over resources such as food will become more frequent and intense as climate change alters the habitats and material conditions of life on Earth. 


      Read more:
      'Scallop wars' between Britain and France are just a pre-Brexit skirmish


 Managing marine resources like fish has always been tricky. Each species responds differently to changes and pressures in its environment, making it difficult for anyone to predict exactly where they will be, when or how far they will migrate, and how many remain. Climate change has introduced new uncertainty.  The effects of rising temperatures, though variable across species, have already begun to alter the sizes, distribution, and food web interactions of marine organisms. Warming seas have led to an overall northward movement for many species, some at a pace of 2.2 kilometres per year. This includes commercial species such as the Atlantic cod, a trend that is observable among land-based animals as well. More carbon dioxide in the atmosphere means more of it dissolves in the ocean, making seawater more acidic. This process, known as ocean acidification, is making it difficult for species such as scallops to grow their tough calcium-carbonate shells, threatening their growth and survival.  On top of all of this, we’re taking from the ocean more than it can replenish. Currently over 90% of large commercial fish species such as tuna and cod have already been caught, and over 70% of the world’s fisheries range from “significantly depleted” to “fully exploited”. Species unable to adapt to this pressure are likely to decline or even disappear.  If the scallop wars end soon, climate change will continue to disrupt marine ecosystems and render political boundaries increasingly outdated. We will need to have a radical rethink of who should have rights to what, who is to have the authority in managing important areas and resources, and what constitutes a truly sustainable harvest.    Greater communication and collaboration between fishers, policymakers, researchers and the wider public will become essential for navigating the troubled waters ahead.  Perhaps it is also time to take the interests of other species into consideration in this process, by viewing the natural world and non-human life as more than mere resources or a backdrop to the unfolding human drama."
"
Share this...FacebookTwitterkebenaran teranyar berkaitan Permainan Bandarq! Bandarq merupakan game terkenal yg dimainkan oleh tidak sedikit orang di semua dunia. Dibuat sudah menciptakan aku polar oleh kemajuan tehnologi. Bandarq menawari jumlahnya opsi pembayaran, maka kamu mampu percaya bahwa kamu dapat memperoleh kemenangan bersama serentak & mudah.
kamu bisa pilih utk tentukan kemenangan di bank kamu. Atau mampu serta dalam wujud token yg sanggup kamu pakai di situs-situs. Inilah argumen kenapa tidak sedikit orang pilih Bandarq & memainkan permainan yg sudah mereka sediakan.
Ada tidak sedikit kasino di internet disaat ini, yg membuatnya susah utk menemukan yg serasi utk kamu & biaya kamu. sesudah kamu mengunduh penerapan Bandarq & menciptakan akun buat kamu sendiri, tinggal mengawali & menyaksikan game mana yg yakni pilihan sesuai utk Anda.
kamu kemungkinan mau main-main poker reguler kalau ini yaitu permainan yg biasa kamu sukai & gemar main-main, atau kamu kemungkinan mau cobalah poker domino baru utk kamu sendiri. bandarq mempunyai tidak sedikit pilihan utk pemain.
Permainan ini mempunyai keseluruhan dua puluh delapan card. tiap-tiap card mempunyai poin yg tidak serupa. Di tiap-tiap putaran permainan, masing-masing pemain mulai sejak dgn empat card. sesudah kompetisi berhenti, juara jadi pemain bersama poin paling signifikan.
Itu mampu gampang atau susah. Ini tergantung terhadap gimana seorang melihatnya & memainkannya. tidak sedikit orang sudah cobalah peruntungan di game ini. Beberapa sudah sukses sementara yg lain kalah. menjadi apa yg menciptakan kamu menang atau kalah dalam game ini?
Sudahkah kamu main online & kehilangan sebahagian gede duit kamu dalam perjudian ini? kenapa kamu kalah? jikalau tak, ini yaitu beberapa petunjuk yg bakal meringankan kamu utk membunuh dalam perjudian ini.
mulai sejak bersama Game Gratis
Iya nih. jangan sampai sempat terburu-buru bertaruh dgn duit hasil jerih payah kamu kalau kamu belum menguasai seni permainan. Ada tidak sedikit web online yg dapat kamu memberi peluang ini. Mereka bebas. kenapa tak mengahdiri mereka? tak dapat menghabiskan tidak sedikit disaat Anda.
Apa bukti teranyar dari Permainan Bandarq?
tetapi, kamu mesti lumayan bersabar. jangan sampai terburu-buru. Luangkan saat kamu buat menuntut ilmu & menghindari menciptakan kesalahan. main-main game cuma-cuma ini bakal menopang menciptakan kamu pintar maka waktu kamu mulai sejak main-main game nyata, kamu sanggup bersama gampang menang. kenapa tak cobalah web free hri ini?
terus Fokus
umumnya orang kalah dalam permainan ini sebab kurangnya perhatian & fokus yg dimanfaatkan. kala kamu memutuskan utk memainkan game ini dengan cara online, kamu mampu memainkannya di mana saja. kamu cuma butuh koneksi internet yg serentak & andal.
Tolong janganlah sempat memainkannya di daerah di mana ada tidak sedikit nada & ganjalan. jenguk ruangan yg dingin & mulailah main-main. hunian, kereta api, & kafe kemungkinan bukan lokasi paling baik lantaran tidak sedikit kebisingan di sekitarnya.
type nada ini menciptakan kamu kehilangan fokus. dgn begitu, kamu tak dapat berada dalam posisi buat memantau lawan kamu. bila kamu bakal memainkan game ini, saksikan utk menghindari risiko taruhan Anda.
Lihatlah aktivitas Lawan Anda
dimanfaatkan konsentrasi kala kamu tak main. Ini berikan kamu peluang sempurna buat menonton wajah lawan kamu. Bisakah kamu membaca langkah kemudian yg paling barangkali? Ini teramat mutlak. Ini meningkatkan kesempatan kamu utk menang. Apa yg dilakukan lawan diwaktu mereka bermain?
bagaimanakah bersama disaat mereka tak main-main? teramat gampang utk memastikan apa yg dapat berjalan bersama paling menyaksikan ini. lihat Ini Erat.
seandainya kamu satu orang Pemula, senantiasa pakai Tabel Kecil
janganlah serakah diwaktu main Bandarq. menggali ilmu yakni satu buah proses. janganlah sempat membawa risiko berfokus terhadap tabel yg lebih akbar. bisa jadi akbar kamu dapat kalah. Dianjurkan utk menempel terhadap meja mungil. Ini dapat menciptakan lawan kamu nyaris mustahil utk mengalahkan Anda.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAn empirical analysis using 2005-2015 data from 15 EU countries indicates that as more renewable energies (i.e., solar PV) are deployed, energy costs increase, household poverty risks rise, and incomes decline.


Image Source: Pereira et al., 2019
In contrast to the negative consequences of switching from fossil fuels to renewables, Dr. Tadesse Weldu Teklu affirms “CO2 emission (energy consumption) is directly correlated to economic prosperity and industrialization.”  
Therefore, least developed countries (LDCs) such as Ethiopia should “increase her CO2 emission per capita as much as possible” to escape from the renewables-centered “poverty trap” foisted upon them by “Earth-friendly” wealthy countries.  
Besides,  fossil fuel consumption will inevitably continue to grow and maintain a similar share to today’s (~80%) by 2040 despite symbolic “destined to fail” Paris agreement gestures.


 

Image(s) Source: Teklu, 2018
Share this...FacebookTwitter "
"The decision by counter-terrorism police to place Extinction Rebellion (XR) on a list of extremist groups was an abuse of the tools available to them (Starmer: police ‘completely wrong’ to label XR extremist, 14 January). This abuse amounts to an admission that the police do not know how to deal with XR. They are familiar with capturing those who avoid arrest. But many in XR welcome arrest as a way of highlighting the climate emergency. I was arrested during the October rebellion last year. As I was leaving Wood Green station, I overheard two police officers talking. One said to the other: “There must be a better way. They are doing this because they believe in it, and we are doing this because it’s our job. There must be a better way.” He was right. A better way is needed – and not one that involves further abuse of police powers. That better way requires the government to listen to XR, and to act on the climate crisis. Until that happens, the police will struggle.Nigel HarveySt Albans, Hertfordshire  • I agree with Les Knight (I want humans to go extinct, Experience, Weekend, 11 January). Planet Earth is suffering from an infestation of human beings. Nor do I want us to colonise another planet. We have plundered the one we are already on. If we colonised another we’d simply carry our polluting ways there too.Donald PelmearLondon • Apocalyptic views have been held, for differing reasons, by many individuals over the centuries. Les Knight’s are a present-day extreme version. Why characterise them as an “experience”? They appear to have nothing to do with lived experience but rather with an ingrained attitude of mind whose deep-seated origins remain opaque.Gillian TindallLondon • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
nan
"This is an article from Curious Kids, a series for children of all ages. The Conversation is asking young people to send in questions they’d like an expert to answer. All questions are welcome: find out how to enter at the bottom.  We have eyes on the front of our heads so we can see where we are going, but birds’ eyes are on the side so how do they see where they’re going? – Thomas and Luke, age six, Sussex, UK Dear Thomas and Luke, Thanks for your question. First of all, I should mention that not all birds have their eyes on the sides of their heads. Pigeons and parrots do, but other birds, such as owls, have large eyes placed close together at the front of their heads – a bit like ours.  Whether they have eyes at the front or on the sides of their heads, all birds can still see straight ahead. But that doesn’t mean all birds see things in the same way. In fact, where a bird’s eyes are on its head can tell us a lot about how it sees the world.  Having two eyes means animals can see a three dimensional image of what’s around them. So they can perceive the height, width and depth of an object, as well as how far away it is.  Where a bird’s eyes are on its head affects its field of vision – that’s how much it can see in front and to the side at any one time. Think about how far you can see to either side without turning your head: these are the limits of your own field of vision.  Because owls have eyes at the front of their heads, they have a smaller field of vision – around 150 degrees for a barn owl (though they can turn their heads very far to look around).  Parrots, pigeons and other birds with eyes on the sides of their heads have a much bigger field of vision, of about 300 degrees. Amazingly, this means that they can see in front and a long way to the side, at the same time.  Where the eyes are placed decides how a bird views its surroundings using different types of vision. Binocular vision means both eyes focus on the same object at the same time, and eye movement is coordinated – this is the kind of vision that predatory birds such as owls rely on most.  Monocular vision means each eye is focused on a different object at any particular moment, and this is normal for parrots and pigeons. Having different kinds of vision helps different kinds of birds survive in the wild. For parrots and pigeons, having eyes on the sides of their heads is a huge advantage. Having a wider field of vision with only a small blind spot behind them lets these birds see where they are going, while also keeping an eye out for predators which might be trying to sneak up on them.  For predatory raptors such as barn owls, having forward-facing eyes helps them to see depth and distance much more clearly, since both eyes can focus on the same object at the same time. This is perfect for spotting and catching small prey such as field mice.  So though it might seem like birds with eyes on the side of their heads can’t see where they are going, they can see forward and sideways at the same time, and in fact can see much more than those with eyes facing forwards.  Hello, curious kids! Have you got a question you’d like an expert to answer? Ask an adult to send your question to us. You can: * Email your question to curiouskids@theconversation.com 

* Tell us on Twitter by tagging @ConversationUK with the hashtag #curiouskids, or

* Message us on Facebook. Please tell us your name, age and which town or city you live in. You can send an audio recording of your question too, if you want. Send as many questions as you like! We won’t be able to answer every question, but we will do our best. More Curious Kids articles, written by academic experts: How does gravity pull things down to Earth? – Gabriel, age 4, Stewartby, UK What sea creature can attack and win over a blue whale? – Drake, age seven, Sydney, Australia What is fire? – Lyra, age seven, Oxford, UK"
"
Share this...FacebookTwitterAt the latest Saturday Summary at Weatherbell Analytics, Joe Bastardi, a well-known 40-year veteran of meteorology, looks at tornadoes and hurricanes.
Although many meteorologists and climatologists confirm that there is no data suggesting global warming is causing more frequent and intense tornado and hurricane activity, there is a small but influential alarmist group who claim otherwise. And it’s no surprise who the click-baiting media parrot at maximum volume.
Landfalling hurricanes downward trend
At the 5:45 mark, Joe presents a chart depicting the frequency of US landfalling hurricanes since 1900:

Thank you global warming!
As the chart above shows, hurricane frequency has declined while global temperatures have risen over the same period, which leads Joe to comment that we “have been fed a bill of goods by people who use the weather as weapons.”
By “people” here, he means the climate-ambulance chasing media, scientists and public figures who seize upon every weather anomaly and claim it’s a sign of manmade global warming.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Also the former veteran AccuWeather meteorologist points out that the alarmists like to forget that there was a record setting 10-year hiatus for major hurricanes striking the U.S from 2005 to 2015. Here he suggests that the warming of the past 117 years may in fact be contributing to the downward trend.
Tornado activity on the decline
Next at the 10:10 mark of the Saturday Summary, Joe looks at tornado activity. Data here as well show that tornado activity has been declining rather than picking up, which is what the climate alarm-heads like to suggest is the case:

Chart: NOAA
As the NOAA chart clearly shows, tornado activity has fallen over the past 50 years. Here as well Bastardi says we’ve “been sold a bill of goods” concerning claims that climate is making tornadoes worse.
And so far 2019 has seen below average tornado activity as well:

Image cropped from April 13, 2019 Weatherbell Saturday Summary.
Share this...FacebookTwitter "
"Leatherback turtles are making exhausting journeys, in some cases nearly twice as long as usual, from nesting to feeding grounds, because of rising ocean temperatures and changing sea currents. After nesting, turtles must move to cooler waters to feed, but higher temperatures mean some are having to swim further to reach suitable areas, according to research from Greenpeace and the French Institut Pluridisciplinaire Hubert Curien, part of the Centre National de la Recherche Scientifique.  The researchers tagged 10 nesting female leatherback turtles last year on the Yalimapo and Remire-Montjoly beaches of French Guiana, and then tracked their migration through the north Atlantic. Some of the turtles were found to have swum as far as Nova Scotia in north-east Canada and to France to find new feeding grounds for the jellyfish which form their main diet. Though small in scale, the research provides an insight into how some marine species are being forced to adapt to the warming oceans. This week scientists warned that ocean temperatures had reached record levels with the last five years, which were the five hottest on record. Warming oceans pose clear dangers to human life as they lead to more intense storms and rising sea levels, but the impact of the increasing frequency of heatwaves at sea on marine species is much less studied. There is evidence that some species, including commercially important fish such as cod, are migrating towards the poles in search of cooler waters, but more research is needed for a fuller picture. In another stark example of the dangers to marine life from human actions, one turtle followed was found dead on a beach in Suriname only 120km (74 miles) from the starting point, drowned after having become enmeshed in a discarded fishing net.  Estimates say more than half of all sea turtles have ingested plastic. The animals also face threats from overfishing, though they are mainly bycatch rather than targets. The beaches of French Guiana were once abundant turtle nesting grounds, but now the eggs laid there are only a small fraction of those laid 30 years ago. Last year, the complete absence of leatherback turtles from a beach in a nature reserve in Nicaragua also raised alarm. “Sea turtles survived the extinction of the dinosaurs, but they might not survive us,” said Will McCallum, a campaigner at Greenpeace. “Human activity has put such severe pressure on sea turtle populations around the world that six out of the seven species are threatened with extinction. Without urgent action the situation will only get worse.”"
"
Share this...FacebookTwitterGeographers from FAU investigating glaciers in South America in more detail than ever
If you compare historical photos of glaciers with those taken more recently, you can see that where there was formerly ice there is now very often nothing but rock. Geographers, however, are less interested in the area covered by a glacier, and more interested in its mass. Researchers from FAU have now investigated all glacial areas in South America in more detail than ever before, from the tropical areas of Venezuela to the subpolar regions of Tierra del Fuego.
Their two major findings are that the highest rate of mass loss is in the Patagonian ice sheet, and that the glaciers in the tropics have lost considerably less mass than previously projected, although this is not the good news which it might appear at first sight. The researchers’ findings have been published in the journal Nature Climate Change.*
Surveying glaciers is nothing new. There are two methods which are used particularly often. In the first method, researchers take several measurements directly at a glacier and project the results for entire regions. This is particularly problematic when it comes to large glacial areas such as the large ice fields in Patagonia, as barely any in situ measurements are available for these areas.
The other option is to take gravimetric measurements using satellites. Scientists base their measurements on the fact that gravity on Earth changes depending not only on the location but also over time. It is influenced by aspects such as the composition of the Earth’s surface, mountain ranges, movements in the core, plate movements – and, of interest for our context, when glaciers lose mass. One disadvantage of this method is that when only small areas are covered by glaciers, as is the case in the South American tropics, the satellite only receives a weak signal and the measurement is significantly less accurate.
One method for measuring all glaciers
Geographers from FAU specialising in both climatology and remote sensing and spatial information, led by Prof. Dr. Matthias Braun and Dr. Tobias Sauter, also used satellite data for surveying South American glaciers, but they focused on calculating elevation levels instead of basing their results on gravimetric measurements. Two radar satellites from the German Aerospace Center (DLR) have been orbiting the Earth since 2010. The aim of the TanDEM-X-mission was to obtain a three dimensional image of the Earth, which is not only of a consistent quality but also more accurate than anything that has gone before.
Differences in elevation were recorded down to the last metre. The researchers from FAU used data collected between 2011 and 2015 and compared them with measurements from the Shuttle Radar Topography Mission of 2000. Using a complex method which involved making various corrections and calculating possible error margins, they compared the data to calculate the changes in elevation in the glacial regions of South America, thus obtaining an accurate picture of the changes in glacial mass.
Their method was unusual in that they were able to use one uniform method to record all glacial areas in the region. In addition, the method even provided accurate data for individual glaciers. Comparing the measurements from both space missions allowed the researchers to gain detailed insights into the situation throughout South America. For the first time, researchers succeeded in analysing the large Patagonian ice fields separately from the surrounding, smaller glaciers.
Entire glaciers have vanished
The greatest loss of mass, both relatively and in comparison to the other South American glaciers, was found in both inland ice fields in Patagonia, two regions with an area of approximately 18,000 square kilometres, roughly equivalent to the Rhineland-Palatinate region in Germany.
Slower rate of mass loss in tropics


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The second important fact revealed by the research is that the mass of glaciers in the tropical regions of South America – in Venezuela, Columbia, Ecuador, Peru and Bolivia – is changing at a considerably slower rate than previously supposed. Projections to date calculated that the 2900 glaciers there were losing approximately 6 gigatonnes of mass per year. The geographers from FAU have discovered, however, that they are only losing 0.55 gigatonnes per year, approximately 10 percent of the estimates to date.
This result is important, as glaciers are an important source of water in the dry period: when no rain falls and the temperatures reach their highest level, glacier melt water is used as drinking water, for irrigation and hydro power. People in these regions therefore have to know to what extent the glaciers are changing, and need quantitative data not only with respect to area but also in terms of their volume and mass.
In some areas such as the Central Andes in Chile and Argentina or the Cordillera Real in Bolivia, experts are even of the opinion that the maximum amount of water available from glacial melt has already been exceeded. This is an indication that glaciers are irrevocably on the retreat and will vanish entirely in the foreseeable future. In future, these areas will have less water available during the dry season.
The survey, however, also revealed that some areas have hardly experienced any change at all, such as the Andes in northern Chile and Argentina as well as in southern Bolivia at the latitude of the Atacama desert.
The researchers from Erlangen now hope that their study will be included in the next report of the Intergovernmental Panel on Climate Change (IPCC). After all, melted glacier ice is contributing to the rise in sea levels and the huge ice fields in Patagonia are particularly relevant. Glaciers are also used as an indicator for climate change in other respects as well.
The geographers from FAU now want to extend their analyses to cover other regions and investigate how the situation develops over a longer period of time. At present, the global terrain model from the TanDEM-X mission is currently being updated. Researchers hope to be able to benefit from these data in future. They are also relying on further national missions which are in the pipeline such as the Tandem-L satellites, which would make it possible for such measurements to be repeated more frequently.
* https://doi.org/10.1038/s41558-018-0375-7
Further information:
Prof. Dr. Matthias Braun
Phone + 49 9131 85-22015
matthias.h.braun@fau.de
=========================================================
Hat-tip: Die kalte Sonne.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA new paper just appeared in the journal of Atmospheric Research titled: “Climate classifications from regional and global climate models: Performances for present climate estimates and expected changes in the future at high spatial resolution“.
Hat tip: Reader Mary Brown

Though the title itself reveals little about the quality of the performance of models, the study suggests that models still have a long way to go before really being useful for policymakers to go by.
The study concludes, “The modeling of precipitation remains the Achilles’ heel of models and thus of multidimensional indices, which are very sensitive to this variable.”
Well, just about every major climate index is directly related to precipitation. Thus if the models cannot get precipitation right, then everything else will also be wrong – or at least so far off the mark as to be useless.
The plea for us to worship crude models
“Nonetheless”, the authors write, “the role of models as privileged tools to advance our scientific knowledge of the Earth’s system remains undisputed.”
In other words, even though the models don’t work, and thus cannot be relied on at all by policymakers, we should still worship them!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Models as snake oil
Climate scientists have a long history of making the public think their models are pretty darn good, and that only a teeny weeny bit more tweaking is all that is needed. In reality, however, climate models are still only at the very embryonic stages of development and nowhere near suitable for performing the tasks that would make them of any use for the long term.
The climate system, which includes the atmosphere, extraterrestrial systems, tectonic activity and our great oceans, is just too poorly understood and so absolutely impossible to accurately model with any degree of certainty. There are still so many huge data holes that need to be filled.
Any scientist who claims otherwise should be put away for fraud, or in the least dismissed as an outright quack.
New data get ignored
What’s especially sad is that many of these gaping holes are gradually being filled, but unfortunately these data contradict the CO2 hypothesis of the alarmist scientists – and so they just ignore them.
The result: their models will remain a sham.
What follows is the paper’s abstract:
Climate classifications based on temperature and precipitation measurements are increasingly being used for environmental and climate change studies. Using three classification methods (Köppen, Extended Köppen, and Holdridge) and one observational dataset for present climate (CRU, Climate Research Unit), we show that GCMs have bridged the gap that led to the emergence of RCMs thirty years ago, as GCMs can now provide global climate classifications whose accuracy and precision are comparable to those of regional outputs of the RCMs. Projections of high-resolution GCMs for future climates under the assumptions of three Representative Concentration Pathways (RCP26, RCP45 and RCP85) can therefore be used as a primary source for climate change and global warming studies at high resolution. This paper provides comprehensive, model-derived climate classifications for the entire planet, using RCMs and two GCMs for present and future climate-change scenarios, and discusses how well the models actually represent the climates of the world when compared with reference, ground validation data. It turns out that both GCMs and RCMs appear still limited to provide practical estimates of the world climates even for present climate conditions. The modeling of precipitation remains the Achilles’ heel of models and thus of multidimensional indices, which are very sensitive to this variable. The conclusion is that model outputs at regional scale need to be taken with extreme caution without venturing into informing policies presenting potentially large societal impacts. Nonetheless, the role of models as privileged tools to advance our scientific knowledge of the Earth’s system remains undisputed.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn most scientific fields, hypotheses that fail to be verified by real-world observations 85% to 100% of the time are rejected immediately.
In Consensus Climate Science, when 126 of 126, 111 of 114, 42 of 49… modeled projections are wrong, or when the opposite sign of the modeled trend is observed, the climate models are still regarded as mechanistically correct, especially with regard to the CO2 climate influence.
Those who disagree are dismissed as “denialists”.


Image Source: Tabari and Willems, 2018

For 2019, the opposite-sign, contradicted-by-observations models continue to be highlighted in the scientific literature.
At what point will Consensus Climate Science actually question if the greenhouse gas forcings the models are predicated on need reconsideration?
Connolly et al., 2019
“Observed changes in Northern Hemisphere snow cover from satellite records were compared to those predicted by all available Coupled Model Intercomparison Project Phase 5 (“CMIP5”) climate models over the duration of the satellite’s records, i.e., 1967–2018. A total of 196 climate model runs were analyzed (taken from 24 climate models). Separate analyses were conducted for the annual averages and for each of the seasons (winter, spring, summer, and autumn/fall). A longer record (1922–2018) for the spring season which combines ground-based measurements with satellite measurements was also compared to the model outputs. The climate models were found to poorly explain the observed trends. While the models suggest snow cover should have steadily decreased for all four seasons, only spring and summer exhibited a long-term decrease, and the pattern of the observed decreases for these seasons was quite different from the modelled predictions. Moreover, the observed trends for autumn and winter suggest a long-term increase, although these trends were not statistically significant.”

He and Yang, 2019


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“However, three combined gridded observational datasets, four reanalysis datasets, and most of the CMIP5 models cannot capture extreme precipitation exceeding 150 mm day−1, and all underestimate extreme precipitation frequency. The observed spatial distribution of extreme precipitation exhibits two maximum centers, located over the lower-middle reach of Yangtze River basin and the deep South China region, respectively. Combined gridded observations and JRA-55 capture these two centers, but ERA-Interim, MERRA, and CFSR and almost all CMIP5 models fail to capture them. The percentage of extreme rainfall in the total rainfall amount is generally underestimated by 25%–75% in all CMIP5 models.”
Bishop et al., 2019
“Atmospheric models forced by observed SSTs and fully coupled models forced by historical anthropogenic forcing do not robustly simulate twentieth-century fall wetting in the SE-Gulf. SST-forced atmospheric models do simulate an intensified anticyclonic low-level circulation around the NASH, but the modeled intensification occurred farther west than observed. CMIP5 analyses suggest an increased likelihood of positive SE-Gulf fall precipitation trends given historical and future GHG forcing. Nevertheless, individual model simulations (both SST forced and fully coupled) only very rarely produce the observed magnitude of the SE-Gulf fall precipitation trend.”
Chung et al., 2019
“Here, by conducting a comprehensive analysis based on multiple independent observational records, including satellite observations along with a large ensemble of model simulations, we objectively determine the relative contributions of internal variability and anthropogenic warming to the emergence of long-term PWC [Pacific Walker Circulation] trends. Our analysis shows that the satellite-observed changes differ considerably from the model ensemble-mean changes, but they also indicate substantially weaker strengthening than implied by the reanalyses. Furthermore, some ensemble members are found to reproduce the observed changes in the tropical Pacific. These findings clearly reveal a dominant role of internal variability on the recent strengthening of the PWC [Pacific Walker Circulation].”
Zhang et al., 2019
“Observed Southern Ocean surface cooling and sea-ice expansion over the past several decades are inconsistent with many historical simulations from climate models. Here we show that natural multidecadal variability involving Southern Ocean convection may have contributed strongly to the observed temperature and sea-ice trends.”


Share this...FacebookTwitter "
"Coral reefs are vanishing from the world’s oceans. At least three quarters of these tropical marine habitats are severely threatened globally and in 2016 alone, the Great Barrier Reef lost up to 30% of its coral cover. But could modern technology simply create more reef? It may sound fantastical, but scientists are working on 3D printing new reef habitats to replace those lost from climate change, overfishing and pollution.  Coral reefs are important ecosystems for people in tropical countries as the sea life which lives on them is a major source of food and income. They also protect shorelines from erosion and storms.  Unfortunately, overfishing, pollution and climate change have changed how most coral reefs look and function. Corals are particularly sensitive to small increases in sea temperature and so highly vulnerable to global warming. Since the 1980s, many reefs have suffered large-scale coral die-offs as a consequence of high temperatures. When corals die, the hard structure of the reef still remains behind and can be colonised by new corals. But this process of recovery can take a long time, particularly if the environmental problems have not been effectively managed. This means there is actually plenty of existing reef structure, but much of what is left is now devoid of corals. Corals are a bit like trees in a forest – they create most of the complex structure that provides a habitat for a diverse range of species.  Most efforts to manage impacts on coral reef ecosystems have focused on establishing and setting up marine protected areas (MPAs), which are regions of the ocean where fishing and other activities are restricted or banned. At least a third of coral reefs are already inside MPAs and, if effectively managed, these provide huge benefits including protecting fish and other vulnerable species, limiting other practices that cause pollution or direct damage.  However, in some cases, even well managed and protected reefs show little recovery due to a poor supply of new corals. These arrive as small larvae carried by currents and use the reef to settle and metamorphose. Sometimes the reef surface has been reduced to rubble and is no longer stable enough to support growing corals, usually due to dynamite fishing or ship groundings. Reefs within protected areas are also not shielded from the effects of global climate change.  To address this, researchers have looked at how to restore degraded reefs, either by directly planting corals onto reefs, or more rarely, repairing or replacing parts of the reef with human-made structures. Restoring the reef’s function as a habitat for wildlife has been attempted in numerous places around the world, often with limited success and usually at very small scales of tens to hundreds of square metres. In many cases, restoration efforts fail to deliver results because the factors that caused a decline in the first place have not been adequately managed. In other cases, the reasons for restoration are not carefully thought through, making it hard to judge if a project has been successful or not.  Recently, one the largest 3D printed coral reef was deployed at a site in the Maldives, as a way of creating new reef habitat, using a new technology called Modular Artificial Reef Structures or MARS for short. MARS consist of lattices that have been 3D printed in ceramic material and designed to be deployed from small boats and pieced together by divers. The idea is that they can be used together with coral farming – where coral is cultivated for commercial purposes or reef restoration – to create new reef habitat in areas that have been degraded or where there were no corals to begin with, such as sandy bottoms.  The potential benefit of modular structures like MARS is that they don’t require heavy-duty machinery to deploy (for example, cranes and barges are needed to deploy large concrete structures), so can be used in remote locations to create artificial reefs at lower cost. Another advantage is that 3D printing technology allows you to make structures that actually look like reefs and have complex structures to create a range of habitat types for fish, corals and other reef organisms. The system can also be tailored depending on the specific restoration goal in a given location. Each of the units is 3D printed and moulded, with hollow pieces filled with marine concrete and steel reinforcement to aid durability.  The surface design allows for corals to be easily transplanted using epoxy or a similar adhesive and the surface is chemically inert, so it is thought not to harm newly-attached corals and coral settlers.  Artificial reef structures such as these may create value at small scales by providing high value dive sites to tourists when natural dive sites have been degraded. They also provide a way of involving tourists and volunteers in conservation efforts if they can be engaged as volunteers to help construct reefs and transplant corals. Much of the value of reefs comes from them having live corals, for example, many tourists prefer to see living rather than dead corals. Living corals continue to build reef. So without sufficient numbers of living corals, the actual reef structure will eventually erode over time and will not grow to keep up with sea level rises. Reefs need growing, healthy corals to continue to function and protect coastlines. So merely increasing the amount of reef structure available for coral growth will not in itself solve the problem of natural reef decline.  Another big concern with using artificial structures as a restoration tool is that they are very expensive and may therefore divert funds from existing proven conservation techniques (for example, policing within marine protected areas). It should also be mentioned that artificial reefs may not necessarily have the same levels and types of biodiversity as natural reefs. The biggest problem with artificial reefs, however, is that these methods cannot be scaled up to anything like that required to counter the current degradation on reefs.  This does not mean that 3D printed reefs cannot be beneficial in coral management as any restoration activity can provide an opportunity to engage the public to learn more about the difficulties facing coral reefs. However, the only way to tackle reef decline in the long term, is to deal head on with its main causes: climate change, pollution and destructive fishing practices."
"
Share this...FacebookTwitterThe Post-1998 Hiatus
Plods On…Regionally

Image Source: Gan et al., 2019
North America (180-0°N, 15-60°N) has been characterized as a “major cooling center” by the authors of a new paper (Gan et al., 2019) published in Earth and Space Science.
The continent warmed from 1982-1998, but a cooling trend since 1998 has nearly wiped out all the previous warming.
Overall, there has been no significant temperature change in North America since 1982.
The warming and cooling trends, especially the daily temperature minimum (Tmin), are well-correlated (r=0.71) with the path of the Atlantic Multidecadal Oscillation (AMO) during 1950-2014, leading the authors to conclude that the temperature trends over this 32-year period are “a result of” natural changes in the AMO.

Gan et al., 2019
The Key Role of Atlantic Multidecadal Oscillation
in Minimum Temperature Over North America
During Global Warming Slowdown
“Daily Minimum temperature (Tmin) is an important variable in both global and regional climate changes, and its variability can greatly affect the ecological system. In the early 21st century, warming slowdown is seen over the North Hemisphere and North America is one of the major cooling centers.”
“In this study, we found that Tmin experienced an obvious decline in North America during warming slowdown period. Such Tmin decline is closely related to the Atlantic Multidecadal Oscillation (AMO), the correlation between the decadal components of Tmin and AMO reached 0.71 during 1950-2014.”
“According to composite analysis, the AMO on the positive (negative) phase takes two low-pressure (high-pressure) systems in the northeastern Pacific and the North Atlantic at night, accompanied by cyclonic (anticyclonic) circulations and warm (cold) advection in North America. Therefore, the analyses conclude that the Tmin decline during warming slowdown period is a result of the synchronous decrease of the AMO. The results emphasize the key role of AMO on the decadal variation of Tmin in North America.”

Image Source: Gan et al., 2019

Another new paper renews the global warming “hiatus” debate and documents a 21st century cooling trend in northern China that also effectively snuffs out the previous decades of warming for the region.

Li et al., 2019
Satellite-based regional warming
hiatus in China and its implication
“Global warming ‘stalled’ or ‘paused’ for the period 1998–2012, as claimed by the Intergovernmental Panel on Climate Change (IPCC) Fifth Assessment Report (AR5) (IPCC, 2013). However, the early drafts of IPCC AR5 have no detailed explanation for this “hiatus” since 111 of 114 climate models in the CMIP5 earth system model did not verify this phenomenon. … In 2017, after a wave of scientific publications and public debate, the climate models as reported in IPCC remain debates, including definitions of “hiatus” and datasets (Medhaug et al., 2017).”

Image Source: Li et al., 2019
“The slowdown in global warming since 1998, often termed the global warming hiatus. Reconciling the “hiatus” is a main focus in the 2013 climate change conference. Accurately characterizing the spatiotemporal trends in surface air temperature (SAT) is helps to better understand the “hiatus” during the period. This article presents a satellite-based regional warming simulation to diagnose the “hiatus” for 2001–2015 in China. Results show that the rapid warming is mainly in western and southern China, such as Yunnan (mean ± standard deviation: 0.39 ± 0.26 °C (10 yr)−1 ), Tibet (0.22 ± 0.25 °C (10 yr)−1), Taiwan (0.21 ± 0.25 °C (10 yr)−1), and Sichuan (0.19± 0.25 °C (10 yr)−1). On the contrary, there is a cooling trend by 0.29 ± 0.26 °C (10 yr)−1 in northern China during the recent 15 yr, where a warming rate about 0.38 ± 0.11 °C (10 yr)−1 happened for 1960–2000. Overall, satellite simulation shows that the warming rate is reduced to −0.02 °C (10 yr)−1. The changes in underlying surface, Earth’s orbit, solar radiation and atmospheric counter radiation (USEOSRACR) cause China’s temperature rise about 0.02 °C (10 yr)−1. A combination of greenhouse gases (GHGs) and other natural forcing (ONAT, predominately volcanic activity, and atmosphere and ocean circulation) explain another part of temperature trend by approximately −0.04 °C (10 yr)−1. We conclude that there is a regional warming hiatus, a pause or a slowdown in China, and imply that GHGs-induced warming is suppressed by ONAT [other natural forcing] in the early 21st century.”

Image Source: Li et al., 2019
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIs Greenland’s Ice Disappearing?

Image Source: AVweb, August 2018 
I. Emergency Landing In 1942
In July, 1942, a squadron of six U.S. P-38 fighter planes and two B-17 bombers embarked on a flight mission to England when they were suddenly bombarded by severe weather.
All 8 planes were consequently forced to emergency-land on the southeastern corner of the Greenland ice sheet, about 29 kilometers from the coastal edge.
While all 25 of the occupants were ultimately rescued, the 8 planes had to be abandoned atop the surface of Greenland as it existed in 1942.  Eventually the planes were buried beneath decades of ice and snow accumulation.
II. The first “Lost Squadron” plane rescued in 1992…buried under 268 feet of ice
Over the course of the next several decades, nostalgic interest in a search-and-recovery effort grew.  After all, the Lost Squadron planes were effectively new when they were abandoned and, if preserved well enough, they could potentially be restored to flying condition .
The first several attempts to locate the planes during the 1980s were unsuccessful, as the search crews had underestimated how deep beneath the surface the planes were after 40-plus years of ice sheet growth.  It ultimately took 12 tries before the first plane was spotted.
In 1988 the search crews were finally able to pinpoint the location of a P-38 that was ultimately named “Glacier Girl”.   She was buried 260 feet (79.2 meters) below the surface of the ice sheet as it existed in 1988.
By 1992 the 260-foot depth had grown to 268 feet (81.7 meters), and “Glacier Girl” was slowly (piece-by-piece) retrieved from the ice.
III. Another Lost Squadron plane was found in mid-2018…buried under 340 feet of ice
Accompanied by far less fanfare, another Lost Squadron P-38 was located in 2018 using drone technology.
This plane was found buried under another 72 feet – 21.9 meters – of ice relative to the 1992 recovery site for the first P-38 rescue (340 feet versus 268 feet).
IV. Potential implications and Greenland observations
• Greenland’s interior ice is melting more slowly now than 95% of the last 9,000 years

Image Source: MacGregor et al., 2016 and AAAS press release
• An anthropogenic influence on Greenland’s ice melt is too small to be detected

Image Source: Haine, 2016


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




• The Greenland Ice Sheet surface area is larger now than 95% of the last 8,000 years

Image Source: Briner et al., 2016

• Greenland hasn’t warmed overall since the 1920s and 1930s

Image Source: Hanna et al., 2011
“The annual whole [Greenland] ice sheet 1919–32 warming trend is 33% greater in magnitude than the 1994–2007 warming.”   (Box et al., 2009)
• Greenland ice melt has added just 1.5 cm to sea levels since 1900 – with no contribution during 1940-2000

Image Source: Fettweis et al ., 2017
• Greenland has been cooling during the last decade

“Here we quantify trends in satellite-derived land surface temperatures and modelled air temperatures, validated against observations, across the entire ice-free Greenland. … Warming trends observed from 1986–2016 across the ice-free Greenland is mainly related to warming in the 1990’s. The most recent and detailed trends based on MODIS (2001–2015) shows contrasting trends across Greenland, and if any general trend it is mostly a cooling. The MODIS dataset provides a unique detailed picture of spatiotemporally distributed changes during the last 15 years. … Figure 3 shows that on an annual basis, less than 36% of the ice-free Greenland has experienced a significant trend and, if any, a cooling is observed during the last 15 years (<0.15 °C change per year).” (Westergaard-Nielsen et al., 2018)

“For the most recent 10 years (2005 to 2015), apart from the anomalously warm year of 2010, mean annual temperatures at the Summit exhibit a slightly decreasing trend in accordance with northern North Atlantic-wide cooling.  The Summit temperatures are well correlated with southwest coastal records (Ilulissat, Kangerlussuaq, Nuuk, and Qaqortoq).” (Kobashi et al., 2017)
• Greenland was much warmer than today throughout most of the last 10,000 years

Image Source: Kobashi et al., 2017
“Greenland temperature reached the Holocene thermal maximum with the warmest decades occurring during the Holocene (2.9 °C warmer than the recent decades) at 7960 ± 30 years B.P.”  (Kobashi et al., 2017)

Image Source: McFarlin et al., 2018
Share this...FacebookTwitter "
"A video recently doing the rounds on Facebook included a segment from the BBC comedy quiz show QI. The video asks which of avocados, almonds, melon, kiwi or butternut squash are suitable for vegans. The answer, at least according to QI, is none of them.  Commercial farming of those vegetables, at least in some parts of the world, often involves migratory beekeeping. In places such as California, there are not enough local bees or other pollinating insects to pollinate the massive almond orchards. Bee hives are transported on the back of large trucks between farms – they might go from almond orchards in one part of the US then on to avocado orchards in another, and later to sunflower fields in time for summer. Vegans avoid animal products. For strict vegans this means avoiding honey because of the exploitation of bees. That seems to imply that vegans should also avoid vegetables like avocados that involve exploiting bees in their production. Is that right? Should vegans forego their avocado on toast? The revelation that avocados might not be “vegan-friendly” could seem to be a reductio ad absurdum of the ethical vegan argument. Some people might point to this and claim that those who are vegan but still consume avocados (or almonds and the like) are hypocrites. Alternatively, this sort of news might lead some people to throw up their hands at the impossibility of living a truly vegan diet, and so to give up. Pass me the foie gras someone … However, one initial defence for vegans is that this is only a problem for certain vegetables that are produced commercially on a large scale and which are dependent on migratory beekeeping. In places such as the UK, this practice is still (as far as I can tell) uncommon. Locally sourced butternut squash would probably be fine (although you could never guarantee a bee kept in a hive hadn’t pollinated a crop), while avocados and almonds (including most almond milk) sourced from California might be a problem. Another answer might depend on someone’s view about the moral status of insects. Commercial beekeeping may injure or kill bees. Transporting bees to pollinate crops appears to negatively affect their health and lifespan. But some may question whether bees are capable of suffering in the same way as animals, while others may wonder whether bees are self-aware – whether they have a desire to continue to live. If they do not, some philosophers argue that they would not be harmed by being killed (others, such as Gary Francione, would beg to differ).  The more important general response is that whether or not migratory beekeeping is a problem depends on your ethical rationale for being vegan. Some vegans have a non-consequentialist justification for being vegan – they wish to avoid acting immorally through their diet. This could be based on something like the Kantian rule of avoiding using another sentient being as a means to an end. Or they may have a rights-based view, according to which animals (including bees) are rights holders. Any amount of rights violation is wrong under this view – it is simply not ethically permissible to use bees as slaves. Other vegans choose not to eat meat or other animal products for consequentialist reasons – they wish to minimise animal suffering and killing. This ethical argument might also have trouble with migratory beekeeping. While the amount of suffering experienced by an individual bee is probably small, this would be magnified by the very large number of insects potentially affected (31 billion honeybees in the Californian almond orchards alone). A vegan who chooses to eat almonds or avocados is not doing what would most reduce animal suffering. However, a different, (perhaps more practical) ethical rationale that might underlie a decision to go vegan is the wish to reduce the animal suffering and killing  and environmental impact involved in food production. Migratory beekeeping also has negative environmental effects, for example, through the spread of disease and effect on native honeybee populations  Taking this view, dietary choices that reduce animal exploitation are still valuable even if some animal exploitation would still occur. After all, there is a need to draw a line somewhere. When we make choices about our diet, we a need to balance the effort we expend against the impact on our daily life. The same applies when we make choices about how much we should donate to charity, or how much effort we should make to reduce water consumption, energy use, or CO₂ emissions. One ethical theory for how resources should be distributed is sometimes called “sufficientarianism”. Briefly, it is the idea that resources should be shared out in a way that is not perfectly equal, and may not maximise happiness, but at least ensures that everyone has a basic minimum – has enough. In another area of ethics, there is sometimes discussion of the idea that the aim of parenting is not to be the perfect parent (we all fail at that), but to be a “good enough” parent. Taking a similar “sufficientarian” approach to the ethics of avoiding animal products, the aim is not to be absolutely vegan, or maximally vegan, but to be sufficiently vegan – to make as much effort as feasible to reduce harm to animals for the sake of our diet – we could call this a “vegantarian” diet. For some people this may mean choosing to avoid Californian avocados, but others may find their personal ethical balance at a different point. What is more, accepting and embracing all these variations may provide room for more people to adopt or sustain a vegan lifestyle.  Pass me the avo on toast, someone."
"
Share this...FacebookTwitterSome critics have slammed Germany’s decision to exit coal power by the year 2038. For example the Wall Street Journal here called Germany’s energy policy “the world’s dumbest” (it is).
Yet, we need to remind ourselves that many in Germany had been calling for an exit within 10 years, or even sooner. For political leaders, however, shutting down what today is still Germany’s backbone of power supply so quickly would mean economic and political suicide. So the decision to push everything off to 2038 was yet again the German government punting the ball down the field, and leaving the messy issue to the next generation of leaders.
The government is not taking action; it’s avoiding it.
Keep in mind that a lot can happen between now and 2038. It’s entirely reasonable to expect that other forms of cleaner energy sources will be developed – 20 years is a long time. And climate can change rapidly, as a number of scientists are warning of cooling ahead.
Under the bottom line, it’s comforting that the Germans have given themselves the extra time, especially amid so many claiming that green technology is already available. Obviously it really isn’t.
World Future Council sees more coal burning
Even hardcore green energy groups are realizing they’ve been had and are beginning to voice their dissatisfaction with the new government-set 2038 coal exit target, for example the Hamburg-based, planet-rescuing World Future Council, Because of the deal, it expects coal CO2 emissions to climb by 16%!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




What follows is their recent press release (my emphasis added):
===============================================
Despite capacity reductions, coal-fired power generation and CO2 emissions can increase by up to 16 percent
Hamburg, February 7, 2019 – Dr. Matthias Kroll, Chief Economist of the Hamburg-based World Future Council, has recalculated the effects of the so-called “coal compromise” on the climate, with the result that coal-fired power generation could even increase by 2030 despite capacity reductions. The reason for this is the increase in the base load on the remaining coal-fired power plants due to the nuclear phase-out.
“The improvements suggested in the coal compromise for climate protection on the way to the 1.5°C target are a deceptive package,” says Kroll.  The main criticism of the coal compromise to date has been the very late phase-out date of 2038.
However, the current compromise conceals yet another problem that has been lost in the debate so far: “For climate protection, it is not decisive how much power plant capacity is shut down, but how much electricity generation with coal actually decreases,” Kroll continues. “In the current model, I see a bottom line increase in electricity production from coal of around 16 percent. The situation is similar with CO2 emissions. Germany must take its foot off the brake and significantly push ahead with the expansion of renewable energies, the associated storage systems (‘power to gas’) and the construction of new natural gas power plants. Otherwise CO2 emissions will increase and not decrease.”
Although about 12 GW of the currently existing 42 GW coal-fired power plant are to be shut down by the end of 2022, it has to be expected that the planned remaining 15 GW of lignite and stone coal each will produce more electricity and CO2 emissions than today. The reason for this is the significantly increasing utilisation of the remaining coal-fired power plants, as it must be assumed that they will take over the last 9.5 GW of nuclear base load that will be eliminated.
While coal-fired power plants today are only used very irregularly because they are increasingly being forced out of the grid by wind and photovoltaic power, they can largely run at their maximum load. In terms of figures, this will amount to an increase of up to 16 percent in coal-fired electricity and the associated CO2 emissions compared with 2018. To ensure that the essential phase-out of nuclear power does not lead to a permanent increase in coal-fired power generation, the remaining 30 GW of coal-fired power from 2022 must be further reduced rapidly.
“It is questionable how Germany intends to achieve the 1.5°C target it has contractually agreed to in the Paris Agreement if CO2 emissions from coal-fired power generation are even higher than current levels for another decade, even though the reduction to zero is necessary,” criticises Kroll.
Share this...FacebookTwitter "
"Conflict between humans and elephants has reached a crisis point in Kenya. As the elephants have begun to regularly raid farms in search of food, it has become not uncommon for local people to attack and kill them in retaliation. Between 2013 and 2016, 1,700 crop raiding incidents, 40 human deaths and 300 injuries caused by wildlife were reported in the Kajiado district alone.  The problem has come as vast parts of Kenya that are home to elephants have been subject to intensive agricultural development in the past few decades. The Maasai people who tend to the land are switching from their traditional nomadic lifestyle to seek a more permanent livelihood. But these lands have also been used by elephants and other wildlife for many generations, providing them with food, water and space for migration.   Tensions are running high, but a controversial solution is being put in place: electrified fencing.  In the 2016 Netflix documentary The Ivory Game, filmed in Kenya’s Kajiado district, the following exchange was caught on camera, between a group of Maasai people and Craig Millar, head of security at non-profit conservation foundation Big Life: Farmer 1: You see this maize? It is for my children, not for elephants … we don’t want to see elephants on our farms. Millar: And what do you think is the solution? Farmer 1: The solution is to kill them!  Farmer 2: A fence. Electrification. Millar: I agree, but … it is expensive. We will ask countries in Europe for help … everybody will have to contribute something. You will have to protect the fence once it is erected. Farmer 1: We’ll take care of it. If you are lying about the fence, the elephants will be in danger. The elephants will die. When the documentary was filmed, an electrified fence was believed to be the only solution to the conflict. So, with support from international investors, work in the borderlands between Kenya and Tanzania was started in 2016 and the foundation has reported that the 50km of fence built to date has already reduced elephant crop raids by more than 90%.  Unfortunately, this is not the only human-elephant conflict hotspot in the country. Kenya is experiencing rapid economic and industrial growth, and small-scale agriculture developments are spreading across Maasai lands, causing more and more problems. Fencing is one of the most commonly used conservation tools in the world. And Big Life’s electrified fence is a great example of how fast and effective it can be. But fencing can have long-term consequences for animals – it can disturb wildlife migration routes, disrupt gene transfer through mating and alter population dynamics.  The possible costs to animals are unknown. South Africa is the only African country that legally requires an environmental impact assessment to be done prior to building fences. Generally speaking, there is no straightforward international policy or legal guidelines for fence planning. In most countries, fences are built in a random and uncontrolled way. But fencing can be an effective tool for conservation – in Australia, fencing is commonly used to save native mammals from introduced carnivores, while in Namibia fencing protects cattle from cheetahs and lions.  In our recently published paper we looked at how an electrified fence being built around crop fields in southern Kenya is affecting major elephant migration pathways. We used GPS collars on 12 elephants from the area where the fence was to be built, and tracked their movement and behaviour. All the elephants were from different families and were collared in various locations.  After two years of data collection we used the information to map where and how the elephants spent their time in the study area. We reconstructed their movement paths and built a connectivity model, highlighting the most important migration routes between large national parks.  After validating our model, we included the fence plan and recalculated, to estimate if the fence would change the elephants’ free movement between parks. The results showed that local managers were right: fencing did not disturb migration corridors nor diminish connectivity between the national parks.  But more detailed examination gave us some food for thought. Areas with limited amounts of the resources that elephants need (wetlands, floodplains and conservancies) are predicted to be more intensively used after fencing because the elephants will no longer have access to their usual grounds – and this may lead to overgrazing and habitat destruction. In addition, fences will not stop elephants from moving – so the conflict will basically be shifted to unfenced areas. These results raise a reasonable question: how much more land will have to be fenced to resolve human-wildlife conflicts? Besides high costs and difficulties in maintenance, the more land is fenced the less habitat remains for elephants. Long-term aerial monitoring in the Amboseli Ecosystem (an 5,700km² conservation area near the Tanzania-Kenya border) confirms that habitat loss to agriculture will become a bigger threat to elephants than illegal poaching in the near future. There is no simple solution here. The benefits of electrified fencing are undeniable, but lack of understanding of the long-term consequences for wildlife is worrying. We recommend that integrated impact assessments – as we did during our study – are made prior to fencing become international policy.  Another approach could be using fences only as a temporary tool for mitigating critical conflicts and considering alternative management approaches – such as fencing which contains beehives, to deter elephants but not restrict their movement – to solve the problem in the long run."
"Three thousand litres of water – that is the amount needed to produce the food each British person eats every day. This is according to a new study into the “water footprint” of diets in Western Europe, conducted by the European Commission and published in Nature Sustainability. The term “carbon footprint”, which accounts for all the emissions of CO₂ associated with the manufacture or production of an item, has become commonplace in recent years. Similarly, the “water footprint” of food can be calculated using information on the amount of water required during cultivation and processing.  The authors of this new study, led by EC scientist Davy Vanham, first gathered existing data on the water footprint of various foods and drinks. They then combined this with census information for regions within the UK, France and Germany, and knowledge of local eating habits, to calculate how much water is used to feed people in each region and how that could be reduced. Considering the record-breaking heatwave and drought across Europe in summer 2018, their insight may have arrived just in time. Of the three countries studied, the UK has the smallest average water footprint at 2,757 litres per person per day, in Germany the average is 2,929 and in France it’s 3,861 (for reference, people in the US use more than 9,000 litres per day). One of the standout reasons for the difference between these countries is that the French drink more wine, compared to the Germans and the British who prefer beer, which has a smaller water footprint.  Another feature of this study is the focus on smaller regions which reveals large differences within these countries. A common theme is that rural areas have higher water footprints than cities, mainly due to differences in diet. People in London, for example, eat less red meat than other regions. This is why the UK’s highest footprints (still less than France’s smallest footprint) are found in the south-west, North Yorkshire and Lincolnshire.  In Germany and France this trend manifests as a distinct north-south divide, with the French wine growing regions in the south-west using up to 5,000 litres per person per day. According to the study, another cause of differences within each country is the make up of regional populations. In London, the amount of wine consumed is closely related to the level of education of residents. In other words, water footprint increases with education. But what does all this mean? Well, 3,000 litres a day adds up to more than a million litres per year – or enough water to fill your local swimming pool three times over. More importantly, a higher water footprint is associated with an unhealthy diet, largely due to meat requiring a lot more water than vegetables or fruit. In all three countries, people “eat too much sugar, oils and fats, (red) meat as well as milk and cheese combined,” write Vanham and colleagues, and in France and Germany “people do not eat enough fruit and vegetables.” Eating less meat through adopting a “healthy meat” diet could reduce water footprint by up to 35%, the authors say. An even greater saving can be made if meat is replaced by fish, lowering water footprint by 55%, but interestingly moving completely to a vegetarian diet makes around the same savings. Making such changes will not only save water, but will have the additional benefit of improving diet in countries where more than a third of people are overweight and around a quarter obese. Convincing people to make such a change to their eating habits will not be simple. A number of suggestions are put forward in the study, including punitive measures for “unhealthy” foods, such as a sugar tax. However, such approaches are controversial, with considerable evidence suggesting that they are harmful to low income families. A more subtle approach would be to change the layout of supermarkets, “nudging” shoppers towards more healthy purchases.  Finally, the authors acknowledge that education of the population in dietary matters will be key. But, as their own analysis shows, more education is associated with higher wine consumption, which increases the water footprint."
"For those who long to live by the sea, the thought of gently breaking waves and waking by the beach sums up the irresistible charm of coastal life. But not, perhaps, in the Yorkshire village of Skipsea. Residents in the tiny seaside parish were warned this week that a large number of homes are at “imminent risk” of tumbling into the North Sea within 12 months because of the rapid erosion of the East Yorkshire coast.  For decades the picturesque seaside from Bridlington to Withernsea has been a haven for holidaymakers from across the country. But it is quickly becoming known for another reason: it is the fastest-eroding coastline in northern Europe. Figures published this week showed that parts of the coast were disappearing far faster than first thought. A combination of stormy weather and rising sea levels caused more than 10 metres of cliff to disappear from a 2-mile stretch of coast in just nine months last year, compared with the annual average of 4 metres. In just six months, three strips of coastline lost nearly double what they expected to lose in a year. On Green Lane, residents are on the frontline of this unwinnable war with nature. “You can get up one morning and open your curtains and you’ve lost your fence, or your garden’s gone,” said Carly Davis, 30, whose rented chalet is one of more than 20 home at imminent risk of being swallowed by the sea in the next year. Davis, not her real name, points to the half-missing fence at the foot of her garden and the wet clay cliff, freshly-exposed by the waves. All along her street, huge chunks are missing from gardens and the cliff is just 9 metres from some people’s back doors. The main road that once led to their street now ends precipitously at the cliff edge. A bright red sign warns: “Danger. Cliffs subject to coastal erosion. DO NOT PROCEED.” Davis moved into her rented home only two months ago so she could live next to her friends. Her son, 12, loves his seafront bedroom but they know it is not a forever home. “You sit here and the waves hit your window and you think: it’s getting close. You go check it for fresh soil all the time and you think: how long have I actually got left?” Looking out to sea, she mused: “It’s a monster, that thing, but then again it’s beautiful. You see the sunset and you think it’s gorgeous, then you hear the crashing waves and you think it’s a monster – it’s a destroyer.” An abandoned amusement arcade stands at the end of Davis’s street, opposite a large hole where Skipsea beach social club served seaside drinkers for 80 years before it was demolished last year. There is no longer public access to the beach, though hardy residents have been known to clamber down ladders from their gardens in summer. The erosion of Yorkshire’s soft clay coast is not a new phenomenon: about 30 villages have been lost to the sea since the Middle Ages. The steady nibbling away began about 10,000 years ago, at the end of the last ice age, but the global climate emergency has accelerated the process. Rising sea levels and more frequent volatile storms have seen huge chunks of land disappear in the past 20 years. “You would have to be Donald Trump to say climate change isn’t happening,” said David Elvidge, who will chair an East Riding council meeting next week to discuss measures to protect homeowners. “There have been occasions on certain areas of the coast where a bad storm has taken in a single night what you would expect to go in three or four years.” The average annual erosion rate remains about 2 metres a year for the whole 52-mile coastline. In Skipsea, there is anger that neighbouring towns and villages have been protected by sea defences but their parish, with its population of about 700, has not. Sea defences are decided on a cost-benefit analysis, with large urban areas and important industries prioritised over farmland and individual houses. On that basis, Skipsea must brave the waves. “There’s half a mile of land gone in 20 years,” said John Keay, 64, serving afternoon pints at the village’s newly-built social club half a mile inland. “You wouldn’t mind if they were trying to slow the erosion down but they’re not – they’re just letting it go. My argument is how far do you want it to go?” Some residents on Green Lane feel the council has not done enough to protect them from erosion or help them to move nearby. As it stands, they will also have to pay thousands of pounds towards the cost of demolishing their homes. Some have already chosen to leave but many of those who remain were too angry and upset to talk to journalists this week. One 80-year-old man, whose wife died recently, said he had lived in his seaside bungalow for 25 years and could not imagine moving. “I’m losing my home. It’s been like this for seven years. I’m at my rock’s end with it,” he said. Another woman added: “I am really furious but I don’t want to talk. They have big meetings and get some money but nothing ever comes to us.” As the tide moves towards her garden, Davis vowed to stay put for as long as she could: “The view, the community and the friends – we’re all a big family down here and we help each other. But you see people leaving and we’re getting less and less and less.”"
"It started in Sweden, where the term flygskam (flight shame) was coined in 2018 to describe the unease about flying experienced by environmentally conscious travellers. The hashtag #jagstannarpåmarken (which translates as #stayontheground) came into use around the same time, as groups sprang up to share tips. Other wealthy countries are not immune from such trends: a recent survey of 6,000 people in Germany, France, the UK and the US found 21% had cut back. Such a shift in attitudes makes it all the more disturbing that members of the current government, including the health secretary, Matt Hancock, have yet to catch up. Asked twice on the radio this week whether people should reduce the number of flights they take, the minister said they should not.  The Swedish activist Greta Thunberg has probably done more than anyone else to promote the idea that flying should, wherever possible, be avoided. In August she went to New York on a zero-emissions sailing boat. In Sweden last year, air passenger numbers fell by 5% as rail numbers went up. The German Green party (which topped 20% and doubled its seats in last year’s European elections) aims to make domestic flights obsolete. With new research showing 2019 was the second-hottest year on record on the planet’s surface, and the hottest-ever for the oceans, it is increasingly difficult to understand why any rational person would not be behind all and any measures designed to reduce carbon emissions. Evidence of the growing danger extends from the devastation caused by the Australian bushfires to this week’s report that up to 1 million seabirds were killed in less than a year by a “hot blob” in the Pacific Ocean. This context made it particularly troubling to hear a senior UK government minister, and one generally considered to be on the moderate wing of his party, blithely deny that reducing flights is a good idea. Just as bad was the fact that his remarks came only hours after the announcement of a tax holiday and review of air passenger duty as part of a rescue deal to save the regional airline Flybe. Mr Hancock’s comment that “we should use technology to reduce carbon emissions” could be dismissed as naive if it was not so irresponsible. Electric flight is in its infancy and, while there have been significant gains in fuel efficiency, zero-carbon flight remains a remote prospect. Projections of future emissions consistently expect aviation to be responsible for an increasing share of the total, although the industry complains that it is unfairly singled out given that the current figure is 2.5%. The UK, however, is a special case. Aviation is responsible for 7% of emissions now and is expected to overtake all other sources by 2050. Britons are the most frequent flyers to international destinations in the world, although a small minority are responsible for the vast majority of flights; by contrast, 48% reported in a recent government survey that they had not flown at all in the previous year. The US, meanwhile, has by far the heaviest air traffic (including domestic flights) overall, with the International Air Transport Association predicting that China will overtake it in about five years’ time – and global air traffic expected to double to around 8.2bn passengers annually by 2037. No one wants remote locations such as some of those served by Flybe to be cut off, which is why the handful of routes deemed socially necessary are exempt from European state aid rules. But ministers should promote alternatives wherever possible. Hinting at a reduction in flight taxes when rail fares are rising by 2.7% sends the wrong message. Individuals altering their habits, even in large numbers, will not avert disaster. In a sense the opposite is true: collective action by whole countries, led by governments, to push entire economies into a clean era is the answer. But “flight shame”, along with movements to restrict other carbon-intensive forms of consumption, is still a force for good. The point is not to show that you are better than other people, or to displace anxiety from the public realm into the private one. It is to show the world’s leaders, in business and politics, that we get it: life must change. • This article’s headline was amended on 18 January 2020 to better reflect the content of the article. The text was amended on 21 January to correct a reference to global air traffic potentially reaching “8.2bn flights” by 2037; the predicted figure relates to the number of air passengers, not flights."
"
Share this...FacebookTwitterLaurent Alexandre: “Greta Thunberg instrumentalized by militant extremists“
In a stinging commentary at Le Figaro here, Dr. Laurent Alexandre, surgeon-urologist, a graduate of Sciences Po, HEC and ENA, and co-founder of the Doctissimo website, asserts that teenage Nobel Prize nominee Greta Thunberg is being shamelessly exploited and “is playing into the hands of economic interests for whom climate protection is of little importance”.

Dr. Laurent Alexandre. Image: https://twitter.com/dr_l_alexandre?lang=de
The French physician blasts the instrumentalization of the special child as “irresponsible” and that “revealing her neuropsychiatric state to the media should be a crime.”
“Substitute for the Marxist dictatorship” and “liberticidal agenda” 
Laurent Alexandre first comments that “the young people who follow Greta Thunberg are the useful idiots of the green dictatorship” much in the same way Lenin called left-wing bourgeois “useful idiots of the revolution” and that the failures of all Marxist models have “left the anti-liberals in turmoil.”
He writes that ecology today serves as “the ideal instrument to propose a new utopia that is a substitute for the Marxist dictatorship”. He adds: “By exploiting the youth, we are imposing a liberticidal agenda in the name of good feelings.”
Targets reachable only possible through a green dictatorship
Alexandre comments that Thunberg and the leftists are demanding that “we reduce our energy consumption by at least to a fourth, and believes that “imposing such a step backwards can only be achieved through the green dictatorship.”
The French physician even characterizes the militant activists as the “Khmer greens” and “green ayatollahs”, and reminds readers that the measures that are demanded by the greens will likely end up leading to more CO2 emissions rather than less because they are also demanding the shut down of nuclear power. If the nuclear power plants in France were to be shut down, fossil plants would need to be on standby and spring into action on sunless, windless days.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Shamefully manipulated victim”

Alexandre implies that Greta Thunberg is unwittingly promoting “the interests of China and Russia” and that her demands would make us “highly dependent on rare metals needed for wind, solar and storage installations, of which China has a near-monopoly.”


The French urologist and book author describes Ms. Thunberg as “a shamefully manipulated victim” who needs to be protected, but adds that her radical ideas “must be attacked relentlessly”.
Criminal child abuse?

The tragedy of Greta Thunberg, Alexandre comments, is that “the child is all the more manipulable as her parents have made her disability public (which is irresponsible on their part)” and that as a doctor he believes that “revealing the neuropsychiatric state of minor children to the media should be a crime!”
He concludes:
We have known since Hans Asperger’s description of the syndrome in 1941 that Asperger’s children are sometimes brilliant but always fragile; instrumentalizing them is a moral fault.”
Movement of “deadly utopias”
Finally, Alexandre comments that following the green path will backfire because it would “aggravate global warming, increase the waste of public money, lead to a regressive green dictatorship and put us at the mercy of China and Russia. All liberal democrats, all Raymond Aron’s heirs, must combat the deadly utopias it conveys.”

 

Share this...FacebookTwitter "
"Rachel Connolly is right to demand that the Labour leadership candidates address the climate crisis (The nuclear button? There really are more pressing issues, Journal, 8 January). But suggesting we remove nuclear weapons from the conversation ignores how intertwined these two existential threats are. Generations of climate scientists have documented that a nuclear war could cause drastic climatic disturbances and global famine. Last year scientists found that the use of a few hundred weapons (less than 10% of today’s global nuclear arsenals) could nearly stop all rain over India and central China, and reduce global precipitation globally by 15%-30%. It would take over a decade to return to rainfall levels before the nuclear war.  Nuclear weapons destroy the climate even when they are not used. Nuclear weapons facilities – not unlike the oil and gas companies exacerbating the climate crisis – have contaminated land and water around the world with waste that will last far beyond even our grandchildren’s lifetimes. Climate change could actually make nuclear war more likely. Increased resource scarcity increases the chance of conflict, according to a growing body of research. The unacceptable humanitarian and environmental consequences of nuclear weapons and the ever-growing risk of nuclear use led 122 countries to vote to ban them in 2017. Today the UN treaty on the prohibition of nuclear weapons has 34 ratified states and 80 signatories – and counting. So perhaps, as Rachel suggests, we should not be asking whether candidates would push the button to launch nuclear weapons. Instead we should join the world’s majority of countries and ask when they will take the nuclear button off the table for good.Alicia Sanders-ZakreInternational Campaign to Abolish Nuclear Weapons • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"The least surprising development in the Flybe saga was Willie Walsh throwing a tantrum. The rescue of the struggling regional airline is “a blatant misuse of public funds”, thundered the boss of IAG, owner of British Airways, as he made an official complaint to the European commission. That’s the same IAG, note, that enjoys a feather-bedded life thanks to its control of 56% of the landing slots at Heathrow, the most capacity-constrained airport in Europe. BA doesn’t get a leg-up via grubby Flybe-style negotiations with ministers but, if the airline industry wasn’t so riddled with politics, and if flag-carriers didn’t enjoy such lobbying power, IAG’s share of landing slots at Heathrow would have been capped at 30% a long time ago.  The continued existence of Flybe maddens Walsh for a couple of reasons, one suspects. First, it is partly owned by the hated Virgin Atlantic. Second, Flybe indirectly secured a few slots at Heathrow via the fallout from BA’s takeover of British Midland in 2012; the competition authorities, in a rare act of resistance, took the view that BA was big enough already at London’s main airport and domestic consumers would benefit from greater choice. Walsh is not a voice of impartiality on Flybe. None of which is to deny that there are big questions to be answered about the rescue package. The Virgin-led Connect consortium has yet to explain how much money it has invested since it bought the assets for a mere £2.8m less than a year ago, and why crisis has arrived so soon. Making money from regional aviation is hard, as evidenced by Flybe’s many problems over the years, but that’s a reason to have a better plan B than begging for a deferral of an Air Passenger Duty (APD) bill and a short-term loan. It may be that the Connect crew is dysfunctional. Virgin Atlantic, 49%-owned by US carrier Delta, is mostly interested in delivering passengers to Heathrow and Manchester for transatlantic flights. Stobart would like more flights out of its Southend airport. Cyrus Capital, an obscure US investment firm, may have viewed the Flybe takeover as a short-term punt that could be abandoned if it threatened to become expensive. Those caricatures may be exaggerated, but the government is taking a risk in backing, even for a while, a consortium that looks fundamentally unstable. The fact that a review of APD has suddenly been thrown into the mix says this is a case of policymaking on the hoof. Yet it’s hard to say definitively that the government has done the wrong thing. If the aim is to ensure that Flybe survives until the peak summer season, that’s not so silly. The approach buys time to develop a coherent strategy. By contrast, the instant demise of Flybe would have been followed, almost certainly, by crises at several regional airports. The government’s ability to implement any policy would have evaporated. What would a sensible strategy look like? Well, there’s certainly a case for redesigning APD as a tax on emissions, rather than being a per-passenger charge. A straightforward reduction in APD – in other words, a pro-flying bung at a cost to the public purse – would make a mockery of the UK’s carbon-reduction ambitions. As for regional connectivity, the important thing is that the government doesn’t become beholden to Flybe’s unreliable owners. If it is really essential (a debate in itself) to run uncommercial flights between regions, let operators pitch for low-margin management contracts. Flybe doesn’t have to get the gig. Most of all, though, make the current help for Flybe transparent. A short-term sticking plaster could be a pragmatic fudge, whatever Walsh says, especially if it means Flybe is more likely to pay its APD liability in full. But any deal that underwrites the current owners would be completely unacceptable. “The government has not given any state aid to Flybe,” says the business department. Let us hope that statement is true. And, if it is, make sure it stays true. Still on aviation matters, here comes the World Economic Forum to claim that its Davos shindig will be a carbon-neutral event this year. Maybe it will be, but it’s safe to assume that many of the big-name participants from business, banking and politics will arrive in Switzerland via private jet. It happens every time, and instantly undermines all the worthy speeches about tackling the climate emergency. The aim this year, by the way, is to produce a manifesto for “a cohesive and sustainable world”. Of course it is."
"Four years ago a viral campaign wooed the world with a promise of fighting climate change and jump-starting the economy by replacing tarmac on the world’s roads with solar panels. The bold idea has undergone some road testing since then. The first results from preliminary studies have recently come out, and they’re a bit underwhelming. A solar panel lying under a road is at a number of disadvantages. As it’s not at the optimum tilt angle, it’s going to produce less power and it’s going to be more prone to shading, which is a problem as shade over just 5% of the surface of a panel can reduce power generation by 50%. The panels are also likely to be covered by dirt and dust, and would need far thicker glass than conventional panels to withstand the weight of traffic, which will further limit the light they absorb.  


      Read more:
      Solar freakin' roadways? Why the future of this technology may not be so bright


 Unable to benefit from air circulation, its inevitable these panels will heat up more than a rooftop solar panel too. For every 1°C over optimum temperature you lose 0.5% of energy efficiency.  As a result a significant drop in performance for a solar road, compared to rooftop solar panels, has to be expected. The question is by how much and what is the economic cost? One of the first solar roads to be installed is in Tourouvre-au-Perche, France. This has a maximum power output of 420 kW, covers 2,800 m² and cost €5m to install. This implies a cost of €11,905 (£10,624) per installed kW.   While the road is supposed to generate 800 kilowatt hours per day (kWh/day), some recently released data indicates a yield closer to 409 kWh/day, or 150,000 kWh/yr. For an idea of how much this is, the average UK home uses around 10 kWh/day. The road’s capacity factor – which measures the efficiency of the technology by dividing its average power output by its potential maximum power output – is just 4%. In contrast, the Cestas solar plant near Bordeaux, which features rows of solar panels carefully angled towards the sun, has a maximum power output of 300,000 kW and a capacity factor of 14%. And at a cost of €360m (£321m), or €1,200 (£1,070) per installed kW, one-tenth the cost of our solar roadway, it generates three times more power.  In America, a company called Solar Roadways has developed a smart highway with solar panels, including sensors and LED lights to display traffic warnings about any upcoming hazards, such as a deer. It also has heating pads to melt snow in winter.  Several of their SR3 panels have been installed in a small section of pavement in Sandypoint, Idaho. This is 13.9 m² in area, with an installed capacity of 1.529 KW. The installation cost is given as $48,734 (about £37,482), which implies a cost per installed kW of €27,500 (£24,542), more than 20 times higher than the Cestas powerplant. Solar Roadway’s own estimates are that the LED lights would consume 106 MWh per lane mile, with the panels generating 415 MWh – so more than 25% of the useful power is consumed by the LEDs. This would reduce performance even further. The heating plates are also quoted as drawing 2.28 MW per lane mile, so running them for just six days would cancel out any net gain from the solar panels. And this is before we look at the actual data from the Sandypoint installation, which generated 52.397 kWh in 6 months, or 104.8 kWh over a year. From this we can estimate a capacity factor of just 0.782%, which is 20 times less efficient than the Cestas power plant.  That said, it should be pointed out that this panel is in a town square. If there is one thing we can conclude, it’s that a section of pavement surrounded by buildings in a snowy northern town is not the best place to locate a solar installation. However, perhaps there’s a bigger point – solar roads on city streets are just not a great idea. Roads don’t actually represent as large an area as we assume. The UK department of transport gives a breakdown of the length of the UK’s different road types.  Assuming we can clad these in solar panels, four lanes of every motorway, two lanes on the A & B roads and half a lane for C & U roads (a lot are single track roads and just won’t be suitable) we come up with a surface area of 2 billion m².  Which sounds like a lot, until you realise that buildings in the UK’s urban areas occupy an area of 17.6 billion m². So just covering a fraction of the UK’s rooftops with solar panels would immediately yield more power than putting them on roads. That’s quite apart from the benefits that a more elevated position would yield for greater power generation.  All of this suggests that only a small fraction of the road network would actually be suitable. And, given the relatively small size of the road network, solar roads could only ever become a niche source of power and never the shortcut to our future energy supply."
"In April 2005, a fire burnt much of Victoria’s beloved national park at Wilsons Promontory leading to the evacuation of holidaymakers from Tidal River. The fire was the result of a fuel reduction burn, which escaped 10 days after it was lit when the weather became hot and windy. I remember it well as I was Victoria’s environment minister at the time, responsible for the park and the burn. The then premier Steve Bracks was one of the campers evacuated.  In 2015 a fuel reduction burn at Lancefield in Victoria escaped, causing a fire that destroyed six homes and caused a great deal of anguish for the local community. There have been many such instances of fuel reduction burns escaping and causing damage in different parts of Australia. The risk of putting fire in the landscape for fuel reduction is real. For years, elements of the media have promoted the idea that “greenies” and environmentalists have prevented fuel reduction burning. This particularly suits those with an agenda to deny climate change as it simultaneously advances the culture war against environmentalists and draws attention away from the need to take action on climate change. As environment minister, I don’t recall ever being influenced or lobbied by environmentalists or “greens” to stop fuel reduction burns. What does stand in the way of planned burns is climate change: higher temperatures, dryer fuel and strong winds in autumn and spring making it unsafe to burn. A shorter timeframe for safe burning – not “debate by environmentalists” – is the overwhelming factor. Much attention has been given to the recommendation of the Victorian Bushfires Royal Commission to implement a program of planned burning based on an annual target of 5% of public land – 390,000 hectares for Victoria. The former Victorian premier Jeff Kennett and others have criticised the Victorian government for not achieving this target. However, these criticisms not only ignore the climate-related difficulties with planned burning, they also fail to take account of the expert advice received in the years since the royal commission reported. The weather-related difficulties in achieving a hectare-based target were born out in 2014, the last year of the Napthine Coalition government, when only 82,022 hectares were burnt despite the government’s commitment to the 5% target. Kennett’s government itself could manage only 40,000 hectares of planned burning in 1997-98 and I had the same experience myself when I was minister in the very dry and hot 2006 year. The royal commission itself acknowledged that planned burning is risky and only available in limited timeframes. The royal commission also recommended that the Victorian government appoint an independent person to monitor the implementation of its recommendations. The former police chief commissioner Neil Comrie was appointed to the role and in his reports in 2012 and 2013 recommended that the planned burning target of 5% be replaced. Comrie concluded that the 5% was not “achievable, affordable or sustainable” and recommended that it be replaced by a risk-based approach with a primary focus on human life and safety. Following Comrie’s reports, the Inspector General of Emergency Management recommended a change from a hectare-based target for planned burns to a risk reduction target. A group of fire experts from around the country reviewed this recommendation and backed the changed approach because it focuses on the areas of highest risk rather than on burning broad acres for the sake of meeting a target. The risk-based approach also creates incentives to pursue alternative forms of risk reduction such as mowing and slashing when planned burning is not possible. In 2016, the Victorian government agreed to adopt this new approach, which means that fuel reduction is now done in a way to maximise the reduction in risk to people and their homes rather than simply burning as many hectares as possible. Fuel reduction burns are now carefully planned using computer-based fire models that indicate where the burning is likely to be most effective. The target is to reduce the risk that homes will be lost by 30%, which experts advised is the right level across the state. Planned burns cannot guarantee that homes will be saved. They are most effective when the fire is at ground level, but they are of limited effect on the most dangerous fire weather days when a fire can race across tree crowns or across already burnt areas. Fuel reduction burns should be part of the toolkit that our firefighting agencies have to tackle the ever-growing risk of bushfire. They should not be used as a weapon in the culture wars in order to divert attention from the need to act on climate change. John Thwaites is the chair of Monash Sustainable Development Institute and ClimateWorks Australia and a former deputy premier and environment minister in Victoria"
"Switching from fossil fuels to renewable energy is an important and necessary step towards averting climate change. However, in our efforts to go green, we also need to be mindful of other consequences, both intended and unintended – and that includes how a mass deployment of renewable technology might affect its surrounding climate.  What if the Sahara desert was turned into a giant solar and wind farm, for instance? This is the topic of new research published in Science by Yan Li and colleagues. They found that all those hypothetical wind turbines and solar panels would make their immediate surroundings both warmer and rainier, and could turn parts of the Sahara green for the first time in at least 4,500 years.  The scientists behind the research looked at the maximum amount of solar and wind energy that could be generated in the Sahara desert and the transition region to its south, the Sahel. The two regions were picked as they are relatively plausible sites for such an enormous roll-out of renewable energy, being fairly near to substantial demand from Europe and the Middle East, while having limited other demands on the land. Both have substantial potential resources of wind and solar energy. Li and colleagues also suggest that The Sahel, in particular, could also benefit from economic development and more energy for desalination, providing water for cities and agriculture.  As the two regions are so large, the solar and wind farms that were simulated in this study are the size of entire countries – 38 times larger than the UK. They would be vastly bigger than any existing solar and wind farms, and could provide up to four times as much energy as is currently consumed globally.  This would prompt quite significant changes in the local environment – massive wind farms would raise temperatures by around 2℃ for instance, similar to the amount of global warming we are concerned about. Solar would cause a smaller temperature change, around 1℃.  Precipitation increases of 0.25 mm per day associated with wind farms sound more modest, yet this would be almost double the previous amount of rainfall. Again, the effect associated with solar parks was smaller – an increase of 0.13 mm/day – but still significant when added up over a year.  Wind farms largely cause temperature increases because their turbine blades bring warmer air down to the surface, especially at night. This has been observed in field studies and using remote sensing. They have also been shown to increase moisture in the air. Solar panels mean more solar radiation is absorbed and less of the sun’s energy is reflected back into space. This causes the land surface to warm up. Several studies have shown this, including one which showed that the effect of warming caused by fossil fuels, via carbon emissions, was 30 times greater than the warming caused by solar photovoltaics absorbing more solar radiation. However, temperature effects may vary within the solar park and with season. In the Sahara simulation, extra rainfall happens because wind turbines represent an obstacle to free-flowing air, slowing it down and reducing the effect of the Earth spinning on air flow. This lowers the air pressure, and the difference in pressure between the Sahara and surrounding areas causes wind to flow there. When the air meets, or converges, in the Sahara it has nowhere else to go but up. As the air rises, water vapour in it condenses and rain drops form.  For solar, the process is slightly different: warmer air, heated by the panels, simply rises. However, this also promotes low pressure, causing air to flow there, converge and rise.  More rainfall also means more vegetation. This increases surface roughness, as with wind turbines, and causes more solar radiation to be absorbed, as with solar panels. This reinforcing cycle is known as a “climate feedback” and incorporating these vegetation feedbacks is a novel aspect of the research by Li and colleagues. Not quite. Decisions aren’t made in response to environmental impacts alone – if this was the case we’d have already ditched fossil fuels. It’s certainly true that developing a mega renewable energy site across the Sahara and the Sahel would be a game-changer, but there are lots of other factors to consider first.  These areas may be sparsely populated but people do live there, their livelihoods are there, and the landscapes are of cultural value to them. Can the land really be “grabbed” to supply energy to Europe and the Middle East? Coherent and stable energy policies are challenging enough within an individual nation, let alone between nations with all the potential political implications and energy security issues. Though mass amounts of cheap Saharan energy sounds like a great thing, it is not clear it would be a secure enough investment for the economics to add up. It’s also hard to tell what this would mean for desertification, which is caused by poor land management, such as overgrazing, as well as by the climate. The changes to rainfall looked at in this study are regional, not global, and once the wind and solar farms were taken away their effects would disappear and the land could revert back to its previous state. Overall, this is an interesting and important piece of research, highlighting the need to be mindful of unintended consequences, be these positive or negative, of the energy transition. Integrating these findings with other social, economic, environmental and technical considerations is essential to ensure we don’t leap from the frying pan into the fire."
"
Share this...FacebookTwitterNDR north German television recently broadcast a report about the protests against a planned windpark near the German village of Kreien, some 200 km east of Hamburg.

White tail eagles being chased away from nest by loudspeakers in order to clear the way for permitting 14 wind turbines over 200 meters tall in Northern Germany. Image cropped: juvenile white-tailed eagle, Christoph Müller (www.christophmueller.org) – CC BY 4.0
One local resident told NDR television the area is already packed with 178 turbines, and that the plans to build 14 new over 200-meter tall behemoths are no longer welcome. The resident had noticed something very peculiar: a loudspeaker system that had been installed in the area of the planned project (see video, 0:20 mark).
Apparently the speaker system had been put in place to scare away white tail eagles that might get the idea to nest atop an adjacent nesting mast just meters away. The mast had been provided earlier for the purpose of providing a nesting place for the endangered bird species. White tail eagles nesting there would mean a sure stop of the project, and shooing them away would ensure the go-ahead for the wind project.
The sound of barking hounds


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Eagles entering the area and looking to establish a nest there would be scared away by the sound of barking dogs blaring from the speaker (2:40). The result: keeping the nest empty and thus a free path for the construction of the wind park by wind project company UKA Nord.
Residents in the area have reacted angrily at the prospect of yet even more giant wind turbines getting erected in their area, and especially at the tactics used by UKA Nord to ward off potential nesting birds.
One local mayor described the loudspeaker measure as “unbelievable”.
Climate protection before habitat protection?
When asked to comment by NDR, windpark builder UKA Nord replied by text message claiming that the nesting mast was not “to protect birds” but instead was “a pure measure to prevent the expansion of wind energy, which is necessary for climate protection.”
Moreover, the written UKA Nord statement appealed to the local policymakers “to live up to their responsibility for transition to green energies and climate protection and strive for a constructive cooperation.”
At the 3:30 mark of the report, citizens are shown banding together to organize a citizen’s group against the project. So far they have seen some success. The UKA Nord has since turned off the speaker system and it’s been decided to dismantle it. Yet, plans for the construction of the park still have not been halted.
Share this...FacebookTwitter "
"Humans are generally getting better at dealing with their mess. In the UK, for instance, 45% of household waste is now recycled – yet that still means more than 12m tonnes are buried in the ground every year.  Burying that rubbish isn’t cheap, and neither is keeping it in the ground once there. Old landfill sites are covered with grass and turned into innocuous-looking hills filled with waste, and even they have to be monitored to make sure they aren’t contaminating the local environment. For instance, as material decomposes, greenhouse gases such as methane are given off. If there is not enough methane to make it economically viable to capture (and there usually isn’t) it often needs to be burned off to convert it to CO₂, a less potent greenhouse gas. There are also concerns that thousands of older sites, often built on flood plains or near the seashore, may be at risk from flooding or coastal erosion.  So what should be done about these old landfill sites? One answer may be to dig them up again. Old landfills do have valuable waste, the most obvious being processed metals, glass and electronics. Indeed, junk electronic goods such as old TVs or computers typically have higher concentrations of gold and rare earth elements per tonne than are found naturally in ore. A 2014 United Nations University report stated that each year more than 300 tonnes of processed gold are dumped in landfills – that’s 10% of the total amount mined worldwide. Belgium, for example, is already mining its old landfills, by extracting waste and filtering for metals and recyclable material. Digging up old landfills could well have a much lower environmental impact than mining in fresh rocks. For example, toxic chemicals like mercury and cyanide are used to find and isolate gold in regular mines. Recovery of materials from landfill could offer a much cleaner solution to feed our need for smart technology, energy storage and electric vehicles.   To demonstrate what all this would involve in practice, we took part in a BBC Four documentary that chronicled the history of rubbish and explored what we have thrown away and how this has changed over time.  Part of this work looked at a municipal landfill in England’s Midlands that closed in the 1980s - it’s now a big grassy knoll - we can tell its age when we dug into it and found dated newspapers. The site has a methane flare burning 24 hours a day which requires periodic maintenance, and the local council will have to keep monitoring things for the foreseeable future.   To locate potentially recoverable and valuable metals, we surveyed a section of the landfill using near-surface geophysics, looking for “hot spots” of high conductivity/magnetism which will be where concentrations of discarded metal will be buried. Once we had found where to look we dug down five metres. We found large amounts of processed metals, recyclable glass, discarded household artefacts, yellow pages, much of which we recycle now, as well as black plastic bin bags.  Interestingly we only found a few electronic items. This is in contrast to today’s landfills, which are full of mobile phones and gadgets and largely avoidable e-waste. Clearly existing old landfills could be, quite literally, untapped gold mines. With growing demand, coupled with scarcity of materials, including rare earth elements, these may be a valuable future national resource for much more than just metal. Waste companies have even recently suggested designing new landfills to capture energy from them and to deal with problematic waste streams such as plastics that can’t be recycled. For instance, heat from decomposing rubbish or burning waste could be trapped and turned into geothermal power, providing a “rubbish solution” to our energy problems too."
"
Share this...FacebookTwitterYet another scientific paper presents evidence that the Arctic region was warmer than recent decades during the 1930s, leading scientists to conclude there is “still-insufficient knowledge of the mechanisms governing the Arctic Climate System.”

Image Source: Araźny et al., 2019

Araźny et al., 2019
A comparison of bioclimatic conditions on
Franz Josef Land (the Arctic) between the
turn of the 19th to 20th century and present day
“Air temperature in 1899–1914 during three expeditions was 1.8–4.6 °C lower than the modern period in winter (Oct–Apr). However, during the 1930/31 expedition it was 4.6 °C warmer than the years 1981–2010. Our results relate to what has been called the ‘1930s warming’, referred to by various authors in the literature as the ETCW or the ETCAW.”
“In individual months, the highest negative anomalies were identified in Calm Bay (hereafter CB) in January 1914 (− 7.4 °C) and in February 1900 (− 6.8 °C). In contrast, during the 1930/31 expedition, it was 4.6 °C warmer than the present day in CB [Calm Bay]. Such a high thermal anomaly was influenced by a warm autumn and winter, especially February 1931, when the average monthly temperature was 10.7 °C higher than in the modern period.”
“In approximately the last 140 years, there have been two periods of significant temperature increases in the Arctic. The first began in around 1918–1920 and lasted until 1938 and has been called the ‘1930s warming’ (Bengtsson et al. 2004). Other works have referred to this period as the ‘Early Twentieth Century Warming’ (ETCW, Brönnimann 2009) or the ‘Early Twentieth Century Arctic Warming’ (ETCAW, Wegmann et al. 2017, 2018). Our results confirm the observations for the last expedition from the historical study period in 1930/1931. These years covered the warmest part of the ETCW.  In turn, the second increased warming of the Arctic began around 1980 (Johannessen et al. 2004) or according to Przybylak (2007) in about the mid-1990s. Changes in overall atmospheric circulation have long been believed to have been the cause of the ETCW (e.g. Scherhag 1937). As the modern climate warming (since 1975) has progressed in a largely similar manner to the progression of the ETCW (Wood and Overland 2010; Semenov and Latif 2012), there has been renewed interest in the insufficiently well-explained causes of the ETCW using the latest research methods, including, primarily, climate models. An analysis of the literature shows that the cause of such a significant warming in the present period is still not clear. There is even controversy over whether the main factors in the process are natural or anthropogenic, although the decided majority of researchers assign a greater role to natural factors (Bengtsson et al. 2004; Semenov and Latif 2012). It would appear that the greatest differences of opinion on the causes of the ETCW are to be found in works presenting climate models (see, e.g. Shiogama et al. 2006; Suo et al. 2013), which is an excellent illustration of the still-insufficient knowledge of the mechanisms governing the Arctic Climate System.”

Image Source: Araźny et al., 2019

Another new paper indicates that West Greenland retreat rates were much higher “(400-800 m/yr)” during the 1930s and 1940s than “after 2000 (>200 m/yr)”.
Vermassen  et al., 2019
A reconstruction of warm water inflow to Upernavik Isstrøm
since AD 1925 and its relation to glacier retreat
“A link between the physical oceanography of West Greenland and Atlantic SSTs has indeed been suggested previously: a positive phase of the AMO [Atlantic Multidecadal Oscillation] is related to an increase of warm Atlantic waters flowing towards and along the SE and W Greenland shelf (Drinkwater et al., 2014; Lloyd et al., 2011). Our data indeed supports that the AMO influences bottom water temperature variability along the West Greenland shelf and shows that this influence is strong within Upernavik Fjord.
“Despite differences in the timing and magnitude of the retreat of the different glaciers, they broadly share the same retreat history. High retreat rates occurred between the mid ‘30s and mid ‘40s (400-800 m/yr), moderate retreat rates between 1965-1985 (~200 m/yr, except for Upernavik) and high retreat rates again after 2000 (>200 m/yr).”
“[O]ur study shows that while warming of ocean waters in Upernavik fjord likely contributed to the retreat phases during the 1930s and early 2000s, ocean warming is not a prerequisite for retreat of Upernavik Isstrøm.”
“This is important since it implies that the future potential oceanic forcing of Upernavik Isstrøm will depend on changes related to circulation in the North Atlantic (i.e. the AMO). Since the meridional overturning circulation strength and associated heat transport is currently declining, (Frajka-Williams et al., 2017), this may lead to cooling bottom waters during the next decade in Upernavik Fjord and most likely also other fjords in West-Greenland.”

Image Source: Vermassen  et al., 2019
Share this...FacebookTwitter "
"Let’s not beat about the bushfires. It’s not the impacts of climate breakdown on our ecosystems or the world’s poorest in the global south that worries Larry Fink, the CEO of that financial behemoth BlackRock. No, what really worries him and his shadow banking peers is the “fundamental reshaping of finance” threatened by climate protesters, and what this means for his company’s interests. Fink made headlines this week with his annual letter to CEOs, which put the climate emergency front and centre. Acknowledging the risks that it poses to markets, and announcing that his fund will no longer invest in companies that generate more than 25% of their revenue from thermal coal production, his letter was hailed as a landmark move. But, before we get too laudatory, it’s worth asking: what is BlackRock?  The US company is the world’s biggest asset management fund. 63% of the staggering $7tn financial assets it manages originates in the Americas and 29% in Europe. In the UK (as far as we know) BlackRock manages £16.5bn of local government pensions, as well as at least £3.8bn of Transport for London’s pension fund. BlackRock’s management of our savings takes place largely in a globalised sphere known as the shadow banking sector. In the past, most savings were placed in carefully regulated high-street banks and other savings institutions. Today, many of these functions have migrated toward shadow banking. This sector is made up of institutions (including pension funds, insurance companies and hedge funds) that use securities (a tradeable bundle of debt or equities) as collateral in a modern form of credit creation. BlackRock, backed by $7tn of the world’s savings, also provides traditional banking services across the international financial system. Asset management funds such as BlackRock operate beyond democratic borders and are not subject to the same regulatory oversight as traditional banks. In his letter, Fink acknowledges that “the money [BlackRock] manages is not [its] own”. “Last September,” he continues, “when millions of people took to the streets to demand action on climate change, many of them emphasised the significant and lasting impact that it will have on economic growth and prosperity – a risk that markets to date have been slower to reflect. But awareness is rapidly changing, and I believe we are on the edge of a fundamental reshaping of finance.” But the “shape of finance”, especially in the shadow sector, remains essentially the same: it spews out massive quantities of credit – forms of new money – much of it aimed at speculative activity. The Financial Stability Board reckons that at the end of 2017 shadow banks generated $184tr in financial assets. This money is then used to invest in the real economy of consumption and production – and in the fossil fuel sector. As Bill McKibben, leader of the campaign group, 350.org, writes, without asset management companies such as BlackRock, “fossil-fuel companies would almost literally run out of gas”; what’s more, the company is the “world’s largest investor” in coal, oil and gas companies, and in those “driving deforestation”. While it is significant that Fink has publicly acknowledged the risks that climate breakdown poses to his and other companies, that is surely not the only point. The real concern is that the world’s politicians and regulators have allowed this behemoth to scoop up our savings, while turning a blind eye to how those savings are managed. This, in turn, has fuelled the creation of vast amounts of credit and debt, which has made the global financial system unstable and fragile. The shadow banking sector is much, much larger than it was after the Lehman Brothers collapse – a collapse precipitated in part by Lehman’s activities in the shadows. If we are to save the planet, then we must begin by switching off the giant tap of unregulated credit. Fink is right: a “fundamental reshaping of finance” is what climate protesters want as the order of the day. But self-regulated divestment is not enough. The “reshaping” needs to be democratically enforced and accountable. We must ensure that companies such as BlackRock are brought back down to Earth and properly regulated by public authority. We have to do this if we are to redirect investment into the transformation of economies away from their addiction to fossil fuels and into more sustainable transport, energy and land-use systems. • Ann Pettifor is director of Prime: Policy Research in Macroeconomics and a fellow of the New Economics Foundation • This article was amended on 17 January 2020 to clarify that 63% of the assets managed by BlackRock originates in the Americas and 29% in Europe, rather than BlackRock managing about 60% of the savings of all Americans, and about 30% of the savings of Europeans"
"What are the consequences of a second term of Donald Trump? To even consider the question sends the left-leaning mind into a paroxysm. Everything from nuclear war to the utter collapse of American democracy looms large in the imaginations of otherwise sober-minded people.  In truth, the damage may be less immediately obvious. Life, in many ways, would go on. But the planet we inhabit will continue to heat up, and the most powerful government on Earth would be doing everything it can to further destabilize the environment around us. Just after the new year, the Trump administration announced it planned to radically revise the National Environmental Policy Act, a landmark measure that forced federal infrastructure projects to take into account their impact on the environment. Under the rewritten rules, builders of highways, pipelines, and other major infrastructure projects would no longer have to consider climate change when assessing their impact. It is, without question, one of the most grievous blows Trump has inflicted since taking office three years ago. It follows more than 100 environmental rollbacks, including relaxing rules limiting emissions from coal plants and weakening protections for endangered species. Fossil fuel projects like the Keystone XL oil pipeline would have free rein, undaunted by court challenges that ruled the Trump administration didn’t properly consider climate change when analyzing the pipeline’s impact. The new rules would dramatically narrow which projects would require environmental review, with many infrastructure initiatives sailing through the approval process without having to disclose plans to discharge waste, cut trees or increase air pollution. The new rule would no longer require agencies to consider the “cumulative” consequences of new infrastructure, a requirement interpreted as a mandate to study the effects of ruinous greenhouse gas emission and rising sea levels. The act currently requires the federal government to prepare detailed analyses of projects that could have major environmental effects. It was a Republican, Richard Nixon, who enacted the law in 1970 after the heavily polluted Cuyahoga River caught fire and a tanker spilled 3m gallons of crude off the coast of California. Though Nixon was a perpetual villain for leftists of the era, he created the Environmental Protection Agency, developing the crucial regulations under attack today. Even conservatives at the time acknowledged that the government had a role to play in being stewards of the environment we all share. We are in a new, terrifying age. Trump’s Republican party is far more savagely conservative than any version that came before it. It’s important to understand that the shredding of environmental regulations is not something that would have been unique to a Trump presidency, unlike his Twitter inanities or nonstop campaign rallies. The Koch brothers and other billionaire funders of the Republican party have been dreaming of the day they could again control the executive branch to pursue an agenda of environmental destruction.Trump presides over a party that denies the existence of climate change, that rejects science itself. There are few equivalents elsewhere. Even Boris Johnson’s Conservatives acknowledge there is a climate crisis afoot. But had Ted Cruz or Marco Rubio won the presidency in 2016, the assault on the EPA would have commenced as expeditiously as it is now. Perhaps they, like Trump, would have named a coal lobbyist to lead the agency. Four years of damage can be undone. Eight is far more difficult. The Democrats running for president, and the millions who will go to the polls this fall, must understand the planetary stakes. A functioning EPA is essential to reversing the worst effects of climate change, which are very likely to be felt at the cataclysmic rate the planet is warming. If Trump has eight years in power, fossil companies will have carte blanche to profit off environmental destruction for a very significant amount of time. The next Democratic president will not only have to undo Trump’s damage but rapidly play catch-up as the world races to secure a future for the human race. The doomsday clock is ticking."
"Scott Morrison needs to take action on global heating or he will become a “climate change casualty”, a former Victorian Labor premier, Steve Bracks, said. Bracks, who is chair of the $55bn industry superannuation fund Cbus, said the fires that have raged Australia have galvanised community support for action and he called on the Morrison government to put a price on carbon.  “It’s really in a sad position in Australia where we’re seeing effectively corporate Australia, industries, the financial sector and business who are leading on climate change and the government’s not,” he told Guardian Australia. The fires, which have burned more than 10m hectares, killed 28 people and covered Sydney and Melbourne with hazardous smoke, “made a world of difference” to public feeling about global heating. “People’s experiences are so important so I think there is a great appetite now for effective climate action in Australia, and even the prime minister I think is sort of starting to recognise that and move in that direction, and that’s a good thing,” he said.  “If he doesn’t do that I think he’ll be another climate change casualty in Australia.” Bracks said Cbus had focused on environmental, social and governance issues for about 10 years under its chief executive, David Atkin, who announced his retirement on Wednesday. Under Atkin’s leadership, Cbus has grown from an organisation with about $12bn under management that was, he said, something of a cottage industry, to one of the nation’s biggest funds. Atkin, who will step down in six months after almost 13 years in the job, said the fires had changed public sentiment on the climate. “There’s nothing like seeing the physical consequences – you can see it in Melbourne, there’s smoke everywhere,” he said. Super funds had “a really important role to play” in combating global heating. “We’re looking for companies that we invest in who have thought carefully about this, have done their scenario testing, understand what their footprint is from a carbon perspective and are changing their business models to ensure that they can be successful in the future,” he said. “We will not support companies, as investors, if we think that they are being too short term or aren’t taking that issue seriously enough.” Cbus and other industry funds are always under pressure from activist organisations to dump their shares in fossil fuel companies and other big emitters. But Atkin said refusing to invest in an industry category was the wrong approach and Cbus looked to invest in companies with a strategy to decarbonise operations. “We are not investing in companies we don’t have confidence in all the time,” he said.  “We do not have the dinosaurs in our portfolio because we’ve already made that call. We think they’re going to lose us money, not make us money.” Bracks said: “All the companies we invest in understand they have to have a long-term sustainable future and they have to assess the risk of climate change within that. “They know that there will be some stranded assets – particularly in energy generation – if we don’t get the right economic settings for investment in generation in the future, and so they’re really taking the lead and doing the work that the government should be doing.”  As well as pushing corporate Australia to take environmental, social and governance issues more seriously, including by serving as a member of a string of investor groups, Atkin also piloted Cbus through two royal commissions. The trade union royal commission, set up by the then prime minister, Tony Abbott, after the 2013 election criticised Cbus and Atkin over the leak of personal information about fund members to the construction union – before itself giving confidential Cbus documents to other parties. But Cbus skated through 2018’s banking royal commission after counsel assisting, Michael Hodge, QC, decided not to call any witnesses from the fund. Instead Hodge and the commissioner, Kenneth Hayne, held hearings that demolished the reputations of the for-profit sector – an outcome that embarrassed the government, which had included superannuation in the inquiry’s terms of reference in a bid to embarrass industry funds over their links to the unions. “We were to be called and they did not call us in the end and they were quite satisfied with the procedures we had in place, and that’s a good thing,” Bracks said. “So we take that as a seal of approval, but more than that the royal commission as it turns out was a great boon for industry funds, and certainly in our fund we had something like $1bn of net inflows extra compared to the previous year over the period of the royal commission.”"
"Imagine if more than a quarter of a century ago, the bushwalker David Noble had not stumbled across the stand of Wollemi pines and they had remained undiscovered. The trees survive in three stands in just one remote canyon in a massive wilderness to Sydney’s north-west. Until they were found, they were a species clinging to the edge of the precipice of extinction – just one disaster away from vanishing. A quarter of a century for a species with a lineage going back to the age of dinosaurs is not even a fraction of a millionth of a blip. And given the monumental effort that has gone into saving this desperately endangered wild population it is highly likely that had they not been found in 1994, then the past few months would have seen them wiped out without anyone ever knowing they still existed. The miracle of their discovery has become the miracle that has saved them – for now. I remember the day in a Sydney newsroom almost 20 years ago when an editor at the paper where I worked at the time heard that I was writing a book about the Wollemi pines. Even though the trees’ discovery in 1994 made news on front pages around the world, my boss walked over to my desk, looked me in the eye and said: “No one is going to read a fucking book about a tree.” Implicit in what he said was that no one cared about Wollemi pines enough to read a book about them. How wrong he was, was demonstrated this week as dramatic news emerged that the trees had been saved from the firestorm of the vast Gospers Mountain fire and people rejoiced. To see the photos of the ribbon of green of the Wollemi pines, surrounded by the charred towering clifftops and ridgelines, was a rare moment of joy and relief for a community that has watched so much destroyed during the past few months. When I visited the canyon in 1997 I was taken in by helicopter wearing a blindfold and then abseiled into a deep and dark prehistoric environment that was absolutely soaked and waterlogged. At the time it seemed impossible that such a place would ever burn. Now it seems impossible that it didn’t. The Wollemi pine has been a story that has captured people’s imaginations. It is a tale of high adventure and academic excellence. First, there was a dramatic canyoning exploration trip that led to its discovery, then scientific detective work to determine exactly what that 40-metre-tall tree found by Noble actually was, followed by the quest to understand how it survived unnoticed, so close to Sydney. Perhaps the significance of the discovery was best captured by a quote given to me by the then director of the Royal Botanic Gardens, Carrick Chambers, on the day the discovery was announced: “This is the equivalent of finding a small dinosaur alive on Earth.” What Chambers was alluding to and that most people don’t realise is that Wollemi pines are time travellers from a different Australia, from a warmer and wetter planet. Their history stretches back more than 100m years and they have survived natural climate change that has seen temperatures swing dramatically and sea levels rise and fall by hundreds of metres, multiple times. The trees tell the story of almost unimaginably deep time. Once, instead of gum trees, Gondwana – of which Australia was a small part – was covered in immense forests of Wollemi pines and their close relatives. These ancient trees deposited so much pollen that it is still found as fossils around the southern hemisphere, retrieved by geologists who find evidence of the trees in cores, from places like Bass Strait, that are kilometres thick. Then, 10m years ago, the trees begin to vanish from the fossil pollen record and two million years ago they disappeared altogether, indicating that the climate had shifted in a way that made their widespread survival untenable. Since then, as the planet shifted towards icier, colder, drier conditions, any surviving populations of the trees would have slowly shrunk, become separated and forced to retreat into the last refuges of wet deep rainforest canyons. After people arrived in Australia and widespread burning was practised, their fate was sealed to imprisonment in a single deep gorge. It is hard, after this week, to consider the remaining original Wollemi pines as wild. Only intensive water-bombing, the installation of emergency irrigation and the intervention of determined firefighting has allowed them to survive until the next threat. The trees are now dependent on us for their survival. And it’s not just our efforts to protect the canyon where they survive, it is also about the research that has seen millions of trees cultivated and sold commercially around the world. It is about the creation of back-up populations in other similar canyons in the greater Blue Mountains. It is also about the ongoing effort to keep the location of the trees secret and protected from fungal pathogens. The fact that out of this catastrophe, Wollemi pines have become a symbol of survival and all that is good about what we can do when we are determined to protect something, shows that all is not lost as human-made climate change tightens its grip. James Woodford is the author of The Wollemi Pine: The Incredible Discovery of a Living Fossil from the Age of the Dinosaurs, Text Publishing"
nan
"We are all too familiar with images of flooding in low lying areas after heavy rainfall or houses destroyed by coastal erosion after a storm. For an increasing number of people, coastal flooding and erosion is a real threat to property, the local economy and, in some cases, life. Hurricane Florence, for example, is forcing more than a million people on the US East Coast to flee from their homes. Coasts support important industries (such as ports and tourism) and their populations are growing faster than inland areas. But coastal areas are also particularly sensitive to impacts of climate change, which are likely to increase the extent, intensity and frequency of coastal flooding and erosion. So not only have we occupied areas that naturally flood and erode from time to time, we have changed the environment in ways that increase coastal flooding and erosion risk. And we continue to do so, sometimes with serious legal consequences. Meanwhile, public policies have not been very effective in managing this predicament.  Traditional hard engineering approaches of coastal protection (such as groynes, revetments and seawalls) are known to cause detrimental effects, which in the longer term can aggravate the problem they were supposed to solve. The impact of Hurricane Katrina in New Orleans was a stark reminder that engineering structures are not effective against all events at all times. They are built based on trade-offs between the level of protection needed and the costs of construction and maintenance.  Soft engineering, such as beach nourishment (where sediment, usually sand, is added to the shore), can offer a level of protection and beach amenity – but these reduce through time, as erosion continues. Meanwhile, “protection” gives a false sense of safety and enables occupation of risk areas, increasing the number of people and assets in risk areas. Climate change has forced a paradigm shift in the way coastal flooding and erosion risks are managed. In areas of lower risk, adaptation plans are being devised, often with provisions to make properties and infrastructure more resilient. Adaptation may involve requiring raised foundations in flood-prone areas or the installation of mitigating measures, such as sustainable drainage systems. Building codes may also be established to make structures more disaster-proof and to control the types of constructions within risk zones.  But such adaptation options are often of limited use or unsuitable for high-risk areas. In such areas relocation is the only safe climate-proof response.  Planning for relocation is problematic. There are large uncertainties concerning the predictions of climate change impacts – and this makes planning a difficult task. Uncertainty is not an easy concept to incorporate in planning and coastal management. In some places, effects of sea level rise are already evident, but it’s still difficult to be sure how fast and how much it will rise.  Similarly, there is still great uncertainty about when and where the next “super storm” will happen and how intense it will be. Inevitably, areas that have already been affected by flooding or erosion will be affected again – the question is when and how badly. Despite these issues, relocation is increasingly being adopted as a strategy. There have been some successes at the local level. One such example is the Twin Streams project in Auckland (New Zealand), where relocation (through the purchase of 81 properties) has provided space to create community gardens and cycleways where 800,000 native vegetation plants were planted. This was made possible by engaging over 60,000 volunteer hours.  Although not on the coast, the town of Kiruna in Sweden shows that, when risks are high, forward thinking and long-term planning can make large-scale relocation possible. Kiruna is at risk of ground collapse due to mining. Over a 20-year period, more than 18,000 residents will be relocated to a new city centre 3km away. The layout of the new city centre has been designed to be more sustainable, energy efficient and have better options for cultural activities and socialising. Local residents were engaged and helped identifying 21 heritage buildings they want relocated to the new area. The French, meanwhile, have instigated the first ever national strategy focused on relocation from high-risk areas. French policy places a duty on local authorities to develop plans by 2020, identifying the areas at serious risk of coastal flooding or erosion, what needs to be relocated and how (including sources of funding). Five pilot areas have been selected to test how the strategy might be implemented at the local level. Two of these areas have contrasting approaches and outcomes. In Lacanau (a top surfing stop in the Bay of Biscay) coastal erosion threatens the tourism-based economy. Although public opposition was initially high, the development of a local plan has generally been positive, mainly due to the inclusive community involvement in the project. A local committee was created to act as a consultation body and decisions were informed by open discussions based on clear communication of technical, legal, financial and sociological issues. In Ault (northern France) the experience was less positive. the risk reduction plan identified a high-risk zone within 70 metres of the cliff edge. It was decided that no new construction would be allowed here and restrictions to improvements on the existing 240 houses were imposed. This would force relocation if the properties were damaged by flooding or erosion. In May 2018 a residents group won a court case which considered the plan illegal, lifting the restrictions imposed on renovation of existing properties until a new plan is drafted. These examples demonstrate that engaging with local communities from the inception of any such project is essential. Unfortunately, people instinctively resist change – and relocation is a complete shift from the centuries-old approach of fixing coastlines and fighting against coastal dynamics. Our current legal and management frameworks are too geared up for maintaining the status quo. Funding and legal aid to support purchase of properties and removal of infrastructure that are not imminently deemed inhabitable are limited. But open and inclusive debate about the need for relocation and the consequences and benefits of it can change people’s perceptions. The “Nimby” (not in my backyard) attitude is strong in coastal communities, but can subside after personal experiences of severe flooding or erosion. The environment around us is changing and we cannot continue living the way we did in the past. Prevention is always less costly and more effective than remediation, particularly when involving people’s safety. The earlier we accept the need to change, the less damaged is the legacy we leave to the next generations."
"
Share this...FacebookTwitterA commentary at flagship German online daily FAZ looked at a recent study by the German Umweltbundesamt – UBA – (Federal Environment Agency) which examined the per capita consumption of natural resources by different population groups.
Not surprisingly, high income groups were found to own a large number of cars and live in large homes with energy-guzzling appliances – thus making this group of people large consumers of energy.
Frequent flier climate activists
Also the study found that the “urban, academic young classes who tend towards voting for the Greens have far above-average CO2 emissions per capita” and these emissions “are not offset by them buying vegetables from the local region in the organic shop”.
The FAZ writes that the study found that this particular class — who are worried about the CO2 emissions and the climate — have “an above-average number of frequent flyers” and like to take long-haul flights to distant places like “New Zealand or Canada to admire nature”.
The UBA study also found that traditional working classes (whose lifestyles the Greens often complain about) in fact are energy modest and fly less frequently.
Here the FAZ concludes:
The bottom line of the study was that those with a ‘positive environmental attitude’ had the highest actual energy consumption and CO2 emissions.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Al Gore: “a hypocrite and a Pharisee”
The FAZ also mentions former Vice President Al Gore’s film “An Inconvenient Truth”, where he “praised his ‘CO2-neutral lifestyle’ and claimed he compensated for his air travel. But later it was exposed how Gore’s 10,000 square foot mansion in Tennessee consumed “about twenty times as much energy as the house of an average American family”.
“The green-preaching politician was a hypocrite and a Pharisee,” the FAZ commented over Gore.
Back to extreme poverty
The FAZ commentary also wrote about the “Fridays for Future” movement. Here the involved activists are calling on society to wean itself off fossil fuels. This for example could be done by enacting a high CO2 tax, they claim. However the FAZ comments that this would lead to “a sharp rise in energy costs, which would be difficult for low-income groups to bear” and that “millions of poor people in other parts of the world, such as Africa, would be pushed below the absolute poverty line.”
High energy tax “a death sentence”
According to the FAZ: “To put it bluntly, the path naively advocated by some well-off activists could, in extreme cases, be the death sentence for the poor in developing countries whose future well-being and survival they are supposed to be fighting for.”
 
Share this...FacebookTwitter "
"Despite the dramatic news coverage of oil spills and other big pollution disasters in our seas and oceans, most environmental pollution is caused by much smaller incidents that are often invisible, persistent, and far more difficult to track. While animals and plants caught up in these disasters are easily identified as stressed or physically affected by the pollution, with smaller incidents, organisms might look and behave perfectly normal. Only over time does the chronic exposure to low-level pollution take its toll. By the time this becomes obvious, often it is too late to do anything to save a particular population, whose decline might have knock-on effects on the surrounding environment, often with socio-economic consequences. So there is not only a moral responsibility to look after the environment, but also a strong financial incentive, because many jobs and livelihoods depend on a healthy environment and its ecosystems. Biomarkers of exposure provide a tool to identify pollution events early on, often at levels that are not detectable by conventional methods. Loosely defined as measurable effects (endpoints) in organisms, providing evidence of exposure to pollutants, biomarkers lead to establishing the cause and giving the necessary data to inform any policy decisions that need to be taken. Such biomarkers exist in a number of biological areas. They can be purely biochemical, manifesting themselves as damages to DNA, alterations to the activity of enzymes involved in metabolism, structural damage to cells and their subsequent ability to perform properly, as well as more obvious pathological, reproductive or behavioural disorders. However, this requires intimate knowledge of the species and the relevant environmental variables, including how these may influence the respective biomarkers. The latest Intergovernmental Panel on Climate Change (IPCC) reports on climate change show that the upper 75 metres of the world’s oceans have been warming at a rate of 0.11°C per decade since at least 1971 and the uptake of CO2 caused by human pollution has depressed pH (acidity level) by -0.0014 to -0.0024 per year, and is predicted to continue. These changes are likely to affect biomarkers on three levels. First of all, commonly used organisms may no longer be available, as they migrate further north in search of cooler water. And they may then be replaced by invasive species from warmer waters that are not be as sensitive to pollution and therefore not as useful as biomarker organisms. Changing migratory patterns may increase the transport of contaminants in the bodies of organisms in significant quantities to other, previously clean locations, in some cases even becoming more important than wind or water-driven methods. Second, the fate and behaviour of contaminants in the environment, particularly their persistence, their ability to be taken up by organisms and how they behave once absorbed, is strongly driven by environmental factors such as salinity, pH and temperature – and these are all subject to change under climate change scenarios. This means, organisms may be more or less susceptible to pollutants; the degree of change will depend on the specific pollutants and the organism species involved. Last of all, organisms unable to migrate will experience increased stress owing to changes in temperature, salinity and pH which may mean they may no longer be sensitive enough for the biomarker task.  A major focus of research in my lab is working towards re-evaluating these biomarkers in several mainstream organisms and assessing the potential of new, better-adapted organisms. The main aim of this work is to future proof our tools for detecting pollution in the marine environment in order to maintain the ecosystem we all depend on. The evidence for climate change driven by pollution caused by humans is overwhelming and it is clear it is affecting the marine environment. As a result, some commonly used biomarker species and endpoints may need to be re-evaluated and adapted for this changing environment if they are to be used in future as early warning systems for pollution."
nan
"Following the 2015 Paris Agreement to hold the global increase in climate to below 2℃ above pre-industrial levels, the UN’s Intergovernmental Panel on Climate Change (IPCC) was asked to produce a report on the impacts of global warming of 1.5℃. The report focuses on what must be done if we want to avoid warming above 1.5℃, and the difference between 1.5℃ and 2℃ warming. The general message is that the ecological and social impacts of 1.5℃ are significantly more manageable than 2℃ – half a degree of warming is a big deal.  The IPCC thinks we still have a chance of keeping warming to 1.5℃. But current nationally determined pledges to take action to reduce warming, when combined, are emphatically “not on track to limit global warming to 1.5°C above pre-industrial levels”. The window of opportunity is small and shrinking – perhaps 12 years before a 1.5℃ target is unattainable, assuming in the meantime there is concerted global action to rapidly scale back carbon emissions. Without that action “researchers find very few (if any) ways to reduce emissions after 2030 sufficiently quickly to limit warming to 1.5°C”. The report is also pretty explicit in claiming that “unprecedented changes” are required to limit warming to 1.5℃. The language is dry and technical, so it’s easy to be lulled into a techno-fix mindset. For example, the required “system transitions” can be “enabled” by “an increase of adaptation and mitigation investments, policy instruments, the acceleration of technological innovation and behaviour changes”. But look closer, and in an important sense, the IPCC report is all about change and upheaval, especially for the well-off citizens of the developed nations. But it is change on a scale we have never experienced before: “There is no historical precedent for the scale of the necessary transitions, in particular in a socially and economically sustainable way.” We appear to stand at a crossroads. And according to Debra Roberts, co-chair of the IPCC Working Group that produced the report, the stakes could not be higher:  The decisions we make today are critical in ensuring a safe and sustainable world for everyone, both now and in the future … The next few years are probably the most important in our history. So can the report and its coverage actually contribute towards making the changes it implicitly demands of us urgent and extensive? Perhaps, but first we need to think a little more about the kind of change that is required. What tends to happen with this kind of information is that it gets translated into a checklist of things we can do to make a difference – as individuals. Those of us in affluent, “developed” societies – because those are the people to whom such lists are exclusively directed – can read the lists, think about what we can or already do individually, commit ourselves mentally to others, then park it and get on with our individual lives, busy, distracted, but doing our bit, and striving or hoping to do more.  Clearly, this is not enough. The need for this latest IPCC report is evidence of that. For some time now, many environmental activists and commentators have pointed out the limitations of individual behaviour and lifestyle change as the primary means of “making a difference”, and instead direct us towards “collective action”. As climate scientist Michael E Mann pronounces, the “single biggest way to have impact on climate change and other environmental crises is through collective pressure on policymakers to act in our interest rather than special interests”. There’s no doubt this is a key point. Change, of the speed and scope required, cannot rely on easily packaged discrete, simple, individual change checklists. We need to shift the story away from the individual towards what we can achieve together.  But where does that leave us – me and you – in terms of what to do? “Collective action” can feel alien, remote, even scary when it’s not already woven into our everyday lives. There’s a danger that we end up caught between the call to “act collectively” (which is difficult, uncertain) and individually (low-impact, compromised). To bridge this gap, we need to start by addressing the issue at the in-between level - with our family, friends, and the spaces and places of civil society. These, after all, are the spaces where climate change has a tendency to disappear once the headlines move on again.  We settle back into “socially generated silence” or “socially organised denial” around the issue. “What can we do about climate change” is a tangible taboo we politely talk around; not despite, but precisely because, of the reminders of scale of the problem we are exposed to. But this is also the space where we can make the first mundane and tentative steps towards something as grand as “collective action”. And there are some historical precedents here, even if they don’t match the scale of the global warming challenge.  The women’s suffrage and abolitionist movements, for example, were built on countless individual “choices” but not “behaviour and lifestyles changes” of the kind we associate with checklists. These movements depended on people starting (awkward) conversations in everyday settings. Collective action is here interlinked with individual choice – choosing to talk, perhaps through awkwardness and embarrassment at first, learning, voting, writing, protesting, divesting and investing, taking a stand and seeking out others to do it with; coming together, to demand societal and cultural change. This isn’t romantic – as the long grind that marked these movements attests, often in the face of virulent opposition. Collective action in response to climate change does depend on changes in individual choices and actions, then, but not those we tend to find on “how to make a difference” checklists. Let’s live without them, and start talking."
"A little bit of bread and no cheese. This short phrase may conjure bucolic scenes of the British summertime in your head, or it may just remind you of what you need to grab from the shops on your way home.  If you fall into the former camp, you’re probably familiar with the song of the yellowhammer, a sparrow-sized bird recently thrust into our news cycle as the namesake of the Brexit no-deal contingency plan – “Operation Yellowhammer”.  The yellowhammer’s tune is believed to sound like someone saying “A little bit of bread and no cheese”. When naming their preparations for stockpiling food and other essentials, the UK government evoked the yellowhammer’s report of a bare kitchen cupboard.  But there’s more to the yellowhammer than the tune it sings. The fortunes of this plucky bird have their own complicated history with the EU. 

A male yellowhammer delivering its famous mnemonic.
 Yellowhammers (Emberiza citronella) are found in open habitats, particularly heathland and agricultural landscapes scattered with hedgerows throughout the UK and Europe.  They are a species of “bunting”, a seed-eating group of birds restricted to Europe, Africa and Asia. Recently, however, they were found to be more closely related to the sparrows and tanagers of the Americas than the sparrows and finches of Europe that they visibly resemble. The common name “yellowhammer”, or “yellow yorlin” as traditionally known in Scotland, refers to the male of the species, with its gaudy, canary yellow head and upper breast set against its brown-streaked body. By comparison, the female sports a rather drab off-yellow head and breast. Males are particularly noticeable during the spring and summer because of the stamina with which they sing their nasal songs, from the tops of small bushes and trees. Their conspicuousness explains the yellowhammer’s place in the folklore of rural idylls, inspiring poems by Thomas Hardy and Robbie Burns. In “Rural the place, with cart ruts by dyke side”, the poet John Clare wrote of the habits of the yellowhammer: Close to a hill of ants where Cowslips bloom And shed o'er meadows far their sweet perfume. In early spring, when winds blow chilly cold, The Yellowhammer, trailing grass will come, To fix a place and choose an early home, With Yellow breast and head of solid gold. As John Clare noted, yellowhammers begin nest building in early April, laying their eggs in nests low to or on the ground between mid-April and July. Their clutches are small – typically three to four eggs which vary in colour from light blue to reddish-brown. The surface of these eggs is covered by fine, ink-like squiggles, earning the bird another traditional name: “scribble lark”. Yellowhammers are resident in the UK, although they disperse away from breeding territories in the autumn and winter where they frequently form large flocks with other ground feeding birds in search of seed. Despite this, British birds are generally quite sedentary. Roughly 70% of British yellowhammers spend winter in habitats within five kilometres of their breeding territories. Adult yellowhammers typically live for three years, although research on individually marked birds has found the oldest to reach the impressive age of nearly 12 years old.  The simple, wheezing song of the yellowhammer has frequently cropped up in popular culture, even being credited with inspiring the opening “Fate at the door” motifs of Beethoven’s 5th Symphony. While Enid Blyton popularised the mnemonic “A little bit of bread and no cheese” as a familiar sound of the British countryside in her books and poems, it has in recent decades become notable by its absence. Yellowhammers are “red-listed” as a species of the highest conservation concern in the UK, as populations have declined by over 50% since the mid-1980s. Like many farmland birds, their decline is attributed to intensive farming practices brought about under the EU’s Common Agricultural Policy (CAP), which prioritised making the land as productive as possible. For example, a switch from spring to autumn crop sowing has reduced seed-rich foraging habitats that yellowhammers need to survive the winter, significantly affecting local populations.  However, a reform of the CAP in the mid-2000s brought in environmental stewardship schemes, which sought to restore and protect important habitats through environmentally sensitive farming. These schemes remain an important part of the UK’s efforts to halt the decline of farmland birds like yellowhammers. Agricultural subsidies, on a level with the CAP, have been guaranteed post-Brexit until 2022. However, it was recently announced that these payments will face a major shake-up from 2021, including a shift to prioritising habitat for wildlife and improved flood defences over the quantity of land farmed. Many have hailed this plan for ensuring that environmental protection in agriculture remains as part of a “green Brexit”, although as yet the amount of money farmers will receive from the public purse remains undisclosed.  Only time will tell, then, if Brexit spells fate at the door, or leaving with a little bit of bread, but no cheese for yellowhammers and beyond.  Five eggs, pen-scribbled o'er with ink their shells, Resembling writing scrawls which fancy reads As nature’s poesy and pastoral spells — They are the yellowhammer’s and she dwells Most poet-like where brooks and flowery weeds As sweet as Castaly to fancy seems And that old molehill like as Parnass’ hill On which her partner haply sits and dreams O'er all her joys of song—so leave it still A happy home of sunshine, flowers and streams. – The Yellowhammer’s Nest by John Clare."
"Museums, archaeological sites and historical buildings are rarely included in conversations about climate change, which tend to focus on the wider impact and global threats to our contemporary world. Yet these threats impact everything, from local cultural practices to iconic sites of outstanding universal value. In light of this, it’s worth exploring the relationship between our heritage and the changing global climate in more detail. More powerful storms, flooding, desertification and even the melting of permafrost are already destroying important sites at an alarming rate. While we race to preserve or record these places before they are lost forever, it is also the case that some sites – especially those that are or have been highly adaptable and flexible – can also be assets in understanding adaptation strategies more generally.  These questions are currently being explored by an expert working group, which we are part of. Our aim is to unpack the intersection between our changing climate and the world’s cultural heritage, specifically world heritage sites. Building on the Paris Agreement, which notes the importance of traditional and indigenous knowledge when thinking about adaptation strategies, we are exploring how global heritage can be used not only to stress urgency about the dangers and risks of climate change, but also as an asset to enforce community resilience and develop adaptation strategies for the future. Take Russia’s Treasures of the Pazyryk Culture. Located in the Altai mountains, this landscape of burial mounds (kurgans) and rock carvings derive from the Scythian nomadic culture of 2,500 years ago. A few of the two- to four-metre tall stone mounds have been excavated in the past. They reveal an incredible array of artefacts, complex funerary practices, and (most famously) tattooed individuals – all preserved due to the sub-zero conditions. The melting of permafrost due to rising temperatures is expected to significantly impact frozen tombs at the site by the middle of this century. The chemical and biological deterioration of the organic and inorganic contents, previously inhibited by the freezing conditions, is likely to accelerate rapidly, while associated ground movement could cause structural damage to the tombs themselves. The threat to these tombs from rising temperatures has been met with efforts to survey and protect them. While many indigenous people and heritage conservators aim to preserve the burials without disturbing them, it is not yet clear if this can be achieved. Elsewhere, rising sea waters and erosion are having a similarly disastrous impact. The Ruins of Kilwa Kisiwani in Tanzania, for example, are at considerable risk from the impact of increased surf, exacerbated by the loss of mangrove forestry on the island.  This site was founded in the ninth century and became a major trading centre by the 13th century. It was inscribed as a UNESCO world heritage site in 1981 as an exceptional testimony to the expansion of Swahili coastal culture, and to the spread of Islam in Africa in this period. Ongoing efforts are being made here to strengthen the sea wall protecting the site, and to encourage alternate land use strategies to increase natural protection. The area’s iconic heritage is helping to deliver important messages concerning climate change.  In Easter Island, meanwhile, rising sea levels and increasing storm surges are eroding the platforms (ahu) upon which famous statues (moai) are stood. Almost all of these statues are on the coast. It is very clear that climate change is having an adverse and worsening impact on these sites. This damage will destroy parts of the archaeological resource, including subsurface archaeological deposits that are particularly under-researched. The loss of these statues could have a significant negative impact on the tourism economy of Easter Island, affecting the livelihoods and resilience of the islanders. But we can learn a lot from some communities’ response to threat at such sites in the study of climate change resilience. While increased flooding and extreme weather conditions represent a considerable challenge globally, coastal and river communities have been living with (and adapting to) similar events for centuries.  A good example of this localised adaptation can be found on the river island of Majuli in the Brahmaputra River in Assam, India. Majuli is a landscape of both natural and cultural significance. The island is also home to over 30 ancient monasteries, known as sattras, which are repositories of both tangible and intangible culture.  Here, annual flooding has led to significant erosion of the river and the displacement of communities, many of which live outside of the protective levees constructed in recent years. Over hundreds of years, communities on Majuli have developed modular and portable building techniques using local materials including building on stilts. The river and its annual flooding have become part of the everyday experience of living on Majuli and is a part of the local worldview.  More permanent structures of the sattras are not immune to the impacts of the river and some have been moved up to five times over the last 300 years. These places and their associated cultural heritage have evolved to be portable, a valuable skill in a landscape which changes regularly.  It should be stressed that, even with these adaptations, the current pace of climate change is unprecedented and its impact on river and coastal communities will be disastrous. Yet, by better understanding places like Majuli, we will learn much about resilience and adaptation to the inevitable impacts of climate change."
"
Share this...FacebookTwitterDuring the Mid-Holocene, when CO2 concentrations were stable and low (270 ppm), Antarctica’s massive Ross Ice Shelf naturally collapsed, adding the meltwater equivalent of 3-4 meters to sea levels.
Because CO2 concentrations changed very modestly during the pre-industrial Holocene (approximately ~25 ppm in 10,000 years), climate models that are predicated on the assumption that CO2 concentration changes drive ocean temperatures, ice sheet melt, and sea level rise necessarily simulate a very stable Holocene climate.
In contrast, changes in ocean temperatures, ice sheet melt, and sea level rise rates were far more abrupt and variable during the Holocene than during the last 100 years.
Modern ocean changes are barely detectable in the context of natural variability

Image Source(s): Rosenthal et al., 2013; Climate Audit
The temperatures of the global ocean have changed by just 0.1°C in the last 50 years, and just 0.02°C during 1994-2013.
According to Levitus et al. (2012), the global ocean’s 0-2000 m layer warmed by 0.09°C during 1955-2010, while the 0-700 m layer warmed by 0.18°C during that span.
In the context of the Pacific Ocean’s 0-700 m temperature changes during the last two millennia (Rosenthal et al. 2013), that 0.18°C change in 55 years is barely detectable.
Mid-Holocene centennial-scale sea level fluctuations were much higher than today’s
During the Early Holocene, when continental ice sheets were still in the process of melting, sea levels rose at rates that ranged between 10 to 60 mm/yr, or 1 to 6 meters per century (Ivanovic et al., 2017; Zecchin et al., 2015; Hodgson et al., 2016).
During the Mid- to Late-Holocene, when relative sea level was about 2 meters higher than today’s levels, sea levels rose and fell at rates of a half-meter to a meter per century, with 13 mm/yr reached on decadal timescales.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Image Source: Meltzner et al., 2017

Image Source: Mörner et al., 2011
In contrast, the modern record indicates that sea levels only rose at a rate of 1.5 mm/yr during 1958-2014, or about 0.15 of a meter (6 inches) per century.

Image Source: Frederikse et al., 2018
Widespread collapse of ice sheets from 5000-1500 years ago
A new paper (Yokoyama et al. [2019]) suggests that the Antarctic (and/or Greenland) ice sheets melted to such an extent around 5000 years ago that they added between 3 and 4 meters to sea levels.
The Ross Ice Shelf (Antarctica) underwent “widespread collapse” during this period (Yokoyama et al., 2016), subjected to rates of retreat and sub-ice shelf water temperatures much higher than present.
These melting events occurred while CO2 concentrations were a low and quiescent 270 ppm.

Image Source: Yokoyama et al., 2019

Image Source: Yokoyama et al., 2016

Image Source: Yokoyama et al., 2016
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHysteria and insults get refuted
Australia’s election results are in, and once again major media are in state of shock.
The New York Times here for example called it a “stunning win” and claimed it was “propelled by a populist wave” that resembled “the force that has upended politics in the United States, Britain and beyond.”
The UK Guardian went on calling the result of the “climate change election” a “major upset”, complaining that in fact “the climate lost.”
The climate skeptic, German-language Ruhrkultour here commented that citizens have grown increasingly tired of the “climate hysteria”, and that this ultimately “cost Labour the election victory”.
Crosshairs on democracy
Now that the dust begins to settle, the search for answers begins in earnest. But as was the case in 2016 in the aftermath of Donald Trump’s stunning victory, don’t expect the losing side to acknowledge the truth and reality.
Rather look for them to search out a scapegoat. Expect them to even start criticizing democracy and blaming “misled voters”, who were deceived by fake news and populist disinformation campaigns. There will be more loud calls for even greater crackdowns on Internet social media platforms.
“Hope you die!”
The real reason for the loss by Labour is the towering arrogance that left of centre parties have been putting on display lately. Nothing illustrates this better than two tweets recently appearing:
Here’s the first by Australian academic, Daniel Best via Not Suit:

The salt is real. See as what a leftie socialist really wants of those that don't agree.
Agree or die.Convert or die. https://t.co/F38TZgpXew pic.twitter.com/V1irBDTLnR
— Not Suit (@Suitologist) May 19, 2019



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In other words it’s: “Vote for us, or eff yourself and die!”
That’s appalling. And these people think it’s “populism” or the “Russians” behind their losses? Try infantilism, and people being turned off by it.
Threats and insults
If these planet rescuers want to start winning elections again, they need to realize it’s their tantrummy, 6-year old attitude that’s turning everyone off. People are sick of — and frankly appalled — by all their phony “expertise”, bullcrap “consensus” claims, emotional hysteria and fake “climate crisis”. Never mind all the insults.
Yet, The Guardian pledges to get even more shrill about climate and use even bigger bogus threats.
Insulting the elderly
And here’s the second reaction, this one concerning the upcoming EU elections, by Matt Kelly


Source: Telegraph, via Twitter. Read story here.
So Mr. Kelly thinks the elderly are just disgusting incontinents who need constant cleaning up and cannot vote correctly.

Well, people are tired of being threatened and insulted into voting a certain way, and it’s people like Kelly and Best who are disgusting. This is the real reason why people aren’t voting for them.
Wishing us dead
And each time after they lose, none of us of course ends up dying and so in a tantrum they wish us all dead. Thankfully the majority of voters have been able to see through the infantile behavior.
In a way, The Guardian’s latest move ought to be welcome. It will only play into the hands of us “populists” and “deplorables” and ensure us more election victories ahead.
Share this...FacebookTwitter "
"Trees do a lot more for us than you probably think. Their roots prevent soil from eroding, their canopies provide shade and their leaves decompose into nutrients for crops, which feed livestock. Trees provide homes for a diverse range of wildlife and tree crops, such as coffee, rubber, and hardwoods, support countless livelihoods and entire economies. Trees also mark boundaries and hold immense spiritual, cultural and social value for smallholder communities around the world. In the 1980s, charities proposed planting more trees to halt “desertification” in the Sahara Desert. This involved “afforestation” – planting trees where they had not grown for a while and “reforestation” – replacing recently lost tree cover. Today the idea is growing strong, and an array of private companies from adult website Pornhub (yes, Pornhub) to clothing brand Ten Tree are using trees as a marketing tool. 


      Read more:
      Pornhub has planted a few more trees, but don't pretend it's being responsible


 Businesses can offset their environmental impact by planting trees or supporting other forms of habitat restoration, so as to “pay off” the damage they cause locally. As climate change escalates, trees are in vogue for their potential to soak up the carbon dioxide we keep putting in the atmosphere.  The United Nations (UN) has even adopted a scheme for offering local communities and governments some sort of financial payout for saving trees from deforestation. This “economy of repair” has been adopted by some of the largest companies in their commitments to corporate social responsibility. One such programme is the Green Belt Movement – a Kenyan conservation NGO started by the late professor and Nobel Prize recipient Wangari Maathai.  Maathai’s original mission was to empower local people, particularly women, to overcome inequality through leading forest restoration and resisting the expanding Sahara Desert. Despite the involvement of charities and businesses, research has suggested that in programmes like these, it is farmers and local people, not companies, which make the biggest contributions to planting new trees. Since local people also inherit responsibility for them, it’s important that projects devised by outside parties are planned and executed wisely, and in the community’s interest. 


      Read more:
      Africa's got plans for a Great Green Wall: why the idea needs a rethink


 While some may argue that tree planting is a win-win for the environment whoever does it, offsetting is just another way of corporate greenwashing. Environmental damage in one place cannot somehow be fixed by repairing habitats elsewhere, sometimes on the other side of the world. Here are some of the ways in which indiscriminate tree planting can cause more harm than good. Diverse forests are often cleared for agricultural production or industrial use, and replaced by uniform stands of the same species selected because of their ability to grow fast.  Tropical forests in some cases take up to 65 years to regrow and their diversity cannot be replicated by a monoculture of reforested plots. Reforestation and afforestation schemes must decide which species are appropriate to plant – native or exotic, multi-purpose or fast growing, naturally regenerating forests or managed plantations. Sometimes the wrong species are selected and Eucalyptus (Eucalyptus globulus) is one such poor choice. Eucalyptus is usually chosen because it is fast growing and economically valuable. Yet, it is exotic to many places it is now planted and requires lots of water, which drains the water table and competes with native crops. In Europe, replacing broad-leafed native oak trees with faster growing conifers has meant that forest cover on the continent is 10% greater than it was before the industrial revolution. However, the new trees are not as good at trapping carbon but do trap heat more efficiently, contributing to global warming. Clearly, tree planting without due caution can do more harm than good. Tree species take a long time to grow and need continual care. However, tree planting schemes usually “plant and go” –- meaning they do not put resources into managing the trees after they are placed into the ground. Young trees are particularly vulnerable to disease and competition for light and nutrients and if not cared for, will eventually die. Trees planted by states or private donors may choose sites without consulting local communities, ignoring any of their customary land rights and management regimes. This locally-owned land may be in fallow or have different economic, cultural or spiritual uses. Blundering into planting in these places may exacerbate tensions over land tenure, spreading disinterest in tree care and stewardship. Dispossessed locals may move to existing forests and clear land for food production. Tenure rights over trees are also not always owned by whole households either, but divided between gender. Planting trees and asking questions later may sow tensions over land ownership for long after the project departs. It’s no surprise that trees are on the green economy agenda, but this does not necessarily mean that planting them is “green” or helpful for social harmony. Allowing trees to regrow naturally is not always effective either, as trees are unlikely to survive on their own. Community involvement is therefore crucial.  This means real consultation over site and species selection, property rights over the trees, their products, and the land they grow in and who takes on the labour to keep the trees alive after they are planted. If companies are serious about planting trees then they need to care about the communities that live with them and not just their own reputations."
"
Share this...FacebookTwitterFor those serious about taking concerted action to combat climate change, implications from a 2018 study suggest that the widespread abandonment of  smartphone use — which is collectively on track to add 125 megatons of CO2 equivalent per year by 2020 — may be key to preventing the planet’s catastrophic demise.

Image Source (adapted): Press-Herald
Most people haven’t considered their smartphones to be significant contributors to global CO2 emissions.
But they are.  And they are poised to become one of the more prominent obstacles to global efforts to reduce CO2 emissions in the coming decades.
The unsustainable expansion of smartphone emissions
A recent analysis by Belkhir and Elmeligi (2018) determined that the greenhouse gas emissions from the Information and Communication Industry (ICT) – smartphones and mobile devices, prominently – will grow from 1% of total global emissions in 2007 to 14% by 2040. That’s more than half of today’s relative contribution from the globe’s entire transportation sector.
In 2010, smartphone use added 17 megatons of CO2 equivalent (17 MT-CO2-e) to annual global emissions. By next year (2020), smartphone emissions are expected to reach 125 MT-CO2-e/year – a 730% explosion in just 10 years.
Last year (2018), there were 2.5 billion smartphone users.  Belkhir and Elmeligi suggest that if there aren’t serious efforts to reduce or eliminate smartphone use in the near future, the number of smartphone units across the globe may reach 8.7 billion by 2040.
This is unsustainable, dramatically undermining global efforts to reduce CO2 emissions.

Image Source: The Conversation
Protesters demand climate action


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This past weekend, climate change protesters took to the streets across the world by the hundreds of thousands.
Many of these protesters were children and youth.  They decided to skip school last Friday to demonstrate just how deeply concerned they are about the Earth’s climate.
There is little these young people can do to save the planet from extinction as far as directly influencing government policy.
However, there is something that they – and we – can do that would make a difference in reducing our CO2 emissions impact: give up our smartphones.
Permanently.
And encourage all our friends and family members to do the same.
Widespread smartphone renunciation would be a symbolic testament to our commitment to rescuing the planet from the oncoming climate catastrophe.
It’s not too late…yet.  Shall we begin?

Image Source: Belkhir and Elmeligi, 2018
Share this...FacebookTwitter "
nan
"Residents are struggling with the aftermath of Hurricane Florence, a record-breaking storm that has hit the US east coast and led to at least 32 deaths, floods and damaged homes. Meanwhile, Typhoon Mangkhut has been ravaging southern China. More than three million people were evacuated. In the last few years, AI has become ever more powerful. It can diagnose diseases, book restaurants, fake presidential speeches, and even compose hit music and produce trailers for horror movies. So in this new era of “big data” and “artificial intelligence”, do we have new tools to protect our society and manage the damage of such storms? AI demonstrated a superior ability to understand certain situations in 2016, when the programme AlphaGo beat Lee Sedol, 18-time world champion, at the game Go, the most sophisticated game in history. But is this superior capability seen elsewhere, too? Could, for example, AI understand, predict and manage natural disasters – such as floods – better than humans can? A computer game and a flood are obviously two very different things. But AI is catching up humans in understanding “things”. For example, researchers recently demonstrated that AI could help diagnose breast tumours from the medical imaging. And more preliminary research is showing that AI could definitely help us monitor floods and could perhaps even deliver more accurate early warning messages in the near future. In a recently published paper, I describe how I used two of the most popular AI techniques to monitor tweets and photos streamed from Twitter and a mobile app called MyCoast. These AI-based algorithms can identify the location mentioned in a tweet about flooding and describe the content of the photos to recognise flood scenes through intensive training with “worked examples”, photos manually labelled by humans using keywords. After such training, the trained AI could make a prediction about whether a new photo is a flood scene or not.  Diagnosing breast tumours and identifying floods is, of course, something that humans can do. But AI can up the potential of such human capability by a major scale. An AI programme, for example, can read thousands of tweets and photos in seconds. In addition, AI does not tire – its judgement is kept at the same level all the time. In comparison, human judgements are subjective, changing due to decreasing concentration and fluctuating emotions. So yes, AI is much more powerful than humans in these aspects, especially in terms of speed and volume. So should we be worried about this power? Many argue that we should worry about AI using natural disasters to destroy human society, as imagined in the recent movie Geostorm. Technology tycoon Elon Musk has also spoken of AI posing an “existential risk” to humans. But it is important to note that AI cannot compete with humans, at least in the foreseeable future, in many other areas. First, AI is a mimicking algorithm of human judgements. AI is better than humans in terms of speed and volume, but not in terms of quality. This is especially true of flood monitoring. My research demonstrated that AI could make mistakes in recognising flood scenes. However, this situation might change in the future, as it did in the case of the game Go. As more training datasets become available, the accuracy and reliability of AI’s predictions will be further improved. Second, AI is still weak when it comes to prediction. Although these algorithms can make acceptable forecasts within the scope of the past, predictions become wild when they go beyond the parameters of the training data. Say you are given a series of points to connect with a line. It’s relatively easy to guess what lies between the points as the guess cannot be absurdly wrong (assuming the data is not fluctuating too much). But it will be far more difficult to guess the point beyond the most right and the most left points because there is no evidence as to how they will change.  In terms of flood-monitoring, then, it is difficult to predict long-term flood  trends based on the past training datasets because climate change is fundamentally changing the trend of many hydrological factors. We have no acceptable training data in this case. But the most fundamental difference between AI and humans, I think, is the difference in consciousness, or more specifically, motivation. So far, AI will do whatever the users ask, but it cannot come up with an idea of its own. My two-year-old daughter can easily exceed AI when she says “I want that candy”. She can even improvise by saying repeatedly “I want want that candy” to emphasise her demand. I cannot imagine an AI algorithm that could do anything even close to that. At the end of the day, we need creative solutions, and AI is not capable of providing them. AI, then, is currently merely a tool to scale up human’s “understanding” and maybe “prediction”. It has a long way to go before it catches up with human thinking, creativity and motivation."
"Hundreds of thousands of native fish are estimated to have died in northern New South Wales after rains washed ash and sludge from bushfires into the Macleay River. Parts of the Macleay River – favoured by recreational fishers – have been turned into what locals described as “runny cake mix” that stank of rotting vegetation and dead fish. One freshwater ecologist told Guardian Australia the impact of the fish kill might be felt for decades to come, with long-lived species like Australian bass hit hard. The NSW Department of Primary Industries has been receiving reports of “hundreds of thousands” of fish dead in the river since December 2019. Locals say rain in the past 10 days has seen more ash and mud from the parched and burned landscape running into the river. The disaster on the Macleay River is one of eight fish kills reported to the department this year, with the cause of most linked to lack of rainfall. Larry Newberry, a recreational fisher from Frederickton, near Kempsey, said he drove 100km to George’s Creek to survey the river last weekend. “I would say from what I’ve seen I would not be surprised that it’s wiped out every fish in at least 100 kilometres of the river,” he said. “The stench was overwhelming – it stank that much it made you heave. It’s the dead fish, the rotting vegetation and the ash from the fires and maybe the fire retardant. It is just like brown sludge. “I’ve been fishing the river for 50 years and I have seen fish kills before, but nothing of this magnitude. This will be happening in every east coast river that’s been hit by bushfires.” Newberry was critical of commercial fishing operations that had been catching Australian bass, and also the primary industry department for what he called its lack of response. Species seen dead and reported to Guardian Australia were Australian bass, eels, bullhead mullet, yellow-eye mullet, herring, gudgeons and catfish. Upstream from Kempsey at the town of Bellbrook, residents have been using pumps and hoses borrowed from firefighters to try and oxygenate the water. Newberry said he admired the efforts but feared it was “like pissing into a 40 kilometre an hour nor’easter”. James Pritchard, a founder of the Bellbrook Social Fishing Club, said rain on Thursday evening had raised the level of the river, but had “brought tonnes and tonnes of debris and dirt with it”. He said: “There’s more ash in the river now than I’ve ever seen before. The top of the river is covered in ash. The water looks like a runny cake mix. It’s terrible. “The river is finished for generations – I won’t see this come back in my lifetime. To say I’m fucking gutted isn’t the word.” Aboriginal elders relied on a healthy river for food and to teach culture, he said, and this would devastate those efforts. “This is so wrong. The DPI knew this was going to happen and they’ve put nothing in place,” he said. Prof Lee Baumgartner, a freshwater ecologist at Charles Sturt University, said the fish would have suffocated.  Adding ash and nutrients to the water promotes bacteria, which in turn removes oxygen from the water. And if the water becomes sludgy, fish are not able to pass enough water over their gills to extract oxygen. Even though efforts to oxygenate the water might seem futile, he said even one saved mature female bass could then go on to spawn and lay hundreds and thousands of eggs. He said there was a precedent for understanding the long-term impacts of an event such as this: major bushfires in 1939 had caused ash to run into the Lachlan River, and “the fish never recovered”. He said: “I think we’ll see more of these events as it rains. These things can have decades of impact. It can be really terrible.” The department’s “fish kills” page also has reports of hundreds of dead fish at Tilba Lake on the south coast of NSW, where soot had been reported on the banks, alongside dead bream, flathead, mullet, eels and blue swimmer crabs. Drought had also likely caused the death of thousands of fish in the Hastings River near Port Macquarie, the page reports. A NSW DPI statement said its fisheries department “continues to investigate a fish kill event on the Macleay River”. The statement said: “The suspected cause of the incident is poor water quality leading to low dissolved oxygen. Rainfall events are adding ash from the extensive bushfires throughout the region into local catchments, as well as other organic matter and sediment. This can cause rapid drops to oxygen levels in the water. “Fisheries staff have conducted numerous field assessments and the main species affected have been Australian bass, freshwater mullet and eel-tailed catfish. The number of fish impacted is estimated to be in the hundreds of thousands.” Community members were encouraged to report fish deaths or observations to the Fishers Watch hotline on 1800 043 536."
