"
Share this...FacebookTwitterA new paper written by Maeng-Ki Kim, Department of Atmospheric Science, Kongju National University, and Seonae Kim of the Applied Meteorology Research Team, Environmental Prediction Research Inc. of Korea has been published by the Journal of Atmospheric Environment.The two scientists examined cities in South Korea and the urban heat island effect. Hat-tip: Dr. Ghana.
According to the abstract here (emphasis added):
The quantitative values of the urban warming effect over city stations in the Korean peninsula were estimated by using the warming mode of Empirical Orthogonal Function (EOF) analysis of 55 years of temperature data, from 1954 to 2008. The estimated amount of urban warming was verified by applying the multiple linear regression equation with two independent variables: the rate of population growth and the total population. […] The cities that show great warming due to urbanization are Daegu, Pohang, Seoul, and Incheon, which show values of about 1.35, 1.17, 1.16, and 1.10°C, respectively. The areas that showed urban warming less than 0.2°C are Chupungnyeong and Mokpo. On average, the total temperature increase over South Korea was about 1.37°C; the amount of increase caused by the greenhouse effect is approximately 0.60°C, and the amount caused by urban warming is approximately 0.77°C.”
According to their results, that means well over a half of the warming is caused by urban warming.
Why aren’t we surprised? Anyone who has read Ed Caryl’s very recent stories here at this blog and is familiar with Anthony Watts’s surface stations audit knows why.
 
Share this...FacebookTwitter "
"
539 new snowfall records were also set.
Since we are often treated to lists of record high temperatures when heat waves occur and they are improperly linked to global warming (like in Russia’s heat wave this summer), I thought it only fair that I show the number of record cold and snow records around the USA for the past week that aren’t linked to global warming.
Record low temperatures, low max, and record snowfall plotted - click for interactive graph
Of course it wouldn’t be fair to show just the lows temperatures and snow, so here are the high temperature records for the USA in the past week. 
Reord high temperatues for the past 7 days - click for interactive map
And here’s just the lows:

The summary of new records of interest for the past week in the USA :



Snowfall:
539


High Temperatures:
18


Low Temperatures:
336


Lowest Max Temperatures:
278



Lows outnumbered highs by a factor of 19 (336/18=18.6 ~19). That’s quite the cold snap.*
The coldest?
Deadhorse, Alaska, 	on Sunday, 26 Dec 2010	at -40°F beating -38°F set in 1984
*Note: some people clicking on the interactive map will see different numbers, since that map will record new highs and lows as this post ages. The headline was originally based on 16 highs during the week (see the highs map for a ratio of 21 to 1) then by the time the post editing was completed and the post made, the number of highs was up to 18, giving an 18.6 to 1 (~19 to 1 in the title) ratio. Later in the day the number of record highs in the one week period increased as new weather occurred (on Dec 31) and reports came in. The numbers were accurate at the time the post started. Weather records, like weather itself are dynamic with the forward moving one week period the interactive map generator uses, so please don’t assume error if you click on the interactive map and the numbers don’t match now, or in the future. – Anthony


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e85a95bd3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"People like to say that we cannot witness evolution because it occurs over timescales immensely greater than our lifetime. That’s incorrect. We can witness evolution all we want, in our lifetime, by watching other things that change and morph freely – for example the evolution of sports, or the evolution of technology. Evolution in technology is the same as the evolution of a biological species. The ‘organism’ in this case is the human-and-machine species. Machines do not happen by themselves; they are created by humans, because of human needs, and it is humans that add the abilities of their creations to their own in order to improve them – to make their bodies move more easily, or more economically, more safely, or further over the earth. More technology tends towards more and better life. Evolution is about facilitating flow, the movement of one thing over or past another. Flow systems, the designs created by this evolutionary process, change freely over time. As such, evolution is a physical phenomenon, not just a biological one. The changing organisational structures that facilitate greater and better flow are physical objects, whether animate or inanimate. In an article just published in the Journal of Applied Physics, we documented the evolution of a single technology – aircraft. We predicted this evolutionary path based on the laws of physics and their application to how designs evolve in the natural world. This is the constructal law: for a flow system to persist in time (in effect, to live) its configuration must evolve to allow greater and easier access to its currents.   We showed that aircraft must have predictable (theoretical) design features that unite them with the birds and other flying animals. For example, larger aircraft must be faster, more efficient as vehicles and must cover greater distances. The engine weight must be proportional to the total body weight; this scaling is the same throughout animal design, where the size of the body parts driving the movement (muscle, heart, lung) is proportional to the body size.  Large or small, an aircraft must have a wing span that is proportional to the fuselage length. The fuel load must be proportional to the body size. The animal design counterparts of these human-designed, technological features are evident. Looking at how these evolutionary laws govern the current trend followed by aircraft until now, we can predict the same laws will govern how aircraft will change into the future. We’ve used the constructal law to predict the design features of many other seemingly unrelated natural phenomena. For example, the shape of river basins (four tributaries feeding into one larger channel), vegetation (roots, trunks, branches, forests), animal design (body insulation, respiration, blood circulation, skeleton, and ability to swim, run, or fly) and the wheel as a natural rather than human design. It has also explained human phenomena such as the evolution of sports (speed vs body size for sprint running or swimming, throwing sports such as baseball, golf and boxing), social organisation (rankings of universities and sports teams, urban design, city traffic), and the evolution of many types of technology such as electronic cooling, steam and gas turbines, power plants, refrigeration plants. The view that emerges is that the phenomenon of evolution is much broader and more visible than simply biological evolution. The constructal law unites the evolutionary designs of the realm of animate creatures with those of the inanimate, social and engineered.  What works is kept. Architectures that offer greater and improved access to flow persist over time, and are joined by even better ones. Together, the vascular tapestry of old and new designs carries the global human flow – from the microscopic to the macroscopic level – easier and farther than the old alone. To return to the example, new and old designs for mass transport by air provide a more effective mechanism to aid mixing and flow of people around the globe more effectively than in the absence of new models.  Flow leads to better flow. Flow architectures are evolving right now, throughout nature and throughout our technologies, in accord with the constructal law. Evolution is one phenomenon of nature, and it belongs under physics, the biggest tent of science."
"

This passage from the EPA’s “Regulatory Impact Analysis for the Proposed Standards of Performance for Greenhouse Gas Emissions for New Stationary Sources: Electric Utility Generating Units” sums up the intent and justification of the proposed standards.



“While sector‐​wide modeling does not project any new coal‐​fired EGUs [electric generating units] without CCS [carbon capture and storage] to be built in the absence of this proposal, we recognize that a few companies may choose to construct coal or other solid fossil fuel‐​fired units. In Chapter 5 of his RIA we present an analysis of the project‐​level costs of a new coal‐​fired unit with and without CCS, and estimate the social benefits of requiring CCS on a new uncontrolled unit. We also present a sensitivity analysis indicating that even in the unlikely event that market conditions change sufficiently to make the widespread construction of new conventional coal‐​fired units economical from the perspective of private investors, this rule would result in net benefits from avoided negative health and environmental effects.”



As we will show, this justification fails in virtually all of its aspects:



1) the social cost of carbon (SCC) estimates used by the EPA to compare project‐​level costs of new coal‐​fired power plants with and without CCS technology are overinflated and thus wrongly favor the adaptation of CCS;



2) the Rule would not result in net benefits from avoided negative health effects as human health is improving — partially as a result of climate change; and



3) the Rule would not result in net benefits from avoided negative environmental effects as the environmental impacts of the Rule are negligible and scientifically undetectable.



As a consequence, this proposed standard should be withdrawn and not revisited.
"
"Q: Can you recommend some climate crisis fiction? The nonfiction is too depressing and fiction often helps the heart cope with the worldPeggy Duesenberry, 61, Massachusetts, US A: Melissa Harrison is a novelist and nature writer whose books include At Hawthorn Time and All Among the Barley. She writes: There are plenty of dystopian cli-fi novels out there, designed to jolt us out of our current complacency – but it doesn’t sound as though that’s what you need. The American poet and climate activist Kate Schapira believes we must “imagine – and learn about! there are precedents! – the structures that would allow us to live well enough without hurting ourselves and each other, and without helping the people currently hurting us”. Fiction can help us do that imaginative work. The brilliant Jenny Offill’s new novel Weather is a great place to start, as it explores what it’s like for ordinary people to move from fear and denial to concrete action. Emily St John Mandel’s haunting Station Eleven (2014) takes us into a near future where disease has led to a breakdown of society, but not a world devoid of hope, for Shakespeare’s plays survive, and art and love remain central to the human experience. Set in an Australia ravaged by climate change, Alexis Wright’s richly strange, genre-bending The Swan Book (2016) is a reminder that other, older cultures may have healthier and more connected relationships to the natural world than the destructive western capitalism currently in the ascendant. Since writing The Dispossessed (1975), Ursula K Le Guin has concluded that an “anarchist utopia” such as the one she describes would eventually destroy itself – but as a way of envisioning a society organised on different principles to ours, it continues to inspire. Finally, Tove Jansson’s gorgeous, sparklingly simple The Summer Book (1972), in which a little girl and her grandmother spend a season on a Finnish island, has two vital lessons for today: how to live a rich, creative life with very few resources, and how to remain clear-eyed and full of courage in the face of grief and loss. The work we need to do now is as much moral and imaginative as it is practical. These are novels that can shift our values and priorities, if we allow them to. Submit your question for bookclinic below or email bookclinic@observer.co.uk"
"Earthquakes threaten to be a show-stopper for fracking. In the Netherlands, the largest gas field in Europe will be shut down by 2030 after sustained damage to homes from earthquakes became too severe. In Oklahoma, US officials have severely curtailed operations after injection of waste water underground caused several earthquakes above magnitude five – one nearly 180,000 times stronger than the 2.3 magnitude earthquake that brought a seven-year pause on fracking in the UK. While operations have since resumed in Britain, the practice still remains a political battleground, with earthquakes at the centre. The UK government’s fracking commissioner, Natascha Engel, recently resigned, claiming that an [unreasonably low] magnitude 0.5 threshold for tolerated earthquakes amounted, in effect, to a ban on fracking. Residents, on the other hand, largely oppose fracking near their homes. Fears of damage to property and the well itself at a fracking location in Lancashire, in the north of England, notably lowered house prices in the area. In the absence of a known mechanism by which fracking could cause earthquakes more than a mile or two from drilling sites, operators have often denied responsibility for such quakes. However, new research has now linked distant earthquakes to fracking, providing evidence that much larger areas surrounding sites may be at risk from drilling operations than previously demonstrated. This is a critical problem not only for fracking, but for cleaner energy solutions too. 


      Read more:
      Fracking causes earthquakes by design: can regulation keep up?


 Fracking involves injecting a high-pressure mixture of water, sand, and chemicals into shale layers to create fractures, opening pathways along which trapped gas in the shale can be extracted. Once this waste water has served its purpose, it can be reused for fracking injections at another site. By design, the breaking of rock that inevitably accompanies both waste water disposal and fracking produces small, usually imperceptible earthquakes. Occasionally though, the injection of fracking fluid or waste water can cause movements in natural pre-existing geological faults – large cracks that already exist in the rock. This can trigger the release of loaded energy stored in the fault, in much the same way a skier can trigger the release of an avalanche. If sufficiently severe, the resulting earthquake can cause damage to houses, threatening local communities. Some of these earthquakes occur very near the fracking site itself, but others have been reported as far as 50 kilometres away, making it difficult to guarantee the safety of surrounding areas. The new study, published in Science, takes a significant step forward in understanding this phenomenon. Experimenting in shallow geological faults, the researchers found that pumping water into these areas caused the rock along the fault lines to slowly slip. These “silent” movements didn’t produce earthquakes at the initial point of slippage, but gradually increased the pressure on more distant parts of the faults, inducing earthquakes much further away from the borehole than the injected fluid could reach. The research shows that by this mechanism, fracking can induce earthquakes tens of kilometres away. In Oklahoma, where fracking is an established practice, millions are at risk from property damage. This, of course, is not good news – but the first step in assessing whether a problem can be solved is understanding it. Setting the wider debate over the legitimacy of fracking to one side, the results are an important step forward in determining whether the key safety concern with fracking can be resolved. For example, we may soon be able to make accurate calculations of the extent of vulnerable areas, and the timescales on which earthquakes could occur. Being able to provide reliable information to residents and authorities would tackle the unknown in what is often an emotionally charged debate, and allow all involved to make an informed decision on whether fracking should be allowed.  It’s important to note that the problem of induced earthquakes is not just reserved to fracking. Several potential sources of clean energy and carbon dioxide removal technologies are also prone to inducing earthquakes. For example, most geothermal power stations re-inject the hot water extracted for electricity generation back into the ground to prevent reservoirs from running dry. Dry rock geothermal power stations also inject high-pressure water into deep wells to extract heat from fractured rock near the Earth’s core, causing earthquakes in a similar way to fracking. Underground storage of captured carbon dioxide – likely to be key in supporting the transition towards clean energy – can also induce earthquakes. An earthquake-induced rupture of an artificial carbon dioxide reservoir would nullify costly efforts to keep the gas out of the atmosphere, as well as posing health risks to local residents – so understanding how to manage such risks is imperative in the development of such technology. Much work is still required, and it’s not yet certain whether there is a way to stop underground fluid injections from causing earthquakes. But at the very least, we are one step closer to finding out. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"
Share this...FacebookTwitterVeteran meteorologist Klaus-Eckart Puls made a presentation on sea level at the 4th climate conference in Munich at the end of last year. The data are clear: sea level rise is slowing down.

Here are the data Puls presents:
0:35 – Not everyone is convinced sea levels will rise quickly. Qatar just built a stadium on a man-made island.
1:30 – Sea level is complex and ranges on the planet from 110 meters below and 85 meters above the average due to gravitational variations. Geophysics is the main factor in sea level, and not climate. From all the physical factors, the talk in the media is only about the relatively minor climate component.
3:40 – Global mean trend from 60°N to 60°S is 2.8 mm. (Topex, Jason 1 and Jason 2, 1993 – 2010).
4:20 – 10,000 years ago the sea level was over 100m lower than today.
5:00 – The North German sea level has risen 1.35 m over the last 400 years, i.e. 35 cm per century. But from 1900 to 2000 it rose only 25 cm – a slowdown even though CO2 and temperature increased.
5:50 – It’s not the climate that’s a catastrophe – it’s the media.
6:40 – The sea level at the North German bight measured by 14 tide gauges shows a deceleration in sea level rise, 1843-2008. German authorities “see no signs of any climatic related sea level acceleration”.
8:30 – International tide gauges also show: No acceleration in sea level rise. In fact tide gauges show a deceleration. Puls asked the Potsdam Institute for Climate Impact Research for an answer, but they have yet to reply.
9:00 – EUMETSAT shows a deceleration over the last few years.
9:30 – “The measured data show us completely different results from the models, and that for 20 years.”
9:40 – The last two years show a distinct sea level drop.
10:30 – Envisat ESA satellite also shows a clear sea level drop since 2009.
11:10 – Puls compares tide gauge data (1.7 mm / year) and satellite measurements (3.27 mm / year). Scientists are baffled by the disagreement. Puls says, “It is obviously a measurement system problem.” Simon Holgate: “It is improbable that the sea level rise accelerated in the same year satellites began to operate.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




12:30 – John Church: It is unclear if there has been an acceleration since 1993.
12:55 – Tuvalu 1992 – 2009 data show that variations are tied to the Southern Oscillation. Moreover, Tuvalu is located on a tectonic fault and measured sea level changes there are due to tectonics, and not climate change.
16:00 – Quotes Mörner: “A 2°C warming of the upper 100 meters of the ocean would lead to only a 35 mm rise”. Thermal expansion of the ocean is completely exaggerated. It would take thousands of years to do that because to warm 1 meter of water 1°C, you need to cool 3000 meters of air 1°C.
17.20 – Quotes Trenberth: “No ocean temperature increase in the last 10 years. Moreover there seems to be a slight cooling”. Clearly if there is no ocean warming, then there can be no thermal expansion.
19:15 – Quotes Hans von Storch: “A statistical relationship between air temperature and change in sea level cannot be postulated.”
20:00 – Puls reminds us that there are still some journalists who keep saying the North Pole is melting and so the sea level is rising.
20:30 – The Antarctic is getting colder, and sea ice extent is growing. So is the thickness.
20:56 – Quotes the Alfred Wegener Institute (AWI), “A warmer climate in the Antarctic could however lead to more snowfall. The Antarctic ice sheet would tend to thicken rather than melt in the event of warming.”
21:50 – Quotes Prof. Dr. Heinz Miller of the AWI. “According to our calculated scenarios, we come to the conclusion that changes in the huge ice mass cannot contribute to sea level rise.”
22:20 – The AWI also said: “Although Greenland will likely lose ice mass, the loss of mass resulting from the melting in Greenland will be compensated by an ice gain in Antarctica.” No wonder the IPCC is continuously revised its sea level projections downwards.
23-20: Rahmstorf’s projection of 1.40 meters sea level rise by 2100 has nothing to do with reality.
23:40 – The newest panic is ocean acidification. Puls concludes: “Ocean acidification is an artifact!”
25:00 – Shows slides(in English of quotes by Nils-Axel Mörner.
27:00 – Puls concludes: “There is not going to be any acceleration of sea level”.
 
Share this...FacebookTwitter "
"Polluting the environment is a crime which can have countless victims – of numerous species and future generations. Whether it’s an oil spill in the sea, a release of raw sewage into a river, or a cloud of toxic gas into the air, the public has a clear interest in seeing criminal acts of pollution punished.  For a long time, courts have often been seen as soft on polluters, hesitating to penalise environmental criminals harshly. Yet recently, it seems that large fines against corporations have become increasingly common in the UK. In March 2019, Severn Trent Water was fined £500,000 for spilling thousands of gallons of raw sewage in a Birmingham park. It was the latest in a series of expensive court appearances for water companies over the last half decade. In 2014, the Court of Appeal handed a £250,000 fine to Thames Water, following the illegal discharge of untreated sewage materials into a stream in the North Wessex Downs. A year later, United Utilities was fined £750,000 after a pumping failure resulted in a raw sewage spill into the protected Duddon Estuary in Cumbria.  In 2016, Thames Water found itself in the dock again for illegally emitting sewage debris and sludge into the Grand Union Canal. It received a record £1m fine – a record which lasted little more than a year. In 2017, the same company was charged with emitting an estimated 1.4 billion litres of raw sewage into the river Thames and fined £20m. These large fines represent a visible change in the way courts have responded to environmental crimes committed by large corporations. It is a change which followed the introduction in 2014 of specific sentencing guidelines for environmental offences, which provide a set of considerations a judge must take into account when sentencing an environmental offender.  They include the culpability of the offender, the level of environmental harm caused, and the offender’s financial means. Evidence from the Sentencing Council indicates that the median fine levied against corporate offenders has more than doubled since they were introduced. So does this mean environmental criminals can now expect hard justice when committing environmental crimes? Sometimes, yes – at least if you are a large utility company causing significant environmental harm. But there are several reasons to think the impact of the fines might be limited.  First, the evidence compiled by the Sentencing Council suggests no spike in the level of fines handed down to individual (non-corporate) criminal offenders. This could mean that severe penalties are not applied to every transgressor.  Second, the increase in severity of fines has taken place against a drop in the overall number of prosecutions brought by the Environment Agency.  Third, many of the companies in charge of Britain’s crumbling water utility infrastructure are large companies which generate hefty profits. The £20m fine against Thames Water amounts to less than two weeks’ worth of the company’s profits. Is that an inadequate deterrent? Yet on the positive side, a move towards stricter penalties does create an incentive for polluters to come forward and report accidental, yet criminal, environmental harm to the Environment Agency. By doing so, they can enter into a so-called “enforcement undertaking”, a legally binding agreement between an offender and a regulator. In these, an offender aims to take certain steps to cease illegal activities which cause environmental harm, and promises to make specific changes to its operations.  Since being made available in 2011, the Environment Agency has accepted over 300 enforcement undertakings, and collected more than £13m in payments to environmental organisations and community groups. Importantly, almost all enforcement undertakings agreed by the Environment Agency include provisions for compensation to third parties affected as a result of the crime or for charitable donations to be made to environmental organisations. An example of this was when after the spillage of raw sewage in County Durham, Northumbrian Water paid £135,000 to three local environmental charities. From an offender’s perspective, there is much to like in an enforcement undertaking, which can avoid the stigma and reputational damage of a criminal sentence. Similarly, they are popular with the Environment Agency which is able to save on the costs of a criminal prosecution. The undertakings also allow for the community affected by pollution to receive some kind of financial compensation.  These positive developments notwithstanding, there are risks associated with the widespread use of enforcement undertakings. We don’t know, for example, what the £13m in payments to environmental organisations is actually spent on, as there is no public scrutiny or accountability mechanism overseeing this. Nor do we know how negotiations between the Environment Agency and a polluter are conducted.  These limitations, however, might not be reason enough to limit the use of enforcement undertakings which are generally seen as a cost-effective and informal way of securing compliance.  Importantly, as Brexit will fundamentally alter the legal landscape for environmental protection, the need for innovative and effective action is likely to increase. The combination of heavy fines and negotiable enforcement undertakings provides a solid foundation from which to respond to those changes."
"

Mr. Chairman and members of the committee, thank you for inviting me to testify today regarding energy efficiency and the federal tax code.



Additional tax incentives, such as tax credits, probably could reduce U.S. energy consumption modestly.1 However, narrow incentives complicate the tax code, create distortions that reduce growth, and move down the slippery slope of widespread social engineering through the tax system.



On the other hand, Congress should reform tax provisions that hinder new investments in energy production and conservation. Current business depreciation rules for energy and conservation investments are unfavorable compared to the rules in other countries. Congress should reform those rules, and it should pursue broader tax reforms to spur more rapid replacement of older structures and equipment with newer, more energy efficient infrastructure throughout the economy.



Policymakers have long considered major reforms to the federal tax system. Some favor a broad‐​based consumption tax, while others favor a broad‐​based (or Haig‐​Simons) income tax. The difference between the two is the treatment of savings and investment. Consumption taxes apply one layer of tax to savings and investment, while income taxes apply two layers. The current federal “income tax” is a hybrid between the two systems.



Reforms to move the current tax code toward a consumption‐​based system dovetail with the goals of those concerned about America’s energy future. A consumption tax would limit current consumption, including energy consumption, while removing tax barriers to investment‐​including investment in energy production, energy technologies, and energy conservation. As discussed below, more favorable depreciation rules would be an important step in a consumption tax direction.



The federal tax system has become enormously complicated in recent years. The anti‐​investment bias and high tax rates under the current system have encouraged the proliferation of narrow loopholes and special preferences. There seems to be more interest on Capitol Hill these days in creating new tax credits than in simplifying the tax code to provide fair and equal treatment of all taxpayers.



By contrast, during the 1980s there was bipartisan agreement that the tax code should be reformed to have a broad and neutral base with low rates. One congressional leader on tax reform at the time, Richard Gephardt (D-MO), noted in 1985:



The main argument for tax reform, I believe, is to achieve greater efficiency in the way the tax code works. When Congress gets into the business of figuring out $370 billion of tax breaks a year, the House Ways and Means Committee and the Senate Finance Committee really are put in the business of trying, at least partially, to plan the American economy. … I confess that I am not qualified to act as a central planner and I do not know anybody on either committee who is.2



The Reagan administration held similar views about tax reform. The Congressional Research Service noted that the administration



opposed using the tax law to promote oil and gas development, energy conservation, or the supply of alternative fuels. The idea was to have a more neutral and less distortionary energy tax policy, which economic theory predicts would make energy markets work more efficiently and generate benefits to the general economy.3



The two parties came together and agreed on the landmark Tax Reform Act of 1986, which ended many narrow tax breaks and reduced rates.4 Unfortunately, “central planning” through the tax code has come back into vogue since then. The number of pages in the federal tax code, regulations, and related rules has increased from 40,500 in 1995 to 67,204 in 2007, an increase of two‐​thirds.5



The number of narrow provisions, or loopholes, in the tax code is rising. Figures 1 and 2 show the number of “tax expenditures” in the income tax, based on data from the Office of Management and Budget.6 The number of tax expenditures for energy jumped from 11 to 23 between 1996 and 2006. The total number of tax expenditures increased from 121 in 1996 to 161 in 2006.



There are problems with these measures of tax expenditures. Some items, such as accelerated depreciation, are counted as loopholes under the income tax. But such pro‐​investment provisions would not be considered loopholes under a consumption tax. Nonetheless, the OMB’s tally of tax expenditures shows that Congress is moving away from the ideal of a neutral tax base toward micromanagement of the economy.





The rising number of narrow provisions in the tax code reduces economic efficiency. Such provisions distort market price and profit signals, which redirects capital and labor into less productive uses. That’s why a tax code with a neutral base and low rates is preferable to one with narrow carve‐​outs and high rates. The economic cost of today’s Swiss cheese tax base is large. U.S. output would be substantially higher if the tax base were reformed and effective tax rates across industries were equalized and reduced.7



Going forward, creating new tax incentives for energy and conservation would exacerbate these complexity problems. New tax incentives would add to the paperwork burden, create more errors in tax administration, further confuse economic decisionmaking, and provide further reason for the IRS to dig into personal affairs.



Current federal tax incentives for energy and conservation are not large. Total income tax expenditures for these items are valued at just $7 billion in 2007.9 That represents just 0.3 percent of total federal revenues. Thus, the discussion about tax incentives for energy and conservation is not a discussion about how high federal taxes ought to be.



Instead, the important issue for policymakers is to consider the sort of tax code that America ought to have. Should we have a tax code that treats families and businesses as equally as possible? Or should we have a tax code full of special provisions that treat people differently as Congress micromanages family and business decisions? I favor the former. After all, equality under the law is a bedrock American principle.



Proponents of tax incentives no doubt think that their favored activities deserve special attention. Many energy and environmental analysts argue that federal tax policies should be used to fix “externalities” in energy markets.10 But such an approach risks opening a Pandora’s box of widespread social engineering through the code.



Many interest groups, such as those promoting education, housing, and scientific research, argue that their favored activities are subject to externalities that need special tax code treatment. But, in theory, there are an endless number of externalities that governments could meddle in. At the risk of promoting bad ideas, tax lobbyists could champion tax credits for



I’m not advocating these tax credits, but they illustrate the slippery slope of social engineering if Congress wanted to fix every externality through the tax code. Just this year, the CRS finds that more than 150 bills on energy efficiency and renewable energy have been introduced, with many proposing narrow tax breaks. I hope Congress resists the temptation to create more tax loopholes.



The Congressional Research Service noted that the “Reagan administration believed that the responsibility for commercializing conservation and alternative energy technologies rested with the private sector and that high oil prices … would be ample encouragement for the development of alternative energy resources.“11 I think Reagan got it right.



Competitive markets have made a huge contribution toward America’s energy security and conservation. Businesses, for example, have powerful market incentives to reduce energy consumption. They are relentless in cutting costs‐​labor costs, tax costs, production costs, fuel costs, heating costs, cooling costs, and lighting costs. Lower costs mean higher profits. That’s why businesses strive continually to improve efficiency, including energy efficiency, particularly in today’s competitive global economy.



Market forces are behind huge improvements in U.S. energy efficiency in recent decades. The amount of energy consumed for each unit of gross domestic product has fallen dramatically since the 1970s. Economist Gilbert Metcalf found that if U.S. energy intensity were still at the level of 1970, the nation would be consuming 187 quadrillion BTUs annually.12 Instead, the United States consumes just 98 quadrillion BTUs annually, and thus we have cut our energy intensity almost in half since 1970.



Some of this improvement stemmed from the changing structure of the U.S. economy. But Metcalf calculates that at least two‐​thirds of the improvements since 1970 came from rising energy efficiency. And much, perhaps most, of that I think is due to the natural competitive processes in the economy, not government policy.



Consider the rising energy efficiency of household appliances. Federal efficiency standards for appliances went into effect in 1990, and appliance efficiency has improved since then. But appliance efficiency also improved markedly between the early 1970s and 1990, apparently as a market response to rising electricity prices.13 The average energy consumption of U.S. refrigerators fell from 1,800 kWh per year in 1974 to just 800 kWh by 1990.



If Congress does not change efficiency standards or enact new tax credits for energy conservation, it seems likely that U.S. energy intensity will continue to fall in coming years due to natural market forces.



Congress can make tax policy reforms to improve energy efficiency. A first step would be to end any tax provisions that encourage excess energy consumption. A good example are the tax preferences for owner‐​occupied homes, which some economists think favor the acquisition of particularly large homes.14 Larger homes need more heating, cooling, and lighting. Thus, one reform would be to combine repeal of the mortgage interest deduction with marginal tax rate cuts.



Another avenue for reform would be to reduce the tax code’s bias against capital investment. The income tax encourages current consumption and discourages long‐​term investment. To fix this bias, Congress should consider more favorable depreciation rules, optimally moving toward immediate expensing of capital purchases. That would remove barriers to all types of investments including those in energy production, alternative fuels, and conservation technologies. The Energy Policy Act of 2005 took some modest steps in this direction, but more could be done.15



Policymakers often say that America needs more job‐​creating investments in computers, automotive plants, transportation, and other activities. Those concerned with energy policy seek greater investment in electricity generation and transmission, oil refining, alternative fuels, pollution control, and conservation technologies. Thus, more favorable tax treatment of capital investment should be a common cause on Capitol Hill.



A new study by Ernst & Young and the American Council for Capital Formation shows that the current tax code stands in the way of energy and energy efficiency investments.16 The study compared U.S. cost recovery, or depreciation, rules to the rules in 11 other countries for 11 types of energy investment. Faster write‐​offs of assets over shorter periods of time reduce effective tax rates on new investment.



The study found that the United States has less favorable tax rules than most other countries for investments in petroleum refining, electricity, pollution control equipment, electricity smart meters, and other items. Here are the results for capital cost recovery after the first five years of an investment:



Consider electricity smart meters. If a U.S. utility installed these assets, it would take depreciation deductions worth 30 percent of the cost over the first five years. The comparable cost recovery values in other countries are Canada (63 percent), Germany (63 percent), Korea (58 percent), and Malaysia (90 percent).



America’s less favorable depreciation rules combined with the industrial world’s second‐​highest corporate tax rate creates a barrier to investment in new and traditional energy technologies. Because Congress is concerned with energy security, conservation, global warming, and high gasoline prices (partly caused by restricted refining capacity), it should focus on removing tax barriers to investment in energy production and energy efficiency.



Congress should consider reinstating the 50 percent capital expensing provisions that were in place in 2003 and 2004.17 That would spur economic growth while promoting the replacement of all types of older business assets with new, more efficient assets. New machines don’t just replace similar old ones, they embody new technologies that increase economic and energy efficiency.



Thank you for holding these important hearings. I look forward to working with the committee on energy tax policy issues.



1 Kevin Hassett, “The Role of Tax Incentives in Energy Policy,” American Enterprise Institute, July 10, 2001. For a history of federal tax incentives, see Chris Edwards, Ada Rousso, Peter Merrill, and Elizabeth Wagner, “Cool Code: Federal Tax Incentives to Mitigate Global Warming,” National Tax Journal 51, no. 3 (September 1998).



2 Richard Gephardt, “The Economics and Politics of Tax Reform,” Cato Journal 5, no. 2 (Fall 1985): 458.



3 Salvatore Lazzari, “Energy Tax Policy: History and Current Issues,” Congressional Research Service, July 28, 2006, p. 5.



4 However, the 1986 Act had numerous anti‐​savings and anti‐​investment provisions.



5 This page count is based on CCH data. See Chris Edwards, “Income Tax Rife with Complexity and Inefficiency,” Cato Institute Tax & Budget Bulletin no. 33, April 2006.



6 Budget of the U.S. Government: FY2008, Analytical Perspectives, p. 291.



7 The literature is summarized in Chris Edwards, “Options for Tax Reform,” Cato Institute Policy Analysis no. 536, February 24, 2005.



8 CCH, “CompleteTax Survey Suggests Taxpayers Confused by Tax Code Complexity,” March 16, 2005.



9 Budget of the U.S. Government: FY2008, Analytical Perspectives, p. 291.



10 For background on the history and purposes of federal energy policy, see Gilbert Metcalf, “Federal Tax Policy Towards Energy,” National Bureau of Economic Research, Working Paper no. 12568, October 2006.



11 Salvatore Lazzari, “Energy Tax Policy: History and Current Issues,” Congressional Research Service, July 28, 2006, p. 5.



12 Gilbert Metcalf, “Energy Conservation in the United States: Understanding Its Role in Climate Policy,” National Bureau of Economic Research, Working Paper no. 12272, May 2006, p. 2. See also International Energy Agency, “The Experience with Energy Efficiency Policies and Programs in IEA Countries,” August 2005.



13 Ronald Sutherland, “The High Costs of Federal Energy Efficiency Standards for Residential Appliances,” Cato Institute Policy Analysis no. 504, December 23, 2003, p. 5.



14 The homeowner tax preference results from the combination of the mortgage interest deduction and the exemption from taxable income of imputed rent on homes.



15 For a discussion of the 2005 law and background on the depreciation of energy assets, see Gilbert Metcalf, “Federal Tax Policy Towards Energy,” National Bureau of Economic Research, Working Paper no. 12568, October 2006.



16 Ernst & Young for the American Council for Capital Formation, “International Comparison of Depreciation Rules and Tax Rates for Selected Energy Investments,” May 2, 2007.



17 For background, see Christopher House and Matthew Shapiro, “Temporary Investment Tax Incentives: Theory With Evidence from Bonus Depreciation,” National Bureau of Economic Research, Working Paper no. 12514, September 2006.
"
"

 _Global Science Report_ _is a weekly feature from the_ _Center for the Study of Science_ _, where we highlight one or two important new items in the scientific literature or the popular media. For broader and more technical perspectives, consult our monthly “Current Wisdom.”_   
  
When it comes down to scaring people into accepting onerous reductions in carbon dioxide emissions, it’s always a good idea to trot out the specter of increased hurricanes, despite the lack of backing for this in the science literature.   
  
“Bluster” isn’t the name of an Atlantic hurricane (although it would be a good one*), but rather our description of the stories about new research out of the Massachusetts Institute of Technology projecting an increase in the frequency and magnitude of hurricanes as a result of anthropogenic climate change.   
  
Publishing in the _Proceedings of the National Academy of Science_ , M.I.T.’s Kerry Emanuel projects a rather large increase in the global frequency of tropical cyclones as well as their intensity over the course of the 21st century.   
  
Emanuel is the first to admit that the changes he found were largely of a different character to those in the generally accepted literature, which projects little change in the frequency of tropical systems (with perhaps even a slight decline) and only a slight increase in the future intensity.   
  
The difference between Emanuel’s results and those from the bulk of other studies arises primarily for two reasons; 1) the future emissions scenario used to drive the global climate models; and, 2) the method of downscaling coarse climate model output to the finer scale necessary to model tropical cyclones.   
  
When it comes to emission scenarios, Emanuel chooses to use the most extreme scenario, which more than triples the effective atmospheric carbon dioxide concentration by the end of the century, while most other studies have used a more modest scenario which leads only to about a doubling. With new technologies opening up vast abundances of lower CO2-emitting natural gas available for power generation, the extreme emissions scenario used by Emanuel seems unlikely.   




(This might also prompt the question as to why it was necessary to use the extreme scenarios in the draft “National Assessment” of climate change released in January by federal climatologists. See our voluminous comments here).   
  
With regard to the downscaling methodology, another paper, to be published later this year, uses a different procedure and arrives at nearly the opposite result. In the North Atlantic basin—the area in which the bulk of tropical cyclones which effect the United States occur—Thomas Knutson (of the Geophysical Fluid Dynamics Laboratory) and colleagues find a _decline_ of hurricane frequency of nearly 25 percent with an intensity increase of only about 6 percent.   
  
It’s worth noting that, according to research by Wang et al. (2011) and Murakami et al. (2012), future storms are actually more likely to remain at sea rather than striking the U.S.   
  
Emanuel, on the other hand, finds increases in both frequency and intensity of storms in the North Atlantic. Emanuel notes that further research into the difference produced with his model compared with Knutson’s “may prove enlightening.”   
  
We concur.   
  
The bottom line is that the significance of the results of Emanuel’s new study depends on an extreme emissions/warming scenario and a methodology which needs further evaluation. And even so, the changes reported by Emanuel in the North Atlantic, the area or primary concern for U.S. interests, do not rise above the noise of natural variability for many decades into the future.   
  
Contrary to the media bluster being generated by the new study, the true bluster of future hurricanes impacting the U.S. will likely be little different in the coming century than it was during the last—with any impact of anthropogenic climate change lost in the noise of the natural system.   
  
As with most global warming scare stories, cocksure stories about increased hurricane activity are a bit blustery.   
  
**References:**   
  
Emanuel, K., 2013. Downscaling CMIP5 climate models shows increased tropical cyclone activity over the 21st century. _Proceedings of the National Academy of Sciences_ , do:10.1073/pnas.1301293110   
  
Knutson, T., et al., 2013. Dynamical Downscaling Projections of Twenty-First-Century Atlantic Hurricane Activity: CMIP3 and CMIP5 Model-Based Scenarios. _Journal of Climate_ , doi:10.1175/JCLI-D-12-00539.1, in press.   
  
Murakami, H., et al., 2012. Future Changes in Tropical Cyclone Activity Projected by the New High-Resolution MRI-AGCM. _Journal of Climate_ , 25, 3237–3260. doi: 10.1175/JCLI-D-11-00415.1.   
  
Wang, C., L. Hailong, S-K. Lee, and R. Atlas, 2011. Impact of the Atlantic warm pool on United States landfalling hurricanes. _Geophysical Research Letters_ , 38, L19702, doi:10.1029/2011GL049265. 




"
"The chancellor missed a key opportunity to take leadership on the climate crisis with his budget, leaving the UK with little leverage to persuade other countries to join in with tougher targets on carbon, green campaigners said on Wednesday. Incentives for electric vehicles, as well as £300m to tackle air pollution, a £640m fund for nature and climate, cash for carbon-capture technology and a tax on plastic, were outweighed by a massive road-building scheme, no change to taxation for the oil and gas industries, and continuation of the 10 years-long freeze on fuel duty.  The fuel duty freeze alone costs about £9bn a year, and according to Carbon Brief that means emissions are 5% higher than they would be if duty were unfrozen. Also missing was any attempt to fix Britain’s heat-leaking housing, despite a £9.5bn pot for affordable housing. In the Conservative party manifesto last year there was a commitment to spend £9bn on domestic energy efficiency, which would insulate homes, making them warmer and lowering household energy bills, while also reducing greenhouse gas emissions. The UK is to host the vital UN COP26 climate talks, in Glasgow, this November, and green groups were hoping the chancellor would set out clear signals as to how the UK would meet its target of net zero emissions by 2050. Doing so is seen as essential in getting other nations to sign up to the tough new carbon commitments needed to drive through COP26 decisions. “This budget fails to put the UK on track to net-zero emissions, which is a major concern ahead of COP26,” said Ed Matthew, COP26 director of the Climate Coalition. “If the UK cannot get its own house in order it is at risk of crashing the climate talks before they have begun.” Youth climate activists tried to challenge the chancellor on his way to deliver the budget in parliament this morning, urging him to do more to stimulate the economy through tackling the climate emergency. But they were disappointed. Fatima Ibrahim, co-executive director of Green New Deal UK, which led the protest, said: “Ahead of COP26 we were hoping today would see a credible and comprehensive plan set out for how the British economy could reach net-zero as soon as possible. Instead, it’s been pushed back – an indication of how seriously this government is taking the climate crisis.” The government’s commitment to scrapping tax breaks on red diesel, a particularly polluting form of the fuel, was set against road-building – which includes among many schemes “improving traffic flows” on the A303, “unclogging Manchester’s arteries”, and investment in the A46 in the Midlands – and a house-building programme without clear accompanying net-zero emission commitments. Some green groups had urged the chancellor to devote at least 5% of public expenditure to the climate. Rebecca Newsom, head of politics at Greenpeace UK, said: “Far from ‘getting it done’ for climate and nature, the chancellor has completely missed the opportunity to address the climate emergency. Instead, by announcing £27bn for new roads it seems he’s driving in the opposite direction. Ending the red diesel tax break, and the Nature for Climate Fund announcements, are important steps. But they are just a fraction of what is needed to get the UK on track to delivering net zero before COP26.” The chancellor was to have announced a new national infrastructure strategy, encompassing hundreds of billions of pounds in public and private sector spending on low-carbon energy, transport, communications. But shortly before the budget that was put off to an undisclosed date later this spring. Whitehall sources said it was because some spending would have to be reviewed in light of the court ruling that ministers should have taken the Paris agreement on climate change into account when deciding on the Heathrow expansion plan. Lord Stern, one of the UK’s leading climate economists, said the national infrastructure strategy would mark another key opportunity to put the UK back on track. “The strategy must embody the commitment to net zero emissions and should lead to the rapid expansion in zero-carbon electricity that is required over the coming decades. The UK has a chance to lead the world at COP26. It must lead strongly by example now, and act in the best interests of the whole world as a key element in ‘global Britain’.”"
"

On May Day, Noah Keenlyside of Germany’s Leipzig Institute of Marine Science, published a paper in _Nature_ forecasting no additional global warming “over the next decade.”



Al Gore and his minions continue to chant that “the science is settled” on global warming, but the only thing settled is that there has not been any since 1998. Critics of this view (rightfully) argue that 1998 was the warmest year in modern record, due to a huge El Nino event in the Pacific Ocean, and that it is unfair to start any analysis at a high (or a low) point in a longer history. But starting in 2001 or 1998 yields the same result: no warming.





Science no longer provides justification for any rush to pass drastic global warming legislation. 



The Keenlyside team found that natural variability in the Earth’s oceans will “temporarily offset” global warming from carbon dioxide. Seventy percent of the Earth’s surface is oceanic; hence, what happens there greatly influences global temperature. It is now known that both Atlantic and Pacific temperatures can get “stuck,” for a decade or longer, in relatively warm or cool patterns. The North Atlantic is now forecast to be in a cold stage for a decade, which will help put the damper on global warming. Another Pacific temperature pattern is forecast not to push warming, either.



Science no longer provides justification for any rush to pass drastic global warming legislation. The Climate Security Act, sponsored by Joe Lieberman and John Warner, would cut emissions of carbon dioxide — the main “global warming” gas — by 66 percent over the next 42 years. With expected population growth, this means about a 90 percent drop in emissions per capita, to 19th‐​century levels.



Other regulatory dictates are similarly unjustified. The Justice Department has ruled that the Interior Department has until May 15 to decide whether or not to list the polar bear as an endangered species.



Pressure to pass impossible‐​to‐​achieve legislation, like Lieberman‐​Warner, or grandstanding political stunts, like calling polar bears an “endangered species” even when they are at near record‐​high population levels, are based upon projections of rapid and persistent global warming.



Proponents of wild legislation like to point to the 2007 science compendium from the U.N. Intergovernmental Panel on Climate Change, deemed so authoritative it was awarded half of last year’s Nobel Peace Prize. (The other half went to Al Gore.) In it there are dozens of computer‐​driven projections for 21st‐​century warming. Not one of them projects that the earth’s natural climate variability will shut down global warming from carbon dioxide for two decades. Yet, that is just what has happened.



If you think about it, all we possess to project the future of complex systems are computer models. Therefore, if the models that serve as the basis for policy do not work — and that must be the conclusion if indeed we are at the midpoint of a two‐​decade hiatus in global warming — then there is no verifiable science behind the current legislative hysteria.



What does this mean for the future? If warming is “temporarily offset” for two decades, does all the “offset” warming suddenly appear with a vengeance, or is it delayed?



Computer models, like the one used by Keenlyside, et al., rely on “positive feedbacks” to generate much of their warming. First, atmospheric carbon dioxide warms things up a bit. Then the ocean follows, raising the amount of atmospheric water vapor, which is a greater source of global warming than carbon dioxide. When the ocean does not warm up, it seems that the additional warming is also delayed.



All of this may mean that we have simply overestimated the amount of warming that results from increases in atmospheric carbon dioxide.



That final point has been a subject of debate for a long time. Several recent publications in the peer‐​reviewed literature argue that observed changes in temperature show the “sensitivity” of temperature to increasing carbon dioxide is lower than earlier estimates.



All of this suggests a 21st‐​century warming trend that will be lower than the average value calculated by the climate models in the IPCC compendium.



But who really knows? Before Keenlyside dropped his bombshell, few scientists would have said publicly that global warming could stop for two decades. Anyone raising that possibility would doubtlessly have been treated to the smug reply that “the science is settled,” and that only the most bumptious ignoramus could raise such a question.



One final prediction: The teeming polar bear population will be listed as “endangered,” and in the next year or two, Congress will pass a bill mandating large and impossible cuts in carbon dioxide.



What is “settled” is the politics, not the science.
"
"Government should budget to spend £10 per cyclist by 2020 in order to make bicycle travel safer, according to a committee of MPs. The report of the Transport Committee also called for a “change in culture” across departments, so that cycling is supported at all levels of government.  Leaving aside the issue of whether £10 per head (up from £2) by 2020 is sufficiently ambitious, comfortably distant in parliamentary terms as it is, the report’s most notable call is for the number of cycling casualties to decrease – 109 cyclists were killed on UK roads last year, and another 3,000 seriously injured – and for the amount of cycling to increase at the same time.   This latter point is very important. The tendency to ignore risk-exposure has long been characteristic of Department for Transport reports, which trumpet decreases in pedestrian and cyclist casualty numbers without showing whether the number of walking and cycling trips has changed. Logically, celebrating a reduction in pedestrian casualties without asking whether people are walking less is like saying dinosaurs are the safest form of travel because no dinosaur riders were hurt last year. So it’s encouraging to see this considered. The next problem is how to measure that risk of injury – incidents per cyclist, per kilometre, per journey, or per day? Each will paint a very different picture.  The report also illustrates a key debate within bicycle safety circles over recent years: are cyclists’ needs best met by making roads safer places to cycle, reducing the dangers imposed by motorists, or by providing dedicated cycle infrastructure?  The argument goes that, as the UK already has an excellent network of roads to almost anywhere a person might want to reach, if this network could just be made safe for cyclists then cycling would be a practical form of transport for most people. The committee talks about taming roads by, for example, making it easier for local authorities to introduce 20mph speed limits and holding the haulage and construction industries to account for the disproportionate number of cycling deaths their members cause. Are such approaches feasible? The idea that people operating heavy machines will inevitably make dangerous mistakes, even if they don’t want to, is the starting point for how we operate aviation, maritime and rail transport systems, to say nothing of industrial workplaces. In these industries, human error is seen as inevitable and systems are put in place to prevent accident or disaster. But governments have never really addressed this issue for those driving motor vehicles on the roads, even though traffic psychologists have long drawn attention to how errors and lapses are normal features of driving. Lower speed limits could mitigate the effects of driver error – less speed means reduced energy on impact and greater time for drivers to react. But this would only work if drivers are sufficiently convinced the new limits are a good idea, and motivated to obey them. Traffic psychology research also shows that drivers’ deliberate violations of traffic rules cause dangers, and a person already happy to drive recklessly is unlikely to be made more safe for others by the imposition of further rules for them to ignore. And this is to say nothing of the risks to rural cyclists who are never going to get their roads reduced to 20mph.  This is why many cycle safety campaigners instead look to improving infrastructure, a solution the committee also raises. However, not all cycling infrastructure is equal. Research has shown that on-road features such as bicycle lanes can lead to motorists blindly following the paint on the road rather than making proper judgements, increasing the risk to riders. So many campaigners today prefer the idea of “gold standard” segregated cycle infrastructure, as found in cycling-friendly countries such as Denmark, Belgium and the Netherlands. This protects cyclists from the danger posed by drivers by using physical separation, which is still effective even with a proportion of reckless or intentionally dangerous motorists.  The key question to arise from this report is whether there can be sufficient impetus to change to established practices across Whitehall required to ensure good-quality segregated infrastructure is provided in the future? My feeling – putting aside one misguided comment about everybody respecting everybody else, which ignores the hugely different levels of harm each road user can inflict – is that the committee’s heart is in the right place. But I am not convinced much will happen. It’s encouraging to see demands for cycling to become safer, and also feel safer. This is the critical shift required to move cycling from something unusual used by a stubborn minority, to something ordinary used by commuters, children and older people. And the committee is right to believe that achieving this kind of change will require banging a lot of heads together across Whitehall.  But I wonder if they realise just how big a task this entails – if we truly want to normalise and encourage cycling, fundamental changes are needed everywhere: planning laws that prevent out-of-town shopping centre sprawl, the health service (doctors should ask if you use sedentary travel before they ask whether you smoke, given the former is a better predictor of premature death), in education, in business. Above all, we must stop making motoring the cheapest, easiest, and most “standard” form of travel, and go further to ensure the true cost of vehicle use is paid by those that use them.  Motor vehicles are of course useful and definitely have a role. But that role should not include, for example, using a five-seat vehicle to move a single person less than 5 urban kilometres. That’s what bicycles are for. We’ll know we have a culture that truly values cycling when we see a government’s message to an able-bodied person driving alone across town is: “What’s wrong? Is your bike broken?”"
"Early spring temperatures in the town of Deadhorse, on the north coast of Alaska, average -17°C. But with global warming affecting the Arctic more than anywhere, things are changing fast. At the end of March 2019, temperatures in Deadhorse hit 3°C, a whole 20°C warmer than the long-term seasonal average. Such huge variations are not normal or natural, and it is important we understand their long term environmental impacts. Now, scientists working on an island off the north coast of Canada, relatively near to Deadhorse, have discovered evidence that warming in the Arctic is triggering thousands of landslides that could reshape the landscape for good. The landslides are found in those high latitude areas where the ground consists of frozen soil and rock, known as “permafrost”. Closer to the poles, and at higher elevations, the surface can be frozen all year. Where temperatures are slightly less cold in the summer, perhaps because of a lower altitude or a greater distance from the pole, the surface of the permafrost melts most years. This melted layer is often saturated with water and thus is very weak, creating boggy conditions when the thaw develops. And where the permafrost is on a slope, melting often rapidly leads to instability, resulting in landslides.  As temperatures rise, those “summer months” above freezing can stretch into spring and autumn, the hottest days become hotter, and large areas of permafrost are melting. One potential impact is an increase in landslides, and recent studies have suggested that there is some evidence that this might be occurring on some high altitude slopes.  But the latest research from Canada, published in the journal Nature Communications, has demonstrated a dramatic increase in landslides in recent years – even at sea level. The researchers focused on Banks Island, an expanse of treeless tundra about the size of Sri Lanka or Ireland, with 68,000 muskoxen and just 112 humans.  They looked at a particular type of landslide known as “retrogressive thaw slumps” which can occur on comparatively gentle slopes when permafrost thaws. These landslides generally move slowly downhill, but what makes them particularly problematic is that once they start they tend to grow, and it is very difficult to arrest their development.  The team looked for signs of these landslides in archive imagery of Banks Island between 1984 and 2015. The results were dramatic: in 1984 only 63 active retrogressive thaw slumps could be identified, but by 2013 this number had increased to 4,077 – a 60-fold increase. Mapping the number of new landslides occurring each year over the study period, scientists realised that many more landslides developed in years with particularly warm summers. In the four warmest summers – 1999, 2011, 2012 and 2013 – almost 3,900 landslides developed. The study has significant implications. First, it shows a dramatic increase in the rate of permafrost degradation through landsliding. Most of the new landslides are now causing substantial erosion as the released sediment moves into watercourses and will cause changes in lakes and rivers even away from the landslides.   Second, it is clear that these changes are associated with years with high summer temperatures. While this study only looked at a single – albeit very large – island in Canada, there is nothing exceptional about this region climatically or geologically, which suggests that something similar will be happening in many other permafrost areas. And finally, rising temperatures in the Arctic mean permafrost is likely to degrade at a dramatically increased rate. Using the IPCC climate projections, in this area alone the researchers expect 10,000 or more new landslides per decade by 2075. If this is extended across other permafrost areas in Canada, Siberia and beyond, high latitude climate change will have a major impact on the landscape. This is likely to alter the ecosystems in these areas, but as yet it is impossible to estimate the ways in which they will change. Through time we are getting a better sense of how landscapes are responding to changes in climate. It is clear that permafrost is extremely sensitive to change – and the effects are likely to be profound. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"
Share this...FacebookTwitterGerman geologist Dr. Sebastian Lüning, co-author of the best-selling skeptic book Die kalte Sonne, which has created a controversy in Germany, is speaking today at the Heartland Climate Conference in Chicago.
Click below for a live feed:

Title of Dr. Lüning’s presentation:
The Medieval Warm Period within the Context of Millennial Scale Climate Cycles
12:45 p.m. – 2:30 p.m local time, which is 19.45 – 21.30 CET. (You may want to check in one hour early to make sure).
Content:
– German reaction to the book
– How solar cycles have impacted climate during the Holocene
– Temperature reconstructions worldwide
– Problems with the IPCC models
– Little Ice Age caused by volcanoes?
– Warming or cooling ahead?
I hope as many readers as possible will join in, watch and comment.
 
Share this...FacebookTwitter "
"Britain’s farmers are almost 18 times more likely to be killed on the job than the average industrial worker, and the fatality rate is increasing. Look through the government’s summary of the 33 fatal farm, forestry and fishing accidents in 2017/18 and there were a number of types of fatalities such as falls, crushes, electrocutions and equipment malfunctions. Most people (but not farmers) might be surprised to learn that work with cows is particularly dangerous – “crushed by a bull” was the single most common cause of death. So what can be done? There’s no doubt that farming is a hard and relentless occupation and workers endure long hours and heavy workloads. For many farmers, it is more a way of life than a hobby or a job, and farms are often passed down from generation to generation, with families following the customs and traditions of their ancestors.  With increasing financial pressures, weather considerations and hard workloads, farmers are often forced to work long hours and cut corners in relation to safety. A number of jobs are required to be carried out on the farm and it has long been tradition among farmers to be a “Jack of all trades” instead of wasting money on specialist tradesmen or contractors. As such, it has become part of the culture of farming to turn your hand to anything, which begs the question of whether farmers actually realise farming is unsafe. This traditional mindset, combined with ever-increasing fatalities from farming incidents, demonstrate an urgent need for change. The sector does not appear to be learning from mistakes made. If farmers themselves won’t take the lead then the government’s Health and Safety Executive (HSE), which regulates safety at work, must change its approach to the industry. Things aren’t simple enough to be solved by top-down action alone, however, and change will also require a more collegiate approach across the sector. Either way, cultural change will be hard and will take time. Farming is one of the most dangerous industries, yet was a latecomer compared to other industries in terms of regulation. Although regulation and enforcement has increased over time, accidents and fatalities continue to rise and the same types of incidents reoccur time after time, demonstrating a failure in the system.  While we understand that agricultural incidents can happen and will continue to happen, there is no legal requirement for farm workers to undertake any form of health and safety course or training. Regulations are in place, but they will only work if farmers understand them and take their time to put measures in place to prevent or at least reduce such horrific incidents. People have been highlighting these issues for a long time. Back in the 1960s, a government researcher named GS Wilson compiled a report on farm safety and concluded that, “although men have readily adapted themselves to new machines and methods, they have not proved as able to recognise new dangers and learn how to guard against them”. The types of agricultural accidents Wilson looked at are still the main causes of injury and death today. It seems there has been little progress over the past five decades, and lessons are not being learned.  The HSE does provide a number of leaflets and booklets to help agricultural workers understand their obligations to comply with the law and work safely. The problem is ensuring that all those who are working on farms, whether that be employed, self-employed or the employer, have engaged with such advice. The HSE and the National Farmers Union are both trying to raise awareness of safety issues, and run various education campaigns. These initiatives are important as there is no legal requirement for farmers to attend any health and safety courses. Farmers do require certification for insurance purposes and for compliance with hazardous substances. Perhaps implementing similar certification for farm safety would be a good step forward. At the turn of the century, it was the construction industry that had more fatalities per worker than any other sector. It then implemented a continued professional development programme, which ensures that workers undertake training at set intervals to enable them to carry on working on sites. If it worked for construction, then surely it could also work in the sector that has now adopted the “most fatal” mantel – farming."
"

A few weeks ago, Senator Josh Hawley wrote a _New York Times_ op‐​ed calling for “abolishing” the World Trade Organization (WTO). I responded to Hawley’s piece here, pointing out the various ways that he had misunderstood the WTO. Hawley’s op‐​ed was apparently intended to lay the foundation for the joint resolution he introduced to withdraw the United States from the WTO. As I noted here, a Senate vote on this resolution is likely in late July.



Over in the House, two Congressmen, Peter DeFazio and Frank Pallone, introduced their own WTO withdrawal resolution. DeFazio had an op‐​ed in _The Hill_ recently, in which he also tried to make the case for the United States leaving the WTO. Due to a rule change passed last week, it now looks extremely unlikely that this resolution will come to the House floor for debate and a vote. Nevertheless, for the sake of completeness, I’m going to respond to his piece as well. I’m not sure I have it in me to address each and every one of his points, but I’ll try to deal with a lot of them. Here goes.



DeFazio says:



Since its establishment in 1995, but even more so since China joined in 2001, the WTO’s ban on Buy American and other domestic procurement preferences, its protections for foreign investors, and its lack of rules against currency misalignments and other forms of unfair trade practices have promoted the outsourcing of American production capacity and decimated well‐​paying manufacturing jobs.



In truth, the WTO doesn’t “ban” Buy American and other procurement preferences, but rather countries can negotiate to open their procurement markets to each other. Many countries have joined the WTO’s Government Procurement Agreement, and have made market‐​opening commitments. Through this process, the United States has opened some (but far from all) of its procurement to foreign bidders, in exchange for U.S. bidders being allowed access to foreign procurement markets. But we are not completely open (although I wish we were, aside from legitimate national security issues), and Buy American procurement preferences still exist. There is, in fact, a federal Buy American Act, which was recently tightened by the Trump administration, as well as state and local procurement preferences.



As for “protections for foreign investors,” this refers to a controversial aspect of many bilateral and regional trade agreements, under which foreign investors can sue governments directly in an international tribunal (I am skeptical of this myself). But the WTO doesn’t have anything like this, so DeFazio can relax. DeFazio should, however, join the debate over foreign investor protections that is going on in the context of bilateral and regional trade agreements.



With regard to “currency misalignment,” the WTO does actually have a vague provision on this (GATT Article XV:4: “Contracting parties shall not, by exchange action, frustrate the intent of the provisions of this Agreement, nor, by trade action, the intent of the provisions of the Articles of Agreement of the International Monetary Fund.”) But DeFazio is free to propose something more detailed and encourage the U.S. government to put it forward for discussion at the WTO. In addition, it is worth noting that the Department of Commerce (DOC) is currently pushing ahead with its own efforts to use countervailing duties to address what it considers to be currency manipulation that leads to a subsidy causing injury to a domestic industry. The WTO does not have specific rules on this, but if the DOC’s actions are challenged there, the general WTO obligations on subsidies/​countervailing duties will be applied.



DeFazio then offers the following:



These are the facts: a quarter of U.S. manufacturing jobs – roughly 5 million – lost. Sixty thousand U.S. factories shuttered. A U.S. goods and services trade deficit explosion of 265 percent, from $170 billion in 1994 to $617 billion in 2019.



There is plenty to dispute with these jobs and factories numbers, but let’s put that aside for now. The figures he presents are not as relevant to the WTO debate as he seems to think. Yes, manufacturing employment has gone down, as the United States has been moving away from relying on manufacturing to employ vast numbers of people, just like hundreds of years ago we moved away from large‐​scale employment in agriculture. This is partly due to increased productivity (including through automation): As we get more efficient in production, we need fewer people to work in factories. And some of it is due to general shifts in the economy over the years. But it’s surely true that some amount of U.S. manufacturing jobs were lost due to competition with foreign producers. It’s also true, however, than many jobs were gained due to increased exports. And it’s most important to point out all the gains to U.S. consumers from this increased trade and competition. You could, in theory, shield your economy from foreign competition and manufacture everything yourself. But centuries of experience with governments using this strategy shows pretty clearly that it does not make you better off.



As for the trade deficit, Cato colleagues of mine have debunked this point many times in the past, including here, here, and here.



Back to DeFazio:



The WTO has promoted corporate protectionism while banning commonsense consumer safeguards. In fact, WTO terms required the U.S. to extend for three years monopoly protections for pharmaceutical firms that they use to charge sky‐​high prices. …



I assume that he is referring here to the extension of patent terms from 17 years to 20 years as part of the Uruguay Round negotiations which created the WTO. But stronger intellectual property rules was something the U.S. government supported. If he wants to make the case for going back to 17 years, I have no objection, but it’s not like “the WTO” did this. The U.S. government was on board with it the whole time and that’s why it’s part of WTO rules.



DeFazio then tries to argue about the fairness of WTO dispute settlement as follows:



The WTO rules and dispute settlement system are so lopsided that the U.S. has lost a staggering 90% of the cases attacking U.S. policies.



This is some wonderful cherry‐​picking of data. He’s not too far wrong, it’s just that he forgot to mention that the United States has won even more of the cases it brought to “attack” foreign government policies. The explanation here is that governments tend to be pretty circumspect about bringing WTO complaints, and the result is that most of the ones that are brought are successful.



Putting aside all of these errors, omissions, and deceptions, what does DeFazio want to see happen now?



A withdrawal vote would put our trading partners on notice that after decades of trade deals and systems that have led to weakened supply chains, structural trade imbalances, and massive income inequality, there is bipartisan appetite for transformative change.



As the largest economy in the world, the U.S. has a powerful hand to play, and we should use it to advocate for new rules, including strong and enforceable labor and environmental safeguards, and a more level playing field. In doing so, we can — and we must — address the understandably immense frustration among Americans whose lives have been ruined by trade policies that put corporate profits over working people.



At a moment where authoritarian nationalism is on the rise, it is also essential that the U.S. bring the world’s democracies together to make the case for a fair and resilient form of global cooperation, encouraging multilateral responses to the pandemic crisis, shared security, marginalization, and climate change.



I can get on board with “bringing the world’s democracies together” and “advocating for new rules” (perhaps not the same ones DeFazio wants, of course). I have suggested some improvements to the WTO myself. But if he thinks U.S. withdrawal from the WTO would lead to any of his desired changes, he has badly misread the situation. Our trading partners, including those that are democracies, want to keep the WTO intact. They would support reform, and they would love to hear reform proposals from the United States. But they don’t want the United States to leave.



In fact, the Trump administration, despite its own skepticism of the WTO, has made some reform proposals. The administration has raised questions about the transparency of some governments’ reporting on their trade practices, as well as the special status that allows some poorer countries to take on fewer responsibilities. These are valid concerns, but a withdrawal from the WTO won’t address them. It will simply cede U.S. leadership of the trading system, leaving us more isolated than we already are.
"
"Those least responsible for global warming will suffer the most. Poorer countries – those that have contributed far less to climate change – tend to be situated in warmer regions, where additional warming causes the most devastation. Extreme weather events such as Syria’s prolonged drought, South Asia’s catastrophic monsoon floods, and Cyclone Idai in South-East Africa, the third deadliest cyclone on record, are becoming more likely and more severe. These events are disproportionately bringing death, displacement, and crop failure. As a result of this, projections estimate that the economies of poorer, warmer countries will be gravely harmed by climate change over coming decades, while the cooler, richer countries responsible for the vast majority of the extra CO2 in the air may even benefit in the short term. But as new research reveals, this is not just a future concern – the economic injustice of climate change has already been operating for 60 years. The study, published in the Proceedings of the National Academy of Sciences, compared different countries’ GDP per capita – a measure of the average person’s economic standard of living – between 1961 and 2010. It then used climate models to estimate what each country’s GDP would have been without the effects of climate change. The findings are stark. Many poorer countries’ economies have rapidly grown in the last 50 years, albeit often at great social and environmental cost and to the benefit of the globalised economy. But even that growth has been held back substantially by climate change – the gap in GDP per capita between richer and poorer countries is 25% higher than it would have been in a climate-stable world. And with most richer countries sitting below and poorer countries above the 13℃ average annual temperature at which economic productivity peaks, global temperature rise is an immediate driver of this inequality. Of the 36 countries with the lowest historical carbon emissions, which are also some of the poorest and hottest countries in the world, 34 have suffered an economic hit compared to a world without warming, losing on average 24% of GDP per capita. The poorest 40% of countries, much of which are located in sub-Saharan Africa, Asia, and Central and South America, have lost between 17 and 31% of GDP in the last half century. India, one of the lowest emitters per capita, has been regarded as an economic growth champion in recent decades – but climate change has slowed its progress by 30%. While the country’s services sector has boomed, the agricultural sector – which employs half of India’s total workforce – has suffered greatly. A three-fold rise in extreme rainfall events and increased severe droughts have reduced crop yields and cause between $9 and 10 billion in damage per year to the agricultural industry alone. The same events also regularly bring India’s urban economic hubs to a standstill. With 12m inhabitants, Mumbai has the world’s largest population exposed to coastal flooding. Deluges in 2005 and 2014 forced the city’s international airport and roads to close, and cost millions in property damage.  Increasingly intense Indian summers that now regularly hit above 45℃ reduce productivity, kill thousands, and cause thousands more to commit suicide.  Add to this the multi-billion pound costs of rescue and rebuilding from cyclones such as 1999’s Odisha storm, which left two million homeless, and it’s easy to see how climate change can stunt the economic growth of India and similarly affected countries. For the world’s wealthiest countries however, climate change has added to the coffers – 14 of the 19 highest-emitting countries now find themselves in a better economic position than they would have been if the planet’s temperature had stayed constant, with an average boost of 13%. The US economy has suffered, but by a miniscule 0.2%, while the UK finds itself 10% better off. The 2018 heatwave there posed its own risks to health and crops, but it also provided huge boosts to ice cream sales and tourism. As is becoming increasingly clear, there are no quick fixes or easy solutions to climate change or inequality. Reducing emissions is, sadly, not enough, and providing yet more high-interest loans to “help” poorer nations adapt to a warmer world will only deepen global inequality. Alongside radically changing the economies of the world’s wealthiest nations, we must demand that reparations for past injustices be paid, that the debts of the Global South be cancelled, that privatisation of local industries and lands be reversed, and that the brutal border regimes surrounding the world’s wealthy nations be torn down. Only then can global inequality truly be tackled. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"**A coronavirus vaccine will be ready to be used in Wales within a week of getting the go ahead, the first minister has said.**
Mark Drakeford said Welsh ministers are ""working on the capacity now. A lot of work has been done already"".
England and Scotland have already made vaccine rollout announcements.
Plaid Cymru called for an ""urgent, clear and comprehensive vaccination plan"", urging the Welsh Government not to be ""vague"" on such a key matter.
Speaking to BBC Radio Cymru's Dros Ginio programme, Mr Drakeford said: ""What other places have done is shown an ambition. What we're doing here in Wales is to plan first before we make an announcement.""
A number of vaccines have recently reported successful trials but none have yet gained safety approval.
Scottish First Minister Nicola Sturgeon has said her government hopes to vaccinate a million people by the end of January, while in England they hope to have all vulnerable people vaccinated by Easter.
Mr Drakeford said:""We don't know yet, and people in Scotland don't know yet, how much of the vaccine will be available because the system hasn't yet been set up.""
On Wednesday, he told the BBC Wales Live programme that If Wales were to use the Pfizer vaccine, which has to be stored at -70 degrees, that the plan is to use equipment from the Welsh Blood Service.
""We can use the equipment the Wales Blood service already has to store material at that temperature and we can make it available for this vaccine,"" he said.
""The vaccine will have limitations, it will be difficult to transport but we will find ways of doing it.""
Plaid Cymru's health spokesman Rhun ap Iorwerth said that ""seeing the kind of roll-out plans in Scotland just reinforces the need for such a clear plan in Wales"". ""We need to know how - once approval is given for the vaccine - the vaccine will be rolled out in Wales, including timings, recipients and logistics,"" he said.
Asked about plans to tighten restrictions before Christmas, Mr Drakeford insisted the ""firebreak was successful"" and that ""it did everything we expected it to do"" but acknowledged the numbers of people with coronavirus were increasing.
He said the Welsh Government was looking at what is happening in other parts of the UK to ""see if there are things we can learn and if there are things we can put in place to help us with the figures we're seeing now"".
""We accept that if we're going to do something in the hospitality sector then we're going to have to find more support for the sector and its supply chain,"" he said.
Mr Drakeford said conversations were ongoing about how to find funds to support the hospitality sector and the best way to distribute it.
He told Dros Ginio: ""We're working on things today- what money can we bring together and to what purpose can we use to help things but we haven't come to the end of those discussions yet."""
"

Today, Senator John McCain will formally announce that he is a candidate for president of the United States. Which reminds me that on Monday, Senator McCain gave a speech at the Center for Strategic and International Studies on what federal energy policy would look like under a McCain administration. So is the omnipresent captain of the “Straight Talk Express” prepared to tell Americans things they might not want to hear about energy? Apparently not. An examination of the speech suggests that we may need to rename McCain's campaign bus the ""Hot Air Express."" Let’s look at this speech and deconstruct it line by line.   




Thank you. I appreciate the invitation to talk with you about a great and urgent challenge - breaking our nation's critical dependence on foreign sources of oil, and making America safer, stronger and more prosperous by modernizing the way we generate and employ energy.   
  
Oil is often called the lifeblood of our economy--the indispensable commodity that keeps commerce humming and America on the move. But, in today's world, our dependency on foreign oil and the way we use hydrocarbons is a major strategic vulnerability, a serious threat to our security, our economy and the well being of our planet.



While this is standard-issue political cant, it pays to dwell on the implication of what is being said. In essence, John McCain would have us believe that free trade is good for everything save energy. But why – what’s so special about energy? As best as I can tell, the grand “energy exception” exists because energy is so important that we dare not rely upon foreign sellers. But couldn’t the same thing be said about food, technology, etc? I must have missed that part of _The Wealth of Nations_ where Adam Smith argued for the virtues of free trade for unimportant things but championed the case for protectionism when truly valuable commodities were in play. 



Fortunately, there are times in a nation's history when great challenges coalesce with great moments of opportunity. We are at such a moment today. We have the urgent need and the opportunity to build a safer and thriving future with more diverse, reliable, and cleaner energy. But it will take another indispensable commodity to make it happen -American leadership. I'm running for President to help provide that leadership. And I want to talk a little today about the direction I want to lead us and why.



Every single presidential candidate that I’m aware of is saying exactly the same thing when it comes to what America’s national energy policy ought to be. It’s as if they are all going to the same speech writer. There’s a reason for that. Politicians are in the business of ratifying public sentiments, and it there’s one thing the public believes these days, it’s that it would be great if we could find a cheap replacement for gasoline. Yes, that would be great. But government isn’t God. 



Oil is a vital resource and we will always need it. But we account for 25% of global demand and possess less than 3% of proven reserves. Most of the world's known reserves are in the Persian Gulf, in the hands of dictators or nationalized oil companies. Its availability and price are manipulated by a cartel of countries where our values aren't typically shared and our interests aren't their first priority.



Actually, we don’t know that. It turns out that academics have been trying to quantify OPEC’s impact on world crude oil markets for decades and have found no compelling evidence to support the contention that prices are higher because of OPEC than they would be absent OPEC. 



By mid-century there will be three-and-a-half billion cars worldwide-over four times the number today. Most of the growth will take place in the developing world, in India and China, but the increase in fuel prices, pollution, and climate impacts will be felt worldwide. As world demand for oil soars, higher prices, severe economic volatility, and heightened international tensions follow.



Really? If we were to draw a line on a graph showing world oil consumption from 1900 to the present, and then we were to draw similar lines for crude oil prices, world GDP, and the number of cross-border conflicts, I guarantee you that oil consumption would correlate with economic growth but would not correlate with higher world crude oil prices or international conflict. A regression analysis would be required to settle the matter, but I’m pretty sure that, if I had the time to undertake one, we’d find that John McCain’s prediction about the future has no basis in past experience.   
  
Regardless, increases in world oil consumption are manifestations of progress and improved human well-being. The fact that people in China, India, and elsewhere in the third world are now wealthy enough to buy cars and gasoline is good news, not bad. 



These unpredictable forces could seriously circumscribe our future if we let them. Great nations don't leave the ""lifeblood"" of their economy in the hands of foreign cartels or bet their future on a commodity located in countries where authoritarians repress their people and terrorists find their main support.



What is a “great nation"" exactly? There must be many qualities that could earn a nation the adjective “great”; leadership in the arts, leadership in the sciences, leadership in wealth creation (GDP), or personal well-being (per capita GDP), leadership in military power, or, for the more ideologically minded, leadership in civic virtue (income equality for some, personal liberty for others). Now, I’m going to hazard a guess here that when John McCain refers to a country as a “great nation,” he’s either defining it as “a nation that would elect John McCain” or “a nation that can blast apart any other nation on earth.” By that criterion, is there a correlation between “great nations” and those that get all of their economically important commodities from within their own borders? No there isn’t. If we broaden our definition of “great nation” to those that meet other criteria of “greatness,” I ask again: Is there any correlation between economic independence and fine art and literature, per capita GDP, aggregate GDP, equality, or personal liberty? Again, no.   
  
In reality, John McCain is making a tautological argument; “A great nation is one that does not rely on trade with others.” By this metric, Albania prior to the collapse of the Soviet block and North Korea today are the world’s greatest nations. Neither the United States – nor ancient Rome for that matter – would ever qualify under those terms. 



Terrorists understand the seriousness of our vulnerability. Al Qaeda plans for attacks on oil facilities in the Middle East to destroy the American economy. A little over a year ago, a suicide attack at a major Saudi Arabian oil refinery came close to disabling its target. Had it succeeded, it would have driven the world price of oil above $150 dollars a barrel -and kept it there for a year.



Yeah, well, “If ‘ifs and buts’ were chickens and nuts, we’d all have enough for winter.” It turns out that it’s a lot harder for terrorists to disrupt the oil trade via targeted attacks than John McCain imagines. They’ve been at it for nearly a decade now and have nothing to show for their efforts. 



We're one successful attack away from an economic crisis. The flow of oil has many chokepoints - pipelines, refineries, transit routes, and terminals; most of them outside our jurisdiction and control. Our enemies understand the effects on America of a significant disruption in supply, a crippled transportation system, gasoline too expensive for many Americans to purchase, businesses closed.



Economists are increasingly of the opinion that oil price spikes have very little impact on the economy as a whole. Think about it – oil prices have almost tripled since 2002 (when oil prices averaged $22 per barrel) but the economy continues to hum along nicely. 



Al Qaeda must revel in the irony that America is effectively helping to fund both sides of the war they caused. As we sacrifice blood and treasure, some of our gas dollars flow to the fanatics who build the bombs, hatch the plots, and carry out attacks on our soldiers and citizens.



Unless John McCain knows something we don’t, he’s just making this up as he goes along. We don’t know who’s running al Qaeda or where their high command happens to be, much less what their financial books look like. 



Iran made over $45 billion from oil sales in 2005, and it is the number one state sponsor of terrorism.



Yeah, and Pakistan earned virtually nothing from international oil sales in 2005, but its military is probably the most dangerous sponsor of Islamic terrorism on the planet. But let’s go back to Iran. Even when sales revenue was less than half that of today (namely, during the entirety of the 1990s), Iran was busy setting up Hezbollah and Allah knows what else. There is no correlation between oil revenues and Islamic terrorism. 



The transfer of American wealth to the Middle East helps sustain the conditions on which terrorists prey.



Actually, hatred of America in the Islamic world sustains the conditions on which the terrorists prey. And in that regard, John McCain – because of his support for the war in Iraq if nothing else – is almost certainly more responsible for Islamic terrorism than ExxonMobil.   
  
But let’s go back to McCain’s contention that drying up the flow of petrodollars going into the Middle East would reverse “the conditions on which terrorists prey.” I don’t think that’s true. What terrorists need most is a recruiting pool from which to draw. If the United States were to reduce oil consumption to such an extent that profits for oil producers declined, oil states would have smaller economies and less to distribute to their underemployed youth. To the extent that deteriorating economic conditions breed social discontent and political resentment, it’s not so obvious to me that reducing oil profits reduces Islamic terrorism. And that’s particularly the case when oil profits are being reduced as a consequence of a policy with a stated intention of bankrupting the economies of the Middle East. Has it not occurred to John McCain that this would almost certainly increase the recruitment pool for Islamic terrorists and make matters worse if we accept that manpower, not money, is the chief limiting factor for terrorist activities? Has our stated policy of strangling the revenues available to the Cuban government increased or decreased the pool of anti-American citizens of Cuba? 



Some of the most oil-rich nations are the most stagnant societies on earth. As long as petro-dollars flow freely to them those regimes have little incentive to open their politics and economies so that all their people may benefit from their countries' natural wealth.



Does anyone seriously think that if the oil revenues dried up that Saudi Arabia, Kuwait, Bahrain, the UAE, and Iran would go happily into that market liberal night? Gee, what do Islamic countries without oil revenue – like Egypt, Syria, Pakistan, and Afghanistan – look like? 



The Middle East's example is spreading to our own hemisphere. Venezuela's Hugo Chavez is using his country's oil revenues to establish a dictatorship, bully his neighbors and succeed Castro as Latin America's leading antagonist of the United States.



Sad but true. Score one valid point for John McCain. But there’s little the United States can do to deny significant oil revenues to producing states. Our ability to radically reduce world crude oil prices via public policy is routinely overstated. The U.S. is just one actor of many in a global crude oil market in which prices are determined by global supply and demand. Sure, we could ban the internal combustion engine and thus cut world crude oil demand by something like 20 percent, but is it worth throwing our economy into a depression just to bring Venezuela’s oil revenues back to 1990 levels? 



The politics of oil impede the global progress of our values, and restrains governments from acting on the most basic impulses of human decency.



Not necessarily. “The politics of oil” didn’t impede the development of the United States throughout the first six decades of the 20th century. Few today remember that the United States once dominated the world crude oil market to the same extent Saudi Arabia does today. There’s no iron link between crude oil extraction and human rights violations. 



There is only one reason China has opposed sanctions to pressure Sudan to stop the killing in Darfur: China needs Sudan's oil.



That and the fact that China has no interest in promoting a global bias against human rights violations for reasons that should be obvious to John McCain. Regardless, China doesn’t need Sudan’s oil – it needs oil. Sudanese oil is no better than anyone else’s. If Sudan is willing to cut China a better deal in return for foreign policy favors, what are we supposed to do about it? 



The burning of oil and other fossil fuels is contributing to the dangerous accumulation of greenhouse gases in the earth's atmosphere, altering our climate with the potential for major social, economic and political upheaval. The world is already feeling the powerful effects of global warming, and far more dire consequences are predicted if we let the growing deluge of greenhouse gas emissions continue, and wreak havoc with God's creation.



Oil consumption has less to do with global warming than does coal consumption, but alas, politicians find it more convenient to lay global warming at “Big Oil’s” feet than at the feet of “Big Coal.” That’s probably because it’s politically safer to attack the oil industry than the coal industry. Declare war on coal and you declare war on coal miners and coal towns. That might very well cost you battleground states such as Pennsylvania, West Virginia, Tennessee, and Ohio … and thus, the presidency. Declare war on oil, on the other hand, and you’ll probably get a bump in your fundraising efforts in California with no obvious downside to speak of. 



A group of senior retired military officers recently warned about the potential upheaval caused by conflicts over water, arable land and other natural resources under strain from a warming planet.



Exactly what expertise do military officers bring to the global warming policy table? Military officers specialize in killing great numbers of people in an organized and efficient fashion. How does that skill set translate into specialized knowledge about atmospheric physics, climatological impacts of a warmer and wetter world, and/or the socio-political responses to the same? 



The problem isn't a Hollywood invention nor is doing something about it a vanity of Cassandra like hysterics. It is a serious and urgent economic, environmental and national security challenge.



According to the “best and the brightest” within the global academy, global warming ranks near the bottom of human worries. 



National security depends on energy security, which we cannot achieve if we remain dependent on imported oil from Middle Eastern governments who support or foment by their own inattention and inequities the rise of terrorists or on swaggering demagogues and would be dictators in our hemisphere.



What does this mean? Canada is a net exporter of oil, which suggests that McCain would deem Canada “energy secure.” America imports lots of oil, so we’re not. If national security depends on energy security, then Canada has relatively more “national security” than the United States. I can spin out even more insane comparison if you like, but I think you get the point. 



There's no doubt it's an enormous challenge. But is it too big a challenge for America to tackle; this great country that has never before confronted a problem it couldn't solve? No, it is not. No people have ever been better innovators and problem solvers than Americans. It is in our national DNA to see challenges as opportunities; to conquer problems beyond the expectation of an admiring world. America, relying as always on the industry and imagination of a free people, and the power and innovation of free markets, is capable of overcoming any challenge from within and without our borders.



We’ve been trying mightily to achieve energy independence ever since the Nixon administration, but we’re as far away from our goal as ever. John McCain can pat us on the backs all he likes, but he’s not the first do so – or the first to argue that a little “can-do” spirit can solve everything from oil dependence to drug use. 



Our enemies believe we're too weak to overcome our dependence on foreign oil.



Look, I’m not asking for Cicero, but can’t American politicians employ better rhetoric than this? 



Even some of our allies think we're no longer the world's most visionary, most capable country or committed to the advancement of mankind.



They think that because politicians like Sen. McCain are so popular in the United States. Need I remind John McCain that our allies’ loss of faith has to do largely with our embrace of a foreign policy straight out of the John McCain playbook? 



I think we know better than that. I think we know who we are and what we can do. Now, let's remind the world.



Yes, let’s impress the world regarding how well we’ve learned the lessons taught by France; give the politicians full power to dictate who makes what in our economy and let her rip! 



George Gershwin wrote that good music reflects its people and times. ""My people are Americans,"" he said. ""My time is today."" That's what made his music memorable. That's what made all America's best accomplishments memorable. We were capable and confident, we aspired to greatness and we understood our times. Our time is today, my friends, and the achievements of our storied past will shine no brighter than those we accomplish right now, in our time, if we meet our problems confidently and honestly; if we trust in the strength and ideals of free people; if we aspire to greatness.



Reagan he isn't. 



As President, I'll propose a national energy strategy that will amount to a declaration of independence from the fear bred by our reliance on oil sheiks and our vulnerability to the troubled politics of the lands they rule.



Even if we imported no Persian Gulf oil whatsoever, a supply disruption there would increase the price of crude oil everywhere in the world no matter where it is produced. 



When we reach the limits of military power and diplomacy to contain the dangers of that cauldron of burning resentments and extremism, energy security is our best defense. We won't achieve it tomorrow, but we must achieve it in our time.



If energy security is our best defense against terrorism, then how do we explain the fact that Great Britain is being menaced by Islamic terrorists? Great Britain, after all, is a net exporter of oil. If energy independence is the thin blue line between us and the terrorists, then it’s not proving to be much of a defense. 



The strategy I propose won't be another grab bag of handouts to this or that industry and a full employment act for lobbyists. It will promote the diversification and conservation of our energy sources that will in sufficient time break the dominance of oil in our transportation sector just as we diversified away from oil use in electric power generation thirty years ago; and substantially reduce the impact of our energy consumption on the planet. It will rely on the genius and technological prowess of American industry and science.



There is no way for McCain to pursue his vision without providing “another grab bag of handouts to this or that industry.” Market actors are currently rejecting alternatives to oil in the transportation sector. The only way to change that reality is to provide subsidies to oil’s competitors. 



Government must set achievable goals, but the markets should be free to produce the means. And those means are within our reach.



Whether government “must set achievable goals” or not depends upon your vision of government. In short, should decisions about what I drive be made by me or some politicians? As far as whether these “goals” that McCain is promoting are within our reach depends on what the goals are and how much we’re willing to pay to meet them. Unfortunately, he’s silent on both of those fronts. 



Energy efficiency by using improved technology and practicing sensible habits in our homes, businesses and automobiles is a big part of the answer, and is something we can achieve right now. And new advances will make conservation an ever more important part of the solution. Improved light bulbs can use much less energy; smart grid technology can help homeowners and businesses lower their energy use, and breakthroughs in high tech materials can greatly improve fuel efficiency in the transportation sector. We need to dispel the image of conservation that entails shivering in cold rooms, reading by candlelight, and lower productivity. Americans have it in their power today to contribute to our national security, prosperity and a cleaner environment. They understand the dangers we face, and are prepared to respond to appeals to patriotism that explain how we can free ourselves from them.



If energy conservation makes sense, people will conserve energy of their own accord. Amazing how that works. 



We need not wait for another age, in which science fiction becomes every day reality. Flexible-fuel vehicles aren't futuristic pie in the sky. We can easily deploy such technology today for less than $100 per vehicle; and we must develop the infrastructure necessary to take full advantage. We were able to overcome the challenges of putting seatbelts, airbags, and computer technology in practically every car. We can provide fuel options and improve the fuel efficiency of our vehicle fleet by making them out of high tech materials that improve their strength and safety. We are doing that very thing right now to beat our foreign competitors in the aerospace industry.



Who’s this “we”? Is John McCain running for President of the United States or overseer of all national business and industry? 



Alcohol fuels made from corn, sugar, switch grass and many other sources, fuel cells, biodiesel derived from waste products, natural gas, and other technologies are all promising and available alternatives to oil. I won't support subsidizing every alternative or tariffs that restrict the healthy competition that stimulates innovation and lower costs. But I'll encourage the development of infrastructure and market growth necessary for these products to compete, and let consumers choose the winners. I've never known an American entrepreneur worthy of the name who wouldn't rather compete for sales than subsidies.



The old John McCain opposed ethanol subsidies. The new John McCain will apparently embrace any idea to win the White House. 



America's electricity production is for the most part petroleum free, and the existing electric power grid has the capacity to handle the added demand imposed by plug-in hybrid vehicles. We can add more capacity and improve its reliability in the years ahead. Nuclear energy, renewable power, and other emission free forms of power production can expand capacity, improve local air quality and address climate change. I'll work to promote real partnerships between utilities and automakers to accelerate the deployment of plug-in hybrids.



Why don’t we just nationalize the car companies and get it over with? 



With some of the savings from cutting subsidies for industries that can stand on their own, we can establish a national challenge to improve the cost, range, size, and weight of electric batteries for automobiles. Fifty percent of cars on the road are driven 25 miles a day or less. Affordable battery-powered vehicles that can meet average commuter needs could help us cut oil imports in half. The reward will be earned through merit by whomever accomplishes the task, whether a laboratory in the Department of Energy, a university, a corporation or an enterprising young inventor who works out of his family's garage.



See, we’re just not trying hard enough. We can all drive to work in hot-rod golf carts if we just put our mind to it.   
  
Seriously though, don’t you think there is sufficient profit incentive to produce such technology now? This strike me as akin to doubling the bounty on bin Laden’s head. Nothing wrong with that, but it’s not likely to lead to his capture any sooner. 



There is much we can do to increase our own oil production in ways that protect the environment using advanced technologies, including those that use and bury carbon dioxide, to recover the oil below the wells we have already drilled, and tap oil, natural gas, and shale economically with minimal environmental impact.   
  
The United States has coal reserves more abundant than Saudi Arabia's oil reserves. We found a way to cut down acid rain pollutants from burning coal, and we can find a way to use our coal resources without emitting excessive greenhouse gases.



We know how to do that. We just don’t know how to do that cheaply. 



We have in use today a zero emission energy that could provide electricity for millions more homes and businesses than it currently does. Yet it has been over twenty-five years since a nuclear power plant has been constructed. The barriers to nuclear energy are political not technological.



Politicians don’t stand in the way of new nuclear power plants. Investment bankers do. That’s because the total cost of nuclear power is substantially greater than the total cost of other sources of electricity. 



We've let the fears of thirty years ago, and an endless political squabble over the storage of nuclear spent fuel make it virtually impossible to build a single new plant that produces a form of energy that is safe and non-polluting.



Even the Nuclear Energy Institute disagrees with this. At a Manhattan Institute conference on March 28 of this year, Richard Myers, vice president of NEI, argued that America’s inability to site a high level radioactive waste disposal facility has nothing to do with the reluctance to build new sites. I know that because I was there on the panel with Mr. Myers. 



If France can produce 80% of its electricity with nuclear power, why can't we? Is France a more secure, advanced and innovative country than we are? Are France's scientists and entrepreneurs more capable than we are? I need no answer to that rhetorical question. I know my country well enough to know otherwise.



If France can have a 35 hour work week, why can't we? If France can guarantee that no person is fired with a damned good reason, why can't we? If France can guarantee all of its citizens a robust income for life whether they work or not, why can't we? The reason France has a lot of nuclear power is because French politicians make the decisions about what kind of power plants are built in France, not French investors or businessmen. In America, we leave more decisions to the market than does Europe.   
  
Seriously, I don’t think that Republicans will take well to an argument that France should be the metric by which all American domestic policy is judged. But maybe I’m wrong about that. 



Let's provide for safe storage of spent nuclear fuel, and give host states or localities a proprietary interest so when advanced recycling technologies turn used fuel into a valuable commodity, the public will share in its economic benefits.   
  
I want to improve and make permanent the research and development tax credit. I want to spend less money on government bureaucracies, and, where the private sector isn't moving out of regulatory fear, to form the partnerships necessary to build demonstration models of promising new technologies such as advanced nuclear power plants, coal gasification, carbon capture and storage, and renewable power so we can take maximum advantage of our most abundant resources.



Maybe the private sector “isn’t moving” towards John McCain’s preferred sources of energy because it makes zero economic sense. Energy demonstration projects, by the way, have a long record of failure in the United States. All that has been demonstrated is that the technology in question isn’t ready for prime time – something market actors managed to figure out without a dime of taxpayer money. 



And I'll make it a national mission to develop a catalyst capable of breaking down carbon dioxide into useful chemical building blocks, and rendering it a new source of revenue and opportunity.



So many national missions, so little time. Where do you think this will be – or should be – on President McCain’s “to-do” list were he to find himself in the Oval Office? 



America competes in a global economy where innovation and entrepreneurship are the pillars of prosperity. The competition is stiff and the stakes are high. We have the opportunity to apply America's technological supremacy to capture the export markets for advanced energy technologies, reaping the capital investment and good jobs it will provide. Our innovators, scientists, entrepreneurs and workers have the knowledge, resources, and drive to lead the way on energy security, as we have in so many other world-changing advancements. The race has always been to the swift, and America must be first to market with innovations that meet mankind's growing energy and environmental needs. Again, government should set the standards, and leave it to the marketplace to win the race.



It’s difficult to read that paragraph without concluding that John McCain sees no real boundary line between government and industry. They are both one – or need to be made one – to work in concert. 



I have proposed a bipartisan plan to address the problem of climate change and stimulate the development and use of advanced technologies. It is a market-based approach that would set reasonable caps on carbon and other greenhouse gas emissions, and provide industries with tradable credits. By reducing its emissions, a utility or industrial plant can generate credits it may trade on the open market for a profit, offering a powerful incentive to drive the deployment of new and better energy sources and technologies; for automakers to develop new ways to lower pollution and increase mileage; for utilities to generate cleaner electricity and capture carbon; for appliance manufacturers to make more efficient products, and for the nation to use energy with maximum efficiency-building conservation into the economy in a manner that produces financial and environmental benefits. Dupont Corporation has reaped $2 billion dollars in energy savings and reduced its carbon emissions by 72% since 1990.   
  
As it always does, the profit motive will attract the transformational power of venture capital, and unleash the market to move clean alternative fuels and advanced energy technologies from the margins into the mainstream.



FYI, economists at Resources for the Future – a rather non-ideological bunch who likewise endorse greenhouse gas emission reductions – report that John McCain’s plan would likely increase electricity prices by at least 35 percent, and probably more. 



Some urge we do nothing because we can't be certain how bad the problem might become ...



That is, they stubbornly point out that we don’t know enough about the costs associated with warming to ensure that any policy we adopt actually passes a cost-benefit test. 



... or they presume the worst effects are most likely to occur in our grandchildren's lifetime.



Actually, that’s true and there’s not a scientist alive who thinks industrial emissions are the primary drivers of warming who would argue to the contrary. 



I'm a proud conservative ...



""Conservative"" apparently means something quite different than it did when I was a boy. 



... and I reject that kind of live-for-today, ""me generation,"" attitude. It is unworthy of us and incompatible with our reputation as visionaries and problem solvers.



But it speaks well for our ability to undertake simple math. Even if global warming were to cut GDP by 10% a year (that is, about 10 times the best estimates at present), that would mean per capita incomes 100 years hence will likely be $289,515 rather than $321,684 assuming a 2 percent annual increase in per capita income, which is a relatively safe bet given past trends. In short, our grandchildren are going to be much, much wealthier than we are – just as we are much wealthier than our grandparents were in 1907.   
  
Would John McCain ever propose a $440 a year tax on those making $44,000 (that’s what per capita incomes were last year) to generate benefits for those making $289,000 (per capita incomes in 2106 under worse case scenarios related to global warming) if this sort of policy were advanced in any other context? 



Americans have never feared change. We make change work for us.



That’s so vacuous let’s turn it around. So what if the planet gets a few degrees warmer over the next couple of centuries? Americans have never feared change. We make change work for us. That's actually a pretty defensible argument given that climate change is unlikely to effect the American economy very much at all. It will have a much more negative effect on our global competitors. 



In the coming months, other proposals will be offered to establish a national climate policy. I welcome this. But let's not let urgency breed rashness and irresponsibility. I claim no monopoly on the best answers. Let the marketplace of ideas flourish. But as there is great reward in the responsible policy, there's also enormous risk in the wrong way forward. The policy must include mechanisms to control costs and protect the economy. Just as there is danger in doing too little, there is peril in going too far, too fast, in a way that imposes unsustainable costs on the economy. I believe ""cap and trade"" is the best way to manage cost and maximize benefits, but we must look at other market-based means to give added assurance that our policies are an instrument of job creation, economic progress, and environmental problem solving.



Economists are almost in complete agreement that “cap & trade” is poor way to go about this exercise if we want to reduce industrial greenhouse gas emissions. Carbon taxes would be far preferable. The reason politicians embrace the former but eschew the latter is because voters will not support climate control policies that impose significant costs on them. Hence, politicians need to endorse policies that impose few visible costs on voters. 



Climate change is a global problem that requires a global solution. But we know America has both an obligation and a compelling national interest in fulfilling our historic leadership role. China's carbon emissions will soon exceed ours. As President, I will invite a collaborative relationship with China to make coal use cleaner and climate friendly. But, we should address the problem on our terms, and bring others into the fold of a common sense effort to solve it, while we sell to the world the technologies needed to do it.



If John McCain has some secret plan to convince China to stop building cheap coal-fired power plants (that is, to stop growing), then I will be quite impressed. If current trends continue, within the next 25 years, China will emit twice as much greenhouse gases as the United States, Europe, Japan, and all other industrial nations combined. 



Answering great challenges is nothing new to America. It's what we do. We built the rockets that took us to the moon not because it was easy but because it was hard. We've sent space probes into the distant reaches of the universe. We harnessed nuclear energy, mapped the human genome, created the Internet and pioneered integrated circuits that possess the computing power of Apollo spacecraft on a single silicon chip you can barely see. In twenty years we've gone from using this cell phone (SHOW), a $4000 toy for the wealthy, to this cell phone (SHOW), an inexpensive and virtually universal means of communication. We can solve our oil dependence. You can't sell me on hopelessness. You can't convince me the problem is insurmountable. I know my country. I know what we're capable of. We're capable of unimaginable progress, unmatched prosperity, and vision that sees around the corner of history. We've always understood our times, accepted our challenges and made from our opportunities, another better world. My people are Americans. Our time is today. That is the country I ask to lead.



Yes, if we wish something into existence, government can make it so. God bless that straight-talkin' John McCain! Now, to be fair, this same intellectual horse-whipping could be administered to every single energy speech being given by every single candidate running for the presidency. So in that spirit, consider these comments as the standard-issue rebuttal to everything you’re about to hear on the campaign trail re our “addiction to oil.”


"
"
I have a few very important (and personal) announcements to share with the WUWT community because they will impact content and moderation over the next few weeks. Please take a moment to read this.

1. There is a pressing and very serious medical challenge in my family that will require surgery and rehabilitation time. I can’t and won’t go into details. This will require me to take periods of time away from WUWT over several weeks if not months. I don’t know the full time impact yet. This coming Friday and perhaps Saturday I’ll be offline.
2. That said, I welcome the help of any who wish to help with moderation or who wish to submit stories and essays. We could use the help of a moderator from midnight to 4AM PST. I know we have a few regulars that post during that time, and if you’d like to help, leave a comment please. WUWT has always had guest posts, and they will continue to be welcome. Leave a comment if you have an idea.
3. In case you missed it yesterday, the new ENSO/SST page is up and running. Be sure to bookmark it. This graphic on the sidebar is a direct link:

…plus it is also available in the header menu under Reference Pages. Other pages of reference graphics pages will be coming soon, more details here.
4. Steve Goddard told me several months ago that he  would like to start his own blog, covering a wider range of scientific, social,  economic and political topics than I wish to cover here at WUWT. You can see his blog at http://stevengoddard.wordpress.com
Thanks to Steve for  all his contributions to WUWT over the last two years.
I’ll be continuing the Sea Ice News feature every Sunday.
5. For those of you wondering about the upcoming surfacestations project paper, let me say that it is now mostly out of my hands and will not be impacted by item 1. I have a team of co-authors with far greater skills than I working on it. I’m pleased with the current draft having survived a critical review designed to strengthen it. When I have more, I’ll pass it along and of course at the appropriate time the surfacestations main page will get an update.
Thank you all for your consideration.  – Anthony


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8982dc23',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Along with the keys to No 11 Downing Street, the chancellor is given the job of doling out hundreds of billions of pounds of taxpayer money every year.**
In fact, for the first time this year, government spending will top a massive Â£1 trillion. But where does it actually go?
Like most of us, the chancellor has priorities, necessities, a wishlist - and unforeseen bills
For every Â£100 the central government spends next year, the biggest slice - more than Â£20 - will go on welfare payments such as pensions and universal credit. Other includes the money which goes to smaller government departments as well as contingency spending, including some of the government's virus-related costs.
Much of the welfare spending is dictated by factors such as an ageing population or unemployment. These fluctuate and so are hard for the government to control.
The next biggest chunk - Â£17.50 - goes on health. Education accounts for a further Â£7, while defence covers Â£4.50.
We've heard a lot about how the government has to borrow to help fund the spending bill this year. But as part of that debt has been picked up by the Bank of England, and interest rates are so low, that slice accounts for just Â£2 of every Â£100 - the smallest in decades.
That interest too is hard to predict. And with spending already sketched out for some big departments, such as health and defence, the chancellor's announcement only revealed plans for about Â£35 of every Â£100 the government will be spending in the next year.
Foreign aid has grabbed headlines but accounts for just 70p; the cuts announced now reduces that to 50p.
Be it fixing potholes or extra cash for the armed forces, government departments have to plead their case with the chancellor. And there are always winners and losers.
In the past couple of years, the government has claimed that austerity is over, the spending tap has been reopened and every department has been bestowed with more cash.
But over the past decade or so, the cost of living has risen and the population has grown. So money has to stretch further. And that money is split between day-to-day spending - from salaries to operations - and investment in the likes of roads, or capital investment.
Strip out that investment spending, and allow for inflation and the growing population, and while the health service will be better off in the next few years, defence actually won't be. In other words, it is more of a stretch to maintain day-to-day public services
One in every Â£4 the government spends, goes towards paying our 5.5 million public sector workers.
Frontline staff from nurses to police officers were awarded inflation-busting pay rises in the summer as they battled in the face of the virus.
But they were also warned not to expect more. Now 1.3 million people will have their pay rises ""paused"" for a year, saving the chancellor a billion or two.
His argument is that it's not fair to give wholesale rises when so many private sector workers have seen their incomes shrink or been laid off - and it is they who foot some of the public sector pay bill.
Exempt from the freeze will be the 31% who work in the health service - and anyone whose pay is under Â£24,000.
Also exempt will be those employed by local government and the devolved administrations, whose pay will be determined there. But the employers of those two groups could decide to impose curbs themselves.
The curb on public sector pay may feel like that Rishi Sunak is playing Scrooge.
But the cost of fighting the spread of coronavirus, and limiting the economic fallout has soared. It has now hit Â£280bn for this year - accounting for about Â£25 in every Â£100 the government is spending.
Much of that has gone on health and other services. About Â£40bn has gone on test and trace, PPE and vaccine implementation - the equivalent of more than Â£1,500 per household. Questions are already being asked if those sums have been spent wisely or effectively.
And then there's the support to the economy. The bill for furlough is expected to reach almost twice as much, at Â£70bn, with a further Â£20bn going to help the self-employed.
Most of such schemes will end come next March. But the health response won't - Mr Sunak expects that he'll have to fork out another Â£55bn, over 5% of the spending pot, on that in the next financial year.
In normal years, the government covers the vast majority of its spending through the tax it takes in - from income tax to VAT to Air Passenger Duty - around Â£94 of every 100 last year.
But this year those sources of income have suffered - just as outgoings have soared. For the first time, government spending will top Â£1 trillion.
This year the government will only fund about two-thirds of spending through taxation. That's equal to the biggest shortfall since World War Two.
At present, the government can borrow cheaply to plug the gap. But not forever. Rishi Sunak has already indicated he'll be looking to raise taxes - not yet, (for it's more than the economy could stand ) but in the years ahead.
The chancellor may still be doling out cash - but payback is coming."
"It is easy to get nostalgic for the era when most music lovers bought LPs. They would save their pennies for a Saturday trip to the local record store, before heading home clutching their glorious new vinyl in a plastic bag to drop the needle on the turntable and listen on repeat. This anachronistic ritual will be resurrected on International Record Store Day on Saturday April 13, as consumers queue to buy exclusive limited edition vinyl releases from their favourite artists. Launched a decade ago, this annual event is an industry drive to boost ailing independent record stores in an age when most people stream music online.  But is it actually true that earlier generations placed a greater value on recorded music than music fans in the present day? We are loath to succumb to the mythology of a “golden age” for music and lend credence to baby boomers moaning of bygone days when music somehow mattered more than it does now. We decided to investigate the numbers to see if they told a different story. As it turns out, they do – and it’s far worse than we expected. We conducted archival research on recorded music consumption and production in the US, comparing the economic and environmental costs of different formats at different times. We found that the price consumers have been willing to pay for the luxury of owning recorded music has changed dramatically.  The price of a phonograph cylinder in its peak year of production in 1907 would be an estimated US$13.88 (£10.58) in today’s money, compared to US$10.89 for a shellac disc in its peak year of 1947. A vinyl album in its peak year of 1977, when The Sex Pistols’ Never Mind The Bollocks came out, cost US$28.55 in today’s money, against US$16.66 for a cassette tape in 1988, US$21.59 for a CD in 2000, and US$11.11 for a digital album download in 2013.  This fall in the relative value of recorded music becomes more pronounced when you look at the same prices as a proportion of weekly salaries. Consumers were willing to pay roughly 4.83% of their average weekly salary for a vinyl album in 1977. This slips down to roughly 1.22% of the equivalent salary for a digital album during its 2013 peak.  With the advent of streaming, of course, the business model of consuming recorded music changed: what used to be a commodity industry, where people bought copies to own, is now a service industry in which they buy temporary access to a music experience stored in the cloud. For just US$9.99 – barely 1% of the current average weekly salary in the US – consumers now have unlimited ad-free access to almost all recorded music ever released via platforms such as Spotify, Apple Music, YouTube, Pandora and Amazon.  Yet if consumers are paying an ever lower price for their music, the picture looks very different when you start to look at environmental costs. Intuitively you might think that less physical product means far lower carbon emissions. In 1977, for instance, the industry used 58m kilograms of plastic in the US. By 1988, the peak year for cassettes, this had dipped slightly to 56m kg. When CDs peaked in 2000, it was up to 61m kg of plastic. Then came the big digital dividend: as downloading and streaming took over, the amount of plastics used by the US recording industry dropped dramatically, down to just 8m kg by 2016.  But if these figures seem to confirm the notion that music digitalised is music dematerialised – and therefore more environmentally friendly – there’s still the question of the energy used to power online music listening. Storing and processing music in the cloud depends on vast data centres that use a tremendous amount of resources and energy.  It is possible to demonstrate this by translating plastic production and the electricity used to store and transmit digital audio files into greenhouse gas equivalents (GHGs). This shows that GHGs from recorded music were 140m kg in 1977 in the US, 136m kg in 1988, and 157m kg in 2000. By 2016 it is estimated to have been between 200m kg and over 350m kg – and remember that this is only in the US. Obviously this is not the last word on the matter. To truly compare past and present, if it were even possible, you would have to factor in the emissions involved in making the devices on which we have listened to music in different eras. You would need to look at the fuel burned in distributing LPs or CDs to music stores, plus the costs of distributing music players then and now. There are the emissions from the recording studios and the emissions involved in making the musical instruments used in the recording process. You might even want to compare the emissions in live performances in the past and the present – it starts to look like an almost endless enquiry.  Even if the comparison between different eras ultimately came out looking different, our overriding point would be the same: the price that consumers are willing to pay for listening to recorded music has never been lower than today, yet the hidden environmental impact of that experience is enormous.  The point of this research is not to ruin one of life’s greatest pleasures, but to encourage consumers to become more curious about the choices they make as they consume culture. Are we remunerating the artists who make our favourite music in a way that accurately reflects our appreciation? Are streaming platforms the right business model to facilitate that exchange? Is streaming music remotely from the cloud the most appropriate way to listen to music from the perspective of environmental sustainability? There are no easy solutions, but taking a moment to reflect on the costs of music – and how they have changed over history – is a step in the right direction. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
nan
"Despite all the treaties, pledges, export bans and labelling schemes, the world’s forests are still disappearing at an alarming rate. In poorer countries a forest may simply be worth less as a living, thriving ecosystem than it is as timber and farmland. So if money is a key factor, why not get rich countries to pay poor countries to stop chopping trees? The UN Climate Summit in New York saw major new agreements along these lines. Norway in particular has pledged to pay Peru and Liberia hundreds of millions of dollars if they protect their forests more effectively. Such so-called REDD+ schemes hope to save millions of tons of carbon emissions while at the same time protecting indigenous people’s rights.  Although these bilateral deals sound good in principle, many NGOs, indigenous people and community groups have expressed significant concerns. The deal with Peru, which also involves Germany, is designed to cut the rate of deforestation in that country, home to large expanses of the Amazon rainforest, by paying its government up to US$300m if certain targets are achieved. A similar deal with Liberia is worth up to US$150m. Norway, Germany and the UK have promised further REDD+ funds if developing countries come forward with credible proposals.  Such bilateral agreements are not new, and Norway in particular has signed similar deals with Indonesia, Brazil, Guyana and other countries in recent years. These latest announcements are part of a wider New York Declaration on Forests, which involves more than 150 governments, companies, indigenous peoples organisations and NGOs, committing to halve deforestation by 2020 and end it by 2030. But the destruction of the world’s forests continues apace, and we are still far away from a truly global agreement. Every single country on earth would benefit from global forest protection, given forests’ importance for biodiversity and their ability to store carbon. But despite efforts ever since the Rio Earth Summit in 1992, it has been impossible to reach a global deal. Given this deadlock, bilateral agreements may be the best alternative. As early as 2006, the Stern Review argued that curbing deforestation was one of the most cost-effective ways to reduce emissions. Indeed, the review recommended precisely the Norwegian approach of compensating countries for the opportunity cost of other forest uses and the cost of managing the resource. Money talks in cash-strapped developing countries. By putting a price on trees that remain standing, such deals potentially introduce a viable alternative to logging or burning. Yet, a range of NGOs, pressure groups, indigenous people organisations and other civil society groups have expressed deep concerns over such schemes.  First, are US$300m and US$150m, as in the Peru and Liberia deals respectively, enough to change decisions and development paths for the long term? The underlying problems generating deforestation are complex and require multiple approaches to correct, including changes in buying behaviours of companies and consumers in the industrialised world.  Indeed, deals have been struck with Liberia and other countries before, but deforestation has continued and hence their results have been mixed. Some have claimed that changes to deforestation rates have generally followed trends begun before the Norwegian interventions and have been driven by other indigenous changes in attitudes, laws, and enforcement. So, deals with Norway alone will not be enough. Political will and leadership in developing countries, and being able to confront economic elites, are essential to address the drivers of the problem.  A second concern is that not all forests are alike, and some are more worth saving than others. A forest plantation should be seen more like an industrial, monocultural crop, with much reduced biodiversity and even increased carbon emission rates, given the uses of fertilisers and pesticides. Such plantations are quite different from untouched Amazon rainforests, for instance, and raise the question of which forests are actually protected by these agreements or should be. Third, how the agreements are implemented and who receives the payments has important equity implications. Experiences so far suggest that it is often elites in the receiving countries that benefit the most, further exacerbating social and economic inequalities. If the environmental problem of deforestation is more clearly understood as social and economic problem, so that wide disbursement of the benefits is necessary to achieving a solution, then the promised US$300m and US$150m deals suddenly seem very modest in comparison to the scale of the problem.  Fourth, and perhaps most importantly, it is often forgotten that forests are the homes of millions of indigenous people around the world. The new deals with Peru and Liberia explicitly acknowledge this, which is a step in the right direction. Yet, serious concerns have been raised by AIDESEP, the main organisation for the indigenous peoples of the Peruvian Amazon, and Rainforest Foundation Norway. These groups point to conflicts of interests and double standards at the centre of the Peruvian government, which has presided over a decline in the protection of forests and indigenous rights in recent years. Hence, the general principle of protection in the letter of intent may not contain enough teeth to be effective. That being said, such deals could be a step in the right direction if the money encourages some of the underlying conditions for better future forest management to take hold, including better mapping and associated enforcement mechanisms, better training and staffing of those in forest management and increasing awareness of standing forests as assets as well as cultural home to indigenous people.  The latest agreements specify some reasonable steps toward the ultimate goal of stopping deforestation by 2030, and to “cut emissions and reduce poverty at the same time,” in the words of one Norwegian government adviser. But actually reaching that goal might be a big ask from such bilateral agreements alone, given the complexity of the problems involved."
"**People coming to the UK from Estonia and Latvia will need to quarantine from 04:00 GMT on Saturday.**
The two Baltic states have been taken off of the UK government's travel corridor list.
At the same time, Aruba, Bhutan, East Timor, Mongolia and some Pacific islands have been added, meaning travellers from those places will not need to self-isolate.
However, current rules ban travel abroad unless for specific reasons.
The UK government has also changed its rules on Denmark, Transport Secretary Grant Shapps said.
While travellers from Denmark to the UK will still need to self-isolate, the government is lifting the ""total travel ban"" on Saturday.
The Foreign Office currently advises against all but essential travel to Denmark amid concerns over a new coronavirus strain that has spread from mink.
Anyone arriving into the UK from most destinations must quarantine for 14 days.
But there are a list of countries exempt from the rules, meaning returning travellers do not need to self-isolate, called the travel corridor list.
From 15 December, people who need to quarantine will only need to do so for five days \- if they pay for a private Covid test and are virus free.
Making the announcement on Thursday, Mr Shapps said latest data means Estonia and Latvia must be taken off the list.
There has been a sharp rise in the number of Covid-19 cases in Latvia in recent weeks, according to the Foreign Office. The Latvian government has announced a state of emergency lasting until 6 December.
Estonia's government has also introduced extra restrictions from 24 November.
Mr Shapps said Bhutan, East Timor, Mongolia, Aruba and six Pacific islands (Samoa, Kiribati, Micronesia, Tonga, Vanuatu and Solomon Islands) had been added to the list, effective from 04:00 on Saturday.
In England until 2 December, foreign travel is currently only permitted for work, education or if someone has another valid reason.
People can only travel in and out of Wales with a reasonable excuse, such as going to work or school.
In Northern Ireland, people are advised to only travel for necessary reasons and to ""carefully consider"" their holiday and travel options, in light of the pandemic.
In Scotland, people living in higher risk areas should avoid unnecessary travel to other places."
"**There have been more than 1.6 million confirmed cases of coronavirus in the UK and about 60,000 people have died, government figures show.**
However, these figures include only people who have died within 28 days of testing positive for coronavirus and other measures suggest the number of deaths is higher.
**Find out how the pandemic has affected your area and how it compares with the national average:**
If you can't see the look-up click here.
After the first peak in April, cases started rising again in July, with the rate of growth increasing sharply in September and October, before falling again in the past two weeks.
On Wednesday, the government announced a further 16,170 confirmed cases.
It is thought the infection rate was much higher during the first peak in spring, but testing capacity at the time was too limited to detect the true number of daily cases.
The data for cases can also be broken down by region and comparing the change in those figures by week gives a sense of where there has been a recent increase in newly-reported infections.
Coronavirus infections in England have fallen by about a third during lockdown, according to a major study carried out by Imperial College London.
While some of the worst-hit areas saw the biggest improvements, cases have remained relatively high across England, according to the React-1 study, which is based on tests of more than 100,000 people between 13-24 November.
The latest figures from the Office for National Statistics (ONS), suggest about one in 185 (16,400 people) in Wales had the virus in the week ending 21 November.
In Northern Ireland rates are thought to be decreasing at around one in 145 people (about 12,700 people), while in Scotland, the figure was one in 115 (about 45,700 people).
The average number of daily deaths began to rise again in September, following the first peak in April.
On Wednesday, the government announced a further 648 deaths.
Of these, 555 deaths were in England, 51 in Wales, 38 in Scotland, and four in Northern Ireland.
Rules were amended over the summer to include deaths in the coronavirus total only if they occurred within 28 days of a positive test. Previously in England, all deaths after a positive test were included.
England has seen the majority of UK deaths from Covid-19. Using the 28-day cut-off, there have been more than 52,000.
Although hospital admissions for Covid-19 remain below the levels seen in the spring, there are big regional disparities.
The North West, North East and Yorkshire, and Midlands have seen the highest number of admissions but the situation in all three now appears to be improving.
Cases have risen across large parts of England, with other spikes in areas of Scotland, Wales and Northern Ireland.
The red areas on the map below are those currently seeing the highest number of cases per 100,000 people.
Restrictions have been tightened across the UK in an effort to tackle the number of rising cases.
In England, each local authority has been placed in one of the new three tiers following the end of the recent national lockdown.
Wales has announced a range of further measures, including a ban on pubs, restaurants and cafes serving alcohol, from Friday 4 December.
In Northern Ireland, a further two-week ""circuit-break"" lockdown began on 27 November.
Scotland has a five-tier system of alert levels with different measures in place in different parts of the country.
UK leaders have agreed to allow up to three households to meet indoors during a five-day Christmas period of 23-27 December.
When looking at the overall death toll from coronavirus, official figures count deaths in three different ways.
Government figures count people who died within 28 days of testing positive for coronavirus.
But there are two other measures.
The first includes all deaths where coronavirus was mentioned on the death certificate, even if the person had not been tested for the virus. The most recent figures suggest there had been almost 70,000 deaths by 20 November.
The second measure counts all deaths over and above the usual number at the time of year - that figure was more than 75,000 by 20 November.
The most recent figures available from the ONS are for the third week of November, which show there were 14,276 deaths registered in the UK.
Some 3,038 of these deaths involved Covid-19 - 199 more than the week before.
Deaths normally do rise at this time of the year, but the data from the ONS and its counterparts in Scotland and Northern Ireland show the second wave of the virus has pushed the death rate above the average seen over the past five years by about 21%.
Overall, the figures are still well below the peak of 9,495 deaths recorded in a week, reached on 17 April.
The ""R number"" is the average number of people an infected person will pass the disease on to.
If R is below one, then the number of people contracting the disease will fall; if it is above one, the number will grow.
The government's current estimate for the R number across the whole of the UK is 0.9 to 1.
The estimate for England is 0.9 to 1, while for Scotland it is 0.8 to 1. The estimate for Wales is 0.8 to 1 and in Northern Ireland it is 0.9 to 1.1.
The government has said in the past that the R number is one of the most important factors in making policy decisions."
"
Share this...FacebookTwitterGerman daily Die Welt here reported last month how the transition to renewable energy development in Europe, particularly Germany, has not been progressing well lately.
Offshore parks are being delayed, the expansion of the power grid is practically DOA and people are realizing that the energy the sun sends for free is actually awfully expensive and inefficient.
The regulatory system designed to steer society through an energy efficiency revolution isn’t working. As a result bureaucrats are getting frustrated as their targets look less attainable than ever. Failure of their grand project is something they refuse to allow. Rather than admitting that the whole idea is unworkable, they instead think that the measures haven’t been drastic enough. Die Welt writes:
It’s no wonder that environmental politicians are considering forcing people rather than waiting for them to volunteer. That’s why the EU Commission has proposed a directive that threatens power utilities with fines in order to get them to finance the energy saving measures of their customers. Also homeowners are once again in the cross-hairs of politicians. After all, homes are the biggest consumers of energy . Too few homeowners are thinking about replacing their heating systems or insulating their walls and attics.”
Hat tip: http://oekowatch.org.
So what do the EU politicians have in mind? They want to force homeowners to renovate their homes to make them more energy efficient. Never mind if it’s economical or not. The idea is to save energy, no matter the cost. Besides, European politicians believe homeowners are too stupid to come up with the right answer when it comes to making investment decisions.
The German government is now considering such a measure. For example, the law would force people to insulate their homes and replace their furnace if they decide to carry out larger scale renovation works.
But as Die Welt writes, such drastic measures that try to force certain behavior are already being tried in the State of Baden-Württemberg, which is attempting to force homeowners there to carry out comprehensive renovation works for energy efficiency. The result: homeowners are renovating less than before. Die Welt:
Even small works are being avoided now because otherwise the law of the state threatens to force a costly full renovation. The laws of the state have only led to strategies of dodging and avoiding and have proven to be counter-productive.”
Little wonder. Whenever the state intrudes this deep into private property and lives, things are sure to go awry. That the state now is contemplating laws that tell people how to run their own private property is a scary measure indeed. They only need to look back at what happened under previous dictatorial regimes, never mind Baden-Württemberg.
Share this...FacebookTwitter "
"
Image: National Science Foundation
Guest post by Indur M. Goklany
In the earlier post reporting on the recent greening of the Arctic, some commentators — Crispin in Waterloo, BillD, Jimbo — have alluded to the notion that Arctic thawing could lead to positive feedback by adding to methane emissions to the atmosphere.
This global warming bogeyman is founded on the plausible notion — plausible, at least at first blush — that warming might release methane from methane clathrates (or hydrates) stored in the Arctic permafrost which would increase its concentration in the atmosphere.

But methane has a “global warming potential” averaged over 100 years of 25, that is, methane, ton-for-ton, is 25 times more powerful a greenhouse gas than carbon dioxide (AR4WG1 Technical Summary: 33). Thus, such releases of methane would constitute a positive feedback for global warming.
The initial concerns about methane stemmed from the fact that by the 1990s the atmospheric concentration of methane, which had been growing rapidly, had exceeded 1,730 parts per billion (ppb), almost twice the maximum amount measured over the past 650,000 years in ice cores (AR4WG1: 3).
Concern of runaway methane feedback was also stoked by a number of modeling studies which suggested rapid disintegration of the permafrost with global warming (e.g., Lawrence and Slater 2005, Zimov et al. 2006).  However, in a modeling study which took into consideration the thermal profile of the permafrost, and the fact that the melting effect of warm air surface temperatures on the upper layers of permafrost would be countered by cooling due to colder deeper layers of permafrost, Delisle (2007) showed that “massive releases of methane in the near future are questionable.”
Even more compelling is that the growth in atmospheric concentrations has slowed substantially. As noted by the IPCC AR4WG1 (p. 796):
Recent measurements show that CH4 growth rates have declined and were negative for several years in the early 21st century … The observed rate of increase of 0.8 ppb yr–1 for the period 1999 to 2004 is considerably less than the rate of 6 ppb yr–1 assumed in all the [IPCC] SRES scenarios for the period 1990 to 2000.”
The latest observations indicate that the rate of change is not increasing, and that they “are not consistent with sustained changes … yet” (Dlugokencky et al. 2009: 4). [Dlugokencky’s “yet” seems gratuitous — no matter, I’ll give it a pass.] They also indicate that the geographical pattern and the isotopic signature of methane increases suggests that the major sources are wetlands — probably tropical wetlands —rather than Arctic permafrost.
Petrenko et al. (2009) examined the source of isotopic methane in a glacial ice core from West Greenland to determine the probable source of the large increase in methane during the abrupt warming of +10±4°C that occurred during the transition from the Younger Dryas to the Preboreal (~11,600 years ago) (Grachev and Severinghaus 2005).  They concluded that “wetlands were the likely main driver of the [methane] increase and that clathrates did not play a large role,” a finding they noted “is in agreement with findings from previous ice core CH4 isotopic studies” (Petrenko et al. 2009: 508). This study essentially reiterated the results of another paper by many of the same researchers that appeared in Nature the previous year (Fischer et al. 2008). Notably the Petrenko et al. study’s publication was accompanied by an announcement titled, “Ancient Greenland methane study good news for planet, says CU-Boulder scientist” (Eureka Alert 2009).
So it seems that while methane emissions might increase if there is warming, there is no evidence of catastrophic releases from clathrates.
References
1. The above is, for the most part, extracted from:
Goklany, Indur M. (2009). Trapped Between the Falling Sky and the Rising Seas: The Imagined Terrors of the Impacts of Climate Change. Prepared for University of Pennsylvania Workshop on Markets & the Environment, draft, 13 December 2009.
2. Specific references follow:
AR4WG1 ≡ IPCC’s Fourth Assessment Report for Work Group 1 ≡ IPCC (2007). Climate Change 2007: The Physical Science Basis. Cambridge: Cambridge University Press.
Delisle, G. (2007), Near-surface permafrost degradation: How severe during the 21st century?, Geophys. Res. Lett., 34, L09503, doi:10.1029/2007GL029323.
Dlugokencky, E. J., et al. (2009). Observational constraints on recent increases in the atmospheric CH4 burden. Geophysical Research Letters, 36, L18803, doi:10.1029/2009GL039780.
Eureka Alert. 2009. Ancient Greenland methane study good news for planet, says CU-Boulder scientist. PR announcement, 23 April 2009. Available at http://www.eurekalert.org/pub_releases/2009-04/uoca-agm042109.php.
Fischer, H., Melanie Behrens, Michael Bock, Ulrike Richter, Jochen Schmitt, Laetitia Loulergue, Jerome Chappellaz, Renato Spahni, Thomas Blunier, Markus Leuenberger  &  Thomas F. Stocker (2008). Changing boreal methane sources and constant biomass burning during the last termination. Nature 452: 864 -865.
Grachev, Alexi M.  and Jeffrey P. Severinghaus (2005).  A revised +10±4 °C magnitude of the abrupt change in Greenland temperature at the Younger Dryas termination using published GISP2 gas isotope data and air thermal diffusion constants. Quaternary Science Reviews 24 ( 5-6): 513-519.
Lawrence, D. M., and A. G. Slater (2005). A projection of severe nearsurface permafrost degradation during the 21st century, Geophys. Res. Lett., 32, L24401, doi:10.1029/2005GL025080.
Petrenko, Vasilii V.; Andrew M. Smith, Edward J. Brook, Dave Lowe, Katja Riedel, Gordon Brailsford, Quan Hua, Hinrich Schaefer, Niels Reeh, Ray F. Weiss, David Etheridge, and Jeffrey P. Severinghaus. 14CH4 Measurements in Greenland Ice: Investigating Last Glacial Termination CH4 Sources. Science 324: 506-508.
Zimov, S. A., E. A. G. Schuur, and F. S. Chapin III (2006). Permafrost and the global carbon budget, Science, 313, 1612–1613.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e86d6d8a1',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterGeologist Dr. Sebastian Lüning’s and Prof. Fritz Vahrenholt’s website looks at the NOAA’s and NCDC’s relentless search for new climate records with which to scare the public. But as they show, despite what these alarmists conjure up, the warming is not getting faster, period.

Figure 1: Temperature development of the last 33 years based on UAH satellite data. Source: climate4you.
We keep hearing scary claims like: “May 2012 was one of the hottest the globe has seen since records began!” or “CO2 in the Arctic hits 400 ppm level!” or “2011 was the warmest year with a cooling La Nina-effect!” are just some recent examples. In the USA, the picture looks the same, where the warmest May since 1895 was recorded (see Climate Central and WUWT).
But as Lüning and Vahrenholt explain, many of these records use arbitrary startpoints in the statistical record and are thus designed to create “a record”. It’s time to get back to science, they say.
A look at the global satellite temperature series shows that May 2012 is in no way anything unusual and fits right into the ongoing temperature plateau the Earth has been stuck at for quite some time now (see Figure 1). Lüning and Vahrenholt write:
It is quite amazing how stubborn this warming stop has been. Not one of the IPCC models had predicted this plateau. Also the hyped up temperature prognoses made by Hartmut Graßl and James Hansen have been shown to be far from reality, [read here, for example.]”
Ok, one could say that the temperature plateau is only 14 years long, and shouldn’t longer periods be considered? Here often the ominous 30-year rule gets applied. Somehow that’s considered okay. But luckily we also here have a development that’s good news. With each year the temperature plateau extends, the 30-year window shifts a step out of the strong warming period of 1977-1998. As a result a greater part of the plateau enters the calculation. Year by year the warming rates decreases.
But for many, 30 years are impractical. Satellite data have been around for only 33 years, for example, and here not much can be statistically calculated. Therefore, a group led by IPCC lead author Ben Santer once checked over which intervval length actually makes sense in order to find the man-made impact on temperature. They reached the result that it has to be at least 17 years.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And lo and behold we find a world record of a completely different type: Currently we are experiencing the lowest temperature rise of a 17-year series since satellite temperature data began. At the moment the warming rate is a minsicule 0.04°C per decade; this is an absolute record low. A few years ago the figure was up to 0.26°C per decade, i.e. more than six times higher.”
Gee, I wonder if we’re going to read that in the newspaper or any NOAA press release? Don’t hold your breath.

Figure 2: Currently we are experiencing the lowest temperature increase of a 17-year series since satellite data began. Source: dh7fb.
While some places like the USA are enjoying warm weather, the opposite is true in great Britain, which has seen weeks of cool, rainy weather. Lüning and Vahrenholt write: “The forecasts project that there will not be any noteworthy warm spell until at least September. Daily Express writes ‘Summer starts in September’.”
That takes us to another new record: the most missed “barbecue summers”!
Lüning and Vahrenholt conclude:
While alarmist pseudo-records can help to fill newspaper space and attract funding, the sense behind this selective approach has to be regarded with great skepticism.”
 
Share this...FacebookTwitter "
"Patrick Barkham asks if nature really can cure us of our mental health problems (Green Prozac, Review, 14 March). He eloquently describes how reconnecting with the natural world can help us at least recuperate and find solace in a way that our urban environments cannot. However, as Richard Mabey says in the article, it is not a panacea and nature itself is going through its own crisis; no amount of walking through silent woodlands and desertified fields will provide the sought-after cure. For those of us who have loved and immersed themselves in the countryside over many decades and written about it, our closeness to it can only add to our stress and worry. When I return to the lanes, hedgerows and woods I loved as a boy, where I found birds’ nests every 50 yards or so, watched field mice clambering with acrobatic agility up the stems of swaying wheat and heard the mournful piping of curlews and redshank from the marshy fields, today there is only an eerie stillness and scarcely a fluttering wingbeat over the monotone greenery.  When, in 2000, I wrote and illustrated my book Wings Over the Valley: A Birdwatcher’s Wales Diary, about the joys of birdwatching and the countryside, communicating that exhilaration gave me renewed strength and optimism, but those feelings have been shattered in the face of the continued destruction of our countryside.John GreenLondon • It’s good to read that highway authorities and the construction industry are taking the greening of our roadsides seriously (Flower power: the route map to a roadside revolution, 14 March), but we also need to get to grips with the huge increase in paved-over front gardens. We may need to find a place to park cars, but the case for having a green space around our homes is very persuasive. Not only do plants and trees help keep our homes cool in summer and warm in winter, but every blade of grass also absorbs carbon dioxide and emits oxygen, thus playing a part in stopping climate change. Green spaces in residential areas are an essential stopping-off point for butterflies, birds and bees. The Royal Horticultural Society reports that almost a third of front gardens are now paved over. The RHS Greening Great Britain campaign gives lots of hints to people who could be encouraged to leave space for flowers, shrubs or trees. If, like me, you’d like to congratulate those who have a green front garden, visit Healthy Life Essex at https://bit.ly/2WeFH6L, where you will find a downloadable thank-you card to pop through the letterbox.Eileen PeckBenfleet, Essex • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition  "
"Tree planting is one of the government’s key strategies for fighting the climate crisis, but ministers have got off to a slow start that shows little sign of speeding up, according to the latest figures: just £5.2m will be spent on new trees in England under the countryside stewardship scheme for the current financial year. That is enough for only 1,260 hectares, according to Friends of the Earth, which is calling for a greater effort on tree-planting to absorb more carbon dioxide from the atmosphere.  Under current plans – revealed in the answer to a parliamentary question by the Labour MP Kerry McCarthy – about £27m will be spent by the end of this parliament, enough for about 6,500ha of forest. These sums fall far short of the 30,000ha of new trees the government has pledged. Friends of the Earth revealed last year that ministers were failing to meet targets on trees, despite assurances from the government that forestry would form a central plank of the push to reach net zero emissions by 2050. Less than £2 per person was being spent on forestry, research found. Each of the major parties included substantial tree-planting pledges in their manifestos at last autumn’s general election. However, details from the government on how this will be achieved have been scant. The agriculture bill currently progressing through parliament will put in place a broad legal framework to reward farmers for providing public goods, such as tree planting, but there have been no concrete plans yet from ministers on how much farmers can expect to be paid, when and how such schemes will be managed. There are also increasing questions over the strategy, which has the backing in principle of many environmental groups, but must be worked out in careful detail if new forests are to be sited in the right places so as to preserve existing habitats and not lead to further unintended emissions. Experts told the Guardian this week that commercial forests would provide little gain in the UK’s ability to store carbon. They also said trees planted in the wrong places could increase emissions, for instance, planting trees in some peatland dries out the peat and causes it to release carbon into the air. Other plantations can threaten local birds and wildlife if not carefully managed. Guy Shrubsole, a campaigner at Friends of the Earth, called on the government to increase funding for forestry and double tree cover in the UK, which, at 13%, is currently sparsely wooded compared with similar European countries. He said: “Ministers love to talk about planting more trees to fight the climate emergency, but seem unprepared to put their money where their mouth is. We have enough land but not yet the political will.” He called on the chancellor to act in Wednesday’s budget. “This budget is an opportunity to free up funding to create and maintain woodlands. Nature benefits from more trees, people feel better, and of course trees help combat climate change so there is absolutely no excuse to skimp on this funding.” The Department for Environment, Food and Rural Affairs said the final figures on funding for trees were likely to be much higher, as cash would flow from other sources within government beyond the countryside stewardship scheme. For instance, the government made a commitment in its manifesto to spend £640m on a Nature for Climate Fund, which would increase tree planting among other efforts to restore the UK’s natural environment. However, no details of any of these new potential sources of funding have yet been laid out. A spokesperson for Defra said: “Forests and woodlands are vital for capturing carbon, protecting wildlife and improving the environment for the next generation. That’s why our commitment to increase woodland cover as we work towards net zero sits at the heart of our ambitious environmental programme.”"
"
Share this...FacebookTwitterThe European Institute for Climate and Energy (EIKE) issued a press release on a 28-page report that German energy expert Dr. Guenter Keil wrote concerning Germany’s transition to renewable energy, and away from nuclear and fossil fuel energy.
KEIL’S FULL 28-PAGE REPORT IN ENGLISH
As the report shows, Germany’s transition to green energy is turning into a real horror story. The 28-page full report will keep you up at night!
What follows is EIKE’s PRESS RELEASE describing the contents of the report.
======================================================
Germany’s Green Energy Supply Transformation Has Already Failed
EIKE Press Release, 24 January, 2012
Energy expert Dr. Guenter Keil has closely examined Germany’s energy policy of shifting away from nuclear and fossil fuels and over to renewables. What he finds is a bleak picture. Years ago Germany ambitiously embarked on transforming its energy supply system, and hopes to supply at least 80% of its energy needs through renewable energies by 2050, and thus become a moral leader on environmental responsibility for the rest of the world.
To do this, the former Socialist-Green coalition government, led by Gerhard Schröder, enacted the so-called Renewable
Energy Feed-In Act (EEG) in 2000. This Feed-In Act requires electric utilities to buy all renewable energies, such as solar and wind power, from all producers at fixed, exorbitant rates and to feed it into the power grid for a period of 20 years. This has led to a boon as thousands of homeowners, businesses, and investors have installed thousands of megawatts of solar and wind power capacity over the years. The current Conservative-Liberal government, not to be outdone by its predecessor, is also gleefully pushing the Feed-In Act to the limit.
Weather-dependent supply wreaking havoc on the power grid
The problem is that these energy sources are weather-dependent and thus their sporadic supply is starting to wreak havoc on Germany’s power grid and is even now threatening to destabilize power grids all across Europe. The other problem: the power grid needed to distribute the decentrally produced green power is simply not there yet. They forgot to build it! So far, after tens of billions of euros spent on renewable energy systems and higher prices for consumers, not a single coal or gas-fired power plant has been taken offline. To the contrary, old inefficient German plants have been brought back into service in an effort to stabilize the grid.
In a panic reaction, Germany shut down 8 nuclear power plants
To make matters worse, in a fit of panic and hysteria, the German government shut down 8 of its older 18 nuclear reactors in the wake of the Fukushima disaster, thus removing a very cheap and stable supply of power and further pushing the grid to the limits. Before the shutdown of the nuclear reactors, Germany had been a net power exporter; today it is a net power importer and is at times severely straining neighboring power grids. To compensate for the missing nuclear power, the government is now heavily promoting even more weather-dependent wind power, which is further destabilizing the German and European power grids. A solution to the problem of storing electricity is still at least a generation away.
The question of course is how could such absurd decisions have been made to begin with? Were there no experts involved in the planning of the new power generation infrastructure? The answer obviously is no. Power executives are viewed as evil, dirty and greedy polluters, and thus were never really consulted. They could not be counted on to give the politically correct solutions. Therefore the decision to shut down the German nuclear power plants and to massively support renewables was done unilaterally by the government, without consulting the power executives or even neighboring countries.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Offshore wind parks, but no transmission lines to industrial regions!
Now that the damage is spreading, Germany’s utilities are now struggling to keep the grid stable and to fill in the power gap left by the shut-down of nuclear reactors. To do this the German government has ordered the installation of large-scale wind parks in the North and Baltic seas, in addition to the re-commissioning of mothballed, inefficient coal-fired plants. This overall energy production transition from nuclear and fossils over to “renewables” is dubbed by German officials as the Energy Supply Transformation. Construction of the offshore wind parks is now progressing rapidly. But there’s just one problem: the huge high voltage power transmission lines needed to bring their power to Germany’s industrial heartland to the south are missing! More than 3000 km of these lines are needed, but are nowhere near in sight. The government forgot about those too.
Activists groups blocking grid expansion
Building the power transmission lines quickly across the landscape will be a virtually impossible task. Activist groups have long since organized and are effectively blocking their approval and construction. So far only a measly 214 km have been built. As a result, surplus wind power cannot be delivered to the markets, and thus either has to be destroyed, dumped on the market at “negative prices”, or wind park owners are simply ordered to stop generating. No problem though – paragraph 12 of Germany’s Energy Feed-In Act requires electric utilities to pay for the electricity that they ask not to have produced! Technically, there is an incentive for wind parks to destabilize the grid.
Eventually all these costs add up and in the end they get passed along to the consumer. Under the bottom line, consumers have to pay more and more, and for a lower and lower quality supply. German industry is getting nervous and surveys show that many are leaving Germany, or are planning to do so. They no longer view Germany’s power supply as reliable.
In a death spiral…”will fail spectacularly”
Dr. Guenter Keil’s report focusses in detail on the amazing absurdities of Germany’s Renewable Energy Feed-In Act and the country’s utopian Energy Transformation. The government, through intrusive meddling and ballooning bureaucracy, has maneuvered Germany’s energy supply system into a vicious death spiral: the more the government intervenes, the greater the mess becomes. And the greater the mess becomes, the more the government intervenes! Dr. Keil concludes:
Germany’s energy transformation has already failed. For Germans, the outlook is bleak. …the planned mismanagement is heavily damaging the economy and will fail spectacularly some years later because its economic and social costs will have become unbearable. The question remaining open is how many billions of euros will have to be destroyed before a new energy policy (a new energy transformation?) picks up the shattered pieces.”
So it’s no wonder that according to a survey of experts from 21 national committees by the World Energy Council, 0% said they could imagine their own country completely taking over the German political approach. An equal number believe Germany will reach its stated targets. Germany’s model will serve as a classic lesson on how not to handle energy production and management.
Dr. Guenter Keil was a scientific employee at the Technical University of Munich / Fraunhofer Society, as well as Project Support at the Federal Research Ministry.
 Contact EIKE at: limburg@grafik-system.de
============================================
KEIL’S FULL 28-PAGE REPORT IN ENGLISH
I’ve read the entire report, and I can say that it sounds worse than Soviet-style central planning.
Share this...FacebookTwitter "
"The concept of the circular economy has left the realm of academic theory and entered the world of business. The price of natural resources and materials is soaring, and in response to volatile markets and increasing competition, developed nations are examining this sort of alternative economic model.  A circular economy is one that exchanges the typical cycle of make, use, dispose in favour of as much re-use and recycling as possible. The longer materials and resources are in use, the more value is extracted from them. This could contribute toward reducing Europe’s dependence on critical materials such as cobalt, fluorspar or gallium, but also reduce overall demand by recovering the resources, nutrients or energy contained in products at the end of their useful life.  Extending the life of products and materials prevents the over-generation of waste and recovers the full value of products. This would create new business opportunities and revenue streams, while minimising the environmental impact of mining, resource extraction, refining and manufacture.  Moving towards a more circular economic model is one of the pillars of the EU 2020 strategy – and within a few weeks of each other the European Commission and a committee of British MPs have released reports on how to bring it about.  The EU proposes to define a headline target of material productivity, a measure of the amount of value generated per unit of raw materials or products. Based on GDP relative to raw material consumption, this would be set at 30% by 2030. The package also includes a legislative proposal to review waste targets which includes targets for 70% recycling of municipal waste, 80% recycling of packaging waste and bans on any landfilling of recyclable goods. Other measures would boost innovation in resource efficiency, and tackle material intensive sectors, such as construction, with measures to improve the material efficiency of buildings through a harmonised framework for life-cycle assessment of buildings and promotion of secondary markets for construction materials. From the UK, the Environmental Audit Committee’s report on “ending the throwaway society” calls for an ambitious strategy to lay down the right conditions to transition to a more circular economy.  The committee’s proposals are more radical, suggesting lower VAT for recycled products and repair services to encourage new markets, innovation and better eco-design of products. The report also calls for a recycling regime that would improve on the limitations of the current system of many different, local schemes. Although all these measures have potential it’s unlikely they are enough to provoke the sort of radical changes in patterns of consumption and production required. From Europe the strategy relies on hefty recycling targets, but the measures to make it easier and more worthwhile to re-use waste to create new products are still missing.  Taxes have proven extremely successful in reducing material waste and in driving demand for secondary, recycled or re-used materials markets. For example, the UK aggregates levy for the construction industry has increased recycling rates of aggregates (sand, gravel, etc) to 25% and boosted the market for recycled aggregates. It has, in other words, made it worthwhile to re-use and not to waste. Run across the entire EU, a similar tax could lead to revenues in the order of €800 billion and hugely reduce material requirements for the building sector. While talk of implementing a circular economy emphasises the opportunities, there’s little reflection on the costs and challenges of the changes required. It’s true that waste is valuable, but recovering that value is complex and costly. For example, construction waste, the single most important waste stream in the EU, contains metals, minerals, glass and wood, but nonetheless in most cases has negative value – companies have to pay others to take it away. The re-manufacturing sector in the UK has a potential to generate £5.6 billion with the right support, but none of the suggested policies do anything to overcome the barriers it faces.  The entire European package lacks any systemic approach. The emphasis on waste and recycling distracts from the need to address the consumption aspect. Although there is some mention of the need to design products to be more recyclable and re-usable from the start, more work is needed to redesign the whole production and consumption system itself. We need not just products that are more easily and economically recycled but also products that last longer and are better for the environment. We also need the production and consumption infrastructure in which resources are optimised to maintain their value and usefulness over the lifespans of a number of products, at the end of each being recycled into another.  This is no mean feat, and will require measures such as industrial symbiosis, which is aimed at closing the loop by promoting co-operation across different industries where waste streams from one become inputs to another. Or an extended producer responsibility schemes where producers have a duty of custody of the resources contained in a product even after its sale.  Another shortcoming of the package is the lack of reference to commerce and industry that accounts for about a quarter of the EU’s waste. Some organisations are taking the lead, for example the ambitious Marks & Spencer’s Plan A, Unilever’s sustainable living plan, or Sainbury’s recent announcement that one of its stores would “close the loop” by using its own food waste to power the store. But until these outliers become the norm there is much more the EU and national governments could do to encourage them."
"**An expansion of coronavirus testing for hospital patients and health and social care staff has been announced by the Scottish government.**
Health Secretary Jeane Freeman said frontline health professionals would receive twice-weekly tests.
Emergency hospital admissions will also be tested from next week, and will be extended to all admissions next month.
Testing will also be expanded in the coming months for care home visitors and staff.
However, the GMB union said it would not be until March that all at-home care workers received regular tests, which it described as ""shameful"".
And opposition politicians accused the Scottish government of making similar promises in the past without delivering, and said the measures should have been introduced months ago.
Ms Freeman said the roll-out to health professionals would include frontline staff in hospitals, the Scottish Ambulance Service, Covid assessment centres in the community and healthcare professionals who visit care homes.
It will be phased in from next week, with the aim of being completed by the end of December.
Visitor testing will be initially introduced in up to 12 care homes across four local authority areas from 7 December, with full roll-out planned for January.
To facilitate Christmas visiting in all care homes, PCR testing will be provided for those that do not have access to lateral flow testing by that time.
Ms Freeman said guidance on visiting arrangements over Christmas is to be published shortly.
Testing for home carers will start to roll-out from mid-January.
December will also see the start of a testing programme for students before they return home for Christmas.
And targeted geographic testing will be trialled in communities covered by NHS Ayrshire and Arran, Forth Valley, and Greater Glasgow and Clyde, which are currently under level four restrictions.
This trial will utilise a mixture of existing and new testing technology, and will include an asymptomatic test site with capacity to test up to 12,000 people over the course of a week in Johnstone, Renfrewshire.
The results of these pilots will inform plans for a wider programme of targeted community testing in early 2021.
Ms Freeman said the plans would ""provide further protection for our communities, our extraordinary health and social care staff and the people they serve"".
She added: ""This expansion is possible because of increases in our testing capacity, delivered through our new regional hub laboratories and supply of new testing technologies, which will help us suppress Covid to the lowest levels possible as we face a challenging winter ahead.""
Scottish Labour MSP Monica Lennon said the Scottish government had made similar promises about testing ""time and time again"", and said there was a ""worrying lack of detail"" on how it would work.
She added: ""SNP ministers were warned months ago to test all hospital workers routinely to help slow virus transmission, but today the SNP government announced that it will be December before this happens.
""For at-home care workers, they will have to wait until March - a full year on from the start of the pandemic.""
And Rhea Wolfson of GMB Scotland added: ""In all probability it will be March 2021 before every home care worker has testing at work and staff could very well be receiving their vaccinations before they ever receive a test.
""Last March the first minister told us that Scotland was prepared for this pandemic and that Scotland had among the best testing capacity in the world. This was a tissue of lies.
""Covid has exposed how poorly Scotland's carers are valued and today's statement is the equivalent of kicking an exhausted workforce when they are already down."""
"The data tells us that climate change is real, but sometimes the feeling on the ground is far from convincing. A spell of hot weather can always be compared to a similar spell of hot weather from way back in the past. Similarly a big storm, intense rain and flooding often have parallels from long ago. Now a study in Geophysical Research Letters reveals that the signs of climate change are harder to spot in mid-latitude countries such as the UK and US, and easier to see in the tropics. Ed Hawkins, from the University of Reading, and colleagues compared global mean temperature fluctuations with local temperature fluctuations for different parts of the world. They show that while the global average temperature has wiggled smoothly upwards, a mid-latitude location such as Oxford in the UK has always had wild swings in temperature. “Climate change impacts in some countries are being hidden by their own changeable weather,” writes Hawkins. By contrast increasing temperatures in tropical regions are more obvious because the background climate is steadier in these regions.  When it comes to rainfall, the data reveals a clear signal of increasing extremes, masked in mean rainfall plots. Large parts of the UK have now experienced exceptional deluges, incomparable to historic records."
"Wherever you go in Britain – in city, town or country – you can come across a hidden wildlife haven. It may be home to sand lizards and stoats, adders and orchids, butterflies and bush-crickets, water voles, peregrine falcons, or great crested grebes. Yet often these oases are not official nature reserves, but little scraps of land we rarely consider important for nature. Churchyards, roadside verges, railway cuttings and disused quarries may not appear to have much in common. But they were all originally created for humans’ needs, before becoming places where wild creatures thrive. Together, they add up to an area larger than all our official nature reserves combined.  Not that these spots are unimportant to people. Often on the edge of urban areas, they are accessible to more people than rural nature reserves – especially to those who, by an accident of birth, background or geography, do not have access to “real” countryside. These places also matter for another, even more urgent reason. Since the second world war, a continuous drive towards more intensive farming has turned much of our countryside into a wildlife-free zone. That’s where the sites featured in this book come in. They provide a much-needed refuge for otherwise scarce species. Without them, some of our most vulnerable wild creatures would already have disappeared. I don’t need to tell you that Britain’s wildlife is under threat. Loss of habitat, pollution, persecution and, above all, the global climate emergency, mean that even our once common and widespread species are now struggling. So, at the start of this make-or-break century, as our wildlife enters one of the most challenging periods in its history, I have travelled round the country to visit these unheralded sanctuaries. Without them, nature in modern Britain might not be able to survive at all.  My taxi driver looked puzzled. ‘No, fella – there’s nothing down there except an industrial estate. I’ve never even heard of the “Window on Wildlife”!’ Fortunately, Google Maps came to our aid, and we headed through the rush-hour traffic towards Belfast docks. Twenty minutes later, we arrived outside “WoW” – the RSPB’s Window on Wildlife. The first thing that struck me was the strident calls of black-headed gulls, floating en masse over the lagoon before drifting down to land on artificial nesting rafts. They were accompanied by more delicate, wraith-like birds – common and Arctic terns – and dozens of black-tailed godwits, feeding voraciously. During the 1960s, when the port was being regularly dredged to permit the passage of large ships, the mud was dumped into three large pools. The plan was that eventually the mud would settle, and the land could then be reclaimed for building. But nature had other ideas. The fertile combination of water and mud created the ideal habitat for waterbirds such as ducks and waders, and they came here to feed in their thousands. Gradually, it became clear that the area was a real hotspot for birds: not just migrants and winter visitors, but breeding species too. Local people began lobbying to save this precious place from development. After long negotiations with the port authorities, the middle of the three lagoons was set aside for wildlife. Back at the visitor centre I had a chat with two regular volunteers, Ken and Phyllis. Ken reflected on the irony that somewhere that looks so natural is entirely created by humans, while Phyllis had noticed that, as the nearby industrial estate and business park grows, more and more workers are dropping in, lured by the sign outside. Belfast WoW is, to be honest, a bit out of the way to attract casual passers-by, as my taxi driver confirmed. But that’s all the more reason why places like this need championing. Phyllis told me she loves the reaction from visitors when they enter the observation area for the first time. ‘They just say, “Wow!”’ The southern migrant hawker is one of the most attractive of all our two dozen dragonfly species, and not only because it is so rare. The male is a dazzling cerulean shade, each azure segment interspersed with jet black. Close up, through my zoom lens, I could see the pale blue eyes and the lattice-like wings, laced with tiny shards of gold. This was just one of the amazing insects I saw on a recent visit to Canvey Wick, Britain’s first “brownfield” nature reserve. It is also home to a plethora of birds such as the whitethroat and stonechat as well as reptiles including adders and common lizards. In the early 1970s, this site was earmarked for an oil refinery, but the oil crisis led to the cancellation of the entire project. Afterwards, it was simply allowed to return to the wild. Had someone wanted to design a nature reserve for insects, they could hardly have done better – yet Canvey Wick is perhaps the most genuinely accidental habitat in this book. The poor, sandy soils only allow vegetation to grow slowly, so the wildflowers and grasses are not swamped as they might be elsewhere. And the large, circular stands of asphalt where the oil tanks would have stood built retain heat, creating a microclimate ideal for continental, warmth-loving species such as the shrill carder bee. Then there is the location: Canvey Island is one of the sunniest, warmest and driest places in the whole of the UK. Canvey Wick has been described as “England’s rainforest”, but as the Guardian’s wildlife writer Patrick Barkham pointed out, “England’s savannah” is a better description, given the absence of large trees. Like so many other wildlife-rich sites I have visited, it is a mosaic of mini-habitats: birch and willow scrub, brambles, dry and damp reedbeds, long grass and earth banks, which between them create exactly the right mix of ecological niches. Canvey Wick may not look special, but for invertebrate life it rivals well-known nature reserves such as Minsmere, Wicken Fen and Dungeness. As ecologist Dr Sarah Henshall notes, its unusual history gives it a special place in our natural heritage: “Canvey Wick is wild, it’s different, it’s rough around the edges. Wildlife thrives in the untidy messiness – that’s what makes the site unique.” I am reminded of my childhood, when I played for hours in places like this. Canvey Wick is the clearest possible evidence why the label “brownfield site” is so unhelpful – indeed positively detrimental. To those who care about Britain’s wildlife, it’s these messy corners that need to be prioritised, not the green swathes of agri-desert that make up so much of our lowland countryside. In May 1974, I cycled from my home to the village of Datchet, where the Queen Mother Reservoir was being built. I walked slowly through the heat-haze towards a distant strip of water, where a slim bird took off a few yards in front of me, giving a persistent, high-pitched whistle I now know was a sign of alarm. I lifted my binoculars to see a small, long-winged wader circling low over the gravel. When it landed, I could see the plain, brownish back, black mask and, most importantly, a thin, lemon-yellow eye-ring: my first ever little ringed plover. This was a classic example of a species adapting to an “analogue habitat”. On the continent, little ringed plovers nest on the shingle banks of rivers, swept clean of vegetation by winter floods. The bare shingle allows them to disguise their eggs, especially from aerial predators such as kestrels. Gravel pits and reservoirs provided an ideal substitute for riverbanks, and during the post-war years they allowed the little ringed plover to gain a foothold this side of the Channel. About this time, I came across Adventure Lit Their Star, by Kenneth Allsop. The name will be familiar to readers of a certain age, for Allsop was a familiar face on TV during the 1960s. This was a Boys’ Own adventure story, in which an airman recovering from tuberculosis joins forces with two young lads to foil attempts by an egg-collector to steal a precious clutch of little ringed plovers’ eggs. The message is that birds need to be protected and welcomed and, more importantly, that nature can offer a form of therapy. This was something Allsop, who had lost a leg in the war and suffered periodic bouts of depression, understood only too well. Little ringed plovers went against expectations to breed in what Allsop described as “the messy limbo that is neither town nor country”. As a definition of the Accidental Countryside, this could hardly be bettered. It took me five minutes to walk round. At the edge of the peat diggings a few miles from Glastonbury I saw 10 birds, of just four species. And yet, apart from the five loitering mallards, the others confirmed these changing times. The first bird was a little egret. I am old enough to remember when one of these impossibly white birds made any birding trip a red-letter day. Even now, I still feel a jolt of pleasure whenever I see this little heron, which when I was growing up was still confined to the area around the Mediterranean. Moments later I saw a buzzard, another bird that wouldn’t have been here 20 years ago. Whereas the little egret extended its range northwards thanks to climate change and habitat restoration, the buzzard benefitted from an end to persecution by gamekeepers, enabling it to recolonise its former haunts. The next bird was one of my favourites: the green sandpiper. I half expected to see it here on this warm, early-August evening, as they drop in to feed on their journey south to Africa. For me, they are the first sign of autumn, despite appearing at the height of summer. The final pair of birds would once have been a very rare sight here. But there are now several dozen great white egrets on the Somerset Levels, and recently they have begun to visit my local patch. Birds like the great white, little and cattle egrets (another recent colonist), give the lie to the idea that all our wildlife is in decline. It’s not, but it wouldn’t take much to destroy these temporary, liminal habitats on which so many wild creatures depend. Before I left, I heard the piping call of that lone green sandpiper, and watched it rise into the sky. As it disappeared, I wished it good luck. It would need it, for just as places like this are being destroyed, so its stop-over points are also under threat, from wetlands being drained, or drying up because of climate change. One day, I fear, I will watch one disappear over the horizon, and that will be the last time I ever see a green sandpiper; not just here, but anywhere. Birds are resilient creatures, for sure, but are they resilient enough? The Accidental Countryside: Hidden Havens for Britain’s Wildlife, by Stephen Moss, is published by Guardian Faber (£16.99). To buy for £11.99 go to bookshop.theguardian.com "
"**A Christmas shop that was ordered to close due to lockdown restrictions has been allowed to reopen.**
Ipswich Borough Council (IBC) served a prohibition order on Christmas Wonderland in Tavern Street, arguing it did not sell enough ""essential"" items.
But it has since been found ""compliant"" because it sells real Christmas trees.
Owner Zoe Scarrott said: ""We're obviously very pleased that they've allowed us to open and they feel that we're now abiding by the legislation.""
A council spokesman said: ""The Christmas Wonderland shop has been assessed for compliance with the regulations since reopening and found to be compliant.
""This is because the government's rules on what's allowed to be sold as 'essential' changed on 21 November to include real Christmas trees.""
IBC said it was ""satisfied that this retailer is complying with the amended regulations"".
It said it continued to monitor compliance of businesses across the town during lockdown and ""will take appropriate action where required"".
When the prohibition order was issued, Ms Scarrott said she felt ""discriminated against"" as a small business.
She said the shop's tenancy agreement had always allowed it to stock essential items in case of a second lockdown.
However, because the prohibition order had already been issued, it was only the change in legislation that allowed it to reopen.
""We never intended to get into a fight with the council but we just wanted people to consider the bigger picture,"" she said.
""We won't claw back what we've lost but it gives us extra time to try to make it up.""
England is due to come out of the current lockdown on 2 December.
_Find BBC News: East of England on_Facebook _,_Instagram _and_Twitter _. If you have a story suggestion email_eastofenglandnews@bbc.co.uk"
"
Share this...FacebookTwitterA couple of days ago I wrote a piece about a paper by some Australian shrinks claiming that skeptics are prone to believe conspiracy theories, like the 1969 moonlanding being staged in Hollywood.
But Marc Morano reminds us that there is a small problem with their assertion. Some of America’s most prominent skeptics are former astronauts who actually walked on the moon: Jack Schmitt and Buzz Aldrin. Gee, do you think they believe it was all done in Hollywood, too?
Please read Marc’s piece from 2009.
==========================================
Oops! Shades of Gore: Joe Romm’s research comes up short: Unknowingly Uses Skeptical NASA Moonwalker Schmitt to Rail on Global Warming Skeptics 
 By Marc Morano
Former Clinton Administration official and climate fear promoter Joe Romm — followed in the footsteps of former Vice President Al Gore — by linking skeptics of man-made global warming fears to those who believe the 1969 moon landing was staged. (Note: Romm and Climate Depot’s Morano debated global warming in March 2009. See: Morano debates former Clinton Official Romm – April 6, 2009).
The embarrassing problem for Romm is that he — unknowingly — used one of the most prominent global warming skeptics, NASA moonwalker Harrison ‘Jack” Schmitt, in an attempt to “prove” climate skeptics are akin to those who believe the moonlanding was staged.
Schmitt, who flew on the Apollo 17 mission, declared in 2008:
“The ‘global warming scare’ is being used as a political tool to increase government control over American lives, incomes and decision making. It has no place in the Society’s activities.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




But Romm, in his July 20, 2009 article railing on climate skeptics, failed to do basic research on moonwalker Schmitt’s skeptical climate views. Romm approvingly cited Schmitt’s scientific views in an article at Climate Progress that was intending to smear climate skeptics.
Romm asserted: ‘I’m just drawing the painfully straight line from the moon hoax people to the climate hoax people.’ (Romm followed in Gore’s footsteps: See: Moonwalkers Defy Gore: NASA Astronaut Dr. Buzz Aldrin and Jack Schmitt reject global warming fears: Defy Gore’s Claim That Climate Skeptics Are Akin To Those Who Believe Moon Landing was ‘Staged’ – July 3, 2009).’
Romm approvingly quoted Schmitt rejecting moon landing conspiracy theories.
‘If people decide they’re going to deny the facts of history…(continue reading…)
=====================================
A final note: Reader Paul Matthews left a comment listing the 8 blogs the Australian shrinks used to get participants in their survey:
http://www.skepticalscience.com
http://tamino.wordpress.com
http://bbickmore.wordpress.com
http://www.trunity.net/uuuno/blogs/
http://scienceblogs.com/illconsidered/
http://profmandia.wordpress.com/
http://scienceblogs.com/deltoid/
http://hot-topic.co.nz/
Need we say more? Now we really know who belongs on the couch.
 
Share this...FacebookTwitter "
nan
"Commercial tree plantations in Britain do not store carbon to help the climate crisis because more than half of the harvested timber is used for less than 15 years and a quarter is burned, according to a new report. While fast-growing non-native conifers can sequester carbon more quickly than slow-growing broadleaved trees, that carbon is released again if the trees are harvested and the wood is burned or used in products with short lifespans, such as packaging, pallets and fencing.  Of the UK’s 2018 timber harvest, 23% was used for wood fuel, while 56% was taken to sawmills. Only 33% of the wood used by sawmills was for construction, where wood used in permanent buildings can lock in carbon for decades. Much of sawmill wood was used for fencing (36%) with a service life of 15 years, or packaging and pallets (24%) or paper (4%). “There is no point growing a lot of fast-growing conifers with the logic that they sequester carbon quickly if they then go into a paper mill because all that carbon will be lost to the atmosphere within a few years,” said Thomas Lancaster, head of UK land policy at the Royal Society for the Protection of Birds (RSPB), which commissioned the report. “We should not be justifying non-native forestry on carbon grounds if it’s not being used as a long-term carbon store.” The Committee on Climate Change has called for 1.5 billion new trees by 2050 – requiring planting on 30,000 hectares (74,000 acres) of land a year, increasing Britain’s forest cover from 13% to 19%. Many of these new forests will also provide a commercial timber crop. But the scientific review by the ecologist Ellie Crane of how forestry can best address the climate and biodiversity crisis finds that there is no simple solution in Britain. The best place for non-native conifers to quickly sequester carbon is on intensively farmed lowland but this high-quality agricultural land is too expensive for forestry to make financial sense for landowners. Planting conifers on the cheapest land such as the blanket bogs of Scotland’s Flow Country is “disastrous” for biodiversity, according to Lancaster, but also leads to carbon emissions because the bogs are drained for forestry and the peat degrades, releasing carbon into the atmosphere. This leaves “shallow peat” moorlands of western Scotland, south and mid-Wales and parts of the Lake District and the Pennines as the most likely locations for new carbon-sequestering forests. Here, the RSPB has concerns about the impact on wildlife. Rare and declining species such as the curlew that breed on open moorland cannot survive close to plantations, which become home to predators of their chicks such as crows. While the best option for wildlife and slower but long-term carbon sequestration is to plant broadleaved woodlands in the right locations and leave them intact, if Britain does not produce its own timber it will import more – in effect exporting its carbon footprint overseas. “It’s clearly not just a question of more trees equals a safer climate. Trees in the wrong place could exacerbate climate change and biodiversity decline,” said Lancaster. “There’s also a big question around the capacity of Natural England and regulatory bodies in Scotland and Wales and the forestry commissions to properly assess what impact any planting schemes will have on nature, both good and bad, and on the climate. “If we’re serious about tackling the climate and ecological emergency there needs to be a huge government investment in capacity to get that right, otherwise we’re going to have lots of inappropriate planting which could be negative for the climate as well as biodiversity.”"
"
As shown by the indicators on WUWT’s new ENSO/SST page there is a deeping of the La Niña that is starting to rival 2008 in depth. While it hasn’t yet reached the level of the 2008 event, indications are that it is possible to match or even exceed it.

The graph above from Australia’s BoM took a dip just today, going from last week’s value of approximately -0.9 to -1.4C.
Other NINO index indicators show similar recent drops:





For those unfamiliar with what these index graphics represent, here is a map that shows the regions covered:

The combined 3.4 index has been deemed a useful metric to gauge El Niño and La Niña events and thus you’ll see it more commonly referenced than the other indices.
Of course a picture is worth a thousand words:



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89739bda',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterIt’s great to see what all those tens of billions of euros spent on renewable energies and the skyrocketing costs of electricity have accomplished. Nothing!
According to the German Press Agency, dpa, European greenhouse gas emissions jumped 2.4% in 2010. The figures were released by the European Environment Agency (EEA) in Copenhagen yesterday. Read about it here.
Officials blame economic recovery in many countries and the harsh winter for the jump. Actually, the tens of billions of euros did have an impact. According to EEA Director Jacqueline McGlade:
…the increase could have been even higher without the fast expansion of renewable energy generation in the EU.”
Boy, I feel a lot better already. Actually I don’t. Even if emissions had gone down, it still would have been a complete waste of money, and is not going to change the climate. And whatever Europe manages to save in emissions over the next decade will simply be offset by China’s explosive growth in just matter of weeks.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to the EEA: Germany, Poland and Great Britain are responsible for 56% of the increase. Finland, Sweden and Austria also posted large emission increases. Shame on you.
But there were some big successes in Europe. Large emission savings were accomplished in Greece, Spain and Portugal. Congratulations! Of course, these happen to be the countries in Europe that have crashed economically. The media just forgot to mention that.
The Express (link above) writes:
Despite the increase in 2010, the 27-nation bloc is on track to meet its emissions targets under the Kyoto protocol, a 1997 climate accord limiting the emissions of most industrialised countries, the EEA said.”
What they don’t mention is that a large part of those cutbacks was achieved by the collapse of the former East Block and the really dilapidated factories of communist central planning.
 
Share this...FacebookTwitter "
"
Many of you watch sea ice as closely as some people follow the NFL, soccer, or NASCAR. So when something of interest happens, I’m not without an inbox full of notices.
Today it is encouraging to see the NANSEN is reporting that both Arctic Sea Ice area and extent are above the normal line. Usually we don’t see both in this mode. Here’s area:

And here is extent:

Source: http://arctic-roos.org/observations/satellite-data/sea-ice/ice-area-and-extent-in-arctic
By itself, this is just a small thing, but it is just one more indication that there’s some improvement in the Arctic Ice situation again, and the indications are that we’ll have another summer extent that is higher than the previous year, for the third year in a row.
Of course our friends will argue that extent and area don’t matter now, that only volume and ice quality (the rotten ice meme) matters.
Interestingly, if you go back to  the press releases on the record minimum extent in 2007 at NSIDC here:
http://nsidc.org/arcticseaicenews/2007.html
And search the entire set of release for the word “volume”, you won’t find it used anywhere that year. The volume worry is a more recent talking point that first appeared in October 2008 when it became apparent that extent wasn’t continuing to decline. They couldn’t tout another record low extent, so volume became the next big thing:
http://nsidc.org/arcticseaicenews/2008/

Arctic  sea ice minimum press release
Please see the NSIDC press release, “Arctic  Sea Ice Down to Second-Lowest Extent; Likely Record-Low Volume” for  a detailed analysis of this year’s Arctic sea ice minimum and a  synopsis of the 2008 melt season.
With nature still not cooperating with “death spiral predictions”, what will be the press release ice meme this year? Color? Texture? Cracks per square kilometer? It will be interesting to watch.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c3f0dc3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterGerman veteran meteorologist Klaus Eckhart Puls writes a piece at the European Institute for Climate and Energy (EIKE) on what he calls the “glaring contradiction between IPCC prognoses and reality”. Rather than increasing 0.2°C per decade, global temperatures over the past decade have actually declined.
Global mean temperature hasn’t risen in over 10 years. (Chart K.E. Puls)
Warmist Max Planck Institute now in a state of panic
Since Fritz Vahrenholt’s and Sebastian Lüning’s skeptic book “Die kalte Sonne” has become a German bestseller, major German climate institutes have gone in a state of panic to salvage global warming scenarios. They refuse to acknowledge that observed data deviate completely from their model projections. Instead they have undertaken a massive campaign to feed the media panic machine by unveiling their “latest model projections” which shows the planet is warming rapidly. However, the observed trends tell the opposite story.
The Max Plank Institute (MPI) for Climate Research in Hamburg and the Alfred Wegener Institute in Bremen last week went on a professional media blitz, claiming that temperatures are going to climb faster than ever and that the Arctic ice cap will melt – all based on their latest computer models, which will become part of the IPCC 5th Assessment Report. Why do they ignore reality and real observed data and focus on crystal ball projections?
Puls writes:
The most beautiful catastrophe from the computer crystal ball – the so called climate model – is always juicier than the arduous look at reality, which looks entirely different.”
Puls makes his point using charts from observed data and trends. Here I will present only the global data charts. Here’s what the Daily Mail said a month ago (see blue text in chart):

Here’s the global trend over the last 10 years:
Falling global temperatures (Chart: K.E. Puls)


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The above chart is from data from the Climate Research Unit of the University of East Anglia – a leading provider of climate data to the IPCC. Where’s the warming catastrophe? Answer: in the climate crystal balls of the Max Planck Institute and others only, and nowhere else!
Modellers ignore natural factors sun and oceans, massively inflate CO2
So why do their models continue to produce only warming? It is because the modellers are deliberately ignoring major climate driving factors such as ocean cycles, solar cycles and their amplification mechanisms, and wrongfully transfering their respective warming effects over to human-emitted CO2. Volumes of data and the trends of the last 15 years show this is wrong to do – but they continue to intentionally do it anyway.
From wrong science to fraud science
Deliberately ignoring the major natural factors while wildly exaggerating another, despite the volumes of data out there, has been going on in the IPCC models for years now. We’ve seen the culture of deception in the Hockey Stick, Al Gore’s exaggerated AIT, Climategate, Hansen’s adjustments and just recently with the behavior of Peter Gleick. With every passing year, scientists have noticed the widening deviation between their models and reality, yet they continue to ignore the major factors of sun, oceans and soot, and they manipulate the models even more to make CO2 appear as the culprit.
This systematic fudging and manipulation of models is increasingly fitting the definitions of criminal fraud. Unless the IPCC changes its course and starts acknowledging the sun, oceans and soot in its models in its next report, then the public will have grounds to sue them for fraud in a class action suit. The sheer weight of the data showing that the sun, oceans, etc. have considerable impacts is overwelming and can no longer be ignored in good faith.
A society the feels defrauded needs to start taking the legal steps to begin moving the case forward. It can be argued that the line between wrong science and fraud science was crossed long ago and that the hand of justice needs to intervene.
German readers can read more about Klaus-Eckhart Puls’s piece at EIKE here and “Die kalte Sonne, here“.
 
Share this...FacebookTwitter "
"

A recent _Science_ paper by J-F. Busteri and 30 named coauthors assisted by 239 volunteers found, looking at global drylands (about 40% of land areas fall into this category), that we had undercounted global forest cover by a whopping “at least 9%.” 239 people were required to examine over 210,000 0.5 hectare (1.2 acre) sample plots in GoogleEarth, and classify the cover as open or forested. Here’s the resultant cool map:   






This has been the subject of a flood of recent stories, blog posts, tweets, and whatever concerning Bastin et al. But here at the Center for the Study of Science, we’re _value added_ , so here’s some added value.   
  
  
Last year, Zaichin Zhu and 31 coauthors published a remarkable analysis of global vegetation change since satellite sensors became operational in the late 1970s. The vast majority of the globe’s vegetated area shows greening, with 25–50% of that area showing a statistically significant change, while only 4% of the vegetated area is significantly browning. Here’s the mind‐​boggling map:   






_Trends in Leaf Area Index, 1978–2009. Positive tones are greening, negative are browning, and the dots delineate where the changes are statistically significant. There is approximately 9 times more area significantly greening up than browning down._



Hope you’re sitting down for the money quote:   




We show a persistent and widespread increase of growing season integrated LAI (greening) over 25% to 50% of the global vegetated area, whereas less than 4% of the globe shows decreasing LAI (browning). Factorial simulations with multiple global ecosystem models show that CO2 fertilization effects explain 70% of the observed greening trend…



And the other greening driver that stood out from the statistical noise was—you guessed it— _climate change_.   
  
  
Now, just for fun, toggle back and forth between the two maps. As you can see, virtually every place where there’s newly detected forest is greening, and a large number of these are doing it in a statistically significant fashion. This may lead to a remarkable hypothesis—that one of the reasons the forested regions were undercounted in previous surveys (among other reasons) is that there wasn’t enough vegetation present to meet Bastin’s criterion for “forest,” which is greater than 10% tree cover, _and carbon dioxide and global warming changed that._   
  
  
**References:**   
  
  
Bastin, F-L., et al., 2017. The extent of forest in dryland biomes. _Science_ 356, 635–638.   
  
  
Zhu, Z., et al., 2016. Greening of the earth and its drivers. _Nature Climate Change,_ DOI: 10.1038/   
  
  
NCLIMATE30004. 
"
"With each monsoon season India waits with bated breath for forecasts from the India Meteorological Department and other international forecasting agencies. This year’s forecast suggested a weakened monsoon, and sure enough for five weeks the monsoon has failed to provide the deluge that is expected.  For India, the monsoon rains typically last from June to September and contribute a whopping 80% of the annual rainfall total.  Indian society is therefore finely tuned to the monsoon for its agriculture, industry and water supply for drinking and sanitation.  If spread evenly over the whole country, the total rainfall during summer amounts to around 850mm. This year has seen a substantial deficit so far, currently standing at about 37% below normal and close to the large deficit in experienced in 2009, which was, like 2002 before it, a year of substantial drought, bringing reduced crop yields and hitting the country’s whole economy. Now in mid-July, the forecast looks set to improve. The monsoons’ advance northwards across the country has been particularly slow, leading to lack of water for agriculture and prolonged heatwave conditions – in Delhi a week or so ago I experienced temperatures near 40°C due to the absence of rain. In some regions, farmers have had to plant alternative crops that require less water due to the lack of rain, and authorities have diverted irrigation to drinking water, exacerbating their problems. The monsoons are the biggest manifestation of the effects of the annual seasonal cycle on the planet’s weather. During spring and summer, the difference between the rapid warming of the Earth’s surface and the slower warming of the nearby ocean generates a tropospheric temperature gradient – a strong gradient in air temperature from north to south of the equator, seen in South Asia most strongly over northern India and the Tibetan Plateau. This temperature gradient stretches far up into the atmosphere forming a difference in pressure, stretching from high pressure over the southern Indian Ocean to low pressure over India. The result of this pressure gradient is the seasonal winds we know as the monsoon, which carry moisture to supply the monsoon rains across Asia. The onset of the monsoon rains typically comes at the beginning of June, with the weather front stretching from the southwest Indian state of Kerala across the ocean to cover the states in the far northeast of India. For Indian society, and especially farmers, knowing about any variation in the intensity and duration of the monsoon and when it will start is vital. The progression of the monsoon across the country normally takes around six weeks, reaching the border of India and Pakistan by around mid-July. In September, the monsoon withdraws in the opposite direction, and as a result northwest regions experience a much shorter monsoon season and consequently greater pressure on water resources. So why has it been happening? While a full study won’t be carried out until after the season, it is likely that it relates to El Niño – a warming of the central-to-east Pacific Ocean along the equator that happens every few years, changing seasonal weather patterns in many parts of the world but particularly around Indian and Pacific Ocean regions.  For India, El Niño is generally associated with monsoon drought. The remote interaction with the monsoon (known as teleconnection) is caused by a disruption to the normal trade winds in the Pacific and Indian Oceans, known as the Walker Circulation after Sir Gilbert Walker, a British meteorologist in India who sought to predict when the monsoon would fail. Rising air and enhanced rainfall meet over the warm ocean surface during El Niño, much further east than Indonesia as is usual. But what goes up must come down, and these shifts in the circulation lead to descending air over India, which reduces the strength of the monsoon. Research has also established that El Niño can delay the monsoon’s onset, shortening the duration of rains over India.   A major concern is that the monsoon will be changed by global warming.  However, all the indications from our climate models are that the Indian monsoon will continue to supply the region with strong seasonal rainfall. In fact most suggest that greater concentrations of atmospheric carbon dioxide will bring more, rather than less, rain.  So far, so good – but the monsoon’s rains are not a statistical average spread equally on each day and in each location. Model simulations also suggest that tropical rainfall will tend to be heavier when it occurs, with potentially longer dry periods between rain events. Both of these factors have important implications for water resources, including crop damage as well as increased flooding. With El Niño conditions forecast to grow in the Pacific throughout the rest of 2014, the full impact on this summer’s monsoon will depend on if the forecast comes true and the location of where El Niño occurs. What we can’t yet say with any certainty is how El Niño’s link to and effect on the monsoon will change under warmer future climate conditions – we only know that greater extremes of variability are likely, and a more variable monsoon may be a problem."
"The hot and dry conditions that helped drive Australia’s bushfire crisis would be eight times more likely to happen if global heating reached 2C, according to new analysis. An international team of scientists also found the risk of Australia being hit by intense fire weather had already risen since 1900 “by more than a factor of four”.  And the scientists said it was “scary” a country as well prepared for tackling bushfires as Australia had seen its systems “severely strained” by what the called the Black Summer Bushfires. Australia’s bushfire crisis began in spring 2019 and burned at least 7.7m hectares in the south of the country, claiming 34 lives and causing an environmental disaster. More than a billion animals were killed and threatened species were pushed towards extinction. Thousands of homes were destroyed. The 17 scientists from across Europe and the US, used computer climate models to examine the impact of increased levels of greenhouse gases in the atmosphere on the risk of intense fires. The bushfire study used the computer models to look at a metric called the Fire Weather Index, which is one way to predict the severity of fires by combining wind speed, relative humidity, temperature, drought and the flammability of the fuel. The index is widely used across the world to forecast dangerous wildfire conditions. The models found the probability of the index reaching levels seen during Australia’s bushfires had increased due to human-caused climate change by 30%. But the scientists said the influence of extra greenhouse gases was likely much higher because when they compared the climate models to the actual temperatures, they found the models underestimated the extreme heat seen during the bushfires. Prof Geert Jan van Oldenborgh, lead author of the study, of the Royal Netherlands Meteorological Institute, said: “We found that climate models struggle to reproduce these extreme events and their trends realistically. “However, they always underestimate the increase in chances for extreme fire risks such as Australia saw in the last few months. This means we know the effect is likely larger than 30% increase lower bound, which is already a significant influence of global warming.” The analysis also looked at conditions under a climate that warms by 2C above the pre-industrial levels. Two climate models found that fire weather conditions like those seen in 2019 “become about eight times more likely” in a 2C world, with a “lower bound of four times more likely.” The study released on Thursday has not been peer reviewed, but is being submitted to a journal with all data being made available. The methods and climate models had been used in previous studies that had been peer reviewed, they said. Dr Sophie Lewis, a co-author of the study from the University of New South Wales, told a briefing the fires had broken out during Australia’s hottest and driest year on record. She said new records had been set for high Forest Fire Danger Index in all states and territories throughout the 2019 spring. Lewis, who is based in Canberra, recalled being stuck in her own home with a young family for weeks to avoid the heavy smoke from the bushfires. She said: “In January, the national park that forms a large part of our home in Canberra exploded in flames. It was just last week the fire was declared out. “Clearly this was an event with an enormous ecological and human cost. It’s because of this that it’s so important to understand the contributing factors to this.” Looking only at observations, the scientists found the chances of Australia experiencing Fire Weather Index ratings as high as 2019 had already risen by “more than a factor of four” since 1900. The scientists that analysed the bushfire conditions are part of a project called World Weather Attribution that has examined the human influence on previous extreme events, including the 2016 bleaching of the Great Barrier Reef. That analysis found human-caused climate change had made the heat during the bleaching event 175 times more likely to happen. Co-author Maarten van Aalst, director of the Red Cross Red Crescent Climate Centre in the Netherlands, said it was “really scary that we are seeing such extreme conditions in countries that are as well prepared [for bushfires] as Australia.” He said: “What’s really obvious in light of these findings of rising risk is that it will become even more important to build resilience and prepare for these rising risks. “But there are also limits to what we can do through that adaptation and preparedness. So it’s critical that we find ways of reducing the underlying drivers of these rising risks to avoid problems getting even further out of hand in the future.” Dr Sarah Perkins-Kirkpatrick, a UNSW climate scientist who examines extreme events who was not an author on the study, said: “Fire weather is a very complex thing to simulate. “Combined with everything about this event being unprecedented, its extremely challenging for climate models to simulate everything about fire weather perfectly. “Australia just just experienced its worst bushfire season on record, overlapping our warmest and driest year on record. We know climate change has a role in increasing temperatures, which is a component in bushfire weather.”"
"
Share this...FacebookTwitterScientists keep finding major knowledge gaps in their “science-is-settled” field of climatology.
The latest gap is revealed by an experiment by an international team of scientists that shows evidence of a new mechanism where light causes atmospheric aerosols to increase in size.
 
Aerosol pollution over India and Bangladesh, 2001. (Photo source: NASA)
The results of the research by a team led by Maria Eugenia Monge et al have been published by the PNAS. Title: Alternative pathway for atmospheric particles growth.
“The new and up to now unknown processes may be the reason why the atmospheric chemistry and physics of aerosol concentrations are often underestimated in models. This photo-induced processes first will be characterized experimentally and then introduced to tropospheric models,“ recommends Hartmut Herrmann of the German Leibniz Institute for Tropospheric Research (IfT) in Leipzig, a member of the team.
The paper’s abstract underscores that major gaps exist in the understanding of the physicochemical pathways that lead to aerosol growth in the atmosphere and that these pathways need to be considered by models.
So once again it’s back to the drawing board for our habitually lost climate modellers.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to a Leibniz Institute for Tropospheric Research press release, light causes the aerosols to grow in size and have an impact on clouds and climate. Photocatalytic reactions can lead to a rapid formation of non-condensing volatile organic compounds (VOCs) on the surface of particles. They found that light can trigger chemical reactions between gaseous bonds and chemicals on the surface of organic particles, which ultimately allows them to increase in size says Dr. Maria-Eugenia Monge of IRCELYON and the University of Lyon.
Experiments showed that the particles under the influence of light can grow about 50 to 65 nanometers, which corresponds to about a doubling of their weight. The intensity of the light was of lesser importance. Already very weak UV radiation is enough to break the chemical bonds of dissolved organic material (DOM) and form free radicals.
The experiments were conducted at the IRCELYON in Lyon under the supervision of Dr. Christian George. Also participating were scientists of the French CNRS research association, the Israeli Weizmann Institute with Prof. Yinon Rudich, and Prof. Hartmut Herrmann of the German Leibniz Institute for Tropospheric Research (IfT) in Leipzig.
The Leibniz press release adds that aerosol particles in the atmosphere influence global climate because they reflect sunlight. They are also a factor in the global water circulation, which effects cloud formation and precipitation. They also impact human health as well. Despite their impacts, the processes that are responsible for the creation and growth of these particles are among the least understood fields of atmospheric science. At the IfT in Leipzig, the development chain of atmospheric particles from fine particulates to the formation of clouds and precipitation in natural areas as well as areas burdened by humans, i.e. large cities, are being researched.
So much for the new study on light and aerosols, which we know have a cooling effect on the planet. But with the last sentence in italics by the IfT, why do I get the feeling they are gearing up (again!) for man-made global cooling? Human activity is throwing up lots of aerosols (industry, agriculture, transportation, etc.) into the atmosphere and so are contributing to blocked sunlight. Time to start curtailing human aerosols!
And one more question: if low intensity light can cause major aerosol growth, wouldn’t it be very plausible that high energy cosmic rays could do the same?
 
Share this...FacebookTwitter "
"

Blame California’s mega‐​fires on global warming. Or at least that’s what Senate Majority Leader Harry Reid (D-NV) said last week in the _Hill_.



Global warming affords endless opportunities to test glib hypotheses by politicians who have no training whatsoever in fields of which they claim pontifical knowledge. And Reid’s statement is easy to test.



By the end of each and every summer, Southern California is drier than the world’s best martini. A couple weeks ago, I took a drive up San Gabriel Canyon, an arroyo typical of the mountains surrounding the Los Angeles basin. The steep hillsides were studded with crackling‐​dry vegetation, and it was obvious that the area was sitting on the precipice of a massive fire season.



California’s big wildfires are, ironically, caused by excessive winter rains. Normally, the region that’s been ablaze averages about a foot from December through March. Owing to the fact that just about every day after the rainy season is warm and sunny, it’s only a matter of a month or two before the surface dries out to the point that there’s not enough water to support additional plant growth. The more it rains in the winter, the more vegetation grows, and the more there is to burn in the summer, which is invariably hot and dry.



The distribution of rainfall between years is a bit unusual. The vast majority of the years have below normal precipitation — about four or so inches below the average of a bit over a foot, as shown in our attached graph. In the fewer years that are above average, when it rains, it pours, with rainfall often 100% (one foot or more) above the mean.



Some of the very wet years are caused by El Nino, a reversal of winds over the Pacific Ocean that has been going on every few years ever since there was a Pacific Ocean. People like Senator Reid (and Vice President Gore) will cite computer models predicting that El Ninos should become stronger or more frequent with global warming, but there are an awful lot of other models showing that they won’t change or that they might even lessen in frequency. The Nobel Prize‐​winning United Nations Intergovermental Panel on Climate Change says “There is no consistent indication of discernible future changes in ENSO [an acronym for El Nino] amplitude and frequency.”



When things get very wet, there’s plenty more time for the soil to remain moist, producing a much longer growing season in the hills where suburbs and very expensive homes are proliferating. The problem is that these rooms‐​with‐​a‐​view are also houses‐​with‐​a‐​risk; i.e., they’re in the path of wildfires. Rain adds fuel to the fire, by bulking up the vegetation mass.



If Senator Reid is right, then rainfall, or the frequency of rainy years, must be increasing in the fire zone. Here is the total December‐​March precipitation for the California South Coast Drainage Climatological Division from 1895 through 2007. Data are from the National Climatic Data Center, a part of the U.S Department of Commerce.



What’s noted in the graph is pretty obvious. Most of the years are below the long‐​term average of about 12 inches, but the relatively few that are above the mean are often way above it. If global warming is causing the increase in Southern California wildfires, then the frequency of very wet years has to be increasing in a significant fashion, because excessive moisture is required to create excessive vegetation.



Obviously it is not. In fact, the biggest agglomeration of far above‐​normal years was a 12‐​year period beginning in 1905.



Ironically it was these rains that prompted some of the massive westward migration of U.S. population, as both California and Arizona were touted as green paradises, which they were, thanks to all that vegetation. Sure, there were wildfires then, but very few people lived within their reach.



Now that the paradise of the Los Angeles Basin is home to so many more people, whenever we have a very wet year (2005 being the last big one), it’s only a matter of time before thousands of homes get torched.



But don’t blame this on global warming. There’s no trend whatsoever in the frequency of heavy‐​rainfall years that would promote wildfires. And our officials should especially avoid making untested statements on global warming to papers like the _Hill_ , which other Senators and Congressmen accept as gospel.
"
"Lurking beneath the authorities’ radar is a vast, international underground movement that stretches from Africa and Europe to the Americas: guerrilla gardening, the un-permitted colonisation of land, is still a mysterious activity about which little research is undertaken.  The movement brings together students, academics, businessmen, planners, architects, chefs, community workers and many more professions making up the ranks. Would-be guerrillas can enlist in a troop online through sites such as guerrillagardening.org; a forum established by Richard Reynolds (“Britain’s 24th most influential gardener”), deemed the father of the modern guerrilla gardening movement. The movement has grown in recent years, fuelled partially by the rise of Twitter and other forms of social media which make it much easier to organise digs. Generally speaking, guerrilla gardeners either aim to beautify a neglected patch of land or, increasingly, pursue the cultivation of space via urban agriculture by growing fruit and vegetables in a city context. A somewhat famous example of this is Incredible Edible Todmorden, a guerrilla gardening project started in 2008 where residents “adopt” areas of the town and plant without permission. Impressed by the displays and ideas, the local authority started to work with the guerrillas and the Incredible Edible Network was soon born – now an international movement promoting the idea of urban agriculture.  Between 2010 and 2013, I carried out an extensive ethnographic exploration of those guerrilla gardeners practising their form of urban agriculture in the Midlands, UK. After some searching (and lots of luck) I tracked down three groups eager to be involved in the study.  The first was a group of local authority employees who named their collective, F Troop – a reference to the 1970s American Western TV show featuring cowboys gallivanting around without much of a plan. In this case, the troop realised this name reflected their practices, with members turning up to the dig site and planting randomly. The group occupied land next to an inner-city dual carriageway, planting nasturtiums, peas, spinach and other produce alongside the road’s barrier. Their core reason for pursuing such an activity was the thrill of transgression from messing with council land (their employer, no less).  The second was an elderly lady who, angry with her local authority’s lack of effort to clean up nearby alleyways, took it upon herself to rid the space of junk. In its place she laid out raised beds in which to cultivate vegetables. Finally, the third was group of women who occupied a large green space in a deprived area and convert it into a large community garden. Their motivation was to bring fresh produce closer to those who needed it, since the majority of those surrounding the site had poor diets. The women opted for the guerrilla route due to the perception that gaining official permission was too arduous and would only delay their activities. These three examples show the spectrum of those involved in guerrilla gardening: from the radical yet middle-class professionals of F Troop, to the group of more working-class women who adopted a large area for those around it, guerrillas come from different backgrounds and all have different reasons for pursuing their action.    As a researcher, the ethics and practicalities of interacting with an activity that exists in a legally grey area were tricky, for instance, the cities in which the above guerrillas practised cannot be named in order to protect the identities of those involved. An extra dilemma was added by the fact that I was a member of the police Special Constabulary at the time. There has been rising interest in guerrilla gardening, but the majority of this portrays it in purely positive terms. There is very little in the way of criticism, despite the fact that guerrilla gardeners often colonise space not only without the permission of the local authority, but also without permission of those who reside nearby. Guerrilla gardening could even be occurring on your street corner or grass verge, perhaps even without you knowing. Interviews with those living close to the sites colonised by the gardeners revealed that not everyone was happy. Some were angry about not being involved, or perplexed as to the appeal of produce grown in such harsh roadside environments. Furthermore, the guerrilla gardeners, especially F Troop, would provide little maintenance of the site, which would soon fell into disrepair between digs.  Guerrilla gardening can make significant changes to our landscapes: the case of Incredible Edible Todmorden demonstrates the potential of this activity. Many large urban agricultural initiatives have stemmed from underground gardening, such as New York’s community gardens or Havana’s allotments; Carrot City, an exhibition on urban agriculture, which I brought to the UK in 2012, features even more examples of projects which started through guerrilla gardening. Yet while guerrilla gardeners often improve spaces, there is a need to delve deeper and provide a more objective account of their actions; reflecting not only on what the gardeners do, but their impact on the area and the community as a whole."
"

Despite indications that much of President Obama’s agenda is meeting intra‐​party skepticism all over Capitol Hill, there is one policy nexus where congressional leaders are still doggedly determined to move the country left: energy and the environment. Speaker Pelosi will reportedly allow a vote on the controversial Waxman‐​Markey “cap‐​and‐​trade” legislation at the end of this week.



And it gets even better. Not content to tempt political fate by imposing huge carbon taxes on the American middle class, Democrats have added a provision which imposes stiff tariffs on our trading partners if they don’t adopt aggressive carbon restrictions of their own.



You heard correctly: progressives have authored a bill that earns the mortal enmity of domestic energy consumers and our most crucial trading partners at the same time. Economy‐​killing climate policies and a trade war — together at last!



What happened is this: An early draft of Waxman‐​Markey already contained triggers that gave the president the choice to introduce carbon tariffs if jobs and industry “leak” overseas to countries that don’t constrain emissions so dramatically. (China and India come to mind.) The original version empowered the president to impose the carbon‐​linked tariffs beginning in 2025.



But though the language is not public yet, the House Ways and Means Committee is reportedly considering provisions that will give extra comfort to protectionists. Leaks from Hill offices indicate that the president would now be forced to impose the carbon tariffs — and could only opt out of doing so with permission from both chambers of Congress. Carbon‐​intensive imports would be subject to penalties at the border unless the country of origin requires emission reduction measures at least 80 percent as costly as ours. (The original Waxman‐​Markey bill had a threshold of 60 percent.) 



Unfortunately for the amendment’s authors, World Trade Organization rules make fairly clear that trade‐​limiting measures imposed to protect the environment should have the purpose of protecting the environment, and not to address any adverse competitiveness effects on domestic industry. Break that connection between measure and purpose, and you’ve got yourself a problem. The result could be litigation, retaliatory tariffs, or both. Does anyone really expect China to stand idly by in 2025 as their trade is embargoed?



And just for the sake of discussion, exactly how much global warming will be prevented by this assurance of future trade turmoil? Well, let’s use the federal government’s own model which — we are not making this up — is called MAGGIC (Model for the Assessment of Greenhouse‐​gas Induced Climate Change). It comes from the National Center for Atmospheric Research in Boulder, Colorado.



Let’s compare the effects of Waxman‐​Markey to the United Nations’ “business‐​as‐​usual” emissions scenario that’s in their big 2007 climate change compendium. If the U.S. only adopts Waxman‐​Markey, global warming would be reduced by a grand total of 0.2ºF by 2100. This is too small to even detect, because global temperatures bounce around by about this amount every year. For those who like to think more near‐​term, the amount of warming prevented by 2050 would be 0.07 of a degree.



According to the UN, without Waxman‐​Markey the warming from 1990 to 2050 would be 2.8ºF, and 5.3º by 2100. (Of course, observed warming since 1990 is running about 40 percent below the expected rate, largely because there hasn’t been any net warming since the very warm year of 1998.)



Now, let’s be completely unrealistic and assume that every nation that has “obligations” under the (failed) Kyoto Protocol cuts emissions as much as we do. Then the saved warming balloons all the way to 0.14ºF by 2050 and 0.4º by 2100, or 5 and 7 percent, respectively, of the “business‐​as‐​usual” total.



Let’s add it all up. We don’t do anything measurable to reduce global warming, we alienate some of our biggest trade partners, we risk a trade war, and Americans are allowed to emit the same carbon volumes as the average citizen did in 1867. What’s not to hate?



All of which explains why Waxman‐​Markey is being rushed to the floor. If people find out what is really in it, how risky it is and how small the purported benefits, it is hard to believe that it will pass.
"
"Fish are acutely aware of sea temperature; it’s one of the key reasons particular species of fish live where they do. As the oceans warm however, many tropical species are moving towards cooler climes. So might the traditional cod and chips one day be replaced by Nemo and chips?  It’s a big question, as the distribution of species across the Earth is one of the most fundamental patterns in ecology. All plants and animals are of course adapted to a limited set of climatic and environmental conditions; if the climate changes, we expect distributions to change. This matters not only because we like to eat many of the species in question, but also because entire ecosystems appear to depend on the number of interacting species present.  In general the tropics have more different species than the poles. This pattern, known as the latitudinal diversity gradient, holds true for plants and animals across the world both on land and in the sea. Compare a rainforest or a coral reef with icy tundra or the Arctic ocean.  As ever in the natural sciences, it’s much easier to describe a pattern than to explain its cause but we do know that temperature seems to have a important role, as solar radiation increases levels of primary production. Temperature impacts the food that species can eat and also their metabolic rates and activity levels.  In aquatic systems, temperature also strongly affects the amount of oxygen that can be dissolved in the water. Changes in temperature, therefore, are very likely to lead to changes in the distributions of marine species, and the current trend of warming temperatures is driving fish away from the tropics and towards the poles. We need to know what’s lurking round the ecological corner. Miranda Jones and William Cheung of the University of British Columbia have modelled the changes in marine species’ ranges – and by summing up, changes in overall biodiversity – expected under the IPCC’s different climate change scenarios. The research, published in the Journal of Marine Science, looks at the known distribution of around 800 marine fish and invertebrate species, matches their distributions with environmental conditions and then projects where these species are likely to be found under future environmental scenarios. Abandoning the tropics: The authors find that tropical seas, particularly the shallow highly diverse seas of South-East Asia are likely to suffer the most local extinctions, while polar – and particularly Arctic – seas are likely to see the greatest number of invasions. Consequently cold regions will generally see biodiversity increases, while tropical regions will suffer. In total, marine fish and invertebrates are expected to shift 26km per decade towards the poles under the IPCC’s worst case scenario (3°C warming by 2100). Even under the best-case scenario, fish will move 16km per decade. Similar predictions have been made before and the fishing industry has certainly seen this coming, with infrastructure already being put in place to exploit expected higher catches in Arctic regions. But what is new in this study is an approach combining several different models of species distributions. By looking at agreements between models, the authors identify likely regional hotspots of both extinction and invasion, marked with black diagonal lines in the maps above and below. Going polar However, while the idea of tropical fish invading chillier waters might sound fun, we’re unlikely to eat Nemo and chips in London any time soon. Temperature (or climate) is not the only limit to a species’ distribution; suitable habitat must also exist. Clown fish such as Nemo need to live in a coral reef and such reefs are complex ecological communities themselves with all sorts of environmental requirements.  At the moment ecological and climate models do not allow us to include interactions between species as additional factors that limit movements. This may significantly alter individual species’ ranges. Competition from well-established resident fish may discourage new arrivals, for instance, or some fish may rely on a different species specifically to feed their young – if the food for the juveniles does not move in the same way as for the adults, then the species range will not change. While it might be tough to predict exactly how fast things will change, or what it will lead to, the general message from this study is clear: change is coming to marine ecosystems. We can’t take the current distribution of marine life for granted."
"**Dozens of cases of Covid linked to an Aberdeenshire food plant are being investigated.**
NHS Grampian said that 78 detected cases had been associated with the Kepak McIntosh Donald plant in Portlethen.
An incident management team has now been set up to monitor the situation involving the premises.
The news came as 122 new Covid cases were reported in Grampian, up from 49 on Tuesday.
NHS Grampian said: ""Following a small number of confirmed cases associated with the plant - and after discussions with management there - we offered asymptomatic testing to all employees on Monday. More than 200 staff took up the offer.
""These results are now being processed and account for much of the increase in our case numbers in Grampian.
""They are not the only reason behind today's increase in case numbers - we continue to see other clusters of cases and the virus continues to circulate in the community.""
The statement added: ""There is no evidence at this time to suggest this cluster has spread beyond those working at the plant. Given the large number of people who were tested it is likely further cases could be confirmed."""
"

The U.S.-China trade relationship, one of the world’s largest, is a flashpoint for concern over the U.S. trade deficit, China’s currency valuation, and Chinese intellectual property regulation. This relationship is under especially keen scrutiny as the 2008 presidential campaign heats up in the United States, with Democratic front‐​runners favoring punitive duties against China if it does not act to revalue its currency. Robert E. Scott, senior international economist at the Economic Policy Institute, and Daniel J. Ikenson, associate director of the Cato Institute’s Center for Trade Policy Studies, debate whether the next U.S. president should get tougher with China on trade.



 _Weigh in on this debate hosted by the **Council on Foreign Relations** by emailing the editors at letters@​cfr.​org. To view other online debates click here._



April 4, 2008(Most Recent)



 **Daniel J. Ikenson**



Space constraints preclude my rebutting each ad hoc, amorphous assertion made in Rob’s last post, but I want to address some of the most outlandish. 



If the current trading system encourages a race to the bottom, how does one explain the large and increasing foreign direct investment flows into the United States? Why is ThyssenKrupp building a $3.7 billion green field steel production facility in Alabama? Why do foreign nameplate automakers continue to invest in U.S. manufacturing? Why do the 5.1 million Americans employed by U.S. subsidiaries of foreign‐​owned companies earn on average 32 percent higher wages than workers at U.S.-owned companies? 



Because there is no race to the bottom, that’s why. There is a race to the top‐​for skilled workers, for access to production facilities closer to markets, for investment in countries where the rule of law is clear and abided, where there is greater certainty to the business climate, where the specter of asset expropriation is negligible, where physical and administrative infrastructure is in good shape, and so on. Seems odd how the same sirens who decry the race to the bottom spend the rest of their day opposing foreign direct investment in the United States.



Are we to believe that America’s elites are behind Walmart’s success? Seems to me Walmart and other retailers have been a conduit of the benefits of trade, allowing ordinary Americans to tap into the division of labor, extend their budgets, and increase their families’ access to clothing, food, and other everyday products. And American manufacturers and their workers are the beneficiaries of huge increases in exports to China‐​our fastest growing large export market since 2001. Beyond question, vast swaths of Americans and Chinese are benefitting from the expanding trade relationship.



With respect to U.S.-China trade, the next president should continue the tradition of this administration, which is to engage in quiet dialogue where there are issues to resolve and to resort to the WTO dispute settlement system when the facts support doing so.



As he or she reflects on the bilateral trade dialogue of the recent past, the next president should recognize that it has been more a litany of U.S. gripes than a dialogue, and that the time has come to start considering carrots to accompany the sticks. The next president should grant China market economy treatment in antidumping cases. While such a reform would take very little out of petitioning industries’ hides, the gesture would win vast sums of goodwill from the Chinese, which will be needed to resolve more important issues going forward.



April 3, 2008



 ** **Robert E. Scott****





If four low‐​wage workers are riding an elevator, the door opens, and Bill Gates gets on, everyone on that elevator becomes, on average, a billionaire. The economic benefits of U.S.-China trade, like the average net worth on that elevator, look good until you consider their distribution.



The gains from trade between the United States and China have flowed to a very small segment of both countries’ elites. The gap between the value of what U.S. workers produce and what they receive has widened dramatically, partly because deregulated trade has suppressed the real wages of all non‐​college educated workers (about 70 percent of the labor force). Between 1980 and 2005, U.S. productivity rose 71 percent while real compensation (including benefits) of non‐​supervisory workers rose just 4 percent. This measure includes all the benefits of globalization received by these workers. Most of the benefits of growth since 1980 have been captured by the top 10 percent, especially the top 1 percent, of U.S. workers. The problem is not trade, _per se,_ but the current trading system which has encouraged a race‐​to‐​the bottom in wages and labor standards. 



The systematic suppression of workers’ rights has reduced Chinese wages by 47 percent to 85 percent according to a recent  labor‐​rights petition, and the problems are worsening. Occupational illness and injury rates have never been higher in Chinese manufacturing. Workers are frequently forced to go unpaid, and their complaints and protests are often met with violent government responses. 



Fueling China’s vast trade surplus with the United States is its very high savings rates, nearing 50 percent of GDP in recent years. Conventional wisdom is that Chinese workers save excessively because China’s pension and public health systems are so poor. However, household savings recently declined to 16 percent of GDP. Business savings, on the other hand have soared to nearly 24 percent of GDP and government savings exceeded 10 percent  according to the IMF.



Thus, globalization’s benefits in China are reaped by an elite cadre who own and operate private and public enterprises. Their savings are piling up in the net worth of the rapidly expanding business empires under their control.



Getting tough with China about international trade and labor rights violations would help workers in both countries. The Bush administration has rejected two labor rights petitions submitted by the AFL-CIO and U.S. Representatives Ben Cardin and Chris Smith, and workers in both countries have suffered as a result. 



China needs more spending on infrastructure, environmental clean‐​up, and public health and other social services. It needs fundamental improvements in labor rights and enforcement, which will raise wages, increase private consumption and reduce China’s need to export. These win‐​win policies can help workers in the United States, China and all our trading partners.



April 2, 2008



 **Daniel J. Ikenson**



The only substantive point of agreement between Rob and me about China is that it makes for a nice wedding gift.



To embrace Rob’s perspective, one must assume away the reality of how the economy actually works and how it is structured. If the U.S. economy comprised only producers who were self‐​sufficient for their material inputs and who had no interest in selling products abroad, Rob’s prescriptions, which subordinate the multitude of individual U.S. economic interests to manufacturers’ interests, might garner some sympathy. But it is fantasy to characterize international trade as a contest between “our” producers and “their” producers. Not only has that line been blurred (thankfully) by foreign direct investment, cross‐​ownership, equity tie‐​ins, and transnational supply chains, but the fact is that the economy is composed of consumers, retailers, importers, shippers, designers, engineers, marketers, financiers, and producers who have great stakes in an open world economy, and who would be hurt by Rob’s proposals.



The currency issue is far more complicated‐​and far less insidious‐​than Rob implies. Is a more‐​weakened dollar what America really needs as prices for essentials like oil and food continue to rise? Do we really want China to have 40 percent more spending power on account of Yuan appreciation when China’s growing demand with a lower‐​valued currency explains much of the world’s commodity price increases? Other countries are looking for ways to bolster their citizens’ purchasing power by suspending tariffs and other import restraints, yet Rob thinks it’s wise to reduce Americans’ purchasing power by rendering dollars worth less.



I strongly disagree with Rob’s assertion that the trade deficits are a major cause of the loss of 3.4 million jobs. Manufacturing jobs are in decline worldwide, even in perennial trade surplus countries like Japan and Germany, as well as in China.



It is worth noting that between 2001 (Rob’s demarcation) and 2007, the increasing bilateral trade deficit has been accompanied by a 20 percent increase in real GDP, a 15 percent increase in manufacturing output, and the creation of 9.1 million net new jobs.



With respect to trade remedies, let’s summon the violins! Out of 263 U.S. anti‐​dumping and countervailing duty orders, there are 62 (24 percent) in place against Chinese imports. And the extremely prosperous U.S. steel industry‐​the victim in Rob’s last post‐​accounts for 126 of the 263‐​nearly half!



Rob’s prescriptions are not only unnecessary; they are particularly ill‐​suited for the twenty‐​first century global economy.



April 1, 2008



 ** **Robert E. Scott****





I’m glad that Dan thinks we need to get tough with China. We have ignored these problems for far too long. China provides vast and extensive subsidies to businesses making goods for export in many industries, artificially reducing the cost of their products. The U.S. government needs to develop new policies and institutions to enforce our fair trade laws and to ensure that the system delivers broadly shared benefits to U.S. workers and businesses producing goods and services in the United States. 



A  recent study by Prof. Usha Haley at the University of New Haven estimated that energy subsidies to the Chinese steel industry alone exceeded $27 billion between 2000 and mid‐​2007. China went from being a net steel importer a few years ago to the world’s largest steel producer and exporter. China’s share of U.S. steel imports increased six‐​fold.



Energy subsidies are rampant in China, and yet the U.S. Commerce Department refused to authorize countervailing duties in recent trade complaints involving tires and coated paper imports, both energy intensive products. U.S. trade laws need to be toughened in this area to ensure that _systematic_ subsidies that benefit all exporters are countervailed.



Beginning in 2001 with their tenth five‐​year plan, China targeted the auto and parts industries for rapid growth, and they have poured subsidies into this industry. U.S. auto parts imports soared from $1 billion in 2001 to $7 billion in 2007, resulting in massive layoffs and plant closures. These cases illustrate two key weaknesses in the U.S. trade policy enforcement system. 



First, our system depends on manufacturing firms and agricultural producers to initiate the vast majority of all U.S. unfair trade complaints. The system makes it hard for them to win cases until they are on their last legs so many cases are never filed. The U.S. government has the right to initiate complaints, but rarely does. Second, only the USTR, which is part of the President’s Executive Office, has the right to file trade complaints with the WTO. It often fails to do so for political reasons. For example, the big‐​three U.S. auto companies benefit from subsidized Chinese auto parts imports, and the USTR has refused to bring a WTO complaint until 2006, five years too late.



Congress should create an independent government agency with the resources and authority to file fair trade cases in the United States and at the WTO. We must insist that Chinese producers compete on a level playing field, and if we do, U.S. workers and businesses can win.



March 31, 2008



 **Daniel. J. Ikenson**





If a tougher stance means using the WTO Dispute Settlement Body [DSB] more systematically to achieve greater Chinese compliance with the vast obligations to which China agreed upon joining the WTO in 2001, the answer is “yes.” If it means supporting or encouraging provocative legislation or taking unilateral administrative actions to compel or punish China in a manner that would violate our own WTO obligations or would benefit a few litigious industries at the expense of broader economic interests, the answer is “no.”



In 2006, the USTR (Office of the United States Trade Representative) published its “Top‐​to‐​Bottom Review” of U.S.-China trade relations, in which it proclaimed the beginning of a new phase in the relationship, stating, effectively, that the honeymoon period (of reform implementation) was over and foreshadowing greater resort to the WTO dispute settlement system to achieve further compliance.



One month after publication of that report, USTR filed a WTO complaint alleging that certain Chinese policies discriminate against imported automobile parts. Very recently, the dispute panel established to hear that case ruled in favor of the United States.



Before the auto parts case, only one complaint about Chinese practices had been lodged with the DSB. It concerned a value‐​added tax on integrated circuits that was allegedly applied in full to imports only. During the consultation phase of the dispute (and without need of formal adjudication), the Chinese agreed to change their practice and the dispute was resolved.



In 2007, the USTR filed three WTO cases against China. The first involved certain tax provisions that allegedly amounted to subsidization of Chinese exporters. In response to the allegations, China changed its tax rebate practices (although the dispute is not completely resolved yet). The second concerned enforcement of intellectual property rights. The third concerned alleged barriers facing foreign traders and distributors of copyrighted materials like books, videos, and DVDs. A dispute panel was recently composed for the IP case, and the distribution barriers case is still in the consultations phase. Earlier this month, USTR brought a sixth case, alleging discrimination against U.S. providers of financial services information in China. 



Since the USTR’s 2006 review, five cases have been filed with positive outcomes achieved in two (the others are pending). It is important to recognize that our trade relationship with China is mutually beneficial, and that unnecessary provocation could open a Pandora’s Box of economic problems. There is no good reason to jettison a process that is working.



March 31, 2008



 ** **Robert E. Scott****



China is a protectionist state that has used all of its powers and resources to build an artificially competitive export powerhouse. The United States is the most important market for its exports. Growing U.S. trade deficits with China and other countries are a major cause of the loss of 3.4 million U.S. manufacturing jobs since 2001, when China entered the WTO. China’s export‐​led growth strategy is also very costly for its people.



We have been down this road before, and know how to deal with such situations. Two decades ago, Japan built an export powerhouse behind an artificially cheap currency and protected home markets. This continued until 1985, when it began to threaten the stability of the world financial system. The problem then, as now, was the U.S. trade deficit.



The Reagan administration, much like the current White House, doggedly ignored the over‐​valued dollar through its first term while millions of jobs disappeared and thousands of factories closed. Finally, Congress acted and passed a measure (HR 3035) which hit countries like Japan, Brazil, and Korea, that maintained large U.S. trade surpluses, with a 25 percent tariff.



In a complete about‐​face, Treasury Secretary James Baker then negotiated the Plaza Accord with the G-5 (Japan, Germany, France and the U.K.), on September 22, 1985. The next day, the Federal Reserve and Central banks in Japan and Europe executed coordinated currency interventions that began to drive the dollar down. The dollar continued to fall until the Louvre Accord 16 months later, which stabilized its level again. The dollar fell 29 percent to 46 percent against the G-5 currencies in this period.



The U.S. never imposed a tariff in the Plaza era‐​HR 3035 never even became law. The mere threat, combined with concerns about a potential financial crisis, were enough to get the deal done. 



China has invested over $1.5 trillion in foreign exchange reserves in order to keep the yuan artificially cheap. Economists estimate than its currency, too, needs to rise by about 40 percent. Other Asian export economies, such as Japan, are following similar strategies and also need to revalue, but they can’t do it alone. While the dollar has fallen sharply against the euro and other freely traded currencies over the past five years, it has barely budged against the yuan and yen. But this won’t happen until we get tough with Beijing. We need to put some backbone in our trade policy to get multilateral currency talks started now.
"
"

Does global warming threaten to permanently cripple the global economy? According to a new report from the British Treasury prepared by economist Nicholas Stern, that’s exactly what will happen unless we cut greenhouse gas emissions to 25 percent below current levels by 2050. Should we do it? A close reading of the report reveals that the answer is “not necessarily.” 



Not to be flip about it, but why should the relatively poor (us) sacrifice for the relatively rich (our children and grandchildren)? The Stern Report argues that the emissions cuts necessary to stave off disaster will likely cost about 1 percent of global GDP every single year, or about $1,154 in current dollars per household in the United States. A small price to pay, we’re told, when GDP losses will likely total 5–10 percent of global GDP every year if we do absolutely nothing. 



But even with a 10% reduction in GDP relative to what it would have been, 100 years from now, people will still be extraordinarily well off by current standards. For example, since 1950 real U.S. GDP per capita has increased by about 2% a year. Given that growth rate, real GDP per capita one hundred years hence would be $321,684, or more than 7 times higher than it is at present ($44,403). If global warming cuts GDP by 10% a year beginning about 50 years from now, then GDP per capita will be $289,515 in 2106 rather than $321,684. 



Would anyone, let alone liberals, ever propose a 1% tax on those who make $44,000 to create benefits for those who make $289,000? In short, paying now to head off warming is a regressive intergenerational tax that takes from the poor and gives to the rich. 



The direct costs associated with greenhouse gas emission controls include avoidable deaths in the developing world. The United Nations, for example, reports that about 2 million people on this planet die every year because they don’t have electricity and must burn biomass for heating and cooking. This results in greatly elevated levels of indoor air pollutants and premature deaths. Increasing the cost of electricity – an unavoidable consequence of ridding the global economy of the fossil fuels that generate greenhouse gases – will slow our ability to conquer this problem. 



Higher fossil fuel costs will also slow the general march out of poverty. Not only is poverty the number one killer on the planet, it is also the number one cause of environmental ruin. Deforestation, habitat loss, and air and water pollution are all strongly correlated with per capita income. 



Nor are citizens in the industrialized West immune from the health effects associated with reduced income. Academics have established that every $15 million reduction of aggregate income causes one statistical death. That stands to reason; the poorer we are, the less likely we are (on average) to eat well, exercise, procure necessary health care services, and avoid unhealthy lifestyles. This effect alone suggests that in the U.S., greenhouse gas abatement, on the scale suggested by the Stern report, would cost more than 8,800 lives per year. 



Of course, the Stern Report argues that the GDP losses associated with doing nothing dwarf the GDP losses associated with effective emissions controls. In a world with no doubts, spending 1% of U.S. GDP to eliminate a loss of 10% of U.S. GDP every year beginning 50 years from now passes a cost‐​benefit test if we assume that GDP grows 2% per year, we discount future costs and benefits by 5% a year, and run our analysis out for 1,000 years. That calculation reveals that the present value of the costs would total $15,541 while the present value of the benefits would total $36,477. If the future stream of benefits were only 5% of future GDP, however, then it’s about a wash; $15,541 would get us only $18,239 in benefits. 



But climate predictions are not certain. The Stern report argues that there’s at least a 50–50 chance that temperatures will rise 5 degrees Celsius over pre‐​industrial levels if we do nothing. You won’t find that argument in the latest report of the International Panel on Climate Change (IPCC), however, which offers a wide band of possible warming scenarios. The Stern Report’s estimate is within the upper boundary of what’s possible, but median warming projections are around 2–3 degrees Celsius. 



It’s worth noting that when economists have crunched those median warming projections in the academic literature, they have found that the costs associated with climate change are 0 – 2% of GDP rather than the 5 – 10% asserted in the Stern report. If the benefits are only 2% of future U.S. GDP, then $15,541 in costs in present value terms produces only $7,295 in benefits. 



Finally, none of the above calculations consider the possibility that the costs will buy no benefits at all. The latest IPCC report, for instance, notes that the warming we’ve detected thus far is “unlikely (bordering on very unlikely) to be entirely the result of internal variability,” and that “natural forcing alone [i.e., solar and/​or volcanic activity] is unlikely to explain the increased rate of global warming since the middle of the 20th century.” 



No matter how you read that, it’s clear that there is greater than zero chance that greenhouse gas emission cuts will produce no economic gains at all. Accordingly, all the benefit estimates above must be discounted to some degree (how much is in dispute) to reflect that possibility. 



Think of the Stern Report as an elaborate economic pitch for an expensive insurance policy. Well, we’re not buying … yet.
"
"
There’s been a lot of worry and speculation over what will happen if a hurricane and the gulf oil spill collide. In response, the National Hurricane Center (NHC) has prepared a document answering some of the questions. There’s of course, a lot of uncertainty too.
Hurricane Katrina Aug28, 2005


What will happen to a hurricane that runs through this oil slick?
• Most hurricanes span an enormous area of the ocean (200-300 miles) — far wider than the current size of the spill.
• If the slick remains small in comparison to a typical hurricane’s general environment and size, the anticipated impact on the hurricane would be minimal.
• The oil is not expected to appreciably affect either the intensity or the track of a fully developed tropical storm or hurricane.
• The oil slick would have little effect on the storm surge or near-shore wave heights.
What will the hurricane do to the oil slick in the Gulf?
• The high winds and seas will mix and “weather” the oil which can help accelerate the biodegradation process.
• The high winds may distribute oil over a wider area, but it is difficult to model exactly where the oil may be transported.
• Movement of oil would depend greatly on the track of the hurricane.
• Storms’ surges may carry oil into the coastline and inland as far as the surge reaches. Debris resulting from the hurricane may be contaminated by oil from the Deepwater Horizon incident, but also from other oil releases that may occur during the storm.
• A hurricane’s winds rotate counter-clockwise.
Thus, in VERY GENERAL TERMS:

A hurricane passing to the west of the oil slick could drive oil to the coast.
A hurricane passing to the east of the slick could drive the oil away from the coast.
However, the details of the evolution of the storm, the track, the wind speed, the size, the forward motion and the intensity are all unknowns at this point and may alter this general statement.

Will the oil slick help or hurt a storm from developing in the Gulf?
• Evaporation from the sea surface fuels tropical storms and hurricanes. Over relatively calm water (such as for a developing tropical depression or disturbance), in theory, an oil slick could suppress evaporation if the layer is thick enough, by not allowing contact of the water to the air.
• With less evaporation one might assume there would be less moisture available to fuel the hurricane and thus reduce its strength.
• However, except for immediately near the source, the slick is very patchy. At moderate wind speeds, such as those found in approaching tropical storms and hurricanes, a thin layer of oil such as is the case with the current slick (except in very limited areas near the well) would likely break into pools on the surface or mix as drops in the upper layers of the ocean. (The heaviest surface slicks, however, could re-coalesce at the surface after\ the storm passes.)
• This would allow much of the water to remain in touch with the overlying air and greatly reduce any effect the oil may have on evaporation.
• Therefore, the oil slick is not likely to have a significant impact on the hurricane.
Will the hurricane pull up the oil that is below the surface of the Gulf?
• All of the sampling to date shows that except near the leaking well, the subsurface dispersed oil is in parts per million levels or less. The hurricane will mix the waters of the Gulf and disperse the oil even further. Have we had experience in the past with hurricanes and oil spills?
• Yes, but our experience has been primarily with oil spills that occurred because of the storm, not from an existing oil slick and an ongoing release of oil from the seafloor.
• The experience from hurricanes Katrina and Rita (2005) was that oil released during the storms became very widely dispersed.
• Dozens of significant spills and hundreds of smaller spills occurred from offshore facilities, shoreside facilities, vessel sinkings, etc.
Will there be oil in the rain related to a hurricane?
• No. Hurricanes draw water vapor from a large area, much larger than the area covered by oil, and rain is produced in clouds circulating the hurricane.
Learn more about NOAA’s response to the BP oil spill at http://response.restoration.noaa.gov/
deepwaterhorizon.
Document available in PDF form here.
Will the oil slick help or hurt a storm from
developing in the Gulf?
• Evaporation from the sea surface fuels tropical
storms and hurricanes. Over relatively calm water
(such as for a developing tropical depression or
disturbance), in theory, an oil slick could suppress
evaporation if the layer is thick enough, by not
allowing contact of the water to the air.
• With less evaporation one might assume there
would be less moisture available to fuel the
hurricane and thus reduce its strength.
• However, except for immediately near the source,
the slick is very patchy. At moderate wind speeds,
such as those found in approaching tropical
storms and hurricanes, a thin layer of oil such as
is the case with the current slick (except in very
limited areas near the well) would likely break into
pools on the surface or mix as drops in the upper
layers of the ocean. (The heaviest surface slicks,
however, could re-coalesce at the surface after the
storm passes.)
• This would allow much of the water to remain in
touch with the overlying air and greatly reduce
any effect the oil may have on evaporation.
• Therefore, the oil slick is not likely to have a
significant impact on the hurricane.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b5bf2a5',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Almost all parts of England will face tough coronavirus curbs with a ban on households mixing indoors and restrictions on hospitality after December 2.
The full list of tiers and areas published by the government is online - but the site is experiencing difficulties. If you can't access it, they are:
**South East**
Isle of Wight
**South West**
Cornwall
Isles of Scilly
**North West**
Cumbria
Liverpool City Region
Warrington and Cheshire
**Yorkshire**
York
North Yorkshire
**West Midlands**
Worcestershire
Herefordshire
Shropshire and Telford & Wrekin
**East Midlands**
Rutland
Northamptonshire
**East of England**
Suffolk
Hertfordshire
Cambridgeshire, including Peterborough
Norfolk
Essex, Thurrock and Southend on Sea
Bedfordshire and Milton Keynes
**London**
All 32 boroughs plus the City of London
**South East**
East Sussex
West Sussex
Brighton and Hove
Surrey
Reading
Wokingham
Bracknell Forest
Windsor and Maidenhead
West Berkshire
Hampshire (except the Isle of Wight), Portsmouth and Southampton
Buckinghamshire
Oxfordshire
**South West**
South Somerset, Somerset West and Taunton, Mendip and Sedgemoor
Bath and North East Somerset
Dorset
Bournemouth
Christchurch
Poole
Gloucestershire
Wiltshire and Swindon
Devon
**North East**
Tees Valley Combined Authority:
Hartlepool
Middlesbrough
Stockton-on-Tees
Redcar and Cleveland
Darlington
North East Combined Authority:
Sunderland
South Tyneside
Gateshead
Newcastle upon Tyne
North Tyneside
County Durham
Northumberland
**North West**
Greater Manchester
Lancashire
Blackpool
Blackburn with Darwen
**Yorkshire and The Humber**
The Humber
West Yorkshire
South Yorkshire
**West Midlands**
Birmingham and Black Country
Staffordshire and Stoke-on-Trent
Warwickshire, Coventry and Solihull
**East Midlands**
Derby and Derbyshire
Nottingham and Nottinghamshire
Leicester and Leicestershire
Lincolnshire
**South East**
Slough (remainder of Berkshire is tier 2: High alert)
Kent and Medway
**South West**
Bristol
South Gloucestershire
North Somerset"
"**All of Essex will be in tier two when England's second lockdown ends on 2 December, it has been announced.**
People in this tier cannot socialise with other households indoors.
The rule of six will apply to gatherings outdoors and pubs and restaurants will shut at 23:00 GMT and only be allowed to serve alcohol as part of meal.
Before the second lockdown, most of the county was in tier two but Thurrock and Southend-on-Sea were in tier one.
Spectators will be allowed to sporting and live events, but numbers will be more limited than those allowed in tier one areas.
Conserrvative county councillor John Spence, cabinet member for health and adult social care, said: ""We understand that going back into tier two will be hard for many, but we must all work together, follow the restrictions in order to save further lives and continue to protect our NHS.""
He said there was now ""a clear incentive"" to bring case rates down so the county could be placed in tier one when the decision was reviewed on 16 December.
Mr Spence said the tier two restrictions before the second lockdown ""had a positive impact"" on the rates of Covid-19.
Conservative MP for Harwich and North Essex, Bernard Jenkin, said: ""Obviously I'm as disappointed as anybody could be that we're not in a fit enough state to go into tier one.""
His colleague, MP for Southend West, David Amess, said he was ""very disappointed... because I did lobby for tier one"".
""I'm just hoping they will have another look at it.""
The government said the rationale for putting Essex into tier two was that cases in the county were at 159 per 100,000 people but the rate in over-60s was 100 cases per 100,000 and falling.
Mark Cory, leader of Colchester Borough Council, said the town had been ""lumped together"" with parts of the county which have higher rates of cases.
The Liberal Democrat said: ""We wouldn't be in this mess with death rates as high as the first peak if government had got test and trace working.""
Labour leader of Southend Borough Council, Ian Gilbert, said he was ""not surprised"" Essex was placed in tier two.
He said: ""Clearly the government's come to a decision that tougher restrictions are still needed in almost of the country.""
The case rate of Covid-19 in Basildon was above the England-wide average in the week to 21 November and has risen week-on-week.
Neighbouring Brentwood, where the rate has fallen, is also above the England average, as is Thurrock where the rate has risen.
Epping Forest is also above the England average and the rate there has stayed the same week-on-week.
Tier two rules mean football clubs can have up to 2,000 spectators at matches.
Colchester United owner and chairman Robbie Cowling said bringing back supporters ""must be safe and as I have said that will mean taking a cautious first step"".
He said the club would have up to 1,000 fans at its home game against Grimsby on 5 December.
Matches at elite level in England has been played behind closed doors since the return of football after the first lockdown.
Southend United, in League Two alongside Colchester, said it was delighted ""with the prospect of 2,000 fans returning"".
It said it would be working ""to ensure the safe return of supporters to the stadium as soon as possible"".
_Find BBC News: East of England on_Facebook _,_Instagram _and_Twitter _. If you have a story suggestion email_ eastofenglandnews@bbc.co.uk"
"
Share this...FacebookTwitterWhat is it going to take? They deny their own data and insist fantasy is correct.
The MAIL Online writes today has an excellent report, and starts with:
The supposed ‘consensus’ on man-made global  warming is facing an inconvenient challenge after the release of new temperature data showing the planet has not warmed for the past 15 years…based on readings from more than 30,000 measuring stations.”
Yet the MetOffice, the supplier of that data, says (the MAIL writes):
“…because the impact of the sun on climate is far less than man-made carbon dioxide. Although the sun’s output is likely to decrease until 2100, ‘This would only cause a reduction in global temperatures of 0.08C.’ Peter Stott, one of the authors, said: ‘Our findings suggest  a reduction of solar activity to levels not seen in hundreds of years would be insufficient to offset the dominant  influence of greenhouse gases.”
Is Stott sane, or what! What little reduction we’ve had in solar activity in just the last 4 years has already offset the GHG effect – no warming in 15 years! The MAIL writes:
In 2007, the Met Office claimed that global warming was about  to ‘come roaring back’. It said that between 2004 and 2014 there would be an  overall increase of 0.3C. In 2009, it predicted that at least three of the years 2009 to 2014 would break the previous temperature record set in 1998.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Wrong on every count. And so what is their reaction? Here’s what the MAIL tells us:
But yesterday a Met Office spokesman insisted its models were still valid.
This is more than stupid – it’s hopelessly stupid. Even though the models don’t work, they insist they’re still valid. This is like saying the well is poisoned, but the water is still safe to drink!
The MAIL interviewed Nicola Scarfetta, who says that eventually they are going to have to admit they are wrong. Judith Curry was more direct, saying: “…the models may have severe shortcomings…’ and that “many scientists’not surprised'”.
Readers, if you like this Mail article, then you are going to like Sebastian Lüning’s and Fritz Vahrenholt’s book: Die kalte Sonne (The Cold Sun). The lay it all out. Only morons and blind ideologues will go on continuing to believe the CO2 bullshit.
Read more: http://www.dailymail.co.uk/sciencetech/article-2093264/Forget-global-warming–Cycle-25-need-worry-NASA-scientists-right-Thames-freezing-again.html#ixzz1ks3bcDhU
 
 
Share this...FacebookTwitter "
"
I missed doing a Sea Ice News last week due to being a bit discombobulated with family health issues which have now thankfully been resolved, so I’ll pick up here with a new report.
The news this week is that Arctic sea ice formation has slowed:
click for a larger image
As you can see above, after making a very fast recovery during most of October, it is now pacing the 2007 rate. This isn’t terribly unusual, as you can see a “choke point” beginning in early November where the rates of formation start to converge. Right now the JAXA daily data report is passing the 8 million square kilometer mark a value of:
10,31,2010,8038906
Earlier this week, there was some concern that there may be a sensor issue of some sort, particularly when comparing and I asked NSIDC’s Dr. Walt Meier about it, see:
NSIDC -vs- Cryosphere Today – a visual discrepancy
Compare this NSIDC Arctic Sea Ice extent chart…

…with this from Cryosphere Today:

It certainly appears that there is more ice in 2010 than 2007 on the Cryosphere Today page. Dr. Meier seems to think that the 2007 map from CT is missing some ice, as NSIDC’s comparison between the dates doesn’t appear off as much as the CT images. Walt’s point is:
There is more ice in the central Arctic this year, but less in the Beaufort Sea, Canadian Archipelago, and Baffin Bay. These areas roughly balance each other out.
Reader Lee Kington provides this blink comparator version of NSIDC’s images:

In other news, Antarctic ice continues to be significantly above normal:
Antarctic Graphs: 
For more maps and graphs, see the WUWT Sea Ice Page


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e876652a3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterWhat if scientists one day concluded that climate was influenced mostly by natural factors and that man had little impact? What would be the result? For one, lots of people would find themselves in the unemployment line. And for many, their companies and operations would have to close shop. Hat-tip: Reader DirkH.
One person who likely would be negatively impacted is Katherine Hayhoe, who is not only an atmospheric scientist with expertise in climate modelling, regional climate impacts and science-policy interface at Texas Tech, but also happens to be CEO of ATMOS Research and Consulting, a Lubbock-based company “providing detailed reports, maps, and other graphics that vividly illustrate changes that have already been observed, as well as highlighting the possible future impacts of climate change over the coming century“.
The bold print in layman terms: climate fortune-telling services.
Climate consulting is surely a business that derives much benefit from the notion that climate change is now happening rapidly and that a catastrophe is imminent. A lot folks want to know what to do in order to prepare, and Katherine takes big money for telling them.  I really don’t see how it is possible for people like Ms Hayhoe to avoid conflicts of interest here. Is it possible to remain objective in a science when you run a business whose very success depends on the output of that science? God knows that consulting fees are exorbitant. Tempting to say the least.
Should we be surprised that Hayhoe, as the CEO and top beneficiary of the climate consulting company, is a big proponent of climate catastrophe scenarios? Seems it would certainly help the ATMOS bottom line.
And how much of the services rendered by ATMOS are actually sourced from the tax-payer funded university where Hayhoe is a professor? As a professor at a state university, is she using research money and all the number-crunching facilities there to supply reports that ATMOS Consulting in turn sells at a high price to clients (after a little cut and paste editing)?  I’d like to know what part of them high-priced consulting reports were actually generated by ATMOS resources alone, and what part was actually generated by her employer Texas Tech (taxpayer). Would Hayhoe confirm it’s 100%/0%?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




ATMOS is an ideal set-up as a real money-making machine: scare the bejesus out of clients on one side, and sell them lucrative consulting services on the other. Though legal, there seems to be some ethical issues here.
And who are her clients? What proportion are private and what proportion are taxpayer funded government agencies, who just happen to love scary reports that sway public opinion? It all seems dubious to me and the potential for conflicts of interest is simply too high.
Crystal ball services: possible 100-year scenarios
The ATMOS website does not provide any information about the quality of its products, especially its climate forecast-related scenarios. Do they come with a guarantee? We get the sense that they don’t and that it’s mostly speculation dressed up to look scientific. Indeed if there is no guarantee, then it would be safe to say that ATMOS is actually selling high-priced crystal ball fortune-telling services. The ATMOS website writes that they “provide possible impacts of climate change over the coming century.”
Read the fine print – no money back!
 
 
Share this...FacebookTwitter "
"If money seems scarce, Clydesdale Bank notes are about to become much more so. The brand's owner, Virgin Money, is retreating from its contracts to supply cash machines run by rival lenders.
No longer will you get a crisp Clydesdale polymer note when drawing cash out of Santander, TSB, Co-op or Asda machines. The contract to supply them is being taken over by the other issuers of notes, Royal Bank of Scotland and Bank of Scotland.
You might think this reflects the fast-declining use of cash. And that may be part of the story.
We're learning today of new Bristol University research for the Financial Conduct Authority showing a 19% reduction, or more than 10,000, in free-to-use cash machines in the two years to last March, while there was a 15% decline in the number of withdrawals.
The move to infection-free contactless card payments during the Covid crisis has accelerated the reduced use of readies.
But this has more to do with the even faster-declining use of the Clydesdale Bank brand, 182 years after its founding in Glasgow.
By the end of February, it will have disappeared from the fascia of all its branches, replaced by Virgin Money.
That bank, based in Edinburgh, was taken over by Clydesdale, or to be more accurate, its parent company listed on the stock market as CYBG. The 'Y' stands for its other legacy brand, Yorkshire Bank.
In a reverse brand takeover, licensed from Sir Richard Branson's Virgin Group, CYBG last year renamed itself Virgin Money. Its plan is to use that to expand beyond Scotland and its Yorkshire turf as the leading challenger to the UK's dominant big five retail and business lenders.
This leaves a banknote anomaly - entirely appropriate, given that Scottish banknotes are themselves anomalous.
Clydesdale Bank, no longer a trading brand, will continue to appear on the notes you get out of Virgin Money cash machines, but not any others.
The idea of issuing a Virgin Money banknote must have appealed to Sir Richard Branson, particularly if his cheerful physog appeared on it with an airliner or balloon. But that's not happening.
Virgin Money is not saying how much cash it's retiring as notes are returned, but it will be a big reduction from the Â£2.3bn which I'm told is now in circulation - around 47% of the Scottish banknote total.
You wouldn't bet on it continuing indefinitely, because it's an odd and expensive advertising and marketing tool to support a brand being consigned to history.
That, after all, is what Scottish banknotes are - something with which to irritate London cabbies, and advertising for their issuers.
It wasn't always thus. Banknotes were an innovation in the early days of Scottish banking, when late 17th Century famine meant gold currency had to be spent on importing food. With gold therefore in very short supply, the banknote represented a promise to refund the holder who presented it with precious metal coinage.
As notes were issued in greater number than the gold and silver that backed them in the vaults, banks innovated in expanding credit. But they had to do so carefully. In the 18th Century, they were at risk of rival banks presenting them with a lot of notes at once, an unscrupulous tactic which sank some issuers.
The modern-day equivalent would be a run on a bank, when savers panic and demand to get their money out, far in excess of the funds available on the day. Remember the queues outside Northern Rock in 2007 - one of the first indications in Britain of the underlying pressures that led to the financial crash the following year?
The Scottish history of this is detailed in the recent magnificent history of Edinburgh (and Scottish) finance, City of Money, penned by Ray Perman.
He relates the dirty tricks visited by the Bank of Scotland, the 'Old Bank' on the Royal Bank of Scotland, 'the New Bank'.
But when two Glasgow rivals were founded, known as the Ship and the Arms banks reflecting the heraldry they used, the established Edinburgh rivals joined forces to see off the Weegie threat. It's a story worth repeating.
Their threats and dirty tricks included successfully blocking the use of Glasgow notes to pay Customs and Excise. But Glasgow's tobacco merchants were loyal to their own.
In 1757, the Edinburgh banks were approached by one Archibald Trotter, a former trade financier, with a plan to undermine the Glasgow challengers.
On a salary of Â£150 and supplied with Â£5,000 in credit, Mr Trotter set up on Clydeside as a dealer in bills of exchange, intending to put the Glasgow banks under pressure with his demands for collateral coinage. The Glasgow bankers, writes Perman, quickly realised what he was up to, and the Arms Bank decided to have fun at his expense.
""They limited the hours when they were prepared to redeem notes, and paid him only in sixpences. There were 40 sixpences to the pound and Trotter was presenting Â£100 or more at a time, giving ample scope for error and delay.
""The bank teller would laboriously count out the tiny silver coins, occasionally losing count and having to begin again, or dropping one on the ground, providing another excuse for restarting the process anew, or finding one which might have been tampered with and having to go off to get a second opinion as to whether it was valid or not. If they ran out of time, the process had to be restarted the following day.""
Banking hours were short, notes Perman, because counting coins by candlelight in winter was a risky business.
Mr Trotter's venture didn't last long. But from my experience, anyone who has spent any time more recently in an Indian bank branch probably knows how he felt."
"

Indonesia is a land in turmoil, home to massive volcanoes, tsunamis, and earthquakes. On Monday, January 14, it experienced a brand new type of disturbance, the world’s first food riot caused by another nation pandering to the global warming mob. Indonesians took to the streets, demanding that their government to do something about the price of soybeans, a dietary staple.



All over the world, food prices are on the rise. For most of the late 1990s and up until 2005, the price of beans on the Chicago Board of Trade had remained stable at about $5 a bushel. Since then, they have shot up over 150 percent, to around $13. Corn has doubled, to $5. Wheat prices have tripled.



It all started with the 2005 Energy Policy Act, passed by a Republican congress and signed by a Republican president, mandating that an increasing amount of ethanol be admixed with gasoline. The bill was sold as a road to “energy independence” and as lowering the amount of carbon dioxide we emit, reducing dreaded global warming.



By now, 15 percent of our corn crop is being distilled, diverted from the proper purpose for such distillates (i.e. drinking), combusted, and sent out your car’s tailpipe.



The Act required production of four billion gallons of ethanol in 2006, increasing by approximately 700 million gallons each succeeding year. Enter those familiar characters supply, demand, and price. Supply tightens, prices escalate, and more and more farmers divert cropland from other crops (mainly soybeans and wheat) to corn. In the U.S., most crops are turned into animal feed, but in poorer countries, such as Indonesia (soybeans) or Mexico (corn for tortillas) they are consumed directly.



The ethanol malaise has also hit here at home, as a trip to the grocery store will reveal that the price of just about everything containing corn, wheat, or soybean products, or parts of animals fed on those crops, is skyrocketing. It’s hard to find a decent steak for under $12 a pound these days.



It’s only going to get worse. As if to add more 200‐​proof to the fire, President Bush, citing global warming in his 2007 State of the Union speech, called for production of 35 billion gallons of ethanol by 2017, displacing 20 percent of our current gasoline consumption with this intoxicating elixir. This is _five times_ the amount mandated in the 2005 Energy Act. He claimed that this would help us get off Middle Eastern oil.



I’ll leave the hocus about energy independence to my fellow energy wonks, because the pocus about global warming is an even easier kill.



Let’s stipulate that, indeed, 20 percent of our current gasoline consumption is somehow replaced. Transportation accounts for roughly one‐​third of our national emissions of carbon dioxide, so this would reduce our total emissions by 6.7 percent. That’s today’s emissions. Based upon recent data, the number of cars on the road will rise by this percent in about four years.





It’s hard to find a decent steak for under $12 a pound these days.



What does that do about global warming? It prevents .02º F worth of warming in the next century, based upon a formula published by the National Atmospheric Research Center in 1998. You experience this ambient temperature change every second of your life.



Now, suppose this policy were extended to all the nations of the world in which there are appreciable numbers of cars (called “Annex 1” countries by the United Nations), and the amount of warming that doesn’t occur is .05º F. No one will ever be able to detect these temperature changes in global records, which vary naturally by about .15º from year to year.



Displacing 20 percent of gasoline consumption is probably impossible. The U.S. produces more than half the world’s corn, and if we turned every kernel of it into ethanol, we’d still be 40 percent short of the President’s target.



To get there, we would have to find an economic way to make ethanol from cruder plant materials — so‐​called “cellulosic” ethanol. No matter how much money governments throw at this (including a lot from the 2005 energy bill), no one has figured out how to do this economically, and people have been at it for decades.



Of course, we won’t completely burn up our corn. We’ll incrementally ratchet it up until the inflation in food prices becomes politically untenable. Don’t be surprised, one day, if there’s a March for Food down Constitution Mall.



In other countries, there will be more riots, perhaps a coup or two, some pretty hungry people, maybe some genocide. And everywhere not a dram of a change in climate owing to ethanol will ever be measured.



The sad fact is that Indonesia’s unrest is only the slightest foreshock preceding the massive civil earthquake that is going to be unleashed as more and more absurd policies are mandated by the global warming mob.
"
"**People have been urged to be cautious of the risk of spreading coronavirus when rules are relaxed over Christmas.**
Up to three households will be allowed to stay together and form a ""Christmas bubble"" from 23 to 27 December, as agreed by all four UK nations.
A scientific adviser to the government said the relaxation of rules amounted to ""throwing fuel on the Covid fire"".
Meanwhile, it is expected most areas of England will be placed in the middle tier of a toughened three-tier system.
Details on what will happen when the current lockdown ends on 2 December will be announced on Thursday. The decision will be based on a number of factors including case numbers, the reproduction rate - or R number - and pressure on local NHS services.
BBC political editor Laura Kuenssberg says a ""handful"" of areas will be in the lightest regime of limits - tier one - but most of the country is likely to be in either tier two or three.
She said London is expected to be placed in tier two.
The measures for Christmas will see travel restrictions across the four nations, and between tiers and levels, lifted to allow people to visit families in other parts of the UK.
Anyone travelling to or from Northern Ireland may travel on the 22 and 28 December, but otherwise travel to and from bubbles should be done between the 23 and 27.
People will not be able to get together with others from more than two other households, and once a bubble is formed, it must not be changed or be extended further.
The guidance says a bubble of three households would be able to stay overnight at each other's home but would not be able to visit hospitality, theatres or retail settings.
Prime Minister Boris Johnson has told people to use ""personal judgement"" on whether to visit elderly relatives.
In a video message from Downing Street, the prime minister described the agreement as a ""special, time-limited dispensation"", saying: ""This year means Christmas will be different.""
Mr Johnson said people must consider the risks of who to form a bubble with and whether or not to visit elderly or vulnerable relatives, adding: ""Many of us are longing to spend time with family and friends... And yet we can't afford to throw caution to the wind.""
He added: ""'Tis the season to be jolly but 'tis also the season to be jolly careful.""
The prime minister has also reassured children that Father Christmas ""will be packing his sleigh and delivering presents this Christmas"".
In response to a letter from eight-year-old Monti, Mr Johnson said Father Christmas would not be a risk to children's health but that ""leaving hand sanitiser by the cookies is an excellent idea"".
It comes as the government recorded another 18,213 Covid cases in the UK. Figures also showed a further 696 people had died within 28 days of a positive test.
The number of deaths is the highest since the start of May and compares to 608 recorded on Wednesday.
BBC health editor Hugh Pym says many of those who have died are likely to have picked up an infection before the current lockdown measures were put in place. He said a rise in the death toll would not be expected to continue into December because the average number of daily cases is now falling and hospital admissions are levelling off.
A mid-week rise can also be down to delays in deaths being reported over the weekend.
First Minister of Wales Mark Drakeford said the ministers agreed they had to ease the rules because people would have flouted restrictions - creating further risk - if they were told Christmas had been ""cancelled"".
Ministers were shown behavioural science evidence that ""too many people simply would not have been prepared to have gone along with such an instruction"", he told BBC Breakfast on Wednesday.
Mr Drakeford also said a UK-wide approach to coronavirus rules after Christmas was needed.
Nicola Sturgeon has said guidance for people in Scotland is still being finalised and will be issued on Thursday, but that her government will not be ""encouraging"" people to meet up.
""The expectation should be that the guidance will probably look to tighten around the edges rather than further expand and that will be true with the travel window of opportunity as well - we want to limit that window, not expand it,"" the first minister said.
Published guidance for England gives further details of the rules for 23 to 27 December:
Prof Andrew Hayward, director of the UCL Institute of Epidemiology and Health Care, and a member of the government's Sage committee, told BBC Newsnight allowing families to meet up over Christmas amounted to ""throwing fuel on the Covid fire"".
He said it would ""definitely lead to increase[d] transmission and likely lead to third wave of infections with hospitals being overrun, and more unnecessary deaths.""
Prof Hayward said while you cannot ban Christmas, he called for clearer messaging to families about the ""dangers"" of socialising and inter-generational mixing.
Gavin Terry, head of policy at the Alzheimer's Society, said thousands of relatives would be in ""complete despair"" at government guidance which says only care home residents of working age should be allowed to leave their care homes to visit family, due to the increased risk of exposure to the virus.
""After eight harrowing months filled with devastation and tragic loss of life, the announcement that many care home residents will be facing Christmas alone is just heartbreaking,"" he said, calling for further testing to allow for more visits.
Meanwhile, Emma McClarkin, chief executive of the British Beer and Pub Association, called on ministers to publish evidence for its Christmas bubble rules, which would ""inflict unnecessary pain and irreversible damage on our sector"".
Local rules mean many pubs and restaurants - such as those in England's tier three or Scotland's level four - will remain closed during the festive period, irrespective of the Christmas change.
**How will your Christmas plans be affected?**haveyoursay@bbc.co.uk **.**
Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways:
If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or comment or you can email us at HaveYourSay@bbc.co.uk. Please include your name, age and location with any submission."
"
Josh of Cartoons by Josh writes: Another in the Surreal Climate series – in response the WUWT story about the EPA rejecting CO2 petitions
I think we all know what the decent thing to do would be…


A couple of weeks ago I started a new series called ‘Fantasy Climate’ where anything goes really – even the title apparently!
So the next week I called it ‘Surreal Climate’ – H/t Tallbloke – rather a nice allusion to another blog.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a1ceebe',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

From its peak on May 19 to its lowest point on Sept. 17, the Russian stock market has fallen by almost 58 percent. This is its largest decline since the crash of 1998. What is the cause of the current cataclysm? 



The Kremlin has been quick to blame the West, and primarily the United States, for the country’s troubles. Prime Minister Vladimir Putin blamed Western “speculators” who pulled out their investments en masse at the first sign of trouble. He also denied that Russia’s aggression toward Georgia played any role in the market’s fall. Putin suggested that the crisis is connected “not with the problems of the Russian economy, but with problems of the West’s economy.” In recent comments, he even referred to it as the “American contagion.” 



President Dmitry Medvedev concurred, saying, “The United States caused the whole crisis with its own financial market. … Regarding the factors that were responsible for the drops in the Russian stock market, I would estimate it as follows: 75 percent of the fall in the stock market is connected with consequences of the global financial crisis and 25 percent due to our internal problem, including consequences of the war in the Caucasus.”



How accurate are these assessments? 



After May 19, stock markets in almost every country of the world started to decline, and Russia followed this downward trend. Therefore, in the first stage of the global crisis, the financial problems were by no means specific to Russia. This global decline continued for almost two months. During this period, the U.S. stock market fell by 11.5 percent, the global market by 12.9 percent and the Russian market by 13.1 percent. Because the Russian market’s decline was slower in comparison to emerging markets, which fell by 17.5 percent overall, this may have confirmed for many observers what Finance Minister Alexei Kudrin claimed in January — that Russia had become an “island of stability.” 



But all of that changed on July 18, when the RTS fell by 4.5 percent, while there was little or no change in the markets in the United States, Europe or in emerging markets. What happened on that day? The Federal Migration Service granted TNK-BP chief Robert Dudley a “temporary visa” — valid for 10 days only. This was followed by a prolonged harassment campaign aimed at Dudley and other top managers from the British side of the joint venture. It became clear that the government was favoring the Russian shareholders in the conflict. In 2003, when TNK-BP was formed, the company had been touted as the crown jewel of successful joint ventures between Russian shareholders and a venerable foreign multinational corporation. It had the support at the highest level of both countries, including then‐​British Prime Minister Tony Blair and Putin. Thus, when this much‐​celebrated joint venture deteriorated into a nasty, underhanded shareholder battle, many investors drew their own conclusions about the unstable, unpredictable and arbitrary investment climate in the country. They started to pull their money out of Russia. 





The Kremlin has been quick to blame the West, and primarily the United States, for the country’s troubles.



In the following weeks, Russia’s stock market continued to drop. These declines were deeper than in other emerging markets, and this was because of the following additional events: Putin’s promise to “send a doctor” to Mechel’s director on July 24; the start of Russia’s intervention in Georgia on Aug. 8; the Kremlin’s unilateral recognition of independence for South Ossetia and Abkhazia on Aug. 26; and a whole series of official, inflammatory statements directed against the West from Sept. 3 to Sept. 17, which were accompanied by the decision to send strategic bombers to Venezuela and the announcement of naval maneuvers in the Caribbean Sea.



The authorities managed to achieve the impossible: In less than two months, Russia’s stock market declined by 51.8 percent. To be sure, stock markets in other countries also declined during this period, but it was nothing like what happened in Russia. The U.S. stock market fell by only 8.5 percent, the global market by 12.4 percent and the overall market of developing countries by 25.4 percent.



Given those dynamics, it would be difficult to blame outside influences — especially the United States — for causing Russia’s financial crisis. Had investors appraised the risk‐​return ratio for their Russian investments to be the same as that in the crisis‐​stricken United States, then the Russian stock market would have lost no more than the U.S. market did. And even if we were to take seriously what was reported in the Western media — that top Russian officials believed that the U.S. government had instructed U.S. banks not to lend to Russian companies — then why didn’t investors from Europe, Asia and the Arab states happily rush in to snatch up those greatly devalued shares at bargain prices? On the contrary, they stayed far away from the Russian market because they also evaluated it as a high‐​risk investment. 



The drop in world oil prices has also been cited as a contributing factor to the country’s stock market crisis. Indeed, oil prices fell by 38 percent over a two‐​month period — from July 17 to Sept. 17. But Russia’s market — which includes far more than just oil company shares — fell even further. In fact, the main evidence against the “oil factor” argument is the performance of markets in other leading oil‐​exporting countries. Even in these countries, where the share of oil production in their gross national product is generally higher than Russia’s, markets fell by only 20 percent. 



In the end, only a small portion of the 51.8 percent decline in Russia’s stock market can be attributed to the “American contagion.” In reality, the “U.S. factor” could not have accounted for more than a 17 percent decline. But by insisting on blaming the United States for its financial woes, the Kremlin is trying to trick the Russian people, as well as themselves. Foreigners, however, would never fall for that nonsense. 



As it turns out, at least half of the market’s fall is attributable to domestic causes. Foremost among them were the Kremlin’s attacks on Russian and foreign businesses, its aggression against Georgia followed by its recognition of independence for South Ossetia and Abkhazia, and the subsequent fears of investors and the international community as a whole that a new Cold War was about to start. Unlike Russia’s leaders, investors are scared off by any form of war — whether it is “hot” or “cold.” 



The total capitalization of Russian companies with shares traded on the stock market has fallen by almost $800 billion since May 19. Capitalization losses since July 17 alone account for more than $600 billion. Half of those losses — more than $300 billion — were the direct result of factors originating from Russia. 



The Russian government pretended to be mitigating the effects of the crisis by pumping more than $100 billion of state funds into the stock market, but nearly all of these funds went to state‐​owned companies and to other businesses that have close ties to the government. 



But Russia’s stock market crisis was brought on by more than just superficial causes. The drop in global oil prices to $90 or $100 per barrel — a symptom of the shifting winds of the global economy — was not damaging enough to trigger a crisis of this depth. Neither could the liquidity crisis be the reason, with Russia currently awash in petrodollars. Systemic, institutional problems are the real cause of this crisis. There is a fundamental incompatibility between open global markets and the universal principles of tolerance and respect that govern it in the West, on the one hand, and the paranoia and aggressiveness of Russia’s current leadership, with its cult of isolation and militarism and the modus operandi of street gangsters, on the other hand. 



In Korney Chukovsky’s classic children’s poem, “Putanitsa” (“The Muddle”), a crocodile is unable to put out a fire with pirogi and blini. Similarly, the fire of Russia’s deep and long‐​term institutional crisis cannot be extinguished with the financial “pirogi and blini” offered by Russian leaders — particularly when these goodies are divvied out only to their close friends. 
"
nan
"
By Steve Goddard

Guardian  photo : Ann Daniels Enjoying The Warming Arctic
Yesterday, WUWT  reported on a University of Melbourne study claiming that melting  ice is behind the warming of the Arctic.
“Findings  published in Nature today reveal the rapid melting of sea ice has  dramatically increased the levels of warming in the region in the last  two decades. The sea ice acts like a shiny lid on the Arctic Ocean. When  it is heated, it reflects most of the incoming sunlight back into  space. When the sea ice melts, more heat is absorbed by the water. The  warmer water then heats the atmosphere above it.”
If this were true, we would expect to see that months with the most  ice loss would also show the most warming.  In fact, we see the exact  opposite.  As you can see in the graph below, most Arctic  warming from 1979-present has occurred in the winter and spring,  with very little warming during the summer.

By contrast, ice extent  trends over that same time interval show that ice loss has  occurred mainly during the summer.  It appears that the relationship  between warming and ice loss is inconsistent with the claims in the  University of Melbourne study. Temperatures have increased the least  during times of year when ice loss was the greatest.

April is the month which has warmed the most, a full seven months  after September – the month of peak ice loss.  There is very little  variation in ice extent year over year during April – except for this  year which is running well above any other recent years.

http://ocean.dmi.dk/arctic/icecover.uk.php
A couple of other familiar graphs showing the same issues can be seen  below.  Note in the DMI  graph below that Arctic temperatures have not warmed at all during  the summer in the central Arctic.

In the Cryosphere  Today graph below, you can see that most ice loss has been during  the summer, when there has been little or no temperature gain.

The scatter plot below shows Arctic temperature trends vs. the  absolute value of ice extent trends, for all 12 months.  Note that there  is no meaningful correlation between temperature trends and ice loss.   In fact, the months with the most increase in temperature seem to be  the ones with little ice loss.

The article claims
” Strong winter warming is consistent with the atmospheric  response to reduced sea ice cover.”
But  this is inconsistent with the fact that there has been very little  reduction in winter ice cover.  The temperature of water under the  winter sea ice is fixed by thermodynamics at -2C down to a depth of tens  of metres, and does not vary from one year to the next. Furthermore,  the rate of heat transfer through 2-5 meter thick 99+% concentration  ice, is very low. NSIDC is currently showing ice  extent right at the 1979-2000 mean, and above the 1979-2009 mean –  yet temperatures in the Arctic have been well above the mean all through  the spring.  How is the heat escaping through all the thick, high  concentration ice?

http://ocean.dmi.dk/arctic/meant80n.uk.php
The article also claims :
“reduced summer sea ice cover allows  for greater warming of the upper ocean….The excess heat stored in the  upper ocean is subsequently released to the atmosphere during winter.”
There is a major problem with that  theory.  The summer minimum occurs at the autumnal equinox when the  Arctic is receiving almost no SW radiation, and that which is being  received is well below the critical angle of water.  By September, the  shortage of insulating ice cover is actually causing a net loss of heat  from the ocean.  NSIDC  explains it like this:

“In the past five years,  the Arctic has shown a pattern of strong low-level atmospheric warming  over the Arctic Ocean in autumn because of heat loss from the ocean back  to the atmosphere. ….  As larger expanses of open water are left at  the end of each melt season, the ocean will continue to hand off heat to  the atmosphere.”


In other words, loss of summer ice  should produce atmospheric warming in the autumn, but not in the winter  and spring when ice is cover is normal or near normal.
Two years ago, WUWT published this article after review by Walt Meier at NSIDC, Roger Pielke Sr. at CU,  and Ben Herman at the University of Arizona.  It explains why changes in  ice cover probably are causing a net cooling effect.  None of the  reviewers had any substantive disagreements with the conclusions.
Conclusion: The University of Melbourne study claims are not  supported by the available data.  The authors seem to have jumped right  into statistical analysis without proposing a physical mechanism that  works.  Heat flows across differences in temperatures, yet the winter  water temperature under the ice is fixed at -2C.  Thus elevated winter  air temperatures should actually cause a reduction in heat flow out of  the ocean.  Whatever is driving increases in winter Arctic temperatures  is not heat coming out of the Arctic Ocean, which is covered with  insulating ice.
A more logical conclusion would be that the decline in ice thickness  is associated with warmer winter temperatures.
If scientific reasoning  were limited to the logical processes of arithmetic, we should not get  very far in our understanding of the physical world. One might as well  attempt to grasp the game of poker entirely by the use of the  mathematics of probability.
– Vannevar Bush


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8bebf274',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

THIS WEEK:
By  Ken Haapala, Executive Vice President Science and Environmental Policy Project  (SEPP)
On Thursday, The French  Academy of Sciences released a report declaring the global warming exists and is  unquestionably due to human activity. The academy president declared the debate  is over. Former education minister Claude Allegre, who questioned the orthodoxy,  signed off on what he considered a compromise report stating: “I have not  evolved, I still say the same thing, that the exact role of carbon dioxide in  the environment has not been shown.”

The report  recognized uncertainties in solar influence, clouds, oceans and atmosphere.  Those who believe that human carbon dioxide emissions may have some warming  effect, but are not the dominant driver of climate change, may find the report  acceptable except that it gives carbon dioxide a principal role in climate  change. We await the translation of the full report, but apparently there is no  precision in the report. A vague statement, no matter how forcefully made,  remains vague. Please see Article # 1
***************************************
In an  article published on October 12, Bjorn Lomborg discusses the change in the  vocabulary of the global warming alarmists. No longer is global warming, or  climate change, the major theme. Instead, it has been replaced by clean energy,  clean jobs – a green economy. Lomborg also discusses how much a green economy is  costing his native country, Denmark. He believes that drastic carbon cuts are a  poor response to global warming. Please see Article # 2.
In another article for the Investors’ Business Daily (IBD), Lomborg  advocates committing streams of money to technical improvements in new wind and  solar energy, as well as other technical innovations. Lomborg’s comments are  rebutted in a follow-up article in IBD by Willie Soon, Bob Carter, and David  Legates who bring up a seldom mentioned issue: the benefits of increased CO2  Much is made of what economists call the external costs of carbon dioxide  emissions, namely global warming which is always considered bad. But increased  CO2 in the atmosphere stimulates more vigorous growth of plant life that  benefits humanity and the environment.
***************************************
The  Department of Interior has approved the building of what is called the world’s  largest solar-thermal power plant on 7,000 acres of Federal land in the desert  of Southern California. The project is a venture by two German companies. The  first half of the project could be eligible for a cash subsidy of $900,000,000  from the stimulus bill. The cash subsidy program ends on December 31, 2010.  Also, the companies are seeking Federal loan guarantees and, no doubt, an array  of benefits from the state.
To put the cash subsidy  perspective, it is useful to calculate the employment benefits. The  administration claims this project will provide up to 300 new permanent jobs.  This calculates out to $3,000,000 per permanent job. At that rate it would cost  about $20.27 Trillion to reduce the current unemployment rate (9.2% est. by US  Bureau of Labor Statistics) to the rough average over the past 15 years of 5%.  $20.27 Trillion is about 1.4 times the entire gross domestic product of the US  in 2009 (estimated to be $14.26 Trillion by the US Bureau of Economic Analysis).  The expenditure is enormous, but does it benefit the citizens of California by  providing affordable electricity?
As seen in other  reports (Article # 3 and articles under California Dreaming) there are  additional solar projects in California which promoters are trying to start  before December 31. These stories indicate that even after subsidies, the cost  of the electricity generated will be 30 to 70 percent more expensive than  electricity generated by natural gas, the dominant electricity generating fuel  in California. The promoters of the projects consider a 30 to 70 percent  increase in cost to be competitive – a clear consequence of the state’s  renewable energy mandates. Only in California!
***************************************
THE NUMBER  OF THE WEEK: 24 to 1 – the number of nuclear power plants under construction  in China (as reported by the World Nuclear Association) compared to the number  of nuclear power plants under construction in the US.
Green energy promoters stridently insist that we are in a race with China  to develop green energy, namely solar and wind. Spain and Germany were in the  race but dropped out and their green energy firms are suffering as the subsidies  stopped.
The question seldom asked is China really  in the same race? Over the next several weeks, The Number of the Week will  explore that question. If China is in a nuclear power race it is clearly  winning. Please see Nuclear Power in China under Energy Issues.
[Please note that the 104 nuclear power plants in  the US have a very high average capacity factor of over 90%.]
——————–
SEPP  SCIENCE EDITORIAL #32-2010 (Oct. 30, 2010)
S Fred Singer Chairman, and President, Science and  Environmental Policy Project (SEPP)
Why the Confusion about Global  Warming?
No one denies that the Earth  has warmed in the past century. So of course, the past decade must be the  warmest – even though there has been no upward trend since the 1998 temperature  peak. [Note the important distinction between temperature level (measured in deg  C or deg F) and trend (expressed in deg C per year).] The dispute is (and always  has been) about the cause of the warming. In fact, the major warming during the  first 50 years of the 20th century and the latter part of the 19th century is  generally accepted to be natural – a recovery from the Little Ice Age. But  there’s no credible evidence that identifies the most recent warming as  human-caused. On the contrary, while the UN’s IPCC claims to be quite certain  that it is anthropogenic, the independent NIPCC (Non-governmental International  Panel on Climate Change) concludes that “Nature – Not Human Activity – Rules the  Climate.” See  http://www.sepp.org/publications/NIPCC_final.pdf
In  this connection note the obfuscatory language used by the EPA in turning down  all of the ‘Petitions for Reconsideration’ of its Endangerment finding on CO2:  “The scientific evidence supporting EPA’s finding is robust, voluminous, and  compelling. Climate change is happening now, and humans are contributing to it.  Multiple lines of evidence show a global warming trend over the past 100 years.  Beyond this, melting ice in the Arctic, melting glaciers around the world,  increasing ocean temperatures, rising sea levels, altered precipitation  patterns, and shifting patterns of ecosystems and wildlife habitats all confirm  that our climate is changing.”
Yet there is no  evidence at all that humans are indeed contributing to warming in a significant  way. We’ll see you in court, dear EPA, and gladly examine your “compelling”  evidence!
– – – – – – – – – – – – – – – –  –
ARTICLES: For the numbered articles below please see:
The Week That Was 
1. Global warming ‘unquestionably’ linked to humans:  France
By Claire Snegaroff, APF, Oct 28,  2010
http://www.google.com/hostednews/afp/article…
2. What Have Climate Activists Learned
By Bjorn Lomborg, Project Syndicate, Oct 12, 2010 [H/t Berol  Robinson]
http://www.project-syndicate.org/commentary/lomborg6….
[SEPP Comment: The new hype is green energy, green jobs but the purpose  is the same – control of carbon dioxide emissions.]
3. Huge Solar-Plant Project Approved
By Cassandra Sweet and Siobhan Hughes, WSJ, Oct 26, 2010
http://online.wsj.com/article/SB10001424052702303467….
4. Disputing The Skeptical  Environmentalist
By Willie Soon, Robert  Carter, and David Legates, IBD, Oct 29, 2010
http://www.investors.com/NewsAndAnalysis/ArticlePrin….
5. Observe Other’s Past Energy  Experiences
By Charles Battig, Letter,  Richmond Times Dispatch, Oct 21, 2010
http://www2.timesdispatch.com/news/2010/oct21/ed-bat….
– – – – – – – – – – – – – – – –  –
NEWS  YOU CAN USE:
Challenging the Orthodoxy
Cabal of climate  skeptics to descend on parliament
By Leo  Hickman, Guardian, UK, Oct 26, 2010
http://www.guardian.co.uk/environment/blog…
Defending the  Orthodoxy
Climate Change May  Alter Natural Climate Cycles of Pacific
Science  Daily, Oct 18, 2010 [H/t Toshio Fujita]
http://www.sciencedaily.com/releases/2010/10/1010171….
[SEPP Comment: The IPCC and other advocates have ignored the influence of  natural cycles in the Pacific on global warming. Now some claim global warming  will change these cycles.]
Why Can’t We Innovate  Our Way To A Carbon-Free Energy Future?
By Bjorn  Lomborg, IBD, Oct 22, 2010
http://www.investors.com/NewsAndAnalysis/Article/551….
Weather  Extremes
Arctic Temperatures  and Ice – Why it is All About Natural Variability
By Joseph D’Aleo, ICECAP, Oct 24, 2010
http://www.icecap.us/…
Warmer Arctic Temps  Tied to U.S. Snowstorms
CBS News, Oct 22, 2010,  [H/t Joe D’Aleo ICECAP]
http://www.cbsnews.com/stories/2010/10/22/tech/main6….
NOAA: “Arctic Report  Card: Update for 2010”
By Arnd Bernaerts,  Digging In the Clay, Oct 25, 2010 [H/t ICECAP]
http://diggingintheclay.wordpress.com/2010/10/27/noa….
2010 Hurricane  Factoids
Roger Pielke, Jr, Blog, Oct 25, 2010  [H/t Marc Morano, Climate Depot]
http://rogerpielkejr.blogspot.com/2010/10/2010-hurri….
[SEPP Comments: Another disappointing season for those hyping  hurricanes.]
BP Oil  Spill and Aftermath
Panel Says Firms Knew  of Cement Flaws Before Spill
By John Broder,  NYT, Oct 28, 2010
http://www.nytimes.com/2010/10/29/us/29spill.html?_r….
Another Drilling  Smackdown
Editorial, WSJ, Oct 25,  2010
http://online.wsj.com/article/SB10001424052702304741….
Energy Issues
Nuclear Power in  China
World Nuclear Association, Oct 22,  2010
http://www.world-nuclear.org/info/inf63.html…
Half The  Productivity, Twice The Carbon
By Staff Writers,  Energy Daily, Oct 26, 2010 [H/t Catherine French]
http://www.energy-daily.com/reports/Half_The_Product….
[SEPP Comment: The IT industry needs affordable, reliable electricity.  This is news?]
Can Solar Shield  Protect The North American Power Grid
By Tony  Phillips, Science News, [H/t Toshio Fujita]
http://www.spacedaily.com/reports/Can_Solar_Shield_P….
Is Wind the Next  Ethanol?
By Ben Lieberman, CEI, Oct 26, 2010  [H/t Cooler Heads Digest]
http://cei.org/studies-point/wind-next-ethanol…
German grid aching  under solar power
UPI, Oct 19, 2010  http://www.upi.com/Science_News/Resource-Wars/2010/10/19/German-grid-aching-under-solar-power/UPI-13471287518368/
Time To Remove The  Roadblocks To A National Transmission Grid
By  Gilbert Metcalf, IBD, Oct 26, 2010
http://www.investors.com/NewsAndAnalysis/Article/551….
Hydrogen-generating  technology might power boats, store energy from wind, solar  sources
By Emil Venere, Press Release, Purdue  University, Oct 7, 2010 [H/t Toshio Fujita]
http://www.purdue.edu/newsroom/research/2010/101007W….
Subsidies and Mandates  Forever
Spending Review:  Honesty is the best policy before the bigger fuel bills start to  bite.
By Charles Moore, Telegraph, UK, Oct 22,  2010 [H/t Bob Ferguson, SPPI]
http://www.telegraph.co.uk/comment/columnists/charle….
Perplexing energy  policy
By Steen Syre, Boston Globe, Oct 26, 2010  [H/t Randy Randol]
http://www.boston.com/business/articles/2010/10/26/p….
Remember Renewable  Energy?
Editorial, NYT, Oct 27,  2010
http://www.nytimes.com/2010/10/28/opinion/28thurs1.h….
The Race for Future  Clean-Energy Jobs
By Terry McAuliffe, Richmond  Times Dispatch, Oct. 27, 2010
http://www2.timesdispatch.com/news/oped/2010/oct/27/….
California  Dreaming
Solar Power Project  Face Potential Hurdles
By Todd Woody, NYT, Oct  28, 2010
http://www.nytimes.com/2010/10/29/business/energy-en….
DOI Approves 1,000-MW  Rated Parabolic Trough Project
Power News, Oct  27, 2010
http://www.powermag.com/POWERnews/3127.html?hq_e=el&….
EPA and other Regulators On the  March
NERC: EPA Regulations  Could Impact System Reliability
Power News, Oct  27, 2010
http://www.powermag.com/POWERnews/3125.html?hq_e=el&….
Oh, Mann!
Cuccinelli Demands  Called ‘Governmental Intrusion’ Into Climate Science
By Eli Kintisch, Science Insider, Oct 21, 2010 [H/t Toshio  Fujita]
http://news.sciencemag.org/scienceinsider/2010/10/cu….
[SEPP Comment: Climate science is largely dependent on government  support. Now an investigation of possible inappropriate application of such  funds is a governmental intrusion?]
Review of Recent Scientific Articles by  NIPCC
For a full  list of articles see NIPCC Report
Flocks of Birds  Coping with Climate Change
Reference: Van  Buskirk, J., Mulvihill, R.S. and Leberman, R.C. 2010. Declining body sizes in  North American birds associated with climate change. Oikos 119:  1047-1055.
http://www.nipccreport.org/articles/2010/oct/27oct20….
Amphibian Population  Declines
Reference Rohr, J.R., Raffel, T.R.,  Romansic, J.M., McCallum, H. and Hudson, P.J. 2008. Evaluating the links between  climate, disease spread, and amphibian declines. Proceedings of the National  Academy of Sciences USA 105: 17,436-17,441.
http://www.nipccreport.org/articles/2010/oct/28oct20….
Effects of Elevated  CO2 on Longevity and Fecundity of an Invasive Weevil Feeding on Aspen, Birch and  Maple Foliage
Reference: Hillstrom, M.L., Vigue,  L.M., Coyle, D.R., Raffa, K.F. and Lindroth, R.L. 2010. Performance of the  invasive weevil Polydrusus sericeus is influenced by atmospheric CO2 and host  species. Agricultural and Forest Entomology 12: 285-292.
http://www.nipccreport.org/articles/2010/oct/28oct20….
Unexpected Biological  Resilience to Climate Change
Reference: Bell,  R.C., Parra, J.L., Tonione, M., Hoskin, C.J., Mackenzie, J.B., Williams, S.E.  and Moritz, C. 2010. Patterns of persistence and isolation indicate resilience  to climate change in montane rainforest lizards. Molecular Ecology 19:  2531-2544.
http://www.nipccreport.org/articles/2010/oct/28oct20….
Other Scientific  Issues
Introducing the  A-Train
By Adam Voiland, NASA Press Release, Oct  27, 2010 [H/t Anthony Watts, WUWT]
http://www.nasa.gov/mission_pages/a-train/a-trainht….
[SEPP Comment: An explanation of a train of satellites measuring the  earth’s changes.]
Changing Our  Understanding Of Atmospheric Aerosol Properties And Climate  Effects
By Staff Writers, Terra Daily, Oct 18,  2010 [H/t Toshio Fujita]
http://www.terradaily.com/reports/Changing_Our_Under….
[SEPP Comment: The influence of aerosols on the earth’s climate is  largely unknown. Better understanding of the physical nature of some aerosols is  an important step.]
Bees’ tiny brains  beat computers, study finds
Bees can solve  complex mathematical problems which keep computers busy for days research has  shown
Guardian, UK, Oct 24, 2010 [H/t A.J.  Meyer]
http://www.guardian.co.uk/world/2010/oct/24/bees-rou….
– – – – – – – – – – – – – – – –  –
BELOW  THE BOTTOM LINE:
Al Gore compares  human heart to hydrological cycle
By Rance  Leroy, French Tribune, Oct 21, 2010 [H/t Best on the Web]
http://frenchtribune.com/teneur/101652-al-gore-compa….
Space tourism to  accelerate climate change
By Adam Mann, Nature  News, Oct 22, 2010 [H/t A.J. Meyer]
http://www.nature.com/news/2010/101022/full/news.201….
 


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e87a86e29',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**The Blackpool Illuminations are to be switched back on when the national lockdown ends.**
The resort's famous light display was suspended on 4 November, although Blackpool Tower has continued to shine.
The illuminations will light up the resort from Wednesday until 3 January to give people ""a lift"", said Blackpool Council.
Neil Jack, council chief executive, said he hoped it would bring ""a little bit of cheer"" to people living locally.
""We're putting them back because retail will be open so we would have Christmas lights on anyway,"" he said.
""But also I think everybody could do with a bit of a lift.""
He added bringing ""a little bit of cheer in the winter months won't do any harm"" to people living in the area.
The illuminations had been due to shine for an extra two months this season, until 3 January, to aid the town's tourism trade hit by Covid-19 restrictions.
_Why not follow BBC North West on_Facebook _,_Twitter _and_Instagram _? You can also send story ideas to_northwest.newsonline@bbc.co.uk"
"

In his State of the Union address, President Bush pressed Congress to quickly pass legislation to make permanent the sweeping spying powers that Congress granted last August. Those powers, which include the ability to eavesdrop on foreign‐​to‐​domestic communications without meaningful judicial oversight, were due to expire last week. Congress has passed a two‐​week extension of the law, but that barely gives Congress time to catch its breath before the White House resumes its campaign to make it permanent.



Bush’s predecessor was also an ardent supporter of increased wiretapping authority. For example, on July 29, 1996, Bill Clinton unveiled a proposal to expand government surveillance by permitting the use of “roving wiretaps.” The nation was still reeling from terrorist attacks on the Atlanta Olympics and American barracks in Saudi Arabia, and many suspected that the explosion of TWA Flight 800 was also the work of terrorists. Clinton argued that these tragedies highlighted the need for legislative changes, and he pressed Congress to act before its August recess.



But Congress had a bipartisan tradition of its own to defend. As they had done since Watergate, Congressional leaders raised concerns about civil liberties. Then‐​Speaker Newt Gingrich said he was willing to consider changes to the law, but vowed to do so “in a methodical way that preserves our freedoms.” Senate Majority Leader Trent Lott vowed that Congress would not “rush to a final judgment” before going on vacation. In the end, the 104th Congress finished its term without giving President Clinton the wiretapping authority he sought.





Why are today’s Democrats less concerned with civil liberties than Republicans were a decade ago?



Today’s Democratic Congress has been far less protective of Americans’ privacy rights. Last August, in a virtual repeat of the events of 1996, Bush demanded that Congress approve expanded wiretapping powers before going on vacation. This time, Congressional leaders showed few qualms about “rushing to judgment.” Indeed, both houses of Congress approved the White House’s preferred legislation with minimal changes within three days of its introduction.



Why are today’s Democrats less concerned with civil liberties than Republicans were a decade ago? Democratic leaders would doubtless point to the 9/11 attacks. Those attacks have certainly contributed to a changed political climate, but they don’t justify Congress’s panicky reaction to the president’s demands. Congress had already expanded eavesdropping powers several times since 9/11. Congress approved new wiretapping authority with the Patriot Act in 2001, and approved further expansions later in 2001 and in 2002, 2004, and 2006. If the new powers the president was seeking weren’t urgent enough to include in those revisions to the law, it’s hard to believe they were an emergency in August 2007.



Moreover, the powers Congress granted last summer are far broader those sought by the Clinton administration in 1996. The “roving wiretaps” Clinton requested in 1996 and finally received in 1998 merely allowed investigators to obtain a single warrant to bug multiple phones used by a specific individual. In contrast, the Protect America Act completely eliminates the warrant requirement for surveillance “concerning persons reasonably believed to be outside of the United States” — even if one party to a call is an American citizen and the wiretap occurs on American soil. The attorney general is required to disclose to a secret court the general procedures used to choose wiretapping targets, but no judge reviews the list of specific targets to verify that the law is being followed. This evisceration of judicial review is an invitation to future abuses.



The lone virtue of the Protect America Act is that the powers it granted are now set to expire in mid‐​February. As this revised deadline approaches, Speaker Nancy Pelosi and Majority Leader Harry Reid will once again face pressure to rush the White House’s preferred legislation out the door. The president will claim that failure to act before the Protect America Act sunsets will undermine the government’s ability to eavesdrop on terrorists.



It’s an ominous claim, but it’s not true. The Protect America Act allows the administration to “authorize” eavesdropping programs for a year at a time. That means that the government’s various warrantless surveillance activities will continue to operate at least through August. And of course, if the need for new wiretaps arises after the act sunsets, the administration still has the opportunity to file for warrants under the Foreign Intelligence Surveillance Act (FISA). FISA even allows the government to begin surveillance first and apply for an emergency warrant after the fact.



In short, the administration will have ample authority to intercept terrorist communications for at least the next six months. As they shepherd FISA reform through Congress, Pelosi and Reid would do well to heed the advice of one of Pelosi’s predecessors: “The goal here is not to allow the terrorists to pressure us into suspending the very freedoms that make America precious.” Those words are as true today as when Newt Gingrich said them in 1996.
"
"
While Americans continue to put global warming aka climate change at the bottom of the list of worries, it seems the electronic media outlets that most often push alarming climate stories are losing favor. This interesting juxtaposition was from my Shoptalk TVSpy business newsletter today:
CNN Fails to Stop Fall in Ratings – from The New York Times

CNN continued what has become a precipitous decline  in ratings for its prime-time programs in the first quarter of 2010, with its  main hosts losing almost half their viewers in a year.
The trend in news ratings for the first three months of this year is all up  for one network, the Fox News Channel, which enjoyed its best quarter ever in  ratings, and down for both MSNBC and CNN.
CNN had a slightly worse quarter in the fourth quarter of 2009, but the last  three months have included compelling news events, like the earthquake in Haiti  and the battle over health care, and CNN, which emphasizes its hard news  coverage, was apparently unable to benefit. More… 

Fox News Has Best Quarter In  Network History – from Mediaite

Fox News had their best year of all time  in 2009. Now that we’ve finished the first quarter of 2010, it’s clear FNC is  showing no signs of letting up –they just finished their best quarter ever, in  total day total viewers.
It was also the second highest rated quarter ever in prime time total  viewers.
While Fox News continues to see record ratings, their cable news competitors  are dropping off even more year-to-year. In the A25-54 demographic during prime  time, FNC was up 16%, while CNN dropped 42%, MSNBC was down 22% and HLN was down  40%. More… 


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8d315c1f',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterGerman daily Bild, number one by circulation in Europe, plants more seeds of man-made global warming skepticism in an article today about this year’s really crappy wet and cool summer.

“And just like the guy whose feet are too big for his bed, nothing seems to fit…”
While Bild asks how long the Azores high pressure system “Xerxes” will hold up and bring Germany the much welcome relief from all the cold and rain, the report also looks into long-term climate trends.
Bild poses the question: “Were summers of the last years really cooler, wetter and less freindly than before?”
To answer that question, Bild consulted wetter.net meteorologist Dominik Jung (a global warming believer). His answer:
It really is so. We took a look at the summer of the last 9 years. The tendency is that they were cooler and rainier than the long-term average.“
Normally a newspaper reporting on the summer’s weather would just leave it at that. But Bild takes the extra step and looks back at the summers over the last 2000 years and brings up Jan Esper’s recently published tree-ring study: Bild writes:
If you don’t believe Domink Jung, then we take a look at the longterm.analysis of an international tean of scientists. In it the scientists measured the wood density of trees and reconstructed the weather of the last 2000 years. Fact is: There is a cooling trend for the season that we call summer.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




It has gotten about 0.3°C cooler each millenium. And we are feeling that trend today as well.”
So what is Bild telling its readers? I’d interpret it as: There’s nothing unusual about the currrent climate and over the long-term we are cooling.
Glad to see that a major media outlet in Germany is open to the broader climate picture. Very very few other media outlets have reported on the implications of Esper’s 2,000-year reconstruction.
Looks like Germany’s über-alarmist, closed-minded institutes, like Jochem Marotzke’s Max Planck Institute for Meteorology and John Schellnhuber’s Potsdam Institute for Climate Impact Research are going to have to go back to the drawing board and completely revamp their “climate models”. So far their projections have completely and massively diverged away from recorded observations.
And once again:

“It doesn’t matter how smart you are, or what your name is – it’s wrong. It’s that simple.”
Also very worthwile watching…on “vague theories”.

 
Share this...FacebookTwitter "
"**Now is the ""time to unite"" across Northern Ireland in order to push down the spread of Covid-19, Health Minister Robin Swann has said.**
He was speaking two days before tougher lockdown restrictions come into force for two weeks.
On Wednesday, seven more Covid-19 related deaths were recorded by the Department of Health.
That brings the total number of coronavirus-related deaths in Northern Ireland to 954.
Speaking at a press conference at Stormont, Mr Swann said if everyone in Northern Ireland follows the lockdown rules, it will make a difference leading up to Christmas.
""Our actions now will have a bearing on the kind of Christmas we can all have,"" he said.
""The greatest gift we can give loved ones this year is to look after them.
""Some restrictions may be relaxed coming up to Christmas but maximum vigilance will still be required - a festive free-for-all would mean a New Year crisis.""
The minister acknowledged the importance of Christmas to many people but said there was ""still work to do"", before people could enjoy a break.
He warned that people should also follow the ""stay at home"" guidance as much as possible.
Northern Ireland's Chief Medical Officer, Dr Michael McBride, said undoubtedly allowing people to bubble with three households over Christmas ""carried some risk"" and would lead to an increase in cases.
But he said he recognised that relaxing household restrictions temporarily would benefit many people and their mental health, given the isolation experienced this year due to the pandemic.
A total of 533 new positive cases of Covid-19 were recorded by the Department of Health on Wednesday.
It said this was higher than normal due to an issue with the ""flow of data"" from Pillar 2 testing on Tuesday when it recorded just 79 new positive cases.
There have been 50,676 positive cases in Northern Ireland since the pandemic began, with 2,421 people testing positive in the last seven days.
There are currently 443 people with Covid-19 being treated in Northern Ireland, 36 of those are in intensive care units (ICU).
Overall bed capacity within the health service is currently at 98%, with two hospitals - the Ulster and the Causeway - operating beyond their capacity.
Dr McBride said the R-number, the rate of coronavirus transmission, remains around one, and that Northern Ireland's hospitals remain under ""significant pressure"".
""We now have a lower incidence than England and Wales, but the incidence here in Northern Ireland remains higher than the Republic of Ireland,"" he added.
These two weeks are absolutely critical in trying to get the R number down.
It has moved slightly below one, but health authorities want it down a lot further, and that will depend on what we all do over the next couple of weeks.
If we get R down over the next fortnight, there's a better chance of the hospitality sector opening up.
The chief medical officer has said hospitality can't stay closed indefinitely, but clearly it won't reopen until the R number comes down.
Northern Ireland's Covid statistics are starting to come down a little bit.
The number of deaths has come down; the number of people in intensive care units has come down and - quite dramatically - outbreaks care homes have come down a lot, reducing by about 20 care homes over the last week or so.
So that's all very good, but what is different this time around is the very high number of people who remain in hospital.
That's because we know more about how to treat people - more people are surviving which is a good thing.
That means our hospitals are still very, very busy
The department also reported there are 140 active care home outbreaks of the virus in Northern Ireland.
Mr Swann said he did not believe that the doors of care homes in Northern Ireland should be closed to visits, in order to manage Covid-19 infections.
It follows reports that some care homes are not facilitating access for families to visit loved ones.
Guidance on visiting care homes and hospitals changed in October, with visits limited to one family member once a week.
Mr Swann said ""contact is so important"", and said he wanted more care homes to facilitate visits or arrange ""care partners"" for families wanting to spend time with their relatives.
Speaking about the potential upcoming vaccination programme, Mr Swann said ""intensive preparation"" is under way for a mass vaccination programme in Northern Ireland.
He said he would bring a presentation to the executive on Thursday about what that programme could look like.
The minister added that all authorisation and checks would need to be carried out before vaccines could be administered.
Mr Swann added that 600 people, including retired health care workers, have come forward to volunteer as vaccinators.
This compares to 880 vaccinators currently working in the health trusts.
There is a light at the end of this long tunnel,"" said the health minister, stressing that nothing should be taken for granted."
"In January, after she posed for a photo in Davos alongside Greta Thunberg and several other white climate campaigners, the Ugandan activist Vanessa Nakate was dismayed to see that the Associated Press news agency had cropped her out of the image. It started a global conversation about how the voices of black, Asian and minority ethnic people are erased from the climate crisis movement. Climate activism has historically been perceived as a white, middle-class pursuit, but nothing could be further from the truth. Across the UK, BAME people are at the forefront of the fight against the climate crisis. Now, their efforts are being recognised by the Climate Reframe Project, an initiative spotlighting BAME voices in climate activism, funded by the Joseph Rowntree Charitable Trust and the Solberga Foundation, and put together by the team behind former Irish president Mary Robinson’s Mothers of Invention podcast. Today, it features a list of the leading figures in the UK, some of whom shared their stories with me.  Why have BAME activists so often been ignored? “Historically, the environmental movement comes from a white, privileged background,” says Suzanne Dhaliwal, 37, who is researching BAME representation in the climate justice movement at the University of Brighton. “But climate change mostly affects people in the global south, so it’s fair to elevate those voices.” Many of the people I speak to have at times felt excluded. Nish Doshi is a 32-year-old climate justice organiser from Edinburgh. When Doshi – who is non-binary, and uses they/them pronouns – goes to Cop26 organising meetings for civil society alongside NGO leaders, they often find they are one of the few BAME people in the room. “There will be 50 or 60 people there, and hardly any people of colour,” they say. “They don’t even think about that at all.” Criticism has also been levelled at Extinction Rebellion (XR), with BAME people pointing out that its tactic of encouraging protesters to get arrested ignores the reality that people of colour are disproportionately likely to be targeted in their interactions with police. Yet BAME people have been central to climate activism for decades. Farhana Yamin, 55, is the international climate lawyer responsible for getting the target of net zero emissions by 2050 included in the Paris accord. She came up with the goal after growing tired of the incremental advances promised by the carbon emission trading system. “I wanted to think bolder and bigger – no more mucking around with carbon budgets,” Yamin says. “These gases are toxic. We shouldn’t create trading systems for toxic pollutants.” Recent years have seen the movement work to address its diversity problem. “When Vanessa was cropped out of that photo, that brought about a lot of healthy debate,” says Tyrone Scott, 28, an activist from London. He has been working tirelessly to get younger people into the movement, going into pupil referral units to teach students about the climate emergency. “They are so engaged,” Scott says. “It gives you so much hope for the future.” The 16-year-old Londoner Jessica Ahmed says she used to think: “Climate change doesn’t affect me. It’s not an African-person problem.” But she became an activist after attending the May 2019 school climate strikes. “I’ve never fallen behind with school,” she says. “I think I’m more on track than most people who don’t go on the strikes.” She now organises for the UK Student Climate Network, mobilising her classmates. “It sucks that we have to miss school,” she says. “But we need to make our voices heard because it’s us that are going to be the most affected by climate change.” Like Ahmed, the Manchester-based pupil Lillia Adetero, aged 10, has been striking from school, attending the Fridays for Future protests since January 2019. She often gives speeches at these strikes. “I talk about how climate change is going to affect our future and how the government isn’t doing enough,” she says. Adetero was delighted by the court of appeal ruling against the third Heathrow runway. “I’m very happy that Heathrow has been cancelled,” she says. “I’d like them to stop the Manchester airport expansion, too.” Others are trying to change the system from within. Scott stood as a Green MP candidate in Hackney South in 2019, doubling the party’s share of the vote. “It was a good experience,” he says. “But I was relieved the day after the election, I’m not going to lie. I was out every day, delivering thousands of leaflets for 10 hours at a time.” Fatima Ibrahim, 27, from London, is a codirector of the Green New Deal UK, which lobbies for the British government to put the climate crisis at the heart of the economic system, rather than seeing it as a stand-alone issue. “We have an economic system that isn’t working for the climate,” she says. “We need a system-wide change.” Her activism is cutting through: the Green New Deal was included in the 2019 Labour and Green manifestos. Many BAME activists feel a connection to the cause because they have family members in the vulnerable global south. Ibrahim is of Somalian heritage; her parents moved to the UK from Canada when she was nine. Climate activism has been her life’s work. “I was that crazy nine-year-old who watched Newsnight,” she says. “Coming from a refugee family made me aware of everything that was going on in the world. And it became clear to me that climate change was the biggest threat to people everywhere. If you care about injustice or refugees, all of those things will be 100 times worse if we don’t deal with the climate crisis.” She sees her Muslim faith as integral to her activism. “I have a responsibility for the people around me and a commitment to my community and other people,” she says. Other activists have turned to nonviolent direct action to force the government to pay attention. Yamin joined XR after becoming depressed by Donald Trump’s decision to pull out of the Paris accord, and the release of an Intergovernmental Panel on Climate Change report in 2018 that warned we had only 12 years to avert climate catastrophe. “I fell into a state of real depression – actual depression – which I’d never had before,” says Yamin. “I felt that we had failed. We hadn’t saved the world at all. It felt really bleak.” Direct action felt like a necessary corrective. “Our laws were being flouted,” says Yamin. “Laws that I helped put in place were being totally ignored.” She attended a number of XR direct actions. “I tried being arrested a few times and failed,” she jokes. “I thought: ‘I have to work harder at this being-arrested thing.’” Eventually, her wish was granted: Yamin was arrested after gluing herself to the Shell headquarters as part of the April 2019 XR protests. But it’s possible to make a difference in less dramatic ways. “It was amazing,” says 38-year-old Dave Fuller, from London, of his experience cooking for the anti-fracking protesters at the Preston New Road site near Blackpool. “When people are doing frontline work, all they want at the end of the day is a hot meal. I went up worrying that people would feel like I wasn’t fulfilling my part, but everyone was thankful someone was willing to turn up with hot food on a cold day.” He now works for Repowering, an initiative bringing affordable renewable energy to local communities. The law can also be a powerful tool. When Tessa Khan, a 37-year-old lawyer from London, heard about a landmark case brought by 900 Dutch citizens against their government for failing to uphold its climate commitments, she phoned the lawyers working on it. “I thought they were amazing,” says Khan. She went on to cofound the Climate Litigation Network, which helps citizens around the world to sue their governments on climate-crisis-related issues. “The gap between what the governments are supposed to be doing to stop global warming and what they are actually doing is growing by the day,” says Khan. Her team of four lawyers is supporting activists in Ireland who are bringing a case against the government to demand more aggressive action on the climate crisis. “We need to hold governments accountable for the promises they are making,” says Khan. “In our view, it’s unlawful for them to be as deeply negligent as they are.” All the activists I speak to are passionate about amplifying the voices of BAME people. “A big part of what I do is pushing for voices from the global south to be included in the climate change discussion,” says Doshi. They run workshops on climate colonialism and speak at events for youth leadership. “We need more black, brown and working-class voices to be heard,” agrees Adetero. “They don’t really get the opportunity to have their voices heard that white people do.” These are challenging times. “I am depressed about things,” says Doshi. “I see Trump pulling out of the Paris accord, the Trans Mountain pipeline in Canada, Bolsonaro taking away indigenous lands in Brazil.” But in spite of everything, there is also hope. “I feel like we have no choice but to be optimistic,” says Ibrahim. “The climate movement is massively growing. We’re reaching new people. The narrative is changing. We have to keep fighting against all odds.”"
"
Share this...FacebookTwitterWhat does Hans von Storch’s “most effective climate policy” look like?


The 1936 German sign reads “We don’t stand alone.” Well, in 2012 add China’s flag to the poster for countries that practice forced sterilizations.
Hat tip a reader/blogger:

Breaking China’s One-Child Law
In an unprecedented crackdown, Chinese officials set out to sterilize 10,000 women — by jailing their relatives until the women submitted.
A dozen Chinese officials had beaten down the man’s door and dragged him away. “What has he done wrong?” Wei asked in alarm. “Nothing,” her husband replied. “He has been jailed because he is related to us.”
Wei, a bird-thin woman with bobbed hair, let lunch burn on the stove as she heard more. “My husband said we had broken the law by having two children. The authorities were imprisoning his brother until we were punished,” she says. “As soon as I learned it was about birth control, I began to cry and shake.” Family-planning officials in the southern county of Puning, in Guangdong province, were going to shocking new extremes to catch and punish violators of the country’s infamous one-child policy: They were seizing family members of women who had given birth illegally and were holding them hostage. The aim? To coerce the women into submitting to sterilization. Says Wei, “The officials said there was only one way to get my brother-in-law released: I had to undergo forced sterilization.”
As Wei panicked in her kitchen, the same scene was playing out in households all over Puning, a region of 2.2 million people, about six hours by bus from the provincial capital of Guangzhou. In early April, the local Family Planning Bureau, which oversees population control, launched what it termed an “Iron Fist Campaign,” targeting 10,000 women who had more than one child…continue reading…
I’m stunned that von Storch actually published that comment. I can’t believe it. Surely he was being cynical. The world is on its head today.
 

Share this...FacebookTwitter "
"
When you think of NASA and crashes, you think of things like this:

But, you usually don’t think about government balloon crashes being “dramatic”, unless of course it’s a balloon crash in Roswell, NM in 1947.
Watch this video from Australia’s ABC:
A huge NASA balloon loaded with a telescope painstakingly built to scan the sky at  wavelengths invisible to the human eye crashed in the Australian outback Thursday,  destroying the astronomy experiment and just missing nearby onlookers, according to  Australian media reports.
In dramatic video released by the Australian  Broadcasting Corporation (ABC),  the giant 400-foot (121-meter) balloon is seen just beginning to lift its payload,  then the telescope gondola appears to unexpectedly come loose from its  carriage. The telescope crashes through a fence and overturn a nearby parked sport  utility vehicle before finally stopping.
Video via Space.com/Yahoo News:

Fortunately, nobody was hurt, but as you can see in the video, it was a close call.
h/t to Steve Goddard


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c3254af',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterGerman site CO2 Handel here writes about a survey on the sentiment of Germans with regards to climate change and their will to do something about it.
It’s no surprise that a vast majority of Germans believe that man is profoundly changing the climate. The major media outlets feed Germans with a constant stream of climate doom & gloom, and rarely mention science that shows otherwise.
But what is surprising is the number of Germans who say they do not plan to change their lifestyles at all “to save the climate”. They agree that something has to be done to protect the climate, but they are not willing to make any sacrifices. CO2 Handel writes:
Two thirds (66 perecent) in a survey for Hamburg-based news magazine Stern declared that they would not do more for climate protection today than before.”
The survey also shows, despite the media bombardment of dire climate prognoses, that Germans are not afraid of a climate catastrophe.
Only 31 percent fear dramatic consequences for nature and environment (women 36 percent).”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




A huge number are skeptical that governments will be able to stop climate change.
According to the Stern survey, 84 percent do not believe the goverments will be able to stop climate change.
And these 84% should continue to believe this, because climate change cannot be stopped. Anyone who claims it can is nothing less than a huge charlatan. That means 16% are completely duped and actually believe that the UN and IPCC can control the climate. Talk about utter ignorance.
If the survey says anything, it is that even if you do manage to convince the population, it doesn’t mean they are going to agree to make sacrifices. So, good luck in implementing climate protection policies in countries with high levels of skepticism. First you have to stop the growing trend of skepticism, then you have to convert their beliefs, and then you’ll have to convince them to make sacrifices, which is the hardest thing to do.
The survey was based on 1001 representatively chosen German citizens on December 1 – 2, 2011 . The margin of error is : ± 3%. The survey was conducted by Forsa, for Stern.
Not surprisingly, the major media outlets buried the survey results.
 
Share this...FacebookTwitter "
"

Well the Telegraph article on rationing our modern lifestyle to reduce CO2 has made some waves since I covered it yesterday, fortunately it has not affected the attendees at Cancun. See the video below.




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e86a78c53',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterWhile reps from European countries are in Durban demanding we go green, CO2 Handel here reports that the very same governments are cutting back on “climate protection” investments. That makes Durban a farce.
According to a report called Durban Dynamics: Navigating for progress on climate change“, by consultancy Ernst & Young, governments around the world are drastically cutting back their investments in climate protection. In the worst case up to $45 billion are planned to be cut from environmental protection measures. The reason they say is the global financial mess.
Now if these investments were truly as lucrative as many like to claim they are, why on Earth would they cut back on them? The answer is obvious: That green energy is lucrative is a lie. It’s been a scam from the first day.

CO2 Handel writes:
If one sums up the already decided savings measures, then a you get a cut of $22.5 billion. ‘If the debt crisis continues to escalate and countries should then become forced to pass additional comprehensive savings measures, then in the worst case that number may double.’ said Peter Nolden, Partner at Ernst & Young.
Strangely, the lion’s share of these cuts is taking place in Europe, the very continent that constantly preaches the global warming doctrine and insists the rest of the world do as it says.  Germany already plans $2 billion less investment in “climate change fighting” projects by 2015. Bankrupt Spain, once a champion in solar energy, is cutting back a whopping $5.1 billion and Great Britain will cut back $4.2.
If push comes to shove (and with the financial situation progressing as it is, that’s very likely) then “the German government in the worst case will cut $8.3 billion in climate costs,” writes CO2 Handel. Other countries to make cuts: USA $6.4 billion and Japan $6.1 billion.
I financial crisis means that fiscal discipline needs to be exercised. Of course you cut out what is wasteful. Do you think the greens have ever wondered why Europe and the US find themselves flat broke? Refusing to heed reality has something to do with that.
 

Share this...FacebookTwitter "
"Christiana Figueres, the Costa Rican diplomat who was an architect of the worldwide Paris climate agreement, is enraged. She thinks you should be too. She was traveling in 2017 when Donald Trump made plans to announce the US withdrawal from the pact. Perched at the end of her hotel bed with pen and paper, she decided to write down each correct statement she heard.  “The speech finished and my piece of paper was completely blank,” Figueres told the Guardian in an interview. “There was not a sentence uttered in that whole speech that was correct, true or even informed.” With tiny silver frogs dangling from her ears and strung around her neck, the small-framed Figueres is animated as she recalls the story, alternately pushing back in her chair and lowering her head toward her crossed arms. Trump gave his remarks in the White House Rose Garden, a venue typically reserved for major events. “My first thought was the poor roses, they had to listen to all this,” Figueres said. Figueres, who was executive secretary of the UN Framework Convention on Climate Change, could easily be swallowed up by her anger at the intensifying climate crisis. But instead she has become an advocate for positivity about climate action. Despite Trump’s planned withdrawal, not a single nation has followed suit. Countries that agreed to the Paris deal, however, are not on track to fulfill their obligations. And, even if they were, their actions wouldn’t be enough to stall significant global warming. Figueres and her former senior advisor Tom Rivett-Carnac, who was once a Buddhist monk, have written a book they pitch as “surprisingly optimistic”. It’s titled The Future We Choose: Surviving the Climate Crisis, and it offers two contrasting visions for how the world might look in 30 years. They also have a podcast, called Outrage and Optimism. Rivett-Carnac said people can be upset and positive at the same time. “We see this form of stubborn optimism as a way of changing the world,” he said. It’s not like we wake up every morning thinking, ‘everything’s ok, don’t worry.’” Figueres argues that society is “paralyzed and obsessed about the consequences of climate change,” and hasn’t been able to separate that fear from the upsides of cutting the fossil fuel and other emissions heating the planet. She lists the possible benefits: stronger economies, energy independence, a livable environment, breathable air, less time wasted commuting, improved health, an increased connection to nature, and “on and on,” she says. Trump believes the Paris deal would sink the US economy. In Figueres’ mind, if there was any country aware of the growth opportunities from addressing the climate crisis, it was the US. “There was hardly any country that had actually gone into such an analysis of the text,” she said. “Frankly, there was barely a country that contributed as much to the text … It’s very sad when you basically cut your nose off to spite your face.” She said “the sad thing is that the US has become irrelevant in the most consequential challenge that humanity has faced,” clarifying that she meant the federal government, and not the states, localities and businesses that have stepped up to make their own pledges in its place. The book and podcast come as eco-anxiety is growing, particularly among younger people. Nearly half of US adults under the age of 35 say stress about climate change affects their lives, according to a poll by the American Psychological Association. Among all adults, seven in 10 say they wish they could do more to combat climate change, but 51% say they don’t know where to start. Figueres wants those people to take their power back. “We would say what makes you feel better quickly is actually to engage in a positive contribution so that you bust through this myth that individual actions don’t count And you begin to realize the world is only made out of individual actions,” she said. “It does count. It does add up.”"
"
Share this...FacebookTwitterI’d like to recommend the German Energy Blog to readers who’d like to know the latest about German energy news and issues. You may want to bookmark it.

German Energy Blog
Their latest article presents a resource called 50Hz:
Friday last week 50Hertz Transmission GmbH, the transmission system operator (TSO) whose grid covers large parts of Eastern and Northern Germany, started publishing the load flow data for its grid on the internet. It is the first TSO in Germany to do so.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Visitors of the web pages shall find an up-to-date map of the grid showing all power lines and interconnectors with other transmission grids. Network conditions shall be shown for the full hour. For a better understanding the lines shall be coloured depending on the specific load flow. Upon clicking on a power line, the load shall be given in megawatt (MW). The information is supplemented by data regarding special measures to secure system stability, i.e. …” (Continue reading)
It would be nice if all grid operators offered this service.
Especially the 50HZ Grid Data page offers up-to-date, interesting data on energy feed-in, etc.. For example here is photovoltaic feed-in for the last 24 hours:

Source: http://www.50hertz.com/en/2805.htm.
 
Share this...FacebookTwitter "
"
Steve Goddard writes:
Below are  animations for the entire year (150 days) so far, based on NOAA SST maps. The  videos are presented with minimal commentary. As they say, “150  pictures are worth 150,000 words.”

El Niño has faded and may be switching genders.

The Northern Pacific has been generally below average.

The tropical Atlantic has warmed significantly over the year, heading in  to the hurricane season.

The ocean just south of Greenland has been persistently above average  temperatures.

Antarctic waters have been getting colder, which is reflected in the  growth of ice.

Arctic waters have been warm on the Atlantic side, and cold on the  Pacific side. This is reflected in excess ice near Alaska and  deficiencies near Greenland and Svalbard.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b287ff1',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"
You know, in science, there was once this thing we called the Theory of Multiple Working Hypotheses.  Anathema (a formal ecclesiastical curse accompanied by excommunication) in modern climate science.  So, in juxtaposition to the hypothesis of future global climate disruption from CO2, a scientist might well consider an antithesis or two in order to maintain ones objectivity.
One such antithesis, which happens to be a long running debate in paleoclimate science, concerns the end Holocene.  Or just how long the present interglacial will last.
Looking at orbital mechanics and model results, Loutre and Berger (2003) in a landmark paper (meaning a widely quoted and discussed paper) for the time predicted that the current interglacial, the Holocene, might very well last another 50,000 years, particularly if CO2 were factored in.  This would make the Holocene the longest lived interglacial since the onset of the Northern Hemisphere Glaciations some 2.8 million years ago.  Five of the last 6 interglacials have each lasted about half of a precession cycle.  The precession cycle varies from 19-23k years, and we are at the 23kyr part of the range now, making 11,500 years half, which is also the present age of the Holocene.
Which is why this discussion has relevance. 
But what about that 6th interglacial, the one that wasn’t on the half-precessional “clock”.  That would be MIS-11 (or the Holsteinian) which according to the most recently published estimate may have lasted on the order of 20-22kyrs, with the longest estimate ranging up to 32kyrs.
Loutre and Berger’s 2003 paper was soon followed by another landmark paper by Lisieki and Raymo (Oceanography, 2005), an exhaustive look at 57 globally distributed deep Ocean Drilling Project (and other) cores (Figure 1), which stated:
“Recent research has focused on MIS 11 as a possible analog for the present interglacial [e.g., Loutre and Berger, 2003; EPICA community members, 2004] because both occur during times of low eccentricity.  The LR04 age model establishes that MIS 11 spans two precession cycles, with 18O values below 3.6o/oo for 20 kyr, from 398-418 ka.  In comparison, stages 9 and 5 remained below 3.6o/oo for 13 and 12 kyr, respectively, and the Holocene interglacial has lasted 11 kyr so far.  In the LR04 age model, the average LSR of 29 sites is the same from 398-418 ka as from 250-650 ka; consequently, stage 11 is unlikely to be artificially stretched.  However, the June 21 insolation minimum at 65N during MIS 11 is only 489 W/m2, much less pronounced than the present minimum of 474 W/m2.  In addition, current insolation values are not predicted to return to the high values of late MIS 11 for another 65 kyr.  We propose that this effectively precludes a ‘double precession-cycle’ interglacial [e.g., Raymo, 1997] in the Holocene without human influence.”
 


Figure 1.  The past 5 million years of climate from 57 globally distributed sediment cores.  (a general definition of an interglacial since the MPT is the oxygen 18/oxygen 16 isotope ratio must drop to 3.6 parts per mil)

To bring this discussion up to date, Tzedakis (Figure 2, his figure 3), in perhaps the most open peer review process currently being practiced in the world today (The European Geosciences Union website Climate of the Past Discussions) published a quite thorough examination of the state of the science related to the two most recent interglacials, which like the present one, the Holocene (or MIS-1) is compared to MIS-19 and MIS-11, the other two interglacials which have occurred since the Mid Pleistocene Transition (MPT) and also occurred at eccentricity minimums.  Since its initial publication in 2009, and its republication after the open online peer review process again in March of this year (2010), this paper is now also considered a landmark review of the state of paleoclimate science.  In it he also considers Ruddiman’s Early Anthropogenic Hypothesis, with Ruddiman a part of the online review.  Tzedakis’ concluding remarks are enlightening:
“On balance, what emerges is that projections on the natural duration of the current interglacial depend on the choice of analogue, while corroboration or refutation of the “early anthropogenic hypothesis” on the basis of comparisons with earlier interglacials remains irritatingly inconclusive.”
Figure 2. Tzedakis (2010) comparing the Holocene with the previous 4 interglacials.
An astute reader might have gleaned that even on things which have happened, the science is not that particularly well settled.  Which makes consideration of the science being settled on things which have not yet happened dubious at best.
As we move further towards the construction of the antithetic argument, we will take a closer look at the post-MPT end interglacials and the last glacial for some clues.
Higher resolution proxy studies from many parts of the planet suggest that the end interglacials may be quite the wild climate ride from the perspective of global climate disruption.
Boettger, et al (Quaternary International 207 [2009] 137–144) abstract it:
“In terrestrial records from Central and Eastern Europe the end of the Last Interglacial seems to be characterized by evident climatic and environmental instabilities recorded by geochemical and vegetation indicators.  The transition (MIS 5e/5d) from the Last Interglacial (Eemian, Mikulino) to the Early Last Glacial (Early Weichselian, Early Valdai) is marked by at least two warming events as observed in geochemical data on the lake sediment profiles of Central (Gro¨bern, Neumark–Nord, Klinge) and of Eastern Europe (Ples).  Results of palynological studies of all these sequences indicate simultaneously a strong increase of environmental oscillations during the very end of the Last Interglacial and the beginning of the Last Glaciation. This paper discusses possible correlations of these events between regions in Central and Eastern Europe.  The pronounced climate and environment instability during the interglacial/glacial transition could be consistent with the assumption that it is about a natural phenomenon, characteristic for transitional stages. Taking into consideration that currently observed ‘‘human-induced’’ global warming coincides with the natural trend to cooling, the study of such transitional stages is important for understanding the underlying processes of the climate changes.”
Hearty and Neumann (Quaternary Science Reviews 20 [2001] 1881–1895) abstracting their work in the Bahamas state:
“The geology of the Last Interglaciation (sensu stricto, marine isotope substage (MIS) 5e) in the Bahamas records the nature of sea level and climate change.  After a period of quasi-stability for most of the interglaciation, during which reefs grew to +2.5 m, sea level rose rapidly at the end of the period, incising notches in older limestone.  After brief stillstands at +6 and perhaps +8.5 m, sea level fell with apparent speed to the MIS 5d lowstand and much cooler climatic conditions. It was during this regression from the MIS 5e highstand that the North Atlantic suffered an oceanographic ‘‘reorganization’’ about 118.73 ka ago.  During this same interval, massive dune-building greatly enlarged the Bahama Islands.  Giant waves reshaped exposed lowlands into chevron-shaped beach ridges, ran up on older coastal ridges, and also broke off and threw megaboulders onto and over 20 m-high cliffs. The oolitic rocks recording these features yield concordant whole-rock amino acid ratios across the archipelago.  Whether or not the Last Interglaciation serves as an appropriate analog for our ‘‘greenhouse’’ world, it nonetheless reveals the intricate details of climatic transitions between warm interglaciations and near glacial conditions.” 
See Figure 3 (also figure 3 in their study)
Figure 3. Rapid Sea Level Spike at the end of MIS-5, the Eemian.
and Figure 4 (figure 5 in their study).



Figure 4. The MIS-5e notch (photo A) and modern notch (photo B) (Hearty and Neumann, 2001, figure 5).


The picture which emerges is that the post-MPT end interglacials appear to be populated with dramatic, abrupt global climate disruptions which appear to have occurred on decadal to centennial time scales.  Given that the Holocene, one of at least 3, perhaps 4 post-MPT “extreme” interglacials, may not be immune to this repetitive phenomena, and as it is half a precession cycle old now, and perhaps unlikely to grow that much older, this could very well be the natural climate “noise” from which we must discern our anthropogenic “signal” from.
If we take a stroll between this interglacial and the last one back, the Eemian, we find in the Greenland ice cores that there were 24 Dansgaard-Oeschger oscillations (Figure 5, originally figure 1. Sole et al, 2007), or abrupt warmings that occurred from just a few years to mere decades that average between 8-10C rises (D-O 19 scored 16C).  The nominal difference between earth’s cold (glacial) and warm (interglacial) states being on the order of 20C.  D-O events average 1470 years, the range being 1-4kyrs.
Figure 5. Dansgaard-Oeschger oscillations with their cycle designations. (Sole et al, 2007)
Sole, Turiel and Llebot writing in Physics Letters A (366 [2007] 184–189) identified three classes of D-O oscillations in the Greenland GISP2 ice cores A (brief), B (medium) and C (long), reflecting the speed at which the warming relaxes back to the cold glacial state:
“In this work ice-core CO2 time evolution in the period going from 20 to 60 kyr BP [15] has been qualitatively compared to our temperature cycles, according to the class they belong to.  It can be observed in Fig. 6 that class A cycles are completely unrelated to changes in CO2 concentration.  We have observed some correlation between B and C cycles and CO2 concentration, but of the opposite sign to the one expected: maxima in atmospheric CO2 concentration tend to correspond to the middle part or the end the cooling period.  The role of CO2 in the oscillation phenomena seems to be more related to extend the duration of the cooling phase than to trigger warming. This could explain why cycles not coincident in time with maxima of CO2 (A cycles) rapidly decay back to the cold state. ”
“Nor CO2 concentration either the astronomical cycle change the way in which the warming phase takes place.  The coincidence in this phase is strong among all the characterized cycles; also, we have been able to recognize the presence of a similar warming phase in the early stages of the transition from glacial to interglacial age.  Our analysis of the warming phase seems to indicate a universal triggering mechanism, what has been related with the possible existence of stochastic resonance [1,13, 21].  It has also been argued that a possible cause for the repetitive sequence of D/O events could be found in the change in the thermohaline Atlantic circulation [2,8,22,25].  However, a cause for this regular arrangement of cycles, together with a justification on the abruptness of the warming phase, is still absent in the scientific literature.”
Figure 6. Sole et al (2007) D/O oscillation classes.
In their work, at least 13 of the 24 D-O oscillations (indeed other workers suggest the same for them all), CO2 was not the agent provocateur of the warmings but served to ameliorate the relaxation back to the cold glacial state, something which might have import whenever we finally do reach the end Holocene.  Instead of triggering the abrupt warmings it appears to function as somewhat of a climate “security blanket”, if you will.
Therefore in constructing the antithesis, and taking into consideration the precautionary principle, we are left to ponder if reducing CO2’s concentration in the late Holocene atmosphere might actually be the wrong thing to do.
The possibility consequently exists that at perhaps precisely the right moment near the end-Holocene, the latest iteration of the genus Homo unwittingly stumbled on the correct atmospheric GHG recipe to perhaps ease or delay the transition into the next glacial.  Under the antithesis “Skeptics” and “Warmists” thus find themselves on the mutual, chaotic climate ground where the efficacy of CO2 as a GHG had better be right.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e85f9cb45',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterNo surprise here. Just more inconvenient results for CO2 broken-record dogmatists.
New paper: GISS temps and solar activity
A recent paper published by the Journal of Atmospheric and Solar Terrestial Physics (74) 2012 87-93 and authored by Souza Echer et al. suggests that solar cycles, to a substantial extent, drive global temperatures, and that likely through amplification mechanisms.
Solar particles interact with Earth’s magnetosphere. (Source: NASA)
 
The paper is titled: On the relationship between global, hemispheric and latitudinal averaged air surface temperature (GISS time series) and solar activity.
The authors decomposed average air surface temperature series obtained from GISS and sunspot number (Rz) from 1880 – 2005 to see if a correlation could be found. They performed a cross correlation analysis between band-passed filtered data around 11-year and 22 years.
Although the authors did not find a strong correlation with the 11-year solar cycle, they found a “very significant correlation” in the 22-year Hale cycle band. The abstract states:
A very significant correlation (Rz 0.57 to 0.80) is found in the 22 yr solar Hale cycle band (16–32 years ) with lags from zero to four years between latitudinal averages air surface temperature and Rz. Therefore it seems that the 22 yr magnetic field solar cycle might have a higher effect on Earth’s climate than solar variations related to the 11-yr sunspot cycle.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Well then, can we not assume that if the 22-year cycles have an impact, also the 78-year, 210-year, and 1000-year solar activity cycles must have a “significant correlation” with the earth’s climate too? Already there are dozens of proxy records showing that this is precisely the case.
Recall that the CO2 warmists in their half-baked models stubbornly keep focusing only on total solar irradiance (TSI), which itself varies only about 0.1% over an 11-year cycle (and thus by itself is no real climate driver) and ignore all the other amplification mechanisms. Well, the results of this study, as do dozens of others studies, show you can’t do that. Like it or not – the sun is a real player. Eventually the CO2 warmists will have to admit this, as anyone with even just an inkling of intuition would do.
New paper: investigating the cosmic ray link
Obviously there are others who feel the same way when it comes to the role of the sun on the earth’s climate. Another paper just published at the same journal shows that other scientists are hot on the sun’s trail. Here Magee and Kavic in their paper titled: Probing the climatological impact of a cosmic ray–cloud connection through low-frequency radio observations suspect a solar mechanism and so propose a method of observation. In the abstract they write:
…in order to establish whether or not such a relationship exists, measurements of short-timescale solar events, individual cosmic ray events, and spatially correlated cloud parameters could be of great significance. Here we propose such a comparison using observations from a pair of radio telescopes arrays,the Long Wavelength Array (LWA) and the Eight-meter-wavelength Transient Array (ETA). These low-frequency radio arrays have a unique ability to simultaneously conduct solar, ionospheric and cosmic rays observations and are thus ideal for such a comparison.”
The direction of climate science and investigation is clear. The real discoveries will involve unraveling the solar mechanisms, and not baking simplistic, straight-line CO2-temperature models. With each new study, the CO2 warmists look more and more like broken records that keep repeating: CO2…CO2…CO2…CO2…
Obviously some scientists just aren’t clever enough to snap out of it.
Additional resources:
http://climaterealists.com/attachments
 
Share this...FacebookTwitter "
"
I don’t actually have this title category, I just invented the title in honor of what I just stumbled across flipping through channels on DirecTV. I landed on the History Channel. Egads! Some diving guys on a boat haul around some scientist with a “magnetic anomaly detector”, which looks like a Radio Shack electronics kit gone bad, and are looking for black holes (yes the gravitational kind) in the Bermuda Triangle. Yes, really.
Here’s the DVD you can buy from the History Channel.

And here’s the program description:
Explore with us the wonders and mysteries of the Black Holes in our  universe. Is it possible that areas on earth might, in fact, show black  hole like tendencies?

We take a hard scientific look at an area  known as the Bermuda Triangle to see if there are indeed any  similarities between the supposed forces in the triangle and the  destructive force of a black hole.
From a research boat trip  through the triangle to interviews with scientists at the US Geological  Survey, Harvard University, and the UK’s Cardiff University, we go far  beyond the event horizon to explore the dangers in this area and what  relation they might indeed have with its counterpoint in space.
===================================
There’s a line in the TV show where they say “…there’s no question that the climate can change suddenly around the Bermuda triangle”…so for these folks, I guess weather is climate. *Sigh* God help us.
The poor chumps at these prestigious organizations they brought in as experts probably had no idea that they’d appear in a dreckumentary that has the crew of the Minnow looking for black holes under the sea in the Bermuda triangle.
Of course the History Channel also shows “Life after people” and Gore’s “An Inconvenient Truth“…so I suppose crap like black hole hunting in the Bermuda Triangle fits right in.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8815c7b5',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

The British government released the Stern Review on global warming by Nicholas Stern, a former chief economist for the World Bank. As an economist, I tend to leave this topic to my Cato Institute colleague Pat Michaels, a professor of Environmental Sciences at the University of Virginia. Since Mr. Stern is also an economist, however, the rules of logic and evidence that economists use should also apply to this report. 



“Economic forecasting over just a few years is a difficult and imprecise task,” the review cautions, so forecasting technology a hundred years from now “requires caution and humility.” Unfortunately, there is little caution or humility in this report. 



The 27‐​page summary begins by saying, “The current level of greenhouse gases in the atmosphere is equivalent to around 430 parts per million (ppm) CO2, compared with only 280 ppm before the Industrial Revolution. These concentrations have already caused the world to warm by more than half a degree Celsius.” 



More specifically, that 54 percent increase of greenhouse gases was apparently associated with a warming of only 0.6 degrees Celsius, give or take two‐​tenths. Citing a 2001 survey of “high projections” for global warming, however, the report claims that a much smaller, 28 percent increase in greenhouse gases by the year 2050 could result in a “global average temperature rise” exceeding 2 degrees. 



Yet if we use the same rule‐​of‐​thumb now used to predict 2 to 3 degrees more global warming by 2050, the much larger increase in greenhouse gases ever since 1750–1850 should already have increased the average global temperature by at least 2 degrees. But it didn’t. 



Suppose this theory works this time, and the Earth actually warms by 2 to 3 degrees Celsius, putting aside what it means to average Chicago’s winters with Key West’s summers. The Stern report reluctantly concedes that places like Canada, Russia and Scandinavia would likely experience “higher agricultural yields, lower winter mortality, lower heating requirements and a possible boost to tourism.” 



Plants thrive in greenhouses, particularly fruits and vegetables. The report claims biodiversity would be at risk, as though no threatened species could possibly benefit from milder winters. 



And the report thinks malaria would increase, as though mosquitoes are picky about the climate. My great‐​grandfather J. Mason Reynolds died of malaria in Grand Rapids, Mich., in 1891. 



Naturally, The Washington Post seized this opportunity to complain that “Bush has declined to sign the 1997 Kyoto Protocol.” Yet the United Nations just reported that from 2000 to 2004 greenhouse gas emissions increased 4.6 percent in Canada, 2.4 percent in Europe and 1.3 percent in the United States. Besides, as the Stern report notes, “most future emissions growth will come from today’s developing countries, because of their more rapid population and GDP growth and their increasing share of energy‐​intensive industries.” 



As I have often noted, passenger cars are not nearly as large a share of greenhouse emissions as people think. In fact, this report’s first graph shows transportation accounting for less than 14 percent of greenhouse gas emissions — the same share as agriculture or industry. Trucks, buses and cars account for less than 10 percent of global greenhouse gas emissions. Electricity is a much bigger offender, which must be why Hollywood lefties are infatuated with electric cars. 



Two contradictory dogmas of the anti‐​auto cult are that consumption of fossil fuels will continue to increase just as rapidly as it has in the past and that fossil fuels will become increasingly expensive because we have passed the peak of oil. 



If the second prediction were correct, people would find ways to use less oil. Because some of Mr. Stern’s conclusions are “based on simple extrapolations,” however, he must and does argue that the world has “an abundant supply of fossil fuels.” Otherwise, we wouldn’t need thousands of international bureaucrats being bribed to decide which uses of fossil fuels are more meritorious than others, and which “alternative” fuels merit the biggest subsidies. 



Mr. Stern’s view of “sensible policies” involves a truly global system of high carbon taxes, tough regulations and generous subsidies “across both developed and developing nations.” Because “low‐​carbon technologies are currently more expensive than fossil‐​fuel alternatives,” he would heavily tax cheaper fuels and subsidize expensive ones. A high and “broadly similar price of carbon” throughout the world is apparently to be enforced in some way by the notoriously ineffectual United Nations and World Bank. 



The Washington Post described the Stern Review as proof that “failing to curb the impact of climate change could damage the global economy on the scale of the Great Depression or the world wars by spawning environmental devastation.” But such sensational comments about “worst‐​case scenarios” use strong words to conceal weak logic and nonexistent facts. 



For one thing, the disaster scenarios largely depend on unconvincing assertions pretending to link “extreme weather events” — such as “heat waves like that experienced in 2003 in Europe” — to extremely gradual and highly variable changes in the average temperature of many nations. The report says, “The risk of outcomes much worse than expected are very real and they could be catastrophic.” But any outcomes that are “very real” must to some extent be expected in a report claiming to deal in probabilities. And why is there no comparable assessment of outcomes much better than expected (such as the past 200 years)? 



There is repeated abuse of the old trick of switching from talking about things that could conceivably happen to things that would happen. Mr. Stern writes that “the temperatures that may result from unabated climate change would take the world outside the range of human experience.” 



The most widely reported conclusion of the Stern Review is that keeping a lid on greenhouse gases would cost “only” about 1 percent of world GDP (about $607 billion last year). Yet the fine print says the actual estimates “are clustered in the range of 2 percent to 5 percent of GDP,” with some estimating costs as high as 15 percent of GDP. 



There may be something truly informative and original concealed within the 700 pages of the Stern Review, but it does not appear as easy to find as the rough edges.
"
"**Police have been granted extra powers, including carrying out random vehicle checks, to ensure people are not breaking Covid-19 rules in Cardiff.**
South Wales Police said it would increase the numbers of officers on duty to encourage people to adhere to the rules.
The powers will be in place from 09:00 on Friday until 17:00 on Sunday.
People breaching regulations could be fined and told to leave the city, the force said.
Wales' ""firebreak"" lockdown ended on 9 November, allowing pubs, restaurants and non-essential retailers to reopen, with social-distancing measures in place.
People living in Wales could also travel anywhere in the country from this date, but travel to and from England, which is still in lockdown until Wednesday, is banned.
Supt Jason Rees said: ""The past few months have been difficult for us all, and with the rules having relaxed slightly, non-essential business reopening and Christmas just around the corner, it's understandable that people will want to get out and about and enjoy all our city has to offer.
""The vast majority are doing so with caution and within the confines of the existing regulations, but those not adhering to the rules are continuing to put others at increased risk.
""We are anticipating another busy weekend in our city centre, and while we will continue to adopt the policing style we have throughout the pandemic - working with the public to encourage voluntary compliance - we are committed to enforcing where blatant and flagrant breaches occur.""
North Wales Police said it had no special operation in place for the coming weekend but had an ""ongoing dedicated operation, which targets unlawful travel movement amongst other types of Welsh Government regulation breaches such as unlawful gatherings"".
In the run up to Christmas many of us would be heading out for drinks and catch-ups with friends and preparing for parties.
But under current coronavirus rules in Wales it is illegal to meet up with too many people, in a bid to curb the spread of the virus.
Mass gatherings and house parties are banned, while only groups from four different households are allowed to meet indoors at pubs, cafes and restaurants.
Pubs, bars and restaurants, gyms, and other businesses are also allowed to reopen, but with last orders at 22:00 GMT, there have been fears people may start going to each other's homes to drink.
There are no travel restrictions in Wales, as local lockdowns have ended - but people are being urged to consider whether they need to travel before setting off.
While England remains in lockdown - until 2 December - it is against the law to travel across the border, unless you have a reasonable excuse, such as providing care or for study or work (if you cannot from home).
Under the coronavirus fixed penalty notices system, people can be fined Â£60 for a first offence, which increases to Â£120 for a second offence and continues to double for repeated offences, up to a maximum of Â£1,920.
If prosecuted, however, a court can impose an unlimited fine."
"

How much in additional taxes are you willing to pay now in order to ensure that the Earth would not be 3 degrees warmer 100 years from now (assuming the science is even possible) — $100 or $1,000 or $10,000 or more? Should the government prevent us from selling some of our body parts to allow others to live or have better lives?



Are we likely to get better health care in the future with more or less government involvement? Are the advances in information technology, such as the Internet, increasing or reducing the power of governments to monitor and control our lives? Is the current global financial crisis the result of too little or misguided government regulation of the financial industry? Does globalization increase or reduce income inequality?



The above questions and many others were the subject of learned discussion at the 60th anniversary meeting of the Mont Pelerin Society (MPS) that just concluded here in Tokyo.



The Society was established in Mont Pelerin, Switzerland, by the late economist/​philosopher and Nobel Laureate F.A. Hayek, with the objective of facilitating “an exchange of ideas between like‐​minded scholars in the hope of strengthening the principles and practice of a free society, and to study the workings, virtues, and defects of market‐​oriented economic systems.”



The Society does not seek “to create an orthodoxy, to form or align itself with any particular party or parties, or conduct propaganda,” nor does it take in the name of the Society positions on public policy issues.



Members come from many countries and include notable economists (including many Nobel prize winners) and other scholars representing the humanities, the law, and the natural sciences, as well as a few business people, high ranking government officials, and journalists. Even though the Society is not an activist organization, many of its members have gone on to create think tanks and other market‐​oriented public policy organizations across the globe.



In contrast to much of the mindless sloganeering that characterizes most political campaigns these days, the members and guests of the Mont Pelerin Society seriously discuss and debate issues with a genuine attempt to understand the costs, benefits and consequences of alternative approaches.



As an example, global warning is an issue where members have different beliefs as to how real a threat it is or is not. The Czech president and MPS member, Dr. Vaclav Klaus, presented a paper in which he argued his very well‐​known public position (he has written a book on the matter) that the science behind global warming is highly suspect, and that many of those who propose expensive solutions for what he believes is a nonproblem are self‐​interested individuals who hope to share in the government booty spent on global warming.



Others had some disagreement with his views, but engaged in a lively discussion of how much should be spent, if any, on a problem whose negative effects are likely to be experienced by future generations.



For instance, assume you believe global warming is both real and man‐​made, but you also understand that expensive actions taken now to deal with a future problem may not be cost‐​effective.



Technologies are improving rapidly so it might be far cheaper to wait until the new technologies become available before taking action. It also might be less expensive to find ways to adapt to climate change (either cooler or warmer) than try to change the climate — people in Minnesota adapt to cooler climates and do not suffer lower incomes than those in warmer Florida.



Finally, people living 100 years from now are likely to be perhaps 10 times richer than those living now (which was roughly the experience of the last 100 years in many parts of the globe). Therefore, does it make sense to tax the poor (those living today) to benefit the rich (those living 100 years from now)?



In sum, when the issue of global warming is looked at dispassionately, both those who see it as a problem and those who do not might conclude it makes sense to wait before taking any expensive action, when normal discount rates — e.g. the cost of capital — are properly taken into account.



Another issue discussed was that of global financial regulation. The common belief, at least in the press and political classes, is that the current financial crisis has stemmed from too little bank regulation. However, knowledgeable and thoughtful scholars among MPS members provided evidence — which is counterintuitive to many — showing the present international bank regulatory standards may have been the problem rather than the solution.



When good scholars and other smart people come together from many countries and professions to present evidence and discuss issues without a narrow political agenda or government sponsorship, it is surprising how often sensible and cost‐​effective solutions can be found that enhance rather than diminish human liberty. The founders of the MPS, such as F.A. Hayek and Milton Friedman, were for the most part optimists. Their vision of a freer and more prosperous future for most of mankind was realized in their lifetimes.



Yet, as they well understood, the threat of oppressive governments and ideologies is never‐​ending and thus requires people of good will to be forever vigilant for freedom and prosperity to continue.
"
"
Share this...FacebookTwitterJoachim Gauck (Photo by J. Patrick Fischer)
Now that Christian Wulff has resigned in disgrace from the office of President of Germany in the wake of a scandal, a new nominee has been found: former pastor and anti-communist  Joachim Gauck. He is expected to be appointed easily.
If you’re like me, the question that comes to mind is: How skeptical is he when it comes to climate science? Surprisingly, there are signs for optimism.
First a bit of background from Wikipedia, my short version:
Endured brutal Soviet occupation
Joachim Gauck was born in Rostock in 1940, is a German politician, Protestant pastor, and former anti-communist human-rights activist in East Germany. His family was a victim of Soviet persecution. When Joachim Gauck was eleven years old, his father disappeared after being arrested by Soviet occupation forces. He was accused of espionage and deported to a Gulag in Siberia, where he was severely mistreated. For nearly three years, the family knew nothing about what had happened to him and whether he was still alive. Only in 1955, he was freed.
An “incorrigible anti-communist”
Gauck’s political activities were inspired by the ordeal of his father, and stated that he grew up with a well-founded anti-communism. In school in East Germany he made no secret of his anti-communist position, and he steadfastly refused to join the Free German Youth. He became a pastor in the Protestant church in Mecklenburg. His work as a pastor in East Germany was very difficult due to the hostility of the communist regime towards the church, and for many years, he was under constant observation and was harassed by the Stasi secret police.The Stasi described Gauck in their file on him as an “incorrigible anti-communist”.
“Tireless pro-democracy advocate”
During the Revolutions of 1989, he was a co-founder of the New Forum opposition movement in East Germany, which contributed to the downfall of the Soviet-backed dictatorship of the Socialist Unity Party of Germany (SED). Following the Reunification of Germany, he was elected by the Bundestag as the first Federal Commissioner for the Stasi Archives, serving from 1990 to 2000. As Federal Commissioner, he earned recognition as a “Stasi hunter” and “tireless pro-democracy advocate,” exposing the crimes of the former communist political police.
Gauck’s views today
Gauck today does not belong to any particular party. His views on an array issues are unknown. But perhaps some of his earlier comments can provide valuable clues.
According to the FAZ, Gauck is quoted as saying:
I’m unbelievably allergic to any politics that reacts to fear. This also applies to other issues, for example the use of nuclear power. We should refrain from forms of actions that are based on the fear of people and derive a dynamic from it.”
Surely he must be absolutely aware of the crude fear driving the global warming movement.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Sueddeutsche Zeitung here provides more interesting quotes and insights on controversial issues.
Occupy-Wall-Street movement
While the media found general praise for the protesters, Gauck had another opinion. He found it “inexpressibly absurd” that people were demonstrating against the unbridled power of the financial markets, and called the dream of a world that simply does away with markets a “romantic idea” and that it is mistake to think that it would be nice to conquer capital.
On the Stuttgart-21-mega rail station project
Here warned of a growing culture of protest. He characterized the German tendency to fall into hysteria and fear as “abhorrent”.
On Thilo Sarrazin
The politically incorrect Sarrazin dared to question multi-culturalism in Germany, Gauck said Sarrazin “showed courage” writing his controversial best-seller Deutschland schafft sich ab (Germany is going down the tubes). “He spoke about a problem that exists in our society more openly than the politicians.”
Climate change?
That’s the mystery – one that even has the warmists a bit worried and wondering. We do know he is no fan of fear and intimidation. A few hours with a good skeptic would probably suffice. The warmists such as Klimaretter have already researched Gauck and found little. That’s encouraging. If he felt half-strong about climate change, then he would have said something to support combating it. But if he disagrees with all the hysteria, and wished to avoid poking a hornets’ nest, then he would have remained silent. That is precisely what he has done on the issue.
Here’s what the warmist Klimaretter (Climate Rescuer) writes about Gauck:
The word “climate change” up to now has only appeared when he criticized the German’s so-called addiction to fear that he himself diagnosed and placed it, from his perspective, on a level with swine flu and e-coli.  Otherwise: a total blank. Gauck’s ecological plea: total silence.”
and,
Gauck, the President to be, is a contemplative man who is certainly ready to reconsider his own positions. Perhaps this will be true for his so far neglected “green” issues. One thing is clear: With this guy, the country will experience some surprises.”
Gauck appears to be a man of principle, integrity – someone who thinks policies have to be based on foundations of truth. The climate movement and its promises, like communism, are not; they are based on a plain lies and distortions. The movement is driven by fear and hysteria over scenarios 100 years in the future. This is not the sort of thing a man like Gauck readily embraces.
 
Share this...FacebookTwitter "
"**Families have been warned against hugging and kissing elderly relatives at Christmas ""if you want them to survive to be hugged again"".**
People ""just have to have sense"", said the UK government's chief medical adviser, Prof Chris Whitty.
Coronavirus rules announced this week mean three households can form a bubble and mix for five days over Christmas.
From 23 to 27 December, three households can mix indoors in homes, at a place of worship or outdoors.
The rules apply to the whole of the UK, although in Scotland the number of people who can be in the Christmas bubble is limited to eight.
And in Northern Ireland, the rules are relaxed from 22 to 28 December, to allow time to travel between the nations.
Speaking at a Downing Street press conference on Thursday, Prof Whitty - who revealed he would be ""on the wards"" over Christmas - said: ""Would I want someone to see their family? Of course, that's what Christmas is about.
""But would I encourage someone to hug and kiss their elderly relatives? No, I would not.
""It's not against the law - and that's the whole point. You can do it within the rules that are there, but it does not make sense because you could be carrying the virus and if you've got an elderly relative, that would not be the thing you'd want to do in the period where we are running up to a point where we actually might be able to protect older people.
""So I think people just have to have sense. The fact that you can do something - this is true across so many other areas of life - doesn't mean you should.""
Sir Patrick Vallance, the government's chief scientific adviser, added: ""It's not going to be a normal Christmas but if you want to make those connections with family, it has to be done in a way where you try and make sure that you don't increase the risk.
""I think hugging elderly relatives is not something to go out and do. It will increase the spread to a vulnerable population.""
Prof Whitty added: ""If you want them to survive to be hugged again.""
Prime Minister Boris Johnson also responded to the question about hugging elderly relatives, urging people to be ""common sensical"".
""Until the vaccine comes on stream, we are not out of the woods yet and we have to be very, very vigilant.""
Prof Whitty also said it was ""not a secret"" that Christmas would increase the risk of transmission.
""Take it really seriously during Christmas. Don't do stupid things. Don't do unnecessary things just because the rules say you can. Think sensibly.""
Scotland's First Minister Nicola Sturgeon has that said the ""default advice"" and ""safest position"" was still that people should avoid contact.
""Just because we are allowing people to meet up in a limited way does not of course mean people have to do so, and people should not feel under pressure to do so,"" she said.
The government's official guidance on Christmas bubbles advises people with loved-ones who are vulnerable advises to take personal responsibility to limit the spread of the virus.
The NHS considers anyone 70 and over as ""clinically vulnerable"" and at moderate risk from coronavirus.
The government guidance also has specific advice for people considered extremely vulnerable, as well as care home residents.
It suggests forming a Christmas bubble is ""a personal choice"" for extremely vulnerable people, while those in care homes should only visit families if they are of working age.
Under the government's rules, the three households must be fixed, so you will not be able to mix with two households on Christmas Day and two different ones on Boxing Day. Households in your Christmas bubble can't bubble with anyone else.
Scotland has announced that the bubbles of three households should contain no more than eight people - but children under 12 are exempt.
People who are self-isolating should not join a Christmas bubble. If someone tests positive, or develops coronavirus symptoms up to 48 hours after the Christmas bubble last met, everyone will have to self-isolate."
"**There have been more than 1.6 million confirmed cases of coronavirus in the UK and about 60,000 people have died, government figures show.**
However, these figures include only people who have died within 28 days of testing positive for coronavirus and other measures suggest the number of deaths is higher.
**Find out how the pandemic has affected your area and how it compares with the national average:**
If you can't see the look-up click here.
After the first peak in April, cases started rising again in July, with the rate of growth increasing sharply in September and October, before falling again in the past two weeks.
On Wednesday, the government announced a further 16,170 confirmed cases.
It is thought the infection rate was much higher during the first peak in spring, but testing capacity at the time was too limited to detect the true number of daily cases.
The data for cases can also be broken down by region and comparing the change in those figures by week gives a sense of where there has been a recent increase in newly-reported infections.
Coronavirus infections in England have fallen by about a third during lockdown, according to a major study carried out by Imperial College London.
While some of the worst-hit areas saw the biggest improvements, cases have remained relatively high across England, according to the React-1 study, which is based on tests of more than 100,000 people between 13-24 November.
The latest figures from the Office for National Statistics (ONS), suggest about one in 185 (16,400 people) in Wales had the virus in the week ending 21 November.
In Northern Ireland rates are thought to be decreasing at around one in 145 people (about 12,700 people), while in Scotland, the figure was one in 115 (about 45,700 people).
The average number of daily deaths began to rise again in September, following the first peak in April.
On Wednesday, the government announced a further 648 deaths.
Of these, 555 deaths were in England, 51 in Wales, 38 in Scotland, and four in Northern Ireland.
Rules were amended over the summer to include deaths in the coronavirus total only if they occurred within 28 days of a positive test. Previously in England, all deaths after a positive test were included.
England has seen the majority of UK deaths from Covid-19. Using the 28-day cut-off, there have been more than 52,000.
Although hospital admissions for Covid-19 remain below the levels seen in the spring, there are big regional disparities.
The North West, North East and Yorkshire, and Midlands have seen the highest number of admissions but the situation in all three now appears to be improving.
Cases have risen across large parts of England, with other spikes in areas of Scotland, Wales and Northern Ireland.
The red areas on the map below are those currently seeing the highest number of cases per 100,000 people.
Restrictions have been tightened across the UK in an effort to tackle the number of rising cases.
In England, each local authority has been placed in one of the new three tiers following the end of the recent national lockdown.
Wales has announced a range of further measures, including a ban on pubs, restaurants and cafes serving alcohol, from Friday 4 December.
In Northern Ireland, a further two-week ""circuit-break"" lockdown began on 27 November.
Scotland has a five-tier system of alert levels with different measures in place in different parts of the country.
UK leaders have agreed to allow up to three households to meet indoors during a five-day Christmas period of 23-27 December.
When looking at the overall death toll from coronavirus, official figures count deaths in three different ways.
Government figures count people who died within 28 days of testing positive for coronavirus.
But there are two other measures.
The first includes all deaths where coronavirus was mentioned on the death certificate, even if the person had not been tested for the virus. The most recent figures suggest there had been almost 70,000 deaths by 20 November.
The second measure counts all deaths over and above the usual number at the time of year - that figure was more than 75,000 by 20 November.
The most recent figures available from the ONS are for the third week of November, which show there were 14,276 deaths registered in the UK.
Some 3,038 of these deaths involved Covid-19 - 199 more than the week before.
Deaths normally do rise at this time of the year, but the data from the ONS and its counterparts in Scotland and Northern Ireland show the second wave of the virus has pushed the death rate above the average seen over the past five years by about 21%.
Overall, the figures are still well below the peak of 9,495 deaths recorded in a week, reached on 17 April.
The ""R number"" is the average number of people an infected person will pass the disease on to.
If R is below one, then the number of people contracting the disease will fall; if it is above one, the number will grow.
The government's current estimate for the R number across the whole of the UK is 0.9 to 1.
The estimate for England is 0.9 to 1, while for Scotland it is 0.8 to 1. The estimate for Wales is 0.8 to 1 and in Northern Ireland it is 0.9 to 1.1.
The government has said in the past that the R number is one of the most important factors in making policy decisions."
"We are living in an era of intense marine urbanisation. More and more artificial structures are being built in the seas and oceans and, while many aim to combat climate change through exploiting wind or tidal energy, there are concerns over what this means for marine ecosystems. Offshore wind farms can present barriers to bird migration, while for seals, tidal turbines present an increased level of underwater noise or collision risk.   On the other hand, there are some indications that introducing man-made structures leads to new opportunities for some animals. Marine life can settle on old oil rigs, turning them into artificial reefs. Fish can seek refuge in their wake, while seals use structures as foraging sites. All of these environmental interactions need to be considered. That’s why we decided to investigate how turbulent wakes generated downstream from man-made structures can act as a form of “conveyor belt” for surface foraging seabirds, serving up a continuous stream of fish. Our results are published in the journal Communications Biology. Let’s rewind. Coastal waters are already very dynamic and complex marine habitats, characterised by headlands, islands or submerged rocks. Where strong tides rush past these features it can lead to turbulent swirls or eddies, including wakes left behind small islands, pier pillars or floating buoys.  Placing large offshore structures into such energetic environments can therefore change local flows, ranging from large sediment wakes behind offshore windfarms, to the emergence of distinct eddy-dominated wakes spanning tens to hundreds of meters behind tidal turbines. Where you see such turbulence, the chances are you see seabirds too. Seabirds scan the waters for conspicuous turbulent patches as there could indeed be something in the water. In fact, these turbulent flows can break up shoals of small fish or even displace individual fish. This can make small prey items available to surface-foraging seabirds such as gulls and terns.  Often nicknamed “sea swallows”, terns are rather slender and elegant seabirds and will only skim the surface or perform very shallow plunges to access their fishy prey. They rely on strong physical processes, such as turbulence or upwelling, to bring prey towards the surface. To understand how terns associate with both natural and man-made wake structures, we set up a study in a highly dynamic tidal channel, linking Strangford Lough in Northern Ireland with the Irish Sea. This is where the UK’s first grid-connected tidal turbine energy structure, SeaGen, was installed in 2008. At the time of our study in the summer of 2018, SeaGen was being decommissioned and its turbine blades had been removed. But the remaining structure still generated a large, turbulent downstream wake, known as a von Kármán vortex street. We focused our observations around SeaGen’s wake as well as two nearby natural dynamic sites, an island wake and a whirlpool, with the latter characterised by powerful eddies and localised up-wellings. Over the next several weeks, we then sat on the shore and counted the numbers of seabirds we saw foraging over each of the three wake features across different times of day and tidal states. We found that, on average, there were three times more terns foraging over the flood wake left by SeaGen than over the nearby natural wake sites. This suggests that the former tidal power plant acted as the most reliable conveyor belt for their prey. What makes the wake a conveyor belt? Imagine tidal flows reaching five meters a second (that is double the top speed of the Olympic swimmer Michael Phelps) rushing past SeaGen. Any small fish caught in these currents would no longer be able to swim against the tide.  To observe this we mapped out the turbulent flows of the wake from below using sound waves, and then used drones to track individual tern flight trajectories from above. Acoustic visualisations showed that SeaGen’s eddy-dominated wake mixes material across the entire water column, lifting potential small prey items towards the surface. Using drones, we could record the highly localised foraging movements of terns directly over the turbulent wake, with the incoming tide constantly replenishing the conveyor belt. The remaining SeaGen tower is set to be removed this month. It may be replaced by a new generation of tidal devices currently being tested in the lough. But in the meantime, these birds will have to stick to natural foraging sites."
"**A bar where fans were filmed celebrating Scotland's Euro 2020 win in apparent breach of Covid rules has had its temporary licence extended.**
Jubilant fans cheered, danced and hugged at the Draft Project in Aberdeen as Scotland beat Serbia on penalties on 12 November.
Dozens of complaints were lodged.
Aberdeen's licensing board has now approved the occasional licence, subject to additional conditions including no televised sport.
There were three votes to approve the application but also three votes to refuse.
Board convener Marie Boulton's casting vote at Wednesday afternoon's meeting extended the temporary licence, which will be in operation until 4 December.
She described the scenes as a ""moment of madness"" and hoped people would have ""learned a lesson"".
A representative for PB Devco, the owner of the pop-up bar, said they appreciated the concern at the footage.
PB Devco also runs the nearby Soul Bar, where eight Aberdeen FC players visited in breach of the coronavirus rules earlier this year.
Scotland's 23-year absence from major men's tournaments ended with the victory over Serbia.
They will face England, Croatia and the Czech Republic in Group D at next summer's finals."
"**Hundreds of residents have joined together to support independent businesses with a social media click-and-collect service.**
Bristol's Gloucester Road is famous for its long strip of independent businesses which include greengrocers, butchers and toy shops.
The Shop Local Gloucester Road Facebook group was set up by mum Alice Darley and has become a ""lifeline"".
One business owner said the group has boosted her shop during lockdown.
Miss Darley opened the Facebook group to allow others to order items from the shops that didnât already have an online service.
""When lockdown came it became clear that there must be another way to shop locally,"" she said.
âIt's been a lifeline for traders and the community.â
Laura Sharp, assistant manager of zero-waste shop Preserve, said: âOur customers feel more comfortable shopping here than large supermarkets during the pandemic because it feels safer.
âWeâve had more customers during lockdown because of the Facebook group.
âIt also definitely brings Gloucester Road together as a community.â
Amy Osborne, the manager of Dave Giles Butchers which has been trading on Gloucester Road for 30 years, said the group had become essential to the strip of businesses.
She said: âThe Facebook group is becoming a lifeline for a lot of independent business here during the lockdown.
âFor a lot of businesses here this lockdown is going to be difficult so the Facebook group is important.â
Bristol wine shop Grape and Grindâs owner, Daren Willis, closed his shop temporarily in March.
He said: âWe were able to tick along online and on Facebook whilst the shutters were down.
âThe support for Gloucester Road is extraordinary.""
_Follow BBC West on_Facebook _,_Twitter _and_Instagram _. Send your story ideas to:_bristol@bbc.co.uk"
"
I’ve been proverbially “sick as a dog” this weekend either from stomach flu, or some food poisoning, not sure which. Spending so much time in bed, I almost forgot to put up my flag today. My neighbors must have wondered why this disheveled man with messed up hair and a three day beard was in a bathrobe out in front of my house this morning.

I put up my flag to remind myself, my family, and my neighbors how much we have to be grateful for, and how much we owe the people that have fought to keep our freedoms. Though lately, the war has changed from one of guns and bombs to one of bureaucracy and paper.
On the plus side, we could live here:

Nighttime satellite  photo of North and South Korea. Note the one light in North Korea.
There’s a great list on Listverse about the psychotic leader of North Korea: Top  10 Crazy Facts About Kim Jong Il
This one was a hoot:
The “Fact”: He is the best natural golfer in history
In 1994, it was reported by Pyongyang media outlets that Kim Jong Il  shot 38 under par on a regulation 18-hole golf course – including 5  holes in one!  That score is 25 shots better than the best round in  history, and is made even more amazing by the fact that it was his first  time playing the sport.  It’s said Kim Jong Il would routinely sink 3  or 4 holes in one per round of golf, and – lucky for the PGA – he has  since given it up.
He lies better than Tiger Woods, and that’s saying something.
I’m thankful we live in America, where if you hear a whopper like that, you can at least laugh about it without being executed.
I wonder if “Tamino” or Eli Rabbet bothers to fly a flag on memorial day? Here’s to hoping that they do.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b384083',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitter21:04 It’s there!
21:03: No earthquake so far here in Germany, no bright flashes – though we are having one heck of a shower right now – hopefully lightning will not knock out the power!
21.00 CET: Still no press release. Speculation has run wild since Friday.
20:57 CET: A few more minutes. Many of the climate science followers and bloggers are commenting over at Lucia’s Blackboard and McIntyre’s CA. McIntyre comments at LB that everyone should dial back expectations.
Share this...FacebookTwitter "
"

When I say “amyloid,” of course, almost everyone thinks of _beta‐​amyloid protein_ (also called “amyloid beta”), which accumulates as the waxy “senile plaques” that cluster around the brain cells of people with Alzheimer’s disease. 



–Aubrey de Grey, _Ending Aging: The Rejuvenation Breakthroughs  
That Could Reverse Human Aging in Our Lifetime_, p. 134



Aubrey de Grey is so deep into geek biogerontology that using “almost everyone thinks of” in the sentence quoted above does not strike him as rather generous. In reality, most of us are thinking “amyloid…amyloid…you’re talking about the singer, right? No, no…what am I saying…Wasn’t she the actress in that movie…?”



Four years ago, I reported that de Grey foresees a not‐​too‐​distant future in which humans can reverse the effects of aging, raising the possibility of living healthy lives for hundreds of years. He has not backed away from that position, and this book, written by de Grey and his research associate Michael Rae, represents an update from his perspective. In brief, he says that



As an economist, I am most interested–and most qualified to form an opinion about–the second point.



 **Accessible Metaphors**



De Grey makes state‐​of‐​the‐​art scientific issues accessible to an intelligent layman. He uses metaphors, as when he describes the role of mitichondria in terms of a power plant analogy (p. 53).



But while hydroelectric dams are (for the most part) environmentally benign, mitochondria are in one key aspect more like conventional power sources [in that they] create toxic wastes during the conversion of energy from one form to another…oxygen is also the sink for the electrons that are not fumbled–that are properly processed by the mitochondria–but that process loads _four_ electrons onto each oxygen molecule…Adding _one_ electron, by contrast, transforms benevolent oxygen into a particularly important free radical, superoxide. With your mitochondria generating ATP day and night continually, the ongoing formation of _superoxide_ is like having a constant stream of low‐​grade nuclear waste leaking out of your local reactor.



De Grey’s overarching metaphor is that the body is like a machine that, if properly maintained, can be kept running forever (p. 21).



we have hundred‐​year‐​old cars and (in Europe anyway!) thousand‐​year‐​old buildings still functioning as well as when they were built–despite the fact that they were not designed to last even a fraction of that length of time…the precedent of cars and houses gives cause for cautious optimism that aging can be postponed indefinitely by sufficiently thorough and frequent maintenance. 



However, maintenance of a car or a building often consists of replacement of components at a macro level. You replace whole tires and lightbulbs. You rip out a transmission or a kitchen and put in a new one.



What de Grey is talking about for humans is not macro replacement–giving you new organs or giving your cardiovascular system the equivalent of a transmission overhaul. Instead, he is talking about maintenance at a molecular level. For a car, it would be like having nanobots that repair corroded parts by reversing rust molecule by molecule. For a house, it would be like having shingles that when damaged by wind or wear are able to grow back to their original shape. 



**Internal Evolution at Work**



De Grey sees aging as a byproduct of an evolutionary process that takes place within the body. Mutations occur over time within your cells, sometimes randomly and sometimes stimulated by external events. This evolutionary process changes the balance between what I might call “good stuff” and “bad stuff” (here I am taking the technical caliber of the scientific exposition down several levels). Sometimes, the “good stuff” gets stronger, as when we develop an immunity to a disease. More often, however, the “good stuff” gets weaker and the “bad stuff” (like arterial plaque or pre‐​cancerous cells) gets stronger. It is this shift in the balance that leads to the symptoms of aging, including susceptibility to disease, which ultimately proves fatal.



Because aging is a natural outcome of the body’s internal evolutionary processes, de Grey argues that the standard paradigm for fighting the diseases of aging one by one is flawed. Prevention of one disease, in the form of slowing the processes that cause it, is a doomed strategy.



First, there is the fact that the processes that cause disease are the very processes that make life possible and enjoyable. The prevention paradigm amounts to lengthening the life of a car by keeping it in a dry, climate‐​controlled garage forever without ever driving it.



Second, there is the fact that if one age‐​related disease does not get you, then another one will. In my research into the causes of rising health care spending, I learned the sad truth that as we have achieved success in the battle against heart disease, we are increasing the chances that people will die of diseases like Parkinson’s or Alzheimer’s, with the result that expenditures on institutional care and full‐​time home care are soaring.



 **Only Seven Types of Damage**



De Grey argues that there are only about seven generic forms of damage, in which our body’s evolutionary processes cause it to lose “good stuff” or produce more “bad stuff” (again, those are my dumbed‐​down expressions). De Grey’s approach to reversing aging is to stimulate the body to throw out the bad stuff and grow more good stuff, maintaining a youthful balance.



For example, his approach to eradicate cancer is particularly radical. Cancer consists of “bad stuff” that has won the evolutionary battle and is now reproducing like gangbusters. He wants to make it impossible for _any_ type of cell to take over the internal ecosystem, so his proposal amounts to programming all cells to self‐​destruct after they reach an expiration date. Obviously, this creates a problem in that we need some of our cells to be able to last longer, or we will run out of “good stuff.” His solution is to use periodic stem cell implants to replenish our inventory of “good stuff.” Along the way, he makes a clear and compelling case that we need embryonic stem cell research.



(As an aside, I did not find his argument against the conventional cancer‐​fighting paradigm fully convincing. I find it more appealing to hope that there is a way to give every cell a “suicide pill” that it takes only if it recognizes that it is about to be captured by the cancer‐​enemy. Instead, killing off every cell, good or bad, and then trying to add new good cells strikes me as inelegant.



De Grey expresses the concern that when a conventional therapy goes after cancer (and the approach that appeals to me is more conventional), the laws of evolution suggest that a few cancer cells are likely to mutate and survive. Those that survive will be drug‐​resistant and therefore much more dangerous. However, I think that this is not like the mutation of germs, where a drug‐​resistant bacteria or virus can get started in one person’s body and continue to evolve somewhere else. The fact that a cancer cell evolves in my body to evade a particular drug does not make that drug any less effective in _your_ body. If your body is going to develop a drug‐​resistant form of that cancer, it is going to have to start from scratch. As a result, there may be a limited number of such mutations, and therefore we may need only a finite set of anti‐​cancer drugs. Of course, I have absolutely no expertise in this area. It is more likely that I misunderstand de Grey’s argument than that he is wrong.)



 **A Crash Course**



Too often, academics use their credentials to spit out biased polemics dressed up as science. _Ending Aging_ is the opposite. It is a crash course in state‐​of‐​the‐​art science dressed up as a polemic. De Grey wears his passion for undertaking a war on aging on his sleeve, yet most of the book consists of scientific analysis that, although simplified to enable a layman to follow, is conscientious in reporting doubts and objections to the author’s point of view.



I would recommend giving _Ending Aging_ to any scientifically‐​inclined youngster. It gives a sense of the possibilities, drama, and frustration of scientific inquiry. Also, it might inspire some young geniuses to undertake the sort of investigations and experiments that de Grey thinks will help win the war against aging.



 **New Institutions**



The polemical component of de Grey’s book is aimed primarily at the institutions and incentives that currently govern the medical research process. Some of the changes that he proposes are radical, and some are subtle.



The first institutional problem, from de Grey’s perspective, is that the incentives lead researchers to focus on specific diseases rather than on general‐​purpose technologies to fix cell damage. In scientific research, the usual distinction is between “basic” research and “applied” research. Almost everything that De Grey is talking about is in the “applied” arena. We can always use more basic research, but I think he would regard the basic research that we have today as sufficient in many respects.



The distinction between disease‐​specific and general‐​purpose fits under applied research. Within the category of applied medical research, there are discoveries that attempt to treat specific diseases, such as prostate cancer or Parkinson’s. However, the technologies that de Grey advocates developing might reverse the processes that are implicated in many diseases.



Today, the incentives to experiment with general‐​purpose anti‐​aging technologies are limited. Only if a technique can be demonstrated as helping to treat a specific disease can its development be funded and its efficacy tested in humans. Of course, many of the techniques necessary to achieve de Grey’s vision can be shoehorned into a disease‐​fighting agenda somewhere, which is why he can report results that justify his belief in the potential to conquer aging. However, there remains the fact that the current system gives too much incentive to find stopgap solutions to specific diseases and too little incentive to develop general‐​purpose anti‐​aging technologies.



The second institutional barrier is risk aversion, which is hard‐​coded into regulations pertaining to research and to clinical trials. De Grey writes (p. 323–324),



Regulation of experimental drugs and therapies…is based on one abiding principle above all others: the minimization of risk that the therapy might make the patient worse…



I take the view, quite simply, that Hippocrates has had his day…the _psychological_ effect of possibly causing harm…skews the objective cost‐​benefit analysis of a given treatment…I believe that the 10:1 (at least) ratio of lives lost through slow approval of safe drugs to lives lost through hasty approval of unsafe drugs is no longer acceptable. 



…[Laws and regulations will change.] People will die as a result; the 10:1 ratio mentioned above will probably be reduced to 2:1. And people will be happy about this change, because they’ll know it’s wartime, and the first priority–even justifying considerable loss of life in the short term–is to end the slaughter as soon as humanly possible.



What de Grey is saying is that today’s cautious approach to experimental medical testing significantly slows the rate of progress, which means that many people will suffer and die unnecessarily. However, those people are unseen and unknown, whereas those who suffer and die as a _result_ of medical experiments are identifiable and visible. I think that trying to sell people on the idea of taking more risks in order to advance medical progress is not as straightforward as de Grey makes it sound.



As an economist, I immediately think in terms of paying people to undergo risky therapies. For better or worse, this might appeal more to people who are very poor–perhaps even people living in other countries. However, those citizens who are squeamish about de Grey’s proposal to expose more people to harm now in order to reduce harm to others in the near future probably would not feel any less squeamish just because those who undergo the experiments are well paid.



At a more subtle level, de Grey wants institutional changes that wrest control of the research agenda from the medical establishment, which is vested in the existing paradigm. Here, the fact that so much medical research is under government auspices makes the outlook discouraging, in my view. If there is one thing that you can count on government to do, it is to protect incumbents and move with great reluctance to support upstarts and innovators. 



My guess is that de Grey will have better luck if he tries to mobilize wealthy philanthropists. If instead of donating buildings to universities our billionaires would donate money for prizes that reward general‐​purpose medical technologies, we might not have to wait for government research to adopt a paradigm shift, which is almost surely not going to happen. Wealthy (and not‐​so‐​wealthy) philanthropists who are reading this should check out de Grey’s organization SENS and look for ways to contribute both to his institute and to a prize fund.



Let me give de Grey the last word (p.328–329):



Just as people were wrong for centuries about how hard it was to fly but eventually cracked it, we’ve been wrong since time immemorial about how hard aging is to combat, but we’ll eventually crack it, too. But just as people have been pretty reliably correct about how to make better and better aircraft once they had the first one, we can expect to be pretty reliably correct about how to repair the damage of aging more and more comprehensively once we can do it a little.
"
nan
"

A little story popped up in the press today that offers what my wife and I, in the context of our responsibilities toward our 4 year-old son, often refer to as ""a teaching moment."" That opportunity is afforded by an accusation out of Greenpeace this morning that Cato, along with 40 other policy organizations, are wholly-owned subsidiaries of Exxon-Mobil and thus should not be trusted.   
  
The contention that Exxon-Mobil funding colors Cato’s analysis (with contributions, by the way, that accounted for less than 1/10th of 1% of our budget in 2006) is compelling only if Greenpeace has some sort of “motive detection device” that can be produced for public inspection. For instance, I say I'm motivated by genuine skepticism that industrial greenhouse gas emissions will usher in the _Book of Revelations_. They say I'm motivated by greed. We can settle this argument to the satisfaction of some third-party observer ... how exactly? Even administering me with liberal doses of sodium pentathol is unlikely to settle this little spat about the nature of my character.   
  
The truth is that my colleagues at Cato and I are skeptical about the end-of-the-world scenarios bandied about by zealots like Greenpeace, we anchor that skepticism in the peer-reviewed scientific literature, and that skepticism naturally attracts funding from those parties who like what they hear. Arguing that causality actually works the other way is not only an unproved and unprovable assertion (let's call it ""faith-based argumentation""), it is impossible to square with all the work we’ve published arguing against many of the things the oil industry is known to support.   
  
For instance, we have vigorously argued against President Bush’s national energy strategy and the resulting Energy Policy Act of 2005, called for the dismantlement of the Strategic Petroleum Reserve, railed against federal oil and gas subsidies, argued for the elimination of the Clean Air Act rules that allow older refineries to escape tough anti-pollution standards, suggested giving the Arctic National Wildlife Refuge to the Greens to do with as they wish, argued against allowing cost-benefit analysis to dictate environmental standards, and defended the government’s right to renegotiate drilling leases in the Gulf of Mexico that provided highly favorable contractual terms to some oil companies.   
  
Regardless, Greenpeace’s assertions — even if true — are founded upon a classic logical fallacy. For those who never took a course in logic, it's called ad hominem. Despite what the body politic might otherwise believe, the merit of an argument has nothing to do with the motives of the person making that argument.   




For instance, if the Institute for Policy Studies argues that minimum wage laws have little net effect on unemployment and produce citations in the literature to back that up, the reply that “IPS is staffed by a bunch of socialists who simply want to bring down capitalism and should thus not be listened too” persuades only those people who are too intellectually lazy or mentally impaired to think straight. Similarly, if Cato argues that it’s very hard to justify tight greenhouse gas emissions controls using strict cost-benefit analysis — and provides academic citations to back that up — the charge that “Cato is paid by Exxon-Mobil to take that position and thus shouldn’t be listened too” is likewise a variation of the argument made famous by Joe McCarthy. ""He's evil — and thus a liar.""   
  
And in that vein, notice the thinly veiled smear entailed in Greenpeace's constant use of the phrase “climate denial” and its related cousins. In this context, it's obviously meant to echo the ugly ""climate denial is like Holocaust denial"" charge rampant at some high-decibel quarters on the Left. Greenpeace's strategy here is to leave no insult or character smear off the table in its drive to censor the policy debate.   
  
That Greenpeace resorts to such a tactics does not surprise. Those with good arguments pound the arguments; those with poor arguments pound the table. God forbid Greenpeace grant that people of good will might actually disagree with them. And God forbid that we ask people to judge an argument by the facts rather than some schoolyard game of ""you stink.""


"
"In the wake of the devastating Australian bushfires, Jeff Bezos announced last month that he will donate $10bn to fight the climate crisis. As a resident of California and the former president of the Sierra Club Foundation, I welcome any contribution toward the struggle against our changing climate. That said, my home state, like all communities with Amazon facilities, would be far better off if Bezos simply paid his taxes. If Amazon’s properties in California were taxed at their current value, the added tax could help bolster our underfunded firefighters and fix our crumbling fire access roads. Contributing vast sums to the global effort is wonderful, but climate change is a local issue too. Our communities need to be well-funded if we’re going to face this threat head-on.  How California fights climate disruption will be a model for states and local governments nationwide, and if this effort fails in California, I worry what others will be able to accomplish. With a rapidly changing climate and underfunded emergency response systems, California residents could soon face another situation like the devastating 2018 wildfires. California’s formerly annual fire season has become a year-round phenomenon; the fires are now larger, hotter and burn longer than ever before. To combat the growing destructive power of these fires, we need a robust and well-equipped emergency response system. That requires raising more revenue. The commercial loophole in Proposition 13, which allows many corporations in California to avoid paying significant amounts of property taxes, unintentionally depleted the funding our communities now desperately need. As a result, our emergency response systems have suffered. According to the California Professional Firefighters, the number of unfulfilled requests for resources and equipment has grown over the past few years despite those resources being needed more urgently than ever. Worse, the Trump administration has promised to cut millions of dollars from the US Forest Service’s firefighting services, with additional cuts to funding for local volunteer firefighting departments. As a result of these shortfalls, firefighters across the state have been forced to appeal to voters to raise taxes to secure consistent funding. That’s a shame. Our public emergency services shouldn’t have to beg for the funding that they need to operate in the largest and most prosperous state in the country. However, there is a simple solution to this issue. Schools and Communities First is a ballot measure for the upcoming 2020 election that seeks to level the playing field by taxing commercial and industrial properties at a fair market value, rather than the decreased value they now use as a result of longstanding loopholes in the state tax code. It is estimated to reclaim $12bn every year, with 60% of that total going toward local governments, including local fire districts. Since the initiative has a clause to exclude small businesses, we can be sure that funding for our neglected public services will come only from wealthy businesses who are currently avoiding paying their fair share. Under the current tax loophole, large industries that have held their land for a long period receive an unfair advantage because their property is undertaxed compared to its current day value. For example, according to an analysis by the Proposition 13 campaign, Chevron underpays up to $100m every year on their Kern county holdings. In Chevron’s case, that same property leaked over 82m gallons of crude oil intermittently since 2003; the company recently sealed up a disastrous 800,000-gallon leak. It makes no sense for us to continue to supply reckless corporations like Chevron with financial incentives for their dirty practices while our firefighters receive pennies. That $100m could be going toward struggling local fire departments, not to mention fixing dilapidated roads and cracked sidewalks and reducing overcrowded classrooms. This tax loophole robs Californians of well-funded community services by taking money from our localities and giving it to wealthy corporations in the form of a tax break. This coming election I urge all Californians to support the Schools and Communities First Act. For that matter, I urge all voters in all states to consider measures that will aid the fight against climate change. All Americans deserve the comfort of knowing that our emergency services are adequately funded to deal with every possible climate disaster. This future is possible when wealthy corporations like Amazon pay their fair share by reinvesting in the communities that support them, not receiving tax incentives to continue their avaricious practices at the expense of local services. Guy T Saperstein is a retired attorney who founded the largest private plaintiff civil rights law firm in America, the former President of the Sierra Club, and a member of the Patriotic Millionaires"
"Over six decades, Sir David Attenborough’s name has become synonymous with high-quality nature documentaries. But while for his latest project, the Netflix series Our Planet, he is once again explaining incredible shots of nature and wildlife – this series is a little different from his past films. Many of his previous smash hits have portrayed the natural world as untouched and perfect, Our Planet is billed as putting the threats facing natural ecosystems front and centre to the narrative. In the opening scenes we are told: “For the first time in human history the stability of nature can no longer be taken for granted.”  This is a very significant departure – and one which is arguably long overdue. Those of us who study the pressures on wild nature have been frustrated that nature documentaries give the impression that everything is OK. Some argue that they may do more harm than good by giving viewers a sense of complacency. Conservation scientists were expecting that the new series wouldn’t shy away from the awful truth: the wonders shown in these mesmerising nature programmes are tragically reduced – and many are at risk of being lost forever. I had the privilege of seeing the One Planet team at work back in 2015 (these films take years to make). I spent three weeks at the camp in western Madagascar where they were working on their forest film. While the camera crew were working day and night filming fossa (lemur-hunting carnivores), and trying to get the perfect footage of leaf bugs producing honeydew (the series is worth watching for this sequence alone), the team was also digging deep into the complex issues of what is happening to this wondrous biodiversity. Their researcher spent many hours with Malagasy conservation scientist Rio Heriniaina talking to local community leaders about the challenges they face and the reasons for the very rapid rate of forest loss in the region. However, none of that fascinating footage made the final cut. Following a scene showing fossa mating, we are told that their forests have since been burnt. This was already happening in 2015. As Heriniaina told me:  Madagascar’s dry forests are vanishing before our eyes. Every burning season large areas of forest go up in flames to clear space for peanuts and corn. There is no simply answer to as why, and no simple solutions. Poverty plays a role but so does corruption and the influence of powerful people who profit from the destruction.  This is my main critique of Our Planet. Despite being billed as an unflinching look at the threats facing the intricate and endlessly fascinating ecosystems being depicted, it actually tends to shy away from showing these threats or, even more importantly, addressing the question of what can be done to resolve them. Like previous documentaries, shots have been carefully positioned to cut out evidence of human influence.  In my three decades of watching wildlife documentaries, I remember only one moment which broke from this tradition. In Simon Reeves’ 2012 series about the Indian Ocean, he showed people living in and around the habitats he was filming. He humanised them. He was also honest about how limited the picturesque natural habitats he was filming were. In a memorable sequence showing a sifaka leaping between trees, he asked the camera man to turn around, revealing the miles of sisal plantation which surround the tiny remnant of forest where endless crews go to film these charismatic lemurs. When Planet Earth II came out in 2016 I was disappointed to see a return to more of the same – that same remnant forest in southern Madagascar appeared, but without the context. As with previous documentaries, you could come away from Our Planet thinking the places being portrayed are completely separate from people. Human presence in and around many of these habitats has been erased. However to be successful, conservation can’t ignore people.  Maybe it is churlish to complain that Our Planet, like other such films, avoids showing the uncomfortable truth about just how threatened so much of nature really is. Perhaps the pure and unsullied vision is what makes them so popular. So many of us working in conservation were drawn in through watching Sir David Attenborough’s other films as children. By introducing viewers to fascinating facts about ecology (who knew that winds blowing across deserts feed life in the ocean?) and the mind-boggling behaviours of birds (such as the manakins shown doing a shuffle dance), Our Planet will engage a whole new generation.  Researchers have shown time and time again that knowledge isn’t enough to change people’s behaviour. However feeling connected with nature does matter. One thing the series will certainly do is make people fall in love with the planet. That is certainly a good thing. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"
In bureaucracy, truth is often stranger than fiction. A non polluting electric car company gets slammed with fine for “non compliance” for a car that can’t produce any emissions.

That’s weird enough by itself, but even weirder is what else is in the company’s Securities and Exchange Commission report under what they cite as “risks”.
Here’s the relevant page of the report where they talk about risks, including the $275,000 fine from the EPA. Note what is highlighted under that. 
click to enlarge
They headline that with:
We are subject to substantial regulation, which is  evolving, and unfavorable changes or failure by us to comply with these  regulations could substantially harm our business and operating results.
That’s right, a zero emissions “green” electric car company cites this as a risk to the company’s business future:
the  imposition of a carbon tax or the introduction of a cap-and-trade  system on electric utilities could increase the cost of electricity;
You can see the Telsa SEC 10Q report for yourself at:
http://www.faqs.org/sec-filings/100813/TESLA-MOTORS-INC_10-Q/#ixzz0yDhK9ON3
Tesla’s crime? Failing to file for a 2009 emissions “Certificate of Conformity” from the EPA to comply with the “Clean Air Act.” until late in the year. Wait, I thought electric cars were supposed to help clean the air?
Damned if you do, damned if you don’t. It is a wonder that anybody would bother even trying to do business anymore where the minefield of bureaucracy looms even for popular and politically correct green companies in California.
h/t to autoblog.com

Sponsored IT training links:
The 642-374 study pack also includes 1Y0-A05 dumps and 350-018 practice exam so you will pass your certification exam on first try.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e893974a7',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Coral reef ecosystems are collapsing, with live coral cover on reefs having nearly halved over the past 150 years. These small polyp-like creatures, related to jellyfish, secrete a calcium carbonate exoskeleton that forms the reef – a habitat that provides shelter and food for a rich diversity of species. Corals cohabit with algae that photosynthesise and provide the corals with nutrition and energy.  But ocean heat waves are becoming more common as the climate warms. When water temperatures are exceptionally high for a prolonged period of time, corals can bleach. They lose their striking colour and the algae which supports them, and often the corals die, leaving the reef vulnerable to erosion. Coral restoration could reestablish corals in areas that have been damaged. Small coral pieces – known as “nubbins” – are taken from donor corals or grown in nurseries and attached to frames that are anchored to the seafloor. These nubbins in some species can grow fast and potentially rebuild a reef in a few years. But what happens when they are hit by another ocean heat wave? Scientists are using selective breeding and genetic engineering to create “super-corals” that are more heat-tolerant and resistant to bleaching. Super-corals could cope with hotter and longer heat waves, giving hope that reefs might persist. A new study shows that super-corals are already out there, occurring naturally in shallow pools in American Samoa. Corals in shallow pools are able to survive high levels of heat stress, as these pools warm more quickly at low tide. But scientists didn’t know if shallow water corals would lose their heat tolerance when moved to a new site, where they might acclimatise to the new conditions. If they kept this adaptation, transplanting heat-tolerant coral nubbins to colder places would provide a good insurance against heat stress as heat waves become longer and more frequent. The new study found shallow pools in American Samoa with corals that have adapted to heat stress and could restore reefs that are resistant to bleaching. For four species, researchers demonstrated that the heat tolerance that these corals acquired in hot pools is maintained even when they are transplanted elsewhere, meaning their heat tolerance is ingrained within their DNA. This is exciting. If the corals were simply acclimatised, their heat tolerance would disappear after transplantation and they would be no good for restoring reefs with corals that are resistant to bleaching under heat stress. So does this study provide hope for the future of coral reefs? It stands out as a positive note among many dire reports on the future of this ecosystem. The study suggests that reef communities could be repopulated with “super-corals” that are more robust against the increasing heat stress that’s predicted. But climate breakdown will transform coral reefs into entirely different environments. Given the global scale of the problem, it’s unlikely that enough resources can be mobilised to roll out restoration everywhere, or that enough corals will survive as suitable donors in every place that needs restoration.  Coral nubbins need time to mature in order to form reefs. Projects needs workers, time and funding to develop restoration sites, most of which are currently set up to replace coral reefs that were damaged in the past. Heat-tolerant coral candidates need to be found among different species using genomic testing and exposure experiments.  It usually takes one day to plant around 100 coral nubbins, although the record is up to 5,000 nubbins a day off the coast of Sulawesi in the Coral Triangle. That may sound like a lot, until we consider how many individual corals make up a reef and how many are lost during bleaching events.  Around 35% of coral colonies died due to bleaching between 2016 and 2017 on the northern Great Barrier Reef. With coral devastation on such huge scales, it seems difficult to imagine that naturally occurring super-corals will revolutionise reef restoration in the short term, at least with the current planting rates. Over the past decade, rapid advances in restoration techniques have provided many examples of small-scale reef restoration projects, but it’s not clear how these can be scaled up to repair reefs and make them more resilient. Without including heat-tolerant corals to protect restored reefs against future heat stress, coral reefs may not survive environmental changes in the future. It seems hopeful at least, that heat-tolerant corals could help reefs naturally adapt to climate change while in the environment. Increasing the number of heat-tolerant corals in restoration sites will help seed new generations of resistant corals onto adjacent reefs, creating a bank of hardy corals which future reefs may depend on. It’s only a small bit of good news, but it may add up to something much bigger. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"

Another day, another negative impact from pernicious global warming caused by humanity’s relentless quest for self-betterment.   
  
Today, it is our coffee supply that is in jeopardy. Earlier this week, global warming was melting mummies in Chile. Last week, it was blamed for war in Syria. Turns out that global warming is a highly selective beast—it only harms the things we love, while enhancing the things we don’t.   
  
Penguins? Polar bears? Songbirds? Coffee?   
  
Harms. Harms. Harms. Harms.   
  
Jellyfish? Poison ivy? Ragweed? War?   
  
Helps. Helps. Helps. Helps.   
  
Mummies are sort of a special case. If they were roaming around attacking people, we’d imagine that global warming would empower them. But in this case, the mummies are harmlessly laying around in the (apparently poorly climate-controlled) vaults in a museum in Chile. There, they are a natural treasure. So, predictably, global warming is causing harm.   




[Gotta wonder what warming could do to poor old Lenin lying entombed in Red Square. Our greener friends might want him reincarnated, while others would hope he would begin to leak like the Chilean mummies].   
  
And the list goes on and on—something that we’ve pointed out previously (see here and here, for example).   
  
Consequently, the news of the past week should hardly come as a great surprise. We’re pretty used to it by now.   
  
But what may come as a surprise is that according to U.K. economist Richard Tol, recent studies into the economic impacts of climate change find the positives to be increasing and the negatives to be decreasing.   
  
Tol writes:   




Since 2009, however, more estimates of the economic impact of climate change have been published…The new trend shows positive impacts for warming up to about two degrees global warming, just like the old trend did. The new trend, however, shows markedly less negative impacts for more profound warming than did the old trend. In other words, in the last five years, we have become less pessimistic about the impacts of climate change.



Couple this result with the bevy of new scientific findings indicating the future climate change is likely to be on the low side of climate model projections and we have some good news about climate change’s impact on something that we all like—money!   
  
Got to wonder why it is that you only find this result highlighted in these pages and not headlining the front page of the _Washington Post_ or _New York Times_.


"
"

It’s that time of year in North Carolina, when everyone from Bird Island to Carova Beach fears the Big One that washes away the beach house. According to the state Coastal Resources Commission, each passing year brings an even greater threat, thanks to rising sea levels.



The CRC scared everybody by predicting a median of 38 additional inches of sea‐​level rise in the next 86 years. For comparative purposes, global warming was associated with an 8‐​inch rise since 1900.



It’s enough to make people panic before the apocalypse. So sell me your beach house. Please.



I’d like to offer you bottom dollar because a) everyone thinks your house is doomed and b) because everyone is probably wrong. 



Note: Global warming is real and is caused, in part, by increasing atmospheric carbon dioxide, and a warmer world has higher sea levels.



So what? In climate, it’s not whether things change (they will, with or without our help), but how much they change.



Remember the adage, “It’s not the heat, it’s the humidity”? With regard to climate, that should be “It’s not the heat, it’s the sensitivity.”



“Sensitivity” is the amount of warming one gets for a doubling of carbon dioxide. Thanks to other greenhouse gas emissions, like methane, we’re already way past halfway there. The sensitivity is also a pretty good estimator of the change in surface temperature expected in this century.



Generally speaking, the ballpark “sensitivity” is estimated around 3.0°C (5.4°F). But the earth has been very reluctant to get with such a rapid warming program.



Global warming first burst onto the political scene on June 23, 1988, when NASA astrophysicist (and political activist) James Hansen testified that there was “a strong cause and effect relationship between the [then] current climate and human alteration of the atmosphere.” He also made a forecast, based upon two plausible scenarios for future carbon dioxide emissions. He predicted twice as much warming as has been observed.



In climate change, that’s the difference between something pretty substantial and something that is easily (and often unconsciously) adapted to. In North Carolina, there’s been an additional 10 inches of sea‐​level rise (for a total of 18 inches, since 1900) at Duck, thanks to the fact that the land there is sinking. People slowly adapted by stabilizing the dunes and building new homes on pilings.



No regulatory fiat, by the CRC or anyone else, is going to stop the coast from subsiding. But Duck is kind of an outlier. Further south, by Wilmington and Southport, the rise of the ocean is pretty much in step with the global average.



Other forecasts of warming are also too high. For example, the “midrange emissions” suite of models used by the United Nations Intergovernmental Panel on Climate Change appears to be predicting about a third more warming than we are getting.



CRC forecasts curiously use a much higher emission scenario than this, and it is clearly wrong. It was made before the discovery of hundreds of years supply of shale gas, which emits about half of the carbon dioxide of coal when used for electrical generation. Adjusting for CRC’s forecast errors (as well as for observed warming trends) yields a sea‐​level rise of about 13 inches from now to 2100.



But won’t the temperature rise accelerate and sea‐​level rise quicken?



Not if we believe the mathematical form of the Intergovernmental Panel’s midrange computer models. Contrary to talk about “ever‐​increasing warming rates,” these models in fact tend to predict a constant rate of warming. Indeed, a graph of the globe’s temperature history since the second warming of the 20th century began, over a third of a century ago, shows a remarkably constant rate of about 1.6°C (2.9°F) per century.



The CRC’s 38‐​inch projection is based upon almost three times as much warming as is being observed. For CRC to be right, the rate of warming will have to increase dramatically, but that would violate the U.N.‘s models showing a constant rate.



Which reminds me, here’s my offer for your beach house.…
"
nan
"

The House is expected to vote as early as Wednesday on a resolution that decries the dangerous threat posed by rising industrial greenhouse gas emissions. The resolution calls for an emissions cap on greenhouse gases as long as (i) the cap doesn’t harm the U.S. economy, and (ii) U.S. trading partners agree to live under a similar cap.   
  
  
While the Greens are quite exited that the GOP seems prepared to go along with this, these things are called “resolutions” for a reason — they echo promises made on New Year’s Eve. In short, it’s nothing but a statement that the Congress thinks that this would be a good idea, but that they are unprepared (at the moment) to do anything about it.   
  
  
Does this represent progress for the enviros? Not really. Show me an emissions cap that won’t have a negative effect on the economy and I’ll show you an alterantive reality where up is down, black is white, and rivers are made of liquid chocolate. Now, depending upon the nature of the cap and the regulations attached thereto, the negative economic impact might be very modest or rather signficant. But ruling out caps that have _any_ negative economic impact is to essentially rule out a cap.   
  
  
Frank O’Donnell, head of the Left’s Clean Air Watch, was not too far off the mark when he was quoted in the subscription trade journal _Energy & Environment Daily_ this morning as noting that “The way [the resolution] is worded, you’d have to be a kook to be opposed to it.” Indeed, who would object to what is in effect an insurance policy with no premium?   
  
  
If the Greens really think that global warming is serious, they are demonstrating both political and intellectual cowardice by backing pablum like this. All this resolution would accomplish is to allow politicians to claim environmental virtue from empty political gestures.   
  
  
So why would the enviros provide an easy out for politicians who want to appear Green but not do anything real to advance the Green agenda? Because it’s the best the enviros can do right now. That speaks volumes. This is a resolution that advertises Green political weakness, not Green political strength.   
  
  
The resolution, then, is pretty meaningless. That having been said, you don’t have to be a “kook” to be skeptical about all the “doom, doom I say” hand‐​wringing that litters the resolution. That is, unless you think a Vice President of the U.N.‘s oft cited International Panel on Climate Change is a kook. And if you do, what does that say about the merit of that much‐​worshiped body of scientific experts?
"
"Electric vehicles produce less carbon dioxide than petrol cars across the vast majority of the globe – contrary to the claims of some detractors, who have alleged that the CO2 emitted in the production of electricity and their manufacture outweighs the benefits. The finding is a boost to governments, including the UK, seeking to move to net zero carbon emissions, which will require a massive expansion of the electric car fleet. A similar benefit was found for electric heat pumps.  In the UK, transport is now the biggest contributor to the climate crisis and domestic heating has been stubbornly stuck on natural gas for much of the country. Across the world, passenger road vehicles and household heating generate about a quarter of all emissions from the burning of fossil fuels. That makes electric vehicles essential to reducing overall emissions, but how clean an electric vehicle is also depends on how the electricity is generated, the efficiency of the supply and the efficiency of the vehicle. That has made some individuals and governments question whether these technologies are worth expanding. The study, published on Monday in the journal Nature Sustainability, produced a decisive yes. Scientists from the universities of Exeter, Nijmegen and Cambridge conducted lifecycle assessments that showed that even where electricity generation still involves substantial amounts of fossil fuel, there was a CO2 saving over conventional cars and fossil fuel heating. They found that in 53 out of 59 regions, comprising 95% of the world, electric vehicles and domestic heat pumps generate less carbon dioxide than fossil fuel powered cars or boilers. The only exceptions are heavily coal-dependent countries such as Poland. In countries such as Sweden, which gets most of its electricity from renewable sources, and France, which is largely powered by nuclear, the CO2 savings from using electric cars reach as high as 70% over their conventional counterparts. In the UK, the savings are about 30%. However, that is likely to improve further as electric vehicles grow even more efficient and more CO2 is taken out of the electricity generating system. Heat pumps use electricity and heat exchange systems – similar in principle to those found in fridges – to take advantage of the difference in temperature underground and at the surface, in the case of ground source heat pumps, and between the outdoor air and indoors in the case of air source heat pumps. If they were widely used, the study found, they could reduce global carbon emissions by up to 0.8 gigatons a year by 2050, or the equivalent of Germany’s emissions today. “The idea that electric vehicles or heat pumps could increase emissions is essentially a myth,” said Florian Knobloch of Nijmegen University in the Netherlands, the lead author of the study. “We’ve seen a lot of disinformation going around. Here is a definitive study that can dispel those myths.” Jean-Francois Mercure, of Exeter University, a co-author of the study, added: “The answer is clear: to reduce carbon emissions, we should choose electric cars and household heat pumps over fossil fuel alternatives.” Among the detractors has been Bjørn Lomborg, the climate controversialist, who argued in a column published in newspapers around the world last week that electric cars were “simply expensive gadgets heavily subsidised for the wealthy to feel good while doing very little for the planet”. Mike Childs, head of science at Friends of the Earth, said: “Electric vehicles and heat pumps are absolutely critical for meeting climate goals so it’s good to see this favourable report. In the UK, both technologies will continue to make big carbon savings alongside our switch from fossil fuels to renewable energy to power the electricity grid.” But he warned that insulating homes and improving public transport remained important goals, alongside electric vehicles and heat pumps, and called for much more government action to realise the benefits. “Where the UK is dragging its feet is supporting the necessary rapid rollout of electric cars and heat pumps as well as the infrastructure to support them,” he said."
"I was invited to speak to a group of teenagers on climate strike in Oxford recently. Like many scientists, I support the strikes, but also find them disturbing. Which I’m sure is the idea.  Today’s teenagers are absolutely right to be up in arms about climate change, and right that they need powerful images to grab people’s attention. Yet some of the slogans being bandied around are genuinely frightening: a colleague recently told me of her 11-year-old coming home in tears after being told that, because of climate change, human civilisation might not survive for her to have children. The problem is, as soon as scientists speak out against environmental slogans, our words are seized upon by a dwindling band of the usual suspects to dismiss the entire issue. So if I were addressing teenagers on strike, or young people involved in Extinction Rebellion and other groups, or indeed anyone who genuinely wants to understand what is going on, here’s what I’d say. My biggest concern is with the much-touted line that “the Intergovernmental Panel on Climate Change (IPCC) says we have 12 years” before triggering an irreversible slide into climate chaos. Slogan writers are vague on whether they mean climate chaos will happen after 12 years, or if we have 12 years to avert it. But both are misleading. As the relevant lead author of the IPCC Special Report on Global Warming of 1.5°C, I spent several days last October, literally under a spotlight, explaining to delegates of the world’s governments what we could, and could not, say about how close we are to that level of warming. Using the World Meteorological Organisation’s definition of global average surface temperature, and the late 19th century to represent its pre-industrial level (yes, all these definitions matter), we just passed 1°C and are warming at more than 0.2°C per decade, which would take us to 1.5°C around 2040. That said, these are only best estimates. We might already be at 1.2°C, and warming at 0.25°C per decade – well within the range of uncertainty. That would indeed get us to 1.5°C by 2030: 12 years from 2018. But an additional quarter of a degree of warming, more-or-less what has happened since the 1990s, is not going to feel like Armageddon to the vast majority of today’s striking teenagers (the striving taxpayers of 2030). And what will they think then? I say the majority, because there will be unfortunate exceptions. One of the most insidious myths about climate change is the pretence that we are all in it together. People ask me whether I’m kept awake at night by the prospect of five degrees of warming. I don’t think we’ll make it to five degrees. I’m far more worried about geopolitical breakdown as the injustices of climate change emerge as we steam from two to three degrees. So please stop saying something globally bad is going to happen in 2030. Bad stuff is already happening and every half a degree of warming matters, but the IPCC does not draw a “planetary boundary” at 1.5°C beyond which lie climate dragons. What about the other interpretation of the IPCC’s 12 years: that we have 12 years to act? What our report said was, in scenarios with a one-in-two to two-in-three chance of keeping global warming below 1.5°C, emissions are reduced to around half their present level by 2030. That doesn’t mean we have 12 years to act: it means we have to act now, and even if we do, success is not guaranteed. And if we don’t halve emissions by 2030, will we have lost the battle and just have to hunker down and survive? Of course not. The IPCC is clear that, even reducing emissions as fast as possible, we can barely keep temperatures below 1.5°C. So every year that goes by in which we aren’t reducing emissions is another 40 billion tonnes of CO₂ that we are expecting today’s teenagers to clean back out of the atmosphere in order to preserve warm water corals or Arctic ice. Assuming people will still want to feed themselves and not turn the world over to biofuels, then scrubbing CO₂ out of the atmosphere currently costs £150-£500 per tonne, plus the cost of permanent disposal. So those 40 billion tonnes of CO₂ represent a clean-up liability accumulating at a cool £8 trillion per year, which is more or less what the world currently spends on energy. So here is a conversation young activists could have with their parents: first work out what the parents’ CO₂ emissions were last year (there are various carbon calculators online – and the average is about seven tonnes of fossil CO₂ per person in Europe). Then multiply by £200 per tonne of CO₂, and suggest the parents pop that amount into a trust fund in case their kids have to clean up after them in the 2040s. If the parents reply, “don’t worry, dear, that’s what we pay taxes for”, youngsters should ask them who they voted for in the last election and whether spending their taxes on solving climate change featured prominently in that party’s manifesto. Get angry by all means, but get angry for the right reasons. Action is long overdue, but to a British public sunbathing in February, weird though that was, it doesn’t feel like an emergency. Middle-aged critics would much rather quibble over the scale of climate impacts (as if they have any right to say what climate young people should have to put up with) than talk about the clean-up bill.  Climate change is not so much an emergency as a festering injustice. Your ancestors did not end slavery by declaring an emergency and dreaming up artificial boundaries on “tolerable” slave numbers. They called it out for what it was: a spectacularly profitable industry, the basis of much prosperity at the time, founded on a fundamental injustice. It’s time to do the same on climate change. Read more: School climate strikes: why adults no longer have the right to object to their children taking radical action or view this years’ Great Debate on Planetary Boundaries and 1.5°C at the European Geophysical Union. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"
Earl looks to have a path grazing the East Coast of the USA. Cape Hatteras, Long Island, and Cape Cod may be in a portion of the projected path.

Satellite image follows along with a recent bulletin. 

Animate the sat loop – click here
BULLETIN

HURRICANE EARL INTERMEDIATE ADVISORY NUMBER  27A

NWS TPC/NATIONAL HURRICANE CENTER MIAMI FL   AL072010

200 AM AST WED SEP 01 2010

...POWERFUL HURRICANE EARL BEGINNING TO MOVE AWAY FROM THE TURKS AND

CAICOS ISLANDS...

SUMMARY OF 200 AM AST...0600 UTC...INFORMATION

----------------------------------------------

LOCATION...23.5N 70.7W

ABOUT 145 MI...235 KM NNE OF GRAND TURK ISLAND

ABOUT 860 MI...1385 KM SSE OF CAPE HATTERAS NORTH CAROLINA

MAXIMUM SUSTAINED WINDS...135 MPH...215 KM/HR

PRESENT MOVEMENT...NW OR 315 DEGREES AT 15 MPH...24 KM/HR

MINIMUM CENTRAL PRESSURE...942 MB...27.82 INCHES

WATCHES AND WARNINGS

--------------------

CHANGES WITH THIS ADVISORY...

NONE.

SUMMARY OF WATCHES AND WARNINGS IN EFFECT...

A HURRICANE WATCH IS IN EFFECT FOR...

* NORTH OF SURF CITY NORTH CAROLINA TO THE NORTH CAROLINA/VIRGINIA

BORDER...INCLUDING THE PAMLICO AND ALBEMARLE SOUNDS

A TROPICAL STORM WARNING IS IN EFFECT FOR...

* TURKS AND CAICOS ISLANDS

A TROPICAL STORM WATCH IS IN EFFECT FOR...

* SOUTHEASTERN BAHAMAS

* CAPE FEAR TO SURF CITY

A HURRICANE WATCH MEANS THAT HURRICANE CONDITIONS ARE POSSIBLE

WITHIN THE WATCH AREA.  A WATCH IS TYPICALLY ISSUED 48 HOURS

BEFORE THE ANTICIPATED FIRST OCCURRENCE OF TROPICAL-STORM-FORCE

WINDS...CONDITIONS THAT MAKE OUTSIDE PREPARATIONS DIFFICULT OR

DANGEROUS.

INTERESTS FROM VIRGINIA NORTHWARD TO NEW ENGLAND SHOULD MONITOR

THE PROGRESS OF EARL.

FOR STORM INFORMATION SPECIFIC TO YOUR AREA IN THE UNITED

STATES...INCLUDING POSSIBLE INLAND WATCHES AND WARNINGS...PLEASE

MONITOR PRODUCTS ISSUED BY YOUR LOCAL NATIONAL WEATHER SERVICE

FORECAST OFFICE. FOR STORM INFORMATION SPECIFIC TO YOUR AREA OUTSIDE

THE UNITED STATES...PLEASE MONITOR PRODUCTS ISSUED BY YOUR NATIONAL

METEOROLOGICAL SERVICE.

DISCUSSION AND 48-HOUR OUTLOOK

------------------------------

AT 200 AM AST...0600 UTC...THE CENTER OF HURRICANE EARL WAS LOCATED

NEAR LATITUDE 23.5 NORTH...LONGITUDE 70.7 WEST.  EARL IS MOVING

TOWARD THE NORTHWEST NEAR 15 MPH...24 KM/HR.  THIS GENERAL MOTION IS

EXPECTED TO CONTINUE ON WEDNESDAY WITH A GRADUAL TURN TO THE

NORTH-NORTHWEST THEREAFTER.  ON THE FORECAST TRACK...THE CORE OF

THE HURRICANE WILL BE PASSING WELL EAST AND NORTHEAST OF THE TURKS

AND CAICOS ISLANDS TONIGHT AND NORTHEAST OF THE BAHAMAS TOMORROW.

MAXIMUM SUSTAINED WINDS ARE NEAR 135 MPH...215 KM/HR...WITH HIGHER

GUSTS.  EARL IS A CATEGORY FOUR HURRICANE ON THE SAFFIR-SIMPSON

HURRICANE WIND SCALE.  LITTLE CHANGE IN STRENGTH IS EXPECTED

THROUGH WEDNESDAY.

EARL IS A LARGE HURRICANE.  HURRICANE FORCE WINDS EXTEND OUTWARD UP

TO 90 MILES...150 KM...FROM THE CENTER...AND TROPICAL STORM FORCE

WINDS EXTEND OUTWARD UP TO 200 MILES...325 KM.  NOAA BUOY 41046

RECENTLY REPORTED SUSTAINED WINDS OF 72 MPH...115 KM/HR...WITH

GUSTS TO 85 MPH...137 KM/HR.

THE MINIMUM CENTRAL PRESSURE JUST REPORTED BY AN AIR FORCE RESERVE

HURRICANE HUNTER AIRCRAFT IS 942 MB...27.82 INCHES.

HAZARDS AFFECTING LAND

----------------------

WINDS...TROPICAL STORM CONDITIONS ARE PROBABLY OCCURRING IN THE

VICINITY OF THE TURKS AND CAICOS ISLANDS.  WEATHER CONDITIONS WILL

LIKELY IMPROVE IN THESE ISLANDS TODAY.

STORM SURGE...ABOVE NORMAL TIDES...ACCOMPANIED BY LARGE AND

DANGEROUS BATTERING WAVES...ARE POSSIBLE IN THE TURKS AND CAICOS

ISLANDS AND THE SOUTHEASTERN BAHAMAS THIS MORNING.

RAINFALL...RAINFALL ACCUMULATIONS OF 1 TO 3 INCHES...WITH ISOLATED

MAXIMUM AMOUNTS OF 6 INCHES ARE EXPECTED FOR THE SOUTHEASTERN

BAHAMAS AND FOR THE TURK AND CAICOS ISLANDS.




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e890352b2',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

The hunger riots arising from soaring food prices are a terrible human drama. The world price of wheat has nearly tripled in three years, and doubled in the last year; the price of rice has increased by more than 50 per cent in three months.



The cost of a meal is 40 per cent higher than one year ago in many poor countries. When food purchases can represent 75 per cent of a household’s budget, those price increases become a nightmare.



This could mean the return of millions under the poverty threshold, wiping out several years’ development efforts.



What are the reasons for this situation? Given that the economy is made of complex interconnections, we shall seek the real reasons for the crisis in more depth than is usually done.



The crisis can be interpreted as the unintended consequence — the perverse effect — of several policies which prevent many decision‐​makers from acting responsibly.



First though, let us recall that each year millions can pull themselves out of poverty — thanks to the integration of their economies into globalisation. This is clearly good news but has induced an increasing demand for food, and especially for meat (and cattle needs cereal).



Now we need to understand why food supply does not follow demand. While we do need to take into account climate hazards (like drought in Australia), we mainly need to focus on the direct or indirect political elements that prevent markets from adjusting quantities and maintaining relatively stable prices where possible.



Subsidies in rich countries are sometimes rightly pointed at. They generate two types of effects. First, subsidies divert producers toward subsidised crops.



And when governments subsidise crops for biofuel production, it means less food crops and higher cereal prices.



The second effect is that subsidies combined with tariffs in rich countries close the door to poor countries, preventing them from competing on the markets of rich countries and developing their competitive advantage.



However, it should also be remembered that protectionism amongst African countries especially, is stifling their economies by reducing the possibilities of having productivity‐​enhancing regional markets. Protectionist policies are thus partly responsible here.



Institutional arrangements for agricultural land property are fundamental to the understanding of food problems today. In Africa, the main problem of agriculture is that poorly‐​defined property rights over the land are disincentives for investment.



The major challenge of development policy is to foster agricultural expansion in some countries by allowing institutional arrangements — integrated to local traditions — enabling the responsibility of “farming entrepreneurs.” Only with such incentives will the supply of agricultural production really emerge in some countries.



Interventionist policies from the World Bank and the IMF brought nearly no positive results compared to the massive amounts swallowed up in the aid process. However, they made several poor economies “sustainably dependent.”



Huge debts were created from counterproductive “Big push” utopian programmes, logically followed by structural adjustment programmes. Hence the obligation in aided countries to sometimes develop non‐​food export crops such as cotton in order to reimburse loans. These aid policies thus disturbed the food security of some poor countries.



But they also enriched and maintained irresponsible or corrupted government cliques. International agencies are still lending them money whilst they are oppressing their peoples and preventing them from enjoying economic freedom.



The recent financial crisis was somewhat deflected on the food market, as rice and corn are now investment shelters for speculators. We therefore must seek an indirect explanation of the food crisis behind the financial crisis. What we find are American banks granting too many risky loans. But few people realise that this is strongly linked to the Federal Reserve policy.



First, the Fed kept interest rates low for far too long in the early 2000’s, artificially feeding the housing boom. Second, what is often called the “Greenspan doctrine” produced at least one major perverse effect: that the Fed in a way “insures” losers (banks) who deliberately take risks.



This policy of wrong incentives led to banks acting irresponsibly and eventually degenerated into a global crisis. There is a striking parallel here with the behaviour of the IMF and World Bank: top organisations render other organisations under their control simply irresponsible. However, States and markets work efficiently only if the responsibility of decision‐​makers is sanctioned.



Finally, the oil price surge has an impact on transportation costs, and thus on the final price of food. The increase in oil prices is explained by an increase in demand at the world level with a supply which is essentially a rigid cartel that has not invested to adapt its production.



Besides, oil also represents an investment shelter for speculators in this period of crisis: the price increase can thus partially and indirectly be attributed to the people responsible for the financial crisis.



Emergency aid is necessary to relieve people from disaster. However, after treating the symptom, we will have to deal with the deep structural causes of these disequilibria.



Yet, “responsible” representatives of various organisations and States do not seem to hold a responsible discourse.



We heard references to the New Deal, to lasting supplementary aid by the president of the World Bank, to new market distortions, and even to lasting European protectionism by the French Agriculture Minister.



These are bad omens. This crisis should be an opportunity to promote the idea of responsibility in the system and to rethink development policies in the widest sense. This means changing attitudes within international aid agencies, governments in poor countries, and, of course, in wealthy countries as well. 
"
"So which Easter tradition came first? The packaging or the egg? The answer is of course not that surprising (it’s the egg). The tradition of giving people eggs at spring time has roots in ancient pagan festivals and exists in the history of a range of religions.  It is only in recent decades that the amount of packaging around a hollow chocolate egg has become a noticeable problem – partly because of a rise in the number of eggs sold. It’s true that some manufactures have made progress in reducing packaging, with a big focus on reducing plastics. Many popular eggs are wrapped in just a layer of foil and a card box (plus any wrappers that come on accompanying confectionary). But this does not mean the problem has gone away.  A report by Which? revealed that around a quarter of the total weight of Easter eggs sold in the UK is taken up by the plastic and cardboard packaging they are wrapped up in. The outer packaging of one of the top-ten selling brands tipped the scales at 152g of a 418g product (36.4%).  According to the environmental charity Friends of the Earth, Easter egg makers are still failing when it comes to plastic waste. This leads to some 3,000 tonnes of packaging waste each year. But it is too easy to blame the manufacturer – after all, we buy the eggs. 


      Read more:
      How to defuse the Easter egg 'arms race'


 And the packaging does play some role in protecting the chocolate from damage and contamination – otherwise you may end up with food waste (which is actually far worse).  We appear to be at a stalemate – manufactures do not want to change the big, bright packaging in fear of losing sales. Customers still want to present their friend or relative with a pristine, attractive, traditional gift.  So how can food providers and consumers help to reduce packaging waste? 
Here are a few options (although some may not be so sweet). Make the eggs flat. A two dimensional egg can be packaged far more easily and is less prone to damage than a 3D egg which requires additional packaging to protect those thin chocolate walls around a hollow space. Flat eggs could be made just as attractive and would certainly taste the same. They would also improve logistics efficiency by not having to transport so much air.  “Build your own” Easter egg kits - packs could include everything you need to produce a bespoke egg (including two egg halves) for your loved one. There would be no need for plastic packaging and you would be giving a personalised, hand-crafted gift. Opt for cardboard and items wrapped in packaging that can be recycled – such as cardboard and foil. Typically, it is the more luxurious brands that want to show off their extravagant produce in-store who still use large amounts of plastic.  Avoid getting drawn in by the additional items or “gifts” that may come with eggs. These are the kind of gifts that nobody really wants, such as a low-quality mug or plastic toy – and the negative environmental impact of producing those could be much greater than that of the chocolate egg and packaging combined. And you will pay a premium for them.  Ignore chocolate this Easter and opt for something more meaningful. Regardless of your religion (or lack of), Easter is about new life, not new waistlines. Bake or make something (egg shaped if you like) that your family will really like and will mean much more to them than manufactured chocolate. And which the planet will thank you for too. Whichever way you choose to cut down on packaging this Easter, remember that this is just one of many ways you can reduce your household waste. The world it seems is in the midst of a packaging crisis. Together we can (ahem) crack it."
nan
"Company bosses need to speak out about environmental and social issues if they want to keep their staff and stay in business for the long term, Mike Cannon-Brookes, co-chief executive of Atlassian, said. Research done for Atlassian by the accounting firm PricewaterhouseCoopers showed almost a third of Australian and US workers were willing to quit their jobs if their employer acted in a way that did not align with their values.  “The responsibility of business leaders to provide leadership in areas of the community and participate in leadership alongside government and other groups is something they should be aware of,” Cannon-Brookes said. The number of people willing to leave a company over its stance on social issues was “a lot higher than we expected across the generations”. “There’s a cost of inaction as much as there’s a cost of action here,” he said. Top issues for Australian workers were the cost of living, the long-running drought and access to healthcare. Mental health, the cost of healthcare, pollution and the climate crisis also featured heavily among workers surveyed in December, before the bushfire season hit its peak. “Anecdotally, and obviously in the media and other areas, climate change, long-term planning, listening to experts – there’s a lot of things that I think the horrific summer that we’ve had have highlighted in the minds of society in general,” Cannon-Brookes said. “People in society [whose] house was confronted by a bushfire emergency, they’re people that work in businesses. Businesses are collections of people; business leaders are people.” In the US, workers were most concerned with the cost of healthcare, the highest in the developed world at almost 17% of gross domestic product. Access to healthcare, mental health and poverty were among US workers’ top concerns, pushing environmental issues – including pollution and global heating – down the table. Cannon-Brookes has been outspoken calling for companies to take positions on economic and social issues. Grok Ventures, his and wife Annie’s private investment vehicle, has supported shareholder resolutions put forward by the activist group the Australasian Centre for Corporate Responsibility, designed to put pressure on BHP to quit the Minerals Council. Cannon-Brookes said other business leaders often told him they agreed with his positions on social and environmental issues but felt they could never go public. “If we could remove some of the hesitation, the fear, some of the sense that this is going to be a negative thing for one’s business or one’s personal position, I think we’ll have better conversations as a whole,” he said. He slammed commentators who have called for business leaders to abandon social activism in favour of a narrower focus on generating returns for shareholders. “I’m not sure that the people who are theoretically commenting on returns to shareholders understand how returns to shareholders work,” he said. “Those returns are generated by the employees at some level in whatever business you are. “Attracting and retaining fantastic people is a non-trivial exercise in business nowadays. “There’s a huge correlation if you look at corporate social responsibility between profitable, sustainable businesses and those who care about their corporate social responsibility. “One of businesses’ goals is to stay in business, and to be a sustainable business you need to have fantastic people and take longer-term sustainable positions on a lot of issues.” He said the survey showed employees wanted their business leaders “not to hide in the corner when it comes to important issues for society at large”. PwC surveyed 1,300 Australian and 2,500 US workers across age groups and industries. A partner at PwC, Diane Rutter, said the research showed the risk of inaction for employers was high. “There is a vocal younger cohort or generation coming through the workplace that are personally engaged and quite vocal around societal issues, and their expectations of workplaces are equally high,” she said. Employers who thought they could ignore the data should also be aware there was a reward for taking action. “There’s a large portion of employees that agree that businesses known for speaking out on issues important to them are much more attractive as future employers,” she said. “We see that is significantly higher for Generation Z – so again, that generation coming through.”"
"When Chitty Chitty Bang Bang was released 50 years ago, flying cars were a flight of fancy. Now, these futuristic vehicles are entering the outer fringes of reality. According to a new study published in Nature, for some journeys flying cars could eventually be greener than even electric road cars, cutting emissions while also reducing traffic on increasingly busy roads. However, gaps in necessary technology and practical uncertainties beyond the cars’ promising physics mean that they may not arrive in time to be a large-scale solution to the energy crisis and congestion – if at all. It might at first seem crazy that a flying car could be more efficient than a road car, especially when conventional planes have such a reputation as gas guzzlers.  But flying isn’t inherently inefficient – after all, birds can fly between continents without eating. Of course, a small, four-passenger car isn’t an albatross, but it isn’t a Boeing 737 either. There are many ways to make a car fly, but most are too problematic to get off the ground. Perhaps the most promising option is that taken in this study, based on the physics of vertical take-off and landing (VTOL) aircraft. They’re pretty amazing beasts. If you’ve heard of VTOL, something like a Harrier Jump Jet probably springs to mind, with two huge engines directing thrust that can be tilted vertically or horizontally. But these much smaller and lighter flying cars operate differently, with lots of tiny electric fans blowing air from many places. This fast-developing distributed electric propulsion (DEP) technology is key for efficiency when cruising, and it also creates possibilities for quieter take-off and hovering, as multiple small noise sources can be better managed. Wing and propeller design can also be optimised to be long, thin, and have lots of moving surfaces, just as birds do to make their flying efficient. The aim of all of these technical enhancements is to achieve maximum lift for minimum drag – the force that opposes an object’s motion through air and slows it down. A better lift-to-drag ratio means lower power consumption, and therefore lower emissions. These energy-saving innovations make cruising a breeze – but they don’t help much with take-off, hovering, or landing, which are still inherently inefficient. So while VTOL flying vehicles are still viable for short intra-city travel and pizza deliveries, they will not solve the energy crisis. For 100km journeys, electric flying vehicles could be 35% more efficient than a petrol-powered car – although, assuming the same number of passengers, still less efficient than an electric road car. However, it’s fair to assume that flying cars will serve primarily as taxi services in pre-defined air corridors, and are therefore likely to consistently carry more people. Taking this into account, for a 100km journey flying car emissions could be 6% less than those of electric road cars. As journey distance increases, so too do the efficiency gains over stop-start road cars, which have to deal with rolling resistance and less efficient airflow. But unfortunately, range is the Achilles heel for electric aviation.  The study looks at a range of up to about 200km and here flying cars could perform well. But while jet-fuelled planes can lose as much as 70% of their weight during flight (albeit at a cost of 100kg of CO₂ per passenger per hour), batteries don’t get lighter as they discharge. This means that beyond 200km or so, carrying batteries becomes a distinct disadvantage. The accepted view is that electric planes will only ever be viable for short-haul flights. It’s energy density that matters, measured in watt-hours per kilogram. Right now, the best batteries provide around 250 W-h/kg, a mere shadow of jet fuel and gasoline’s 12,000 W-h/kg. Batteries could creep up to 800 W-h/kg by the middle of this century, increasing their feasible range to 700 miles – half of all global flights fall within this distance. But without more dramatic innovation in battery technology, biofuels and liquid fuel from air-capture of CO₂ will likely need to play a substantial role in long-haul air travel. In focusing entirely on the physics of flying cars, the paper steers clear of a number of practicalities that must be considered before we embrace VTOL flying cars as a sustainable form of transport for the future. For example, it is important to consider the carbon costs of production, maintenance and down time, known as Life-Cycle Analysis (LCA). Electric vehicles have been criticised for both the energy and environmental costs of mining primary materials for batteries, such as lithium and cobalt. Added infrastructure required for flight may worsen the problem for flying cars. And of course, a grid powered by low-carbon sources is essential to make battery-powered vehicles part of the solution to our climate crisis. Aircraft also have highly stringent criteria for maintenance and downtime, which can often offset gains in performance and emissions. As an entirely new breed of planes, it’s impossible to predict how much it might cost to keep them air-worthy. Unforeseen maintenance complications can cost billions – just ask Boeing.   Finally, weather matters. A tailwind of 35mph reduces power use and emissions by 15%, but a 35mph headwind increases them by 25%. Having to carry heavy extra batteries to avoid the potential catastrophe of running out of charge before encountering a suitable landing place could offset emissions savings. Road cars, by contrast, can easily pull over to the side of the road when needed, without consequence. So when it comes down to CO₂ emissions per passenger kilometre, at present these advanced DEP flying cars are at best comparable to their road-going electric equivalents, and, at worst, little better than conventional combustion cars. With technology and safety improvements, they could yet play a part in our fossil-fuel-free future, taking short-haul planes out of our skies and freeing up fume-filled roads. The question on everyones’ lips is whether these flying cars will be ready in time to make a jot of difference to our very pressing energy crisis. Can we wait 30 years? Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"The coronavirus pandemic is shutting down industrial activity and temporarily slashing air pollution levels around the world, satellite imagery from the European Space Agency shows. One expert said the sudden shift represented the “largest scale experiment ever” in terms of the reduction of industrial emissions. Readings from ESA’s Sentinel-5P satellite show that over the past six weeks, levels of nitrogen dioxide (NO2) over cities and industrial clusters in Asia and Europe were markedly lower than in the same period last year. Nitrogen dioxide is produced from car engines, power plants and other industrial processes and is thought to exacerbate respiratory illnesses such as asthma. While not a greenhouse gas itself, the pollutant originates from the same activities and industrial sectors that are responsible for a large share of the world’s carbon emissions and that drive global heating. Paul Monks, professor of air pollution at the University of Leicester, predicted there will be important lessons to learn. “We are now, inadvertently, conducting the largest-scale experiment ever seen,” he said. “Are we looking at what we might see in the future if we can move to a low-carbon economy? Not to denigrate the loss of life, but this might give us some hope from something terrible. To see what can be achieved.” Monks, the former chair of the UK government’s science advisory committee on air quality, said that a reduction in air pollution could bring some health benefits, though they were unlikely to offset loss of life from the disease. “It seems entirely probable that a reduction in air pollution will be beneficial to people in susceptible categories, for example some asthma sufferers,” he said. “It could reduce the spread of disease. A high level of air pollution exacerbates viral uptake because it inflames and lowers immunity.” Agriculture could also get a boost because pollution stunts plant growth, he added. The World Health Organization describes NO2 as “a toxic gas which causes significant inflammation of the airways” at concentrations above 200 micrograms per cubic metre. Pollution particles may also be a vector for pathogens, as well as exacerbating existing health problems. The WHO is now investigating whether airborne pollution particles may be a vector that spreads Covid-19 and makes it more virulent. One of the largest drops in pollution levels could be seen over the city of Wuhan, in central China, which was put under a strict lockdown in late January. The city of 11 million people serves as a major transportation hub and is home to hundreds of factories supplying car parts and other hardware to global supply chains. According to Nasa, nitrogen dioxide levels across eastern and central China have been 10-30% lower than normal. NO2 levels also dropped in South Korea, which has long struggled with high emissions from its large fleet of coal-fired power plants but also from nearby industrial facilities in China. The country has avoided putting entire regions under lockdown but is meticulously tracing and isolating suspected coronavirus cases. The changes over northern Italy are particularly striking because smoke from a dense cluster of factories tends to get trapped against the Alps at the end of the Po Valley, making this one of western Europe’s pollution hotspots. Since the country went into lockdown on 9 March, NO2 levels in Milan and other parts of northern Italy have fallen by about 40%. “It’s quite unprecedented,” said Vincent-Henri Peuch, director of the Copernicus Atmosphere Service. “In the past, we have seen big variations for a day or so because of weather. But no signal on emissions that has lasted so long.” The source is not yet clear. One possibility is a slowdown of activity in Italy’s industrial heartland. Another factor is likely to be a reduction in road traffic, which accounts for the biggest share of nitrogen dioxide emissions in Europe. Peuch said satellites were now starting to pick up similar signals in other European cities that are entering into lockdowns, though the data needs to studied over over a longer period to confirm this is a pattern. Although the UK is more than a week behind Italy in terms of the spread of the disease and the government’s response, roadside monitors already show significantly reduced levels of pollution at hotspots such as Marylebone in London. Road traffic accounts for about 80% of nitrogen oxide emissions in the UK, according to Monk. For the average diesel car, each kilometre not driven avoids 52 milligrammes of the pollutant entering the air. “What I think will come out of this is a realisation - because we are forced to - that there is considerable potential to change working practices and lifestyles. This challenges us in the future to think, do we really need to drive our car there or burn fuel for that,” said Monk."
"

From NASA news:


See inset view below.

 On April 29, the MODIS image on the Terra satellite captured a wide-view  natural-color image of the oil slick (outlined in white) just off the  Louisiana coast.  The oil slick appears as dull gray interlocking comma  shapes, one opaque and the other nearly transparent.  Sunglint — the  mirror-like reflection of the sun off the water — enhances the oil  slick’s visibility.  The northwestern tip of the oil slick almost  touches the Mississippi Delta. Credit: NASA/Earth Observatory/Jesse  Allen, using data provided courtesy of the University of Wisconsin’s  Space Science and Engineering Center MODIS Direct Broadcast system.
› Larger image
NASA’s Terra and Aqua satellites are helping the National Oceanic and  Atmospheric Administration (NOAA) keep tabs on the extent of the recent  Gulf oil spill with satellite images from time to time. NOAA is the lead  agency on oil spills and uses airplane fly-overs to assess oil spill  extent.
A semisubmersible drilling platform called the Deepwater Horizon located  about 50 miles southeast of the Mississippi Delta experienced a fire  and explosion at approximately 11 p.m. CDT on April 20. Subsequently,  oil began spilling out into the Gulf of Mexico and efforts to contain  the spill continue today. NASA’s Terra and Aqua satellite imagery has  captured the spill in between cloudy days.
NOAA used data from the Moderate Imaging Spectroradiometer or MODIS  instrument from the Terra satellite on April 26, 27 and 29 to capture  the extent of the oil spill, which measured 600-square-miles. The MODIS  instrument flies aboard both the Terra and Aqua satellites.
 This satellite image from NASA’s Terra satellite on April 27 at 12:05  CDT shows the outline and extent of the oil slick from the Deepwater  Horizon drilling platform. The red dot represents the platform.  The  coasts of Mississippi and Alabama appear at the top of the image. Credit: NOAA/NASA
› Larger image In the satellite image from April 27 at 12:05 p.m. CDT the MODIS image  showed that the oil slick was continuing to emanate from the spill  location. Individual slicks lay just north of 29 degrees and zero  minutes north, where they have been noted in the days before. Oil had  spread further east and the edge of the slick passed 87 degrees and 30  minutes west compared to the MODIS image taken on April 26. The April 26  satellite image came from NASA’s Aqua satellite.
On April 29, the MODIS image on the Terra satellite captured a  natural-color image of the oil slick just off the Louisiana coast. The  oil slick appeared as dull gray interlocking comma shapes, one opaque  and the other nearly transparent. The northwestern tip of the oil slick  almost touches the Mississippi Delta.
Deepwater Horizon had more than120 crew aboard and contained an  estimated to 17,000 barrels of oil (700,000 gallons) of number two fuel  oil or marine diesel fuel.
Today, April 30, NOAA declared the Deepwater Horizon incident “a Spill  of National Significance (SONS).”  A SONS is defined as, “a spill that,  due to its severity, size, location, actual or potential impact on the  public health and welfare or the environment, or the necessary response  effort, is so complex that it requires extraordinary coordination of  federal, state, local, and responsible party resources to contain and  clean up the discharge” and allows greater federal involvement. NOAA’s  estimated release rate of oil spilling into the Gulf is estimated at  5,000 barrels (210,000 gallons) per day based on surface observations  and reports of a newly discovered leak in the damaged piping on the sea  floor.
NOAA reported on April 29 that dispersants are still being aggressively  applied to the oil spill and over 100,000 gallons have been applied.   NOAA’s test burn late yesterday was successful and approximately 100  barrels of oil were burned in about 45 minutes.    NOAA is flying planes over the area and using NASA satellite imagery  from the Terra and Aqua satellites to monitor the spill.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8bc8ea96',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"British-owned car manufacturing has been in decline in UK for decades but the shift to electric cars might be just what is needed for a revival. The recent announcement by US-based Detroit Electric that it will move its production to the UK highlights some of the engineering strengths Britain possesses – but will local entrepreneurs see it too?  Britain might be a minor player in the emerging hybrid and pure electric vehicle (EV) market, but it was not always so. Indeed, the UK has a credible claim to have invented both the electric locomotive carriage in the 1830s, and the electric car in the 1880s. By the late 1880 and 1890s, the UK and France were leading the world in the deployment of the vehicles, with an electric taxi firm operating on London streets by the turn of the 20th century. Sadly its time was not to be and during most of the 20th century, the internal combustion engine made greater advances in price, range and performance; electric vehicles were pushed into niche markets such as indoor moving equipment or milk deliveries. The decline in British industry throughout the 1960s, 1970s and 1980s meant EV firms lacked access to both the most recent technology and domestic car-makers who might operate as partners and clients. One of the reasons why Japan played such a prominent early role is that advances made in industries such as consumer electronics could be transferred across to automotive mass-production – sometimes within the same group of companies. Yet, to say Britain can’t compete because it lacks a “domestic champion” car-maker would be letting its would-be innovators off too lightly. Tesla Motors succeeded precisely because it wasn’t a large car maker, but a small company with a big idea that was willing to take the risks it’s bigger rivals wouldn’t.  In 2008, many automotive multi-nationals were sceptical of EV technology and the electric cars they developed were typically less reliable and lower powered than their petrol and diesel equivalents. Tesla upturned expectations by aiming squarely at cash-rich early adopters. It was an audacious pitch and Elon Musk, internet tycoon turned Tesla founder, was not an experienced car-maker. He therefore turned towards the British firm Lotus Cars to provide the “glider” or body of the car. In this move Californian money and technology was married with British design and production to provide an eye-catching, prestige vehicle that was also sufficiently lightweight to suit the lower weigh-to-power ratio of EVs.  Given Tesla’s success it is not surprising that others such as Albert Lam, a former Lotus executive, emulated its strategy. Lam first moved into the EV market by reviving the Detroit Electric brand – a firm that had been one of the pioneers of electric vehicles in the early 1900s, before ceasing production in 1939. Today its flagship SP.01, marketed as “the fastest EV on the market” also makes use of a Lotus designed body but goes a step further than Tesla by basing its European factory in Royal Leamington Spa, West Midlands. Lam himself is no stranger to the area: he has a degree from Coventry University and has held positions in local car-makers Jaguar and Land Rover. No doubt he is aware of the region’s association with low-volume prestige brands, its excellent supply base, world-leading motorsports expertise and strong R&D facilities focused on low-carbon vehicles.  Indeed, the British car industry looks attractive for overseas investors in general. Nissan’s decision to assemble the market-leading Leaf in its Sunderland plant makes sense: the UK has high-levels of productivity in the sector (second only to Germany in Europe), favourable corporate tax levels, a package of government incentives for electric vehicle consumers and a buoyant car market. In short, the country has a lot to offer EV manufacturers. This being the case it’s worth asking why it has taken an American company to recognise the value of these assets. Mostly it comes to down to technology, money and perhaps some entrepreneurial caution. The UK has its strengths but there are notable gaps to make the transition to EV. Industry analyst Peter Harrop of IDTechEx notes that the UK is “world-class in terms of innovative component suppliers” but “nowhere” in terms of electric car batteries. Another big problem is the availability of cash (or even credit) to fund a jump into electric. Britain’s small band of domestic car makers tend to operate on a relatively small scale and often struggle to finance their existing lines. Coventry University Entreprise’s research into suppliers found that without big clients emergent EV technology firms lack partners to take prototypes into production and often shift into engineering consultancy rather than manufacturing. Detroit Electric’s move into the UK could certainly catalyse the industry. It would provide a client for component suppliers looking to move into a new field; a partner for training academies to develop a new generation of engineers – and, most importantly, it represents a model for other entrepreneurs to follow.  Albert Lam is not a tycoon in the style of Elon Musk, but a businessman who has spotted an opportunity and brought together a classic brand, US technology, British production and access to the North American and European markets in an endeavour that is likely to capture people’s attention, at the very least. Succeed or fail, the lesson for British entrepreneurs is clear: make use of the assets you’ve got, but think global. The window for innovations in the electric vehicle market is still open but it may not be for too long."
"Everybody seems to be talking about climate change again. This time, a great deal of the coverage has been sympathetic to the idea that we are facing an emergency that demands drastic action.  Extinction Rebellion’s protests caused some outrage, but also some surprising support. Swedish campaigner Greta Thunburg has been widely admired, David Attenborough has been spreading the word with urgency, and primetime programming has led to serious discussions about climate change across living rooms, offices and social media.  So is this the fabled tipping point in public opinion which will see widespread support for radical changes? That is a question that can only be answered in hindsight.  Yet despite the significant surge in interest and concern, most people are probably unaware of what climate change really means: that it’s not just about nudging our emissions a bit lower or taking incremental action generally. This is a challenge that is perhaps unprecedented in all of human history.  Given that I teach climate change to university students, I can (and do) talk for hours about the importance of global temperature change, or ecological impacts.  But these are academic concerns in the sense that they are almost completely separated from what climate change means to me, my family, friends and pretty much everything else I care about. It’s taken me some time to realise that I was in a sort of denial about climate change. I was able to compartmentalise it.  Reflecting on this led me to take a step over the line that separates academia from activism. I have colleagues and friends who are strict observers of this separation of states. Some of them have deeply principled concerns that advocating for particular climate related policies could undermine their professional objectivity.  Others have little desire to be the subject of the online abuse which often comes with sticking your head above the parapet and into the public debate.  I had these same reservations. But over time they have been gradually worn down by the steady drum beat of bad news and insufficient action. My personal tipping point was an otherwise unremarkable lecture to one of my undergraduate classes.  I was discussing atmospheric concentrations of carbon dioxide in the atmosphere over time, and pointed out that this has been increasing ever since they were born. On each one of their birthdays, there was more CO₂ in the atmosphere than on the same day the previous year. Every additional birthday cake candle celebrated another one, two, or even three per cent annual increase.  As I spoke, I looked into the faces of a generation that had been completely failed by their predecessors. It is a failure which came despite two decades of the science being perfectly clear that increasing CO₂ concentrations would produce further warming, and that dangerous changes to the global climate were lurking.  That was when I realised that the positive professional and personal changes I had managed to make were hopelessly inadequate. Yes, I avoided flying where possible, and yes, I had largely eliminated meat and dairy from my diet.  I cycle rather than drive. I had switched to a green energy supplier. All that was good. All that was important. But I keenly felt the need to do more.  So I decided to make a documentary about climate change – about what drives it and what we can do individually, and together, to ensure a stable natural world for our children and future generations.  Why a film? It was a chat with a good friend, film maker Paul Maple of Global Documentary, about our shared frustrations over the lack of climate change programmes being broadcast which led to plans to make our own.  I had no idea what would be involved, and Paul didn’t tell me – perhaps from fear of scaring me off. That was over three years, a thousand miles of travel around the UK, terabytes of data, and countless coffee-fuelled hours in the editing suite, ago.  All of that work has now been rendered down to the 39 minutes of The Race Is On: Secrets and Solutions of Climate Change. In making the film, we were extremely fortunate to be able to interview leading figures in climate change science, economics and activism. I wouldn’t be able to name them all here without also naming the 67 people who contributed to the crowdfunding of the project and so help turn our initial sketchy plans into reality.  Early on, we agreed that a film, no matter how slick, could only be one part of an engagement strategy. So we planned community screenings, in which the film would be followed by panel discussions and town hall style meetings. We also produced a companion website containing information on practical steps we can all take to reduce our climate impacts.  The journey from academic to film maker activist is not something I can unreservedly recommend. I’ve had to park aspects of my professional and personal life, given how all consuming the project was. And now I seem to have taken up a new role as distributor and promoter, as the film will have no value unless people watch it.  But while I hope that this will be more than offset by generating positive impact, it’s also true that on a personal level it’s been worth it. I’ve met some incredible people, been allowed to go places and do things that otherwise would have been out of bounds (it’s amazing what you can get away with when accompanied by a film crew), and learnt new skills that have helped both my teaching and research.  The film project has been a labour of love. At times, a stress test, and finally a ragged race to deadlines – so something like a microcosm of the civilisation-scale climate challenge we all now face.  Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"
Me ~ ctm
By charles the moderator
Here’s the link.
I have no other comment.
From congress.org

Global Warming could make Humans EXTINCT within 50 years
Kill mechanisms list
Global Warming could make the human race EXTINCT.   The #1 kill  mechanism is famine.   See “The Long Summer” by Brian Fagan and  “Collapse” by Jared Diamond.   Shifting winds and warmer oceans have  already created a weird moving checkerboard of drought and flood that  has interfered with agriculture here and elsewhere.
The extra heat has caused heat related deaths already.
The book “Six Degrees” by Mark Lynas says:  “If the global warming is 6  degrees centigrade, we humans go extinct.”  The book lists several kill  mechanisms, the most important being famine and methane fuel-air  explosions.   Other mechanisms include fire storms.
“Under a Green Sky” by Peter D. Ward, Ph.D., 2007 says H2S bubbling out  of hot oceans is the final blow at 6 degrees C warming.
===========================
read the rest at congress.org



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b01272b',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterI was going to post this tomorrow, but what the hell…

ATTENTION GERMAN READERS: 21:05 mark has a rather damning observation about Germans in general. So why is it Germans are so damn pessimistic?

Does it have to do with all the alarmist scientists out here at places like the PIK, AWI and MPI, to name a few? Why is pessimism viewed as intellectually superior to optimism? The best thing Germany could do would be to start deporting all the top pessimism spreaders. Just imagine how quickly and how much better the country would get.
And if you haven’t already, also read Ridley’s view on why wind energy is going to flop.
http://www.rationaloptimist.com/blog/the-beginning-of-the-end-of-wind.aspx
 
Share this...FacebookTwitter "
nan
"**The number of cases in a Covid cluster linked to an Aberdeenshire food plant has risen to 86.**
NHS Grampian said a further eight cases were now associated with the Kepak McIntosh Donald plant in Portlethen.
An incident management team has been set up to monitor the situation involving the premises.
More than 200 workers at the site took up the offer of testing after the first cases were detected.
NHS Grampian previously said that given the large numbers of people being tested, it expected the number of confirmed infections to rise.
In a statement on Thursday the health board said: ""All are being supported to self-isolate as required.
""We continue to work closely with Kepak McIntosh Donald and are very grateful for their co-operation."""
"


From the “weather is not climate” department.
By Steven Goddard
I noticed something interesting in the  NCEP forecast for the  coming week. Temperatures are predicted to be below normal across a  7,000 mile swath of the Americas. That is more than one fourth of the  way around the earth. Below is a composite image of generated from three  of the NCEP maps.
Looks like another cold soccer Saturday, across the entire US. Of course there are other places on the Earth that will have above normal temperatures, but this seemed noteworthy for the dual hemispheric scope, even it is just “weather”.
Here’s the USA forecast to May 6th. Note that much of the West will be well below normal with neutral to slightly above normal in the East:

And South America:

Source: NCEP forecast page.
=====================
Please no grousing about the USA being in °F and South America being in °C. That’s the way NCEP provides the maps. – Anthony




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c7c681d',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterChris Horner posted a video on Facebook a few a hours ago where he reviews and brings us up to date on the efforts by the University of Virginia faculty to defy the law of the land by refusing to release taxpayer-owned documents surrounding Climategate.

There must be some something really embarrassing that needs to stay hidden, no matter the cost, as Mann and the faculty appear awfully desperate in their attempts to defy the Freedom of Information Act. Chris Horner states at the 12:18 mark:
Those people who don’t like us asking for the records have a problem with the law, and they have a problem with the University of Virginia complying.”
Mann and the faculty are applying a pressure campaign against the University in order to keep the public records under wraps. Horner:
The UVA said to us that they find themselves in a very difficult position with their faculty. And we pointed out to them that this difficult position they find themselves in is between their faculty and the law.”
And judging from Steve McIntyre’s latest post, Mann’s desperation is visible throughout his book, and reveals a person on the verge of losing it. Whenever you start getting paranoid ideas that the fossil fuel industry is and is out to get you by orchestrating a few blog sites, then you really have got to wonder. Not only has Mann run out of lies, but he is resorting to re-lying, as McIntyre points out. Mann s becoming a serious embarrassment to Jefferson’s university.
 
Share this...FacebookTwitter "
"**Here are five things you need to know about the coronavirus pandemic this Thursday morning. We'll have another update for you this evening.**
People in England will find out later which of three tiers of restrictions they will face when the national lockdown ends next week. And our political editor Laura Kuenssberg understands only a handful will be in the lowest tier, with most areas - including London - in tier two and ""significant numbers"" facing the toughest restrictions.
A government scientific adviser says the UK-wide relaxation of rules over Christmas - allowing three households to form a bubble between 23 and 27 December - amounts to ""throwing fuel on the Covid fire"". However, as health correspondent Nick Triggle reports, others argue there are huge benefits, and that the pivot from ""paternalism to partnership"" could help build public trust ahead of mass vaccination.
Average pay packets could be Â£1,200 a year smaller by 2025 as a result of the pandemic, according to analysis from a think tank focused on improving living standards for people on low-to-middle incomes. ""Weaker pay growth and higher unemployment will serve to prolong Britain's living standards squeeze"", warns the Resolution Foundation. Meanwhile, with union leaders furious over a pay freeze on at least 1.3 million public sector workers, Chancellor Rishi Sunak tells the BBC he ""couldn't justify"" a rise when the disparity with private sector pay had widened.
Our knowledge of the long-term illness ME - or chronic fatigue syndrome - has helped specialists treat long Covid, the lingering effects suffered by some people who catch coronavirus. Evan was diagnosed with ME in 2017, and she believes her experience can help her support those living with long Covid.
It's been a terrible year for many industries and cinema has been among the worst hit, with most of the year's planned blockbusters put on hold in light of the various global lockdown restrictions. Movie theatres have paid the price, with Cineworld temporarily shutting up shop in the UK. But is the era of the Hollywood blockbuster over, or do busy cinemas in Asia offer a glimmer of hope?
Get a longer daily news briefing from the BBC in your inbox, each weekday morning, by signing up here.
You can find more information, advice and guides on our coronavirus page.
Here's a rundown of the rules around Christmas across the UK, restrictions for the various tiers in England and Scotland, and details of what's allowed in Wales and Northern Ireland.
**What questions do you have about coronavirus?**
_ **In some cases, your question will be published, displaying your name, age and location as you provide it, unless you state otherwise. Your contact details will never be published. Please ensure you have read our**_terms & conditions _ **and**_privacy policy.
Use this form to ask your question:
If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or send them via email to YourQuestions@bbc.co.uk. Please include your name, age and location with any question you send in."
"
No Swearing sign on Atlantic Avenue, Virginia Beach, VA Photo: Steph Doyle
Gosh, I try to keep a semblance of decorum here at WUWT. I get upset when name calling starts and moderators are trained to clamp down on this sort of thing. That being said, can you imagine the caterwauling that would ensue if I wrote something like this piece below?
Andrew Revkin and I disagree on climate, but we maintain what I deem to be a civil, professional tone when we correspond. That’s how it should be. Foul language isn’t needed to get points across.
Joe Romm at Climate progress just showed his true colors by not only allowing such foul behavior, but actually encouraging it in the form of a guest post that he edited. I don’t buy Romm’s excuse that he was trying to “show some of the real anger over Revkins column”.
In my view, profanity is the last refuge of the disingenuously desperate.
Warning – foul language follows

Here’s the guest piece from Climate Progress, the last few paragraphs follow:
So, here’s a challenge for Andy Revkin: Do not write another word about climate science until you have spent one whole month as a visitor in a climate research institute. Attend the seminars, talk   to the PhD students, sit in on meetings, find out what actually goes  on  in these places. If you can’t be bothered to do that, then please shut the fuck up.
Update: On reflection, I think I was too generous to Revkin when I   accused him of making shit up, so I deleted that bit. He’s really just   parroting other people who make shit up.
Update #2: Oh, did I mention that I’m a computer scientist? I’ve   been welcomed into various climate research labs, invited to sit in on   meetings and observe their working practices, and to spend my time   hanging out with all sorts of scientists from all sorts of disciplines.   Because obviously they’re a bunch of tribalists who are trying to hide   what they do. NOT.
– Steve Easterbrook
=================================================
Gosh.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e899a4ec3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

Madame Chairman, Distinguished Members of the Committee:



My name is Michael Tanner and I appreciate the invitation to appear today and the opportunity to share my perspective on the vital issue of reforming health care and what Wisconsin should and should not do to help resolve this issue.



For the past 14 years, I have been director of health & welfare studies for the Cato Institute in Washington, DC. Before that I served as legislative director for the Georgia Public Policy Foundation and as legislative director for health & welfare with the American Legislative Exchange Council. In all, I have spent more than 20 years studying the American health care system and am the author of five books on health care reform, most recently _Healthy Competition: What’s Holding Back American Health Care and How to Free It_.



During my time studying this issue, I have concluded that, in developing health policy it is vital to keep in mind one pertinent fact: for all its problems, the United States offers the highest quality health care in the world. Most of the world’s top doctors, hospitals, and research facilities are located in the United States. Eighteen of the last 25 winners of the Nobel Prize in Medicine either are U.S. citizens or work in this country.1 U.S. companies have developed half of all the major new medicines introduced worldwide over the past 20 years.2 In fact, Americans played a key role in 80 percent of the most important medical advances of the past 30 years.3 Nearly every type of advanced medical technology or procedure is more available in the United States than in any other country.4 By almost any measure, if you are diagnosed with a serious illness, the United States is the place you want to be. That is why tens of thousands of patients from around the world come to this country every year for treatment.



Of course, I’m aware that, as critics of American health care often point out, other countries have higher life expectancies and lower infant mortality rates, but those two indicators are not a good way to measure the quality of a nation’s health care system. In the United States, very low‐​birth‐​weight infants have a much greater chance of being brought to term with the latest medical technologies. Some of those low‐​birth‐​weight babies die soon after birth, which boosts our infant mortality rate, but in many other Western countries, those high‐​risk, low‐​birth‐​weight infants are not included when infant mortality is calculated.



And life expectancy is a poor measure of a health care system. Life expectancies are affected by exogenous factors such as violent crime, poverty, obesity, tobacco and drug use, and other issues unrelated to health care. As the OECD explains, “It is difficult to estimate the relative contribution of the numerous non‐​medical and medical factors that might affect variations in life expectancy across countries and over time.“5 Consider the nearly three year disparity in life expectancy between Utah (78.7 years) and Nevada (75.9 years), despite the fact that the have essentially the same health care systems.6 In fact, these exogenous factors are so distorting that if you correct for homicides and accidents, the U.S. rises to the top of the list for life expectancy.7



On the other hand, when you compare the outcome for specific diseases like cancer or heart disease, the United States clearly outperforms the rest of the world. Take prostate cancer, for example. Even though American men are more likely to be diagnosed with prostate cancer than their counterparts in other countries, we are less likely to die from the disease. Less than one out of five American men with prostate cancer will die from it, but 57 percent of British men and nearly half of French and German men will. Even in Canada, a quarter of men diagnosed with prostate cancer, die from the disease.



Similar results can be found for other forms of cancer. For instance, just 30 percent of U.S. citizens diagnosed with colon cancer die from it, compared to fully 74 percent in Britain, 62 percent in New Zealand, 58 percent in France, 57 percent in Germany, 53 percent in Australia, and 36 percent in Canada. Similarly, less than 25 percent of U.S. women die from breast cancer, but 46 percent of British women, 35 percent of French women, 31 percent of German women, 28 percent of Canadian women, 28 percent of Australian women, and 46 percent of women from New Zealand die from it.8



Wisconsin, in fact, is the home of several top flight medical centers, including the University of Wisconsin Hospital and clinics.9



Clearly, there are problems with the U.S. health care system. Costs are rising and distributed in a way that makes it difficult for some people to afford the care they want or need. Moreover, while the number of uninsured Americans is often exaggerated, there are far too many Americans without health insurance, including as many as 481,000 Wisconsin residents at any point in time, roughly 8.8 percent of the population. And while the U.S. provides the world’s highest quality health care, that quality is uneven and too often Americans don’t receive the standard of care that they should.



It is important, therefore, that any reform of the health care system, either nationally or here in Wisconsin, not destroy those things that make our health care system so effective‐​individual choice and free markets. In particular, you should avoid the temptation to increase government regulation and control over the state’s health care system. I am concerned, therefore, that Healthy Wisconsin is headed down the wrong road to reform.





Under Healthy Wisconsin, every state resident except government workers and those currently enrolled in Medicare or Medicaid/​SCHIP/​BadgerCare would be required to join a tax‐​financed “healthy care network.“10 Healthy Wisconsin also extends its reach across the state’s borders, requiring some 158,000 workers who live in other states but work in Wisconsin to enroll.11



These networks would be composed of a wide range of health care providers, including physicians (both primary care and specialists), physicians’ assistants, nurses, clinics, one or more hospitals, and facilities for the treatment of mental illness, drug abuse, and alcoholism.



Each network would submit a bid detailing the per‐​person cost for providing health care to all persons signing up for that network. On the basis of these bids, the state will divide networks into two categories‐​low cost and high cost. Those who enroll in the low cost network will have their costs fully covered by the state, while those enrolling in high cost networks may have to pay an additional fee of up to $1,200 per year for an individual and $2,400 for a family.12



For the most part, networks would be geographically‐​based, generally defined by the board as being within a 30 minute drive, or 60 minutes by mass transit from the patient’s residence.13 However, statewide networks would also exist to serve a few special occupational groups, notably farmers and teachers.14



The legislation does not specify how network providers are to be reimbursed. However, since the network’s total revenue is limited to their bid, presumably reimbursement will be on a capitated, rather than a fee‐​for‐​service basis. Networks are required to spend at least 92 percent of revenues on the provision of services or capital investments.15



Private health insurance will be prohibited for services covered under Healthy Wisconsin.16 Individuals who are currently satisfied with their health insurance would nonetheless lose that insurance and be required to join the new plan. In many cases, this would mean that individuals would no longer have access to their current providers. For instance, if a woman’s primary care physician joined network A, but her ob‐​gyn joined network B, she would be forced to choose between them. Moreover, since the networks are geographically based, it is possible that none of her current physicians may be included in the networks from which she’s allowed to choose. And if their networks were classified in the upper tier, she would have to pay extra in order to join that network and continue to see the physician of her choice.



In theory, the state will also establish a state‐​wide, fee‐​for‐​service plan similar to Medicare or Canada’s single‐​payer system.17 There is to be an additional charge for participating in this plan unless an individual lives in an area without a network. The Board will determine reimbursement rates under this plan, which are to be “fair and adequate,” yet these terms remain undefined.18 Supporters of Healthy Wisconsin have suggested that Medicare’s “very reasonable” fee schedule should be the basis for reimbursements.19



It is unclear whether physicians would be able to accept patients outside the new system on a cash, private‐​contract basis. However, since participation in Healthy Wisconsin is mandatory for patients, those who wanted to pay out‐​of‐​pocket for care would necessarily be paying twice for such care–once through taxes to support Healthy Wisconsin and once on their own.



The benefits networks provide must be at least as generous as those provided by the state to lawmakers and the governor, and must also provide mental health and drug and alcohol rehabilitation benefits not currently included in the state plan.20 But the benefits may be far more generous. The Healthy Wisconsin Board is given unrestricted powers to add whatever benefits it decides would “reduce health care costs, avoid health care risks, or result in better health outcomes.“21 That language represents a virtual blank check and an open invitation for special interests to seek inclusion for their specialty or disease. Considering that Wisconsin already has some 31 mandated insurance benefits adding as much as 20 percent to the cost of an insurance policy in the state, it is reasonable to expect a further expansion of the benefits package.22



Public choice dynamics are such that providers (who would make money from the increased demand for their services) and disease constituencies (whose members naturally have an urgent desire for coverage of their illness or condition) will always have a strong incentive to lobby legislators for inclusion under any minimum benefits package. The public at large will likely see resisting the small cost increase caused by any particular additional benefit as unworthy of a similar effort. It is a simple case of concentrated benefits and diffused costs.



Even Alain Enthoven, who helped develop the idea of managed competition (see below) says that Healthy Wisconsin advocates are “naive” to believe that special interests and provider lobbies can be restrained.23





Healthy Wisconsin combines many aspects of a single‐​payer health care system with the central structure of a concept known as “managed competition,” the brainchild of Stanford University professor Alain Enthoven who testified in favor of the bill at the hearing that the Senate held on the proposal.24 The underlying concept behind both the 1993 Clinton health care plan and Mitt Romney’s Massachusetts reform, it is designed to take advantage of market competition, but within an artificial and carefully regulated marketplace.



Thus, in theory, Wisconsin residents are able to choose between competing “healthy care networks.” But any competition between networks would take place on a very constrained basis. For example, since all plans are required to offer the same core benefits package, there will only be marginal competition based on benefit design. There is price competition only in so far as upper‐​tier networks may require an additional fee. But again, such competition is strictly at the margins. For the vast majority of Wisconsin residents, they will pay the same amount (through their payroll tax) regardless of which plan they choose.



In addition, networks are prohibited from adjusting premiums based on such risk factors as age, sex, or health status.25 This is especially problematic because an inability to price according to risk typically results in overprovision of care to the healthy and under‐​provision to the sick.26



As University of Chicago law professor Richard Epstein has pointed out, “Managed competition is not so much a coherent government plan as an oxymoron. It is possible to have either managed health care or competition in health care services. It is not possible to have both simultaneously.“27 Even Alain Enthoven agrees that “managed competition is not a free market.“28



Healthy Wisconsin goes a step further, combining managed competition with key features of a single‐​payer plan such as global budgeting, thereby borrowing the worst of both worlds.





While universal coverage is the most discussed rationale for Healthy Wisconsin, the proposal also has a second, and to some degree contradictory goal-“health care reform shall implement cost containment strategies that retain and assure affordable coverage for all residents of this state.“29



However, it contains few effective cost control mechanisms. Deductibles are limited to $300 per year for an individual and $600 for a family.30 Co‐​payments are limited to $20 per health care encounter, and combined yearly, out‐​of‐​pocket expenses (for both co‐​payments and deductibles) are limited to $2,000 for an individual and $3,000 for a family.31 There are no deductibles or co‐​payments at all for children, pregnant women, or people in disease management programs, and the Board has the authority to reduce or eliminate co‐​payments and deductibles for everyone else if they choose.32 Health savings accounts, part of the bill’s initial draft, were stripped from the final legislation.



Instead of consumer cost‐​sharing, the legislation establishes a statewide global budget for health care, limiting the growth of health care costs to no more than the national average. However, in recent years Wisconsin health care costs have been increasing faster than the nation’s costs as a whole. In 2006, state health care spending rose by 9.3 percent while the increase in national health care spending was slightly below 8 percent.33



If Wisconsin’s health care costs exceed the national average, the state’s Secretary of Administration, together with the Board of the Healthy Wisconsin Authority, is empowered to “establish, by rule, a program to contain health care costs.“34 The legislation gives no direction and puts no limitation on how this is to be done, beyond a mandate to eliminate “unnecessary operating and capita costs.” Yet if we look at how global budgets are enforced in other countries, or even how U.S. government programs like Medicare attempt to control costs, we can assume that any attempt to reduce costs would include reductions in reimbursements and/​or capital spending.



This would almost inevitably reduce the availability of and access to care. A reduction in capital expenditures means fewer hospital beds and less modern medical technology. Simply compare the U.S. to Canada. The United States has more than five times as many MRI units per million people, three times as many CT scanners, and three times as many lithotripters.35



Similarly, reducing reimbursement rates will drive physicians out of the state. Canada has roughly 2.1 practicing physicians per 1,000 people, far less than the OECD average. Worse, there has been absolutely no growth in the number of physicians per 1,000 people since 1990. And while the number of nurses per 1,000 people remains near the OECD average, that number has been declining since 1990.36



Indeed, waiting lists are a major problem under the Canadian system. There is no accurate government data available, though provincial reports do show the existence of at least moderate waiting lists. The best information may come from a survey of Canadian physicians by the Fraser Institute, which suggests that as many as 800,000 Canadians are waiting for treatment at any given time. According to this survey, treatment time from initial referral by a GP, through consultation with a specialist, to final treatment, across all specialties and all procedures (emergency, non‐​urgent, and elective), averaged 17.7 weeks in 2005.37



Defenders of national health care have attempted to discount these waiting lists, suggesting that the waits are shorter than commonly portrayed or that most of those on the waiting list are seeking elective surgery. However, a look at specialties with especially long waits shows that while the longest waits are for procedures such as hip or knee replacement and cataract surgery, which could arguably be considered elective, fields that could have significant impact on a patient’s health such as neurosurgery, also have significant waiting times.38 In some cases, the delays could be life threatening. A study in the Canadian Medical Association Journal found that at least 50 patients in Ontario alone have died while in the waiting list for cardiac catheterization.39 And Canadian Supreme Court Chief Justice Beverly McLachlin wrote in a 2005 decision striking down part of Canada’s universal care law, that many Canadians waiting for treatment suffer chronic pain and that “patients die while on the waiting list.“40



It is also worth noting again that there will be no health care professionals on the Board. Yet, the Board is empowered to determine if care is “medically appropriate” and conforming to “best practices.” You thus have the possibility of a group of union representatives and corporate executives overruling doctors on questions of medical treatment.



Of course, advocates assume that costs can be controlled without resorting to rationing. They predict substantial savings from the elimination of insurance overhead costs, increased preventive care, and integrated disease management. One study suggests savings of more than $800 million in the first year alone.41 However, there is reason to be skeptical.



For example, it is assumed that the plan’s emphasis on primary and preventive care will lead to $565 million in savings.42 Preventive care advocates assume that if we focus on preventive medicine, we can prevent people from getting sick in the first place. And by emphasizing timely primary care, those who do end up with a chronic illness will develop fewer complications. By spending money up front to reduce the frequency and severity of illness we can reduce the amount of money needed to eventually treat those illnesses in the future.



As logical as this may seem, studies actually show that preventive care usually ends up costing money in the long run because there is no way to precisely target such care.43 For every disease that we prevent or catch early, we end up testing and treating many people who will never get sick. For example, Jay Bhattacharya, a doctor and economist at Stanford’s School of Medicine, estimates that to prevent one new case of diabetes, an anti‐​obesity program must treat five people.44 Similarly, a study of retirees in California by Jonathan Gruber, a health economist at MIT and long‐​time advocate of national health insurance, found that when retirees had fewer doctors visits and filled fewer prescriptions, overall medical spending declined.45 People became ill more frequently, but treating their illnesses was still less costly than paying for preventive care for everyone. Thus, increased preventive and primary care may well be beneficial for the individual in terms of health, but it is unlikely to provide a societal benefit in terms of reduced costs.



Second, there is an assumption that centralizing the purchase of prescription drugs and allowing the state to negotiate drug prices directly with producers will yield another $178 million in savings.46 But as the Congressional Budget Office concluded about a similar proposal for Medicare Part D, that is only likely to occur if the purchaser adopts a restrictive formulary limiting the number of drugs available in a therapeutic class.47 In the absence of such restrictions, government is unlikely to achieve significant savings beyond what private insurers, particularly managed care plans, have been able to negotiate. But the public is unlikely to accept a statewide restrictive formulary‐​not even considering the important medical reasons for rejecting such formularies‐​meaning that actual savings will be far less than projected.



Finally, it is assumed that a government‐​run system would result in substantial reduction of administrative costs, as much as $407 million.48 There is no doubt that administrative costs under private insurance plans add considerably to the cost of health care, roughly 8–16 percent.49 However, advocates of a government run system frequently underestimate the administrative burden under those systems. A study by Patricia Danzon of the Wharton School has estimated that administrative costs under Canada’s system run as high as 45 percent of claims.50 And even Medicare, often cited as a model of government efficiency, has administrative costs of more than 5 percent.51



If the predicted savings fail to materialize, it could pose serious problems for Healthy Wisconsin since the same actuaries analyzing an early iteration of a Wisconsin universal coverage proposal (the Wisconsin Health Plan) predicted nearly $1 billion per year in new costs from increased utilization.52 Similar utilization increases should be expected under Healthy Wisconsin. And this does not include the added cost if the political economy dynamics discussed above lead to the addition of yet more benefits.



In all likelihood, proponents of Healthy Wisconsin have overestimated savings and underestimated costs. This is not unusual with government programs, especially those regarding health care. In 1967, the House Ways and Means Committee predicted that Medicare would cost $12 billion in 1990. In reality, the program cost over $110 billion that year.53 In 1987, Congress estimated that the Medicaid Special Hospitals Subsidy would reach $100 million in 1992. The actual cost exceeded $11 billion.54 Should something similar happen with Healthy Wisconsin, rationing will be almost inevitable.





Healthy Wisconsin is estimated to cost at least $15.2 billion initially and increase state spending by 23 percent. Financing would primarily come through a new payroll tax. The exact size of the payroll tax will be determined later, but the legislation gives the Healthy Wisconsin Board the power to set employer contributions between nine and 12 percent of wages and employee contributions from two to four percent, up to the social security wage cap (currently $97,500).55 Proponents of the Healthy Wisconsin estimate that an initial payroll tax of 14.5 percent will be needed to raise the $15.2 billion necessary to fund the program.56



This represents more in taxes than the state currently takes in through income, sales, and corporate taxes combined.



In theory, the tax would be split, with the employee paying four percent and the employer paying 10.5 percent. But, while it might be politically appealing to claim that business will bear the new tax burden, nearly all economists would see it quite differently. The amount of compensation that a worker receives is a function of his or her productivity. The employer is generally indifferent to the composition of that compensation. It can be in the form of wages, benefits, or taxes. What matters is the total cost of hiring that worker. Mandating an increase in the cost of hiring a worker by adding a new payroll tax does nothing to increase that worker’s productivity. Employers will therefore seek ways to offset the added cost by raising prices (the most unlikely solution in a competitive market), lowering wages, reducing future wage increases, reducing other benefits (such as pensions), reducing hiring, laying off current workers, or outsourcing. In the end, one way or another, workers will bear the full cost.



Of course, the added cost of the payroll tax will be offset to the degree that businesses no longer have to pay health insurance premiums. Surveys suggest that health insurance currently costs the average Wisconsin business between 11.8 and 12.7 percent of wages.57 However, that average is not equally distributed. Wisconsin’s small and medium sized businesses generally pay far less, on average 5–7 percent of wages.58 And, of course, nearly 40 percent of Wisconsin’s small businesses currently do not offer health insurance.59 Thus, there will be a net increase in the cost of employing each worker for most businesses, and an enormous tax increase for small and medium sized businesses. Overall, it is estimated that employers will face $579 million per year in additional costs.60



The most obvious thing a business could do is relocate outside of Wisconsin. Given that Wisconsin’s tax burden and business climate are already significantly worse than surrounding states, the increased burden of Healthy Wisconsin is an almost certain recipe for slowed economic growth and lost jobs. The non‐​partisan Tax Foundation currently ranks Wisconsin 7th in the nation in terms of state and local tax burden. By comparison, Minnesota ranks 11th, Michigan ranks 14th, Iowa 17th, and Illinois 22nd.61 Similarly, Wisconsin ranks only 32nd in terms of business friendliness, well behind Michigan and Illinois (although Minnesota and Iowa did rank worse).62



It is no wonder that from August 2006 to August 2007, Wisconsin actually lost nearly 16,000 jobs. The state’s unemployment rate is now 5.3 percent, on a seasonally adjusted basis.63



If the 14.5 percent payroll tax is enacted, Wisconsin’s tax burden will rise to number one in the nation.64 Added to the other tax increases included in the Senate‐​passed budget, the state’s tax burden would rise from 12.3 percent of state income today, to 20.1 percent. To put this in perspective, the federal tax burden is only slightly higher, 21.7 percent of national income. On average, Wisconsin taxpayers will be paying more than 40 percent of their income in combined federal, state, and local taxes.



However, all of this may understate both the cost of the program and the taxes necessary to support it. The Wisconsin Department of Revenue projects wages in the state to grow by 4.6 percent annually, bringing revenue from the payroll tax to $23.4 billion by 2017.65 If health care costs grow by 6.5 percent annually, as projected by actuaries with the Lewin Group, benefits under Healthy Wisconsin would top $33.1 billion by 2017, leaving a nearly $10 billion deficit.66 That may not be the worst. As noted above, nationally, health care inflation has been running close to 8 percent annually, and the cost of employer provided health care in Wisconsin rose by 9.3 percent in 2006. If health care inflation in Wisconsin merely mirrors the national average over the next decade, the program’s cost will rise far faster than previously estimated, leading to a still greater budget shortfall.



And its not just businesses that are likely to relocate. Particularly in border areas, Health Wisconsin sets up a perverse set of incentives that will encourage healthy and insured residents to move out of state, while also encouraging uninsured and sick from out of state to relocate to, or at least take jobs in, Wisconsin.



This would significantly strain the health facilities in those areas, especially since the border areas largely consist of smaller communities with limited medical facilities. Wisconsin faced a similar burden in the 1980s, when the state’s higher welfare benefits acted as a magnate for poor families relocating from places like Chicago. Healthy Wisconsin could act as a similar magnate, particularly since it covers undocumented immigrants and extends special benefits to low‐​income pregnant women.67 Such an outcome would drive up program costs and create a host of other problems for the state.





Whatever Healthy Wisconsin’s merits or lack thereof as policy, there are significant questions about its legality. The federal Employee Retirement Income Security Act (ERISA) preempts state regulation of certain employer‐​provided benefits, including self‐​funded health insurance plans. The courts have generally interpreted this very broadly as prohibiting not only direct regulation of such plans, but any law or regulation that “relates to” or has a “connection with” them. A state law is a violation of ERISA if it “effectively mandates some element of the structure or administration” of an employer’s ERISA‐​protected plan.68



For example, when Maryland attempted to require businesses with more than 10,000 employees to either provide all their workers with health insurance or contribute a payroll tax, the court struck it down, holding that because it would require employers to “change how they structure their employee benefit plans,” it violated ERISA.69 Similarly in Wisconsin, laws attempting to regulate health insurance convertibility and continuation, and the Health Insurance Risk‐​Sharing Plan were struck down.70



Supporters of Healthy Wisconsin argue that ERISA does not apply because the plan neither requires employers to provide benefits to their workers nor conditions the payroll tax on the provision of those benefits. However, as the Wisconsin Legislative Council has noted, “it is undeniable that it will have an effect on [ERISA‐​protected] plans.“71 As the courts have pointed out, one purpose of ERISA is to enable multi‐​state companies to provide uniform benefits across state lines. But under Healthy Wisconsin, employers would have to change the benefits they currently offer. They would be offering different plans for Wisconsin workers than for those in other states (in many cases there would be no employer provided health benefits for Wisconsin workers).



Therefore, it is hard to see how Healthy Wisconsin could survive an ERISA‐​based court challenge.





If Healthy Wisconsin is not the answer, then what can Wisconsin do to improve its health care system?



The unfortunate reality is that the state’s options are limited because both the real villains and solutions to America’s health care problems lie in Washington, and specifically with the federal tax code, beyond the reach of state lawmakers. However, there are some important steps that this state can take that will reduce the cost of health care and increase the number of people who are insured, while preserving‐​and even improving‐​the quality of the current system.



First, Wisconsin should do what it can to reduce the cost of health insurance. After all, the number one reason that people give for not purchasing insurance is that they cannot afford it.72 This is particularly true for young and healthy individuals: precisely the people who should be encouraged to enter the insurance market before they become older and sicker. Yet, current state regulations drive up the cost of health insurance and make it a reasonably logical decision for these young, healthy individuals to remain uninsured.



For example, Wisconsin currently has some 31 mandated benefits. These mandates force all insurance policies sold in the state to cover treatment for things like cleft palates and blood lead poisoning, and for in‐​vitro fertilization and AIDS vaccines.73 These mandates add significantly to the cost of insurance. The requirement for mental health parity alone adds as much as 10 percent to the cost of an insurance policy. Many of the other mandates add 1–3 percent each to insurance costs.74 Clearly, people should be able to purchase coverage for such conditions and providers if they desire it. But just as clearly, those who wish to purchase a less inclusive but also less expensive policy should be able to do so. Repealing such mandates would be one of the most effective steps that Wisconsin could take to reduce the cost of health insurance and thereby increase the number of people with insurance.



Of course repealing such mandates will encounter fierce resistance from special interests and may prove politically difficult. There is a potentially easier step that Wisconsin could take to achieve similar and possibly more comprehensive results. The state could amend its insurance laws to allow the sale of any health insurance plan approved for sale by any state.



Currently health insurance purchasers are essentially stuck with the regulatory regime of the state in which they reside. Wisconsin businesses and individuals are held hostage by Wisconsin insurance regulation. But if free to purchase health insurance regulated by states other than their own, customers could avoid regulations that added unwanted costs. They could in effect, “purchase” another state’s set of regulations by purchasing insurance from an insurer chartered in that state. If Wisconsin residents do not wish to purchase all 31 coverage mandates the state requires, they could purchase insurance from, say, Idaho, where there are only 13, or any state whose laws are more closely aligned with their own preferences.



Not only would such a simple change to Wisconsin’s insurance laws benefit consumers, reduce costs, and increase the number of people with insurance, the same competitive process that drives producers to improve quality and reduce costs in other products could help produce higher quality regulations. Wisconsin would have to compete for the best regulatory environment in the same way it currently competes with other states to have the best tax environment.



Secondly, the state should institute a thorough review of how it can reduce the cost of providing health care. In particular it should look at such issues as expanding the scope of practice for non‐​physician professionals, and removing barriers to hospital competition.



And third, the state should continue to do all it can to expand the use of consumer‐​oriented health plans such as Health Savings Accounts. I know that I have been widely quoted in the press and elsewhere as saying that “health savings accounts are not a silver bullet.” That is correct. That is because there are no silver bullets when it comes to health care reform. No single reform will solve all of Wisconsin’s, or the country’s, health care problems. A combination of interlocking reforms dealing with providers and consumers, supply and demand, will be required. And even then, utopia is not an option.



However, let me be clear about this. Health savings accounts are an important tool in health care reform. Any successful health care reform requires increasing price transparency within the system, making health care consumers more cost‐​aware, and health savings accounts are an important tool in accomplishing this. I fully support them.



I regret that I have not been able to come here and offer a silver bullet to fix the problems with Wisconsin’s health system. Indeed, some may be disappointed that so much of my advice is in the form of what not to do. This is because I believe, that in pursuing health care reform, legislators should be guided by the Hippocratic admonition, “First do no harm.”



It is understandable that you and your constituents are frustrated by the inability of Congress to address the undeniable need for health care reform. Yet it is sadly true that the keys to health care reform lie in federal, not state, legislation. There are limited steps that Wisconsin can take to make the situation better. But, in the end, you should be extremely careful to make sure that impatience does not push you into taking steps that will ultimately make the problem far worse, hurting Wisconsin taxpayers, businesses, health care providers, and perhaps most importantly, patients.



I thank you once again for your time and consideration. I would be happy to answer any questions.



1“Nobel Prize in Physiology or Medicine Winners 2006–1901,” The Nobel Prize Internet Archive, http://​almaz​.com/​n​o​b​e​l​/​m​e​d​i​c​i​n​e​/​m​e​d​i​c​i​n​e​.html.



2Pharmaceutical Manufacturers Association, “Facts about the U.S. Pharmaceutical Industry,” 2002.



3 _Economic Report of the President_ (Washington: Government Printing Office, 2004), p. 192



4Gerard Anderson et al., “It’s the Prices Stupid: Why the United States Is So Different from Other Countries,” _Health Affairs_ 22, no. 3 (May/​June 2003): 99.



5“Health at a Glance: OECD Indicators, 2005,” Paris, OECD Publishing, 2005.



6U.S. Census Bureau, 2000 Census.



7Robert L. Ohsfeldt, John E. Schneider, _The Business of Health: The Role of Competition, Markets, and Regulation_ (Washington AEI Press, 2006).



8Varduhi Petrosyan, and Peter Hussey, _Multinational Comparisons of Health Systems Data, 2002_ (New York: The Commonwealth Fund, 2002), pp. 55–62; Gerard Anderson and Peter Hussey, _Multinational Comparisons of Health Data Systems Data, 2000_ (New York: The Commonwealth Fund, 2000), pp. 17–18; Gerard Anderson and Bianca Frogner, _Multinational Comparisons of Health Data Systems Data, 2005_ (New York: The Commonwealth Fund, 2006).



9“America’s Best Hospitals, 2007,” _U.S. News & World Report_, July 2007.



10Government workers would eventually be transitioned to Healthy Wisconsin, but only after their current labor contracts expire. The plan anticipates that the state will provide significant “wrap around” coverage to ensure that government workers do not lose any of the generous benefits they currently enjoy.



11“Healthy Wisconsin (HW) — Your Choice — Your Plan: Cost and Coverage Impacts,” AARP Wisconsin and the Lewin Group, June 19, 2007.



12Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.30(7)(b)(4)(a).



13Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.30(2)(b)(4)(c)(1).



14Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.30(4)(m)(2).



15Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.30(4)(b)



16 _Private insurance could continue to cover services over and above those covered by Healthy Wisconsin._



17Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.30(2)(a).



18Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.30(7)(b)(1).



19Jack Lohman, “Lohman: Pass, Expand Healthy Wisconsin Bill,” _Wisconsin State Journal_ , July 16, 2007.



20Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.15



21Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.15(1)



22Victoria Craig Bunch, JP Wieske and Vlasta Prikazsky, “Health Insurance Mandates in the States 2007.” Council for Affordable Health Insurance, 2007.



23Guy Boulton, “Reformer Weighs in on Health Plan,” _Milwaukee Journal‐​Sentinel_ , July 13, 2007.



24See Alain Enthoven, “The History and Principles of Managed Competition,” _Health Affairs_ , supplement (1993).



25Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.30(4)(m).



26John Goodman and Gerald Musgrave, “A Primer on Managed Competition,” National Center for Policy Analysis Policy Report no. 183, April 1994.



27Richard Epstein, “Unmanageable Care,” Reason, May 1993.



28Alain Enthoven, “The History and Principles of Managed Competition,” _Health Affairs_ , supplement (1993), p. 44.



29Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.05(4)(a)(2)(a)



30Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.20(2)(a).



31Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapters 260.20(3)(a) 260.20(4)(a,b).



32Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.20(3)(e)



33Guy Boulton, “Benefit Tab 26% Higher in State,” _Milwaukee Journal‐​Sentinel_ , Nov. 20, 2006; “Health Insurance Cost,” National Coalition on Health Care, www​.nchc​.org, lasat visited August 30, 2007.



34Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 16.004(d).



35“OECD Health Data 2007: Statistics and Indicators for 30 Countries.” Organization for Economic Co‐​operation and Development, July 2007.



36“Health at a Glance: OECD Indicators, 2005,” Paris, Organization for Economic Co‐​Operation and Development, 2005.



37Nadeem Esmail, Michael Walker,and Dominika Wrona, “Waiting Our Turn 16th Edition: Hospital Waiting Lists in Canada,” Fraser Institute, 2006.



38Ibid.



39Madhu Natarajan et al., The Risks of Waiting for Cardiac Catheterization: a Prospective Study, _Canadian Medical Association Journal_ , November 26, 2002.



40 _Chaoulli v. Quebec_ (Attorney General) 2005 SCC.



41“Healthy Wisconsin (HW) — Your Choice — Your Plan: Cost and Coverage Impacts,” AARP Wisconsin and the Lewin Group, June 19, 2007.



42Ibid.



43David Leonhardt, “Free Lunch on Health? Think Again,” _New York Times_ , August 8, 2007.



44Jay Bhattacharya and M. Kate Bundorf, “The Incidence of the Health Care Costs of Obesity,” Stanford University, April 2005.



45Amitabh Chandra, Jonathan Gruber and Robin McKnight, “Patient Cost‐​Sharing, Hospitalization Effects and the Design of Optimal Health Insurance,” NBER Working Paper No. 12972, March 2007.



46“Healthy Wisconsin (HW) — Your Choice — Your Plan: Cost and Coverage Impacts,” AARP Wisconsin and the Lewin Group, June 19, 2007.



47“Issues Regarding Drug Price Negotiation in Medicare: Letter to the Honorable Ron Wyden,” Congressional Budget Office, April 10, 2007.



48“Healthy Wisconsin (HW) — Your Choice — Your Plan: Cost and Coverage Impacts,” AARP Wisconsin and the Lewin Group, June 19, 2007.



49Steffie Woolhandler, Terry Campbell and David Himmelstein, “Costs of Health Care Administration in the United States and Canada,” _New England Journal of Medicine_ vol. 349, no. 8, August 21, 2003, 768–775.



50Patricia Danzon, “Hidden Overhead Costs: Is Canada’s System Really Less Expensive?” _Health Affairs_ 11 (Spring 1992): 21–43.



51Merrill Matthews, “Medicare’s Hidden Administrative Costs: A Comparison of Medicare and the Private Sector,” Council for Affordable Health Insurance, January 10, 2006.



52“The Wisconsin Health Plan (WHP): Estimated Costs and Coverage Impact: Final Report,” The Lewin Group, June 2007.



53Steven Hayward and Erik Peterson, “The Medicare Monster: A Cautionary Tale,” Reason Magazine, January 1993.



54Chris Edwards, “Government Schemes Cost More Than Promised,” Cato Institute Tax and Budget Bulletin no.17, September 2003.



55Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.40 (2 and 3).



56“Healthy Wisconsin (HW) — Your Choice — Your Plan: Cost and Coverage Impacts,” AARP Wisconsin and the Lewin Group, June 19, 2007. This is slightly less than the 15.5 percent payroll tax that Lewin estimated would be necessary to fund the Wisconsin Health Plan. “The Wisconsin Health Plan (WHP): Estimated Costs and Coverage Impact: Final Report,” The Lewin Group, June 2007. While Lewin now suggests a 14.5 percent payroll tax, others continue to suggest a 15.5 percent tax will be required. As noted above, the Board has the authority to set the tax as high as 16 percent without further legislative action. Senate Amendment 1 to Senate Substitute Amendment 1 to SB 40, Chapter 260.40 (2 and 3).



57M. Scott Niederjohn and Mark C. Schug “An Evaluation of the Wisconsin Health Plan” Wisconsin Policy Research Institute Report vol. 20, no.1, January 2007. Although this study was focused on the Wisconsin Health Plan rather than Healthy Wisconsin, the underlying survey numbers and analysis remain valid.



58Ibid.



59Edward Neuschler, “A Profile of Employer Coverage in Wisconsin,” _Institute for Health Policy Solutions_ power point presentation, September 20, 2001.



60“Healthy Wisconsin (HW) — Your Choice — Your Plan: Cost and Coverage Impacts,” AARP Wisconsin and the Lewin Group, June 19, 2007.



61“State and Local Tax Burdens Compared to Other U.S. States,” Tax Foundation Tax Data, April 4, 2007. http://​www​.tax​foun​da​tion​.org/​n​e​w​s​/​s​h​o​w​/​3​3​5​.html



62Curtis Dubay and Chris Atkins, “State Business Tax Climate (Fourth Edition),” Tax Foundation Background Paper no. 52, October 11, 2006.



63State of Wisconsin, Department of Workforce Development, “August Unemployment Rates Announced,” press release, September 20, 2007.



64Curtis Dubay, “Things We Thought We’d Never See at the Tax Foundation, But Thanks to the Wisconsin Senate …,” Tax Foundation Tax Policy Blog, June 28, 2007. http://​www​.tax​foun​da​tion​.org/​b​l​o​g​/​s​h​o​w​/​2​2​4​5​4​.html



65“Wisconsin’s Eroding Household Income,” _The Wisconsin Taxpayer_ vol. 75, no.2, The Wisconsin Taxpayer’s Alliance, February 2007.



66“Healthy Wisconsin (HW) — Your Choice — Your Plan: Cost and Coverage Impacts,” AARP Wisconsin and the Lewin Group, June 19, 2007.



67Wisconsin Manufacturers and Commerce, “State‐​Run Health Care Proposal Will Cover Illegal Aliens,” press release, July 16, 2007.



68 _Retail Industry Leaders Association (RILA) v. Fielder_ , 475 F. 3d. 180 (4th Cir. 2007). At 192.



69Ibid.



70 _General Split Corporation v. Mitchel_ l, 523F. Supp. 427 (E.D. Wisc. 1981).



71Memorandum from Richard Sweet, senior staff attorney, to Rep. Leah Vukmir, “Federal Preemption of Employer Assessments under the Healthy Wisconsin Plan,” Wisconsin Legislative Council, August 1, 2007.



72“The Uninsured: A Primer, Key Facts About Americans Without Health Insurance,” Kaiser Family Foundation, December 2003



73Victoria Craig Bunce, JP Wieske and Vlasta Prikazsky, “Health Insurance Mandates in the States 2007,” Council for Affordable Health Insurance, 2007.



74Ibid.
"
"
A trio of tropical storms can be seen on this satellite image below. Former Hurricane Danielle (at top) has simply become a low pressure system now. 
click to enlarge
From NOAA: GOES-13 Catches 3 Tropical Cyclones Thrashing Through the Atlantic
Powerful Hurricane Earl, growing Tropical Storm Fiona and fading  Danielle were all captured in today’s visible image from the GOES-13  satellite.   The Geostationary Operational Environmental Satellite called GOES-13  captured an image of the busy Atlantic Ocean at 1145 UTC (7:45 a.m. EDT)  on August 31. In the visible image, was the large and powerful  Hurricane Earl passing Puerto Rico, Tropical Storm Fiona located to  Earl’s east, and Danielle far in the Northern Atlantic. Hurricane Earl’s  eye appear to be covered with high-clouds in the GOES-13 image, while  Fiona appeared somewhat disorganized with no apparent center. Farther  north in the North Atlantic Ocean, Danielle appeared more “U” shaped on  the satellite imagery, although her maximum sustained winds were still  near 70 mph at that time.
GOES satellites are operated by NOAA, and the NASA GOES Project at  NASA’s Goddard Space Flight Center in Greenbelt, Md. provides images and  animations of satellite data.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e88f73fff',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"Though it can still be found in the forests of Europe, the Eurasian lynx has not been seen in the UK for more than 1,000 years. This medium-sized wild cat with its distinctive pointy ears was driven to extinction during the medieval period, thanks to low numbers of its preferred prey, roe deer, as well as a disappearing habitat and excessive hunting. But recently the Lynx UK Trust has argued strongly for its reintroduction. Scotland is home to the majority of the UK’s forests, has a relatively low population and an abundance of roe deer. This combination of habitat and prey makes it the most realistic place to consider reintroducing this species. The arguments for bringing back the lynx are numerous, from restoring ecological processes, controlling spiralling deer numbers and economic benefits from increased tourism. But these arguments face considerable opposition from farmers concerned about the risk to livestock and questions about the species’ long-term impact and the suitability of the landscape to accommodate them. Resolving these issues is greatly hindered by a lack of clear evidence of how suitable Scotland is, whether reintroduction is something people want to see happen – and how likely it is to succeed. Without robust evidence, effective and informed decisions cannot be made. Reintroducing large carnivores anywhere around the world is often controversial, complex, costly and challenging. For a species such as the lynx it could take up to 100 years before it is known whether a reintroduction has been a success or not. So getting things right first time is essential. Our work uses cutting-edge computer modelling tools to bring clarity and provide robust evidence about one key aspect of this debate in Scotland: is there enough suitable habitat to support a successful reintroduction of the lynx – and, if so, where should efforts be focused?  Computer modelling provides a safe and inexpensive space to test the effectiveness of proposals before implementing them on the ground. So, any advances in modelling that accurately reflect developments in ecological theory and take account of specific characteristics of a particular species in relation to complex landscapes, are extremely valuable.  Our research used a computer model, not just to contribute reliable evidence to the current lynx debate in Scotland, but to provide a case study that demonstrates how our approach could be used for animal reintroductions elsewhere in the world. The International Union for Conservation of Nature (IUCN) has very clear guidelines when considering if a reintroduction is suitable. Ranked highly is establishing that the historic causes of extinction are no longer present or pose a threat to future populations. It is essential, then, that the availability of habitat and prey and the risk of persecution are no longer barriers to establishing a healthy and viable lynx population. The abundance of roe deer in Scotland covers suitable prey, but the risk of persecution is linked to whether there is public appetite to see lynx return. Equally, knowledge of the location, its size and how easily lynx can move between forest habitats is essential. Until recently these were all relatively unknown quantities, but our research has shed much-needed light on the last of these points. Part of making informed decisions means having the latest information and the best tools for the job. While a previous study investigated the suitability of Scotland for reintroducing lynx, some of the landscape data used is now more than 30 years old.  But technological advances have drastically improved the power of our predictions. So to bring this original work up to date, we generated high-resolution maps using available information for all of the different habitats across Scotland, focusing particularly on suitable woodland areas. Then we gathered detailed information on the ecology of the Eurasian lynx from other studies. Finally, we entered it all into a recently developed model called “RangeShifter”, designed to capture realistic animal movement patterns across complex landscapes.  Once all these pieces were in place, we were able to run 100-year simulations to test which areas of Scotland previously identified as potential release sites might be most suitable for a reintroduction in terms of current habitat availability. The three locations we considered were Aberdeenshire in Scotland’s north-east, the Kintyre Peninsula on the west coast, and the Scottish portion of Kielder Forest in the Borders, all sites that had been proposed in the past. Regardless of how we chose to measure success – and irrespective of the changes we made to the model parameters (such as how many kittens the lynx would have or how long they would live) – the Kintyre Peninsula always came out on top. Parts of Kielder Forest have been the focus of much of the recent debate. But our results found that the Scottish section of this forest was always the least suitable location. The Kintyre Peninsula offers up to an 83% chance that 100 years after the release of 10 lynx, a good population would still be around. In contrast, Aberdeenshire gave a 35% chance of success, but in Kielder Forest there was only a 21% chance a population would still exist after a century. Crucially, we showed how the Highlands of Scotland, the region in which the Kintyre Peninsula and the majority of suitable habitat exists, is completely cut off from habitat south of the Glasgow-Edinburgh “Central Belt”, including Kielder Forest. This raises concerns about the area’s long-term viability for a lynx population, as it would not be able to reach and colonise the Highlands.  Our work does not investigate the political will or public opinion surrounding the reintroduction of lynx – both of which are essential considerations of any reintroduction planning – but it does offer an encouraging step forward, demonstrating the suitability of Scotland’s landscape to support and sustain lynx in the future. And, critically, this depends on location.  The novel application of this model to reintroduction planning holds great promise, not just for informing the lynx debate in Scotland, but also for the conservation of large carnivores and other species around the world."
"Europe has become the global centre of the coronavirus pandemic, according to the World Health Organization. In France, where I am writing from, President Macron has put the country in a “health war” lockdown. Cafes, restaurants, theatres, public parks are closed and all non-essential activities have stopped. In living memory there’s never been anything like this: under Nazi occupation, as we know, Paris culture and nightlife kept functioning rather well. Covid-19 is upon us now, and many of our continent’s large cities feel like they’re fast sliding into one of those dystopian movie scripts with empty streets, face masks, surgical gloves and self-isolation the new normal. With hospital emergency units bracing themselves for much worse yet to come, it feels almost irrelevant to dwell on what this moment says about our place in the world as Europeans, or which feelings we are able to muster – or not – for one another and for others overseas. Postwar Europe’s institutional set-up was meant to epitomise international cooperation and solidarity, and to set a form of global example in the process. Will any of that survive now as countries start to wall themselves in? And what can we citizens do about it? Postwar Europe’s institutional set-up was meant to epitomise international solidarity. Will any of that survive now? After Donald Trump signalled last week that the US wanted to de facto seal itself off from Europe, I remembered an oped by two of his senior team members published in 2017. “The world is not a ‘global community’, but an arena where nations ... compete for advantage,” they’d written. With Covid-19, that “arena” is put into even sharper focus. And nationalist reflexes are hardly a Trumpian monopoly these days. (Reports that Trump offered a German biopharmaceutical company a fat sum of money to secure a vaccine exclusively for the US only added to a general go-it-alone picture.) There isn’t much official coordination or sticking-together on display in Europe itself. National governments, including Germany’s, have sealed their national borders to neighbouring states or are increasing controls. The rationale for much of this can be mind-boggling. Borders don’t stop the virus. Some of what’s at work is that rightwing populist credos have in recent years infected entire swaths of our continent’s politics. For them, there is only one single measure of collective self-identification and solidarity: the ethno-national level. Hungary’s prime minister Viktor Orbán, to take an example, lost no time holding “foreigners” responsible for the pandemic. As events spiralled and with the death count mounting, I wondered about empathy and solidarity: what triggers them? What does a pandemic crisis say about our capacity for such feelings and modes of action? And could grassroots, citizens’ initiatives possibly course-correct some of the egoism of states? In his book Ordinary Virtues, Michael Ignatieff quotes a speech Eleanor Roosevelt gave at the United Nations in 1958. She was speaking about human rights conventions, but the gist of her text can apply to the notion of human solidarity at large. “Where, after all, do universal human rights begin? In small places, close to home – so close and so small that they cannot be seen on any maps of the world. Yet they are the world of the individual person ... Without concerted citizen action … we shall look in vain for progress in the larger world.” Being the global centre of the pandemic means we in Europe hold a specific responsibility in the way we react to this situation, and in how we behave also towards others beyond our shores. Perhaps it helps to think a bit about how we approached the climate crisis as a collective cause for mobilisation (think of the Paris climate agreement). Why couldn’t we now clearly identify Covid-19 as another danger that needs to be addressed collectively – and take up the task as citizens to make that message loud and clear? However different, both these perils have this in common: they transcend all national boundaries and they threaten lives. The “us” versus “them” logic of nationalists and populists becomes absurd in the face of these phenomena. So here’s a question. While governments scramble, is it too early to think of launching a Europe-wide citizens’ online campaign for solidarity in the age of the coronavirus? Could people create a movement that says, let’s help each other as much as we can, and in ways that cut across the national divides many of our governments are resorting to? Videos of Italians in lockdown singing from their balconies to keep their spirits up have been admirable. Could some of that gusto spread and morph into a Europe-wide flurry of videos chanting our empathy and willingness to show solidarity with one another? Wherever we may live and whatever language we may speak, sending that kind of message across our “Corona-centre” continent would hold special meaning, surely not just for ourselves now, but for others also, and perhaps for the future as well. To be sure, for the moment we are stunned by the shock of what’s unfolding and bewildered by what is yet heading our way. Also, still too many people seem confused or in a form of denial as to the exact extent of what we’re facing. Until just days ago, some people in Paris thought best to keep partying, or to attend crowded public protests. Likewise in Ireland, videos of people celebrating in packed bars last weekend have caused outrage. Trust in institutions and resistance to fake news are being put to the test. Pessimists will say our European capacity to come together and show generosity, or even elementary openness to others, has already been entirely blunted by the crises of the past decade (our numbness to Syria’s killing fields is, to me, the greatest case in point). We are no doubt now in severe, introspective, fear-and-fragmentation European mode. But for those who still believe we can be a community of a kind, and that our continental space (or the world beyond) should not be turned into an “arena”, now is the time to ask ourselves how we will want to look back at this phase of our collective history. How will we want future generations to look back at us, and what kind of message do we want to send to the rest of the world? And please note, with every mention of Europe I include the UK. We are one continent, and the virus is among us all. Discord or “social distancing” among nation-states makes no sense in the face of an invisible enemy in our midst which makes no distinction about its victims. And look around: ordinary virtues aren’t absent at all. Gestures of empathy and solidarity are multiplying at a local level – medical students volunteering to help hospitals, or neighbours helping the elderly get food. Why not invent something symbolically similar at a wider, transnational level, and by making use of digital tools? Politicians have done little of this. But citizens can show the way. Artists, creators, start-ups, activists, anyone or any network that’s part of the fabric that binds us together in beautiful, meaningful ways under ordinary circumstances, could take a stand for cross-border solidarity in these extraordinary circumstances. Scientists and medics are of course sharing and coming together. Why not extend that to other parts of our societies? It’s obvious that our only chance to somehow mitigate this catastrophe is to act together, or at least to act in ways that are closely attentive to others, not blind or negligent towards them. Many of us are now hunkering down at home, and it’s all but natural that we focus on immediate day-to-day needs, the health of loved ones, saving our work or our livelihoods, in our entirely up-ended lives. But if our claims to human empathy have any meaning at all, then now is a good time to think of building up a pan-European chorus of voices for solidarity. Sure, it won’t in itself bring us any closer to a vaccine, nor immunise us against the virus, but it could help immunise us against something else – the nasty undercurrents of nationalism that are lurking under the surface. As we Europeans stand at the epicentre of it all, it’s up to us to make solidarity viral.  • Natalie Nougayrede is a Guardian columnist "
"
Greg Craven
by Steven Mosher
In the last episode of  “Craven Attention” I recounted some of the things Greg Craven said during a panel discussion after Oppenheimer’s lecture of the role of scientists. [GC33D The 2010 Stephen Schneider Global Environmental Change Lecture (Webcast)Moscone South, Gateway Ballroom, Room 103, 1345h–1440h Scientists, Expert Judgment, and Public Policy: What is Our Proper Role? Presented by M. Oppenheimer, Geosciences, Princeton University]
Greg seemed to take issue with my characterization of some of his comments.
I have no problem with analysis and criticism of my presentation, but I do feel strongly that the facts of it be correctly conveyed, as I have already been significantly misquoted. I expect that you do not appreciate having your statements mischaracterized or misquoted either…

But I believe some of your characterizations of what I said to be misrepresentative. You are of course free to give your assessment of my presentation, demeanor, or state of mental health. But everyone in the debate says “look at the facts and let them speak for themselves.” I ask that you do the same thing and limit yourself to quoting my actual words, criticizing them and myself as you will, without taking upon yourself to characterize what I said. I am painfully aware that I am a pathological overtalker and can’t be succinct to save my life.
I do not expect you to agree with my words or me. But I do expect you have the discipline and principle to convey the speech accurately, rather than settling for your interpretations and summaries of what I said (as you did in the “Basically it goes like this…” set-out). I’m sure that you’ll agree that characterizing your opponent’s words yourself does no service to forwarding the discussion.

And he seeks to vindicate himself by posting a transcript of  the episodes.
And my remarks have already been mischaracterized and misquoted, to further malign the AGU.  In the interests of accuracy and truthful reporting, I will post an audio file and transcription of my presentation as given at www.gregcraven.org as soon as I can.
He has now posted a transcript of a different presentation he gave earlier  in the day. Huh? Strangely the audio that produced that transcript is still not available. The problem is my piece covered a different episode. He posted a transcript of the meeting at 1020 AM on the 15th and I covered the panel that followed Oppenheimer who spoke at 13:40-14:00. Still, we can note some things and see if it’s possible that I got the gist of what Craven was saying correct. That is, by looking at the first transcript we can see that my characterization of the second speech is not implausible. Let’s just say the second presentation was a good model for the first.
First lets note this. The Craven who cares about being misquoted had this to say; take special care to note his definition of the meaning of communication below:
my message to you now is that you must stop communicating as scientists. You must begin communicating as citizens, as a father, as a mother, with whatever feelings are in your heart, with your fears, speak to them of your hopes, let them know about your befuddlement at the divergence. And tell them frankly, forthrightly, sincerely, about any terror that you are ignoring…..
You say you want to have an effect on the public? If you trod a journey at all similar to mine, think, visualize, take five minutes to meditate on the impact it would have if you took off your goddamned scientist hat for just a moment, and put on your citizen hat. And said frankly to the public through the largest mouthpiece you can: “As a scientist, here’s my understanding. As a citizen, here’s my hope, my vision. And as a mother, here’s my contingency plan, here’s my lifeboat.”….
If you obliterated your comfort zone and the hard line of purity of your scientific sensibilities–that you do cling to, with the faith of a god–and you actually went forth as an actual advocate, a sentiment normally anathema to the constitution of a scientist, imagine if you went out into the fray bearing your heart, with your emotion and the authority of your understanding as your weapon. For what you’ve been giving them as a scientist up to now is information, and with that increasing divergence between public and scientific opinion…
You must stop selfishly pursuing your pleasure in finding things out. To be frank: f*** your research. We. Need. You. I know I am almost certain to outrage you with my impertinence and the audacity of my message. And my word choice, for substituting ‘f*** for ‘screw’. [Mild laughter.] And that’s the lesson you must absorb into the fiber of your being, for the meaning of communication is not what you intend, or the information. The meaning of communication is the response it elicits in the listener. And that’s where we have failed. So while you may be likely to forget the details of my rant, you will always feel the emotional aftertaste of it. And that is the purpose of communicating the science of climate change to the lay public. To give them an emotional aftertaste.
Your role, your job–the one we have assigned you and gladly supported–has always been to stand on the hill overlooking the bloody battlefield and give reconnaissance and convey information about what’s ahead. But there comes a time in the last stand for every single support troop, no matter how far removed, to pick up a weapon, come down into the fray, and fight to the death for what they stand for. To charge into the face of annihilation itself and fight with their teeth, tearing out the jugular of their enemy with their bloody mouth if they have no weapons left. That time is now.
If you do not believe that, if you do not feel that, I challenge you to be intellectually honest–that part of you that you hold up as better than any other profession, and I support you in that opinion–you are the only rational thinkers on the planet. Beware, psychological research shows that people don’t generally make decisions rationally. If you don’t agree with this–that this is the time to radically challenge your comfort zone, and your traditional mores of never letting feelings or opinions on policy pass your lips–I’m not going say “If not now, then when?” I’m going to say: detail an operational definition of a test to test whether a situation would merit that extreme action or not. Come up with the characteristics. And then I defy you to compare them to the situation now. If you do that, forget everything I’ve said. I absolve you. That’s all I ask. But if your intellectually honest operational definition tells you that the time is now. . . .
These snippets are from his earlier speech. However, in the panel after Oppenheimer’s talk he gave a similar version of the “comfort zone”  challenge. The “emotional aftertaste” I was left with after I forgot the details of his second rant was this:
Craven took charge again and argued the “if not now, when” argument.Basically, it goes like this. As a scientist you have to decide  at some point that enough is enough. You have to put your scientific commitment to the discipline of doubt aside and “blow past” your boundaries.  Say what you feel, not what you can prove….
Steve Easterbrook, thankfully, asked the only intelligent question. On one hand we have Oppenheimer telling us take care when going beyond our expertise. On the other hand we have Craven, saying “blow past” your boundaries. Oppenheimer tried to paper over the difference, and Oreskes, who seemed to be shooting me looks as I sat there laughing, agreed that there was a difference between these views. Craven, breaking his promise again, read what he had been scribbling. Some sort of challenge to climate scientists that he promises to post.
I apologize if I got it “wrong,” but on Greg’s view my emotional “aftertaste” IS the meaning of what he said. I guess those years of studying Stanley Fish and Roland Barthes came in handy. Personally, I want scientists to keep their science hat on at all times. Others can panic without any practice or education. To be fair to Greg and to present his argument a bit more precisely and rigorously  he seems to want  scientists to speak emotionally about policy while retaining their objectivity in science. Except, for the ” f*** your research part”  which is a bit hard to square with things. Craven thinks scientists research because they take pleasure in it. Removing doubt and uncertainty is an equally likely motivation. So there he seems to be saying they should put their desire to remove doubt and uncertainty aside in favor of passion.  Oppenheimer’s point, on the other hand, was this: as an expert you have a problem. People make take your positions on policy to be expert scientific opinions, when they are not.  And my point would be this. The passion for policy is part and parcel of the problem of trust in climate science. For Craven, the “understanding” drives the passion. But for many of the people that need to be convinced the displays of passion undermine trust in the science. That’s their emotional aftertaste.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e864be554',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

On the eve of Newt Gingrich’s landslide victory in the South Carolina primary, CNN’s Erin Burnett let the former speaker expound on the success of his “kick the moderator” debate strategy.



“I think there’s something going on here that’s very deep,” Gingrich said. “People want a leader who’s forceful… Part of it is, you know, if I’d said ‘The color is blue!’ — it’s the forcefulness… That delivery, that clearness is as important as the specific topic,” he explained.



Watching the interview, I had a disturbing thought: Has Newt Gingrich become self‐​aware?



I’ve never heard a better explanation for the former speaker’s ability to cloud conservatives’ minds. How, after all, did a man who’s the very model of a Beltway‐​consensus influence‐​peddler convince Tea Party voters he represents “real change”? It’s the “forcefulness,” stupid!



Unfortunately, what’s going on here is not “very deep.” Gingrich’s rise represents the triumph of rhetorical style over substance. In a way, it’s the ultimate tribute to Barack Obama.



The _Washington Post’s_ Ezra Klein asked a good question on Sunday: “What are Newt Gingrich’s big ideas?” “I’m at a loss to name even one,” he admitted.



Gingrich has an enviable rep as a one‐​man think tank, but in his wilderness years, he made a sweet living as a “forceful” pitchman for utterly conventional center‐​left policies: Medicaid expansion, the individual mandate, cap and trade, “clean energy” subsidies, and the like. Newt does a great impression of a red‐​state firebrand, but when it comes to policy, “the color is blue.”



That’s not to say that Gingrich has never had an unconventional idea. This is a guy who bragged in a 2005 GQ interview that “I first talked about [saving civilization] in August of 1958” — when he was a rising sophomore in high school.



Some of Gingrich’s big ideas are charmingly batty. Given his worries about global warming, Newt has probably abandoned his 1984 plan for “a mirror system in space” that “could affect the earth’s climate by increasing the amount of sunlight.”



But the Trekkie zeal remains, judging by one of my favorite recent headlines: “Gingrich Said Freddie Mac Could Be Good Model for Mars Travel” (Bloomberg, Dec. 2, 2011).





Gingrich’s rise represents the triumph of rhetorical style over substance.



Some of Gingrich’s other fancies are less charming. The candidate who’s warned of a “gay and secular fascism” sweeping the country has an impressive authoritarian streak of his own.



As Klein notes, in 1996, Gingrich had the “big idea” of instituting the death penalty for anyone who brought more than 2 ounces of marijuana into the United States.



Today, Gingrich condemns the Stop Online Piracy Act as censorship, but in 2006 he supported empowering “federal judges who’ve served in combat” to shut down “jihadist” websites.



This December, he advocated sending U.S. marshals to arrest activist judges who rule against religious displays in public schools (maybe combat‐​hardened jurists will get a pass).



Say what you will about Gingrichian authoritarianism — at least it won’t be “gay and secular”!



At this writing, Gallup has Gingrich neck and neck with Romney for the Republican nomination. If he gets the nod, no doubt he’ll send a thrill up many a leg in the debates. But his odds of actually winning the presidency are slim indeed.



Recall that in 2004, after Obama’s GOP opponent for the U.S. Senate, Jack Ryan, imploded in a sex scandal, the party nominated Alan Keyes: another “forceful” debater with a weakness for loopy ideas. How’d that work out?



Keyes went on to run a short‐​lived cable talk show (the somewhat defensively titled “Alan Keyes Is Making Sense”) and a role as lead plaintiff in a birther lawsuit. Obama went on to the U.S. Senate and, in short order, the presidency.
"
"
This is the final report, which has been embargoed until 5:01 PM PDT / 00:01 GMT March 31st.
Click for PDF of report
Below is the emailed notice to MP’s sent with the PDF of the report.
Date: 30 March 2010 10:30
Subject: EMBARGOED REPORT: CLIMATE SCIENCE MUST  BECOME MORE TRANSPARENT SAY MPs
To: [undisclosed recipients]
Phil Willis MP, Committee  Chair, is available for embargoed interviews today. Please let me know if you  wish to bid (I will be at the embargoed briefing until approx 1pm but will  respond once I return).
Embargoed press briefing for science, environment  and news corrs at Science Media Centre (21 Albemarle Street London, W1S 4BS),  11.30 am today.
SCIENCE & TECHNOLOGY COMMITTEE
Select Committee  Announcement
[X]
31 March 2010
***EMBARGOED UNTIL 00.01 WEDNESDAY  31 MARCH 2010***
CLIMATE SCIENCE MUST BECOME MORE TRANSPARENT, SAY  MPs
The Science and Technology Committee today publishes its report on  the disclosure of climate data from the Climatic Research Unit (CRU) at  the University of East Anglia. The Committee calls for the climate  science
community to become more transparent by publishing raw data and  detailed methodologies.
Phil Willis MP, Committee Chair,  said:
“Climate science is a matter of global importance. On the basis of  the science, governments across the world will be spending trillions of  pounds on climate change mitigation. The quality of the science therefore has  to be irreproachable. What this inquiry revealed was that climate scientists  need to take steps to make available all the data that support their work  and full methodological workings, including their computer codes. Had both  been available, many of the problems at CRU could have been  avoided.”
The focus on Professor Jones and CRU has been largely  misplaced. On the accusations relating to Professor Jones’s refusal to share  raw data and computer codes, the Committee considers that his actions were in  line with common practice in the climate science community but that those  practices need to change.
On the much cited phrases in the leaked  e-mails-“trick” and “hiding the decline”-the Committee considers that they  were colloquial terms used in private e-mails and the balance of evidence is  that they were not part of a
systematic attempt to mislead.
Insofar as  the Committee was able to consider accusations of dishonesty against CRU, the  Committee considers that there is no case to answer.
The Committee found  no reason in this inquiry to challenge the scientific consensus as expressed  by Professor Beddington, the Government Chief Scientific Adviser, that  “global warming is happening [and] that it is induced by human activity”. But  this was not an inquiry into the science produced by CRU and it will be for  the Scientific Appraisal Panel, announced by the University on 22 March, to  determine whether the work of CRU has been soundly built.
On the  mishandling of Freedom of Information (FoI) requests, the Committee considers  that much of the responsibility should lie with the University, not CRU. The  leaked e-mails appear to show a culture of non-disclosure at CRU and  instances where information may have been deleted to avoid disclosure,  particularly to climate change sceptics. The failure of the University to  grasp fully the potential damage this could do and did was regrettable. The  University needs to re-assess how it can
support academics whose expertise in  FoI requests is limited.
Ends.
NOTES TO EDITORS:
Further  details about this inquiry can be found at:
http://www.parliament.uk/parliamentary_committees/science_technology/s_t_cru_inquiry.cfm

Media  Enquiries: Becky Jones: 020 7219 5693 Committee Website:
http://www.parliament.uk/science Publications / Reports / Reference
Material: Copies of all select committee  reports are available from the
Parliamentary Bookshop (12 Bridge St,  Westminster, 020 7219 3890) or the
Stationery Office (0845 7023474).  Committee reports, press releases,
evidence transcripts, Bills; research  papers, a directory of MPs, plus
Hansard (from 8am daily) and much more,  can be found on
www.parliament.uk<http://www.parliament.uk/>.
Rebecca  Jones
House of Commons Select Committee Media Officer Children, Schools  &
Families; Health; Science & Technology; Northern Ireland; Scotland;  Wales
===================================================
UPDATE: 
Steve McIntyre has a few points to make, which I encourage reading here at Climate Audit


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8d096ce1',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Some of the world’s most notorious infections – including Lyme disease, rabies, and Ebola come from zoonotic diseases. These illnesses are caused by pathogens (bacteria, viruses, or other parasitic organisms) which can be passed from animals to humans. But, even though they can lead to serious health problems, there is a gap in our knowledge when it comes to these diseases. We don’t yet fully understand how pathogens “shift” between different host species and cause epidemics – and research is starting to show that the changing environment could be a factor. The number of animal species that a pathogen infects is an indicator of its capability to shift to other host species and infect them, too. Pathogens that infect more animal species should be more likely to jump to a new host. Rabies viruses, for example, are seemingly capable of infecting virtually any mammalian species they encounter, putting humans worldwide at risk of spillover.  Research has also found that how infected animals are related to one another is important. If a pathogen infects monkey and ape species, for example, it will probably have a better chance of infecting humans than one that primarily infects birds or fish.  Our new study highlights that there is a growing body of evidence showing that host shifting is inexorably linked to the environment, too. Studies have found that the environments around us – including different habitats as well as climate conditions – provide new opportunities for humans to pick up different pathogens from wildlife.  The world’s growing human population and the way we utilise and modify our planet means that we are living closer to wildlife than ever before. Hardly any wildlife lives alone in a pristine environment. In addition, invasive species are also rising unprecedently, with animals such as rats spreading their parasites across former biogeographical borders. Now, previously isolated wildlife and their pathogens have become embedded in a global and ever-changing network, spreading diseases further than seen previously. This new line of thinking – that pathogens could infect more hosts if they had access to them – is important for how we address emerging diseases in times of global change. The spread of multi-host pathogens has already become a worldwide phenomenon, with wild animals often playing a big role in zoonotic events. Even seemingly benign holiday wildlife encounters can cause problems. For example, since 2012, tourists from Europe and elsewhere have been contracting Middle East respiratory syndrome (MERS) from camels in Saudi Arabia. But the threat is not just about wildlife pathogens infecting humans. Many pathogens have been introduced by us and our pets to new areas. Of the nearly 400 parasitic worm species recorded in people, almost 50% have been found in a diverse range of animals, including dogs, cattle, and wildlife such as primates, rodents and deer. Research has found that this shifting of parasites has likely been intensified by globalisation as humans and their companion animals move around the world. So what’s the next step in understanding how these diseases shift? And what can we do to stop their spread? Environmental measures are certainly needed but we also need to work out how pathogens may move between species, and how to minimise the risks when that happens. Predicting the next emerging infectious events has much in common with daily weather forecasts. First, we must build our knowledge of the diseases using basic research, and then use sophisticated algorithms to generate predictions. Computational tools to tackle this kind of challenge are available, but they are generally used in other ways.  Many disciplines – including physics and social sciences – deal with “contagious processes” to understand the spread of objects. And researchers commonly use algorithms to study sensor networks, process images, and track information spread in social media. Similar models have a long history in health research, but they could now be used to account for changing environmental conditions in order to predict when and where pathogens will be exposed to new host species. This is not just about new infectious diseases. Implementing a system like this could help track the reemergence of diseases that are under control in humans and domestic animals, but still present in wildlife. It could also increase awareness of the large diversity of poorly studied pathogens which have unpredictable zoonotic capacity. There is still much to be learned about how diseases are shared among humans and animals, but by preempting global disease spread we can start to understand their origins and hopefully predict their movements."
"**Exeter's Nightingale hospital will open to coronavirus patients for the first time on Thursday.**
The emergency field hospital will get patients from the Royal Devon and Exeter Hospital ""which is very busy"", said an NHS spokesperson.
It is one of seven Nightingale Hospitals built in England, set up in the spring as an insurance policy in case the NHS became overwhelmed.
The 116-bed hospital has also been used for vaccine trials.
On Twitter, Exeter MP Ben Bradshaw said the opening was ""very good news"".
He added it will ""take pressure off the RD&E hospitals and other local NHS services"".
The Labour MP noted he recently raised the issue with Health Secretary Matt Hancock.
A total of 540 people have died with coronavirus in South West hospitals, with four dying in Devon on Wednesday.
A Nightingale hospital spokesperson said: ""We would ask that the public continue to observe the government's advice on observing the lockdown and social distancing so that we can keep patients safe.""
**How will your Christmas plans be affected?**haveyoursay@bbc.co.uk **.**
Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways:
If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or comment or you can email us at HaveYourSay@bbc.co.uk. Please include your name, age and location with any submission."
"
Share this...FacebookTwitterHere we go again. Global warming causes cold European winters! So no matter what happens – it proves man-made global warming is for real.
Just a few years ago, these off-the-wall scientists claimed that global warming would lead to warm, snowless winters, with palm trees eventually reaching Scandinavia.
But now that cold winters have caught the hapless scientists with their pants down and signs pointing to even colder winters ahead are piling up, scientists have now concocted a model that they say shows that warming lack of summertime Arctic sea ice cover leads to cold winters. At least that’s what some adventurous scientists are saying at Germany’s state-funded Alfred Wegener Institute in a new paper.
The Alfred Wegener Institute press release here claims that because of the near surface warming, the air goes into upward motion and the atmosphere becomes unstable. According to the paper’s lead author Ralf Jaiser:
We have analysed the complex non-linear proceses that are behnind this destabilization, and have shown how the changed conditions in the Arctic have an impact on the typical circulation and air pressure patterns.”
The AWI tells us about the air pressure difference between the Arctic and the middle latitudes the so-called Arctic Oscillation, with the Azores high and the Iceland lows that we know from weather reports. If the index is high, then westerly winds prevail and transport warm, moist oceanic air deep into Europe. But if these westerly winds cease, then Arctic air penetrates into Europe, like the last 2 winters. The models calculation now show that in times of low Arctic ice cover, this air pressure index is weakened during the subsequent winter and thus allows Arctic air to penetrate down to the middle latitudes. It’s that simple – period. So let’s all just keep moving on.
So their knowledge of nature is complete now, and their models are tuned like no others and can recreate all the mysteries of nature. This may sound hard to believe, but it’ll do for the hordes of stupid gullible journalists out there. Overall the AWI press release takes on a sort of silly paternal attitude and treats the reader like a parent treats a 4-year old when explaining how Santa Claus brings presents at Christmas. Of course, when the child reaches the age of 8, he or she realises that he/she had been duped the whole time. Right now the media is at about age two and half, and stuck there.
 
 
Share this...FacebookTwitter "
"
By Steven Goddard,

The headline reads “NASA Satellites Detect Unexpected Ice Loss in East Antarctica”
ScienceDaily (Nov. 26, 2009) — Using gravity measurement data from the NASA/German Aerospace Center’s Gravity Recovery and Climate Experiment (GRACE) mission, a team of scientists from the University of Texas at Austin has found that the East Antarctic ice sheet-home to about 90 percent of Earth’s solid fresh water and previously considered stable-may have begun to lose ice.
Better move to higher ground! NASA also reported :
“Antarctica has been losing more than a hundred cubic kilometers (24 cubic miles) of ice each year since 2002” and that “if all of this ice melted, it would raise global sea level by about 60 meter (197 feet).“
In 2007, NASA generated this map (below) of Antarctica showing just how hot it is getting down there in the land of Penguins.

Now I am really worried! But wait……. There are a few minor problems.
Assume for a minute that we accept the GRACE numbers.  The first problem is Antarctica contains a lot of ice :  30 × 10^6 km³.  At 100 km³ per year, it will take 300,000 years to melt.
The next problem is with the NASA temperature map. From the NASA article “The scientists estimate the level of uncertainty in the measurements is between 2-3 degrees Celsius.” They are claiming precision of better than 0.05°C, with an error more than an order of magnitude larger than their 25 year trend. The error bar is large enough that the same data could just as easily indicate rapid cooling and blue colors. That will get you an F in any high school science class.
And that is exactly what happened. The hot red map above was preceded by a cold blue map which showed Antarctica getting cooler. What motivation could NASA have had to change colors without mathematical justification?

NASA justified their heating up Antarctica with this comment :
This image was first published on April 27, 2006, and it was based on data from 1981-2004. A more recent version was published on November 21, 2007. The new version extended the data range through 2007, and was based on a revised analysis that included better inter-calibration among all the satellite records that are part of the time series.
As I have already pointed out, this is absurd. Their error bar is so large that they could have painted the map any color they wanted. Apparently someone at NASA wanted red.
But why are we looking at temperature trends anyway? The real issue is absolute temperatures. Some of the regions in which GRACE claims ice loss in East Antarctica average colder than -30°C during the summer, and never, ever get above freezing. How can you melt ice at those temperatures?

http://en.wikipedia.org/wiki/File:Antarctic_surface_temperature.png
I overlaid the Antarctica summer temperature map on the GRACE “melt” map, below. As you can see, GRACE is showing ice loss in places that stay incredibly cold, all year round.

The problem with GRACE is that it measures gravity, not ice. Changes in gravity can be due to a lot of different things beneath the surface of the ice. Antarctica has active magma chambers. Plate tectonics and isostasy also cause gravity changes.
We should be clever enough not to be blinded by technology. The claims that ice is melting in East Antarctica don’t have a lot of justification.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ac16b27',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Two-week quarantine restrictions apply to people entering the UK from almost every country, because of the second wave of coronavirus.**
From the middle of December, travellers will be able to pay for a private test, which will cut their self-isolation time to just under a week if it comes back negative.
In England, people cannot travel abroad for non essential reasons until 2 December.
People arriving in the UK from most countries - including British nationals - must **self-isolate for 14 days**.
Exceptions are made for people coming from the Common Travel Area - Republic of Ireland, Channel Islands, or the Isle of Man - or countries in travel corridors with the UK.
Travellers must fill in a ''passenger locator'' form, with contact details and their UK address. Anyone who does not provide an address will have to pay for accommodation arranged by the government.
For 14 days, starting the day after arrival, people quarantining **should not:**
If you have to self-isolate after a trip you may not get statutory sick pay, unless you meet the required conditions \- such as displaying coronavirus symptoms.
Scotland,Wales and Northern Ireland have brought in their own rules, which vary slightly.
From 15 December, people arriving in England will be able to cut their quarantine period by at least half if they pay for a Covid test after five days.
The tests will cost between Â£65 and Â£120 and the results will normally come back within 24 to 48 hours. This means people could stop self-isolating six days after arrival if they test negative.
Breaking quarantine rules is a criminal offence, and people who do it face a fine and potentially a criminal record.
Those not self-isolating when they are supposed to can be fined Â£1,000 in England, Wales and Northern Ireland, or Â£480 in Scotland. Fines in England for persistent offenders have doubled to Â£10,000.
People can be fined up to Â£3,200 in England if they do not provide accurate contact details, or Â£1,920 in Wales.
There is also a fine of Â£100 for not filling in the passenger locator form.
A small number of jobs offer exemption from quarantine rules. These include:
People living in Wales are currently not allowed to travel abroad for a holiday, but can still make work trips.
In England, leaving home in order to travel for holidays before 2 December can be punished by a fine, with penalties starting at Â£200 and going up to Â£6,400. After that, non-essential travel is allowed.
There are currently only a handful of places that travellers from England can visit without encountering restrictions either when they arrive at their destination, or when they return.
These include:
The Joint Biosecurity Centre \- set up by the government to monitor coronavirus - advises on which destinations should be on the list.
In the past, the decision appears to have been made when 20 or more people out of every 100,000 in a country, or island, are infected over seven days, but other factors are also considered. These include:
**Are you planning to travel to or from the UK? How will the quarantine regulations affect you? Share your experiences by emailing**haveyoursay@bbc.co.uk **.**
Please include a contact number if you are willing to speak to a BBC journalist."
nan
"**Britain's major pub groups and brewers have pleaded with Prime Minister Boris Johnson to save an industry facing the ""darkest of moments"".**
Executives at Fuller's, Carlsberg UK, Greene King, and Heineken UK are among more than 50 signatories of a letter warning of huge job losses.
They call on him to publish the evidence justifying the coronavirus restrictions on the industry.
A Downing Street spokesperson said they would respond in due course.
The letter says: ""The pub is clearly being singled out for exceptionally harsh and unjustified treatment and unless your government changes course, and soon, huge portions of this most British of institutions will simply not be there come the spring.
""We believe it is in the interests of openness and transparency that any evidence showing pubs to be the source of outbreaks of the virus, and thereby justifying these extra restrictions, must be published immediately.""
The letter comes ahead of a planned announcement on Thursday that could see two-thirds of the country placed into tiers two or three when the current lockdown lifts next month.
Pubs in tier two areas will be able to serve drinks only to customers having a substantial meal, and those in tier three will not be able to open.
Pubs, and the hospitality industry generally, have been among the hardest-hit sectors during lockdown.
More than a third of hospitality firms say they have little or no confidence of surviving the next three months, according to data collected by the Office for National Statistics (ONS) earlier this month.
Other signatories to the letter include executives at Adnams, Marston's, Budweiser UK, Punch Pubs, Shepherd Neame and Young's.
They tell the PM they employ ""hundreds of thousands of people and contribute billions of pounds of economic value to the UK economy - all of this is at risk today"".
""Your Winter Plan, compounded by the Christmas announcement, have been greeted with utter dismay and incredulity by publicans up and down the country, and made the situation facing us exponentially worse,"" they say.
""How can it be that people mixing in unregulated private homes is deemed safer than gathering in limited numbers in larger, regulated and ultimately Covid-secure venues like pubs? There is no logic to this decision.
""It is clear that pubs are being scapegoated despite a lack of available evidence that they are any more responsible for outbreaks than other types of venue. We cannot stand idly by and allow these measures to destroy our businesses.""
If restrictions cannot be relaxed, the pubs are demanding, among other things, financial support in line with the first lockdown, immediate changes to business rates, and a cut in the ""punitively high"" beer duty rate."
"

The Kansas Legislature has wisely written a proposed tax on carbon dioxide emissions out of this year’s energy legislation. That’s the good news: As originally written by the Committee on Utilities, the Sunflower Energy bill’s CO2 tax would have been a first, and a very bad precedent. The bad news is that the original bill will be copied and wind up before other legislatures that are more likely to pass it, like those of California and Oregon.



A CO2 tax will largely be levied on utilities that exceed modest limits on their carbon dioxide effluent, so consumers won’t “see” it — except in their electric bills. They’ll send in their monthly checks, quite unaware that the new tax revenues are likely to be shoved into a slush fund for solar energy, windmills, biodiesel, ethanol and other green gadgetry boondoggles.



Never mind that even the _New York Times_ now acknowledges that biofuels add more carbon dioxide to the atmosphere than the equivalent amount of conventional fuels, or that the diversion of a third of the U.S. corn crop to ethanol production has driven world food prices up so much that we are now witnessing riots, including a major one in Jakarta last month.





The satellite temperature surveys also show there has been no net global warming since 2000.



Let’s just consider the merits of this legislation vis‐​a‐​vis some pretty well‐​known (if poorly publicized) global warming science.



Further, we’ll cheat a bit and stipulate that the bill results in a 10% net reduction of carbon dioxide emissions, and that global warming fever sweeps the nation, resulting in similar legislation passing in every other state.



Based upon a widely accepted formula originated at the U.S. National Center for Atmospheric Research in Boulder, Colorado, if the entire United States adopted the original Kansas legislation, it would prevent a total of 0.11 degrees F of global warming _per century_. Read that again, because it’s not a typo: Eleven one‐​hundredths of a degree in 100 years.



Instead, let’s apply the original Kansas legislation to every nation on the planet that agreed to limit its emissions under the infamous 1997 Kyoto Protocol, an amendment to a 1992 United Nations global climate treaty that would require the U.S. to reduce emissions far beyond what was written out of the Kansas bill. The new law would prevent 0.27 degrees F of warming per century. That’s an amount too small to measure, because global temperatures vary by more than that from year‐​to‐​year — global warming or not.



Since 1979, satellites have been measuring lower atmospheric temperatures around the globe. In the last 12 months, they show that the earth’s mean temperature has dropped by 1.13ºF. Thus, in one year, that natural variability is four times greater than the amount of warming that would be prevented if the entire industrialized world adopted the original Kansas statute.



The satellite temperature surveys also show there has been no net global warming since 2000. It’s a little unfair to go back much further in this discussion, because 1998 was an extremely hot year — the high point in both satellite and land‐​based temperature histories — because of a huge El Nino (which, incidentally, proved to be a great boon to Kansas’s wheat farmers).



All of which is to say that global warming isn’t exactly proceeding apace. Rather, the rate of planetary warming is falling in line with the low end of 21st century projections made by the UN’s Intergovernmental Panel on Climate Change, with the smart money now riding on a bit more than 3 degrees F of warming this century. It’s worth noting that the 20th century saw about half of that warming, along with a doubling of life expectancy in the industrialized world, and an approximately ten‐​fold increase in real personal wealth.



But we hear over and over that if we don’t “do” something serious about carbon dioxide emissions in the next eight years (a conveniently presidential number), we are condemning ourselves to an unmitigated climate disaster, as much of Greenland’s ice crashes into the sea, raising sea level as much as 20 feet.



That’s about as likely as a bill limiting CO2 emissions in Kansas putting a detectable dent in global warming. Congratulations to the legislature for its wisdom in writing out the carbon tax. But beware, electronic copies of the original are flying around the country, looking for places to land.
"
"

Well here’s an interesting, if three‐​weeks‐​old, story. Apparently the North Dakota Farm Bureau’s annual convention recently passed a policy calling for the elimination of all agricultural programs. Reading between the lines of the original press release indicates that the call was part of a broad political position by the NDFB to move away from government intervention in many areas of the economy apart from farm programs, including cap‐​and‐​trade and health care:   




“As people in this country expect more from the government and less from themselves, our delegates are urging everyone, including farmers, to step away from the public trough and get back to the principles of individual responsibility and initiative,” said NDFB President Eric Aasmundstad.…   
The only way government can get money is to take it from its citizens. We don’t believe raising taxes to pay for health care or climate change will help our country get out of our economic slump or even improve health care or the environment. And the more they take, the less we have to find the innovative solutions to the problems we face.



He sounds like a Catoite.   
  
  
To what extent the NDFB’s position flows through to the rest of the farm lobby remains to be seen, so hell hasn’t quite frozen over yet. But this is positive news. At the very least it spells sweet, sweet trouble for long‐​time free trade nemesis and farm bill supporter Sen. Byron Dorgan (D), who is up for reelection next year.   
  
  
HT: Chris Edwards.
"
"**Leicester and Leicestershire will be subject to the toughest tier of restrictions after the national lockdown ends on 2 December.**
The city and county will move from tier two to three, meaning very high risk, the government announced.
It means household mixing is banned and pubs and restaurants will close except for delivery and takeaways.
The city and parts of the county were subject to the UK's first local lockdown in June.
The neighbouring county of Rutland will go into tier two of the government's three-tier system.
Leicester has been subject to some level of coronavirus restrictions since the first national lockdown in March.
The government has set out the reasoning behind the tier decisions for each area.
In a written ministerial statement, the government said of Leicester and Leicestershire: ""Improvements have been seen in overall case rates in all but one lower tier local authority, but remain very high at 355 per 100,000, including in over 60s at 250 per 100k. The pressure on the local NHS remains very high.""
Health Secretary Matt Hancock told the Commons: ""I know how tough this is, both for areas that have been in restrictions for a long time like Leicester and Greater Manchester, and also for areas where cases have risen sharply.""
The system will be regularly reviewed - with the first scheduled for 16 December.
The new allocations will put some areas under significantly tighter restrictions than before the second lockdown started.
Places like Market Harborough and Lutterworth have managed to remain in tier one since the system was first introduced, but they along with the rest of the county will go into tier three.
Reacting to the news, the county's director of public health Mike Sandys said: ""Over the past few days, rates have started to fall and we've made some progress. But it's important to put this into perspective.
""Figures are over 20% down compared to this time last week but they're still worse than the day we went into lockdown.
""Leicestershire's average is significantly higher than the national level so there is still work to do.""
In a joint statement, the three Labour MPs for the city - Claudia Webbe, Liz Kendall and shadow health secretary Jonathan Ashworth - said: ""The news that Leicester will go into tier three - on top of the 150 days of our extra lockdown - is extremely difficult to hear.
""The government must now spell out how we can get out of tier three, and the measures they will use to review Leicester's position, to give people hope their sacrifices will make a difference.""
Meanwhile, the Conservative MP for Rutland and Melton said she is pleased about the decision to put Rutland into tier two.
Alicia Kearns said: ""I welcome that Rutland has been respected as the independent county it is and therefore tiered separately.""
But she added she was ""deeply disappointed"" the likes of Melton and Harborough had been grouped with all of Leicestershire.
Leicester had a seven-day coronavirus infection rate of 398.3 per 100,000 people for the week to 21 November - the 14th highest rate in England.
The number of confirmed cases in the same week was 1,411, down from 1,857 in the seven days up to 14 November. The infection rate is also down from 524.2.
The borough of Oadby and Wigston has the county's highest rate of 417.4 - putting it 11th nationally - but the rate has also decreased from 526.2.
The average for the whole of England is 208.7.
The Christmas lights might be up in Leicester, but let's be honest, not many people are going to see them.
It has the title that no city wants - it has been in Covid-restrictive measures for longer than anywhere else in the country.
Today's news from Health Secretary Matt Hancock has confirmed what Leicester's mayor Sir Peter Soulsby and many people here feared - that the city is going into the highest tier.
That's tough news for those here and means it has been eight months since people have not been allowed to have family and friends in their homes.
Some non-urgent operations in Leicester have been cancelled, with one local health boss fearing the second wave of the virus will be worse than the first.
The Leicester, Leicestershire and Rutland's clinical commissioning groups (CCGs) said their hospitals were treating 260 people with coronavirus, compared with 204 at the peak in April.
Last week Leicester mayor Sir Peter Soulsby said the ""hopeless"" performance of the national test and trace system had contributed to the recent surge in city cases.
Both the city and county have been sent thousands of rapid result lateral flow tests to help bolster Covid-19 testing.
_Follow BBC East Midlands on_Facebook _,_Twitter _, or_Instagram _. Send your story ideas to_eastmidsnews@bbc.co.uk _._"
"

 _The_ Current Wisdom _is a series of monthly articles in which Patrick J. Michaels and Paul C. “Chip” Knappenberger, from Cato’s Center for the Study of Science, review interesting items on global warming in the scientific literature or of a more technical nature that may not have received the media attention that they deserved, or have been misinterpreted in the popular press._   
  
\---   
  
Despite what you may think if you reside in the eastern United States, the world as a whole in 2014 has been fairly warm. For the past few months, several temperature-tracking agencies have been hinting that this year may turn out to be the “warmest ever recorded”—for whatever that is worth (keep reading for our evaluation). The hints have been turned up a notch with the latest United Nations climate confab taking place in Lima, Peru through December 12. The mainstream media is happy to popularize these claims (as are government-money-seeking science lobbying groups).   
  
But a closer look shows two things: first, whether or not 2014 will prove to be the record warmest year depends on whom you ask; and second, no matter where the final number for the year ranks in the observations, it will rank among the greatest “busts” of climate model predictions (which collectively expected it to be _a lot_ warmer). The implication of the first is just nothing more than a jostling for press coverage. The implication of the latter is that future climate change appears to be less of a menace than assumed by the president and his pen and phone.   
  
Let’s examine at the various temperature records.   
  
First, a little background. Several different groups compile the global average temperature in near-real time. Each uses slightly different data-handling techniques (such as how to account for missing data) and so each gets a slightly different (but nevertheless very similar) values. Several groups compute the surface temperature, while others calculate the global average temperature in the lower atmosphere (a bit freer from confounding factors like urbanization). All, thus far, only have data for 2014 compiled through October, so the final ranking for 2014, at this point in time, is only a speculation (although a pretty well-founded one).   
  
The three major groups calculating the average _surface_ temperature of the earth (land and ocean combined) all are currently indicating that 2014 will likely nudge out 2010 (by a couple hundredths of a degree Celsius) to become the warmest year in each dataset (which begin in mid-to-late 1800s). This is almost certainly true in the datasets maintained by the U.S. National Oceanographic and Atmospheric Administration (NOAA) and the UK Met Office Hadley Centre. In the record compiled by NASA’s Goddard Institute for Space Studies (GISS), the 2014 year-to-date value is in a virtual dead heat with the annual value for 2010, so the final ranking will depend heavily on the how the data come in for November and December. (The other major data compilation, the one developed by the Berkeley Earth group is not updated in real time).



There is one other compilation of the earth’s surface temperature history that has recently been developed by researchers Kevin Cowtan and Robert Way of the University of York. This dataset rose to prominence a year ago, when it showed that if improved (?) methods were used to fill in data-sparse regions of the earth (primarily in the Arctic), the global warming “hiatus” was more of a global warming “slowdown.” In other words, a more informed guess indicated that the Arctic had been warming at a greater rate than was being expressed by the other datasets. This instantly made the Cowtan and Way dataset the darling of folks who wanted to show that global warming was alive and well and not, in fact, in a coma (a careful analysis of the implications of Cowtan and Way’s findings however proved the data not up to that task). So what are the prospects of 2014 being a record warm year in the Cowtan and Way dataset? Slim. 2014 currently trails 2010 by a couple hundredths of a degree Celsius—an amount that will be difficult to make up without an exceptionally warm November and December. Consquently, the briefly favored dataset is now being largely ignored.   
  
It is worth pointing out, that as a result of data and computational uncertainty, _none_ of the surface compilations will 2014 be statistically different from 2010—in other words, it is impossible to say with statistical certainty, that 2014 was (or was not) the all-time warmest year ever recorded.   
  
It is a different story in the lower atmosphere.   
  
There, the two groups compiling the average temperature show that 2014 is nowhere near the warmest (in data which starts in 1979), trailing 1998 by several _tenths_ of a degree Celsius. This difference is so great that it statistically clear that 2014 will not be a record year (it’ll probably fall in the lower half of the top five warmest years in both the Remote Sensing Systems (RSS) and the University of Alabama-Huntsville (UAH) datasets). The variability of temperatures in the lower atmosphere is more sensitive to the occurrence of El Niño conditions and thus the super El Niño of 1998 set a high temperature mark that will likely stand for many years to come, or at least until another huge El Niño occurs.   
  
Basically, what all this means, is that if you want 2014 to be the “warmest year ever recorded” you can find data to back you up, and if you prefer it not be, well, you can find data to back up that position as well.   
  
In all cases, the former will make headlines.   
  
But these headlines will be misplaced. The real news is that climate models continue to perform incredibly poorly by grossly overestimating the degree to which the earth is warming.   
  
Let’s examine climate model projections for 2014 against the observations from the dataset which has the greatest chance of 2014 as the warmest year—the NOAA dataset.   
  
Figure 1 shows the average of 108 different climate model projections of the annual surface temperature of the earth from 1980 through 2014 along with the annual temperature as compiled by NOAA.   




  




_Figure 1. Global annual surface temperature anomalies from 1980 to 2014. The average of 108 climate models (red) and observations from NOAA (blue) are anomalies from the 20 th century average. In the case of the NOAA observations, the 2014 value is the average of January-October._   
  
**For the past 16 straight years, climate models have collectively projected more warming than has been observed.**   
  
Over the period 1980-2014, climate models projected the global temperature to rise at a rate of 0.24°C/decade while NOAA observations pegged the rise at 0.14°C/decade, about 40 percent less. Over the last 16 years, the observed rise is nearly 66 percent less than climate model projections. The situation is getting worse, not better. This is the real news, because it means that prospects for overly disruptive climate change are growing slimmer, as are justifications for drastic intervention.   
  
We don’t expect many stories to look any further than their “2014 is the warmest year ever” headlines.   
  
As to the rest of the picture, and the part which holds the deeper and more important implications, well, you’ll have to keep checking back with us here—we’re happy to fill you in!


"
"Ash dieback – a fatal disease of Britain’s native ash trees (Fraxinus excelsior) – is one of the worst tree disease epidemics the UK has ever seen. The disease is caused by a fungus that originated in Asia but is thought to have arrived in Europe on exotic plants in the early 1990s, where it has devastated native ash species which have very little natural immunity. Ash dieback has since spread ferociously throughout Europe due to airborne spores and trade in ash saplings which have no visual symptoms of the disease. In 2012, the disease was confirmed in the UK and later shown to have been imported on saplings to multiple sites across the country. It is now found throughout the UK. There’s no cure and very few trees show signs of long-term resistance. The environmental impacts of the disease are likely to last a long time, but as our new paper explains, they’ll also carry a shockingly high economic cost. There are 150m mature ash trees in the UK, making ash one of the most common native tree species in the country. We estimate that ash dieback will kill at least 95% of ash trees and cost the UK economy £15 billion – a cost one third greater than that reported from the foot-and-mouth disease outbreak in 2001. Half of this cost will arise in the next ten years. Putting a monetary value on ecosystem services – the beneficial effects that trees provide for people and the economy - helps people understand the scale of the problem. Roughly £10 billion worth of ecosystem services will be lost as ash trees disappear. Losing these services will have wide-ranging consequences. Less carbon dioxide will be absorbed from the atmosphere and the risk of flooding will increase. Studies have also shown that losing trees from a community is linked to poorer physical and mental health among the people who live there. Tackling climate change calls for an enormous effort to plant trees but ash dieback will rob the UK of using this valuable native species. Clearing up dead and dying ash trees will carry another major cost, particularly where they present a risk to human safety. Stricken ash trees are prone to shedding limbs or collapsing completely, either directly due to the ash dieback fungus or a secondary pathogen such as honey fungus infecting the weakened tree. More than 4m ash trees line Britain’s roadsides. Felling these will be expensive and involve road closures and power and communications outages as work is carried out.  Ash trees in towns and cities will need the same treatment. A major national replanting effort could reduce the total cost of losing ash trees by as much as £2.5 billion, but a diverse mixture of native species will need to be planted to improve the resilience of new trees to pests and diseases. Replanting should also be carefully managed to ensure habitats are connected throughout the landscape. Exotic disease is not a problem limited to ash trees. People move plants – and unwittingly, their diseases – around the world at rates that far outstrip natural disease spread. The international trade in plants, travel and climate change are all contributing to an acceleration in the rate of new tree diseases emerging and spreading.  More tree pests and diseases have arrived in Britain in the last 40 years than at any time before then. As more native species are threatened, the effects will combine and multiply. Losing most ash trees will be bad enough, but what if the UK loses oak next, or birch? The idea of a landscape largely devoid of trees is appalling, and the economic costs incalculable. People aren’t powerless in this story though. The science is clear that the largest pathway for spreading tree diseases is the international trade in live plants and soil. Stricter controls on this trade could better protect our trees for generations to come. Most countries prioritise the value of trade in live plants over the risks to their native flora. Our paper shows that the value of the annual trade in ash saplings amounted to only 2% of the estimated cost of ash dieback. The costs of restricting trade and improving border controls have long been used to block the introduction of stronger biosecurity measures for plants. But we now know that the costs of diseases like ash dieback have been wildly underestimated and this new evidence demands an urgent rethink. The health of native trees, in fact of all wildlife, needs to be valued far more highly. We must recognise not only the essential benefits that the natural environment provides for us, but how severe the consequences are for society when new pathogens are spread."
"**Greater Manchester's mayor said he hopes the region will only face the toughest government coronavirus restrictions for a couple of weeks.**
Areas with the highest infection rates, including Greater Manchester, will go into tier three when lockdown ends.
Mayor Andy Burnham said that, although cases of coronavirus were still high locally, rates were declining.
He said if they continue to fall ""we will be making the strongest possible argument"" to be moved to tier two.
The area's tier level may change before Christmas with a review scheduled for 16 December.
The new tier rules will come into force on Wednesday. In tier three, people can only meet other households in outdoor public spaces like parks, where the rule of six applies.
Gyms and close-contact beauty services like hairdressers will be able to open but in tier three, pubs and restaurants can only operate as a takeaway or delivery service.
Mr Burnham said: ""I feel for people who have been living under restrictions for a long time now,"" and called for additional support for businesses.
""The new tier three will hit the hospitality sector extremely hard. While there are grants for businesses forced to close, there is no extra support for business which supply them like security, catering and cleaning.
""This will cause real hardship for people whose jobs will be affected and risk the loss of many businesses.""
In October, Mr Burnham was involved in a lengthy public dispute with the government over Greater Manchester being placed in tier three and the level of financial support.
Health Secretary Matt Hancock said the battle had been ""bad for public health"" and ruled out negotiations with local leaders in favour of a formula to decide which areas are placed in what tier.
Greater Manchester's night-time economy adviser, Sacha Lord, said: ""We're in tier three and we're not surprised"".
But he added ""the R rate is dropping rapidly, so it does feel like if we carry on like this, we could be in tier two shortly"".
**Tier three (very high)**
William Wragg, Conservative MP for Hazel Grove, said he will ""most likely be voting against these measures"".
""What I've been pushing for is for the different boroughs in Greater Manchester to be treated separately given the range of data that we have about the prevalence of the virus,"" he said.
UnitedCity - a group of business leaders across Manchester- said the news was ""a massive blow to hospitality, leisure, culture, events and sports businesses based in the region"".
""Data has clearly shown that cases of the virus were starting to fall before the November lockdown, so for restrictions as harsh as the 'new' tier three ones are to be placed upon us does feel somewhat rancorous.""
Karen Hill, a hairdresser in Oldham, said she is glad she can reopen but she expects business to be quiet: ""I do feel better that we can open, but because there's not going to be Christmas dos, it's not going to be our normal December.
""No-one's going to be going anywhere in January and February, so we're not going to have the new year, new me.""
_Why not follow BBC North West on_Facebook _,_Twitter _and_Instagram _? You can also send story ideas to_northwest.newsonline@bbc.co.uk"
"Microplastics have been discovered in a remote area of the French Pyrenees mountains. The particles travelled through the atmosphere and were blown into the once pristine region by the wind, according to a new study published in Nature Geoscience.  This is just the latest example of the “hidden risks” posed by plastics that humans cannot see with the naked eye. For now, governments and activists are focused on avoiding plastic litter in the environment, driven mainly by concern for wildlife and worries over unsightly drinks bottles or abandoned fishing nets on beaches. Plastic bag usage has been cut in many parts of the world, and various projects are exploring how to gather up the floating plastic waste in oceans. But little has yet been done to deal with polluting plastic particles that are usually invisible. There is however growing concern about these micro and nanoplastics, classified as particles smaller than 5mm. These come in part from deliberately manufactured sources, such as scrubbing materials in cleaning and cosmetic products, but also from secondary sources, such as the inevitable breaking up or wearing down of larger items such as tyres or fibre shed from tumble driers and washing machines. We are becoming increasingly aware of their presence but know surprising little about how much is out there, how it behaves in our environment, and what the implications are for human and animal well-being. As more studies publish their findings we are learning that microplastics are more widespread than we imagined, and that they are found in every environmental system investigated. Plastic particles have been found in record-breaking quantities in river sediments in the UK, for instance, while a study in Paris found plastic fibres in wastewater and the air.  This is perhaps to be expected in built up and polluted urban environments, but the new findings from the Bernadouze meteorological station in the Pyrenees are a different matter. This part of the mountain range is normally considered clean and pristine, not somewhere scientists would expect to find contamination. But the researchers looked for airborne plastic by collecting samples of atmospheric “fallout” over a five-month period. And they did indeed find microplastics, lots of them, in the form of tiny fragments, fibres and films. While their exact source is a mystery they were shown to have potentially travelled up to 95km. Particles have also been found in deep ocean floor sediments, far from immediate sources of pollution, carried there by ocean currents and settling slowly. Other research has identified some astonishing ways microplastics can move between one environmental sub-system and others. Alongside the obvious route of direct ingestion by animals who become prey for others higher in the food chain, it is now apparent that there are other more innocuous routeways, such as mosquito larvae in water ingesting plastics that are then retained in their bodies as the animals become flying insects. This releases particles into the atmosphere allowing them to float for thousands of miles, or to be inhaled. The amount of plastic in the environment has increased and we are still making lots more. It stands to reason that microplastics are going be with us for a while yet, since plastic itself has many beneficial uses. If these fragments were unreactive and harmless they would not pose a threat, but unfortunately the risks are not yet fully understood. Alongside the issues associated with inadvertent ingestion of large volumes of material without any nutritional value, there are some hidden risks. Microplastics have a relatively large surface area and so could potentially provide sites for surface reactions and act as rafts for organic pollution. Given that microplastics are turning up in drinking water and food we need to do more work to understand the risks to health and work out ways to manage this risk. A study that found microplastics in a fish liver raised concerns that plastic can cross the gut if it is ingested. The trouble is, these plastics are so small they are not easy to remove from the environment once they get there. The key is preventing their escape into the environment in the first place. Focusing on the bigger plastics we can see may be a distraction from this potentially larger problem in the air we breathe and the food we eat, but tackling the problem at the source could go a long way to helping with damage limitation."
"The record temperatures of summer 2019 helped make it the best season for butterflies in 22 years, with more than half of Britain’s species increasing in number. Last summer delivered a winning combination of warmth, sunshine and rain which ensured that caterpillars fed up on lush plants before emerging as adult butterflies.  The marbled white enjoyed its best year since scientific monitoring began in 1976, continuing its climate-assisted march northwards, and the dark green fritillary enjoyed its third best year on record, its numbers up 51% on the previous year. The drought of 2018 led to fears of a crash in butterfly populations, particularly among species whose caterpillars feed on grasses that shrivelled up that summer. Unexpectedly, however, the annual UK Butterfly Monitoring Scheme revealed that plenty of grass-feeding species thrived in 2019 including the ringlet, enjoying its second-best year on record, the meadow brown, which had its fifth-best year, and the rare Lulworth skipper, numbers of which increased by 138% on the previous year. The monitoring of 3,014 sites by volunteers supported by Butterfly Conservation, the UK Centre for Ecology & Hydrology, the British Trust for Ornithology and the Joint Nature Conservation Committee, showed that summer 2019 was also a notable year for the painted lady. The migratory butterfly flew in from Africa via continental Europe in greater numbers than in any summer apart from 2009 and 1996. Prof Tom Brereton of Butterfly Conservation said the encouraging results “provide evidence that the overall rate of decline of butterflies is slowing and for some species being reversed”. He said conservation through agri-environment schemes, increased woodland cover, climate warming and “increases in grazing levels by wild animals and a slowing in the rate of agricultural intensification” had all played their part. Dr Marc Botham of the UK Centre for Ecology & Hydrology said two warm summers in succession, which allowed population numbers to build up over a longer period, had also contributed to the boom year. “In addition to record numbers of spring species such as orange-tip and brimstone, it was also encouraging to see annual increases in garden favourites such as peacock and small tortoiseshell, both of which have had some poor years recently,” he said. Some species, however, are struggling to adapt to rapid climatic changes. The rare heath fritillary saw its annual abundance drop by 34%. Its numbers have fallen by 91% over the long term as a result of climate change and a loss of traditional coppicing in woodlands and grazing on moorland. The figures show that targeted conservation work is helping many rarer species, including the chequered skipper, up by 175% on 2018, and the Duke of Burgundy, which a decade ago was threatened with extinction but recorded its eighth best year since 1976. Other species benefiting from habitat management include the marsh fritillary, silver-studded blue and silver-spotted skipper, none of which are now in long-term population decline. “We’re really heartened to see a shift in the fortunes of many of our most loved species,” Brereton said. “The long-term situation for butterflies in general does remain a cause of concern though, with more species declining than increasing since the 1970s.”"
"
Josh, of Cartoons by Josh has a take on the attendance of COP16 at Cancun, said to be down more than 50% over last year’s COP15 shindig in Copenhagen. 



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e87546866',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"Anyone who has ever spent time observing wild animals in nature will know that silence is golden. Wildlife tours recommend that people stay quiet in order to see more, but research on Tibetan macaques suggests that high levels of noise from tourists can also lead to more aggressive behaviour. Although wildlife tourism can generate funds for conservation and sustainable work for local people, these benefits may be meaningless if visitors negatively impact animals and their habitats. Is the mere presence of humans off putting to wild animals or does it all have to do with the noise they make? By playing recordings of people talking from speakers in the animals’ environment, scientists can observe how wild animals respond to human speech alone. Large canivores such as wild pumas in California and Amazonian bird communities were shown to flee when they heard human voices. Fleeing is useful to escape potentially dangerous situations, but it comes at a cost for animals and tour companies as paying tourists see less wildlife and animals exert themselves. This leaves animals stressed and less able to reproduce and could mean they go hungry if they have to give up food in the area they fled from.  Our study found that the wildlife was less likely to flee from humans if speech was quieter. By simply asking people to be as quiet as possible, the full benefits of wildlife tourism to animals and people could be realised. We conducted a playback study with wild pygmy marmosets in the flooded forest of the Peruvian Amazon to see if longer or louder speech was more disruptive to their behaviour. Pygmy marmosets are the world’s smallest monkey, and family groups form a small territory around the gum producing trees which they feed on. For each experiment, the behaviour of a single pygmy marmoset in the group was recorded on video for four minutes.  Two minutes into the recording, a sound was played from a speaker positioned on a boat. We then categorised the behaviours shown in these videos and compared the behaviour of individuals before and after the playback. When played recordings of human speech, pygmy marmosets fed and rested less and spent more time in an alert posture. These effects were observed at all volumes and durations of human speech but there was no change in their behaviour when humans were present but no voice was played.  Like the puma and hoatzin, pygmy marmosets moved away when human speech was played, even at the volume of a whisper. Although the duration of the speech had no effect, the louder the playback the more likely individuals were to move away. As a pygmy marmoset family group can depend on a single feeding tree in their territory, fleeing from these places can have serious consequences. These results were surprising as some of the ten experimental groups were regularly visited by tourists, and two groups were even located in back gardens in a local village. These animals are regularly exposed to humans, but still find human speech – and particularly loud speech – disturbing.  So wildlife tourism can be good for animals and humans if tourists lower their voices – even whispering can disturb animals and may allow tourists little more than a fleeting glance of wildlife."
"

In the past year, concern for the environment has risen to the top of the public’s agenda. Now the environmental movement must face a monster of its own making. The very success of environmentalism threatens to undo two of mankind’s most significant environmental victories. The first is the near stabilization of humanity’s agricultural footprint, expansion of which is the single largest threat to biodiversity worldwide. The second is the spectacular reduction in chronic hunger and malnutrition without which the pressure to convert land for agricultural use would have been stronger.



Around the globe between 1990 and 2003, the amount of land given over to agricultural uses increased less than 2 percent, even though population growth increased 20 percent. Chronic hunger in developing countries declined to 17 percent from 37 percent between 1970 and 2001, despite an 83 percent increase in population. These improvements, largely due to greater agricultural productivity, increased food production per capita, helping to drive down global food prices by about 75 percent since 1950. As a result, access to food increased worldwide, despite increasing demand from a wealthier and more populated world.



The resulting reductions in hunger further reduced pressures for converting more land for agricultural uses.



Global warming hysteria — a boon for the ethanol and other biofuel enterprises — has boosted demand for crop‐​based fuels worldwide. This now threatens to reverse a half century of gains not only against world hunger, but also in holding the line against conversion of undeveloped land.



The cost of food has jumped over 10 percent in India over the past year, and 6 percent in China, according to The Wall Street Journal. This is partly due to the diversion of corn to biofuels.



In the United States, driven by subsidized ethanol, farmers were planning to plant a record 90.5 million acres in corn in 2007, the highest since 1944, while at the same time reducing acreage in soybeans, rice and cotton.



Meanwhile, European demand for biofuels to replace gasoline is fueling plans for massive clearing of rainforests for palm‐​oil plantations in Indonesia and Malaysia.



These rainforests, among other things, provide refuge for the Sumatran tiger, Borneo’s orangutan and the Malaysian elephant. 



Ironically, much of the hysteria over global warming is itself fueled by concerns that it may drive numerous species to extinction and increase hunger worldwide, especially in developing countries. Yet the biofuel solution would only make bad matters worse on both counts. 



As long as global warming is hyped as the world’s most important environmental problem — as many politicians and environmental pressure groups claim — it will be virtually impossible to rationally evaluate other options in dealing with climate change, or confront the unintended consequences unleashed by global warming hysteria. 
"
"Whenever I visit the Sahara I am struck by how sunny and hot it is and how clear the sky can be. Aside from a few oases there is little vegetation, and most of the world’s largest desert is covered with rocks, sand and sand dunes. The Saharan sun is powerful enough to provide Earth with significant solar energy. The statistics are mind-boggling. If the desert were a country, it would be fifth biggest in the world – it’s larger than Brazil and slightly smaller than China and the US. Each square metre receives, on average, between 2,000 and 3,000 kilowatt hours of solar energy per year, according to NASA estimates. Given the Sahara covers about 9m km², that means the total energy available – that is, if every inch of the desert soaked up every drop of the sun’s energy – is more than 22 billion gigawatt hours (GWh) a year.  This is again a big number that requires some context: it means that a hypothetical solar farm that covered the entire desert would produce 2,000 times more energy than even the largest power stations in the world, which generate barely 100,000 GWh a year. In fact, its output would be equivalent to more than 36 billion barrels of oil per day – that’s around five barrels per person per day. In this scenario, the Sahara could potentially produce more than 7,000 times the electricity requirements of Europe, with almost no carbon emissions. What’s more, the Sahara also has the advantage of being very close to Europe. The shortest distance between North Africa and Europe is just 15km at the Strait of Gibraltar. But even much further distances, across the main width of the Mediterranean, are perfectly practical – after all, the world’s longest underwater power cable runs for nearly 600km between Norway and the Netherlands. Over the past decade or so, scientists (including me and my colleagues) have looked at how desert solar could meet increasing local energy demand and eventually power Europe too – and how this might work in practice. And these academic insights have been translated in serious plans. The highest profile attempt was Desertec, a project announced in 2009 that quickly acquired lots of funding from various banks and energy firms before largely collapsing when most investors pulled out five years later, citing high costs. Such projects are held back by a variety of political, commercial and social factors, including a lack of rapid development in the region.  More recent proposals include the TuNur project in Tunisia, which aims to power more than 2m European homes, or the Noor Complex Solar Power Plant in Morocco which also aims to export energy to Europe. There are two practical technologies at the moment to generate solar electricity within this context: concentrated solar power (CSP) and regular photovoltaic solar panels. Each has its pros and cons. Concentrated solar power uses lenses or mirrors to focus the sun’s energy in one spot, which becomes incredibly hot. This heat then generates electricity through conventional steam turbines. Some systems use molten salt to store energy, allowing electricity to also be produced at night.  CSP seems to be more suitable to the Sahara due to the direct sun, lack of clouds and high temperatures which makes it more efficient. However the lenses and mirrors could be covered by sand storms, while the turbine and steam heating systems remain complex technologies. But the most important drawback of the technology is its use of scarce water resources.  Photovoltaic solar panels instead convert the sun’s energy to electricity directly using semiconductors. It is the most common type of solar power as it can be either connected to the grid or distributed for small-scale use on individual buildings. Also, it provides reasonable output in cloudy weather.     But one of the drawbacks is that when the panels get too hot their efficiency drops. This isn’t ideal in a part of the world where summer temperatures can easily exceed 45℃ in the shade, and given that demand for energy for air conditioning is strongest during the hottest parts of the day. Another problem is that sand storms could cover the panels, further reducing their efficiency.  Both technologies might need some amount of water to clean the mirrors and panels depending on the weather, which also makes water an important factor to consider. Most researchers suggest integrating the two main technologies to develop a hybrid system.  Just a small portion of the Sahara could produce as much energy as the entire continent of Africa does at present. As solar technology improves, things will only get cheaper and more efficient. The Sahara may be inhospitable for most plants and animals, but it could bring sustainable energy to life across North Africa – and beyond. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t. This article was updated on April 30 to correct an error. Saharan solar could potentially produce more than seven thousand times the electricity requirements of Europe (not 7)."
"**Two Northern Ireland charities have said they are facing huge losses and staff cuts because of Covid-19.**
The Stroke Association and Children's Heartbeat Trust said they have been denied vital support from Stormont because they did not meet the criteria.
The charities pleaded on Thursday with MLA's on Stormont's Communities Committee for help.
Both organisations said their service users were missing out on vital services.
Sarah Quinlan, chief executive of the Children's Heartbeat Trust, which provides financial support for children to travel outside Northern Ireland for vital surgery, said they are facing a deficit of Â£100,000 at a time when demand for their services is growing.
She said last year the charity helped 171 children and their families while already this year they have helped 232 families.
""Our services are life changing and yet we are not getting the support we badly need,"" she said.
""If we are forced down the road of making redundancies then we will be losing services.""
She said the charity did not qualify for support from the Covid charity fund because it holds reserves, which meant it was unlikely to close.
The Stroke Association was also ruled out of the support scheme because of reserves held by its parent organisation in London.
Director Barry Macaulay told MLAs it had lost Â£125,000 from direct fundraising, which had to be abandoned because of Covid-19, and they lost a further Â£100,000 in support from its headquarters in London.
""That leaves us having to operate with a deficit of Â£225,000 at a time when people are still having strokes and not being able to access rehab,"" he said.
He warned if they don't secure more funding they will be forced to cut their staff from 25 to 12.
Both charities called on the communities minister to widen the criteria of the fund, which is due to reopen before Christmas.
The fund will provide Â£6.8m to help charities directly affected by the Covid-19 crisis.
Members were informed that of the 645 charities that applied for support, 501 were eligible."
"The UK government is prepared to accept funding for studies on the risks of pesticides to bees and other pollinators from the manufacturers of the chemicals in question. Not surprisingly, this raises uncomfortable questions about trust and transparency, as a report from the Environmental Audit Committee points out. I share their concerns that the Department for the Environment, Food and Rural Affairs (Defra) has insufficient capacity to monitor environmental safety and to carry out the sort of urgent testing needed for these neonicotinoid pesticides. The testing demanded is limited to industry-funded field trials. Will the fields chosen for outdoor trials reflect all fields where neonicotinoids may be used? Unlikely as most environments are complex and unique. Therefore, conclusions are hard to interpret – there are so many influencing factors including weather, disease, habitat structure and the use of other pesticides. And despite all farmers being required by EU regulations to record their use of pesticides, this information is not collected in the UK. Without knowledge on how farmers have used pesticides, singly and combined together, a huge unknown risk exists – not just to insects, but all life. Lab studies simplify a problem by breaking it down into testable hypotheses, in carefully controlled experiments, with other potential varying factors removed. Field studies can control some factors, but this is at the expense of being realistic – their claimed advantage. Alternatively, as Defra proposes, one can include other variables into the analysis. An excellent idea, but the experiments would need to be impossibly large, and one critical variable is missing – the presence of other pesticides – as Defra does not currently consider this important. The fact is we need both laboratory and field trials, and a more rigorous understanding of what insect pollinators are important and affected, the impact of different habitats and threats, what pesticides are there and how these all interact. Without adequate funding, we cannot hope to acquire this full scientific knowledge, and so we should adopt a precautionary principle wherever evidence of risk exists. This shouldn’t consider economic interests. It should be use-dependent, and consider what alternatives exist. Regardless of your opinion on the risks of neonicotinoid pesticides, nobody would recommend replacing them with even more toxic compounds; yet alternative pesticide options are not compared side by side in order to make a strategic choice. It has become clear that a simple lethal dose at which 50% (LD50) of bees or pollinators die is too crude a test to gauge a pesticide’s environmental risk. Which insects should be studied? In the laboratory, choices are limited due to issues of which insects can be easily bred and adapted for tests. In the field, we need a baseline to know what existed beforehand. What test? We need more assessment carried out on individual insects and how this impacts a colony’s performance. We also need to know about how long and in what concentrations pesticides persist in the environment.  Finally, we must investigate the effects of chemical cocktails. We can only achieve this through laboratory studies, and a mechanistic approach to screening. If we accept Defra’s view that only field studies are required, then we can never understand the full risk potential of chemical cocktails. But by combining the careful monitoring of insect pollinator populations (both managed and wild) and the information farmers record of which pesticides they use and how, we could actually learn from past mistakes using real field data. If the results are to be trusted by the public, the industry cannot be given control. Yet it is the pesticide chemical industry that needs the data in order to get approval for their products, for which they stand to financially benefit. So it’s obvious the industry should pay – but they must not control the research. Funds for such research should be collected by Defra and passed to research council funding agencies such as BBSRC and NERC to distribute anonymously to expert independent academic laboratories for blind testing. The researchers should know only what is essential to conduct safety tests in the field and laboratory. Industry should also be blinded to the identity of the researchers throughout, but receive the full dataset for comment.  This conflict of interest between safety and profit isn’t impossible to break. There is an urgent need for evidence of neonicotinoids’ safety, and perhaps anonymity can’t be achieved this time. Nevertheless the industry must not be involved at any stage of the research until after the findings have been peer-reviewed and published. Because if the public can’t trust the results, then the money has been wasted."
"
Share this...FacebookTwitterCountries like the USA who have been seduced by German socialists and Greens into thinking that solar energy and green energy feed-in schemes are a job creator and an engine to prosperity ought to think again. Der Spiegel reports.
 
Eastern Germany Hit Hard by Decline of Solar
By Charles Hawley
The global solar industry has entered a brutal phase of consolidation and nowhere are the effects as dramatic as in eastern Germany. Several companies have already declared bankruptcy, leaving towns and cities in the region struggling with job losses and tax revenue shortfalls. The future bodes ill.
The sun, it was said, was going to save Frankfurt an der Oder, a city of 60,000 on the Polish border. After years of post-reunification economic doldrums, whose nadir came with the 2003 failure of a much-ballyhooed microchip factory project, the burgeoning German solar industry took an interest in the down-on-its-luck city.
In 2006, solar-panel manufacturer Conergy moved into the never-used computer chip factory, joining Odersun, already headquartered in the city. In 2007, the United States solar giant First Solar opened a factory as well, followed by a second one last year.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Now, though, the future suddenly looks decidedly dark. Odersun declared bankruptcy in March and Conergy, while pledging to return to profit this year, has seen its share price lose 99.6 percent of its value in the last five years. Many doubt the company will survive. Worst of all, however, was the announcement earlier this month that First Solar was closing both of its factories in Frankfurt an der Oder; 1,200 people will soon be jobless as a result.”
Keep reading…
It is indeed strange how so little of the mainstream media is reporting on one of the greatest industrial failures ever in Germany.
Even worse, solar industry has become a huge burden on the rest of the country due to the astronomically high cost of the energy and its sporadic supply.  More on that tomorrow. What a mess.
Readers in Vermont please send the Spiegel link to your drugged-up-on-green political leaders with the slim hope it’ll sober a few up.
 
Share this...FacebookTwitter "
"Solving environmental problems usually just means cleaning up the mess people have made. But scientists are increasingly interested in creating something valuable from pollution. “One man’s trash is another man’s treasure”, as they say, and researchers have now demonstrated several ways that useful products can be obtained from waste in industry and agriculture while also remediating contaminated soil, water and air. One environmental problem scientists are urgently trying to solve is the problem of carbon dioxide emissions which cause climate change. Researchers are developing processes which can capture carbon dioxide and convert it into useful chemicals like methanol – which can be used for fuel cells – or urea, which is used as a solvent in the chemical industry, in nitrogen fertiliser and in lactic acid, which can be used as a food preservative.  Carbon dioxide can also be captured and used to help grow algae, which are then harvested for biofuel. Wastewater – what we all flush away from our homes, offices and elsewhere – contains toxins and organic pollutants that treatment facilities remove before they can reach natural water systems like rivers and the ocean. However, researchers are trying to recover and turn this organic matter into something useful. Phosphorus and nitrogen are essential soil nutrients that are found in wastewater which could be returned to farm fields as fertilisers. Researchers have also taught microorganisms to break down toxic organic contaminants which are found in wastewater and generate electricity from them. As well as cleaning the water, microbial fuel cells would turn wastewater treatment facilities into giant batteries for green energy as electrochemically active bacteria degrade organic substances and release electrons to generate an electric current. Soil contamination with heavy metals is particularly tricky to solve. Usually, the only solution is to dig out the contaminated soil and dispose of it at a landfill site. Even then, contaminants can leach out of the soil and into underground water reservoirs, potentially ending up in plants and food crops, which soak up the water during growth. An alternative method involves a combination of phytoremediation and biorefinery. Biorefinery means processing biomass – such as food waste and the plant remains from agriculture – to produce valuable commodities. Phytoremediation cleans up environmental pollution using plants to extract metals from the contaminated soil in the same way a white rose would absorb red food colouring from dyed water and grow red petals.  Chinese brake fern (Pteris vittata) can accumulate arsenic as it grows and could be used to clean up areas contaminated with arsenic, such as land surrounding former mines in Cornwall and Devon. Phytoremediation can help recover rare earth elements and precious metals from the world’s most polluted places like Guiyu town in China, which became heavily contaminated from electrical waste disposal. By harvesting the plants with metal deposits stored in their cells, the toxic metals can be removed from the environment. The plant biomass can then be processed to recover metals for use in producing energy, fuel or industrial chemicals, making the whole process pay for itself. Environmental engineers are using their imagination to clean up the environment and generate wealth from waste at the same time. As our environmental woes intensify, we’ll need even more creative thinking."
"

On September 28, 1955, a Category 5 hurricane named Janet slammed into Chetumal, on Mexico’s Yucatan Peninsula, killing over 600 people.



Hurricane Dean, another Category 5, and the third‐​strongest storm ever measured at landfall, hit in exactly the same place last Friday and killed no one. Maximum winds in both storms were indistinguishable. Not surprisingly, the hurricane‐​hunter pilot who flew through the eyewall of the storm Tuesday reported severe turbulence, a temporary loss of aircraft control. Probably for the first time in human history, a Category 5 storm hit a populated area and everyone lived.



Because of its peculiar location, the Yucatan takes more big hurricane hits than just about anywhere else in the Western hemisphere. When Mexico was dirt‐​poor, as it was in 1955, hurricanes could kill hundreds. They were warned, then, too. Hurricane‐​hunter planes also monitored Janet. Only one of these has ever been lost, and it was as Janet was making landfall.



Similar storms, huge storms, very different results. What’s happening here?



Since then, people in the Yucatan have learned to adapt. While storms like these used to kill hundreds, even thousands, we now have the technology to forecast their tracks, at least for the critical last 24 hours, with reasonable confidence. Forecasting the intensity is a bit trickier, but everyone in the hurricane business was pretty convinced that Dean was going to bomb out sometime before it hit land. After all, it was passing over the same region in which the 1988 hurricane Gilbert set the record for the lowest barometric pressure ever measured in the Atlantic Basin.



Gilbert was the second‐​strongest storm ever recorded at landfall, and it also hit the Yucatan. While it was responsible for 202 deaths in Mexico, almost all of these were caused by mountain floods hundreds of miles away and days away from landfall.



Adaptation includes technology, infrastructure, and response. National Hurricane Center forecasts and data are available to everyone. But the infrastructure to respond to a forecast hurricane costs money, and poor nations don’t have it. Among other things, it requires good roads for evacuation.



Perhaps even more important, adaptation to hurricanes or other natural disasters is political. No elected official wants to be blamed for hundreds of preventable deaths, so the nations that can afford it develop evacuation plans, open shelters, and deliver people from danger.



When Janet killed hundreds, per‐​capita income in Mexico was less than a tenth of what it is now, when Dean killed no one.



So why is it that people are wringing their hands about global warming causing more severe hurricanes and deaths?



The best computer estimate for future hurricanes was published by Tom Knutson and Robert Tuleya in the _Journal of Climate_ in 2004. They calculated that maximum winds should increase by about 6% over the next 75 years. Even this may be an overestimate because the method used assumes carbon dioxide — the main global warming emission — is increasing in the atmosphere about twice as fast as it actually is.



Clearly, this small increase in hurricane strength is going to be dramatically overshadowed by adaptation as the developing world continues to develop. Mexico is a case in point.



We see other adaptations to climate change in our cities. In the United States, cities with the most frequent heat waves have the fewest heat‐​related deaths, and heat‐​related deaths are themselves dropping, as our cities warm. Remember, a city doesn’t need global warming to get hot. All it needs is a skyline, and a lot of blacktop and concrete to impede the flow of air and retain heat. But in our warming cities, just as with hurricanes in the Yucatan, frequency + affluence = adaptation.



An odd example of this is that there is only one major U.S. city in which heat related deaths are increasing, and it is the coolest one in summer: Seattle.



Anyone concerned about climate change should take a lesson from Hurricane Dean. Even if storms like this become more frequent in the future, people will adapt and survive if they have the financial resources. How silly it seems to take those resources away in futile attempts to “stop global warming” — which no one even knows how to do — when they could save lives by allowing people to adapt to our ever‐​changing climate.



The truth is that money in the hand is a lot more useful than treaties on paper when it comes to sparing yourself and your family from bad weather. So people truly worried about climate change should be cheerleading for the global trade and economic development that will continue allowing us to adapt.
"
"
Photo by Warner Bros. Pictures (Inception)
Canadian actress Ellen Page (Juno, Inception) has produced a great YouTube video urging everyone to participate in 350.org’s “Global Work Party Day” on October 10, 2010.
From the Huffington Post:
Page cites this summer’s floods in Pakistan and the Gulf oil spill as  evidence for the need to tackle the climate change crisis directly and  reduce dependence on dirty energy, and that the solution begins at the  local level.
“I’m tired of waiting around and listening to politicians argue.   They need to stop talking and start working,” Page says.  And she thinks  the Global Work Party on October 10 is the perfect way to show them  how. 
10/10/10 is a day to meet up with others in your community and work  toward different climate change solutions.  For example, Page mentions  that in Pakistan, women will be teaching how to use solar stoves, and  sumo wrestlers in Japan will be biking to practice.
Go to 350.org to find events in your area, or organize your own.  They even have plenty of ideas to help get you started.
“We want to send a clear message to our politicians:  We’re getting to work, so what about you?”


Oh wow:  sumo wrestlers in Japan will be biking to practice!  That will definitely “save the planet”.  There are over 5000 events on the 350.org webpage from all around the world.  Many are great like beach cleanups, tree plantings, and other feel-good community service efforts that will clearly help the environment.  However, there are some that really cause some head-scratching.  Here, as touted on the 350.org main page:  European 350 Team Become Strippers for the Climate … WUWT?  …and the previous posting by Anthony here …
So, please check out events in your area — and get the word out to your politicians.  Or submit your own idea in the comments / pick your favorite event and let us know!



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e88763f13',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

Advocates of health care reform and other big government programs, this is the business you have chosen: 



Main Street has had a tough year, losing jobs and seeing little evidence of the economic revival that experts say has already begun.   
  
  
But K Street is raking it in.   
  
  
Washington’s influence industry is on track to shatter last year’s record $3.3 billion spent to lobby Congress and the rest of the federal government — and that’s with a down economy and about 1,500 fewer registered lobbyists in town, according to data collected by the Center for Responsive Politics.…   
  
  
Plenty of sectors have scaled back their K Street spending, including traditional big spenders like real estate and telecommunications. But Obama’s push for legislation on health reform, financial reform and climate change has compensated for the grim economic times.   
  
  
And that’s after Obama kicked off the year with a massive economic stimulus package — and every major business sector tried to get a piece of the action. …   
  
  
“If lobbying the federal government did not work, people wouldn’t spend money doing it,” [Dave Levinthal, a spokesman for CRP] said.



Lay out a picnic, you get ants. Hand out more wealth through government, you get lobbyists. As Craig Holman of the Ralph Nader‐​founded Public Citizen says: _“the amount spent on lobbying … is related entirely to how much the federal government intervenes in the private economy.”_   
  
  
More on the lobbying bonanza in President Obama’s Washington here. Back in 2001 David Laband and George McClintock tried to estimate the total costs to society of efforts to effect forced transfers of wealth in their book _The Transfer Society_.
"
"The European Green Deal aims to transform the 27-country bloc from a high- to a low-carbon economy, without reducing prosperity and while improving people’s quality of life, through cleaner air and water, better health and a thriving natural world. If that sounds ambitious, it is. The European commission president, Ursula von der Leyen, called it “Europe’s man on the moon moment”. Nothing similar has been attempted before, as the pattern of human progress since the industrial revolution has been one of relentless exploitation and despoilment of the natural world, filling the atmosphere with carbon and the seas with plastic. Nearly every major aspect of the European economy will have to be overhauled, from energy generation to food consumption, from transport to manufacturing and construction. In part, this will build on two decades of work in a few of these sectors, such as directives mandating renewable energy and cutting air pollution. Previous attempts were piecemeal, limited in scope and sometimes flaccid in execution. Energy-intensive industries, for instance, have been covered by an emissions trading scheme since 2005, but political pressure kept the price of carbon low, rendering it largely ineffectual. The green deal will work through a framework of regulation and legislation setting clear overarching targets – a bloc-wide goal of net zero carbon emissions by 2050, and a 50%-55% cut in emissions by 2030 (compared with 1990 levels) are supposed to be at the core – alongside incentives to encourage private sector investment, with action plans for key sectors and goals such as halting species loss, cutting waste and better use of natural resources. All of the EU’s budget will be subject to checks to ensure it is spent in ways that benefit the environment. That includes the common agricultural policy, scorned by green campaigners for promoting intensive farming, which will retain farm subsidies but direct more to green measures. Science, research and development budgets will take on more of a low-carbon slant, and there will be a detailed roadmap of “50 actions for 2050” for other sectors. Jobs will be created, the commission believes, in new high-tech industries from renewable energy to electric vehicle manufacturing and sustainable building, and efficiencies in resource use will repay the cost of the changes. “The European green deal is our new growth strategy – a strategy for growth that gives back more than it takes away,” von der Leyen said. All of this will require myriad changes and detailed measures, which will have to pass through tortuous EU processes, requiring the approval of all member states and parliament, so the details will inevitably be subject to horse-trading and backroom deals. East European states have been promised financial incentives, as their economies are more fossil fuel dependent. The backing of the UK – which despite covertly watering down some measures in the past has broadly pushed for the low-carbon agenda – will be missed, predicts Jean Lambert, the former Green party MEP. The new European parliament also has more rightwing MEPs, so it may be harder to pass some measures, she says. The hole that Brexit has created in the EU budget will also be hard to fill. But what is clear is that the incoming presidency under von der Leyen and her vice-president, Frans Timmermans – charged with delivering the green deal – will throw all of its might behind the effort. “It’s not going to be straightforward to get all this through,” says Tom Burke, co-founder of the environmental group E3G. “It will be a typical EU process. But it has become the touchstone issue for this commission.” It needs to. Europe has cut emissions by roughly one quarter since 1990 – good but nowhere near enough to put the bloc on track to net zero by mid-century. Current measures will not suffice for that – disruptive change is required, which is why the green deal targets are key. On other environmental scores, the EU’s record is mixed. There have been vast improvements in areas such as air and water quality across EU states, western and eastern, in the past five decades, spurred by EU regulations since the 1980s. Dozens of harmful chemicals have been phased out, farm animal welfare standards raised and recycling rates beat most of the world. But alongside those successes, the natural world has suffered a calamity across the continent: birds, insects, mammals, fish … few creatures (other than humans) have had a good time of it since the EU was created in 1992.  At least €1 tn (£852bn) needs to be found over the next decade, according to the European commission. The biggest share, €503bn, should come from the EU budget, unleashing a further €114bn from national governments (because EU programmes often require a contribution from member states). The next €279bn would come mostly from the private sector: the idea is that companies would be encouraged to make risky green investments by loan guarantees from the European Investment Bank, the EU lender, which recently pledged to phase out loans to fossil fuel projects. On top of this Brussels has promised a €100bn “just transition” mechanism to help retrain workers who lose jobs in shuttered coal mines or steel factories. Even friendly experts detect wishful accounting in Brussels’ figures. Economists at the Bruegel thinktank say it is a stretch to consider the €503bn from the EU budget as “green investment”, as much of the money would be spent on traditional EU policies such as farm subsidies. Previous attempts to “green” the common agricultural policy have failed dismally. In a damning report in 2017, the EU’s auditors highlighted how farmers were being paid to undertake environmentally friendly measures they would have done anyway, such as crop rotation, while governments handed out “green” cash with little oversight. Others fear that carbon financiers will game the system, meaning EU cash fails to trigger truly green investment from the private sector. And don’t forget, EU governments last month failed to agree a new seven-year budget, with four “frugal” net payers leading the charge to cut EU spending. The €503bn is not even in the bank. Even if the EU realised its €1tn plan, it wouldn’t be enough. Bruegel argues the €1tn is only one third of what is needed, if the EU follows through with the commission’s plan to reduce European greenhouse gas emissions by up to 55% by 2030. Meanwhile, critics in eastern countries complain there is not enough money to help coal regions. In 2015 there were 128 coal mines alone in the EU employing more than 238,000 people from Aragón to Silesia. This year – coronavirus permitting – will see the most important international climate meeting since the landmark Paris agreement was signed in 2015. Then, all of the world’s functioning states signed up to hold global temperature rises to no more than 2C, and preferably to below 1.5C, beyond which the ravages of climate breakdown become catastrophic and irreversible. But the national pledges made at Paris on curbing greenhouse gases fell short of what is required to stay below 2C, and since 2015 the world’s carbon output has risen by 4%. At the Cop26 climate talks, to be held in Glasgow this November, nations are supposed to come up with tougher targets for 2030, and preferably also with goals for reaching net zero emissions by mid-century, or soon after. But enthusiasm has ebbed since Paris, from Donald Trump’s US, to Brazil, India and big oil producers such as Russia and Saudi Arabia. The key player will be China, the world’s biggest emitter of greenhouse gases and second biggest economy. At Paris, a pact between the US and China was the core of the deal. This time, the EU must bring China to the table alone. “EU climate leadership [in the form of] the green deal is crucial to putting pressure on China and other major emitters to make more ambitious climate commitments,” says Paul Bledsoe, a climate adviser in Bill Clinton’s White House, who has attended more than a dozen climate negotiations since the 1990s. “In the face of Trump’s climate nihilism, only the EU can show that the world’s largest economy can decarbonise while continuing to provide a high standard of living for its 500 million people.” The EU will face a backlash from its citizens, fuelled by populist politicians, for persisting with green policies, predicts Charles Grant, director of the Centre for European Reform thinktank. He points to the gilets jaunes protests in France, which took off after rises in fuel taxes intended to reduce carbon dioxide emissions, and the rise of the AFD in Germany. “The AFD is fuelled partly by climate scepticism. Populists are keen to promote anti-greenery, as they listen to voters,” he says. “The green agenda will meet more and more opposition as voters start to realise it will make them poorer and affect their lifestyles, and they will worry about Europe becoming less competitive than, say, India and China, which won’t be going carbon-neutral,” says Grant. “This will increase the electoral strength of populists.” Some leftwing campaigners have also attacked the plans. Taking issue with the “just transition” mechanism, Yanis Varoufakis and David Adler of the Democracy in Europe Movement 2025, wrote in the Guardian: “Will there be justice for the communities across Germany and France that have been asked to shoulder the costs of the climate transition? Does it speak to the swathes of Greek or Portuguese people who cannot afford to care about carbon emissions in 2050, preoccupied as they are with making ends meet this week? The stark answer is no.” Boris Johnson’s government has made it clear that the UK wants to depart from EU environmental standards after Brexit. The post-Brexit environment bill, agriculture bill and fisheries bill now going through the British parliament contain various loopholes that green campaigners say would reduce in the UK the environmental protections that current EU law guarantees. The UK does officially have a 25-year environment plan, with the government pledging to leave the UK’s natural realm in a better state than this generation inherited, but how that will hold up after Brexit is moot. On the climate crisis, the UK is aligned with the EU. Last summer, a target of reaching net zero by 2050 was enshrined in law, and all major parties are pledged to uphold it. What’s missing, though, is a clear plan of action to meet the net zero aim. That is what Europe’s green deal is meant to provide, and unless the UK forms its own parallel plans soon, its 2050 target will look increasingly adrift. The idea of a Green New Deal has been kicking around US politics since at least 2006. The European Green Deal (minus the word “new’ with its radical overtones) is not yet one year old. The EU plan resulted when an unexpected political leader collided with newly-elected MEPs, energised by the global climate movement. Von der Leyen, a German defence minister, was a surprise choice to become European commission president, leapfrogging candidates who had run in the European elections in May. Those elections resulted in a record number of seats for European Greens, as climate change topped the agenda in Germany and the Nordic countries. Von der Leyen’s last-minute elevation angered the European parliament, pressuring her to lean to the left, liberals and Greens to gain support. To win MEPs over, she promised a European Green Deal within 100 days of taking office. Beyond the Brussels power play, politicians were responding to the streets, as school children walked out of their classrooms, demanding action. The school strike was personal. Chief executives, heads of government and senior UN officials told EU officials their children were asking what they were doing to save the planet. As one official recounts: “You can imagine a conversation with your own children is much more confrontational than a conversation with a shareholder, or a bad headline in a newspaper.” It’s a bit like world peace: everyone backs the European Green Deal, in theory. But there is a big hole in the ambition to be net-zero by 2050: Poland, which says it will reach climate neutrality at “its own pace”. And beneath the surface, tensions over Europe’s green ambitions are not hard to find. At least eight countries, including Spain, Sweden and Latvia, want the EU to increase its 2030 emissions reduction target. Poland and Hungary think that is too much. Divisions will also come when hard choices have to be made: from closing coal mines, demanding more from farmers, to tougher emissions standards for the car industry. EU governments agree environmental laws with the European parliament. That gives MEPs a weighty role across a swathe of new laws expected to flow from the European Green Deal: a revision of the EU’s heavily criticised carbon trading scheme, new performance standards for cars and vans, an overhaul of farm policy, changes to EU rules on state subsidies that will phase out support for fossil fuels. Typically, the parliament tends to raise the bar on green action – it last year declared a climate emergency. But MEPs often lose the battle against EU ministers, who usually get the upper hand in EU negotiations. Reading list The European Green Deal, the European commission A trillion reasons to scrutinise the Green Deal Investment Plan, Bruegel How good is the European commission’s Just Transition Fund proposal?, Bruegel Europe’s Green Deal, Jeffrey Sachs, Project Syndicate"
"**Scotland's finance secretary has said the chancellor's plan to freeze some public pay ""absolutely misjudges the value of frontline services"".**
Kate Forbes said she disagreed with the decision, announced by Rishi Sunak during the UK government's Spending Review on Wednesday.
The chancellor said the pay freeze will affect 1.3 million workers.
He said the freeze was part of the ""tough choices"" arising from the Â£280bn cost of the pandemic so far.
The Scottish government will publish details of the public sector pay awards it controls in January.
Ms Forbes stopped short of promising a public sector pay rise but said January's Scottish budget would include ""a recognition of the work that our key workers have done"".
Staff on less than Â£24,000 and some NHS workers will still get a pay rise under the UK government's plans.
Speaking to Good Morning Scotland, Ms Forbes: ""I think the pay freeze absolutely misjudges the value of frontline services, I absolutely disagree with the chancellor's approach to freezing pay of public sector workers.
""Just a few short months ago we were applauding the key workers who were working on the frontline and responding to Covid, and now they are seeing their pay frozen.
""What you can assume is we will build on our approach of the last few years which is to recognise the work of key workers.""
In Scotland, many public sector pay awards are made or negotiated separately from the UK, including local government workers, GPs and teachers.
January's budget comes ahead of the Holyrood election on 6 May.
Mr Sunak has said the economic emergency the UK faces means ""tough choices"" had to be made over which public sector workers would get a pay rise.
Speaking to BBC Breakfast, he said: ""I've had to make some tough choices and what I couldn't do is justify an across-the-board rise in public sector pay.""
Alister Jack, the Scottish Secretary, added that the chancellor's Spending Review was aimed a trying to ""re-inflate the economy by keeping money in it and see tax receipts go up from business activity."""
"**With England's lockdown coming to an end, it's all change.**
A new system of regional tiers will come into force next week. That will be followed by a relaxation of rules at Christmas across the UK which will allow up to three households to meet over the festive period.
But scientists are warning the move risks a third wave of Covid. Is the government making a mistake?
Scientists have been pretty vocal about their concerns. Prof Andrew Hayward, an expert in infectious diseases at University College London and member of the government's Scientific Advisory Group on Emergencies (Sage), believes the relaxation of restrictions at Christmas is tantamount to ""throwing fuel on the Covid fire"".
He warns it is likely to lead to a third wave of infection with ""hospitals being overrun and more unnecessary deaths"".
Edinburgh University global public health chair Prof Devi Sridhar, who advises the Scottish government, agrees. She says she cannot understand the move given that the rollout of vaccines is so close.
""Why risk getting infected and infecting others over the holidays? Delaying by a few months is perfectly rational given solutions within sight in the spring."" She now fears we will ""pay for"" Christmas with lockdowns in the new year.
What is certainly true is that more mixing will lead to more infections. That is a given since the virus thrives on human contact. But there is an argument that what the government is doing will actually help curb infections in both the short and long-term.
Modelling done for the government has suggested that for every day of restrictions being relaxed, five days of tougher ones are needed.
But others advising ministers think this way of looking at things is too one-dimensional. ""The problem with the modellers,"" says a member of SPI-B, the government committee that advises on human behaviour, ""is that they see a nut and reach for the sledgehammer.
""Banning Christmas was never going to work. People were not going to follow the rules. Providing guidance to help them celebrate safely is perhaps a much better way of managing the situation.""
The UK is also not unique in taking this approach. France has announced it will be relaxing the rules at Christmas and other parts of Europe look likely to follow suit in the coming weeks.
Prof Stephen Reicher, an expert in social psychology at the University of St Andrews who also sits on SPI-B, says it is impossible to know to what extent the public would have followed the restrictions at Christmas had they remained in place.
But he says there was certainly a danger that people would have ""asserted their will"", arguing: ""People don't like being lectured to.""
He says that by providing people with the autonomy to make their own decisions, you encourage people to take more responsibility and become actively engaged in working out the best choice to make.
And he thinks the pivot from ""paternalism to partnership"" could actually help build trust in the longer term, which will stand the UK in good stead for the rest of the winter in terms of adherence to restrictions and take-up of the vaccine.
More trust is certainly needed. Polling by YouGov shows public trust in the government has halved since the spring, with just a third of people happy with its handling of the pandemic.
Prof Reicher says what the government has to do now is provide good, clear advice on how to reduce the risks, from ensuring rooms are ventilated to the benefits of isolating before getting together.
But he would also like to see some more practical support. As an example, he says the government could provide ""Covid fuel allowances"" to allow people to leave windows open and the heating on during Christmas.
Another idea, he says, would be to introduce an extra bank holiday at Easter to provide an incentive to delay family get-togethers to a time when those at most risk are likely to have been vaccinated, and the change in the seasons means there is likely to be less virus around.
There are some signs the government is moving in this direction. Ministers have being speaking about the need to use the opportunity to meet up responsibly - with the key message being just because you can, it does not mean you have to.
A crucial consideration will, of course, be assessing who is the most vulnerable in each Christmas bubble.
Age is the overriding factor when it comes to risk from Covid.
But as well as minimising risk, there is also a need to assess the benefits. For some, this could be the last chance they have of a family Christmas.
And, even where that is not the case, a year spent not seeing family and being isolated from people has clearly taken its toll.
Prof Paul Hunter, from the University of East Anglia's school of medicine, says the benefits on people's mental health of being able to meet up with family over this time ""should not be underestimated"".
Indeed, he believes for some it will provide the boost that people need to ""make it through the rest of winter"".
But the other factor that is just as important - and this was a point made earlier this week by England's chief medical officer Prof Chris Whitty - is adherence to the regional tier restrictions in the lead up to Christmas and afterwards.
Doing this, he says, will minimise the risks.
The move into lockdown was widely interpreted as a sign the regional tiers introduced in mid October were not working. But infection rates were actually stabilising by the time lockdown came in as the chart below shows.
And now an analysis by the University of East Anglia has shed more light on how they could be more effective.
It looked at infection rates across 315 local authority areas across England during the period where tiers were used. It found the tier with the least restrictions - tier one - was largely inadequate in that it was unable to control the virus because rates of infection were too high.
Tier two was effective in about half of local authority areas placed in it, while tier three was good enough to drive the R number measuring the rate of infection below one.
One of the key problems, the research said, was the fact that areas were often not moved into a higher tier quickly enough.
The government says it will learn the lessons from that. It has already moved to beef up the tiers - the top two will see tighter restrictions on hospitality in particular.
The hope is that a more intelligent use of the system coupled with the Christmas boost to the public's resolve could suppress virus enough to avoid another lockdown and get us through winter.
_Follow Nick_on Twitter
Read more from Nick"
"**South Yorkshire's mayor has said ""lockdown must not become limbo"" as the county, along with West Yorkshire, was named in the toughest coronavirus tier.**
Both areas will be in tier three after 2 December, meaning households can only meet in public outside spaces like parks, where the rule of six applies.
Mr Jarvis said: ""It is now essential we get a roadmap to get us out of tier three as a matter of urgency.""
Restrictions will be reviewed on 16 December, the government said.
Mr Jarvis said South Yorkshire had been under tighter restrictions since 24 October, and the rules were ""slowly suffocating businesses"" which were being hit again at their busiest time of year.
He added: ""Any restrictions must come hand in hand with a robust package of economic support to protect livelihoods. There must be no gaps in support for people and businesses affected by Covid.""
Meanwhile, Kirklees Council in West Yorkshire said the announcement was ""devastating"" for the area's hospitality sector.
Under the restrictions, pubs and restaurants are only allowed to stay open for takeaway services.
Kirklees Council leader Shabir Pandor said: ""I'm urging government to think more creatively about these restrictions and about how it can support the sector and the supply chain that relies on it so they are not laying more misery on these businesses.""
Non-essential shops and close-contact beauty services like hairdressers will be able to open in all tiers. Guidance said people in all tiers who can work from home should continue to do so.
Around 21 local authority areas in England will be in tier three - the highest level of restrictions - while just three areas will be in the lowest-level of restrictions - tier one.
York and North Yorkshire will face fewer restrictions than other parts of Yorkshire and will be placed into tier two.
Director of public heath at York City Council Sharon Stoltz said she had expected the city to be in the lowest level of restrictions, but instead it will go into the ""high"" alert tier from next Wednesday.
York has the lowest rate of new coronavirus infections in Yorkshire, recording 126.8 new cases per 100,000 people in the seven days to November 22.
For the same period, the England average was 202.4 infections per 100,000 people.
Ms Stoltz said: ""While we were hopeful we would be in the lowest level of restrictions, the restrictions can help us further drive down the virus.""
City of York Council leader Keith Aspden said: ""Although we are disappointed with today's news, we must continue to follow the new national guidance and protect the people and places we love.""
**Analysis**
**James Vincent, Political Editor BBC Yorkshire**
To nick someone else's joke - we've been on the verge of tiers all day.
Now we know.
Well at least we thought we knew until the government's postcode checking website crashed.
Those places in tier three will want information on how they can get out of it - and when.
Remember all the back and forwards we had when places were negotiating with the government on the last set of tiers? That's changed too. Locally, there will be no say on which tier places go into. The government is telling them.
There are tough times ahead for places in tier three. In West Yorkshire, Bradford, Calderdale and Kirklees have had higher measures since the start of August.
They've tightened over time and now, could possibly last until March.
In West Yorkshire, Leeds City Council said it was working to provide support and minimise the impact restrictions would have on residents and businesses.
Leader Judith Blake thanked people for their ""patience, diligence and compassion over what has been an incredibly challenging time for the city"".
She added: ""There is light at the end of the tunnel and if we continue to do all that we can to protect ourselves and each other, we can and will emerge from this crisis together.""
The system will be regularly reviewed and an area's tier level may change before Christmas, said the government.
_Follow BBC Yorkshire on_Facebook _,_Twitter _and_Instagram _. Send your story ideas to_ yorkslincs.news@bbc.co.uk _or_send video here _._"
"Globally, we still catch enough fish to eat – just about. But numbers of fish caught from the sea haven’t kept up with human population growth and unsustainable fish farms have filled the gap. So why are we still being encouraged to eat more fish? The health benefits are clear: fish protein is typically low in saturated fats and high in nutrients and essential fatty acids. UK and US food standards agencies recommend eating two portions of fish per week, while Australia, New Zealand and Estonia advocate two or three servings per week and Greece five or six. Yet as our recent research has shown these health recommendations must be set against a backdrop of declining global fish stocks and food security concerns. While in the UK fish constitutes just one choice of animal protein among many, one billion people throughout the world rely upon it as their primary source of animal protein and our global fisheries are in crisis.  Some fisheries do exist that successfully balance production and sustainability, but many more are under increasing pressure from over-exploitation, destructive fishing practises like trawling and dredging, pollution or other factors. As the world’s population continues to expand these pressures are likely to intensify, not decrease. Over the past 50 years fisheries have rapidly expanded and today fish is one of the world’s most globalised commodities. The UK is typical: the fish you buy in supermarkets comes from all over the world. Cod and haddock are sourced from Iceland and Norway, while much of our tuna comes from the Indian Ocean, South-East Asia and West Africa. Shrimp and prawns are sourced from Asia, Iceland and Canada. The UK also exports fish – mainly mackerel, herring and farmed salmon – to the EU, the US and Russia, although far less than it imports. For a nation surrounded by the sea, the British have never been especially ardent lovers of fish. Before the advent of freezers and swift transport networks you could understand why; fish spoils rapidly unless salted or smoked. However, railways built in the mid-19th century provided reliable transport to inland markets for the first time and helped drive the expansion of industrial fisheries around the UK. Subsequently, the British developed a taste for fish, although mainly when covered in batter and deep-fried.  National recording of landings and fishing effort began in the 1880s and help us chart the development of the UK’s fisheries. Fuelled by steam power and ice, accessible fishing grounds expanded to the Arctic, North America and Africa during the early 20th century and the total catch grew rapidly. However the formation of exclusive economic zones in the late 1970s forced a return to home grounds and it became ever more apparent that fish had been over exploited and stocks were seriously depleted. Government records show that landings of fish by UK vessels peaked in 1913 at 1.27m tonnes and declined throughout the remainder of the 20th century. Today, a significant proportion of UK vessels land their fish abroad, but even accounting for these ships domestic production is still half what it was a century ago. This can be partly attributed to a loss of European markets during and after the war, and restriction of traditional fishing grounds from the 1970s, but many fish stocks are also at historically low levels. During this period, the UK population has also increased and to keep up with demand as well as diversify our fish supply, greater and greater quantities of fish are sourced from other nations’ waters. Clearly, fish supply is not merely a domestic issue and policies that support increased consumption at the national level must also strive to adopt a more global outlook. For example, the quantity of domestic fish available (through landings and aquaculture) per person in the UK plummeted throughout the 20th century, with overall supplies only kept stable by imports. But even despite this declining supply UK consumers still eat less fish than the recommended two portions (280 g) per week, which is fortunate really, since only twice in the past 120 years have supplies been sufficient to meet this aspiration. If demand should rise further, either through population growth or changes in consumer preference, it is likely that even more extra fish will have to be sourced from other nations.  Increased imports are not necessarily an indication of unsustainability, but they do demonstrate the potential for developed nations to mask domestic shortfalls in wild fish. This experience is not just restricted to the UK: Europe imports around 55% of the fish it consumes; last year the US imported 91% of its fish. While developed countries are able to mask domestic declines, this is not the case in societies that rely upon fish as their major source of protein. Global wild fish landings plateaued at 85-95m tonnes during the 1990s. However, when human population growth is taken into account, wild fish availability per person has been in decline since 1970.  Global fish supplies have only been stabilised by increasing aquaculture production, which is currently exceeding the pace of human population growth. Yet fish farms come with associated environmental costs of habitat loss, pollution, introduced species, pests and diseases, which will need to be addressed if aquaculture production is to keep up with future population growth. Though aquaculture has so far prevented a downturn in global fish supplies, many developed nations continue to aspire to consume more fish than they produce. Until demand is balanced with sustainable methods of production governments should consider carefully the global social and environmental implications of national policies that promote greater fish consumption."
"Shared knowledge is an important currency for humans. It shapes everything from what we eat and how we dress, to how we raise our children. Some things we learn individually, some things we learn socially – from our parents, peers, teachers and the media. But how is shared information important for other species?  Mendel’s pea breeding experiments and the discovery of DNA were huge steps in the revelation that there are physical “packets of information”, in the form of genes, passing between generations. This has been instrumental in our understanding of the evolution of biodiversity, and how organisms are shaped by their environment.  However, in addition to this physical transmission through DNA, there are other sources of information available in the natural world. Social information can operate both within and between different generations, and is vital in shaping how animals response to their ever changing world.  I have previously argued  that social knowledge is important for whales and dolphins. Research also shows that social learning is widespread across a wide variety of wildlife, from birds to elephants, from fish to meerkats.   Birds can learn foraging techniques from each other (such as opening the foil caps of milk bottles to extract the cream). Bottlenose dolphins have been observed learning from their mothers how to use sponges to help protect their jaws while foraging on the sea bed for fish. Southern right whales share migration routes between critical feeding and breeding habitats. African elephants learn from older matriarchs the location of watering holes, and how safe it is to interact with different social groups. Evidence for social learning can be seen in the depths of the oceans, in deserts and on mountain tops. It is an important mechanism across the natural world, helping organisms adapt to changes in their environment. These adaptations often occur much more swiftly than in the slower process of natural selection, which brings about incremental change between generations. Social learning is a rich seam of exploration for behavioural ecologists and conservation biologists. And because it can result in discrete units within a population which use that knowledge, it can help to inform us about focusing conservation efforts.  For example, understanding more about the mechanisms of social learning may be invaluable for the reintroduction of some captive-bred migratory bird species. It could help negotiate solutions in areas of human-wildlife conflict, such as when elephants or apes help themselves to human crops. One of the results of social learning – not itself an endpoint, but an ongoing process – is animal culture. But what is animal culture? With our own inherited cultural perspective, it is understandable that animal culture is sometimes a challenging concept for us to grasp.  It is not the many and different ways in which other species are integrated into human culture (although that is interesting in itself). Animal culture can be defined as “information or behaviour, shared within a community, which is acquired from members of the same species through some form of social learning”.  The idea that other species have rich social lives, which includes some socially learned, collective ways of behaving that differentiate social groups, seems like a significant philosophical leap. But the evidence is now unequivocal that humans are not alone in having distinct cultures. The revelation of animal cultures raises a number of both ethical and scientific questions. But from a practical perspective, what does the existence of animal culture mean for our efforts to conserve the natural world?  To better understand the relationship between animal sociality and conservation, the Convention on the Conservation of Migratory Species of Wild Animals, a treaty under the aegis of the United Nations Environment Programme, has been spearheading work to explore how best to use the emerging science in this field to optimise conservation efforts. Its efforts so far are described in a recent article in Science. Beginning a serious dialogue on animal culture represents a paradigm shift in our understanding of what exactly biodiversity is. In addition to genes, specific kinds of behaviour are also an important aspect of the rich diversity of our planet. In order to work towards conserving genetic diversity, we must now also work towards maintaining animal cultural diversity across different ecosystems. This is the challenge that lies ahead for global environmental agreements – a culture of conservation that respects the cultures of the natural world."
"
Share this...FacebookTwitterOne of the IPCC’s most dubious achievements is ignoring so many papers showing that the sun plays a huge role in our climate. The sun play a role? Yeah, right!
A reader brings our attention to some recent papers showing that the sun plays a major role on climate, not that the IPCC will be the least bit interested. Here are a few in case you may have missed any.
1. Variations in tree ring stable isotope records from northern Finland and their possible connection to solar activity; Ogurtsov et al, 2010, see abstract here.
Statistical analysis of the carbon and oxygen stable isotope recordsr eveals variations in the periods around 100, 11 and 3 years.A century scale connection between the 13C/12C record and solar activity is most evident.”
2. A possible solar pacemaker for Holocene fluctuations of a salt-marsh in southern Italy; Di Rita, 2011 abstract here.
The chronological correspondence between the ages of saltmarsh vegetation reductions and the minimum concentration values of 10Be in the GISP2 ice core supports the hypothesis that important fluctuations in the extent of the salt-marsh in the coastal Tavoliere plain are related to variations of solar activity.”
3. Solar and volcanic fingerprints in tree-ring chronologies over the past 2000 years; Breitenmoser et al, 2012
Results from wavelet analysis and SEA reveal significant periodicities near the solar DeVries frequency in the volcanic and residual ‘volcano free’ contributions during the LIA, making a clear separation of the solar and volcanic forcing signals difficult. Nevertheless, the ‘volcano free’ temperatures show significant periodicities near the DeVries frequency during the entire past 1500 years, pointing to a solar imprint on global climate.
4. Holocene hydrological changes in south-western Mediterranean as recorded by lake-level fluctuations at Lago Preola, a coastal lake in southern Sicily, Italy; Magny et al, 2011, see abstract here.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This major oscillation may be related to a non-linear response of the climatic system to the gradual decrease in insolation, in addition to seasonal and inter-hemispherical changes in insolation. Another major climate oscillation around 7500 – 7000 cal BP may have resulted from combined effects of a strong rate of change in insolation and of variations in solar activity.”
5. Variations in climate parameters at time intervals from hundreds to tens of millions of years in the past and its relation to solar activity; Raspopov et al, 2010, see abstract here.
Our analysis of 200-year climatic oscillations in modern times and also data of other researchers referred to above suggest that these climatic oscillations can be attributed to solar forcing. The results obtained in our study for climatic variations millions of years ago indicate, in our opinion, that the 200- year solar cycle exerted a strong influence on climate parameters at those time intervals as well.”
6. Climate patterns in north central China during the last 1800 yr and their possible driving force; Tan et al, 2011, see abstract here.
Solar activity may be the dominant force that drove the same-phase variations of the temperature and precipitation in north central China.
7. Multifractal Detrended Cross-Correlation Analysis of sunspot numbers and river flow fluctuations; Hajian, 2010, see abstract here.
Our results show that there exists a long-range cross-correlation between the sunspot numbers and the underlying streamflow records.”
Doesn’t Hajian work for the Iranian gas and oil industry?
 
Share this...FacebookTwitter "
"
Forecasting The NSIDC News
By Steven Goddard and Anthony Watts
Barring an about face by nature or adjustments, it appears that for the first time since 2001, Arctic Sea ice will hit the “normal” line as defined by the National Snow and Ice Data Center (NSIDC) for this time of year.
NSIDC puts out an article about once a month called the Sea Ice News.  It generally highlights any bad news they can find about the disappearance of Arctic ice.  Last month’s news led with this sentence.
In February, Arctic sea ice extent continued to track below the average, and near the levels observed for February 2007.
But March brought good news for the Polar Bears, and bad news for the Catlin Expedition and any others looking for bad news.  Instead of ice extent declining through March like it usually does, it continued to increase through the month and is now at the high (so far) for the year.
If it keeps this trend unabated, in a day or two it will likely cross the “normal” line.

Source: NSIDC North Series

The Danish Meteorological Institute shows Arctic ice extent at the highest level in their six year record.

Source: DMI Ice Extent
The Norwegians (NORSEX) show Arctic ice area above the 30 year mean.

Source: NORSEX Ice Area
And the NORSEX Ice Extent is not far behind, within 1 standard deviation, and similar to NSIDC’s presentation. Note that is hit normal last year, but later.

Source: NORSEX Ice Extent
And JAXA, using the more advanced AMSR-E sensor platform on the AQUA satellite, shows a similar uptick now intersecting the 2003 data line.

Source: IARC-JAXA
WUWT asked NSIDC scientist Dr. Walt Meir about this event to which he responded via email:
It’s a good question about the last time we’ve been above average. It was May 2001. April-May is the  period when you’re starting to get into the peak of the melt season for the  regions outside of the Arctic Ocean (Bering Sea, Hudson Bay) and the extent  tends to have lower  variability compared to other parts of the year as that  thinner ice  tends to go about the same time of year due to the solar  heating. Even  last year, we came fairly close to the average in early  May.
He also mused about a cause:
Basically, it is due primarily to a lot more ice in the Bering Sea, as is evident in the images. The Bering ice is controlled largely by local winds, temperatures are not as important (though of course it still need to be at or at least near freezing to have ice an area for any length of time). We’ve seen a lot of northerly winds this winter in the Bering, particularly the last couple of weeks.
As we’ve been saying on WUWT for quite some time, wind seems to be a more powerful factor in recent sea ice declines than temperature. Recent studies agree.
See: Winds  are Dominant Cause of Greenland  and West Antarctic Ice Sheet Losses and also NASA  Sees Arctic Ocean Circulation Do an About-Face
You can  watch wind patterns in this time lapse animation, note how the ice has been pushed by winds and flowing down the east coast of Greenland:
Animation of Arctic sea-ice being pushed by wind patterns - CLICK IMAGE TO VIEW ANIMATION- Above image is not part of original story, but included to demonstrate the issue. Note that the animation is large, about 7 MB and may take awhile to load on your computer. It is worth the wait Source: National Snow and Ice Data Center

Dr. Meier also wrote:
This has very little implication for what will happen this summer, or  for the long-term trends, since the Bering Sea ice is thin and will melt completely well before the peak summer season.
There’s certainly no reason to disagree with the idea that much of the Bering Sea ice will melt this summer, it happens every year and has for millenia. But with a strong negative Arctic Oscillation this year, and a change in the wind, it is yet to be determined if Arctic Sea ice minimum for 2010 is anomalously low, and/or delayed from the usual time.
In 2009, WUWT noted it on September 15th: Arctic sea ice melt appears to have turned the  corner for 2009
Dr. Mark Serreze of NSIDC offered some hopeful commentary in a press release back on October 6th 2009, but still  pushes that “ice free summer” meme:
“It’s nice to see a little recovery over the past couple of  years, but  there’s no reason to think that we’re headed back to conditions seen in  the 1970s,” said NSIDC Director Mark Serreze, also a professor in  CU-Boulder’s geography department. “We still expect to see ice-free  summers sometime in the next few decades.”
Remember this 2007 prediction from The Naval Postgraduate School?
http://news.bbc.co.uk/2/hi/7139797.stm
==============================


Arctic summers ice-free ‘by 2013’






By Jonathan Amos
Science reporter, BBC News, San  Francisco












Arctic summer melting in 2007 set new records

More details




Scientists in the US have presented one of the most dramatic forecasts yet  for the disappearance of Arctic sea ice.
Their latest modelling studies indicate northern polar waters could be  ice-free in summers within just 5-6 years.
Professor Wieslaw Maslowski told an American Geophysical Union meeting that  previous projections had underestimated the processes now driving ice loss.
Summer melting this year reduced the ice cover to 4.13 million sq km, the  smallest ever extent in modern times.
Remarkably, this stunning low point was not even incorporated into the model  runs of Professor Maslowski and his team, which used data sets from 1979 to 2004  to constrain their future projections.






 In the end, it will just melt away quite suddenly 


Professor Peter Wadhams





“Our  projection of 2013 for the removal of ice in summer is not accounting for the  last two minima, in 2005 and 2007,” the researcher from the Naval Postgraduate  School, Monterey, California, explained to the BBC.”So given that fact, you can argue that may be our projection of 2013 is  already too conservative.”


========================================
Joe Romm wrote up a clever piece last year on this subject:
Exclusive: New NSIDC director Serreze explains the “death spiral” of Arctic ice, brushes off the “breathtaking ignorance” of blogs like WattsUpWithThat
June 5, 2009
I interviewed by email Dr. Mark Serreze, recently named director of The National Snow and Ice Data Center.  Partly I wanted him to explain his “death spiral” metaphor for Arctic ice
So now that Arctic ice has returned to normal extent and area, we eagerly await the explanation from the experts about how that fits into the “death spiral” theory.  Richard Feynman famously said “Science is the belief in the ignorance of the experts.”
Time will tell. 2010 is looking promising for sea ice recovery again. After all, who wouldn’t want the Arctic Sea ice to recover? WUWT is predicting a recovery again this year, which we started mentioning as a prediction last fall.
So given what we know today, what will NSIDC highlight in their April Sea Ice News?
Take Our Poll
And even more importantly, will the MSM cover it like they do the ‘terrible’ minimums?
NOTE: The poll code got messed up, duplicating an entry, press REFRESH if you see a double entry. -A



Forecasting The NSIDC News
 NSIDC puts out an article about once a month called the Sea Ice News.  It generally highlights any bad news they can find about the disappearance of Arctic ice.  Last month’s news led with this sentence.
In February, Arctic sea ice extent continued to track below the average, and near the levels observed for February 2007.
But March brought good news for the Polar Bears, and bad news for the Catlin Expedition and any others looking for bad news.  Instead of ice extent declining through March like it usually does, it continued to increase through the month and is now at the high (so far) for the year.
 
http://nsidc.org/data/seaice_index/images/daily_images/N_stddev_timeseries.png
The Danish Meteorological Institute shows Arctic ice extent at the highest level in their six year record.


DMI Ice Extent
The Norwegians (NORSEX) show Arctic ice area above the 30 year mean.
 
NORSEX Ice Area
Joe Romm wrote up a clever piece last year on this subject:
Exclusive: New NSIDC director Serreze explains the “death spiral” of Arctic ice, brushes off the “breathtaking ignorance” of blogs like WattsUpWithThat
June 5, 2009
I interviewed by email Dr. Mark Serreze, recently named director of The National Snow and Ice Data Center.  Partly I wanted him to explain his “death spiral” metaphor for Arctic ice
So now that Arctic ice has returned to normal extent and area, I eagerly await the explanation from the experts about how that fits into the “death spiral” theory.  Richard Feynman famously said “Science is the belief in the ignorance of the experts.”
So what will NSIDC highlight in their April Sea Ice News?


The 	increase in both ice extent and quantity of multi-year ice


The 	long-term downwards linear trend line


The 	lack of 4+ year old ice





Sponsored IT training links:
Get free resources including 642-972 tutorial and 1z0-048 dumps questions for guaranteed success in JN0-532 exam.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8cb7c1de',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

The Nordic countries are widely regarded as world leaders in gender equality. In the Global Gender Gap Index, the Nordic nations are top performers. Iceland leads the list, followed by Norway, Finland, and Sweden in second, third, and fifth places, respectively. Denmark ranks lowest in 14th place, but still considerably higher than the United States, which is in 49th place.



A common view is that Nordic gender equality reflects the social welfare policies of these nations. Indeed, Nordic governments advertise their welfare systems as a recipe for gender equality and even promote these policies in the United States for that reason. Several other European countries have followed in Norway’s tracks by legislating gender quotas for board of director positions in publicly traded firms. Although the political climate in the United States is not ripe for quotas, that policy does lie on the horizon.



This analysis argues that gender quotas have been ineffective and that several aspects of Nordic social policies have negatively affected women’s career progress and even contributed to a glass ceiling. The glass ceiling is a metaphor for the barriers women face in reaching leadership positions.



While Nordic societies are indeed role models when it comes to gender equality, this equality stretches back centuries before the modern welfare state and reflects traditional Nordic culture.



The rise of the Nordic welfare state has been a double-edged sword: creating some benefits for women’s careers, but also creating barriers to women’s professional progress. For example, benefits include various public systems that encourage a combination of family and work, such as public daycare and parental leave benefits.



But barriers abound. Public monopolies in health care, child care, and elderly care reduce development of these women-intensive parts of the labor market. High taxes and welfare policies encourage women to work fewer hours, and generous parental leave systems influence women to stay home, all of which reduce their ability to climb the career ladder.



I begin my paper by outlining significant cultural and historical elements that underpin equality in the region. These historical features fall outside of touted modern social democratic policies. Next, I describe how Nordic public-sector monopolies, tax policy, and welfare policies have affected women’s careers. Finally, I compare women’s professional outcomes in the Nordic countries and find them lacking. Nordic countries seemingly have the best possibilities for women to reach the top, but Nordic women are not world leaders when it comes to the rate of women advancing to top positions in the private sector. In spite of their intentions, gender quotas are unable to meaningfully improve Nordic women’s professional outcomes in terms of leadership, pay, or career goals. And although Norwegian gender quotas are inspiring similar policies throughout the world, few admirers seem aware of the Norwegian research literature that shows they have had little or no positive meaningful effect on women’s careers.



In an age of women’s progress, the Nordic societies are worth admiring for a culture that supports gender equality. But when it comes to supporting women’s professional development, the Nordic model has disadvantages.



A common assumption is that Nordic gender equality is a product of prevalent welfare-state policies.1 But a broader perspective shows egalitarian gender values predate modern welfare states by centuries in Sweden and other Nordic countries. The Viking ancestors of today’s Nordic societies had a culture that emphasized women’s rights.



Norse societies are often portrayed in books and media as having a relatively even distribution of power between the sexes. Although these cultures were patriarchal, women had considerably more influence in Norse societies than women in other contemporary cultures. For example, Scandinavian folklore includes _shieldmaidens_ , women who fought as warriors. Byzantine historian John Skylitzes records that women were participating in Nordic armies during the 10th century.2 This suggests that gender segmentation in early Norse societies was considerably more flexible than in other parts of contemporary Europe.



There is also evidence that women in early Nordic societies could inherit land and property, control their dowry, and own a third of the property they shared with their spouses. They could sometimes participate in the public sphere with men. Additionally, women could opt for divorce.3 Medieval laws show that Nordic women had greater rights than women in other parts of the contemporary world: inheritance laws in Norway followed family relations through female lines as well as male lines.



These rights might not seem impressive today, but they were historically unusual. In many contemporary European and Asian societies, the legal system was based on women belonging to their fathers or husbands and the women held minimal property, contractual, and public participation rights.



Nordic gender egalitarianism continued following the Viking age. In much of the world, women were excluded from participating in the rise of capitalism during the 18th and 19th centuries; free markets and property rights were treated as institutions for men. Although Nordic countries were far from perfectly egalitarian, they challenged contemporary gender norms by inviting female participation in early capitalism.4



For example, Swedish women began managing businesses during the second half of the 18th century. In 1798 a reform was passed that stipulated that married women had legal majority and juridical responsibility within the affairs of their businesses, and in 1864 Swedish business freedom was granted to virtually all unmarried adult women and all adult men.5



Although married women were initially excluded, it is noteworthy that business freedom was granted to both sexes at the same time. Swedish women were given the right to stipulate in premarital contracts that their husbands could not impose on the business 10 years later.6



Alongside American states, the Nordic nations were pushing for women’s economic rights. Married women in Maine gained the right to a separate economy in 1844, and four years later the Married Woman’s Property Act was passed in New York, allowing women to enter contracts on their own.7 In other regards, the Nordic countries were ahead of the American states. For example, in 1850 Iceland became the first country to institute unconditional equal inheritance rights.8 Nordic and American advances in women’s economic rights were, at their time, groundbreaking, and inspired similar reforms in other parts of the world.



Nordic policies continued developing during the beginning of the 20th century. The question of labor legislation to “protect” women from factory work was suggested in the beginning of the century, inspired by international developments. These proposals caused heated debate. Sweden did introduce a night-work prohibition in 1909, after considerable criticism from the women’s movement. Unlike other European countries, Australia, and the United States, a prohibition on women’s night work was never included in Danish and Norwegian factory laws. Women were allowed to participate in the industrial development of these two countries.9



Nordic countries recognized married women as individuals in their own right in the early 20th century, before the rise of the modern welfare state.10 Nordic tax law and marriage law provide an example of this treatment. They are based on a dual-breadwinner model, so men and women are taxed independently. In societies where spouses are taxed jointly, both spouses will face high marginal tax rates if one has a high income. In Nordic tax systems, the spouse with a lower income (often the wife) will not experience a higher marginal tax rate if the other spouse has a higher income. This model encourages both spouses to invest in their careers.



In addition, marriage legislation in the Nordic countries has been built around the idea that men and women are jointly responsible for family provision. In the rest of Europe, marriage legislation has traditionally given the husband the responsibility to provide for his family, declaring the husband’s guardianship over his wife and children.



The Nordic tradition of gender equality is evident today in the values of these societies. The World Values Survey shows that Sweden has the smallest proportion of respondents who believe men should have more of a right to a job than women if jobs are scarce. As shown in Figure 1, Sweden stands out as unusually gender egalitarian in this regard. While similar attitudes can be found in other modern societies such as the United States and Australia, the Nordic countries stand out as having the most gender-equal values. Previous surveys that included other Nordic countries show egalitarian gender beliefs are held throughout the region.11





Similarly, a 2015 YouGov survey found that a minority of Nordic respondents agree with the statement “It is likely to cause problems if a woman earns more money than her husband.” Just 26 percent in Finland, 20 percent in Sweden, and 18 percent in Norway and Denmark rated this statement as true, contrasted with 32 percent of Americans.12



The long tradition of gender-equal laws and values should theoretically create optimal conditions for Nordic women to reach the top of the career ladder. But Nordic countries are not world leaders in the share of women who climb to the top. The modern welfare state seems to create a glass ceiling.



It has long been evident that Nordic countries have a lower representation of women in business than many modern economies. A Eurostat study from 1995 found that only 6 percent of top earners in Sweden were women, considerably lower than France’s 15 percent.13 A study from the University of California–Los Angeles (UCLA) concluded that merely 11 percent of managers and professionals in Sweden were women, lower than in other developed economies.14



As early as 1998 the International Labor Office published a report that noted an unusually gender-segregated labor market in Scandinavian countries, with many women working in the public rather than the private sector.15



Economists Magnus Henrekson and Mikael Stenkula note in an academic literature review that women are underrepresented in executive positions in Sweden—behind the United States, United Kingdom, West Germany, and France. They conclude that “broad-based welfare-state policies impede women’s representation in elite competitive positions.”16



A key explanation lies in the expansion of the welfare state into the service sector. The Nordic countries adopted large welfare sectors that expanded into education, health, and elderly care.17 In Sweden and other Nordic countries, female-dominated sectors such as health care and education are almost entirely financed by the public sector. The Nordic Innovation Centre notes that the high percentage of women working in public monopolies explains some of the difference in entrepreneurship rates between genders.18



The emergence of a large public sector has been both positive and negative for women. It played an important historical role in women’s entry into the labor market because many women entered through the expanding public sector. Public-sector services also facilitated the combination of work and the fulfilment of family responsibilities. The expansion of the public sector partly explains why Nordic nations reached a high employment rate among women earlier than other Western countries and stayed that way. The provision of public daycare was particularly important in this regard.



But labor-force participation is only one measure of female professional success. Another measure is female business ownership. Anita Lignell Du Rietz studied women’s business ownership in Sweden and found that many businesses, including taverns, tailor shops, breweries, and stores were run by women entrepreneurs during the 19th century. Over time, women dominated businesses such as schools and pharmacies.



However, government monopolies crowded out private enterprise as the Swedish welfare state grew during the 20th century. Meanwhile, male-dominated sectors, including manufacturing, mining, and forestry, remained under private control. The transition toward welfare-state monopolies meant that women’s business ownership suffered.19



Government monopolies have combined with a strong influence of union wage-setting to undermine incentives for work: wages in the female-dominated public sectors in Nordic countries are flat, and rise based on seniority rather than achievement. Although there are public-sector managerial positions, the opportunities for individualized careers and business ownership are comparatively limited.



Recent labor liberalizations highlight the effects of government monopolies. Since the early 1990s, Swedish public monopolies have gradually opened up to private enterprise. New systems have been created in which tax-funded welfare services such as education, elderly care, and health care are partially provided by the public sector and partially through private for-profit businesses. These systems are mainly based on vouchers, but also on public procurements.



The Swedish Agency for Economic and Regional Growth noted that market reforms have gradually opened up the public sector for private businesses, paving the way for more women business owners.20 In their paper, researchers Elisabeth Sundin and Malin Tillmar suggest that restructuring the public sector reduced business ownership obstacles for women.21



The benefits of industry privatization are not limited to female business ownership. For example, the Confederation of Swedish Enterprise found that privatization drove wages up 5 percentage points compared with similar employees whose workplaces remained public.22 Individuals whose workplaces were privatized also benefited from a stronger foothold in the labor market and reduced risk of employment.23



A survey of international literature supports the theory that wages rise following privatizations, partially because of productivity gains.24 Lars Calmfors, one of Sweden’s leading economists, and Katarina Richardson, an expert on women’s career opportunities, argue that wage decentralization in the public sector led to equality gains because of individualized, higher wages for women. They conclude this is a more efficient method of reducing the gender pay gap than legislation.25



It is likely unintentional that public-sector monopolies limit women’s career opportunities, but the effect remains. Although some steps toward privatization and competition have been taken in Nordic countries, public-sector monopolies still reduce economic opportunities for women.



High tax rates are another obstacle for Nordic women’s professional advancement because women are more responsive to taxes than men. Women take more responsibility for housework and childcare, on average. When high taxes reduce incentives for paid work by reducing take-home pay, women’s “opportunity cost” is higher because they would otherwise use the time on other productive domestic activities. Women are inclined to reduce their paid work and spend more time on unpaid work as taxes increase.



Alexander Gelber and Joshua Mitchell conducted a detailed analysis of time usage for single men and women in the United States between 1975 and 2004. The authors look at how tax changes have affected the decision to spend time on housework. They find that for single women, when income taxes are reduced, productive domestic activities decline substantially as women presumably increase their paid work. Expenditure on goods and services that can substitute for housework increases with greater labor-market incentives. However, for single men the authors find limited change in response to tax policy.26 Single men continue to invest time in the labor market when taxes are high, while single women shift to household work. Single women increase their participation in the labor market and purchase goods and services such as housecleaning and prepared dinners that substitute for household work when taxes are low.



A number of studies have shown the ability to purchase services that alleviate household work is crucial for women’s career prospects.27 Henrekson and Stenkula find that the development of substitutable services is especially important for producing female executives.28 Rachel Ngai and Barbara Petrongolo find that increasing substitutable services raises women’s wages and market hours. In their abstract they write: “The rise of services, driven by structural transformation and marketization of home production, raises women’s relative wages and market hours. Quantitatively, the model accounts for an important share of the observed trends in women’s hours and relative wages.”29



Although Nordic countries have high female employment rates, many women are part-time workers and part-time housewives. This is partly because high taxes reduce incentives to work and purchase “substitutable services.” For example, highly skilled individuals such as professors often paint their own houses during the summer holidays. But a professor who sets aside an hour a day to paint her or his own house could spend the same time teaching a class. Teaching provides greater economic value because the professor is specialized in the task. It is therefore economically rational to spend the time teaching and pay for a professional painter, but high taxes change this decision.30 So Nordic professors and other workers are more inclined than their lower-taxed American counterparts to devote unpaid time to domestic work rather than work longer hours in their paid work.



High taxes significantly affect women’s careers by reducing their ability to purchase service substitutes for household work. Instead, husbands trade services with wives. Husbands spend time at work, while their wives spend time on domestic activities. High-earning women’s opportunities are limited because of gender roles and the fact that husbands are, on average, somewhat older than their wives and have higher wages.



 _The Economist_ suggests Nordic career women “find it harder to afford domestic help than their American equivalents” because public welfare services are paid for by high taxes. When time-sensitive domestic work can’t be outsourced, women do it.31 Even in the lesser-taxed United States, the combined tax effect significantly reduces incentives for individuals to buy substitutable services (Table 1).





Provision of public services encourages women to work, but high taxes discourage them from working more. International evidence supports this theory. Evridiki Tsounta concludes that women’s work was stimulated in Canada through policies that have created greater access to childcare and lower tax wedges for secondary earners.32 Michelle Rendell finds evidence that high taxes are associated with smaller service sectors and reduced female labor-force participation.33



Governments in Sweden, Finland, and Denmark realize high taxes create problems and have introduced tax deductions for personal services to counteract the problems. In 2012, 150 female executives advised the Swedish government to expand tax deductions related to the purchase of personal services and increase opportunities for flexible working time.34 These reforms have helped to improve women’s business ownership and have made it easier to combine careers with family responsibilities.



But although tax deductions for personal services have made it easier to buy some services, these targeted deductions are limited in size. Thus, high taxes still reduce the incentive for market work compared with untaxed housework, and this affects women’s professional progress.



Nordic welfare institutions influence work incentives for women in a number of ways. The Nordic welfare system has been designed to encourage parents to engage in market work while benefiting from various forms of public funding.35 But research suggests that national paid and unpaid leave policies, work entitlements, and other family benefits encourage women to work part-time rather than full-time. This hinders their ability to develop top careers.36



The European Commission’s research suggests that part-time work often accompanies public parental benefits in Sweden.37 Eva Meyersson Milgrom and Trond Petersen similarly conclude in a study that the glass ceiling “appears to be more severe in the Scandinavian countries with their generous family policies, than in the U.K., U.S., and other comparable countries.” Childcare and maternity leave policies make reducing work hours attractive, but can later disqualify women for top jobs. As a result, the policies “may not overcome the effects of domestic division of labor (and indeed may possibly exacerbate them).”38



Publicly funded programs, including childcare and parental-leave payments, reward families where both parents work at least part-time. The outcome is often that the wife works some hours, but too few to realize her marketplace potential. Her spouse often commits fully to his career. _The Economist_ , citing Danish researcher Nina Smith, suggests generous Nordic social policies are backfiring for this very reason.39



The generous family policies also affect women who decide not to take lengthy leave(s). Nordic employers have minimal or no input in this negotiation. In fact, it might be seen as discrimination if an employer asks during a job interview whether a potential employee is planning to have children in the near future. Consequently, employers may assume it is risky to hire a women of child-bearing age to a key position if the position is difficult to find a substitute for.



In some cases, parental leaves are not a major concern for employers, at least when employees are easily substitutable. But for smaller firms and vvkey roles, lengthy parental leaves ignore employers’ needs. For example, imagine a small or medium firm recruiting a person to be in charge of sales. The firm depends on the competence of this person in day-to-day operations. In practice, it may not be easy to find a substitute for this position if the employee takes leave. If a young woman applies for the job, she might be discriminated against on the grounds that she is likely to take long parental leave. This affects young women who are not planning to do so because the employer doesn’t know in advance who will or won’t take leave. If parental leave were based on agreements made between employers and employees, this would happen less often.



The parental leave system particularly  
affects those in managerial or expert positions. An employee who is easily replaced on short notice will not be affected as strongly as someone in a specialized position. It is no coincidence that women who have successful careers tend to either take short parental leaves or time their childbearing to minimize career disruption.



Because welfare programs hinder women’s professional trajectories and women take greater responsibility for family caretaking on average, Nordic countries (similar to other nations) have looked for policies that would resolve this problem.



For centuries, women in Nordic societies have progressed without relying on state-  
mandated policies. It was a break with tradition when Norway passed a gender-quota law at the end of 2003, requiring 40 percent of board members of public companies to be women.



The law became mandatory at the beginning of 2006, and the letter of the law was followed in Norway’s law-abiding society. Most companies used affirmative action to change the gender composition of their boards. Some chose another difficult but legal strategy: around 100 of approximately 500 companies targeted by the legislation changed their corporate ownership structure to free them from the legislation.40



It is telling that so many firms invested time and energy to circumvent the legislation. Once firms were forced to follow the law, another challenge became apparent: a shortage of experienced individuals to fill the positions. New female directors were eight years younger than their existing male counterparts on average, which suggests they also had less professional experience.41



The literature on corporate governance suggests that board diversity is positively related to firm performance. The explanation given is that more diversity can increase the talent pool, and diversity of origin can sometimes be linked to diversity in knowledge. Kenneth Ahern and Amy Dittmar examined the Norwegian evidence by looking at firm stock prices and Tobin’s Q, a measure of the market value of firms.42 They find that firm value fell by more than 12 percent with every 10 percent increase of female board members. The gender quota led to less experienced board members, greater company leverage, higher company acquisition rates, and declining operating performance.



Before the quotas were introduced in Norway, the rise of women among board members was achieved without declines in experience.43 Ahern and Dittmar note that once board-member characteristics—such as age and CEO experience—are accounted for, the proportion of female board members is no longer significantly related to firm market value. This suggests that it was the change in board member experience and not the gender of board members that reduced firm performance.44



Additional studies have shown that firm performance improves as gender equality grows. For example, Nina Smith, Valdemar Smith, and Mette Verner study 2,500 Danish firms from 1993 to 2001. The authors find that having a greater proportion of women in top management roles is associated with improved firm performance, even when controlling for firm characteristics.45 This effect is not because individuals are better or worse at their jobs because of their gender. Instead, some of the women who reach the top among the studied companies are particularly good at their jobs. The paper concludes that the effect of women in top management roles is related to women’s individual qualifications.46 When firm performance suffers as a result of gender quotas, gender quotas give diversity a bad name.



In spite of this, gender quotas have gained considerable international attention, and politicians around the world are pointing to the quotas as a success story.47 The rationale is that quotas were intended to increase the proportion of women on corporate boards, and have achieved that goal. But this criterion has limited usefulness.



A more holistic view suggests gender quotas have had negative effects and didn’t accomplish their goal. The purpose of quotas was to catalyze a wider change in society. Legislators hoped to break the glass ceiling so women would generally gain a professional boost. Instead, the benefit is confined to a few individuals who already had top careers. Cathrine Seierstad and Tore Opsahl write that the law has had the effect of creating “a small elite of women directors who rank among the top on a number of proxies of influence.”48 In a more recent paper, Marianne Bertrand and coauthors find that the policy has had no trickle-down effect to the broader group of female employees, no obvious effect on highly qualified women who were not appointed to boards, no significant effect on the gender pay gap, and no impact on women’s career plans.49



Norwegian researchers Sigtona Halrynjo, Mari Teigen, and Marjan Nadim analyze how women’s careers were affected by the quotas and note they had no apparent effect on the gender division of managers.50 Kjersti Misje Østbakken, Harald Dale-Olsen, and Pål Schøne investigate whether quotas have led to higher earnings for women, in accordance with the theory that quotas would break patriarchal wage-setting. The researchers do not find a visible effect.51 In mid-2015 the _Nordic Labour Journal_ published an article explaining that Norway had no female CEOs in its 60 largest firms, even though eight years had passed since the quotas were introduced.52



These studies give us insight into the quota’s effects. Women’s progress is often discussed in simplistic terms, where the share of women on company boards is seen as a goal in itself. But this is a narrow view of women’s professional success, and a more holistic view paints a different picture.



Reforms that enable women to climb the professional ladder organically or create successful firms provide a superior approach. Eliminating public-sector monopolies in service industries and reducing the tax wedge to improve incentives for work and purchasing household service substitutes would be a good start. These reforms produce new professional choices for women, and would gradually increase their representation on company boards. This is a different mechanism from legislation, which leads to a more rapid, but largely symbolic, change.



Nordic public-sector monopolies, tax policies, and welfare and family policies, along with ineffective gender quotas, combine to create the Nordic glass ceiling. The glass ceiling is a metaphor for the barriers women face in reaching leadership positions.



Nordic women might be expected to fare well in the private labor market. After all, Nordic countries have an unusually high rate of women’s labor-force participation, and generous public parental leave and daycare are intended to encourage women’s economic participation. However, when it comes to the actual share of women managers, the Nordic countries are not on top.



Some 28 percent of managers are female in Denmark, 32 percent in Finland, 32 percent in Norway, and 36 percent in Sweden (Table 2).





Iceland in particular stands out among the Nordic states, since it has a smaller welfare state than its larger Nordic cousins and also ranks among the highest share of female managers in the world. On the other hand, Denmark has the highest tax rate among all the nations in the Organisation for Economic Co-operation and Development and ranks at the bottom in terms of its proportion of female managers.



In the dataset for developed economies, there are three countries with equal or higher rates of female managers than Iceland: New Zealand, the United States, and Latvia.55 These countries have relatively low tax rates: 26.4 percent in the United States, 29.0 percent in Latvia, and 32.8 percent in New Zealand.56



Of course, government size is just one factor influencing women’s careers. Nevertheless, the relationship between government size and the proportion of female managers is interesting to note.



Another metric that can be used to measure female professional attainment is _The Economist_ ’s glass-ceiling index. The index compares opportunities for women in various countries. Table 3 compares the Nordic countries with the United States along several metrics.





The Nordic countries do well on some of the index’s metrics. They consistently outperform the United States on issues such as the gender gap in higher education and women’s labor-force participation. Direct childcare expenditure is relatively low in the Nordics because much of it is tax-funded. The Nordics also have generous public paid-leave programs.



The United States has a larger gender gap in labor-force participation, a smaller advantage for women in tertiary education attainment, higher private childcare costs, and no public paid leave. As a result, it might seem the United States has woman-unfriendly policies and the Nordics have woman-friendly policies. However, the United States has the highest rate of female managers among all countries in the Index. The Nordic countries have a lower share.57 _The Economist_ has written about this pattern and suggests professional gender segregation by role is high in the Nordics.58



One place that Nordic women break the glass ceiling is in the political arena. The feminist movement was successful in pushing for women’s political representation. Women have played a key role in Nordic politics historically, both on the political left and the right.59 The proportion of women in parliament ranges from 37 percent in Denmark to 44 percent in Sweden. This is higher than the United States, where 19 percent of those elected to the U.S. House of Representatives and 20 percent of those elected to the U.S. Senate are women.60 This success may be admired in isolation.



However, when compared with trends in the broader private economy, it only calls further attention to the Nordic Gender Equality Paradox: if Nordic policies are the best at supporting women’s climb to the top, then women should be successful in roles throughout the economy. Unfortunately, Nordic societies with large welfare states have surprisingly few women in managerial positions in the private sector.



The Nordic countries are in many ways the most gender-equal in the world, owing to their history, culture, and some beneficial policies. Therefore, foreign observers assume replicating Nordic policies is the key to women’s progress, even when facts and research tell us the opposite.



Welfare policies, high taxes that make it costly to purchase substitutable services, generous benefit systems that reduce economic incentives for full-time work, public-sector monopolies/oligopolies in female-dominated sectors, and paid-leave policies that incentivize long breaks from working life prevent women from reaching the top. Taken together, these policies create a Nordic glass ceiling. Gender quotas are unable to make up the difference, even though politicians routinely point to gender quotas as a policy success story. In reality they fall short of their objectives.



It is true that Nordic countries have high female employment rates and an unusually gender-equal history and gender-equal values, and these achievements merit admiration. Still, the proportion of women managers, executives, and business owners is disappointingly low. Several other countries that lack the advantages of the Nordics, but have more small-government and market-oriented policies, have a larger proportion of women who reach the top. This is true of the United States. The Nordic Gender Equality Paradox is important to keep in mind in countries such as the United States, where Nordic-style welfare policies are routinely touted as a way of promoting gender equality without tradeoffs.61



The pattern within the Nordics is also worth keeping in mind. More women reach executive positions in Iceland, the Nordic country with a smaller welfare state, than in Denmark, the Nordic country with an unusually large welfare state. This pattern, together with various studies cited in this report, suggest that key aspects of social welfare policy hold professional women back.62



1. Saadia Zahidi, senior director and head of gender parity and human capital at the World Economic Forum, has stated that the Nordic countries “have made it possible for parents to combine work and family,” which results in better female labor-force participation, more egalitarian sharing of domestic work, and improved work-life balance. Saadia Zahidi, “What Makes the Nordic Countries Gender Equality Winners?” _Huffington Post_ , October 24, 2013, https://www.huffingtonpost.com/saadia-zahidi/what-makes-the-nordic-cou_b_4159555.html.



Katrin Bennhold at the _New York Times_ argues that Sweden’s feminist model is beneficial both to men and women in tearing down traditional gender roles. Like other international proponents of Nordic gender equality, Bennhold admires the “social engineering” that has made “a new definition of masculinity” possible. Likewise, Bennhold writes enthusiastically about laws that have “set off profound social change.” Katrin Bennhold, “In Sweden, Men Can Have It All,” _New York Times_ , June 9, 2010, http://www.nytimes.com/2010/06/10/world/europe/10iht-sweden.html.



In the left-wing American journal _The Nation_ , Ann Jones states that equality between genders is “the heart of Scandinavian democracy.” Jones argues that the United States should follow in the footsteps of Norway, where “feminists and sociologists pushed hard against . . . the nuclear family.” In particular, Jones admires the policy in which an expanded role for the state has undermined the family institution. Ann Jones, “After I Lived in Norway, America Felt Backward. Here’s Why,” _The Nation_ , January 28, 2016, https://www.thenation.com/article/after-i-lived-in-norway-america-felt-backward-heres-why/.



Norwegian political scientist Helga Maria Hernes introduced this narrative in 1987, and the narrative has significantly influenced policy research. Anette Borchorst and Birte Siim, “The Women-Friendly Welfare States Revisited,” _NORA—Nordic Journal of Feminist and Gender Research_ 10, no. 2 (2002): 90–98.



Eva-Maria Svensson and Åsa Gunnarsson write in an article published in a feminist law journal that “a prominent characteristic of the Swedish model is . . . that gender equality policy is closely intertwined with the Swedish welfare state ideology.” Eva-Maria Svensson and Asa Gunnarsson, “Gender Equality in the Swedish Welfare State,” _Feminists@law_ 2, no. 12 (July 23, 2012): 1–27.



2. During the 10th century Battle of Dorostolon, the Kievian Rus forces—who were essentially Swedish Vikings with a strong presence in today’s Russia—invaded present-day Bulgaria. A counteroffensive by the Byzantine Empire dealt a devastating defeat to the Vikings. The Byzantine were stunned at discovering armed women among their fallen enemies. Dick Harrison and Kristina Svensson, _Vikingaliv_ (Värnamo: Fälth & Hässler, 2007).



3. Marianne Moen, “The Gendered Landscape—A Discussion on Gender, Status and Power Expressed in the Viking Age Mortuary Landscape,” Department of Archaeology, Conservation and History (IAKH) Faculty of Humanities, University of Oslo, 2010.



4. Anders Johnson, “Kvinnliga handlare trots förbud,” _Handelns Historia_ , October 5, 2011, www.handelnshistoria.se/historien/handelns-lagstiftning/kvinnliga-handlare-trots-forbud/.



5. Sweden included Finland from the 13th to the beginning of the 19th century, and was in union with Norway between the beginning of the 19th and the end of the 20th century. Thus, during this period, Sweden’s history is key to understanding the development in the region as a whole. The country also has the largest population in the Nordics.



6. Christine Bladh, “Kvinna med eget företag—från 1700-talets mitt till 1800-talets slut,” p. 127-142 in “Mot halva makten – elva historiska essäer om kvinnors strategier och mäns motstånd”, ed. Ingrid Hagman (Stockholm: Arbetsmarknadsdepartementet, 1997). This report was, in turn, part of a government inquiry regarding the economic resources and influence of men and women in Sweden, entitled “Utredningen om fördelningen av ekonomisk makt och ekonomiska resurser mellan kvinnor och män Stockholm 1997.”



7. Suzanne McGee and Heidi Moore, “Women’s Rights and Their Money: a Timeline from Cleopatra to Lilly Ledbetter,” _Guardian_ , August 11, 2014, https://www.theguardian.com/money/us-money-blog/2014/aug/11/women-rights-money-timeline-history.



8. Ibid.



9. Kari Melby, Anna-Birte Ravn, and Christina Carlsson Wetterberg, _Gender Equality and Welfare Politics in Scandinavia_ (Bristol, UK: The Policy Press, University of Bristol, 2009).



10. Ibid.



11. Source: “World Values Survey, Wave 3 (1995–1999),” World Value Survey Association, http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp; and “World Values Survey, Wave 6 (2010–2014),” World Value Survey Association, http://www.worldvaluessurvey.org/WVSDocumentationWV6.jsp. Data files are aggregated by Asep/JDS, Madrid, Spain.



12. “Global Report: Attitudes to Gender,” _YouGov_ , November 12, 2015, https://yougov.co.uk/news/2015/11/12/global-gender-equality-report/.



13. “The European Structure of Earnings Survey,” _Eurostat_ , 1995, http://ec.europa.eu/eurostat/web/microdata/structure-of-earnings-survey.



14. Torben Iversen, Frances Rosenbluth, and David Soskice, “Women and the Service Sector,” University of California–Los Angeles (UCLA) Postindustrial Working Group, April 18, 2004.



15. The report concluded that “studies comment on how Nordic countries, and in particular Sweden, have among the greatest inequalities.” See Richard Anker, “Gender and Jobs: Sex Segregation of Occupations in the World,” International Labour Office, 1998.



16. Magnus Henrekson and Mikael Stenkula, “Why Are There So Few Female Top Executives in Egalitarian Welfare States?,” IFN Working Paper no. 786, February 9, 2009, http://www.ifn.se/wfiles/wp/wp786.pdf.



17. Matti Alestalo, Sven E. O. Hort, and Stein Kuhnle, “The Nordic Model: Conditions, Origins, Outcomes, Lessons,” Hertie School of Governance Working Papers no. 41, June 2009, http://edoc.vifapol.de/opus/volltexte/2013/4255/pdf/41.pdf.



18. “Women Entrepreneurship—A Nordic Perspective,” Nordic Innovation Centre, August 2007, http://nordicinnovation.org/Global/_Publications/Reports/2007/women_entrepreneurship_final_report_web.pdf.



19. Anita Lignell Du Rietz, Svenskornas företagsamma historia (Stockholm: Timbro, 2009).



20. “Många miljarer blir det. . . Fakta och nyckeltal om kvinnors företag,” Swedish Agency for Economic and Regional Growth, 2010. Translated into English by Nima Sanandaji.



21. Elisabeth Sundin and Malin Tillmar, “Kvinnors företagande i spåren av offentlig sektors omvandling,” in Forskning om kvinnors företagande, presentation av projekten (Stockholm: Vinnova, 2008). Translated into English by Nima Sanandaji.



22. Increased competition from private firms also pushes up the wages in the public sector, as previous public-sector monopolies had to begin competing for talent retention. Since the study does not take this into account, it likely underestimates how important privatization can be for wage increases.



23. Johan Kreicbergs and Carl Oreland, _Nyföretagande inom den offentliga sektorn—ett lyft för kvinnor_ (Stockholm: Svenskt Näringsliv, 2009).



24. Andrew Pendleton, “What Impact Has Privatization Had on Pay and Employment? A Review of the UK Experience,” _Industrial Relations_ 52, no. 3 (1997): 554–82.



25. Lars Calmfors and Katarina Richardson, “Marknadskrafterna och lönebildningen i landsting och regioner,” Institute for Evaluation of Labour Market and Education Policy, Uppsala, Sweden, 2004, http://www.ifau.se/globalassets/pdf/se/2004/r04-09.pdf.



26. Alexander Gelber and Joshua Mitchell, “Taxes and Time Allocation: Evidence from Single Women and Men,” _Review of Economic Studies_ 79, no. 3 (November 2011): 863–97.



27. See, for example, Patricia Cortes and Jessica Pan, “Outsourcing Household Production: Foreign Domestic Workers and Native Labor Supply in Hong Kong,” _Journal of Labor Economics 31, no. 2 (April 2013): 327–71; and Jan Kabatek, Arthur Van Soest, and Elena Stancanelli, “Income Taxation, Labour Supply and Housework: a Discrete Choice Model for French Couples,” _Labour Economics_ 27 (April 2014): 30–43._



28. Henrekson and Stenkula, “Why Are There So Few Female Top Executives in Egalitarian Welfare States?”



29. L. Rachel Ngai and Barbara Petrongolo “Gender Gaps and the Rise of the Service Economy,” _American Economic Journal: Macroeconomics_ 9, no. 4 (2017): 1–44.



30. The professor pays taxes on income, including indirect employer’s fees and direct taxes on work. Afterwards, consumption taxes are paid on the service purchased. Finally, the painter pays direct and indirect taxes on the income received. This adds up to a high total tax burden. The tax wedge ranges from 34.0 percent in Iceland to 43.8 in Finland (Table 1). This captures both indirect and direct taxes on labor for an average worker. Thus, if the first individual works an additional hour in Finland to create an economic value of 100 euros, 56.2 euros will be rewarded to the individual while 43.8 euros will go to the government. When the same individual purchases a service from a second individual, a VAT of 24 percent is charged on top of that, leaving 42.7 euros. The second individual is also affected by indirect and direct taxes on labor, leaving 24.0 euros in her or his pocket at the end of the transaction. In Iceland, the Nordic country with the lowest tax rate, a third of the original value created is left after taxes. This is equivalent to a situation where the individual simply performs the service him or herself, paying no taxes at all. It is rational for Nordic professors to paint their own houses under this system, even if their time would create three times more value if they worked in their specialty.



31. Schumpeter, “A Nordic Mystery,” _The Economist_., November 15, 2014, https://www.economist.com/news/business/21632512-worlds-most-female-friendly-workplaces-executive-suites-are-still-male-dominated.



32. Evridiki Tsounta, “Why Are Women Working So Much More in Canada? An International Perspective,” International Monetary Fund Working Paper 06/92, April 2006, https://www.imf.org/external/pubs/ft/wp/2006/wp0692.pdf.



33. According to Rendell, Nordic countries balance the effects by providing public-sector benefits including subsidized full-day childcare. Michelle Rendell, “Rise of the Service Sector and Female Market Work: Europe vs US,” University of Zurich Working Paper Series no. 23, February 2014, http://www.econ.uzh.ch/ipcdp/Papers/ipcdp_wp312.pdf.



34. “Rut och flex vägen för kvinnors framgång,” _Ny Teknik_ (Stockholm), February 10, 2012.



35. Child support is provided to all families, regardless of income.



36. Catherine Hakim, _Work-Lifestyle Choices in the 21st Century_ (New York: Oxford University Press, 2000).



37. “The current situation of gender equality in Sweden—Country Profile,” European Commission, 2013.



38. E. M. Milgrom and T. Petersen, “The Glass Ceiling in the US and Sweden: Lessons from the Family-Friendly Corner of the World, 1970–1990,” in _The Declining Significance of Gender?_ , ed. F. D. Blau, M. C. Brinton, and D. Grusky (New York: Russell Sage Foundation, 2008), pp. 2, 39.



39. Schumpeter, “A Nordic Mystery.”



40. Kimberly Weisul, “Women on Boards: Are Quotas Really the Answer?” _Fortune_ , December 5, 2014, http://fortune.com/2014/12/05/women-on-boards-quotas/.



41. “The CS Gender 3000: Women in Senior Management,” Credit Suisse Research Institute, 2014, https://glg.it/assets/docs/csri-gender-3000.pdf.



42. To be more precise, the Tobin’s Q, which was introduced in 1968 by James Tobin and William Brainard, is the ratio between a physical asset’s market value and its replacement value.



43. Johanne Grosvold, Stephen Brammer, and Bruce Rayton, “Board Diversity in the United Kingdom and Norway: An Exploratory Analysis,” _Business Ethics: A European Review_ 16, no. 4 (2007): 344–57.



44. Kenneth Ahern and Amy Dittmar, “The Changing of the Boards: The Impact on Firm Valuation of Mandated Female Board Representation,” _Quarterly Journal of Economics_ 127, no. 1 (February 1, 2012): 137–97.



45. Nina Smith, “Gender Quotas on Boards of Directors,” _IZA World of Labor_ , 2014. https://wol.iza.org/articles/gender-quotas-on-boards-of-directors/.



46. Nina Smith, Valdemar Smith, and Mette Verner, “Do Women in Top Management Affect Firm Performance? A Panel Study of 2,500 Danish Firms,” _International Journal of Productivity and Performance Management_ 55, no. 7 (August 2006): 569–93.



47. Norway’s gender-quota policy has received attention in the United States, as well. Aaron Dhir, professor of law at Yale Law School, argues that “while quotas might not be palatable in the United States, it is clear that a more forceful regulatory shove is needed to disrupt the status quo.” He suggests that law is a “powerful tool” and we shouldn’t be afraid to use it to shape culture or address biases. Aaron A. Dhir, “What Norway Can Teach the U.S. about Getting More Women into Boardrooms,” _The Atlantic_ , May 4, 2015, https://www.theatlantic.com/business/archive/2015/05/what-norway-can-teach-the-us-about-getting-more-women-into-boardrooms/392195/.



48. Cathrine Seierstad and Tore Opsahl, “For the Few Not the Many? The Effects of Affirmative Action on Presence, Prominence, and Social Capital of Women Directors in Norway,” _Scandinavian Journal of Management_ 27, no. 1 (2011): 44–54.



49. Marianne Bertrand, Sandra E. Black, Sissel Jensen, and Adriana Lleras-Muney, “Breaking the Glass Ceiling? The Effect of Board Quotas on Female Labor Market Outcomes in Norway,” National Bureau of Economic Research, Working Paper no. w20256, July 2017, http://www.nber.org/papers/w20256.



50. Sigtona Halrynjo, Mari Teigen, and Marjan Nadim, “Kvinner og menn i toppledelsen: Ringvirkningar av lovkrav om kjønnsbalanse i bedriftsstyrer?” in _Virkninger av kjønnskvotering i norsk næringsliv_ (Oslo, Gyldendal Akademisk, 2015), pp. 18–22. Translated into English by Nima Sanandaji.



51. Kjersti Misje Østbakken, Harald Dale-Olsen, and Pal Schøne, “Kjønnsbalanse i styrer og kvinners karriere,” in _Virkninger av kjønnskvotering i norsk næringsliv_ (Oslo: Gyldendal Akademisk, 2015), pp. 31–33. Translated into English by Nima Sanandaji.



52. Björn Lindahl, “Norway’s Female Boardroom Quotas: What Has Been the Effect?” _Nordic Labour Journal_ , May 21, 2015, http://www.nordiclabourjournal.org/artikler/forskning/research-2015/article.2015-05-20.3011019632.



53. “Women in Business and Management Gaining Momentum,” International Labour Organization, 2015.



54. As measured by taxes as share of GDP. Ranking of Nordic countries by government size is as follows: Denmark has the highest tax rate as a share of GDP among the Nordic countries and the industrial world. According to OECD data, the tax rate of Denmark was 46.6 percent of GDP in 2015. Finland is second, at 44.0 percent of GDP, and Sweden follows at 43.3 percent. In Norway, public expenditure is partly funded through oil revenues, and the tax rate is lower, at 38.1 percent. Iceland has the lowest tax rate, at 37.1 percent.



55. “Women in Business and Management Gaining Momentum,” International Labour Organization, 2015.



56. “Revenue Statistics—OECD Countries: Comparative Tables,” _OECD Stat Extract_. https://stats.oecd.org/Index.aspx?DataSetCode=REV. Latest available data for 2015.



57. “Glass Ceiling Index,” _The Economist_ , http://infographics.economist.com/2017/glass-ceiling/.



58. Ibid.



59. A. Johnson, _De gjorde skillnad: liberala kvinnor från Anna Maria Lenngren till Marit Paulsen_ (Stockholm: Folkpartiet Liberalerna, 2009).



60. “Women in National Parliaments,” Inter-Parliamentary Union, 2016, http://archive.ipu.org/wmn-e/arc/classif011216.htm.



61. The social democratic Swedish government that took office in 2014 describes itself as “the first feminist government in the world.” The BBC published a story entitled “Is Sweden’s Feminist Agenda Working?,” and reported that “things are getting better for women” but did not state any factual support for this conclusion. “Is Sweden’s Feminist Agenda Working?,” BBC, February 17, 2017, http://www.bbc.com/news/world-europe-39004991.



An opinion column by Gabrielle Jackson argues that the Swedish welfare-state model of providing generous paternity leave is a model that should be adopted in other parts of the world. Gabrielle Jackson, “Force Men to Take Paternity Leave. It Will Make the World a Better Place,” _Guardian_ , April 9, 2015, https://www.theguardian.com/commentisfree/2015/apr/10/want-better-dads-happier-mums-and-healthier-kids-make-men-take-paternity-leave.



In March 2017, the Nordic Council of Ministers and New America think tank cohosted a public event in New York on how the United States could be inspired from Nordic countries in expanding the public parental leave system. Anne-Marie Slaughter, the president of New America, explained before the event that the Nordic countries have outpaced the United States “in terms of valuing families and shifting gender roles” and said that “Americans should learn from them.” “US Think Tank to Showcase Nordic Gender Equality,” _Norden_ , March 9, 2017, http://www.norden.org/en/news-and-events/news/us-think-tank-to-showcase-nordic-gender-equality.



62. For more information, see Nima Sanandaji, _Jämställdhet inom räckhåll_ (Stockholm: Captus, 2009); Nima Sanandaji, _Att Spräcka Glastaken_ (Stockholm: Captus, 2013); and Nima Sanandaji, _The Nordic Gender Equality Paradox_ (Stockholm: Timbro, 2016).
"
"**Tier three is the ""right place"" for Hull due to high coronavirus rates in the city, a council leader has said.**
Hull City Council's Stephen Brady admitted residents may be ""tired of restrictions and changing advice"" but needed to comply with the rules.
The city, which previously had the highest infection rate in England, was placed in the ""very high alert"" category from 2 December.
Restrictions will be reviewed on 16 December .
The tougher measures mean households can only meet in public spaces like parks, where the rule of six applies.
Infections in the city have been falling in recent days.
In the seven days to 22 November, 460 cases per 100,000 people were reported in the city - down from 748.3 the previous week.
Mr Brady said: ""Tier three is not where anyone wants to be but, with our infection rates still very high, it is what we expected and it's the right place for Hull to be at this time.
""This is a very difficult time and we would all like it to be over. What the last few weeks have shown is that, if we can continue to do all we can to minimise spreading the virus, we can continue to bring the rate down and, hopefully, move towards an easing of restrictions.""
He added that people should think about what's best for the city over Christmas and warned against mixing households, despite the government allowing some limited mixing.
In a tweet, MP for Hull East Karl Turner thanked residents for their ""hard work and sacrifice"".
He said: ""Tier 3 is sadly still where we need to be, but the government must provide more support for those hit the hardest and a clear route back to lower restrictions.""
Health Secretary Matt Hancock set out the reasoning behind the tier decisions for each area in a written ministerial statement.
_Follow BBC East Yorkshire and Lincolnshire on_Facebook _,_Twitter _, and_Instagram _. Send your story ideas to_yorkslincs.news@bbc.co.uk _._"
"

 _Global Science Report is a weekly feature from the Center for the Study of Science, where we highlight one or two important new items in the scientific literature or the popular media. For broader and more technical perspectives, consult our monthly “Current Wisdom.”_   
  
  
There seems to be a noticeable murmur around town about a carbon tax—a tax on the amount of carbon dioxide that is released upon generating a unit of energy. Since fossil fuels—coal, oil, natural gas—are both the source of over 75% of our energy production and emitters of carbon dioxide when producing that energy, a carbon tax insures that the price of everything goes up.   
  
  
There is one and only one justification for a carbon tax—an attempt to influence the future course of the earth’s climate (or, as some people prefer, to mitigate anthropogenic climate change) by trying to force down the emissions of the most abundant human‐​generated greenhouse gas.   
  
  
But of all the things that a carbon tax will do (raise prices, increase bureaucracy, elect Tea Partiers, etc), mitigating anthropogenic climate change in any meaningful manner is not one of them.   
  
  
The annual carbon dioxide emissions from the U.S., currently about 5,500 million metric tons per year, only contributes roughly 0.003°C/per year of warming pressure on global temperatures (see here for a handy way of making that calculation). So the best that a carbon tax could ever hope to achieve, climatically, would be to prevent this amount of warming each year by completely eliminating all carbon dioxide emissions from the U.S.   
  
  
If we went to zero emissions tomorrow, the carbon tax would prevent about 0.26°C of global temperature rise by the year 2100. According to the latest projections from the Intergovernmental Panel on Climate Change (IPCC), the projected temperature rise by the end of the century ranges from about 1.1 to 6.4°C, with a business‐​as‐​usual rise of around 3°C (put me down for 1.6° until then, unless nature is being a blatant liar). The “mitigated” rise is proportional to the expected temperature rise. A carbon tax enacted today that is immediately and completely successful at eliminating all U.S. CO2 emission would lower rise in temperature expected by the end of the century around 10%. This amount is small, of little consequence, and in fact will be difficult to detect.   
  
  
It is also not going to happen. We only have the capacity to produce about 30% of our electricity from non‐​carbon emitting fuel sources (primarily nuclear and hydroelectric). So it will take time, and probably a lot of time (many decades) before our energy needs could possibly be met without emitting CO2 into the atmosphere. And of course, as time ticks by before eliminating or at least appreciably reducing our emissions, the amount of global warming saved by such action declines (and become less and less consequential), as does the justification for the carbon tax.   
  
  
I am just in the early stage of this analysis, so the numbers above are a bit rough (but conservative). In the future I hope to produce a menu of emissions reductions/​climate savings options—but one without prices. That way the policymakers will see what they are going to be getting for whatever price they decide to assign. So too will the general public. And what they will all see is that whatever level of carbon tax they decide upon, they will get a lot of climate nothing for a lot of financial something.   
  
  
The best thing would be for policymakers to just leave well enough alone, for on their own, carbon dioxide emissions in the U.S. have been declining for more than a decade (and in fact are pushing levels of the early 1990s, http://​www​.eia​.gov/​e​n​v​i​r​o​n​m​e​n​t​/​e​m​i​s​s​i​o​n​s​/​c​a​rbon/). And even if such a reduction doesn’t result in any scientifically detectable climate impacts, at least it hasn’t cost us anything.
"
"**Reports of rape dropped by more than 20% during lockdown compared with the same period last year, according to Police Scotland.**
Between 24 March, when lockdown started, and 5 July, 529 rapes were recorded by the force.
The figure represents a 20.2% reduction on the same three-and-a-half month period in 2019, police said.
The force said rape reports had since increased as Covid restrictions eased, but figures remained lower than 2019.
Between 24 March and 15 November, the number of both recent and non-recent rape offences reported was down 6.5% to 1,427 compared with 1,526 for the same period in 2019.
A recent offence is categorised as one within a year of the crime occurring - reports of which were down 10.8% between March and November from 959 in 2019 to 855 this year.
Despite the decrease in figures, the force issued a reminder that a reduction in reporting did not equate to less offending and said all forms of sexual crime continued to be under-reported.
It said it was too early to draw conclusions about why there had been a fall.
Rape Crisis Scotland chief executive Sandy Brindley said: ""Lockdown has been incredibly tough for so many people and for survivors it's posed real challenges in accessing support and - for those who choose to report - going to the police."""
"
  John A: This is a provocative essay, and I’ve thought of at least a couple of replies to counter some of the arguments, but I think it deserves a wider audience.

The Global Warming Policy Foundation

by Dr Terence Kealey, Vice-Chancellor, University of Buckingham
Member of the Academic Advisory Council for the Global Warming Policy Foundation
The Mont Pelerin Society Meeting Seminar on Science, Scepticism and the Future. Sydney, Australia, October 2010
 
The hard core of a programme is rendered unfalsifiable by the methodological decision of its protagonists. — Imre Lakatos Criticism and the Growth of Knowledge 1974
The  scientist is restricted by his instruments, money, the attitudes of his  colleagues, his playmates, and by innumerable physiological,  sociological, historical constraints.  –Paul Feyerabend, Against Method 1975

The  emails sent by members of the climatic research centre at the University  of East Anglia have provoked international outrage, as have the many  flawed global warming papers that have appeared in recent years such as  those describing the hockey stick graph(1), to say nothing of the flawed  predictions of the Intergovernmental Panel on Climate Change (IPCC)  over such issues as the rate of disappearance of the glaciers in the  Himalayas. But such outrage has been naive because it has been premised  on the assumption that scientists are – and should be – dispassionate  seekers after truth. Yet in fact scientists are and should be advocates.  Science has always been rooted in advocacy, as was illustrated by an  episode from its very beginnings during the 5th century BC.
Pythagoras  (of the Theorum) was a good scientist but he was of a mystical bent and  he revered ‘rational’ numbers (whole numbers or whole fractions).  He believed they explained the Harmony of the Spheres. Pythagoras,  indeed, believed that whole numbers underpinned the universe from music  to the movement of the planets. But Pythagoras had a student called  Hippasus, and Hippasus discovered that the square root of 2, √2 is not a  rational number. It is in fact an ‘irrational’ number, and its exact  quantity will never be precisely calculated because, as Hippasus showed  two and a half thousand years ago, irrational numbers can never be  definitively calculated. This proof upset Pythagoras and he asked  Hippasus to retract it. But Hippasus refused, so Pythagoras had him  drowned.
That’s  what scientists are like in their natural state. Now – call me soft –  but I think Pythagoras went too far; I think that scientists should  desist from killing each other or even from telling outright falsehoods.  But, like advocates in court, scientists can nonetheless be expected to  put forward only one very partial case – and that as strongly as  possible – and no-one should expect a scientist to be anything other  than a biased advocate.
Consider  the early controversy over the age of the earth. The 19th  century geologist Sir Charles Lyell had, by his study of the rate of  erosion of cliffs, proposed the earth not to have been created at 9.00  am on the 23rd of October 4004 BC but, rather, some hundreds of millions  of years earlier. But, as we know from volcanoes, the core of the earth  is red hot. And when contemporary geologists measured the temperature  of the molten core, and when they calculated its rate of heat loss,  they concluded that the earth could be only a few millions of years old.  Had it been any older its core would have completely cooled. Lyell had  apparently been falsified.
In  the face of this apparent falsification, did Lyell’s followers ditch  their ideas? No. Like advocates presented with contradictory data that  cannot be challenged, they simply ignored it. They knew how old the  sedimentary rocks had to be, and they didn’t believe the falsifiers. So,  not knowing how to falsify the falsifiers, they simply pressed on with  their own pre-existing programme of research, assuming
that  something helpful would turn up eventually. Which it did. Somebody in  some other discipline discovered radioactivity, somebody discovered the  core of the earth to be radioactive, somebody discovered that  radioactive reactions emitted heat and hey presto the problem was  resolved: the core of the earth generates heat, which is why it is still  hot; and the earth is indeed very old.
In  his 1605 book The Advancement of Knowledge, which helped launch  the modern discipline we call the philosophy of science, Francis Bacon  proposed a four-step process by which science advanced, namely by (i)  observation, (ii) induction, (iii) deduction and (iv) experimentation.  Bacon saw this as an almost mechanical or determinist activity based on  logic, which he supposed precluded individualistic human whims. But  because the number of potential observations is so large (does  the colour of an astronomer’s socks correlate with his or her recordings  of the movement of a planet?) scientists must inevitably select the  observations they believe to be relevant, from which they then deduce  and induce the theories they seek to test.
Scientists  therefore select particular theories out of a range of possibilities.  And they then (being human) design experiments to prove their own  theories right. Consequently, contrary to what many people believe that  Karol Popper wrote, science is in practice not about falsification.2 In  practice great scientists ignore embarrassing data, and they refuse to  feel falsified when they don’t want to be.
Scientists  know they are working at the limits of knowledge, which means that  that knowledge must necessarily be imperfect, so (like Charles Lyell)  scientists will refuse to draw definitive negative conclusions from  unhelpful new findings because they know that those new findings might  themselves need re-evaluation in the light of further subsequent data  (such as radioactivity) that has yet to be revealed.
Indeed,  as Thomas Kuhn explained in his classic 1962 book The Structure  of Scientific Revolutions, scientists’ personal attachment to their own  theories in the face of conflicting data means that the research  community’s dispassionate collective verdict over what is  ’truth’ can  be delivered only after all the competing data has come in and only  after all the arguments have been made (or, as was said humorously by  Max Planck:-  “A new scientific truth does not triumph by convincing its  opponents and making them see the light but rather because its  opponents eventually die and a new generation grows up that is familiar  with it “). These arguments have been summarised by Alan Chalmers of  Finders University in his excellent introduction to the philosophy of  science What Is This Thing Called Science? (3rd ed 1999, Open University).
Consequently,  we can see how the climate change scientists of the IPCC and of the  conventional global warming paradigm saw no conflict between their  partiality in the arguments they put forward and their responsibilities  to  ‘truth’, just as advocates in court under the common law see no  conflict between their partiality in the arguments they put forward and  their responsibilities to  ‘justice’.
In both cases, the  scientists and advocates see their prime responsibility as being the  putting forward of the best arguments to support their case/client, and  they delegate the adjudication over impartial ‘truth’ to the jury of  peers.
Such  partiality cannot excuse misrepresentation, of course, nor the  persistent non-disclosure of inconvenient facts, and those will always  be ethical crimes, but it would be naive of the general public to expect  scientists always to present their work and theories dispassionately.  It would also be naive of the general public to expect scientists to  disclose all their data promptly. In his otherwise excellent 2010 book  The Hockey Stick Illusion (Independent Minds) where he  dismissed the claims of many climate change scientists, AW Montford  nonetheless professed astonishment that researchers might feel that they  can legitimately withhold original data. But as Tim Birkhead recently  reported in the Times Higher Education, such withholding is  a conventional aspect of many disciplines in science. Indeed, it is  endorsed by the British Government’s research councils. Thus the Natural  Environment Research Council states that “individual scientists,  principal-investigator teams and programmes will be permitted a  reasonable period of exclusive access to data sets they have collected”  while the Biotechnology and Biological Sciences Research Council states  that  ‘researchers have a legitimate interest in benefiting from their  own time and effort in producing the data, but not in prolonged  exclusive use. ‘3
But why should scientists publish anything at all? In his 1942 essay The Normative Structure of Science Robert Merton, the great sociologist of science, described science with  the acronym CUDOS (note how it is pronounced). The letters stand for  Communism, Universalism, Disinterestedness and Organised Scepticism,  by which Merton meant that scientists share knowledge (communism), that  knowledge is judged objectively (universalism), that scientists act in  ways that appear selfless, and that ideas are tested collectively.
But actually Merton was being ahistorical. Pace his acronym, scientists indeed seek either kudos or money or both (ie,  they are not communistic, they are selfseeking, which is legitimate but  not particularly noble) but their publishing has always been dictated by  self-interest. Indeed, in its natural state science was  originally characterised by the paradox of secret publishing:  researchers did not want others to benefit from their advances. So some  scientists, having dated the report of a discovery, would seal and  deposit it with a college or lawyer, to open it only to dispute priority  with a later competitive publication. Others would publish in code  or in anagrams: Galileo published his discovery of the rings of Saturn  in 1610 as smaismrmilmepoetaleumibunenugttauiras for Altissimum planetam tergeminum observavi (I have observed the most distant planet to have a triple form) while Robert Hooke published his law of elasticity in 1660 as ceiiinosssttuu for ut tensio sic vis (stress is proportional to strain.)
Secrecy  was originally normal: when around 1600 a young London obstetrician  called Peter Chamberlen invented the obstetric forceps, for over a  century he, his younger brother, his younger brother’s son and that  son’s son (all obstetricians) kept the invention a secret. Rich women,  knowing that the Chamberlens were the best obstetricians in Europe,  engaged them to deliver their babies, but the price those women paid  (apart from handsome fees) was to be blindfolded and trapped alone with  the Chamberlens in a locked room during labour so that no one could  discover the secret of the forceps. That emerged only during the 1720s  when the last Chamberlen, having retired rich but childless, finally  divulged it.
It  was Robert Boyle who, by his leadership of the Royal Society of  London, which was created exactly 350 years ago this year, negotiated  (i) the convention whereby priority – and therefore esteem – goes to the  scientist who publishes first, not to the scientist who might  have made the discovery earlier but who has kept the findings secret,  and (ii) the convention that papers are accepted for publication only  if they contain a methods section as well as a results section, to allow  reproducibility.
We see here, therefore, that science is not innately a public good: it is innately a discreet one where, in a state of  nature, scientists would publish not their methods but only their  findings – and where they would sometimes delay or obscure the  publication even of those. But it was Boyle who realised, in classic  game theory mode, that if the Fellows (aka members) of the infant Royal  Society collaborated with each other in publishing their findings (i)  openly, and (ii) including their methods sections, then the scientists  within the Society would do better, by virtue of their access to the  whole of the Society’s membership’s collective discoveries, than  would those isolated researchers who worked outside the circle of mutual  disclosure. And it was because the Royal Society’s original experiments  were conducted collectively but in the presence only of its Fellows,  and because its publications were preferentially circulated to its  Fellows, that the Fellows enjoyed an advantage over non-Fellows.
Science, therefore, only appears to  be public because, over the centuries, most scientists globally have  gradually modelled themselves on the Royal Society’s ‘new’ conventions,  the better to take advantage of the mutuality of knowledge. But not all  scientists have done so completely, and as Birkhead showed in his THE  article many disciplines have elaborated the convention of publishing  their findings a year or two before they publish their data, thus  keeping a lead on the further study of their data.
Everyone  in those disciplines agrees that, since the exploitation of other  people’s data is so much easier than discovering it for oneself, a  discoverer’s year or more of monopoly is only fair.
To  conclude, therefore, scientists are not disinterested, they are  interested, and as a consequence science is not dispassionate or fully  transparent, rather it is human and partially arcane. As I argue  elsewhere, science is not the public good of modern myth, it is a  collegiate and quasi-private or invisible college good.4 That means,  by the way, that it requires no public subsidies. More relevantly, it  means that individual scientist’s pronouncements should be seen more as  advertisements than as definitive.
Peer  review, too, is merely a mechanism by which scientists keep a  collective control over access to their quasi-private enterprise. One  the e-mails leaked from the University of East Anglia included this  from Professor Phil Jones, referring to two papers that apparently  falsified his work:-  “I can’t see either of these papers being in the  next IPCC report. Kevin and I will keep them out somehow – even if we  have to redefine what the peer-review literature is!”
So  what? Climategate tells us no more than the philosophers of science have  long told us about research, and the public should be less naive.
Notes and References
1. Mann ME, Bradley RS, Hughes MK, 1999, Northern Hemisphere Temperatures During the Past Millennium Geophysical Research Letters 26: 759.762
2.  It should be noted that falsification and falsifiability are different.  As Popper proposed, a statement cannot be seen as scientific unless it  is falsifiable and can thus be tested by the scientific method. So the  statement that the moon is made of green cheese is a scientific one,  because it can be tested and falsified. But the fact that none of the  moon missions to date has found green cheese does not falsify the  hypothesis because not every part of the moon has yet been explored.
3. Birkhead T, 2009, Whose Data is it Anyway? Times Higher Education 1,901, 27.
4. Kealey T, 2008, Sex, Science and Profits William Heinemann


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8675b289',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterThe millions of Germans who read my blog 🙂 may wish to pick up FOCUS magazine tomorrow at the newsstands.Tomorrow’s edition features Professor Dr Fritz Vahrenholt, author, along with Sebastian Lüning, of the upcoming climate catastrophe skeptic book, Die kalte Sonne. It’s the book that warmists fear, and that open minds will surely absorb. Focus report on page 66.
Skepticism of the alarmist junk climate science is spreading in Germany.
The FOCUS report will also feature Freeman Dyson.
Michael Miersch writes of the FOCUS article:
A Bishop Leaves the Church
Fritz Vahrenholt wrote one of the standard books for the environmental protection movement, was the most well-known green-type social democrat, and today leads a company that is investing billions in renewable energy. But now not even he believes any longer in the forecasts of the IPCC and the Potsdam Institute concerning climate warming. More on that in tomorrow’s FOCUS (only in the print edition, not online). Also there is an interview with physicist and mathematician Freeman Dyson, who feels global cooling is far more problematic than a warming.”
German readers, please pick up a copy and tell us what you think.
Photo source: Die kalte Sonne website.
Share this...FacebookTwitter "
"In every part of our daily routines technology makes its presence felt. Now, forward-thinking Finland plans to change the way Europe goes about urban travel using a novel system, based on a smartphone app, to help people get the most out of public transport. It might even herald the end of the dominance of the private car. The driving force behind this move is that the younger generation want practical travel options. With incomes falling and motoring costs soaring, cars are increasingly seen as an unwelcome burden rather than the liberating symbol of personal freedom they once were. A recent report shows Generation Y (18 to 29-year-olds) hold different attitudes to cars than their predecessors. For Generation Y, being debt-free is suddenly sexy, while less than one in five consider car ownership a reflection of personal success. This is reflected by the lower car ownership levels among Generation Y (68%), compared to the previous Generation X (81%). While cars have been elevated to status symbols representing something aspirational, public transport, walking, and cycling only account for a small amount of total travel, and are often perceived as the fallback option for those with no other choice. The social, economic and cultural power attributed to private automobiles has meant that modern cities prioritise the car. The automobile industry sets new records each year, selling 69m cars in 2013 as emerging markets follow in the footsteps of Western Europe and North America.  In social and environmental terms, this is incredibly destructive. Car culture has contributed to a rise in individualism that cuts off social interactions and damages community relations. Neighbours simply pass by one another in their separate metal boxes.  Astoundingly, a quarter of all energy-related carbon dioxide emissions originate from road transportation, with passenger vehicles the main culprit. It is no small matter that this equates to a fifth of global oil usage. The Finnish capital has announced plans to transform its existing public transport network into a comprehensive, point-to-point mobility on-demand system within the next ten years. City-wide, this would link together taxis, shared cars, ferries, trains, shared bikes, driverless cars, buses, trams and, also, the Kutsuplus – the minibus rolled out last year that lets riders specify where they want to be picked up and put down via smartphone. In theory the Finnish set up would render car ownership essentially pointless in the city.  The Planning Department-approved plans come from an engineering student, Sonja Heikkilä, who believes young Helsinki residents view transportation differently from their parents. They want simple, flexible and inexpensive transportation so she has suggested a mobility model based on how services are provided in the telecommunications industry (in which Finland was also a trailblazer). Like internet service providers or mobile phone companies, residents might get around by paying by the kilometre, or by purchasing a monthly package with kilometres included. This integrated approach goes beyond traditional public transport systems, with transport procured in real time through a single app, providing residents with a range of options available at the touch of a screen. Users simply specify an start and a destination, and the software then acts as a journey planner to both identify and book the most efficient means of completing the journey.  This approach allows users to tailor their journeys from point to point, offering all the convenience of owning a car without much of the cost. As other economies still suffer fallout from the global economic crisis, the Nordic model of capitalism is gaining increasing attention. The Scandinavian approach entails a pragmatic judgement on public services: as long as they work, it does not matter who provides them. The city’s transportation will continue to be run as a public utility but will include competition to ensure the services that most benefit residents win out as commuters vote with their feet. This is Nordic capitalism in action: public authorities facilitating capitalist innovation to improve the overall standard of living, state-private partnerships that promote the comfortable life in Helsinki. But the impact of this plan could be felt beyond Northern Europe. It’s clear that, in the name of sustainable mobility, radical measures in urban planning need be undertaken. The electric car is currently the most popular alternative to petrol and diesel engines. However, by replacing cars with more cars we are not solving the problem. The electric car competes with public transport, walking and cycling. It displaces sustainable transport options in urban areas and requires precious raw materials to build. Add to this the fact that they are generally powered by electricity from fossil fuel-burning power stations and we are faced with the truth that realistically, the problem can only be remedied through changing our relationship with cars, not just changing the car with which we have a relationship."
"**Derby and Derbyshire will be subject to tier three restrictions after the national lockdown ends on 2 December, the government has announced.**
The city and county were in tier two prior to the lockdown but will move to the highest alert level.
This means pubs and restaurants must close except for takeaways and delivery and mixing indoors is banned.
Derby currently has a seven-day infection rate of 268.6 per 100,000 people for the week up to 21 November.
Bolsover has the county's highest figure with 301.6, although that is down from 427 the week before.
The average for the whole of England is 208.7.
Talking specifically about Derby and Derbyshire, the government said in a ministerial statement: ""There has been improvement in this area, but case rates remain very high at 275 per 100,000, and in those over 60 it is 220 per 100,000. The pressure on the local NHS remains high.""
The area's new tier placing means they are eligible for rapid or ""lateral flow"" tests to help bring down infections.
The system will be regularly reviewed - with the first scheduled for 16 December.
Toby Perkins, Labour MP for Chesterfield, called his area being put into tier three ""disastrous"" and a ""nightmare"".
He tweeted: ""Matt Hancock celebrating that mass testing has helped Liverpool drive down the R rate and move into tier two. Exactly. That is what every area should have had for months.""
Mr Perkins added the suggestion in the House of Commons by Mr Hancock that the reason Cornwall, Isle of Wight and Suffolk have lower rates than the rest of England was because their residents have been more responsible was ""deeply offensive"".
High Peak MP Robert Largan said he was ""disappointed"" all of Derbyshire was in tier three, while fellow Conservative and Derby North MP Amanda Solloway said though tier three restrictions in the city were ""not unexpected"", they were required ""to keep us all safe"".
The county's director of public health Dean Wallace said: ""We all want to celebrate Christmas safely so it is more important than ever that we all continue to do everything we can to protect our friends and family by sticking to the rules.""
Derbyshire County Council leader Barry Lewis said he was ""disappointed"" at the decision to place the county in tier three.
Mr Lewis, along with other council leaders, wrote to the prime minister on Wednesday urging him to consider placing Derbyshire in tier two in order to protect the economy, especially the hospitality and tourism sectors.
Following the announcement, he tweeted: ""Disappointed for our tourism, hospitality, retail sectors and others who will be economically impacted before Xmas.
""Epidemiology tells us we're in upper tier three and declining - in a few days we'd have been squarely tier two.""
A week before the second national lockdown began, Derby and most of Derbyshire were in tier two.
This is why Health Secretary Matt Hancock said people will be disappointed to find themselves in the top tier of restrictions.
His explanation for the move is that there have been improvements in the area but infection rates remain high and this is putting pressure on the local NHS.
Pauline Latham, Conservative MP for Mid Derbyshire, had previously spoken out against the new rules.
Speaking in the House of Commons on Wednesday, she described the tier system as ""illogical"" and said it would lead to job losses.
Last week Derby City Council said it was in discussions with the government about Derby Arena being used as a mass vaccination centre.
_Follow BBC East Midlands on_Facebook _,_Twitter _, or_Instagram _. Send your story ideas to_eastmidsnews@bbc.co.uk _._"
"**The four UK governments have announced their plans to enable families to celebrate Christmas together.**
So how is the festive period likely to be different this year?
The governments of England, Scotland, Wales and Northern Ireland have agreed a common approach allowing up to three households to form a Christmas bubble and meet up from 23 to 27 December (22 to 28 December in Northern Ireland).
People can mix in homes, places of worship and outdoor spaces, and travel restrictions will also be eased.
However, a Christmas bubble must be exclusive, so people cannot swap between them. Bubble members also will not be able to visit pubs or restaurants together.
There will be no limit to the number of people in a household joining a bubble in England, Wales and Northern Ireland.
But the Scottish government has said that Christmas bubbles should contain no more than eight people. Children under 12 will not count in the total.
Fears that a lack of skilled overseas workers on poultry farms could hit the supply of turkeys have been overcome after travel rules were relaxed so they could travel to the UK.
But many people are buying smaller turkeys than usual because they are likely to have fewer guests.
An Aberdeenshire farmer has warned many birds could go to waste, while a farm in Wales cut its turkey numbers by 20% in September.
Any turkey shortage may make some people consider a vegetarian or vegan meal instead.
This year's work celebrations seem certain to take place on Zoom and other online platforms.
Rules on big groups meeting up in pubs or anywhere outdoors are very unlikely to be eased in December, so seeing friends for a pre-Christmas drink or meal will probably not be allowed.
Current rules for socialising outside your household/support bubble/extended household are:
At the moment, it is not known what will happen about traditional Christmas religious services like midnight Mass.
From 2 December in **England,** places of worship will reopen for communal prayer.
Up to 50 people can attend indoor services in **Scotland** in levels zero to three areas, but only up to 20 in level four places.
Places of worship have reopened in **Wales,** but with social distancing in place and communal singing banned.
They are also open in **Northern Ireland with**no limit on numbers if safety measures are in place. Weddings, civil ceremonies and funerals can happen, but only 25 people. can attend
While in-person shopping in non-food shops can currently happen in all of the UK except England, online retailers are expecting a big surge in demand this year.
In September, shoppers were warned by an industry boss to buy as early as possible.
Andy Mulcahy, from the online businesses' industry body, told the BBC: ""At this point, I think we can expect an increase of at least 30% for the peak festive trading season, but if stores have to close this might push to 50%.""
In **England,**non-essential shops will reopen on 2 December. They are currently open in all of **Scotland**except level four areas, across Wales, and in Northern Ireland.
Last posting dates inside the UK range from 18 to 23 December, while we have already passed some international dates.
Theatres in **England** can reopen on 2 December, and plans have been made for some Christmas pantomimes.
While many venues and production companies have cancelled their shows, others are going ahead thanks to National Lottery backing.
One is at the London Palladium, where the Lottery will buy seats that cannot be used because of social distancing. It will also donate 20,000 free tickets to Lottery players.
Meanwhile a drive-in show - the Car Park Panto - will tour Great Britain with audience members watching from inside their cars.
Theatres in **Scotland** are closed in level two, three and four areas, throughout Wales, and to audiences in **Northern Ireland,** where they can open for rehearsals or a live recording.
The Christmas relaxation of meeting up rules does not extend to New Year's Eve, so that is likely to be a quiet affair this year, with house parties banned in most places.
Fireworks have been cancelled in London and Edinburgh's Hogmanay street party is off."
"
Guest post by Bob Tisdale
There are numerous blog posts and discussions about how the GISS global  temperature anomaly product GISTEMP differs from the Hadley Centre and  NCDC datasets.
The repeated reasons presented for this are, GISS uses  1200km radius smoothing to fill in the areas of the globe with sparse  surface temperature readings, and the area this has the greatest impact  is the Arctic. Typically, a map or comparison of global temperature  anomaly maps is included, similar to Figure 1. The top two maps were  cropped from Figure 3 in the Real  Climate post “2009  temperatures by Jim Hansen”. I added the third.
The bottom map was  created at the GISS Global  Maps webpage. It’s a map of the GISTEMP Global Temperature Anomaly  product with 250km radius smoothing for the calendar year 2005, the same  year as the top two maps. I did not include a temperature scale because  the bottom map was provided to allow a visual comparison of the spatial  coverage of the HadCRUT product and the GISTEMP product with 250km  radius smoothing. Examine the Arctic and the ocean surrounding  Antarctica, the Southern Ocean. Notice a difference? In 2005, the  HadCRUT data had better coverage of the Arctic and Southern Oceans than  the GISTEMP dataset with 250km radius smoothing. What’s missing in the  GISTEMP product? There’s no sea surface temperature data.
 http://i45.tinypic.com/htsgeq.jpg
Figure  1
GISS DELETES POLAR SEA SURFACE TEMPERATURE DATA
The  general regions where GISS deletes Sea Surface Temperature data are  shown in Figure 2. Three areas are highlighted: two cover the Arctic  Ocean, and a third surrounds Antarctica. The specific locations are  clarified in the following. GISS then uses their 1200km radius smoothing  to replace the sea surface data with land data.
 http://i48.tinypic.com/33adj86.jpg
Figure  2
Tilo Reber in his recent “Diverging  views” post at Watts Up With That? noted that  the GISS Current  Analysis webpage includes the following statement:
“Areas  covered occasionally by sea ice are masked using a time-independent  mask.”
This means that vast regions of Sea Surface  Temperature (SST) anomaly data in the Arctic Ocean and Southern Ocean  are deleted from the GISTEMP record. GISS does not delete all of the  Arctic and Southern Ocean SST anomaly data, just the data from the areas  where the annual sea ice melt occurs, and those are good portions of  them.
I have looked for but have not found an explanation for  this exclusion of Sea Surface Temperature data in the papers provided on  the GISTEMP  references page.
THE AREA OF THE ARCTIC OCEAN WHERE  GISS DELETES SST DATA

Figure 3 shows four Arctic (North  Pole Stereographic, 65N-90N) maps prepared using the map-making feature  of the KNMI Climate Explorer. The maps illustrate temperature anomalies  and sea ice cover for the month of September, 2005. The calendar year  2005 was chosen because it was used in the RealClimate post by Jim  Hansen, and September is shown because the minimum Arctic sea ice  coverage occurs then. The contour levels on the temperature maps were  established to reveal the Sea Surface Temperature anomalies. Cell (a)  shows the Sea Ice Cover using the Reynolds (OI.v2) Sea Ice Concentration  data.
The data for the Sea Ice Cover map has been scaled so that zero  sea ice is represented by grey. In the other cells, areas with no data  are represented by white. Cell (b) illustrates the SST anomalies  presented by the Reynolds (OI.v2) Sea Surface Temperature anomaly data.  GISS has used the Reynolds (OI.v2) SST data since December 1981. It’s  easy to see that SST anomaly data covers the vast majority of Arctic  Ocean basin, wherever the drop in sea ice permits. Most of the data in  these areas, however, are excluded by GISS in its GISTEMP product. This  can be seen in Cell (c), which shows the GISTEMP surface temperature  anomalies with 250km radius smoothing. The only SST anomaly data used by  GISS exists north of the North Atlantic and north of Scandinavia.
The  rest of the SST data has been deleted.
The colored cells that appear  over oceans (for example, north of Siberia and west of northwestern  Greenland) in Cell (c) are land surface data extending over the Arctic  Ocean by the GISS 250km radius smoothing. And provided as a reference,  Cell (d) presents the GISTEMP “combined” land plus sea surface  temperature anomalies with 1200km radius smoothing, which is the  standard global temperature anomaly product from GISS. Much of the  Arctic Ocean in Cell (d) is colored red, indicating temperature  anomalies greater than 1 deg C, while Cell (b) show considerably less  area with elevated Sea Surface Temperature anomalies.
 http://i46.tinypic.com/dpygcj.jpg
Figure  3
Basically, GISS excludes Arctic Ocean SST data from 65N to 90N  and, for round numbers, from 40E to 40W. This is a good portion of the  Arctic Ocean. Of course, the impact would be seasonal and would depend  on the seasonal drop in sea ice extent or cover. The sea ice extent or  cover has to decrease annually in order for sea surface temperature to  be measured.
I’ll use the above-listed coordinates for the examples that  follow, but keep in mind that they do not include areas of sea ice in  the Northern Hemisphere south of 65N where sea surface temperature data  are also deleted by GISS. These additional areas are highlighted in  Figure 4. They include the Bering Sea, Hudson Bay, Baffin Bay and the  Davis Strait between Greenland and Canada, and the Sea of Okhotsk to the  southwest of the Kamchatka Peninsula.
http://i50.tinypic.com/28j9u6u.jpg
Figure  4
Note: GISS uses Hadley Centre HADISST data as its source of  Sea Surface Temperature (SST) data from January 1880 to November 1981  and NCDC Reynolds (OI.v2) data from December 1981 to present. To  eliminate the need to switch between or merge SST datasets, this post  only examines the period from 1982 to present. And to assure the  graphics presented in Figures 3 and 6 are not biased by differences in  base years of the GISTEMP data and the Reynolds (OI.v2) SST data, the  latter of which has only been available since November 1981, I’ve used  the period of 1982 to 2009 as base years for all anomaly data.
WHY  WOULD DELETING SEA SURFACE TEMPEATURE DATA AND REPLACING IT WITH LAND  SURFACE DATA BE IMPORTANT?

Land Surface Temperature  variations are much greater than Sea Surface Temperature variations.  Refer to Figure 5. Since January 1982, the trend in GISTEMP Arctic Land  Surface Temperature Anomalies (65N-90N, 40E-40W) with 250km radius  smoothing is approximately 8 times higher than the Sea Surface  Temperature anomaly trend for the same area.
The Arctic Ocean SST  anomaly linear trend is 0.082 deg C/ decade, while the linear trend for  the land surface temperature anomalies is 0.68 deg C/decade. And as a  reference, the “combined” GISTEMP Arctic temperature anomaly trend for  that area is 9 times the SST anomaly trend.
 http://i46.tinypic.com/1zpheme.jpg
Figure  5
By deleting the Sea Surface Temperature anomaly data, GISS  relies on the dataset with the greater month-to-month variation and the  much higher temperature anomaly trend for its depictions of Arctic  temperature anomalies. This obviously biases the Arctic “combined”  temperature anomalies in this area.
GISS DELETES SEA  SURFACE TEMPERATURE DATA IN THE SOUTHERN HEMISPHERE, TOO
Figure  6 shows four maps of Antarctica and the Southern Ocean (South Pole  Stereographic, 90S-60S). It is similar to Figure 8. Cell (b) illustrates  the SST anomalies presented by the Reynolds (OI.v2) Sea Surface  Temperature anomaly data. SST anomaly data covers most of the Southern  Ocean, but GISS deletes a substantial portion of it, as shown in Cell  (c). The only SST anomaly data exists toward some northern portions of  the Southern Ocean. These are areas not “covered occasionally by sea  ice”.
 http://i50.tinypic.com/aensly.jpg
Figure  6
Figure 7 illustrates the following temperature anomalies for  the latitude band from 75S-60S:
-Sea Surface Temperature, and
-Land  Surface temperature of the GISTEMP product with 250km radius smoothing,  and
-Combined Land and Sea Surface of the GISTEMP product with  1200km radius smoothing, the GISTEMP standard product.
The  variability of the Antarctic land surface temperature anomaly data is  much greater than the Southern Ocean sea surface temperature data. The  linear trend of the sea surface temperature anomalies are negative while  the land surface temperature data has a significant positive trend, so  deleting the major portions of the Southern Ocean sea surface  temperature data as shown in Cell (c) of Figure 6 and replacing it with  land surface temperature data raises temperature anomalies for the  region during periods of sea ice melt.
Note that the combined GISTEMP  product has a lower trend than the land only data. Part of this decrease  in trend results because the latitude band used in this comparison  still includes portions of sea surface temperature data that is not  excluded by GISS (because it doesn’t change to sea ice in those areas).
 http://i45.tinypic.com/im6q29.jpg
Figure  7
ZONAL MEAN GRAPHS REINFORCE THE REASON FOR THE GISS  DIVERGENCE
When you create a map at the GISS Global Maps webpage,  two graphics appear. The top one is the map, examples of which are  illustrated in Figure 1, and the bottom is a Zonal Mean graph. The Zonal  Mean graph presents the average temperature anomalies for latitudes,  starting near the South Pole at 89S and ending near the North Pole at  89N. Figure 8 is a sample. It illustrates the changes (rises and falls)  in Zonal Mean temperature anomalies from 1982 to 2009 of the GISTEMP  combined land and sea surface temperature product with 1200km radius  smoothing. The greatest change in the zonal mean temperature anomalies  occurs at the North Pole, the Arctic. This is caused by a phenomenon  called Polar Amplification.
 
http://i48.tinypic.com/spd4li.jpg
Figure  8
To produce a graph similar to the GISS plot of the changes in  Zonal Mean Temperature Anomalies, I determined the linear trends of the  GISTEMP combined product (1200km radius smoothing) in 5 degree latitude  increments from 90S-90N, for the years 1982 to 2009, then multiplied the  decadal trends by 2.8 decades. I repeated the process for HADCRUT data.  Refer to Figure 9.
The two datasets are similar between the latitudes  of 50S-50N, but then diverge toward the poles. As noted numerous times  in this post, GISS deletes sea surface temperature data at higher  latitudes (poleward of approximately 50S and 50N), and replaces it with  land surface data.
 http://i47.tinypic.com/2uzfc6r.jpg
Figure  9
Figure 10 shows the differences between the changes in GISTEMP  and HADCRUT Zonal Mean Temperature Anomalies. This better illustrates  the divergence at latitudes where GISS deletes Sea Surface Temperature  data and replaces it with land surface temperature anomaly data, that  latter of which naturally has higher linear trends during this period.
 http://i45.tinypic.com/xnsp40.jpg
Figure  10
SOURCE

Maps and data of sea ice cover  and temperature anomalies are available through the KNMI Climate  Explorer:
http://climexp.knmi.nl/selectfield_obs.cgi?someone@somewhere


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b14f7c9',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterSebastian Lüning recently wrote a piece on a new study by a French team of scientists.  Conclusion: Mediterranean storm activity decreases during warm periods and there appears to be a solar link.
==========================================
The worst storms at the French Mediterranean coast? Always when the sun was weak and temperatures declined!
By Daniel Albig and Sebastian Lüning
(Translated by P Gosselin with permission)
The area of the Mediterranean Sea is regarded as a region that reacts especially sensitively to climate fluctuations. An increase in temperature there would be especially noticeable, say certain model projections. In 2007 some scientists even prophesied that there would soon be a danger of cyclones forming at the Mediterranean. But what does the pre-industrial climate history tell us about this possibility? Is there really a relationship between storm activity and temperature in the Mediterranean region?
A French team of scientists led by geologist Pierre Sabatier studied in detail how storms and global warming behaved historically in the region. In a study that appeared in January 2012 in the journal Quaternary Research, they examined the last 7000 years. The basis for their study was an 8-meter long sediment core that had been extracted in March, 2006 from the seabed of the Pierre Blanche Lagoon of the southern French Golf of Lion, about 10 kilometers south of Montpelier.
The scientists studied changes in the deposits in the lagoon, which today are covered by 60 cm of water. Changes in storm patterns in the region can be discerned by the variations in the particle size of the sand, the clay composition and fossils present. The frequency of the various species of water snails were analyzed. For example the hydrobia acuta lives in the brackish waters, the bittium reticulatum lives in the open seas. A sudden increase in deposits of the needle whelk indicates greater storm activity because the lagoon gets flooded more often by the sea.
Using various indicators, the French scientists identified seven periods of increased solar activity: 6300-6100 years ago, 5650-5400 years ago, 4400-4050 years ago, 3650-3200 years ago, 2800-2600 years ago, 1950-1400 years ago and 400-50 years ago. Storm activity increased over and over again over the last few thousands of years, and settled down during the times in between.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So what could have triggered storm activity at the French Mediterranean? In the search for possible relationships, the French scientists compared storm development with the temperature development of the North Atlantic, which was reconstructed more than 10 years ago by a team led by Gerard Bond who examined cores of ice berg rafted sediment and published the results in the journal Science. The Bond group could show that the temperature cycles were in sync with solar activity.
And what did this comparison yield? Storms in the Northwest Mediterranean occurred more often during the cold periods. Solar activity played an important role: Whenever the sun weakened, it became cold and stormy. When the sun got active, temperatures increased and the winds died down (Figure 1). The main drivers were obviously the solar Bond cycles. Also added are some solar-dependent, climate-system-internal fluctuations which complete the picture.
How could the relationship function? The scientists suspect that a stark north-south temperature gradient prevailed during the cold periods and thus resulted in more storms. In addition the westerly winds could have shifted southwards.
If you look back at the last 1000 years, the natural pattern becomes clear. During the Medieval Warm Period (1150 to 650 years ago) the new research results show that a period of weak storm activity prevailed. During the Little Ice Age that followed, tempestuous storms raged over the area of study. During the transition to the current Modern Warm Period the storms died down. The good news: An increase in storm activity is not anticipated, at least for the south French coast, with further warming of the Earth. Instead a decrease in storm activity is expected.
Interestingly, the relationship is not only valid for the Mediterranean region. Already in February 2012 we reported on a study from the Netherlands. That study showed that the strongest storms occurred during the Little Ice Age (read: Die kräftigsten Stürme gab es in Holland während der Kleinen Eiszeit).
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe recent long-term forecasts for Europe show we most likely aren’t going to be escaping winter this year. Over the last week or so, the forecasts couldn’t seem to make up their minds, would it be cold or not cold?

Source: http://wxmaps.org/pix/temp4.html
One day the forecast showed cold on the way, and the next day the charts would be revised and showed mild weather in the pipeline.
But over the last few days, the signs have all been converging and showing that cold is on the way from Russia. Europe this year may get a hard winter after all – it may be just arriving late. The bottom chart for Europe shows the anomaly for the coming week. The middle chart shows the forecast for the week after. It’s going to get even colder. We’ll see how it pans out.
Asia is already freezing to death!
Below if you click on the charts for Asia, you see that cold is the story of the day. In fact it’s rare to see that much cold over such a vast continent.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Source: http://wxmaps.org/pix/temp11.html
The lower chart of central Asia shows below normal temps are forecast for almost every region for the coming week, and the middle chart shows even deeper cold for the week after, as we saw is the case for Europe.
Hansen ought to put his red crayons away and grab for blue or purple ones.
Charts for…
Central Asia: http://wxmaps.org/pix/temp11.html
East Asia: http://wxmaps.org/pix/temp5.html
South Asia: http://wxmaps.org/pix/temp6.html
North America: http://wxmaps.org/pix/temp2.html
Australia: http://wxmaps.org/pix/temp7.html
Africa: http://wxmaps.org/pix/temp10.html
Middle East: http://wxmaps.org/pix/temp9.html
South America: http://wxmaps.org/pix/temp8.html
Look at Asia and South America! See all the global warming?
Yet the kooks say it’s still too warm!
Remember that for the climate dummies, like Hansen, NOAA, and a host of others, this is still dangerously too warm. Temperatures are supposed to be a lot lower in order for the Earth to be normal and for life on it to be safe.
Yeah right! Go tell that to the billions of folks In Europe, Asia, Middle East and South America who are now struggling to stay warm.
Share this...FacebookTwitter "
"**The Democratic mayor of the US city of Denver has apologised after breaking his own Thanksgiving travel advice.**
In a message posted to Twitter early on Wednesday, Michael Hancock urged residents to ""host virtual gatherings"" and ""avoid travel, if you can"".
Just hours later, however, it emerged he had travelled to Mississippi to join his wife and daughter for the holiday.
""I apologize to the residents of Denver who see my decision as conflicting with the guidance,"" he responded.
Millions of Americans are travelling home to celebrate Thanksgiving this Thursday, despite warnings from health officials amid a significant wave of coronavirus cases and deaths.
The US has recorded more than 12.7 million infections and 262,000 deaths since the pandemic began.
Acknowledging his decision on Twitter, Mr Hancock said that his wife and daughter were in Mississippi and he ""decided it would be safer for me to travel to see them than to have two family members travel back to Denver"" for the holiday.
""I recognize that my decision has disappointed many who believe it would have been better to spend Thanksgiving alone,"" the mayor wrote on Twitter.
""I made my decision as a husband and father, and for those who are angry and disappointed, I humbly ask you to forgive decisions that are borne of my heart and not my head.""
Mr Hancock is not the only US official to be caught breaking coronavirus guidance.
Andrew Cuomo, the governor of New York, has been forced to cancel his own Thanksgiving plans after saying in an interview that he planned to host his 89-year-old mother and his two adult daughters for dinner.
Californian Governor Gavin Newsom, meanwhile, recently faced controversy after he was pictured dining indoors at a restaurant with people from other households."
nan
nan
"
I’m remiss in getting this up until now, as Leif sent it back on May 12th. Prep, travel and recovery for ICCC4 took up quite a bit of my time, but I’m pleased to be able to offer this from Dr. Svalgaard now.

Cartoon from community.acs.org
Dr. Svalgaard writes:
Back in October WUWT had an article about my paper ‘Heliomagnetic Magnetic  Field 1835-2009‘.
The paper has now gone through extensive peer review. I  promised to let people in on the review process and can now do that. They contain a mixture of arcane  technical points and general whining. The review history may be of  general interest, at least as far the ‘flavor’ and tone of the reviews  are concerned.
The entire review is condensed into a PDF file, which can be viewed below:
Leif_IDV09-Review-History


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ba7f40a',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Most of the West Midlands will be under the toughest Covid-19 restrictions when the region comes out of England's second lockdown on 2 December.**
The region will enter tier three - the highest alert level - in Birmingham and the Black Country, Solihull, Coventry, Warwickshire, Stoke-on-Trent and Staffordshire.
It is the first time local areas must obey the tier system's stiffest rules.
Tier three measures include a ban on households mixing indoors.
Worcestershire, Herefordshire, Shropshire and Telford and Wrekin are set to enter tier two where restrictions are slightly more relaxed.
Nowhere in the region will face the lowest level of restrictions, tier one.
It means all local areas have moved up one level compared to their status before the second lockdown, with Warwickshire leaping from tier one to three.
The government says it will review the tier allocations on 16 December, although there will be a UK-wide relaxation of rules for five days over Christmas.
England's first tier system was brought in this autumn to curb a second wave of coronavirus, but it was replaced with a four-week national lockdown from 5 November that applied stiff and uniform measures across the country.
But the nationwide approach will make way for varied restrictions again from 2 December under new tiers.
Differences between the new tiers include restrictions on where households can meet up:
Pubs and restaurants in tier two can only open to serve ""substantial meals"", while those in tier three can only operate as a takeaway or delivery service.
Gyms and close-contact beauty services like hairdressers will be able to open in all tiers.
Guidance says people in all tiers who can work from home, should continue to do so.
Health Secretary Matt Hancock used a government webpage to outline his reasoning for each area's status.
Warwickshire, where restrictions have jumped from tier one to tier three, is listed as part of a group with Coventry and Solihull, which were previously both in tier two.
Mr Hancock says high yet falling infection rates and pressure on the local NHS are behind the grouping's tier three status.
But Izzi Seccombe, Conservative leader of Warwickshire County Council, said the news came as a shock, and queried the method used and whether one of the trio had skewed the outcome for the others.
She said: ""I'm going to be asking about the validity of the rates that they've put us in.
""Coventry and Warwickshire are nip and tuck on the rates and right at this moment Coventry is slightly lower than Warwickshire. Solihull is higher, and we're in a grouping, a regional grouping together, so I will be checking with government about whether the evidence that they have used is fair and is reasonable.""
Ms Seccombe also raised fears the measures would impact on the local hospitality sector - concerns echoed by businesses.
Among them was the Royal Shakespeare Company (RSC) based in Stratford-upon-Avon.
""We are deeply disappointed by the news that [Warwickshire] has moved to tier three Covid restrictions,"" said executive director Catherine Mallyon.
She said the RSC had planned to welcome back audiences for the first time since March to events set for 19 and 20 December, but they would now be streamed online instead.
Ms Mallyon added: ""The announcement today means further difficulties and hardship to theatres and freelance colleagues around the country on top of those already faced over the last eight months.""
For Alcester-based Hillers Farm Shop and Restaurant there is an unusual frustration.
The Warwickshire venue is set to enter tier three restrictions, forcing its restaurant to close, while businesses over the road go into tier two - because they fall under Worcestershire.
Director Emma Taylor said she had been preparing for the venue's reopening, expecting her part of rural Warwickshire to be tier two at the worst.
She said she had to respect the situation and hoped something would change when the tiers were reviewed.
Meanwhile, a businessman behind a luxury boutique hotel set to open in Coventry on 4 December said the city's move to tier three was ""just devastating"".
Ian Harrabin, director of Complex Projects, said: ""It's just hard to understand the logic - and it's the wrong move from the government.""
A pop-up experience at the hotel's rooftop bar was planned for the launch. Mr Harrabin said: ""We had over 400 bookings for our rooftop experience, and it doesn't make sense you can't sit outside yet you can go into a gym - where's the logic in that? We're just gutted.""
_Follow BBC West Midlands on_Facebook _, on_Twitter _, and_sign up for local news updates direct to your phone _._"
"

Nuclear energy is to the Right what solar energy is to the Left: Religious devotion in practice, a wonderful technology in theory, but an economic white elephant in fact (some crossovers on both sides notwithstanding). When the day comes that the electricity from solar or nuclear power plants is worth more than the costs associated with generating it, I will be as happy as the next Greenpeace member (in the case of the former) or MIT graduate (in the case of the latter) to support either technology. But that day is not on the horizon and government policies can’t accelerate the economic clock. 



Many free market advocates support nuclear because it costs less to generate nuclear power than it does to generate electricity from any other source (save, perhaps, hydroelectric power), thanks to nuclear’s low operation and maintenance costs. However, someone has to first pay for‐​and build‐​these plants and the rub is that nuclear has very high, upfront construction costs ranging from $6–9 billion. By contrast, gas plants cost only a few hundred million dollars to build and coal a couple of billion depending upon the capacity and type of plant.



This raises the opportunity and risk costs of nuclear, making it unattractive to investors. Capital‐​intensive power facilities take longer to build, which means that investors have to defer returns for longer than if they had invested elsewhere. What’s more, electricity markets have a very peculiar pricing mechanism that makes it harder for nuclear to maximize returns compared to gas‐​powered or other plants. In essence, there are two electricity markets: a market for base‐​load power (electricity sold 24‐​hours a day) and a market for peak power (electricity sold as needed during peak demand periods like hot summer days). Much of the demand for new power‐​and thus much of the profit available to investors today‐​is found in the peak market. But nuclear power plant construction costs are so high that it would take a very, very long time for nuclear facilities to pay for themselves if they only operated during high demand periods. Hence, nuclear power plants are only profitable in base‐​load markets. Gas‐​fired power plants, on the other hand, can be profitable in either market because not only are their upfront costs low but it is much easier to turn them off or on unlike nuclear.



Nuclear’s high up‐​front costs don’t just mean delayed profits, it also makes nuclear a more risky investment, especially since 20 states have scrapped policies that used to allow investors to charge rates that would guarantee their money back. This means that investors in new nuclear power plants are making a multi‐​billion dollar bet on disciplined construction schedules, accurate cost estimates, and the future economic health of the region. Bet wrong on any of the above and the company may well go bankrupt. Bet wrong on a gas‐​fired power plant, on the other hand, and corporate life will go on because there is less to lose given that the construction costs associated with gas‐​fired power plants are a small fraction of those associated with nuclear plants.



One metric that reflects this difference is the “levelized” cost‐​the price that must be received by owners to cover fixed and variable costs while returning profits to investors. This cost is substantially higher for nuclear than coal‐​fired electricity. Tufts economist Gilbert Metcalf, for instance, has calculated that, under current law, the levelized cost of nuclear power in the United States is 4.31¢ per kilowatt hour (kWh). Coal‐​fired electricity, on the other hand, cost 3.53¢ per kWh and “clean” coal cost 3.55¢.



But even these nuclear estimates are almost certainly too low. That’s because Metcalf uses an “overnight cost” (construction costs minus financing costs) figure of $2,014 per installed kilowatt (kW) which is much too low. The Energy Information Administration (EIA) puts this cost at $2,475 per kW at present‐​although even this figure is suspicious because it relies on a world‐​wide average for nuclear power plant construction‐​including the grossly unreliable estimates from state‐​managed economies. The Standard & Poor’s overnight cost estimate of $4,000 is likely the most reliable because it is based on nuclear plant construction costs in economies where labor and material costs are very similar to those found in the United States. Industry analyst Jim Harding, who uses overnight cost figures similar to Standard & Poor’s, puts the levelized costs for new nuclear power generation at 12–15c per kWh right now.



Investors are also wary of nuclear plants because of the construction delays and cost over‐​runs that have historically plagued the industry. For instance, the Areva/​Siemens nuclear power plant being built for TVO in Finland‐​the first nuclear power plant to be built in a relatively free energy market in decades‐​once scheduled to be operational within 54 months, is now two years behind schedule and 60% over budget. Nor have these construction delays had anything to do with regulatory obstruction or organized public opposition.



If nuclear power plants are so uneconomical, how then to explain the blizzard of permit applications for the construction and operation of new nuclear power plants that the Nuclear Regulatory Commission has received? Easy: These applications cost little and oblige utilities to do nothing. Industry analysts maintain that federal approvals will not translate into actual plants without a federal promise to private equity markets that, in case of default by power plants, the taxpayer will make good on the full sum of all bad nuclear loans.



Nuclear supporters often counter that construction costs would be a lot lower if regulators didn’t impose insanely demanding safety standards, byzantine and time‐​consuming permitting processes, or endless public hearings, any one of which could result in the plant being stopped in its tracks. Investors would also be more likely to invest, we’re told, if there were a high‐​level waste repository in place or more political support for nuclear power.





[H]ow do France, India, China, and Russia build cost‐​effective nuclear power plants? They don’t.



I would love to tell that story. I do, after all, work at the Cato Institute, and blaming government for economic problems is what keeps me in business. But what stops me is the fact that those complaints are not echoed by the nuclear power industry itself.



On the contrary, the industry in the early 1990s asked for‐​and got‐​exactly the sort of safety regulations, permit review process, and public comment regime now in place. Both public and political support for nuclear power is running so high than even a majority of Democrats in Congress are happy to not just tolerate nuclear power, but lavish even more subsidies upon it. And while Yucca Mountain may not be open now or ever, everyone seems reasonably content with the current on‐​site waste storage regime.



Indeed, if government were the reason why investors were saying “no” to their loan applications, I would expect that industry officials would be the first to say so. But they do not.



There’s another good reason why the industry is not protesting government intervention these days‐​the industry would not exist without it. Take away the 1.8¢ per kWh production tax credit available to the first 6,000 megawatts of new nuclear generation built prior to 2021, for instance, and Metcalf calculates that the levelized cost of new nuclear power plants jumps by 30 percent. Replace accelerated depreciation tax rules with regular depreciation rules and costs jump another 9 percent. Even zero taxation on nuclear power would increase costs by 6 percent because right now nuclear power enjoys a negative effective tax rate. Indeed, this jump by itself would make nuclear much more expensive than conventional coal, “clean” coal, and natural gas. Finally, repealing the $18 billion in federal loan guarantees recently promised the industry and eliminating regulations that relieve nuclear plant owners of the responsibility to pay third‐​parties to accept the risks associated with waste disposal would dampen market interest in nuclear power even further.



But the final nail in the coffin for the industry would be if the federal cap on the liability that nuclear power plant owners face in case of accidents (the Price‐​Anderson Act) were to be lifted.



Given all of this, how do France, India, China, and Russia build cost‐​effective nuclear power plants? They don’t. Government officials in those countries, not private investors, decide what is built. Either these governments build expensive plants and shove them down the market’s throat‐​or they build shoddy plants and hope for the best.



Conservatives project nuclear power as the solution to greenhouse gas emissions. But they should resist that argument. If we slapped a carbon tax on the economy to “internalize” the costs associated with greenhouse gas emissions‐​the ideal way to address emissions if we find such policies necessary‐​then the “right” carbon tax would likely be about $2 per ton of emissions according to a survey of the academic literature by climate economist Richard Tol. That’s not enough to make nuclear energy competitive against coal or natural gas according to calculations performed by the Electric Power Research Institute. In any case, if nuclear offers a cost‐​effective way to reduce greenhouse gas emissions, it should have to prove it by competing against alternatives in some future carbon‐​constrained market.



There’s nothing new about today’s rhetoric about the supposed “nuclear renaissance.” Back in 1954, GE maintained: “In five years‐​certainly within 10‐​a number of them (nuclear plants) will be operating at about the same cost as those using coal. They will be privately financed, built without government subsidy.” Now, 54 years later, the talk of “renaissance” is back‐​as are promises about the imminent economic competitiveness of nuclear.



Those who favor nuclear power should adopt a policy of tough love. Getting this industry off the government dole would finally force it to innovate or die‐​at least in the United States. Welfare, after all, breeds sloth in both individual and corporate recipients. The Left’s distrust of nuclear power is not a sufficient rationale for the Right’s embrace of the same.
"
"**Nearly 40 people were handed fines after police raided a party at a student accommodation block in Nottingham.**
Officers said they were called to the gathering in Union Road by security staff at about 22:50 GMT on Tuesday.
Several revellers had tried to hide in a kitchen to avoid being found by officers, Nottinghamshire Police said.
The party's organiser, a 19-year-old woman, is now facing a possible fine of up to Â£10,000.
Penalties were handed out to 37 other guests.
Insp Paul Gummer said: ""At a time when the whole country's in a second lockdown and people are following the rules in the hope of being able to see their family at Christmas, it's really selfish that people are still having these big parties.""
A Nottingham Trent University spokesperson said: ""We are working with Nottinghamshire Police to investigate this as a matter of urgency and our internal disciplinary processes have already begun.""
Earlier this month, Nottinghamshire's chief constable called for students who broke Covid-19 rules to be expelled.
_Follow BBC East Midlands on_Facebook _,_Twitter _, or_Instagram _. Send your story ideas to_eastmidsnews@bbc.co.uk _._"
"
Share this...FacebookTwitterBy Ed Caryl
SH shows no warming!
In A Recent Temperature History, Part 1, the temperature trends for the contiguous United States were examined. In part 2, the rest of the world (as far as there is data) will be explored. Again, the selection criteria were: less than 10,000 population, and (as much as possible) a continuous record from 1940 or before to the present.
Ten stations were found in the Arctic and Siberia, six stations bordering the North Atlantic Ocean, and thirteen stations in the southern hemisphere, in South American, Australia, the south Atlantic, and south Pacific. All of these stations are well away from any population centers and are isolated or in or associated with very small towns and villages. No stations were found in continental Europe or Africa that met the above criteria. Station records at GISS either ceased in 1990, had a large gap during WWII, or both.

Figure 1. These are Arctic and Siberian temperature anomalies using 1930 to 1980 as the baseline period. The bold black trace is the average of these ten anomalies.
In the Arctic and Siberia we see the familiar pattern of warming in the first half of the 20th century, followed by cooling until 1970, then warming until recently.

Figure 2: The Arctic and Siberia average anomaly and a linear trend line from 1930 to the present. The trend is +0.33° C over the 80 years, or about 0.4° C per century.
The problem with the trend in Figure 2 is that it includes part of the earlier warming trend and only one cooling period. In Figure 3, the 66-year complete cycle is chosen, and there is no trend.

Figure 3. The Arctic and Siberian trend over the period 1943 to 2000.
The North Atlantic shows the same shape as the other Northern Hemisphere records.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 4. There are six North Atlantic temperature anomalies. The bold black trace is the average of the six stations. Before 1900, only the Akureyi station on Iceland was active.

Figure 5. This is the North Atlantic average anomaly and the linear trend from 1930 to the present. The trend from the mid 1930’s to the present is flat.
In the northern hemisphere the temperature trend is a cycle, roughly paralleling the Atlantic Multi-decadal Oscillation (AMO), and the Pacific Decadal Oscillation (PDO). Between the cycles of that oscillation, there is no trend. There may have been a trend in the 19th century of warming from the LIA, but that is now over.
The Southern Hemisphere
There are few stations in the Southern Hemisphere that meet the criteria for admission into this exclusive club. South Africa has none. Australia has three, two at airports, but not large airports. South America has four stations, the rest are on islands in the Pacific, and there is one in the South Atlantic. There were no stations in Antarctica before 1955. Most stations in Antarctica were established during the International Geophysical Year from July 1, 1957, to December 31, 1958. Still, there are five stations in the southern hemisphere that go back to the turn of the 20th century.

Figure 6. There are 13 Southern Hemisphere stations with long records. The baseline for these anomalies is, again, 1930 to 1980. The bold trace is the average anomaly.
In Figure 6, the Argentine Base Orcada on the South Orkney Islands in the South Atlantic provides much of the noise.

Figure 7: This is the Southern Hemisphere average anomaly with the linear trend line.
The notable thing about the southern hemisphere trend is that there isn’t any trend. The eye tries to detect a pattern of cooling early and a slight warming since 1930, but it would be about 0.1° C. If real, this may be half of the 200-year cycle discussed in the Lui et al paper, and here. But it might be urban warming creeping into the data. Some of the positive peaks coincide with major El Nino years, particularly 1891, 1982-83, 1997-98, and 2010. Over the last 50 years, continental Antarctica itself seems to be cooling slightly. See A Wind in Antarctica.
In the beginning, the exercise described in this two-part article was an attempt to tease out an accurate measure of global warming in order to determine CO2 sensitivity, the amount of warming we would experience if CO2 were to double. During the 20th century, CO2 in the atmosphere has increased from about 280 parts per million (ppm) to 390 ppm. This is about 40% of doubling. If doubling the CO2 in the atmosphere were to cause appreciable warming, we should see a measurable amount now. The climate sensitivity can be calculated from that amount. That number has now been found.
It’s zero.
Share this...FacebookTwitter "
"Next up on the global development agenda: the UN’s Sustainable Development Goals (SGDs). The UN hopes the goals will form a framework of rules and ideals that can influence development plans and actions around the world. Yet the idea of “culture” in development was largely absent from the Millennium Development Goals that the SDGs will replace and, judging by the “Zero Draft”, the same mistake is about to be made again. It’s not for want of talking – a growing consensus calls for culture to be included in the SDGs. The UN secretary-general, Ban Ki-moon, stressed that “culture is at the top of this agenda”, echoing the heads of UNESCO and the UN’s development programme and various civil society organisations. The UN has even hosted a debate on culture and sustainable development. So plenty of talk about culture. But there is little room – and, it seems, little time – to build a solid evidence-based argument. Such evidence does exist, including a range of studies and reports on the subject – and academics from across the world have grouped together to investigate cultural sustainability. However the big UN discussions tend to ignore the evidence around culture. And in any case “culture” is difficult to reduce to a handful of indicators in the same way that infant mortality is a good indicator of health, or female workforce participation is a useful proxy for gender equality – not that this has stopped UNESCO from trying to develop a set of cultural development indicators.  That is why we point out here how culture can contribute to sustainable development processes in at least three ways.  First, cultural expressions can provide a way to articulate voices and ideas to reconsider the transition from unsustainable to sustainable patterns of living. NYU anthropologist Arjun Appadurai calls this the “capacity to aspire”.  In Canada, this has been made explicit. Integrated community sustainability plans outline a broad and long-term strategic vision for towns and villages – one that includes culture. Hundreds of communities have incorporated their cultural aspirations into the official vision for their future development. Furthermore, cultural expressions – from storytelling to photography – have been used to help articulate and share these visions. They also develop new narratives about local culturally resonant pathways toward greater local sustainability and resiliency. Second, cultural “ways of life” form the basis of how people interact. A community won’t be able to successfully transition to a more sustainable lifestyle without taking the particularity of these practices is taken into account. This argument builds on decades of development anthropology, where the bottom line is that ways of living matter in approaches to change.  Take the city of Auckland. New Zealand’s largest urban area is surrounded by harbours and bays and is particularly vulnerable to water pollution. A project called Fluid City brought together artists, scientists, indigenous understandings and personal storytelling. This, to encourage visitors to see water as far more than a physical resource or commodity and to see themselves as “water-dependent citizens”. Anti-pollution laws or shipping regulations on shipping are important, but this form of cultural change goes right to the roots of Auckland’s environmental issues. Thirdly, culture also forms the basis of the creative industries. This is the bottom line of the creative economy debate brought together by UN agencies. UNCTAD argues that these industries are a feasible development option. And UNESCO stresses that they help widen development pathways.  The cultural industries are, for example, a key pillar of the sustainable development plan of Burkina Faso as crafts and culture contribute to tourism. In fact, the country has developed a range of internationally respected public and private cultural events (such as FESPACO, SIAO and Rendez-vous Chez Nous). These, as well as the promotion of heritage sites (such as the Opera Village and the sculpture park at Laongo and the Ruins of Loropeni) attract tourists and domestic visitors and bring in foreign currency into the country.  The challenge with this approach is that the role of culture is often reduced to the cultural industries alone, while its potential for sustainable development depends on combining it with recognising culturally resonant aspirations and lifestyle changes. UNESCO seems to recognise this – its world forum on October 2-4 explicitly focuses on both culture and cultural industries. Culture certainly does not provide a magic solution to persistent development challenges. But precisely because sustainable development is about the future we want, we should pay far more attention to the cultural “capacity to aspire”, the transformational potential of societies – and the books, movies and programmes that articulate visions of sustainable justice. The current sustainable development goals try to incorporate a huge number of issues and perspectives into a global agenda to change how we act. This is both its strongest point and its weakest point.  It is strong because the SDGs are more inclusive, balanced and holistic than previous attempts to set such a framework. It is, however, also weak precisely because it may include too much. And, like all complex policy agendas, it risks collapsing under its own weight. This is why culture cannot simply be an addition to the goals – sustainable culture change must be a goal itself. Culture in all its facets is a reminder that as much as we need a joint global agenda, we also need to show sensibility to the different ideas, life worlds, and creative expressions addressed above that give form to the kind of transformations that are not only necessary, but also possible."
"

I've been reading a lot of coverage of the FISA debate this week. I'm getting a little tired of reading commentary from supporters of eliminating judicial oversight who seem to have no clue what they're talking about. Consider this from _FrontPageMag_ 's Jacob Laksin: 



Instead of enjoying the flexibility necessary for real-time intelligence gathering, government officials would be forced to revert to the antiquated standards of the Foreign Intelligence Surveillance Act (FISA), which requires the approval of a special court even to monitor terrorist targets overseas.



In the first place, FISA has been updated repeatedly since the September 11, 2001, so the idea that it's ""antiquated"" is silly. Don't listen to me, listen to the president: ""The new law [in 2001] recognizes the realities and dangers posed by the modern terrorist. It will help us to prosecute terrorist organizations — and also to detect them before they strike.""   
  
In the second place, FISA does not, and never has, required a warrant to eavesdrop on foreign communications. FISA only comes into play when intercepting communications between foreigners and Americans, or when conducting surveillance entirely within the United States.   
  
Laksin continues: 



One of the signal virtues of the PAA is the fact that it provides liability protection to private companies, like telecoms, who cooperate with the government and aid surveillance efforts. Companies like AT&T already face multibillion dollar lawsuits from leftist activist groups like the Electronic Frontier Foundation, who charge that the companies broke the law by assisting government efforts to prevent terrorist attack. With the expiration of the PAA, these companies will lose their legal protections. In the current litigious climate, it is more than likely that they will simply stop aiding the government in its intelligence work.



The Protect America Act, which was passed last August, did not include retroactive immunity. That's why there are pending lawsuits against the telecom companies from those ""leftist activist groups."" The PAA _does_ include liability protection for firms that cooperate after the law takes effect, and those provisions will expire on Saturday. However, the idea that this will cause telecom companies to stop ""cooperating"" is absurd. Telecom companies cooperate with eavesdropping not out of the goodness of their heart, but because (once the executive branch has gotten the appropriate warrant) they're legally required to do so. That will continue to be true after the PAA expires. And in any event, the law is pretty clear on this subject. The only ""liability protection"" they really need is to follow it.   




And on we go: 



To be sure, the version of the PAA bill that passed the Senate is far from perfect. For one thing, the bill vastly expands the role of the FISA court in surveillance work, a prospect that should alarm anyone concerned about intelligence agents’ ability to respond rapidly to potential threats.



I'm not sure what he's referring to. It's true that the Senate legislation would require the executive branch to file various reports with the FISA court. But given that it simultaneously eviscerates the requirement to get a FISA warrant for foreign-to-domestic communications, I don't see how it could plausibly be considered an expansion of the FISA court's role. And these reporting requirements _certainly_ wouldn't degrade agents' ability to respond rapidly to potential threats because it gives the government several days after the fact to submit the appropriate reports. Probably the most stringent requirement in the Senate bill is the one requiring the attorney general to send a copy of each ""certification"" he signs to the FISA court within five days. Running off a copy of an order and sending a courier over to drop it off hardly seems like an intolerable burden.   
  
I could go on, but you get the point. The problem is that most readers have neither the time nor the patience to research these issues in any detail. So when conservative pundits make misleading claims, a lot of readers can't tell the difference. It's very frustrating for those of us who are actually familiar with the underlying facts.   
  
(Cross-posted at The Technology Liberation Front)


"
"The economic rescue packages to deal with the impact of the coronavirus must also be green, a growing chorus of environmental campaigners have urged, concerned that hasty measures will lock the world into a high-carbon future. “Governments need to put huge amounts of money into trying to sustain jobs and livelihoods,” said Mary Robinson, a former Irish president and UN high commissioner for human rights, who served twice as UN climate envoy. “But they must do it with a very strong green emphasis. The threat from climate change is as real as the threat from Covid-19, though it seems far away.” “Money has poured into the fossil fuel industry since the Paris agreement [of 2015],” she said. “That can’t continue.” But she said the changes wrought in societies around the world by dealing with Covid-19 would also demonstrate to people that the changes needed to achieve a low-carbon future were much less drastic and far more palatable. As far as the climate was concerned, “we must not go back to bad habits afterwards”, she said. “It will be easier to persuade people, as we have had to change so dramatically because of this threat.” Economic plans worth trillions of dollars in public money are being rolled out to stave off the immediate collapse of some badly hit businesses, such as airlines and tourism – and to protect the incomes of workers in danger of redundancy as normal life becomes impossible across Europe and large parts of the US, as it already has in many parts of east Asia. But while people’s health and the immediate welfare of workers caught up in the crisis are paramount, campaigners and experts fear that if the longer-term packages are not carefully designed they will only entrench fossil fuel dependence across the global economy. “Governments are drawing up stimulus plans to counter the economic damage from coronavirus,” said Fatih Birol, the executive director of the International Energy Agency. “These stimulus packages offer an excellent opportunity to ensure that the essential task of building a secure and sustainable energy future doesn’t get lost amid the flurry of immediate priorities.” Covid-19 is caused by a member of the coronavirus family that has never been encountered before. Like other coronaviruses, it has come from animals. The World Health Organization (WHO) has declared it a pandemic. According to the WHO, the most common symptoms of Covid-19 are fever, tiredness and a dry cough. Some patients may also have a runny nose, sore throat, nasal congestion and aches and pains or diarrhoea. Some people report losing their sense of taste and/or smell. About 80% of people who get Covid-19 experience a mild case – about as serious as a regular cold – and recover without needing any special treatment. About one in six people, the WHO says, become seriously ill. The elderly and people with underlying medical problems like high blood pressure, heart problems or diabetes, or chronic respiratory conditions, are at a greater risk of serious illness from Covid-19. In the UK, the National health Service (NHS) has identified the specific symptoms to look for as experiencing either: As this is viral pneumonia, antibiotics are of no use. The antiviral drugs we have against flu will not work, and there is currently no vaccine. Recovery depends on the strength of the immune system. Medical advice varies around the world - with many countries imposing travel bans and lockdowns to try and prevent the spread of the virus. In many place people are being told to stay at home rather than visit a doctor of hospital in person. Check with your local authorities. In the UK, NHS advice is that anyone with symptoms should stay at home for at least 7 days. If you live with other people, they should stay at home for at least 14 days, to avoid spreading the infection outside the home. The Bank of England is resuming its quantitative easing programme of buying up assets to create liquidity in the financial system, as it did after the 2008 crash, but there are concerns that the programme has previously been used to buy bonds from fossil fuel companies including Shell, BP and Total. There have been calls in some areas, such as eastern Europe and in Asia, to ignore climate concerns and pour stimulus money into existing high-carbon businesses and fossil fuels, rather than seeking a balance with a longer-term view that includes the need to curb emissions. John Sauven, the executive director of Greenpeace UK, said governments must act urgently to protect people’s livelihoods, which could be done without directing the money to prop up ailing sectors whose long-term future was already threatened by the climate crisis. “Decisions are being made now about whether to spend billions rescuing airlines, cruise ships, the oil and gas industry, among many others,” he said. “Bailing out the shareholders of dirty industries to continue businessasusual rather than protecting workers and their families means we would have learnt nothing from the bank bailout during the financial crisis.” Green campaigners have long talked about a “just transition” that would enable workers to move away from fossil fuel-dependent jobs and into skilled jobs with long-term low-carbon prospects. They argue this is compatible with tackling the coronavirus, too – but only if governments resist calls to downgrade environmental aims in light of the new crisis. “Diluting or doing away with environmental regulations to get a quick economic hit, as China and Poland are suggesting, would be misplaced – out of the frying pan, into the fire, even if the fire seems a few years away,” said Shaun Spiers, the executive director of the Green Alliance thinktank. “It is striking that the ruling party in South Korea has not let coronavirus deter it from proposing a green new deal election manifesto. But I would expect the UK to prioritise the immediate economic impact while also applying a climate lens and thinking about the longer term.” In the US, campaigners are concerned that Donald Trump’s hostility to climate science and wooing of fossil fuel industries will skew the economic rescue packages in harmful ways. The planned bailout for airlines and the cruise industry’s request for cash are an immediate worry. “Given that airlines produce a very large and growing amount of climate pollution, any financial assistance should include requirements that these companies take action to reduce their emissions,” said Annie Petsonk of the US-based Environmental Defense Fund. “The cruise industry, which has also requested billions in aid, has serious environmental impacts as well, and should meet new standards in exchange for government funding.” She said that in return for public money, companies should give firm commitments on carbon. “[That] would be a major step in the fight against climate change. Taxpayers, many of whom are now struggling financially, have the right to expect responsible behaviour in exchange for bailouts. They should not be funding private businesses only to see them create more costs for the public – in the form of climate impacts – in the future.” For many experts, the vital point is that the lessons from the stimulus following the financial crisis more than a decade ago are learned. Then, as now, global greenhouse gas emissions paused as the crisis hit. But after the immediate impact, emissions began their steady rise again and have continued to do so since, partly because the chance was missed to use the vast amounts of public money to set the world on a green path. “Given the state will never again play such a powerful role in our economy, and more broadly the global economy, if there was ever a time to join the dots between responding to the health emergency and the climate and nature emergency then this is it,” said Sauven. “The worst case would be that you haven’t used this awful crisis to reorientate the economy to achieve a much better outcome for people and the environment globally.”"
"
Share this...FacebookTwitterA few days ago I wrote here how green activists are (suddenly) horrified that the state of Vermont and Green Mountain Electric Company are defiling pristine mountain ridge-lines to make way for Big Wind, and thus are now protesting (and no longer supporting) wind parks in northeastern Vermont.

Scott Wheeler interviews 2 Big Wind protesters, who propose solar energy as a way to keep prices down in Vermont.
One of the leaders of the protest is Steve Wright, who with Stacey Burke, are shown being interviewed by Scott Wheeler at a sort of homemade TV station. There are some interesting parts that show how the green mind ticks (not very well, you’ll soon see).
Once a Big Wind fan, now an opponent!
At the 8:20 mark note how Burke says she was once enthusiastic about wind power on mountain tops, and now admits she had been too ignorant to know better.
When I first heard about the wind towers going up on Lowell Mountain, I actually thought, oh wow, how cool is that? […] Because I was ignorant of what was really gonna happen.”
Don’t you just love people who can’t make up their minds?
Intermittent wind can’t replace nuclear power, but solar can!
At the 13:00 minute mark, anti-Big Wind activist Wright is asked if wind towers could replace Vermont Yankee Nuclear power plant. His answer:
“The answer is no with a big exclamation point. There is no relationship between whether Vermont Yankee lives or dies and the placement of industrial wind turbines on Vermont ridge-lines, especially with Lowell Mountain. And the reason is that Vermont Yankee represents a kind of power source that is referred to as base load. That means it’s running all the time. It is always available. The wind doesn’t always blow, so therefore the turbine installations are referred to as intermittent power. Intermittent power cannot replace baseload power.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So far so good. He’s right about that. But then listen to what he says just seconds later at the 14:55 mark after being asked how we could supply the GROWING need for power:
Our answer for the long term with Vermont, is to invest seriously in two approaches. One is solar, and two is aggressive action on efficiency. We can especially reduce the use of home heating fuels in that situation, thereby reducing our carbon emissions…”
Intermittent solar can work, but intermittent wind cannot? Who is he trying to kid? Solar, like wind, is also an intermittent supply. And it’s a heck of a lot more expensive. Maybe the sun shines at night in Vermont.
Wind energy is too expensive…the solution is solar!
At the 18:55 mark Wright is asked about the high costs of wind power for consumers: Listen to his ridiculous answer:
Actually what we’re trying to do is to save Vermomt rate payers money by having a more effective energy planning process and an effective long term energy plan in Vermont. The rates that will emerge, imposed on Vermonters, on customers, from wind projects are gonna be higher than basically anything we have functional right now. So the ratepayers are gonna get hosed by the high prices, high electrical prices the more aggressively wind energy is installed.”
Yet he above proposes solar energy, which is several times more expensive than wind! He proposes using solar energy to rescue Vermonters from high electricty prices. I wonder if he takes a hammer to his head to cure a headache.
I probably should be grateful for Wright and the protests, which do seem to be having an effect. But what Wright proposes instead of wind is much worse. Solar power? Get real.
Greens grateful that FOX NEWS covered the protests!
Finally at the 25:00 minute mark, they discuss media coverage of the Big Wind protests. The greens give kudos to (conservative) FOX 44…the only statewide media outlet to be present at a protest. Now I bet that’s something they didn’t expect.
 
Share this...FacebookTwitter "
"
Guest Post by Thomas Fuller
Depending on when this gets posted, the post Anthony put up titled “O…M…G – Video explodes skeptical kids in bloodbath” may have sunk quite a bit down the pile of posts–Anthony and his squad are prolific posters.
But it can’t get any lower than the content shown in 10 10’s video. A relatively innocuous campaign to persuade people to lower their own emissions by 10 percent has pretty much exploded (literally) any hope that the debate can rise above the Wes Craven level. What’s next? The Last House on the Left… Isn’t Insulated?

The idea that blowing up skeptics is the proper response isn’t at all new–and skeptics have known this for ten years, if the drivel I get in my inbox is any indication at all. The very phrase ‘denier’ comes from a concerted campaign to show skeptics (and lukewarmers like myself, although we often get the double whammy title delayer and denier) as equivalent to those who denied the Holocaust occurred.
There has been a concerted campaign to paint everyone who does not agree with Al Gore and James Hansen as monstrous, ranging from allegories with the railroad trains filled with coal heading to some concentration camp to the late Stephen Schneider’s pathetic paper attempting to assert primacy and purity by miscounting academic publications.
But this is hate speech, pure and simple. It legitimizes almost any action against or characterization of those who do not agree with the most hysterical version of Catastrophic and Cataclysmic Climate Change–shoot ’em all and let God sort ’em out.
Using ten-year-old kids as both props and victims is a particularly nice touch.
When DDB created an ad for the WWF showing planes crashing into the World Trade Center as an advertisement asking for support for green activism, it was grotesque, tasteless and an insult to all who suffered losses on September 11th, 2001. It would have been impossible to imagine a cruder, less sensitive call to green action.
Until now.
For any of those on the activist side who wonder why skeptics (and lukewarmers) don’t trust the communications put forward by their team, they might wonder just how much any sign of reason might be contaminated by the stench from garbage like this.
Thomas Fuller href=”http://www.redbubble.com/people/hfuller


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e88627db3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

In a recent and wonderful _New York Times_ essay, John Tierney documented the pervasive left‐​leaning bias of the social sciences in particular and academia in general, which he persuasively painted as the home of tired ideological groupthink. No doubt his essay was an eye‐​opener for anyone without much experience in the ivy morass, even as it came up short in its search for causation.



There is a dangerous synergy between the academy’s attitudes and what is permitted or proscribed in our scientific journals. An interesting example is in the February 4th issue of _Science_ , the nation’s most prestigious technical magazine and the flagship of scientists’ Washington lobby, the American Association for the Advancement of Science.



The mixing of politics and science, particularly with respect to climate change, has been spilling onto _Science’s_ pages for decades now, but no more blatantly than in the recent paper by Ulf Büntgen of the Swiss Federal Research Institute and 11 coauthors.





The conflation of political agendas with science is destroying the credibility of academia, with the complicity of the editors of our major scientific journals.



This paper is one of many reviving the grizzled ghost of climatic determinism, an idea that originated in the 19th century, which attempts to explain complex social phenomena with simple phenomena like average temperature. For example, proponents of this theory argued that mean annual temperature is why colder regions were industrialized democracies, while the tropics were torpid and despotic. The story went (I am not making this up) that people at low latitudes can just laze around in hammocks and don’t have to go very far to find fruit, while people closer to the poles have to develop economies that coax food from the ground. This is only slightly racist, and climatic determinism went into hibernation as people realized that crank scientific theories have a way of developing into mass murder.



In the Büntgen et al. article, climatic determinism is the cause of good times, bad times, and wars. The core of the paper is a graphic showing tree‐​ring reconstructed summer temperature and spring precipitation in central Europe for the last 2,500 years. Superimposed upon the figures are what the authors feel are salubrious times, given as the Late Iron age, the Roman Empire and the Medieval period, as well as bad ones. These include the “migration period” from 1,700 to 1,400 years ago, and the “modern migration” of the 19th century. Apparently people came to the U.S. because temperatures in Europe were a degree lower than average, rather than in search of economic and political freedom.



Looking at Figure 4 in the paper, it’s pretty clear that when it was warm in central Europe, times were peachy (literally), and when it was chilly there were wars, pestilences and other bad things.



This didn’t stop the authors from making a blatant political plea — completely unsupported by the results — nor did it prevent the editors from writing it out. Remember that this is a paper in which warm periods are good times. That notwithstanding, we read:



The historical association of precipitation and temperature variation with population migration and settlement desertion in Europe may provide a basis for questioning the recent political and fiscal reluctance to mitigate projected climate change.



Imagine if they had concluded, “Such historical data may provide a basis for the support of the recent political and financial reluctance to mitigate projected climate change,” which in fact is what it does! Tierney’s analysis predicts that would have been severely criticized as a bad example of using science for political purposes.



The process is synergistic and self‐​fulfilling. Periodicals like _Science_ are what academia uses to define the current truth. But the monolithic leftward inclination of the reviewing community clearly permits one interpretation (even if not supported by the results) and not another. This type of blatant politicized science is becoming the norm in the environmental arena, and probably has infiltrated most every other discipline, too.



The conflation of political agendas with science is destroying the credibility of academia, with the complicity of the editors of our major scientific journals.
"
"
The statement and document from the Royal Society follows this press release
 The  Global Warming Policy Foundation, 30 September 2010
LONDON, 30 September – The Global Warming Policy  Foundation has welcomed the Royal Society’s decision to revise and tone down its  position on climate change. Its new climate guide is an improvement on their  more alarmist 2007 pamphlet which caused an internal rebellion by more than 40  fellows of the Society and triggered a review and subsequent revisions.
The former publication gave the misleading  impression that the ‘science is settled’ – the new guide accepts that important  questions remain open and uncertainties unresolved. “The Royal Society now also  agrees with the GWPF that the warming trend of the 1980s and 90s has come to a  halt in the last 10 years,” said Dr Benny Peiser, the Director of the GWPF.

Dr David Whitehouse, the science editor of the GWPF  said: “The biggest failing of the new guide is that it dismisses temperature  data prior to 1850 as limited and leaves it at that. It would cast a whole new  light on today’s warming if the Medieval Warm Period, the Roman Warm Period and  the Bronze Age Warm Period were as warm as today, possiblity even warmer than  today. A thorough discussion of the growing empirical evidence for the global  existence of the Medieval Warm Period and its implications would have been a  valuable addition to the new report.”
In their old guide, the Royal Society demanded that  governments should take “urgent steps” to cut CO2 emissions “as much and as fast  as possible.” This political activism has now been replaced by a more sober  assessment of the scientific evidence and ongoing climate debates.
“If this voice of moderation had been the Royal  Society’s position all along, its message to Government would have been more  restrained and Britain’s unilateral climate policy would not be out of sync with  the rest of the world,” Dr Peiser said.
###
The statement and document from the Royal Society follows:
Climate change: A Summary of the  Science
The Royal  Society, 30 September 2010
Climate change continues to be a subject of intense  public and political debate. Because of the level of interest in the topic the  Royal Society has produced a new guide to the science of climate change. The  guide summarises the current scientific evidence on climate change and its  drivers, highlighting the areas where the science is well established, where  there is still some debate, and where substantial uncertainties remain.
The document was prepared by a working group chaired  by Professor John Pethica, Vice President of the Royal Society and was approved  by the Royal Society Council.
Download  the guide here (PDF).


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e88979985',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
IPCC chairman Dr. Rajenda Pachauri
Guest Post by Thomas Fuller 
There is a core of uber-consulting professionals, jetting around the world  advising companies, governments and NGO’s. They are well-educated, have  impeccable resumes and travel more than George Clooney did in ‘Up in the Air.’  They work for companies like McKinsey, Price Waterhouse Coopers, and a handful  of others.
Rajendra Pachauri is one such, coming from the Tata school of consultancy.  He is charismatic, projecting leadership qualities and obviously considers  himself a polymath, able to lead a secretariat of the UN, continue his  professional duties and write a popular bodice ripper of a novel.
Sadly, like so many other uber-consultants, Pachauri’s leadership qualities  have been more apparent than real. While others are using the current troubles  at the IPCC as a reason to argue for his resignation, they are really more of a  symptom of the real problems.

Because the IPCC is very small and its primary mission is to produce a  report once every five or six years, it is vulnerable to the type of leadership  Pachauri apparently provides–detached, aloof, hands-off. That Pachauri had time  to write a book during the firestorm of Climategate and COP-15 is evidence that,  whatever his capabilities, his performance at the IPCC was not sufficiently  engaged. His shabby treatment of IPCC scientists regarding the error on  Himalayan glaciers is more of an exclamation point than anything else.
Roger Pielke Jr. and others are saying Pachauri should resign because of  conflicts of interest. Pachauri is director of TERI and advises third parties on  energy policy and investment decisions. Pielke is right in saying that Pachauri  would not meet the standards for avoiding conflicts of interest in many other  organisations, including other UN bodies.   But those standards are not in place at the IPCC, although they are  recommended in yesterday’s report from the InterAcademy Council.
I also think Pachauri should resign. But not because of conflicts of  interest. His continued involvement with TERI, his taking time to write a book,  his hectic social schedule all point to another, more serious problem.    His detached style of leadership has coincided with a period of continuous  problems at the organisation he leads. And I’m not referring to the occasional  error that inevitably slips into their huge assessment reports.    The IPCC has not moved with the times during Pachauri’s tenure. They have  not adapted to an age of the Internet in facilitating communications.
They have not recognised the political pressure that environmental  organisations are trying to put on national and international governments and  institutions. This has led to a careless over use of ‘grey’ literature, which is  not peer reviewed and often has a clear point to push.   The IPCC has not instituted a clear and effective way of dealing with  mistakes, despite it getting ever easier to do this.   Perhaps most damaging, the IPCC has adopted a view on communications that  is from another century, focused on getting their message out, as opposed to  listening and responding.
These are classic failures of leadership. Nobody but Rajendra Pachauri is  responsible for these problems. Good leadership would have corrected them years  ago. Detached leadership smiles and writes a book.   Pachauri played socialite while his organisation stagnated. He received  awards–not just the Nobel Prize, which he shared with Al Gore, but also the  French Legion of Honour, Order of the White Rose from Finland, and the Padma  Bhushan from his native India. He is apparently his organisation’s chief press  officer, and its ambassador as well, flying all over the world to meetings and  conferences. And yes, he does have other interests, including the Tata Energy  Research Institute.
The IPCC’s–and Rajendra Pachauri’s–real problem is not a conflict of  interest. It is a lack of interest. Pachauri fiddled while the IPCC foundered.  He should go.
Thomas Fuller http://www.redbubble.com/people/hfuller


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e894a214a',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

The Republican tax reform framework envisions cutting the federal corporate tax rate from 35 to 20 percent. There may be pressure in coming weeks to scale‐​back some of the framework’s pro‐​growth provisions in order to hit revenue targets, but policymakers should stick with their corporate rate target.   
  
  
Various groups have modeled the revenue effects of proposed corporate rate cuts, but they generally do not account for the full dynamic effects of reform. We can get an idea of the full effects by looking at actual reforms abroad.   
  
  
Sharp corporate tax rate cuts in Canada and Britain do not seem to have lost those governments much, if any, revenue. That is likely because companies responded with a wide range of real and paper changes that increased their reported income. The same would happen in the United States, which is why dropping our rate to 20 percent would probably not lose revenue over the long term.   
  
  
Here is some evidence. For 19 OECD countries with good rate and revenue data back to the 1960s, I calculated the average corporate tax rates and average corporate tax revenues as a share of GDP. The chart illustrates the Laffer Curve effect of chopping high tax rates on a mobile tax base—rates go down, the tax base expands, and revenues remain strong.   
  
  
From 1985 to 2005, corporate tax revenues as a share of GDP soared even though the average tax rate across the 19 countries fell from 45 to 29 percent. Then there is a sharp drop in revenues in 2010, presumably because of the recession or slow growth in many countries at the time. But note that even in the poor economic climate of 2010, corporate tax revenues were the same or higher than in years prior to the 2000 boom year.   
  
  
By 2015, revenues were rising again even as the average tax rate continued to fall to a new low of 24 percent. The average revenue for these countries in 2015 at 2.9 percent of GDP is below 2000 and 2005, but above all prior years when rates were much higher.   






Data Notes:   
  
  
The 19 countries are Australia, Austria, Belgium, Canada, Denmark, Finland, France, Germany, Greece, Ireland, Italy, Japan, Luxembourg, Netherlands, New Zealand, Spain, Sweden, United Kingdom, and the United States.   
  
  
OECD revenue data is here and rate data is here. I used the central government rates because I have not found a source for subnational rates prior to the OECD data, which goes back to 1981. As a result, the revenues (which include subnational) and the rates (which do not) are not an exact match, but that is not a big problem for illustrating trends over time.
"
"

Today's _NYT_ features a front page, above-the-fold story about former surgeon general Richard Carmona's charge that the Bush administration interfered with his office by (in the words of the _NYT)_ ""repeatedly [trying] to weaken or suppress important public health reports because of political considerations."" He made the charge yesterday in testimony before the House Committee on Oversight and Government Reform.   
  
Carmona described Bush administration behavior that ranged from petty (urging him not to attend Special Olympics events because of the Kennedy family's connection to the program) to outright worrisome (directing him, again in the words of the _NYT_ , ""to put political considerations over scientific ones""). His claims add to the image of a Bush White House in which political considerations and ideology trump all others.   
  
However, Carmona's prepared statement suggests that the Bushies aren't the only folks caught up in ideology.   
  
Carmona considers himself a person of science, and scientists have an important role in policymaking. They try to determine the existence of various empirical relationships (e.g., certain emissions trap heat in the atmosphere; exposure to tobacco smoke increases the risk of cancer) and use those determinations to make predictions about the future (e.g., ongoing emission of greenhouse gases at certain levels will affect the climate; reduced tobacco use will decrease the incidence of cancer). In this way, science informs policymaking by predicting the outcomes of various policy choices.   
  
But though science informs policy choices, it cannot make those choices. Science is a non-normative endeavor, and cannot answer such questions as whether climate change _should_ be avoided, and whether reducing tobacco use _should_ be used as a means to reduce the incidence of cancer. Those are the subject of value judgments — and, for public decisions, of politics.   




Many ""people of science"" do not appreciate this limit on science's role in policymaking. They assume that once a relationship is established scientifically, policy choices cogently follow. In making this assumption, they enter their own value judgments as suppressed premises in their analyses. Many doctors see bad health outcomes as not just undesirable, but so undesirable that they should be avoided even at high costs; many environmental scientists have the same opinion about environmental damage. Hence, they would argue that ""objective, nonpartisan science"" calls for policies to limit greenhouse emissions and reduce smoking. In fact, science can do no such thing; value judgments call for (or against) various choices.   
  
To better understand this, consider the role of a doctor. Five separate times in his testimony, Carmona refered to the surgeon general as ""the nation's doctor"" (conjuring the image of 300 million Americans sticking out their collective tongues and saying ""ahh""). I trust my doctor to make a scientific determination of the state of my health and to lay out various courses of action concerning my health (e.g., lose weight, take medication, exercise more, quit smoking). But I am the one who sets policies concerning my health — I decide whether the costs of some course of action (e.g., the side effects of some drug, or the pleasure forgone by dieting) is worth the health benefits. Likewise, public health policy should be set by elected representatives who are directly accountable to the citizenry, not by ""the nation's doctor.""   
  
But Carmona apparently wants the surgeon general to become a policymaker. He told the House committee: 



[T]he Surgeon General [should] speak and act openly and as often as necessary on contemporary health and scientific issues so as to improve the health, safety, and security of the nation.



Indeed, that role may be too modest for Carmona's surgeon general; he repeatedly argued that the surgeon general should ""serve the people and the world."" He offered lawmakers a five-point plan for the U.S. Public Health Service that included the following: 





So, instead of just being the nation's doctor (with policymaking power), Carmona's surgeon general would be a force projector for the world.   
  
Carmona is correct that politicians should not interfere with the scientific analysis of the surgeon general — the surgeon general should follow an empirical question wherever the science leads. And he may even state his personal opinion — couched as such — on the value judgments that ensue from the science. But the surgeon general should not supplant the politicians in making public policy decisions, nor supplant private individuals in making personal health decisions. And, of course, the surgeon general should not doctor scientific findings to conform them to his own value judgments.


"
"**Nativity plays and outdoor carolling will be able to go ahead in England after the national lockdown ends on 2 December, MPs have been told.**
Tory MP Andrew Selous - who speaks for the Church of England - said ""churches and cathedrals can now approach Advent and Christmas with certainty.""
Indoor singing would be limited to formal performers, he added, but everyone can take part outdoors.
Children's church nativity plays will be allowed if they follow Covid rules.
Rules on outdoor gatherings will vary across England as the tier system comes in to force after the full lockdown, but all areas restrict groups to no more than six people.
However, churches and other places of worship will be able to perform services in all three tiers, including at Christmas.
During England's national lockdown, places of worship have been closed for group activities and services, with only private prayer allowed.
Speaking at Church Commissioners question time in the Commons, Mr Selous said: ""From 2 December places of worship can reopen for public worship and churches and cathedrals can now approach Advent and Christmas with certainty.""
He said the clergy had already made their buildings ""Covid-secure"" and said ""many cathedrals and churches are planning to have multiple services to accommodate more people as less are allowed in each service"".
""The further good news is that while indoor singing is limited to performers only, we can all take part in outdoor and door-to-door singing, staying two metres apart or away from the threshold, and nativity plays for under-18s are permitted in accordance with the performing arts guidance,"" he added.
On Tuesday, all four UK governments announced plans to allow families to meet for the festive period.
People will be able to form a ""Christmas bubble"" of three households, who can meet indoors between 23 and 28 December.
The news on carolling comes after a group of leading musicians wrote to Culture Secretary Oliver Dowden to encourage him to allow outdoor singing.
They said traditional house to house carolling groups usually raise Â£10m for charities each festive season."
"

In a piece last Wednesday on _The American Spectator_ website, David Hogberg argues that the notion that limited government supporters will be happier if Republicans lose in November — thereby ushering in at least two years of divided government — might be too clever by half.



Hogberg explains we “should never underestimate politicians’ ability to glean the wrong lesson from an election.” It’s reasonable to fear that post‐​loss Republicans will conclude that their electoral problem wasn’t that they ushered in a new era of Big Government but that they failed to endorse an era of Even Bigger Government instead.



But it seems to me the bigger problem is that Republicans are learning the wrong lessons from their victories. Right now, the message they’re receiving is that voters are peachy with how things are going on the Hill.



The GOP seems to learn the right lessons from their electoral losses. They certainly did after the 1992 elections. Without the loss of George H.W. Bush, the Republican Revolution of 1994 would not have been possible. Many of the candidates who ran in 1994 were motivated by Clinton’s rush to nationalize the health‐​care system. But many were also fed up with “me too” Republicans like House minority leader Bob Michel.



What about the morning after the elections? In the wake of a Republican loss of the House, “there will likely be challenges and possibly ‘coup attempts’ against House GOP leaders,” Hogberg writes. “While the long‐​term fallout of losing in 2006 may be positive, the short run losses could be very ugly.”



Also true. But when has the learning process in politics — indeed, much of anything in politics — ever been pretty? Necessary, yes, but certainly not a thing of beauty. Besides, there are probably very few conservatives who see the current crew of House and Senate leaders as strong captains. Denny Hastert isn’t someone who leaps to mind as a swashbuckling budget‐​cutter.



Finally, Hogberg takes aim at the divided government thesis: “It rests heavily on the Reagan and Clinton years,” he writes, “but a look at the year‐​to‐​year percentage change of the government portion of gross domestic product suggests that fiscal restraint is far more contingent on the political climate.”



You’d find plenty of agreement on this among supporters of the divided government thesis. The thesis itself is nothing if not an attempt to explain how the political climate affects policy.



As Hogberg rightly notes, the big net declines in government spending occurred only after substantial victories by candidates who professed an explicitly stated goal of scaling back government. And he’s right to point out that over time, fiscal discipline flagged. Divided government, however, puts an outer limit on how bad things can get. Republicans just weren’t interested in spending all that much money on the programs that Clinton wanted, nor was Clinton interested in spending on many of the programs the GOP wanted.



The divided government thesis rests on a key assumption about the political environment: The one thing you can count on in Washington is partisanship. When Republicans are fighting a big‐​spending Democratic White House — or when they are a beleaguered congressional minority — they are in their element. Big Government is the clear enemy. But once they find themselves in control of the game, they are less willing to throw punches out of fear that they’ll hit their own teammates.



Consider how the GOP Congress reacted to non‐​defense budget requests under both Clinton and George W. Bush. They managed to cut Clinton’s domestic spending requests by an average of $9 billion each year between fiscal 1996 and 2001. Contrast that with the budget outcomes under President Bush, specifically the years in which Congress was held entirely by Republicans. Between fiscal years 2004 and 2006, Congress passed, and Bush refused to veto, non‐​defense budgets that were an average of $16 billion more than the president proposed each year.



The rules of partisanship imply that a Big Government scheme proposed by a Republican president is more likely to be accepted by a Republican Congress than if it were proposed by a Democrat. That’s exactly what happened with the Medicare drug benefit. It’s unlikely the drug benefit would ever have passed if it had been proposed by, say, President Al Gore or President Hillary Clinton. And if the Medicare expansion had gotten traction in Congress, Republican leaders would probably have been more interested in slowing it down and tacking on real reforms instead of abandoning the reforms as they did in 2003.



“Would Bush and a Democrat‐​controlled House be an improvement over recent years? Doubtful,” Hogberg concludes. “Bush is, at best, a squish on fiscal restraint (and that’s being charitable).”



One thing we have seen, however, is that Bush, like all politicians, is a political animal. On domestic policy, he usually cares more about scoring one for his own team than upholding a coherent position on the role of government in a free society. I suspect the president would go hunting for his veto pen more often if he were faced with a Democratic House. And imagine how congressional Republicans would fight the sorts of big government schemes they currently push if those proposals came instead from the mouths of Democratic majority leaders.



Divided government isn’t a cure‐​all. But I’m willing to entertain the notion that those who value limited government would be at least no worse off under it than they are now.
"
"**Slough will face the toughest level of measures when England's national lockdown finishes next week.**
The government has announced the local authority area will be in the ""very high"" alert tier three from 2 December.
Slough Borough Council said the number of the cases was falling but not ""quickly enough"".
The measures mean pubs and restaurants will remain closed in the town, and no mixing between households is allowed indoors or in private gardens.
However people can meet in groups of six in outdoor public spaces, and non-essential shops, gyms, and personal care services will all reopen.
Lead member for health councillor Natasa Pantelic said: ""Unfortunately cases in Slough, though coming down, are not dropping significantly or quickly enough putting Slough people at risk.
""While this risk remains so high, I call on all residents to follow the lockdown rules until 2 December and then stick to the regulations of our new tier to protect themselves, their families and communities from what can be a devastating illness.""
Although Slough has seen a dip in the number of cases, it still has the highest infection rate in Berkshire with 313.6 cases per 100,000 as of Thursday, according to the Local Democracy Reporting Service (LDRS).
Reading, Wokingham, Bracknell Forest, Windsor and Maidenhead and West Berkshire will go into tier two on 2 December.
It comes as it was announced most of England will be place in the two toughest levels of measures when lockdown ends."
"This week’s budget will be the first passed by parliament since MPs declared a climate emergency, but it could be the last before the UK hosts the Cop26 climate talks later this year. Many people have drawn legitimate comparisons between the respective responses to coronavirus and the climate crisis – both big shocks to the economy. But it’s important not to lose sight of why the response to Covid-19 has been so rushed and dramatic – we were caught by surprise. We have not, however, been taken by surprise by the climate crisis.  If we let things get to that point with our climate – whether through increased water scarcity, coastal flooding or wildfires – the consequences will not only be severe and tragic, but unlike an epidemic they will also be long-lasting. And so this week’s budget can’t afford to miss the bigger picture; it must be a climate budget. Measures to contain or delay the spread of disease will be a necessity. But that won’t be an excuse to detract from efforts to mitigate and adapt to the climate emergency in a way that serves society. The problems facing the chancellor, Rishi Sunak, are clear. To reach net zero, annual household emissions of carbon will need to fall from about 8,000kg of C02 today to not much more than 1,000kg by 2050. The largest reductions will need to be in heating, transport and electricity. But while good progress has been made to reduce emissions from the UK’s power sector, we are far behind in almost every other part of the economy. According to the Committee on Climate Change, the UK remains behind schedule in all but seven of its 24 indicators to reach even our previous legally binding emissions targets, before these were increased to “net zero by 2050”. More importantly, we know private investment alone won’t cut it. This is partly because many of the risks in developing new technology are too high without significant government support. But we also know creating greener jobs in the right places is unlikely to succeed if we rely on markets alone. The UK remains one of the most regionally unequal countries in Europe, with GDP per head about three times higher in Milton Keynes compared with the Wirral. Transitioning to zero-carbon industry must be used to address the geographical imbalance of our economy at the same time. So, what are the things that a chancellor serious about the climate emergency needs to do at this budget? Top of the list is significantly increasing investment in low-carbon infrastructure, prioritising electrification of transport, reforestation, and home insulation and heating. We currently spend a little under 1% of GDP per year on such investments (equivalent to around £15-20bn in 2019/20 terms), but the evidence suggests this will need to rise to more like 2-3%. Current plans see public investment sitting between 2-2.5% of GDP over the coming four years. So to avoid false trade-offs with other social infrastructure priorities such as schools and hospitals, the Conservative party’s arbitrary 3% limit on public investment will also need to be discarded. Then, of course, there’s “levelling up”. The government’s new favourite mantra must quickly find meaning and ways of genuinely improving the lives of those living in places that first powered our industrial revolution and now power our high-carbon industries. Zero-carbon transformation and levelling up are mutually dependent: outside of major airports, each of the 40 local authorities where 30% or more jobs are reliant on carbon-intensive industries are situated in the Midlands and the north. Unless these areas are supported in transitioning to low-carbon industries through government intervention, they risk high levels of unemployment and inequality. A genuine industrial strategy for regions outside London – one that centres on transport and energy efficiency – would provide this support, and in ways that go beyond making the rest of the country a glorified, one-way commuter belt. For the chancellor then, this is a no-brainer; yes, invest in the regions you want to level up, but make that investment green and you’ll be putting those places – and the country – on track for a more resilient and fairer economy as well. Alongside investment, we also need to raise money to pay for higher day-to-day spending, such as for new skills training and a stronger social safety net for the most affected regions. At the same time, an ageing population and reduced inward migration are likely to shrink tax – and increase the costs of older age care – over exactly the same period. So the chancellor will likely be considering some higher taxes, and wherever possible these will need to be green too. Things like replacing air passenger duty with a frequent flyer levy will help, as will replacing fuel duty with a more progressive alternative. Cuts to national insurance – costing billions, disproportionately benefiting higher income households and doing nothing to reshape consumption – will not. Get this right now, and the chancellor will not only help address existential threat, but he could give us the chance of becoming a healthier and fairer society for a generation. Get this wrong, and history will judge cruelly. Being resigned to last-minute damage limitation is an inevitability with an epidemic, but with the climate crisis it is ours to choose. • Alfie Stirling is head of economics at the New Economics Foundation"
"

Robert G. Kaiser shows in today’s _Washington Post_ what many of us have known for some time: notwithstanding their differences over the wisdom of going to war in Iraq, Barack Obama and John McCain may largely agree on the wisdom of going to war in general.   
  
  
Neither man wants you to believe that, of course. It behooves them to highlight their differences, both to rally their core supporters, and to make an affirmative case for why they should be chosen by the voters to lead the country for the next four years. These differences are most pronounced in domestic matters: in fiscal policy and on taxes, on health care, and on the benefits of international trade.   
  
  
But, Kaiser writes, the two candidates share many similar views on national security: 



[B]oth have revealed a willingness to commit U.S. forces overseas for both strategic and humanitarian purposes. Both agree on a course of action in Afghanistan that could lead to a long‐​term commitment of American soldiers without a clear statement of how long they might remain or what conditions would lead to their withdrawal.   
  
  
Both candidates favor expanding the armed forces, Obama by 92,000 and McCain by as many as 150,000. Both speak of situations when the United States might have to commit its troops for “moral” reasons, whether or not a vital American interest was at risk. Both accept what Andrew Bacevich, a retired Army colonel and professor at Boston University, calls the “unspoken consensus which commits the United States to permanent military primacy” — shared, Bacevich said, by leading figures in both parties.



Obama has worn his opposition to the Iraq War as a badge of honor. And rightly so. His principled stand, taken at a time when precious few politicians were willing to do the same, has allowed him to turn his opponents’ (first Clinton and now McCain) supposed advantage — their experience — into a liability, or at least a nullity. If experienced politicians could make such a colossal blunder as to support a war that now two thirds of all Americans believe to have been a mistake, then what is the value of experience?   
  
  
But the great unknown remains the lessons that Obama has taken away from the Iraq experience. Was the forcible removal of Saddam Hussein from power a good idea, poorly executed? Or was it a bad idea at the outset, further complicated by bungling in the Executive Branch? Obama has signaled that he believes the latter, but some of his advisers seem to have more confidence in their ability to pull off similar missions in the future — say, for example, against the government in Sudan, as Obama advisers Susan Rice and Tony Lake suggested in late 2006.   
  
  
Given the continuing influence within the Democratic Party of the so‐​called liberal hawks, there is even the disturbing possibility that a President Obama would be more prone to military intervention than his predecessor.   
  
  
That said, John McCain’s continued strong support for the Iraq War is merely one of many examples of his enthusiasm for using our military to solve distant problems. He has adopted a similarly bellicose stance toward North Korea and Iran, and has hinted darkly at a confrontational posture toward Russia that could ultimately result in a ruinous military conflict. In that respect, I wholeheartedly agree with Justin Logan’s deliberate ambivalence in his most recent paper, “Two Kinds of Change: Comparing the Candidates on Foreign Policy”: “The best case that can be made for Senator Obama’s foreign policy is the fact that the alternative to his approach is Senator McCain’s.”   
  
  
It is possible, perhaps even likely, that the lingering effects of the Iraq War will greatly limit the next president’s enthusiasm for foreign military intervention. But nothing that either candidate has said during this campaign gives me sufficient assurances that that is the case. Foreign policy has generally been pushed aside during this long campaign, an understandable shift given the current economic climate. But it is not too late for both men to clarify their views on the use of force, and to explain how they might differ from their opponent.
"
nan
"
Share this...FacebookTwitterIn the 5-minute video below, there are lots of statements made that are worth quoting.
Many are from environmentalists who now seem to realize something went horribly wrong. “Green yes, but not like this!”

One of my favorites is by Justin Lindholm at the 4:35 mark:
Maybe 10,000 years from now they’ll come around and wonder what went on here. […] Pads and pedestals look like sacrificial sites of some sort, and they are.”
10,000 years? The human species indeed can be frustratingly stupid at times, but not that stupid. I say give them less than a generation, 20-30 years tops. Already people are waking up, now even making protest videos against the madness. The protest is already getting into full swing.
I wonder how many of the environmentalists in the video were staunch supporters of these windmills in the beginning, before the heavy equipment rolled in and removed the mountain tops? I’d suspect most of them were. For example, see here at the 8:25 mark of this do-it-yourself TV.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Another part I find amusing is the one with activist Gaelen Brown near a home surrounded by panels at the 4-minute mark. Nothing like endowing the landscape with a little traditional Vermont charm! Sorry Gaelen, but that yard with the panels and home look god-awful ugly. I’m glad that house is not in my neighborhood. At least put the damn panels on the roof.

Dream eco-home? It looks more like a solar-powered guard tower for a prison. Other amenities: no windows facing south (or the panels are facing north), the roof cannot support very many panels, installed on the ground instead, and the sun hardly shines – which is typical in Vermont. Classic example of what the Big Green virus can do to someone’s mind. The architect of this beauty was definitely out to lunch. (Photo source: energizevermont.org video)
German readers should send this video to the leaders of Baden Wurttemberg and Bavaria, as they too appear to have been recently infected by the Big Green virus, which leads to clouded thinking and even to irreversible madness in some cases.
Finally, one last point on Gaelen’s remark about “cheap” solar panels. Today solar panel energy is still about 10 times more expensive than conventional electricity, and its forced ineffective use is one of the reasons other products like cement and glass are getting more expensive.
===========================
Also, state prosecutes journalist reporting the story for trespassing!
Share this...FacebookTwitter "
"

 _Valleywag_ has an excellent rant on the problems with environmentalists’ blackmailing the technology industry: 



To ignore the wider benefits of the digital revolution is obtuse. Here’s the fundamental truth: the more human activity is pursued online, the less the environmental footprint. Apple’s pioneering of desktop publishing did away with much of the filthy print industry; its easy video‐​conferencing will make some business trips unnecessary; Ebay’s person‐​to‐​person marketplace bypasses cumbersome retail logistics; and Google is replacing inefficient physical libraries and filing systems across the world. Frankly, if a few computers end up in dumps, rather than recycled: so what.   
  
  
I can understand why it would be convenient to go after Apple. Steve Jobs’ computer maker is more easily pressured than most companies, because of its pristine brand, and because so many of its customers are environmentally conscious. Al Gore, the planet’s foremost defender, is on the board. Apple makes things, which are messy. And, given the holy war against climate change, and the political correctness that stifles critical thinking, the company can’t defend itself.   
  
  
The green lobby may choose to target high‐​tech companies rather than, say, the oil, coal or auto industries. The ex‐​hippies in charge of Silicon Valley companies are easy targets. But any victory, in converting them to the cause, will be purely symbolic, useful for fund‐​raising, maybe, but ultimately meaningless. This campaign against Apple is, at best, moral blackmail and, at worst, a cynical shakedown. Shame on them.



Thanks to Joe for the pointer. There’s a broader point here, that was best articulated by Julian Simon: in the long run, free markets and technological progress are good for the environment, because reducing costs often means reducing waste, and reducing waste often means reducing your environmental footprint. Technological progress and rapid economic growth also allows us to devote more resources to cleaning up the environment. Plus it leads to more people having the luxury to spend their time hectoring companies like Apple for their environmental records.
"
"

No real news came out of the three days of Amy Coney Barrett’s Supreme Court confirmation hearings. As expected, Democrats focused on Obamacare and abortion, with a little bit on guns and voting rights. Also as expected, the nominee declined to discuss any pending or potential cases, or any legal issue on which she hadn’t already opined in scholarly or judicial writings.



For their part, Republicans allowed Barrett to show her intellect and verbal facility by explaining such frequently used terms as “originalism” (interpreting constitutional provisions according to their original public meaning), “textualism” (interpreting statutes according to the plain meaning of their text as opposed to legislative purpose), and stare decisis (letting erroneous precedents stand because correcting them would cause more social harm than allowing the error to persist).



In all, no senator’s vote was changed. However, the public, which according to a CNN poll last week was divided on Barrett’s nomination, did get a chance to sympathize more with the judge, who showed grace and poise under pressure. Like it or not, she will be confirmed before the election, barring a black swan event, like a massive Covid‐​19 spread that prevents the Senate from meeting or some Kavanaugh‐​like post‐​hearing allegations.



Does that mean the hearings are pointless, a kabuki process that wastes everyone’s time? Elsewhere I’ve written that they once served a purpose but have at best devolved into empty platitudes and gotcha games. I won’t rehash those arguments here, other than to note that it may have served the Democrats better to parallel the Merrick Garland maneuver of four years ago by abstaining from what they consider to be a pointless exercise — refraining from attacking Barrett’s views while making a process argument to the voters.



With the two parties adopting incompatible judicial philosophies, it’s impossible to find an “uncontroversial” nominee. 



Of course, they didn’t do that, so we’ve been treated to what then‐​professor Elena Kagan called a “vapid and hollow charade.”



But even if we didn’t learn anything this week, there was refreshing clarity on the parties’ divergent judicial philosophies. By that I don’t mean whether Roe v. Wade was correctly decided or the scope of the Second Amendment, but the difference between law and policy. To take two contrasting examples from Wednesday’s session: (1) Republican Senator from Texas Ted Cruz discussed how he favors school choice — calling it “the civil rights issue of the next century” — but that it’s not the place of a federal judge to impose it, while (2) Democratic Senator from Hawaii Mazie Hirono called the distinction between law and policy “artificial” in arguing that the Affordable Care Act must be constitutional because so many people depend on it. Indeed, each of the Democratic senators had blown up pictures of constituents who would be harmed if Obamacare went away.



Now, emotional arguments are all well and good if you’re trying to appeal to an electorate — as California Senator Kamala Harris used most of her time to do with regard to everything from health care to climate change, because she’s the Democratic nominee for Vice President.



But judges are supposed to do something else: They’re supposed to apply the law, which sometimes leads to unpopular outcomes. Judicial power is not a means to an end, but an enforcement mechanism for the strictures of a founding document intended just as much to curtail the excesses of democracy as to empower its exercise.



In a country ruled by law, the proper response to an unpopular legal decision is to change the law or amend the Constitution. Any other method leads to a sort of judicial abdication and the loss of those very rights and liberties that can only be vindicated through the judicial process.



Nevertheless, given the expansion of federal power, and then the shifting of that power away from the people’s legislative representatives and toward executive branch administrative agencies, the judiciary affects public policy more than it ever did. And court decisions increasingly hinge on the partisan affiliation of the president who nominated the judges making them.



With the two parties adopting incompatible judicial philosophies, it’s impossible to find an “uncontroversial” nominee. That’s doubly so when a nominee’s philosophy represents a big shift from that of the previous justice. As Democratic Senator from Delaware Chris Coons highlighted, Justices Antonin Scalia and Ruth Bader Ginsburg were often on opposite ends of close cases. Replacing Ginsburg with Scalia’s former clerk Barrett would mean a bigger change than replacing the moderate Anthony Kennedy with his former clerk Brett Kavanaugh.



Those jurisprudential differences, and their alignment with ideologically distinct parties, are a relatively new phenomenon; in the grand sweep of American history, things didn’t always line up so neatly. But regardless, the Barrett hearings showed that the parties do have different approaches to the law — and that Democrats don’t see legal questions as divorced from political ones.
"
"
Share this...FacebookTwitterGerman veteran journalist and publicist Dirk Maxeiner at his website is a bit shocked by the over-the-top, misdirected investigations recently conducted against sceptic bloggers and free speech in general. In his short piece:
Climategate On The Path To A State Scandal

Maxeiner writes:
This is the kind of thing you’d expect to see against Chinese dissidents. […] The British police and the American Department of Justice are conducting a coordinated action against climate bloggers. Supposedly it is an effort to find the source of the “Cimategate” e-mails.  In Great Britain the first blogger has been interrogated and his computers have been confiscated. Canadian and American bloggers have been informed that their e-mails have been searched. It is obvious that critical thinkers are now to be criminalized.
See here:
http://wattsupwiththat.com/
http://blogs.telegraph.co.uk/news
Washington Examiner
Guardian
http://joannenova
http://climateaudit
We can only hope all this backfires. Many people we now beginning to show more interest in the contents of the Climategate e-mails. Also for those e-mails that have yet to be posted in the internet. It’s possible that some real juicy ones are on the way. Perhaps this is making a few people very nervous.”

Boy – talk about officials being desperate and looking frustrated! No wonder that the IPCC wants to be above the Freedom of Information Act (i.e. be above the law).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This action sounds very much like what they did with Galileo – talk about the dark, spooky ages coming back.
Welcome to the next chapter of the Climategate saga. Obviously for anyone concerned about freedom of speech and open debate, now is the time not to be intimidated. Instead it is now the time to cover every single detail of this development and make sure our friends in the Senate and Congress become aware of this threat. If they think they can just get away with this kind of behaviour, then someone is making one serious misjudgement.
Hey, but who knows? Maybe us bloggers and all the sceptics out there will all be holding the next climate conference somewhere out in Siberia at some reopened gulag or something:  6th International Climate Conference – Siberia, Russia – June 2012 to June 2037.
Whatever happens, look to read more about this in the future. Pandora’s box has been opened.
Dirk Maxeiner is the author of the climate-catastrophe sceptical book: Hurrah, wir retten die Welt (Hooray we’re rescuing the world!). Every German ought to read this book.

Share this...FacebookTwitter "
"

The last 20 years have brought the world more trade, more globalization and more economic growth than in any previous such period in history. Few commentators had believed that such a rise in trade and living standards was possible so quickly.



More than 400 million Chinese climbed out of poverty between 1990 and 2004, according to the World Bank. India has become a rapidly growing economy, the middle class in Brazil and Mexico is flourishing, and recent successes of Ghana and Tanzania show that parts of Africa may be turning the corner as well.



Despite these enormous advances, however, there is a backlash against globalization and a widespread belief that it requires moderation. Ordinary people often question the benefits of international trade, and now many intellectuals are turning more skeptical, too. Yet the facts on the ground show that the current climate of economic doom and gloom simply isn’t warranted. The classic economic recipes of trade, investment and good incentives have never been more successful in generating huge gains in human welfare.





For all the talk of a needed “timeout” from globalization, world trade is actually accelerating, and that is for the better.



The globalization process has had its bumps, of course, as reflected recently by rising commodity prices, but that is largely a consequence of how much and how rapidly prosperity has grown. Countries like China have become richer so fast that global production of energy and food have been unable to match the pace. But rapid economic growth is the right direction, even if some of the remaining poor are suffering from high food prices.



For all the talk of a needed “timeout” from globalization, world trade is actually accelerating, and that is for the better. Big changes often come bunched together, so that when good things are happening it is important to maintain the trend. It’s true that the tariff‐​reducing talks at the World Trade Organization have stalled and that the Democratic Party, at least in its rhetoric, has moved away from the free‐​trade legacy of President Bill Clinton.



But the volume of trade is nonetheless likely to keep rising, if only because the world economy is expanding. Furthermore, a vast majority of Americans have never been better poised to benefit from global exchange and from the prosperity of the rest of the world.



Trade advocates focus on the benefits of goods arriving from abroad, like luxury shoes from Italy or computer chips from Taiwan. But new ideas are the real prize. By 2010, China will have more Ph.D. scientists and engineers than the United States. These professionals are not fundamentally a threat. To the contrary, they are creators, whose ideas are likely to improve the lives of ordinary Americans, not just the business elites. The more access the Chinese have to American and other markets, the more they can afford higher education and the greater their incentive to innovate.



Conservative and liberal economists agree that new ideas are the fundamental source of higher living standards. We urgently need new biotechnologies, a cure for AIDS and a cleaner energy infrastructure, to name just a few. Trade is part of the path toward achieving those ends. A wealthier China and India also mean higher potential rewards for Americans and others who invest in innovation. A product or idea that might have been marketed just to the United States and to Europe 20 years ago could be sold to billions more in the future.



Those benefits will take time to arrive, but trade with China has already eased hardships for poorer Americans. A new research paper by Christian Broda and John Romalis, both professors at the Graduate School of Business at the University of Chicago, has shown that cheap imports from China have benefited the American poor disproportionately. In fact, for the poor, discounting in stores such as Wal‐​Mart has offset much of the rise in measured income inequality from 1994 to 2005.



Despite all these gains, the prevailing intellectual tendency these days is to apologize for free trade. A common claim is that trade liberalization should proceed only if it is accompanied by new policies to retrain displaced workers or otherwise ameliorate the consequences of economic volatility.



Yes, the benefits of a good safety net are well established, but globalization is not the primary source of trouble for most American workers. Health care problems, bad schools for our children or, in recent times, bad banking practices have all produced greater disruptions — and these have been fundamentally domestic failings.



What’s really happening is that many people, whether in the United States or abroad, are unduly suspicious about economic relations with foreigners. These complaints stem from basic human nature — namely, our tendency to divide people into “in groups” and “out groups” and to elevate one and to demonize the other. Americans fear that foreigners will rise at their expense or “control” some aspects of the economy.



One approach is to appease these sentiments by backing away from trade just a bit, or by managing it, so as to limit the backlash. Giving up momentum, however, isn’t necessarily the right way forward. If we are too apologetic about globalization, we can feed core irrationalities, instead of taming them. The risk is that we will frame trade as a fundamental source of suffering and losses, which would make voters more nervous, not less.



It is wrong to play down the costs of globalization, but the reality is that we’ve been playing down its benefits for a long time. Politicians already pander to Americans’ suspicion of foreigners. There is no need for the rest of us to jump on this bandwagon. Instead, we need more awareness of the cosmopolitan benefits of trade and the often hidden — but no less real — gains for ordinary Americans.



If we look at trends of the last 20 years, we have every reason to believe that the modern era of free trade is just getting started.
"
"**England enters a tougher version of its three tier system of restrictions on Wednesday, as a four-week lockdown ends.**
Northern Ireland has a two-week circuit-breaker lockdown, while Wales is banning the sale of alcohol in pubs, cafes and restaurants from Friday. Scotland has its own five-tier system.
Across the UK, some restrictions will be relaxed over Christmas, to allow three households to form a ""Christmas bubble"".
From just after midnight on Wednesday 2 December, areas will be placed in one of three tiers: medium, high and very high.
About 99% of England has been placed into the high and very high coronavirus risk category - tiers two and three.
The placing of areas in each tier will be reviewed every 14 days, with the first review on 16 December.
**Areas in tier two**
**Tier two (high) rules**
**Areas in tier three**
**Tier three (very high) rules**
Additional restrictions apply:
**Areas in tier one**
Only three areas have been placed in the lowest tier:
**Tier one (medium) rules**
Areas in the lowest tier will have some restrictions relaxed:
There are exceptions in all tiers for childcare and support bubbles. More details of the plan are here.
The new coronavirus tier restrictions will mean 55 million people will be banned from mixing with other households indoors. The decision about which tier to place an area in is based on:
Lockdown restrictions in Wales were eased on 9 November.
**The current rules say:**
People who you don't live with still cannot come into your home socially, unless you are in an extended household (bubble) with them. Tradespeople can enter your home to carry out work.
However, from **Friday 4 December:**
Read Wales' official guidance.
Northern Ireland started a two-week circuit-breaker lockdown from 00:01 GMT on Friday 27 November.
Read Northern Ireland's official guidance.
Each area of Scotland has been placed in one of five tiers.
Eleven local authority areas in west and central Scotland have recently moved from level three to level four, affecting two million people.
First Minister Nicola Sturgeon told MSPs the level four measures would be lifted at 18:00 GMT on Friday 11 December.
**Areas in level zero**
No areas have been placed in the lowest tier.
**Level zero (nearly normal) rules**
**Areas in level one**
**Level one (medium) rules**
Additional restrictions apply:
**Areas in level two**
**Level two (high) rules**
Additional restrictions apply:
**Areas in level three**
**Level three (very high) rules**
Additional restrictions apply:
**Areas in level four**
**Level four (lockdown) rules**
Additional restrictions apply:
Schools stay open in all levels, and here must also be no non-essential travel between Scotland the rest of the UK.
**Do you meet other people for exercise? Have you been out walking during the November lockdown? You can share your experiences by emailing**haveyoursay@bbc.co.uk **.**
Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways:"
"
Richard North of the EU Referendum sends word of this new paper. I’m sure Greenpeace won’t be amused as more polar bears turn into dumpster divers with this new influx of miners and drillers in the new ice free future.
After the Ice Melts: Conflict Resolution and the International Scramble for Natural Resources in the Arctic Circle
Oklahoma Land Rush of 1889 - Image: wikimedia
Wei-en Tan, Department of Diplomacy, National Chengchi University, Yu-tai Tsai Institute of Strategic and International Affairs Studies, National Chung Cheng University No. 64, Sec. 2, Chinan Rd., Taipei 11605, Taiwan (PDF available here )

Abstract
It is a well-known fact that global warming is melting the Arctic ice cap.
As this happens, the natural resources in the Arctic will become available for exploitation. As such, the five countries with major claims to the region—the United States, Canada, Russia, Denmark, and Norway—are looking to extend their claims to the natural resources beneath the ice-covered ocean. The size of the Arctic Shelf is about 4.5 million square kilometers, and the U.S. Geological Survey posits that 25 percent of the world’s undiscovered gas and oil reserves may be there. Clearly, there are large amounts of untapped resources that these five countries could use to satisfy their increasing demand for development and economy.
This paper will try to explore the current disputes over Arctic seabed resources surrounding the five states in North Pole, evaluate the regimes for resolving the conflict in UNCLOS. Furthermore, the paper will introduce the appropriate points
of view and discuss the alternative dispute settlement mechanism (DSM) for this significant problem caused by global warming in the coming future.
…
It is very clear that the Arctic region stands at the threshold of significant changes. The increasing rate at which the Arctic ice is melting will surely have a major impact on local ecosystems and the potential exploitation of natural resources. By virtue of their sovereign rights and jurisdiction, the five countries with claims to the Arctic region are presently at a critical juncture for addressing their current and future conflicts of interest. This paper explores the current disputes over Arctic Ocean resources and evaluates the mechanisms in UNCLOS for resolving these kinds of disputes. Furthermore, this paper introduces the viewpoints and discusses the alternative dispute settlement mechanisms (DSM) which can be employed to solve this kind of significant problem.
…
Conclusion 
Global warming has not only challenged the authority of UNCLOS and its legal regime for resolving disputes relating to the continental shelf under the Arctic Ocean, but has also marked the beginning of the end for freedom of the high seas in the Arctic region. In addition to its environmental implications, global warming has caused a shift in the way the international community regards the Arctic, shifting the paradigm away from physical dominion and towards control over resources on the sea floor. The unprecedented access to untapped resources brought about by the receding permafrost in the Arctic Circle may soon cause an international gold rush as well as a variety of conflicts.
The conflicts over the Arctic region are unlikely to be resolved within the very near future. With five major states making claims to extensive parts of the Arctic seabed, there is a lot of scientific and professional work that needs to be done. Fortunately, there has been one good development since the conflict began. On May 28, 2008, Canada, Denmark, Norway, Russia, and the United States came together for the Arctic Ocean Conference in Greenland. (Note 66) The goal of the Conference, initiated by Denmark’s Foreign Minister, was to foster unity and cooperation in the Arctic area so as to prevent an environmental catastrophe. The result of the Conference was the Ilulissat Declaration. This document states that no new legal framework will be set up to govern the Arctic. Instead, the parties agreed to proceed using the guidelines set forth in UNCLOS. (Note 67) While this Declaration is not necessarily ground-breaking, it is encouraging in that it signals a willingness of the involved Arctic states to work together in settling their disputes.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ca73846',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterAlthough Peter Gleick confessed almost 2 days ago to stealing and leaking documents designed to damage the Heartland Institute and others, one of Germany’s leading warmist climate blogs continues to ignore it and is still actively spreading rumors about them. About 12 hours after Anthony Watts’s story Breaking: Gleick confesses appeared, Klimaretter.de went ahead and published a new opinion piece to further smear Heartland and those involved.
First on February 16, Hanno Böck of Klimaretter wrote in piece titled The Financing Of Climate Change Doubt, where he gleefully broke the story about the acquired Heartland documents: He wrote:
Internal documents of the conservative Heartland-Institute of the USA show the strategies that the organization pursues in order to discredit climate sciences. The institute receives donations from industry and finances other blogs and alleged neutral organizations, who then spread doubt about climate change. Among others, donators include Bayer, Microsoft and General Motors.[…]
Canadian DeSmogBlog has revealed internal documents from conservative lobby organization Heartland Institute. […] From the documents it is clear that many seemingly independent voices in the debate are funded by donations from industry provided though Heartland Institute.”
Up to now, neither corrections nor omissions have been undertaken by Klimaretter, which is run by journalists and German Parliamentarians. To the contrary, as you will read below, they actively took steps to sustain the phony Heartland story by posting an opinion piece by Dr. Hermann Ott, who again using the fake document smears Heartland and the skeptics.
In its February 16 piece, Klimaretter listed the alleged funders of skeptic sites: Koch Industries, Microsoft, AT&T, Time Warner, Bayer – but did point out that the donations were mainly targeted for pharmaceutical lobbying.
Klimaretter then singled out blogger Anthony Watts, claiming he received donation checks from industry. Böck wrote:
One of these for example is the project of blogger Anthony Watts, who writes the widely read “Climate skeptical” blog Watts up with That, and the organization NIPCC (Nongovernmental International Panel on Climate Change) of American physicist Fred Singer, who views himself as a counter voice to the UN IPCC, but who is regarded as unscientific by climate scientists.
In the year 2012 the Institute plans to create educational material for schools.”
Klimaretter then wrote that Heartland had been funded by Big Tobacco to fight against the rights of non-smokers before it began to focus on climate change. Klimaretter claimed that much the pressure to attack scientists stemmed from the Tea Party movement.
Concerning the document “2012 Heartland Climate Strategy”, Klimaretter wrote that “the Heartland Institute claims the questionable document is a fake” and that “no further details concerning the authenticity of the other documents could be added, so says Heartland in a Press Release.”
Geick confesses, Ott quotes a faked document
Now, six days later, a full day after Gleick confessed he leaked the documents, you’d think Klimaretter would have taken down the story by now and added a correction. They haven’t. In fact, they’ve added an opinion by German Green party member Dr. Hermann Ott, who goes after Fred Singer and Heartland with renewed vigor. He posted his opinion (read it here) at Klimaretter 12 hours after Gleick’s confession.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Green Parliamentarian Dr. Hermann Ott, who is a regular contributor at Klimaretter and skeptic smearer, posted his piece yesterday (February 21, 3:01 pm CET) ) dubbed: How US Companies Undermine Climate Policy, which more or less reiterates everything Hanno Böck had written days earlier, and quotes the faked document:
And what does the Institute [Heartland] do with the money? Taking a first look at the figures, one sees that climate change denier Fred Singer alone, who unfortunately appeared in the Bundestag, is financed by the Heartland Institute with 5000 dollars per month (plus expenses). $100,000 is available for developing alternative educational curricula for schools for promoting doubt about climate change. In the description of this project for schools, there’s even the sentence that their goal includes: ‘dissuading teachers from teaching science’. Unbelievable and revealing.”
Ott later writes:
The entire ‘datacheck’ of the Heartland-Institute makes it perfectly clear what I was saying about the strategies of the climate change skeptics in my discussion in the Green Bundestag faction last year, namely that the funders stem mostly from the fossil fuel industry and that it is always about increasing doubt and nothing to do with scientific findings.”
Scientific findings? Does he mean the dubious sort that Gleick uses? Why Ott would continue to insist the Heartland story is real is baffling, and if done intentionally – it is malicious and slanderous. I can only speculate that he thinks nobody in Germany is going to notice, and so he thinks he can get away with it.
In light of the known fact that Gleick used fake documents (because the other docs simply weren’t going to produce the desired effect), Ott still has the temerity to conclude:
One can only hope that making the documents public will hamper the strategy of the fossil fuel industry and also lead to such books like the one by RWE-Manager Vahrenholt to disappear from the bestseller charts.”
And
Instead, they will be seen for what they really are: cold hearted egoists who put the future chances of humanity at stake for the sake of their profits.”
P.S.: If you wish to give Peter Gleick some kind words, you can do so at Twitter unter @PeterGleick.”
Recall that Hermann Ott posted this on February 21 at 3:01 p.m. CET, 12 hours AFTER Anthony Watts broke the story that Gleick had confessed. Obviously Ott is comfortable putting himslef in the same company as document fakers and mudrakers.
In case Heartland, WUWT, or the lawyers representaing them, would like to give Klimaretter some kind words, you can reach the editor in chief at:
nick.reimer@klimaretter.info
They undertand English very well.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOn Cosmic Rays and Clouds
By Ed Caryl
There have been several papers and articles recently about Svensmark’s theory that claim cosmic rays produce cloud nuclei, which in turn produce clouds that affect the Earth’s climate. My recent article showed the relationship between atmospheric transmission, the Earth’s albedo, and temperature.
Photo by Krish Dulal.
If cosmic rays produce micro-particles that grow into cloud nuclei, and if these particles are large and numerous enough to interfere with sunlight, it should be possible to show a relationship between cosmic rays and atmospheric transmission, and thus clouds.
Relationship between albedo and atmospheric transmission
The transmission is measured in a clear-sky situation. Albedo reflection is mostly from clouds. If aerosols impede transmission and aerosols ultimately produce clouds, then there should be a relationship.
Figure 1: Relationship between albedo and atmospheric transmission.
The problem with Figure 1 is that we only have a few annual data points for albedo. There isn’t a single database for global cloudiness with any temporal extent other than the above data. Two of the points are due to a volcanic eruption. Without those points only a slight relationship remains.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 2: Relationship between albedo and atmospheric transmission after subtracting the two years of Pinatubo volcanic dust.
This result seems to suggest that only large dust and sulfate particles make much difference to clouds and albedo. This may explain the next result.

Figure 3: Monthly data plot of atmospheric transmission and the Oulo, Finland neutron count proxy for cosmic rays. Source of neutron data here.
The problem with this plot is that the volcanic eruptions just happened to occur at negative cycles of the neutron count. We know (or are at least fairly certain) that volcanoes and cosmic rays are not related in any way. For that reason, in the next plot, data from the two years after each volcanic eruption was deleted to avoid a false appearance of correlation.

Figure 4: Monthly data plot of atmospheric transmission versus Oulu neutron count.
Without the volcanic activity in the plot there is no relationship between atmospheric transmission and cosmic rays as measured by the neutron count at Oulu, Finland. The R-squared value is below 0.01, and in the wrong direction. The relationship is completely random.
This result does not necessarily falsify Svensmark’s theory. There may be an explanation as to why cosmic ray flux does not show up in atmospheric transmission. As suggested above, perhaps the particles are too small, or too infrequent compared to other aerosols, but it is another mystery that demands an explanation.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterCold temperatures are nothing unusual in Antarctic, especially in the wintertime. But one observer in the Internet here has noticed it’s been far colder than usual.

Shown above is the projected 2m temperature anomaly for Antarctica for 30 July until 6 August, 2012. Source: Dr. Ryan N. Maue.
The observer writes:
For weeks I’ve been observing extreme, unusual deviations from the mean by as much as -20°K. Even in Australia it’s been too cold. What’s the reason for this cold over there, the powerful Antarctic polar circulation?
While the media remains locally fixated on a warm June in the US, it is ignoring an extreme cold event in a region that is supposed to be a “canary in the coal mine”.
Note:
I’m a bit tied up right now, and so blogging will be on the light side until this weekend. If anyone has more on the Antarctic cold, let me know!
Share this...FacebookTwitter "
"American congresswoman Alexandria Ocasio-Cortez recently shook up environmental politics by releasing a broad outline of a Green New Deal – a plan to make the US a carbon-neutral economy in the next ten years, while reducing both poverty and inequality. Lauded by many as a radical and necessary step, president Trump responded in typical style: The Green New Deal doesn’t directly call for people to consume less meat. But the argument that solving climate change means changing our diets is widespread, and Ocasio-Cortez herself has made the link.  Yet Trump’s tweet was actually on the money in more ways than one. Environmental measures, and solutions to climate change, often appear (or are talked about) as programs of austerity. To reduce “our” impact “we” need to consume less: eat less meat, walk and not drive, fly less, buy less fast fashion, and so on. From personal carbon footprint calculators to articles outlining how many Earths we need to sustain the consumption of the average citizen of the UK, Europe or the US, consumption is identified as the problem. Reduce consumption, runs the argument, and you solve climate change. But is “our” consumption really the problem? Who is “we” anyway? This point has been made before, but bears repeating. Most of the world’s population produces very little in the way of either carbon emissions or broader environmental impacts. We can go further here by also looking at imported carbon emissions – that is, the emissions that come from the production of goods and services in countries such as China that are then consumed in the wealthy countries of the global north. If we include imported emissions, the UK’s overall emissions have only marginally decreased since 1990.  When we approach carbon emissions this way, it’s clear the problem isn’t overpopulation or China, but the richest people on earth. After all, being rich, especially ultra-rich, means being directly responsible, either through consumption or control, for the majority of the world’s carbon emissions. For instance, the charity Oxfam has found that the richest 10% of people produce half of the world’s carbon emissions, while the poorest half contribute just 10%. Who are the richest 10%? The figure is not about nations but people – the 770m or so people who make up the richest tenth of the world’s population. The disparity is even more startling when we look at the differences between the ultra-rich and the bottom 50% at a global level, where a typical ultra-rich individual produces 35 times the carbon emissions of someone in the bottom half, and 175 times the amount of someone in the poorest 10%. This cohort of ultra-consumers are not spread evenly around the globe. Some 40% live in the US, around 20% live in the EU and 10% in China. Focusing on the richest 10% is a useful way of looking at things as carbon emissions aren’t only globally uneven, they are also uneven within national borders. The key detail here is the massive disparity in most wealthy countries between the emissions of rich and poor households. In both the US and the UK, the richest 10% produce at least five times the emissions of the poorest 50%. And this is just their consumption emissions (and doesn’t include those emissions produced by the people who work for them – their cleaners, drivers, and so on – which would further expand their impacts). We could further compound these figures by looking at the imbalance between genders, where men tend to produce more carbon emissions than women, or racial inequality that extends even to emissions, with white people producing more than everyone else. But that’s not all. While it’s relatively simple to account for the vast initial disparity – being rich after all is about having more money, more stuff, bigger super-yachts and houses – this fails to account for the entirety of the disparity. Being wealthy gives you more political influence. It means funding political parties and campaigns, having access to law makers and lobbyists. And it means control over major corporations, and thus power over the businesses and industries which produce most of the carbon emissions.  The problem with stories of over-consumption isn’t just that consumption is far from even – the problem is that consumption is often made out to be a matter of choice. Discretionary income – the portion of your money left over after paying for everything you need – increases the richer you get. For most people, there just isn’t much left over once you’ve paid for the things you need. And if we then include those so-called discretionary items that really aren’t anything of the sort – mobile phones, for instance – then most people really don’t “choose” to consume in any meaningful way. More than this, what they can choose from is largely determined by large transnational corporations, which are often controlled by the same ultra-wealthy people whose consumption is disproportionately the problem. Given the problem is overwhelmingly, dare I say it, rich white men, we don’t do ourselves any favours by assigning blame to whole populations – be it humanity, Americans, or even the whole global north. Thinking this way makes it harder to identify the actual source of the problem and formulate solutions to it. That is to say, rather than signing on for yet another call for meat free Mondays and giving up meat, we’d be better off “eating the rich”. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"

_Global Science Report_ _is a feature from the_ _Center for the Study of Science_ _, where we highlight one or two important new items in the scientific literature or the popular media. For broader and more technical perspectives, consult our monthly “Current Wisdom.”_   
  
Global warming beater Justin Gillis of the _New York Times_ had an article yesterday describing a new paper in the current issue of _Nature_ magazine, the point of which seems to be scaring people with alarming global warming statistics.   
  
Gillis’ article “By 2047, Coldest Years May Be Warmer Than Hottest in Past,” describes the results of a class-project-cum- _Nature_ -article headed by Camilo Mora from the University of Hawaii at Manoa (please, no puns). The class assignment was to identify the year for each spot on the globe in which all future years were, according to climate model projections, warmer as a result of greenhouse gas emissions than the warmest year simulated by the models during the historical period 1860 to 2005. Mora and students termed this pivotal year the “climate departure.”   
  
This work is significant, according to Gillis, because:   




Thousands of scientific papers have been published about the model results, but the students identified one area of analysis that was missing. The results are usually reported as average temperature changes across the planet. But that gives little sense of how the temperature changes in specific places might compare with historical norms. “We wanted to give people a really relatable way to understand climate,” said Abby G. Frazier, a doctoral candidate in geography.



Perhaps Dr. Mora should have injected a little climate-science history in this class.   
  
Looking at the time that a human climate signal will rise above the background noise is not particularly a novel concept. It’s commonplace. We would guess that a signal-to-noise ratio was probably present in the first papers describing the performance and output of the very first climate models.   
  
After all, without such information it is impossible to put absolute changes in perspective. Some measure of the statistical significance of climate change has been present in every climate assessment report from the U.N. Intergovernmental Panel on Climate Change dating back to 1990.   
  
In our presentation to the Science Policy Conference of the American Geophysical Union this summer, we even included a table listing the number of years into the future it would be before projected changes in precipitation across the U.S. rose above the level of nature variability. We guess we just didn’t give that year a catchy enough name like “climate departure,” because our results didn’t capture the attention of the press (nor were they very frightening).   
  
But Gillis does manage to carve some new, scary Jack-o-Lanterns from the Mora study.   
  
Here is his lead paragraph:   




If greenhouse emissions continue their steady escalation, temperatures across most of the earth will rise to levels with no recorded precedent by the middle of this century, researchers said Wednesday.



Uh, correct us if we are wrong, but we already thought that global temperatures were reported to be at unprecedented levels in recorded history. According to the IPCC’s _Fifth Assessment Report_ :   




Each of the last three decades has been successively warmer at the Earth’s surface than any preceding decade since 1850.



So, is this recycled news, or is the new paper saying that we have to wait until 2047 for that to happen? Well, whatever, it sounds B-A-D.   
  
Or how about this one:   




“Go back in your life to think about the hottest, most traumatic event you have experienced,” Dr. Mora said in an interview. “What we’re saying is that very soon, that event is going to become the norm.”



Hot Tub Time Machine came immediately to mind, but Gillis provided another scenario:   




With the technique the Mora group used, it is possible to specify climate departure dates for individual cities. Under high emissions, climate departure for New York City will come in 2047, the paper found, plus or minus the five-year margin of error.



How scared should you be about passing the date of “climate departure”?   
  
Not at all.   




In Figure 1, we show the complete observed (rather than modeled) history of the annual average temperature from New York City’s Central Park, spanning from 1869 through 2012.   






_Figure 1. Annual average temperature from New York’s Central Park, 1869-2012 (_ _data_ _from the New York City Office of the National Weather Service)._



Here are some not-so-scary facts, that by others would be passed off as horrors:   
  
● The _average_ temperature in Central Park for the past 83 years (since 1930) (54.8°F) is greater than the _warmest_ year during the first 39 years of the record (1869-1907) (54.7°F).   
  
● There has only been one year in the last 20 years of the record that was _colder_ (by just 0.2°F) than the _warmest_ year during the first twenty years of record.   
  
So essentially, New York City has already reached its “climate departure” date and no one noticed.   
  
By his own estimation, the older author of this blog post (PJM) has lived through nine environmental ends-of-the-words-as-we-know-it. What’s new here?   
  
Whether the climate departure date in New York was reached as a result of the heat of urbanization, natural climate variability, human-induced global warming, or the likely combination of all three, its passage is of virtually no practical significance. Yes, it is warmer now that it was 150 years ago.   
  
As concerned as readers of the _New York Times_ might be, they are living twice as long as they did back then, and, in Manhattan, are richer than Croesus.   
  
Science/science policy expert Roger Pielke Jr. put the new Mora article in perspective (although not in the Justin Gillis article, but rather at NBCNews.com):   




But trying to compel action with a stark warning about a future that is coming regardless of what efforts are taken to curb greenhouse gas emissions may be misguided, according to Roger Pielke Jr., a climate policy analyst at the University of Colorado at Boulder.   
  
""It is better to design policies that have short-term benefits"" such as jobs, energy access or less pollution ""which can also address the longer-term challenge of accumulating (carbon dioxide) in the atmosphere,"" he said. ""That is a policy-design problem that we have yet to figure out, and which does not involve trying to scare the public into action.""



But what attention would come to climate change if the researchers, the media, and the government weren’t complicit in trying to scare people into giving up some of their freedoms to try to mitigate it?   
  
Trick or treat? Happy Halloween!


"
"**Five more people have died at a Llangollen care home, taking the total Covid-19 deaths in the last three weeks there to 20.**
There are 11 new positive test results at Llangollen Fechan Care Home, which include four residents and seven staff.
A total of 60 residents and 40 staff have tested positive for the virus since the outbreak began.
An incident management team is investigating the cause of the outbreak.
Nicola Stubbins, co-chairwoman of the incident management team which involves Denbighshire County Council, Public Health Wales and Betsi Cadwaladr University Health Board, said the team continued to monitor the situation.
""We are very sad to report these further deaths and are very concerned about a number of residents who are currently very poorly,"" she said.
""Unfortunately, residents who are already vulnerable through their age or pre-existing conditions are more likely to suffer the worst outcomes from this deadly virus and our thoughts are with all of those affected.
""We still expect to see cases in a variety of settings, and we manage any clusters of coronavirus appropriately.""
Wales' first minister described the deaths at the care home as ""a very sad story"" on November 20.
At a coronavirus briefing, Mark Drakeford said the rules around care homes were much stronger now than they were in the spring because of a better understanding of how Covid-19 spreads.
""A lot of help is being provided both to that care home in Llangollen, where there is that very sad story today, but other care homes as well, to make sure that all those basic things the care home itself has to take responsibility for are being done in the best possible way,"" he said.
Mr Drakeford also explained that discussions are continuing over the use of the latest testing equipment and that care home staff and residents ""are very much part of that conversation""."
"The amount of the earth’s ocean surface covered by sea ice has been continually observed by satellites and its extent estimated since 1978. The trend has been for shrinking sea ice in the Arctic and, more recently, expanding sea ice in the Antarctic.  This somewhat counter-intuitive finding has been explained by reference to the ozone hole, currents, and winds. But it seems in part it has a more straightforward origin, stemming from an error in how the data is recorded and processed. Several mathematical algorithms have been developed to convert raw satellite data into estimates of the area covered by at least some sea ice. While for the most part the results of different algorithms are in reasonable agreement, there are differences. A widely used method is the Bootstrap algorithm, developed at NASA Goddard, which performs particularly well at estimating Antarctic sea ice compared to others. As satellite sensors have only a limited lifespan, to calculate trends over longer time periods requires stitching together the records from several sensors. However, each sensor is a little bit different, and these differences need to be corrected to create a consistent record over several decades. Slight adjustments in the algorithms are made to ensure the estimates from the new sensor match as closely as possible to the estimates from the old sensor during the period when their records overlap. This can never be done perfectly, but with care disagreements can be minimised. All algorithms, including Bootstrap, do some form of inter-calibration to try to ensure the data is consistent. Bootstrap was used to report sea ice extent for the last two IPCC reports, AR4 in 2007 and AR5 in 2013. Between AR4 and AR5, Bootstrap changed from Version 1 to the improved Version 2. The reprocessed data set, V2, shows a magnified sea ice increase over V1. This wasn’t noticed at the time because Antarctic trends, being relatively small in magnitude and with large year-to-year variations, could change fairly substantially from year to year in any case. However, Ian Eisenman who led our investigation, published in the Cryosphere journal, found that the growth of Antarctic sea ice between the last set compiled with V1 and the first compiled with V2 was greater than could be explained just from adding more data. I helped find and provide the earlier V1 data and he and fellow co-author Joel Norris compared the two versions. We found the discrepancy can be pinned to a sensor calibration change in 1991. Our analysis doesn’t discern in which version the inter-calibration  error occurred – we simply compared the two versions and noticed the jump. The data set producer, Joey Comiso, has now looked at the issue and is confident that the error lies in V1, meaning the current version in use and used in AR5 is correct. Ian, Joel, and I are interested in looking further into this to confirm the V1 error. It’s important to emphasise that this sort of reprocessing of climate data – any scientific data, in fact – is not just common, but part of the scientific process; better data becomes available, methods are improved, errors are found and corrected. Data sets are never perfect, but as scientists we continually work to improve our data and understanding of it in order to get closer and closer to the truth. I think this paper and the reprocessing of Bootstrap are good examples of this process.  Fundamentally the paper doesn’t change our understanding of Antarctic sea ice. Today, regardless of which version of the data or sensor you use, Antarctic sea ice extent is increasing at a statistically significant rate. The paper documents that the jump in trend numbers reported between V1 and V2 was due to processing and not due to variation in sea ice extent. Our results simply correct the published literature and show that, contrary to what was previously thought, the increase in Antarctic sea ice hasn’t accelerated in the past 15 years, but has been remained consistently positive at moderate levels. Unlike Arctic sea ice, and the Antarctic continental ice sheets, which have been consistently, and substantially, falling. Next, read this: The Arctic melts, but oceans and ozone hole may cool Antarctica "
"Search online for “climate change” and “tipping points” and you’ll find some scary results. Melting ice sheets, the collapse of the Atlantic thermohaline circulation , the permafrost methane “time bomb” and the die-back of the Amazon rainforest threaten to exacerbate the climate crisis and send global warming spiralling out of control. But what if we could leverage similar tipping point dynamics to solve the climate problem? Like physical or environmental systems, socioeconomic and political systems can also exhibit nonlinear dynamics. Memes on the internet can go viral, loan defaults can cascade into financial crises, and public opinion can shift in rapid and radical ways. 


      Read more:
      What climate 'tipping points' are – and how they could suddenly change our planet


 In an article just out in Science, we outline a new approach to climate change that tries to find areas in socioeconomic and political systems that are “sensitive” – where modest but well-timed interventions could generate outsized impacts and accelerate progress towards a post-carbon world. These “Sensitive Intervention Points” – or SIPs – could trigger self-reinforcing feedback loops, which can amplify small changes to produce outsized effects. Take, for example, solar photovoltaics. As more solar panels are produced and deployed, costs fall through “learning-by-doing” as practice, market testing and incremental innovation make the whole process cheaper.  Cost reductions lead to greater demand, further deployment, more learning-by-doing, more cost reductions and so on. However, the spread of renewables isn’t just dependent on technology and cost improvements. Social dynamics can also play a major role. As people observe their neighbours installing rooftop solar panels they might be more inclined to do so themselves. This effect could cause a shift in cultural and social norms. Financial markets are another key area where SIPs could help accelerate the transition to post-carbon societies. Many companies are currently failing to disclose and account for climate risks associated with assets on their balance sheet. Climate risk can entail physical risks, caused by extreme weather or flooding. They can also entail the risk of assets such as fossil fuel reserves becoming stranded as economies transition to limit warming to 1.5℃ or 2℃, when such resources are no longer valuable. Most of the world’s current fossil fuel reserves can’t be used if the world is to limit warming and they become effectively worthless once this is acknowledged. By not accounting for these risks to fossil fuel assets, high-emission industries are effectively given an advantage over low-carbon alternatives that shouldn’t exist. Relatively modest changes to accounting and disclosure guidelines could make a significant difference. If companies are required to disclose information about the climate risks associated with their assets – and if such disclosure is consistent and comparable across companies – investors can make more informed decisions and the implicit subsidy enjoyed by high-emission industries is likely to rapidly disappear. Opportunities for triggering SIPs in a given system can also change over time. Sometimes “windows of opportunity” open up, where very unlikely changes become possible. A key example in the UK was the political climate in 2007-2008 which enabled the 2008 UK Climate Change Act to pass with near unanimous support. This national legislation was the first of its kind and committed the UK to reducing greenhouse gas emissions by 80% relative to 1990 levels by 2050. The act also created a regular ratcheting cycle which encourages more ambitious future climate action. Since 2008, emissions in the UK have fallen dramatically. However, the UK Climate Change Act’s influence beyond the UK is also significant as it encouraged similar legislation in other countries, including the Paris Agreement, which contains the same self-reinforcing ratcheting mechanism. Thinking about SIPs in policy and business could accelerate the post-carbon transition – but much work lies ahead. The first step is to systematically identify potential SIPs and the mechanisms by which they can be amplified.  Unfortunately, traditional economic models commonly used to evaluate climate policy are poorly equipped to do this, but new analytical methods are increasingly being used in policy.  These new methods could provide more accurate insights into the costs, benefits and possibilities of SIPs for addressing climate change. As SIPs could be present in all spheres of life, experts in social and natural sciences will need to work together. The window to avert catastrophic climate change is closing fast, but with intelligent interventions at sensitive points in the system, we believe success is still possible. Since the stakes are so high – and the time frame so limited – it is not possible to chase every seemingly promising idea. But with a smart, strategic approach to unleashing feedback mechanisms and exploiting critical windows of opportunity in systems that are ripe for change, we may just be able to tip the planet onto a post-carbon trajectory. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"
New study documents harmful effects of  “cap-and-trade” and “endangerment” schemes
Guest post by Paul Driessen
Environmental justice demands  that the United States address global warming, the gravest threat facing  minority Americans, insist the EPA, Congressional Black Caucus and White House.  Are they serious?
The alleged threat pales next to  unwed teen motherhood, school dropouts, murder and other crime. But even  assuming human carbon dioxide emissions will cause average global temperatures  to rise a few degrees more than they have already since the Little Ice Age  ended, it is absurd to suggest that any such warming would harm minorities more  than policies imposed in the name of preventing climate change.

Human activities have not  replaced the complex natural forces that drove climate change throughout Earth’s  history. But even if manmade greenhouse gases do contribute to planetary  warming, slashing US emissions to zero would bring no benefit, because steadily  rising emissions from China, India, Brazil and other rapidly growing economies  would almost instantly replace whatever gases we cease emitting.
Most important, fossil fuels  power the economic engine that ensures justice and opportunity in America today.  Policies that make energy less reliable and affordable reduce business revenues  and profits, shrink investment and innovation, imperil economic recovery, and  hobble job creation, civil rights, and the pursuit of happiness and the American  dream.
Whether they take the form of  cap-and-trade, carbon taxes, restrictions on drilling and coal mining, or EPA  rules under its claim that carbon dioxide “endangers” human health and welfare,  anti-energy policies frustrate the natural desire of poor and minority Americans  to improve their lives.
As to coping with higher  temperatures, restrictive energy policies send electricity prices skyrocketing,  making it harder for low-income households to afford air conditioning, and  putting lives at risk. They send poor families back to pre-AC misery of bygone  eras, like the 1896 heat wave that killed 1,300 people in New York City’s  sweltering tenements. In wintertime, they make heating less affordable, again  putting lives at risk.
I recently documented the  connection between energy policies and civil rights. My “Justice through  Affordable Energy for Wisconsin” report focuses on the Dairy State, where I grew  up. However, its lessons apply to every state, especially the 26 that get 48-98%  of their electricity from coal or have a strong manufacturing base. (The full  report can be found at www.CFACT.org)
Energy is the foundation for  America’s jobs, living standards, and everything we make, grow, eat, wear,  transport and do. Climate change bills, energy taxes and renewable energy  mandates deliberately restrict supplies of reliable, affordable hydrocarbon  energy – sending shockwaves through the economy.
Fossil fuels generate  three-fourths of Wisconsin’s electricity, keeping costs low and enabling its  $45-billion-a-year manufacturing sector to compete in a tough global  marketplace. Hydrocarbons sustain thousands of jobs in agriculture, tourism and  other sectors of the state’s economy. They ensure that hospitals and clinics can  offer high-tech diagnostic, surgical and treatment services.
They enable school districts,  families, churches, shops and government offices to operate in the black.  Soaring fuel and electricity prices would force schools to spend millions more  for buses, heating and lighting. That would mean higher taxes – or reduced  music, sports, language and special education programs. Poor and minority  neighborhoods would be impacted worst.
Small and minority businesses are  often young and undercapitalized. Increasing their operating costs, while  decreasing the disposable income of their customers, puts them on the verge of  bankruptcy.
“A single worker in our  Rhinelander fabrication plant can do the work of ten who do not have access to  cranes, welding machines, plasma burners and all other machinery that allows us  to cut, bend and fabricate steel up to six inches thick, and make all kinds of  heavy equipment,” says Oldenburg Group executive vice president Tim Nerenz. But  the machinery and facilities are energy-intensive. If energy costs rise, the  company would have to cut wages and benefits or lay off workers, as  contract prices are fixed and overseas competition is fierce.
Indoor pools and other facilities  make tourism a year-round industry, sustaining local economies during frigid  Wisconsin winters, making resorts like the Chula Vista Resort in Wisconsin Dells  popular jumping-off points for cross country skiing, snowmobiling and dining.  Rising energy costs would reduce family vacations, hammer bottom lines, force  layoffs, and cause foreclosures throughout these communities.
In every case, it is blue-collar  workers, low and moderate income families, minorities and the elderly that are  affected most severely.
Nor are these impacts likely to  be offset by “green” jobs. As Spain, Germany and other countries have  discovered, wind and solar power require constant infusions of money from  increasingly strapped taxpayers and energy consumers. When the economy sours,  the subsidies disappear, and so do the jobs.
Wind and solar electricity is  expensive, intermittent and unreliable – necessitating expensive gas-powered  backup generators, and further damaging family and business budgets. Plus, most  of the jobs will be in China and India, where low energy and labor costs, and  access to rare earths and other raw materials that America refuses to mine,  supply wind turbine and solar panel factories that easily under-price US firms.
The entire cap-tax-and-trade,  renewable energy and green-jobs edifice is a house of cards, propped up by  claims that humans are affecting the Earth’s climate. As EPA and EPA  Administrator Lisa Jackson repeatedly assert, “Climate change is already happening, and human activity is a  contributor.”
However, that is  not the issue. The issue is whether our use of fossil fuels is now the dominant  factor in global warming and cooling, and whether future manmade climate change  will be catastrophic. There is no replicable or credible evidence to support  that proposition.
Headline-grabbing disaster  scenarios forecast for 50 or 100 years in the future are the product of  speculation, assumptions, unreliable computer models, and articles by climate  activists falsely presented as peer-reviewed scientific papers in IPCC reports,  news stories and political speeches. As my Wisconsin study explains, they are  not supported by actual data and observations regarding historic and current  global temperatures, ice caps, glaciers, sea levels, rainforests or cyclical  weather patterns.
Energy taxes and  subsidies, renewable energy mandates, soaring prices for everything we need –  and severe impacts on families, businesses, jobs, opportunities, living  standards and basic civil rights – might be justified if we did indeed face a  manmade climate disaster. But even then we should carefully examine the costs  and benefits of any proposed actions.
We should determine  whether slashing fossil fuel use will stabilize our planet’s ever-turbulent  climate, and whether our limited resources might be better spent on adapting to  future changes, natural and manmade, just as our ancestors did.
If global warming science is  inaccurate, dishonest, slanted or fraudulent, there is even less justification.
We cannot have justice without  opportunity, or opportunity without energy. We cannot have justice by sharing  scarcity, poverty and skyrocketing energy prices more equally – especially on  the basis of erroneous, speculative or manipulated climate science.
We must therefore be forever  vigilant, to ensure that Congress does not slip cap-tax-and-trade proposals  through during a post-election lame-duck session – and EPA does not shackle our  economy and civil rights progress with its job-killing “endangerment” rules.
Paul  Driessen is senior policy advisor for the Committee For A Constructive Tomorrow  (CFACT) and Congress of Racial Equality (CORE), and author of  Eco-Imperialism: Green power – Black death.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89bddb93',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Joe D’Aleo and Don Easterbrook have produced a new paper for SPPI. This graph of US Mean temperature versus the AMO and PDO ocean cycles is prominently featured:
Figure 18: With 22 point smoothing, the correlation of US temperatures and the ocean multidecadal oscillations is clear with an r-squared of 0.85
I particularly liked the regression forecast fit: 
Figure 20: using the PDO/AMO to predict temperatures works well here with some departure after around 2000.
They have this caveat:
Note this data plot started in 1905 because the PDO was only available from 1900. The divergence 2000 and after was either (1) greenhouse warming finally kicking in or (2) an issue with the new USHCN version 2 data.
Hmm. I’m betting USHCNv2.
Abstract:
Perlwitz etal (2009) used computer model suites to contend  that the 2008 North American cooling was naturally induced as a result  of the continent’s sensitivity to widespread cooling of the tropical (La  Nina) and northeastern Pacific sea surface temperatures.
But they  concluded from their models that warming is likely to resume in coming  years and that climate is unlikely to embark upon a prolonged period of  cooling. We here show how their models fail to recognize the  multidecadal behavior of sea surface temperatures in the Pacific Basin,  which determines the frequency of El Ninos and La Ninas and suggests  that the cooling will likely continue for several decades. We show how  this will be reinforced with multidecadal shift in the Atlantic.
Here’s the paper you can download:
Click for full report (PDF)
UPDATE: The goodness of fit,  seems almost too good. There may be a reason. I’m reminded in comments of this article by statistician William Briggs – (thanks Mosh)
Do not smooth times series, you hockey puck!
Where he points out:
Now I’m going to tell you the great truth of time series analysis.  Ready?  Unless the data is measured with error, you never, ever, for no reason, under no threat, SMOOTH the series! And if for some bizarre reason you do smooth it, you absolutely on pain of death do NOT use the smoothed series as input for other analyses!   If the data is measured with error, you might attempt to model it  (which means smooth it) in an attempt to estimate the measurement error,  but even in these rare cases you have to have an outside (the learned word is “exogenous”) estimate of that error, that is, one not based on your current data.
If, in a moment of insanity, you do smooth time series data and you do use it as input to other analyses, you dramatically increase the probability of fooling yourself!  This is because smoothing induces spurious signals—signals that look real to other analytical methods.   No matter what you will be too certain of your final results!   Mann et al. first dramatically smoothed their series, then analyzed  them separately.  Regardless of whether their thesis is true—whether  there really is a dramatic increase in temperature lately—it is  guaranteed that they are now too certain of their conclusion.
Perhaps Mr. Briggs can have a look and expound in comments. I only have the output, not the method. But let’s find out and determine how good the “fit” truly is. – Anthony
UPDATE: Statistician Matt Briggs responds in depth here. He says:
I want to stress that if D&E did not smooth their data, the  correlation would not have been as high; but as high as it would have  been, it would still have been expected.   All that smoothing has done  here is artificially inflated the confidence D&E have in their  results.   It does not change the fact that AMO + PDO is well correlated  with air temperature.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8826965b',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterThis just released prestigious report is not going to please the IPCC scientists. It calls for a profound change of course in climate research.

Snip of the report’s front cover.
The Research Council Of Norway has conducted a comprehensive evaluation (see right side bar) of the status of climate science in Norway and released their results. The document: Norwegian Climate Research – An Evaluation writes, “This evaluation provides a critical review of Norwegian climate research in an international perspective and recommends measures to enhance the quality, efficiency and relevance of future climate research.”
Hat-tip to Dr Sebastian Lüning and Dr. Jan-Erik Solheim.
In early 2011, the Norwegian Research Council (RCN) appointed a committee to review Norwegian climate research. The aim of the evaluation was to provide a critical review of Norwegian climate research in an international perspective and to recommend measures to enhance the quality, efficiency and relevance of future climate research.
Key findings of the report are found on page 22, and include the following (my emphasis):



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Although the expressed political needs regarding science results primarily relate to the impact of anthropogenic greenhouse gasses, there is also a need for increased research on the impact of human activity on land cover and land-use change, especially in relation to the albedo and the biogeochemical and hydrological cycles. Furthermore, a good understanding of the climate system cannot be reached without a dedicated effort to understand the contribution to climate change from natural climate processes. The geological history very clearly documents a strong climate forcing associated with solar variability, although the exact mechanism has not been identified. This should call for a coherent international effort, but surprisingly, the worldwide scientific effort to increase our understanding of the natural variations is very limited, and this is most probably related to the limited funding available for basic, not agenda-driven research. Therefore, in addition to implementing the recommendations of Klima21, this committee recommends an increased effort in research on the natural causes of climate change, in particular the activity variations of the sun, the mechanism of cloud formation, and the multi-decadal variations in ocean current systems.
2.1.1.7 Summary of key findings
Largely funded by RCN, Norway has developed internationally recognised top competency in many of the scientific disciplines that are necessary for understanding current climate and its development. In particular, the numerical comprehensive climate and Earth system models are highly regarded. Less effort has been devoted to studying and explaining the natural causes of climate change because these have been regarded as having a relatively minor impact on the climate system and global temperature compared with the effect of man-made greenhouse gasses. In setting priorities, Norwegian climate research is in harmony with the mainstream of international climate science, but, taking into account the strong competencies in a wide spectrum of disciplines, an increased effort to understand the basic natural climate processes could be advantageous for Norwegian climate research.
Moreover, page 9 adds that: “…more effort is needed to understand natural climate variability in order to better quantify the uncertainty in predicting future climate.”
Obviously the Research Council of Norway feels the climate models are inadequate and need a good dose of improvement and getting back to reality.
Clearly the report shows that more and more scientists are now realizing that a course correction is needed in climate research, and that the focus has to shift to natural causes.
 
Share this...FacebookTwitter "
"

Oklahoma Attorney General Scott Pruitt’s nomination for administrator of the Environmental Protection Agency is as clear a signal as the incoming administration can send with regard to its environmental policies. 



It is also a sign that the administration is far more meticulous, internally consistent and thorough than its detractors have thought, and that it is on a clear mission not just to stop, but to reverse many of the actions of Obama’s EPA.



It is noteworthy that global warming was the second action item mentioned in President Obama’s 2009 inaugural, and that a mere 90 days later, the administration had issued a “preliminary finding of endangerment” from carbon dioxide and other greenhouse emissions.



Under their interpretation of the Supreme Court’s landmark 2007 climate change ruling, Massachusetts vs. Environmental Protection Agency, such a finding not only permitted the EPA to regulate carbon dioxide under the Clean Air Act Amendments of 1992, it compelled the agency to do so.





Fasten your seat belts, for we may be about to witness the scientific‐​cat fight of our time.



Seven years ago, on Pearl Harbor Day 2009, the administration announced its final Endangerment Finding. By March, Pruitt and 15 other state AG’s joined in a combined suit against it, which was ultimately not successful.



As long as the Endangerment Finding stands, any EPA, including one headed by Pruitt, will be in court defending against any subsidiary attempt to halt or reverse any regulation of carbon dioxide.



It may very well be held that the EPA remains responsible for regulation under the Supreme Court’s 2007 decision unless there is a specific act of Congress reversing its progeny policies, such as the Clean Power Plan. So the Endangerment Finding must be reversed.



But how to do it? For years, federal agencies have thrown massive support at scientists who, as human beings, serve their best interests (and their employer‐​universities) by generating horror‐​show results that also generate more support and professional advancement.



The Trump administration is going to have to stock up on scientists and administrators who are savvy to this game, and they are going to be very hard to find, as there’s very little incentive to not play along.



There’s going to have to be a massive effort to pick apart failing climate models and questionably‐​adjusted data. They’re going to have to find people willing to expose the current regime’s blatant abuse of logic in generating inflated “costs” of global warming, while largely ignoring the co‐​benefits of fossil fuel power, like doubled life expectancy and undreamt‐​of wealth.



The academy is going to howl, and Washington’s science lobbies, like the American Association for the Advancement of Science (headed by Democratic ex‐​congressman Rush Holt) are going to go berserk.



Fasten your seat belts, for we may be about to witness the scientific‐​cat fight of our time.



On one side will be a massive and entrenched establishment, defending models that we now know were (and this is truly shocking) often adjusted to give a predetermined result. On the other will be a dogged and far smaller clan, tearing apart the code of these models, much like the ENIGMA busters of Bletchley Park. This will get ugly.



In nominating Pruitt, the administration is signaling that it is clearly up to such a fight — and not just over climate change.



He is also on record as being against EPA’s most recent interpretation of Section 404 of the Clean Water Act, which was used to pre‐​emptively prohibit the owners of what may be the largest copper‐​gold‐​molybdenum deposit on earth, the Pebble deposit in southwestern Alaska, from even applying for a permit to mine. This, even though it is on land zoned for mining by the State of Alaska.



Our friends in the environmental movement should rightly be at Defcon Five. It appears that President‐​Elect Trump — in many ways just like his predecessor — is going to keep his environmental campaign promises, which means reversing eight years what many feel was an era of green overreach.



Remember that Obama said he would “bankrupt” anyone foolish enough to build a new coal‐​fired power plant, because he would render them unprofitable. That’s just what his Clean Power Plan does. Trump promises to nix it.



The nomination of Scott Pruitt is further evidence that the president‐​elect is serious, and circumstantial evidence that the influence of Al Gore’s recent visit was of little consequence.
"
"
by Jill Sakai, University of Wisconsin
Though still under construction, the IceCube Neutrino Observatory at the South Pole is already delivering scientific results — including an early finding about a phenomenon the telescope was not even designed to study.


This “skymap,” generated in 2009 from data collected by the IceCube Neutrino Observatory, shows the relative intensity of cosmic rays directed toward the Earth’s Southern Hemisphere. Researchers from UW-Madison and elsewhere identified an unusual pattern of cosmic rays, with an excess (warmer colors) detected in one part of the sky and a deficit (cooler colors) in another.

IceCube captures signals of notoriously elusive but scientifically fascinating subatomic particles called neutrinos. The telescope focuses on high-energy neutrinos that travel through the Earth, providing information about faraway cosmic events such as supernovas and black holes in the part of space visible from the Northern Hemisphere.
However, one of the challenges of detecting these relatively rare particles is that the telescope is constantly bombarded by other particles, including many generated by cosmic rays interacting with the Earth’s atmosphere over the southern half of the sky. For most IceCube neutrino physicists these particles are simply background noise, but University of Wisconsin-Madison researchers Rasha Abbasi and Paolo Desiati, with collaborator Juan Carlos Díaz-Vélez, recognized an opportunity in the cosmic ray data.
“IceCube was not built to look at cosmic rays. Cosmic rays are considered background,” Abbasi says. “However, we have billions of events of background downward cosmic rays that ended up being very exciting.”
Abbasi saw an unusual pattern when she looked at a “skymap” of the relative intensity of cosmic rays directed toward the Earth’s Southern Hemisphere, with an excess of cosmic rays detected in one part of the sky and a deficit in another. A similar lopsidedness, called “anisotropy,” has been seen from the Northern Hemisphere by previous experiments, she says, but its source is still a mystery.
“At the beginning, we didn’t know what to expect. To see this anisotropy extending to the Southern Hemisphere sky is an additional piece of the puzzle around this enigmatic effect — whether it’s due to the magnetic field surrounding us or to the effect of a nearby supernova remnant, we don’t know,” Abbasi says.
The new result publishes Aug. 1 in The Astrophysical Journal Letters, published by the American Astronomical Society.
You can read the rest of the article here…


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a10a901',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"The world’s largest investment banks have funnelled more than £2.2tn ($2.66tn) into fossil fuels since the Paris agreement, new figures show, prompting warnings they are failing to respond to the climate crisis. The US bank JP Morgan Chase, whose economists warned that the climate crisis threatens the survival of humanity last month, has been the largest financier of fossil fuels in the four years since the agreement, providing over £220bn of financial services to extract oil, gas and coal. Analysis of the 35 leading global investment banks, by an alliance of US-based environmental groups, said that financing for the companies most aggressively expanding in new fossil fuel extraction since the Paris agreement has surged by nearly 40% in the last year. Using Bloomberg financial data and other sources to analyse loans, equity issuances and debt underwriting services from 2016 to 2019, the analysis is published on Wednesday in the Banking on Climate Change 2020 report. It has been compiled by Rainforest Action Network, BankTrack, Indigenous Environmental Network, Oil Change International, Reclaim Finance and Sierra Club. Although the last 12 months has seen many investment banks announce financing restrictions on coal, Arctic oil and gas, and tar sands extraction, the report warns that the business practices of financial institutions are not aligned with the Paris agreement. Alongside JP Morgan Chase, the US banks Wells Fargo, Citi and Bank of America dominate financing for fossil fuels, accounting for nearly a third of the £2.2tn of financial services since the Paris agreement, according to the report. The report said big banks overall have increased their funding in the four years since Paris to companies with significant Arctic oil and gas reserves. Alison Kirsch, a researcher at Rainforest Action Network who led the analysis in the report, said: “The data reveal that global banks are not only ramping up financing of fossil fuels overall, but are also increasing funding for the companies most responsible for fossil fuel expansion.” Barclays, which has been under increasing investor pressure over its environmental stance, has been the top European financier of fossil fuels in the last four years, the figures show. Last year, the London-based bank was the largest financier of Arctic oil and gas, according to the figures. A group of influential shareholders are now urging the bank to phase out lending to fossil fuel companies, and have filed a resolution to be voted on at Barclays’ AGM in May. Fracking has been the focus of intense business activity by investment banks since the Paris agreement, with JP Morgan Chase, Wells Fargo and Bank of America leading £241.53bn of financing, much of it linked to the Permian basin in Texas. The Royal Bank of Canada and Toronto Dominion led financing for tar sands crude oil projects in Alberta, north-west Canada, which have caused widespread damage to ecosystems. The big-four Chinese banks have dominated financing for coal mining and coal power since the Paris agreement and have no policies restricting business practices. Kirsch said: “This makes it crystal clear that banks are failing miserably when it comes to responding to the urgency of the climate crisis. As the toll of death and destruction from unprecedented floods, droughts, fires and storms grows, it is unconscionable and outrageous for banks to be approving new loans and raising capital for the companies that are pushing hardest to increase carbon emissions.” Ahead of the next major international climate talks, Cop26 in Glasgow this November, the UK government has sought to make the business and the banking sector the focus of tacking the climate crisis. The former head of the Bank of England Mark Carney has been appointed as a climate envoy, warning that businesses must improve how they disclose their impact on the environment or risk failing to meet climate targets. Johan Frijns, director of BankTrack, an NGO which monitors the activities of major financial institutions, said it was time for banks to commit to phasing out financing for all new fossil fuel projects. “In the last year, banks have been queueing up to proclaim support for the goals of the Paris agreement. Both the Principles for Responsible Banking and the new Equator Principles, each signed by over a hundred banks, acknowledges the global climate goals. Yet the data in Banking on Climate Change 2020 show these laudable pledges making little difference, and bank financing for the fossil fuel industry continuing to lead us to the climate abyss,” he said. “It is high time banks recognised that reaching the Paris climate goals requires an immediate end to finance for all new fossil fuel projects, and a rapid phase-out of existing fossil finance. This should be the Global Glasgow Goal for all banks.” JPMorgan Chase said the commitments it announced last month “reflect our ongoing efforts to help address climate change and promote more sustainable development”. It added: “This includes financing to support climate action and the United Nations Sustainable Development Goals, backing market-based policy solutions to reduce carbon emissions, expanding restrictions on financing for coal mining and coal-fired power, and prohibiting project financing for new oil and gas development in the Arctic.” The bank looked forward, it said, to growing “its impact over time”. A Barclays spokesperson said: “We are working hard to help tackle climate change including facilitating £34.8bn of social and environmental financing last year. We continue to engage with ShareAction and other stakeholders on how we can make further progress.” Wells Fargo told the Guardian that it believes that climate change is one of the most urgent environmental and social issues of our time, and is committing to a low-carbon economy. The bank said it is working to measure and report on the carbon intensity of its credit portfolio. A Bank of America spokesperson said they recognise their role in managing climate risk and in financing the transition to a low-carbon economy. Citigroup did not respond when contacted by the Guardian for comment."
"The UN’s proposed sustainability targets are riddled with conflicts that could make them ineffective or outright harmful.  In theory, there is nothing wrong with such targets. After all, the Millennium Development Goals (MDGs) had mixed success on health, education and poverty but established the principle that measuring key indicators was a good way to at least begin tackling major issues. Now, with increasing concern over environmental degradation and climate change the Sustainable Development Goals (SDGs) are currently being negotiated as the successors to the MDGs.  Despite a huge effort in setting these goals, the compartmentalisation of major areas such as energy, water and the economy means that they are already in conflict – and this is before climate change is even added. The latest set of sustainability goals was drafted by a UN working group and presented to the UN General Assembly in September. What we have ended up with is a set of 17 goals, each with various sub-goals, which cover everything from poverty and education to water, climate change and sustainable cities.  While at first glance they appear comprehensive and ambitious, further examination reveals a potentially dangerous lack of understanding of how the different goals will affect each other. As the whole range of goals is so large, we’ll just focus on the interaction between the water, energy and climate change goals. In the official language, those goals are: Goal 6: Ensure availability and sustainable management of water and sanitation for all Goal 7: Ensure access to affordable, reliable, sustainable, and modern energy for all Goal 13: Take urgent action to combat climate change and its impacts Goals 8 and 9 on economic growth and “sustainable” industrialisation are phrased in such a way that they will impact most others, so we’ll consider them too. The above graphic illustrates the ways in which the three goals might affect each other and not always in a positive way. The conflicts are caused, to some degree, by the very nature of the goals.  The water goal focuses on water provision and access to modern water services. The proposed model of provision is  very Western, based on large infrastructure projects, low levels of water re-use and high energy use.  For example, achieving universal access to drinking water and sanitation could be achieved by expanding desalination and waste-water processing, both of which are highly energy intensive. So achieving the water SDGs seems likely to increase energy use, undermining other goals. The energy goal itself appears to be lifted from Ban-Ki Moon’s Sustainable Energy for All initiative. The concern is that it prioritises access and affordability and the very word “sustainable” is absent from the sub-goal that states: “by 2030 ensure universal access to affordable, reliable, and modern energy services”. Without sustainability within this goal, the risk is that countries will focus on coal or gas to ensure they achieve it. This is compounded by the unambitious and vague goals around renewable energy: “increase substantially the share of renewable energy in the global energy mix by 2030” and “double the global rate of improvement in energy efficiency by 2030”.  We would hazard to suggest that, if globally we only “substantially increase” renewable energy share and the rate of energy efficiency improvement (both are only relative, not absolute, targets), then there is very little chance of meeting the climate change SDGs. Energy production and industry also use lots of water, making the water access goals harder to achieve. In both cases, it is the concrete, tangible targets that don’t take into account sustainability and environmental impact. For other “aspirational” goals, such as:  Goal 6.6: By 2020 protect and restore water-related ecosystems, including mountains, forests, wetlands, rivers, aquifers and lakes. It’s hard to say what it might look like in practice, or how it is to be measured. Is it compatible with 6.1: “By 2030, achieve universal and equitable access to safe and affordable drinking water for all”? All that affordable water has to come from somewhere; that somewhere probably means rivers and lakes full of plants and fish and potentially unsustainable new dams or reservoirs. Even aside from the cross-SDG conflicts, the problem with the climate change goals is they do not exactly exist yet. Goal 13 acknowledges that the UN Framework Convention on Climate Change is the international forum for setting climate change targets. However slow progress in negotiations means that the new targets from the UNFCCC will not be agreed until after the official announcement of the SDGs in September 2015.  Of course, as our graphical analysis suggests, if national governments choose to prioritise goals such as: 8.1: Sustain per capita economic growth in accordance with national circumstances, and in particular at least 7% per annum GDP growth in the least-developed countries. and  9.2: Promote inclusive and sustainable industrialisation and by 2030 raise significantly industry’s share of employment and GDP in line with national circumstances and double its share in LDCs [least developed countries]. then all other actions will be constrained. In such a scenario, it seems unlikely that the goals on water, energy or climate change will be achieved.  Such absolute, rather than qualified, targets for economic growth and industrialisation are extremely likely to lead to greater levels of energy demand, water use and GHG emissions. Such confusion emphasises the persistent lack of an environmental, climate change or sustainable development champion within the UN system. If it is left to the existing UN organisations to achieve the targets in their focus areas without sufficient dialogue and co-operation we are likely to see some unexpected and unwanted results. What is now required is a thorough assessment of what checks can be put in place to ensure that the Sustainable Development Goals are genuinely sustainable, as well as what potential negative interactions could take place between the goals. Without this, we might have some goals but we won’t have sustainable development."
"
Share this...FacebookTwitterThe German langauge Voice of Russia here reports a news item you’ll never hear from the mainstream media. Top scientists of Russia’s most prestigious academy say global warming is ending.
Hat-tip: European Institute for Climate and Energy.
Here’s the Voice of Russia report I’ve translated in English:
Global warming is coming to an end: In the coming years the temperature over the entire planet will fall and the cooling will provide a character of relief. This is the conclusion reached by Russian scientists from the Physics University of the Russian Academy of Science.
The process of a general temperature decrease has already begun, according to the research. After having peaked in 2005, the average temperature on Earth is now returning to the level of the 1996-1997 years, 0.3°C lower.
According to the scientists, global temperatures will fall another 0.15°C by 2015, which corresponds to the climate of the early 1980s.”
Wow! More great news that rebut the claims of the climate catastrophe. I’d think the media and western political readers would embrace all this and be relieved.
The persons most relieved to hear this should be the panicky James Hansen and Al Gore. Surely they’ll be very happy to hear this news.
Now climate scientists can go back to the old narrative of the early 1980s: global cooling!
 
Share this...FacebookTwitter "
"
This graphic, seen on many websites, was not part of Vonk's essay, but added by Anthony to visually tag the topic

Guest Post by Tom Vonk
In a recent post I considered the question in the title. You may see it here : http://wattsupwiththat.com/2010/08/05/co2-heats-the-atmosphere-a-counter-view/
The post generated great deal of interest and many comments.
Even if most of the posters understood the argument and I answered the comments of those who did not, I have been asked to sum up the discussion.
Before starting, I will repeat the statement that I wished to examine.

“Given a gas mixture of CO₂ and N₂ in Local Thermodynamic Equilibrium (LTE) and submitted to infrared radiation, does the CO₂ heat the N₂?”

To begin, we must be really sure that we understood not only what is contained in the question but especially what is NOT contained in it.



The question 	contains no assumption about the radiation. Most importantly there 	is no assumption whether a radiative equilibrium does or does not 	exist. Therefore the answer will be independent from assumptions 	concerning radiative equilibrium. Similarly all questions and 	developments concerning radiative transfer are irrelevant to the 	question.



The question 	contains no assumption about the size or the  geometry of the 	mixture. It may be a cube with a volume of 1 mm³ or a column of 10 	km height. As long as the mixture is in LTE, any size and any 	geometry works.



The question 	contains no assumption about boundary conditions. Such assumptions 	would indeed be necessary if we asked much more ambitious questions 	like what happens at boundaries where no LTE exists and which may be 	constituted of solids or liquids. However we do not ask such 	ambitious questions.


Also it is necessary to be perfectly clear about what “X heats Y” means.
It means that there exists a mechanism transferring net (e.g non zero) energy unidirectionaly
from X to Y .
Perhaps as importantly, and some posters did not understand this point, the statement
“X heats Y” is equivalent to the statement “Y cannot cool X”.
The critical posts – and here we exclude posts developing questions of radiative transfer which are irrelevant as explained in 1) above – were of 2 types.

Type 1

The argument says “LTE never exists or alternatively LTE does not apply to a mixture of CO₂ and N₂.”
The answer to the first variant is that LTE exists and I repeat the definition from the original post : “A volume of gas is in LTE if for every point of this volume there exists a neighborhood in which the gas is in thermodynamic equilibrium (TE)”
2 remarks to this definition:


It is not said 	and it is not important how large this neighborhood of every point 	is. It may be a cube of 1 mm³ or a cube of 10 m³ . The important 	part is that this neighborhood exists (almost) everywhere.



LTE is 	necessary to define local temperature. Saying that LTE never exists 	is equivalent to saying that local temperatures never exist.


The second variant admits that LTE exists but suggests that a mixture of CO₂ and N₂ cannot  be in LTE.
The LTE conditions are given when energy at every point is efficiently spread out among all available degrees of freedom (translation, rotation, vibration).
The most efficient tool for energy spreading are molecular collisions.
Without going in a mathematical development (see statistical thermodynamics for those interested), it is obvious that LTE will exist when there are many molecular collisions per volume unit.
This depends mostly on density – high density gases will be often in LTE while very low density gases will not.

For those not yet convinced, hold out a thermometer in your bedroom and it is probable that it will show a well defined temperature everywhere – your bedroom is in LTE .
We deal here with a mixture of CO₂ and N₂ in conditions of the troposphere which are precisely conditions where LTE exists too.

Type 2

The argument says “The mean time between collisions is much shorter than the mean decay time (e.g time necessary to emit a photon) and therefore all infrared energy absorbed by the CO₂ molecules is immediately and unidirectionaly transferred to the N₂ molecules.”
In simple words – the CO₂ never has time to emit any IR photons because it loses vibrational energy by collisions instead.
This statement is indeed equivalent to the statement “CO₂ heats N₂”.




Now let us examine the above figure.
The good understanding of this figure will do much better than only answering  the original question. It will also make clear to everybody what is really happening in our gas mixture in LTE.
The figure shows the distribution of the kinetic energy (Ox axis) among the N₂ molecules (Oy axis).
This typical curve is called the Maxwell Boltzmann distribution, has been known for more than 100 years and experimentally confirmed with high accuracy.

We know that the temperature is defined by <E>, the energy average.
Hence it is the curve shown in the figure that defines the temperature of a gas.
Another way to say the same thing is to say that the curve depends only on temperature. If we wanted to have the distribution for another  gas than N₂ , f.ex CO₂ or O₂, it would be given by an identical curve.
The blue curve gives the distribution of kinetic energy at 25°C while the red curve gives the distribution at 35°C.
The minimal energy is small but non-zero and there is no maximal energy.
A very important point on the Ox axis is the energy of the first vibrationally excited state of a CO₂ molecule.
You notice that at 25°C the majority of N₂ molecules has insufficient kinetic energy to excite this vibrational state.
Only the proportion of them given by the dark blue surface has enough energy to excite the vibrational state by collision.
When the temperature increases to 35°C, you notice that the proportion of N₂ molecules able to excite the vibrational CO₂ state by collision has significantly increased .
This proportion is given by the sum of the dark blue and light blue surface.
You also notice that as there exists no maximal energy, there will be a proportion of N₂ molecules able to  excite the vibrational CO₂ state at any temperature.

Trivial so far? Well it will not get much more complicated.
First 2 technical points which play no role in the argument but which I would like to mention for the sake of completness.


The figure 	shows the translational kinetic energy. Even if in some (popular) 	literature the temperature is defined as being an average of the 	translational kinetic energy, this is not strictly true.

The temperature is really defined as an average of all energy modes. So what about the vibrational and rotational energy?
At the low tropospheric temperatures we are considering, the distribution of the vibrational energy is extremely  simple : about 5% or less of the molecules are in the first excited state and 95% or more are in the ground state.
As for the rotational energy, it can be computed classically without quantum corrections and the result is that it also follows a Maxwell Boltzmann distribution.
Therefore if we wished to plot the total energy (Etranslational + Evibrational + Erotational) we would rescale the Ox axis and obtain exactly the same curve as the one that is shown.
However as we are interested in studying the T/V interactions, it is the curve of the translational kinetic energy that interests us.


We find the 	omnipresence of LTE again. This curve has been derived and 	experimentally confirmed only, and only if,  the gas is in TE. 	Therefore the following 2 statements are equivalent :

“The gas is in LTE” , “The energy distribution at every point is given by the Maxwell Boltzmann distribution” .
If you feel that these statements are not equivalent, reread carefully what is above.

Now we can demonstrate why the Type2 argument is wrong.

Imagine that you mix cold N₂ represented by the blue curve in the Figure with highly vibrationally excited CO₂. The mixture would then not be in LTE and a transient would take place.
In the molecular process (1) CO₂* + N₂ → CO₂ + N₂⁺ which says that a vibrationally excited CO₂ molecule (CO₂*) collides with an N₂ molecule , decays to the ground state (CO₂) and increases the translational kinetic energy of N₂ (N₂⁺) , there would be a net energy transfer from CO₂* to N₂ .

As a result of this transfer the temperature of N₂ would increase and the blue curve would move to the red one.
However doing that, the number of molecules able to excite CO₂ vibrationally would increase (see the blue surfaces in the figure).
That means that during the increase of the temperature of N₂ , the rate of the opposite molecular process (2) CO₂ + N₂⁺ → CO₂* + N₂ where N₂ molecules (those from the blue surface in the figure)  vibrationally excite CO2 molecules, will increase too.

Of course the transient net energy transfer from CO₂ to N₂ will not continue forever because else the mixture would transform into superheated plasma.
A local equilibrium will be established at each point and in this equilibrium the rate of the process (1) will be exactly equal to the rate of the process (2). 
The curve of energy distribution will stop moving and the Maxwell Boltzmann distribution will describe this distribution at every point.

This is exactly the definition of LTE.
The transient will stop when the mixture reaches LTE and its characteristic feature is that there is no local net energy transfer from CO₂ to N₂.
This result demonstrates both that the Type2 argument is wrong and that the answer on the question we asked at the beginning is “No”.
In very simple words, if you take a small volume (for example 1 m³) of the CO₂ and N₂ mixture in LTE around any point ,  then there cannot be any net energy transfer from CO₂ to N₂ within this volume.

To establish the last step we will take the following statements.


The result 	obtained for the CO₂ and N₂ mixture in LTE is equally true for a 	mixture containing  78% of N₂ , 21% of O₂ , x% of CO₂ and 1-x 	% H₂O in LTE.



The mixture 	defined above approximates well the troposphere and the troposphere 	is indeed in LTE



From the 2 	statements above and the demonstrated result follows :

“The CO₂ does not heat the troposphere” what is the answer on the question asked in the title.


Caveat1

I have said it both in the initial post and in this one.
Unfortunately, I know that it can’t be avoided and that some readers will still be confused about the result established here and start considering radiative transfers or radiative equilibriums.
That’s why I stress again that LTE and the result established here is totally independent of radiative equilibriums and radiative transfer properties.

However it does falsify one misconception concerning radiative properties of CO₂ that has also figured in the comments and that is that “CO₂ does not  radiate at 15µ because it “heats” N₂ instead”.

It is also to be noted that we consider only the T/V process because it is only the vibrational modes that interact with IR radiation.
There are also rotational/translational and rotational/vibrational transfers.
The same argument used for T/V applies also for the R/T and R/V processes in LTE – e.g there is no net energy transfer between these modes in LTE even if for example the R/T process has a much higher probability than a T/V process.
For the sake of clarity we don’t mention specifically the R/T and R/V processes.

Caveat2

The result established here is a statistical thermodynamics bulk property.
This property is of course not sufficient to establish the whole dynamics of a system at all time and space scales.
If that was our ambition – and it is not – then we would have to consider boundary conditions and macroscopic mass, momentum and energy transfers, e.g convection, conduction, phase changes, lapse rates etc.
More specifically this result doesn’t contradict the trivial observation that if one changes the parameters of the system, for example composition, pressure, radiation intensity and spectrum, etc,  then the dynamics of the system change too.

Yet it contradicts the notion that once these parameter are fixed there is a net transfer of energy from CO₂ to the troposphere. There is not.

Caveat3

It will probably appear obvious to most of you but it has also to be repeated.
This result says little about comparisons between the dynamics of 2 very different systems such as, for example, an Earth without oceans and atmosphere, and an Earth with oceans and atmosphere. Clearly the dynamics will be very different but it stays that in the case of the real Earth with an atmosphere in LTE, there will be no net energy transfer from the CO₂ to the atmosphere.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8959e795',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

 ** _State legislatures should_**



• enact punitive damages reforms;  
• eliminate joint and several liability;  
• strengthen judicial review of dubious expert testimony; and  
• prohibit government litigants from engaging private attorneys on contingency fee.



 ** _Congress should_**



• restore meaningful sanctions for meritless litigation in federal court;  
• constrain courts’ long‐​arm jurisdiction over out‐​of‐​state defendants;  
• enact a federal choice‐​of‐​law rule for multistate litigants in product liability cases; and  
• implement further reforms for class actions that cross state lines.



 ** _Both state legislatures and Congress should_**



• strengthen the role of contract and consent‐​based alternatives to tort litigation, including predispute arbitration, venue selection, disclaimers of liability, and assumption of risk.



Although America has long been considered a litigious nation, its lawsuit sector really took off after the 1960s, following changes in the law aimed at making it easier to sue. As a share of the U.S. economy, tort costs are two‐​and‐​a‐​half times as high as in Western Europe and four times as high as they were after World War II. The direct cost of American tort litigation is upward of $250 billion a year, a figure that does not include important categories such as securities litigation and the multistate tobacco settlement. In a global marketplace, that means costs are not competitive, business investment is discouraged, there are fewer jobs, and wealth is reduced.



Widely shared discontent over the many ill effects of litigation has made lawsuit reform a popular issue at both state and federal levels. At the state level, advocates have enjoyed considerable success. For example, with California’s Medical Injury Compensation Reform Act in the lead, most states have enacted curbs on medical malpractice litigation. The result has been a turnaround in what was once a soaring rate of claims and insurance rate increases associated with that sector.



At the federal level, reform has faced tougher resistance. It is true that Congress has enacted two broad‐​based reform laws, applying to securities litigation and to multistate class actions, as well as a number of more specialized bills pertaining to specific areas, such as gun liability and small aircraft liability. One reason the federal government has not taken the lead in more areas is that the predominant share of injury litigation goes on in state courts, rather than federal. Under our constitutional structure, though the federal government does play some role in supervising state courts (for example, when they infringe on constitutional rights, or when one state rules on matters affecting the rights of residents of other states), that role does not extend to broadly displacing state authority over conventional, usually smaller, in‐​state disputes.



Because of the strong ongoing interest in state‐​level reform, lawmakers can choose from a large menu of ideas that have proved themselves in other states. Here are four.



First, states should limit or abolish the availability of punitive damages in civil cases. One good beginning would be to limit them to cases involving actual malice, intentional wrongdoing, or gross — as distinct from ordinary — negligence. Punitive damages share some of the functions of criminal law, and thus call for — yet commonly lack — procedural protections that parallel those afforded criminal defendants. Among those protections is a higher burden of proof than the usual civil standard, which is preponderance of the evidence. Another is double jeopardy protection. Current rules allow punitive damage claims over the same conduct to be made again and again in multiple lawsuits. Another is protection against coerced self‐​incrimination by way of compulsory discovery. Many modern jurisdictions do not allow civil claims for punitive damages at all.



Second, states should dispense with joint and several liability. That’s the “deep pockets” rule that permits plaintiffs to collect all of a damage award from any one of multiple defendants, even if the paying defendant was responsible for only a small fraction of the harm. The better rule is to apportion damages in accord with defendants’ degree of culpability.



Third, holdout states should join the predominant trend toward stronger judicial review of expert testimony (so‐​called Daubert review, after the leading Supreme Court case) to cut down on speculative litigation based on flimsy scientific premises.



Fourth, contingency fee contracts between private lawyers and government entities should be prohibited. Private lawyers acting on behalf of government should bear the same ethical responsibility as in‐​house government lawyers — as public servants beholden to all citizens, including the defendant, and obliged to seek justice. Imagine a state attorney receiving a contingency fee for each indictment, or a state trooper receiving a bonus for each speeding ticket. Contingency fees are equally corrupting.



The Constitution foresees a number of roles for Congress in supervising civil litigation. The least controversial is Congress’s power to prescribe rules for the handling of lawsuits brought in federal courts and those based on the federal government’s own laws. One example is sanctions against meritless litigation in federal courts under so‐​called Rule 11. Congress should enact a measure restoring strong sanctions, which were unwisely cut in 1993 after a decade‐​long experiment in vigorous sanctions. Sanctions should be based on the monetary cost of responding to meritless claims and motions, as specified in the bill known as the Lawsuit Abuse Reduction Act.



Congress also has considerable power to supervise the doings of state courts — for example, when those courts violate litigants’ due process, impair the obligation of contract, or abridge the privileges and immunities of citizens of other states. But its power is not “plenary,” or unlimited; it may act only when it can cite constitutional authority. Some proposals for federal‐​level malpractice reform, for example, are unwisely premised on broad New Deal readings of the power to regulate interstate commerce.



On a practical level, not every national problem requires a federal solution. Most states have capped damages in health care suits, with favorable results for their climate of medical practice, and virtually all have at least considered reforms. In the long run, excessive lawsuit recoveries by in‐​state plaintiffs against in‐​state doctors over in‐​state therapy are likely to generate in‐​state political pressure for reform. The substantive rules of tort law are not commerce, and proposals to override them with federal law because they have some indirect effects on interstate commerce have no obvious stopping point. Congress is better off focusing its energy on lawsuits in which a state is tempted to assert its sovereignty beyond its borders through its courts. Federal procedural reforms do have an important role to play in curbing that behavior.



A guiding principle in supervising interstate litigation is that federal lawmakers and courts are authorized to act when there is a high risk that states will appropriate wealth from the citizens of other states. One federal reform consistent with that principle is to amend the currently lax and ambiguous rules that control state exercise of so‐​called long‐​arm jurisdiction over out‐​of‐​state businesses. Congress might, for example, preclude a local court from hearing a case unless the defendant engages directly in business activities within the state. A company’s mere awareness that the stream of commerce could sweep its product into a particular state should not suffice to confer jurisdiction. A sensible rule would give firms an exit option — that is, they could withdraw from a state and thus avoid the risk of a runaway jury, even if a product somehow ends up in the state.



A second federal reform compatible with federalist principles is a federal choice‐​of‐​law rule to prescribe which law governs in cases where plaintiff and defendant in product liability cases are from different states. It might provide that the applicable law is that of the state where the manufacturer was located, or where the product was first sold to a consumer. Consumers would be on notice of the system and could evaluate the rules, if of a state other than theirs, when deciding whether to buy a particular manufacturer’s product. States would be more likely to balance the voting interest of in‐​state consumers against the in‐​state benefit of a healthy retail or manufacturing sector. In effect, competition among the states would enlist federalism as part of the solution to bad incentives.



Multistate class actions were once a rarely used procedural device designed to litigate an assemblage of largely identical claims. In the last half century, they have morphed into a commonly used device for bundling cases that are often quite dissimilar but which together may command a higher settlement value and steering them into a favorable court.



The 108th Congress attempted to address the latter problem in the Class Action Fairness Act of 2005 (CAFA) by giving defendants the power to remove some class suits from state to federal courts. Although helpful, CAFA left unresolved many issues that courts have had to address through prolonged litigation. Congress should clarify CAFA’s gaps and advance the fairness of the process in ways that go beyond the 2005 law. Following are three suggestions to address gaps and four suggestions to go further.



First, under CAFA, a class action can be removed to federal court so long as at least one‐​third of the class members reside outside the state where the suit was filed and the amount at stake overall exceeds $5 million. The amount‐​in‐​controversy threshold, in particular, occasions needless litigation since plaintiffs’ damage theories at the outset of a case may lack specifics. Congress can and should clarify what types of evidence and level of certainty are needed to establish a basis for removal. In general, because most national class actions do seek more than the $5 million threshold, Congress should set a rebuttable presumption in favor of removal for national classes.



Second, the key make‐​or‐​break stage in a case is typically the motion for class certification. CAFA did not explicitly provide that one federal court’s denial of certification bars attempts to relitigate the question before other federal courts. Congress should spell out that federal courts have power to enjoin multiple bites at the certification apple when one has been adequately argued.



Third, CAFA does not provide a means for removal of cases in which plaintiffs’ lawyers and defendants, in effect, collude against the interests of the class. At present, if they have in mind what is known as a “sweetheart settlement” — one in which the lawyers get a big payoff, defendants get a slap on the wrist, and absent class members recover little or nothing — they can file in a friendly state court and simply not file removal. Congress should provide that absent class members, and not just defendants, can file for removal.



Beyond plugging gaps in CAFA, Congress should seize the opportunity to rethink the class device itself in its current form. The present rules create a presumption that individuals out of court, who have not affirmed their connection to the class, favor being represented on nothing more than the say‐​so of the trial lawyer who steps forward to file the action. Modern class‐​action lawyers often claim to represent the interests of thousands or even millions of people who have no idea that they are litigants at all.



Lawmakers should take four steps to confine class actions to the kinds of cases in which they can best advance justice:



1\. Class action rules should require would‐​be litigants to affirmatively _opt in_ to a class action (for example, by mailing a consent form to the court) before being counted as part of the class.



2\. Class action rules should assure defendants of their due process right to assert defenses that may apply to some but not other individual plaintiffs. Presently, classes are certified even when a governing statute or common‐​law rule requires that key elements of proof — such as reliance, causation, or damages — be shown on an individual basis. That means trial lawyers can use the class device to combine tens of thousands of factually dissimilar claims into one proceeding, making it impossible for defendants to adequately smoke out and identify weak or meritless individual claims. Congress should enact a rule stating that, unless a statute clearly provides otherwise, certification and liability in class actions arising under federal law require proof as to all class members of all the elements of each claim.



3\. Lawmakers should act to head off the problem of certification of classes in low‐​merit cases. Class certification decisions are made very early — before plaintiffs have demonstrated that they have evidence to support their allegations. That allows trial lawyers to game the system by filing cases that are extremely unlikely to succeed at trial, but for which the sheer monetary risk generated by a million‐​member class generates settlement value: Why take even a 1‐​in‐​20 risk of a fluke jury outcome if the stakes are of bet‐​the‐​company magnitude? Congress should nip meritless class actions in the bud by providing that classes may be certified only after the class “representative” — the main plaintiff — is able to make a preliminary factual showing that he or she has a reasonable likelihood of success.



4\. Congress must clarify when, if at all, class actions may go forward on the basis of statistics. Class actions generally must be proved using evidence “common” to all class members, but some federal statutes allow statistical sampling to prove injuries to a large group. Where this is so, plaintiffs sometimes have gotten away with shoddy statistics purporting to show that all class members suffered the same injury. Congress should provide that, before a class action can go forward, plaintiffs’ statistical evidence must meet the same demanding reliability standards imposed on expert evidence sent to a jury.



Allowing parties to set the terms of their own deals reduces the uncertainty that gives rise to litigation and advances the values of individual choice. Yet too often courts and legislators have been hostile to waivers and disclaimers of liability and to contractual provisions that seek to prescribe methods of handling disputes before they arise (such as agreements to arbitrate or mediate, venue selection clauses, and clauses excluding class action treatment of a claim). Arbitration in particular is under attack from organized trial lawyers who would prefer all‐​out, open‐​ended litigation as an alternative. Both state and federal lawmakers should defend consumer arbitration.



Courts and lawmakers have also neglected the vital doctrine of assumption of risk, which gives legal force to the choice consumers make to engage in risky activities, such as recreation. Legislators should act to bolster assumption of risk, where appropriate, by codifying doctrines like the “baseball rule” (spectators at a ball game assume the risk of balls hit into the stands) and suitable doctrines limiting liability for ordinary risks experienced by skiers, hikers, and others in search of recreation.



For the most part, the states have reformed and are continuing to reform their civil justice systems. Under those circumstances, time‐​honored principles of federalism dictate that each state exercises dominion over its substantive tort law. Still, Congress does have appropriate roles to play, both in setting a good example with federal‐​court litigation and in restraining states from exercising inappropriate jurisdiction beyond their borders or discriminating against out‐​of‐​state businesses.



American Tort Reform Foundation. _Judicial Hellholes 2015–2016_. Washington: ATRF, 2015.



Copland, James R. _Trial Lawyers, Inc.: Mass Torts and Class Actions_. New York: Manhattan Institute, 2016.



Judiciary Committee, U.S. House of Representatives. “Lawsuit Abuse Reduction Act of 2013.” Report 113–255. Washington: Government Publishing Office, 2013.



Levy, Robert A. _Shakedown: How Corporations, Government, and Trial Lawyers Abuse the Judicial Process_. Washington: Cato Institute, 2004.



Moller, Mark K. “Common Problems for the Common Answers Test: Class Certification in _Amgen_ and _Comcast_.” _Cato Supreme Court Review: 2012–2013_ , 2013.



—. “Controlling Unconstitutional Class Actions: A Blueprint for Future Lawsuit Reform.” Cato Institute Policy Analysis no. 546, June 27, 2005.



Olson, Walter K. _The Litigation Explosion_. New York: E. P. Dutton, 1991.



Olson, Walter K., and occasional guest contributors. “Overlawyered.” Cato blog on the American legal system, 1999‐​present.



Redish, Martin, and Nathan D. Larsen. “Class Actions, Litigant Autonomy, and the Foundations of Procedural Due Process.” _California Law Review_ 95, no. 1573 (2007).



Trask, Andrew. “Litigation Matters: The Curious Case of _Tyson Foods Inc. v. Bouaphakeo_.” _Cato Supreme Court Review: 2015–2016,_ 2016.
"
"
I am delighted to report that “Our Climate” made it to the Number 1 paid weather App position in the Canadian iTunes store (out of 570 paid weather apps)!   It took only 40 hours to get there. See screen shot below:
click to enlarge
See my review here: New “Our Climate” iPhone app released
“Our Climate” is number 2 in both Norway and the UK,  and number 3 sales rank in the US for ITunes Weather Apps. It has broken into the top 10 list for iPhone Weather Apps in 7 countries already. To help sustain that growth, I have created a sidebar widget for those that wish to help promote it. See below.

Apple has also put “Our Climate” in the number 1 position in their “New and Noteworthy” featured panel (in the weather app category ) in a number of iTunes jurisdictions, including the US, the UK, Australia, the Netherlands and Canada.
In the countries where the App is gaining user reviews, it is generally (read: invariably) gaining 3.5 to 5 stars average ratings.  This is reflective of very good customer satisfaction metrics.  In addition the software is proving highly stable with no reported crash logs.
The list below is a sampling of how we are doing in various countries so far.
Brackets denote current sales rank in ITunes “top paid weather apps”
Featured in New and Noteworthy (generally number one spot – top left):

Australia  (5)
Canada   (1)
Netherlands  (12)
New Zealand (9)
UK (2)
US  (3)

Not featured in New and NoteWorthy, but good sales rank

Norway (2)
Sweden  (6)

New link widget:
To help this app get wide exposure, I’ve created a link widget for anyone to place in the sidebar of their website. Feel free to copy/paste either of these. Free use granted to everyone.
Pixel size 180×340

HTML CODE: (be sure to cut n’ paste into text editor, then past into your website from there to prevent character formatting issues)
<a href=”http://itunes.apple.com/app/our-climate/id371849150?mt=8″ target=”_blank”><img title=”OurClimate for iPhone – click for details” src=”http://wattsupwiththat.files.wordpress.com/2010/07/ourclimate_iphone_screen_drop2.jpg” alt=”” width=”180″ height=”340″ /></a>

With App Store logo (180×400):

HTML CODE: (be sure to cut n’ paste into text editor, then past into  your website from there to prevent character formatting issues)
<a href=”http://itunes.apple.com/app/our-climate/id371849150?mt=8″  target=”_blank”><img title=”OurClimate for iPhone – click for  details”  src=”http://wattsupwiththat.files.wordpress.com/2010/07/ourclimate_iphone_screen_drop3.jpg”  alt=”” width=”180″ height=”340″ /></a>

Or if you just want to provide a link:
http://itunes.apple.com/app/our-climate/id371849150?mt=8
==============================================
UPDATE: For those people that are unable to cut/paste into your blog, please read this.
I’ve tested this HTML. It works.
You have to paste into web pages and blogs as HTML, using the HTML editor of the website. To do that you must first copy the HTML above and paste it into a text editor like Notepad, and then copy and paste into your blog/website HTML editor.
Just pasting the text above into the regular content editor won’t work. You have to switch to HTML editing where you can see all the tags and text.
Failing that, select one of the images, and copy/paste into your content editor.
It really is easy, millions have done it. Just give it a try. – Anthony

Sponsored IT training links:
Subscribe for 642-436 online training and pass your PMI-001 and 70-432 certification exam on first attempt.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89d03488',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

For nearly a century, Californians have fashioned themselves the innovators the United States and the world follow. Not so on global warming. The California Legislature and Governor Schwarzenegger have just passed and signed global warming legislation that looks an awful lot like a watered‐​down version of the failed Kyoto Protocol. That’s soooo 1990s. 



Kyoto was supposed to reduce our emissions of carbon dioxide, the main human‐​generated global warming gas, to 7% below 1990 levels by 2008–2012. Nationally, carbon dioxide emissions have risen about 18% since then. California legislation cuts state’s emissions to 1990 levels by 2020, a much larger effective cut than Kyoto because of expected population growth in the next fifteen years. 



Why on earth did they do this, and what will it accomplish? 



California’s global warming legislation is all politics. Arnold is up for re‐​election, and California is (and has always been) politically green. Hint: “Sierra Club” stands for Sierra Nevada Mountain Club. While everyone back east pretty much yawns over its antics, people in California pay attention to it much the same way Euros worship Greenpeace (another organization simply ignored here). 



Greens are in record high dudgeon over global warming. Al Gore’s movie has them pumped. The California public is alarmed, and scientists don’t see any incentive to quell the hysteria — after all, it’s quite a living. So it’s totally logical that there has been a political response. 



Specifically, the current clamor revolves around a scientific absurdity: that unless we drastically cut our emissions of carbon dioxide in the next nine years, there will be an irreversible climate catastrophe caused by the rapid shedding of Greenland and Antarctic ice. (While climate populists still say “ten years,” they’ve been making this claim for a year now. Time marches on.) 



It’s science fiction. The slight loss of Greenland ice in the last few years is hardly unprecedented. Its cause is thought to be a reversal of a fifty‐​year cooling trend that ended in the late 1990s over the southern (melting) part of the landmass. For several decades in the early 20th century — before humans could be considered a factor in climate change — Greenland was much warmer than it has averaged in the last decade. Look for yourself. The UN’s climate history is at this site. 



In the early 20th century, Greenland had to have been shedding ice at a much higher rate than it is today (or, God forbid, today’s loss isn’t being driven by warmer temperatures!), and indeed this is documented. Check out “The Present Climate Fluctuation,” published in 1948 by Hans Ahlmann, in _Geographic Journal_ , a peer‐​reviewed periodical of the Royal Geographical Society. 



Antarctica? Suffice it to say that every recent climate model for the 21st century predicts that it will gain, not lose, ice. 



Another big driver of the current hysteria is the notion that hurricanes are getting worse because of global warming. Again, there’s little that’s unprecedented. Today’s frequency of Category 4 and 5 storms, the worst kind, is mathematically indistinguishable in the Atlantic and Western Pacific (the world’s most active hurricane regions) from what it was a half‐​century ago…right around the time Ahlmann published his paper. 



The idea is simple. Warmer water yields more energy for stronger storms. But that notion is simplistic, as other factors that correlate with warmer water serve to mitigate storms. 



Further, the oceans just haven’t been cooperating recently. An upcoming paper by John Lyman in _Geophysical Research Letters_ has the scientific cheerleaders for Gore’s apocalypse worried. It shows, inexplicably, that in the last two years the world’s oceans lost 20% of the heat they had gained in the last half century. 



It’s easy to say that California’s global warming bill rests on nonsensical overkill. But if people insist that all of these horrible things are being caused by global warming, what will California’s leadership do about it? 



The answer, in the rosiest of policy scenarios, is easy: absolutely nothing. Further, if global warming is bad on the whole (a debatable hypothesis), California’s law could easily make things worse. 



Let’s be really rosy, and say that California does lead the nation, and Congress passes a similar law. Further, let’s say that California leads the world, and every nation that has to reduce emissions under the Kyoto Protocol — quotas that virtually no one has met — indeed adopts and meets the California mandates. According to scientists from the U.S. National Center for Atmospheric Research, the amount of global warming the law would prevent by 2060 is .05 degrees Celsius. That’s right, one‐​twentieth of a degree. 



That’s a reasonable estimate, because Kyoto is predicted to prevent .07 degrees of warming along this timeframe, and California’s law doesn’t reduce emissions quite as much as Kyoto. But in any case, there’s no network of global thermometers or satellites that will ever be able to detect such a change, because global surface temperature fluctuates about .15 degrees Celsius from year to year. 



Will California itself meet its own legally imposed emissions limits? Doubtful, unless there will be some chicanery whereby carbon dioxide is fobbed off on, say, power plants in neighboring states. California would have to reduce its emissions substantially while, thanks to immigration, its population rises rapidly. The entry‐​level car for entry‐​level Californians will not be a $30,000 hybrid. While the chi‐​chi may buy them, they will sell their existing cars to the newcomers. Thanks to California’s climate, those beaters will live long lives in the Golden State. 



If people think that current hurricanes are being juiced by global warming, if they think that the calving of Greenland is unprecedented (despite decades of warmer temperatures in the early 20th century), then they will expect some return for their grief. But hurricanes will continue, and more people will be exposed to them. The earth’s temperature trajectory won’t be altered a measurable iota. Despite their efforts to lower emissions, people will see absolutely no current weather change that could possibly be ascribed to this policy. 



Basing policies on hysterical exaggerations is a sure recipe for failure, particularly when the policies will do nothing but sour people on carbon dioxide emission restrictions. So much for Californian leadership. Sounds much more like politics as usual: full of sound and fury, accomplishing nothing. How retro.
"
"
Share this...FacebookTwitterBy Ed Caryl
On Friday, June 22nd, 2012, the The National Academy of Science issued a press release titled, “California Sea Level Projected to Rise at Higher Rate Than Global Average; Slower Rate for Oregon, Washington, But Major Earthquake Could Cause Sudden Rise”. Just in time for Rio+20.

Figure 1: Arial photo of San Andreas fault in California Central Valley.
The press release was picked up by the Associated Press, and in turn, on Saturday the story appeared in newspapers all across the country, including my local paper, and most California papers. The press release breathlessly stated:
The committee that wrote the report projected that global sea level will rise 8 to 23 centimeters by 2030, relative to the 2000 level, 18 to 48 centimeters by 2050, and 50 to 140 centimeters by 2100. The 2100 estimate is substantially higher than the United Nation’s Intergovernmental Panel on Climate Change’s projection made in 2007 of 18 to 59 centimeters with a possible additional 17 centimeters if rapid changes in ice flow are included.
For the California coast south of Cape Mendocino, the committee projected that sea level will rise 4 to 30 centimeters by 2030, 12 to 61 centimeters by 2050, and 42 to 167 centimeters by 2100. For the Washington, Oregon, and California coast north of Cape Mendocino, sea level is projected to change between falling 4 centimeters to rising 23 centimeters by 2030, falling 3 centimeters to rising 48 centimeters by 2050, and rising between 10 to 143 centimeters by 2100. The committee noted that as the projection period lengthens, uncertainties, and thus ranges, increase.
The committee’s projections for the California coast south of Cape Mendocino are slightly higher than its global projections because much of the coastline is subsiding. The lower sea levels projected for northern California, Washington, and Oregon coasts are because the land is rising largely due to plate tectonics. In this region, the ocean plate is descending below the continental plate at the Cascadia Subduction Zone, pushing up the coast.
Extreme events could raise sea level much faster than the rates projected by the committee. For example, an earthquake magnitude 8 or greater north of Cape Mendocino, which occurs in this area every several hundred to 1,000 years with the most recent in 1700, could cause parts of the coast to subside immediately and the relative sea level to rise suddenly by a meter or more.”
Of course the newspapers picked the most extreme of the above numbers, stating a six inch rise by 2030, and three feet by 2100. I downloaded and read the entire paper, all 275 pages, including 15 pages of “boiler-plate” introduction, title pages, table of contents, Committee members names, etc, and 95 pages of references. The 150 or so pages of real content essentially repeated the above four paragraphs, ad nauseam, with supporting hyperventilation about extreme storms, cliff and beach erosion, and wetlands damage. Surprisingly, the last paragraph, and the last part of the title, on the possibility of an earthquake event, had the least discussion.
Willis Eschenbach was the first to respond to this drivel. By Saturday evening he had posted his response on WUWT here, pointing out the impossibility of the above projection, using the actual San Francisco tide gauge plot. Others, in the comments to his posting, added details. I will add a few more.
The geology of the west coast of the U. S. is dominated by two features. The southern coast of California is moved by the San Andreas fault. From Point Reyes north of San Francisco, to the Gulf of California, the coast is moving to the northwest at about 2.5 inches (6.3 cm) per year. There is very little motion up or down as can be seen in Figure 1 above.
North of Cape Mendocino, ground motions are dominated by the Cascadia Subduction Zone. The Juan de Fuca plate is sliding under the North American Plate. The bending of the North American Plate looks like a playing card being pushed at the edge: the edge bends down, but further back the card bends up, and further back yet, it bends down again. In the case of the Northern California, Oregon, Washington, and Southern British Columbia coasts, the edge is off-shore, the upward-bending part is the coast, and inland is bent down again.
Tide gauges reflect these motions. Crescent City is on the California coast just south of the Oregon boarder in the subduction zone, well north of Cape Mendocino.

Figure 2 is the sea level changes at Crescent City, California. Crescent City is rising at about 0.76 mm per year. In 75 years, there has been no significant change to that trend. Sea level rise will not be a problem to Crescent City.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Figure 3: Sea level anomaly at San Francisco.
The tide gauge at San Francisco has been at three locations. Early on it was at Fort Point, then at Sausalito, before moving to Presidio Park near the Golden Gate Bridge before the turn of the century. During the whole history of this gauge, the trend has been a rise of about 1.4 mm per year. But as you can see from figure 2, there have been four distinct periods with very different trends. Since 1980, including the El Niño of 1982, the trend has been flat or slightly down, at about -0.13 mm per year. This precludes any rise of 6 inches by 2030. The prediction should be between this trend and the last 115 year trend, or between a fall of about 0.4 cm (about -1/8th of an inch) and a rise of 5.6 cm (about 2.2 inches).
The last 30-year trend could be an artifact of local changes at San Francisco. To check that, two tide gauges further south were checked. Gauges around Los Angeles were avoided, because oil reservoir depletion and water injection, aquifer depletion and restoration, have altered coastal rise and fall much more than sea level changes. Instead, two tide gauges further south, La Jolla and San Diego, were examined.

Figure 4: Sea level changes at La Jolla, California.
 
 Figure 5: Sea level change at San Diego, California.
These two gauges roughly agree, with a long-term trend of about 2 mm/year rise, and a short term trend of about 0.6 mm rise. These would correspond to a rise of between 1.8 cm and 6 cm (0.7 inch to 2.4 inches) by 2030, hardly catastrophic. Extending these trends to 2100 would result in a 2 to 7 inch rise, far short of the National Academy of Science prediction.
Part 2
 Oregon and Washington Sea Level
On the evening of January 26th, 1700, at 9:30 PM, the world ended! At least it did for many Native Americans on the coast of Oregon and Washington, and First People on Vancouver Island, British Columbia in Canada. A magnitude 9+ earthquake, lasting several minutes, knocked everyone standing off their feet, collapsed native long-houses, and made people motion-sick. Elders told the children to run for high ground. After spending a cold night in the hills, the children returned to find their villages totally gone. Whole tribes from Crescent City, California to Vancouver Island, were wiped out. Across the Pacific in Japan the next day, multiple waves came ashore:
It flooded farmed fields, ruined salt kilns, damaged fishermen’s shacks, ascended a castle moat, entered a government warehouse, drove people to high ground, and probably ran 2 kilometers up a river…. It wrecked houses not only by flooding them but also by starting a fire. It contained multiple waves that range in reported time from midnight until the following noon. The tsunami initiated a nautical accident in which were lost two crew members and tons of rice.”
We know the exact date and time because it took 10 hours for the tsunami to cross the Pacific and be recorded in Japan. We know what happened to Native Americans and First People in Canada from oral histories and archaeological evidence. The coastal elevation immediately sank five feet (1.5 meters). Drowned forest tree rings show death occurred between the 1699 and 1700 growing seasons. Some dead cedar snags still stand in inland wetlands on the Washington coast.
Similar events have happened 13 times since the eruption of Mt Mazama (Crater Lake) in Oregon 7770 years ago. The shortest interval between these events has been 390 years, the longest, about 1000 years. The next one could happen around 2100, or it could wait until 2700. For an idea of the devastation that will result, look to the Japanese tsunami of last year. It could be much worse because the fault that could slip is much longer and it is much closer to the coast.
Sea level rise is not a hazard on the U. S. Pacific coast. Mega-thrust earthquakes are the real hazard. Thankfully, on the Cascadia Subduction Zone, they are separated by hundreds of years. The National Academy of Science needs to look at real tide gauge data and do some real science.
 
Share this...FacebookTwitter "
"In proposing a 30% rather than a 40% energy demand reduction target, the European Commission is increasing the risks that European Union member states face from fossil fuel dependence and slowing the economic and social benefits of better insulated homes and lower energy bills. The EU should have the courage to adopt a legally binding target of 40% energy savings by 2030 as was originally proposed. This would ensure that all member states introduce effective energy efficiency policies and would reinforce the EU’s leadership role in reducing carbon emissions and preventing dangerous climate change.  The proposed 30% target suggests a weakening of political commitment. Several studies have shown how the technology and strategies are available to achieve more ambitious reductions without imposing a burden on the economy. For example, there are already cars currently available that are 40% more fuel-efficient than the current EU standard – and changes in design and materials can reduce emissions by more than 40%.  A legally binding 40% target would potentially reduce EU gas imports by up to 40% compared to 2010, roughly equivalent to the amount of gas currently imported from Russia. It would reduce household energy bills through improved energy efficiency, lowering levels of fuel poverty and reducing the effects of poor-quality housing on health. And it would reduce the scale of investment in renewable energy infrastructure by reducing energy demand. A binding target would ensure political commitment to the task of developing effective energy-efficiency policies and provide long-term confidence for investors delivering commercial goods and services for energy efficiency. It would also drive innovation in energy-efficient products, opening up market opportunities for EU industries around the world. Why adopt a target as well as energy efficiency policies? Improving energy efficiency is the cheapest and fastest way of reducing carbon emissions, while at the same time providing economic, social and environmental benefits. Without an ambitious overall energy-efficiency target it’s unlikely that member states would unlock these benefits. Nor can these benefits be achieved through the carbon price delivered through the EU emissions trading scheme. An aggregate target helps ensure that energy savings in one area are not offset by the rebound effect of increased energy demand in another. A legally binding target at the EU level would help ensure that progress is monitored, action is taken and results achieved. None of this is incompatible with the emissions trading scheme provided the appropriate steps are taken to ensure a minimum carbon price. A 40% target is within our grasp, technically and economically, and would send a strong message that EU intends to lead on these issues. Regional instability in North Africa, the Middle East and now Ukraine has shown time and again that over-reliance on imported fossil fuels makes countries vulnerable to price shocks and supply interruptions. We need to reduce those risks and at the same time protect the climate. Improved energy efficiency comes top of the list for cost-effectiveness and wider benefits. Recent progress has demonstrated that significant reductions in energy consumption can be achieved while maintaining productivity and quality of life – UK energy consumption fell by 12% between 2000-2012, while GDP increased by 58%. Improvements in technology and changes in behaviour will make a 40% reduction by 2030 not only desirable but entirely achievable. But it must be backed up by political commitment."
"
I’m really disappointed that I didn’t get the “fossil of the day” award. Watch the presentation at COP16 and get some popcorn.


I wonder if the producers of Jurrasic Park gave permission to licensed use of the logo, of if they are just scofflaws?

h/t to Tom Nelson


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e86cd407c',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Demand for food is increasing rapidly – the global population is expected to reach 11.2 billion by 2100. To keep up with the additional mouths to feed, intensive farming practices have maximised production, but often at the expense of the environment and human health. Livestock is reared to maximise economic returns, which often means animals are kept in close confinement with each other, increasing the risk of disease. As a result, antibiotics are often used to treat animals destined for human consumption, but relying on them can cause bacteria to develop resistance in the long run. A recent review found 100 academic studies on antimicrobial resistance had detected a link between antibiotic consumption in animals and antimicrobial resistance in humans.  This means that using antibiotics in animal rearing can cause resistant bacteria that may also affect humans down the food chain. Antibiotics have been phased out of livestock rearing in the EU and in their place zinc has been introduced into the diet of animals to help kill bacteria which cause Salmonella and E. coli. High levels of zinc in the diets of pigs and cows can help them grow bigger and kill E. coli, but it’s starting to become an environmental issue in its own right. Most of the zinc fed to the animals is excreted and washed into waterways and soils where it can harm aquatic life and acidify the soil. As a result, European legislation will phase out the use of zinc by 2022. This leaves the producers of livestock feed and farmers in a difficult position. New products are needed to prevent infection in livestock which don’t harm the environment or human health by contributing to antimicrobial resistance, but where could they come from? Seaweed could be the answer. Brown seaweeds synthesise a unique class of compound called phlorotannins as they grow. These compounds can kill bacteria that emerge among farm animals. How effectively these compounds can kill bacteria depends on the species of seaweed being used, with different species producing more potent bactericides. The flock of North Ronaldsay sheep in Scotland have grazed on nothing but seaweed for generations. Animals raised on such diets which are rich in Omega-3 fatty acids produce healthier – and arguably tastier – meat. Seaweed can be grown in the ocean and harvested from natural stocks in a rotational manner, ensuring natural habitats don’t have to be plundered to supply livestock farmers. Seaweed farming also doesn’t have to compete for land space like traditional feed crops and could reduce pressure on agricultural land – allowing space for habitat restoration and rewilding which helps fight climate change. Seaweed farms in the ocean draw in a lot of carbon dioxide – which helps de-acidify the seawater around them – and release oxygen. This improves the health of sea life nearby and helps organisms such as coral or sea snails to grow stronger exoskeletons of calcium carbonate. Modern farming uses huge quantities of fertiliser which run off the land and into rivers and the ocean. There, these nutrients stimulate algae which grow and multiply. When algal blooms die and decay, they’re decomposed by bacteria which absorb oxygen from the water, creating vast dead zones where fish and other aquatic life suffocate. Luckily, growing seaweed requires no fertiliser and only uses nutrients which already exist in seawater. Global seaweed production rose from 10.5 to 28.4 million tonnes between 2000 and 2014, but 95% of this was in Asia. There’s therefore huge growth potential for seaweed agriculture in the rest of the world. The brown seaweeds which produce the helpful antibacterial compounds are widespread on temperate shores, and by converting them into supplements for livestock feed, a vibrant industry that’s good for humans and the environment could flourish. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"The current climate and ecological crisis demands a radical redesign of how we live and organise our societies. Yet these urgent changes, though complex, are far from impossible. Some of them are simple, beautiful, and beneficial to all. By greening our cities with street trees, urban parks, and community and rooftop gardens, we can keep ourselves cool amid rising temperatures, reverse the steady erosion of the rich tapestry of life on Earth, and foster happiness and social connection in the process.  It is widely known that greenery in urban spaces helps improve city microclimates. Thanks to heat generated by traffic and industrial activity, as well as the spread of heat-trapping concrete buildings that have steadily replaced plant life, urban air temperature is often higher than in rural environments. Hotter cities compel urban denizens to opt for air conditioners in order to stay cool, which further strains energy demands and worsens the urban heat island effect. Plants can help cool cities through the water that evaporates from their leaves when exposed to the sun’s rays, and by shading surfaces that otherwise might have absorbed heat. Research has found that on a sunny day, a single healthy tree can have the cooling power of more than ten air-conditioning units. Plants also help keep harmful pollutants such as microscopic particulate matter at bay through a complex process known as dry deposition, whereby particles penetrate and become trapped in the wax or cuticles of leaves. Although banning or at least restricting vehicle use in city centres is crucial, mass greening can further reduce pollution and keep cities cool in the increasingly scorching summers that lie ahead. Urban greenery wouldn’t just help lessen the impacts of climate change and improve air quality. Evidence from a range of disciplines has uncovered numerous social, psychological, and health benefits of human exposure to green spaces. These include stress and anxiety reduction, improved cognitive functioning, lowered risks of depression, and overall greater mental and physical wellbeing. Others have shown how involvement in community gardening can increase social cohesion and social bonds among participants and the wider community, in addition to providing local and affordable food sources. The Japanese preventative healthcare practice of Shinrin-yoku, or “forest bathing”, is modelled on a recognition of the many benefits of immersion in natural spaces. We’re not yet sure why we seem happiest and healthiest when we’re surrounded by our fellow lifeforms. But the universality and antiquity of our appreciation for nature suggests that our biophilia may originate from the millions of years humans and plants spent co-evolving in close contact with each other.  Perhaps most importantly, greening and rewilding our cities can offer vital refuges for rapidly vanishing biodiversity. Human socioeconomic activities, especially those of the world’s rich, have destroyed natural habitats, consumed vast tracts of forest, polluted waterways, and disrupted the seasonal rhythms on which life depends. In the midst of the sixth mass extinction, many species are increasingly finding themselves with nowhere to go. Urban rewilding can help the complex natural communities and processes that are essential for all life to flourish once again. For example, establishing wild meadows and native plant and tree communities provides pollinators and other threatened animals with new spaces to thrive, while creating spaces to reintroduce keystone species, whose presence is crucial for maintaining ecosystem diversity. The mass greening and rewilding of our cities is no novel or abstract ideal. It is already happening in many urban spaces around the world. The mayor of Paris has ambitious plans to “green” 100 hectares of the city by 2020. London mayor Sadiq Khan hopes to make London the world’s first “National Park City” through mass tree planting and park restoration, greening more than half of the capital by 2050.  Singapore, a partner city in the Biophilic Cities Network, is a shining example of how to incorporate “nature” into building and city designs. The Parkroyal on Pickering Hotel, for instance, is shrouded in thickly forested terraces and sky gardens that are inhabited by local insects and birds. More cities need to follow the lead of these forward-thinking designs and initiatives. Alongside these efforts, educational programmes, such as Singapore’s Community in Nature initiative, could also be put in place to help the public learn about, respect, and appreciate wild spaces. Of course, urban greening alone will not be enough to meet the daunting challenges ahead. We also need to fundamentally transform our growth-oriented economies and massively reduce global inequality. But giving some new life to our cities would be a great start. And it wouldn’t just benefit people but, crucially, other species as well. This is their home, too, and they deserve a more viable future. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"

Cancer is a terrible way to die, even for someone as unattractive as Venezuelan President Hugo Chavez. Still, one wonders at those who rushed to offer their condolences. Such as the profoundly naïve Jimmy Carter—who decades ago expressed his surprise at being lied to by his Soviet counterpart, Leonid Brezhnev—lauding Chavez’s “commitment to improving the lives of millions of his fellow countrymen.”



Venezuela is better off with Chavez gone. However, the country will prosper only if Chavismo disappears as well. Which requires the opposition to offer a vision of opportunity and prosperity for Venezuela’s dispossessed.



Chavez was elected in 1998, a populist who challenged the country’s profoundly corrupt political establishment. In Venezuela the class structure essentially was determined by access to state privilege. If your friends were in power, you could get rich. Ideology wasn’t important.



Thus, the electoral surge for Chavez, though unfortunate, was not surprising. People desperate for change voted for change.



And he brought it. But not a positive variety. Roger Noriega of the American Enterprise Institute assessed “Chavez’s destructive legacy: deep political polarization, authoritarian manipulation, hateful rhetoric, disastrous economic policies, and the devastation of Venezuela’s petroleum industry.”





What Venezuelans most need is a government which empowers them, not political elites claiming to speak for them.



Chavez failed even on his own terms. Venezuelans remain profoundly poor and dependent on the state. Poverty has fallen because of lavish social spending, but the country’s oil revenue provides only a temporary palliative. In fact, the Chavez government has mismanaged even this asset, and has done nothing to encourage Venezuelans to become independent wealth producers.



Rather, an otherwise productive people suffer from an economy which doesn’t work. Food shortages emerged earlier this year which the government, naturally, blamed on private hoarding. Chavez was dedicated to the sort of socialist state which has failed all over the world. Indeed, Venezuela ranked 144 in last year’s Economic Freedom of the World index, after war‐​torn Congo, bankrupt Zimbabwe, and long‐​isolated Burma.



Indeed, Chavez wasted his people’s money on political objectives, such as subsidizing the failed communist experiment in Cuba. After a half century of revolution, the island state remains an economic wreck, locked in a time warp in which vintage 1950s American automobiles ply streets filled with weathered buildings unfamiliar with basic maintenance.



Chavez gained some other allies on the continent, such as Bolivia’s Evo Morales and Ecuador’s Rafael Correa. However, in other countries, such as Mexico and Peru, Chavez’s meddling created a backlash that boosted more mainstream candidates. Explained Javier Corrales of Amherst College: “the foreign influence of Chavismo, in Latin America, at least, is ailing.” Today Latin Americans are far more likely to look to Brazil and Mexico for leadership than to Venezuela.



Venezuela remains nominally democratic, but Chavez’s abuses were legion—and not surprising for a onetime army lieutenant colonel who led an unsuccessful (and bloody) coup attempt in 1992. Like the Castros and other communist dictators, he used economic redistribution as a pretext for authoritarianism. Even some Americans buy the explanation. Said historian Greg Grandin: “I’ll be perverse and argue that the biggest problem Venezuela faced during his rule was not that Chavez was authoritarian but that he wasn’t authoritarian enough.”



Actually, Chavez was plenty authoritarian. For instance, Freedom House classified Venezuela as “partly free.” The human rights group cited exploitation of state resources, manipulation of election rules, centralization of power, and attacks on an independent press. Freedom House explained that “the media climate is permeated by intimidation, sometimes including physical attacks, and strong anti‐​media rhetoric by the government is common.” In fact, the group’s press freedom rating for Venezuela was “not free.”



Human Rights Watch was no less critical in its latest World Report released earlier this year. Under Chavez, explained HRW: “the accumulation of power in the executive branch and the erosion of human rights guarantees have enabled his government to intimidate, censor, and prosecute Venezuelans who criticize the president or thwart his political agenda. President Chavez and his supporters have used their powers in a wide range of cases involving the judiciary, the media, and human rights defenders. While many Venezuelans continue to criticize the government, the prospect of facing similar reprisals—in the form of arbitrary or abusive state action—has undercut the ability of judges to adjudicate politically sensitive cases, and forced journalists and rights defenders to weigh the consequences of publicizing information and opinions that are critical of the government.”



Similar were the result of the State Department’s last annual human rights report, which pointed to “the government’s partisan use of state‐​owned media” and “instances in which elements of the security forces acted independently of civilian control.” In December 2010 the National Assembly voted to allow the president to issue laws by decree, while the government acted “to impede freedom of expression and criminalize dissent.” There also were instances of torture, arbitrary arrests, harsh imprisonment, and even summary executions of criminal suspects. The report offered 47 pages of unpleasant specifics. That is a lot, but not compared to the 300‐​page report issued by the Inter‐​American Commission on Human Rights in 2010.



New elections are to be held in a month. Chavez designated Vice President Nicolas Maduro as his political successor and the latter will enjoy support from many Chavistas who benefited from Chavez’s rule. However, Maduro lacks Chavez’ charisma which held together a disparate movement and created an emotional bond with Venezuela’s poor. Some of Chavez’s followers have said: “With Chavez everything, without Chavez nothing.”



Moreover, the late Alberto Muller Rojas once called Chavez’s United Socialist Party, of which Rojas was vice president, a “scorpions nest.” Maduro faces serious rivals in National Assembly President Diosdado Cabello and Oil Minister Rafael Ramirez. Other influential Chavistas include Chavez’ older brother Adan Chavez, Governor and former Defense Minister Henry de Jesus Rangel, Governor and former Interior Minister Tareck el‐​Aissami, and Science Minister (and Chavez son‐​in‐​law) Jorge Arreaza.



Henrique Capriles Radonski, the state governor who opposed Chavez in last October’s election, is likely to be the opposition candidate. Radonski is an attractive candidate, but lost by 11 percent points. The opposition also was badly beaten in gubernatorial elections held in December.



The good news for Venezuela is that Chavez never really created Chavismo. It was a movement and regime based on one person. Remove that person, and the foundation disappears. The system may stagger on for a time, but likely has been irretrievably weakened.



The Obama administration has begun discussions with Caracas about restoring full diplomatic relations—most importantly, returning ambassadors to both capitals. That is a worthwhile objective, but Washington should avoid political meddling during the transition. The best the U.S. can do is urge Venezuela’s neighbors, such as Brazil, to press for a fully free and fair election.



Washington’s democratic credentials in the region long ago were tarnished by support for authoritarian regimes. In Venezuela the Bush administration smiled benevolently at a 2002 coup attempt against Chavez, which quickly collapsed. Today there is little for official America to do or say other than wish Venezuelans well in charting their own future—hopefully in a more liberal and democratic direction.



What Venezuelans most need is a government which empowers them, not political elites claiming to speak for them. A government which disperses rather than concentrates power, accepts rather than punishes criticism, and allows rather than impedes enterprise. Hopefully Chavez’ death will provide the necessary opportunity for Venezuelans to take back control of their lives and country.
"
"As trees grow they remove carbon from the atmosphere. New forests can therefore play an important role in meeting the goal of keeping Earth’s temperature to 1.5℃ above pre-industrial levels. Governments and wider civil society are increasingly recognising these benefits. One important step was the 2011 launch of the Bonn Challenge to restore 350m hectares of forest by 2030. This is a major undertaking – the area is a little larger than the size of India. Spurred by the necessities of drastically cutting emissions and removing carbon dioxide from the atmosphere to meet climate targets, many countries, including Brazil, India and China, have committed large areas to forest restoration. Adding up the Bonn Challenge and other national pledges from 43 countries across the tropics and sub-tropics – where trees grow fast – reveals that these governments have pledged to restore 292m hectares of degraded lands. This very welcome news is, unfortunately, not all that is seems. Our new analysis, published in Nature, shows that implementing the current pledges under the Bonn Challenge will mean the 1.5℃ climate goal is still missed. More than half of the countries involved (24), covering two thirds of the pledged area, have stated what type of forest restoration they will do: 45% of the area is slated to become plantations of a single tree species (monocultures); 21% to agriculture that mixes trees and crops, known as agroforestry; and only 34% is given to restoring natural forests.  Such choices have profound carbon implications: for instance, our analysis shows that restoring natural forests over the whole 350m hectares of land would remove 42 billion tonnes of carbon by 2100. If instead we use the current proportion of pledges for plantations, natural forests and agroforestry applied to the whole area this is reduced to 16 billion tonnes (assuming that all new natural forests are protected to 2100). And if commercial monocultures were planted across 100% of the area just a billion tonnes of carbon would be sequestered. Our research demonstrates that within these countries, land put aside for natural forests to return holds 40 times more carbon than plantations and six times more than agroforestry. This is mainly because natural forests continue to remove carbon from the atmosphere for many decades, whereas plantations are harvested every decade or so, which means almost all the carbon stored in the trees goes back into the atmosphere, as the plantation waste and wood products – mostly paper and chipboard – decompose. To put these numbers into context, the recent Intergovernmental Panel on Climate Change Special Report on 1.5℃, noted that meeting this target requires 200 billion tonnes of carbon to be removed from the atmosphere this century. This colossal number is equivalent to the total emissions from 1800 to 2015 from the US, China, Germany and the UK combined. New forests and other land sequestration plans are expected to account for about one quarter of this carbon removal. At 42 billion tonnes of carbon uptake, restoring only natural forests across the entire Bonn Challenge area would clearly get close to this target. But scientists have modelled a number of emissions decline “pathways” to limit warming to 1.5℃ by 2100. All models require a reduction in emissions to net zero by about 2050. Yet, the average requirement of 200 billion tonnes of carbon removal hides wildly different levels of how much carbon will have to be removed directly from the atmosphere, a process known as negative emissions. The faster we reduce emissions from fossil fuels and deforestation to zero, the lower the level of negative emissions required.  The total scale of negative emissions deployment matters, because as well as forests the other main technology that is central to 1.5℃ scenarios also has a huge land footprint. Bioenergy with carbon capture and storage is expected to capture, on average, around 130 billion tonnes of carbon via planting crops for biofuel that are then burnt in power stations. The carbon emissions are then captured and stored underground. It is expected that an additional area of one or two times the size of India is needed for bioenergy crops by 2050. Assuming food producing areas and old-growth forests are spared, this huge extra demand for land is most likely to displace restored forests. We estimate that if the restored natural forests under the Bonn Challenge and national schemes were converted to bioenergy crops after 2050, just three billion tonnes of carbon would be sequestered by 2100.  The solution here is that newly restored natural forests need protecting in order to protect the climate benefits they provide. Otherwise, one area of climate policy may wipe out the gains made in another. Of all the negative emissions technologies available, allowing natural forests to return is safe, often not costly, and brings many other obvious benefits. But forest restoration can only play the critical role that it needs to if it means the same thing to policy makers as it does to everyone else: restoring areas back to largely intact largely natural forest. A new definition of “forest restoration” that excludes monoculture plantations is needed. Our new research is part of a new interest in restoring ecosystems to help mitigate climate change. We have both signed an open letter published in The Guardian by top scientists and activists which calls for a well-funded programme to restore ecosystems to meet our 1.5C climate goal, under the banner of “natural climate solutions”. A new website elaborating on these plans notes that just 2.5% of mitigation funds goes to natural solutions, despite their promise. Curbing climate change via restoring Earth’s ecosystems to their former glory could be a profound positive legacy of the 21st century, but not if governments and their advisers pretend that vast commercial monocultures of trees are forest restoration. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"Hail, heavy rain, lightning and flash flooding – not necessarily typical summer weather in southeast England. But the recent unexpected deluge saw homes evacuated, stations flooded, and road and rail services interrupted. According to the Met Office, more than half the monthly average total rainfall fell in just an hour. In Hove, Brighton and Worthing, the storm kicked off with a particularly heavy hailstorm leaving many waking up to positively wintry scenes. Such unexpected weather, described as “extreme” in nature, has prompted many to declare that freak weather events are becoming more common and more damaging. But is this really the case? The Met Office is an important source of information on the history of weather extremes. Its national weather records can help put current events into an historical context. However, while it can be difficult to make sense of historical meteorological information, the records held at city and county record offices, libraries and archives can provide a human dimension, transforming meteorological data into stories of people and communities. Those in Sussex affected by the storm used Twitter to share reactions and experiences, whereas in the past letters, diaries, newspapers and official documents recorded the effects of extreme weather. With this documentary archive stretching back hundreds of years we can investigate how one event was described in relation to another, and whether and why they were judged to be unusual or extreme.  The records of Leicestershire County Quarter Sessions document the huge community response to a “dreadful storm of hail” on July 28 1814. A committee was formed to collect subscriptions to provide relief for those who had suffered losses from the storm. From the committee’s papers we know that William Collishaw of Birstall lost a quantity of the fruit from his orchards in the storm, and that John Blockley lost wheat, potatoes, onions and peas to the value of £106.  The same storm is also recorded in the diary of Peter Pegge-Burnell of Winkburn Hall, Nottingham:  Dull close morn betwixt one & two, loud thunder, some lightg & heavy showers – about six in the afternoon came on the most dreadful hailstorm I ever beheld – a number of hailstones pointd and as large as my thumb end – or first joint – sometime after a continuation of some hours of vivid flashing & constant thunder, a deluge of heavey rain followed – the damage by this horrid storms to my corn, hay, garden & windows is very considerable – thank God no lives lost as I have heard. Joseph Woolley, a framework knitter and stocking maker from Nottingham, recorded a hailstorm in his diary entry for August 11, 1809 in which he notes “hail stones seven inches long,” breaking windows in a number of houses at Beeston Rylands.  Records from the Edgbaston Estate papers include a letter from a tenant, E. Whigg, to his landlord’s agent Charles Yates informing him that the severe hailstorm of August 1846 “completely destroyed the windows in the front of our house” and suggesting a change in design (a suggestion rejected by his Landlord). On July 25, 1900 the Haverfordwest and Milford Haven Telegraph reported on a “terrible hailstorm in Northampton”, when “those of the bigness of the thin-shelled English walnut were the average but hail-stones as big as hens’ eggs were in abundance”. So extreme summer hailstorms are not without historical precedent in the UK, as recorded in descriptions found in diaries, letters, official documents and newspapers. With many accounts of the same event, it’s possible to build a picture of how people responded. It’s also possible to build up a picture of how certain events enter a community’s cultural memory – the extremely cold and snowy winter of 1947, the extreme heat of the summer of 1976, and the extreme floods of 2007 – while others are quickly forgotten.  In a letter to Lord Manvers dated February 14, 1795, William Sanday at Holme Pierrepont in describing a flood in Nottingham refers back to an earlier flood:  We have had a most dreadful flood upon the River Trent; it was 3 feet one inch higher than the Midsummer flood, which happened between 50 & 60 years ago; this was ascertained from a mark then made, and which still remains.  Like many accounts of extreme weather events, William Harwood’s diary entry for February 11, 1795 refers directly to flood memory, “SW wind fine day, the largest flood upon the Trent ever remembered.”  Different ways of recording the past transmit information and awareness of extreme weather across generations, beyond the memory of individual lives. Being aware of extreme events that have occurred in the past can help people comprehend the problems of risk and uncertainty in the face of extreme weather events now and in the future."
"**There have been more than 1.6 million confirmed cases of coronavirus in the UK and about 60,000 people have died, government figures show.**
However, these figures include only people who have died within 28 days of testing positive for coronavirus and other measures suggest the number of deaths is higher.
**Find out how the pandemic has affected your area and how it compares with the national average:**
If you can't see the look-up click here.
After the first peak in April, cases started rising again in July, with the rate of growth increasing sharply in September and October, before falling again in the past two weeks.
On Wednesday, the government announced a further 16,170 confirmed cases.
It is thought the infection rate was much higher during the first peak in spring, but testing capacity at the time was too limited to detect the true number of daily cases.
The data for cases can also be broken down by region and comparing the change in those figures by week gives a sense of where there has been a recent increase in newly-reported infections.
Coronavirus infections in England have fallen by about a third during lockdown, according to a major study carried out by Imperial College London.
While some of the worst-hit areas saw the biggest improvements, cases have remained relatively high across England, according to the React-1 study, which is based on tests of more than 100,000 people between 13-24 November.
The latest figures from the Office for National Statistics (ONS), suggest about one in 185 (16,400 people) in Wales had the virus in the week ending 21 November.
In Northern Ireland rates are thought to be decreasing at around one in 145 people (about 12,700 people), while in Scotland, the figure was one in 115 (about 45,700 people).
The average number of daily deaths began to rise again in September, following the first peak in April.
On Wednesday, the government announced a further 648 deaths.
Of these, 555 deaths were in England, 51 in Wales, 38 in Scotland, and four in Northern Ireland.
Rules were amended over the summer to include deaths in the coronavirus total only if they occurred within 28 days of a positive test. Previously in England, all deaths after a positive test were included.
England has seen the majority of UK deaths from Covid-19. Using the 28-day cut-off, there have been more than 52,000.
Although hospital admissions for Covid-19 remain below the levels seen in the spring, there are big regional disparities.
The North West, North East and Yorkshire, and Midlands have seen the highest number of admissions but the situation in all three now appears to be improving.
Cases have risen across large parts of England, with other spikes in areas of Scotland, Wales and Northern Ireland.
The red areas on the map below are those currently seeing the highest number of cases per 100,000 people.
Restrictions have been tightened across the UK in an effort to tackle the number of rising cases.
In England, each local authority has been placed in one of the new three tiers following the end of the recent national lockdown.
Wales has announced a range of further measures, including a ban on pubs, restaurants and cafes serving alcohol, from Friday 4 December.
In Northern Ireland, a further two-week ""circuit-break"" lockdown began on 27 November.
Scotland has a five-tier system of alert levels with different measures in place in different parts of the country.
UK leaders have agreed to allow up to three households to meet indoors during a five-day Christmas period of 23-27 December.
When looking at the overall death toll from coronavirus, official figures count deaths in three different ways.
Government figures count people who died within 28 days of testing positive for coronavirus.
But there are two other measures.
The first includes all deaths where coronavirus was mentioned on the death certificate, even if the person had not been tested for the virus. The most recent figures suggest there had been almost 70,000 deaths by 20 November.
The second measure counts all deaths over and above the usual number at the time of year - that figure was more than 75,000 by 20 November.
The most recent figures available from the ONS are for the third week of November, which show there were 14,276 deaths registered in the UK.
Some 3,038 of these deaths involved Covid-19 - 199 more than the week before.
Deaths normally do rise at this time of the year, but the data from the ONS and its counterparts in Scotland and Northern Ireland show the second wave of the virus has pushed the death rate above the average seen over the past five years by about 21%.
Overall, the figures are still well below the peak of 9,495 deaths recorded in a week, reached on 17 April.
The ""R number"" is the average number of people an infected person will pass the disease on to.
If R is below one, then the number of people contracting the disease will fall; if it is above one, the number will grow.
The government's current estimate for the R number across the whole of the UK is 0.9 to 1.
The estimate for England is 0.9 to 1, while for Scotland it is 0.8 to 1. The estimate for Wales is 0.8 to 1 and in Northern Ireland it is 0.9 to 1.1.
The government has said in the past that the R number is one of the most important factors in making policy decisions."
"What could be more important than sustaining habitable living conditions on Earth? Climate change, biodiversity loss and other environmental problems demand changes on an order of magnitude well beyond the trajectory of business-as-usual. And yet, despite accumulative social and technological innovation, environmental problems are accelerating far more quickly than sustainable solutions.  The design industry is one of many industries mobilising to address environmental imperatives. While sustainability-oriented designers are working towards change from many angles, addressing climate change and other environmental problems on this scale demands much more dramatic transformations in economic ideas, structures and systems that enable – or disable – sustainable design.  Put simply, designers cannot design sustainable future ways of living on scale without a shift in economic priorities. Human impacts on planetary processes in the Anthropocene require new types of ecologically engaged design and economics if the necessary technological, social and political transitions are to take place. Design is crucial to this debate because it is key to the creation of future ways of living. Designers make new ideas, products, services and spaces desirable to future users. With the shape of a font, a brand, the styling of a product, the look and feel of a service, the touch of a garment, the sensation of being in a particular building, designers serve the interests of customers (generally, those with disposal income). They do so according the logic and modes of governance generated by what is valued by economic structures. Design is the practice that makes capitalism so appealing. Designers make new products, services and spaces that shape future ways of living – and can use their skills to create sustainable options. But there is a dilemma here. The market rarely prioritises interests that do not pay the bills or otherwise bring capital to the table. Design sits at the intersection of economic value and social values. Design transforms what economic systems value into new ways of living – which in turn produce certain types of social values. This work is generated by priorities in the design industry, driven by economic imperatives.  Traditional neoclassical economics was developed in an era when all knowledge systems essentially ignored ecological concerns. In conventional economics, value – which is created by generating profit and accumulating capital for owners and investors – is systematically extracted from the systems in which economic systems are embedded: the social and the ecological systems.  Contemporary economic systems reproduce this tradition by rewarding individuals and companies for using (and often exploiting) resources to generate profit, regardless of the ecological or social consequences. The extractive and exploitative dynamics of capitalist economics generate economies locked into accelerating climate change, species extinction and other severe environmental and social problems. This economic system continues to produce ever greater degrees of crises as planetary boundaries are breached in ever more extreme ways. But there are economic alternatives. Heterodox economic theory (such as ecological, feminist and Marxist economics) challenges the assumptions of mainstream economics. It has shown how neoclassical and neoliberal economics produce unsustainable economies that consistently devalue the natural world, women’s work and the labour of other groups historically denied equal access to capital.  For example, the Iceberg Model depicts a feminist economic framework where non-market activities, including the unpaid labour that buttresses capitalist economics, are made explicit. The challenges of the Anthropocene demand that we overcome the exploitative and anti-ecological biases in neoclassical and neoliberal economics. One popular alternative is Kate Raworth’s Donut Economics. This would prioritise both social justice and environmental sustainability to create a safe operating space for humanity. Unlike conventional economics, heterodox economics takes the ecological context and planetary boundaries into account – while also addressing the interests of historically disadvantaged populations. The design industry, like most industries, is governed by economic ideas, structures and systems. Economic systems determine priorities in design studios and design education – including whether or not designers can focus on sustainable solutions.  And so economic factors govern whether designers can direct their energies towards making sustainable ways of living possible – or not. Few of us are employed to do tasks that make it possible to respond responsibly to environmental circumstances because the current political economy is not oriented towards prioritising the preservation of life on this planet. When the priorities of an individual designer who is oriented towards sustainability conflict with those of the design industry, which is often governed by an economic system oriented towards profit, the designer finds it hard to make a living. If sustainable solutions will not generate profits, they will not succeed in this economic system (without either government intervention or charitable support). The design industry does not systemically prioritise the needs of the environment within this economic system because the way value is generated in contemporary economics depends on the systemic dismissal of ecological priorities. Addressing this dilemma is a severe challenge. It is now evident that the economic system must be designed to reflect priorities and values associated with preserving habitable conditions on the planet. Climate change and other severe environmental threats require dramatic shifts in economic priorities. The fields of economics and design must be redirected so that economic services, structures and systems will support socially distributive and environmentally regenerative design. Humankind already has the knowledge to make sustainable and socially just ways of living on this planet possible. What we do not yet have is the ability to make these transitions possible in the current political context. New types of design and economics could be a basis for systemic transitions. Key to this transition is ecologically literate education in both design and economics. Both fields must be radically transformed to meet the challenges of the Anthropocene. With critical, ecologically-engaged design and economic education, new redirected design economies could facilitate sustainable transitions and make another world not only possible – but desirable. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"
Share this...FacebookTwitterSomeone forgot to tell the Russians that natural climate factors no longer count for anything, and that from the 20th century on man-made CO2 is the sole driver of the climate – now making the Earth only warmer and warmer.

Lake Vostok under almost 4000 meters of ice in Antarctica. Source: US Government.
The German edition of Russian online daily Ria Novosti here writes how a team of Russian scientists in Antarctica has reached Lake Vostok, isolated from the rest of the world by a massive ice sheet for over 15 million years. A team of Russian scientists bored through 4000 meters of ice to reach the lake on 5 February 2012.
Minister President Vladimir Putin congratulated the researchers on their feat last Friday. Project leader Vladimir Lipenkov said that it will be very important for studying climate change on Earth. The Russian team plans to drop a robot into the lake to collect water samples and sediments from the bottom. According to Ria Novosti:
A new ice age is unavoidable, but will occur in 10,000 years at the earliest. This is what Vladimir Lipenkov, member of the Russian expedition said concerning the millions of years old Vostok Antarctic lake on Friday during a meeting with Minister President Vladimir Putin and the research team.”
Why the statements are not published in the English edition of Ria Novosti, let alone the western mainstream media, is unknown. And the report provides no information on what they base the timing of the new ice age on.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Vostok station. Photo source: National Oceanic and Atmospheric Administration.
This is not the first time Russian scientists predict cooling ahead. In 2006 Chabibullo Abdussamatow of the Pulkovo Observatory and a member of the Russian Academy of Sciences said global warming had already reached its peak and that reduced solar activity would start the Earth on a cooling phase. According to Ria Novosti here:
‘With respect to solar activity, the increase in energy emission was indeed the most important event of the 20th century,’ the scientist said.”
and:
The start of the temperature decline can be expected in 2012 or 2013 according to the scientist. By 2035 or 2045 the strength of the sun will again reach a minimum. A strong cold will then grip the Earth 15 to 20 years later.
 
Share this...FacebookTwitter "
"The demise of AAP has unexpectedly ignited a war of words between media companies over who is to blame. According to News Corp – one of the major shareholders who actually took the decision to close AAP – the shuttering of the vital news service is the fault of digital giants Google and Facebook … and the ABC and Guardian Australia. Wait. What?  In the fallout over AAP in the last few days, News Corp has used its significant real estate to attack both media organisations, with articles appearing in the Australian, the Daily Telegraph and other Murdoch titles shifting blame to competitors. A page three story in the Australian on Friday accused Guardian Australia of “gobsmacking hypocrisy” for reporting that, along with the very compelling financial reasons for closing the service, News Corp and Nine told staff they no longer wanted to subsidise a breaking news service for their competitors. Neither News nor Nine have denied making the comments. The AAP chairman, Campbell Reid, fired off a statement after the Guardian report saying it was “one of the very companies that slashed the amount it was prepared to pay for AAP”. A senior executive for News Corp, Reid is also furious with the media union, the MEAA, for questioning News Corp’s motives for suddenly closing the wire service and throwing 600 people into unemployment. Guardian hypocrisy over AAP shutdown https://t.co/bonD9uUIdh “[The Guardian] is one of the organisations whose decisions have contributed to the closure of AAP and it and the [Media Entertainment and Arts Alliance’s] leadership should confront the bigger, tectonic forces our entire industry faces rather than trot out this arrant nonsense,” Reid thundered. Guardian Australia’s editor, Lenore Taylor, who was not given a right of reply by the Oz, says: “We were offered a discount by AAP when we renegotiated last year because we were using fewer services as we expanded our own reporting teams.” “Mr Reid’s statement is based on false premises,” Taylor said on Twitter. “No one at Guardian Australia has ever suggested the decision to close AAP was made primarily to hurt small media organisations. We have written that it was a commercial decision. We did publish what Mr Reid TOLD staff at AAP – that as well as commercial considerations, News and Nine felt they were propping up a news wire that helped competitors.” via @p_hannam pic.twitter.com/HJK4anovx0 Then there was that other whipping boy, the public broadcaster. An editorial in the Daily Telegraph argued that Aunty’s free content was cutting their lunch. “Additionally, AAP found itself competing with an ever-expanding ABC, which in defiance of the public good and media viability now dominates a great deal of the online realm through tax-funded content,” editor Ben English editorialised. “The forthcoming loss of AAP will be a crushing blow to media diversity, brought about by behemoth organisations that care little for a plurality of sources.” We know that News Corp is responsible for much of the climate denial published in the Australian media – no matter what Rupert Murdoch claimed – but now we have some hard data to put it in context. First the good news. Reporting on bushfires is now far more likely to mention climate change, a study by Monash University has found. The report from the Monash Climate Change Communication Research Hub, found that 49% of the media coverage of the recent bushfires mentioned climate change, compared with 5% of reports about Black Saturday in 2009. The researchers analysed 1% of articles between 1 September and 31 January and found only 5% of overall coverage featured climate denialism, down from 21% in 2009. But it was News Corp publications that represented 59% of all the denialist discussion of climate change. The former Fairfax papers, now owned by Nine Entertainment, made up 19% of denialism. The coverage of protests by school children and Extinction Rebellion showed that, of the 2% of articles that criticised the actions of the protesters, a whopping 84% appeared in News Corp. The ABC wants the government to reverse its decision to impose an $84m indexation pause, an unlikely outcome with the details of cuts to staff and services due to be unveiled this month and no sign of the government softening. But before the ABC managing director, David Anderson, could make a final plea to parliamentarians on Tuesday, the delicate behind-the-scenes negotiations between the communications minister and the ABC were leaked to the papers – twice. A letter written by the communications minister, Paul Fletcher, to Anderson appeared in the pages of the Sydney Morning Herald. Fletcher had “strongly urged” the ABC to consider selling its capital city offices to cope with the $84m budget cut. Anderson addressed the suggestion in Senate estimates later that day, saying the property portfolio had been examined many times and the idea was not new. He also told senators the summer bushfires added an extra $3m in emergency broadcasting costs to the ABC budget at a time when the corporation had to absorb an ongoing annual budget cut of $105.9m. That $105.9m figure represents all the cuts the Coalition has made to Aunty between 2014, when Tony Abbott promised no cuts to the ABC or SBS, and 2022, when the indexation pause ends. The next day the Australian had another leaked letter, this time from Anderson to Fletcher. Anderson said if the government reversed the cuts the corporation would find $10m to fund additional regional services. Alas, we’re digesting our own ‘indexation pause’ budget cuts .. $84 million over three years, more jobs in the industry will be lost. https://t.co/S1qHcGF6by “If indexation was restored, combined with savings and efficiencies that the ABC has identified in recent months, the corporation would be in a position to commit an additional investment of up to $10m per annum to employ more journos in regional Australia and generate more content from regions for local and international stories,” the MD wrote. With the defence minister, Linda Reynolds, angrily insisting it was an “indexation pause” and ABC executives saying it was a cut, we can’t see the negotiations being successful. The ABC’s editorial director, Craig McMurtrie, was grilled at estimates about whether there had been any political interference in ABC News in relation to a report about sports rorts and another about a Rural Fire Service volunteer, Paul Parker, who told the prime minister to “get fucked from Nelligen” in a viral news clip. ABC’s Media Watch revealed last month that a news story about Parker was filed for the ABC’s 7pm bulletin but didn’t run. Then the story was slated to run on News Breakfast, only that didn’t run either. ABC management told Media Watch it had nothing to do with politics and everything to do with “accuracy, newsworthiness and priorities”. Why the ABC spiked an exclusive interview with the volunteer firefighter who abused the PM on national TV. #MediaWatchhttps://t.co/YaYWzg7xVz pic.twitter.com/CPWKrAM9XI McMurtrie told senators the story didn’t run on the news bulletin because it was unclear whether he had been sacked or was stood down. At the next opportunity the story wasn’t run because the “news cycle had moved”, he said “The important thing was that the newsroom had made the call and there was no pressure or intervention,” McMurtrie said. What did emerge from the exchange was that Anderson has never had a call from Scott Morrison personally – but he has received emailed complaints from the PM’s office. Anderson said the PMO emailed him about a story on the Lilli Pilli sports club, and after the story was examined it was amended and a correction published because it was based on a false assumption in a Facebook post. The story didn’t meet ABC editorial standards, McMurtrie said, and it had nothing to do with political influence. “On 20 January, ABC News Online published a story that suggested the Lilli Pilli Soccer Club may have had prior knowledge of a Sport Australia grant for the second stage of the expansion of its clubhouse,” the ABC correction says. The ABC accepts that was not the case.” Journalists snickered on Monday when a media release arrived in their inboxes trumpeting a world-first event: the first official KFC wedding. Of course Australia’s first “KFC Wedding” was in #Toowoomba 🍗🍟...Super Rooster should have broken into this market already 👰🏻🤵🏻 details @WINNews_TWBA 6pm pic.twitter.com/5OpTNrhWE4 “Having had their first date in KFC in 2017, Kate and Harrison applied to the KFC Weddings competition in September last year and were the first lucky couple to be wed through KFC Weddings,” the media release said. “Having won the competition for their take on the Fresh Prince of Bel-Air theme tune about their love, Kate and Harrison surprised 150 guests to the KFC Wedding complete with the KFC Food Truck, personalised buckets and Colonel themed celebrant and entertainer.” However, the PR firm that sent out the release and their clients KFC had the last laugh. Multiple Australian and international outlets, including news.com.au, 7news.com.au, the Daily Telegraph, 10 Daily, Pedestrian TV, Toowoomba Chronicle, the Courier Mail and KIIS 1065 covered the stunt, complete with multiple pictures and video. Most stories had bylines, and some were even pay-walled. Expect more of this press-release journalism when AAP shutters in June. Before we leave the subject of dumb press releases the great toilet paper shortage provided some publicists with priceless opportunities to flog their clients. We heard from one PR agent on behalf of a manufacturer of bidets. She wondered if Weekly Beast would like to interview him: “In light of the toilet paper shortage over coronavirus fears I thought you might be interested in talking about bidets”. Residents In Vaucluse And Toorak Have Started Panic-Buying Bidets https://t.co/Y9Z5hsYiEF pic.twitter.com/CCz24MDxPQ The manufacturer could talk about: how bidet seats work – “they are often retrofitted on your existing toilet taking the place of the old toilet seat”; how they “provide a better clean than toilet paper and how they are eco-friendly”."
"
Share this...FacebookTwitterNASA has recently issued a press release, here. A recent study by Davies & Molloy (2012) appearing in the Geophysical Research Letters shows that clouds have gotten lower over the first decade of this century. Hat tip: Die kalte Sonne.
Data from NASA's MISR instrument show that global average cloud height declined by about 1 percent over the decade from 2000 to 2010, (Source: NASA)
Here’s the NASA press release (emphasis added):
February 21, 2012
Earth’s clouds got a little lower — about one percent on average — during the first decade of this century, finds a new NASA-funded university study based on NASA satellite data. The results have potential implications for future global climate.
Scientists at the University of Auckland in New Zealand analyzed the first 10 years of global cloud-top height measurements (from March 2000 to February 2010) from the Multi-angle Imaging SpectroRadiometer (MISR) instrument on NASA’s Terra spacecraft. The study, published recently in the journal Geophysical Research Letters, revealed an overall trend of decreasing cloud height. Global average cloud height declined by around one percent over the decade, or by around 100 to 130 feet (30 to 40 meters). Most of the reduction was due to fewer clouds occurring at very high altitudes.
Lead researcher Roger Davies said that while the record is too short to be definitive, it provides a hint that something quite important might be going on. Longer-term monitoring will be required to determine the significance of the observation for global temperatures.
A consistent reduction in cloud height would allow Earth to cool to space more efficiently, reducing the surface temperature of the planet and potentially slowing the effects of global warming. This may represent a negative feedback mechanism a change caused by global warming that works to counteract it. “We don’t know exactly what causes the cloud heights to lower,” says Davies. “But it must be due to a change in the circulation patterns that give rise to cloud formation at high altitude.”
NASA’s Terra spacecraft is scheduled to continue gathering data through the remainder of this decade. Scientists will continue to monitor the MISR data closely to see if this trend continues.
For more information, visit: http://www.auckland.ac.nz/uoa/home/news/template/news_item.jsp?cid=466683.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




MISR, built and managed by NASA’s Jet Propulsion Laboratory, Pasadena, Calif., is one of five instruments on NASA’s Terra spacecraft, launched in December 1999. The instrument uses nine cameras at different angles to produce a stereo image of clouds around the globe, allowing measurement of their altitude and movement. For more on MISR, visit: http://www-misr.jpl.nasa.gov/ . For more on Terra, visit: http://terra.nasa.gov/ .
Another NASA mission that studies clouds is NASA’s CloudSat, also built by JPL and launched in 2006. CloudSat is the first satellite that uses an advanced radar to “slice” through clouds to see their vertical structure, providing a completely new observational capability from space. CloudSat’s primary goal is to furnish data needed to evaluate and improve the way clouds are represented in global models, thereby contributing to better predictions of clouds and thus to their poorly understood role in climate change and the cloud-climate feedback. For information on NASA’s CloudSat mission, visit: http://cloudsat.atmos.colostate.edu/ and http://www.nasa.gov/clouds.”
Cooling is the result of warming? How much more tangled up in a web of fantasies can one possibly get? And when they say “we don’t exactly know”, it really means they don’t have a clue, or they know but it’s a reason they are not supposed to mention.  Wasn’t CO2 supposed to cause positive feedbacks, and not negative feedbacks? Time to rework the models.
Fritz Vahrenholt and Sebastian Lüning at Die kalte Sonne site provide their remarks:
The decrease in high clouds means an additional cooling effect has been in place over the first decade, one that has not been taken into account up to now. It is known that global temperatures have not risen since the year 2000. The exact cause of the newly described cloud effect is still not known.
Larger deviations of the falling effective cloud height appear to be controlled by the Southern Oscillation, which is an internal oceanic cycle (see p. 313-314 in ‘Die kalte Sonne’). Could there be another longer period Pacific Ocean Cyclic, the PDO, behind the cloud trend? This remains speculation. But it is interesting to observe that the PDO also began its downward trend in the year 2000.

Die publication from Davies & Molloy (2012) appeared in the  Geophysical Research Letters of the AGU.
At MeteoKlima Christian Heuer discusses whether this could be Richard Lindzen’s Iris Effect (see p. 168-170 in “Die kalte Sonne”), that is a negative, dampening feedback that counteracts global warming.”
Amazing how everything that Vahrenholt and Lüning wrote in their book, which a number of German scientists have just recently dismissed offhand without reading, is turning out to be spot on.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterWe’ve got to keep the planet from warming 2°C since industrialization began, the AGW alarmist scientists warn us. So far we are told that manmade greenhouse gases have warmed the planet 0.8°C since about 1880, which means it must not warm more than another 1.2°C.

Hoffmann’s video shows that nobody has a clue as to what the real global mean temperature is. Estimates vary over a whopping 1.5°C range!
Rainer Hoffmann of solarkritik.de has put together an outstanding montage of video clips depicting various global mean temperature charts used by top scientists and media. What they reveal is truly stunning: the world’s top climate scientists have no clue what the real global mean temperature really is. As you will see, figures range from 14.5°C to 16.0°C!
First, it is important to know that according to scientists, the greenhouse effect adds 33°C to the temperature of the Earth’s atmosphere near the surface. That’s the consensus that the first 8 minutes of the video clearly shows. Wthout greenhouse gases, the temperature of the planet would be a frigid -18°C (0°F). Thanks to the greenhouse effect, the planet’s surface warms to a mean of 15°C.
So using the 2°C target, the globe therefore should not warm up beyond 15°C + 2°C = 17°C. Over 17°C, all hell will break loose they warn us.
Most climate scientists agree that temperatures have risen 0.5° since the 1950s, and 0.3°C from 1880 to 1950. So that means the global mean temperatures should appear as follows:
Today: 15.8°
1950: 15.3°C
1880: 15°C
Right? Well, it turns out IPCC scientists are all over the board when it comes to these figures and nobody really knows. What follows next are examples of what the German public has been hearing over the last few years from leading scientists and media. Rainer Hoffmann put together a number of videos depicting charts used by scientists and media. Now hold on to your seat!
10:56, Hans Schellnhuber on German public television, 11/2009:
Today: 15.3°C
1950: 14.8°C
1880: 14.5°C
11:40, Stefan Rahmstorf, chart implies:
Today: 15.5°C
1950: 15.0°C
1880: 14.7°C
12:25, IPCC 2007 4AR (brace yourself!)
Today: 14.5°C
1950: 14.0°C
1880: 13.7°C
According to the IPCC, we still haven’t reached natural greenhouse temperature of 15°C! All those “weather extremes” we’ve had over the recent years occurred below the natural greenhouse temperature! So how could it be CO2?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




14:20, ZDF German public television, 12/2009
Today: 14.5°C
1950: 14.0°C
1880: 13.7°C
15:31, IPCC lead scientist Mojib Latif, 03/2012
Today: 14.5°C
1950: 14.0°C
1880: 13.7°C
15:50, Book by Schellnhuber & Rahmstorf, 2006
Today: 14.5°C
1950: 14.0°C
1880: 13.7°C
Here we see that global mean temperature for Schellnhuber (see above) has gone up 0.8°C in just 3 years! Now that’s fast.
16:16, Der Spiegel, 1988
Today: 15.5°C
1950: 15.0°C
1880: 14.7°C
18:20, Ravenburger children’s book, 2010
Today: 16.0°C
1950: 15.5°C
1880: 15.2°C
According to Ravenburger, we’re now down to our last degree before we all die!
It gets even more bizarre. The video at the 20:20 mark shows Environment Minister Peter Altmaier saying in July, 2012, that the target was to limit global warming to 2 percent!
Finally at the 22:00 mark, Hans Schellnhuber takes the cake saying in 2008 that if the world’s population reaches 9 billion, the world will explode!
If anything, all this shows that leading IPCC scientists have no idea what the real mean global temperature is. They’re making things up. Hoffmann only looked at charts used in Germany. Imagine what we would find if looked all over the world.
Next time you see a temperature chart, check the vertical temperature axis. You may find more surprises.
Would somebody please tell me WTF the real global mean temperature is? This whole thing is just a total circus.
Hats off to Rainer Hoffmann for this observation.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHere’s something in line with yesterday’s post…how people can get caught up in mass hysteria (prerequisite: mass ignorance).Hat tip; DirkH
Germany’s online Süddeutsche Zeitung reports here on Environment Minister Nortbert Röttgen’s comments on the results of Durban.
Röttgen calls the outcome of Durban a “huge success”, yet “criticized global climate protection with clear words” in his offical government declaration. Obviously he isn’t happy with the “huge success”.
The following comments from Röttgen and the Süddeutsche Zeitung do not only confirm that mass climate hysteria has spread to the upper levels of the German government, but also to the Süddeutsche Zeitung, which quotes Röttgen:
…climate change is worldwide a central source of conflict and a ‘fundamental threat’ for more and more people.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Especially for people of island nations and desert regions, it is even a question of life and death. And that ‘we are are doing too little,’ Röttgen declared. ‘There is still a scary gap.’ Here it is a ‘question of humanitarian solidarity,’ that has to be committed to those who are impacted.”
In a nutshell – stop questioning the climate threat and start falling into line with the movement. Everything is at stake.
Of course, that is not true. It is hysterical. I wonder if Minister Röttgen or the writers at the Süddeutsche have ever read a single scientific paper on the subject of climate change. This climate “life and death” nonsense is what one typically hears from those who are either completely hysterical, or from people who maliciously spread hysteria.
While climate change is a matter of “life and death” for some, to me it is more a matter of sanity versus insanity, being informed versus being ignorant, or of being curious versus being just plain too lazy to get informed.
For journalists and environment ministers who would like to become informed, I recommend this: Die kalte Sonne.

Share this...FacebookTwitter "
"Last year’s summer was so warm that it helped trigger the loss of 600bn tons of ice from Greenland – enough to raise global sea levels by 2.2mm in just two months, new research has found. The analysis of satellite data has revealed the astounding loss of ice in just a few months of abnormally high temperatures around the northern pole. Last year was the hottest on record for the Arctic, with the annual minimum extent of sea ice in the region its second-lowest on record.  Unlike the retreat of sea ice, the loss of land-based glaciers directly causes the seas to rise, imperiling coastal cities and towns around the world. Scientists have calculated that Greenland’s enormous ice sheet lost an average of 268bn tons of ice between 2002 and 2019 – less than half of what was shed last summer. By contrast, Los Angeles county, which has more than 10 million residents, consumes 1bn tons of water a year. “We knew this past summer had been particularly warm in Greenland, melting every corner of the ice sheet, but the numbers are enormous,” said Isabella Velicogna, a professor of Earth system science at University of California Irvine and lead author of the new study, which drew upon measurements taken by Nasa’s Gravity Recovery and Climate Experiment (Grace) satellite mission and its upgraded successor, Grace Follow-On. Glaciers are melting away around the world due to global heating caused by the human-induced climate crisis. Ice is reflective of sunlight so as it retreats the dark surfaces underneath absorb yet more heat, causing a further acceleration in melting. Ice is being lost from Greenland seven times faster than it was in the 1990s, scientists revealed last year, pushing up previous estimates of global sea level rise and putting 400 million people at risk of flooding every year by the end of the century. More recent research has found that Antarctica, the largest ice sheet on Earth, is also losing mass at a galloping rate, although the latest University of California and Nasa works reveals a nuanced picture. “In Antarctica, the mass loss in the west proceeds unabated, which is very bad news for sea level rise,” Velicogna said. “But we also observe a mass gain in the Atlantic sector of east Antarctica caused by an increase in snowfall, which helps mitigate the enormous increase in mass loss that we’ve seen in the last two decades in other parts of the continent.” The research has further illustrated the existential dangers posed by runaway global heating, even as the world’s attention is gripped by the coronavirus crisis. Crucial climate talks are set to be held later this year in Glasgow, although the wave of cancellations triggered by the virus has threatened to undermine this diplomatic effort. “The technical brilliance involved in weighing the ice sheets using satellites in space is just amazing,” said Richard Alley, a glaciologist at Penn State University who was not involved in the study. “It is easy for us to be distracted by fluctuations, so the highly reliable long data sets from Grace and other sensors are important in clarifying what is really going on, showing us both the big signal and the wiggles that help us understand the processes that contribute to the big signal.”"
"
By Steve Goddard and Anthony Watts

The Navy requires accurate sea ice information for their operations, and has spent a lot of effort over the years studying, measuring, and operating in Arctic ice both above and below, such as they did in the ICEX 2009 exercise.
The US Navy attack submarine USS Annapolis (SSN 760) rests in the Arctic Ocean after surfacing through three feet of ice during Ice Exercise 2009 on March 21, 2009. The two-week training exercise, which is used to test submarine operability and war-fighting capability in Arctic conditions, also involved the USS Helena (SSN 725), the University of Washington and personnel from the Navy Arctic Submarine Laboratory.
So, if you are planning on bringing a $900 million Los Angeles class submarine through the ice, as the captain might say to the analyst after receiving an ice report: “you’d better be damn sure of the ice thickness before I risk the boat and the crew”.
Below is a blink comparator of U.S. Navy PIPS sea ice forecast data,  zoomed to show the primary Arctic ice zone.

The blink map above shows the change in ice thickness from May 27,  2008  to May 27, 2010. As you can see, there has been a large increase in   the area of ice more than two metres thick – turquoise, green, yellow   and red. Much of the thin (blue and purple) ice has been replaced by   thicker ice.
Source images for the blink comparator:
http://www7320.nrlssc.navy.mil/pips2/archive/pips2_thick/2008/pips2_thick.2008052700.gif
http://www7320.nrlssc.navy.mil/pips2/archive/pips2_thick/2010/pips2_thick.2010052700.gif
This was quantified by measuring the area percentage in the Arctic  Basin of the 0-1, 1-2, 2-3, 3-4, and 4-5 metre ranges. The graph below  shows the results. This technique assumes an equal area projection,  which should be fairly accurate north of 70N.
In 2008, less than half of the ice (47%) was greater than two metres  thick. Now, more than 75% of the ice is greater than two metres thick.  In 2008, 18% of the ice was more than three metres thick. This year that  number has increased to 28%. There has been nearly across the board ice  thickening since 2008. There was slightly more 4-5 metre ice in 2008,  due to the big  crunch in the summer of 2007.

Now on to calculating the volume. That calculation is straightforward  :
volume = (A1 * 0.5) + (A2 * 1.5) + (A3 * 2.5) + (A4 * 3.5) + (A5 *  4.5)
Where A1 is the area of ice less than one metre, A2 is the area of  ice less than two metres, etc.  The 2010/2008 volume ratio came out to  1.24, which means there has been approximately a 25% increase in volume  over the last two years. The average thickness has increased from about  2.0 metres to 2.5 metres. That means an extra 20 inches of ice will have  to melt this summer. So far, this seems unlikely with the cold Arctic  temperatures over the last couple of weeks.

http://ocean.dmi.dk/arctic/plots/meanTarchive/meanT_2010.png
Now let’s look at the volume percentages. In 2010, 87% of the ice (by  volume)  is greater than two metres thick. But in 2008, only 64% of the  ice (by volume) was greater than two metres thick.

A few weeks ago, when extent was highest in the JAXA record, our  friends were asking for “volume, not extent.” Their wishes have been  answered. Ice volume has increased by 25% in the last two years, and  those looking for a big melt are likely going to be disappointed.

Here is the measured data:

Do you think it odd that this increase isn’t prominently mentioned on the PIOMAS  site? It seems very relevant.
———————————————–
If a man will begin with certainties, he shall end in doubts; but  if he will be content to begin with doubts he shall end in certainties.
– Sir Francis Bacon

Sponsored IT training links:
If your are looking for quick success  in 350-018 exam then join today to explore useful 642-974 resources and pass EX0-101 on first try guaranteed.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8bb7ea81',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**A UK-wide approach to coronavirus rules after Christmas is needed, Wales' First Minister Mark Drakeford has said.**
The UK government and ministers in Wales, Scotland and Northern Ireland have agreed three households can meet from 23 December until 27 December.
Mr Drakeford said it ""makes sense"" to ""respond to the consequences of greater household mixing"" together in the aftermath of the five-day period.
The UK government said it was ""a key example"" of a unified UK-wide response.
Mr Drakeford said his own family would make ""some modest use of the freedoms"".
Speaking on BBC Radio Wales, he said: ""I am cheered up by the fact that by meeting together four times, we've been able to reach a common position on the five days of Christmas.
""But I want us to reach a common position on how we approach the aftermath of Christmas as well and I think it makes sense to do that across the United Kingdom as well - have a common approach to responding to the consequences of greater household mixing.
""I do think that getting around the table together to go through a plan for it should be the next step [in] what I think of as the successful way in which we've been able to plan together for the five days of Christmas itself.""
Under the agreement for Christmas, made at a meeting of Cobra on Tuesday afternoon:
Plaid Cymru leader Adam Price called for the Welsh Government to ""keep a close eye"" on infection rates and impose further restrictions if necessary.
Mr Price also called for quicker test results so ""tracing teams can begin their work of clamping down on cases and possible clusters or outbreaks"".
The leader of the Welsh Conservatives in the Senedd, Paul Davies, claimed it was Mr Johnson who had suggested the ""collaborative approach"".
Meanwhile a UK government spokesman added: ""We welcome the desire of the Welsh administration to work even more closely with the UK government, delivering for communities across all four corners of the country.""
However some scientists have warned that the relaxation of Covid restrictions over the festive period could spark another wave of infections and further deaths.
They said a typical Christmas gathering at home was the type of environment where infections could spread.
People have been advised to take precautions when meeting their Christmas bubble, such as washing hands frequently and opening windows to clear potential virus particles.
When asked what his plans were for Christmas, Mr Drakeford said: ""I am looking forward to seeing some members of my family who I haven't been able to meet indoors for many, many months now, but we will do it in a very contained, careful way.
""We certainly won't be mixing with people who are vulnerable or whose age puts them at a particular disadvantage.
""I am looking forward to being able to make some modest use of the freedoms.""
When asked about introducingÂ tougherÂ restrictionsÂ ahead of Christmas, he said his cabinet would meet on Thursday ""to see whether or not the position in Wales means that we have to introduce some further restrictions to create the headroom we need to be able to use those five days over Christmas in a responsible way"". Â Â
On Tuesday, Mr Drakeford said an agreement to relax Covid rules over Christmas was not ""an instruction to meet with other people"".
""So it's not a choice between relaxation or no relaxation. It's having a form of relaxation where there are rules that people will recognise that will allow people to enjoy Christmas, but we'll do it in a controlled way."""
"
Share this...FacebookTwitterToday some German warmist sites are busy touting a new paper authored by Lewandowsky et al in the journal Psychological Science: NASA faked the moon landing—therefore (climate) science is a hoax: An anatomy of the motivated rejection of science.

Paper now wants us to believe that it is the Bush-followers (Tea Party followers) who believe in the 9-11 and moon-landing conspiracies. (Photo: dbking, via Wikipedia)
According to the paper’s abstract (emphasis added):
We report a survey (N > 1100) of climate blog users to identify the variables underlying acceptance and rejection of climate science. Paralleling previous work, we find that endorsement of a laissez-faire conception of free-market economics predicts rejection of climate science (r is approx. 0.80 between latent constructs). Endorsement of the free market also predicted the rejection of other established scientific findings, such as the facts that HIV causes AIDS and that smoking causes lung cancer. We additionally show that endorsement of a cluster of conspiracy theories (e.g., that the CIA killed Martin-Luther King or that NASA faked the moon landing) predicts rejection of climate science as well as the rejection of other scientific findings, above and beyond endorsement of laissez-faire free markets. This provides empirical confirmation of previous suggestions that conspiracist ideation contributes to the rejection of science. Acceptance of science, by contrast, was strongly associated with the perception of a consensus among scientists.
So we have here is a study that attempts to stigmatise and marginalise anyone who questions the notion that trace gas CO2 modulates global temperature and storm intensity. Forget that global temps have not risen in 15 years and that 70% of the Holocene was warmer than it is today. And forget that some important ocean cycles were in their positive modes from from 1980 to 2000 and that solar activity during the 20th century was at its most intense level in all of the Holocene. On and on goes the list.
The other point is that climate skeptics are not the ones who are paranoid and obsessed with the notion that human lifestyles are pushing the planet over the brink. Skeptics are not the ones who become hysterical with every wind gust. The true nuts are the extreme warmists.
Warmist media pushed the junk 9/11 and moon-landing theories
Moreover, it was the “enlightened”, i.e. the warmist media, in Germany who zealously promoted the 9/11 and moon-landing conspiracies – all in  an effort to fan the flames of resentment against the USA during the Bush years. What follows are some examples of German television and media drugging up its viewers with the silly conspiracy theories.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Here’s a “documentary” questioning the moon-landing shown on warmist German television:

And here’s another:

And the following was delivered by the renowned, warmist Spiegel TV!

Or read all about it in print at the über-warmist Stern magazine here. These are just a few examples. All these above media outlets floating the whacko 9/11 and moonlanding theories were and are still fervently pushing AGW theory today. So let’s be clear who the real 9/11 and moon-landing kooks are: the same ones who think we can regulate climate and weather with a few molecules of CO2.
Of course, the documentaries above tried to give an impression of neutralality, but their true intentions were clear -it was to sow the seeds of anti-Americanism in the viewers’ minds.
Today in Germany, many of the purveyors of this twisted propaganda would like us to forget their involvement in this. After Obama became president, some even aired pieces debunking the conspiracy theories to clean the slate – but not before Bush left office. And today, as the above nutty psychology report shows, we see they are attempting make people believe that it is actually the Bush-followers (Tea Partiers) who are spreading nutjob conspiracy theories they themselves hatched earlier.
Should we be surprised? What else should we expect from those who are losing the debate and have no scruples about being dishonest?
 
Share this...FacebookTwitter "
"Even by the standards of overpriced San Francisco, the Sea Cliff neighborhood is astronomically expensive. Nestled between two gorgeous parks and with what a realtor might describe as commanding views of the Golden Gate, it could hardly be different. Homes in the area routinely go for more than $10m. Jack Dorsey, the CEO of Twitter and the payment service Square, recently bought a place here for $21.5m – next door to his $18m present home. The 0.62-acre compound is recessed from the street and perched on a cliff overlooking the beach. And that’s where things get interesting, because cliffside living has become an increasingly risky proposition in California. Warming ocean temperatures are whipping up stronger surfs and more brutal winter storms, causing cliffs to crumble ever faster into the sea. The consequences for thousands of cliff-top houses such as Dorsey’s could be catastrophic. Still, @Jack’s bet isn’t a bad one: depending on when the house goes over the edge, it might well be the rest of us that gets stuck with the bill.  That’s because most of the cost of protecting California properties from coastal erosion, wildfires and other effects of the climate crisis will eventually have to be met by the state, with public money. This means those costs won’t fall on the disproportionately white and wealthy people who own property. Rather, they’ll be increasingly borne by the working- and middle-class Hispanic, black and brown Californians that make up the majority of the state, many of whom don’t own real estate. Without really grappling with this reality, the state is slipping step by step towards a massive wealth transfer from the general public to the owners of private property. It’s one more way in which the climate crisis is also a crisis of racism and inequality. What Sea Cliff could look like in a few years’ time can be glimpsed in the town of Pacifica, 14 miles to the south. Parts of the town, which is much more middle-class than Sea Cliff, sit directly on beautiful bluffs that overlook – and are tumbling into – the Pacific Ocean. When the town’s mayor proposed a “managed retreat” from the coast, home owners and local realtors revolted: the proposal would have effectively taken their homes off the market, cutting them off from potential profits. (Owners does not mean residents: about a third of Pacifica’s housing stock, including many of the most threatened buildings, consists of rental units.) So instead of a managed retreat, the city is taking money from the public coffers and using it to protect property investments by building sea walls and replenishing eroding beaches with trucked-in sand, among other measures. This is a dynamic we have seen throughout the late capitalist economy. The sociologist Ulrich Beck described it as a change from “a logic of wealth distribution” to one of “risk distribution”. Profits are privatized, but risk is made public. The banks made a bunch of bad bets on crappy mortgage debts? Bail them out with public money and give the executives multimillion-dollar bonuses. Someone half bakes a fundamentally unprofitable tech business? Let them IPO it so they can liquidate hundreds of millions of dollars of stock options while transferring the ultimately worthless company into the hands of public pension funds and workers’ 401ks. That’s the same thing that is now happening in California, where the land is uniquely threatened and at the same time uniquely valuable. There is a concerted political effort not to manage the risk, but rather to keep it from impacting value by making the public bear the costs of the climate crisis through things such as the sorts of publicly funded disaster relief programs and state-subsidized insurance payouts that Jack Dorsey could theoretically benefit from. This is, in fact, what many of the owners of capital and real estate think the government is for: protecting the value of private property at all costs. It’s one of the reasons we have a climate crisis – instead of a robust, rapid transition away from fossil fuels – in the first place. The sheer immensity of the climate crisis, and of California, ensures that more and more of the costs will be borne by the public. The Los Angeles Times estimates that $150bn in California property might be impacted by coastal flooding and erosion by 2100. That’s $150bn in private wealth which the government has made it a public priority to preserve. Those costs are dwarfed by the risks created by the region’s intensifying wildfires, which threaten millions of properties around the state. Individuals and insurance companies currently bear financial responsibility for property damaged by wildfires, but there is already pressure to collectivize these risks. It will go something like this: as houses become astronomically expensive, insurance payouts become astronomically large. In response, in threatened areas, private insurers will cancel coverage, or multiply rates to the point of unaffordability. The state will be forced to step in to stabilize the rates, and keep the land valuable, which will likely involve something like the National Flood Insurance Program, which subsidizes flood insurance provided by private insurers and underwrites the full extent of their losses. Currently, the state is forcing insurance companies not to cancel coverage, but reinsurers are getting worried, meaning the pressure is on to decline coverage – something that is already happening in various parts of the state. This is exactly the point where historically the government has stepped in — and there are already calls for it to do so now. The racist dimension to this wealth transfer must not be overlooked. Fewer than 55% of California households own their dwelling and only 42% of Latino households and 33% of black ones do. Non-urban space, open space, and at-risk space in California is today particularly white, or at least white-owned. Especially in the sorts of rural areas threatened by wildfire, that disparity is highly dependent on California’s history of racial violence and exclusion. The genocide of California’s first peoples; restrictions on the citizenship status of Asian immigrants; the seizure of Japanese American land during the second world war; the arrogation of land for infrastructure projects in the postwar period; discriminatory lending practices, racial covenants and other racist real estate policies, perpetuated by de facto segregation – all worked to ensure that non-white property ownership in rural California has remained low and concentrated in dense cities. All of this creates an unjust mismatch: the collective that is underwriting the risk of climate catastrophe will not be the same as the group that is incurring it. As a result, the siphoning off of public wealth to protect private property will increasingly favor white Californians. Of course, that’s one of the reasons it’s likely to be politically acceptable. It would be difficult to imagine the government sanctioning a massive wealth transfer in the other direction, for example by relieving the mortgage debts of the black and brown Americans who were the primary victims of the subprime crisis. But when fire and other types of home insurance markets fail, as they are already beginning to do and inevitably will, the state will have to step in to shore up the largely white property market with black, brown, working and middle-class public money. As the incalculably large price tag of climate change comes due, those excluded from the property market will increasingly foot the bill for California’s cult of the homeowner. It remains to be seen whether that cult will endure, or whether the state can rethink its relationship to real estate. • This article was updated on 9 March 2020 to emphasize that individuals and insurance companies currently bear the risk for wildfire damage"
"
Share this...FacebookTwitterEnergy poverty is sweeping over modern Germany like never before.
Flagship German newspaper Die Welt has an online report titled: Fast 800.000 Deutsche können Strom nicht bezahlen. In English: Almost 800,000 Germans cannot pay for electricity. 

Green energy leaves Germans in the dark.
As Germany subsidies wealthy homeowners and businesses owners to install solar panels on their homes and commercial buildings, low income families living in rented apartments are getting stuck footing skyrocketing electric bills. Many can no longer afford to pay for electricity, and so the utilities are cutting off their power.
Indeed high energy prices are causing everything else to get more expensive as well – all this while the euro is threatened to collapse under the weight of massive debt due to financial ineptitude.
So it’s little wonder that German politicians are beginning to panic and coming up with really nutty solutions. Instead of scaling back the cause of the energy mess (government meddling in the energy sector) they are threatening to do the opposite: i.e. meddle even more – much more.
Aribert Peters, Chairman of the Bund der Energieverbraucher (Association of Energy Consumers) says that already 600,000 to 800,000 people in Germany have had their electricity cut off, all thanks to skyrocketing electricity prices due to friendly green energy. Spooked, a number of leading politicians and consumer advocates are now calling for financial assistance for low income households, i.e. energy welfare. Die Welt writes:
Energy companies should be obligated to offer the first 500 kilowatt-hours per household at a low rate, SPD (social democrat party) faction vice chairman Ulrich Kelber demanded in a strategy paper, which he wants to present to the SPD leaders.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Peters of the Association of Energy Consumers, however, goes even further, saying there’s a need for a general cost exemption for the first 500 kilowatt hours consumed per year and household. The exemption should apply to all citizens.
Also the VdK Social Association of Hesse-Thuringia is demanding social tariffs. VdK chairman Udo Schlitt says that without a price rebate, more and more people with low incomes are going to have their power shut off. He proposes:
Therefore all power producers must be mandated to offer binding social rates by law.”
So in summary, here’s Germany’s latest energy plan: 1) Force power companies to buy exorbitantly-priced, inefficient and intermittent-supply green energy on one side, and then force them to give it away, or sell it at a low price, on the sales side!
How long can that go on before it all collapses?
Not only is electricity to be given away, DIE WELT also brings up another SPD scheme, one of course that the other parties will join in on:
Moreover, there should also be a billion-euro subsidy program so that, for example, energy saving refrigerators can be bought.”
There you have it. First the government took over the energy sector, and now we see it is moving in to take over private households. If this allowed to happen, then in 10 years Germany will no longer be recognizable.
You can think out the rest.
 
Share this...FacebookTwitter "
"The national infrastructure strategy to invest £100bn in boosting the economy and tackling the climate crisis is expected to be delayed until after the budget. The plan to improve transport connectivity and work towards achieving net-zero emissions by 2050 had been set to be published “alongside” the budget, which is due on Wednesday.  But the chancellor, Rishi Sunak, who took over at the Treasury last month, is not expected to unveil the plans seen as being crucial to the government’s “levelling up” agenda until a later date. Whitehall sources were unable to say when it would be published, but expected the delay to be only a matter of days or weeks. However, the shadow chancellor, John McDonnell, said the delay represented “absolute chaos” in government. “We are facing the threat of climate change and an economy at risk of recession. That’s why we desperately need an immediate start to large-scale infrastructure investment,” he said. “Delaying implementation of investment is unacceptable.” Sir John Armitt, the chair of the national infrastructure commission, said they were “disappointed” at the delay but expressed confidence that ministers remained committed to infrastructure investment. “Naturally we are disappointed about the further delay in the government’s formal response to the national infrastructure assessment, which we published over 18 months ago,” he said. “However, we are encouraged by the evident focus the government wishes to place on investing in the UK’s future infrastructure. “Prioritising that investment within a long-term plan is key to success and if a short delay leads to a better strategy that more comprehensively addresses our recommendations, it will be worth the wait.” A Downing Street spokesman said: “It is vital that we give these decisions the proper time and care they deserve. The national infrastructure plan will follow in the coming months and government officials are working on it as a priority.”"
nan
"
Story from AFP via Breitbart, h/t to Leif Svalgaard. Maybe the Chinese had it right way back then with this gadget:
The earliest seismoscope was invented by the Chinese philosopher Chang Heng in A.D. 132. This was a large urn on the outside of which were eight dragon heads facing the eight principal directions of the compass. Below each dragon head was a toad with its mouth opened toward the dragon. When an earthquake occurred, one or more of the eight dragon-mouths would release a ball into the open mouth of the toad sitting below. Image: USGS

Toad is a telltale for impending quakes:  scientists
For ages, mankind has craved a tool that can  provide early warning of that terrifying moment when the earth begins to  shake.
But if a scientific paper published on Wednesday is confirmed, we may at  last have found one.
The best hope yet of an earthquake predictor could lie in a small,  brown, knobbly amphibian, it suggests.
The male common toad (Bufo bufo) gave five days’ warning of the  earthquake that ravaged the town of L’Aquila in central Italy on April 6, 2009, killing more than 300 people  and displacing 40,000 others, the study says.
Biologist Rachel  Grant of Britain’s Open University embarked on a toad-monitoring project at San Ruffino  lake, 74 kilometres (46 miles) north of L’Aquila, 10 days before the 6.3-magnitude quake  struck.
Her two-person team observed the site for 29 days, counting toad numbers  and measuring temperature, humidity, wind  speed, rainfall and other conditions.
By March 28, more than 90 male toads had mustered for the spawning  season, but two days later, their numbers suddenly fell, Grant reports.
By April 1 — five days before the quake — 96 percent of the males had  fled.
Several dozen ventured back on April 9 for the full moon, a known  courtship period for toads, although the tally was some 50-80 percent  fewer than in previous years.
After this small peak, the numbers fell once more, only picking up  significantly on April 15, two days after the last major aftershock,  defined as 4.5 magnitude or higher.
In addition, the number of paired toads at the breeding site also  dropped to zero three days before the quake. And no fresh spawn was  found at the site from April 6 until the last big after-tremor.
Grant says  the toads’ comportment is a “dramatic change” for the species.
Once male toads hole up at a breeding site, they usually never leave  until the annual spawning season is over, she notes.
Eager to answer the riddle, Grant obtained Russian measurements of electrical activity in the ionosphere,  the uppermost electromagnetic layer in the atmosphere, which were picked  up by very low frequency (VLF) radio receivers.
The toads’ two periods of exodus both coincided with bursts of VLF  disruption.
Read the entire article at Breitbart


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8cd3bace',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"I’ve heard it many a time, and you probably have too. It’s supposedly the trump card to any argument on addressing climate change globally: “Yeah, but what’s the point? Isn’t China building a new coal plant every week?”   If the world’s largest country, with a population of 1.4 billion and counting continues its unwavering march to build carbon intensive fossil fuel generation, what meaningful negotiations can happen on climate change?  The factual origin of the “one plant a week” claim is difficult to trace, but clearly warrants some investigation. If you’re a straight-to-the-point kind of person, the answer is no. When it was coined it was likely to have been true, but in a dynamic and growing economy, it’s one of those “facts” that is outliving the conditions it emerged from. The present-day story is a little more complex. True, China has seen rampant growth in coal energy over the past decade and we know the country has relied on cheap coal to fuel its growth; buckets of the stuff in fact. In 2010, China alone consumed about 3.3 billion tonnes (around 47% of the world total) and it maintains a planning pipeline of 363 new projects under consideration; a whopping total of 558GW additional coal.  That’s compared to a total installed coal capacity of 313GW in the US, the world’s second biggest coal user. Spread those planned Chinese projects evenly over the next 15 years, that’s roughly one every two weeks. But this simplistic extrapolation is outdated and misleading. Since those coal plants were proposed, China has changed its energy policy to curb carbon emissions and pollution. A five-year plan for the coal industry was introduced in 2012, with a target to cap annual domestic coal consumption to 3.9 billion tonnes by 2015.  Since then, the net buildout of coal plants has dropped dramatically.  Planning rejections have been on the rise and the coal industry has been overtaken by new renewable energy. About one-third of the proposed new coal–fired plants that have been approved are delaying the start of their construction, resulting in a big slowdown in newly added coal power capacity. At the same time, coal generation is being phased out (80GW of old capacity was removed from 2001-2010) and there are plans to  phase out a further 20 GW of coal.  Consider the graph below; even as China’s GDP continues to rise on a fairly stable path, coal consumption is beginning to tail off. So why the change in heart?  First and foremost, 70% of China’s coal companies are reportedly losing money as rising production costs squeeze the viability of adding more coal.   Renewable energy meanwhile, is growing from strength to strength. The country is already the world’s largest producer of wind power, and it plans to double capacity by 2020. New renewable capacity surpassed new fossil fuel and nuclear for the first time last year. The Chinese renewables boom comes as its citizens are increasingly worried about air pollution. This is the other reason the country’s leadership has gone off coal – persistent smog in industrial and developed areas is hard to ignore, especially when it almost ruined the Beijing Olympics.  Since then, there has been mounting social unrest and growing discontent at the expansion of coal and its impact on health. China’s leadership has been anxious to head off potential sources of unrest, hence its decision to slash coal consumption and close polluting mills, factories and smelters. These considerations point to more optimism than the 558GW pipeline of coal would suggest. Coal build-out rates are slowing dramatically while China continues to make the world’s biggest investments in renewables.  If someone brings out the “one coal plant a week” argument, you can arm yourself with the knowledge that the Chinese coal juggernaut is wounded and slowing, and will, based on China’s own policy objectives, soon trundle to a halt.  As world leaders continue to meet and negotiate the global scale of the climate challenge, it would be unfair to claim that China is not pulling its weight."
"**The Scottish government has published its**guidance on forming household bubbles over the festive period **. The advice covers how many people will be able to meet in Scotland, and the rules on where that can happen.**
The current Covid rules will be relaxed between 23 and 27 December to allow people to travel within the UK and spend Christmas together in bubbles of up to three households.
The Scottish government has recommended that these bubbles should contain a maximum of eight people - although children under the age of 12 do not count towards that total, and do not need to physically distance from others.
Everyone else is encouraged to keep 2m (6ft 6in) away from those outside their own household as much as possible to lower the risk of transmitting the virus.
You can only be in one Christmas bubble, and cannot change to a different one.
The government says anyone thinking of creating a bubble should carefully consider the risks. It stresses that people do not have to meet other people or feel pressured to spend Christmas with another household.
The advice is to keep in touch using technology wherever you can, limit the number of times that you meet in person - and to gather outside if possible. For example, go for a walk rather than having a meal together.
Those in extended households can form a bubble, but it can only contain one extended household.
Where parents do not live in the same household, children can still move between their homes if they are in different bubbles.
Those in a bubble can only gather in a private home, outdoors or at a place of worship. For those meeting in someone's home, it is possible to stay overnight.
If you are meeting in someone's home it is recommended that you:
People should not mix with other households elsewhere. If you are going to a pub, restaurant or a leisure or entertainment venue, you are urged to stay within your own household.
The opening hours for hospitality venues will follow the rules which apply in that area at the time.
The government says people in a bubble should not stay in tourist accommodation together as a group.
In addition, you should not go shopping with those in your bubble, and should shop on your own wherever possible.
Travel restrictions will be relaxed from 23 to 27 December to allow people to travel between local authority areas and the four UK nations to join a bubble.
If you are using public transport, the advice is to book ahead where possible and follow the rules on wearing face coverings while travelling.
Anyone travelling to or from a Scottish island should make their journey within the five-day period from 23 to 27 December.
Once you have arrived, you should then follow the travel guidance which applies in the area where you are staying. If that is in level three or four, for example, you would have to avoid any non-essential travel outside that council area.
Students who return home at the end of term will be part of the household they have returned to. Plans are already in place to allow students return home over Christmas if they return two negative Covid-19 tests.
People other than students who live in a shared flat or house are considered a household.
The government is urging them not to split up and enter separate bubbles over the festive period.
If people are joining different bubbles, they should isolate from their flatmates for about a week both before and after joining the bubble.
The government says anyone who has previously been advised to shield because they are at highest clinical risk from Covid-19 should ""take time to think"" about forming a bubble because it would bring greater risks.
It says people should not feel pressured to enter an environment which makes them anxious.
People can still go into another household to provide care and support for a vulnerable person.
However, if you visit someone in hospital, hospice or a care home the government says the safest way to spend Christmas would be not to form a bubble with another household.
That is because doing so would increase the risk of being exposed to Covid-19 and passing it on to other people, and those in care homes, hospitals and hospices can be particularly vulnerable.
If someone in a bubble develops Covid-19 symptoms, everyone within the bubble must isolate immediately if they met that person any time between two days before and 10 days after their symptoms started.
If that person tests positive, all members of the bubble must self-isolate for 14 days from the start of symptoms or their most recent contact.
UK government guidance for people in England does not set a limit on the number of people in a bubble, but says this should be kept ""as small as possible"".
It adds that the rules on meeting people outside your home will depend on the regulations which apply in the tier you are staying in.
No separate guidance has been published for Wales or Northern Ireland at this stage, although people can travel to or from Northern Ireland on 22 and 28 December. The NI executive is meeting on Thursday to discuss the rules for the festive period.
**Use the form below to send us your questions and we could be in touch.**
_ **In some cases your question will be published, displaying your name and location as you provide it, unless you state otherwise. Your contact details will never be published. Please ensure you have read the terms and conditions.**_
If you are reading this page on the BBC News app, you will need to visit the mobile version of the BBC website to submit your question on this topic."
"**Coronavirus infection rates in England are continuing to show signs of levelling off - but the picture across the UK is mixed, according to data from the**Office for National Statistics **.**
In Wales and Northern Ireland, infections have been decreasing in recent weeks - but in Scotland, they seem to be rising.
After lockdown ends in England, most areas face tougher tier restrictions.
Most will be in tier two - high alert, including London and Liverpool.
In Scotland, Wales and Northern Ireland the devolved administrations have the power to set their own coronavirus regulations, though all four UK nations have agreed a joint plan for Christmas.
In England, decisions on post-lockdown tiers are based on how fast case rates are falling or rising in different areas, as well as numbers affected in the over-60s.
With the second lockdown having started on 5 November, Prof Kevin McConway, statistics expert from the Open University, says it might seem disappointing that progress to reduce infections hadn't been faster.
""People continue to give positive test results, on average, for at least 10 days after they were first infected, so some of the people who tested positive in the most recent week would have been infected before the English lockdown began,"" he said.
The ONS figures are based on thousands of people tested for the virus in households across the UK, whether they have symptoms or not.
Of those tested in the week to 21 November, one person tested positive out of every:
How many confirmed cases are in your area?
What are the new rules in England, Scotland, Northern Ireland and Wales?
According to the ONS estimates, rates in England increased in the East Midlands and North East that week, while continuing to fall in the North West.
In the east of England, London, the South East and South West, rates now appear to be decreasing too.
The areas with the highest number of people infected per head of population are Yorkshire and the Humber, the North West and North East.
Secondary-school-age children and young adults are seeing the highest infection rates.
This information is based on a relatively small number of people testing positive in each age group and region, so there is a wide margin for error.
In Scotland, an estimated 45,700 people had the virus in the week to 21 November - one person in every 115, up from one in 155 the previous week.
But the ONS says the results are based on modelling and ""should be interpreted with caution"".
The ONS figures are one source of data which helps the government's scientific advisers estimate the reproduction (R) number of the virus every week.
Another source is the Covid symptom study app, which suggests there has been a fall in new UK daily symptomatic cases - from 34,279 to 29,311 - over the two weeks up to 22 November.
This estimate is based on one million people using the app every week.
Data from Public Health England shows rates of coronavirus cases are still rising in 45% of areas (shown as pink, red or dark red in the map), despite the second lockdown.
However Dr Yvonne Doyle, PHE medical director, says ""there is now reason for hope"".
""Case rates have fallen across every age range and in all regions, and positivity in both pillars [NHS and community testing] has also decreased. Over time we can expect that to lead to fewer hospitalisations and deaths.
""The huge efforts people have made over the past few weeks are starting to pay off,"" Dr Doyle said.
The government's daily figures for confirmed UK cases of coronavirus are often much lower than the ONS numbers because they only count people with symptoms testing positive.
On Thursday, the government reported that 17,555 people tested positive and 498 people had died within 28 days of a positive test.
Over the past week, that's a 25% reduction in cases. The number of patients admitted to hospital is also falling - but deaths continue to rise."
"
Share this...FacebookTwitterAccording to the University of Wisconsin, Madison here, on June 11, 2012, the South Pole Station measured a new record low temperature.

Antarctica weather station. Photo source: http://amrc.ssec.wisc.edu/aboutus/
The mercury dropped to -73.8°C/-100.8°F, breaking the previous minimum temperature record of -73.3°C/-99.9°F set in 1966.
Must be because of global warming!
Hat/tip: http://www.kaltesonne.de/
 
Share this...FacebookTwitter "
"London’s cycle hire scheme has become a prominent fixture in the capital’s transport network since it opened in 2010. Known as “Boris Bikes”, it is Barclays Bank that has provided commercial sponsorship for the scheme from the beginning, a relationship that is due to end in 2015. So the search is now on for a successor with deep pockets, one that is willing to play a role in shaping the future of the scheme. Many bike hire schemes begin small, with the number of bikes initially in the hundreds rather than thousands. But in London, helped by a swelling population of more than 8m people and the support of the city mayor, the scheme opened with 5,000 bikes and has gradually expanded to 11,200. It is now the second largest scheme in Europe, after Paris. The financial support pledged by Barclays (£25m over five years) was certainly a factor that enabled the scheme to open at this scale. The end of 2013 saw a decline in the number of journeys made, in comparison to the same period in 2011 and 2012, before picking up again in 2014 to hit a milestone of 30 million journeys. A study of the scheme’s users found they were disproportionately male and from more affluent areas of the city. Hopefully this issue will be addressed by the extension of the scheme to other parts of London, encouraging access to a wider spectrum of the city’s population.  For many schemes, including London’s, private sponsorship is an important element of the business model. JCDecaux and Clear Channel (both outdoor advertising companies) are involved in many European schemes. They typically manage the scheme and supply capital for the start-up and running costs in exchange for rights to a proportion of the advertising boards across the city. The London scheme differs here in that the sponsor’s investment provides advertising of their brand, as opposed to increasing the share of the market they operate in.    For London, this external sponsorship is vital – Transport for London are looking for £37.5m – and the scheme has not yet shown to be profitable. As Barclays withdrew their financial support, the scheme’s expansion into southwest London in 2013 was taxpayer funded. Nearby councils were reported to have jointly paid around £4m towards the £10m cost.  Schemes have sometimes relied upon an individual to champion the policy and ensure its success, especially in the early days of a scheme. London mayors Ken Livingstone and Boris Johnson have had important roles for London, but a champion will continue to be needed to prevent the scheme from faltering.  As the London cycle hire scheme reaches a crossroads, what can be learnt from other schemes? The Paris scheme is seen as a great success but it relies upon high user numbers to offset the expense of sustaining it. Smaller schemes – for example those run by Nextbike– offer a greater likelihood of financial sustainability, but lower running costs are a key factor in this. Crucially, in many cities cyclists benefit from wider roads and more defined space. In contrast, one of the most pressing issues for London is the safety of cyclists, which is a problem for the city as a whole, including those using the bike hire scheme.  Busy, narrow roads and insufficient or absent cycling infrastructure dissuade many from using the scheme. Data suggests that a London hired bike is used far less frequently over the course of a day than a bike would be in many schemes elsewhere. Infrastructure problems are seen as a key factor in this, and this raises the issue of value for money. Resolving the safety and infrastructure problems are of course not easy tasks, and real change in authorities’ attitudes towards cycling is occurring very slowly. But concerted effort and change here may well be the key to reigniting the initial success of the scheme. The importance of a suitable sponsor for the scheme cannot be underestimated as their financial support will be essential. Public funding will undoubtedly continue to be needed but to a lesser extent if the scheme prospers. It has been contested that Barclays’ decreasing interest in the scheme may be the result of the growing cycling safety issues in London. This is perhaps the most difficult hurdle that the scheme, and whoever its new sponsor will be, must overcome in coming years. Bikes that aren’t used are no use to anyone, whoever pays for them."
"

My misadventures in state government led me to coin a phrase for what has become the economic growth model of choice for a lot of governors: “Press Release Economics.” It comes in many shapes and sizes, but it basically boils down to the orchestrated PEZ‐​dispensing of taxpayer money on short‐​term “economic growth” schemes for crass political gain.   
  
  
The most common form is probably the targeted tax break and/​or corporate welfare grant/​loan to incite a company to relocate within a state’s borders. Politicians love these taxpayer‐​financed giveaways because they come complete with lots of visible media coverage: press releases, newspaper articles, radio and television reports, and best of all…the photo op. Ah yes, that priceless picture of the governor all dressed up with a hard hat, ceremonial spade in hand, and a big toothy grin.   
  
  
One would be hard pressed to find justification for these political endeavors in the economic literature, but then again the little Potemkins who run state “economic development” bureaucracies don’t have time to be bothered with trivialities when there are “jobs to create.”   
  
  
Today I read that Gov. John Corzine has come up with a $150 million package to help the New Jersey economy. The concoction includes two peculiar items: money for banks to get them to lend and a $3,000 check to small businesses for each employee they hire and employ for a year. “Create a job and we will send you a $3,000 check,” Gov. Corzine says.   
  
  
With regard to the first one, the _New York Times_ reports: 



James Silkensen, president of the New Jersey League of Community Bankers, said he had not heard complaints from his members about needing more cash. “Our members are telling us that they’ve got money to lend,” Mr. Silkensen said. “They aren’t going to change their underwriting standards. I can’t say every bank has sufficient funds to lend. But most I have talked to are lending, though they’re being careful.”



With regard to the second one, it’s pure press release economics. Why not $4,000 an employee? Or $5,000? Why just “small” businesses? Do “large” businesses contribute nothing to the New Jersey economy? How will this initiative be enforced? How much will it cost taxpayers for New Jersey bureaucrats to make sure each and every new hire was employed not less than 365 days? How many of the $3,000 check employees would have been hired anyhow? How many jobs will be lost because of the tax burden needed to pay for this scheme and others?   
  
  
Here’s a better idea, Governor: propose serious tax and spending cuts. New Jersey’s general fund is up 40% from just five years ago, which amounts to a $1,000 per New Jersery citizen spending increase. At the same time, New Jersey’s business tax climate was recently found to be the **worst** of the fifty states.
"
nan
"**When it comes to vaccine making, India is a powerhouse.**
It runs a massive immunisation programme, makes 60% of the world's vaccines and is home to half a dozen major manufacturers, including Serum Institute of India - the largest in the world.
Not surprisingly, there's no lack of ambition when it comes to vaccinating a billion people against Covid-19. India plans to receive and utilise some 500 million doses of vaccines against the disease and immunise up to 250 million people by July next year.
This confidence is bolstered by its track record of immunising large numbers of people every year. India's 42-year-old immunisation programme, one of the world's largest health programmes, targets 55 million people - mainly newborns and pregnant women who receive some 390 million free doses of vaccines against a dozen diseases every year. The country also has a well-oiled electronic system to stock and track these vaccines.
Yet vaccinating a billion people, including hundreds of millions of adults for the first time, against Covid-19 is going to be a daunting and unprecedented challenge, say experts.
Five of the 30 vaccine candidates being developed in India are in clinical trials. They include the Oxford-AstraZeneca vaccine which is being tested by Serum and a home-grown one being developed by Bharat BioTech. ""Having a home-grown vaccine is a top priority,"" Dr Renu Swarup, secretary of India's Department of Biotechnology, told me.
From choosing a bouquet of vaccines to grappling with distribution to identifying groups for the early jabs, ""everything is a challenge"", says Dr Gagandeep Kang, a microbiologist and the first Indian woman to be elected Fellow of the Royal Society of London.
""We are underestimating the complexity of the exercise. It will take at least a couple of years to get half of Indians vaccinated.""
Here are some of the main challenges:
India has some 27,000 ""cold chain"" stores from where stocked vaccines can reach more than eight million locations. (Nearly all vaccines need to be transported and distributed between 2C and 8C in what comprises the so-called cold chain.) Will that be enough?
India will also need enough auto-disabled syringes that will prevent reuse and possible reinfection. The country's biggest syringe maker says it will be making a billion such syringes by next year to meet rising demand.
Then there are questions about smooth supplies of medical glass vials. And what about the disposal of the huge amount of medical waste that will be generated by this mass vaccination drive?
Nearly four million doctors and nurses power India's immunisation programme, but India will need more to carry out Covid vaccinations.
""I worry about how we can [extend all the resources] to rural India,"" Kiran Mazumdar Shaw, founder of Biocon, the country's leading biotechnology enterprise, told me.
Vaccine supplies will be tight next year, and deciding who will get the jabs first is going to be tricky.
Health Minister Harsh Vardhan says private and government health care workers and frontline workers ""of other departments"" will receive the early doses.
Experts believe it's not going to be easy.
""We will never have sufficient supply of vaccines. The prioritisation of recipients is going to be a considerable challenge,"" says epidemiologist Dr Chandrakant Lahariya.
Consider this. In a country where the majority of healthcare is private, will a private health worker get priority over a public one? Will permanent workers get priority over people working on contracts?
If elderly people with underlying conditions are eligible for early shots, how will different co-morbidities be prioritised?
India, for example, has more than 70 million diabetics, the second highest in the world. Will all of them be given a blanket preference?
Rolling out the vaccine in all the 30 states will not be possible. So will early supplies go to states worst-hit by the pandemic?
Questions about equity and non-partisanship are inevitable.
Stitching up manufacturing contracts with vaccine makers with a ""reasonably good portfolio"" of vaccines should help India give sufficient doses to people relatively quickly, according to Prashant Yadav, who studies health care supply chains at the Washington-based Centre for Global Development.
But the success at routine immunisation doesn't guarantee success with Covid-19 vaccines, he says.
""The routine immunisation infrastructure has a huge footprint, but is mostly for government-run clinics. There is no large-scale adult vaccination programme and adults don't routinely seek primary care in government public health care centres,"" says Dr Yadav. A well-regulated public-private partnership is the only way out this time, he adds.
People like Ms Shaw and Nandan Nilekani, a co-founder of Infosys, one of India's biggest information technology services companies, suggest that India should use Aadhaar, the unique 12-digit identification number that over a billion Indians use to access welfare and pay taxes, to record and track each dose.
""We need to design a system than can do 10 million vaccinations a day across the length and breadth of the country but all unified by a digital backbone,"" Mr Nilekani told a newspaper.
Some of the concerns are about corruption over access to vaccines.
How do authorities prevent fraud such as people getting fake papers to include themselves in lists of people who are selected for early shots? And how do you prevent fake vaccines being sold in remote markets?
Vaccines come with side effects for some people. India has a 34-year-old surveillance programme for monitoring such ""adverse events"" following immunisation.
But researchers have found that benchmarks for reporting side effects still remain weak and the number of serious adverse events are still far less than the expected numbers.
A failure to transparently report adverse effects could easily lead to fear-mongering around vaccines.
This is possibly the biggest question. Will the government acquire all the doses and roll out a state-run free or subsidised vaccination programme? Or will the affluent pay for their doses at market prices through private distribution and sale?
Experts like Dr Lahariya believe that the government should be footing the bill for vaccinating every Indian until the pandemic is over. Others like Dr Shaw say that private firms could pay to vaccinate their employees.
Mr Nilekani reckons that with vaccines costing between $3 and $5 (Â£2.24 and Â£3.74) in the beginning, a dual dose vaccine could cost up to $10 for each Indian and $13bn for India. That would be very expensive.
That's why, says Gagandeep Kang, a good vaccine for India should cost below 50 cents a shot, be plentifully available and delivered as a single dose.
**Follow Soutik**on Twitter"
"In 2014, Joe Duggan started reaching out to climate scientists to ask them a question: how did climate change make them feel? “I was just blown away when I started getting the letters back,” he says.  Duggan, a science communicator at Australian National University, set up a website and starting publishing the mostly handwritten responses. “[Professor] Katrin Meissner was one of the first, and her letter really hit me. It was so ... unscience-y. Almost poetic.” “It makes me feel sad. And it scares me,” Meissner wrote. “It scares me more than anything else. I see a group of people sitting in a boat, happily waving, taking pictures on the way, not knowing that this boat is floating right into a powerful and deadly waterfall.” In the end, more than 40 scientists responded – many leaders in their field. Some wrote neatly on lined notepaper, others scrawled on the back of student papers they were marking. “It became a big part of my life,” Duggan says. “I felt a little bit out of my depth. It took its toll on me and in the end I felt I had to step away. I went into my shell and pretty much turned off my phone for three years. “But I’ve got some emotional resilience back now. My partner and I found out we’re pregnant – due in August. I don’t want that kid to grow up asking why we didn’t actually do anything.” So Duggan has returned to his “passion project” – Is This How You Feel – by asking the scientists to write again. Have their feelings changed in the intervening years? The first 10 return letters are emotional outpourings of despair, hope, fear and determination in the age of the climate crisis, from the people helping the world understand its impacts while also being mums, dads and grandparents. Since the first letters were written, two Australian correspondents Tony McMichael and Michael Raupach have died. But Duggan is trying to reach their family members to see if they can keep the legacy moving. Meissner, now director of the Climate Change Research Centre at the University of New South Wales, didn’t hesitate to respond partly because “it was the right thing to do”. “But also because we have not been very good at communicating climate science to the public and I believe that it is my duty as a citizen to alert people to the urgency of the situation.” But does Meissner think there’s a risk in scientists lifting their veil of cool objectivity to show their personal feelings? Could it cause some to question their objectivity? “I actually think that the opposite is the case,” she says. “When I saw the whole collection of letters a few years ago, I was surprised by the number of colleagues who had participated. “We are talking here about world-leading scientists, people who built their career on facts and data, who are spending their lives questioning every result they find, over and over again. People who are continuously challenging the status quo. People who are trained to be objective. “When these people start to speak up about their feelings, about being frustrated, desperate, worried, angry or scared, then we really should listen very carefully.” Duggan wants anyone who has read the letters to write their own, and share them. Here are some excerpts from the latest scientist letters from Duggan’s project. How do I feel about it? I am still very worried. I am also profoundly sad. I am probably sadder than I was five years ago. I feel powerless and, to a certain extent, guilty. I feel like I have failed my duty as a citizen and as a mother because I was not able to communicate the urgency of the situation well enough to trigger meaningful action in time.What we are doing right now is an uncontrolled, risky experiment with the planet we live on. I’m angry because the lack of effective action on climate change, despite the wealth not only of scientific information but also of solutions to reduce emissions, has now created a climate emergency. The students are right. Their future is now being threatening by the greed of the wealthy fossil fuel elite, the lies of the Murdoch press, and the weakness of our political leaders. These people have no right to destroy my daughter’s future and that of her generation. My emotions haven’t really changed since I last wrote one of these letters, but things around me have. The beacon of light that is Greta Thunberg, speaking truth to power. Our own wonderful, passionate school kids taking to the streets, making me cry with pride. The only way to cope with all of this is to focus on what I can do, what I’m best at, and hope like hell that enough people, doing what they do best, can overcome. I have some very dark moments, but more than ever before, I feel wrapped in a blanket of collective determination. Hope is a necessary emotion, but more than that, it must be our fundamental strategy to keep us going. Lose it, and we are lost. For the most part my comments of 19 September 2014 still apply except that the glimmer of hope has diminished if not vanished entirely. With Obama as US president and the Paris agreement in late 2015, a glimmer of hope seemed to emerge, but with Trump and his ignorant accomplices, the hope has vanished. I am close to retirement and as I was cleaning up in 2019 I found some old VHS tapes recording me on shows, such as the Lehrer News Hour on PBS in 1988, and the message then was much the same as now except we are now more confident and the progress has been nil. It was depressing. My solution has been to move back to New Zealand along with my daughter and family (grandchildren). Realistically, we are already too late to meet a 1.5 degree target and will struggle to achieve 2 degrees.So, the future, basically, looks bad. Hard to stay hopeful. Change is too slow, too late.Yet we have to stay optimistic. Dear Joe,​Climate Change feels very real and I think this summer we reached a tipping point in Australia. As I write this my husband, a bushfire fighter, is battling a fire in Canberra and I’m working from home as a freak hailstorm destroyed my car three days ago. In four days, we’ve been smashed by our climate: hail, extreme winds, toxic smoke and fire. …. So how do I feel? Frustrated, angry that our science is ignored by politicians, scared for my husband and all the others who are on the frontline fighting these fires and trying to help. But mostly I feel devastated for my son, and his generation, who will have to heal this planet and live with the mass environmental destruction we have caused. I feel scared for the future when faced with simple downright ignorance from some political leaders.I feel tired, tired that in spite of bushfires, floods etc I still seem to be banging my head against a brick wall to convince people that the threat of climate change is severe.I feel relieved that now I am retired I don’t have to live and breathe this every minute of every day.I feel guilty that I am stepping back from the frontline, so even though I am retired I feel compelled to carry on working.I feel unspeakable joy at the news that I am to become a grandfather for the first time, but fearful of the world my grandchild will grow up in. I feel relieved that when my grandchild grows up and asks me why we did nothing to stop climate change I can at least say that I did my best.As I sit writing this on a bench looking out over the moors I feel uplifted that despite everything the world is still the most beautiful place. The full collection of letters is available at Is This How You Feel."
"We know elements of the story. It was 1911, as Robert Scott and Roald Amundsen raced to the South Pole. Temperatures were below -50˚C. Scott was British; Amundsen a Norwegian. Sled dogs were dying, and the explorers suffered from frostbite. The stakes were high, with financing of future explorations hanging in the balance of which team would be first to reach the South Pole.  But in a sense human impact, if not humans themselves, had beaten both of them to it. More than 100 years after Amundsen won the race to the South Pole, my research group found that industrial pollution had reached Antarctica more than 20 years before the race to the pole. Thousands of kilometres away, a source of lead, zinc, and silver had been discovered in 1883 at Broken Hill in Australia. Mining and processing operations began soon after, and smelting began at nearby Port Pirie in 1889.  Scott and Amundsen were travelling over apparently untrammelled snow that was in fact heavily contaminated from smelting and mining in Australia, with lead pollution at the time almost as high as at any time since.  Using data from 16 ice cores collected from widely spaced locations in Antarctica, including the South Pole, our team created the most accurate and precise reconstruction to date of lead pollution over Earth’s southernmost continent. This effort required braving temperatures as low as -75˚C with wind chill, as it was at our shallow ice core site about 15km from South Pole. Our new record spans a 410-year period from 1600 to 2010, and is published in the Nature journal, Scientific Reports.  As well as the ice core samples we had taken, our study used data from others sampled by the British Antarctic Survey, the Australian Antarctic Division, and the Alfred Wegener Institute in Germany. These cores from our international collaborations were critical in that they allowed us to examine records from parts of Antarctica rarley visited by US-based scientists, such as the Law Dome region of East Antarctica and a region visited by the Norwegian-United States Scientific Traverse of East Antarctica.  All measurements of lead and other chemicals from this study were made with my collaborators using a unique continuous ice core analytical system that I developed as director of the Desert Research Institute’s ultra-trace ice core analytical laboratory. Lead is a toxic heavy metal with proven strong potential to harm humans, animals and ecosystems. While the concentrations measured in Antarctic ice cores are very low they record that atmospheric concentrations and the rate of accumulation increased six-fold in the late 1880s – the same time mining began at Broken Hill and smelting at Port Pirie. The similar timing and magnitude of changes across Antarctica, as well as the characteristic isotopic signature of lead from Broken Hill that was found throughout the continent, suggest that this single source of emissions in southern Australia was responsible for polluting Antarctica at the end of the 19th century, and remains a significant source of pollutants today. Lead ore is found in deposits containing different isotopes of lead – atoms which contain different numbers of neutrons in the nucleus. This gives different lead deposits mined in different areas a characteristic and recognisable signature, and as lead is found in the atmosphere in generally low background concentrations this makes it an ideal tracer of industrial pollution. Data from our new set of ice cores show that concentrations of Antarctic lead reached a peak in 1900 and remained high until the late 1920s, with brief declines during the Great Depression and the end of World War II. Then there was a rapid increase in lead concentrations until 1975, remaining high until the 1990s. Lead concentrations have declined across Antarctica since, but are still are about four-fold higher than before industrialisation, despite stricter controls on lead pollutants from industrial sites and the phasing out of leaded transport fuels in many countries. Our measurements indicate that about 660 tonnes of industrial lead have reached the snow-covered surface of Antarctica during the past 130 years, and clearly detectable pollution continues to accumulate today."
"
Share this...FacebookTwitterIt’s not a well known fact but it’s pretty much just the EU and a few other activists scattered across the rest of the world who are supporters of forcing CO2 emissions reductions through binding greenhouse gas emission treaties. Indeed about 86% of the world opposes binding, Kyoto-type treaties, and so disagree with the remaining 14% fringe EU minority.
 
Europe’s emissions law threatening trade war. Photo: Alan Radecki (Akradecki)
Countries like India, China and Russia only support such treaties if they themselves are exempt from compliance and if the US isn’t.
The EU has decided to defy the vast global majority and is now demanding that all airlines flying into or from its territory purchase GHG emission permits. Furious, 23 countries (among them China, USA, Russia, India, etc.) convened in Moscow last week and signed a joint declaration expressing their disapproval and threatening the EU with a trade war should it continue to defy international will.
Read more here in English at http://www.spiegel.de/international/europe/0,1518,817426,00.html
 
Share this...FacebookTwitter "
"What can we do in the face of the climate emergency? Many say we should drive less, fly less, eat less meat. But others argue that personal actions like this are a pointless drop in the ocean when set against the huge systemic changes that are required to prevent devastating global warming.  It’s a debate that has been raging for decades. Clearly, in terms of global greenhouse gas emissions, a single person’s contribution is basically irrelevant (much like a single vote in an election). But my research, first in my masters and now as part of my PhD, has found that doing something bold like giving up flying can have a wider knock-on effect by influencing others and shifting what’s viewed as “normal”. In a survey I conducted, half of the respondents who knew someone who has given up flying because of climate change said they fly less because of this example. That alone seemed pretty impressive to me. Furthermore, around three quarters said it had changed their attitudes towards flying and climate change in some way. These effects were increased if a high-profile person had given up flying, such as an academic or someone in the public eye. In this case, around two thirds said they fly less because of this person, and only 7% said it has not affected their attitudes.  I wondered if these impressionable people were already behaving like squeaky-clean environmentalists, but the figures suggested not. The survey respondents fly considerably more than average, meaning they have plenty of potential to fly less because of someone else’s example.  To explore people’s reasoning, I interviewed some of those who had been influenced by a “non-flyer”. They explained that the bold and unusual position to give up flying had: conveyed the seriousness of climate change and flying’s contribution to it; crystallised the link between values and actions; and even reduced feelings of isolation that flying less was a valid and sensible response to climate change. They said that “commitment” and “expertise” were the most influential qualities of the person who had stopped flying. It’s not all a bed of roses, of course. Flying represents freedom, fun and progress. It boosts the economy and can provide precious travel opportunities. So suggesting that everyone should fly less, which may seem the implicit message of someone who gives up flying because of climate change, can lead to arguments and confrontation. One person for example said that my gently worded survey was “fascist and misinformed”. You don’t get that when you ask about washing-up liquid.  My research also probed ideas of inconsistency and hypocrisy. In short, people hate it. If Barack Obama takes a private jet and has a 14-vehicle entourage to get to a climate change conference, or a celebrity weeps for the climate while rocking a huge carbon footprint, it doesn’t go down well. And if future laws are introduced to reduce flying because of climate change, it looks essential that politicians will have to visibly reduce their flying habits, too. Other research has shown that calls for emissions reductions from climate scientists are much more credible if they themselves walk the talk. That people are influenced by others is hardly a shocking result. Psychology researchers have spent decades amassing evidence about the powerful effects of social influence, while cultural evolution theory suggests we may have evolved to follow the example of those in prestigious positions because it helped us survive. Pick up any book on leadership in an airport shopping mall and it will likely trumpet the importance of leading by example.  Which raises the question: if our political and business leaders are serious about climate change, shouldn’t they be very visibly reducing their own carbon footprints to set an example to the rest of us? This is now the focus of my research. Weaving an invisible thread through all of the above is the thorny issue of fairness and inequality. The wealthiest 10% of the global population are responsible for 50% of emissions, and plenty of that will be due to flying. In the UK, around 15% of people take 70% of the flights, while half of the population don’t fly at all in any one year. As emissions from aviation become an ever increasing slice of the total (currently around 9% in the UK, 2% globally) this inequality will become harder for everyone to ignore. In the mean time, the debate about personal vs. collective action will continue. My research supports the arguments that this is a false dichotomy: individual action is part of the collective. So, while you won’t save the world on your own, you might be part of the solution. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
nan
"**US President-elect Joe Biden has called for an end to the ""grim season of division"", as the country faces a long, hard winter with Covid-19.**
In a speech for the Thanksgiving holiday, he said Americans were at war with coronavirus, not each other.
The US saw more than 1.2 million cases last week, with 2,200 deaths on Tuesday - the highest number since late May.
Meanwhile, President Donald Trump urged supporters to work to overturn the results of the 3 November election.
Speaking via phone from the White House to an event organised by Republican state legislators in Pennsylvania, Mr Trump repeated unsubstantiated claims about widespread electoral fraud.
""We have to turn the election over,"" he said, adding that it was ""rigged"".
Mr Trump had been expected to attend the event in person but the trip was cancelled after two associates of his lawyer Rudy Giuliani tested positive for the virus. Mr Giuliani attended in person.
Mr Biden won the election with a comfortable victory in electoral college votes, and the transition to his presidency is already well under way. Mr Trump's efforts to challenge the results in key states in courts have so far failed.
On Wednesday, China's President Xi Jinping sent a message congratulating Mr Biden, more than two weeks after his victory was projected by US media.
However, a number of world leaders have still not reached out to the president-elect, including Russia's Vladimir Putin and Mexican President AndrÃ©s Manuel LÃ³pez Obrador, who said on Wednesday that he would not offer congratulations until ""the electoral process in the US ends"".
In his speech on Wednesday, Mr Biden told the nation: ""I believe you always deserve to hear the truth from your president. We have to slow the growth of this virus. We owe it to the doctors and the nurses and the frontline workers... We owe it to our fellow citizens.""
He said Covid-19 had ""brought us pain and loss and frustration"" and cost many lives.
""It's divided us, angered us, set us against one another. I know the country's grown weary of the fight, but we need to remember - we're at war with the virus, not one another.
""We have to steel our spines, redouble our efforts and recommit ourselves to the fight.""
The president-elect urged Americans to modify their Thanksgiving celebrations. He said that instead of the usual large gathering he would be spending the holiday with just his wife Jill and their daughter and son-in-law, while the rest of the family would be in small groups.
Millions of Americans are travelling to be with their loved ones despite warnings from health officials, although numbers are down on previous years.
The president-elect vowed that in due course, the pandemic would be beaten.
""I know that we can and will beat this virus,"" he said. ""Life is going to return to normal, I promise you. I believe this grim season of division... is going to give way to a year of light and unity.""
The Thanksgiving holiday comes as new cases of the virus continue to increase in the US.
More than 260,000 Americans have now died with the virus, the largest number of any country in the world, according to a tally from Johns Hopkins University.
Mr Trump finally agreed to allow the formal transition process to begin on Monday, nearly three weeks after the presidential election.
Mr Biden can now access key government officials and millions of dollars in funds as he prepares to take over the presidency on 20 January.
He will also receive the Presidential Daily Brief - an update on international threats and developments. Aide Jen Psaki said he would get his first briefing on Monday, and classified information was already being shared with Mr Biden's senior team.
On Tuesday he named six key posts in his administration, including his picks for secretary of state and national security adviser. He is set to name more staff including his economic team next week.
Most of his picks will need to be confirmed by the Senate."
"Shell is to end its relationship with two of the UK’s leading arts institutions amid growing concern about big oil’s role in the escalating climate crisis. The fossil fuel corporation has confirmed it is not renewing its corporate membership deals with the Southbank Centre and the British Film Institute (BFI) when they come up for renewal later this year.  Campaigners say the decision underlines the shrinking “social licence” of fossil fuel companies in the midst of the climate crisis. It follows similar moves by the Royal Shakespeare Company (RSC), National Theatre and National Galleries Scotland, which have all severed ties with major oil companies in the last year. Chris Garrard, from the campaign group Culture Unstained, said the end of Shell’s involvement with the BFI and the Southbank Centre was a crucial milestone in the campaign. “From its HQ on the South Bank, Shell has pursued a business plan that has trampled indigenous people’s rights and pushed the world deeper into climate crisis,” said Garrard. “Meanwhile, it has sponsored its cultural neighbours as part of a cynical attempt to deflect attention from the damage it was causing. But the show is over for Shell.” A spokesperson for Shell said the decision not to renew the contracts had been taken last year and mutually agreed with the Southbank and the BFI. “Last year we decided not to renew annual memberships with the BFI or the Southbank Centre, collectively worth around £20,000, when they expire later this year,” it said. The BFI confirmed it had been Shell’s decision. Harriet Finney, the BFI’s director of external affairs, said the institute was “committed to supporting a sustainable future”. “We are in the process of reviewing the impact of our own activities across all our sites; how we can better support the UK’s screen industries to move towards sustainable practice and how we respond culturally to the climate and ecological emergency.” The Southbank Centre has had a relationship with Shell stretching back to 2006 and lists the company as a partner on its website. A spokesperson said the decision to end the two-year corporate membership had been mutual and declined to comment further. The leading tenor Mark Padmore, who will perform at the Royal Festival Hall in October, said he was delighted with Shell’s decision. “Today, more than ever, we all need to examine our way of life and the implications of our actions, as we respond to the growing climate emergency,” he said. “Making beautiful music does not excuse us from seeking to understand how our work is funded and asking questions about the kind of unsustainable businesses those partnerships might promote.” Last year, the actor Mark Rylance resigned as an associate artist with the RSC after 30 years over its sponsorship deal with BP, arguing it allowed the company to “obscure the destructive reality of its activities”. A few months later, the RSC announced it was cutting its links to BP after a “careful and often difficult debate” internally. The latest move increases pressure on other arts institutions such as the British Museum, National Portrait Gallery and Science Museum Group, which have all faced criticism over their oil sponsorship deals in the past 18 months. Last month, the activist theatre group BP or not BP? occupied the British Museum for three days, sneaking a “Trojan horse” into the courtyard and staging a mass protest in the museum involving 1,500 people."
"
Share this...FacebookTwitterSome German professors are beginning to speak up against the climate shenanigans. Take for example Prof. Dr. Dr.Knut Löschke, physicist, who gave a speech on Climate Policy titled “Give Reason Another Chance!” at the University of Passau last Friday. Ralph Bärligea has the story at eingentümlich frei.de.
Bärligea summarizes Löscke’s speech. Here’s an excerpt:
Man-made climate change as a hypothesis is in the end one that has never been confirmed by any single experiment and does not harmonize in any way with existing physical theory. But even so, the hypothesis is implemented in real politics. Representatives of the IPCC do not shy away from using fraud and falsifications in its effort to fulfill its political agenda: which is to show that man influences the global climate. This is proven by the Climategate Scandal, and an especially crass example of a falsification that Professor Löschke introduced in his presentation. By spreading the hypothesis of man-made climate change and the “solution proposals” for global “climate control”, dangerous limits that go beyond the absurd have long since been over-stepped.”
Löschke thinks the whole climate issue is a dangerous political sham and called on the public: “Wehret den Anfängen!“ This is a call to defend against a dangerous movement. Those are the milder points he brought up.
At the end of his speech Professor Löschke compared the “international climate regime“ to the socialist regimes in Germany. According to Bärligea, up to 8 people walked out.
So, some are speaking up in Germany, and doing so loudly!
Well done! I say.
Knut Löschke is a university lecturer, business owner and a member of the supervisory board at the Deutsche Bahn AG.
 
Share this...FacebookTwitter "
"The full impact of coral bleaching across the Great Barrier Reef will become clearer this week as aerial surveys of hundreds of reefs are completed in the bottom two thirds of the world’s biggest reef system. An aerial survey carried out last week over almost 500 individual reefs between the Torres Strait and Cairns revealed some severe bleaching of corals closer to shore, but almost none on outer reefs.  From Monday the spotter plane will head south over reefs where satellite observations and temperature readings have shown corals are likely to have undergone higher levels of heat stress than those in the north. Scientists fear those corals could be found to have been badly bleached, as they are less used to higher temperatures and had escaped major impacts in 2016 and 2017. The chief scientist at the Great Barrier Reef Marine Park Authority, Dave Wachenfeld, told Guardian Australia that whatever the survey concluded, the current bleaching should sound “a very loud alarm bell” on the plight of the reef under global heating. Heat stress has been building across the length of the reef this summer with many anecdotal reports from tourism operators, tourists and recreational diver of severe bleaching. Day 4: We have now completed assessment of #coral bleaching between Cairns and northern Torres Strait. Today, we saw extreme levels of bleaching on coastal reefs from Lockhart River to Cairns. Mid-shelf reefs in this region have variable levels of bleaching, from mild to severe pic.twitter.com/QdN16S0cV3 In February, average sea surface temperatures on the reef were 1.25C above normal and the highest on record going back to 1900. Scientists have said the world’s oceans are gathering heat due to accumulating levels of greenhouse gases in the atmosphere, mostly from burning fossil fuels. Corals bleach if they sit in unusually hot water for too long. Survival from bleaching depends on how high and for how long temperatures get. Some species of corals have higher tolerance for heat than others. Observations of conditions on the reef from satellites and in-water temperature loggers suggest central and southern parts have accumulated high levels of hat stress. But the authority said the full picture would only come clear once the aerial surveys were completed at the end of this week, and the data had been analysed. In 2016 and 2017, the world heritage reef experienced back to-back bleaching that was intense enough to kill almost half the reef’s corals over those two years. Central and southern parts of the reef were not severely impacted in those years, meaning they are not used to the heat stress and could be harder hit. Prof Terry Hughes, director of the ARC Centre of Excellence for Coral Reef Studies at James Cook University, spent 17 hours across four days in the air last week scoring bleaching on reefs with a staff member from the authority. After completing the first four of nine days of aerial surveys, Hughes told Guardian Australia most of the severe bleaching had been seen at coastal reefs. On Friday, flying from Lockhart River to Cairns, Hughes said corals at Princess Charlotte Bay at the bottom of the Cape York Peninsula had been severely bleached, but the impacts were much less on reefs further away from the coast. Many of the outer reefs in the north – known as “ribbon reefs” because of their slim and snaking appearance from above – had escaped bleaching. Hughes said: “A lot of the reefs we have been looking at were badly affected in 2016 and 2017. They don’t have a lot of corals on them and the corals that are there have managed to survive 2016 and 2017, and so they are tough.” Hughes said it “remains to be seen what will happen in the south” but there were more coral species in those areas – including staghorn and table acroporas – that would be more susceptible to bleaching. Some of those central and southern reefs “have accumulated a lot of heat, particularly near the coast,” he said. “This is shaping up to be strongly coastal – 2016 and 2017 were cooler in the south and, this time around, it is not cool in the south.” Hughes said: “Even if it turns out to be a relative moderate event event compared to 16 and 17, it is still cumulative and because the footprints are different, the cumulative amounts of the reef that’s affected severely or moderately will go up.” Townsville-based Dr William Skirving, of the US government’s Coral Reef Watch program at the National Oceanic and Atmospheric Administration, said the agency’s analysis showed how localised the heat stress had been. But whether that heat stress had translated to severe bleaching would be be answered by the aerial surveys. He said according to his agency’s analysis, one area of Swains Reefs off Townsville had showed some of the highest levels of heat stress across the entire reef, but some of the lowest levels had also been in the same group. This was one reason, he said, why the aerial surveys were important. He held concerns for the corals in southern areas. He said: “Let’s cross our fingers that the corals were not as susceptible as they were in the past.” Wachenfeld told Guardian Australia that whatever the final assessment was “these are still significant events that are sounding a very loud alarm bell about what’s happening to the reef in the face of climate change.” He said there had been reports of “at least moderate bleaching” from Magnetic Island, near Townsville, and Heron Island, off Gladstone. “Bleaching does not necessarily mean death and that some people do misunderstand that,” he said. “Yes, the reef is in trouble, but what that means is that it needs more help.” Aerial surveys this week of the Ribbon Reefs, above Cairns, show little to no bleaching. Aerial surveys continue over the coming days in areas that experienced more heat stress. #GreatBarrierReef #video pic.twitter.com/4cdjpbj4ZE Wachenfeld said whatever the final detailed assessment of the severity of this summer’s bleaching revealed, this needed to be seen in the context of the broader challenges the reef was facing, including the ongoing impacts from climate change. He said 2016 and 2017 were “the worst events that have ever happened” for the reef, and so if this year turned out to be less severe, this should “not lull us into a false sense of security”. He said he was encouraged to hear that outer ribbon reefs in the north – which he had personally dived on many times – had seemingly escaped bleaching this summer. “They are some of the most beautiful places on the planet and so to know they have done well in this event gives me enormous hope for the future and of what we have left to protect,” he said. “There are still places that are absolutely amazing. The reef as a whole is still a gobsmackingly amazing and beautiful place and it needs us to do more globally to protect it.”"
"**Northamptonshire will be in tier two when England's second lockdown ends on 2 December, it has been announced.**
People in tier two cannot socialise with other households indoors and the rule of six will apply outdoors.
Prior to England's second shutdown, the county was subject to the lowest level tier one restrictions.
Lucy Wightman, director of Public Health Northamptonshire, said: ""This is the result of activities in the week before lockdown.""
Mrs Wightman said she believed the lockdown had been too short to ""make up the ground we covered"" before lockdown.
The number of cases in the county leapt up by 50% after the lockdown was announced.
""We're not back to the point of the week before lockdown,"" Mrs Wightman said.
She added that it was ""too early to say"" if the peak of the second wave of coronavirus had been reached, warning ""we could see another surge in January"".
Mrs Wightman added that she had only found out what tier the county would be in by looking on the government's postcode tracker, which details which areas will be in which category.
She said the decision had been made entirely in Westminster: ""I can't tell you if we are close to the bottom of level two or nearly in level three.
""We've been promised the thresholds will be set. The problem is they just haven't been shared.""
Earlier this week, Prime Minister Boris Johnson told the House of Commons the three-tiered regional measures would return from 2 December, but added that each tier would be toughened.
The allocation of tiers is dependent on factors including each area's case numbers, the reproduction rate - or R number - and the current and projected pressure on the NHS locally.
Tier allocations will be reviewed every 14 days, and the regional approach will last until March.
There are exceptions for some of the tier two rules, for childcare and support bubbles.
Speaking prior to the announcement, Kettering MP Philip Hollobone told BBC Radio Northampton that all seven of Northamptonshire's MPs had favoured the county being put in the lowest tier (tier one).
Mr Hollobone said he feared severe restrictions would mean ""many small businesses - especially in the retail sector and hospitality sector - will go under because they make between a quarter and a third of their profits in the run up to Christmas"".
Rachel Roberts, who owns Mooch in Northampton with husband Paul, said the gift shop had been closed since 5 November.
The couple, who have five shops across Northamptonshire and Buckinghamshire, have been able to operate a click and collect facility from St Giles Street.
However, Mrs Roberts said it had only been ""a very small lifeline"" and her books were ""looking pretty grim"".
""We're already going to be limited in terms of capacity whatever tier we happen to be in,"" she said.
""The biggest reality check we've had to have in our business is that we're only going to be able to have, certainly in St Giles Street, three or four people in the shop at a time across the two floors.""
Steve Ward, co-owner of St Giles Cheese, said he would be taking the same precautions regardless of what tier the county was in.
""We'll limit numbers through the door, having a small shop that's quite easy to manage,"" he said.
""I think running up to Christmas people are going to come out whatever happens.
""They are going to - hopefully - be careful, keep their masks on, avoid getting too close to everybody and just be sensible about it.""
**Analysis by Laura Coffey, BBC Radio Northampton Politics reporter**
Northamptonshire went into this lockdown in tier one, but we'll come out of it next Wednesday in tier two.
Here in the county cases had continued to rise despite the lockdown, although last week's figures from Public Health Northamptonshire seemed to be showing a levelling out.
Public health officials in the county hope figures will have dropped when they're published in the weekly surveillance report on Friday.
This drop can already be seen in figures published by the government on a daily basis.
This tier system will feel very different this time as the government has tightened restrictions.
For us in Northamptonshire it means no household mixing indoors; rule of six applies outdoors; pubs and restaurants shut at 11pm, alcohol can only be served with a substantial meal - so bars and pubs only selling booze must close.
Director of Public Health, Lucy Wightman, speaking on Thursday morning in the weekly Covid board meeting, said we cannot be complacent and need to keep the figures low ahead of the five-day break over Christmas to avoid a third wave after.
Following the announcement, Northampton Town Football Club said it would be welcoming season ticket holders back to matches.
In a statement on its website, the club said: ""The news comes as a huge boost to both the club and our loyal season ticket holders.""
The club will first have to stage a pilot event with around 1,000 season ticket holders. This will take place at Sixfields Stadium on 5 December, for the match against Doncaster Rovers.
A ballot will take place to determine which fans can attend that game.
Northampton made national headlines earlier this year when an outbreak of Covid-19 at M&S sandwich maker Greencore meant it had the highest rate of new coronavirus cases in England.
The town was made an 'Area of Intervention' - then the highest category on the government's watchlist - in August, with the factory closed.
In all, almost 300 workers tested positive, but the town avoided going into a local lockdown.
South Northamptonshire and Northampton have rates above the England-wide average in the week to 21 November, but both have fallen week-on-week.
All districts in the county have seen their rates fall week-on-week.
_Find BBC News: East of England on_Facebook _,_Instagram _and_Twitter _. If you have a story suggestion email_eastofenglandnews@bbc.co.uk"
"
Share this...FacebookTwitterHere comes the sun!
Climate skepticism is doing more than just striking a chord here in Germany. It’s turning into a full blown concert! Yesterday we wrote about how Prof. Dr. Fritz Vahrenholt’s and Dr. Sebastian Lüning’s book Die kalte Sonne – Warum die Klimakatastrophe nicht stattfindet (The cold sun – why the climate catastrophe is not taking place) reached No. 4 on the Amazon.de list for ecology and environment books.
Today it was at No. 1 on the Amazon.de list of ecology and environment books.

Not considering it is still not even at the bookshops. It’ll be available next week!
I urge every German reader to pick up extra copies and to give them away as birthday presents, or for whatever occasion.
Share this...FacebookTwitter "
"

We don't need no stinkin' environmental regulations to save the earth -- all we need are well functioning property rights for environmental resources and common law courts to protect that property against trespass. Pollution is simply a neighbor's garbage dumped in your backyard without permission. If we simply recognize and enforce property rights for nature, the need for most environmental regulation goes away.   
  
That's the libertarian pitch anyway, and it goes by the moniker ""Free Market Environmentalism,"" or ""FME"" to its acolytes. FME was given a firm theoretical foundation by Ronald Coase, embellished and blessed by libertarian economist Murray Rothbard, given academic life by the Political Economy Research Center and the Foundation for Research on Economics and the Environment, popularized in Washington by the Competitive Enterprise Institute, and even pitched by yours truly to the Board of Trustees of the Natural Resources Defense Council about nine years ago.   
  
Alas, there has never been much evidence to suggest that libertarians were making much headway with these arguments and I have come to believe that they have less promise than I had once imagined. But what do you know? FME is now all the rage amongst environmentalists who have discovered that suing polluters for tresspass is easier than passing satisfactory laws against the same.



Think I'm pulling your leg? Read this from Darren Samuelsohn in today's issue of _Greenwire_ (subscription required): 



_Efforts to force a stronger U.S. global warming policy through the courtroom came under sharp scrutiny yesterday as eight states, New York City and conservation groups pressed for reduced greenhouse gas emissions from the nation's five largest electric utilities._   
  
_A three-judge panel of the 2nd U.S. Circuit Court of Appeals pressed plaintiffs over why their case was necessary when other avenues exist for addressing global warming -- from Capitol Hill to state courts. ""My basic question is should we be invoking this doctrine in this very unusual case when there are many other remedies available?"" asked Judge Sonia Sotomayor, the lone Democratic appointee on the 2nd Circuit's panel._   
  
_Connecticut Attorney General Richard Blumenthal (D) replied that the utilities' emissions violate federal common law by harming residents in multiple states. The utilities' emissions are creating a public nuisance and must be reduced to counteract a variety of global warming effects, including California's diminished snow pack and more intense heat waves._   
  
_Addressing Sotomayor's question, Blumenthal said his case is not unusual compared with other seminal common law challenges upheld by the Supreme Court, including suits over Illinois sewer water running into Lake Michigan and air pollution from two Tennessee smelters._   
  
_""We're dealing with a developing area of science where federal common law provides a remedy under the doctrines that exist,"" Blumenthal said._   
  
_Plaintiffs singled out the five companies and their subsidiaries for litigation almost two years ago because they are the largest emitters of carbon dioxide from the power sector in the United States._   
  
_... The electric utilities' defense covered some of the same ground offered successfully last summer before a federal district court, which dismissed the case on the grounds it raised political questions better left to the other two government branches. Both current and former sessions of Congress and presidents have not adopted such an aggressive climate change policy, argued Washington-based industry attorney Joseph Guerra._   
  
_Guerra also insisted federal common law has not been applied to an issue of such sweeping scale. Of the Supreme Court precedents Blumenthal cited, Guerra replied, ""None of those cases could have possibly affected the entire U.S. economy.""_   
  
_Pushing another line of the industry's defense, Guerra cautioned the litigation would be a precursor to more global-warming nuisance claims -- with no end in sight as plaintiffs tick through other sources of greenhouse gas emissions._   
  
_But Sotomayor, who asked the bulk of the questions during the hearing, took issue with the line of industry defense. ""That's the nature of every tort action,"" she told the utility attorney._   
  
_Sotomayor also said she had a problem with dismissing the case just because potential remedies were so large._



OK, I'll grant that enviros are going the common law route less out of conviction than out of necessity. But so what? What was once a fringe argument has now migrated into the political and legal mainstream with a vengeance. Good news for libertarians, right?   
  
Well, if libertarians and fellow-travelling conservatives are popping champagne bottles, it has escaped my attention. FME blogs are dead silent. Conservatives are taking the corporate line that common law is an inappropriate venue for all of this with no dissenters that I can tell. In short, FME'ers either aren't paying attention or aren't willing to back their doctrines when they are employed by the Left.   
  
Sure, one can argue that the plaintiffs don't have proper standing, that there is really no nuisance here to begin with, that the tort system is so messed up that employing it in such cases is problematic, etc. But nonetheless, this is a growing trend and libertarians seem surprisingly ambivalent about it.


"
"

It is no secret that we don’t think much of carbon trading here in the USA. Witness the fact that the much ballyhooed Chicago Climate Exchange has closed up trading for good after the spot price for carbon fell to a nickel per ton. They couldn’t give it away. At that price, had they issued them, the fancy carbon credit certificate paper would be worth more than the carbon itself. I’d actually like to get my hands on those, because they’d sell better on Ebay as novelties and earn a better price.
So, when I read this sentence about the EU carbon market, I couldn’t help but chuckle and think it makes a good QOTW: 
The European commission’s emergency suspension last week of trading in carbon allowances to put a halt to rampant theft of credits by hackers has been extended  indefinitely until countries can prove their systems are protected from  further fraud.
Hmmm…”further fraud”… isn’t that an oxymoron when it comes to describing carbon trading?
Story at The Guardian
This shows what can happen when emissions trading doesn’t have proper checks and balances – Carbon trading tempts firms to make greenhouse gas
If you want carbon certificates that aren’t a fraud risk, try these, which are worth exactly what you pay for them:
Get yours here: freecarbonoffsets.com
Now if somebody can just talk some sense into California.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e858a1f15',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Nobel Peace Prize nominee Greta Thunberg claims we need system change to save the planet, and the majority of experts, from the IPCC, through to our own research, would certainly agree with this.  But for most people, it often isn’t clear what changes actually need to be made to address environmental problems. And ideas that are presented can be seem as extreme to some. This is despite the fact that many experts agree that to really tackle climate change, the focus needs to be on changing the capitalist system to make it more environment-friendly.  System change can sound scary, but as the current system drives social injustice and environmental destruction, a new approach to address both is called for. These are some suggestions to help build that new system which also aim to improve people’s lives in the process. The suggestion that GDP is a good measure of a country’s progress has been frequently challenged. To achieve growth, we consume more products, these products need raw materials and energy to produce – and often result in excessive waste when they are disposed of. Hence pursuit of economic growth drives a wasteful use of scarce resources.  Achieving growth isn’t necessarily bad – but focusing solely on growth is. it prevents many other important strategies being put in place, even if they are actually beneficial for the majority of society. As economist Kate Raworth states, we need to be “agnostic about economic growth” and embrace other measures of societal well-being, such as the Human Development Index and Genuine Progress Indicator, which combine financial gains with non-market benefits – such as human health and reduced environmental degradation. Incremental increases in tax (for example on fuel), without alternatives, do little to change behaviour. Instead, it just increases the financial burden on the less well-off – this being one factor behind the recent “yellow vests” (gilets jaunes) protests in France. To achieve rapid and fair changes in consumer behaviour, there needs to be large tax increases on the most environmentally damaging products to turn them from everyday items into luxury goods. This would include air travel, fossil fuels and red meat. We also need to ensure environmentally sound alternatives are available and heavily subsidised. This would see subsidised and reliable public transport, car share schemes to allow occasional use of cars, bike hire, and subsidies on fresh vegetables and meat alternatives – all of which would help people easily transition to a more (environmentally) healthy lifestyle. From an environmental perspective, working less – whether a four-day week, or working only a proportion of the year – has many benefits. Less commuting to work, more time to cook healthy food and more time to take holidays, without the need for flying. The reduction in household income also means less opportunity for over-consumption of “luxury” goods that drive economic growth without adding much value to society.   Plans for a four-day work week and a universal basic income would also help to create greater levels of meaningful employment, safeguard people’s mental health and reduce societal inequality – as well as providing more leisure and family time.  Few people can really identify with the scale of deforestation in Asia for palm oil, or in the Amazon for cattle farms. This is why, to really tackle climate change, we need to think locally and understand the impact of our behaviours on our communities. Farming, energy production and waste disposal are obvious examples.  Localised processes can also be more environmentally sound. Recent research on small-scale coastal fisheries across the globe suggests that if we rely on these for fish – rather than large-scale industrial fishing – we can dramatically increase fish stocks, increase food security in developing countries and improve the local economies of fishing towns in countries such as the UK.  There is a disconnect from the natural world, exemplified even in academic and policy circles with the monetisation of nature through “ecosystem services” and how they contribute to human well-being – by providing food, water, wood and medicines, for example. All of which, puts a price on nature – by defining the Earth’s resources as “natural capital”. We need to appreciate nature for what it is – and protect it now. Teaching natural history in schools is a good place to start. Protecting, restoring and rewilding ecosystems on a large scale will also enhance biodiversity, store carbon and reduce pollution – three of the major environmental planetary boundaries – or safe environmental limits – we have greatly exceeded.    Technological advances such as renewable energy, electric vehicles and smart cities are important steps to reduce our carbon emissions. But they are not the only “solution” to climate change. Manufacturing lithium ion batteries, solar panels and turbines has an environmental cost, too. And, in the same way, changing your car to an electric vehicle is likely to have a bigger short-term carbon footprint than running your current car. This is why technological advances must be used in conjunction with lifestyle changes if we want to transform our society in an environmentally and socially just manner.  Of course, this is not an exhaustive list, but serves as a starting place to show how environmental issues can be addressed and at the same time we can create a fairer and more just society. A society with more free time, more interaction with our local communities and better physical and mental well-being. The future is only scary if we continue on our current path. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"
Errors in GHCN metadata inventories show stations off by as much as 300 kilometers

Guest post by Steven Mosher 

In the debate over the accuracy of the global temperature nothing is  more evident than errors in the location data for stations in the GHCN  inventory. That inventory is the primary source for all the temperature  series.
One question is “do these mistakes make a difference?” If one  believes as I do that the record is largely correct, then it’s obvious  that these mistakes cannot make a huge difference. If one believes, as  some do, that the record is flawed, then it’s obvious that these  mistakes could be part of the problem. Up until know that is where these  two sides of the debate stand.
Believers convinced that the small  mistakes cannot make a difference; and dis-believers holding that these  mistakes could in fact contribute to the bias in the record.  Before I  get to the question of whether or not these mistakes make a difference, I  need to establish the mistakes, show how some of them originate,  correct them where I can and then do some simple evaluations of the  impact of the mistakes. This is not a simple process. Throughout this  process I think we can say two things that are unassailable:

1. the mistakes are real. 2. we simply don’t know if they make a difference. Some believe they cannot (but they haven’t demonstrated that) and some  believe they will (but they haven’t demonstrated that). The  demonstration of either position requires real work. Up to now no one  has done this work.
This matters primarily because to settle the matter of UHI stations  must be categorized  as urban or rural. That entails collecing some  information about the character of the station, say its population or  the characteristics of the land surface. So, location matters. Consider  Nightlights which Hansen2010 uses to categorize stations into urban and  rural. That determination is made by looking up the value of a pixel in  an image. If it is bright, the site is urban. If it’s dark (mis-located in  the ocean) the site is rural.
In the GHCN metadata the station may be reported at location xyz.xyN  yzx.yxE. In reality it can be many miles from this location. That means  the nightlights lookup or ANY georeferenced data ( impervious surfaces,  gridded population, land cover) may be wrong. One of my readers alerted  me to a project to correct the data. That project can be found here.  That resource led to other resources including a 2 year long project to  correct the data for all weather stations. Its a huge repository. That  led to the WMO documents one of the putative sources for GHCN. This  source also has errors. Luckily the WMO has asked all member nations to  report more accurate data back in 2009. That process has yet to be  completed and when it is done we should have data that is reported down  to the arc second. Until then we are stuck trying to reconcile various  sources.
The first problem to solve is the loss of precision problem. The WMO  has reports that are down to the arc minute. It’s clear that when GHCN  uses this data and transforms it into decimal degrees that they round  and truncate. These truncations, on occasion, will move a station.  I’ve  documented that by examining the original WMO documents and the GHCN  documents. In other cases it hard to see the exact error in GHCN, but  they clearly dont track with WMO. First the WMO coordinates for WMO  60355 and then the GHCN coordinates:
WMO:   60355	SKIKDA	36 53N	06 54E  [36.8833333, 6.9000]
GHCN: 10160355000 SKIKDA  36.93    6.95
GHCN places the station in the ocean. WMO places it on land as seen above.
To start correcting these locations I started working through the  various sources. In this post I will start the work by correcting the  GHCN inventory using WMO information as the basis. Aware, of course that  WMO may have it own issue. The task is complicated by the lack of any  GHCN documents showing how they used WMO documents. In the first step  I’ve done this. I compared the GHCN inventory with the WMO inventory and  looked at those records where GHCN and WMO have the same  station  number and station name. That is difficult in itself because of the way  GHCN truncates names to fit a data field. It’s also complicated by the  issue of re spelling, multiple names for each site and the issue of GHCN  Imod flags and WMO station index sub numbers.
Here is what we find. If we start with the 7200 stations in the GHCN  inventory and use the WMO identifier to look up the same stations in the  WMO official inventory we get roughly 2500 matches. Here are the  matching rules I used.
1. the WMO number must be the same
2. The GHCN name must match the WMO name (or alternate names match).
3. The GHCNID must not have any Imod variants. (no multiple stations per WMO)
4. The WMO station must not have any sub index variants. (107 WMO numbers have subindexes)
That’s a bit hard to explain but in short I try to match the stations  that are unique in GHCN with those that are unique in the WMO records.  Here is what a sample record looks like.WMO positions are translated  from degrees and minutes to decimal degrees and the full precision is  retained. You can check that against GHCN rounding. As we saw in  previous posts slight movements in stations can move them from Bright to  dark and from dark to bright pixels.
63401001000     JAN MAYEN 70.93 -8.67              1001    JAN MAYEN 70.93333 -8.666667
63401008000     SVALBARD LUFT 78.25 15.47    1008    SVALBARD AP 78.25000 15.466667
63401025000 TROMO/SKATTO      69.50 19.00    1025   TROMSO/LANGNES 69.68333 18.916667
63401028000 BJORNOYA                 74.52 19.02    1028    BJORNOYA 74.51667 19.016667
63401049000  ALTA LUFTHAVN 69.98 23.37    1049  ALTA LUFTHAVN 69.98333 23.366667
You also see some of the name matching difficulties where the two  records have the same WMO and slightly different names. If we collate  all differences on lat and lon in matching stations we get the  following:

And when we check the worst record we find the following
WMO:  60581  HASSI-MESSAOUD             31.66667      6.15
GHCN:  10160581000 HASSI-MESSOUD 31.7               2.9
GHCN has the station at longitude [smm] 2.9. According to GHCN the station is an airport:

The location in the WMO file

And the difference is roughly 300km.WMO is more correct than GHCN. GHCN is off by 300km

An old picture of the approach (weather station is to the left)

And diagrams of the airfield
Now, why does this matter.  Giss uses GHCN inventories to get  Nightlights. Nightlights uses the location information to determine if  the pixel is dark (rural) or bright (urban)
NASA thinks this site is dark. They think it is pitch dark. Of course  they are looking 300km away from the real site. From the inventory used  in H2010.
10160581000 HASSI-MESSOUD   31.70    2.90  398  630R  HOT DESERT    A    0






			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e877a8562',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

Jolee Mohr died in July at the age of 36 after receiving experimental treatment for arthritis. “It was supposed to be just a simple thing,” said her husband, Robb, but something went horribly wrong.



“No one knows yet whether the treatment was to blame,” wrote Rick Weiss of the _Washington Post_. “But a close look at the events leading to Mohr’s death reveals failures in the safety net that is supposed to protect people from the risks of medical experimentation.”



Last week, the U.S. Court of Appeals for the District of Columbia ruled that terminally ill patients do not have a constitutional right to use experimental treatments without being enrolled in a clinical trial or participating in other very limited Food and Drug Administration‐​approved options, even if their doctors believe that such treatment is their best chance for survival. The case is being appealed to the Supreme Court.



The D.C. appeals court and so many others who share a “safety first” approach to experimental treatment are only seeing half the picture. Experimental treatment is inherently risky. But overemphasizing safety prevents patients from taking a calculated risk when they think it’s worthwhile.



As my husband and I learned, that freedom is important. Our son was diagnosed with cancer when he was 9 months old. Next week, he leaves for college, and the only visible reminder of his brush with death is a scar from surgery.



No, I’m not saying that an experimental treatment saved his life. What probably saved him was his parents’ persistent questions, and events resulting in a course of treatment that changed so often no doctor would have recommended it at the beginning.



Individuals often react unexpectedly even to conventional treatments, let alone experimental ones. What would have happened if someone had told us, “Sorry, that treatment is no longer an option. It has been found unsafe because children have died from it.”



At the time, all the treatments — including the experimental ones we were offered but ended up not choosing — resulted in about a 50% chance of death, and in many cases they killed the children before the cancer did. But there were still crucial choices to make. No one was as well suited to make them than we were, in consultation with our son’s doctors.



In the appeals court case, the Abigail Alliance for Better Access to Developmental Drugs sued the FDA for refusing to allow terminally ill patients to purchase experimental drugs. Patients who couldn’t gain access to the medicines they wanted — because the trials were closed or the patients were too sick or otherwise didn’t qualify for FDA permission — petitioned the FDA to be allowed to take medicines under the supervision of their own doctors.



According to the FDA, such treatments would lead to unacceptable risk.



Unacceptable to whom?



In denying patients the right to weigh the risks for themselves, the FDA and the court denied them their only hope for survival. The government essentially told them that it would be better for them to do nothing and die than to take risky experimental treatments.



We do not need a governmental authority involved in medical decisions that are uniquely personal to patients and their families. But along with the right to make decisions comes the obligation to think them through. Any doctor who lies to patients or intentionally misleads them about the risks of certain treatments should be punished, but patients need to read informed‐​consent forms carefully, ask questions and not assume that their doctors can do risk‐​benefit analyses without knowing what’s most important to the patient.



In our case, each option had its own set of risks, including death, but also a chance at a better life. One experimental protocol we were offered tested a new course of chemotherapy that had a lower chance of stunting our son’s growth or causing sterility, but possibly also a lower chance of curing his cancer. But at least we had this option.



I wonder if in this “safety first” climate toward experimental treatment — and with this latest court ruling — any of the protocols we considered would be approved. All had the possibility of deadly side effects. It’s frightening to think a government agency might have limited our options because it thought one treatment safer than another.



The proper response to tragedies like the one that befell Jolee Mohr is not to try to make experiments risk‐​free, but to help patients understand the risks.



Robb Mohr told the _Post_ that “the science seemed good. There’s nothing I knew of that could have predicted this.” But the consent form his wife signed stated that the experimental therapy had possible “unknown side effects” including “in rare circumstances, death.”



Participating in experimental treatments is a decision not to be taken lightly. If the public goes along with the “safety first” mentality and abdicates decision‐​making authority to government regulators, we will lose an important right. We’ll lose the choice to participate in experiments that might kill us, but we’ll also lose the option to make a choice that might save our lives.
"
"

Interest groups in the United States have focused on the possibility of including provisions in trade agreements with the intent of countering currency manipulation. The concern is that another country may choose to reduce the value of its currency relative to the U.S. dollar in order to encourage its businesses to export more goods to the United States. Such currency realignment also would tend to make it more expensive for the devaluing nation to import products from this country.   
  
It’s true that an adjustment in currency exchange rates – regardless of the reason for the adjustment – can have an effect on trade flows. U.S. industries that export to foreign customers, or compete with imported goods in the domestic marketplace, understandably would prefer that currency relationships not become skewed against their commercial interests. Currency stability improves the business climate by making it easier to build long-term relationships with customers and suppliers.   
  
However, currency exchange rates have fluctuated throughout recorded history. Sometimes those changes may be driven by a government’s conscious desire to devalue its currency. More often the variability in exchange rates reflects fundamental economic realities. Economies that experience growing productivity and rising prosperity should not be surprised to find that market pressures cause their currencies to strengthen. The reverse is true for countries that are growing slowly or not at all.   
  
A shift in exchange rates changes a country’s “terms of trade,” which is a term used by economists to describe the ratio of a country’s export prices to its import prices. From a U.S. perspective, if another country sets its currency at an artificially low level relative to the dollar, the U.S. terms of trade will improve. The United States will be able to obtain a greater value of imports for the same value of exports. Exporting the same number of airplanes and soybeans as before will pay for the importation of larger quantities of shoes, coffee, and automobiles.   




The country that chooses to undervalue its currency will be placing an artificially low value on the output created by workers and capital in its domestic economy. It will, in effect, be selling its exports for less than their true economic worth, thus transferring wealth to the United States. People in this country experience meaningful increases in their standards of living at the expense of the country that has devalued.   
  
Yes, most buyers like to get a good deal. An increase in affordable imports generally doesn’t strike consumers as a bad thing. Assuming those imports don’t compete too directly with goods and services produced widely in the United States (think of coffee, bananas, shoes, clothing, diamonds, rare earth metals, etc.), they tend to be well accepted even by people with mercantilist tendencies. Some imports that do compete directly with U.S. products – such as crude oil or cars – also may not raise strong political objections, either because domestic demand is larger than can be served solely by domestic supplies, or because consumers desire a variety of choices.   
  
The politics of affordable imports become more complicated when those products compete directly with goods and services produced in the importing country. Competition always is a challenge, whether it comes from other domestic firms or from overseas. Firms often struggle to deal with forces as diverse as changing technology or changing consumer tastes and preferences. Not all firms survive forever. Rather, the process of creative destruction keeps the economy in an ongoing state of reinvigoration and renewal. There’s no doubt, though, that an increase in imports can create adjustment headaches for import-competing U.S. companies and their workers.   
  
The good news is that the United States already has a policy framework with which to address unfairly priced imports, regardless of whether those imports relate to currency undervaluation. U.S. trade remedy laws allow industries to seek antidumping or countervailing duty (AD/CVD) protection against imports that may be injuring domestic producers. From a free-trade perspective, it’s important to understand that U.S. trade remedy laws leave a lot to be desired. They generally are seen to be relatively protectionist – slanted in favor domestic industries over imports.   
  
However, trade remedies are a better policy response (even though suboptimal) to currency manipulation than would be the case for special provisions in trade agreements. Trade remedies are relatively selective. They are applied only to unfairly priced imports that are troublesome to U.S. industries, and only after those producers have demonstrated that they’ve been injured. On the other hand, currency provisions included in trade agreements would apply to all imports from the offending country. American consumers would end up paying more even for tea and T-shirts, for which there is little or no U.S. production. Given the broad negative implications of using trade agreement provisions to counteract currency manipulation, U.S consumers would be much better off dealing with the narrower negative consequences of AD/CVD measures.   
  
A concluding thought: Since currency undervaluation by other countries serves to transfer wealth to the United States, should we consider finding some diplomatic way to thank them? Such a gesture likely would do far more good than including misguided currency provisions in trade agreements. It might help prompt policymakers around the world to rethink the plusses and minuses of allowing currencies to get out of alignment.   
  
(For more detail on issues surrounding currency manipulation, see this article from Forbes.com by my colleague, Dan Ikenson.)


"
"Even large ecosystems the size of the Amazon rainforest can collapse in a few decades, according to a study that shows bigger biomes break up relatively faster than small ones. The research reveals that once a tipping point has been passed, breakdowns do not occur gradually like an unravelling thread, but rapidly like a stack of Jenga bricks after a keystone piece has been dislodged.  The authors of the study, published on Tuesday in the Nature Communications journal, said the results should warn policymakers they had less time than they realised to deal with the multiple climate and biodiversity crises facing the world. To examine the relationship between an ecosystem’s size and the speed of its collapse, the authors looked at 42 previous cases of “regime shift”. This is the term used to describe a change from one state to another – for example, the collapse of fisheries in Newfoundland, the death of vegetation in the Sahel, desertification of agricultural lands in Niger, bleaching of coral reefs in Jamaica, and the eutrophication of Lake Erhai in China. They found that bigger and more complex biomes were initially more resilient than small, biologically simpler systems. However, once the former hit a tipping point, they collapse relatively faster because failures repeat throughout their modular structure. As a result, the bigger the ecosystem, the harder it is likely to fall. Based on their statistical analysis, the authors estimate an ecosystem the size of the Amazon (approximately 5.5m km2) could collapse in approximately 50 years once a tipping point had been reached. For a system the size of the Caribbean coral reefs (about 20,000 km2), collapse could occur in 15 years once triggered. The paper concludes: “We must prepare for regime shifts in any natural system to occur over the ‘human’ timescales of years and decades, rather than multigenerational timescales of centuries and millennia. “Humanity now needs to prepare for changes in ecosystems that are faster than we previously envisaged through our traditional linear view of the world, including across Earth’s largest and most iconic ecosystems, and the social-ecological systems that they support.” The paper says this could be the case in Australia where the recent Australian bushfires followed protracted periods of drought and may indicate a shift to a drier ecosystem. Scientists were already aware that systems tended to decline much faster than they grew but the new study quantifies and explains this trend. “What is new is that we are showing this is part of a wider story. The larger the system, the greater the fragility and the proportionately quicker collapses,” John Dearing, professor in physical geography at the University of Southampton and lead author of the study, said. “What we are saying is don’t be taken in by the longevity of these systems just because they may have been around for thousands, if not millions, of years – they will collapse much more rapidly than we think.” Dearing said he was concerned that one of the possible implications of the study was that complete destruction of the Amazon could occur within his grandchildren’s lifetimes. “This is a paper that is satisfying from a scientific point of view, but worrying from a personal point of view. You’d rather not come up with such a set of results,” he said. A separate study last week warned the Amazon could shift within the next decade into a source of carbon emissions rather than a sink, because of damage caused by loggers, farmers and global heating. Experts said the new findings should be a spur to action. “I think the combination of theory, modelling and observations is especially persuasive in this paper, and should alert us to risks from human activities that perturb the large and apparently stable ecosystems upon which we depend,” said Georgina Mace, professor of biodiversity and ecosystems at University College London, who was not involved in the studies. “There are effective actions that we can take now, such as protecting the existing forest, managing it to maintain diversity, and reducing the direct pressures from logging, burning, clearance and climate change.” These views were echoed by Ima Vieira, an ecologist at Museu Emílio Goeldi in Belém, Brazil. “This is a very important paper. For Brazil to avoid the ecosystem collapse modelled in this study, we need to strengthen governance associated to imposing heavy fines on companies with dirty supply chains, divestment strategies targeting key violators and enforcement of existing laws related to environmental crimes. And we have to be quick.” However, the methodology was not universally accepted. Erika Berenguer, a senior research associate at the University of Oxford and Lancaster University, said the regime shifts paper relied too much on data from lakes and oceans to be useful as an indicator of what would happen to rainforests. “While there is no doubt the Amazon is at great risk and that a tipping point is likely, such inflated claims do not help either science or policy making,” she said. The authors said their study was not a forecast about a specific region but a guide to the speed at which change could occur."
"
Share this...FacebookTwitterDistinguished IPCC climate scientist Professor Hans von Storch wrote what to me appears to be a very twisted and disturbing statement at his Klimazwiebel blog. I’m really quite surprised by it.
Von Storch writes he got correspondence from a friend, who asked him how he personally thinks people can contribute to reducing climate change. HvS provides his “brief and spontaneous” answer by writing that a single person can’t really do anything and that technology needs to be developed to reduce CO2 emissions, and to do it economically.
So far so good.
He then writes that people installing solar panels on their rooves, though with good intentions, is in fact ineffective symbolism, and indeed is only merely spreading the illusion that one is doing something good. If anything, feel-good people are in fact impeding the development of truly effective approaches.
Then come his last two sentences, which I have translated below:
Die globalen Emissionen sind im letzten Jahr laut IEA um 3.2 % gestiegen. Ich glaube, das entspricht der jährlichen Emission von Deutschland, um und bei.
Die wirksamste Klimapolitik der letzten Jahrzehnte war die 1-Kind Politik in China, die der Welt ca. 400 Millionen CO2-Emittenden und Emittenden-Vermehrern erspart hat.
IN ENGLISH:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to the IEA, global emissions last year climbed 3.2%. I believe that corresponds to the annual emission of Germany – roundabout.
The most effective climate policy of the last decade was the 1-child policy in China which saved the world from approx. 400 million emitters and emitter-reproducers.”
Denial of human life as an effective climate policy? Is he being cynical or has he totally lost his marbles?
I can only assume he is being cynical and is indirectly criticising what has been ineffective “climate policies” so far. (Personally, I don’t see how anyone can say “climate policies” have been ineffective when global temperatures have not risen at all over the last 10 years. Where’s the failure?).  Cynical or not, that 1-child statement goes way too far. Unusual coming from a man who dislikes extreme views from either side.
It would be disturbing enough if HvS were just another climate scientist trying to get attention, but he is much more than that. He is professor at the Meteorological Institute of the University of Hamburg, Director of the Institute for Coastal Research at the Helmholtz Research Centre in Geesthacht, and a member of the advisory boards of the journals Journal of Climate and Annals of Geophysics. He is one Germany’s leading climate scientists.
And when the world’s leading scientists run loose and start spewing about the virtues of mass population reduction in scientific terms, then the rest of us really need to worry. Dangerous politicians have a nasty habit of gravitating in their direction.
Strangely, HvS wrote his short essay in German, and not in the usual English which one finds more often at Klimazwiebel. Perhaps the elimination of 400 million people just seems to come across better in the more authoritarian German.
Cynical or not, it’s time for the professor to retire. In the very least he’d be wise to call his statement a mistake and to retract it.
 
Share this...FacebookTwitter "
"

John McCain’s idea — now embraced enthusiastically by Hillary Clinton — to temporarily suspend the federal gasoline tax between Memorial Day and Labor Day is rich fodder for energy analysts. Even richer, however, is the somewhat curious response that the proposed “tax holiday” has provoked from political actors and policy pundits of various stripes. A quick tour of the issues in play is instructive.



First, if there is any math out there to refute Barack Obama’s claim that the proposed tax holiday would save the average driver a grand sum of $28 — “otherwise known as $9 a month” as he puts it, or the grand sum of one‐​half of a tank of gas — it has escaped our attention. Of course, even that calculation presupposes that service station owners will pass on the full tax cut to the consumer — which they most definitely would not. How much of that tax cut would reach consumers is unclear. What is clear, however, is that Sen. McCain’s claim that the tax holiday would provide a powerful stimulus to the economy is risible. Sen. Clinton’s claim that the savings represents “real money” to the poor, hard‐​trodden masses yearning to keep their heads above water is similarly hard to swallow.



Second, the McCain/​Clinton plan is directly at odds with other stated policy objectives forwarded by McCain/​Clinton. Both candidates, for instance, dutifully call for the government to do more to promote energy conservation, reduce greenhouse gas emissions, encourage renewable energy, and to break our national “addiction to oil.” And they hope to do this by … reducing gasoline prices?



Consider the McCain‐​Lieberman bill to reduce greenhouse gas emissions by one‐​third below 2000 levels by 2050. The EPA estimates that the bill would increase gasoline prices 26 cents per gallon in current dollars by 2030 and 68 cents per gallon by 2050. Electricity bills would likewise go up by 22 percent in 2030 and 25 percent in 2050. So what John McCain proposes to give with one hand will be taken — in spades! — by the other.



Hillary Clinton’s two‐​handed policy is even more striking. Her big complaint with McCain‐​Lieberman is that it doesn’t go far enough. Tie the tax holiday with a windfall profits tax, however, and the tension between the various aspects of the McCain/​Clinton energy agenda disappears. That’s Hillary Clinton’s plan; replace the lost revenues from the tax holiday with a windfall profits tax on “big oil” and tell the voters that you’ll make the oil companies pay their gasoline taxes for a while. What she doesn’t tell her adoring working‐​class fans is that a windfall tax will send oil prices up, not down. That’s the conclusion of the only analysis of the economic impact of that tax that we are aware of — written by Salvatore Lazzari of the Congressional Research Service — which found that the 1980 windfall‐​profits tax reduced domestic oil production by 3–6 percent, a result that should come as no surprise.



But even that result probably understates the long‐​term effect. Some analysts regurgitate the standard textbook line that a one‐​time, lump‐​sum tax on windfall profits shouldn’t alter market conditions. But once such a tax is imposed, who’s to guarantee that it won’t be imposed again? The effect of the windfall profits tax (repealed in 1988) is almost certainly still with us because domestic producers are forced to consider the possibility that new windfall profit taxes will be imposed in the future. Hence, some subset of otherwise profitable investments in domestic production are never made because the possibility of a new windfall profit tax tips the balance against the investment.



Gall over the manifest hypocrisy of these two candidates, however, does not explain the vicious response the tax holiday has received from pundits and public intellectuals. No, their anger largely stems from outrage over the public betrayal of the case for high‐​energy prices. That case, however, is as dubious as the case for a tax holiday.



Some pundits argue that the feds need to discourage oil consumption — and thus increase fuel taxes — to reduce the flow of money going to Islamic terrorists. There is no correlation, however, between world oil prices (and thus, oil profits) and Islamic terrorism. Even when crude oil prices were in the $20s per barrel, al‐​Qaeda, Hezbollah, and Hamas were doing quite nicely and statistical analysis concretely demonstrates that terrorism does not correlate with oil revenues.



Others argue that we need higher gasoline prices to internalize the costs associated with climate change. That argument sounds correct, but no one has convincingly established the correct premium on the price of gas that would yield the appropriate degree of conservation. Such a task is understandably difficult, if not impossible. But a probable “market failure” in gasoline production and consumption does not guarantee “government success” in attempting to correct it via a gas excise tax. Indeed, the more we hear on this from our current crop of presidential candidates, the more afraid we are of an eventual “government failure” that’s worse.



On balance the greater danger is that, once elected, any one of the remaining presidential candidates will increase, not reduce, the gas tax. And, as appears likely, devoting the additional revenues to the highway trust fund would extend the current confused government policy: Building and maintaining roads and highways with revenues from a gas conservation tax promotes more, not less driving and gas consumption by the public.



The gas tax cannot do both — serve as a stick to promote gas conservation for slowing global warming and as a carrot to provide an economic boost for families in trouble. That’s the reality, but everyone seems intent on taking a holiday from it.
"
"

Al Gore has finally won his Nobel Prize, reminiscent of the proverbial little nut that stood his ground, evolving into a giant oak. Now we can only hope that he runs for president, an office that, given recent history, surely deserves him.



Where else — except perhaps via the Kyoto Protocol on global warming, which Gore negotiated — can someone accomplish so little while spending so much? But, to get there, or at least to the Demo nomination, Gore’s going to have to do something he has assiduously avoided: debate.



Gore’s standard rule on live TV has been there will be no live challenge. The last time he ran for president (2000), he succeeded de facto, with George “Carbon Bonoxide” Bush as the token global warming flyweight. This time, debates happen.



That’s because Gore represents a party gone global warming ga‐​ga, with some of the world’s goofiest environmental legislation in history awaiting a Bush veto and a Gore signature.



Consider what Bernie Sanders (“I”-VT) has in the docket: A legislative magic wand that will require us to reduce our emissions of carbon dioxide by 90% in a mere 42 years. Since 1990, we’re up a little under 20%. Sanders’ legislation takes us back to the 1930s, a technological stone age. True, there’s other, more “moderate” legislation. John Kerry’s (D-MA) proposal would cut it back 80%. Dianne Feinstein (D-CA) is at 50%.



Each and every one has a good chance of Senate passage, and an even better chance of a veto. So, now that you have your Nobel, _come out and fight like a man, Al, and don’t even worry about picking on someone your own size_.



The fact is that Al has ducked, feinted, dived away from, or fluffed each and every opportunity for a reasoned debate with any global warming scientist not of his choice, a choice he no longer enjoys. Heartland Institute, a Chicago think tank, spent over a million dollars filing ads in the _Wall Street Journal_ , the _New York Times_ and their ilk, begging Al to debate. No dice. In a less public venue, my own Cato Institute sent kind and courteous letters asking him to share our pretty auditorium on Washington’s Massachusetts Avenue, for a civil discussion with our scholars. Again, no dice.



Here’s the rub: if any opposition were so easy to vanquish, Gore would relish the opportunity. Obviously there’s a substantive and cogent argument he can’t kill.



In essence, it is that Gore has massively departed from the scientific mainstream on global warming, even as that community may be itself biased by the funding afforded by emphasizing the negative.



For example, the United Nations’ Intergovernmental Panel on Climate Change (of which I am a member, while Gore is not) predicts a mean sea‐​level rise of about 13 inches by 2100. Gore’s book and movie contain an undated montage showing Florida sliding beneath the waves, something that could only happen with 13 _feet_ or more.



How on earth does one accomplish such a disconnect from scientific reality?



Gore only has one scientist, James Hansen of NASA, whispering the sweet nothings into his ear that sea‐​level could rise this much or more in the next 92 years, as Greenland’s ice sheets are destabilized by climate change.



No other scientist is willing to climb out on this limb, because it is simply not supported by the observed climatic history of Greenland since the end of the last ice age. For much of six millennia, ending 3,000 years ago, it had to be warmer, and yet the ice stuck like glue. Hansen’s amazing response, which you can read on his blog, documented at www​.real​cli​mate​.org (not exactly a peer‐​reviewed scientific journal!) is that other scientists don’t agree with him because they suffer from what he calls “scientific reticence.” In other words, all his colleagues are chicken‐​bleeps because they don’t agree with him.



How about the other pole? Every computer model mentioned by the United Nations shows Antarctica _gaining_ ice this century because a slight warming will result in more precipitation which must fall as snow. Would Gore like that out in public? Or how about the fact that Antarctica just set its _record maximum_ for sea‐​ice extent, as measured by satellite.



The world can only hope that Gore’s Nobel propels him into another run for the Presidency. He received it for his climate lunacy. Now he can defend it and the Nobel Prize by merely debating those who must be so easy to defeat.
"
"
Surrounding these recent revelations, some hilarity from the world’s preeminent skeptic cartoonist, Josh.

Thanks to Josh at www.cartoonsbyjosh.com


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89295a23',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

Does global warming threaten to permanently cripple the global economy? According to a new report from the British Treasury prepared by economist Nicholas Stern, that’s exactly what will happen unless we cut greenhouse‐​gas emissions to 25 percent below current levels by 2050. Should we do it? A close reading of the report reveals that the answer is “not necessarily.”



Not to be flip about it, but why should the relatively poor (us) sacrifice for the relatively rich (our children and grandchildren)? The Stern Report argues that the emissions cuts necessary to stave off disaster will likely cost about one percent of global GDP every single year, or about $1,154 in current dollars per household in the United States. A small price to pay, we’re told, when GDP losses will likely total 5–10 percent of global GDP every year if we do absolutely nothing.



But even with a ten‐​percent reduction in GDP relative to what it would have been, 100 years from now, people will still be extraordinarily well off by current standards. For example, since 1950 real U.S. GDP per capita has increased by about two percent a year. Given that growth rate, real GDP per capita 100 years hence would be $321,684, or more than seven times higher than it is at present ($44,403). If global warming cuts GDP by ten percent a year beginning about 50 years from now, then GDP per capita will be $289,515 in 2106 rather than $321,684.



Would anyone, let alone liberals, ever propose a one‐​percent tax on those who make $44,000 to create benefits for those who make $289,000? In short, paying now to head off warming is a regressive intergenerational tax that takes from the poor and gives to the rich.



The direct costs associated with greenhouse gas emission controls include avoidable deaths in the developing world. The United Nations, for example, reports that about two million people on this planet die every year because they don’t have electricity and must burn biomass for heating and cooking. This results in greatly elevated levels of indoor air pollutants and premature deaths. Increasing the cost of electricity — an unavoidable consequence of ridding the global economy of the fossil fuels that generate greenhouse gases — will slow our ability to conquer this problem. 



Higher fossil fuel costs will also slow the general march out of poverty. Not only is poverty the number one killer on the planet, it is also the number one cause of environmental ruin. Deforestation, habitat loss, and air and water pollution are all strongly correlated with per capita income.



Nor are citizens in the industrialized West immune from the health effects associated with reduced income. Academics have established that every $15 million reduction of aggregate income causes one statistical death. That stands to reason; the poorer we are, the less likely we are (on average) to eat well, exercise, procure necessary health care services, and avoid unhealthy lifestyles. This effect alone suggests that in the U.S., greenhouse gas abatement, on the scale suggested by the Stern report, would cost more than 8,800 lives per year.



Of course, the Stern Report argues that the GDP losses associated with doing nothing dwarf the GDP losses associated with effective emissions controls. In a world with no doubts, spending one percent of U.S. GDP to eliminate a loss of ten percent of U.S. GDP every year beginning 50 years from now passes a cost‐​benefit test if we assume that GDP grows two percent per year, we discount future costs and benefits by five percent a year, and run our analysis out for 1,000 years. That calculation reveals that the present value of the costs would total $15,541 while the present value of the benefits would total $36,477. If the future stream of benefits were only five percent of future GDP, however, then it’s about a wash; $15,541 would get us only $18,239 in benefits.



But climate predictions are not certain. The Stern report argues that there’s at least a 50–50 chance that temperatures will rise five degrees Celsius over pre‐​industrial levels if we do nothing. You won’t find that argument in the latest report of the International Panel on Climate Change (IPCC), however, which offers a wide band of possible warming scenarios. The Stern Report’s estimate is within the upper boundary of what’s possible, but median warming projections are around 2–3 degrees Celsius.



It’s worth noting that when economists have crunched those median‐​warming projections in the academic literature, they have found that the costs associated with climate change are 0–2 percent of GDP rather than the 5–10 percent asserted in the Stern report. If the benefits are only two percent of future U.S. GDP, then $15,541 in costs in present value terms produces only $7,295 in benefits.



Finally, none of the above calculations consider the possibility that the costs will buy no benefits at all. The latest IPCC report, for instance, notes that the warming we’ve detected thus far is “unlikely (bordering on very unlikely) to be entirely the result of internal variability,” and that “natural forcing alone [i.e., solar and/​or volcanic activity] is unlikely to explain the increased rate of global warming since the middle of the 20th century.”



No matter how you read that, it’s clear that there is greater than zero chance that greenhouse‐​gas‐​emission cuts will produce no economic gains at all. Accordingly, all the benefit estimates above must be discounted to some degree (how much is in dispute) to reflect that possibility.



Think of the Stern Report as an elaborate economic pitch for an expensive insurance policy. Well, we’re not buying … yet.
"
"**In 2020, the billion-dollar blockbuster has been defeated by Covid-19 more convincingly than by any on-screen villain.**
Most of the year's proposed blockbusters - films with a budget of more than Â£100 million - are on hold.
The James Bond film No Time To Die has been postponed twice; Disney's live-action Mulan was released on the studio's streaming platform; and Top Gun: Maverick is still riding a motorbike to nowhere.
Even Marvel films such as Black Widow - reliable stalwarts of the summer event season - have been pushed back indefinitely, as studios wait for a return to normality.
But while screen heroes can't currently save the world, they may still be able to save the big screen experience, says Screen International's chief film critic, Finn Halligan.
""It's like we've been having a staring contest,"" she says, of the stand-off between film studios and cinemas. ""Someone's got to blink.""
A small sign of eye movement came with recent news that Wonder Woman 1984 would be released simultaneously at both US cinemas and online, on Christmas Day 2020.
The film, which plunges Gal Gadot, as the returning superhero, into an '80s universe, cost around Â£145m ($US 200m) to make. Originally scheduled to open in June, its release has already been delayed twice.
""The studios haven't wanted to sacrifice any potential billion-dollar movie during the pandemic,"" explains Halligan. ""They're too much of a valuable commodity.""
But the longer cinemas remain shut, the harder these decisions become.
According to The Hollywood Reporter, No Time To Die is costing film studio MGM $1m in interest every month. That money, which it originally borrowed to make the film, can't be made back until 007 hits the big screen.
Last year, nine films made more than $1bn at the global box office - including The Lion King, Joker, Avengers: Endgame and Captain Marvel.
Fast forward to summer 2020, and Christopher Nolan's Tenet - a film with a budget of $205m (Â£150m) - was the only mega-budget movie to be released in cinemas, grossing around $350m (Â£270m).
""The profits of Tenet spooked them, although I don't think it did badly in the circumstances,"" says Halligan.
""Studios still hope they can get the numbers, but the crunch point isn't the future existence of the blockbuster, the stress point will be the cinemas themselves.
""Will audiences feel safe to come back for a new Marvel film in the cinema, or wait for it on Disney+? And how long can cinemas survive in this situation?""
However, Asia may already be pointing the way towards a movie-going recovery. Wonder Woman 1984 will have a full theatrical release in China a week before the film is released in the US.
Up until now, Hollywood has refused to show its biggest movies first to audiences in Asia, Australia and New Zealand - where many cinemas are open again - partly due to piracy fears.
It's also significant that China is behind 2020's biggest blockbuster so far - Hu Guan's war epic, The Eight Hundred, about a group of Chinese soldiers under siege by the Japanese army. It made $468m (Â£345m) at the box office.
""2020 is the year that China, not the US, became the world's biggest movie market,"" Asian film critic Stevie Wong says. ""It's surpassed $1.9bn (Â£1.4bn) this year.
""And without Hollywood movies, local films have had a bigger chance in cinemas,"" Wong adds, citing the success of Chinese drama My People, My Homeland and Japanese Anime movie Demon Slayer: Kimetsu No Yaiba.
""The Eight Hundred's made close to half a billion dollars, although that can't compare with cinema profits from 2019,"" says Wong.
""But there are more local blockbusters coming, like Andy Lau's Shock Waves 2 or Daniel Wu's Caught in Time, that should bring in the audiences again.""
Film traffic between the US and Asia has historically been one-way, to Hollywood's benefit. Yet a Jackie Chan movie, Vanguard, the veteran action star's latest collaboration with director Stanley Tong, has just enjoyed one of the biggest ever North American releases for an Asian film.
The lavish action movie, which was made across five different countries including the UK, India and China, is playing on 1500 cinema screens replacing the delayed Bond film, No Time to Die.
""It was only about eight weeks ago that we acquired the film,"" explains Nolan Gallagher, the CEO of Gravitas Ventures. ""We moved fast.""
Gallagher believes that where cinemas are open, audiences are eager to see big-screen action.
""There is a business for blockbusters. Yes, it's only a fraction of what it was before the pandemic, but there's still a box office business,"" he says.
""People are looking for enjoyment over the Thanksgiving holiday, especially if you're looking for something that's got that globe-trotting action experience to it.""
The sight of busy cinemas in Asia have also given hope to Hollywood, according to Mark Gill, President of Solstice Studios, based in Los Angeles. The independent film company has just bought the rights to Gerard Butler action thriller The Plane, which starts shooting in 2021 and is set to be released, in cinemas, in 2022.
""China, Japan and Korea have showed us this year that fundamental movie-going habits haven't changed,"" Gill argues.
""The film Demon Slayer, which was such a hit in Japan, wasn't necessarily the most sophisticated film ever, but clearly there was pent-up demand for audiences to go to the cinema.
""I think it shows that one good blockbuster can be a real tipping point, if the conditions are right.""
Solstice was the first company to release a new film in US cinemas following the first wave of the pandemic.
""We feel that we got into the movie business to show films in cinemas,"" he explains. ""Someone had to go first.""
The film in question was psychological thriller Unhinged, starring Russell Crowe.
""Certainly, the box office was less than in normal times, but it was solid. And the reaction from Hollywood was amazement that we pulled it off - and helped us get a lot more movies going.""
The release plan for Wonder Woman 1984 - which sees Asia, Europe and Africa get the film before is Christmas Day debut in the US - might suggest Hollywood is waking up to Asia's growing self-sufficiency in the blockbuster market.
""It's yet another challenge to Hollywood's way of doing things,"" says Steven Gaydos, executive editor of content at Variety magazine.
""Asia has a freestanding movie industry making its own films, for its own audiences.
""Hollywood has historically relied on the rest of the world for about 65% of its movie profits. If Asia has a self-sufficient movie industry, they're saying that they don't need Hollywood films - that's a huge blow to the accepted wisdom.""
Yet Gaydos believes the behemoth-budget blockbuster is one of the few films guaranteed a future in Hollywood, with budgets unlikely to be cut at the top.
""The blockbuster is going nowhere,"" he says. ""Hollywood makes almost nothing else apart from them - they account for 95% of the box office. These film studios that make them have bet their own future on their continued success.
""These big expensive films are actually better bets than the cheaper movies, as you're pre-selling the spectacular production values and the stellar cast - that's the built-in appeal.
""But the whole world of independent movies and dramatic cinema - basically risky films that won't guarantee a return - was already drifting to streaming services,"" he adds.
It seems unlikely streaming services will be content to stop there, especially given reports that the makers of No Time to Die were in recent, unsuccessful, talks to put the Bond film on a home entertainment platform.
Netflix has just announced that Don't Look Up, a space-asteroid comedy starring Jennifer Lawrence and Leonardo DiCaprio is in production and will premiere on its app.
""Before Covid, in Hollywood, there was a room on fire,"" Gaydos comments. ""The pandemic has poured gasoline on the rest of the house.
""I never expected to wake up and read that Leo Di Caprio - one of the names in Hollywood that can launch a film in cinemas - will premiere on Netflix.""
If Wonder Woman 1984 performs strongly, and with reports of successful vaccines on the horizon, 2021 may still save the traditional big-screen blockbuster.
But Finn Halligan warns that studios have to act decisively, bearing in mind the immediate financial plight of many cinemas.
""Film companies should remember if you want to achieve those billion-dollar profits, you'll need a lot of cinema screens on which to show your films.""
_Vanguard is on release in cinemas across the US._"
"

Mr. Chairman, distinguished members of the subcommittee:



My name is Roger Pilon. I am vice president for legal affairs at the Cato Institute and director of Cato’s Center for Constitutional Studies. 1 I want to thank you, Mr. Chairman, for inviting me to testify today on “Guns and Butter: Setting Priorities in Federal Spending in the Context of Natural Disasters, Deficits, and War”—the purpose of the hearing being, as your letter of invitation states, “to focus on the limits and role of our federal government as outlined in the Constitution.”



I can well understand your concern to focus on that issue, Mr. Chairman. In Federalist 45, James Madison, the principal author of the Constitution, spoke to a skeptical nation, worried that the document the Constitutional Convention had just drafted gave the central government too much power. Be assured, he said, the powers of the new government were, and I quote, “few and defined.” How things have changed. Yet in its 218 years, the Constitution itself has changed very little. The questions before us, then, are (1) under that Constitution, how did we go from limited to essentially unlimited government, (2) what are the implications, and (3) what should be done about it?



A closely related question is whether Madison understood and correctly reported on the document he’d just drafted, or whether modern interpretations of the Constitution, which have allowed our modern Leviathan to arise, are correct. Let me say here that Madison was right; the modern interpretations are wrong. As a corollary, most of what the federal government is doing today is unconstitutional because done without constitutional authority. That contention will doubtless surprise many, but there you have it. I mean to speak plainly in this testimony and call things by their proper name.



But before I defend that contention by addressing those questions, let me note that the nominal subject of these hearings—“setting priorities in federal spending”—concerns mainly a matter of policy, not law. Unless some law otherwise addresses it, that is, how Congress prioritizes its spending is its and the people’s business—a political matter. By contrast, the subtext of these hearings, which I gather is the subcommittee’s principal concern, is “the limits and role of our federal government as outlined in the Constitution,” and that is mainly a legal question. I distinguish those questions, let me be clear, for a very important reason. It is because we live under a Constitution that establishes the rules for legitimacy. Thus, in the case at hand, Congress may have pressing policy reasons for prioritizing spending in a given way, but such reasons are irrelevant to the question of whether that spending is constitutional.



 **Constitutional Legitimacy**



Because that distinction and the underlying issue of legitimacy are so central to these hearings, they warrant further elaboration at the outset. In brief, our Constitution serves four main functions: to authorize, institute, empower, and limit the federal government. Ratification accomplished those ends, lending political and legal legitimacy to institutions and powers that purported by and large to be morally legitimate because grounded in reason. Taken together, the Preamble, the first sentence of Article I, the inherent structure of the document, and especially the Tenth Amendment indicate that ours is a government of delegated, enumerated, and thus limited powers. The Constitution’s theory of legitimacy is thus simple and straightforward: To be legitimate, a power must first have been delegated by the people, as evidenced by its enumeration in the Constitution. That is the doctrine of enumerated powers, the centerpiece of the Constitution. For the Framers, it was the main restraint against overweening government. In fact, the Bill of Rights, which we think of today as the main restraint, was an afterthought, added two years later for extra precaution.



Once that fundamental principle is grasped, a second follows: Federal powers can be expanded only by constitutional amendment, not by transient electoral or congressional majorities. Over the years, however, few such amendments have been added. In the main, therefore, Article I, section 8 enumerates the 18 basic powers of Congress—the power to tax, the power to borrow, the power to regulate commerce with foreign nations and among the states, and so forth, concluding with the power to enact such laws as may be necessary and proper for executing the government’s other enumerated powers. It is a short list, the idea being, as the Tenth Amendment makes explicit and the _Federalist_ explains, that most power is to remain with the states—or with the people, never having been delegated to either level of government. 2



In fact, given the paucity and character of the federal government’s enumerated powers, it is plain that the Framers meant for most of life to be lived in the private sector—beyond the reach of politics, yet under the rule of law—with governments at all levels doing only what they have been authorized to do. Far from authorizing the ubiquitous government planning and programs we have today, the Constitution allows only limited government, dedicated primarily to securing the conditions of liberty that enable people to plan and live their own lives. I turn, then, to the first of the questions set forth above: How did we move from a Constitution that limited government to one that is read today to authorize effectively unlimited government?



 **From Limited to Unlimited Government**



The great constitutional change took place in 1937 and 1938, during the New Deal, all without benefit of constitutional amendment; but the seeds for that change had been sown well before that, during the Progressive Era. 3 Before examining that transition, however, I want to lay a proper foundation by sketching briefly how earlier generations had largely resisted the inevitable pressures to expand government. It is an inspiring story, told best, I have found, in a thin volume written in 1932 by Professor Charles Warren of the Harvard Law School. Aptly titled, _Congress as Santa Claus: or National Donations and the General Welfare Clause of the Constitution,_ this little book documents our slow slide from liberty and limited government to the welfare state—and that was 1932! In truth, however, Warren’s despair over that slide notwithstanding, the book is a wonderful account of just how long we lived under the original design, for the most part, before things started to fall apart during the Progressive Era. And so I will share with the subcommittee just a few snippets and themes from the book, along with material from other sources, to convey something of a sense of how things have changed—not only in the law but, more important, in the culture, in our attitude toward the law.



When Thomas Jefferson wrote that it was the natural tendency for government to grow and liberty to yield, he doubtless had in mind his rival, Alexander Hamilton, for hardly had the new government begun to operate when Hamilton proposed a national industrial policy in his 1791 _Report on Manufactures._ 4 To Hamilton’s argument that Congress had the power to pronounce upon the objects that concern the general welfare and that these objects extended to “the general interests of learning, of agriculture, of manufacturing, and of commerce,” 5 Madison responded sharply that “the federal Government has been hitherto limited to the specified powers, by the Greatest Champions for Latitude in expounding those powers. If not only the _means,_ but the _objects_ are unlimited, the parchment had better be thrown into the fire at once.” 6 Congress shelved Hamilton’s _Report._ He lost that battle, but over time he won the war.



The early years saw numerous attempts to expand government’s powers, but the resistance mostly held. In 1794, for example, a bill was introduced in the House to appropriate $15,000 for the relief of French refugees who had fled to Baltimore and Philadelphia from an insurrection in San Domingo, 7 whereupon Madison rose on the floor to say that he could not “undertake to lay [his] finger on that article of the Federal Constitution which granted a right to Congress of expending, on objects of benevolence, the money of their constituents.” 8 Two years later a similar bill, for relief of Savannah fire victims, was defeated decisively, a majority in Congress finding that the General Welfare Clause afforded no authority for so particular an appropriation. 9 As Virginia’s William B. Giles observed, “[The House] should not attend to what… generosity and humanity required, but what the Constitution and their duty required.” 10



Those early attempts to expand Congress’s power, and the resistance to them, centered on the so‐​called General Welfare Clause of the Constitution, found in the first of Congress’s 18 enumerated powers. 11 Hamilton argued that the clause authorized Congress to tax and spend for the general welfare. Not so, said Madison, Jefferson, and many others. South Carolina’s William Drayton put it best in 1828:



If Congress can determine what constitutes the General Welfare and can appropriate money for its advancement, where is the limitation to carrying into execution whatever can be effected by money? How few objects are there which money cannot accomplish! …Can it be conceived that the great and wise men who devised our Constitution… should have failed so egregiously… as to grant a power which rendered restriction upon power practically unavailing? 12



Stated differently—with reference to constitutional structure—what was the point of enumerating Congress’s powers if any time it wanted to do something it was not authorized to do, because there was no power granted to do it, Congress could simply say it was spending for the “general welfare” and thus make an end‐​run around the limits imposed by the doctrine of enumerated powers? Enumeration would have been pointless.



That argument largely held through the course of the 19th century. To be sure, inroads on limited government were made on other constitutional grounds, as Warren recounts. Congress made gifts of land held in trust under the Public Lands Clause, for example, with dubious consideration given in return; then gifts of revenues from the sale of such lands; and finally, gifts of tax revenues generally. 13 But there were also numerous examples of resistance to such redistributive schemes. Thus, in 1887, 100 years after the Constitution was written, President Grover Cleveland vetoed a bill appropriating $10,000 for distribution of seeds to Texas farmers suffering from a drought. 14 In his veto message he put it plainly: “I can find no warrant for such an appropriation in the Constitution.” 15 Congress sustained the veto. And as late as 1907 we find the Supreme Court expressly upholding the doctrine of enumerated powers in _Kansas v. Colorado:_



The proposition that there are legislative powers affecting the Nation as a whole which belong to, although not expressed in [,] the grant of powers, is in direct conflict with the doctrine that this is a government of enumerated powers. … The natural construction of the original body of the Constitution is made absolutely certain by the Tenth Amendment. 16



Thus, although the doctrine of enumerated powers faced political pressure from the start, and increasing pressure as time went on, the pattern we see through our first 150 years under the Constitution can be summed up as follows. In the early years, measures to expand government’s powers beyond those enumerated in the Constitution rarely got out of Congress because they were stopped by objections in that branch— _constitutional_ objections. Members of Congress actually debated whether they had the power to do whatever it was that was being proposed; they didn’t simply assume they had the power and then leave it to the courts to check them. _Congress took the Constitution and the limits it imposed on congressional action seriously._ 17 Then when constitutionally dubious bills did get out of Congress, presidents vetoed them—not simply on policy but on constitutional grounds. And finally, when that brake failed, the Court stepped in. In short, the system of checks and balances worked because the Constitution was taken seriously by sufficient numbers of those who had sworn to uphold it.



The Progressive Era called all of that into question. Marked by a fundamental change in the climate of ideas, it paved the way for the New Deal. In fact, as early as 1900 we could find _The Nation,_ before it became an instrument of the modern left, lamenting the demise of classical liberalism. In an editorial entitled “The Eclipse of Liberalism,” the magazine’s editors surveyed the European scene, then wrote that in America, too, “recent events show how much ground has been lost. The Declaration of Independence no longer arouses enthusiasm; it is an embarrassing instrument which requires to be explained away. The Constitution is said to be ‘outgrown.’ ” 18



The Progressives to whom those editors were pointing, sequestered often in elite universities of the East, were animated by ideas from abroad: British utilitarianism, which had supplanted the natural rights theory on which the Constitution rested; German theories about good government, as reflected in Chancellor Otto von Bismarck’s social security experiment; plus our own homegrown theories about democracy and pragmatism. 19 Combined with the emerging social sciences, those forces constituted a heady brew that nourished grand ideas about the role government could play in improving the human condition. No longer viewing government as a necessary evil, as the Founders had, Progressives saw the state as an engine of good, an instrument through which to solve all manner of social and economic problems. In a word, it was to be better living through bigger government. 20



But a serious obstacle confronted the political activists of the Progressive Era—that troublesome Constitution and the willingness of judges to enforce it. Dedicated to liberty and limited government, and hostile to government planning garbed even in “the public good,” the Constitution stood as a bulwark against overweening government, much as the Framers intended it would. Not always, 21 to be sure, but for the most part.



With the onset of the New Deal, however, Progressives shifted the focus of their activism from the state to the federal level. But they fared little better there as the Court found several of President Franklin Roosevelt’s schemes unconstitutional, holding that Congress had no authority to enact them. 22 Not surprisingly, that prompted intense debate within the administration over how to deal with “the nine old men.” It ended early in 1937, following the landslide election of 1936, when Roosevelt unveiled his infamous Court‐​packing scheme—his plan to pack the Court with six new members. The reaction in the country was immediate. Not even the overwhelmingly Democratic Congress—nearly four to one in the House—would go along with the scheme. Nevertheless, the Court got the message. There followed the famous “switch in time that saved nine” and the Court began rewriting the Constitution—again, without benefit of constitutional amendment.



It did so in two main steps. In 1937 the Court eviscerated the doctrine of enumerated powers. Then in 1938 it bifurcated the Bill of Rights and invented a bifurcated theory of judicial review. For the purpose of these hearings, it is one half of the 1937 step that is most important, the rewriting of the General Welfare Clause; but the rest merits a brief discussion as well, to give a more complete picture of this constitutional revolution.



In 1936, in _United States v. Butler,_ 23 the Court had found the Agricultural Adjustment Act 24 unconstitutional. But in the course of doing so it opined on the great debate between Madison and Hamilton over the meaning of the so‐​called General Welfare Clause, coming down on Hamilton’s side—yet only in dicta and hence not as law. A year later, however, following the Court‐​packing threat, the Court elevated that dicta as it upheld the Social Security Act 25 in _Helvering v. Davis._ 26 The words were ringing: “Congress may spend money in aid of the ‘general welfare,’ ” 27 said the 1937 Court. Moreover, “the concept of the general welfare [is not] static. Needs that were narrow or parochial a century ago may be interwoven in our day with the well‐​being of the nation.” 28 Thus were the floodgates opened. The modern welfare state was unleashed.



But if Congress could now engage in unbounded redistribution, so too could it regulate at will following the Court’s decision that same year in _NLRB v. Jones & Laughlin Steel Corp._ 29 The issue there was the scope of Congress’s power to regulate interstate commerce, a power Congress had been granted to address the impediments to interstate commerce that had arisen under the Articles of Confederation as states were imposing tariffs and other measures to protect local merchants and manufacturers from out‐​of‐​state competition. Thus, the power was meant mainly to enable Congress to ensure the free flow of goods and services among the states—to make that commerce “regular,” as against state and other efforts to impede it. 30 It was not a power to regulate anything for any reason. Yet that, in effect, is what it became as the 1937 _Jones & Laughlin_ Court held that Congress had the power to regulate anything that “affected” interstate commerce, which is virtually everything.



The doctrine of enumerated powers now effectively eviscerated—the floodgates open for the modern redistributive and regulatory state to pour through—only the Bill of Rights stood athwart that unbounded power. So in 1938, in famous footnote 4 of _United States v. Carolene Products,_ 31 the Court addressed that impediment to Leviathan by distinguishing “fundamental” and “nonfundamental” rights, in effect, and inventing a bifurcated theory of judicial review to complement that distinction. If a law implicated “fundamental” rights like speech or voting, the Court would apply “strict scrutiny” and would doubtless find it unconstitutional. By contrast, if a law implicated “nonfundamental” rights like property, contract, or the rights we exercise in ordinary commercial relations, the Court would uphold the law as long as there was some “rational basis” for it. 32 That judicial deference to the political branches regarding economic rights, coupled with strict scrutiny for political rights, amounted to the democratization and to the politicization of the Constitution, to opening the door to political control of economic affairs, public and private alike, beyond anything the Framers could have imagined. 33



The rest is history, as we say, with redistributive and regulatory schemes, federal, state, and local, pouring forth. Others on this panel can testify as to the numbers that illustrate that explosion in government programs. My concern, rather, is to outline how it happened that under a Constitution meant to limit government we got a government of effectively unlimited power.



Toward that end, and beyond the history of the matter, let me add that most of the spending that is the focus of these hearings has arisen under the so‐​called General Welfare Clause, which the Court has also referred to as the Spending Clause. In truth, however, there are no such clauses in the Constitution, 34 which is why I have invoked the term “so‐​called.” A careful reading of the first of Congress’s 18 enumerated powers, which is the nominal source of those so‐​called clauses, coupled with reflection on the structure of the document, will reveal merely a power to tax at the head of Article I, section 8, much as the second of Congress’s enumerated powers is the power to borrow. If Congress exercises either or both of those powers—or its Article IV power to “dispose” of public lands, for that matter—and it wants then to appropriate and spend the proceeds on any of the ends that are authorized to it, it must do so under the Necessary and Proper Clause. For taxing, borrowing, disposing, appropriating, and spending are distinct powers. The first three are expressly authorized to Congress. Appropriating and spending, by contrast, are necessary and proper _means_ toward executing the powers authorized to the government—means provided for under the Necessary and Proper Clause. As such, they are not _independent_ but only _instrumental_ powers, exercised in service of ends _that in turn limit their use to those ends._ Put simply, Congress cannot appropriate and spend for any end it wishes, but only for those ends it is authorized to pursue—and they are, as Madison said, “few and defined.”



We come, then, to the nub of the matter. Search the Constitution as you will, you will find no authority for Congress to appropriate and spend federal funds on education, agriculture, disaster relief, retirement programs, housing, health care, day care, the arts, public broadcasting—the list is endless. That is what I meant at the outset when I said that most of what the federal government is doing today is unconstitutional because done without constitutional authority. Reducing that point to its essence, the Constitution says, in effect, that everything that is not authorized—to the government, by the people, through the Constitution—is forbidden. Progressives turned that on its head: Everything that is not forbidden is authorized.



But don’t take my word for it. Take the word of those who engineered the constitutional revolution. Here is President Roosevelt, writing to the chairman of the House Ways and Means Committee in 1935: “I hope your committee will not permit doubts as to constitutionality, however reasonable, to block the suggested legislation.” 35 And here is Rexford Tugwell, one of the principal architects of the New Deal, reflecting on his handiwork some thirty years later: “To the extent that these new social virtues [i.e., New Deal policies] developed, they were tortured interpretations of a document [i.e., the Constitution] intended to prevent them.” 36 They knew exactly what they were doing—turning the Constitution on its head. That is the legacy we live with today.



 **Implications of the Constitutional Revolution**



That legacy has many implications. Let me distinguish five. First, and perhaps most important, is the loss of legitimacy—moral, political, and legal. Today, we tend to think mainly of political legitimacy, failing to see how the several grounds of legitimacy go together. We imagine that the people, by their periodic votes, tell the government what they want; and to the extent that it responds to that expression of political will, consistent with certain state immunities and individual rights that might check it, the government and its actions are legitimate. Whatever moral legitimacy flows from that view is a function of the moral right of self‐​government, but that right is largely open‐​ended regarding the arrangements it might produce. It could produce limited government. But it could as easily produce unlimited government. 37 And without a keen sense of the role and place of moral legitimacy, we are indifferent as to which it is.



That view characterizes legitimacy in a parliamentary system, more or less; it is not how legitimacy operates in our constitutional republic. Rather, as shown by the Declaration of Independence, the main principles of which shaped the Constitution, we find our roots in Lockean state‐​of‐​nature theory and its underlying theory of natural rights. 38 Legitimacy is first defined by the moral order, by the rights and obligations we have with respect to each other. Only then do we turn to political and legal legitimacy, through the social contract—the Constitution—that facilitates and reflects it. As outlined earlier, the federal government gets its powers by delegation from the people through ratification—reflecting mainly the (natural) powers the people have to give it—not through subsequent elections, which are designed primarily to fill elective offices. To be sure, many of the powers thus delegated leave room for discretion by those elected. That is why elections matter: different candidates may have different views on the exercise of that discretion—the discretion to declare war, to take a clear example. But through elections the people can no more give government a power it does not have than they can take from individuals a right they do have. In a constitutional republic like ours, it is the Constitution that sets the powers, not the people through periodic elections.



But when powers or rights are expanded or contracted not through ratification but through elections and the subsequent actions of elected officials, and the courts fail to check that, the Constitution is undermined and the powers thus created are illegitimate. That happened when the New Deal Court bowed to the political pressure brought on by Roosevelt’s Court‐​packing threat. And that paved the way for powers that have never been _constitutionally_ authorized by the people—for illegitimate powers, that is—and for the accompanying loss of rights.



Some would argue that we could correct that problem of illegitimacy simply by putting our present arrangements to a vote through the supermajoritarian amendment and ratification procedures provided for in Article V. Were that vote successful, that would indeed produce political and legal legitimacy. But because the Constitution as it stands today reflects fairly closely, in my judgment, the moral order that can be justified—in other words, the Framers and those who subsequently amended the document got it right, for the most part—I would object to amending the Constitution simply to lend political and legal legitimacy to the modern welfare state. Better, I believe, to be able to point not simply to that state’s moral illegitimacy but to its political and legal illegitimacy as well.



The second untoward implication of our departure from the Constitution is the chaos that follows for law more generally. 39 The judicial methodology the Constitution contemplates for most constitutional questions is really quite simple. Assuming a court has jurisdiction in a case challenging a given federal statute, the first question is whether Congress had authority to enact the statute. If not, that ends the matter. If yes, the next question is whether and how the act may implicate rights, enumerated or unenumerated.



Those questions are not always easy to answer and often involve close calls. But the difficulties are multiplied exponentially when the floodgates are opened and federal, state, and local legislation pours through, producing often inconsistent and incoherent “law” from every direction. Add to that, as noted above, the tendentious and politicized judicial methodology that flowed from _Carolene Products_ —today we have three and sometimes four “levels” of judicial review, 40 each with its own standards, and multi‐​factored “balancing” tests—and it soon becomes clear that we are far removed from a Constitution that was written to be understood at least by the educated layman. Life is complicated enough on its own terms. When government intrudes in virtually every corner of life, the complications can easily become overwhelming and unbearable. The Constitution was meant to bring order. If under it “anything goes,” order goes too, and chaos follows.



Closely related to those two implications is a third: disrespect for the Constitution entails disrespect for the rule of law itself. If Congress can redistribute and regulate virtually at will, unrestrained by the limits the Constitution imposes, the rule of law is at risk. By definition, unauthorized powers intrude on rights retained by the people; but a cavalier attitude toward powers can lead more directly to the same attitude toward rights: if powers can be expanded with impunity, so too can rights be contracted. 41 In fact, a “living constitution,” interpreted to maximize political discretion, can be worse than no constitution at all, because it preserves the patina of constitutional legitimacy while unleashing the political forces that a constitution is meant to restrain. And how long can “anything goes” for officials go unnoticed by the citizenry? A general decline in respect for law must follow.



Fourth, when constitutional integrity declines we lose the discipline a constitution is designed to impose on government. A constitution makes it harder for government to act, which is one of the main reasons for having one. This implication speaks to one of the basic functions of a constitution, which is not only to empower but to _limit_ the government that is created through it. In the original position, when we created and ratified the Constitution, we agreed to limit the government’s power as an act of self‐​discipline. We could have set no limits on the government’s power, of course; but that would have left us to a future determined by the political winds, and experience had taught us the perils of that course. Thus, we struck what we thought was a careful balance, giving the government enough power to do what we thought it should do, but reserving to ourselves the liberty appropriate to a free people. With that balance struck, the Constitution would serve to discipline us and future generations who might be tempted, given the circumstances, to grant the government more power than, in our considered judgment, we thought prudent.



Future generations could adjust that balance, of course, by amending the Constitution, provided sufficient numbers among them wanted to do so. In fact, that is just what happened following the Civil War. Troubled as the Framers were about the institution of slavery, which they recognized only obliquely in the Constitution to ensure union, they left its regulation to the states. After the Civil War, however, a new generation not only abolished slavery but, through the Fourteenth Amendment, fundamentally changed the balance between the federal government and the states. With the ratification of that amendment we finally had federal remedies against state violations of our rights. 42 Thus, although the amendment is properly read as having expanded _federal_ power, it was done to discipline _state_ power. A new balance was struck, to be sure, but because it was done through the constitutional process it did not amount to abandoning the discipline a constitution imposes, which is what happens when we stray from the document’s principles. In fact, the contrast between the different ways in which the Civil War and the New Deal generations changed the rules is stark and instructive. The Civil War generation did it the right way—through the ratification process. The New Deal generation, faced with a choice between amending the Constitution and changing it by judicial legerdemain, chose the latter.



But the larger picture regarding discipline should not be lost. For just as the Constitution disciplines the government, so too it disciplines the people in their daily lives. Professor Warren captures that point nicely with a quote from South Carolina’s Warren R. Davis, speaking in the House on April 4, 1832:



This system of transferring property by legislation—of giving pensions and gratuities to individuals, companies, corporations, and the States— … will degrade the States by inducing them to look for bounties, to the Federal Government; will degrade and demoralize the people, by making them dependent on the Government; will emasculate the free spirit of the country …. As soon as the people of ancient Rome were taught to look to the public granaries for support, the decay of public virtue was instantaneous. 43



Vast numbers of Americans today look to Washington for a rich array of “entitlements” that speak of nothing so much as the illusion of something for nothing. And politicians nurture that illusion, propelling us all in the downward spiral that Thomas Hobbes aptly called a war of all against all. Stated otherwise, as contributors to public largesse become fewer and recipients more numerous, the downward spiral becomes a death spiral. And we are headed in that direction as discipline continues to erode.



Finally, and closely related, let me little more than mention the economic implications of effectively unlimited government as I expect that others on the panel will address those more fully. By this point in human history, and especially after the collapse of the socialist experiments of the 20th century, we have a fairly clear understanding of the connection between liberty and prosperity—a connection that Adam Smith articulated so well in 1776, 44 and economists like Mises, Hayek, and Friedman, among many others, have refined and extended in our own time. What that understanding points to, once again, is the prescience of the Framers in drafting a constitution dedicated to securing our liberty and hence our extraordinary prosperity. But neither liberty nor prosperity is guaranteed by a mere parchment, especially by one that is ignored. The American economy has proven resilient enough to withstand the blows imposed by the galloping government of the 20th century—although we will never know how much more prosperous we might have been had that government been better reined. In future, however, to the extent we ignore the lessons of economics we invite the consequences that have befallen so many other nations that have chosen economic planning over economic liberty. And the basic lesson of economics is that liberty, property, and contract are the fundamental preconditions of prosperity.



 **What Is to Be Done?**



We did not create our overextended, unconstitutional government overnight. We cannot restore constitutional government overnight—too many people have come to rely on the irresponsible promises that have been made. But we can begin the process of restoration. For that, the most important thing to do now is to start restoring a constitutional ethos in the nation. And that should be the business of all branches, not simply the Court, which can hardly do the job by itself, even if it were the right body to do so. What we have here, in short, is not simply or even mainly a legal problem. Rather, it is a political and, more deeply still, a moral problem.



Because I have discussed what needs to be done in some detail in chapter 3 of the _Cato Handbook on Policy,_ 45 copies of which are available in every congressional office, I will simply outline those proposals here.



Limits on government today, when we’ve had them, have come largely from political and budgetary rather than from constitutional considerations. It has not been because of any perceived lack of constitutional authority that government in recent years has failed to undertake a program but because of practical limits on the power of government to tax and borrow—and even those limits have failed in times of economic prosperity. To restore truly limited government, therefore, we have to do more than define the issues as political or budgetary. We have to go to the heart of the matter and raise the underlying constitutional questions. In a word, we have to ask the most fundamental question of all: Does the government have the authority, the constitutional authority, to do what it is doing?



That means, of course, that we are going to have to come to grips with the present state of public debate on the subject. It surely counts for something that a substantial number of Americans—to say nothing of the organs of public opinion—have little apprehension of or appreciation for the Constitution’s limits on activist government. Thus, when thinking about how and how fast to reduce government, we have to recognize that the Court, after nearly 70 years of arguing otherwise, is hardly in a position, by itself, to relimit government in the far‐​reaching way a properly applied Constitution requires. But neither does Congress at this point have sufficient moral authority, even if it wanted to, to end tomorrow the vast array of programs it has enacted over the years with insufficient constitutional authority.



For either Congress or the Court to be able to do fully what should be done, therefore, a proper foundation must first be laid. In essence, the climate of opinion must be such that a sufficiently large portion of the American public stands behind the changes that are undertaken. When enough people come forward to ask—indeed, to demand—that government limit itself to the powers it is given in the Constitution, thereby freeing individuals, families, and communities to solve their own problems, we will know we are on the right track.



Fortunately, a change in the climate of opinion on such basic questions has been under way for some time now. The debate today is very different than it was in the 1960s and 1970s. But there is a good deal more to be done before Congress and the courts are able to move in the right direction in any far‐​reaching way.



To continue the process, Congress should take the lead by engaging in constitutional debate in Congress, much as happened in the 19th century, thereby encouraging constitutional debate in the nation. That was urged by the House Constitutional Caucus during the 104th Congress. Under the leadership of House freshmen like J. D. Hayworth and John Shadegg of Arizona, Sam Brownback of Kansas, and Bob Barr of Georgia, together with a few more senior congressmen like Richard Pombo of California, an informal Constitutional Caucus was established in the “radical” 104th Congress. Unfortunately, the caucus has been moribund since then. It needs to be revived—along with the spirit of the 104th Congress—and its work needs to be expanded.



By itself, of course, neither the caucus nor the entire Congress can solve the problem before us. To be sure, in a reversal of all human experience, Congress in a day could agree to limit itself to its enumerated powers and then roll back the countless programs it has enacted by exceeding that authority. But it would take authoritative opinions from the Supreme Court, reversing a substantial body of largely post‐​New Deal decisions, to embed those restraints in “constitutional law”—even if they have been embedded in the Constitution from the outset, the Court’s modern readings of the document notwithstanding.



The ultimate goal of the caucus and Congress, then, should be to encourage the Court to reach such decisions. But history teaches, as noted above, that the Court does not operate entirely in a vacuum—that to some degree public opinion is the precursor and seedbed of its decisions. Thus, the more immediate goal of the caucus should be to influence the debate in the nation by influencing the debate in Congress. To do that, it is not necessary or even desirable, in the present climate, that every member of Congress be a member of the caucus—however worthy that end might ultimately be—but it is necessary that those who join the caucus be committed to its basic ends. And it is necessary that members establish a clear agenda for reaching those ends.



To reduce the problem to its essence, every day members of Congress are besieged by requests to enact countless measures to solve endless problems. Indeed, one imagines that no problem is too personal or too trivial not to warrant _federal_ attention, no less. Yet most of the “problems” Congress spends most of its time addressing—from health care to day care to retirement security to economic competition—are simply the personal and economic problems of life that individuals, families, and firms, not governments, should be addressing—quite apart from the absence of constitutional authority to address them.



Properly understood and used, then, the Constitution can be a valuable ally in the efforts of the caucus and Congress to reduce the size and scope of government. For in the minds and hearts of most Americans, it remains a revered document, however little it may be understood by a substantial number of them.



If the Constitution is to be thus used, however, the principal misunderstanding that surrounds it must be recognized and addressed. In particular, the modern idea that the Constitution, without further amendment, is an infinitely elastic document that allows government to grow to meet public demands of whatever kind must be challenged. More Americans than presently do must come to appreciate that the Framers, who were keenly aware of the expansive tendencies of government, wrote the Constitution precisely to check that kind of thinking and that possibility. To be sure, they meant for government to be our servant, not our master, but they meant it to serve us in a very limited way—by securing our rights, as the Declaration of Independence says, and by doing those few other things that government does best, as spelled out in the Constitution.



In all else, as discussed above, we were meant to be free—to plan and live our own lives, to solve our own problems, which is what freedom is all about. Some may characterize that vision as tantamount to saying, “You’re on your own,” but that kind of response simply misses the point. In America individuals, families, and organizations have never been “on their own” in the most important sense. They have always been members of communities, of civil society, where they could live their lives and solve their problems by following a few simple rules about individual initiative and responsibility, respect for property and promise, and charity toward the few who need help from others. Massive government planning and programs have upset that natural order of things—less so in America than elsewhere, but very deeply all the same.



Those are the issues that need to be discussed, both in human and in constitutional terms. We need, as a people, to rethink our relationship to government. We need to ask not what government can do for us but what we can do for ourselves and, where necessary, for others—not through government but apart from government, as private citizens and organizations. That is what the Constitution was written to enable. It empowers government in a very limited way. It empowers people—by leaving them free—in every other way.



To proclaim and eventually secure that vision of a free people, the Constitutional Caucus should reconstitute itself and rededicate itself to that end in the 109th Congress and at the beginning of every Congress hereafter. Standing apart from Congress, the caucus should nonetheless be both of and above Congress—as the constitutional conscience of Congress. Every member of Congress, before taking office, swears to support the Constitution—hardly a constraining oath, given the modern Court’s open‐​ended reading of the document. Members of the caucus should dedicate themselves to the deeper meaning of that oath. They should support the Constitution the Framers gave us, as amended by subsequent generations, not as “amended” by the Court’s expansive interpretations.



Acting together, the members of the caucus could have a major impact on the course of public debate in this nation—not least, by virtue of their numbers. What is more, there is political safety in those numbers. As Benjamin Franklin might have said, no single member of Congress is likely to be able to undertake the task of restoring constitutional government on his own, for in the present climate he would surely be hanged, politically, for doing so. But if the caucus hangs together, the task will be made more bearable and enjoyable—and a propitious outcome made more likely.



On the agenda of the caucus, then, should be those specific undertakings that will best stir debate and thereby move the climate of opinion. Drawn together by shared understandings, and unrestrained by the need for serious compromise, the members of the caucus are free to chart a principled course and employ principled means, which they should do.



They might begin, for example, by surveying opportunities for constitutional debate in Congress, then making plans to seize those opportunities. Clearly, when new bills are introduced, or old ones are up for reauthorization, an opportunity is presented to debate constitutional questions. But even before that, when plans are discussed in party sessions, members should raise constitutional issues. Again, the caucus might study the costs and benefits of eliminating clearly unconstitutional programs, the better to determine which can be eliminated most easily and quickly.



Above all, the caucus should look for strategic opportunities to employ constitutional arguments. Too often, members of Congress fail to appreciate that if they take a principled stand against a seemingly popular program—and state their case well—they can seize the moral high ground and prevail ultimately over those who are seen in the end to be more politically craven.



All of that will stir constitutional debate—which is just the point. For too long in Congress that debate has been dead, replaced by the often dreary budget debate. This nation was not established by men with green eyeshades. It was established by men who understood the basic character of government and the basic right to be free. That debate needs to be revived. It needs to be heard not simply in the courts—where it is twisted through modern “constitutional law”—but in Congress as well.



Before concluding, Mr. Chairman, let me leave the subcommittee with three basic recommendations, which I have discussed more fully in the _Cato Handbook_ I referenced above:



 **Conclusion**



America is a democracy in the most fundamental sense of that idea: authority, or legitimate power, rests ultimately with the people. But the people have no more right to tyrannize each other through democratic government than government itself has to tyrannize the people. When they constituted us as a nation by ratifying the Constitution and the amendments that have followed, our forefathers gave up only certain of their powers, enumerating them in a written constitution. We have allowed those powers to expand beyond all moral and legal bounds—at the price of our liberty and our well‐​being. The time has come to return those powers to their proper bounds, to reclaim our liberty, and to enjoy the fruits that follow.



BIOGRAPHICAL SKETCH OF ROGER PILON



Roger Pilon is vice president for legal affairs at the Cato Institute where he holds the B. Kenneth Simon Chair in Constitutional Studies and directs Cato’s Center for Constitutional Studies, which he founded in 1989. Prior to joining Cato he held five senior posts in the Reagan Administration, at the Office of Personnel Management, the State Department, and the Justice Department. A philosopher of law by profession, Mr. Pilon did his undergraduate work at Columbia University, earning a B.A. in philosophy in 1971. He did his graduate work at the University of Chicago, earning an M.A. in 1972 and a Ph.D. in 1979, both in philosophy. In 1988 he earned a J.D. from the George Washington University School of Law. He taught philosophy at the California State University at Sonoma in 1977 and philosophy of law at the Emory University School of Law from 1978 to 1979. From 1979 to 1980 he was a national fellow at the Hoover Institution on War, Revolution and Peace at Stanford University and from 1980 to 1981 an Institute for Educational Affairs fellow at the Institute for Humane Studies in Menlo Park, California. Mr. Pilon has published and lectured widely in the area of moral, political, and legal theory. He testifies often before Congress and is a frequent guest on television and radio programs discussing legal issues of the day. In 1989 the National Press Foundation and the Commission on the Bicentennial of the U.S. Con¬stitution presented him with the Benjamin Franklin Award for excellence in writing on the U.S. Constitution. In 2001 Columbia University’s School of General Studies awarded him its Alumni Medal of Distinction.



1 A biographical sketch is attached.



2 The Tenth Amendment states: “The powers not delegated to the United States by the Constitution, nor prohibited by it to the States, are reserved to the States respectively, or to the people.”



3 For a discussion of the Progressives’ approach to the Constitution, see Richard A. Epstein, “The Monopolistic Vices of Progressive Constitutionalism,” 2004–2005 _Cato Supreme Court Review 11_ (2005); Richard A. Epstein, _How Progressives Rewrote the Constitution_ (Cato Institute, 2006) (forthcoming).



4 See Arthur Harrison Cole ed., _Industrial and Commercial Correspondence of Alexander Hamilton_ 247 (A. M. Kelley, 1968).



5 Id.



6 Letter to Henry Lee, in 6 _The Writings of James Madison,_ at 81n. (Gaillard Hunt ed., G. P. Putnam’s Sons, 1906) (original emphasis).



7 Act of Feb. 12, 1794, 6 Stat. 13.



8 4 Annals of Cong. 170 (1794).



9 6 Annals of Cong. 1727 (1796).



10 Id. at 1724.



11 The Congress shall have Power To lay and collect Taxes, Imposts and Excises, to pay the Debts and provide for the common Defense and General Welfare of the United States; …”



12 4 Reg. Deb. 1632–34 (1828). Madison made a similar point on several occasions. See, e.g., James Madison, “Report on Resolutions,” in 6 _The Writings of James Madison_ 357 (Gaillard Hunt ed., G. P. Putnam’s Sons, 1900): “Money cannot be applied to the _general welfare,_ otherwise than by an application of it to some particular measure conducive to the general welfare. Whenever, therefore, money has been raised by the general authority, and is to be applied to a particular measure, a question arises whether the particular measure be within the enumerated authorities vested in Congress. If it be, the money requisite for it may be applied to it; if it be not, no such application can be made.” (emphasis in original). And Jefferson also addressed the issue. See, e.g., “Letter from Thomas Jefferson to Albert Gallatin” (June 16, 1817) in _Writings of Thomas Jefferson_ 91 (Paul Leicester Ford ed., New York, 1899): “[O]ur tenet ever was, and, indeed, it is almost the only landmark which now divides the federalists from the republicans, that Congress had not unlimited powers to provide for the general welfare, but were restrained to those specifically enumerated; and that, as it was never meant they should … raise money for purposes which the enumeration did not place under their action; consequently, that the specification of powers is a limitation of the purpose for which they may raise money.”



13 Charles Warren, _Congress as Santa Claus_ 32 (Arno Press, 1932).



14 H.R. 10203, 49th Cong., 2d Sess. (1887).



15 18 Cong. Rec. 1875 (1887).



16 _Kansas v. Colorado_ 206 U.S. 46, 89 (1907).



17 Contrast that with Congress’s enactment of the Gun‐​Free Schools Act of 1990 (18 U.S.C. § 922 (q)(1)(A) (1988 ed., Supp. V), which the Court found unconstitutional in 1995, holding for the first time in nearly 60 years that Congress had exceeded its authority under the Commerce Clause. _United States v. Lopez,_ 514 U.S. 549 (1995). In enacting the statute, Congress had not even bothered to cite its constitutional authority for doing so.



18 _The Nation,_ Aug. 9, 1900, p. 105.



19 See Robert S. Summers, Pragmatic Instrumentalism: America’s Leading Theory of Law, 5 _Cornell Law Forum_ 15 (1978).



20 Progressives did not limit their attention to economic regulation. In 1927, for example, we find Justice Oliver Wendell Holmes, the “Yankee from Olympus,” writing for the Court to uphold a Virginia statute that authorized the sterilization of people thought to be of insufficient intelligence. _Buck v. Bell,_ 274 U.S. 200 (1927). There followed in this country some 70,000 sterilizations. For an insightful discussion of the case and surrounding issues, see William E. Leuchtenburg, Mr. Justice Holmes and Three Generations of Imbeciles, ch. 1 in _The Supreme Court Reborn: The Constitutional Revolution in the Age of Roosevelt_ (1995).



21 _Buck v. Bell, supra_ note 20, is a good example, as is _Euclid v. Ambler Realty,_ 272 U.S. 365 (1926), which upheld a zoning ordinance involving a regulatory taking of property without compensation.



22 Thus, on “Black Monday,” May 27, 1935, in three 9–0 decisions, the Court invalidated the National Industrial Recovery Act and the Frazier‐​Lemke Act on mortgage moratoria and, in _Humphrey’s Executor v. United States,_ circumscribed the president’s power to remove members of independent regulatory commissions. For a discussion of this era, see Leuchtenberg, _The Supreme Court Reborn,_ supra note 20.



23 262 U.S. 1, 65–66 (1936).



24 7 U.S.C.A. 601 (1933).



25 49 Stat. 620 (1935).



26 301 U.S. 619, 640 (1937).



27 Id.



28 Id. at 641.



29 301 U.S. 619 (1937); see also _Wickard v. Filburn,_ 317 U.S. 111 (1942)./p>



30 See Randy E. Barnett, The Original Meaning of the Commerce Clause, 68 U. Chi. L. Rev. 101 (2000); Brief of _Amicus Curiae_ Cato Institute, _Jones v. United States,_ 529 U.S. 848 (2000) (visited Oct. 21, 2005).; Cf., Richard A. Epstein, The Proper Scope of the Commerce Power, 73 _Va. Law Review 1387_ (1987).



31 304 U.S. 104 (1938). For a devastating critique of the politics behind the _Carolene Products_ case, see Geoffrey P. Miller, The True Story of _Carolene Products,_ 1987 _Supreme Cato Review_ 397.



32 I have discussed that methodology in Roger Pilon, Foreword: Substance and Method at the Court, 2002–2003 _Cato Supreme Court Review_ vii. (2003).



33 See Bernard H. Siegan, _Economic Liberties and the Constitution_ (1980).



34 See Gary Lawson, Making a Federal Case Out of It: _Sabri v. United States_ and the Constitution of Leviathan. 2003–2004 _Cato Supreme Court Review_ 119 (2004).



35 Letter from Franklin D. Roosevelt to Rep. Samuel B. Hill (July 6, 1935), in 4 _The Public Papers and Addresses of Franklin D. Roosevelt_ 91–92 (Samuel I. Rosenman ed., 1938).



36 Rexford G. Tugwell, A Center Report: Rewriting the Constitution, _Center Magazine,_ March 1968, at 20. This is a fairly clear admission that the New Deal was skating not simply on thin ice but on no ice at all. For comments from the other side, see, e.g., Gary Lawson, The Rise and Rise of the Administrative State, 107 _Harvard Law Review_ 1231 (1994): “The post‐​New Deal administrative state is unconstitutional, and its validation by the legal system amounts to nothing less than a bloodless constitutional revolution;” Richard A. Epstein, Commerce Clause, _supra_ note 30, at 1388: “I think that the expansive construction of the [commerce] clause accepted by the New Deal Supreme Court is wrong, and clearly so.”



37 That was pretty much the view of Justice Holmes in his famous dissent in _Lochner v. New York,_ 198, U.S. 45 (1905). Declaring that the case was “decided upon an economic theory which a large part of the country does not entertain,” and adding that his “agreement or disagreement [with the theory] has nothing to do with the right of a majority to embody their opinions in the law,” Holmes proceeded to read out of the Constitution all economic substance: “a constitution is not intended to embody a particular economic theory, whether of paternalism and the organic relation of the citizen to the state or of laissez faire.” Id. at 75. But we find a similar view in many modern conservatives as well. Thus, Robert H. Bork speaks of the “two opposing principles” of what he calls the “Madisonian dilemma.” Our first principle, Bork says, “is self‐​government, which means that in wide areas of life majorities are entitled to rule, if they wish, simply because they are majorities. The second is that there are nonetheless some things majorities must not do to minorities, some areas of life in which the individual must be free of majority rule.” Robert H. Bork, _The Tempting of America_ 139 (Touchstone, 1990). That gets Madison exactly backward. Madison’s vision was that in wide areas of life individuals are entitled to be free simply because they are born free. Nonetheless, in _some_ areas majorities are entitled to rule because we have authorized them to rule, giving them powers “few and defined.”



38 John Locke, _The Second Treatise of Government,_ in _Two Treatises of Government_ (1960) (1690).



39 I have discussed this issue more fully in Roger Pilon, Foreword: Can Law this Uncertain Be Called Law? 2003–2004 _Cato Supreme Court Review_ vii (2004).



40 For my critique of an opinion by Justice Anthony Kennedy distinguishing four “levels” of review, _Turner Broadcasting System v. FCC,_ 512 U.S. 622 (1994), see Roger Pilon, A Modest Proposal on “Must‐​Carry,” the 1992 Cable Act, and Regulation Generally: Go Back to Basics, 17 _Hastings Comm/​Ent. Law Journal_ 41 (1994).



41 That is arguably what happened in _McConnell v. FEC,_ 124 S. Ct. 619 (2003), upholding the McCain‐​Feingold Campaign Finance Act, 116 Stat. 81 (2002), which President George W. Bush signed while saying it was unconstitutional. See Eric S. Jaffee, _McConnell v. FEC:_ Rationing Speech to Prevent “Undue Influence,” 2003–2004 _Cato Supreme Court Review_ 245 (2004).



42 See Robert J. Reinstein, _Completing the Constitution: The Declaration of Independence, Bill of Rights, and Fourteenth Amendment,_ 47 _Temple Law Review_ 361 (1993). In 1833 the Court had ruled that the Bill of Rights applied only against the government created by the document (the U.S. Constitution) to which it was appended. _Barron v. Mayor and City Council of Baltimore,_ 32 U.S. 243 (1833).



43 Warren, _Santa Claus, supra_ note 13, front page, citing only to 22d Cong., 1st Sess.



44 Adam Smith, _An Inquiry Into the Nature and Causes of the Wealth of Nations_ (1776).



45 Roger Pilon, Congress, the Courts, and the Constitution, ch. 3, in _Cato Handbook on Policy_ (2005).
"
"Conservative politicians have long declared there is no alternative to capitalism. Many of capitalism’s cruelties, from housing crises and crumbling public amenities to increasingly precarious forms of employment, are most visible in towns and cities. But it’s also in these places that new movements are emerging and rebuilding politics from the bottom up. In cities such as Barcelona, Amsterdam, Berlin and Naples, local activists are defending human rights and public services against a rising tide of anti-immigrant xenophobia and fiscal austerity. We call these urban movements “municipalism”. By achieving small victories around the world, municipalist movements are proving that there is another way of doing politics – one that begins in the places closest to us. It’s thanks to this movement that someone such as me, a woman from a working-class family who began my political career as a housing activist, can today govern a city such as Barcelona. A tide of municipal movements connects cities across the world, creating networks of alliances and shared objectives. Together, we have put pressure on our national governments and demanded greater powers to fight gentrification, increase the stock of affordable housing, and safeguard our collective right to the city. In Barcelona we have curbed the Airbnb rentals that drive up demand for a limited housing supply, and have repossessed unused housing owned by banks. The city of Berlin has pledged to freeze rents for five years in an effort to halt gentrification. New York City has promised to divest $5bn from fossil fuels and to sue oil companies for their contribution to global warming. These small victories show that alternatives to our dominant economic system are within reach – and that cities are a key part of this future. This doesn’t mean urban politics is without challenges. There’s a risk that we’ll be reduced to resolving quotidian problems and fall short of our ambition to confront systemic crises. Though cities will be central to the transition towards a fossil fuel-free future, the climate emergency doesn’t respect borders, and demands networked, international solutions. For this reason, it’s crucial that the climate emergency declarations made in cities including Barcelona, Amsterdam and New York transcend mere symbolic gestures – and that we hold our national leaders to account. What does municipalism have to do with the future of Europe? Everything. Europe has been immersed in a crisis of legitimacy for the past decade. The EU has functioned as a single market, but not as a joint democratic project. It has suffered from a lack of citizen participation, with a distanced parliament and a cruel migration policy that has violated human rights and betrayed the principles of solidarity agreed by Europe’s leaders in the wake of the second world war. Part of our work in Barcelona has been to develop an approach to migration that protects the rights of residents in our city, and their access to public services, regardless of their immigration status. We firmly believe that border crossings should be places of meeting and welcome, not of death. Europe can only be strong if it is capable of reinventing itself from the bottom up. To secure its future, Europe must recommit itself to its founding values: the guarantee of human rights and democracy. Today, the politics of hate and xenophobia are the main threats to the values that the EU once espoused. We urgently need to avert their spread and build societies that are fair, inclusive and diverse. The municipal movements in cities across Europe are already building networks of solidarity that will be essential in fighting the political forces threatening the union, and in resisting the siren call of the far right. It is my deep conviction that there is no greater power than that which is built by people working together at the grassroots, and that our neighbourhoods, towns and cities are the only places where this can happen. • Ada Colau is the mayor of Barcelona"
"Sir David Attenborough has urged governments to ban deep sea mining, following a study warning of “potentially disastrous” risks to the ocean’s life-support systems if it goes ahead. The study, by Fauna and Flora International (FFI), warns proposed plans to mine the seabed could cause significant loss of biodiversity, disruption of the ocean’s “biological pump”, and the loss of microbes important for storing carbon. The process, requiring machines operating thousands of metres under the sea, could also create plumes of sediment that smother areas far from the mining sites and kill wildlife.  Dozens of exploratory licences, two of which are sponsored by the UK, have already been granted for huge tracts of the sea bed, ahead of a race to mine commercially for ores and minerals such as copper, used in mobile phones and batteries. But the rules to govern the responsible exploitation of this global resource are not finalised – they are expected to be completed at a meeting in July at the UN International Seabed Authority. Attenborough, the vice president of FFI, said deep sea mining could create a “devastating series of impacts” threatening processes critical to the health and function of the oceans, and called on governments to be guided by scientists. “Fauna & Flora International is calling on global governments to put in place a moratorium on all deep sea mining – a call I wholeheartedly support,” Attenborough said. In a foreword to the report, Attenborough said it was “beyond reason” for countries to consider the destruction of deep sea places before they have understood them or the role they play in the health of the planet. Attenborough said: “The rush to mine this pristine and unexplored environment risks creating terrible impacts that cannot be reversed. We need to be guided by science when faced with decisions of such great environmental consequence.” FFI warned that human activity was already putting a huge strain on the oceans, which have absorbed a third of our carbon emissions and 93% of the extra heat trapped by the rising concentration of greenhouse gases. Oceans are becoming more acidic because of the carbon dioxide dissolving into them, fisheries are under pressure as a result of over-exploitation and there are hundreds of huge “dead zones”, it said. Pippa Howard, director at FFI and lead author of the report, called for a moratorium on deep sea mining. She said: “The conclusions we have come to after extensive study could hardly be more troubling. “From methane release to disruption of the ocean’s life-support systems and the destruction of unstudied ecosystems, the risks of deep sea mining are numerous and potentially disastrous.” Louisa Casson, of Greenpeace’s Protect the Oceans campaign, said the UK government’s holding of exploration contracts for deep sea mining was at odds with its position as a “global ocean champion”.Casson said: “The UK government now has a choice to make: listen to industry and press ahead with this dangerous new practice, or listen to scientific warnings, public concern and the creator of Blue Planet himself and ban deep sea mining.” A government spokesman said: “The UK continues to press for the highest international environmental standards, including on deep sea mineral extraction. “While we have sponsored two exploration licences, these allow only for marine research to understand the effects of deep sea mining. “We will not issue a single exploitation licence without a full assessment of the environmental impact.” • This article was amended on 21 May 2020. It is Louisa not Louise Casson of Greenpeace."
"
Share this...FacebookTwitterThe days when Europe considered the rest of the world its colony and servant are over. But some EU bureaucrats and bossy greens obviously haven’t grasp that yet. Hat tip: Manfred Messmer here.
A group of EU climate commissars lead by Connie Hedegaard once got the idea they could boss the rest of the world, and impose a CO2 reduction scheme on the world’s airlines. Read here, background.
China and India, once ruthlessly exploited by European colonial rule, are sending tough messages back to Brussels: If you think you can still boss us around, then you’ve got another thing coming.
Al Jazeera reports on news which the European mainstream media are too embarrassed to make public in Europe. The EU’s unilateral move to charge for carbon emitted by flights in and out of Europe is escalating an international row and threatens to turn into an all out global trade war – one that Europe would certainly lose big time.
India is now following China’s lead and is set to ask its airlines not to take part in the European Union emissions trading scheme. In February China barred its airlines from participating in the European emissions-reduction scheme. Other powers like the USA and Russia are also joining in with China and India.
Al Jazeera writes that an Indian official “told Reuters news agency that India will soon ask local airlines not to share emissions data with the bloc or buy any carbon credits.” And the official added:
‘We have lots of measures to take if the EU does not go back on its demands. We have the power of the economy, we are not bleeding as they are,’ the government official said, adding that Europe’s position would harm its own economy and airlines. ‘The questions is, are you (EU) provoking the world into a trade war?’ the official said.”
China has already suspended the purchase of 10 more Airbus jets, and India has left that option open. China and India are important growth markets for Airbus. Cancelling orders for dozens of planes would deal a crushing blow for Europe’s aviation industry. Al Jazeera writes:
European planemaker Airbus has a 73 per cent share of the commercial plane market in India. It has orders for more than 250 planes with IndiGo, Go Air and Kingfisher Airlines, making fast-growing India a crucial growth market. Foreign governments say the EU is exceeding its legal jurisdiction by charging for an entire flight, as opposed to just the part covering European airspace.”
The European Commission, however, claims that all this is necessary to rescue the climate from a certain Armageddon – never mind the data.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




To send a signal to show it means business, India disrupted the flight schedules of many European airlines to let them know “how disruptive a dispute with the country could be.”
Al Jazeera quotes the Indian official:
If things continue like this, then European airlines will be forced to avoid flying over India and go over the Indian Ocean and the Bay of Bengal. That’s not viable for them. They won’t have fuel to do that.”
The European Voice reminds readers of the gravity of the measures now being taken by China:
What we see today is that the Chinese authorities are blocking airlines from placing firm orders with Airbus. Airlines are likely to now consider the competition. And that could destroy years of efforts to bring Airbus to a market-leading position in China.”
And reminds the EU government that the European Trading Scheme for taxing CO2 is misguided policy:
It is time for European politicians to see the facts. Over the past decade, aviation achieved 45% growth while consuming only 3% more fuel. That is the best evidence for our industry’s prolonged and continuing efforts to reduce our environmental impact in all areas, and to allow for sustainable growth.”
I can’t imagine what Europe is thinking here. Are they dreaming that they can treat the world like its colony to boss around? Do the climate commissars really believe they can get away with this?
Clearly Europe is trying to fool the world with the climate climate issue in order to get back to the good old days of colonialism – when it bossed everyone around.
These climate commissars and green Napoleons are about to learn, however, that their days of running colonies are over.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMore bad news for the catastrophe-insisting climate alarmists who claim 95% of climate change is due to 0.04% trace gas CO2. Yet another prominent scientist, this one a big-league heavy hitter, has expressed serious doubt on CO2’s sole dominance during a recent interview. The once much ballyhooed consensus keeps falling apart.

Professor Wolfgang Baumjohann, Director of the Institute for Space Research of the Austrian Academy of Sciences. Graz, Austria. (Photo credit: Sissi Furgler)
Professor Wolfgang Baumjohann, Director of the Institute for Space Research of the Austrian Academy of Sciences, one of the world’s heavyweights in physics, gave an interview with the online Austrian flagship daily Der Standard here. Hat-tip: http://kaltesonne.de/.
The interview was in part to get his opinion on Fritz Vahrenholt’s and Sebastian Lüning’s bestselling skeptic book Die kalte Sonne, which has been creating a row within the scientific community throughout Germany and Europe since it was released earlier this month.
When asked about the role of solar activity on the Earth’s climate and whether Vahrenholt’s claims were nonsense, Baumjohann said:
There’s not a serious scientist claiming that CO2 emissions can be neglected. However, one cannot say that it’s the sole reason for global warming when it is obvious that increased solar activity correlates. One has to take that into account. When the solar dynamo runs more strongly, then a warming is logical.”
and
One seriously has to separate all the various cycles and make comparisons to see just how strongly solar activity impacts the climate.”
Actually, Vahrenholt and Lüning did precisely just that in their book. And the data that is available now show a clear, indisputable correlation. Here Baumjohann would likely have used much bolder words had he read that section of the book. Or maybe he’s just being diplomatic.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On the subject of cosmic rays and weakening magnetic fields (h/t: DirkH) Baumjohann is completely open to Svensmark’s theory and does not disguise that the theory is entirely plausible and just comes out and says that they directly impact the Earth’s climate (emphasis added):
Indeed, more cosmic rays and more solar particles would hit the top of the atmosphere – and this would have direct implications for our weather. We can’t tell yet whether these will be positive or negative consequences. Long term, climatic changes depend on cosmic rays and their influences on cloudiness.”
This is as major an endorsement as you’ll ever get!
We’ll remind readers that Vahrenholt in no way neglects CO2 as a factor. He is being chastised for cutting it down to size as a climate driver, saying that it is likely responsible for up to half of last century’s warming. But he dismisses that we are headed for an imminent catastrophe.
Note how Baumjohann contradicts Max Plank Institute Director Jochem Marotzke, who never even bothered to read Vahrenholt’s book, and who remains stuck on pre-AR4 science, i.e. focusing only on total solar irradiance and thus insisting the sun has not played any important role over the last century.
Baumjohann adds:
Us humans certainly know what life-giving energy the sun holds. Everyone feels it in the springtime. That’s a really personal experience.”
The latter part of the interview looks at the Earth’s magnetic field and the financing of scientific institutes.
Baumjohann’s Career Summary here
 
Share this...FacebookTwitter "
"

And people thought I was being impertinent when I wondered in these pages whether or not global warming actually _reduced_ the impacts of Superstorm Sandy.   
  
  
Now comes this abstract from a paper by Elizabeth Barnes and colleagues just published in the _Proceedings of the National Academy of Sciences_ :   




Superstorm Sandy ravaged the eastern seaboard of the United States, costing a great number of lives and billions of dollars in damage. Whether events like Sandy will become more frequent as anthropogenic greenhouse gases continue to increase remains an open and complex question. Here we consider whether the persistent large‐​scale atmospheric patterns that steered Sandy onto the coast will become more frequent in the coming decades. Using the Coupled Model Intercomparison Project, phase 5 multimodel ensemble, we demonstrate that climate models consistently project a decrease in the frequency and persistence of the westward flow that led to Sandy’s unprecedented track, implying that future atmospheric conditions are less likely than at present to propel storms westward into the coast.



Just because global warming enthusiasts are quick to link all weather disasters to climate changes from human greenhouse gas emissions, doesn’t mean they really are. In fact, just the opposite may be the case—global warming may be acting to _avert_ some weather disasters. I know, I know, I am being impertinent again.
"
"**A North East airport has warned it could take up to four years before its passenger numbers return to pre-coronavirus levels.**
About 5.5m people flew through Newcastle International Airport in 2019, but disruption caused by Covid-19 has seen nearly all flights cancelled.
Passengers numbers were currently ""2 to 3%"" of normal levels, bosses said.
Charter flights have been scrapped with only a small number of essential business routes operating.
""In the original lockdown we had zero passengers through the airport,"" Graeme Mason, planning and corporate affairs director, said.
""It crept up to about 20% later in the summer but during the second lockdown we've been running 2 to 3% of what we'd have expected in a November period.
""It's going to be a long road to recovery, several years - possibly three or four years - to get back to passenger numbers we had in 2019.""
The airport hopes a scheme reducing the isolation period for travellers will aid its recovery.
From 15 December people arriving in England from abroad will be able to shorten their quarantine by more than half if they pay for a Covid test after five days.
The tests from private firms will cost between Â£65 and Â£120.
Mr Mason said he believed it would ""help encourage people to travel"".
_Follow BBC North East & Cumbria on _Twitter _,_Facebook _and_Instagram _. Send your story ideas to_northeastandcumbria@bbc.co.uk _._"
"
Guest Post by Willis Eschenbach
Today I thought I’d discuss my research into what is put forward as one of the key pieces of evidence that GCMs (global climate models) are able to accurately reproduce the climate. This is the claim that the GCMs are able to reproduce the effects of volcanoes on the climate.
One of the most-cited papers in this regard is the Soden et al. study of the eruption of the Philippine volcano, Mt. Pinatubo. Their study is entitled Global Cooling After the Eruption of Mount Pinatubo: A Test of Climate Feedback by Water Vapor, available as a PDF. [hereinafter “Soden08”]

Figure 1. A NASA graphic showing satellite measurements of the spread of ash and aerosols from Mt. Pinatubo. In the first month (top right), the volcanic emissions had circled the earth (red area, Philippines on right). In six months, they were fairly evenly spread around the planet. Graphic Source NASA
The eruption of Mt. Pinatubo on 15 June 1991 injected aerosols and volcanic ash high into the atmosphere. This measurably changed the climate for a couple of years. It provided a wealth of observational data, as well as a good test for climate models.
Regarding the match between models and volcanic reality, the authors of Soden08 say (emphasis mine):


Because the transient response of the model depends on both its sensitivity and the external radiative forcing imposed on it, we first demonstrate the consistency between the model-simulated radiative forcing with that measured by satellites (Fig. 1 [of Soden08]). Both the observations and model simulations yield very similar reductions in the absorbed solar or shortwave (SW) radiation, which are nearly twice as large as the reduction in emitted LW radiation, a net loss of radiative energy that cools the surface and lower troposphere.

Parenthetically, when a scientist starts talking about “consistency” between observations and model results, I check my wallet. Consistency? What units are used to measure that? But I digress, back to my question.
How do the models actually stack up against the observations shown in their paper, in the Figure 1 they mention?
Before I get to the question and to their Figure 1, a bit of a diversion. For reasons that will become clear shortly, I want to make a distinction between simple negative feedback, and a governor. A governor is a system that keeps a heat engine running at a (relatively) constant speed. The most common example of a governor in daily life is the “cruise control” on a car. It keeps the car going at the same speed regardless of uphill and downhill grades.
Negative feedback is like increasing wind resistance on an accelerating car. Wind resistance slows the car down. Eventually at some speed wind resistance balances the energy pushing the car, and the car goes no faster. It balances out at a certain speed, where increasing feedback matches energy input. Fig. 2 shows how a negative feedback and a governor respond to increasing forcing.

Figure 2. A comparison of the actions of a governor and negative feedback. Qualitative only, numbers are nominal values.
Note that in response to changed forcings, the governor brings the value back to the desired equilibrium value. The governor does this by producing what is called “overshoot”. “Overshoot” is where the action of the governor drives the system past equilibrium (represented in Fig. 2 by the thick horizontal line at zero). This gives the governor the ability to recover quickly from perturbations.
Simple negative feedback, on the other hand, cannot maintain a specified speed. All it can do is reduce the size of a speed increase or a decrease . It cannot produce overshoot. As shown in the right side of the graph, simple negative feedback can create what appears to be a controlled equilibrium situation. This happens when feedback balances forcing so there is no change in speed.
However, this balance of negative feedback is not stable — any change in the forcing will lead to a new equilibrium speed. A governor, on the other hand, maintains the same speed despite changes in forcings.
Overshoot is necessary to control a “lagged” system such as the climate. This is a system where response to inputs is not instantaneous. I have argued elsewhere that the earth has at least one governor system incorporating overshoot which actively controls the temperature. For our current purposes, please take note of the very different shapes of the response curves of negative feedback and of a system with a governor.
With that as prologue, let us now look at the Soden08 Figure 1.

Soden08 Figure 1. ORIGINAL CAPTION. Comparison of the observed anomalies in absorbed SW (top) and emitted LW (bottom) radiative fluxes at the top of the atmosphere from Earth Radiation Budget Satellite observations (black) and three ensembles of GCM simulations (red). The observed anomalies are expressed relative to a 1984 to 1990 base climatology, and the linear trend is removed (30). The results are expressed relative to the pre-eruption (January to May 1991) value of the anomaly and smoothed with a 7-month running mean (thick line). The GCM anomalies are computed as the difference between the control and Mount Pinatubo simulations for each ensemble member. Both the model and observed global averages are from 60N-60S due to the restriction of observed data to these latitudes. 
This looks good at first blush, and the authors say that the GCM results (red) are “consistent” with the observations. However, closer examination reveals issues. What struck me immediately about their results is that the actual observations of both the shortwave and longwave anomalies show clear signs of overshoot. After being knocked down by the volcano, after 1994 they both come back higher than pre-eruption. This worked to quickly restore the pre-disturbance state.
None of the GCMs show this sign of overshoot. Instead, the GCMs gradually drift back to the pre-eruption anomaly value of zero. This is similar to the negative feedback balance shown in Fig. 2. Unlike the overshoot in the observations, the GCM results flatline after 1994. While this doesn’t prove anything, it is another piece of evidence that the GCMs are missing some basic climate mechanisms.
How Much Total Difference did Pinatubo Make?
There is a second problem with the Soden08 model results, one which is less theoretical and more mathematically demonstrable. This has to do with the cumulative energy deficit from the volcanic eruption.
As you can see in the Soden08 Fig. 1 above, after the eruption the amount of incoming solar energy (SW, or shortwave radiation) dropped about twice as much as outgoing energy (LW, or longwave radiation). As a result, after the volcano there was a global net energy deficit. There was less energy entering the system than there was leaving the system. This deficit continued for some months.
The total magnitude of this deficit is an important indicator of the overall impact of the Pinatubo eruption on the climate system. It is a basic measurement of the phenomenon, answering the fundamental first question everyone asks — how big is it? We can investigate the total magnitude of the volcanic disturbance by looking at the cumulative energy deficit created by the eruption.
To do that, I first digitized the data in the Soden08 Figure 1. The data is available here as an Excel worksheet. Results in the worksheet for the GCMs are the average of the three runs shown in their Figure 1.
I then calculated the net energy balance (solar energy absorbed minus longwave energy emitted to space) for each month. I then started a cumulative total at zero, and added each month’s net energy balance to the cumulative total. This cumulative total shows how far out of balance the system was each month.
The resulting curve shows the size of the total disturbance caused by the volcano, as well as showing the path of recovery. The units are Watt-months/metre^2 (for convenience, since the data is monthly). For example, a two-Watt/m2 deficit that continued for three months would give a cumulative deficit of six Watt-months/m2. Fig. 3 illustrates the problem with the GCM results.

Figure 3. Cumulative effect of the Pinatubo eruption. Red line shows data from the average of the models (GCMs) shown in Soden08 Figure 1 above. Blue line shows data from the ERBS observations shown in Soden08 Figure 1 above. 
So what does this result mean? Well, among other things it means that in this case the general “first glance” similarity of observations and models is misleading. A closer examination shows that the models did a very poor job at being consistent with the observations.
• The models greatly underestimated the magnitude of the peak impact of the eruption.
• They showed recovery starting much sooner than the observations show.
• They greatly underestimated the speed of the recovery once it started.
• They greatly underestimated the total impact of the eruption.
To put some numbers on those statements:
• The peak energy deficit in the observations was -42 Watt-months/m^2. This is more than twice the -18 Watt-months/m2 in the model results.
• The models show recovery starting about a year and a half after the eruption. The observations show about two and a half years before things turn around.
• The observed speed of the recovery is more than five times that of the modelled speed of recovery (post-1994 linear trends).
• The total impact of the eruption on the global energy balance is given by the area underneath the curves. Alternatively, it can be expressed as the average value of the energy deficit over the time period of the curves (1991-1995). The observed average energy deficit over that period is -21 Watt-months/m2. Again, this is more than twice the models’ estimate of -10 Watt-months/m2.
My conclusion? These models are not doing a credible job of representing Pinatubo’s effect on the global energy balance. The total size of the disturbance is a fundamental, basic measure of the accuracy of a simulation. Both the observed peak energy deficit and the observed total impact of the volcano were more than double the model results.
An error where the raw observed size of the phenomenon is more than double the model estimate? That sounds like a government project. Bad model, no cookies. Clearly, there is some fundamental problem with their simulation — they are showing the eruption of Mt. Minitubo, the half-size model.
When models show that kind of error in the raw size, peak size, and timing of the effects of a volcanic eruption … are the models “consistent” with the observations? Would you pay good money for a model that gave that size of error?
In addition, model results do not show the observed “overshoot” that leads to a speedy recovery from a disturbance. The results of this observed overshoot are seen in the difference between modelled and observed recovery rates. Driven by overshoot, the observed recovery rate is five times that shown by the models.
In short, I see no support for their implied claim that the models are an accurate representation of reality. Far from that, I don’t even see support for their vague claim of “consistency”. Their idea of consistency reminds me of the line from the old song, “She could easily pass for forty-threeeeee … in the dusk … with the light behind her.”
Their model results are inconsistent with observations. I do not see the Soden08 study as support for the idea that GCMs can successfully model the changes from volcanic eruptions.
Regards to all,
w.
PS – A final note for clarification. As the title suggests, the main thrust of Soden08 is concerned with whether the models perform better if they include a water vapor positive feedback. It finds that the GCMs do in fact perform better if there is positive feedback from a warming.
My analysis of the model results and observational data above is completely separate from the Soden08 analysis. We are simply using the same results and data. I make no claim that their analysis is right or wrong. In fact, I strongly suspect they are right, that the models do perform better if there is positive feedback from warming, although I have my own ideas what that demonstrates. But that is distinct from my analysis above.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e873dd058',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterA recent study by A.R. Agatova et al investigated glacier dynamic and climatic variations in the southeastern part of the Russian Altai during the last 7000 years and show distinct natural climatic changes had occurred.
Not surprisingly, these changes coincide with changes occurring at other parts of the globe, and so add to the massive weight of evidence refuting the claim that climate fluctuations on centurial in millennial scales are regional phenomena and occur over a small temperature range.
The scientists exhumed organic material and carried out radiocarbon dating on wood remains from buried dead trees at the upper tree limit, and from rock glaciers on trough slopes from six glacial valleys in the North Chuya Range, SE Altai. They compiled an extensive dataset, which form the basis for understanding the relative magnitudes and timing of the most important glacial and climatic events of SE Altai.
Their conclusion:
New data refute the traditional concept of the Russian Altai Holocene glaciations as a consecutive retreat of the late Würm glaciers and argue their complete degradation at the head of trough valleys at least 7000 cal. years BP.”
Moreover, they identified three periods of glacial advances: from 4900 to 4200 cal. years BP (Akkem stage), from 2300 to 1700 cal. years BP (Historical stage) and in the 13th–19th centuries (Little Ice Age (LIA) or Aktru stage). The coincident extremes of lowering temperature and increasing precipitation during the Akkem stage led to abrupt glacier advances and forming of the most remote moraine complexes downstream in the valleys.
The authors also write that in addition to the radiocarbon data, the time limits of the Historical stage were defined more precisely using dendrochronological and archaeological data from Scythian burials of Pazyryk culture in SE Altai.
Repeated forest regrowth in the presently glaciatiated area indicates significant retreat or even complete glacier degradation during interstage warming. The decreases of glacier length in the following stages argues for intensification of aridity in the SE Altai during the second half of the Holocene. The thermal minimum in the middle of 19th century, the greatest in the last millennium, did not positively influence the mass balance of glaciers, which also supports this conclusion.”
So much for bogus claim that climate was more or less stable before man populated and developed.
Also strong glacial variations in the Alps as well


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Interestingly, Prof. em. Dr. Gernot Patzelt, University of Innsbruck, made a presentation at the International Climate and Energy Conference in Munich late last year, which the European Institute for Climate and Energy has just released.

In his presentation, Dr. Patzelt also reveals glacier advances and retreats in the Alps throughout the Holocene, thousands of kilometers away from the Russian Altai. Forests existed at elevations that were higher than today – in areas that are presently covered by glaciers.
At the 12:22 mark, Patzelt summarizes the data of the three glaciers examined in the Alps and presents a temperature reconstruction. His conclusion at the 13:42:
Over the last 10,000 years it has been warmer than today 65% of the time. Our current climate does not in any way show an anomaly in temperature development. That’s an important result.”

Top curve shows the reconstructed temperature of the Alps over the Holocene. Dark-shaded areas show warm periods. (Snipped from Patzelt’s presentation at the 13:30 mark).
Clearly from his chart one sees the millennial cycles that coincide with documented solar activity. And as Dr. Sebastian Lüning showed yesterday in Chicago, we are not talking about fluctuations of a couple of tenths of a degree, but of fluctuations over 1, 2 or even 3°C.
At 14:50 Patzelt shows the Greenland ice core reconstruction for comparison.
Clearly there are natural forces at work. Claims that natural factors retired 100 years ago are simply absurd.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIt used to be that climate skeptics in Germany never got interviews with major media outlets. It was a sort of unwritten rule.

Headline: “The Temperature will rise only one degree”
But now that seems to be changing – ever since the release of Prof. Fritz Vahrenholt’s and Sebastian Lüning’s skeptic book, Die kalte Sonne, last February. Although still lopsided, the skeptics are getting heard more and more. This provides some hope that Germany is beginning to return to a balanced discussion and environmental tolerance.
Indeed this is very important because history shows that Germany always flourished and made great contributions to the world when open discussion of ideas was allowed. And in times when this was not the case, Germany and the world suffered – at times immensely.
The latest is an interview with Fritz Vahrenholt appearing in Germany’s leading financial daily, the Handelsblatt.
The following are the questions and answers, in summary:
HB: In your book, you say the climate catastrophe is not going to take place. Why?
FV: The temperature increase since 1850 is nothing unusual. Such changes have occurred time and again in history.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




HB: Is that the case this time?
FV: Yes, because of strong solar activity. Now that the sun has been weak, we have not had any warming in 12 years.
HB: So Co2 is not the culprit?
FV: To some extent it is, maximum 50%. The rest is due to natural factors, i.e. the sun and oceans.
HB: Will temperatures rise this century?
FV: Not more than 1°C, i.e. far below the 4 – 5°C that often gets mentioned.
HB: But natural catastophes are increasing. USA is having a record drought.
FV: Contrary to what is claimed, hurricanes and storms are not increasing. Hurricanes are actually on the decline.
HB: Then why is the reinsurer Munich Re warning of catastrophes?
FV: Because an elevated fear of storms means more policies can be sold. Also it makes it easier to ram through new energy policy.
HB: But a majority of scientists are warning of climate change.
FV: There are also thousands of scientists who disagree. Let’s recall that agreeing with climate change makes it much easier to get funding.
HB: So we do not need alternative energies?
FV: Of course we need them. But we have have to develop them in an sensible way, and they should not trump all policy decisions.
 
Share this...FacebookTwitter "
"

Over at the Huffington Post, enviro activist Laurie David complains today that the media is willing to give some ink to my colleague, Prof. Pat Michaels, on the issue of global warming. One of her main complaints is that Pat is nobody (scientifically speaking) and the fact that he has ""(finally) gotten a paper published"" does not qualify him as an expert.   
  
And Laurie has published peer reviewed papers ... where? Anyway, Prof. Laurie has nothing substantive to say about the arguments in the Michaels paper that sent her around the bend.   
  
It's truly a wondrous thing when Hollywood celebs with no scientific training feel free to attack the credentials of academics with Ph.Ds in their (momentary) field of interest. She did a similar smear-job on MIT Prof. Richard Lindzen. More such attacks are likely to come.   
  
Regardless, Laurie's ad hominem attack is bogus. Pat is in fact one of the most widely published climate change experts in the peer-reviewed literature. If she had ever bothered to actually read the U.N.'s ""state of the science"" IPCC reports she claims to have digested, she would have seen multiple references therein to his work.   
  
But for the record, Pat's peer-reviewed papers and presentations since 2000 follow:   




Michaels, P. J., P. C. Knappenberger, and R E. Davis, 2006. Sea-surface temperatures and tropical cyclones in the Atlantic basin, _Geophysical Research Letters_ , **33** , L09708, doi:10.1029/2006GL025757.   
  
Davis, R.E., Michaels, P.J., Knappenberger, P.C., 2006. Global warming and Atlantic hurricanes. 2006 Annual Meeting of the Association of American Geographers, Chicago, IL, March 7-11.   
  
Michaels, P.J., Knappenberger, P.C., and C. Landsea, 2005. Comments on “Impacts of CO2-Induced Warming on Simulated Hurricane Intensity and Precipitation: Sensitivity to the Choice of Climate Model and Convective Scheme”. _Journal of Climate_ , **18** , 5179-5182.   
  
Michaels, P.J., Knappenberger, P.C., and R.E. Davis, 2005. Sea surface temperature and tropical cyclone intensity: Breaking the paradigm, 15th Conference on Applied Climatology, American Meteorological Society, Paper No. 2.4, Savannah, GA, June 19-23.   
  
Davis , R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2005. Changing Heat Wave Sensitivity in U.S. Cities, 15th Conference on Applied Climatology, American Meteorological Society, Paper No. 4.6, Savannah, GA, June 19-23.   
  
Davis, R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2005. Evidence of Adaptation to Increasing Heat Wave Intensity and Duration in U.S. Cities. 17th International Congress on Biometeorology, Garmisch-Partenkirchen, Bavaria, Germany, September 5-9.   
  
Davis, R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2004. Changing Heatwave Mortality in U. S. cities. _Proc. 14th Appl. Clim. Conf_., Seattle, WA, paper no. J8.4.   
  
Davis, R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2004. Seasonality of climate-human mortality relationships in U.S. cities and impacts of climate change. _Climate Research_ , **26** , 61-76.   
  
Davis, R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2004. Heat Wave Mortality in Large U. S. cities. _Proc. 16th Conf. Biometeorol. Aerobiol. and the 17th ISB Cong. Biometeor_., Vancouver, British Columbia, WA, paper no. 6A.3.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2004. Presentation of “Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2003. Decadal changes in summer mortality in the U. S. cities, _International Journal of Biometeorology_ , **47** , 166-175,” to the Association of American Geographers in accepting the 2004 “Paper of the Year” award from the Climate Specialty Group.   
  
Douglass, D.H., Pearson, B.D., Singer, S.F., Knappenberger, P.C., and P.J. Michaels, 2004. Disparity of tropospheric and surface temperature trends: New evidence. _Geophysical Research Letters_ , **31** , doi:10.1029/2004GL020212.   
  
McKitrick, R., and P. J. Michaels. 2004. A Test of Corrections for Extraneous Signals in Gridded Surface Temperature Data. _Climate Research_ , **26** , 159-193.   
  
Michaels, P.J., McKittrick, R., and P.S. Knappenberger, 2004. Economic Signals in Global Temperature Histories. 14th Appl. Clim. Conf., Seattle, WA, paper no. J1.1.   
  
Michaels, P.J., Knappenberger, P.C., Frauenfeld, O.W., and R.E. Davis, 2004. Trends in Precipitation on the Wettest Days of the Year across the Contiguous United States. _International Journal of Climatology_ , **24** , 1873-1882.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2003. Decadal changes in summer mortality in the U. S. cities, _International Journal of Biometeorology_ , **47** , 166-175.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2003. Winter Mortality, Climate, and Climate Change in U.S. Cities. 37th Canadian Meteorological and Oceanographic Society Congress, Ottawa, Ontario, Canada.   
  
Davis, R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2003. Changing heat-related mortality in the United States. _Environmental Health Perspectives_ , **111** , 1712-1718.   
  
Douglass, D.H., Clader, B.D., Christy, J.R., Michaels, P.J., and D.A. Belsley. 2003. Test for harmful collinearity among predictor variables used in modeling global temperature. _Climate Research_ , **24** , 15-18.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2002. On seasonal differences in weather-related mortality trends in the United States. _Proc. 13th Appl. Clim. Conf_., Portland, OR, 326–330.   
  
Michaels, P.J., Knappenberger, P.C., Davis, R.E., and O.W. Frauenfeld, Rational analysis of trends in extreme temperature and precipitation, _Proc. 13th Appl. Clim. Conf_., Portland, OR, 153–158.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2002. Climate change adaptations: trends in human mortality responses to summer heat in the United States, _Proc. 15th Conf. Biometeorol. Aerobiol. and the 16th ISB Cong. Biometeor_., Kansas City, MO, Paper 9B.1.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2002. Spatial pattern of human mortality seasonality in U. S. cities since 1964, _Proc. 15th Conf. Biometeorol. Aerobiol. and the 16th ISB Cong. Biometeor_., Kansas City, MO, Paper 2B.2.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2002. Decadal changes in heat-related human mortality in the Eastern United States. _Climate Research_ , **22** , 175-184.   
  
Michaels, P.J., Knappenberger, P.C., Frauenfeld, O.W., and R.E. Davis. 2002. Revised 21st century temperature projections. _Climate Research_ , **23** , 1-9.   
  
Knappenberger, P.C., Michaels, P.J., and R.E. Davis, 2001. The nature of observed climate changes across the United States during the 20th century. _Climate Research_ , **17** , 45–53.   
  
Michaels, P.J., Knappenberger, P.C., and R.E. Davis, 2001. Integrated Projections of Future Warming based Upon Observed Climate During the Attenuating Greenhouse Enhancement. _Proceedings of the1st International Conference on Global Warming and The Next Ice Age_ , co-sponsored by the Atmospheric Science Program at Dalhousie University, the Canadian Meteorological and Oceanographic Society, the American Meteorological Society and the European Space Agency, 19-24 August, 2001, at Dalhousie University in Halifax, Nova Scotia, Canada, pp.162–167.   
  
Michaels, P.J., Knappenberger, P.C., Balling, R.C., and R.E. Davis, 2000. Observed Warming in Cold Anticyclones. _Climate Research_ , **14** , 1-6.   
  
Balling R.C., MacCracken, M.C., Michaels, P.J., and A. Robock, 2000. Assessment of uncertainties of predicted global climate change modeling: Panel 1. _Technology_ , **7** , 231–256.   
  
Michaels, P.J., and P.C. Knappenberger, 2000. Natural Signals in the MSU Lower Tropospheric Temperature Record. _Geophysical Research Letters_ , **27** , 2905–2908.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2000. Decadal Changes in Summer Mortality in the United States. _Proceedings of the 12th Conference on Applied Climatology_ , Asheville, NC, 184–187.   
  
Michaels, P.J., Knappenberger, P.C., Gawtry, S.D., and R.E. Davis, 2000. Anticyclonic Warming. _Proceedings of the 12th Conference on Applied Climatology_ , Asheville, NC, 119–122.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2000. Decadal Shifts in Summer Weather/Mortality Relationships in the United States by Region, Demography, and Cause of Death. _Proceedings of the 14th Conference on Biometeorology and Aerobiology_ , Davis, CA, 250–251.


"
"**The coronavirus pandemic could wipe out 25 years of increasing gender equality,**new global data from UN Women **suggests.**
Women are doing significantly more domestic chores and family care, because of the impact of the pandemic.
""Everything we worked for, that has taken 25 years, could be lost in a year,"" says UN Women Deputy Executive Director Anita Bhatia.
Employment and education opportunities could be lost, and women may suffer from poorer mental and physical health.
The care burden poses a ""real risk of reverting to 1950s gender stereotypes"", Ms Bhatia says.
Even before the pandemic, it was estimated women were doing about three quarters of the 16 billion hours of unpaid work that are done each day around the world.
In other words, before coronavirus, for every one hour of unpaid work done by men, three hours was done by women. Now that figure is higher.
""If it was more than three times as much as men before the pandemic, I assure you that number has at least doubled,"" says Ms Bhatia.
Though the 38 surveys carried out by UN Women primarily focused on lower and middle-income countries, data from more industrialised countries show a similar picture.
""More alarming is the fact that many women are actually not going back to work,"" says Ms Bhatia.
""In the month of September alone, in the US, something like 865,000 women dropped out of the labour force compared to 200,000 men, and most of that can be explained by the fact that there was a care burden and there's nobody else around.""
UN Women warns that the ripple effect from having fewer working women will be dire on not only women's wellbeing but their economic progress and independence.
BBC 100 Women has spoken to three women, looking at how the pandemic has impacted the amount of work they do. They were asked to keep a time diary, noting down how they used the hours in a typical day, covering a 24-hour-period.
Even before the pandemic, women in Japan spent on average almost five times longer than men on unpaid care work and chores.
Teni Wada is a brand consultant based in Tokyo and was working a part-time nursery teacher before lockdown began.
""It's 5am and I'm desperately trying to complete this article on sake. The deadline isn't for a few days, but I like to stay ahead of the game. 'Mum life' is unpredictable, and I don't want this unpredictability to cost me a pay cheque,"" she writes in her diary.
Teni says time is a luxury she doesn't have in between home-schooling, planning meals, working and doing the laundry.
During lockdown, Teni and her husband have both been working from home, but their days look very different.
""He works from 9.30am to around 5-6.30pm, and I do feel like he has the luxury of going into a room and can concentrate on his work, but I don't have that luxury, she says, ""I do feel it's a bit unfair.""
At home, Teni says she does around 80% of the unpaid work which includes home-schooling her three-year-old daughter.
""The first two-three months were awful, mentally I reached my limit almost every day, my daughter would be crying and then I'd be crying,"" she recalls.
""We are seeing worrying impacts, including high levels of stress and mental health challenges, particularly for women, partly as a result of the increased workloads,"" says Papa Seck, Chief Statistician at UN Women.
Delina Velasquez is a farmer from the Cercado province in the southern city of Tarija in Bolivia.
Her days usually start around 5am, and she splits most of her time between working in the greenhouse and housework. But every two months she travels to the city's farmers' market to sell the vegetables she's been growing.
""The days are very exhausting in the field, at least for me, because I have other tasks in the house, but for now my daughter helps me, she is my right hand. She helps me in the house, in the field, in the greenhouse,"" she says.
Traditional gender norms reinforce the idea that men are the breadwinners while women are the homemakers, and girls are often expected to take on housework.
""When it comes to children's assistance [in unpaid work], parents are more likely to cite help from daughters than sons,"" says Mr Seck.
But Delina is happy that she gets to spend more time with her family during the pandemic.
""Before, I had to do everything alone in the nursery, buying seeds, storing, propagating, watering, cooking, cleaning,"" she says.
""But now that the school year has closed, my daughter helps me with cleaning, cooking, washing clothes; my little boy helps me in the nursery, my husband spends more time with us and helps us in everything he can. It's more relaxing for me.""
Dr Ijeoma Kola is a Nigerian-American woman living in Nairobi, Kenya.
She says part of the reason she has been able to juggle becoming a new mum and her job is because her husband is supportive and they can afford to hire someone to help them at home.
""Not all women have that, or are an economic position where they can afford help. But I still wake up every day at 6 or 7 to nurse our son,"" she says.
Ijeoma says society is not economically set up in favour of women and instils gender norms that make it impossible for the average women to be able to have it all.
""Women can have it all, but not all at the same time and not without major sacrifices,"" she explains.
""I think that they're probably very few of us and I count myself very lucky to be able to have most things, if not everything.""
Being able to hire someone to help out, made lockdown a bit easier for Ijeoma and her family.
""There was about a month where it was just us and I was miserable,"" she says.
""I felt like I just had so much work to do and couldn't get any professional work done because I was doing so much household work.""
Although her husband is a good partner when it comes to parenting and takes the lead on things like cleaning, dishes, and laundry, she says she often feels that the responsibility of managing the home falls on her.
""My mind is always thinking about things he doesn't think about like the grocery list, our son's first birthday, whether we should take family photos for the holidays, or scheduling a Zoom hangout with friends,"" she says.
The mental load - having to juggle things like healthcare appointments, meal plans and house repairs - can take a toll on women's physical and mental health as well.
Women's unpaid work often covers the cost of care that sustains families, supports economies and fills in for the lack of social services, but it's rarely officially recognised as work.
""The key point here is that this has always been undervalued and it has always been treated as something that you didn't have to worry about because there wasn't compensation involved,"" says Ms Bhatia.
""The pandemic has shone a spotlight on the fact that unpaid work has really been the social safety net for the world and has made it possible for others to go out and earn a productive income, while actually hampering the growth opportunities and the employment opportunities of those women who are carrying the care burden.""
Women who do the bulk of unpaid work will either have less time to engage in paid labour, or work longer hours, and often face financial insecurity either way.
""You cannot underscore enough how big a problem this is and how big an impact it's going to have if governments and businesses don't do something,"" says Ms Bhatia.
The UN is calling on governments and businesses to acknowledge that unpaid work exists and implement measures such as extra family leave, or extra paid leave, and keeping childcare centres open.
""This is not just a question of rights, it's also a question of what makes economic sense,"" says Ms Bhatia.
""And it makes economic sense that women participate fully in the economy,""
_Additional reporting by Will Dahlgreen and illustrations by Sana Jasemi._
BBC 100 Women _names 100 influential and inspirational women each year and shares their stories. Find us on Facebook, Instagram and Twitter, and use #BBC100Women._"
"

I came here today as president of the free and democratic Czech Republic.a country that succeeded more than 17 years ago in getting rid of communism; a country that quite rapidly, smoothly, and without unnecessary additional costs overcame its communist heritage and transformed itself into a normally functioning European‐​style parliamentary democracy and market economy; a country that is an integral part of the free world, a member of NATO and of the European Union, and a good friend of the United States of America.



Everyone has a list — mostly an implicit one — of issues, problems, and challenges that he feels and considers — on the basis of his experiences, prejudices, sensitivities, preferences, and priorities — to be crucial, topical, menacing, and relevant. I will reveal at least some of the items on my own list. All are inevitably related to something that was absent during most of my life in the communist era. 



What I have in mind is, of course, freedom.something that Americans value very highly, in spite of the fact that they have not experienced its nonexistence or absence personally. The experience of living under communism provides me with a special sensitivity, if not an oversensitivity, to lack of freedom.



Where do I see the main dangers to freedom at the beginning of the 21st century? I will not speak about the current headlines, and I will decline to speak about our external enemies, such as the Taliban, al‐​Qaeda, and Islamic fundamentalism, because I have nothing special to say or add to the issue of terrorism and I don’t want to just repeat well‐​known arguments and facts. Suffice it to say that our ability to go ahead and eventually face external dangers depends to a large extent on our beliefs, visions, convictions, internal strength, coherence, ability to function, and so on.



I consider it more important, therefore, to speak about our internal challenges, three of which are main challenges of the current era.



 **Neostatism**



My first topic is connected to communism. The Czech Republic — as did all the other former communist countries — had to undergo a difficult transition. We came to understand very early on that the transition had to be homemade as it was impossible to import a system devised abroad. We also came to understand that such a fundamental change was not an exercise in applied economics but a man‐​made evolutionary process and that we had to find our own path, our “Czech way,” toward an efficiently functioning society and economy.



Over the last 15 years, I spoke many times in the United States about the process of transition; about its nonzero costs; about its benefits, tenets, and pitfalls. Now, when it is over, we face a different problem.



We succeeded in getting rid of communism, but along with many others, we erroneously assumed that attempts to suppress freedom, and to centrally organize, mastermind, regulate, and control society and the economy, were matters of the past, an almost‐​forgotten relic. Unfortunately, those centralizing urges are still with us. I see more examples of such urges in Europe and in most international organizations than in the United States, but they can be found here as well.



The reason for my concern is the emergence of new, very popular and fashionable, “isms” that again put various issues, visions, plans, and projects ahead of individual freedom and liberty. There is social‐​democratism, which is nothing more than a milder and softer version of communism, and there is human‐​rightism, which is based on the idea of mostly positive rights applicable all over the world. There are also internationalism, multiculturalism, europeism, feminism, environmentalism, and other similar ideologies.



Communism is over, but attempts to rule from above are still here, or perhaps they have merely returned.



 **Europeism**



The second main challenge that I see is connected to our experience with the European Union, but goes beyond the EU, because it is part of a broader tendency toward denationalization of nation‐​states and toward worldwide supranationalism and global governance.



The special sensitivity that I and many of my countrymen have makes me view many current trends in Europe rather critically. My opponents do not seem to hear my arguments. They keep rejecting the views that they don’t like a priori. To understand my criticism requires knowledge of developments in the EU — its gradual metamorphosis from a community of cooperating nations to the union of nonsovereign nations — and of prevailing supranationalistic tendencies. Those developments are not well‐​known in the United States.



I have always been in favor of a friendly, peaceful, and mutually enriching cooperation and collaboration among European countries. However, I have many times pointed out that the move toward an ever‐​closer Europe, the so‐​called deepening of the EU, as well as rapid political integration and Europe’s supranational tendencies that are not buttressed by an authentic European identity or European demos, are damaging to democracy and freedom.



Freedom and democracy — those two precious values — cannot be secured without parliamentary democracy within a clearly defined state territory. Yet that is exactly what the current European political elites and their fellow travelers are attempting to eliminate.



 **Environmentalism**



I see the third main threat to individual freedom in environmentalism. To be specific, I do understand the concerns about eventual environmental degradation, but I also see a problem in environmentalism as an ideology.



Environmentalism only pretends to deal with environmental protection. Behind their people‐ and nature‐​friendly terminology, the adherents of environmentalism make ambitious attempts to radically reorganize and change the world, human society, our behavior, and our values.



There is no doubt that it is our duty to rationally protect nature for future generations. The followers of the environmentalist ideology, however, keep presenting us with various catastrophic scenarios with the intention of persuading us to implement their ideas. That is not only unfair but also extremely dangerous. Even more dangerous, in my view, is the quasi‐​scientific guise that their oft‐​refuted forecasts have taken on.



What are the beliefs and assumptions that form the basis of the environmentalist ideology?



All of those beliefs and assumptions are associated with social sciences, not with natural sciences. That is why environmentalism — unlike scientific ecology — does not belong to the natural sciences and can be classified as an ideology. That fact is, however, not understood by the average person and by numerous politicians. 



The hypothesis of global warming and the role of humanity in that process is the last and, to this day, the most powerful embodiment of the environmental ideology. It has brought many important “advantages” to the environmentalists:



It is not my intention here to present arguments for the refutation of that hypothesis. What I find much more important is to protest against the efforts of the environmentalists to manipulate people. Their recommendations would take us back into the era of statism and restricted freedom. It is therefore our task to draw a clear line and differentiate between ideological environmentalism and scientific ecology.
"
"

Paul Krugman's column in today's _NYT_ laments the lack of a national policy to combat global warming. He writes: 



It’s true that scientists don’t know exactly how much world temperatures will rise if we persist with business as usual. But that uncertainty is actually what makes action so urgent. While there’s a chance that we’ll act against global warming only to find that the danger was overstated, there’s also a chance that we’ll fail to act only to find that the results of inaction were catastrophic. Which risk would you rather run?



He then cites the work of Harvard economist Martin Weitzman, who surveyed the results of a number of recent climate models and found that (in Krugman's words) ""they suggest about a 5 percent chance that world temperatures will eventually rise by more than 10 degrees Celsius (that is, world temperatures will rise by 18 degrees Fahrenheit). As Mr. Weitzman points out, that’s enough to 'effectively destroy planet Earth as we know it.'”   
  
Krugman concludes, ""It’s sheer irresponsibility not to do whatever we can to eliminate that threat"" and he calls for opprobrium against those who might impede global warming legislation: ""The only way we’re going to get action, I’d suggest, is if those who stand in the way of action come to be perceived as not just wrong but immoral.""   
  
There is merit to the argument that society should consider a policy response to the threat of global warming. A small chance of an enormous calamity equals a risk that may deserve mitigation. That's why people buy insurance, after all.   
  
However, Krugman doesn't accept that argument — at least, not when applied to other worrisome risks that trouble people whose politics are different than his. Less than two months ago, he wrote this about another future crisis: 



[O]n Friday Mr. Obama declared that he would “extend the promise” of Social Security by imposing a payroll-tax surcharge on people making more than $250,000 a year. The Tax Policy Center estimates that this would raise an additional $629 billion over the next decade. But if the revenue from this tax hike really would be reserved for the Social Security trust fund, it wouldn’t be available for current initiatives. Again, one wonders about priorities. Whatever would-be privatizers may say, Social Security isn’t in crisis: the Congressional Budget Office says that the trust fund is good until 2046, and a number of analysts think that even this estimate is overly pessimistic. So is adding to the trust fund the best use a progressive can find for scarce additional revenue?



In Krugman's view, policies to address Weitzman's 5 percent risk of ecological disaster by the early 23rd century (Weitzman's time frame, which Krugman didn't specify) are responsible and moral, but policies to address the economic crisis of Social Security's insolvency in less than four decades' time are unnecessary and overly pessimistic. And Krugman clobbers anyone who suggests otherwise .   
  
Make sense to you? Me neither.   
  
Krugman's double-standard on risk is not confined to Social Security. He has (rightly, IMO) blasted the Bush administration for going to war in Iraq. But couldn't the war be justified as mitigating a small risk of a great catastrophe? Was there, perhaps, a one-in-20 risk that Hussein's Iraq would develop weapons of mass destruction and direct them at the United States (in the next 200 years)?   
  
I write this not to argue that the United States should be unconcerned about global warming, or about rogue states' possession of super-weapons, or about Social Security's (and Medicare's) unsustainability. All are risks, and it is right for us to consider policy responses for each of them. My point is that it makes little sense to say one risk must be addressed while we should dismiss another risk with an expected value that's probably the same order of magnitude.   
  
Moreover, if this dichotomy is simply the product of Krugman's political allegiances (""Red team fears are stupid, Blue team fears are heroic""), isn't he being irresponsible, wrong and immoral?


"
"
By Blake Snow – 				 				FOXNews.com
Image: NASA / Goddard Institute for Space Studies – Maps from NASA’s GISS reveal temperatures where  no data exist, thanks  to mathematical extrapolation of data.

NASA was able to put a man on the moon, but the space agency can’t  tell you what the temperature was when it did. By its own admission,  NASA’s temperature records are in even worse shape than the besmirched  Climate-gate data.
E-mail messages obtained by a Freedom of Information Act request  reveal that NASA concluded that its own climate findings were inferior  to those maintained by both the University of East Anglia’s Climatic  Research Unit (CRU) — the scandalized source of the leaked Climate-gate  e-mails — and the National Oceanic and Atmospheric Administration’s  National Climatic Data Center.
The e-mails from 2007 reveal that when a USA Today reporter  asked if NASA’s data “was more accurate” than other climate-change data  sets, NASA’s Dr. Reto A. Ruedy replied with an unequivocal no. He  said “the National Climatic Data Center’s procedure of only  using the best stations is more accurate,” admitting that some of his  own procedures led to less accurate readings.
“My recommendation to you is to continue using NCDC’s data for the  U.S. means and [East Anglia] data for the global means,” Ruedy told the  reporter.
“NASA’s temperature data is worse than the Climate-gate temperature  data. According to NASA,” wrote Christopher Horner, a senior fellow at  the Competitive Enterprise Institute who uncovered  the e-mails. Horner is skeptical of NCDC’s data as well,  stating plainly: “Three out of the four temperature data sets stink.”
…
Global warming critics call this a crucial blow to advocates’ arguments  that minor flaws in the “Climate-gate” data are unimportant, since all  the major data sets arrive at the same conclusion — that the Earth is  getting warmer. But there’s a good reason for that, the skeptics say:  They all use the same data.
…
Neither NASA nor NOAA responded to requests for comment. But Dr. Jeff  Masters, director of meteorology at Weather Underground,  still believes the validity of data from NASA, NOAA and East Anglia  would be in jeopardy only if the comparative analysis didn’t match. “I  see no reason to question the integrity of the raw data,” he says.  “Since the three organizations are all using mostly the same raw data,  collected by the official weather agency of each individual country, the  only issue here is whether the corrections done to the raw data were  done correctly by CRU.”
Corrections are needed, Masters says, “since there are only a few  thousand surface temperature recording sites with records going back  100+ years.” As such, climate agencies estimate temperatures in various  ways for areas where there aren’t any thermometers, to account for the  overall incomplete global picture.
“It would be nice if we had more global stations to enable the groups  to do independent estimates using completely different raw data, but we  don’t have that luxury,” Masters adds. “All three groups came up with  very similar global temperature trends using mostly the same raw data  but independent corrections. This should give us confidence that the  three groups are probably doing reasonable corrections, given that the  three final data sets match pretty well.”
But NASA is somewhat less confident, having quietly decided to tweak  its corrections to the climate data earlier this month.
In an  updated analysis of the surface temperature data released on  March 19, NASA adjusted the raw temperature station data to account for  inaccurate readings caused by heat-absorbing paved surfaces and  buildings in a slightly different way. NASA determines which stations  are urban with nighttime satellite photos, looking for stations near  light sources as seen from space.
Of course, this doesn’t solve problems with NASA’s data, as the  newest paper admits: “Much higher resolution would be needed to check  for local problems with the placement of thermometers relative to  possible building obstructions,” a  problem repeatedly underscored by meteorologist Anthony Watts  on his SurfaceStations.org Web site. Last month, Watts told FoxNews.com  that “90 percent of them don’t meet [the government’s] old, simple rule  called the ‘100-foot rule’ for keeping thermometers 100 feet or more  from biasing influence. Ninety percent of them failed that, and we’ve  got documentation.”
Read the entire story at Fox News.com


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8cf3ea0c',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

An election’s end provides merciful relief from politicians’ claims that they will “transform” our lives and our economy. Whether it be pledges to turn around failing regions, deliver rapid decarbonisation, or plant hundreds of millions of trees per year, this particular campaign was littered with promises that we know, in our hearts, would not or could not be delivered.



Commentators worry about the breakdown of trust in politics and politicians. Nothing does more to accentuate it than unmeetable political commitments that subsequently have to junked or downgraded when reality hits. Yet many pundits still use “radical” or “bold” as synonyms for “good” when describing election manifestos.



The Conservatives’ offering this time around, for example, was criticised for its supposed absence of ambition. The “lack of significant policy action is remarkable,” concluded the Institute for Fiscal Studies’ Paul Johnson. Surely, big challenges — weak productivity growth, an aging population, climate change — require radical rethinks about policy?



In the past, I might have echoed such reasoning. Yet recent history surely shows the opposite: British politics suffers from a deficit of interest in modest, marginal improvements in government policy, not “big ideas”. Major overhauls of public services or welfare have proven either a waste of time or a disaster, while many headline‐​catching promises continually fall by the wayside.



Think about major policy change over the past decade. Universal Credit, though well intentioned, has seen vast resource and political capital invested in attempting to roll six working‐​age benefits into a single credit.



Near constant problems of delivery have beset it, with significant numbers suffering its teething problems. And all for a relatively small economic improvement in some recipients’ work incentives.



Andrew Lansley’s major reorganisation of the NHS saw a bitter passage through the House of Commons and cost billions to implement. Yet in the dying days of the last Parliament, a reversal of some of its key features was already underway. The director of the Nuffield Trust, Nigel Edwards, says that in future we will regard the Lansley reforms as “one of the most major public policy failures” of all time.



Then there’s the ongoing farce of our main grand transport project today — HS2. Its projected costs have now spiralled from £62bn to between £81bn and £88bn, all to deliver a much smaller projected “bang for the buck” than other minor transport projects elsewhere.



Rather than these bungled attempts to completely overhaul our welfare and health systems, imagine what might have been achieved with modest pro‐​work reform of tax credits or small‐​scale NHS experiments with automation. Instead of spending gargantuan sums for a prestige project to get marginally faster travel times between the midlands and London, think how many localised transport bottlenecks could have been relieved, easing commute times for thousand of families.



True, much smaller projects would not have generated the sexy headlines, but they would have almost certainly delivered better outcomes.



Now consider instead some policy areas that have gone well in recent years. Unemployment has fallen to extremely low levels, after a big post‐​recession spike. Most agree this reflects in part the more flexible labour market delivered by Thatcher’s liberalising agenda. But it also comes from welfare reforms and active labour market policies honed and refined under both political parties over decades.



In other words, gradual, incremental change has produced a jobs market that, while vulnerable to sharp shocks in recessions, is structurally strong.



Though it benefited both parties to exaggerate the differences, the seemingly successful Conservative school reforms under Michael Gove really built on the academies of New Labour too. Yes, other very targeted changes in how children are taught in certain areas have been rolled out — not least a mandatory focus on phonics in teaching reading. But these were well‐​evidenced, and not just delivered on a whim.



In an election campaign, of course, it’s too much to ask for politicians to really get into the weeds discussing small ideas. Big promises help them show they care about a particular issue and are determined to change it. But the arms race we’ve seen on planting trees, decarbonisation targets, or government investment levels are exactly the sorts of promises that ultimately lead voters to lose faith with politicians.



Trust requires delivering what you say you will. It’s why Boris Johnson is right that Parliament’s inability to deliver Brexit, more than anything else, has profoundly worsened the disconnect between electors and politicians.



Grand projects or major structural policy overhauls invariably disappoint. Not only do they bring large, unforeseen downsides that create political anger; they are high cost to reverse if they prove a dud. With Brexit already enough of a major disruption for the coming years, politicians should heed the lesson.



It would be much better to have some relatively stability in other areas, with gradual reforms that can try to improve things where current policies clearly fail.



No doubt, Britain does face major economic challenges. But not every big challenge requires a radical new solution. Just a generation ago, we understood that having a robust and growing economy, for example, required getting the conditions right in individual sectors. It meant making the necessary changes to taxes, regulations, or entry barriers to foster a competitive environment conducive to innovation.



Nowadays we hear less interest about how changes to incentives or structural conditions could deliver better outcomes in specific markets, instead obsessing over the supposed macroeconomic benefits of more spending.



History suggests that in delivery or outcomes, a top‐​down agenda will disappoint. If politicians are really interested in delivering those outcomes, they should focus less on the grandiose projects, and more on small scale reforms that could make markets and public services work better. 
"
"I run 50km per week on my treadmill and eat a calorie-restricted diet; this is something our ancestors didn’t have to do. But then they didn’t sit at a desk all day and certainly did not have access to such energy rich food. Unfortunately our animals have joined us on the couch. Take a walk down the pet food aisle in the supermarket and you may be surprised to see rows of diet cat and dog food. In the US more than 50% of cats and dogs are obese or overweight, just 10% less than the human population.  Obese people are less likely to recognise that their pet is also obese: a body perception failure which will result in a cramped sofa. Thus, the world obesity crisis is not just affecting humans but also the animals that live with us.   Just as with humans, obesity has an extremely negative effect on animal health, and their causes appear to be similar: sedentary life style and easily available energy rich foods. In both humans and animals the consequences include diabetes, cancer, hypertension or heart-disease. In the case of pets we are killing them with “kindness”. We as humans are responsible for our own health and the health of the animals that share our lives. This includes animals in zoos. A study published this year showed that more than 40% of elephants in captivity are obese. They are so obese that it is negatively affecting their longevity and fertility. Fertility rates in the captive elephant population are so low that it is not self-sustaining; this could result in the need to collect individuals from the wild. Pot-belly problems affect all groups of zoo animals from primates such as lemurs to crocodilians. Food means life.  It is for this reason that your parents constantly checked if you were eating properly as a child – in our evolutionary history filling your children up with food meant increasing their chances of survival.  But in an environment where energy rich food is permanently available the opposite is true. Food isn’t just nutrition, the possession or control over food also represents power and status. We have all bribed our kids to do things with sweets – and food treats are the reward most used by people to train animals. Thus, food is power.  In the animal world it may also represent status – for instance in carnivores such as wolves and lions it is the dominant animal that eats first. In modern human society food can also be a status symbol, think about caviar or wagyu beef. Food can be bling. Outside of our pets, the animals we most commonly feed are garden birds.  Ironically, many people who feed birds are aware of the need to provide them with healthy food but may ignore this advice for themselves.  The impacts of this activity on bird populations has shown to be mixed.  For example, it may enhance overwinter survival but reduce clutch sizes.  Extra food for wild animals, as per humans, it would seem is a two-edged sword. So what is to be done about this problem of animal obesity?  For captive animals we can of course put them on a diet and increase their activity levels. But what type of diet?  We should definitely avoid “fad diets” and crash diets for animals. Research on fish has shown that crash dieting (and yo-yoing weight) reduces lifespan by 25%. The simple answer is calorie restriction, which of course animals just like humans do not find pleasant, but it is a part of our natural ecology. Unhappily, calorie restriction does not appear to increase lifespan in primates as it does in rats. Physical activity helps you burn up calories and stay at a healthy weight. So why are humans and captive animals so prone to inactivity? Energy is a limited resource for wild animals and one not to be wasted frivolously. In captivity, animals still behave in this manner, as do humans.  This explains the difficulty in motivating individuals to undertake physical activity.  One solution to this is to reward individuals for their physical activity: research I have recently carried out with colleagues has shown this to be highly effective with rats. I suspect that the problem in rewarding people and animals for exercising is that rewards need to be very frequent and not just an “endorphin high” after an hour on the treadmill."
"**Paul Gilley says he has never seen so few new jobs in the UK hospitality sector - across restaurants, bars and hotels.**
Recruitment is bad overall but in hospitality it is ""non-existent"", says the boss of London-based recruitment firm PJ Search & Selection.
Mr Gilley has run his business for 20 years, specialising in the hospitality sector. Back in March, he says that everything stopped overnight.
""Contracts were being cancelled, all permanent vacancies were drying up and within a week we had nothing,"" he says.
Despite England being set to come out of the current lockdown on 2 December, returning to a tier-based system and with Christmas fast approaching, Mr Gilley does not see things improving until well into 2021.
""The hospitality sector is going to try its damnedest to have a good Christmas, but with social distancing rules in place you can have only less than half the normal number of customers, so extra staff just aren't needed,"" he says.
""Places are opening their doors not to make money, but to lose less.""
Recruitment agencies are a very good barometer of a country's economy. And across the UK they have seen business dry up, as unemployment has risen due to Covid and the subsequent lockdowns and tier restrictions.
The latest official figures show that the UK unemployment rate rose to 4.8% in the three months to September, up from 4.1% in the previous quarter. And the unemployment rate among 16 to 24-year-olds, who make up much of the staff across restaurants, bars and hotels, is now 14.6%, also according to official data. Overall UK unemployment is now expected to reach 7.5% next year.
This bleak situation also applies to retail, and is replicated globally, says Ann Swain, the chief executive of APSCo, an international trade body that represents the recruitment sector.
""In March, education recruitment fell off a cliff because schools were closed down, and other markets followed with permanent recruitment dying for weeks or longer for the likes of retail and hospitality,"" she says.
But Ms Swain says recruitment has since picked up in areas such as distribution, healthcare and the pharmaceutical sector, where firms have been looking for Covid vaccines.
In fact, some entrepreneurs are launching new recruitment firms to capitalise on these trends. One such is UK industry veteran David Spencer-Percival, who has started Life Sciences People, focusing on the pharmaceutical and life sciences sector.
""The sector is seeing record investment,"" he says. ""If you are already in a downturn or recession then there's everything to play for if you time it right, as the economy can only move one way - up.""
New Economy is a new series exploring how businesses, trade, economies and working life are changing fast.
Looking at how the UK's recruiters have fared this year compared with other countries, Ms Swain says German firms have had an easier time, because Germany has had fewer coronavirus cases.
Meanwhile in Australia, the situation has varied from city to city, she says. The stricter the Covid restrictions, the more unwilling firms have been to recruit. As a result, recruiters in Melbourne were badly affected while the situation was much better for those in Sydney.
""In Singapore and South East Asia it has been a lot of 'on-off', whereby everything goes back to some normality, then closes down, therefore permanent recruitment has been restricted,"" says Ms Swain.
Kathryn Woof, managing director of 33 Talent, a Singapore recruitment firm for the public relations and marketing sectors, says she might have had to close her business if it had only focused on recruitment.
In March ""we went from working on a million dollars' worth of jobs to zero in three weeks,"" she says.
""Even though our sector was not as affected as hospitality, a lot of our clients didn't have the luxury of proceeding as if nothing was wrong. They had to freeze their headcount, reduce wages and shorten work weeks because they were assuming the worst.""
Ms Woof says her business was already doing some human resources consulting and training work, so pivoted her team to focus on those two areas instead.
As a result of gaining business in these areas, as well as moving to a four-day week, she has been able to keep all 12 of her staff employed.
While the recruitment side of the business is now slowly recovering, it is only working on about 20% of the number of jobs compared with pre-Covid levels, she says.
The bounce back for recruitment firms in other parts of the world has been better. This has been the case for MatcHR in Ukraine, which helps western firms employ remote tech staff. Its clients include Booking.com, TikTok, Stripe and Merck.
""In March the whole world stopped, so in a matter of two to three weeks we lost 70% of our turnover. We had to fire 60% of our staff, and we were still bleeding money,"" says MatcHR co-founder Adriaan Kolff.
A deal with TikTok signed in February kept the business going, he says. Then in recent months a growing number of US firms have been wanting to hire Ukrainian tech workers.
Mr Kolff say this has helped MatcHR return to making 90% of its pre-pandemic earnings and it has hired back some of the staff it had made redundant.
While MatcHR is one of the lucky ones, many recruitment firms are pinning their hopes on the roll-out and success of the Covid-19 vaccines.
Until then, Paul Gilley in London says he is more focused on an e-commerce business he set up earlier this year, to bring in a much-needed income.
APSCo's Ann Swain says: ""The global recruitment market is always a bellwether for the economy because the minute organisations or governments feel unease they stop recruiting."""
"

Trade and globalization have become more inviting targets during the current economic downturn. As output falls and unemployment rises, politicians in Washington are questioning not only imports but U.S. companies that invest in production abroad.



The incoming president, Barack Obama, pledged during his campaign that, “Unlike John McCain, I will stop giving tax breaks to corporations that ship jobs overseas and I will start giving them to companies that create good jobs right here in America.“1 That campaign refrain, echoed by a number of other successful candidates, raises three basic questions:



Why do U.S. multinational companies establish affiliates abroad and hire foreign workers? What kind of tax breaks are they receiving? And should the new Congress and new president change U.S. law to make it more difficult for U.S. multinational corporations to produce goods and services in foreign countries?



 **Reaching millions of new customers**



To demonize U.S. multinationals operating production facilities abroad is to indict virtually every major American company. At latest count more than 2,500 U.S. corporations own and operate a total of 23,853 affiliates in other countries. In 2006, according to the U.S. Department of Commerce, majority‐​owned foreign affiliates of U.S. companies posted $4.1 trillion in sales, created just under $1 trillion in value added, employed 9.5 million foreign workers, and earned $644 billion in net income for their U.S.-based parent companies.2



The primary reason why U.S. companies invest in affiliates abroad is to sell more products to foreign customers. Certain services can only be delivered on the spot, where the provider must have a physical presence in the same location as its customers. Operating affiliates abroad allows U.S. companies to maintain control over their brand name and intellectual property such as trademarks, patents, and engineering expertise. U.S. companies also establish foreign affiliates because of certain advantages in the host country‐ lower‐​cost labor, ready access to raw materials and other inputs, reduced transportation costs and proximity to their ultimate customers. Yes, the motivations can include access to “cheap labor,” but labor costs are not the principal motivation for most U.S. direct investment abroad.



Politicians focus most of their attention on comparing exports and imports, but the most common way American companies sell their goods and services in the global market today is through overseas affiliates. In 2006, U.S. multinational companies sold $3,301 billion in goods through their majority‐​owned affiliates abroad and $677 billion in services. For every $1 billion in goods that U.S. multinational companies exported from the United States in 2006, those same companies sold $6.2 billion through their overseas operations. For every $1 billion in service exports, U.S.- owned affiliates abroad sold $1.6 billion.3



Contrary to popular myth, U.S. multinational companies do not use their foreign operations as an “export platform” back to the United States. Close to 90 percent of the goods and services produced by U.S.-owned affiliates abroad are sold to customers either in the host country or exported to consumers in third countries outside the United States. Even in Mexico and China, where low‐​wage workers are supposedly too poor to buy American products, more than half of the products of new and existing U.S. affiliates are sold in their domestic markets, whereas customers in the United States account for only 17 percent of sales.4



 **More Jobs Abroad, More Jobs at Home**



Investing abroad is not about “shipping jobs overseas.” There is no evidence that expanding employment at U.S.- owned affiliates comes at the expense of overall employment by parent companies back home in the United States. In fact, the evidence and experience of U.S. multinational companies points in the opposite direction: foreign and domestic operations tend to compliment each other and expand together. A successful company operating in a favorable business climate will tend to expand employment at both its domestic and overseas operations. More activity and sales abroad often require the hiring of more managers, accountants, lawyers, engineers, and production workers at the parent company.



Consider Caterpillar Inc., the Peoria, Illinois‐​based company known for making giant earth‐​moving equipment. From 2005 through 2007, the company enjoyed booming global sales because of strong growth in overseas markets, especially those with resources extracted from the ground. According to the company’s 2007 annual report, Caterpillar earned 63 percent of its sales revenue abroad, including $1 billion in sales in China alone. As a result, Caterpillar ramped up employment at its overseas affiliates during that time from 41,238 to 50,788, an increase of almost 10,000 workers. During that same three‐​year period, the company expanded its domestic employment from 43,878 to 50,545, a healthy increase of 6,667.5



Caterpillar’s experience is not unusual for U.S. multinational companies. A 2005 study from the National Bureau of Economic Research found that, during the 1980s and 1990s, there was “a strong positive correlation between domestic and foreign growth rates of multinational firms.” After analyzing the operations of U.S. multinational companies at home and abroad, economists Mihir A. Desai, C. Fritz Foley, and James R. Hines Jr. found that a 10 percent increase in capital investment in existing foreign affiliates was associated with a 2.2 percent increase in domestic investment by the same company and a 4 percent increase in compensation for its domestic workforce. They also found a positive connection between foreign and domestic sales, assets, and numbers of employees.6 “Foreign production requires inputs of tangible or intellectual property produced in the home country,” the authors explained. “Greater foreign activity spurs higher exports from American parent companies to foreign affiliates and greater domestic R&D spending.“7



The positive connection between foreign and domestic employment of U.S. multinational companies has continued into the current decade. As Figure 1 shows, parent and affiliate employment have tracked each other since the early 1980s. More recently, employment rose briskly for parents and affiliates alike in the boom of the late 1990s, fell for both during the downturn and slow recovery of 2001 through 2003, and then rose again from 2003 through 2006.8 Although the numbers have not been reported yet for 2007 and 2008, it’s likely that the loss of net jobs in the domestic U.S. economy will be mirrored by much slower growth or outright decline in foreign affiliate employment.



 **Modest Investment in China and Mexico**



Investment in China and Mexico drew the most fire on the campaign trail. In a primary debate in Texas in February 2008, then‐​senator Obama said, “In Youngstown, Ohio, I’ve talked to workers who have seen their plants shipped overseas as a consequence of bad trade deals like NAFTA, literally seeing equipment unbolted from the floors of factories and shipped to China.“9 That makes for a good sound‐​bite in the heat of a campaign, but it does not accurately reflect the broader reality of outward foreign investment by U.S. manufacturers.





Outflows of U.S. manufacturing investment to Mexico and China have been modest by any measure. Between 2003 and 2007, U.S. manufacturing companies sent an average of $2 billion a year in direct investment to China and $1.9 billion to Mexico. That pales in comparison to the average $22 billion a year in direct manufacturing investment “shipped” to Europe during that same period, but talking about equipment being unbolted from the floors of U.S. factories and shipped to England just doesn’t have the same bite.10 The modest annual outflow in investment to China and Mexico is positively dwarfed by the annual $59 billion inflow of manufacturing investment to the United States from abroad during those same years11 and the average of $165 billion per year that U.S. manufacturers invested domestically in plant and equipment.12



The fear of manufacturing jobs being shipped to China and Mexico is not supported by the evidence. While U.S. factories were famously shedding those 3 million net jobs between 2000 and 2006, U.S.-owned manufacturing affiliates abroad increased their employment by a modest 128,000 jobs. An increase in 172,000 jobs at U.S.-owned affiliates in China was partially offset by an actual decline of almost 100,000 jobs at affiliates in Mexico.13 The large majority of factory jobs lost in the United States since 2000 were not “shipped to China” or anywhere else, but were lost to automation and other sources of increased efficiency in U.S. manufacturing.



U.S. manufacturing investment in China remains modest compared to the huge political investment that candidates and pundits have made in making it an issue. U.S. direct investment in China remains a relatively small part of China’s overall economy, and a small part of America’s total investments abroad. Of the nearly 10 million workers that U.S. affiliates employ abroad, fewer than 5 percent are Chinese; Americanowned affiliates employed just as many manufacturing workers in high‐​wage Germany in 2006 as they did in low‐​wage China.14



 **“Tax breaks” Keep U.S. Companies Competitive**



Politicians are not usually specific about exactly what “tax breaks” they want to repeal. The biggest tax exemption for U.S. companies that invest abroad is the deferral of tax payments for “active” income. U.S. corporations are generally liable for tax on their worldwide income, whether it is earned in the United States or abroad. But the relatively high U.S. corporate tax rate is not applied to income earned abroad that is reinvested abroad in productive operations. U.S. multinationals are taxed on foreign income only when they repatriate the earnings to the United States. Not surprisingly, the deferral of active income gives U.S. companies a powerful incentive to reinvest abroad what they earn abroad, but this is hardly an incentive to “ship jobs overseas.”



Such deferral may sound like an unjustified tax break to some, but every major industrial country offers at least as favorable treatment of foreign income to their multinational corporations. Indeed, numerous major countries exempt their companies from paying any tax on their foreign business operations. Foreign governments seem to more readily grasp the fact that when corporations have healthy and expanding foreign operations it is good for the parent company and its workers back home.15



If President Obama and other leaders in Washington want to encourage more investment in the United States, they should lower the U.S. corporate tax rate, not seek to extend the high U.S. rate to the overseas activities of U.S. companies. Extending high U.S. tax rates to U.S.-owned affiliates abroad would put U.S. companies at a competitive disadvantage as they try to compete to sell their goods and services abroad. Their French and German competitors in third‐​country markets would continue to pay the lower corporate tax rates applied by the host country, while U.S. companies would be burdened with paying the higher U.S. rate. The result of repealing tax breaks on foreign earnings would be less investment in foreign markets, lost sales, lower profits, and fewer employment and export opportunities for parent companies back on American soil.



Politicians who disparage investment in foreign operations are wedded to an outdated and misguided economic model that glorifies domestic production for export above all other ways for Americans to engage in the global economy. They would deny Americans access to hundreds of millions of foreign customers and access to lower‐​cost inputs through global supply chains. In short, they would cripple American companies and their American workers as they try to compete in global markets.
"
"You might not be able to stomach soybeans for breakfast, lunch and dinner, but the animals you eat do. Cultivation of the staple crop takes up an area five times the size of the UK, and 85% of that area is used for animal feed. Thanks to projected rapid growth in both world population and in the meat-eating global middle class, demand for soybean is set to grow 80% by 2050 – more than any other staple crop. With arable land at a premium, our desire for animal products is already responsible for the deforestation of vast swathes of the Amazon and other rainforests. This massive increase in demand is likely to lead to a whole lot more destruction, at precisely the time when we need to be curbing what is the second biggest cause of global warming. But this destruction is not yet a certainty. I recently travelled to Iceland to investigate a cutting-edge commercial technology that soups up photosynthesis. It could help save the bio-diverse, CO₂-sucking ecosystems that are so vital to the health of our planet. Light, carbon dioxide, and water are what give plants life. Through photosynthesis, plants convert these three ingredients into the vital carbohydrates needed to flourish and blossom. But conventional agriculture has surprisingly little control over these factors. It’s dependent on the sun to shine, and while irrigation has substantially improved crop yield, water scarcity is often an issue for farmers. This novel method, trialled in Iceland’s Hellisheidi geothermal park, swaps sunlight with LED light, fresh water with saltier “brackish” water, and ambient air with concentrated carbon dioxide, controlling their concentrations in innovative modules called photo-bioreactors. Think of them as nuclear reactors, except with concentrated CO2 and light as the inputs and organic material as the output. These photo-bioreactors are designed to grow not soybeans, but plant microorganisms. In tubes of different shapes and sizes, fluids rich with micro-algae are stirred carefully, and exposed to light, water, and CO₂. Using the same logic as systems designed by NASA for space travel, they recycle carbon, phosphorus and nitrogen. Compared to conventional agriculture, these closed-loop modules allow for much greater control and measurement of fertilisers and water, use CO₂ more efficiently, are at lower risk of crop loss from contamination, pests, and storms. Most importantly, they maximise the efficiency of the key ingredient in photosynthesis: light. By keeping the microalgae fluid constantly moving and closely regulating temperature and harvest timing, these microorganisms are exposed to the maximum healthy amount of light, shedding the natural constraints of the day-night cycle and the weather. Using this technique, photo-bioreactors can provide similar nutritional content to soybeans at less than 0.6% of the land and water use. A production unit uses 130m² to grow 10,500kg of biomass per year – a 200-fold improvement in resource efficiency. The reactors have a minimal ecological footprint. Iceland’s reactors are powered geothermally, and can be paired with any form of renewable electricity. After the carbon costs of production, they are net absorbers of CO₂. They eliminate the need for pesticides and herbicides. They can be placed on unproductive lands, and can be stacked vertically like LEGO bricks. The modular design could even be deployed in city centres. Crucially, the technology is cost-effective. Thanks mainly to the commercialisation of cannabis, LED technology is now much cheaper and more efficient than before, and other recent engineering innovations have further reduced costs. If the monetary costs of the environmental and social harm caused by soy cultivation are taken into account, micro-algae now represent much better value for money – albeit with a higher level of initial investment required for producers. While the shift from conventional agriculture to technical skills would require a short period of intensive training, for both farmers and states this cost would be far outweighed by greater profits and ease of production. Further trials are needed to prove that a fully microalgae-based diet is not detrimental to animal health in the long-term, but research suggests that they have the potential to feed chicks, hens, pigs, and cows. Photo-bioreactors could already be used to grow microalgae strains that are suitable for human consumption too, such as popular health food spirulina.  The livestock economy, like many other industries, tends to be resistant to change.
But these alternative food systems are now attainable, and if backed by soy-dependent governments, the technology could save millions of hectares of rainforest, and provide space for the rewilding of already deforested areas. As the pressure on countries to cut emissions hots up, such a switch is likely to become increasingly attractive. It could also free up valuable land and water resources to feed a population that is expected to increase by half in the next 80 years.  With more extreme patterns of deluge, drought, and crop failure expected as the planet warms photo-bioreactors like these could avert famine for millions. As with many of the planet’s existential problems, the solutions are out there. We just have to implement them. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"Having been traumatised by the Canberra firestorm of 2003, and then impacted by this summer’s bushfire crisis which culminated for me at Malua Bay on New Year’s Eve, I am left with a feeling of discombobulation. We saved our house by deciding to stay and defend against all warnings to evacuate, yet I am still afraid of further bushfires. I don’t feel normal any more. I feel life has changed into a Mad Max movie that could reappear any moment with loss of power and communications. Columbia Law School professor Jedediah Purdy wrote a remarkable 2016 essay about getting back to nature as a way of navigating politics, particularly in times of fear and collapse. “I have been hungry for naive responses to nature, as I have been for naive political lucidity,” he wrote. “These days, when I see a flock of birds in synchrony, I feel as if a dimension of awareness has opened that is not occupied territory. I feel this other site of consciousness, this fast-banking incipient intelligence, is a rip in the curtain drawn between the world and me.” This past summer cost Australia something as a country. I think part of what happened is that when we paid attention to what was going on in nature we didn’t find something that stood outside the occupied territory of contemporary politics. Instead we saw something that seemed to be a roaring, incandescent expression of it. The sheer senselessness of the damage wrought by a literally mindless force. The feeling of watching a system in combat with itself, individual parts facing catastrophe from a terror somehow produced by the whole. The need to pantomime normalcy around life-threatening warnings, the cognitive inability to stand in mourning for the parts that have already burned while someone still has to buy milk. It was biblical in its literalness: what we cherish is being incinerated. You’re right to not feel normal any more. Things aren’t normal. In the audience Q&A of an event I did last year, a therapist raised his hand. “Clients are coming to me asking how to process their climate grief. What can I possibly tell them when their despair is so obviously warranted?” I’ll say to you what I said to him: that when we talk about climate grief we talk as though it’s already dead. It’s not. But it is dying, and you know what to do against the dying of the light. Audre Lorde taught us “everything can be used”. Your despair can be used. Find an organised and energised group that vigorously defends the causes you care about and pick up the phone with them. Bother legislators. Talk to your friends in agitation; do not let their despair stay inert. Help them turn it into fuel. Ask “who benefits from this?” when you want to curl inwards in a ball with a wet blanket over your head. I want more than anything to promise you that if you do this, and I do this, we can turn things around. But I can’t make that promise. There will be more fires, they might very well be worse. The sense of doom in politics and the sense of doom in the environment are almost certainly not unrelated phenomena and it may turn out that we simply cannot fight both. But at least if both these spheres collapse you’ll be able to tell your children – and yourself – you fought to stop what matters from burning. • Question has been edited for clarity ************************************* Do you have a conflict, crossroads or dilemma you need help with? Eleanor Gordon-Smith will help you think through life’s questions and puzzles, big and small. Questions can be anonymous. If you’re having trouble using the form, click here. Read terms of service here."
"
Guest Post by Ira Glickstein
The December 2010 issue of the Atlantic shows an amazing turn-around by some of the Global Warming warmists! Yes, they are still tuned in to the CAGW crowd predicting imminent climate change disaster, but … BUT, some have reversed themselves on their previous ‘ol devil coal! Turns out we need coal to generate Watts of electricity for our electric cars and, they say, we can do it in a way that is environmentally correct.
The cover story, by respected author James Fallows, is titled Why the Future of Clean Energy is Dirty Coal. {Click the link to read it free online.}
Recall that, only last year, a leading alarmist, NASA’s James Hansen, one of the key science advisors on Al Gore’s The Inconvenient Truth movie, wrote:


“..coal is the single greatest threat to civilization and all life on our planet. … The dirtiest trick that governments play on their citizens is the pretense that they are working on ‘clean coal’… The trains carrying coal to power plants are death trains. Coal-fired power plants are factories of death.” 
 
Fallows writes: 
“To environmentalists, ‘clean coal’ is an insulting oxymoron. But for now, the only way to meet the world’s energy needs, and to arrest climate change before it produces irreversible cataclysm, is to use coal—dirty, sooty, toxic coal— …” 
 
Amazingly, while atmospheric CO2 is still the bogeyman of what alarmists say is an imminent Global Warming disaster, coal, which is nearly all carbon and generates CO2 when burned as intended, is part of the solution! Fallows writes:
Before James Watt invented the steam engine in the late 1700s—that is, before human societies had much incentive to burn coal and later oil in large quantities—the concentration of carbon dioxide in the atmosphere was around 280 parts per million, or ppm … By 1900, as Europe and North America were industrializing, it had reached about 300 ppm.
Now the carbon-dioxide concentration is at or above 390 ppm, which is probably the highest level in many millions of years. “We know that the last time CO2 was sustained at this level, much of the Greenland and West Antarctic ice sheets were not there,” Michael Mann, a climate scientist at Penn State, told me. Because of the 37 billion annual tons of carbon-dioxide emissions, the atmospheric carbon-dioxide level continues to go up by about two ppm a year. For perspective: by the time today’s sixth-graders finish high school, the world carbon-dioxide level will probably have passed 400 ppm, and by the time most of them are starting families, it will have entered the 420s. …
Michael Mann told me. “What we have with rising CO2 levels in general is a dramatically increasing probability of serious and deleterious change in our climate.” He went down the list: more frequent, severe, and sustained heat waves, like those that affected Russia and the United States this summer; more frequent and destructive hurricanes and floods; more frequent droughts, like the “thousand-year drought” that has devastated Australian agriculture; and altered patterns of the El Niño phenomenon, which will change rainfall patterns in the Americas. …
You should recognize Michael Mann as the creator of the deceptive “hockey stick curve” at the center of many of the Climategate emails. (See this and this and this and this.) Note also the standard line that, whatever happens to the weather: hotter, colder, dryer, wetter, stormy, calm, sunny, cloudy, … whatever, it is all due to high CO2 levels (even if they don’t plow your streets after a blizzard :^)
So, what is the solution? Fallows writes:
Isn’t “clean energy” the answer? Of course—because everything is the answer. The people I spoke with and reports I read differed in emphasis, sometimes significantly. Some urged greater stress on efficiency and conservation; some, a faster move toward nuclear power or natural gas; some, an all-out push for solar power and other renewable sources …
Note the mention of nuclear, also a bogeyman of the green crowd until a few years ago. In this regard much of the world is ahead of us. When I bicycled in France a few years ago, you could see nuclear power plant cooling towers in much of the countryside (except near Paris – I guess that is where the professional environmentalists live) and France generates most of its electricity using nuclear energy. It will take the US quite a while to catch up, but it is good to see a mainstream liberal literary magazine starting to lead the way. The above paragraph also mentions natural gas, a fossil fuel, ahead of “solar power and other renewable sources” stuck in at the end. It seems they finally realize that we need energy and, at least for the next decades, it will continue to be coal, burned in a cleaner way, plus nuclear and natural gas.
Fallows continues:
“Emotionally, we would all like to think that wind, solar, and conservation will solve the problem for us,” David Mohler of Duke Energy told me. “Nothing will change, our comfort and convenience will be the same, and we can avoid that nasty coal. Unfortunately, the math doesn’t work that way.”…
Coal will be with us because it is abundant: any projected “peak coal” stage would come many decades after the world reaches “peak oil.” It will be with us because of where it’s located: the top four coal-reserve countries are the United States, Russia, China, and India, which together have about 40 percent of the world’s population and more than 60 percent of its coal. …
“I know this is a theological issue for some people,” Julio Friedmann of Lawrence Livermore said. “Solar and wind power are going to be important, but it is really hard to get them beyond 10 percent of total power supply.” …
What would progress on coal entail? The proposals are variations on two approaches: ways to capture carbon dioxide before it can escape into the air and ways to reduce the carbon dioxide that coal produces when burned. In “post-combustion” systems, the coal is burned normally, but then chemical or physical processes separate carbon dioxide from the plume of hot flue gas that comes out of the smokestack. Once “captured” as a relatively pure stream of carbon dioxide, this part of the exhaust is pressurized into liquid form and then sold or stored. …
“Pre-combustion” systems are fundamentally more efficient. In them, the coal is treated chemically to produce a flammable gas with lower carbon content than untreated coal. This means less carbon dioxide going up the smokestack to be separated and stored.
Either way, pre- or post-, the final step in dealing with carbon is “sequestration”—doing something with the carbon dioxide that has been isolated at such cost and effort, so it doesn’t just escape into the air. … All larger-scale, longer-term proposals for storing carbon involve injecting it deep underground, into porous rock that will trap it indefinitely. In the right geological circumstances, the captured carbon dioxide can even be used for “enhanced oil recovery,” forcing oil out of the porous rock into which it is introduced and up into wells.
According to Fallows, China is in the lead on this clean coal technology, with help from American and other western corporations. While it is good that at least some of the Global Warming alarmists are warming up to coal as a necessary part of the solution, it would be better IMHO, if they were also more realistic about the actual dangers of climate change and the likelihood (again IMHO) that most of the warming of the past century is due to natural cycles not under human control and that we are likely already in a multi-decade period of stable temperatures, and perhaps a bit of cooling.
Yes, I think we need to do something about the unprecedented steady rise in CO2 levels, but we have to do it is a way that will not destroy our economies or force us to drastically reduce our lifestyles. One thing I agree with James Hansen about is that an across-the-board carbon tax, assessed equally against all sequestered fuels (coal, oil, natural gas) and collected at the mine, well, or port, is the best solution, far more suitable to the task than the “cap and trade” political scam, and more likely to work.
Rather than have governments pick winners (and mess up as they did with corn ethanol subsidies that raised food prices and reduced gas mileage without doing much to control CO2 emissions) I prefer to tax carbon progressively a bit more each year and let industry and other users decide for themselves how to adapt to the higher prices. Nothing stimulates action and invention like saving your own money. Nothing wastes money like government taking money from “Mr. A” and giving it to “Mr. B” for the “good of society”.
I’m working on a future posting that will propose use of gassified coal along with enhanced CO2 farming as a clean coal implementation that may make sense in a decade or so. I hope to post it next week.
***************************
Another story in the same issue of the Atlantic is about famed physicist Freeman Dyson and The Danger of Cosmic Genius.{Click the link to read it free online.}
They write:
In the range of his genius, Freeman Dyson is heir to Einstein—a visionary who has reshaped thinking in fields from math to astrophysics to medicine, and who has conceived nuclear-propelled spaceships designed to transport human colonists to distant planets. And yet on the matter of global warming he is, as an outspoken skeptic, dead wrong: wrong on the facts, wrong on the science. How could someone as smart as Dyson be so dumb about the environment?
Does it occur to them that the CAGW warmists and alarmists may be the ones who are wrong?


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e85ba2566',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

The politics of happiness research just got a bit more interesting. British Conservative leader David Cameron is now campaigning on a happiness platform. In a speech at a conference organized by Google in Hertfordshire, Cameron said, 



It's time we admitted that there's more to life than money, and it's time we focused not just on GDP, but on GWB---General Well-Being.



This is interesting because up until now, the politics of ""well-being"" have been primarily a welfare-liberal or social democratic phenomenon. So why the happiness schtick for the Tories? Why now? The Financial Times editorial page says:   




Mr Cameron's call for the Tories to address GWB is not a coded cry for redistribution. After green issues and childcare it is another sensible step towards increasing the opposition party's appeal by redefining popular values in modern Britain. From the Thatcher era onwards, the Conservatives have faced the charge of being cold and uncaring. Mr Cameron's task is, in part, to persuade voters that the Tories are warm and cuddly.



Although there is much support in the happiness literature for proposals to allow individuals greater control over our lives, I worry that creating a climate hospitable to risk-taking, entrepreneurship, and greater personal control (and, necessarily, greater personal responsibility) may be perceived as bracing, but not so much as ""warm and cuddly."" In his talk, Cameron dilated on the wonders of Howies, a ""socially conscious"" Welsh company in the mold of the US's American Apparel, praising their lack of hierarchy and the flexibility in work arrangements.   
  
Now, greater work flexibility is great, and that's a big part of what it would mean policy-wise to enhance well-being by giving people more control over their lives. But what does Cameron have in mind? Is this anything more than emotionally appealing talk? If so, genuine work flexibility requires deregulating the labor market, allowing individuals to bargain terms of employment for themselves, rather than getting stuck with the terms their union (which workers in certain areas often have little choice but to join) negotiated, or with terms set by the government, independent of the desires of the parties to the agreement. A system in which a certain wage, a certain package of benefits, certain labor conditions, etc., are mandated by the government is a system in which it is harder for people to opt in and out of the labor market, or to negotiate flexible contracts that uniquely suit their individual and family needs. There is a lot to be said in favor of companies that create a hospitable, flexible climate for their employees. But as the _FT_ editorialist points out: 



Not every employer can introduce flexible work practices and not every job carries high satisfaction levels. To behave as though this were possible could invite cause for dissatisfaction.



If Cameron seeks to mandate Howie's-like flexible work practices, rather than removing existing labor market interference from unions and government, he will end up reducing real flexibility for workers. Furthermore, as UCLA law professor Stephen Bainbridge points out, not every worker wants a non-hierarchical work environment. Not everyone likes being saddled with participation in management decisions in addition to their regular work. Companies should certainly be encouraged to create work environments that inspire loyalty and productivity from their workers---and good returns for their shareholders. And if you're a consumer for whom the production process is part of what you're buying, you should feel free to patronize businesses that reflect your values. But mandating flexibility, or a particular ""work-life balance,"" won't deliver it. The heirs of Thatcher should know this, and it is sad if they think thay have to act like they don't. We'll see.   
  
In defense of GDP, it is worth pointing out that focus on the size of the economy does not imply the state's endorsement of a narrow-minded, acquisitive ethos. Wealth is not a morally questionable, or even a morally neutral, end. It is easy for people to imagine that the size of the economy grows magically, due to some incomprehensible ju ju down in the basement at Google Labs or something. But it's not magic; it's virtue. The economy grows primarily because innovations in knowledge enable us to produce more, and therefore to offer more, to others in cooperative exchange. GDP growth is the steady increase in the size of the surplus from human cooperation. Extended, peaceful, increasingly effective human cooperation is not an easy thing to sustain, and the institutions, and the habits of heart and mind, that do sustain it are moral triumphs. As Deidre McClosky draws out in the brand new Cato Policy Report : 



""Modern economic growth,"" as the economists boringly call the fact of real income per person growing at a ""mere"" 1.5 percent per year for 200 years, to achieve a rise in per capita income by a factor of 19 in the countries that most enthusiastically embraced capitalism, is certainly the largest change in the human condition since the ninth millennium BC. It ranks with the first domestications of plants and animals and the building of the first towns. Possibly, modern economic growth is as large and important an event in human history as the sudden perfection of language, in Africa around 80,000 to 50,000 BC. In a mere 200 years our bourgeois capitalism has domesticated the world and made it, from Chicago to Shanghai, into a single, throbbing city.



There has been no force in history that has done more to promote ""general well-being"" than economic growth. There is no force that will do more good in the foreseeable future. I hope that Cameron takes note that in cross-national econometric studies the only variable that correlates with reported well-being more strongly than GDP per capita is a society's degree of economic freedom.   
  
There _is_ a politics of limited government and personal repsonsibility lurking in the happiness data. If Cameron is going to run on happiness, let's hope he is able to find it, and allay Frank Furedi's worries, and mine, about an illiberal, infantalizing therapeutic state.


"
"The British government has taken its first small steps towards tackling carbon emissions from the most polluting sectors of the economy by ploughing billions into decarbonising heavy industry, transport and heating. The Treasury set out a multibillion-pound plan to support electric vehicles, green home heating networks and carbon capture technology – while cracking down on plastic packaging too.  The Committee on Climate Change (CCC), the government’s official climate advisers, described the Treasury’s package of green measures as a “realistic start” but said it did not “close the climate policy gap” enough to meet the UK’s climate targets. The Treasury’s green pledges include: £1bn on green transport. An £800m fund to develop at least two carbon capture projects. A £270m green heat network fund. A £100m grant for homes to adopt low-carbon heating. A rising levy on gas use through the Green Gas Levy and the Climate Change Levy. A freeze on fuel duty, and scrapping tax relief on red diesel by 2022. A £200-a-tonne tax on plastic packaging with less than 30% recycled content for companies that use more than 10 tonnes a year. One of the Treasury’s most ambitious pledges was its first major investment in carbon capture technology in the last five years. It plans to spend at least £800m to decarbonise at least two heavy-industry “carbon clusters”, the first in 2025 and the second by 2030. These schemes could keep millions of tonnes of carbon from contributing to global heating and create 6,000 highly skilled green jobs in industrial areas such as Teesside, Merseyside, the Humber and St Fergus in Scotland. The funding is less than the £1bn demonstration fund axed by the Conservative government in 2015, and falls short of calls from MPs and the CCC to roll out multiple carbon capture projects by 2025. The government also plans to spend £1bn on green transport, including more than £400m to extend grants for new electric vehicles and £500m to support the rollout of new rapid charging hubs so that drivers are never more than 30 miles away from being able to charge up their car. It has also maintained a long-held freeze on fuel duty for fossil fuel vehicles. Jayne Harrold, a leader on environmental tax at PricewaterhouseCoopers, said the Treasury’s green measures offered mixed messages before the UN climate talks in Glasgow in November. “On the one hand we have the freezing of fuel duty and the building of 4,000 miles of new roads and on the other we have incentives for cleaner forms of transport, minor shifts to energy taxes, and significant investment in carbon capture and storage,” she said. “Let’s hope the autumn strategic review will bring a much more coherent, bigger and bolder approach that really gets it done.” Heating remains a major source of carbon and the government plans to open a grant scheme from April 2022 to help households and small businesses invest in heat pumps and biomass boilers, backed by £100m of exchequer funding. It will also invest a further £270m in a new green heat networks scheme which the Association for Decentralised Energy estimates could help connect 4.25m homes to heat networks by 2050, from 500,000 today. The government also confirmed plans to introduce a plastic packaging tax under which producers and importers will pay £200 a tonne on wrappings with less than 30% recycled content from April 2022. Green campaigners welcomed the tax but questioned why the government was waiting another two years to introduce it."
"
In 2005, the European Union (EU) put into place a  carbon trading scheme. Prices for carbon permits promptly plunged, and have remained depressed since then. The price for a permit to emit a tonne of CO2 went from 21.59 Euros in 2005, to 17.28 in 2006, to 0.68 in 2007, to 2.16 in 2008, to 13.03 in 2009. Today, however, you will be glad to know that some academics declared the scheme a resounding success …

Say what? Here’s what Reuters News Service had to say:

(Reuters) – The European Union’s Emissions Trading Scheme (EU ETS) is a success and its flaws have not harmed its basic aim of reducing carbon dioxide emissions, multi-national research showed on Friday.
 
Experts at French state bank Caisse des Depots, the Paris-Dauphine University, the Center for Energy and Environmental Policy Research in the United States and University College Dublin collaborated to evaluate the scheme’s trial period, which has widely been viewed as a failure.
 
The EU’s flagship carbon trading scheme requires companies to buy permits for each tonne of carbon they emit. Carbon output is capped and the level is lowered year by year.
 
The scheme’s first trading phase ran from 2005 to 2007. Installations in the 27-nation bloc were over-allocated with carbon permits and the carbon price fell to zero.
 
The research concluded that although there were many problems in the first phase, they were overcome and did not hamper the scheme’s ultimate objective of reducing emissions. …   SOURCE  
Now, as some of you might have noticed, I’m a suspicious fellow and I like to run the numbers myself. So, what numbers should we be looking at here?
After some thought, I decided that I would look at the change from the four years prior to the institution of the carbon trading scheme (2001 through 2004), to the first four years of the scheme (2005 through 2008). [Figures for 2009 are not yet available] That would let me see if things improved or got worse.
The most logical measures to look at, it seemed to me, were per capita fuel use and CO2 emissions . (Excel spreadsheet) Using per capita figures removes the effects of  population changes .  If we just looked at fuel use, for example, a population increase would affect the fuel use. I didn’t want to be measuring the effect of population changes, so I used per capita figures.
Using those measures, I decided to compare the EU with the US. Their economies are of a comparable size and development. Since the US is the global CO2 pariah, and has no carbon trading scheme, that would give me a good baseline to compare with the EU performance.
Without further prologue, here are my results:

Figure 1. Percentage change from the period before the EU carbon trading scheme (average 2001-2004) to the period after the carbon trading scheme (average 2005-2008). All measurements are per capita.
By every single measure, the US has outperformed the EU. And the most telling point is that per capita, EU carbon dioxide emissions have increased since 2005 when the scheme started, while US carbon dioxide emissions have decreased. For a scheme designed to reduce emissions, that’s not good news.
The US did better by every measure than the EU, and did it without any restriction on carbon. Now perhaps some folks in a think-tank somewhere call that a whacking great success for the trading scheme … but not on my planet. Call me crazy, but my conclusion is that the EU carbon trading scheme was a failure.




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ce308d3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"**South Africa, which had one of the world's earliest and strictest lockdowns, is marking a significant shift in its fight against coronavirus, writes BBC Africa correspondent Andrew Harding.**
It was hardly a ""mission accomplished"" moment.
South Africa's President Cyril Ramaphosa looked appropriately dour, and sounded appropriately cautious, as he appeared on national television this week to warn of the dangers of a second wave of infections and to urge the public against relaxing their guard against the virus.
And yet the president's key message was a simple, optimistic and impressive truth.
""We have succeeded in overcoming the worst phase of this epidemic,"" he declared.
As the infection rate here sinks below an important threshold of one new case per day per 100,000 people, South Africa is moving - with relief, and with some pride - into a new phase.
What the president and his scientific advisers describe as ""a new normal"".
With almost all economic activity resuming, the nation's borders slowly opening, and one of the world's earliest and strictest lockdowns ending, this feels like a significant moment - an opportunity to take stock, even to celebrate, and to explore the ever-thorny issue of who, or what, should share most credit for containing Covid-19.
""I had visions of Italyâ¦ that we're not ready, that we're going to get overwhelmed,"" recalled Professor Salim Abdool Karim - chair of the government's Covid-19 advisory panel and the public face of the scientific community - thinking back to March, and to what he and the government publicly warned was an oncoming viral ""storm"".
Instead, very few hospitals were overwhelmed, and the official death toll of some 15,000 is significantly lower than even the most optimistic modelling predicted.
Speaking on an internet link from his office in Durban, Prof Karim does not disguise the relief he feels.
But, like many scientists, his inclination is not to sit back and enjoy the good news, but rather to keep probing and testing hypotheses in order to better understand both Covid-19, and South Africa's response to it.
There is plenty of data to wade through now.
Much of it contradictory. Or rather, much of it still needing to be put in proper context.
Take South Africa's long battle against HIV and tuberculosis.
New evidence suggests TB patients are particularly vulnerable to Covid-19.
But, on the flip side, the systems put in place to cope with both pre-existing diseases, ""assisted us and better prepared us to cope with Covid,"" said Prof Karim.
And while South Africa may have good reason to celebrate its successes, there is plenty to criticise too.
""We've had a pretty bad epidemic,"" said Prof Karim.
""At one stage we were the fifth worst in the world. I wouldn't call that something to be proud of.
""I'd have been really proud if we'd been able to mitigate the impact to a much greater extent.""
As we've reported here in recent months, there have been instances of appalling mismanagement, alarming allegations of corruption, and some grave errors in handling the outbreak.
I will leave the economic impact of the lockdown - and the legitimate debate, enriched by hindsight, about whether the government got the balance right - to another day.
But what of the reasons for South Africa's relative success in fighting the virus?
Prof Karim has drawn up a list of nine factors, or hypotheses, which he applies not just to South Africa, but to other countries - not least on this continent - which appear to have been spared the worst.
Nine theories. But true to form, Prof Karim is not fully convinced by any of them, at least not without further proof.
""I doubt that any one of these is a major contributor that explains the entire difference [of why some countries have done better than others],"" he said.
""Even in combination, these would not explain the bulk of the difference we are seeing. It remains intriguing to me."""
"Natural climate solutions let nature do the hard work in the fight against climate change by restoring habitats such as forests and wetlands. This could absorb carbon dioxide from the atmosphere and help biodiversity thrive. Stephen Woroniecki – a PhD Researcher in Climate Change Adaptation from Lund University in Sweden – discusses how this approach could address the ecological crisis with Guardian columnist and environmental campaigner George Monbiot. Q: What has inspired you about natural solutions to climate change and what are their chief advantages over other approaches? They bring together our two crucial tasks: preventing climate breakdown and preventing ecological breakdown. They are all things we should be doing anyway, to limit the scale of the sixth great extinction and protect and restore threatened ecosystems. In these fields, as in all others, we have often tended to act in isolation, replicating effort, failing to recognise the synergies. Natural climate solutions show how we can use the self-regulating power of the living world to help fend off climate catastrophe. I should emphasise that even if we use natural climate solutions to the max, we still need to halt almost all greenhouse gas emissions and leave fossil fuels in the ground, if we are to prevent more than 1.5℃ (or even 2℃) of global heating. But it’s now clear that mitigation alone is not enough: we need to draw down carbon that we have already emitted from the atmosphere. The other main strategies for carbon drawdown are both, in my view, disastrous. The first is bioenergy with carbon capture and storage (BECCS). This means growing biomass in plantations, burning it in power stations to produce electricity, capturing carbon dioxide from the exhaust gases and burying it in geological formations. Any deployment of BECCS sufficient to cause significant carbon abatement will also cause either humanitarian or ecological disaster, because of the vast amount of land – cropland or wild land – the plantations will replace. It is also likely to be self-defeating, due to the massive carbon pulse that conversion of forest lands to plantations will cause, and the vast amount of extra nitrogen fertiliser required, with its associated greenhouse gas emissions. The second is direct air capture. Not only is this likely to be extremely expensive, but the carbon-heavy infrastructure it requires, reliant on a huge deployment of steel and concrete, could help push us past crucial climate tipping points before its positive impacts were felt. These are both bad ways of addressing the problem. Why deploy them when there’s a much better one? Q: Clearly this is an emerging field, and research is needed to understand how best to implement natural climate solutions. What are some of the boldest and most exciting examples that have already been tried across the world that we can learn from and be inspired by? At the moment, the two biggest identified carbon sinks are forests and peatlands, but one of the things that excites me most about this field is how little we yet know. Every year, major new possibilities are identified, in ecosystems that hadn’t been fully considered before. For example, we now know that vegetated coastal habitats – such as mangroves, saltmarsh and seagrass beds – can accumulate carbon 40 times as quickly per hectare as tropical forests can, because of the way they catch and bury organic sediments in waterlogged conditions. One issue that has scarcely been explored at all is the carbon storage impact of stopping trawling and dredging. The seabed is a vast carbon store, but these activities, that scour over three quarters of shelf seas every year, kick carbon into the water column, where it can be oxidised and released. We don’t yet know for sure, as so little research has been done, but it could be that severely curtailing these destructive activities, which we should do anyway, as they are by far the greatest cause of ecological damage to marine habitats, could result in massively greater carbon storage. I should mention two key principles. First, that this isn’t just about creating new or renewed ecosystems. We also need to protect the Earth’s existing carbon repositories – such as old growth forests – whose sequestration capacity would take centuries to reproduce. Second, that fertile cropland should not be used. Mass rewilding of the kind I propose should take place only on less productive land. Unlike BECCS plantations, natural ecosystems can thrive on infertile land, without extra fertilisation. Q: The proposal for a Green New Deal in the US has called for a green transition of society and the economy through investment in renewable energy and by phasing out fossil fuels. How do you see the role of natural climate solutions within a broader transformation of our society and the world we live in? I think natural climate solutions now need to be urgently deployed by all governments, alongside extremely rapid reduction in energy consumption and substitution of fossil fuels. To avoid full-spectrum climate breakdown, we need a global cooperative effort on a scale that has not yet materialised. My hope is that the new, uncompromising mood among young people, and the brilliant protest movements, such as the Youth Strike4Climate and Extinction Rebellion, will help to make this happen. Q: Geoengineering proposals are often criticised for taking risks with natural systems that could have catastrophic consequences, often with little to no consultation from the people who could be most affected. How do we ensure natural solutions are carried out democratically and without echoing the technocratic arguments of many geoengineering projects? Whatever we do has to be done with and through the people it might affect, under the “nothing about us without us” principle. Natural climate solutions must work with the free, prior and informed consent of indigenous people and other local communities, and their benefits must flow to these communities. No project should be pursued that undermines their land rights, economic security and well-being. On the contrary, all projects should seek to strengthen them. There are some excellent examples of how this can be done around the world, compiled by the Equator Initiative. Q: Restoring natural habitats can sometimes mean giving authority to external experts at the expense of local people. What do you think is important to bear in mind when making the case for natural solutions to local communities? I believe all projects should be guided by the Freirean approach – developed by the Brazilian philosopher Paolo Freire – of mutual education and understanding. An outsider should not turn up with the attitude that she has come to impart her superior knowledge to local people. She starts by asking them to teach her about themselves, their lives and needs, and to exchange knowledge, in the hope that all become both educators and educated. The outsider might bring new ideas and perspectives – that are, I believe, essential – while local people bring intimate insights into and knowledge of the peculiarities of place and community, that are also essential. Q: How can people get involved in designing, implementing and managing natural solutions to climate change? We list on our website the organisations already involved in the field, some of whom would welcome your help. But the most important thing right now is to spread the word as far as you can. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"**The Government of Jersey has been given the power by the States Assembly to make wearing masks in shops mandatory.**
Members also approved laws to limit the size of gatherings, as part of updated Covid-19 regulations.
Currently the wearing of masks is not legally enforceable, with the government continuing to promote them in guidance.
The regulations have not created new rules, rather they have set the terms of possible restrictions.
The maximum penalty for individuals breaching any mask or gathering law would be set at Â£1,000.
Children under 12 years old would not have to wear a mask, along with people exempt for health or disability reasons, according to the regulations.
If a law requiring wearing of face coverings is introduced, it would apply to specific workplaces where a member of the public is present as a customer.
The regulations also allow orders to oblige businesses to collect personal data to aid contact tracing and to refuse service to those not wearing masks.
Any restrictions on the size of gatherings will only apply to groups of 10 or more people.
Visiting people's homes in Jersey was banned during the first wave of the pandemic before the ban was lifted in May, although public health guidance has discouraged meeting indoors since."
"
Share this...FacebookTwitterLast week parts of Germany’s media were reporting on the latest (again) alarmist findings of the Max Planck Institute (MPI), which announced that the Arctic was melting faster than expected, and that its latest model scenarios projected an ice-free Arctic in the summertime by the middle of the 21st century and, should CO2 emissions continue their rise, the Arctic would also be ice-free in the wintertime.
The Arctic is melting faster than expected, alarmist Max Planck Institute claims (US Navy photo)
But today something is different. Back just a couple of years ago, media coverage of such announcements in Germany were far more intense and spectacular. Not so today. Fewer media are turning up for the weekly end-of-world press conferences. Major media outlets are gradually losing interest in the fading climate catastrophe. Indeed it’s as if some are realizing that something is rotten in Germany’s once prestigious climate science institutes – and in those around the world.
For example, top selling German daily Bild did not even bother to feature the MPI’s Arctic meltdown press conference. Instead Bild featured a story on how clouds have been getting lower and that a negative feedback seems to be in play and is acting to cool the planet.
German flagship news magazine Spiegel also skipped reporting on the MPI doom and gloom crystal ball model findings, at least online up to now. Instead it featured a story on the Gleick stolen identity and document theft scandal in the USA, thus further tarnishing the already soiled image of climate science today.
So when Bild newspaper and Spiegel shift gears and change directions, then it’s undoubtedly a worrisome development for those on-board for the climate catastrophe joyride. Gone are the days of universal, lock-step media consensus.
Germany’s movement of skepticism started some years ago, and then picked up steam in 2009 in the wake of the Climategate emails and Germany’s 2nd international skeptic climate conference. A series of brutal winters, combined with weird Politburo-type explanations claiming it was caused by warming, provided yet more fertile ground for the seeds of skepticism. German skeptic blogs also sprouted and coordinated. The Internet buzzed with skepticism and before you knew it, the global warming establishment began having fits about the budding open discussion.
Then came Vahrenholt and Lüning.
Bild Feb. 6 page 2 story.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And with them a mushroom cloud. On February 6, influential Hamburg-based publisher Hoffmann & Campe released a skeptic book called “Die kalte Sonne” – on what happened to be Germany’s coldest day of the winter. The release of the book also coincided with Bild’s smashing page 2 story “CO2 Lies – Renowed Team of Scientists Catastrophe Is Panic Mongering” and Spiegel’s “We’re Being Fooled” interview with Vahrenholt.
Die Welt newspaper followed the next day with a full page report called “The Sun is Giving Us Time“. In no time Vahrenholt’s and Lüning’s book became a bestseller. The grand climate gig was over.
Even more revealing was the reaction of the German environmental press and the alarmist climate institutes. Jochem Marotzke, director of the Max Planck Institute for Meteorology in Hamburg slammed the book, but did so without even reading it. So did Mojib Latif. Both claimed that the book’s line of argumentation had long since been dispelled. But this was a ridiculous claim since the book’s conclusion is based in large part on the latest scientific findings, which are now just in the process of being discussed. The few other counter arguments that they offered were of pre-IPCC AR4 nature. They fully neglected solar amplification mechanisms and ocean cycles. Horrifying is the appearance that these renown scientists are not even aware of historical climate cycles.
Lüning recently wrote that he had expected much tougher counter argumentation and is surprised that it’s been so easy so far.
Hartmut Grassl, former Director of the Max Planck Institute for Meteorology, took on an indignant attitude in a TV interview, refusing to even acknowledge the book and insisting his catastrophe fantasy is real.
The University of Osnabrück even cancelled a scheduled speech by Vahrenholt at the last minute, saying it wasn’t interested in his kind of discussion – calling it “provocative”. One student later told me that she found the University’s reaction strange and had nothing to do with expanding knowledge.
Today these institutes wonder why influential media like Spiegel and Bild are no longer bothering to report on their science. It’s not surprising – you can hear “We’re right, and we don’t want to discuss it!” only so many times before you lose interest altogether.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Ed Caryl
The sun supplies about 1360 watts per square meter to the Earth as seen by satellites at the top of the atmosphere. This power varies by about 1.3 watts over the 11-year solar cycle. Energy is reflected back to space by clouds and the earth’s surface. Some energy is radiated to space as infrared. Energy is radiated from the atmosphere to the surface, the so-called greenhouse effect. There is variation in all the factors that make up the radiation balance. None of the factors are fixed. CO2 may be increasing, but other factors are also changing. The albedo of the Earth varies with the amount of cloud cover, seasonal vegetation, ice, and snow. Of course the heat seen by any part of the Earth depends on the sun angle; the maximum is when the sun is directly overhead, almost none when the sun is on the horizon, none at all when the sun is below the horizon. The Earth loses heat to space by radiation, but this also varies with time of day, cloud cover, temperature, and humidity.
Water vapor accounts for 60 to 95% of the greenhouse effect. The remainder is due to CO2 and other trace gases. According to the IPCC the theoretical extra absorption by CO2 in the atmosphere if it doubled from the current amount is 4 watts per square meter. This extra absorption will be modified by clouds, cloud height, humidity, and other factors. According to the same source, the extra absorption at current levels of CO2 above the historical level is about 1 Watt. This additional energy is offset and balanced by the other outgoing factors. For an excellent explanation of the greenhouse effect see: http://www.ucar.edu/learn/1_3_1.htm.
Figure 1 shows how solar energy input is balanced by the radiated and reflected output. The 342W per square meter solar input figure is an average over the Earth’s surface that supposedly takes into account sun angle and the night and day cycle. This graphic is from Wikipedia and is seen in many publications in two versions with slightly different numbers. It originates with Kevin Trenberth et al.
One of the criticisms of this graphic is that the 342 W/m2 Back Radiation is assumed to be completely absorbed by the surface with no reflection. This would require that the surface be a perfect black-body at all wavelengths. This is obviously not the case. Another criticism is that it inadequately describes the difference in radiation conditions between night and day, and the variable influence of clouds.

Figure 1: Earth’s radiation balance according to Kevin Trenberth et al.
A third criticism is that it does not take into account the Earth’s albedo changes over time. Albedo is the percent of solar radiation that is reflected back to space by the Earth’s surface and clouds. The Earth’s albedo is measured by satellite or by looking at earthshine on the moon, the light from Earth reflected back from the lunar dark side. Here are Earth’s albedo changes from 1984 to 2004.

Figure 2, Earth’s albedo:  The red vertical bar represents the total forcing of all the greenhouse gases added to the atmosphere in the last 100 years. Using the IPCC figures, they add up to about 2.8 W/m2, about the same as the albedo variation. Clearly the albedo variability is the same as the greenhouse gas forcing, especially over any short term. The albedo change is primarily due to cloud and ice changes. Data source: Pallè et al here.
Albedo isn’t the only variable in the radiation balance graphic. The opposite of albedo (reflectance) is transmittance, the percentage of solar radiation that reaches the surface. This is also a variable, changing with the amount and kind of aerosols in the atmosphere. Since 1958 this has been measured at Mauna Loa Observatory in Hawaii, the same place that CO2 is measured. Their data is stated in percentage and is taken under the following conditions.
The ‘apparent’ transmission, or transmission ratio (Ellis & Pueschel, Science, 1971), is derived from broadband (0.3 to 2.8um) direct solar irradiance observations at the Mauna Loa Observatory (19.533 ° N, 155.578 ° W, elev. 3.4 km) in Hawaii. Data are for clear-sky mornings between solar elevations of 11.3 and 30 degrees.”
In the chart below the data has been converted to energy anomaly, based on the solar irradiance at the top of the atmosphere, 342 W/m2, in Figure 1 above.

Figure 3: Atmospheric transmission anomaly in terms of energy in Watts/m2.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




You can see that the transmittance anomaly is quite large, even disregarding very large perturbations such as the Agung, El Chichón, and Pinatubo volcanoes. Pinatubo is also visible in the albedo data. All traces are annual averages.

Figure 4: Annual albedo and transmittance in W/m2, and global annual satellite temperature anomaly plotted together.
Because transmittance and albedo are inversely related, in the chart above, albedo (the red trace) has been inverted so that transmittance, albedo, and temperature can be related. The temperature anomaly is scaled on the right axis. The two volcanic eruptions and the last two El Niño’s can be clearly seen in the temperature. The dip in transmittance in 1963 is the Agung volcano. All three volcanic eruptions were sulfur-rich and pushed gasses and dust into the stratosphere.
What about greenhouse gases?

Figure 5: Greenhouse gas forcing since 1978.The scale is also in W/m2. Source.
Figure 5 uses the IPCC figures for greenhouse gas forcing, 4°C for CO2 doubling, which may overstate the numbers. CO2 and methane (CH4) dominate the total. But let us plot the total greenhouse gas forcing (the top trace in Figure 5) on the Figure 4 graph.

Figure 6: Albedo, greenhouse gases, transmittance, and TSI anomalies plotted together with the Global Satellite Temperature anomaly. The transmittance linear trend line is also included. The vertical scale has been changed, truncating the large negative transmittance spikes, so that the smaller forcings can be seen.
The TSI anomaly has been added to Figure 6 along with the greenhouse gas trace. Note that the transmittance trend is in the opposite direction of the greenhouse gases, and is of similar magnitude.
It is clear that aerosols, albedo, and ocean cycles are very largely what drive global temperature in the short term. Carbon dioxide is a minor player. TSI (total solar irradiance) plays very little direct role on this time scale. If the sun has an effect it must be via some other mechanisms.
Because we know so little with certainty about water vapor, it has been left out of this analysis. Water vapor is a very important greenhouse gas, by some accounts resulting in 60 to 95% of the greenhouse effect. The problem is that because water exists in all three phases in the atmosphere, and convection, evaporation, condensation, and precipitation produces wildly variable amounts at different altitudes, times, and locations, calculating the resulting forcing is very problematic. In general, water vapor tracks temperature. In the lower troposphere, this has meant that water vapor is increasing along with temperature. Some have stated that this results in positive feedback further increasing temperature. But in the stratosphere, the temperature has been decreasing, and so has the water vapor content. (See discussions here and here.) This allows increased radiation to space. As a result, others have argued that this results in negative feedback. It may well be that the two variabilities cancel.
Among the variables that control climate change, atmospheric transmission is by far the largest factor. Even in the absence of volcanic activity, upper atmosphere aerosols vary on a scale that dwarfs the other factors. Ocean cycles are next in importance. Third in importance is albedo. The reflection of clouds, ice, smoke, land and sea surfaces are continuously changing. Fourth on the list are the greenhouse gases excluding water vapor. The big unknown variable is water vapor. We know it is varying. To some extent we even know how much. What we don’t know is what forcing water vapor provides. We don’t even know where water vapor ranks on this list.
 
Share this...FacebookTwitter "
"Independent MP Zali Steggall is launching a national advertising campaign drawing on the summer bushfire crisis to rally public support for her private member’s bill on climate change, due to be introduced to parliament later this month. The campaign will kick off on Monday and include digital billboards, and bus shelter and telephone booth advertisements across Sydney, Melbourne, Brisbane and Adelaide.  The ads will feature images of the destruction wreaked by the summer bushfire season, with one pointing to the experience of “one hell of a summer” and another featuring a koala in burnt bushland. The ads call for the public to support Steggall’s climate act, making the appeal that “what happens next is up to you”. The campaign is being funded by community climate change groups, donors of the Climate Act Now campaign and pro-bono assistance, with more than 120 “Climate Act Now” advertisements set to appear across the country this month. Steggall is hoping to garner bipartisan support for a national climate change framework bill aimed at transitioning Australia to a decarbonised economy that is based on the UK’s Climate Change Act, passed in 2008. The bill would put in place national plans for climate change adaption and enshrine a net-zero emissions target by 2050 to be reviewed every five years by a newly established independent climate change commission. Steggall has been arguing that the framework legislation would take the politics out of the climate change policy debate, while putting in place an effective process for national targets, actions and reporting. She has been lobbying both Labor and government MPs to allow a conscience vote on the legislation, and has already locked in the support of the crossbench in the lower house. On Monday, four digital billboards will be in place in Melbourne, Brisbane and Adelaide, followed by a rotating poster advertisement campaign across the Sydney CBD and North Sydney, and in Melbourne. Steggall said the campaign was designed to keep the legislation in the public eye, and said there was strong support coming from North Sydney and Wentworth, where moderate Liberal MPs are under pressure to do more on climate change. “After such a horrific summer, this advertising campaign is there to remind Australians that the country needs a sensible approach to climate change,” Steggall said. “We have received enormous support from our neighbouring electorates of Wentworth and North Sydney who want their local federal members to vote for the bill.” So far more than 73,000 Australians have supported the climate change bill through the “Climate Act Now” website. While the bill will be introduced when parliament next sits on 23 March, there is a risk that it will be left to languish on the notice paper without government support. If the government refuses to allow debate on the bill in the House of Representatives after it is introduced, Centre Alliance, which is co-sponsoring the legislation, could introduce it into the Senate later in the year. This would force Labor to declare its hand on the bill, which has so far failed to land a position, saying it will never come to a vote in the lower house. “For Zali Steggall’s bill to be considered, Scott Morrison would need to allow a full debate in the parliament,” the shadow climate change minister, Mark Butler, said last month. As part of the campaign, B-Corp – a group that certifies businesses for making positive decisions on the community and the environment – will support the bill , backed by 16 of B-corp’s 300 registered companies. Community groups in Wentworth and North Sydney have also funded particular advertising within their electorate."
"

Nearly eight‐​and‐​a‐​half years after its initial application, the Keystone XL pipeline project has been given the green light (“subject to a renegotiation of terms by us”) by an executive order signed by President Trump today. Finally.   
  
  
Whether the impetus and economics is still there to build it (with oil prices in the mid-$50 barrel range) remains to be seen. But I’d imagine so, if nothing more than as an infrastructural investment in the future.   
  
  
But from the federal government standpoint, this shouldn’t matter. If private monies want to take the risk, the federal government should not stand in the way. After all, the Keystone XL pipeline passed each and every environmental impact/​safety assessment along the way. Even the climate impact, much touted and hyped by the previous Administration and its supporters, was shown, dispassionately, to be inconsequential—a mere 1/100th of a degree of warming by century’s end (and that’s being generous).   
  
  
President Obama rejected the pipeline for no other reason than for appearances—to make it seem to the rest of the world that the U.S. was serious about climate change. Apparently, he didn’t see the irony.   
  
  
His successor is resurrecting the pipeline for the same reason—appearances. In this case, the appearance of creating jobs. But as I exasperatingly explained in these pages some two years ago (“Keystone XL Pipeline: Enough Already!”):   




This project is so small in the grand scheme of _any_ thing it boggles the mind anyone outside of those directly involved in building and operating it gives it a second thought…   
  
  
At this point, the Keystone XL is just another construction project. In fact, that is all it ever was. If it didn’t require crossing the border with Canada (which required a “presidential permit”), we never would have heard a peep about it.



With the pipeline’s apparent revival, now at least, all the government resources spent examining and re‐​examining and fretting and re‐​fretting, etc. over the project will have amounted to something—even though that something should have been decided (and approved) some four or five years ago.   
  
  
What executive powers taketh away, executive powers giveth. I’m sure this won’t be the last of Obama’s symbolic actions on climate change that President Trump overturns. Each will better clear the way for us to move on to more important matters.   
  
  
—   
  
  
Update: With the release of the actual text of the Executive Order (made available several hours after Trump signed it), it’s not so much an “approval” of the Keystone XL pipeline as it is an invitation for TransCanada to resubmit its application with the promise that it will be decided upon within 60 days with, wink, wink, a more favorable outcome. So, it seems though this won’t be the last we’ve heard of it, this battle is moving closer to its completion.
"
"

U.S. foreign policy is changing. With the selection of CIA Director Mike Pompeo to replace Rex Tillerson as secretary of state, President Donald Trump appears to be taking charge of his foreign policy. National Security Adviser H.R. McMaster and Defense Secretary Jim Mattis remain counsels of caution on many issues, but the former’s tenure could be short, and the latter might choose to exit if his advice has increasingly less effect.



Secretary Tillerson’s departure reflected both personality and substance. He and the president never established personal rapport. Last fall the secretary was reported to have called the president a “moron,” which suggested a relationship irreparably sundered. Moreover, the two disagreed on many, if not most policy issues: negotiation with North Korea, nuclear agreement with Iran, the dispute between Saudi Arabia/​United Arab Emirates and Qatar, Russia, climate change, and free trade.



The outcome is likely to result in several course corrections, mostly in a more confrontational and hawkish direction. China in particular is more likely to become a target of the administration. That already has happened on trade, with Peter Navarro, more nationalist than economist, pushing for a trade war against virtually everyone, ranging from Europe and Mexico to South Korea and the People’s Republic of China. Although Pompeo is no protectionist, unlike Tillerson he probably won’t challenge his boss on the issue. After the administration announced its tariffs on aluminum and steel, Pompeo cited “trade or the theft of intellectual property” as areas where the administration was “pushing back against” the PRC.





Whatever the prospective secretary thinks of China, he must work to make the relationship work.



On both Iran and North Korea, the CIA director disdained diplomacy. Indeed, he appeared to welcome possible regime change in Pyongyang, in contrast to Secretary Tillerson, who denied such an interest in an attempt to assuage North Korean concerns over giving up the regime’s missiles and nuclear weapons.



Secretary‐​designate Pompeo also appears to take a harsher attitude toward the PRC. Of course, Rex Tillerson suggested the possibility of interdicting Chinese ships in the South China Sea during his confirmation hearing. However, he took a more restrained and responsible stance once in office.



Nevertheless, Pompeo starts with a negative view of Beijing. Last year, regarding security threats, he said in one interview: “It’s hard to pick between China, Russia and Iran to be honest with you. I guess if I had to pick one with a nose above the others, I’d probably pick China.” He pointed to the PRC’s economic strength, population, and intellectual property theft. Moreover, he said, “I think it’s very clear when they think about their place in the world, they measure their success in placing themselves in the world where they want to be vis‐​á‐​vis the United States and not as against anyone else.”



He perceives a potentially dangerous rivalry between China and the United States: “It is also the case that the Chinese have moved to a place where they, I think, see themselves as a rival superpower.” Moreover, “They have as part of their mission to reduce the relative power of the United States vis‐​á‐​vis their own country.” Pompeo recently told the BBC that, “We have to do better pushing back against Chinese efforts to covertly influence the world.” He also emphasized the problem of Chinese espionage, obviously reflecting his position as CIA director.



He believes that administration pressure caused Beijing to shift its position on North Korea. Last August he praised the president: “We’ve seen the Chinese now say for among the first times that they believe the correct answer has to be a denuclearized peninsula. And that’s exactly the policy of the Trump administration.” Of course, the PRC has taken that position for years. Beijing has steadily, if sometimes erratically, backed ever‐​tighter economic sanctions against the Democratic People’s Republic of Korea. Administration pressure may have accelerated China’s willingness to act, but so did the speed‐​up of North Korean missile and nuclear testing. Unfortunately, Pompeo’s belief that administration action caused the PRC to cave could influence his future positions.



Shortly before being chosen as secretary of state he declared that “this administration has been very clear of pushing back against the Chinese threat.” More specifically, “If you look at the president’s national security strategy, it was very clear that what the Chinese are doing, whether that would be on trade or the theft of intellectual property or their continued advancement in East and South China Seas, this administration is prepared and engaged in pushing back against the Chinese threats so that we can have a good relationship with China in a way that the world desperately needs.” Alas, Beijing may not perceive these steps as an invitation to have “a good relationship.” CNBC’s Jim Cramer worried that Pompeo’s appointment “says to China you are our enemy.”



Pompeo was not uniformly negative about China. Last fall he praised its efforts regarding North Korea and said that “We think that President Xi will come out of this in a dominant position with incredible capability to do good around the world.” Whether he believes the Chinese president actually will do so is not so clear. Although the incoming secretary’s attitudes toward the PRC sound tough, they are not unusual. If U.S. policy shifts, it is likely to be in degree rather than in kind, as Pompeo reinforces rather than counterbalances the president’s views.



That almost certainly will be true elsewhere, such as Iran. The sanctions waiver comes up for renewal in May.



There is no similar deadline for China-U.S. relations, but there is no more important long‐​term issue. American analysts, pundits, and officials all have legitimate concerns about the direction of policy toward the PRC. However, it is important that Washington avoid treating Beijing as an enemy. Whatever the prospective secretary thinks of China, he must work to make the relationship work. Upon his and the administration’s success will depend peace and stability in East Asia.
"
"**Here are five things you need to know about the coronavirus pandemic this Wednesday evening. We'll have another update for you tomorrow morning.**
The chancellor has warned the ""economic emergency"" caused by coronavirus has only just begun in the UK. In his Spending Review, Rishi Sunak said the pandemic would deal lasting damage to growth and jobs, and that it had triggered the largest fall in Britain's economic output for 300 years. He added that the UK economy is expected to shrink by 11.3% this year and not return to its pre-crisis size until the end of 2022. And he confirmed a pay freeze for most public sector workers and a cut in overseas aid. Our economics editor Faisal Islam says the UK economy remains ""in rescue mode"". Read the key points from the chancellor's statement, how the Spending Review will affect you and why some young people think Mr Sunak hasn't gone far enough.
The number of unemployed people will surge to 2.6 million by the middle of next year, according to the government's independent forecaster, the Office for Budget Responsibility. The latest figures show 1.62 million people are unemployed, a number which has risen by more than 300,000 since last year amid the coronavirus pandemic. The last time the UK unemployment figure was as high as 2.6 million was in May to July 2012. The number exceeded 3 million from 1983 to 1987 and for a few months in early 1993. In his Spending Review, the chancellor said government borrowing will rise to its highest outside of wartime to deal with the economic impact. So, why is unemployment rising?
People have been urged to consider the risk of spreading coronavirus when rules are relaxed over Christmas. It comes after it was confirmed that up to three households will be allowed to stay together and form a ""Christmas bubble"" from 23 to 27 December, as agreed by all four UK nations. Prime Minister Boris Johnson told people to use ""personal judgement"" on whether or not to visit elderly or vulnerable relatives. Meanwhile, there have been calls for a UK-wide approach to coronavirus rules after Christmas. Wales' First Minister Mark Drakeford said it ""makes sense"" to ""respond to the consequences of greater household mixing"" together in the aftermath of the five-day period. Here's our guide to the Christmas rules and how to keep the virus at bay this festive season.
The number of domestic abuse offences recorded by police in England and Wales has increased during the pandemic. However, the Office for National Statistics said such offences gradually rose in recent years so it cannot be determined if it was related to the pandemic. Police recorded 259,324 domestic abuse offences between March and June - 7% up on the same period in 2019. During and after the first lockdown in April, May and June, roughly one-fifth of offences involved domestic abuse.
Intensive care nurse Valerie Bednar, who struggled to get face masks to fit her, has inspired the design of custom-fit ones for frontline healthcare workers. Her husband Gareth Smith set up MyMaskFit, which is aiming to become the first in the UK to make custom-fit, reusable, filtering face piece masks to a medical grade standard. Based in Swansea, the firm hopes to further develop a prototype designed by researchers at Birmingham University and King's College London - with the aim of making them available to the NHS in Wales in the new year. Read Valerie and Gareth's story.
Get a longer news briefing from the BBC in your inbox, each weekday morning, by signing up here.
Find more information, advice and guides on our coronavirus page.
Plus, remind yourself of the rules for visits to pubs and restaurants over the Christmas period.
**What questions do you have about coronavirus?**
_ **In some cases, your question will be published, displaying your name, age and location as you provide it, unless you state otherwise. Your contact details will never be published. Please ensure you have read our**_terms & conditions _ **and**_privacy policy.
Use this form to ask your question:
If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or send them via email to YourQuestions@bbc.co.uk. Please include your name, age and location with any question you send in."
"When Linda Erskine looked outside her window last week, she saw an intense flare from the Mossmorran petrochemical plant in Fife. The flaring, which she says collapses night into day, can be seen more than 20 miles away in Edinburgh. Erskine, a local Labour councillor, describes living in Lochgelly, a former mining community neighbouring Mossmorran, as unpleasant. “When that flare goes, the house does vibrate. For me it’s something akin to a Nimrod [maritime patrol plane] landing on top of your house. The first time I went out to see if there’s a helicopter flying overhead.”  Residents, who formed a local action group, are calling on the government to set up an independent inquiry into the health, social, and environmental impact of what they describe as an “ageing” plant, but this demand has been ignored. For the local community, the flaring has come to symbolise a disconnect from the Scottish government’s rhetoric about the climate emergency and what it does on the ground. ExxonMobil’s Fife Ethylene Plant at Mossmorran began production in 1985. Flaring, a process that burns off gas that cannot be processed, can last for several days. As well as planned flaring events, unexpected flaring also occurs as a safety mechanism. It’s legal on the site that ExxonMobil shares with Shell Fife NGL, but the company has a duty to mitigate the impact it can have on local communities. Last April, the Scottish environmental agency (Sepa) launched a criminal investigation into ExxonMobil because of unplanned flaring. The investigation follows “final warning letters” issued to ExxonMobil in April 2018 regarding flaring that was found to be “preventable and unacceptable”. “In our bedroom, which faces towards Mossmorran, it’s impossible to keep the light out. It’s a nightmare,” said Joe Purves, a 69-year-old recently retired accountant who has lived in Lochgelly for 45 years. He believes the frequency and severity of the flaring has got worse over the last few years. “The community are told when there’s going to be planned flaring, but it’s the fact the emergency flaring keeps on taking place,” said Linda Holt, an independent councillor at Fife council. “They always say it’s ‘process upset’ but everyone knows it’s because something has gone wrong. And things have gone wrong more in the last few years because the plant is ageing.” Last summer, the plant was shut down to address the mechanical issues the company was having with its boilers and implement preventive work to improve the plant’s reliability. But unexpected elevated flaring occurred within a month of the plant reopening in February, sparking widespread anger. Chris Dailly, Sepa’s head of environmental performance, said the watchdog had made it clear ExxonMobil needed to invest further in flaring mitigation technologies and given the company a timeline for compliance. “We’ve been clear that flaring has been unacceptable and that compliance with Scotland’s environmental rules is non-negotiable,” he said. While 42-year-old James Glen, a graphic and web designer who set up the Mossmorran action group in 2017 with Holt, welcomes Sepa’s investigation, he argues it’s not enough. The action group calls for an independent inquiry that looks at health, site safety, and social issues. More than 2,000 people have written to the Scottish environment secretary, Roseanna Cunningham, echoing the action’s group demand. A spokesperson for the Scottish government said that as Sepa was concluding its investigation, it “would not be appropriate nor helpful for ministers to interfere in independent regulatory decisions, particularly while enforcement investigations are ongoing”. Glen accuses the Scottish government of “hiding behind Sepa” and said it should come to meet the community to discuss their concerns. Erskine said Holyrood is already losing credibility on the issue. “We should be looking after our constituents, not big business. Our job is the safety and wellbeing of the people that live here. If that plant had been any place near Edinburgh, it would have been shut down.” Glen says the community’s concerns about their health had long been dismissed until a 2019 NHS Fife report, which he believes just scratches at the surface, concluded “it is clear that the degree of physical and psychological disturbance caused to people in the vicinity of Mossmorran has been considerable”. The report noted the most common health-related concerns among local residents were anxiety, respiratory issues such as asthma, sleeping difficulties, and headaches. It found no evidence of higher than expected cancer rates, while 32 Sepa’s air quality reports demonstrate no breach of the UK air quality standard. Stuart Neill, the plant’s public affairs manager, said: “We very much regret any concern that flaring may have caused to members of the local community. The safety of our people and neighbours is our most important priority and the ability to flare is a critical part of the plant’s multiple safety mechanisms.” Neill added that the plant is one of the youngest facilities of its kind in Europe and as well as investing £20m annually in maintenance, this year the company would be investing an additional £140m to upgrade infrastructure to improve operational reliability and reduce flaring. Glen set up an impact map so residents can report health, social or environmental issues related to Mossmorran. There have been 363 incidents added so far. One report from a resident in Edinburgh notes: “I genuinely thought tonight that there had been an explosion at the plant given the intensity [of the flaring].” Another writes: “If we see it as far away as North Berwick what must it be like up close?”"
"The challenges of growing enough food to feed the world have grown more severe in the 21st century. We need to feed more people with limited agricultural land and resources. We need to make better use of land, light and logistics for an increasingly urban population. And we need to incorporate zero-waste and low-energy technologies into the task of food production. What can achieve the intensification of food supply we require, but in a way that is also sustainable and less harmful to the environment?  There is an urgent need to develop new methods for sustainable food production. This includes a greater emphasis on urban agriculture such as vertical farming which, properly designed and planned, could provide the sustainable means to improve food supply we need. Ideally, urban agriculture fits neatly alongside or within existing buildings in a self-contained and sustainable manner without competing for resources. Such urban plots can be at ground level or on rooftops. They can use greenhouses in order to take advantage of the sun’s energy, or grow indoors with the help of artificial lights. Vertical Farming is promising because it requires no soil, and can save space and energy – and improve crop yield. It takes advantage of the vertical space of city buildings rather than turning over wide expanses of land to agriculture and uses advanced greenhouse technology: hydroponics or aeroponics, and environmental controls that regulate temperature, humidity and light to produce vegetables, fruits and other crops year-round.  In large cities such as New York, Chicago, Tokyo and Singapore, these ideas are taking root. Singapore has taken local urban farming to a high level – Skygreens has built the world’s first commercial vertical farm in large three-storey greenhouses, providing a sustainable source of fresh vegetables.  Vertical farming’s biggest limitation is energy consumption. Considerable energy is required to power a closed, indoor greenhouse facility’s artificial lighting, heating and cooling, and hydroponic or aeroponic growing systems. The amount of energy required per unit of product is an important factor for ensuring not only that the farm is sustainable, but that it is economically viable. Recently, more and more studies have focused on pairing solar panels and wind turbines with greenhouses to provide self-generated renewable electricity on-site.  But the single technology that will be key to making vertical farms possible is lighting. New LED light technology is the key that makes it possible to build vertically integrated farms. This kind of artificial light has an extremely high photoelectric conversion efficiency, consuming only one eighth the power of incandescent lamp, half of the power of fluorescent lamp, and using a lower supply voltage (6-24V) that makes it safer to work with and reduces transmission losses.  They’re also physically small, have a long service life, lower power consumption, generate less heat, and can produce light of varying intensity. Because it produces less heat, the light can be moved closer to the plants. This increases efficiency, not just in terms of energy use but by allowing layers of growing plants to be more densely packed, making more efficient use of space.  LED lights can be tuned to emit only a narrow wavelength of light, they can be combined to create perfect lighting that provide light on the ideal spectrum for a plant’s growth. Evidence is emerging that specific wavelengths of light have distinct effects on crop yield, quality, and even pest and disease resistance.  There is potential for these multifunctional techno-greenhouses built around LED grow lights to increase the quality of the food we eat and the amount that we can grow with the same land and resources: the very 21st-century problems we now face – and through technology are getting closer to solving."
"
Cover page
Just a note to let everyone know that the Parliamentary inquiry into Climategate has produced the final report and that I have an advance copy, which is embargoed until 5:01PM PDT (00:01 GMT).
I’ll be posting it then, be sure to check in.
There are some wins in it, and there are some disappointments too. I’ll also provide links to other analysis and commentary that arises after the embargo lifts.
Layman readers should bear in mind that this report comes from a bunch of policy wonks, so there’s that sort of flavor to it. OTOH, they seem to have done a better than usual job of trying to communicate their findings.
Unfortunately, the inquiry failed to interview key people, such as Steve McIntyre, and for that they deserve an earful IMHO.
In the meantime, Mike Haesler points out in comments that the Irish Times apparently didn’t wait for the embargo to lift:
Climate unit criticised for stonewalling sceptics
http://www.irishtimes.com/newspaper/breaking/2010/0330/breaking78.html


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8d20675e',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"It was hard, chilly work for nine-year-old Alfie Perry and his eight-year-old classmate Dempsey Owens. But, after a bit of cajoling from their pals and teacher on a windswept hillside above the town of Neath, the pair succeeded in planting a sessile oak that could soon be part of a forest stretching continuously the length and breadth of Wales. The Welsh government is initially ploughing £5m into its national forest scheme, aiming to link existing woodland with new forests, parkland and hedges, creating green corridors for flora and fauna – and people. The Labour-led government says the scheme will help it to create new, important environments, meet carbon reduction targets, combat flooding – but also boost tourism and people’s sense of wellbeing as they criss-cross the country under, or next to, trees. Lesley Griffiths, the Welsh government’s environment minister, was on hand in Neath to help Alfie and Dempsey dig and set out the vision. “We love our woodland in Wales,” Griffiths said. “Welsh businesses, communities and, particularly, our farmers and foresters, will want to help create the national forest.” Griffiths accepted there would be challenges but pointed out that people had doubted the country could create a footpath right around the coast, but it had done just that. “We’re a small country. You’re able to do things differently.” The spot for the launch – Coed Brynau - is a beautiful one. High above Neath, with views of the Brecon Beacons and the Mumbles Lighthouse, Coed Cadw (the Woodland Trust in Wales) is in the process of planting 150,000 trees here by 2025, including rare species such as the small-leaved lime and the black poplar. The estate used to be owned by the coalmine owner and Tory MP Herbert Mackworth (1687-1765), who created a parkland on the hill. There are vestiges of ancient woodland that will be linked with the new tree planting. The area is home to barn owls, Daubenton’s bats and possibly the very rare blue ground beetle. Welsh white cows, which look ghostly in the landscape, are being introduced to graze grassland areas of the site. There is not yet a route for the forest – this will evolve as the consultation moves on. But Natalie Buttriss, director of Coed Cadw, suggested one option could be to link the great forest of Wentwood in Monmouthshire along the M4 corridor to Coed Brynau. It could then head north towards the “Celtic rainforest” of mid Wales and Snowdonia, one of the most important and historic habitats in Wales, and perhaps veer east towards Wrexham, where a plan is in place to increase the urban tree canopy to a minimum of 20% by 2026. Chris Matts, Coed Cadw’s woodland manager for south and west Wales, likes the government’s ambition, though he thinks perhaps forest is the wrong word. “It’s a word that in English originally meant a hunting ground for kings,” he said. Matts prefers the Welsh word: coed, which has more of the connotation of “an area of trees”, which takes in parkland and hedgerows as well as thick forest and woodland. Mary Gagen, a professor of geography at Swansea University, praised the ambition of the scheme. “We need to get trees in the ground now. Trees are a brilliant multi-tasker, good for the environment, good for habitats, good for us.” The Welsh first minister, Mark Drakeford, said the February floods reinforced the need to plant more trees. “In planting, growing and protecting the right network of trees we can increase our resilience to flooding. “Trees improve air quality, they remove harmful greenhouse gases from the atmosphere, they provide material for construction, they regenerate soil for food, they clean the water in our rivers and they provide a home to all the life that finds shelter in their canopy. “The project is ambitious and dynamic and will not grow overnight. Over the next 20 years, we will work with all kinds of stakeholders – from the Woodland Trust to farmers, landowners and school pupils – to grow the right network of trees that will greatly improve biodiversity, trap carbon from the air and provide economic opportunities too. “These ambitious projects work – the Wales Coast Path, which created a path around the entire coastline of Wales, has been a real success story. We’re looking forward to growing a forest that benefits Wales for future generations to come.”"
"**Tougher rules for England will ""strike a balance"" when the national lockdown ends next week, Boris Johnson has said.**
At a Downing Street briefing, the PM acknowledged that the stricter three-tiered system of regional measures to tackle coronavirus would bring ""heartbreak and frustration"".
But he said ""your tier is not your destiny"" and stressed that ""every area has the means of escape"".
Most of England will be in the toughest two levels of measures from 2 December.
The system will be reviewed every two weeks, with the first review scheduled for 16 December - so an area's tier level may change before Christmas.
However, it means 55 million people will remain banned from mixing with other households indoors after the lockdown ends.
More than a third of England's population, including large parts of the Midlands, North East and North West, as well as Kent, will be in the highest level - tier three.
And the majority of places are in the second highest level - tier two - including London, and Liverpool city region.
The Isle of Wight, Cornwall and the Isles of Scilly - where there have been no recorded cases in the past week - will be the only areas of England in the lowest level of curbs - tier one.
The new tier restrictions will be voted on by MPs next week, with a revolt already brewing among the government's own backbenchers.
Meanwhile, hospitality bosses have warned the sector will be ""decimated"" by the new tiers.
On Thursday, another 498 deaths within 28 days of a positive test were reported in the UK, and a further 17,555 positive cases, the latest figures showed.
The prime minister warned that easing off risked ""losing control, casting aside our hard-won gains and forcing us back into a new year national lockdown"".
He said there was ""no doubt the restrictions in all tiers are tough"" but admitted previous tiers ""were never quite enough"".
The new approach was ""designed to reduce"" the R number - the average number of people an infected person will pass the disease on to - ""below one"", he added.
Mr Johnson said mass community testing would be offered to tier three areas ""as quickly as possible"" and hailed Liverpool City region as a ""success story"", where mass testing had brought the area down to tier two.
The BBC's political editor Laura Kuenssberg asked the PM to clarify ""what was the point"" of the second national lockdown, if more people were facing tougher rules than before it began.
Mr Johnson insisted this was ""not continuing the lockdown"".
""Across all tiers, shops will be open, hairdressers, personal services will be open, gyms will be functioning, places of worship will be open for communal worship as well, so this is a very different thing,"" he said.
The PM added: ""And I'm convinced that by April things genuinely will be much, much better.""
Some cold hard truths are emerging about the government's approach to controlling coronavirus.
Much about today's announcement was familiar.
A promise of hope on the horizon followed by a dose of reality about the spread of the virus and tough measures taken as a result.
But months on from the arrival of Covid-19, the once solid political consensus over the response to the pandemic has worn thin.
Now new measures are met with Conservative MPs up in arms and cutting criticism from the opposition.
But wearily, reluctantly, the prime minister has clearly priced all that in and come to the view that tighter restrictions are needed for many more months before things can even begin to get back to something like normal.
Meanwhile, the UK government's chief medical adviser Prof Chris Whitty and its chief scientific adviser Sir Patrick Vallance have warned against hugging and kissing elderly relatives this Christmas.
Speaking at the news conference, Prof Whitty said people's behaviour at Christmas would ""matter a great deal"" this year.
""Would I encourage someone to hug and kiss elderly relatives? No, I would not,"" he said.
""It's not against the law. You can do it within the rules that are there, but it does not make sense because you could be carrying the virus.""
Sir Patrick echoed his remarks, saying ""hugging elderly relatives is not something to go out and do"" over the festive season.
Prof Whitty also said tier two would ""hold the line"" but not bring cases down - prompting scepticism from Conservative MP Mark Harper about the PM's claim that ""your tier is not your destiny"".
Mr Harper, whose Forest of Dean constituency is in tier two, tweeted: ""Unfortunately, just after the PM said this, Chris Whitty, the chief medical officer, said tier two would only hold infections level, and tier one would see them go up.
""That rather suggests if you're in tier two, it is your destiny - at least until the spring.""
Differences between the new tiers include restrictions on where households can meet up:
Gyms and close-contact beauty services like hairdressers will be able to open in all tiers. People in all tiers who can work from home, should continue to do so.
Pubs in tier two can only open to serve ""substantial meals"", while those in tier three can only operate as a takeaway or delivery service.
Decisions on tiers are based on public health recommendations informed by a series of public health data, including Covid-19 cases among the over-60s, positivity rates, pressure on the NHS and how quickly cases are rising or falling.
BBC analysis shows a north-south divide in England when it comes to restrictions:
Devolved administrations in Scotland, Wales and Northern Ireland have the power to set their own coronavirus regulations, though all four UK nations have agreed a joint plan for Christmas.
Earlier, data from the Office for National Statistics showed coronavirus infection rates in England were continuing to show signs of levelling off."
"
Share this...FacebookTwitterDonna Laframboise attended the 4th International Climate and Energy Conference in Munich, Germany last November, and granted an interview with Achgut.TV here.

Die kalte Sonne 3 from Tim Maxeiner on Vimeo.
We know that one third of the 34 authors of the IPCC summary report are connected to either Greenpeace or the WWF. Professor Fritz Vahrenholt, author of the bestselling German skeptic book Die kalte Sonne, brought this up in a recent interview:
It is indeed interesting that of the 34 members of the IPCC editorial team that wrote the summary report, one third are connected to the WWF and Greenpeace. That is legitimate, but that has to be made transparent. Imagine just the opposite and the editorial team were one third Exxon supporters. Wouldn’t people say: ’Hello! Is that really necessary?’”
Can activists be trusted to make objective judgements?
In a court of law, the guilt of the accused person is not decided exclusively by the prosecution or by the defense. To decide on guilt, we need an objective jury to weigh the evidence. And the accused never gets put away “just to be on the safe side”.
Humanity is on the dock when it comes to climate change, but 2 things are missing in the climate court: 1) a chance for the defense to present its case unobstructed and 2) an objective jury. So far we’ve had neither. In fact it could be argued that in some cases all we’ve seen so far is an angry lynch mob donning green pillow cases and armed with phony evidence, pitchforks, clubs, and torches.
 
Share this...FacebookTwitter "
"
This artist's conception shows the inner four planets of the Gliese 581 system and their host star, a red dwarf star only 20 light-years away from Earth. The large planet in the foreground is the newly discovered GJ 581g, an Earth-size planet that orbits in the star's habitable zone. Artwork by Lynette Cook.
From the University of Hawaiʻi at Mānoa
The planet,  which is probably 30 percent larger than Earth, was discovered using one  of the telescopes of the W. M. Keck Observatory on Mauna Kea. It orbits  a relatively small star, Gliese 581, that is 20 light-years from Earth  in the constellation Libra.

“By determining the  orbit of this planet, we can deduce that its surface temperature is  similar to that of Earth,” said Haghighipour. This means that at least  some of any water on the surface of the planet and in its atmosphere  will be in liquid form rather than ice or vapor. The discovery of   liquid water in space is an important step in the search for  extraterrestrial life.
The team estimates that  the new planet, called Gliese 581g, has a mass three to four times that  of Earth, and orbits its star in just under 37 Earth days. Its mass  indicates that it is probably a rocky planet with enough gravity to hold  on to its atmosphere. It is one of six known planets orbiting the  star.
To discover the planet, the team looked  for the tiny changes in the star’s velocity that arise from the  gravitational tugs of its planets. They used 238 separate observations  of Gliese 581 taken over a period of 11 years.
Haghighipour  said that the team is keeping tabs on many nearby stars using the Keck  Observatory. “As we collect more and more data about how these stars are  moving, we expect to find many more planets with potentially Earth-like  conditions,” he said. He noted that to learn more about the conditions  on these planets would take even bigger telescopes, such at the Thirty  Meter Telescope planned for Mauna Kea.
The team  that made the discovery is led by Steven Vogt of the University of  California, Santa Cruz (UCSC) and Paul Butler of the Carnegie  Institution of Washington. Other team members include UCSC associate  research scientist Eugenio Rivera, and Gregory Henry and Michael  Williamson of Tennessee State University.
This research was supported by grants from the National Science Foundation, NASA, and the NASA Astrobiology Institute.
###
For a related press release, see http://news.ucsc.edu/2010/09/planet.html.
For more information, visit: http://www.ifa.hawaii.edu/info/press-releases/Gliese581g/
Contact:Dr. Nader Haghighipour, (808) 956-6098
Associate Astronomer, Institute for Astronomy
Louise Good, (808) 956-9403
Publications Editor, Institute for Astronomy
Posted: Sep. 29, 2010


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e88863cb4',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
In the New York Times:
For science that’s accessible but credible, steer clear of polarizing  hatefests like atheist or eco-apocalypse blogs. Instead, check out scientificamerican.com, discovermagazine.com and Anthony Watts’s blog, Watts Up With That?
Of course, we can’t have that, now the howling begins. Some context below.
More from the New York Times Virginia Heffernan:
Clearly I’ve been out of some loop for too long, but does everyone take  for granted now that science sites are where graduate students,  researchers, doctors and the “skeptical community” go not to interpret  data or review experiments but to chip off one-liners, promote their  books and jeer at smokers, fat people and churchgoers? And can anyone  who still enjoys this class-inflected bloodsport tell me why it has to  happen under the banner of science?
Hammering away at an ideology, substituting stridency for contemplation,  pummeling its enemies in absentia: ScienceBlogs has become Fox News for  the religion-baiting, peak-oil crowd. Though Myers and other science  bloggers boast that they can be jerky in the service of  anti-charlatanism, that’s not what’s bothersome about them. What’s  bothersome is that the site is misleading. It’s not science by  scientists, not even remotely; it’s science blogging by science  bloggers. And science blogging, apparently, is a form of redundant and  effortfully incendiary rhetoric that draws bad-faith moral authority  from the word “science” and from occasional invocations of  “peer-reviewed” thises and thats.
Under cover of intellectual rigor, the science bloggers — or many of the  most visible ones, anyway — prosecute agendas so charged with bigotry  that it doesn’t take a pun-happy French critic or a rapier-witted Cambridge atheist to call this whole ScienceBlogs enterprise what it is, or has become: class-war claptrap.
This is all about Pepsigate. See Heffernan’s column The Medium
h/t to Tim Lambert of Deltoid, hosted by Scienceblogs who couldn’t bring himself to reference anything else here at WUWT with his collection of supposed gotchas, only the one point where he was sure he could get a dig in:
Heffernan reckons that Whats Up With That presents credible science.   This is a blog that argues that Venus is hot, not because of the  greenhouse effect, but because of the high pressure in the atmosphere  (so hence Jupiter and Saturn are the hottest planets right?) .  Look:
If there were no Sun (or other external energy source) atmospheric  temperature would approach absolute zero. As a result there would be  almost no atmospheric pressure on any planet -> PV = nRT
Only if there was no such thing as gravity.
Umm, Tim, can you tell me what gases on Venus remain in a non-solid state at temperatures approaching absolute zero? What happens to solidified gases like dry ice (Frozen Carbon Dioxide) in a (planetary) gravitational field? Here’s an experiment to help you get the answer:
1. Acquire some dry ice
2. Go outside
3. Toss it upwards into the atmosphere
4. Observe
The point that was being made in that article by Goddard is that with no external energy source (the Sun) Venusian atmospheric gases would contract and eventually freeze at near absolute zero and cling to the surface of the planet, thanks to gravity.
PhysLink agrees:
Question

What will happen to the gas at absolute zero temperature (0 K)?

Asked by: Rohit
Answer

First of all, the gas will no longer be a gas at absolute zero, but rather a solid.  As the gas is cooled, it will make a phase transition from gas into liquid, and  upon further cooling from liquid to solid (ie. freezing).  Some gases, such as  carbon dioxide, skip the liquid phase altogether and go directly from gas to solid.
…
First off, 0K can never be achieved, since the amount of entropy in a system can  never be equal to zero, which is the statement of the second law of thermodynamics.  This can be nicely illustrated by your question:
Using the state equation for an ideal gas:
PV = nRT
T, the thermodynamic temperature will be equal to 0, so the product of the molar  gas constant R (8.31 J/mol/K) and the amount of moles n, will also be zero.
Therefore the product of PV must be zero also.   the pressure of the gas must be zero   or volume of the gas must be zero
As an example, look at the Ice Caps of Mars, still well above absolute zero but below the freezing point of Carbon Dioxide:

From Wiki:
The polar caps at both poles consist primarily of water ice. Frozen  carbon dioxide accumulates as a thin layer about one metre thick on the  north cap in the northern winter only, while the south cap has a  permanent dry ice cover about eight metres thick.[62]
As we see in the Physlink description, a planetary wide near absolute zero temperature (if the sun blinked off), all the rest of Mars atmosphere would be bound to the surface as a solid too. The result: no atmosphere and no atmospheric pressure.
UPDATE: As is typical anytime somebody not on the team that gets a voice or mention, those who deal in mudslinging and angry rhetoric swarm in to squash it and convince the writer of the “wrongness” of it all.
Here’s a comment from Virginia Heffernan after she’s had the treatment here. Note the number of angry labels preceding her response.
Virginia Says:
July 31st, 2010 at 12:00 am
I’m grateful for all the replies. Nice to meet you here, David.
I get the sense that Pepsigate was the last straw – or not the first,  anyway – for at least some of the dissenters from ScienceBlogs. Out of  curiosity: Did no one quietly resign over PZ Myers’s Mohammad cartoons?  Or question whether they wanted to be part of a network to which he’s  the main draw?
In my experience, legacy media types, who do kick up furors over  stuff like Mohammad cartoons, nonetheless see *debate* over ad-ed  breaches as common, especially now because of the confusion what  old-media road rules mean in digital times.
With notable exceptions, blogging, as a form, seems to me to have  calcified. Many bloggers who started strong 3-5 years ago have gotten  stuck in grudge matches. This is even more evident on political blogs  than on science blogs. In fact, after being surprised to find the same  cycles of invective on ScienceBlogs that appear on political blogs  (where they’re well documented), I started to think the problem might be  with the form itself. Like many literary and art forms before it (New  Yorker poetry, jazz, manifestos) blogs may have had a heyday – when huge  numbers of people were inspired to make original contributions –  before, seemingly all at once, the moment is gone. Some people keep  doing it, and doing it well, but the wave of innovation passes, and the  form itself needs new life. (Twitter? Tumblr?)
I have no training in science. My surprise at ScienceBlogs was akin  to the surprise a scientist who might feel if he audited a PhD seminar  on Wallace Stevens. Why aren’t they talking about “Anecdote of the  Jar”?! Why are they talking about how “misogyny intrinsic to the  modernist project”? I saw political axe-grinding bring the humanities  almost to a standstill in the 1990s. I thought science was supposed to  be above that!
One regret: the Watts blog. Virtually everyone who emailed me pointed  out that it’s as axe-grinding as anything out there. I linked to it  because has a lively voice; it’s detail-oriented and seemingly not  snide; and, above all, it has some beautiful images I’d never seen  before. I’m a stranger to the debates on science blogs, so I frankly  didn’t recognize the weatherspeak on the blog as “denialist”; I didn’t  even know about denialism. I’m don’t endorse the views on the Watts  blog, and I’m extremely sorry the recommendation seemed ideological.
All best,
Virginia Heffernan
heffernan@nytimes.com


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89e9e5ad',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitter!!! UPDATE: Story now (indirectly) on the Drudge Report !!! (31 May 2012, 20.00 h CET)
Not only does he not feel bad about the tab taxpayers have to pick up for his haircuts, President Obama obviously also does not care much about the massive carbon footprint his haircuts are leaving on our planet which, we are told, is tipping precariously.
With each passing day, Barack Obama is looking more and more like the Imelda Marcos President.
German public radio here has a gossip report on how the world’s most likable Commander-in-chief gets his haircut, and about the cool dude who trims his hair. The President is a man of the common people, the report tells its listeners. He hangs out with regular folks, like his barber for example. Obama’s Chicago barber, who goes by the name Zariff, has been cutting the Chief Executive’s hair 17 years.
But now that the President has his residence in Washington D.C., you’d think he’s find another barber in town to cut his hair and save us lots of costs. Wrong.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to German public radio, the President flies Zariff from Chicago to DC for a trim dozens of times per year (on the taxpayers’ dime of course). Not only does this cost the taxpayers a bundle, but think about the carbon footprint the supposedly environmentally-concerned President is producing. The German NDR reporter says:
The barber never says a word about what they discuss. Perhaps that’s also a reason why Obama feels comfortable being around him. Otherwise he would not fly his barber in from Chicago to Washington every ten to 14 days.”
Think of all the jet fuel getting burned for them clippers.
In these tough times when Americans by the score are struggling with high unemployment, tight budgets, tattered finances and deep worries about the future, wouldn’t it be more appropriate for the President to get a barber from DC? My God -surely there’s got to be somebody in town who can cut his hair.
With all due respect, Mr. President, such small things make all the difference between a great democracy and a banana republic.
 
Share this...FacebookTwitter "
"It is set to be one of the largest ever co-ordinated protests. The People’s Climate March is due to take place in cities all over the world this weekend to try and influence the UN climate summit that follows on September 23. The marches promise to be a major global event, billed by organisers as an “unprecedented mobilisation”. No doubt it will be enjoyable to take part in – but that’s no guarantee it will work. The anti-war protests in 2003 mobilised somewhere between 6m and 10m people across 60 countries but famously failed to prevent an attack on Iraq. There is of course a substantial risk that a climate change march will similarly have no immediate discernible effect on climate policy. On the other hand, the 2003 anti-war demos may still be affecting debates about the use of force and security and ongoing efforts to take account of opinion. Popular protests have of course toppled governments and even political systems before. And sometimes it takes years or even decades to recognise what protests and revolutions really meant, including wider changes in values and priorities. So it is not that simple. A better question is: when does protest work, and when not? Sorting out clear causal effects and hard and fast rules in systems as chaotic as entire societies is of course nearly impossible. But social science research tries anyway. Current findings seem to indicate a few things which will have a bearing on the success or otherwise of the People’s Climate March: Firstly, even if marches come and go without immediate effect, one review ventures that public opinion matters to policy-making “roughly three quarters of the times”, especially by making issues “salient”. If protests actually affect public opinion then they can work indirectly. Obviously mobilisation is then required: you have to be in it to win it. Among political sociologists “resource mobilisation theory” emphasises the importance of the ability to mobilise support and marshal resources effectively. Be big and beautiful as a movement. At the same time, tightly co-ordinated action has been linked to success, and efficient organisations therefore seem also to be a key factor. Other research indicates that mobilisation is not enough and organisations don’t matter much. A rival theory focused on “political opportunity structures” says that mobilisation happens all the time – what matters is contextual factors and whether the system is ready. In particular, there have to be strong allies on the inside to convert pressure from the outside into policy change. These days media framings of protest appear also to be important, but they are rarely kind to direct action protests. Inevitably, timing also matters. A crisis moment can be a perfect moment to break down institutional barriers – although it may also make the system close ranks.  In sum: luck is when preparation meets opportunity, as Roman philosopher Seneca reputedly said (long before sociologists reached a similar conclusion). To maximise chances of success, climate change marchers will need a lot of factors to come together: high mobilisation and wide public sympathy, strong allies on the inside, a constructive media and perhaps a crisis of some description to weaken  the defences of the vested interests blocking decisive action. How does this bode for the People’s Climate March? Overall, quite well.  Firstly, public support for climate action seems to have risen slowly but steadily over the past 20 years but evidence shows that globally awareness is patchy and there is clearly potential for more awareness and support to be garnered. If the march is to add to – rather than detract from – this then size, but also charm, will be important to winning over public opinion: In terms of size, the march itself appears to be well co-ordinated: events are autonomously planned in more than 2,500 locations (compared to 600 in 2003). There are multiple agents in multiple cities and countries, with a clear message that is being communicated effectively via social media. It may beat the 2003 record set by the anti-war demos – but social movements are unpredictable entities. In terms of beauty, organisers are committed to non-violence and peaceful demonstration, which is a good start. If the media focus on the festival rather than the fringes, even better. Secondly, to be a success, the march should be adding its weight to some strong “internal” actors and institutions with similar ideas who can take things forward more consistently – what is sometimes called an “advocacy coalition”. The coalition is probably growing. The scientific community started it of course, and pressure groups and some politicians have taken it up. But businesses have begun to come on side as the opportunities for energy transition and new industries become apparent. The march may be part of a coalition, but to be part of a winning one, it has to match – and eventually overcome – opponents to change. And there are still strong opponents and almost intractable problems in organising collective actions as states wait for others to take the lead. On the other hand, for some, the global fossil fuels industry is showing signs of a crisis of sorts, as record investments have failed to bring commensurate new supplies on stream. This could be the right kind of crisis, if renewables keep falling in price and utilities are left floundering – although another financial crisis triggered by a carbon bubble bursting probably won’t help much. In any case, urgency dictates that now is probably the best time to try to make headway. However, the biggest problem in predicting success is perhaps that it is not clear what “winning” really would look like. Climate change is such a wicked problem, that it shouldn’t really be considered as a single problem at all. Dealing with climate change means addressing numerous different goals and dilemmas, not all of which can be solved at the same time. Preventing more than two degrees of global average warming acts as a rough proxy, but for some this is too much and averages miss the point anyway. But that should not worry the marchers on Sunday unduly. Their job is primarily to push the question, garner salience and apply pressure. And to enjoy themselves."
nan
"**A top council officer says Middlesbrough is planning for the highest tier of covid-19 restrictions.**
The second lockdownÂ ends on 2 December and a three tier system will then be introduced, with an announcement due on Thursday revealing each area's fate.
Tony Parkinson, chief executive of the council, said rates had dropped but were ""still high"" compared to others.
The ""very high"" tier three restrictions would see bars and restaurants remain closed except for takeaways.
Middlesbrough mayor Andy Preston said there was talk of the whole of the North East going into the top tier, the Local Democracy Reporting Service said.
Mr Parkinson gave an update on how the council planned to recover from the impacts of the pandemic at the latest Middlesbrough Council executive on Tuesday.
""Our rate has come down from about 507 per 100,000 to about 307 per 100,000 which is great,"" he said.Â
""Thank you to everyone who has conformed and sacrificed everything.Â
""We're still higher than average in the country so we've got to expect tier three, the rumours are tier three but until Thursday we don't know.""
Strict rules would also remain in place to prevent households mixing, apart from between 23 and 27 December when up to three households will be able to meet at Christmas.
Mr Preston told BBC Breakfast on Tuesday that Middlesbrough would be in tier three if he had to bet on it but was hoping for Tier Two, again pointing to falling infection rates.Â
The NHS data dashboard showing rolling covid rates from 16 to 22 November records a rate of 307.1 per 100,000 people.
Redcar and Cleveland has fallen below the 300 mark on 292.4 per 100,000 with Stockton on 299 per 100,000 over the same seven day period.Â
The Government has indicated it will look at the rate of covid among over 60s, whether rates are rising or falling, the ""positivity rate"" - or number of positive covid cases as a percentage of the number of tests - and pressure on the NHS in deciding the tiers.
_Follow BBC North East & Cumbria on _Twitter _,_Facebook _and_Instagram _. Send your story ideas to_northeastandcumbria@bbc.co.uk _._"
"We’ve all been caught out by a thunderstorm or freezing winter morning down on planet Earth, but up in space things are rather different. Fluctuations in the weather up there won’t make you cold or damp, but they could end up crippling much of our technology. The UK government recognises this worry: “severe space weather” was added to the most recent National Risk Register for Civil Emergencies alongside flu pandemics, volcanoes and floods. Now the Met Office has opened a Space Weather Operations Centre in Exeter.  But what is this “space weather” anyway, and why does it matter so much? So-called space weather storms occur when radiation from the Sun disturbs the Earth’s magnetic field and the upper extremes of the atmosphere, a region known as the ionosphere. Such storms happen when solar flares suddenly release flashes of electromagnetic radiation or when explosions on the Sun called coronal mass ejections release charged particles, which interact with and perturb the Earth’s magnetic field and the ionosphere. This space weather in the ionosphere creates what most of us know as the Northern Lights. At present relatively little is understood about the likelihood of a huge space weather storm happening soon. We know there have been such storms in the past however, most famously the Carrington Event of 1859 which disrupted telegraph systems across Europe and North America. In those days, electronic communication was relatively new and rare. Today we have very different technology that supports our everyday lives. As society has advanced, so it has become far more vulnerable to the effects of space weather storms. Solar storms can induce current surges strong enough to knock out power supplies, as happened in 1989 when a solar storm cut power to millions of people in Quebec for nine hours. Satellite navigation systems including GPS would also be hit, with limited availability and reduced accuracy. Think of all the core services that now rely on GPS for navigation or timing: the national grid, internet banking, mobile phones, TV, aircraft landing systems and so on. As a result, understanding the impact of large solar storms on GPS accuracy is increasingly essential. Researchers at the University of Bath’s Invert Centre for Imaging Science have figured out a way to warn of the effects on the ionosphere from natural solar events and correct for them. By studying images of the ionosphere during solar storms, we can quantify the effects and correct for GPS errors. To enable this, the university runs a network of GPS scintillation receivers located from the Arctic to the South Pole, which take 50 GPS measurements per second and provide information about rapid variations in signal strength and timing. In the polar regions, where the Earth’s geomagnetic field is near-vertical, the upper atmosphere is exposed to solar radiation continuously. Lower latitudes such as the UK are only exposed during the most extreme solar storms. By studying these areas, we can understand the physical interactions underlying the processes disturbing GPS signals. Using this information, the team has developed an algorithm which gives us real-time imaging of the earth’s ionosphere. This means ionospheric errors can be measured and largely removed, allowing for more accurate GPS timing and real-time positioning.  This is part of the technology the Met Office is now using to provide real-time space weather ionosphere forecasting. The new centre will give us an insight into what the weather is like in space at any given moment and should help address how vulnerable our infrastructure and services are to a rogue solar storm. Where next? Well, we’re working to help the global satellite and communications industry model space weather effects in a sophisticated commercial GPS simulator. This would mean that GPS receivers can in the future be more robust against space weather."
nan
nan
"
Share this...FacebookTwitterIt’s a definite bang, but nothing like I was expecting. Let’s just say it was a little bang out here in Europe.
Anthony Watts shut down his popular WUWT website Friday because “something happened” and he needed time to prepare a “major announcement” that he was sure would “attract a broad global interest due to its controversial and unprecedented nature”. Because of “the magnitude of this event” he was even able to convince his wife that it was necessary to suspend vacation plans. Now that sounds big!
The press release excerpt:
A reanalysis of U.S. surface station temperatures has been performed using the recently WMO-approved Siting Classification System devised by METEO-France’s Michel Leroy. The new analysis demonstrates that reported 1979-2008 U.S. temperature trends are spuriously doubled, with 92% of that over-estimation resulting from erroneous NOAA adjustments of well-sited stations upward.
Other findings:
– Poorly sited station trends are adjusted sharply upward, and well sited stations are adjusted upward to match the already-adjusted poor stations.
· Well sited rural stations show a warming nearly three times greater after NOAA adjustment is applied.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




· Urban sites warm more rapidly than semi-urban sites, which in turn warm more rapidly than rural sites.”
Admittedly, my expectations concerning the implications were surely too high. It’s nothing that we haven’t already suspected or known. But it is good that this issue has been examined scientifically, formally and published. It’s now certified that US temps have been massively overstated and that the NOAA needs to clean up its act.
In summary:
1. Major announcement? Yes, but nothing like it was made out to be.
2. It’s of global interest? Some, but in Europe it’ll be pretty much ignored – local issue that does not change anything globally.
3. Controversial? For temperature record keeping at the NOAA, yes. But little global impact.
4. Unprecedented? Not really. It confirms what everyone expected. Temperature data are botched everywhere, every day.
This paper will put the NOAA on the defensive of course, at least for a little while. I don’t expect any of the German mainstream media to report on this, though. But I’ll keep my eyes peeled.
The announcement is big, but not that big. Some things could have been spared in the run up to the announcement.
And so the great global warming debate continues…
 
Share this...FacebookTwitter "
"

World leaders have sounded alarm bells against a repeat of the 1930s, when tit‐​for‐​tat protectionism followed hard on the heels of the Wall Street crash. But they are fighting the wrong enemy. Current events suggest a different, but still vexing, scenario: the creeping protectionism of the 1970s, rather than the spiraling protectionism of the 1930s.



In the 1970s, oil‐​price hikes and other shocks triggered inward‐​looking, mercantilist policies, including in Europe and the United States. Immediate policy responses were not overly protectionist: There was no equivalent of America’s 1930 Smoot‐​Hawley tariff. But escalating domestic interventions on both sides of the Atlantic exacerbated economic stress and prolonged stagnation. Not least, they spawned protectionist pressures. Industry after industry, coddled by government subsidies at home, sought protection from foreign competition. The result was the “new protectionism” of the 1970s and 1980s.



Then, as now, manufacturers of gas‐​guzzling cars faced bankruptcy. Congress bailed out Chrysler in 1979. The British government bailed out Rolls Royce and British Leyland, and Renault was saved by French taxpayers. Several other sectors — timber, energy, minerals, railways, airlines, shipbuilding — received government subsidies in the 1970s, in both Europe and the U.S. Many companies were nationalized.



On both sides of the Atlantic, “voluntary export restraints” and other nontariff barriers were also deployed to “manage trade.” The sectors that received subsidies at home were also protected from foreign competition. Through the 1980s, American car manufacturers were protected by VERs that restricted the number of Japanese cars exported to the U.S. Europe negotiated a similar agreement with Japan in 1983. Many other sectors, such as semiconductors and VCRs, were also protected. The French government even demanded that all Japanese VCR imports enter France via Poitiers, a small town hundreds of miles from the nearest shipping port.



Now, as in the 1970s, there is a big global push to expand domestic regulations which “manage” the market. Most new regulatory proposals are not directly protectionist, but they do have subtle and indirect consequences for global economic integration. New financial‐​market regulations are brewing in OECD countries as well as in emerging markets. They concern everything from a global college of financial regulators and stricter capitalization requirements to limits on executive pay and directions to lend to small enterprises. Unless current regulatory ambitions are scaled down, they run the risk of stifling market signals and emasculating the entire global economy.



Regulatory agendas are also becoming cluttered with government subsidies. These measures comprise bailouts for ailing corporate behemoths (such as the U.S. car industry), and funds to protect “national champions” in “strategic” sectors from foreign takeover (as President Nicolas Sarkozy has proposed for France and the EU). Such measures inevitably distort global commerce and trigger retaliatory responses: If one country subsidizes, others follow; if one sector gets subsidized, others will demand like treatment. That will in turn lead to a clamor for other forms of protection against foreign competition, such as antidumping and safeguard duties, export subsidies, and discriminatory product standards.



Where will this creeping protectionism lead next? Financial services remain first in the line of fire. Tighter prudential regulations may be called for in some cases, but they should be distinguished from the rules that underpin market access for financial services firms, whether domestic or foreign. This distinction is now being ignored. Politicians and regulators — including those in China and India — will likely use the financial crisis as cover to block further market opening to foreign financial‐​services providers. Indian commerce minister Kamal Nath said after the EU‐​India summit in September that the financial crisis has vindicated his government’s policy of avoiding a comprehensive liberalization of the country’s banking system.



Creeping protectionism will not be restricted to finance: It can also be directed at specific countries and other economic sectors. Much Western protectionism in the 1970s and 80s was directed at blocking imports from Japan and other East Asian Tigers. Now, on a much grander scale, there is a protectionist backlash against the global integration of China and India. In the U.S. and EU, allegations against China of “unfair trade” linked to “currency manipulation,” bilateral trade deficits, hidden subsidies, and low labor and environmental standards are resurfacing.



Investment nationalism, often combined with energy nationalism, is also on the rise. The United Nations Conference on Trade and Development has recorded an increase in the number of new laws unfavorable to foreign direct investment. Since 2005, a quarter of all new FDI laws are considered to be unfavorable to FDI, compared with an average of 7.5% from 1992 to 2004. These restrictions are bunched in energy‐​related sectors, but they are spreading to other sectors. Congress, for instance, blocked a bid by China National Offshore Oil Company for Unocal, and it scuppered Dubai Port’s attempt to take over the management of six U.S. ports. Meanwhile, the Chinese government has recently tightened foreign‐​investment restrictions to protect national champions in a range of industrial, energy and service sectors.



Last but not least, the climate‐​change agenda appears set to become the Trojan horse of “standards protectionism” in the 21st century. Technical standards have long been a popular form of protectionism because they aren’t as obvious as tariffs or quotas, and can be disguised politically as matters of “safety” or “quality.” The EU has an emissions‐​trading scheme in operation. Congress will probably pass a similar cap‐​and‐​trade scheme next year. Because such schemes will impose substantial compliance costs on energy‐​intensive sectors at home, the EU and the U.S. will seek to impose similar costs on cheaper, carbon‐​intensive production elsewhere that is not subject to carbon‐​reduction policies. Hence the threat of trade sanctions on “free riders” — China in particular.



Because we’ve been down this road before in the 1970s, we can see where it is leading. Giving way to protectionism will deepen and prolong the global recession. Containing protectionism, and extending open markets, will facilitate flexibility and adaptation. It will speed up recovery and lay the foundations for future prosperity.
"
"**The US Supreme Court has temporarily blocked New York from enforcing attendance limits at places of worship in areas hit hard by coronavirus.**
In a 5-4 vote, the court ruled that the state's congregational cap violated rights to religious freedom.
In an unsigned order, it said the rules ""single[d] out houses of worship for especially harsh treatment.""
This was one of the first consequential rulings since conservative Justice Amy Coney Barrett was appointed.
President Donald Trump appointed her to replace liberal predecessor Ruth Bader Ginsburg, who died in September.
Justice Barrett voted in the majority, along with other Trump appointees Neil Gorsuch and Brett Kavanaugh.
The three liberal justices dissented, as did conservative Chief Justice John Roberts.
Earlier this year, before Justice Ginsburg's death, the court voted to leave similar restrictions in place in California and Nevada.
The US is continuing to battle the world's largest outbreak of coronavirus. Over 12.7 million cases have been recorded nationally, and more than 262,000 deaths, according to a tally by Johns Hopkins University.
The Supreme Court's decision was a major victory for the Roman Catholic Diocese of Brooklyn and Agudath Israel, an Orthodox Jewish congregation, which had challenged the restrictions imposed by New York's Governor Andrew Cuomo.
On 6 October, Governor Cuomo shut down non-essential businesses in targeted areas where coronavirus infections had spiked, as part of efforts to control infection rates. Places of worship were also limited to gatherings of 10 in ""red"" zones, and 25 in ""orange"" ones.
In court, the Catholic Diocese of Brooklyn said the restrictions unfairly singled out places of worship. Agudath Israel of America also argued that its members were subject to ""discriminatory targeting.""
New York argued in response that it had been the epicentre of the US coronavirus outbreak in the spring. It also said religious gatherings were being treated less stringently than secular gatherings like concerts, which were banned entirely.
But the Supreme Court's unsigned majority ruled that ""even in a pandemic, the Constitution cannot be put away and forgotten. The restrictions at issue here... strike at the very heart of the First Amendment's guarantee of religious liberty.""
The court's action will not have an immediate impact since the groups that sued are no longer subject to the restrictions they fought against."
"

Last August, the _Federal Register_ announced a period of public commentary on information germane to a new set of Corporate Average Fuel Economy (CAFE) standards for the 2022–2025 period. The extant standard, of roughly 50 miles per gallon (MPG) for passenger cars and other light vehicles, was put in place in January 2017, right at the end of the Obama Administration.   
  
  
It is not surprising that EPA Administrator Scott Pruitt announced the Obama standards are _not_ to stand; we hope our extensive public comments submitted on September 27 exerted some influence on this decision.   
  
  
We noted:   




There is a paradigm‐​shift occurring in global warming that is highly relevant… It began with the revelation of remarkable and increasing discrepancies between the climate models…in the most recent report of the U.N’s Intergovernmental Panel on Climate Change (IPCC), and observations in the bulk atmosphere over vast swaths of the planet.



Figure 1 (below) shows this discrepancy.   






Figure 1. Average of the IPCC computer model projections for the tropical mid‐​troposphere versus three standard sets of observations: weather balloons, temperature sensed from satellites, and “reanalysis” data used to initialize the daily weather map. The growing discrepancy is obvious, even with the 2016 El Nino warm spike at the end.   






Figure 2 (above) shows the problem in the vertical tropics, where as much as _seven times as much_ warming has been predicted at high altitude since the satellites became operational in 1979.   
  
  
Figure 2 has enormous consequences for weather. It is the vertical distribution of temperature that determines how much moisture is wafted sky ward in the fetid tropics. Much of the extratropical temperate zone depends upon this juice.   
  
  
It is noteworthy that models in general predict the greatest amounts of future warming, while observationally‐​based studies, often about interglacial‐​glacial transitions, or differences between geological eras, tend to come up with less warming. Given data or a model, most folks will pick the former.   
  
  
We detail our reasons for re‐​examining the 2022–25 CAFÉ standards here. Have a look and we think you’ll agree that Administrator Pruitt has pretty sound science behind the need to revisit standards that were generated absent some of this very important data.
"
"British companies are expected to spend more than £12bn switching their fossil fuel vehicles for clean electric versions over the next two years.  A survey found that nearly half of UK businesses are planning to invest in chargeable cars and vans in advance of the government’s ban on sales of new internal combustion engine vehicles by 2035.  The Treasury is expected to accelerate the trend in this week’s budget by signalling an end to a decade of freezes on fuel duty for millions of drivers, as part of plans to meet tougher climate laws. Sales of electric vehicles are climbing quickly but official figures show that they still accounted for only 2% of new car registrations last year. The uptake of low-emissions driving is a key pillar of the government’s plans for cutting carbon emissions to virtually zero by 2050 to end the UK’s contribution to the climate crisis. Cars make up slightly less than a fifth of the UK’s total carbon footprint, a proportion that has risen in recent years in part thanks to the popularity of energy-hungry SUVs. Rachel Maclean, the transport minister, said: “It is encouraging to see UK businesses investing in electric vehicles and embracing greener technology to decarbonise our transport network. “Businesses having confidence in electric vehicles is crucial to end the UK’s contribution to climate change and improve air quality for all.” More than a third of companies say the government’s looming ban on petrol and diesel cars has made them bring forward plans to shift to clean driving, according to a survey by the owner of British Gas. The same proportion of companies told Centrica that access to ultra-low emissions driving zones was also a factor in their decision. Alan Barlow, managing director at Centrica’s business solutions division, said: “There is clear recognition among UK businesses of the increasingly important operational role electric vehicles can play in meeting decarbonisation goals. But concern is still widespread over how to finance this change, particularly for those with large petrol and diesel fleets.” More than two-thirds of companies said they were discouraged from investing in electric vehicles by the cost of new cars and vans, and concerns over a spike in their energy bills. Barlow said companies intending to switch to electric vehicles would be able to limit their bills by investing in solar panels and battery packs, or smart software that automatically charges vehicles at night, when energy prices are at their lowest."
"

Last January, media outlets reported that cancer had overtaken heart disease as the number one killer in the United States. Sounds scary, no? 



Fear not. As is usually the case, beyond the scary headline, deep into the copy, came the real story. _Both_ diseases are in steady decline. Cancer rates and deaths from cancer have fallen every year since the early 1990s. The thing is, incidence and mortality rates of heart disease and stroke have fallen _even more_ over the same period (25 percent since 1990). So while it’s true that cancer has “overtaken” heart disease, that’s really not the story. The story is that both are in decline, heart disease remarkably so.



Late last February, another health story hit the wires: Americans are living longer than ever before. Life expectancy is up across the board, among both genders and all ethnicities. The gaps in life expectancy between men and women and between black and white are shrinking, too. 



At the same time all of this good news has transpired, the number of Americans classified as “obese” and “overweight” has been on a steadily upward trajectory since about the mid‐​1970s. In 1985, 8 states reported that at least 10% of their populations were obese. By 1990, the number rose to 33. By 2001, it was all fifty. 



Of course, as you might expect, the scariest numbers about the condition of America’s waistline are overblown – there are significant problems with the way the government measures obesity, which I’ll discuss in a moment. But most researchers agree that the average American is carrying 10–15 more pounds than he was thirty years ago. 



If you believe media, nutrition activists, and public officials, those extra 10–15 pounds portend a looming healthcare catastrophe. U.S. Surgeon General Richard Carmona, for example, said in 2004 that childhood obesity is “every bit as threatening to us as the terrorist threat.” A congressionally commissioned report from the Institute of Medicine published in the fall of 2004 called for massive government intervention to stave off the crisis. One author said we need “nothing short of a revolution.” The World Health Organization warned “If immediate action is not taken, millions will suffer from an array of serious health disorders.”



But if we’ve been getting fatter for 30 years, shouldn’t we be seeing at least the front end of this coming crisis? Why are we getting _healthier_? In fact, a closer look at the statistics suggests that even some of the diseases most associated with obesity are in retreat.



Take cancer, for example. In 2002, the BBC reported researchers had found that “the more excess weight a person carries, the greater their risk of certain types of cancer.” In 2004, _USA Today_ echoed that claim. “The nation’s current epidemic of overweight and obesity is likely to drive up cancer rates in coming years,” the paper wrote. The Associated Press wrote that, “heart disease and diabetes get all the attention, but expanding waistlines increase the risk for at least nine types of cancer, too” (other sources put it at ten).



But of the ten types of cancer commonly associated with obesity, deaths from nine – pancreatic, ovarian, gall bladder, stomach, prostate, kidney, colal‐​rectal, cervical‐​uteran, and breast – have _decreased_ since 1992, some of them significantly. Only one – pancreatic cancer – has seen an increase in mortality rates over that period.



And heart disease? Case Western Reserve University researcher and obesity skeptic Paul Ernsberger notes that “The greatest improvements are in cardiovascular disease deaths, which are most strongly linked to obesity.”



As noted, the gap in life expectancy between black and white is shrinking. But at the same time, blacks as a group have put on more weight than whites. Incidence of obesity among black women, for example, jumped 11.7% between 1988 and 2001, compared to 7.3% among white women. Yet black women increased their life expectancy by 2.3 years, versus 1.3 years for white women over that period. It’s true with men, too. The rate of obesity among black men jumped by 7.5%, versus 7.0% among white men., yet black men on average added 4.2 years to their lives, versus 2.8 for white men. So blacks have narrowed the longevity gap with whites, even while widening (pardon the pun) the “obesity gap.”



In 2003, the _Journal of the American Medical Association_ published a study commissioned by the Center for Disease Control that said 400,000 annual American deaths are attributable to obesity. A Lexis search reveals that as of late fall of 2004, that 400,000 figure had been cited over 1,000 times in mainstream media outlets. It was also routinely cited by politicians, activists, and bureaucrats as justification for large‐​scale government intervention to curb our pudginess. At a Time Magazine‐​ABC News summit on obesity in June of 2004, attendees were inundated with the refrain that “obesity will soon overtake smoking as the number one cause of preventable death in America.” Demands for government action inevitably followed.



But there were fatal flaws in the CDC study’s methodology. First, it was a “meta” study, which incorporated data from dozens of other studies, some of them dating back to the 1940s, and attempted to apply that data to today’s demographics. Second, the study used the Body Mass Index as its arbiter of obesity, a crude formula that factors only height and weight, and which consequently mislabels as “overweight” or “obese” people who are extremely fit. According to the BMI, for example, half the National Basketball Association is either overweight or obese. But few would suggest they’re out of shape or unhealthy. Third, the study assumed that all premature deaths by obese people were caused by obesity – a leap of faith, to say the least. Finally, the study lumped the “overweight” in with the “obese,” even though there’s little evidence that overweight has any seriously ill‐​effects on health. The study’s own data, in fact, showed no correlation between being overweight and premature death, and in fact showed some benefit.



In December of 2004, the CDC reluctantly admitted its study was flawed, but only by a little — 20 to 25 percent. Critics insisted the flaws in the study’s methodology was much more significant, and in response the National Institutes for Health finally commissioned a review. In April, an independent team of researchers led by the University of North Carolina’s Katherine Flegal released a new study sharply at odds with the original 400,000 study. Flegal’s team determined the original study exaggerated the effects of obesity by some 300 percent. She put the real number of annual deaths attributable to overweight and obesity closer to 100,000. What’s more, the new study found that modest overweight actually _protects_ against premature death. When adjusted for the lives _saved_ by extra weight, the number of deaths due to obesity falls to around 25,000 — putting the original figure off by a factor of fifteen.



A subsequent internal investigation revealed that CDC officials were actually made aware of the original study’s flaws during the peer review process. So why was the more alarmist study published and relentless promoted anyway? 



As it turns out, one of the co‐​authors of the original 400,000 study was Dr. Julie Gerberding. Gerberding also happens to be the current Director of the Center for Disease Control. Comments from members of the internal investigation team reveal that the study was likely published over objections from other scientists at the CDC because the head of the agency’s name was on the study.



Gerberding still refuses to accept the new numbers. She has told the media that the CDC will continue with its anti‐​obesity campaign, and the campaign will continue to ignore the subsequent study. 



Local and state legislatures, the U.S. Congress, regulators at all levels of government, and public health advocates have since seized on the idea that nearly a half million people are needlessly dying every year because of their love handles. The Bush administration has earmarked millions of federal dollars for anti‐​obesity initiatives (though not nearly enough for the obesity warriors). Congress is considering menu‐​labeling laws, some in Washington have suggested taxes on high‐​fat or high‐​sugar foods, and others are calling on the FTC to regulate the marketing of junk food. Many states have banned junk food from school cafeterias and vending machines. And the Medicare program announced last summer that it would begin considering paying for treatment for obesity, a new entitlement that could prove to be more costly as the prescription drug benefit.



America is at war with obesity. We could eventually come to find, however, that this war’s origins are dubious as the sinking of the Maine.



None of this is to say extreme or morbid obesity is healthy, or even benign (though again, there seems to be some modest protective effects to carrying some excess weight). The decline in incidence and deaths from heart disease and cancer are almost certainly due to advances in medical research and technology. We’re getting better at uncovering these diseases early, and with pharmaceutical marvels like Statin drugs and chemotherapy, we’re making huge leaps in treatment once we’ve diagnosed them. And it’s of course likely that the gains we’ve made would be even more significant were the most obese among us a bit more svelte. 



But the notion that our expanding waistlines have put us on the verge of a calamitous offensive against our health care system simply isn’t borne out by the evidence. And so these incessant calls for immediate, large‐​scale government interference in how we grow, process, manufacture, market, prepare, sell, and eat our food ring hollow, hyperbolic, and needlessly invasive. 



The _Seattle Times_ recently did an investigation of the obesity hype, and found that much of the panic could be traced back to an aggressive campaign in the late 1990s by the pharmaceutical companies with diet drugs like Phen‐​Phen in the pipeline to get the government in the business of weight‐​watching. In 1996, the industry convinced the federal government to move the goalposts when it comes to determining the definition of “overweight” and “obesity.” At hearings dominated by researchers with ties to the pharmaceutical industry, an FDA panel eventually agreed to the change. One magical night in 1997, then, some 29 million Americans went to bet healthy, and woke up the next morning “overweight” or “obese.” And none of them gained a pound.



Debunking junk science studies and bogus chicken‐​little pronouncements are important to refute the idea that obesity represents a looming healthcare crisis. But those of us who value free markets and personal liberty wouldn’t support government intervention even if the worst pronouncements of the anti‐​fat activists were proven true. What we put into our mouths, how often we exercise, and what we feed our children are simply none of the government’s business. How did we get to the point where it could be? 



There are two answers to that question, and they should be considered separately. First, we’ve vastly expanded the concept of “public health” to include government intervention into nearly every sphere of our lives. And second, our health care system is slouching toward socialism, a troubling trend that undermines personal responsibility, and exacts a public cost on private behavior.



 **Public Health**



The proper conception of “public health” is innocuous enough. There are unquestionably some threats to our health and safety for which the remedies constitute a legitimate public good. They’re limited to risks to which no rational person would submit himself – examples might include communicable diseases like tuberculosis or typhoid, calamitous events like asteroid impacts or tsunamis, or biological or chemical terrorism. Under these limited circumstances, it’s understandable, even advisable, for a government limited to protecting the lives and property of its citizens to take collective measures to eradicate or minimize such risks, or minimize the damage should they come to pass.



But “public health” as it’s advocated today goes well beyond public goods. Over the last century, “public health” has come to mean state pressure coercing us to avoid risks, even risks we knowingly and willingly undertake. The most obvious and conspicuous example was alcohol prohibition. And though Prohibition took an untold number of lives, bred corruption, and legitimized criminal behavior, it is distinguishable from more recent expansions of public health in that lawmakers at least recognized it as a failure, and repealed it (Unfortunately, we don’t seem to have learned. The last twenty years have seen increasingly aggressive restrictions on the production, sale, and consumption of alcohol by local, state, and federal government).



But the Harrison Act – which fired the first shots of the drug war – was passed even earlier, in 1914. Drug prohibition has marched onward since. Its episodic ratchetings‐​up and coolings‐​down have commenced to a particularly aggressive and militaristic incarnation over the last twenty‐​five years.



Once we’ve accepted a definition of “public health” expansive enough for government to dictate what we can and can’t put into our bodies, it’s a short leap to seat belt laws, motorcycle helmet laws, assisted suicide bans, and prohibitions and restrictions on all sorts of other risky behavior. More recently, we’ve been given “public” smoking bans that extend to private businesses such as bars and restaurants. The Supreme Court recently upheld an Alabama ban on sex toys and marital aides. And parents are all too aware of the myriad regulations on the risks to which they can legally subject their children. Over just the last several years, governments at some level have prohibited motor scooters, “pocket bikes,” all‐​terrain vehicles, snowmobiles, alcohol vaporizers, and fireworks, to name just a few — all designed to keep people from hurting themselves. 



So it shouldn’t be the least bit surprising that “public health” might now come to include the size of our pants and the content of our refrigerators.



The justification for expansions of the government’s power to promote the “public health” is typically couched in “the number of lives this will save.” Sometimes, we’re told that a law will add x number of years to the average life. The most‐​used and easiest tactic is to simply state that the law’s necessary to protect “the children.” 



The _ad naseum_ recitation of the 400,000 figure is a good example. As is a report released in January of 2004 stating that being overweight at forty would cut several years off the typical life. The public health activists at the Center for Science in the Public Interest have long been fighting for marketing restrictions on junk food, particularly on programs directed “at our children.” 



Longevity seems to be an obsession among the public health crowd. There seems to be no limit to the costs they’re willing to endure if some policy promises to lengthen lives. It seems improbable to them that there may be people who’d sacrifice a month or two of their senior years for the lifetime of pleasure some get from a daily cigarette, a night of hard‐​drinking, or a slice of cherry pie after dinner. It’s as if adding more days to the end of our lives were the only reason for living. 



Even then, as British doctor and author Michael Fitzpatrick explains in his book _The Tyranny of Health_ , death can’t be prevented. It can only be postponed. And “death can generally be postponed only for a relatively short time by relatively intensive preventative measures,” Fitzpatrick writes. That is, high‐​cost measures that would typically add just a few days or months to the average life.



There’s certainly nothing wrong with studies or public awareness campaigns designed to discover and inform us about how we can make healthier choices. It’s that the “advice” rarely stops there. Inevitably, such studies and campaigns lead to calls for government policies aimed at increasing longevity, and in so doing, take options and choices away from people who may value pleasure, convenience, or indulgence more than perfect health or a prolonged geriatry.



In the eloquent polemic _Cigarettes Are Sublime_ , Richard Klein writes, “Healthism in America has sought to make longevity the principle measure of a good life. To be a survivor is to acquire moral distinction. But another view, a dandy’s perhaps, would say that living, as distinct from surviving, acquires its value from risks and sacrifices that tend to shorten life and hasten dying.”



Classical liberals should argue against the ever‐​expanding “public health” initiatives not only because they’re supported by junk science or manipulated data (though that’s often the case), but because the freedom to risk, indulge, and “sin” are essential to preserving individual liberty and a free society. Governments of free people aren’t authorized to ensure good health, they’re charged with securing liberty, which most certainly includes the liberty to hold bad habits.



 **Socialized Medicine**



The other chief reason why “public health” has been able to include ridiculous measures like obesity legislation and seat belt laws is because of our increasingly collective system of healthcare. Even private health care has a collective component to it. Today, routine, maintenance‐​oriented doctor visits are typically paid for by employer‐​provided health insurance, calling to mind the old Milton Friedman axiom about how generous we tend to be with other people’s money. Health insurance by definition pools risk. But many states (as well as the general culture of the health care industry) put restrictions on so‐​called “medical underwriting” – or allowing health insurers to vary premiums base don risk, the same way auto or life insurers do. All of these factors together create a system of perverse incentives which undermine the notion that we ought to let people take personal responsibility for their own health and well being. Healthy people subsidize unhealthy people. When the consequences of poor decisions are shared, there’s less incentives to make good decisions.



And that’s just the private sector. At the same time, politicians seem to be falling all over themselves in a rush to expand Medicare and Medicaid benefits for the aging, politically potent Baby Boom generation. The Cato Institute estimates that the new prescription drug benefit could in the end exceed a trillion dollars. Medicare’s noodling with the idea of covering obesity treatments could very well end up costing nearly as much.



This creeping socialization of medicine gives government new license to meddle with our private affairs. It creates a climate where excessive state interference in the most intimate of personal matters – what we put into our mouths – becomes not only acceptable among the electorate, but _desirable_. After all, if that cheeseburger you’re eating clogs your arteries and puts you in the hospital, your poor choices will be reflected in my health insurance premiums. If you’re on Medicare or Medicaid, it’ll show up in my taxes.



That’s exactly the argument the government put forward in the summer of 2004 when the Department of Health and Human Services announced that Medicare would consider covering the costs of obesity treatments, including diet plans, counseling, and gastro‐​bypass surgery, all new frontiers for preventative government intervention. HHS officials insisted that the change would save taxpayers money over the long haul if obesity were prevented or treated before the ill‐​health effects associated with the condition begin to present themselves.



It isn’t difficult to see how this argument could be applied in a larger sense – that we need to tax fatty or sugary foods, for example, to save everyone money on health insurance premiums and to keep the obesity problem from bankrupting Medicare and Medicaid. In fact, that exact argument _has_ been made – and by a credentialed _conservative,_ no less. Writing on _National Review Online,_ David Frum wrote:



And as Americans struggle with an epidemic of obesity — and the ensuing costs to the taxpayer — conservatives who favor (as almost all conservatives do favor) Medicare and Medicaid need to ask themselves whether their easy libertarian attitude to the worst practices of the fast food industry retains its relevance. Big Gulp drinks and super‐​sized fries are making America sick — and you are paying the bill. A little moderation would cure a lot of medical and fiscal ills; and a little incentive might induce that moderation.



It’s bad enough hearing that kind of talk from the left. But when it comes from the right, too, it’s a bad harbinger for what might be ahead.



The solution to this is to return some semblance of personal responsibility to the health care system. Health or Medical Savings Accounts, for example, enable consumers to roll money not spent on routine medical procedures into a retirement account, tax free. In contrast to the current system — which if anything incentivizes poor decisions — HSAs or MSAs encourage consumers to take care of themselves. Money not spent on visits to the doctor’s office is money saved for retirement.



Another suggestion would be to free up health insurers to do medical underwriting. The Bush administration has said it sees no federal barriers to the practice, so to the extent that barriers exist, they’re likely at the state level. Congress could facilitate the process by passing legislation (justified by the Commerce Clause) that would allow consumers in any state to purchase health insurance from companies in any other state, under the laws and regulations of the state where the insurer is incorporated. This would not only free up health insurers to medically underwrite, it would create a kind of competition between the states to ease regulatory burdens to attract insurers.



The result would unleash market forces on the task of finding the best carrot‐​and‐​stick approach to encouraging healthy lifestyles. Insurers would compete amongst themselves for customers, while states would lower regulatory barriers while competing for insurers. Currently, there’s much debate over whether the ill‐​health effects often associated with obesity are from obesity itself, or from the sedentary activity levels that often accompany being overweight. Hundreds of insurers competing with one another to both attract consumers and develop plans that reward the healthiest habits among their patrons (which of course benefits the insurers in the way of lower healthcare costs) might bring us closer to an answer to such questions. At the very least, if each us were solely responsible for the consequences of our diet and activity level, the point would be rendered moot from a public policy perspective.



The bizarre thing about the obesity debate is that less than a decade ago, the very thought of it was often discussed only in parody, or in a _reductio ad absurdum_ context. Opponents of the tobacco lawsuits often invoked the idea of trial lawyers suing fast food restaurants as one example of the “parade of horribles” that might follow should the tobacco suits be allowed to go forward. 



Well, we’re here now. This is post‐​reductio America. If the anti‐​obesity proposals currently up for debate become law, it’s difficult to come up with any aspect of our lives that’s out of the reach of the public health activists. Or, as one advocacy group that represents the food industry has put it, the question will no longer be “what’s next?” …but _“what’s left?”_
"
"**The Irish government plans to ease Covid restrictions for ""close to two weeks"" over Christmas.**
Tighter rules will only be brought back in if virus rates are increasing, according to the tÃ¡naiste (Irish deputy prime minister).
Leo Varadkar said it made sense to ease restrictions ""in phases"" and a full reopening next week was ""not safe"".
Gyms, retail, hairdressing and personal services will reopen first, he confirmed.
The reopening of bars and restaurants next week has not been ruled out, according to the tÃ¡naiste, but he said it was still ""a matter of discussion"".
He added that as virus rates in the Republic were lower than in the UK, the Irish government hoped to ease restrictions for longer than the five days being allowed there.
Mr Varadkar said consideration was being given to allowing three households to mix during the festive period, like the four UK nations.
The Republic of Ireland is currently under level five restrictions, the highest level of its Covid-19 tier system.
Under the rules, people can only exercise within 5km (three miles) of their home, many non-essential shops are shut and takeaway services can only be offered by bars and restaurants.
A final decision is set to be taken on new restrictions by the Irish government after a cabinet meeting at 13:00 local time on Friday, RTÃ reports.
On Wednesday, a further six deaths linked to Covid-19 were reported, bringing the Republic of Ireland's total to 2,033.
There have been 71,187 confirmed cases of the virus after an additional 269 positive tests were recorded."
"Difficult and almost impossibly daunting as it may seem, the world is faced with not one but two existential crises and two races against time: the coronavirus and the climate emergency. Dealing with both is going to require extraordinary focus and resolution. Already there is a whiff of political opportunism in the air. Last week, the Czech prime minister, Andrej Babiš, said that the €1tn European Green Deal, unveiled and enshrined in law by the European commission barely three weeks ago, should be put to one side. Member states, he advised, should concentrate all resources on combating a pandemic which, one by one, is shutting down societies and economies. Along with other eastern European states such as Poland, the Czech government has been reluctant to acknowledge the scale of action required to combat global heating, which would have a severe impact on fossil fuel industries in their countries. The extreme urgency of defeating Covid-19 scarcely needs stating. But Mr Babiš’s broader suggestion has been rightly rejected. “This is one of the very reasons why we presented the climate change law: to avoid that climate action, a generational task, is obfuscated by more pressing and immediate challenges,” said a Brussels spokesman. Frans Timmermans, the Dutch commissioner who is leading the EU response on the climate emergency, has made the same point.  The new climate law commits member states to zero emissions by 2050. A stringent new target is also to be set for 2030, which will be enshrined in the law.  Mr Timmermans has said that the climate law will act as a ‘“compass” for the next 30 years as EU member states seek sustainable forms of growth. In these extraordinary times, local imagination and creativity in developing a sustainable future will be at a premium. There are at least some hopeful signs that such thinking is taking place. In the city of Utrecht, plans have been unveiled for the largest purpose-built pedestrianised residential area in Europe, which will attempt to harness the virtues of the sharing economy. The Merwede estate will house 12,000 people on a 60-acre site. Transport will be provided by bus and train networks and a shared pool of bikes and cars – one car for every three families. Schools, shops, sports and medical services will all be within walking distance, and water from the local canal will be used to heat the area. The intention is for the district to become close to energy neutral. Utrecht is one of the fastest-growing cities in the Netherlands and is projected to add 100,000 people to its 350,000 population by 2040. In terms of factoring in a necessary environmental dimension to new construction, Merwede looks like best practice. It is the kind of project that is relatively small scale, but repeatable. It helps of course that the Dutch have a historically passionate relationship with the bicycle. But as the EU attempts to hold the line on implementing its green deal, many more Utrechts will be required."
nan
"Einstein probably didn’t say “insanity is doing the same thing over and over again and expecting a different result”, but might have done had he kept tabs on the impact of the annual climate negotiations. We have now had 25 of them – the 26th Conference of the Parties (Cop26) will take place in Glasgow in November – yet greenhouse gas concentrations continue to rise inexorably. Cops – especially the one in Paris in 2015 – have changed attitudes and influenced policy. But to meet the goal of reducing global emissions to net zero by mid-century we have to start doing something substantial and different in addition to seeking stronger commitments at Cop26. The good news is that there are now real grounds for optimism that we can slow and ultimately stop greenhouse gas emissions. Renewable energy currently outcompetes fossil fuels in many areas and continues to become cheaper every year. New energy storage options, ranging from cheaper batteries to green ammonia, are emerging. New ways to produce proteins at scale without destroying rainforests are being developed.  When these solutions become so good, and so cheap, that they routinely outcompete their fossil fuel and biodiversity-destroying counterparts, greenhouse gas emissions will decline to near zero. Getting there, though, needs some serious focus on green technologies supported by policies that will get them rolled out. For almost three decades, world governments have met every year to forge a global response to the climate emergency. Under the 1992 United Nations Framework Convention on Climate Change, every country on earth is treaty-bound to “avoid dangerous climate change”, and find ways to reduce greenhouse gas emissions globally in an equitable way. Cop stands for conference of the parties under the UNFCCC. The UK will host Cop26 this November in Glasgow. In the Paris agreement of 2015, all governments agreed for the first time to limit global heating to no more than 2C above pre-industrial levels, and set out non-binding national targets on greenhouse gases to achieve that. However, these targets are insufficient, and if allowed to stand would lead to an estimated 3C of heating, which scientists say would spell disaster. For that reason, the Cop26 talks in Glasgow are viewed as the last chance for global cooperation on the emergency, with countries expected to come with tough new targets on emissions. The negotiations will be led by environment ministers and civil servants, aided by UN officials. Nearly every country is expected to send a voting representative at the level of environment secretary or equivalent, and the big economies will have extensive delegations. Each of the 196 nations on earth, bar a few failed states, is a signatory to the UNFCCC foundation treaty. The Cops, for all their flaws, are the only forum on the climate crisis in which the opinions and concerns of the poorest country carry equal weight to that of the biggest economies, such as the US and China. Agreement can only come by consensus, which gives Cop decisions global authority. Fiona Harvey Environment correspondent A research group in Oxford, led by my co-authors and myself has been identifying groups of “unicorn” technologies, named by analogy with “unicorn” startups valued at over $1bn, that can each deliver a reduction of at least a billion tonnes of CO2 a year. Unicorns don’t depend on fundamental new discoveries so should be ready for large-scale deployment within a decade. With a moderate investment in research and development or other support, they could in combination unlock multiple benefits across whole “energy ecosystems”. One example of such an ecosystem centres on converting cheap renewable energy – either from sunny places with few people, or spare wind from the North Sea – into hydrogen and ammonia, to provide zero-carbon fuel for shipping, heavy goods vehicles and even potentially aviation. They could provide the energy storage needed to complement variable wind and solar energy, process heat for industry, and turn iron ore into steel. The technologies that would unlock this ecosystem are the next generation of high-efficiency solar cells, low-cost electrolysers, and hydrogen and ammonia fuel cells and engines. All are proven technologies that simply need to be cheaper – further development could rapidly unlock a virtuous circle of falling costs and increased deployment. Another example is exceptionally water-efficient plants that can grow in semi-arid areas or on degraded land – prickly pear, pineapples and euphorbias are examples. Such plants could sequester carbon in soil on a large scale, and be fermented to proteins in place of soya beans, whose growth causes widespread deforestation and huge greenhouse gas emissions; they could even be used to make plastics. The unicorn technologies in this case include learning how to grow plants that we have historically ignored, along with precision separation and fermentation of the biomass. Getting a bold, unanimous agreement to ratchet up global ambition to act on climate at Cop26 will be very hard at this stage of the game, with the usual cabal of petro-states and coal producers doing their utmost to dilute any decisions of consequence. However, an approach focused around “coalitions of the willing” in the bottom-up spirit of the Paris climate agreement, could enable substantial progress without being stymied by vested interests. Each of these coalitions, built from nation states but also regions and even corporates, could focus on one or more of the unicorns. They would support research and development, advance demonstrators, or provide lower-cost finance or performance guarantees to encourage rollout and help the technologies become cheaper. They would allow least-developed and developed nations to share ambitions and interests in technologies where they have comparative advantages, such as solar resources, land or skills. Management and licensing of intellectual property could encourage coalitions to form and accelerate technology deployment. The formation of these coalitions could be seen as evolution of an earlier UK initiative called Mission Innovation. It targeted sectors or problems, rather than – as we are proposing – selected technology areas that underwrite whole energy ecosystems, which we believe would be a very much more productive approach.  This should not be seen as “picking winners”, but rather as “picking runners”. Funders should be prepared to see failures as well as successes. As co-chair with Italy of Cop26, the UK has an excellent opportunity to build coalitions that would lead to cheaper alternatives to fossil fuels. The UK is home to several companies and world experts in both the “hydrammonia” economy and semi-arid plants, and British businesses could be leading players in these two examples of ecosystems. In parallel with preparing for Cop26, the government should also change the UK’s broad approach. Neither academia nor industry on their own has the principal objective of solving the climate crisis. They have neither skills nor funding to develop technologies that are (nearly) out of the laboratory, build demonstrators when necessary, and create the technical and financial conditions needed to enable large-scale rollout. We believe the UK needs something like the Advanced Research Projects Agency-Energy, created in the US, which “advances high-potential, high-impact energy technologies that are too early for private-sector investment”. By fostering coalitions of the willing, which would focus on clusters of unicorn technologies, the UK could make a major contribution to solving the climate crisis. Cop26 could indeed be a turning point – but it cannot simply be more of the same. • Mike Mason is a fellow at the Smith School of Enterprise and the Environment, University of Oxford. This piece was written in collaboration with Cameron Hepburn, director of the Smith School, and Chris Llewellyn Smith, of the department of physics"
"

It’s official: 2006 is the warmest year in the temperature history of the lower 48 states. The records go back to 1895, and so far, with the exception of the far West, the winter of 2006–7 hasn’t been much cooler than your average fall. Last summer was the third hottest of all. 



Our hot summers have tended to be about 2 degrees F warmer than the century‐​scale average, while our winters have warmed by about 4 degrees. But a global warming or cooling trend doesn’t guarantee that any individual year or season will be warm or cold. The summer of 2004, for example, was the 15th coldest since 1895, and the winter 2000-01 was pretty chilly across the entire country. 



Let’s be candid. This is the way global warming is supposed to work. It raises the probability that a given season will be above average, but it doesn’t guarantee it. Further, it’s been known for well over a hundred years — long before scientists were taking regular measurements of U.S. temperatures — that putting carbon dioxide in the air will warm winters here much more than summers. 



There’s another peculiar (and predicted) characteristic about the winter warming: more than anything else, it’s the coldest days of winter that have warmed the most since 1976, while the hottest days of the summer have budged very little. 



Just as not all “global warming” winters are warm, there were some spectacularly warm ones in the early 20th century. It’s nothing new. 



“The official Washington temperature climbed to 76 degrees yesterday to tie the all‐​time January maximum temperature,” the _Washington Post_ reported on January 15, 1932. “Flowers have never ceased to bloom in the capital this year, coaxed out by the succeeding days of warm weather…frogs are croaking in the reservoir…just like they do in the summer.” 



The warmth of the eastern half of the U.S. in the winter of 1931–2 is like one of those baseball records people thought would never be topped. But, of course, both baseball and climate change, assisted by modern chemistry and technology, break old records. Barry Bonds hit 73 home runs, and one winter will eventually best 1931–32. 



And that winter will probably be even more enjoyable. As the _Post_ further reported that year, “Coatless citizens pluck pansies and pussy willows at New Haven, Conn.…Cleveland schoolboys go swimming in Lake Erie with temperature at 70.” 



Sounds like people were having fun back then, just as they are now. Hard to find a downbeat face, even here in politically shocked Washington. Maybe people are thinking about their heating bills. Maybe they are relieved not to have to experience the sheer terror that a single inch of snow causes around here. 



Temperatures began their recent climb with a sudden climate shift in the Pacific Ocean in 1976. In the succeeding three decades, winters warmed more than summers, colder temperatures rose more than hot ones, some places were drier, and some were wetter. 



But meanwhile, life expectancy, per‐​capita income, and crop yields went up, while the real cost of most commodities dropped. Global warming didn’t make all those salubrious things happen — although it had a little to do with higher crop yields — but it surely did not stop them. 



That prosperity and Washington’s smiling winter faces won’t stop the new legislative express on global warming. Nor will it stop naysayers who correctly proclaim that no politically viable proposal will ever do anything to slow planetary warming in a fashion that can even be measured. 



It’s not just the usual suspects who tout this. Scientists way on the left of the global warming spectrum, like Tom Wigley of the National Center for Atmospheric Research in Boulder, and Germany’s Paul Crutzen, now speak of technological “fixes,” such as injecting particles into the stratosphere to block sunlight, precisely because they appreciate how little any global warming law could accomplish, and how much it would cost. 



That, coupled with the people’s general satisfaction with the warm winter and their prosperity as the planet warms, should provoke the real debate concerning global warming. If, in fact, we can develop technology to choose the planet’s mean temperature, where should we set it? 



Before we began burning much fossil fuel, the hemisphere was mired in the “Little Ice Age.” Glaciers threatened European villages. Want to go back there? Or, maybe we’d like it like it is now, or even warmer. 



I don’t know the answer, but that’s the question society will ultimately wrestle with as it enjoys warmer winters, and finally acknowledges the futility of attempting to stop warming with impotent legislative acts
"
"
Share this...FacebookTwitterHere’s Germany’s solution to saving energy and reducing its carbon foortprint- make electricity affordable only to a few rich people! German online DIE WELT daily has an article titled: Hundreds Of Thousands Have Had Their Power Turned Off.
Germany’s power and gas has become so expensive thanks to its Renewable Energy Feed-in Act that it is now an unaffordable commodity for many among the poor.
Under the feed-in act, power companies are forced to buy up the expensive renewable energy from producers and pay them exorbitant tariffs. This has driven Germany’s electricity prices up and has made them among the most expensive in the world. So much so, that many can no longer pay for it.
According to DIE WELT:
Because of unpaid electricity bills, an estimated 600, 000 households in Germany had their power cut off in 2010, according to the Consumer Agency of North Rhine Westphalia in Düsseldorf. […] Price increases of about 15% for electricity and gas over the past 2 years have made energy an unaffordable commodity for many households.” said Chairman Klaus Müller. The increasing energy poverty is alarming.”
DIE WELT also writes that power companies had to send out millions of payment reminders. Many of these consumers, who were in arrears, paid their bills, but a portion were unable to do so.
 
Share this...FacebookTwitter "
"

Reuters reports that: 



Heat is more likely to kill an American than an earthquake, and thunderstorms kill more people than hurricanes do, according to a U.S. “death map” published on Tuesday…   
  
  
Heat and drought caused 19.6 percent of total deaths from natural hazards, with summer thunderstorms causing 18.8 percent and winter weather causing 18.1 percent, the team at the University of South Carolina found.



However, the result that heat is the most deadly natural hazard seems to be an artifact of the data source employed by the authors of the so‐​called “death map.” Their primary data source is the National Climatic Data Center’s _Storm Data_. However, the NCDC data for mortality from extreme heat and cold is questionable.   
  
  
As is evident from the paper, the authors are aware that mortality data for these two types of extreme events from NCDC are substantially different from mortality data from the Center for Disease Control (CDC) based on the Compressed Mortality File for the United States. The latter uses death certificate records, which provide the cause of each recorded death (based on medical opinion). I would contend that when it comes to cause of death, particularly for extreme cold and heat, medical opinion as captured in death certificate records is probably more reliable than determinations made by the meteorologists in the National Oceanic and Atmospheric Administration’s NCDC.   
  
  
The following table from Goklany (2007) provides a breakdown of mortality due to the major types of extreme weather events for 1979–2002 based on data from the CDC database for extreme cold and extreme heat, and various arms of the National Oceanic and Atmospheric Administration for floods, lightning, hurricanes, and tornadoes. It indicates that extreme cold, rather than heat, is the deadliest form of extreme weather event. In fact, over this period, extreme cold was responsible for slightly more than 50 percent of deaths during this period for the categories listed in the table.   






Note that despite the hoopla about natural weather disasters, they contribute less than 0.06% to the annual U.S. death toll!   
  
  
Moreover, as the following figure, also from Goklany (2007), shows, both US death and death rates from weather events are declining, despite any climate change, which we are assured can only make matters worse.   






Finally, the Reuters report notes, “Researchers who compiled the county‐​by‐​county look at what natural disasters kill Americans said they hope their study will help emergency preparedness officials plan better.” [The study was apparently funded by the Department of Homeland Security.] As a taxpayer, I hope that emergency preparedness officials look beyond this study to identify and prepare for future emergencies, or they might miss out on the larger disasters, even as they prepare for lesser ones.
"
nan
nan
nan
"**Staff at a North East university have voted in favour of strike action over health worries caused by Covid-19.**
Northumbria University in Newcastle saw hundreds of students test positive last month, although the number of infections dropped to 33 this week.
The ballot was issued after the University and Colleges Union (UCU) said university management ""refused"" to address in-person teaching concerns.
The university said talks with the union were ongoing.
The UCU described the vote as a ""massive step forward"" as it worked to keep campuses ""safe"".
It revealed 66% of members who voted approved taking strike action with 89.9% also agreeing to take action short of a strike.
""We regret that it took a ballot for industrial action for Northumbria to take this matter seriously,"" general secretary Jo Grady said.
""If the employer had listened to our concerns from the start then we could have avoided this escalation.""
Earlier this week Northumbria announced it would offer a ""limited amount of teaching on campus until 4 December"" with students then completing two weeks' work online before Christmas.
The union has welcomed that move, describing it as a ""safety-first approach"".
Responding to the strike vote, a university spokesman said: ""We are doing all we can to protect colleagues who feel unable to teach on campus at this present time.
""This will usually be where colleagues have an underlying physical health condition or mental health concerns or share living space with someone who is vulnerable.
""In these circumstances we have made it clear that colleagues will not be compelled to deliver face-to-face teaching on campus.
""Discussions between the university and UCU have continued during the ballot period and at this stage it is not clear whether any action will be taken so it is not possible to comment in detail.""
_Follow BBC North East & Cumbria on _Twitter _,_Facebook _and_Instagram _. Send your story ideas to_northeastandcumbria@bbc.co.uk _._"
"

In March 1990, NASA’s Roy Spencer and University of Alabama-Huntsville’s (UAH) John Christy dropped quite a bomb when they published the first record of lower atmospheric temperatures sensed by satellites' microwave sounding units (MSUs). While they only had ten years of data, it was crystal clear there was no significant warming trend.   
  
It was subsequently discovered by Frank Wentz of Remote Sensing Systems (RSS), a Santa Rosa (CA) consultancy, that the orbits of the sensing satellites successively decay (i.e., become lower) and this results in a spurious but slight cooling trend. Using a record ending in 1995, Wentz showed a slight warming trend of 0.07⁰C/decade, about half of what was being observed by surface thermometers.   
  
In 1994, Christy and another UAH scientist, Richard McNider, attempted to remove “natural” climate change from the satellite data by backing out El Niño/La Niña fluctuations and the cooling associated with two big volcanoes in 1983 and 1991. They arrived at a warming trend of 0.09⁰C/decade after their removal.   
  
Over the years, Spencer and Christy slightly revised their record repeatedly, and its latest iteration shows a total warming trend of 0.13⁰C/decade, which includes natural variability. But it is noteworthy that this is biased upward by very warm readings near the end of the record, thanks to the 2015–16 El Niño.   




Recently, Christy and McNider carried out a similar analysis to what they did in 1994 and found removing the volcanoes and natural sea surface temperature changes resulted in a warming trend nominally the same as their 1994 finding, at 0.10⁰C/decade—far, far beneath the 0.2–0.3⁰C/decade predicted for the current era by the models in the latest (2013) report of the UN’s Intergovernmental Panel on Climate Change.   
  
Much as Christy and McNider said in 1994, it appears that the sensitivity of temperature to carbon dioxide changes in those models is just too high.   
  
Here’s the illustration at the heart of the paper:   




![Because the print is so small in the figure legend, we’ll paraphrase it here. The top plot \(red\) is the temperature of the lower troposphere \(“TLT”\), from the surface to about eight kilometers in altitude.  The blue plot is the “natural” sea surface temperature \(SST\) component, now a combination of El Niño and other known oscillations, such as the Pacific Decadal Oscillation \(PDO\) and the Atlantic Multidecadal Oscillation \(AMO\). The middle black plot is the raw satellite data minus the oceanic oscillations, and the bottom one adjusts that for the two big volcanoes in 1983 and 1992. ](https://object.cato.org/sites/cato.org/files/wp-content/uploads/christy2017.png)



_Because the print is so small in the figure legend, we’ll paraphrase it here. The top plot (red) is the temperature of the lower troposphere (“TLT”), from the surface to about eight kilometers in altitude. The blue plot is the “natural” sea surface temperature (SST) component, now a combination of El Niño and other known oscillations, such as the Pacific Decadal Oscillation (PDO) and the Atlantic Multidecadal Oscillation (AMO). The middle black plot is the raw satellite data minus the oceanic oscillations, and the bottom one adjusts that for the two big volcanoes in 1983 and 1992._



The new Christy and McNider paper also calculates the “transient sensitivity” of temperature to increasing carbon dioxide. The transient sensitivity is the temperature change observed at the time that atmospheric carbon dioxide doubles from its preindustrial background. Given observed rates of increase, this should occur sometime around 2070. The sensitivity works out to 1.1⁰C, which is slightly below half of the average transient sensitivity of all the climate models in the latest (2013) report of the UN’s Intergovernmental Panel on Climate Change.   
  
This is another indication that if business-as-usual continues, including a continued transition from coal to natural gas for electrical generation, the world will easily meet the Paris Accord target of total anthropogenerated warming of less than 2.0⁰C by the year 2100.   
  
Note that this is based on the satellite-sensed lower atmospheric temperatures. Our next post will compare them to the reanalysis data described in our last Global Science Report.


"
"

Al Gore’s cinematic lecture contends, in part, that rising global temperatures from industrial greenhouse gas emissions are at this very moment melting the Greenland Ice Sheet, a phenomenon that will eventually inundate global coastal areas and submerge countless cities. True? Not according to a new paper that appears in the June 13 issue of _Geophysical Research Letters_ , a prominent peer‐​reviewed publication of the American Geophysical Union. The authors conclude their study with the following discussion: 



We have analyzed temperature time series from available Greenland locations and we have found that:   
  
  
i) The years 1995 to 2005 have been characterized by generally increasing temperatures at the Greenland coastal stations. The year 2003 was extremely warm on the southeastern coast of Greenland. The average annual temperature and the average summer temperature for 2003 at Ammassalik was a record high since 1895. The years 2004 and 2005 were closer to normal being well below temperatures reached in 1930s and 1940s (Figure 2).   
  
  
Although the annual average temperatures and the average summer temperatures at Godthab Nuuk, representing the southwestern coast, were also increasing during the 1995–2005 period, they stayed generally below the values typical for the 1920–1940 period.   
  
  
ii) The 1955 to 2005 averages of the summer temperatures and the temperatures of the warmest month at both Godthaab Nuuk and Ammassalik are significantly lower than the corresponding averages for the previous 50 years (1905–1955). The summers at both the southwestern and the southeastern coast of Greenland were significantly colder within the 1955–2005 period compared to the 1905–1955 years.   
  
  
iii) Although the last decade of 1995–2005 was relatively warm, almost all decades within 1915 to 1965 were even warmer at both the southwestern (Godthab Nuuk) and the southeastern (Ammassalik) coasts of Greenland.   
  
  
iv) The Greenland warming of the 1995–2005 period is similar to the warming of 1920–1930, although the rate of temperature increase was by about 50% higher during the 1920–1930 warming period.   
  
  
v) There are significant differences between the global temperature and the Greenland temperature records within the 1881–2005 period. While all the decadal averages of the post‐​1955 global temperature are higher (warmer climate) than the pre‐​1955 average, almost all post‐​1955 temperature averages at Greenland stations are lower (colder climate) than the pre‐​1955 temperature average.   
  
  
An important question is to what extent can the current (1995–2005) temperature increase in Greenland coastal regions be interpreted as evidence of man‐​induced global warming? Although there has been a considerable temperature increase during the last decade (1995 to 2005) a similar increase and at a faster rate occurred during the early part of the 20th century (1920 to 1930) when carbon dioxide or other greenhouse gases could not be a cause. The Greenland warming of 1920 to 1930 demonstrates that a high concentration of carbon dioxide and other greenhouse gases is not a necessary condition for period of warming to arise. The observed 1995–2005 temperature increase seems to be within a natural variability of Greenland climate. A general increase in solar activity [Scafetta and West, 2006] since 1990s can be a contributing factor as well as the sea surface temperature changes of tropical ocean [Hoerling et al., 2001].   
  
  
The glacier acceleration observed during the 1996–2005 period [Rignot and Kanagaratnam, 2006] has probably occurred previously. There should have been the same or more extensive acceleration during the 1920–1930 warming as well as during the Medieval Warm period in Greenland [Dahl‐​Jensen et al., 1998; DeMenocal et al., 2000] when Greenland temperatures were generally higher than today. The total Greenland mass seems to be stable or slightly growing [Zwally et al., 2005].   
  
  
To summarize, we find no direct evidence to support the claims that the Greenland ice sheet is melting due to increased temperature caused by increased atmospheric concentration of carbon dioxide. The rate of warming from 1995 to 2005 was in fact lower than the warming that occurred from 1920 to 1930. The temperature trend during the next ten years may be a decisive factor in a possible detection of an anthropogenic part of climate signal over area of the Greenland ice sheet.



So who are you going to believe—a couple of scientists from Los Alamos and an atmospheric physicist … or a politician who is, _ahem_ , NOT a scientist and his similarly uncredentialed Hollywood friends? The latter group may turn out to be right, of course, but if you only paid attention to what was in the _New York Times_, you’d think studies such as the one above are the paid figments of oil company imagination. They are not.
"
"The episodes of violence as a result of the Gilets Jaunes protests in France, which were initially triggered by increasing fuel prices, are an example of a recent type of conflict related to energy resources. Although these fuel riots have been happening for years now, these have never been studied or defined in an academic context. In my research, I collected the first database of fuel riots that occurred across the world between 2005 and 2013, which amounted to 44 different events. Analysing the data, I found that these violent riots are more likely when the international price of oil increases, and in countries that are politically fragile.  There are two ways in which climate change and scarcity can cause conflict over energy resources, and both act through the price of fossil fuels. The first is through climate action: governments introduce higher taxes on fossil fuels and related products in order to tackle climate change, which increases their price, which in turn triggers conflict. France is the only example we know of this pathway. The second comes about because fossil fuels themselves are also becoming scarcer and more difficult and expensive to extract, and this also increases their prices on the international market. To ensure poorer people still have access, essential products such as petrol and heating fuel are heavily subsidised all over the world. But, as the international price goes up, poorer nations often cannot afford high subsidies or prefer to redirect funds to other causes such as healthcare and other services to boost development. When governments slash subsidies, regular people end up having to pay more.  This is what happened in Nigeria, which despite being rich in crude oil, does not have many refineries and imports large quantities of fuel. The government in 2012 decided to cut a subsidy, leading to the doubling of fuel prices and transport fares. The reaction of the population was immediate, with violent protests and strikes that led to several deaths. Violent episodes from these two pathways have been called “fuel riots”, but no definition has ever been provided. So to define these events I adapted the definition of food riots coined by the World Bank: “Violent, collective unrest leading to a loss of control, bodily harm or damage to property, essentially motivated by a lack of fuel availability, accessibility or affordability, as reported by the international and local media, and which may include other underlying causes of discontent.”  If you were to monitor international fuel prices and national political fragility to identify countries at risk of experiencing fuel riots, as suggested in my research, France would have been one of the countries flagged up. Two thirds of the historical increase in France’s pump prices can be attributed to international oil prices, which rose steadily between June 2017 and October 2018, the month before the start of the demonstrations.  In addition, according to the World Bank’s indicator of Political Stability and Absence of Violence, France’s stability had been deteriorating between 2010 and 2016 and is considerably lower than the average in high-income countries. This measure of fragility takes into account several social and economic indicators and expert opinions. According to this evidence, there will inevitably be more fuel riots in future across the globe, thanks to rising international fossil fuel prices and (hopefully) increased action against climate change from national governments. However, governments still need to tackle climate change and many policies will target the price of energy-related products to encourage a switch to sustainable practices such as renewables and electric cars. So if governments need to implement these unpopular policies, how can they avoid a violent rejection from populations? First of all, the design and implementation of new policies needs to become more inclusive. In fact, one of the most cited reason behind the riots in France was the need for acknowledgement from a working class that feels neglected.  In addition, there needs to be better communication of why these measures are required to ensure the support of communities who are likely to be most affected. Climate policy needs to be seen as relevant for those communities, if they are to support its implementation.  Also, cash transfers or other forms of support need to be put in place to guarantee that the most deprived parts of the population – who cannot switch to more sustainable but expensive options as swiftly as others – still have access to basic resources such as heating and petrol to drive to work. Finally, parts of the revenue (in case of a tax) or saved expense (in case of a slashed subsidy) should be redirected to important causes or to fund the cash transfers mentioned above. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"The world is “way off track” in dealing with the climate emergency and time is fast running out, the UN secretary general has said. António Guterres sounded the alarm at the launch of the UN’s assessment of the global climate in 2019. The report concludes it was a record-breaking year for heat, and there was rising hunger, displacement and loss of life owing to extreme temperatures and floods around the world.   Scientists said the threat was greater than that from the coronavirus, and world leaders must not be diverted away from climate action. The climate assessment is led by the UN’s World Meteorological Organization (WMO), with input from the UN’s agencies for environment, food, health, disasters, migration and refugees, as well as scientific centres. In 2019 the oceans were at the hottest on record, with at least 84% of the seas experiencing one or more marine heatwaves. Surface air temperatures around the world were the hottest ever recorded, after a natural El Niño event boosted figures in 2016. The report says results from the World Glacier Monitoring Service indicate 2018-19 was the 32nd year in a row in which more ice was lost than gained. The melting of land ice combined with thermal expansion of water pushed sea levels up to the highest mark since records began.  The long-term decline of Arctic sea ice also continued in 2019, with the September average extent – usually the lowest of the year – the third worst on record. “Climate change is the defining challenge of our time. We are currently way off track to meeting either the 1.5C or 2C targets that the Paris agreement calls for,” said Guterres. 2019 ended with a global average temperature of 1.1C above pre-industrial levels. “Time is fast running out for us to avert the worst impacts of climate disruption and protect our societies.” He added: “We need more ambition on [emission cuts], adaptation and finance in time for the climate conference, Cop26, in Glasgow, UK, in November. That is the only way to ensure a safer, more prosperous and sustainable future for all people on a healthy planet.” Prof Brian Hoskins, of Imperial College London, said: “The report is a catalogue of weather in 2019 made more extreme by climate change, and the human misery that went with it. It points to a threat that is greater to our species than any known virus – we must not be diverted from the urgency of tackling it by reducing our greenhouse gas emissions to zero as soon as possible.” The physicist Edward Teller tells the American Petroleum Institute (API) a 10% increase in CO2 will be sufficient to melt the icecap and submerge New York. “I think that this chemical contamination is more serious than most people tend to believe.” Lyndon Johnson’s President’s Science Advisory Committee states that “pollutants have altered on a global scale the carbon dioxide content of the air”, with effects that “could be deleterious from the point of view of human beings”. Summarising the findings, the head of the API warned the industry: “Time is running out.” Shell and BP begin funding scientific research in Britain this decade to examine climate impacts from greenhouse gases. A recently filed lawsuit claims Exxon scientists told management in 1977 there was an “overwhelming” consensus that fossil fuels were responsible for atmospheric carbon dioxide increases. An internal Exxon memo warns “it is distinctly possible” that CO2 emissions from the company’s 50-year plan “will later produce effects which will indeed be catastrophic (at least for a substantial fraction of the Earth’s population)”. The Nasa scientist James Hansen testifies to the US Senate that “the greenhouse effect has been detected, and it is changing our climate now”. In the US presidential campaign, George Bush Sr says: “Those who think we are powerless to do anything about the greenhouse effect forget about the White House effect … As president, I intend to do something about it.” A confidential report prepared for Shell’s environmental conservation committee finds CO2 could raise temperatures by 1C to 2C over the next 40 years with changes that may be “the greatest in recorded history”. It urges rapid action by the energy industry. “By the time the global warming becomes detectable it could be too late to take effective countermeasures to reduce the effects or even stabilise the situation,” it states. Exxon, Shell, BP and other fossil fuel companies establish the Global Climate Coalition (GCC), a lobbying group that challenges the science on global warming and delays action to reduce emissions. Exxon funds two researchers, Dr Fred Seitz and Dr Fred Singer, who dispute the mainstream consensus on climate science. Seitz and Singer were previously paid by the tobacco industry and questioned the hazards of smoking. Singer, who has denied being on the payroll of the tobacco or energy industry, has said his financial relationships do not influence his research. Shell’s public information film Climate of Concern acknowledges there is a “possibility of change faster than at any time since the end of the ice age, change too fast, perhaps, for life to adapt without severe dislocation”. At the Rio Earth summit, countries sign up to the world’s first international agreement to stabilise greenhouse gases and prevent dangerous manmade interference with the climate system. This establishes the UN framework convention on climate change. Bush Sr says: “The US fully intends to be the pre-eminent world leader in protecting the global environment.” Two month’s before the Kyoto climate conference, Mobil (later merged with Exxon) takes out an ad in The New York Times titled Reset the Alarm, which says: “Let’s face it: the science of climate change is too uncertain to mandate a plan of action that could plunge economies into turmoil.” The US refuses to ratify the Kyoto protocol after intense opposition from oil companies and the GCC. The US senator Jim Inhofe, whose main donors are in the oil and gas industry, leads the “Climategate” misinformation attack on scientists on the opening day of the crucial UN climate conference in Copenhagen, which ends in disarray. A study by Richard Heede, published in the journal Climatic Change, reveals 90 companies are responsible for producing two-thirds of the carbon that has entered the atmosphere since the start of the industrial age in the mid-18th century. The API removes a claim on its website that the human contribution to climate change is “uncertain”, after an outcry. Exxon, Chevron and BP each donate at least $500,000 for the inauguration of Donald Trump as president. Mohammed Barkindo, secretary general of Opec, which represents Saudi Arabia, Kuwait, Algeria, Iran and several other oil states, says climate campaigners are the biggest threat to the industry and claims they are misleading the public with unscientific warnings about global warming. Jonathan Watts The WMO said its report provided authoritative information for policymakers on the need for climate action and showed the impacts of extreme weather. A heatwave in Europe was made five times more likely by global heating, and the scorching summer led to 20,000 emergency hospital admissions and 1,462 premature deaths in France alone. India and Japan also sweltered and Australia started and ended the year with severe heat and had its driest year on record. Australia had “an exceptionally prolonged and severe fire season”, the WMO noted. Floods and storms contributed most to displacing people from their homes, particularly Cyclone Idai in Mozambique and its neighbours, Cyclone Fani in south Asia, Hurricane Dorian in the Caribbean, and flooding in Iran, the Philippines and Ethiopia. The number of internal displacements from such disasters is estimated to have been close to 22 million people in 2019, up from 17 million in 2018. The US saw heavy rains, with the total from July 2018 to June 2019 being the highest on record. Total economic losses in the US for the year were estimated at $20bn, the WMO said. Unpredictable climate and extreme weather was a factor in 26 of the 33 nations that were hit by food crises in 2019, and was the main driver in 12 of the countries. “After a decade of steady decline, hunger is on the rise again – over 820 million suffered from hunger in 2018, the latest global data available,” the report says. The WMO said unusually heavy precipitation in late 2019 was also a factor in the severe desert locust outbreak in the Horn of Africa, which is the worst for decades and expected to spread further by June 2020 in a severe threat to food security. Prof Dave Reay, of the University of Edinburgh, said: “This annual litany of climate change impacts and inadequate global responses makes for a gut-wrenching read. Writ large is the ‘threat multiplier’ effect that is climate change on the biggest challenges faced by humanity and the world’s ecosystems in the 21st century.”"
"Full marks to colleagues at the World Wildlife Fund and the Zoological Society of London for the Living Planet Report 2014 and its headline message which one hopes ought to shock the world out of its complacency: a 52% decline of wildlife populations in the past 40 years.   Over the summer I re-read Fairfield Osborne’s 1948 classic Our Plundered Planet – the first mass-readership environmental book that detailed the scale of the damage humanity wrought on nature. Faced with the figures in this report it is easy to slip into despondency and to blame others. But this would be a mistake. At the time, Osborne’s report must have been equally alarming, but the eclectic conservation movement of which he was part responded with confidence, hope and vision.  Their achievements were huge: the creation of a reserve network that forestalled the extinction of African creatures such as the elephant and rhino, the creation of a nature conservation agency, the International Union for Conservation of Nature) (IUCN) within the UN, and a raft of international wildlife agreements.   Today, conservation-minded people will probably be wondering what can be done to reverse wildlife declines. For me the question is how can today’s conservationists leave a wildlife legacy for the 21st century, and I think there are five ways we can change conservation to better fit the circumstances we face.  The effort to ensure that nature conservation became a policy area of the UN necessitated developing a strong international conservation regime. This has served us well, but the world has changed: centralised authority has given way to messy, networked governance organised across many levels.  If the Balinese want to restore Bali Starling populations in coconut plantations I say applaud their vision and learn from their innovation. What matters is that wildlife populations flourish, not that some institutionalised notion of a “wild species” gains global consensus. It is time to nurture diversity in conservation practice. Since the 1990s conservation has become overly technocratic, with nature framed as a natural resource and stock of capital available for human economic development. Given human self-interest this just leads to arguments over who gets what share.  I suggest a better way to frame environmental policy is in terms of natural assets – places, attributes and processes that while representing forms of value to invest in, are also at risk of being eroded and must be protected. We’ve done this before – think of great national parks where wildlife conservation, natural beautification and outdoor recreation combine for the benefit of wildlife, while also emphasising regional or national identity, health and cultural and economic worth.  Re-wilding is gaining traction. I see re-wilding as an opening, an opportunity for creative thinking and action that will affect the future. A key theme is restoration of trophic levels – in which the missing large animals at the top of the food chain are reintroduced, allowing natural ecosystem processes to reassert themselves. We might ask whether today’s reported declines in wildlife are a symptom of the ecosystem becoming more simple and, if so, whether re-wilding will lead to more abundant wildlife. Ecological intuition suggests the latter but in truth we don’t know.  In my view we need large-scale, publicly-financed re-wilding experiments to explore and develop new ways of rebuilding wildlife populations as an asset for society.   It’s clear that wildlife conservation is moving from being a data-poor to a data-rich science. The methods that underpin the Living Planet Report are state-of-the art, but even so we have yet to capture the analytical potential of “big data”.  Recent rapid developments in sensor technologies look set to bring about a step change in environmental research and monitoring. In ten year’s time, I predict that the challenge for indexing the planet will shift from searching out and compiling data sets to working out how to deal with an environmental “data deluge”. Despite this, wildlife conservation lacks a coherent vision and strategy. There are plenty of interesting technological innovations, but they are fragmented and individualistic in nature. We need leadership and investment to better harness them. Like it or not, the wildlife conservation movement was at its most influential – as a policy and cultural imperative – when it was filled with active members drawn from the political, aristocratic, business, scientific, artistic and bureaucratic elites.  This was between 1890 and 1970. Over the past 40 years conservation organisations have become more professional, building close working relations with bureaucrats, but approaching other elites simply as sources of patronage, funds and publicity. Conservation organisations must open-up, loosen their corporate structures and let leaders from other walks of life actively contribute their opinion, insight and influence to the cause.  These are five starting points for discussion rather than prescriptions. Perhaps the greatest asset we have is the deep-rooted sense of concern for wildlife found across cultures, professions and classes. It’s time to open up the discussion, to put forward new ideas for debate, and to ask others to suggest new and novel ways to save wildlife."
"
BBC news has reported that 40,000 homes are still without water in Northern Ireland after the recent spell of freezing temperatures. Many have been without water for more than 10 days, and reservoirs are being drained due to an unprecedented number of leaks since the thaw. Calls to a few friends confirmed that, yes, it is bad – friends in Lisburn have been without water since Christmas Eve due to a frozen mains supply (i.e. not in their house); others in Belfast report low water pressure.  Water is being rationed in places.
Was it really that cold? A search of the BBC site revealed “‘Baltic’ Northern Ireland” tucked away on the BBC NI news page. Castlederg in the West of the province recorded a low of -18°C on 20th December – a new record.  The thing about Ireland is that it sits on the very western fringes of Europe, bathed by the warm Gulf Stream (which is why Doug Keenan considered the 7000 years of Irish tree ring data so important that he pursued Queen’s University through FOI requests).  Ireland, despite its latitude, just doesn’t do ‘very cold’ (or ‘very hot’ for that matter).
When I first got interested in climate I ended up corresponding with Tonyb about the temperature records of the Armagh Observatory in Northern Ireland.  These stretch back to 1796. Incidentally there are a couple of WUWT posts featuring Armagh in the last year (here, here and here). How does this current cold month compare with the historical record at Armagh?  Was the recent cold unprecedented?
The currently incomplete December record for Armagh consists of raw data – three automated readings per hour.  Rather than waiting until they calculate the December average I looked for nearby stations on Weather Underground and found Glenanne PWS, about 15km to the SW of Armagh.  The average temperatures for the two stations over the month of November is plotted in Figure 1.  This gave a good linear fit (R^2 = 0.889) with an offset – Armagh being on average colder by just over 1°C.
Figure 1. Average temperatures for Armagh and Glenanne N. Ireland through November 2010
Figure 2 shows the December data for Glenanne on the same scale. Up to the 28th December, the monthly average is -0.86°C.  Mild conditions are expected for the next three days and, if I plug the forecast max/min (29th 8/6; 30th 8/4; 31st 6/2)  into my spreadsheet to complete the month, the monthly average rises to an estimated -0.23°C for Glenanne, remembering that this is an approximation for Armagh, which is typically colder.
Figure 2. Average temperatures for Glenanne N. Ireland through December 2010
In the Armagh historical record, which I have for 1796-2002 from [1] the average temperature for December is 4.9°C; January average is colder (4.1°C).  There are just two individual months colder than December 2010: January 1814 (-2.2°C) and January 1881 (-0.9°C) which puts this one as the third coldest on record at Armagh (2010 might yet tie with 1881 when the actual average for the month is published).
Coldest months according to the Armagh record:

January 1814 -2.2°C
January 1881 -0.9C
December 2010  -0.2C
February 1855  0.0C,  January 1963 0.0C
February 1895  0.2C
February 1947 0.4C
January 1985 0.5C,  December 1878 0.5C

The list above also puts it in perspective with respect to other extreme years in living memory – most notably 1963 and 1947. According to the Armagh records none of the coldest months in these years saw such extreme cold as the Christmas period this year.  The Arctic cold cut though the mild Atlantic air this year resulting in a monthly average 4-5°C below normal (Figure 3).
Figure 3. 
Even without all the warming we have been led to expect 😉 December’s cold probably can be described as unprecedented. I’ll await with interest the actual December figures for Armagh (and those from the Met Office).  As for this being caused by global warming – bull – it was just an extreme weather event.  They happen.  Go back >100 years and they happened then too.
Reference
[1] C.J. Butler, A. M. García-Suárez, A.D.S. Coughlin and C. Morrell. Air Temperatures at Armagh Observatory, Northern Ireland, from 1796 to 2002 Int.J.Climatol. 25: 1055-1079 (2005) [Full paper]
UPDATE – from the Daily Mail (h/t Spectator in Tips & Notes).  Looks as if this will be a similar record in other parts of the UK too:


“Met  Office figures show that the average temperature from December 1, the  first day of winter, to December 28 was a bitter minus 0.8c (30.5f).
This equals the record December low  of 1890.”

The article goes on to point out that December is rarely the coldest month in the UK and a continued cold spell could beat the record set in 1683-84 of -1.17C.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e86619a43',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
I’ve been aware of this for a couple of days on our Sea Ice page, but hadn’t done anything about it since I wanted to see if it might change. When blogger Kate of Small Dead Animals noticed it and published on it, I figured it was time to start asking NSIDC some questions.
Compare this NSIDC Arctic Sea Ice extent chart…

…with this from Cryosphere Today:


The NSIDC plot has since intersected the 2007 line, but CT has no new images up since 10-27-10:

It certainly appears that there is more ice in 2010 than 2007 on the Cryosphere Today page. CT hardly ever responds to email, so I didn’t even bother asking them why the discrepancy. NSIDC’s Walt Meier though, takes our concerns seriously and responded rather quickly to my questions:
~~~~~~~~~~~~~~~~~~~~~~~~~~~
From: Walt Meier
To: Anthony
Subject: Re: you might have a  problem
Sent: Oct 29, 2010 8:42 AM
Hi Anthony,
Thanks for the  heads up. I looked at it and it doesn’t look like there
is any  problem.
As we went through before with Steve [Goddard], looking at the images can  be
misleading because they’re not on an equal area projection. There is
more ice in the central Arctic this year, but less in the Beaufort Sea,
Canadian Archipelago, and Baffin Bay. These areas roughly balance each
other out.
I also recall Cryosphere Today having an issue of changing  their images,
so I don’t know if you can consistently compare them anyway –  it looks
like their 2007 image is missing some ice. Attached is our  concentration
images from 2007 and yesterday and there doesn’t look like  much
discrepancy (apologies for the different image  sizes).
walt
~~~~~~~~~~~~~~~~~~~~~~~
I fixed the size differences, and here they are:


Of course we don’t have the daily extent data from NSIDC, since they so far have refused to publish it (they do give monthly though) so, we have to be content with image comparison rather than data comparison with NSIDC.
=======================================
Walt, as I said before, you really should publish the daily data. Consider how this looks: NSIDC director Serreze screams “death spiral” to the media while at the same time holds back publicly funded data. It is the same sort of bull-headedness that got CRU in deep trouble.  – Anthony
=======================================
UPDATE: Reader Lee Kington provides this blink comparator version:



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e87ddeb03',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

When Amazon announced that half of its new corporate headquarters would be in Long Island City, it was revealed that the company also hit the jackpot with up to $3 billion in New York state and local subsidies. This angered a lot of people, including Rep.-elect Alexandra Ocasio‐​Cortez, D‐​Queens, but officials dug their heels in. As Gov. Andrew Cuomo said, “It’s not a level playing field to begin with … All things being equal, if we do nothing, [Amazon is] going to Texas.”



But all things are not equal between New York and Texas, and New York should fix its policies rather than hand out pork. There is considerable room for improvement, as New York state has the second‐​worst business tax climate and New York City has some of the most expensive housing per square foot in the nation. To fix the problem, New York should lean out taxes and regulation.



Cuomo is right that high taxes are a turn‐​off for business. But rather than provide Amazon with a special, targeted break, why not improve the rules for everyone? In order to attract business, states could cut or repeal corporate income taxes, which account for only 2% of state and local revenues yet act as a major growth hurdle given how mobile corporate investment is today.





Company‐​specific subsidies put the retail giant’s interests ahead of everyone else’s.



Because half of all business income flows through individual income taxes, these taxes also deter investment. New York should reduce income taxes to be more competitive. High taxes in places like New York are driving wealthy entrepreneurs out to zero‐​income‐​tax Florida and other low‐​tax states.



Governments could also reform property taxes and reduce development fees, which are a drag on business and residential development. Property taxes are by far the largest state and local tax burdens on businesses, and in many states don’t just hit land and structures but also machinery and equipment. States and cities with heavy business property taxes dissuade investment by capital‐​intensive businesses such as manufacturing.



Poor state and local policy isn’t only a drag on business: it also affects workers’ lives. High tech‐​firms need to hire talent, but workers won’t be so interested if livability is low and costs are high. For example, $200,000 only buys 126 square feet of living space in Manhattan, the worst in the nation. But the regulatory tax associated with zoning is estimated to account for 50% of the cost of housing there. This is something that policymakers should change.



Increasing allowable development density in New York’s boroughs and streamlining discretionary development approval processes would help support the growth New York needs, improve affordability for current and future residents, and even ease gentrification pressures when big business arrives.



Other policy reforms could reduce the cost of living. For example, occupational licensing increases the cost of services such as child and medical care that working families need. One study suggests that just requiring lead day care teachers have a high school degree is associated with an increase in child care costs of 25% to 46%. New York City has more restrictive occupational licensing requirements, and the state has the fourth‐​most expensive child care in the U.S.



Policymakers in New York should attend to these issues rather than handing out pork. Instead, they generated a series of one‐​off incentives and subsidies that were Amazon‐​specific, putting Amazon’s interests ahead of everyone else’s.



That would be less offensive if economic development incentives were critical to sustained economic growth. But mega‐​companies do less for cities’ long‐​term economic growth and health than smaller, organically grown companies do. And as Harvard economist Edward Glaeser argues in _Triumph of the City_ , having a diversity of industries, rather than a large and economically dominant company, is vital for cities’ long‐​term health.



Only broad‐​based reforms can provide a diverse and competitive economy. If governments were genuinely interested in the benefits of economic development for their residents, they would look for opportunities to improve the economic and regulatory landscape in an inclusive way. After all, businesses and workers don’t need more pork, they need lean government.
"
"Guardian journalist George Monbiot wrote a damning critique of the BBC and Sir David Attenborough’s wildlife documentaries in late 2018, arguing that they do little to illustrate the huge environmental issues faced by the natural world. Since then, Attenborough has adopted a much stronger position. He spoke at both the UN Climate Summit and the World Economic Forum in Davos, and used his platform to highlight the threats of climate change. Embarking on a new collaboration, Attenborough and the BBC are set to confirm their position in a one-off documentary entitled Climate Change - The Facts, airing on April 18. The 90-minute film will explain the effects that climate change has already had and the disasters it might cause in future. Although it’s crucial to raise awareness among the public about the impacts and threats of climate change, it’s equally important to explain how to fight it. That’s something the BBC has been more quiet about. The recent series Blue Planet Live featured a segment on the Great Barrier Reef in which it stated that coral bleaching is the result of climate change. That places the BBC in line with the scientific consensus. The same episode later described the “heroic research” effort that is needed to save the world’s reefs from coral bleaching, and covered the capture and transfer of coral spawn to a new location.  However, science has already given the solutions to address this problem. Recent reports from the Intergovernmental Panel on Climate Change, the Institute for Public Policy Research  and some of our own research all clearly indicate that tackling climate change and other environmental issues – including biodiversity loss, soil erosion and even ocean plastic pollution – requires major changes to society. We need to revise our economic system and its dependence on growth to prevent the unnecessary consumption of the world’s resources. As the youth climate strikes leader, the 16-year-old Greta Thunberg, clearly puts it, we need “system change, not climate change”.  In an era when schoolchildren are striking for climate action and radical proposals for climate action are entering the political mainstream, the BBC’s timidity towards even discussing solutions seems odd. Covering these arguments is political but goes way beyond party politics and certainly wouldn’t breach impartiality guidelines. Audiences might understand that this isn’t as interesting as coral spawning being captured during a lightning storm, as was shown on Blue Planet Live. But if the BBC don’t address the solutions to climate change, then how can there be an educated public which understands that saving the planet requires more than individual gestures like carrying a reusable coffee cup? There’s no doubt that Attenborough’s BBC documentaries have inspired millions of people around the world to take environmental issues seriously. His programmes have encouraged many of our students to undertake degrees in environmental sciences. Their insights into the natural world can present a sense of environmental optimism that promotes action. But failing to address the political and economic solutions necessary to stop climate change means the BBC could fail to respect its own values in education and citizenship. With their new documentary, Attenborough and the BBC should challenge our current economic system – only then can they fulfil their duty to inform the public with accuracy and impartiality. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"
Share this...FacebookTwitterA new book is coming out. Personally I believe it’s going to cause a political storm in Germany, if not Europe. It’s going to upset a large number of climate Scrooges and the profiteers of doom.
The book Die kalte Sonne, Warum die Klimakatastophe nicht stattfindet (The Cold Sun, Why The Climate Catastrophe Is Not Taking Place) seriously challenges global warming alarmism. The book is written by Prof. Dr. Fritz Vahrenholt and Dr. Sebastian Lüning. Deliveries start at Amazon.de February 22, 2012. But I’m told the date may actually be February 8!
The publisher is influential publishing house Hoffmann & Campe in Hamburg.
What compelled the authors to write the book?
In short, being trained scientists, they noticed stark contradictions between model projections and real-life observations. Nothing matched up, something was wrong with the science, the models, and the IPCC. They explain it in detail in the book and in layman’s terms. The German Amazon description writes:
The IPCC is sure: The climate warming is because of man. However, are the infamous climate gases really the primary driver of our climate? And why hasn’t it been getting warmer? Vahrenholt and Lüning have taken a close look at the various climate models during their research. They reach the conclusion that a part of the Earth’s warming of the last 150 years is because of a natural cycle that is predominantly controlled by the sun. The next decades are more likely to lead us to a slight cooling instead of a warming. This provides the time to rationally develop and expand renewable energy sources, and to carry out the energy transformation in an economically,
sensible and sustainable way.”
The book is up-to-date, and its content is well-researched – over 800 footnotes. Many of the cited sources are the most recent peer-reviewed scientific papers and findings. Also many of the well-known climate blogs and sites are cited as well. Some blogs are prominently featured, like Climate Audit, WUWT, and Real Climate. I had the privilege of reading the manuscript, so I’m familiar with the book’s content. I really wish I could spill more about it. The book concludes, paraphrasing:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




 The IPCC is in error, the models are bogus, and the climate catastrophe is not coming. The climate debate has to be started anew.”
Die Kalte Sonne also features guest contributions by leading international scientists.
I think this book is surely going to change the minds of a lot of readers here in Germany, and hopefully lead to a new and rational discussion, which is so badly needed here. The authors make a powerfully convincing case that the science behind global warming alarmism is extremely shaky and dubious, and that the current, panicked energy transformation stampede cannot continue on its current path without something very painful happening.
The book also underscores that a transition to renewable energy source is essential and that we need to do it. But it has to be done rationally and in a sensible step-by-step approach. Only in this way will it be possible to make an energy transition that assures the needs of 9 billion people on our home planet are humanely met.
Why not order here and give a voucher for Christmas!
About the authors
Fritz Vahrenholt
Prof. Dr. Fritz Vahrenholt is a professor of chemistry at the University of Hamburg. He has been active in politics and renewable energy for 30 years. From 2001 to 2007 he was Chairman of the Board of wind turbine manufacturer REpower Systems, Since 2008 he has been the CEO of RWE Innogy, the renewable energies arm of German energy giant RWE. Vahrenholt was also a member of the council for Sustainable Development under Chancellors Gerhard Schroder and Angela Merkel.
Sebastian Lüning
Dr. Sebastian Lüning has a doctorate in geology and paleontology. He has been involved in the reconstructions of natural environmental changes for 20 years. He was a guest professor at the University of Vienna, and has received a number of awards for his studies and research. He is currently a geological expert for Africa for RWE Dea.
Share this...FacebookTwitter "
"

Manslaughter is the killing of a human being without expressed or implied malice. Average life expectancy is very highly correlated with per capita income, and income growth is very highly correlated with economic freedom (note accompanying table).



When politicians enact anti‐​economic growth regulations and taxes, even in the name of “global warming,” “environmentalism,” and “fairness,” they are, in fact, shortening the lives of many of their fellow citizens and those in other countries.





The fundamental problem is that many politicians do not understand or, perhaps, do not wish to understand tradeoffs. 



I do not pretend to know with much certainty whether the Earth will be much warmer at the end of this century and whether any increase in temperature that does occur will reduce or increase human life expectancies. But I do know the following with high confidence: The global warming alarmists told us 15 years ago that the Earth would be getting steadily warmer — yet, in fact, it has been getting cooler for the last 10 years, and some of their new models say this cooling trend might continue for another 10 or 15 years. The restrictions on drilling for new oil have driven up the price of oil products to the extent they are causing unnecessary real hardship to billions of people on the planet and, as a result, people are spending less money on their medical care and medical research.



The political requirements to use corn and other food plants for fuel have driven up the price of food again for billions of people in the world, and those at the bottom of the income ladder are increasingly suffering from malnutrition.



In sum, millions, if not billions, of people right now are unnecessarily having their lifespans reduced because of an overreaction to a projected climate change which may or may not have an affect on the lifespans of humans living sometime in the future.



A 2002 National Bureau for Economic Research paper by Frank R. Lichtenberg showed that the empirical data (from 1960–97) provide strong support that medical innovation and expenditures on medical care contribute to increased longevity. “The estimates imply that the medical expenditure needed to gain one life‐​year is about $11,000, and the pharmaceutical R&D expenditure needed to gain one life year is about $1,354. Previous researchers have estimated that the average value of a life‐​year is approximately $150,000.”



Probably many politicians think they are being responsible when they do things like imposing costly environmental taxes, prohibiting new mining for needed metals, and coming up with costly CO2 trading schemes as the Europeans have done, and which are now being debated in the U.S. Congress. Yet, all these actions impede the proper functioning of the market, reduce economic growth and lower life expectancies, in part, by reducing the funds available for medical research and treatments.



Environmental laws that require reasonably clean air and water can clearly be a net gain for human health and economic development. But, like anything taken to excess, the costs of many of the new and proposed measures to curb CO2 greatly exceed the benefits, thus costing both lives and treasure. Most serious economists who have looked at the issue believe environmental adaptation (as humans and other plants and animals have done for millions of years) would be far less costly than speculative actions to try to change the climate.



The fundamental problem is that many politicians do not understand or, perhaps, do not wish to understand tradeoffs. That is, every time they increase a regulation or a tax, or require a government expenditure that reduces economic freedom and does not meet a reasonable cost benefit test, they are not engaged in just some annoyance, but they are costing real human life years.



Vaclav Klaus, president of the Czech Republic and also a noted economist, has written a book titled “Blue Planet in Green Shackles, What Is Endangered: Climate or Freedom?” Mr. Klaus does understand tradeoffs, and he also understands the nature of many in the political class, having spent much of his life under a communist regime.



He argues, as he did in an interview with The Washington Times last week, that global warming “is used to justify an enormous scope for government intervention vis‐​a‐​vis the markets and personal freedom.”



One might take issue with President Klaus’ assertion that those who advocate more regulation and higher taxes are not all well‐​meaning public servants, except for the unwillingness of many such as former Vice President Al Gore to debate both the science and economic costs with serious opponents and support serious cost‐​benefit analysis.



It is possible to make rational decisions about such issues as how much to spend on the environment, defense, public health, infrastructure, etc., and how to best fund such activities.



Unfortunately, all too many in the political class, whether in Washington, Brussels or wherever, want to turn the issues into a “religion,” as Mr. Klaus says, rather than to coolly analyze the pros and cons, and rationally debate the merits. If it were only possible to indict politicians for “manslaughter” for their costly and destructive acts, many billions of life years would be saved.
"
"
CU-NASA Research Center to Study Sun’s Effects on Earth’s Climate 





Image of sun courtesy of NASA.




The University of Colorado at Boulder’s Laboratory  for Atmospheric and Space Physics and NASA’s Goddard Space Flight Center  in Greenbelt, Md., today announced the formation of a new collaborative  research center dedicated to the study of the sun’s effect on Earth’s  climate.
The center, called the Sun-Climate Research Center, or  SCRC, will be co-directed by LASP Research Scientist Peter Pilewskie as  well as Robert Cahalan, who heads Goddard’s Climate and Radiation  Branch, and Douglas Rabin, head of Goddard’s Solar Physics Laboratory.

“The  exciting thing about this collaboration is that we believe it will  promote studies to help answer key questions about the climate system,  including how Earth’s atmosphere responds to the sun’s variability and  how that affects climate,” said Pilewskie, a faculty member in  CU-Boulder’s atmospheric and oceanic sciences department. “This question  is particularly important now as we seek to quantify the human-induced  impact on Earth’s climate.”
Made possible by a Federal Space Act  Agreement, SCRC will foster collaboration between Earth-atmosphere and  solar sciences at the two institutions.  Opportunities will include a  scientist exchange program between the organizations and the ability for  postdoctoral scientists and graduate students in science, engineering  and mission operations to move between LASP and Goddard. The partnership  also will include international research symposia on sun-climate  interactions.
“In recent years Goddard and LASP have worked  together on several Earth and sun missions,” said Cahalan.  “Now we look  forward to continuing to drive growth in this key interdisciplinary  field of sun-Earth research, bringing new focus to the study of  multiyear changes in the sun and its influence on Earth’s climate.”
According  to the center’s co-directors, the SCRC represents a rare and innovative  step that underscores LASP’s ability to take its high-caliber research  and program opportunities to a new level with Goddard.
“LASP has  developed some remarkable areas of expertise that are key to studying  the sun and its effect on climate and on human activities,” said LASP  Director Daniel Baker. “By working with our colleagues at Goddard, we  can leverage our skills and help take an important step toward greater  cooperation between NASA centers and leading university research teams.”
For more information on LASP visit lasp.colorado.edu/home/. For more information on NASA’s Goddard Space Flight Center visit www.nasa.gov/centers/goddard/home/index.html.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e86f0e138',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"
I swear, I had nothing to do with this. Speaking tonight in Canberra, details here. Weather records for Sydney here.
From the “weather is not climate department”:
Sydney recorded its coldest June morning today since 1949, with   temperatures diving to 4.3 degrees just before 6:00am (AEST).
Cold snap set to stay By Amy Simmons

 


  
Experts say it is unusual to  see such widespread cold weather in June. (User submitted photo: Rick Box)

//

People across south-east Australia are complaining  about unusually chilly temperatures and experts say there will be no  relief from the cold until Sunday at the earliest.
From Brisbane this morning, Miss7t7 wrote on Twitter “Still in bed,  so dam cold.. What’s going on Brisbane !!!!”. While in Melbourne,  lexandraKR tweeted “Waiting for frostbite to set in… Sooo cold in  Melbourne! Too scared to get out of bed incase I get hypothermia”.
Others are embracing the weather and urging those who are complaining  to toughen up.
“I am in love with this cold weather. Melbourne reminds me of Paris  at the moment. How can that be a bad thing?” wrote hannahjtoy. “Is it  seriuosly newsworthy that sydney temps are in the low single digits?  seriuosly? it not cold! suck it up!” FilthiAssistant tweeted.
But ABC weather specialist Graham Creed says people’s complaints are  justified.
“It’s definitely quite unusual to see such widespread cold weather in  June, it would be more typical in July and August,” he said.
“So people are complaining about the cold for a good reason.”
Mr Creed says most areas across the south-east are experiencing  temperatures well below average.
“Last weekend a cool change moved through and that introduced some  significantly colder air across most of south-east Australia,” he said.
“Quickly in behind that we had a high pressure ridge move through,  producing clear skies during both the day and the night, but it’s also  helping to trap that cold air in.
“The clear skies mean we are losing what little daytime heating there  is and overnight temperatures are dropping into the minuses through  many of those states, producing widespread frosts.
“On top of that we’ve got quite a breeze in certain areas and the air  is very dry so that’s producing very low wind chill, so not only is the  sun not providing much warmth, you’ve also got the assistance of the  wind making it feel colder than it actually is.”
He says Queensland is in for a particularly rough few days, as  widespread rainfall will see the conditions change from cold and sunny  to cold, cloudy and wet.
Yesterday, an icy blast through Adelaide brought enough rain to  supply the city for a month, with a hail storm capping off the  exceptionally wintry day.
Yesterday was also the coldest day in Melbourne in nearly two years,  with the city not reaching its maximum temperature of 10.8 degrees  Celsius until 7:55pm (AEST).
If the temperature in Melbourne fails to hit its forecast maximum  today, it will be the first time in 14 years the city has recorded three  consecutive days of temperatures below 12 degrees.
Last night Brisbane was coldest at 9:00pm (AEST), when the mercury  dropped to below 8 degrees, but experts say it will be even cooler  tonight.
Sydney recorded its coldest June morning today since 1949, with  temperatures diving to 4.3 degrees just before 6:00am (AEST).
more at ABC Radio


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a8ad639',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Is it possible for humans to fulfil their needs without also destroying the environment? It’s a question we need to find an answer to soon, as the world’s poorer regions demand the same perks that come with development. On one hand, people need to consume some of a region’s resources so that those living there can drink clean water, grow nutritious food and get access to health services and education. But such consumption comes with unavoidable impacts. If these impacts increase beyond a region’s ability to continue to provide services such as water, pollination, soil stabilisation and climate regulation then the process of development can actually hinder rather than improve people’s welfare and well-being.  Striking the right balance is tricky and requires a new way of defining places that are both environmentally safe and socially just. Over the past two years, working with an international group of scientists, we have developed such a definition of safe and just operating spaces. In doing so we have tackled the tension that often exists in low-income regions between raising standards of living and keeping environmental impacts within bounds that allow the environment to supply vital services. The findings of our research have been published this month in the journal Global Environmental Change.   Such a formula must factor in everything humans need for themselves and all of their impact on the environment. While environmental impacts and human needs can be loosely grouped together, they don’t necessarily exert pressure in the same direction – think of how demand for more jobs differs from better health, for instance. This calls for a more rounded idea of a safe and just space, where human needs exert an outward pressure and environmental boundaries constrain humanity.  Think of it as a doughnut: If we wish to help people out of poverty then we must remain within the doughnut – the safe and just space – where people are above a social foundation in which they have what they need, but are not exceeding environmental ceilings by stressing nature beyond breaking point.  In order for our approach to have practical use, we needed to show how to define both social foundations and environmental ceilings for a particular region.  For defining social foundations, we built on the work of the economist Kate Raworth who synthesised nationally and internationally agreed minimum living standards. Meeting these minimums means moving into the “doughnut zone”. But this zone is of course constrained by impact on nature and we propose four different types of environmental ceiling – cross any of the points below and you’ve escaped the doughnut and are into unsustainable territory. The red line is a limit that is deemed unacceptable to go beyond. A good example is air pollution. The Beijing skyline disappearing behind thick clouds of smog is producing iconic images of the environmental impacts of development in China. What is deemed an acceptable level of air pollution varies from country to country. The runaway can be explained with a cycling metaphor. Zooming downhill on a bike can be a thrilling experience. Unfortunately, fun can quickly turn to terror if you realise that your brakes are not slowing you down and in fact you are going faster and faster. Continual over-fishing of certain species on coral reefs can produce a series of rapidly unfolding disruptions to the entire system that quickly get out of hand and lead to the collapse of the reef.  The tipping point is how close to a critical transition a system may be. A good example here is the sudden change in water quality in a lake that within weeks can go from a seemingly healthy system with clear water and teeming with fish, to green and clogged with suffocating algae. Moving the system back to the clear-water state can be as challenging as putting Humpty Dumpty back together again.  The early warning signal can be best explained with another cycling metaphor. Your brakes may be able to handle very steep slopes but you may be unfortunate to experience a speed wobble where the front wheel begins to oscillate. These wobbles can feed back on themselves until the entire bike starts shaking from side to side. In such situations you slow down either gradually by applying the brakes or much more suddenly by getting thrown off the bike and sliding across the road. But there is hope that for some systems we may be able to detect these oscillations in time to be able to reduce our impacts. Consequently, detecting early warning signals themselves can be considered as a threshold that we should be wary of.  Two of our co-authors Rong Wang and Ke Zhang analysed environmental and socio-economic data to help define the social foundations and environmental ceilings for two case-study regions in China: Shucheng County and Erhai Lake. In both regions, intense agricultural development since 1960 has reduced poverty, but at significant environmental cost. The regional doughnut for Shucheng County shows that water quality, air quality and sediment quality have breached the environmental ceiling while access to clean water, sanitation and education is well below the social foundation.  Identifying such environmental ceilings is of little use if we simply power on past them. We hope that our integrated approach will lead to sustainable strategies that are based on a better understanding of the ecosystems that we all ultimately depend upon.  We may not be able to completely avoid all environmental impacts associated with poverty alleviation – we cannot have our cake and eat it – but we can try to ensure as many people as possible enjoy living within the doughnut."
"

The era of trade liberalization is dead. Yet it could get worse still. Not only have prospects for liberalization over the next few years been dashed, but Congress is considering legislation that could precipitate a retreat from the trade policies and institutions that have served U.S. interests for 60 years.



These are indeed dark days for trade. The Democratic Party, which has grown increasingly hostile to trade over the past decade, controls the legislature. The president’s authority to negotiate trade agreements and present them to Congress for an up‐​or‐​down vote has expired, and will not be renewed. The bilateral trade agreements completed with South Korea, Colombia, Peru and Panama will likely rot on the vine, as Congress shunts them aside to consider instead trade legislation that is either antagonistic or protectionist. And for the first time in post‐​World War II history, a multilateral trade negotiating round has ended in failure. The era of negotiation and accommodation may yield to one of confrontation and litigation.



One thing that has become clear this year is that Democratic Party opposition to trade runs much deeper than the leadership has been willing to admit. When the Democrats assumed control of Congress in January, the party’s leadership whispered assurances that, notwithstanding the strident anti‐​trade rhetoric adopted by its rank and file, they understood the importance of continuity in U.S. trade policy. With some modifications to the U.S. trade agreement template to reflect Democratic priorities on labor and environmental issues, the Congressional leadership would be able to help the administration move the agenda forward.



A grand bargain was struck in the spring, which was nothing more than a wholesale capitulation by the administration to Congressional demands for strict, enforceable labor and environmental provisions in prospective trade agreements, including the four pending congressional consideration. But as the ink was drying, the Democrats moved the goalposts.



The South Korea agreement was deemed unsupportable by House Ways and Means Chairman Charles Rangel (DNY) and Ways and Means Trade Subcommittee Chairman Sander Levin (D-MI) because its terms do not condition Korean automobile access to the U.S. market on the performance of U.S. automobile exporters in the Korean market. Of course, such a provision, which was put forward by Rangel and Levin in the waning days of the negotiations, would leave the U.S. auto producers in a position to decide just how much competition it wanted from Korean producers. Accordingly, that provision was a nonstarter.



The Colombia agreement was deemed unsupportable because the Uribe government allegedly has done an inadequate job of finding and prosecuting thugs who have terrorized and killed Colombian unionists over the years. Thus, Democratic disdain for a right‐​ofcenter Latin American government, which also happens to be one of the few regional governments not openly hostile to U.S. policy, suffices for justification to deprive Colombian citizens of the opportunity to improve their lots through better trade terms with the United States.



Consideration of the Peru agreement was sidelined until Chairman Rangel and others have a chance to visit Peru, see first hand how its factories are run, and possibly change the agreement’s terms, again. Democrats have used the labor conditions excuse to camouflage Big Labor’s real motive, which is to kill trade deals at all costs. At least that truth now has been exposed. But regrettably, the anti‐​trade objectives of organized labor and importcompeting interests have dovetailed conveniently with proliferating misconceptions and myths about imports, jobs, and manufacturing to produce a phony sense of crisis.



Most of the anti‐​trade legislation introduced this Congress is premised on the myth of U.S. manufacturing decline at the hands of rising imports, mostly from China. But U.S. manufacturing is thriving. In 2006 the manufacturing sector achieved record output, record sales, record profits, record profit rates, and record return on investment.



Imports are not a bane for U.S. producers. In fact, there is a strong correlation between manufactured imports and manufacturing output, as U.S. producers account for more than half of the value of all U.S. imports. When imports rise, output rises. When imports fall, output falls. In the past quarter century, imports have increased six‐​fold, while real GDP has grown by more than 130 percent, creating an average of 1.8 million net new jobs each year.



But policymakers fail to acknowledge this crucial relationship. Instead, too many in Congress view exports as good, imports as bad, and the trade account as the scoreboard. Given the large and growing U.S. trade deficit, policymakers conclude that we are losing at trade. And we are losing at trade because our trade partners are cheating.



In China’s case the alleged cheating involves currency manipulation, subsidization of industry, unfair labor practices, hidden market barriers, dumping, and other transgressions. Some of these allegations may carry a degree of truth, but by and large the trade relationship has been conducted within the rules and consensually, yielding huge benefits for Americans.



In any event, the proper course for redress for complaints is through the dispute settlement system of the World Trade Organization. The Bush administration lodged three formal complaints earlier this year, which are working their way through the process. Congress should allow that process to continue and restrain its urge to be seen doing something. There is a distinct risk that unilateral, punitive actions on trade could severely damage the trade relationship and lead to a contagious deterioration of respect for the WTO and its decisions. That, ultimately, would take us back to the days when tit‐​for‐​tat trade wars were common, and uncertainty in trade prevailed.



Plenty of blame for the current state of affairs rests with the Congressional Democratic leadership, which has reckoned there is very little political downside to receding on trade, economic consequences be damned. That position has the blessing of Big Labor, and opposing the initiatives of an unpopular president might prove to be good politics.



But Republicans are on the hook too. The strong pro‐​trade consensus among Republicans that was so evident in the 1990s began breaking down in the early part of this decade, as China’s economic emergence was becoming evident. Steel‐ and textile state Republicans have presented some of the greatest obstacles to the Bush administration’s trade policy agenda.



And by failing to make a comprehensive case for trade liberalization, the Bush administration itself bears some responsibility for the current state of affairs. Rather than talk about the benefits of imports, which keep prices in check for consumers and input costs competitive for producers, the administration has focused almost exclusively on the potential export gains from trade agreements, affirming the mercantilist world view of Congress. The U.S. Trade Representative’s office is fond of pitching further trade liberalization by pointing to the U.S. trade surplus with countries with which this administration has negotiated bilateral trade agreements. But by treating a trade surplus as a success metric, it’s only a small step to the conclusion that our overall trade policy is failing, given our nearly $1 trillion deficit.



The Bush administration’s quest for further trade liberalization came to a grinding halt when the 110th Congress convened. But in many ways the President’s trade policy legacy might be forged during its final 18 months. By holding the line against bad trade legislation from an increasingly confrontational Congress, the administration can make the task less arduous for a subsequent administration to rebuild the consensus for trade when the political climate improves.
"
"
Share this...FacebookTwitterIf your “Globe” Is Only 10 Meters From Your Door – It’s Warming!
By guest writer Ed Caryl
In A Recent Temperature History – Part 1, 22 stations in the midwest U. S. were examined. On an average, these stations were cooling slightly over one AMO cycle, from 1934 to 2000, but there was much variability. The greatest cooling was –0.76°C, and the greatest warming was 0.59°C. As these sites are all within a few hundred kilometers of each other, why the large variation? Was it population density? Or is it something else?
The towns in this group are all small, according to GISS under 10,000 population. The actual population was found to be from about 500 to just less than 7000, with one outlier at 24,900. The station distance from the center of that city is more than 7 kilometers, so GISS can be forgiven for that classification.
But perhaps it isn’t the surrounding population that counts, but simply the closest heated dwelling. To test that hypothesis, this author researched each station at the SurfaceStations.org website, and found the distance from each measurement sensor (MMS) to the nearest heated building. For some it was necessary to go to Google maps using the latitude and longitude along with other clues, to find the information. For others it was necessary to estimate the distance from photographs. This information was then plotted in Figure 1.

Figure 1. This is a plot of the temperature trends for 22 mid-western U. S. stations versus town population (black) , and distance from the measuring instrument to the nearest heated building (pink and red), usually a residence.
As can be seen on the plot, town population made almost no difference to the trend. The dots are nearly completely random with respect to population. On the other hand, the distance from a heated dwelling made a much larger difference. The two coolest sites were more than 100 meters from the nearest building. Within the population limits of this study, the Urban Warming Influence is simply the distance to the nearest heated building, not the size of the city.
This phenomenon is the reason for much of the Arctic warming. Urban Warming in the Arctic, and indeed in the Antarctic, is an occupied-building-to-temperature-sensor distance problem. In the polar regions, the temperature differential between occupied buildings and the outdoor temperature sensors is much greater than in the temperate mid-west U. S., so the distance must be greater to avoid the UWI problem. But man doesn’t like digging long cable trenches in ice or permafrost (it’s like concrete!), or walking long distances in –40° weather, so the measurements are not done properly.
It is clear to this author that measured “Global Warming” is simply due to increasing nearby energy use and the temperature sensor proximity to the resulting heat. Of course if we all reduce our “carbon footprint”, this reduced energy use will surely slow “Global Warming”; but it will not be because CO2 emission is reduced, and it will result in all of us freezing.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWarmist Spiegel journalist Axel Bojanowski presents today a story on Peter Gleick’s Fakegate scandal and on what it means. In a nutshell: climate science is far from settled and there is a bitter war waging between the skeptics and alarmists. Consensus does not exist!
Climate scientist pilfers secret documents from a lobbyist group“
Spiegel writes at the top of its report in bold print that the documents, which were intended to discredit the Heartland Institute:
…ended up disgracing the person revealing them.” Renowned climate scientist Peter Gleick using a fake name, succeeded in obtaining documents from a lobby group. He led a group on scientific ethics.”
Here Spiegel’s juxtaposition of Gleick’s seedy behaviour and his leadership of a group on ethics could not be more profound. Spiegel mentions that the bitter conflict between the skeptics and alarmists has been raging for 20 years (there never ever was a consensus).
Slowly one gets the feeling that the influential Spiegel is getting tired of the warmists obvious shenanigans and deception, and are not letting it go unnoticed, as much of the media are doing.
Even Spiegel seems to be going skeptic (at times). Get a load of this statement in the article (emphasis added):



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The UN climate report, which is summarized every few years with the involvement of hundreds of scientists, comes to worrisome conclusions. However, the environment comprising air and earth is so complex that there are still huge gaps of knowledge – and they provide the fuel for fierce debate.”
So much for settled science. Bojanowski, a journalist who has written some of the warmist of articles in the past, doesn’t seem to believe in settled science anymore.
Spiegel explains how Gleick obtained the documents and how they were published by Desmogblog, and informs readers that “a simple apology will not suffice” and that Heartland is “demanding a complete clarification” from Gleick and that “legal consequences will follow”and that the integrity of many members and the reputation of the institute were damaged.
Spiegel goes into Gleick’s “downfall” – from being a leader of an ethics workgroup for the renowned American Geophysical Union (AGU) – to now reaping the outrage from Mark Fennel of the AAAS, and how Kevin Knobloch of the Union of Concerned Scientists has distanced himself from Gleick.
As the war between skeptics and alarmists intensifies in bitterness, Spiegel concludes with the following observation:
The recent affair fully confirms that the complexity of the climate topic is presenting challenges that are simply too much for the public debate to handle. Even intelligent scientists like Peter Gleick can lose their rationality.”
Indeed the science is complex and far from being settled. But we should remind Spiegel why intelligent scientists lose their rationality in the first place. It has something to do with the quality of their arguments and their failure to convince.
Share this...FacebookTwitter "
"

In a recent op-ed Robert Kagan laments that (Western) Europe is sliding into irrelevance. But that might be the best thing for the rest of the world.   
  
Don’t get me wrong, the world owes plenty to Europe. It’s given the world great art, architecture, literature, and music. It’s also given the world the ideas of universal education, the scientific method, research institutions, property rights, rule of law, democracy, religious freedom, and freedom of thought and expression, among other things. These ideas and institutions coalesced to power the engine of progress that drives the economic and technological development that have improved human well-being — not only in Europe but elsewhere — to levels far beyond what our ancestors could have imagined. Consequently, today we live longer, healthier, more educated, freer, and wealthier than ever before. But for the past century, Europe seems determined to undo all the good it’s ever done.   
  
Europe gave the world the ideologies of Fascism and Marxism, which were responsible — or provided rationalizations — for 100–150 million deaths worldwide, including many outside Europe, most notably in China, Cambodia and North Korea. Then in a few short decades, despite having risen Phoenix-like from the ashes of destruction of World War II, instead of brimming with optimism, Europe has taken a decidedly pessimistic turn.   
  
It no longer believes in progress. Its birth rate has dropped below replacement rates, yet, despite its protestations of equality, fraternity, secularism, and respect for human rights, it’s unwilling or unable to welcome or integrate immigrants of different colors or religious backgrounds into its societies. And one by one it’s abandoning the great ideas that brought it, and the rest of the world, progress, and advanced human well-being.   




Its political leadership, although democratically elected, has abandoned democracy in its pursuit of a united Europe. The more the idea of the EU fails in democratic tests — most recently in Ireland — the more devious its politicians' machinations to bypass popular approval.   
  
It has abandoned scientific inquiry, relying instead on mantras such as the “science is settled.” Having abandoned science, it now relies on superstition, manifested in the notion of a global-warming-triggered apocalypse of Biblical proportions if average temperatures exceeds 2 degrees Centigrade above pre-industrial levels — an apocalypse complete with death, disease, pestilence, droughts, famines and floods. Not only is there no evidence for this, this superstition persists despite the current reality that more Europeans die in winter than in summer, Europe’s long history of misery and want during cold periods and plenty during warm eras, and that even as media coverage of extreme weather events becomes more compelling and ubiquitous, globally the deaths and death rates from such events are in long term decline. If Europe had spent a fraction of the resources in adapting to climate change as it did on complying with the futile, but politically-correct Kyoto Protocol, it might have reduced by thousands the death toll of its 2003 heat wave.   
  
Europe is now on the verge of abandoning the quest for technological progress, preferring instead to be ruled by the so-called precautionary principle which, as applied by Europe, actually increases human misery and death. It does this by discouraging, if not vetoing, new and safer technologies that could displace older and less safe technologies on the grounds that “safer” is not good enough — it has to be absolutely safe.   
  
The precautionary principle was used to justify relinquishing its use of DDT, which was easy, because Europe had already conquered malaria. It is also used against genetically modified crops. The misapplication of the precautionary principle, coupled with its abandonment of scientific inquiry evident in the torching and destruction of experimental trials on genetically modified crops and its reliance on superstition, has resulted in a _de facto_ ban on such crops in most of Europe. But giving up such crops isn’t hard either. Western Europe is well fed — in fact today it worries more about obesity than hunger — and its farmers’ excessive productivity is actually a drag on its taxpayers. Some Europeans would also give up nuclear and coal, but that would actually be giving something up, so protestations to the contrary, that will come about only after renewable energies mature and are better able to pay for themselves without subsidies.   
  
But worst of all, Europe is once again exporting dangerous, misanthropic ideas, which unfortunately are echoed even in the US where many are in thrall of European ideas, no matter how ill-conceived. These ideas are couched in doublespeak, such as the European version of the precautionary principle, which could kill as many people as the failed ideologies of Fascism and Marxism.   
  
Europe talks endlessly of helping developing countries and offering token amounts of aid but then refuses to reform its agricultural policies which would do a lot more for helping the latter help themselves. At the same time it bemoans the new prosperity of long-suffering Asia that has lifted over a billion out of a poverty that Europe has not known since even before the French Revolution because it's enabled by and rides on greater energy use. And for that, some Europeans threaten punishment through carbon tariffs.   
  
But energy use and economic development are inextricably linked not only in China and India but in Europe and elsewhere. Even as energy use fueled economic development, it freed human beings from back-breaking physical labor, allowed women to escape the drudgery of household work, equalized economic opportunities for women, reduced the need for child labor, liberated animals from being our beasts of burden, and enabled brains to displace brawn, laying the foundation for a less energy-intensive economy.   
  
Europe campaigned actively, but fortunately unsuccessfully, to ban DDT. Despite this, African nations, deferring to European “expertise” on matters technological while fearing a European boycott of their agricultural exports if even trace amounts of DDT are found on them, have been slow to adopt DDT to combat malaria — fears that Europe did nothing to dispel and may, in fact, have actively encouraged. For the same reasons, Africans have been reluctant to turn to genetically modified crops to reduce hunger and malnutrition. And once again, Europe is standing silently by if not actively discouraging the use of genetically modified crops.   
  
For context, consider that over 6 million people die each year from malaria, hunger and malnutrition, a toll that annually rivals that of the entire Holocaust. Yet Europe has done little to help or reassure Africa in this regard, thereby abandoning one of the Holocaust’s most important lessons, namely, inaction can be no less culpable than active participation.   
  
Europe may be able to walk away from further economic and technological development, but the rest of the world can't afford to, not if it values human and environmental well-being.   
  
An irrelevant Europe could save innumerable lives in the developing world. And that might be best for this world.


"
"**Six members of Pakistan's cricket team have tested positive for Covid-19 while on tour in New Zealand.**
All six have been moved from managed isolation into quarantine and the team's exemption from social-distancing rules for training has been suspended.
Health officials said all 53 members of the visiting squad were tested on arrival in the country.
New Zealand, widely praised for its pandemic response, had previously seen a total of 2,040 cases and 25 deaths.
It implemented a stringent but brief lockdown at the start of the crisis, along with targeted testing and successful surveillance. The country reported its most recent case of transmission within its borders on 18 November.
Pakistan meanwhile has seen 356,198 confirmed cases and 7,843 deaths.
New Zealand's cricket authorities said two of the six cases were ""historical"" and the other four were new. Historical can refer to a positive test returned some time after a person has recovered.
Some members of the Pakistan team had contravened protocols on their first day in managed isolation in Christchurch and would be reminded of their responsibilities, New Zealand Cricket (NZC) said.
A health ministry spokeswoman told Stuff.co.nz that several members of the Pakistan team had been seen on CCTV breaking the rules and the team was now on its ""final warning"". The rules had been broken despite ""clear, consistent and detailed communication of expected behaviour"", the spokeswoman was quoted as saying.
All members of the Pakistan squad had earlier tested negative four times before leaving the Pakistani city of Lahore.
The outcome was ""disappointing for the Pakistan squad"" but the ""testing outcomes and the actions taken show the government system is working"", NZC said.
Earlier this month the West Indies cricket squad - who are also in New Zealand - were also briefly banned from training and confined to their hotel rooms after CCTV showed them sharing meals and mingling together in breach of managed isolation guidelines.
The Pakistan team is scheduled to play two Test matches and three T20 matches while in New Zealand."
"
Share this...FacebookTwitterThe Church of Global Warming is shattering in Germany, one of the last bastions of the movement. Even the environmental bishops are leaving the Church.The print edition of FOCUS magazine has an article today on a new upcoming skeptic climate book, Die kalte Sonne, authored by former warmist Prof. Dr. Fritz Vahrenholt and geologist/paleontologist Dr. Sebastian Lüning.
Even though the book will not be available until February 6th, it has climbed to no. 4 on the Amazon-Germany bestseller list  under the category of environment and ecology.
(Thanks Die Zeit!)
That number will of course rise soon now that national weekly FOCUS has a write-up in today’s issue, and once it’s officially launched on February 6.
Only 31% of Germans are afraid of global warming
One very interesting statistic in today’s FOCUS article that even surprised me:
Only 31% of Germans are afraid of a global warming. In 2006 that number was double.”
Indeed skepticism has reached a point where now even leading environmentalists are abandoning the movement, as profoundly demonstrated by Vahrenholt’s and Lüning’s book. Many simply feel they have had the wool pulled over their eyes. Although there have been skeptic books in Germany, none had the impact that the soon-to-be-released Die kalte Sonne is expected to deliver. With the book ready to take off in Germany, preparations have already been taken for a possible launch of an international edition in English.
The book cites more than 800 sources, many are peer-reviewed papers that appeared after the IPCC 2007 report. It’s the latest summary of the state of climate science out there. It does not dispute CO2 as a driver. The book simply cuts it down to size, and backs it up with hard literature and data.
No more trust in the IPCC
Undeniably there’s a feeling that the stars are now aligned, the mood has swung, and key players are changing their minds. As FOCUS reports, even the most die-hard of warmists are converting, or at least softening their tones. Prof. Fritz Vahrenholt, a renewable energy expert, was once one of the fathers of the modern green movement in Germany and believed everything the IPCC preached – until 2 years ago. FOCUS writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Fritz Vahrenholt, one of the fathers of the green movement, no longer trusts the forecasts of the IPCC.”
and FOCUS tells us why, quoting Vahrenholt:
Doubt came two years ago when he was an expert reviewer of an IPCC report on renewable energy. ‘I discovered numerous errors and asked myself if the other IPCC reports on climate were similarly sloppy.”
In his book he explains how he dug into the IPCC climate report and was horrified by what he had found. Then add the 10 years of stagnant temperatures, failed predictions, Climategate e-mails, and discussions he had with dozens of other skeptical elite scientists. That was more than enough. FOCUS quotes:
I couldn’t take it any more. I had to write this book.”
Latif, Schellnhuber and Edenhofer softening?
In December we wrote about Mojib Latif backpedalling away from alarmism here, greatly scaling back from his earlier alarmist scenarios.
FOCUS also reports that even Climate Pope Hans Schellnhuber appears to be softening his tone. Recently at a speech he made at a seminar before agricultural experts, he admitted that “warmer temperatures and high CO2 concentrations in the air could very well lead to higher agricultural yields”. Is Schellnhuber preparing a back exit?
And FOCUS adds that even Ottmar Edenhofer might be softening his climate hard line. A few days after Schellnhuber’s admission, Vahrenholt and Edenhofer were both at a press conference in Munich, where Vahrenholt claimed that temperatures had not risen in a decade and that they would likely cool a bit in the future. FOCUS tells us Edenhofer’s reaction:
Edenhofer did not wish to contradict, even when requested.”
 
Share this...FacebookTwitter "
"Each of the 125 leaders attending the New York climate summit this week has been given four minutes to speak to the world. They (or their aides) may well have dipped into the climate literature to add scientific ballast to their speeches. But they may not be as familiar with the vast array of academic studies on effective communication about climate change. They should be. If world leaders and climate advocates really want to improve the chances of mobilising political will and citizen action behind a new deal, they will need to think carefully about what sort of key messages actually work. Clearly there is a balance to strike between doom-ridden messages and “bright-side” opportunities, and uncertainties around the science and the expected effects of climate change must be factored in too. Can risk language help? Part of their challenge is that the world’s media need – and use – overarching narratives to describe the climate change “mega-story”.  Alarming stories of more famine, sea level rises, floods, hurricanes and droughts are easy ones to grab attention. This “disaster” story is by far the most common one in the coverage of climate change, as shown by several studies. At times, this “alarming” story morphs into the more “alarmist” language of catastrophe, calamity or doom. A new study I carried out for the Reuters Institute for the Study of Journalism shows that in the television reporting of the three recent blockbuster reports by the Intergovernmental Panel on Climate Change (IPCC), the disaster narrative was still by far the most common in the six countries it examined. The study examined the coverage on television, which is still in most countries the most used and trusted source of information for news in general, and for news about science. For instance, just one evening news bulletin often enjoys far more audience that the circulation of a national newspaper. The channels monitored in the study have a combined audience of about 50m viewers. It is not surprising that disaster should be more common than the other “frames” or narratives the study surveyed (uncertainty, opportunity and explicit risk). The IPCC reports were full of the adverse impacts from runaway greenhouse gas emissions, which make for compelling news. But it is surprising that the risk narrative hardly got a look in. In the press release and communication efforts around the second report released early this year, the IPCC went to considerable lengths to portray the climate change challenge as one of “risk management”. The co-chair of the working group responsible for the report, climate scientist Chris Field, spoke repeatedly and eloquently about the need, in the face of uncertainty, to weigh up the risks of possible outcomes. Part of the explanation is that television news needs pictures to tell stories and is better at telling stories than dealing with issues. The disaster frame lends itself to a strong narrative, whereas risk is more of an issue than a story. Why is this important?  Doom-laden depictions of climate change are ubiquitous in the media. But results from focus groups show that such disaster narratives are good at attracting attention, but not so good at motivating genuine personal engagement or behaviour change. Some scientists are really tackling this problem head on. An inquiry this year on communicating climate science led by Professor Chris Rapley at the UCL spelled it out: strong appeals to fear are unlikely to avert danger and can generate defensive avoidance (“this is too scary to think about”) or worries of being pressured or constricted (“they are trying to manipulate me”). As the report says, initial states of worry and anxiety can change over time to numbness, desensitisation and disengagement from the issue altogether. But nor should one jump into overdoing positive narratives about climate change as the antidote to all the disaster narratives.  A balance needs to be struck. Last week’s New Climate Economy report was a good example of giving a sober assessment of the challenges (rapid urbanisation, growing populations, resource constraints, climate change), accompanied by a positive story that cutting greenhouse emissions can be low cost and improve people’s lives. Many politicians and climate reports now talk about risk, which works for some audiences – particularly in the business sector – who deal every day with assessing investment, insurance and other types of uncertain outcomes. They were clearly the target audience for a groundbreaking report out in June this year called Risky Business, which used a risk management perspective to lay out the threat to agriculture, energy and coastal real estate in the US. One of the authors was the former Republican treasury secretary Hank Paulson. As he explained: “taking a cautiously conservative stance – that is, waiting for more information before acting – is actually taking a very radical risk”. As the Columbia Journalism Review noted, the report helped to shift the nature of the climate change story in the media. It became a business story on the business pages, reaching a new and powerful audience. Now that’s a story."
"The UN Climate Summit in New York brought together politics, business and civil society to build up momentum for major climate change talks in Paris next year. After the disappointments of the acrimonious Copenhagen meeting in 2009, there is now a chance for a global agreement on action against climate change. Low carbon development pledges and substantial financing of the Green Climate Fund are one side of the coin. But climate justice is also about social justice, and leaders must address the demands and respect the needs of people most vulnerable and already suffering from the impacts of climate change. The world’s poorest people are the worst affected by climate change and these groups were certainly represented in New York, but will they be listened to? If it is to have a lasting impact, the Paris meeting must successfully integrate a “top-down” global agreement to restrict global warming to 2°C, together with a “bottom-up” strategy whereby countries set their own contributions to reduced emissions. However this latter strategy must go beyond emissions and do more to ensure that action on climate change listens to the grassroots and prioritises the world’s poorest and most vulnerable groups. The summit looked promising for proponents of an inclusive, “bottom-up” strategy. Its key themes included forests, agriculture and resilience to climate change, all of which have a sizable body of evidence to show that placing people directly affected at centre stage is a critical opportunity for success. There was also a thematic session on Voices from the Climate Front Lines which gave a platform to children, women and indigenous people suffering the effects of climate change. However the outcomes don’t match the hype. There were specific examples of progress: the president of Peru outlined a strategy for reducing emissions from deforestation and degradation that he said would put the country on a path to sustainability by reaching out to indigenous groups and securing a vast area of land under indigenous rights.  He won public support from both Germany and Norway, and France also pledged funds to help the poor cope with climate change, but the global commitment to social justice called for by the Rights and Resources Initiative and the World Resources Institute was largely missing.   The anticipated, voluntary New York declaration on forests was marred by Brazil’s refusal to sign up, and the seven action statements released following the summit directly address local people’s rights and roles just twice (and one of these requires action from indigenous civil society groups rather than national or international governments). Similarly, the Global Agricultural Alliance aims to secure “climate smart” agriculture for 500m farmers by 2030. However it was left to civil society organisations to release a joint statement prioritising making food systems socially just and protecting the poorest and most vulnerable in these efforts. The recently published New Climate Economy report outlines a vision for “better growth, better climate”, a win-win scenario that ties investment and innovation to poverty and hunger reduction. But while investment and innovation may be able to secure the 70% more calories they estimate humans will collectively require by 2050, it is unclear how it will address the political aspects of access to those calories, and whether such strategies can support the livelihoods and resilience of the poorest farmers. Without putting social justice at the core of our thinking on climate action, we risk harming the most vulnerable groups of people. For example environmental concerns have been used by big corporations and national governments to justify claiming land for themselves, a process known as green grabbing that threatens the well-being of groups dependent on natural resources. Perhaps we can eventually find a way to put people on an equal footing with the green economy but, judging from developments in New York, we don’t seem to be there yet. Paris must be about much more than the pledges on emissions and the green economy that have dominated the headlines since the UN summit. It appears New York was yet another example of a big international climate forum recognising the importance of social justice (itself a big achievement) without actually clarifying how it will be built into objectives or commitments. People will remain on the agenda, but not quite centre stage."
"The polar ice caps are melting six times faster than in the 1990s, according to the most complete analysis to date. The ice loss from Greenland and Antarctica is tracking the worst-case climate warming scenario set out by the Intergovernmental Panel on Climate Change (IPCC), scientists say. Without rapid cuts to carbon emissions the analysis indicates there could be a rise in sea levels that would leave 400 million people exposed to coastal flooding each year by the end of the century. Rising sea levels are the one of the most damaging long-term impacts of the climate crisis, and the contribution of Greenland and Antarctica is accelerating. The new analysis updates and combines recent studies of the ice masses and predicts that 2019 will prove to have been a record-breaking year when the most recent data is processed. The previous peak year for Greenland and Antarctic ice melting was 2010, after a natural climate cycle led to a run of very hot summers. But the Arctic heatwave of 2019 means it is nearly certain that more ice was lost last year. The average annual loss of ice from Greenland and Antarctica in the 2010s was 475bn tonnes – six times greater than the 81bn tonnes a year lost in the 1990s. In total the two ice caps lost 6.4tn tonnes of ice from 1992 to 2017, with melting in Greenland responsible for 60% of that figure. The IPCC’s most recent mid-range prediction for global sea level rise in 2100 is 53cm. But the new analysis suggests that if current trends continue the oceans will rise by an additional 17cm. “Every centimetre of sea level rise leads to coastal flooding and coastal erosion, disrupting people’s lives around the planet,” said Prof Andrew Shepherd, of the University of Leeds. He said the extra 17cm would mean the number of exposed to coastal flooding each year rising from 360 million to 400 million. “These are not unlikely events with small impacts,” he said. “They are already under way and will be devastating for coastal communities.” Erik Ivins, of Nasa’s Jet Propulsion Laboratory, in California, who led the assessment with Shepherd, said the lost ice was a clear sign of global heating. “The satellite measurements provide prima facie, rather irrefutable, evidence,” he said. Almost all the ice loss from Antarctica and half of that from Greenland arose from warming oceans melting the glaciers that flow from the ice caps. This causes glacial flow to speed up, dumping more icebergs into the ocean. The remainder of Greenland’s ice losses are caused by hotter air temperatures that melt the surface of the ice sheet. The combined analysis was carried out by a team of 89 scientists from 50 international organisations, who combined the findings of 26 ice surveys. It included data from 11 satellite missions that tracked the ice sheets’ changing volume, speed of flow and mass. About a third of the total sea level rise now comes from Greenland and Antarctic ice loss. Just under half comes from the thermal expansion of warming ocean water and a fifth from other smaller glaciers. But the latter sources are not accelerating, unlike in Greenland and Antarctica. Shepherd said the ice caps had been slow to respond to human-caused global heating. Greenland and especially Antarctica were quite stable at the start of the 1990s despite decades of a warming climate. Shepherd said it took about 30 years for the ice caps to react. Now that they had a further 30 years of melting was inevitable, even if emissions were halted today. Nonetheless, he said, urgent carbon emissions cuts were vital. “We can offset some of that [sea level rise] if we stop heating the planet.” The IPCC is in the process of producing a new global climate report and its lead author, Prof Guðfinna Aðalgeirsdóttir, of the University of Iceland, said: “The reconciled estimate of Greenland and Antarctic ice loss is timely.” She said she also saw increased losses from Iceland’s ice caps last year. “Summer 2019 was very warm in this region.”"
"Every now and then, the idea of powering Europe using the vast solar resources of the Sahara Desert comes up. Were this to actually happen, we may witness the rise of new energy superpowers in Northern Africa. But a look at the economic and political energy system suggests what’s more likely is the oil-rich countries of the Arabian (or Persian) Gulf will continue to dominate energy trade even in the post-fossil era. Renewable energy, of course, is very location dependent – the sunnier a place is, the more energy you get out of photovoltaic panels. Over the course of a year, southern Algeria, for example, gets more than twice as much solar energy as southern England. The graph below, which I put together as part of my PhD, shows that some of the best solar resources in the world are indeed found in Algeria, Libya, Egypt, Niger, Chad and Sudan.  So, one could build large Saharan solar farms and then transmit the power back to densely populated areas of Europe. Such a project would need to overcome various technical challenges, but we can say that in theory it is possible, even if not practical. Yet plans to actually set up mass Saharan solar have floundered. The most notable project, Desertec, was fairly active until the mid 2010s, when a collapse in the price of oil and natural gas made its business case more difficult. At that time, the major technology considered was concentrated solar power, where you use the heat from the sun to run a steam turbine. Energy can be stored as heat overnight, therefore enabling uninterrupted energy supply and making it preferred to then expensive batteries.  Since then, however, the cost of both solar panels and battery storage have dropped drastically. But, while conditions might look favourable for Saharan solar, it is unlikely that new solar energy kingpins will arise in North Africa. Instead, we should look one desert further to the East – the Rub al Khali on the Arabian peninsula, the home of the reigning energy powers. The economies of the United Arab Emirates, Saudi Arabia, Qatar and the other Gulf nations are built around energy exports. And as climate change imposes pressure on the extraction of fossil fuels, these countries will have to look for alternative energy (and income) sources in order to keep their economies afloat. The International Renewable Energy Agency set up its headquarters in Abu Dhabi, and the region has no shortage of ambitious solar projects promising extremely cheap electricity. However only a small amount of capacity has actually been deployed so far. Low oil revenues have not helped with the megaprojects. Countries in the Sahara also have little history of trading fossil fuels, outside of Libya and Algeria, while things are rather different for the petro-states of the Gulf. And this matters because, in the energy business, worries over longer-term security of supply mean countries tend to trade with the same partners.  This would be the Achilles’ heel of a Northern African energy project: the connections to Europe would likely be the continent’s single most important critical infrastructure and, considering the stability of the region, it is unlikely that European countries would take on such a risk.  Which brings us to an alternative way to transmit energy: hydrogen. A process called electrolysis can use renewable electricity to split water into hydrogen and oxygen, and the resulting hydrogen can store lots of energy. Soon it will become feasible to move energy around the world in this form, using shipping infrastructure similar to that already in use today for liquefied natural gas. Sure, there are disadvantages compared to batteries. It would mean introducing two more conversion stages and thus reduced efficiency (30% roundtrip efficiency compared to 80% for batteries), but it would overcome the distance barrier. And perhaps just as importantly: shipping energy by hydrogen would mean no significant change to the existing maritime trade infrastructure, which will hand an advantage to established energy exporters.  If this means the Sahara is unlikely to develop renewable energy superpowers, then perhaps this is for the better. With the booming populations of Sub-Saharan Africa in dire need of electrification, clean solar power might be better used to alleviate the energy crisis in somewhere like Nigeria rather than sent to Europe. While these countries may eventually be able to shake off any solar resource curse, in the short term, exports like these could just look like yet another European attempt to extract natural resources from Africans. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"An unusually warm winter has caused bears to stir early from hibernation in several countries, raising concerns of an increased number of conflicts with humans. There have been multiple sightings of bears emerging from hibernation in February and early March in Russia, Finland and the US, a situation apparently triggered by the mild winter experienced in many countries.  This winter was the warmest ever recorded in Europe “by far”, according to scientists, with the US just experiencing its hottest December and January on record. Moscow Zoo has been preparing to deal with the emergence of two Himalayan bears a month early, while a grizzly bear sighting was reported on 3 March in Banff national park in Canada, the earliest such sighting in a decade. Bears are also on the move in theYellowstone national park in the US, with a grizzly spotted prowling around the park’s famed Grand Prismatic Spring on 7 March. Park officials said that visitors should keep at least 100ft away from the bears, not to run away and keep bear spray to hand. It’s not just bears that have been waking early from their hibernation slumber – there are also reports of an itinerant groundhog in Maine. Although there is sparse data on hibernation trends, experts have warned that the climate crisis could be spurring a harmful mismatch in seasons for animals, especially those who hibernate through the cold winter months when food is scarce. Among bears males are usually the first to emerge, in March or April, followed by females and then females with cubs. If they emerge in unusually warm winter weather, they may find there is little to eat. “From my experience we are hearing more reports of bears out in late February and early March,” said Chris Servheen, the former grizzly bear recovery coordinator at the US Fish and Wildlife Service. Servheen said he had heard about black bears coming from hibernation already in the Rocky Mountains as their snow dens melt and they are forced to leave their soggy homes. Even some grizzly bears at high elevations are departing their dens too. “We aren’t sure why they are coming out earlier but if there are more sunny, warm days they sense that, they see the conditions are good and they go out,” he said. “The problem is they can’t stay in but there’s nothing for them to eat. They are burning up energy moving around but the plants haven’t started to grow yet, I’d expect it’s not a good thing for them.” This mismatch raises the possibility that hungry bears will be involved in confrontations with humans as they desperately search for food. Towns in Canada and Russia have been the stage for tangles between people and bears as the ursine visitors ransack bins and gardens for food. “If we see this as a continuing thing with climate change we will probably see more conflicts because there’s not much food for the bears,” Servheen said. “If bears come out early they will potentially seek food around people, such as in garbage, bird feeders and crops. The potential for conflict is certainly higher as they come out earlier.”"
"

Policymakers shouldn’t waste time worrying about a falling dollar. As Milton Friedman wisely advised, the exchange rate of our currency should be set by markets, not by fallible and fidgety politicians.



President Bush sounded the right note in his interview on the Fox Business Channel on Tuesday when he said, “We have a strong dollar policy, and it’s important for the world to know that. We also believe it’s important for the market to set the value of the dollar, relative to other currencies.”



A weaker U.S. dollar is a two‐​edged sword for Americans. The declining dollar has boosted U.S. exports to record levels, partially offsetting the downward tug on the economy from turbulence in the housing and mortgage markets. It’s also moderating the U.S. trade deficit in goods and services, which is on track to end 2007 almost 10% smaller than the 2006 deficit.



On the downside, the slide in the dollar has fueled higher import prices, most spectacularly for oil, imposing costs on U.S. consumers and producers alike. It’s no coincidence that a sharply depreciating dollar has preceded every major spike in oil prices since the early 1970s.



The right response from Washington should be to let the dollar find its own value in global markets while avoiding policy mistakes that undermine its worth. Spiraling inflation, runaway government spending, hostility to foreign investment and the specter of protectionism would scare away foreign investors, causing the dollar to falter further and maybe even crash.





A weaker U.S. dollar is a two‐​edged sword for Americans.



A freely floating currency allows our economy to adjust to shifting fundamentals. Any attempt to intervene would soon be overwhelmed by the $2 trillion exchanged daily on global currency markets. Efforts to artificially boost or depreciate a currency only postpone needed adjustments, as South Korea, Thailand, Brazil and other countries painfully discovered in the late 1990s.



Instead of manipulating the currency, policymakers should keep their eyes on the sound fundamentals that ultimately determine its value. The most important are low inflation, an open and flexible economy, fiscal restraint, and an attractive investment climate, including reasonable regulations and low tax rates. As long as the U.S. government pursues such policies, the world will want our dollars.
"
"

The rise of anti–Americanism in Europe is a danger to both American and European pocketbooks, and our collective liberty. Here is why: Europe and America are each other’s biggest trading and investment partners, and anything that damages that relationship is harmful to everyone involved.



This past year more than one trillion dollars flowed between the U.S. and the EU. The EU now accounts for 21 percent of U.S. merchandise exports and 19 percent of U.S. merchandise imports, and about 34 percent of U.S. services exports and 37 percent of U.S. services imports.



The U.S. is not only the largest recipient of foreign direct investment, but far and away the world’s largest investor elsewhere. Of the more than two trillion dollars the U.S. has invested directly abroad, a little more than half ($1.1 trillion) is invested in Europe. Europeans account for 70 percent ($1.2 trillion) of the direct investment in the U.S.



The bottom line is that the U.S. and Europe are economically joined at the hip, and any actions which damage trade and investment between these two economic giants hurt everyone. The U.S. and EU have a combined population of about 650 million people, and their combined GDP equals 57 percent of the world’s total.



The U.S. has also provided a security umbrella over Europe for almost 65 years. Europe has adopted much of American culture — from movies and music to fast food and dress, and increasingly the English language (the American version). Even France has about a thousand McDonald’s restaurants. Given the growing economic and cultural ties, why the rise in anti–Americanism (despite the hopeful signs coming from Sarkozy’s election)?



Some Europeans will argue that it is only anti–Bush–ism — in that they dislike the Bush foreign policy and his personal style. And it is generally true that Europeans dislike Bush more than they dislike Americans. But there is more to it. Europe by and large was pro–American when Europe was growing faster than the U.S., and the U.S. was protecting them from the Soviet menace. But over the last two decades, the major European economies have grown more slowly than the U.S., and the Soviet threat has disappeared.



The increasingly globalized world where the U.S. appears to be more aggressive and economically competitive causes fear and resentment. The U.S. success and dominance highlights the weaknesses of the European welfare state. Only the U.S. morass in Iraq and the relatively low level of the dollar (which most likely will soon be reversed) has given the Europeans reasons to smile.



If the anti–Americanism were confined to verbal belly aching, it would not be much of a problem. However, it is now leading to destructive policies. The Europeans have been more reluctant to further liberalize global trade than the Americans and, in fact, destructive protectionist forces on both sides of the Atlantic are gathering strength.



Some of the European nations have been concerned about capital out–flows (brought on by their own excessive taxation and regulation), and demanded that other countries help them enforce their tax laws (e.g., the EU Tax Saving Directive). Recently, some of the new Democratic leaders in the U.S. Congress have proposed equally destructive proposals to prevent U.S. monies from flowing into lower tax jurisdictions — some of which are in Europe (e.g., Senators Dorgan’s and Levin’s bills to penalize certain capital outflows).



When members of Congress and others whine about U.S. companies moving abroad, they have no one to blame but themselves, because they have made it uncompetitive for some companies to come to or stay in the U.S. The U.S. used to have one of the lowest corporate tax rates in the world but now it is at the top of the list. The EU has an average maximum corporate income tax rate of 25 percent (with some EU members as low as 10 percent) versus 40 percent in the U.S. Even France and Germany now have lower corporate tax rates than the U.S. The Europeans correctly rely more on consumption taxes (the VAT), which are rebated on exports. There is no rebate for corporate income taxes, putting U.S. firms at a disadvantage.



The EU has brought anti–trust actions against some U.S. multinationals, not because these companies’ activities hurt EU consumers, but because they hurt their EU competitors. The EU has also challenged the protection of intellectual property held by some U.S. companies. The EU has attacked the U.S. for not doing enough about climate change, even though EU members have not met the goals of agreements they signed, such as the Kyoto Protocol.



Economic warfare between the EU and U.S. can be averted if officials on both sides will act more responsibly. Many tax disputes would disappear if the U.S. would move to a territorial tax system (like most European nations have) and to a consumption–based tax system, such as a national sales tax, rather than an income tax — which would have the significant side benefit of increasing economic growth in the U.S. The EU needs to move more aggressively towards trade liberalization and deregulation — which would greatly increase economic growth in the EU. The solution to much, but not all, of the tension between the EU and U.S. is to create more economic opportunity on both sides of the Atlantic — but particularly in Europe.
"
"**Kent and Medway will face the toughest coronavirus curbs when the national lockdown ends, it has been announced.**
The areas will be placed under tier three from 2 December.
Swale and Thanet have the two highest rates of Covid-19 infection in England. Medway has risen to fourth and Gravesham is in the top 20.
There will be a ban on households mixing, except in limited circumstances such as parks, and people will be urged to avoid travel outside their area.
Pubs and restaurants will only be able to offer delivery or takeaways. Indoor entertainment venues will also be shut.
The government said it would review the tier allocations on 16 December.
It explained that infections across Kent and Medway were high, and continuing to rise ""with large increases in case rates in almost all areas in the last seven days"".
It said some of the highest case rates in the country were currently in Kent, with rising cases in people aged over 60 a particular concern.
Swale continues to have the highest rate in England, with 799 new cases recorded in the seven days to 22 November - the equivalent of 532.4 cases per 100,000 people, down from 637.7 in the previous seven days.
Thanet has the second highest rate, down from 522.8 to 478.4, with 679 new cases.
However, other parts of Kent, including Tunbridge Wells and Ashford, have been below the national average.
**by Lauren Moss, BBC South East Political Editor**
Placing more than 1.5 million people in Kent and Medway into the toughest level of restrictions will be greeted with dismay by some, but perhaps it shouldn't come as a huge surprise.
The rate of coronavirus infection varies pretty widely across the area but figures show it is climbing up in Folkestone and Hythe, Dover, Gravesham, Maidstone, and Medway, although it has now started to slow down in Thanet and Swale.
Both authorities will be hoping mass rapid testing that has been promised to all areas in tier three will play a part in bringing down the spread of infection, much like it's believed to have done in Liverpool.
Everyone will be keeping a close eye on those numbers when the restrictions are reviewed on the 16 December.
Tory MPs in Kent had lobbied the Prime Minister to not impose county-wide restrictions due to the variations in case numbers.
The group said: ""We must allow businesses to prosper and not be held back by restrictions not suitable for their area.""
Sir Roger Gale, the Conservative MP for North Thanet, said while the tier restrictions would not be a shock to his constituents, he nevertheless had backed the call for a district approach.
""The pandemic doesn't understand county boundaries. There is no logic to this at all,"" he said.
Roger Truelove, leader of Swale Borough Council, said he agreed with the tier three restrictions.
""I hope that that's an incentive for local people to comply as much as possible with the guidance so we get our numbers down.
""We want to push them further down,"" he said.
Leader of Medway Council, Alan Jarrett, said the restrictions were ""absolutely necessary"".
""I appreciate we all want to get back to doing the things we love and therefore each and every one of us must act now and join the fight against Covid-19,"" he said."
"Despite the significant benefits they have and will continue to provide, the traditional approaches of protected areas and in situ conservation management alone cannot shield vulnerable species from the growing threats they face. Habitat loss and fragmentation, over-exploitation, invasive species, pollution and climate change are all problems that have grown as the world’s human population increases and expands.  This is why we have to consider more risky and intensive conservation options such as translocations: the intentional movement and release of endangered creatures for conservation benefit. There is a spectrum of conservation translocations. Reinforcing existing threatened populations by “topping up” with individuals taken from other areas where they thrive increases numbers and genetic diversity, which improves their ability to withstand change and disease. Reintroductions are attempts to restore populations after they have gone locally extinct.  More risky and uncertain is the controversial technique of conservation introductions. The two techniques are assisted colonisation, in which species are moved from their native range where they are threatened to somewhere they have never naturally inhabited in order to preserve them, and ecological replacements, where a suitable substitute species is introduced to perform the ecological role of one that has become extinct. Understandably, given the history of terrible consequences from ill-planned species introductions – perhaps most obvious in Australasia – these are seen as extreme methods and not actions to be undertaken lightly. The key challenge is therefore to understand and manage the risks involved. It’s also necessary to have an exit strategy – to be sure you can reverse the releases if things do not go as planned. For threatened species at low-population densities released into confined areas of habitat this would be feasible. There are already great gains being made using conservation translocations of all kinds. Reintroductions are restoring whole suites of species – mostly mammals and birds, but increasingly plants, reptiles, amphibians, fish and invertebrates are being released into suitable areas. For example some 55 species of birds have been translocated in more than 1,000 projects, and populations of reptiles and amphibians are now also being restored in New Zealand. Assisted colonisation is also used in Australia and New Zealand, where native species have been moved beyond their normal range in order to protect them from the threats posed by exotic mammals. And on islands in the Indian Ocean giant tortoises have been introduced as ecological replacements for extinct species, to restore the seed dispersal and vegetation grazing functions that had been lost. Early conservation translocations have had low success rates, but as techniques are developed and refined, results are getting better and we are seeing an exponential increase in the number of translocation projects worldwide. There is however still a bias towards the more charismatic species of birds and mammals, but this is slowly changing. But there is a major challenge facing conservation translocations. If we are seeking to restore wildlife populations we must ask the question: restore to what? What is the target state, the ideal we are seeking? In the New World, perhaps in the past the answer would have been to restore the environmental balance to how things were before (European) human settlement. But there is a growing awareness that pre-European landscapes were not the pristine wilderness of our imagination. It is unrealistic to seek such ideals in the anthropocene, our modern human-dominated world. We need to move away from the idea of having free-ranging wild species roaming over large areas of wilderness untouched by human influences. We must understand now that virtually every ecosystem on earth has been modified by humans, and some of those modifications go back to prehistory. An obvious example is the extinction of megafauna species or massive deforestation across Europe after the first arrival of humans in the Pleistocene period, many tens of thousands of years ago. We need instead to think about how we can restore “wildness” rather than the unobtainable “wilderness”. By that I mean finding a place for wildlife to persist in areas alongside humans, both for their sake and ours. Too quickly we can lose a sense of how much we have lost, with each generation handed a natural world to grow up in that is progressively more impoverished than the last. Species restorations give people a chance to experience, appreciate and learn to cherish their natural heritage."
"
Guest Post by Willis Eschenbach
In the US House of Representatives, there is something curiously yclept the “Select Committee on Energy Independence and Global Warming” despite the lack of connection between the energy independence and warming. They have a very professionally done website, filled with some of the most outrageous misrepresentations imaginable. It is designed to promote the “Waxman-Markey” cap and trade carbon tax bill by means of the historically tried and tested “Big Lie” method, viz:
All this was inspired by the principle–which is quite true within itself–that in the big lie there is always a certain force of credibility; because the broad masses of a nation are always more easily corrupted in the deeper strata of their emotional nature than consciously or voluntarily; and thus in the primitive simplicity of their minds they more readily fall victims to the big lie than the small lie, since they themselves often tell small lies in little matters but would be ashamed to resort to large-scale falsehoods.
It would never come into their heads to fabricate colossal untruths, and they would not believe that others could have the impudence to distort the truth so infamously. Even though the facts which prove this to be so may be brought clearly to their minds, they will still doubt and waver and will continue to think that there may be some other explanation. For the grossly impudent lie always leaves traces behind it, even after it has been nailed down, a fact which is known to all expert liars in this world and to all who conspire together in the art of lying.
I’m going to take the website’s misrepresentations one at a time, as time permits. The first one is from a page entitled “Impact Zone – U.S. New England“, which contains this lovely photograph designed to tug at the heartstrings:

Figure 1. Photo of maple trees in New England, professionally chosen for maximum emotional impact.
The accompanying text says (emphasis mine):

Global Warming in New England: Slushier Slopes and Faded Foliage
Life and economic activity across New England is marked by the seasons – maple sugaring in the spring, trips to the beach in the summer, the riot of color of the fall foliage, and the swoosh of skis and skates in the winter. This familiar cycle is already changing in noticeable ways.
Changing seasons
Since the 1970’s average winter temperatures have risen more than 4 degrees Fahrenheit in the Northeast region. If the current rate of heat-trapping emissions continues, by 2070 summers in Boston will feel like those of South Carolina today. By the end of the century, temperatures could rise up to 14 degrees Fahrenheit in the region. Cities across New England, which historically experience only one or two days per year above 100 degrees each summer, could average 20 such days per summer, while more southern cities such as Hartford could average nearly 30 days.
The character of the seasons will change significantly. Spring could arrive three weeks earlier, with summer lengthening by about three weeks, autumn becoming warmer and drier, and winter becoming shorter and milder.
So what’s wrong with that?
Well, once we note the conjectures (marked by the weasel words in bold), we see that most of it is nothing but unfounded, un-cited alarmist claims about imaginary future calamities. They have presented only one claim of fact – that winter temperatures in the Northeast Region have risen by more than 4°F.
Now, the USHCN has the data for all of the states, as well as by region. The Northeast Region is the data that starts with “101” in the first column. Figure 2 shows the temperature record for the four seasons, as well as the annual average temperature, for the Northeast Region:

Figure 2. Annual and seasonal temperatures, US Northeast Region. Photo shows winter surf in New England. PHOTO SOURCE.
As you can see, there has not been much of a change over the last 115 years in any of the seasons. The trend for all of the datasets is not significantly different from zero (winter p=0.06, spring p=0.15, summer p=0.34, fall p=0.68, annual p=0.06).
And more to the point, the winter trend over the last 40 years (1970-2009) is only 2.7°F, not the “more than 4 degrees Fahrenheit” claimed by their website. Such a swing is not surprising in a dataset such as the winter temperatures, which shows a 10 °F swing in one year, from 2001 to 2002.
But wait … there’s more. Because of the short length (40 years) and high variability of the 1970-2009 winter temperatures, the 1970-2009 trend is not significantly different from zero either (p = 0.12, a ways from significant).
SUMMARY: Their web page contains two misrepresentations of fact about US Northeast winters, two implied misrepresentations, and a big lie:
Misrepresentation of fact 1: the 1970-2009 winter temperatures have not “risen more than 4 degrees Fahrenheit”, they have risen 2.7 degrees Fahrenheit. There is no rise of more than 4 °F in the winter temperature record, no matter where you start.
Misrepresentation of fact 2: the 1970-2009 winter trend is not statistically significant, so we cannot reject the null hypothesis that there is no trend at all, much less a claimed 4 °F trend.
Implied misrepresentation 1: The US Northeast winters are not warming. Over the full period of record (1895-2009), there is no statistically significant trend in the winter record.
Implied misrepresentation 2: The seasonal temperatures in the US Northeast are not warming. Over the full period of record (1895-2009), there is no statistically significant trend in the overall record for any season.
THE BIG LIE: When you look at the full record for the US Northeast, there is no statistically significant trend anywhere. Neither spring, summer, winter, fall, nor the full annual average temperatures have any statistically significant trend for the period of the study, 1895-2009. And remember, this is measured by ground stations that contain spurious UHI warming, and there still is no warming trend.
The big lie is that the US Northeast is warming. The best records that we have say that it is not.
I will examine more of the malarkey from their web site as time permits, although the statements are so obviously untrue that it’s hardly sporting. It’s like shooting fish, not in a barrel, but in a bucket …
w.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ae0a327',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Vortice in a teacup, from the worldisround.com - click
Via press release: (Santa Barbara, Calif.) –– Scientists can use cylinders as small as  teapots to study the mechanisms involved in powerful hurricanes and  other swirling natural phenomena.
The earth’s atmosphere and its molten outer core have one thing in  common: Both contain powerful, swirling vortices. While in the  atmosphere these vortices include cyclones and hurricanes, in the outer  core they are essential for the formation of the earth’s magnetic field.  These phenomena in earth’s interior and its atmosphere are both  governed by the same natural mechanisms, according to experimental  physicists at UC Santa Barbara working with a computation team in the  Netherlands.

Using laboratory cylinders from 4 to 40 inches high, the team  studied these underlying physical processes. The results are published  in the journal Physical Review Letters.
“To study the atmosphere would be too complicated for our purposes,”  said Guenter Ahlers, senior author and professor of physics at UCSB.  “Physicists like to take one ingredient of a complicated situation and  study it in a quantitative way under ideal conditions.” The research  team, including first author Stephan Weiss, a postdoctoral fellow at  UCSB, filled the laboratory cylinders with water, and heated the water  from below and cooled it from above.
Due to that temperature difference, the warm fluid at the bottom  plate rose, while the cold fluid at the top sank –– a phenomenon known  as convection. In addition, the whole cylinder was rotated around its  own axis; this had a strong influence on how the water flowed inside the  cylinder. Rotation, such as the earth’s rotation, is a key factor in  the development of vortices. The temperature difference between the top  and the bottom of the cylinder is another causal factor since it drives  the flow in the first place. Finally, the relation of the diameter of  the cylinder to the height is also significant.
Ahlers and his team discovered a new unexpected phenomenon that was  not known before for turbulent flows like this. When spinning the  container slowly enough, no vortices occurred at first. But, at a  certain critical rotation speed, the flow structure changed. Vortices  then occurred inside the flow and the warm fluid was transported faster  from the bottom to the top than at lower rotation rates. “It is  remarkable that this point exists,” Ahlers said. “You must rotate at a  certain speed to get to this critical point.”
The rotation rate at which the first vortices appeared depended on  the relation between the diameter and the height of the cylinder. For  wide cylinders that are not very high, this transition appeared at  relatively low rotation rates, while for narrow but high cylinders, the  cylinder had to rotate relatively fast in order to produce vortices.  Further, it was found that vortices do not exist very close to the  sidewall of the cylinder. Instead they always stayed a certain distance  away from it. That characteristic distance is called the “healing  length.”
“You can’t go from nothing to something quickly,” said Ahlers. “The  change must occur over a characteristic length. We found that when you  slow down to a smaller rotation rate, the healing length increases.”
The authors showed that their experimental findings are in keeping  with a theoretical model similar to the one first developed by Vitaly  Lazarevich Ginzburg and Lev Landau in the theory of superconductivity.  That same model is also applicable to other areas of physics such as  pattern formation and critical phenomena. The model explains that the  very existence of the transition from the state without vortices to the  one with them is due to the presence of the sidewalls of the container.  For a sample so wide (relative to its height) that the walls become  unimportant, the vortices would start to form even for very slow  rotation. The model makes it possible to describe the experimental  discoveries, reported in the article, in precise mathematical language.
###
The other UCSB author is postdoctoral fellow Jin-Qiang Zhong.  Additional authors are Richard J. A. M. Stevens and Detlef Lohse from  the University of Twente and Herman J. H. Clercx from Eindhoven  University of Science and Technology, both in the Netherlands.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e86e1a064',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
The months of flatlining at the Chicago Climate Exchange (CCX) should be a hint to the rest of the world that carbon trading is dead. Time to take it off life support. Even at 10 cents a ton, nobody wants it. At it’s peak in July 2008, it traded for $7.50 per ton of CO2.

Chicago Climate Exchange close on June 30th, 2010 - click for source
See who is on the CCX advisory board here
From ACM:
Token Gesture Alert as the government of New Zealand, unable to think  straight thanks to years of green environmental propaganda, brings in  its emissions trading scheme. 
New Zealand emits about 0.1% of global  CO2. So even if New Zealand reduced its emissions to zero overnight,  AND it were demonstrated that the climate sensitivity is large enough  to notice (which it hasn’t been), it would make not the slightest  bit of difference to the climate.
Not only that, but I hardly think  that China and India are going to look at New Zealand, and, wracked  with guilt and remorse by the plucky little country’s valiant efforts to  save the planet, stop their coal fired economies in their tracks. Not  on your life. China and India are far too busy building their prosperity  and lifting their populations out of poverty. It’s only wealthy  countries can afford the luxury of pointless environmental gestures like  this.
So the only result will be higher prices for poor Kiwis. Everything  will cost more: electricity, petrol, groceries, consumer goods –  everything – since everything (virtually) requires energy for its  production or transportation. As the ABC reports:
New Zealanders are bracing for higher electricity  and fuel prices with the introduction of an emissions trading scheme  (ETS).
From today New Zealanders will pay around three cents a litre more for fuel.
Electricity bills are set to increase by up to 5 per cent as companies pass on the costs of buying carbon credits to consumers.
Environment minister Dr Nick Smith says New Zealand had to act  because its greenhouse gas emissions have increased by 25 per  cent over the past 20 years. [So from absolutely tiny, to  slightly less absolutely tiny]
“It’s actually about New Zealand starting the path, starting  the change to a less carbon intensive economy,” he said. (source)
Good luck with that. Just watch your industries move offshore, and  your economy decline for no purpose whatsoever.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a54b0af',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Nearly 1.5m students around the world walked out of school on March 15 2019 to protest about the failure of the world’s governments to tackle climate change. The young climate strikers are forcing climate change onto the news agenda but researchers have warned that without a way to mobilise their passion in the long-term, the momentum they’ve generated for climate action could be lost. In this first issue of Imagine, we asked academics how the strikes can translate into long-term impact. One researcher proposes directly channelling the energy of young people into climate action with a national service for the environment. Others tell us how youth enthusiasm can play an integral part in changing climate policy around the world – and what it all means for tackling this huge issue. What is Imagine? Imagine is a newsletter from The Conversation that presents a vision of a world acting on climate change. Drawing on the collective wisdom of academics in fields from anthropology and zoology to technology and psychology, it investigates the many ways life on Earth could be made fairer and more fulfilling by taking radical action on climate change. You are currently reading the web version of the first issue. Here’s how this issue appears when sent to your inbox. To get new issues delivered straight to your inbox, subscribe now.  1. Global temperatures are on the rise. 2. The US bears an “extraordinary responsibility to respond to the climate crisis”, says D.T. Cochrane, Lecturer in Business and Society at York University, Canada. The country produces an “excessive amount of emissions” and has an unequal share of resources. 3. Business as usual is not an option. Michelle Bloor, Principal Lecturer and Environmental Programme Manager at University of Portsmouth, argues that a volunteer force of conservationists could offer experience and training to young people and ensure there are eager applicants for the vital work of helping the world’s species and habitats most threatened by climate change. Young people could get on the act straightaway, from replanting mangrove swamps in Vietnam and helping reintroduce beavers in Scotland to measuring coastal pollution in Senegal. Bloor groups the work a national service for the environment could cover into four categories: Data collection – by surveying wildlife abundance or measuring water quality in lakes and rivers, volunteers could help scientists understand how ecosystems are changing. Green construction – restoring wooded habitat could absorb carbon and create corridors which connect pockets of wildlife in fragmented habitats. Large-scale construction projects could involve volunteers working on habitat highways – green corridors which help wildlife cross road networks. Species reintroduction – helping ecosystem engineers, such as beavers, return could help the process of expanding natural habitats. These animal recruits could create new dams and lakes, which provide new opportunities for more species to thrive. Reforestation – humans have cut down three trillion trees since the dawn of agriculture – around half the trees on Earth. A mass reforestation effort would need plenty of volunteers worldwide, something a youth volunteer force could supply. In the UK, increasing total forest cover to 18% could soak up one third of the required carbon emission cuts needed by 2050, according to the 2008 Climate Change Act. 


      Read more:
      National service for the environment – what an army of young conservationists could achieve


 A conservation army of millions was active in 1930s America The idea of enlisting millions of young people in conservation work is not new. It has origins in a public work relief programme from the 1930s. During the depths of the Great Depression and while the Dust Bowl ravaged rural America, US president Franklin Roosevelt implemented a series of reforms as part of the New Deal to implement a more sustainable land policy and revive economic growth. One of those reforms was the creation of the Civilian Conservation Corps (CCC). It enlisted 3m young men who planted over two billion trees on more than 40m acres of land between 1933 and 1942. Their aim was to repair ecosystems throughout the US with hundreds of projects in forestry and conservation. A national service for the environment would see individuals taking a direct role in mitigating climate change, but there is also an emerging political project aiming to capitalise on public support for action. The Green New Deal – an ideological heir to Roosevelt’s plan – is energising debate on climate action in the US. Endorsed by Congresswoman Alexandria Ocasio-Cortez and numerous 2020 presidential candidates, the Green New Deal is a plan to enact a “green transition” in society and the economy within the next ten years. The idea has attracted worldwide attention, including in the UK, where members of the Labour Party are urging the party’s leadership to adopt a similar plan as policy. What is the Green New Deal? The Green New Deal is a proposed series of reforms with three broad aims: To eliminate greenhouse gas emissions from energy, transport, manufacturing and other sectors of the economy within ten years. To create full employment in the manufacture of clean energy infrastructure and other essential work. To redistribute wealth and tackle social and economic inequality. Rebecca Willis, Researcher in Environmental Policy and Politics at Lancaster University says: Alongside an aim for net-zero greenhouse gas emissions and 100% renewable energy, the Green New Deal demands job creation in manufacturing, economic justice for the poor and minorities, and even universal healthcare through a ten-year “national mobilisation”, which echoes president Franklin Roosevelt’s New Deal in the 1930s. 


      Read more:
      The Green New Deal is already changing the terms of the climate action debate


 Decarbonisation to become a zero-carbon society What would decarbonisation involve? The Green New Deal entails shifting electricity generation from coal and natural gas to wind, solar, hydroelectric and other zero-carbon technologies. The decarbonisation process may require an emergency mobilisation effort akin to that seen in World War II. Because, according to Kyla Tienhaara, Canada Research Chair in Economy and Environment at Queen’s University, Ontario, the scale and speed of decarbonisation needed today cannot be delivered by carbon taxes alone: The carbon price has to be incredibly high and cover a broad swathe of the economy to significantly reduce greenhouse gas emissions. Governments haven’t shown a willingness to do this and recent research suggests that even steep prices will not produce the deep emissions reductions required to limit global warming to under 2°C. 


      Read more:
      America can afford a Green New Deal – here's how


 Will people lose jobs because of the Green New Deal? The Green New Deal resolution guarantees full employment, but Fabian Schuppert, Lecturer in International Political Theory and Philosophy at Queens University Belfast, believes its promised changes to the economy would have immediate consequences for workers in many industries which rely on fossil fuels. Job losses in sectors such as coal mining and manufacturing could erode popular support for a Green New Deal and harm the plan’s commitment to a just transition, he argues. A just transition is a commitment to ensure the costs of a transition from fossil fuels – such as tax rises and redundancies – aren’t forced on working people. Schuppert suggests that introducing a universal basic income – a guaranteed payment to everyone in society without means-testing – would help cushion the initial shock of a green transition by providing people with support while they look for new jobs or training. In the long run, he argues, it could have broader social effects: A universal basic income might offer citizens time to engage in fulfilling community-based work that doesn’t generate profit but which has social value. Taking them out of their cars in long lines of commuter traffic and putting them in allotments growing food or in parks enjoying nature could help usher a whole new way of life. 


      Read more:
      Green New Deal: universal basic income could make green transition feasible


 Does the US have the money for a Green New Deal? This is arguably the question most often asked of the Green New Deal. Edward Barbier, Professor of Economics at Colorado State University, says it does and has some suggestions: Passing a carbon tax is one of the best ways to go. A US$20 tax per metric ton of carbon that climbs over time at a pace slightly higher than inflation would raise around US$96 billion in revenue each year – covering just under half the estimated cost. At the same time, it would reduce carbon emissions by 11.1 billion metric tons through 2030. Redirect subsidies currently given to fossil fuel companies. Those subsidies are estimated to be around US$5 trillion a year globally, 6.5% of global GDP.  Raise taxes on the highest-earning Americans. Imposing a 70% tax on earnings of US$10m or more would bring in an additional US$72 billion a year … 


      Read more:
      America can afford a Green New Deal – here's how


 In an article for CNN, economist Jeffrey Sachs of Columbia University also argued that the Green New Deal is “feasible and affordable”. But climate justice is still a grey area with the Green New Deal While one of the central aims of the Green New Deal is to redistribute wealth and tackle social and economic inequality in the US, its impact on poorer parts of the world has perhaps been less discussed. Olúfẹ́mi O. Táíwò, Assistant Professor of Philosophy at Georgetown University, says that climate justice must not end at the borders of a country implementing a Green New Deal. Otherwise, he states, the Green New Deal may become “the next chapter in a long history of US industrial policies that have oppressed people”. Táíwò believes there is a risk that a Green New Deal could spark a race for vast territory on which to build solar farms or grow biofuel crops. In the process, historic injustices could be perpetuated through “climate colonialism”. He says: A research institute reported in 2014 that Norwegian companies’ quest to buy and conserve forest land in East Africa to use as carbon offsets came at the cost of forced evictions and food scarcity for thousands of Ugandans, Mozambicans and Tanzanians. The Green New Deal could encourage exactly this kind of political trade-off. 


      Read more:
      How a Green New Deal could exploit developing countries


 The contradiction at the heart of the Green New Deal Matthew Paterson, Professor of International Politics at Manchester University says that new infrastructure and redistribution proposed by the Green New Deal may boost carbon emissions: Many of the measures proposed – such as investing in infrastructure and spreading wealth more evenly – will intrinsically work in tension with efforts to decarbonise the economy. They create dynamics that increase energy use at the same time as other parts of the Green New Deal are trying to reduce it. For example, building infrastructure such as new road networks will both create demand for carbon-intensive cement manufacture and opportunities for more people to travel by car. 


      Read more:
      The Green New Deal's contradiction – new infrastructure and redistribution may boost carbon emissions


 Other academics like Joe Herbert, a researcher at Newcastle University, have argued that sustaining emission reductions in the long term can only be achieved by managed degrowth of the economy. As the Green New Deal develops and its policy details are refined, its proponents may choose to adopt such novel ideas. At such an early stage in the Green New Deal’s development as a political project, much of the discussion around it remains speculative. However, Rebecca Wills argues that it has already achieved something by reinvigorating the debate over climate action: The Green New Deal is already succeeding in putting climate action where it belongs, as the defining political issue of our time. How strange that we have the current US political environment to thank for this huge step forward. 


      Read more:
      The Green New Deal is already changing the terms of the climate action debate


 Michelle Bloor believes that including her vision of a national service for fighting climate change within the aims of a Green New Deal could help galvanise support for the latter, by providing an outlet for some of the enthusiasm of young people who have taken part in the climate strikes. Building a coalition for radical climate action under the Green New Deal is likely to lead the ongoing strategy of the project. Bloor believes that mobilising the growing youth movement is a good place to start. 
Click here to subscribe to Imagine. Climate change is inevitable. Our response to it isn’t."
"
Share this...FacebookTwitterYet another German solar manufacturer appears to be reaching the end of the line.
The German TAZ here reports that profits for SMA Solar in 2011 fell by more than a half, to 166 million euros.
In light of the fall in prices in the branch and planned cuts in subsidies in Germany, SMA anticipates a further decrease in sales and profitability.”
Yet, SMA director Pierre-Pascal Urbon is still optimistic. To avert the ill fate of other solar manufacturers in Germany, like Q-Cells and Solarworld, SMA aims expand business in foreign markets. China is a huge market, but Chinese manufacturers are subsidized by the Chinese government, which distorts competition, Urbon claims. Imagine that – subsidies distorting competition. That of course would never happen in Germany or Europe, now would it?  (sarc off)
SMA sales in 2011 sank from 1.9 billion euros to 1.7 billion. The TAZ writes:
This year revenue is expected to sink to 1-2 to 1.5 billion euros, the company said.
The main reason for the expected decline are the reduced feed-in rates that the government mandates for producers of solar energy in Germany, which go into effect on April 1, 2012. The change in feed-in tariffs will result in drops of up to 40%,
Because of Germany’s overly generous feed-in tariff paid to solar power producers in the past, half of the world’s solar power generation capacity is said to have been installed in Germany, a country that gets as much sunshine as Alaska.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterFor Christmas I present to you my favourite Scrooge film – with Seymour Hicks. It’s a classic.
Let’s hope that the climate Scrooges among us, those who think that 6 billion people or more are “surplus population” and see only the dark side of everything, will open their hearts and minds for once, and stop being so pessimistic and morose about the future of our planet.

Note how both Scrooge and alarmists get mad when we burn coal and spend our money on consumerism, or advocate throwing people who think differently in prison.
If we can convert one Scrooge alarmist out there, then we can call this Christmas a success. But don’t let your expectations get to far ahead of you. The alarmists are truly a pessimistic, unhappy, and difficult-to-convert bunch. You have to view them as Nephew Fred views Scrooge.
Enjoy –
MERRY CHRISTMAS EVERYBODY!!
Share this...FacebookTwitter "
"
What an ice free Arctic might look like from space
We all know how much NSIDC’s Dr. Mark Serreze has been touting the idea of the “Arctic death spiral“,  and we’ve had predictions of ice free summers in 2008, 2013, 2015, 2020, 2030, 2040, 2050, 2060, 2070, and 2100 to name a few. Other forecasts don’t give specific dates but say things like within 5 years,  10 years, 20 years, 30 years, 100 years, decades, and sooner than expected. Such “all over the road forecast certainty” doesn’t really build any confidence that any of these climate soothsayers have any idea when or even if the Arctic will be “ice free” in the summer in the next 100 years.
Now, inconveniently, we have this new paper via ScienceDirect New insights on Arctic Quaternary climate variability from palaeo-records and numerical modelling which says that their studies show that the early Holocene might very well have had ice free summers. This is interesting, because as this generally well accepted graph shows, temperature was higher then. But there’s more.


From the description for this graphic: The main figure shows eight records of local temperature variability on multi-centennial scales throughout the course of the Holocene, and an average of these (thick dark line). (to 10000 BC-2000CE (from 0 — 12000 BP)) The records are plotted with respect to the mid 20th century average temperature, and the global average temperature in 2004 is indicated. An inset plot compares the most recent two millennia of  the average to other recent reconstructions. At the far right of this  plot it is possible to observe the emergence of climate from the last glacial period of the current ice age.  During the Holocene itself, there is general scientific agreement that  temperatures on the average have been quite stable compared to  fluctuations during the preceding glacial period. The above average  curve supports this belief. However, there is a slightly warmer period  in the middle which might be identified with the proposed Holocene climatic optimum. The magnitude and nature of this warm event is disputed, and it may have been largely limited to high northern latitudes.
But, the other rub of the early Holocene is CO2 in the atmosphere. We know from ice core records that CO2 concentration has varied with ice ages.  Coming out of the last ice age into the Holocene, we know that atmospheric CO2 concentrations rose as CO2 came out of the oceans as they warmed. This graph from the American Association for the Advancement of Science (AAAS) shows that the early Holocene (~10,000 years before present), had a rise coming out of the ice age and then had CO2 concentrations stabilize lower than that of today, about 260-270 ppm:

Figure 1. Top: One sigma-calibrated age ranges for the 14C control points 1, 2 and 6 as an indicator of the possible age range of the CO2 record reconstructed from stomatal frequency. The labels are the same as in Wagner et al. (1). Center and Bottom: Atmospheric CO2 concentration reconstructed from stomatal index () (1) and direct measurements of CO2 concentration of air enclosed in bubbles in the ice cores from Taylor Dome () (3, 4) and Vostok () (7, 8).
This new paper in the journal Quaternary Science Reviews throws a formidable monkey wrench into the the theory that CO2 induced warming is the cause of current Arctic ice loss. Because if we had ice free summers ten thousand years ago at ~ 260 ppm CO2, and we had warmer temperatures than today, we can’t then conclude that an additional 100 ppm of CO2 since then would be the cause of an ice free summer in the Arctic today. And ice free summer at lower CO2 and higher temperature is an incongruity with today’s theory of the “Arctic Death Spiral”.
Here’s the paper abstract:
 
Quaternary Science Reviews
New insights on Arctic Quaternary climate variability from palaeo-records and numerical modelling

Martin Jakobssona, , , Antony Longb, Ólafur Ingólfssonc, Kurt H. Kjærd and Robert F. Spielhagene



a Department of Geological Sciences, Stockholm University, 106 91 Stockholm, Sweden
b Department of Geography, Durham University, Science Site, South Road, Durham DH1 3LE, UK
c Faculty of Earth Sciences, University of Iceland, Is-101 Reykjavik, Iceland
d Centre for GeoGenetics, Natural History Museum, University of Copenhagen, Øster Voldgade 5-7, DK-1350 Copenhagen, Denmark
e Academy of Sciences, Humanities and Literature, Mainz, and Leibniz  Institute of Marine Sciences, IFM-GEOMAR, Wischhofstr. 1-3, D-24148  Kiel, Germany


Accepted 26 August 2010.
Available online 2 October 2010.


Abstract
Terrestrial and  marine geological archives in the Arctic contain information on  environmental change through Quaternary interglacial–glacial cycles. The  Arctic Palaeoclimate and its Extremes (APEX) scientific network aims to  better understand the magnitude and frequency of past Arctic climate  variability, with focus on the “extreme” versus the “normal” conditions  of the climate system. One important motivation for studying the  amplitude of past natural environmental changes in the Arctic is to  better understand the role of this region in a global perspective and  provide base-line conditions against which to explore potential future  changes in Arctic climate under scenarios of global warming. In this  review we identify several areas that are distinct to the present  programme and highlight some recent advances presented in this special  issue concerning Arctic palaeo-records and natural variability,  including spatial and temporal variability of the Greenland Ice Sheet,  Arctic Ocean sediment stratigraphy, past ice shelves and marginal marine  ice sheets, and the Cenozoic history of Arctic Ocean sea ice in general  and Holocene oscillations in sea ice concentrations in particular. The  combined sea ice data suggest that the seasonal Arctic sea ice cover was  strongly reduced during most of the early Holocene and there appear to  have been periods of ice free summers in the central Arctic Ocean. This  has important consequences for our understanding of the recent trend of  declining sea ice, and calls for further research on causal links  between Arctic climate and sea ice.
~~~~~~~~~~~~~~~~~~~~~~~~~~

Fig. 1. Map showing the locations of some of the studies included in the papers presented in this special issue. Numbers refer to Table 1,  which contains the references to the respective study. Some of the  papers on the Arctic Ocean involve sediment cores from a large spatial  area; these are only plotted with boxes enclosing the areas of the  studied cores. Furthermore, Cronin et al. (2010) analyzed sediment cores from virtually the entire central Arctic Ocean  and, therefore, there is no number representing that study on the map.  The maximum extensions of the Eurasian Ice Sheet during the late  Quaternary compiled by the QUEEN project (Svendsen et al., 2004)  are shown. LS: Late Saalian (>140 ka), EW: Early Weichselian  (100–80 ka), MW: Middle Weichselian (60–50 ka), LGM: Late Weichselian  (25–15 ka). The speculative extent of an MIS 6 ice shelf inferred by Jakobsson et al. (2010) is shown by the hatched area enclosed by a gray stippled line. The  approximate spatial minimum cover of sea ice during 2007 is shown with a  white shaded area enclosed by a black stippled line as a comparison to  the median extension for the period 1979–2005 shown by a blue stippled  line (Data is from National Snow and Ice Data Center). MJR: Morris Jesup  Rise; YP: Yermak Plateau. (For interpretation of the references to  colour in this figure legend, the reader is referred to the web version  of this article.)
================================
h/t to WUWT reader “josh”
Addendum: Some follow up graphic from comments, in my response to Richard Telford:
Here’s an interesting plot of solar insolation at 65 degrees north over time. To give readers an idea of this line, here is a map:

(Map from WikiMedia) Fairbanks, AK is at 64.5° N
The plot below shows how insolation varied with the Milankovitch cycles at 65° N. I’ve added the deltas comparing 10KYA to present.

The “Fermi Paradox” blogger who originally made the graph I annotated wrote: The graph shows the insolation in W/m^2 at 65 degrees norther latitude from 20ky before present to 10 ky in the future, calculated with the program insola from J. Laskar et al. The four plots are for the two months after the summer solstice and the two months before. It can be seen that the change in insolation over time is quite significant. Note though that this only applies at high latitudes – the global mean barely changes at all.
Note the magnitude of the change in insolation from 10K years ago to present, from 15 to 40 Watts/m2
Now look at this image from NOAA’ s Environmental Research Laboratory (ESRL):

CO2 accounts for 1.4 Watts/m2 of forcing in the last 150 years, so compared to the forcings of the Milankovitch cycles (at least at 65N) it is an order of magnitude lower. My point is that given the small impact of CO2 in forcings, it is not likely to be the driver of Arctic ice melt in the present, just like it wasn’t much of a significant factor 10K years ago.




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e87bd7e30',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Wildlife populations are declining globally, but it’s not all doom and gloom. We’re in the midst of an exciting time for UK mammals. There are beavers and wild boar living free in the UK again. Otter populations are recovering and can now be found in all English counties. Polecats are expanding their range and pine martens, with a little assistance, are growing in number. Nevertheless, the information we have on many of these species is still very limited, making it difficult to understand the bigger picture. With a growing human population, it’s more important than ever that scientists and the public work together to monitor mammals effectively. Only with accurate information can conservation benefit both wildlife and the people living alongside it. 


      Read more:
      How to stop the humble hedgehog disappearing from British gardens and countryside forever


 Unfortunately, there’s little data on many British mammal species, and this prevents precise population estimates. With limited historical data, too, it’s difficult to know if populations are becoming more or less abundant and why. Without this information, it’s hard to say if conservation is needed. Important debates on issues such as badger culling and fox hunting may also be ill informed. Many mammals are nocturnal and elusive so people are unlikely to come across them. More visible species, such as rabbits or grey squirrels, are so common that people are unlikely to keep a record of sightings. To ensure the successful protection and management of Britain’s mammal community, there need to be effective ways of monitoring them long term. One technique that has proved successful in the study of mammals is the use of camera traps. These are motion-sensitive cameras that are triggered to take a photograph or short film when an animal moves in front of them. These cameras are battery powered and can be left in place for weeks or even months at a time, recording wildlife. Although some animals seem curious about the cameras, they cause less disturbance than humans would. Once set up, a camera trap can collect lots of footage – meaning large amounts of data for scientists to search through to identify species. This is one area in which the public can help. I recently started working on MammalWeb – a citizen science project that invites people to help build a better understanding of the UK’s mammals through camera trapping. People can participate by setting up a camera trap in their garden, or on any land they have permission to access. This makes it possible to have more cameras in the field, spread out across a wider area than any single researcher could manage on their own, generating a more comprehensive data set. Everyone, including those without their own camera trap, can contribute by identifying which animals are present in photos collected by other participants. There are over 500,000 photos in the MammalWeb database – nearly 250,000 uploaded by members of the public, and others by researchers seeking help with classifying species in images they’ve collected. More than 500 people have helped make 500,000 classifications, but as images must be classified by multiple people to ensure accuracy, more classifications are always needed. Participants have recorded 34 mammal species, ranging from the largest UK land mammal – the red deer – right down to some of the smallest, such as bank voles, captured using specially modified camera traps. Many of the participants were surprised by what the animals were doing in their own back gardens. There’s the typical predatory behaviour of foxes hunting pheasants and the more unusual behaviour of badgers predating hedgehogs. This behaviour among badgers may be contributing to a decline in hedgehog populations, but the camera traps have found evidence that they can coexist happily, too. One particularly surprising find was a North American raccoon (Procyon lotor), captured living wild in the north-east of England. Thanks to these records, the authorities were able to locate the raccoon and transfer it to a local zoo to be looked after. This highlights how easily wild mammals can go unobserved. It’s unknown how long the raccoon was roaming free and, without the aid of the public and their camera traps, we may never have known about it. While a single raccoon may not seem like a serious conservation issue, non-native species can spread rapidly, with serious consequences for native wildlife. The raccoon is not the only American visitor to have made itself at home in the UK. American mink, which are threatening water vole populations, have been recorded, and American grey squirrels, which compete with native red squirrels, are the most common mammal sighted on MammalWeb – although recovering pine marten populations may help to balance the odds and aid red squirrel recovery. Volunteers are assisting NatureSpy, a non-profit organisation working on wildlife research and community engagement that MammalWeb is partnering with, in its search for the elusive pine marten in North Yorkshire as part of their Yorkshire Pine Marten Support Programme which followed video footage of a single pine marten in 2017.  There hasn’t been another caught on camera yet, but continually monitoring the area offers the best chance of spotting the animals as they move into new areas. This will help conservationists understand where and when this species is dispersing and where help can be given. Camera traps offer fascinating insights into the secret lives of Britain’s mammals. With the help of ordinary people, we can all learn more about them, and how to look after them well into the future."
"The deep sea is the largest habitat on earth and incredibly important to humans, but it faces many threats – from increased human exploitation to the effects of climate change. As this exploitation expands we need to decide to what extent we will try to conserve the oceans, and this is a decision that must be informed by what the oceans provide. This was the motivation for our study, published in the journal Biogeosciences. One of the constant challenges faced by deep-sea researchers is the impression often held that the deep-sea is too unknown and remote to be important to humans. This makes it an uphill battle to explain why our research is of more than just scientific interest. The fact that the deep oceans are largely in international waters outside national jurisdiction means that its importance is truly global, because it is only at a planet-wide level that they can be properly managed. We are on the verge of expanding the range of what we take from the sea: developments such as manganese nodule mining are closer to fruition, terrestrial supplies of rare earth elements are dwindling making the massive reservoirs under the ocean more attractive, and mining claims for massive sulfides, rich in elements used in electronics, are likely to start in the next year.  This is the time to discuss deep-sea stewardship before it is already underway. Already commercial fishing has expanded to encompass more species, taking more from the sea with ramifications for the entire marine ecosystem. We need to realise how these ecosystems are important to human society now, so that those who are beginning to harvest yet more resources from the oceans can see what impact that may have.  In addition to summarising what the deep sea provides to society already, we also emphasise that a different approach needs to be taken. For example, manganese nodules take centuries or longer to form and are not renewable.  Many commercial fish stocks are in decline – even with precautionary management. Fishing is often treated more as mining than management of a living resource; no time is allowed for certain slow-growing deep-sea fish stocks to recover resulting in the complete loss of the stock. It’s not just the biological resources that are important. Because of its vast size, the physical and chemical aspects of the ocean essentially shape and regulate the way the planet works.  One of the most important services provided by the deep sea is its role in gas cycling: as one of the largest sinks for greenhouse gases on the planet, the world would not look like it does now without the deep sea. Already the ocean has absorbed a massive amount of the CO2 we have released, bearing the brunt of the human impact on the climate. There are also vast reservoirs of methane under the seafloor, which is consumed by bacterial and biological processes when it is released, preventing it from reaching the atmosphere and exacerbating the effects of global warming. Also vital is the remineralisation of nutrients  which provides the nitrogen, phosphate, and other nutrients needed to sustain the most productive surface fisheries on the planet.  When that deep, nutrient rich water comes to the surface it stimulates plankton to create the base of the most productive marine food webs, which in turn feed billions of humans. The most important result of this study is to highlight the diversity of what ocean habitats offer to humans for our benefit, from the deep-sea trenches to vents and seeps. While this vast environment still contains a staggering list of unknowns, what we do know highlights the extent of what it provides to society.  From materials for jewellery or electronics to oil and gas and other future potential energy reserves or novel pharmaceuticals, its value should be recognised. In this way, as we decide to use it more in the future we work to avoid damaging or losing the services it already provides.   What the ocean provides reaches all across humankind, from fishers providing food or income from the sea, directly or indirectly, or those far removed from the ocean whose climates are changing less fast than they would if the deep ocean was not absorbing 25-50% of all the CO2 already released into the atmosphere since the industrial revolution. The importance of these services makes it less like many of the other systems that are managed and so the traditional methods and frameworks need to be changed. We hope that the managers, stakeholders and scientists involved with the ocean’s resources will be able to use our work to develop their understanding of the interconnected nature of everything the deep sea has to offer."
"**The hospitality sector will be ""decimated"" by the new Covid tiers, according to bar chain owner Martin Greenhow, who says it ""isn't viable to operate"" under the conditions.**
Mr Greenhow, who has bars in cities including Manchester, says the measures are ""a mortal blow"" to the sector.
The hospitality industry has warned that tens of thousands of businesses will close without extra support.
It comes as more pub groups have been forced to make additional job cuts.
Mitchells & Butlers, owner of the All Bar One and Harvester chains, revealed it had cut 1,300 jobs while Fuller Smith & Turner made 350 redundancies.
The government has set out what level of restrictions England's regions will face when lockdown ends with cities such as Manchester, Birmingham and Newcastle put in the highest tiers.
But chains such as Mr Greenhow's Mojo bars were struggling even before the second lockdown in England, imposed on 5 November.
On the Friday before lockdown, Mr Greenhow's Manchester bar took Â£175. On the same Friday night a year before, it took Â£10,000.
Even tier one means that bars have less than half the usual number of customers, he says.
""It's simply not a business model that can work,"" he adds. ""Right now, for hospitality, all the tiers are a version of waterboarding. We're allowed out for a brief gasp of fiscal oxygen, then we're slammed back down.""
""This is pure and simple business torture.""
UK Hospitality boss Kate Nicholls said the sector is ""bearing the brunt of the pain of closure"" under the new Covid rules. She added that tens of thousands of businesses will close without additional support.
Under the new restrictions, pubs in tier 2 regions can only open if they serve substantial meals and households are not allowed to mix indoors.
Under tier 3, pubs and restaurants must close their doors but can offer takeaways.
Ms Nicholls said that 98% of its members were in areas with tier 2 or tier 3 coronavirus restrictions, and nearly nine in 10 ""say that they are not viable to operate at those level of restrictions"".
""Without additional support to sustain these businesses through this crisis, we are going to see tens of thousands of businesses closing and over a million job losses,"" she added.
Birmingham City Council leader Ian Ward said hospitality and other businesses needed a ""meaningful package"" of support from the government so the economy can ""continue to function in an effective way"".
""The crisis faced by hospitality businesses across Birmingham is of particular concern from an economic perspective - a crisis that would have been exacerbated whether our city was placed in tier 2 or 3,"" said Mr Ward.
""Many businesses in this previously thriving sector are warning they may not survive the coming months if they are dealt the double blow of more restrictions and inadequate financial support.""
The Night Time Industries Association (NTIA) described the imposition of the tier three level as ""devastating news"" for those areas.
""The government must compensate these businesses for the period of time they have been closed, and the loss of business suffered due to restrictions through the festive period,"" said NTIA chief executive Michael Kill.
The British pub industry sent a letter on Wednesday pleading with Prime Minister Boris Johnson to save the industry, which it said was facing ""the darkest of moments""."
"

If his Miami speech on January 27 serves as any guide, Mitt Romney may be missing a great opportunity to connect with the youth (18–29) vote. Here’s what he said:



Our young people have a great deal of concern. They’re a very humanitarian people. They’re concerned about issues like global warming and things of that nature, and they’re concerned about humanity



Judging from the most recent _Survey of Young Americans_ from Harvard’s Institute of Politics (IOP), Romney’s got it about 100% wrong. By and large today’s young Americans are self‐​interested, isolationist, want handouts, and they rank global warming last among domestic issues. Sounds like the general public to me!



Harvard’s methodology is a bit obtuse but yields interesting results. It samples twenty issues in one‐​on‐​one comparisons. For example, it asks a subsample of its 3,000+ respondents, “which do you think is more important, combating the impacts of climate change or addressing social security”; then climate change versus reducing the federal deficit, etc. (result: climate lost both comparisons handily).



I have rearranged their data in a different fashion that allows one to rank their 20 issues in order of descending importance.



Readers may have seen a very incomplete version of this by Charles Blow in last Saturday’s _New York_ _Times_. Probably to save space, only “domestic” issues were shown, but another matrix, with the remaining “international” ones is available at their online site.



The only place that I have been able to find the raw matrix is at the IOP site, and it lumps domestic and international in the same chart. This gives a slightly different impression with regard to climate change.



Anyway, I gave each issue one point each time it “beat” a competitor issue head‐​on, regardless of whether the margin was statistically significant (almost all were, thanks to the large sample size).



Here we go; I also indicate which were listed as “Domestic” or “International” in the _Times’_ presentation



1\. Jobs and unemployment DOM



2\. Ensuring affordable access to health care DOM



4\. Addressing Social Security (tie) DOM



4\. Creating a world‐​class education system (tie) DOM



4\. Lowering the tax burden for all Americans (tie) DOM



4\. Becoming energy independent (tie) DOM



7\. Reducing the federal deficit DOM



9\. Protecting individual liberties from government (tie) DOM



9\. Preventing the spread of terrorism (tie) INT



10\. Withdrawing from Afghanistan (tie) INT



10\. Preventing Iran from acquiring a nuclear weapon (tie) INT



12\. Addressing income inequality DOM



13\. Developing a comprehensive immigration policy DOM



14\. Reducing the role of big money in U.S. elections DOM



(There is a large drop‐​off in support beneath this level)



16\. Promoting peaceful resolution to Israel‐​Palestine (tie) INT



16\. Promoting stable democracy in the Middle East/​North Africa (tie) INT



16\. Combating the impacts of climate change (tie) DOM



18\. Countering China’s rising influence INT



19\. Solving the European debt crisis INT



20\. Re‐​integrating North Korea into the world community INT



So what’s “humanitarian” here? “Affordable” health care sounds like “I want someone else to pay my doctor fees” The surveyed group certainly has a conflict of interest about a “world‐​class education”, given that many of the respondents were in some type of college or university. Lowering my taxes? No. The mirage of energy independence? Reducing the deficit? Getting the snoopy government out of my life? No, no, no.



And what about the dinosaur media’s mantra that it is the “young people” who are most concerned about climate change? Of all the issues designated “domestic”, it’s at rock bottom. But is it really a domestic issue? After all, any effective climate change mitigation program is going to have a substantial international component. So let’s call it both.



In that case, it comes in ahead of three other international issues, including a humanitarian one—“Solving” (whatever that means) the European debt mess. I think our students are writing the headline: **Youth to Euros: Drop Dead _._**



Mr. Romney would do well to revisit his January assessment of young voters in light of the Harvard survey. Let Obama appeal to their penumbra of altruism. Instead, campaign for this demographic by promoting economic development, jobs, social security reform (read: investment in things other than our insolvent government), and reforming higher education by concentrating on teaching and research instead of the armies of administrators that are now employed to deal with the federal leviathan. And stay away from climate change, the Far East, and bailing out the Euros.
"
"
Share this...FacebookTwitterI’ll spare you all the old warmist warnings of balmy winters with rare and exciting snowfalls.
Now, as global warming advances faster than ever seen (so say the “experts”) Europe should now expect colder and colder winters instead. That’s what their new models show. Looks like they’re right. Check out all the warming that’s coming up in the days and weeks ahead. The warmer it gets – the colder it gets!
Reader DirkH brings our attention to a weather warning for the next two weeks from wetter.t-online.de, which warns that temperatures in parts of Germany may plunge to 25°C below zero.
Perfect timing for the launch of Drs Lüning and Vahrenholt’s book on February 6. Critics have already accused the two authors of denying the warming. Incidentally the two authors warn in their book that it will likely get cooler over the next few decades, and not warmer. The greens laugh at this. But we’ll see who laughs last.
Nuclear power-free South Germany to get hit the hardest
According to Andreas Wagner of the Meteomedia Storm Centre site, “Temperatures of -15°C during the daytime and strong wind gusts will make the temperature feel like -25°C in some regions – it’s going to be really bitter warm cold.” And Wagner warned that “Arctic conditions will prevail during the nights by the end of the week. That concerns large regions in Southern Germany.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Good time to buy a Honda home generator – just in case
Southern Germany? Isn’t that where the government forced the shut down of 8 nuclear power plants? I think everybody ought to go out and buy electric heaters and test the new green energy supply system :). Actually, please don’t. I get the feeling there could be a nasty power supply interruption coming. You may want to go out and buy a Honda portable generator instead to power the furnace. Don’t rule anything out. Just think about who the masterminds behind energy management are right now.
If the grid crashes, there will certainly be holy hell to pay. The government would be wise to screw CO2 eimissions reductions and recommission any moth-balled coal plant they can find – and right now!
!! MUST READ !! (h/t: mwhite)
http://www.dailymail.co.uk/sciencetech/article-2093264/Forget-global-warming–Cycle-25-need-worry-NASA-scientists-right-Thames-freezing-again.html
 
Share this...FacebookTwitter "
"
Readers may recall a story on WUWT from April titled: Solar Dynamics Observatory – STUNNING first images and movies
Now, SDO imagery of the sun is online. This week spaceweather.com has started using SDO sunspot imagery in place of the familiar SOHO MDI image on their left sidebar.  See all resolutions: 4096, 1024,              256 The upside of the 4096 pixel image is that the detail is striking, the downside is that even tiny sunspecks are now visible in exquisite detail.
SDO sunspot image - click to enlarge
The real question now is; what will this new detail do to sunspot counts. As we saw in August 2008, when SIDC retroactively counted a sunspeck to snatch away a spotless month, will the SDO now be the new speckometer? Older telescopes and projection methods would never have seen the sunspecks we see today.
As we see with Geoff Sharp’s Layman’s Sunspot Count, both SIDC and NOAA’s counts are higher than the layman’s count. Now with SDO imagery, will even more miniscule sunspecks widen the gap between them? See the graph below comparing SIDC, NOAA, and LSC:

click to enlarge
From Geoff Sharp’s website, here’s how the new Layman’s count works:
THE LAYMAN’S COUNT METHOD & HISTORY
There has been a lot of comments recently  about the tiny specks that have been counted as sunspots. A tiny speck  can get a daily count of 11 which severely skews the record. Also I have  noticed on the SIDC record some days where the Sun is completely blank  but the records show a sunspot count. NOAA is another magnitude higher  than the SIDC, NOAA using a different method not meant to compare with  the historical count. During times of high speck count we need a new  standard to record sunspots that gives us a realistic measure of today’s  activity verses the last Grand Minimum.
Robert Bateman a very motivated amateur solar enthusiast and myself started a thread at www.solarcycle24.com (which has unfortunately developed into an anti Landscheidt, Pro AGW  forum) and soon devised a plan to come up with a reliable standard. We  would use the existing SOHO 1024 x 1024 Continuum images and measure the  pixels involved in a Sunspot. Initially it had to be determined what a  standard sunspot should represent in size and density, to try and  represent a minimum counter like Wolf may have done 200 years ago. After  some deliberation and advise from Robert who also dabbles in Astronomy  with his own equipment, we came up with a minimum standard.

To be counted, a sunspot or group must have 23 pixels which have a reading in the green channel of 0-70 for at least 24 hours.
All pixels in a digital image have a RGB  reading which split out into separate Red, Blue, Green channels and can  be easily measured and counted in one action using a freeware graphics  program called GIMP.
So the standard was set, which now enabled us to go back over the records and weed out the offending specks and blank days.
The official Layman’s Sunspot Count is  compared against the SIDC record which is considered conservative when  compared with other institutions involved. Basically we use the same  sunspot number as SIDC but replace them with zero on days that don’t  make the grade. When the SIDC count is made up of two or more areas and  if any of the area’s do not make the Layman’s Count, the overall SIDC  daily count will be reduced by the areas that fail. Spots that count 23  pixels and over before midnight and then continue on to pass the 24 hour  rule will take the SIDC value of that day. Existing Spots that have  made the grade but measure less than 23 pixels at midnight are not  counted on the next day.
===================================================
Unless solar science comes up with a way to deal with the advances in technology and properly merge it into the older human-optical record, the sunspot record will start looking like the surface temperature record, with upwards trends due to adjustments (or lack thereof).
I think Sharp and Bateman are on to something, and if you’ll provide me a graphic that isn’t drop shadowed onto a dark background, I’ll add it to the upcoming WUWT solar page with a link to yours. – Anthony


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a2c4fc3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Skywatcher Michael Jäger of Stixendorf, Austria, took this photo of the newfound comet McNaught C/2009 R1 on June 6, 2010, while the comet was visible in the northeastern morning sky. Image via Space.com
From University of Chicago Press Journals: New research challenges the controversial  theory that an ancient comet impact devastated the Clovis people, one of  the earliest known cultures to inhabit North America.
Writing in the October issue of Current Anthropology, archaeologists Vance Holliday (University of Arizona) and David Meltzer  (Southern Methodist University) argue that there is nothing in the  archaeological record to suggest an abrupt collapse of Clovis  populations. “Whether or not the proposed extraterrestrial impact  occurred is a matter for empirical testing in the geological record,”  the researchers write. “Insofar as concerns the archaeological record,  an extraterrestrial impact is an unnecessary solution for an  archaeological problem that does not exist.”  
The comet theory first emerged in 2007 when a team of scientists  announced evidence of a large extraterrestrial impact that occurred  about 12,900 years ago. The impact was said to have caused a sudden  cooling of the North American climate, killing off mammoths and other  megafauna. It could also explain the apparent disappearance of the  Clovis people, whose characteristic spear points vanish from the  archaeological record shortly after the supposed impact.
As evidence for the rapid Clovis depopulation, comet theorists point  out that very few Clovis archaeological sites show evidence of human  occupation after the Clovis. At the few sites that do, Clovis and  post-Clovis artifacts are separated by archaeologically sterile layers  of sediments, indicating a time gap between the civilizations. In fact,  comet theorists argue, there seems to be a dead zone in the human  archaeological record in North America beginning with the comet impact  and lasting about 500 years.

Caption: This image shows the excavations at the Lubbock Lake  site, on the High Plains of Texas. The crew is working in the laminated  lake beds dated 13,000 to 12,000 years old. The time of the purported  extraterrestrial impact would be at the base of the lake beds. The pale  olive yellow layer below contains Clovis-age bone. The black layers  represent a marshy valley bottom and contain archaeological bone beds  (with butchered remains of extinct bison). The white layers are  archaeologically “sterile” because they represent standing lake water  (probably 1 to 2 m deep). Thus, the presence of “sterile” zones between  occupation layers has no bearing on the issue of an impact and people.
Credit: Vance Holliday
But Holliday and Meltzer dispute those claims. They argue that a  lack of later human occupation at Clovis sites is no reason to assume a  population collapse. “Single-occupation Paleoindian sites—Clovis or  post-Clovis—are the norm,” Holliday said. That’s because many  Paleoindian sites are hunting kill sites, and it would be highly  unlikely for kills to be made repeatedly in the exact same spot.
“So there is nothing surprising about a Clovis occupation with no  other Paleoindian zone above it, and it is no reason to infer a  disaster,” Holliday said.
In addition, Holliday and Meltzer compiled radiocarbon dates of 44  archaeological sites from across the U.S. and found no evidence of a  post-comet gap. “Chronological gaps appear in the sequence only if one  ignores standard deviations (a statistically inappropriate procedure),  and doing so creates gaps not just around [12,900 years ago] but also at  many later points in time,” they write.
Sterile layers separating occupation zones at some sites are easily  explained by shifting settlement patterns and local geological  processes, the researchers say. The separation should not be taken as  evidence of an actual time gap between Clovis and post-Clovis cultures.
Holliday and Meltzer believe that the disappearance of Clovis spear  points is more likely the result of a cultural choice rather than a  population collapse. “There is no compelling data to indicate that North  American Paleoindians had to cope with or were affected by a  catastrophe, extraterrestrial or otherwise, in the terminal  Pleistocene,” they conclude.

Caption: These are Clovis Points.
Credit: David Meltzer
###
Vance T. Holliday and David J. Meltzer, “The 12.9-ka ET Impact Hypothesis and North American Paleoindians.” Current Anthropology 51:5 (October 2010).
Current Anthropology is a transnational journal  devoted to research on humankind, encompassing the full range of  anthropological scholarship on human cultures and on the human and other  primate species. The journal is published by The University of Chicago  Press and sponsored by the Wenner-Gren Foundation.
SMU is a private university in Dallas where nearly 11,000 students  benefit from the national opportunities and international reach of SMU’s  seven degree-granting schools. For more information see www.smu.edu.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e88aee260',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

Journalists continue to insist that President-elect Obama has named a largely centrist Cabinet. But they're clinging to a storyline that might have been true two weeks ago but no longer is. Obama's national security team — Hillary Clinton, Robert Gates, and James L. Jones — and his economic team — Lawrence Summers, Tim Geithner, Christina Romer, and Bill Richardson — could be regarded as centrists, or at least as centrist Democrats.   
  
But as the Cabinet selection process went on, Obama increasingly named left-wing activists to jobs in which they could carry out his ambitious plans to ""transform our economy"" and be the 21st-century Franklin Roosevelt. Tom Daschle at HHS wrote a book on how we need a Federal Health Board to manage and regulate every aspect of our health care. Hilda Solis at Labor is a sponsor of the bill to eliminate secret ballots in union authorization elections and of heavy regulatory burdens on business. She opposed the Central America Free Trade Agreement and generally opposes free trade. Shaun Donovan worked on affordable housing issues in the Department of Housing and Urban Development during the Clinton administration — just the policies that led to the mortgage crisis and then the general financial crisis. His reward for a job well done? He's coming back as secretary of HUD.   
  
White House science adviser John Holdren is an old-time ""running-out-of-resources"" Paul Ehrlich cohort who disdains economics and famously lost a bet with Julian Simon on whether the prices of natural resources would rise, reflecting growing scarcity. He and Steven Chu as Secretary of Energy; former New Jersey Department of Environmental Protection chief Lisa Jackson as the head of the Environmental Protection Agency; and Carol Browner, former administrator of the Environmental Protection Agency under President Bill Clinton, as the White House's ""energy/climate czar,"" are all global-warming catastrophists who see an urgent need to impose crushing burdens on the economy in the name of influencing the climate a century from now.   
  
The choice of Tom Vilsack to be secretary of agriculture is said by the _Washington Post_ to be an example of Obama's moderation and intention to balance competing interests. You see, he's popular with ""groups representing big agricultural interests, which praise him for his support of biotechnology and subsidies for corn-based ethanol."" But also with groups that want to shift Ag dollars to smaller farms. So the question to be decided is who gets the gravy, not whether the gravy will be ladled out by Washington. There doesn't appear to be anyone in the Obama Cabinet who will speak for the taxpayers' interest. Or who will argue that it would best for the whole country to let the market work and not have the government pick _any_ winners or losers.   




Sometimes journalists just don't seem to reconcile the ""centrist"" claim with their own understanding of Obama's intentions. The _Los Angeles Times_ , for instance, begins its article, ""The Cabinet that President-elect Barack Obama completed on Friday is a largely centrist and pragmatic collection of politicians and technocrats without a pronounced ideological bent."" But two paragraphs later the authors note: 



Obama wants this Cabinet to market and put in place the most dramatic policy changes in the country since Franklin D. Roosevelt's New Deal: a mammoth program to improve roads and bridges; a healthcare system that covers more sick people at less cost; limitations on fossil fuels and greenhouse gases that contribute to global warming; big investments in energy efficiency; middle-class tax cuts along with a tax hike on wealthy Americans.



That doesn't sound like the agenda for a pragmatic and non-ideological administration. That's what you would expect from a bunch of statist ideologues who have been waiting years or decades for an election and a crisis that would allow them to fasten on American society their own plan for how energy, transportation, health care, education, and the economy should work. That's not centrist, it's a collectivist vision hammered out by Ivy Leaguers and activists over the past couple of decades. In its more idealistic formulation, it's based on the premise that smart people know what the people need better than the people themselves do, and that command and control work better than markets and individual choice. In its more practical application, it's interest-group rent-seeking dressed in the trappings of public interest.   
  
The proof will be in the pudding, of course. It's the policies that matter, not the people. But these are people who weren't selected for the misty dream of listening ""not to your doubts or your fears but to your greatest hopes and highest aspirations"" but rather for their determination to ensure that ""generations from now, we will be able to look back and tell our children that this was the moment when we began to provide care for the sick and good jobs to the jobless; this was the moment when the rise of the oceans began to slow and our planet began to heal; this was the moment . . . when we came together to remake this great nation."" And for their commitment to use ""this painful crisis [as] an opportunity to transform our economy.""   
  
And for the rest of us, this is a time to remember that limited constitutional government and free markets sustain life, liberty, and the pursuit of happiness better than collectivist agendas carried out by powerful states.


"
"Who should political leaders follow when it comes to climate change:  environmental scientists, powerful corporations, or a million marchers? Sometimes the three groups disagree, sometimes they concur; but even then, their claims to authority are based on different and frequently conflicting ideas. The recent United Nations climate summit highlighted the confusion over how best to make progress. Gaining agreement on an emissions treaty will require governments of all kinds to pitch in and there are competing ideas of how even democratic states make climate policy. One idea concerns supranational government: the dream of liberal internationalists since at least the post-World War I invention of the League of Nations, it is incarnated today in the UN. The organisation is founded on a utopian faith in the possibility of transcending narrow national interests in favour of the general good of humanity. This goal has proven elusive because the anarchic world of international relations, driven by economics and ethnicity, has resisted pacification. The other aspect of supra-nationalism is more technical, and has seen greater success. UN bodies such as the Food and Agriculture Organization and the World Health Organization are occasionally branded as political, but have become almost technical spaces for the application of rationality. This faith in a disinterested expertise that can triumph through the power of objective evidence dominates hopes for positive summit outcomes. A second view of the state regards it as subject to competing perspectives, which determine its conduct. Parliamentary democracies are open to influence when voices are loud, cogent, numerous and attached to material interests. The remarkable power of the oil, coal and gas industries is clear when lobby groups and unscientific deniers stake a place alongside technical experts. The UN’s Intergovernmental Panel on Climate Change does not have the same status as the FAO or the WHO, because of the opposition lined up against it. Politicians’ platitudes on the environment are easily uttered, even as their policies and programmes are based on ephemeral self-interest and pseudo-science. This gloomy reality dominates pessimism about the outcome of the summit, because corporate power and short-term priorities trump existential crisis. Then there is the idea that states are inherently undemocratic and hopelessly compromised by these interest groups, but can be forced through spectacle to watch, listen, and learn. This assumes that sovereignty resides in universal values expressed through righteous indignation that transcend government to represent the popular will in an unmediated way via civil society. Hence groups believing that anti-climate change gatherings of a few hundred thousand in a population of two billion signify a people’s message. Theirs was the authentic assembly, not the UN. There are fascinating contradictions at play here about knowledge and elitism. On the one hand, many environmental activists are animated by scientific research. On the other, they claim legitimacy through grassroots connections, not expertise. So bodies such as the IPCC are invoked, but experiential stories are privileged. Claims to organic community ties and a need for business and state transparency are asserted at the same time as small numbers of operatives work clandestinely to disrupt corporate activity. Hence Greenpeace occupying a coal train in England’s East Midlands last Tuesday while Leonardo DiCaprio and David Cameron were addressing an assembly on the Upper East Side. One of these activities is about agitprop and illegality, the other about speechmaking and legitimacy. One is naughty attention-seeking, the other is haughty attention-seeking. One claims to be community-based while being vanguardist, the other claims to be democratically based while being elitist. In the lonely hour of the last instance, alternatives must be found to the use of limited resources that in turn threaten our most basic resource, life itself. It’s clear that supra-national deals are necessary to mitigate the dangers we face, because the climate itself is supranational. Can and should the three theories come together to account for this mazy, hazy world of policy-making and offer better outcomes? We need the technical authority and quiet science that come with avoiding controversy and establishing proofs. The science is hard to contest, even as it is uncertain on some detail – and it should be, given the difficulty of prediction. We must also acknowledge that corporate power manifests itself again and again on national and global stages, and disclose its malevolent impact on public policy. And we should recognise that pranks by non-government organisations can draw attention to the silent and invisible way that fossil fuels can distort democracy and compromise sovereignty. All three ideas about states have their uses here: the technical possibilities of a rational world, the sceptical capacity to counter powerful distortions of the truth and the magical self-anointment of spectacle-based activism. If our crisis is to be averted – or rather, survived – we need contributions from all three models, despite their contradictions."
"
By Steve Goddard

The   last piece of ice remaining in the Arctic
The death spiral continues, with Arctic ice extent and thickness  nearly  identical to what it was 10 years ago.



The graph above shows superimposed volume data (calculated  from PIPS) for 2010, on top of the NSIDC extent data. Interesting  to note that volume continued to increase for about a month after extent  started to decline. This is because the Arctic Basin has remained below  freezing, while the lower latitudes have been melting.
In the video of 2010 ice below, you can see how ice has been piling  up to a depth of nearly five metres (red) on the windward side of  Wrangel Island, the New Siberian Islands, and the Taymyr Peninsula.

Ice thickness in Barrow, AK seems to have reached it’s maximum this  week, at about 4.3 metres feet.

University  of Alaska – Barrow Ice Sensor
Temperatures in the Arctic interior have remained cold, and well  below freezing. Not much opportunity for melt.

http://ocean.dmi.dk/arctic/meant80n.uk.php
You can see the Arctic temperature anomalies over the last 30 days in  the video below:


The four major extent indices continue to diverge, with the next  couple of weeks showing almost no year over year variability.

http://ocean.dmi.dk/arctic/plots/icecover/icecover_2010.png
The modified NSIDC image below shows in red where ice has disappeared  since early April.

The modified NSIDC image below shows in red where ice has disappeared   in the last week.

The modified NSIDC image below shows a comparison between 2010 and  2007. Areas in green have more ice than 2007. Areas in red have less ice  than 2007.

The modified NSIDC image below shows in red areas of ice deficiency  relative to the 30 year mean, with areas of excess shown in green. The  cold Pacific side has excess ice, while the warmer Atlantic side has a  deficiency..

This corresponds quite closely with sea surface temperature anomalies  seen below.

http://weather.unisys.com/surface/sst_anom.html
The image below from September 15, 2007 is the one which most  interests me this week. After the big “melt” of 2007, it was widely  reported that researchers expected  the ice to be gone by 2013, and that “in the end, it will just melt away  quite suddenly.”

How is five metre thick ice supposed to “just melt away quite  suddenly?”
————————————————————————————-
From the linear predictions department :
Temperatures in Colorado have warmed up 20 degrees in the last two  weeks. If that trend continues, it will become hot enough to boil water  before Christmas. And  the Arctic will be ice free by 2013.

Sources:
http://seaice.alaska.edu/gi/observatories/barrow_sealevel/brw2010/BRW_MBS10_overview_complete.png
http://seaice.alaska.edu/gi/observatories/barrow_sealevel/brw2010/BRW_MBS10_overview_complete.png
And finally, GLOBAL sea ice has returned to normal:
Click to enlarge


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b485c7f',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
My Inbox exploded with tips today, this one in particular. This unbelievably vile video from the 10:10 campaign takes the award for the most disgusting climate and carbon reduction video ever. It is in a class by itself, which is off the scale. See also Ryan Maue’s post below this one on the 350.org tie in for 10:10.

What were they thinking? They weren’t, because this is going to have the exact opposite effect they intended it to have. I don’t have words to describe my disgust with the video.
WARNING: GRAPHIC VIDEO IMAGERY



Here is what they say about it on YouTube:

The1010Campaign | September 30, 2010
http://www.1010global.org/no-pressure
Whippersnapping climate campaign 10:10 teams up with legendary comic screenwriter Richard Curtis – you know, Blackadder, Four Weddings, Notting Hill, co-founded Comic Relief – and Age of Stupid director Franny Armstrong to proudly present their explosive new mini-movie “No Pressure”. The film stars X-Files’ Gillian Anderson, together with Spurs players past and present – including Peter Crouch, Ledley King and David Ginola – with music donated by Radiohead. Shot on 35mm by a 40-strong professional film crew led by director Dougal Wilson, “No Pressure” celebrates everybody who is actively tackling climate change… by blowing up those are aren’t.
I know people will be upset by this, please keep your comments civil – Anthony
=======================================================
RELATED STORIES:
Lower Than This They Cannot Stoop
Global Work Party Day on 10/10/2010: come up with your own event
UPDATE1: 
Some people in comments whether this is some sort of horrible spoof. It appears to be direct from 10:10, as the URL highlighted in yellow below on the YouTube description links directly to the 10:10 promotional web page:
http://www.1010global.org/no-pressure
which is a subpage of their main website.
http://www.1010global.org

UPDATE2: They are so proud of this “mini-movie” they did a “behind the scenes” video of it.h/t to WUWT reader “scarlet pumpernickel”.

UPDATE3: Hot Topic (an AGW proponent site) in New Zealand thinks this video is “obviously effective“


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e883e448e',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Yes, our forebears started global warming by hunting the woolly mammoth. Right. Must be the mammoth albedo effect, much like the sheep albedo effect. Oh, wait, no it’s birch trees albedo calculated via pollen proxy. The mammoths stopped eating birch trees, that’s wot did it. And those hunters used cooking fires too. Gosh. I wish I had more time to refute this, travel beckons, but I’m sure readers can lend a hand in comments.
UPDATE: Carl Bussjaeger points out in comments that;
Just last month, USA Today told us that Felisa Smith of the University of New Mexico in Albuquerque discovered that…
Mammoth extinction triggered climate COOLING
http://content.usatoday.com/communities/sciencefair/post/2010/05/mammoth-extinction-triggered-climate-cooling/1
Woolly mammoths (Mammuthus primigenius) in a late Pleistocene landscape in northern Spain. (Information according to the caption of the same image in Alan Turner (2004). National Geographic Prehistoric Mammals. Washington, D.C. Image: Wikipedia
Man-made global warming started with ancient hunters
AGU Release No. 10–15 Link here
 30 June 2010
For Immediate Release
WASHINGTON—Even before the dawn of agriculture, people may have caused the planet to warm up, a new study suggests.
Mammoths used to roam modern-day Russia and North America, but are now extinct—and there’s evidence that around 15,000 years ago, early hunters had a hand in wiping them out. A new study, accepted for publication in Geophysical Research Letters, a journal of the American Geophysical Union (AGU), argues that this die-off had the side effect of heating up the planet.
“A lot of people still think that people are unable to affect the climate even now, even when there are more than 6 billion people,” says the lead author of the study, Chris Doughty of the Carnegie Institution for Science in Stanford, California. The new results, however, “show that even when we had populations orders of magnitude smaller than we do now, we still had a big impact.”
In the new study, Doughty, Adam Wolf, and Chris Field—all at Carnegie Institution for Science—propose a scenario to explain how hunters could have triggered global warming.
First, mammoth populations began to drop—both because of natural climate change as the planet emerged from the last ice age, and because of human hunting. Normally, mammoths would have grazed down any birch that grew, so the area stayed a grassland. But if the mammoths vanished, the birch could spread. In the cold of the far north, these trees would be dwarfs, only about 2 meters (6 feet) tall. Nonetheless, they would dominate the grasses.
The trees would change the color of the landscape, making it much darker so it would absorb more of the Sun’s heat, in turn heating up the air. This process would have added to natural climate change, making it harder for mammoths to cope, and helping the birch spread further.
To test how big of an effect this would have on climate, Field’s team looked at ancient records of pollen, preserved in lake sediments from Alaska, Siberia, and the Yukon Territory, built up over thousands of years. They looked at pollen from birch trees (the genus Betula), since this is “a pioneer species that can rapidly colonize open ground following disturbance,” the study says. The researchers found that around 15,000 years ago—the same time that mammoth populations dropped, and that hunters arrived in the area—the amount of birch pollen started to rise quickly.
To estimate how much additional area the birch might have covered, they started with the way modern-day elephants affect their environment by eating plants and uprooting trees. If mammoths had effects on vegetation similar to those of modern elephants , then the fall of mammoths would have allowed birch trees to spread over several centuries, expanding from very few trees to covering about one-quarter of Siberia and Beringia—the land bridge between Asia and Alaska. In those places where there was dense vegetation to start with and where mammoths had lived, the main reason for the spread of birch trees was the demise of mammoths, the model suggests.
Another study, published last year, shows that “the mammoths went extinct, and that was followed by a drastic change in the vegetation,” rather than the other way around, Doughty says. “With the extinction of this keystone species, it would have some impact on the ecology and vegetation—and vegetation has a large impact on climate.”
Doughty and colleagues then used a climate simulation to estimate that this spread of birch trees would have warmed the whole planet more than 0.1 degrees Celsius (0.18 degrees Fahrenheit) over the course of several centuries. (In comparison, the planet has warmed about six times more during the past 150 years, largely because of people’s greenhouse gas emissions.)
Only some portion—about one-quarter—of the spread of the birch trees would have been due to the mammoth extinctions, the researchers estimate. Natural climate change would have been responsible for the rest of the expansion of birch trees. Nonetheless, this suggests that when hunters helped finish off the mammoth, they could have caused some global warming.
In Siberia, Doughty says, “about 0.2 degrees C (0.36 degrees F) of regional warming is the part that is likely due to humans.”
Earlier research indicated that prehistoric farmers changed the climate by slashing and burning forests starting about 8,000 years ago, and when they introduced rice paddy farming about 5,000 years ago. This would suggest that the start of the so-called “Anthropocene”—a term used by some scientists to refer to the geological age when mankind began shaping the entire planet—should be dated to several thousand years ago.
However, Field and colleagues argue, the evidence of an even earlier man-made global climate impact suggests the Anthropocene could have started much earlier. Their results, they write, “suggest the human influence on climate began even earlier than previously believed, and that the onset of the Anthropocene should be extended back many thousands of years.”
This work was funded by the Carnegie Institution for Science and NASA.
Notes for Journalists
As of the date of this press release, the paper by Doughty et al. is still “in press” (i.e. not yet published). Journalists and public information officers (PIOs) of educational and scientific institutions who have registered with AGU can download a PDF copy of this paper in press.
Or, you may order a copy of the paper by emailing your request to Maria-José Viñas at mjvinas@agu.org. Please provide your name, the name of your publication, and your phone number.
Neither the paper nor this press release are under embargo.
Title:
“Biophysical feedbacks between the Pleistocene megafauna extinction and climate: The first human‐induced global warming?”
Authors:
Christopher E. Doughty, Adam Wolf, and Christopher B. Field, Department of Global Ecology, Carnegie Institution for Science, Stanford, California, USA
======================
Readers, I urge you to write to newspapers and magazines that carry this story.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a64f07f',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Pictures of masked and gowned healthcare workers have become recurrent images as the Ebola virus continues to spread in West Africa. It is the largest Ebola virus outbreak ever recorded, and the death of approximately 70% of patients ensures that the disease remains headline news. There has been debate as to whether this outbreak is unprecedented in scale, now the concern is over its lack of control. Others are questioning how an outbreak happened.  In an editorial published in the journal PLOS Neglected Tropical Diseases, Daniel Bausch and Lara Schwarz from Tulane and McGill universities argue that these “unforeseen” outbreaks of Ebola are in fact more predictable than first thought. They say the socio-political landscape in West Africa, and particularly in Guinea, Liberia, and Sierra Leone, the nations most affected, is a key driver of the emergence of Ebola. They argue that regional poverty and governance issues force people to plunder the forests for resources, increasing the chance of viruses passing from animals to humans.  The impoverished health-care systems then facilitate Ebola transmission among humans. And the authors make a good point. As part of a team including ecologists, virologists, and social anthropologists, we have argued along much the same lines. Genetic evidence suggests the virus causing this outbreak is closely related to those that caused outbreaks in Gabon and the Democratic Republic of Congo in the 2000s, and the genetic differences are those collected during the virus’s journey from those locations. How, then, did it get to West Africa? Bausch and Schwarz pose the question as to why this Zaire ebolavirus strain appeared in West Africa, when another, Taï Forest ebolavirus, was thought to circulate in the region.  As is increasingly the case for emerging viruses, the source of Ebola viruses is presumed to be bats. Evidence remains slight, but data suggests fruit bats are hosts for Ebola. Antibodies against Ebola virus, which usually indicate historical but not current infection, were detected in non-migratory fruit bats in Ghana only a few years before this outbreak. The distributions of these bat species include the nations currently affected by the outbreak. Unfortunately, methods that detect antibodies are not yet discriminatory enough to determine which of the virus strains was circulating, but the results indicate at least one circulated in West African bats. Whether or not this was due to a wave of infection from central Africa through bats requires further data from bats themselves, which have proven elusive. If we assume Ebola can go wherever its host bats go, we return to Bausch and Schwarz’s central argument – was this outbreak predictable because of a perfect storm of bat infection and socio-political issues? To some degree, all events have a random component. However, like all probabilistic events, there are things that increase or decrease chances of events occurring, and Ebola outbreaks are no different.  Comparing Ebola outbreaks to another bat-borne virus may be informative. Outbreaks of Nipah virus, which often causes encephalitis and death, are linked to drinking raw palm sap in neighbouring parts of Bangladesh and India. Bat species that host Nipah occur throughout much of Asia, but greater risk of infection appears to be linked to drinking palm sap in these locations. What then links Ebola and bats and humans? One possibility is hunting. Bats are widely eaten in Africa, with more than a hundred thousand bats eaten annually in Ghana alone. However, the most commonly hunted species does not seem to be infected with Ebola as frequently as other fruit bats. It may be that other, non-bat species occasionally get infected and it is contact with these that leads to human infection. However, evidence from Ebola’s relative, Marburg virus, suggests close contact through mining activities with the putative host, a cave dwelling fruit bat, may lead to human infection and Ebola may be no different. How then can Ebola virus outbreaks be prevented? If the argument by Bausch and Schwarz is true, there will be no simple solution. No mechanism for transmitting Ebola from bats to humans (such as in the case of drinking palm sap infected with Nipah virus) has been discovered. Vaccines exist, but are at the preliminary stage of development and unlikely to be commercially viable. There is no capacity to deliver the vaccines either, because of the chaotic nature of these countries. We need a more all-encompassing approach that can reduce contact between humans and bats. Improving health-care infrastructure, restoring degraded habitats and decreasing bat hunting might have conservation and public health benefits. But these all rely on hugely improved governance in those most affected nations, which will be difficult to achieve."
nan
"**People should limit their contact with others before Covid-19 restrictions are relaxed at Christmas, Deputy First Minister Michelle O'Neill has said.**
Across the UK, three households can mix for five days from 23-27 December.
However, Ms O'Neill said it was important to reduce Covid-19 transmission ""as low as possible"".
First Minister Arlene Foster said the next two weeks ""are crucial... so that we can all have the safest and the happiest Christmas possible"".
From midnight, Northern Ireland enters a two-week circuit breaker, with the closure of many businesses in the retail, leisure and hospitality sectors.
The deputy first minister also said a ""number of things need clarified"" around Christmas arrangements which will be the focus of the executive's meeting on Tuesday.
She said these included care home arrangements, students coming home and the definition of a household.
""There is a different in approach across all the jurisdictions in terms of, for example, what a household looks like and it's important that we define that for ourselves,"" the deputy first minister added.
In Scotland, a three household bubble should contain no more than eight people over the age of 11.
The executive also announced that a Covid-19 Taskforce was being established to oversee the roll-out of the vaccine and testing programmes.
The deputy first minister said it will be chaired by a new interim head of the Civil Service and will also be responsible for public messaging to improve compliance.
Mrs Foster said the rate of transmission was currently believed to be ""just below 1"".
She said she commended ""all those who are re-doubling their efforts to make our high street as Covid secure as possible for their reopening on 11 December"".
""I want to pay tribute to our scientists, our academics, medics and health workers who are providing us with the pathways out of this pandemic through mass vaccination and testing programmes,"" she continued.
The broadcast press conferences from Stormont that follow executive meetings have understandably often been sombre occasions.
The news of daily deaths and increased hospital admissions bring home the reality of Covid-19.
The news that many families are suffering shows that eight months on, we are still struggling with this pandemic.
Whilst this is bleak and painful, today's press conference did offer some shades of light for the future.
The news of a vaccination programme offers hope that could save lives and end talk of lockdown and restrictions.
There was also news that Northern Ireland's R value is just below one - lower than England and Wales.
The first and deputy first ministers also offered some hope to the hospitality sector who desperately want to get back into business on 11 December.
Conversations with the Chief Medical Officer Dr McBride and the Chief Scientific Adviser Professor Ian Young about lifting the trading restrictions are ongoing.
Much depends on how the next fortnight pans out.
Today offered some glimpses of the future and for some at least there is hope on the horizon.
On Thursday, eight further deaths linked to Covid-19 in Northern Ireland were reported by the Department of Health, bringing its total to 962.
The department also recorded 442 new cases of coronavirus.
Five hospitals are currently operating beyond their bed capacity. They are the Causeway, Mater, Royal Victoria, Ulster and South West Acute.
There are confirmed outbreaks of Covid-19 in 139 care homes.
The UK government has said anyone travelling to or from Northern Ireland can travel on 22 and 28 December, but ""only meet with their Christmas bubble"" between 23 and 27 December."
"
Share this...FacebookTwitterThe warmists keep insisting that it’s CO2 and that the sun is not playing a role in our climate today. According to them, the sun has been on strike and stopped playing a role since mankind started its sinful use of CO2.
Yet another study is out and shows that the warmists are off in Cuckooland with their CO2 science.
Die kalte Sonne website brings our attention to a paper by Nozomu Hamanakaa, Hironobu Kana, Yusuke Yokoyamad, Takehiro Okamotoc, Yosuke Nakashimag and Toshio Kawanah of Okayama University titled:
Disturbances with hiatuses in high-latitude coral reef growth during the Holocene: Correlation with millennial-scale global climate change, where an ancient coral reef was studied.
The study was published in the journal Global and Planetary Change in January 2012.
A 6000-year old coral reef on the Japanese island of Kodakara, which was exposed during street construction works, was studied in great detail and reporesents a valuable climate archive of the last several thousand years. The reef was lifted over the surface of the water by tectonic action two and half thousand years ago.
Field observations and coral radiocarbon dating of excavated trench walls of the uplifted middle-to-late Holocene coral reef on Kodakara Island show evidence of the existence of disturbances with hiatuses in coral reef growth and coral composition differences before and after the disturbances. The scientists found three disconformities in the reef occurred at approximately 5.9 to 5.8, 4.4 to 4.0, and 3.3 to 3.2 cal yr B.P.
The abstract also writes (emphasis added):



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The coral composition clearly changed before and after the disturbances, with gradually reduced diversity resulting in a reef dominated by acroporiid coral. These data led to the hypothesis that coral reef growth was interrupted by suborbital millennial-scale global climate change induced by persistent solar activity during the Holocene in high-latitude coral reefs, such as those in the Northwest Pacific, leading to low diversity in the reefs that experienced each disturbance. Our results may provide new insights into theories of past and future coral reef formation worldwide.
As recent studies have shown, the new study shows that climate changes occurred globally and cyclicly – in sync with the 1000-year solar cycles. Die kalte Sonne writes:
The scientists found by comparison with other studies that the coral die-off events occurred in times when the current weakened and the ocean apparently cooled off because of the cold Asian winter monsoons, and did so to the point that the corals could no longer live. Interesting is the fact that the cooling phases were synchronous with solar activity minima, the solar quiet periods of the combined Hallstatt and Eddy cycles (see Chapter 3 in “Die kalte Sonne“).”
Once again the claims made in the skeptic book “Die kalte Sonne” are reinforced. Critics are left standing there without an explanation. The results of the Japanese study also add yet more evidence that cooling periods are global, and not just isolated local events. Die kalte Sonne summarizes:
One has to be permitted to ask in what magical way the sun was able to have this enormous impact on the climate. When one believes the claims made by the last IPCC report, then this in fact has to be a miracle. According to the IPCC, the climatic impact of the known solar cycles is ‘negligible’ and is only a couple of tenths of a degree, which is in stark contradiction to the real geological findings from various regions all over the globe. Now that the IPCC is just working on its latest report, don’t you think they would correct this obvious error? You guessed wrong! As we have learned, the IPCC has reduced the sun’s impact on climate even more.
They can try of course. But as the science mounts with every passing study, the dogmatic warmists are going to look more and more like the lone fool at the town square that everyone ignores.
 
Share this...FacebookTwitter "
"
By Steve Goddard
Earlier in the month I wrote an article showing the trend in Arctic ice since 2002.

I took a lot of criticism from people for not measuring “crest to crest or trough to trough.”
Any  one schooled in analysis of cyclical data would know that one must go  from crest-to-crest or trough-to-trough, to maintain some semblance of  symmetry about the x-axis.
It is time now to see how serious people are about their belief  systems. We have passed the 2010 El Niño peak, and can see what the  “real” trend is since the cyclical El Niño peak of 1998.


http://www.woodfortrees.org/plot/rss/from:1998/last:2010/plot/rss/from:1998/last:2010/trend
Hansen claims :
“Global  warming on decadal timescales is continuing without let-up … we  conclude that there has been no reduction in the global warming trend of  0.15-0.2C/decade that began in the late 1970s.”
Talk about cherry-picking! Look at his start point. He chose the worst case trough to crest to measure his trend.

Question for readers. Is Hansen correct, or does he need some serious graphing lessons? Below are the trend graphs from 1998-present for all four sources. GISS is way out of line.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89fcd5a5',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

 _Global Science Report_ _is a feature from the_ _Center for the Study of Science_ _, where we highlight one or two important new items in the scientific literature or the popular media. For broader and more technical perspectives, consult our monthly “Current Wisdom.”_   
  
  
—   
  
  
Making headlines today (like the one above) is a new paper by Zoë Doubleday and colleagues documenting an increase the population of cephalopods (octopuses, cuttlefish, and squid) over the past 61 years. The authors, after assembling a data set of historical catch rates, note that this population increase, rather than being limited to a few localized areas, seems to be occurring globally.   
  
  
End of analysis.   
  
  
From then on its speculation.   
  
  
And the authors speculate that human‐​caused climate change may be behind the robust cephalopod increase. After all, the authors reason, what else has had a consistent large‐​scale impact over the past six decades? No analysis relating temperature trends (spatially or temporally) to cephalopod trends, no examination of other patterns of climate change and cephalopod change, just speculation. And a new global warming meme is born—“Swarms of octopus are taking over the oceans.”   
  
  
There is an overwhelming tendency to relate global warming to all manner of bad things and a great hesitation to suggest a potential link when the outcome is seemingly beneficial. We refer to this as the global‐​warming‐​is‐​bad‐​for‐​good‐​and‐​good‐​for‐​bad phenomenon. It holds a great majority of the time.   
  
  
In the case of octopuses, squids, and cuttlefish, the authors are a bit guarded as to their speculation of impact of the increase in cephalopod numbers—will they decimate their prey populations or will they themselves provide more prey to their predators? Apparently we’ll have to wait and see.   
  
  
No doubt, the outcome will be a complex one as is the case behind the observed population increases. Depletion of fish stocks, a release of competitive pressure, and good old‐​fashioned natural environmental variability are also suggested as potential factors in the long‐​term population expansion. But complex situations don’t make for great scare stories. Global‐​warming‐​fueled bands of marauding octopuses and giant squid certainly do.   
  
  
**Reference:**   
  
  
Doubleday, Z. A., et al., 2016. Global proliferation of cephalopods. _Current Biology_ , **26** , R387–R407.
"
"Curious Kids is a series by The Conversation, which gives children of all ages the chance to have their questions about the world answered by experts. All questions are welcome: you or an adult can send them – along with your name, age and town or city where you live – to curiouskids@theconversation.com. We won’t be able to answer every question, but we’ll do our best. How is spider silk so easy to break when it’s stronger than steel? - George, aged ten, Hethersett, UK. Thanks for the question, George – the simple answer is that spider silk breaks easily because it’s really, really, really thin. A thread in the web of a garden spider is just 0.003 millimetres across – that’s more than 20 times thinner than a hair from your head.  But there are a few more matters we need to untangle, to see how strong spider silk is, compared with steel.  Steel is a material called an alloy, which means it is a mixture of metals. The main metal in steel is iron. Other metals are added to the iron, depending on what you want the steel to do.  For example, knives and forks are made from stainless steel that doesn’t rust. To make this you’d mix iron and chromium.  But maybe you want a steel that is really strong so you could make buildings and cranes from it. Then, you would need to mix iron with a load of different metals including titanium and vanadium.  But there are even stronger steels. Your bike might be built with something called maraging steel and it’s made with iron, nickel, cobalt, molybdenum, titanium and aluminium. Silk is a very different material from steel. It is actually protein – the same stuff that your hair and finger nails are made from.  We use steel for different jobs and spiders use silk for all sorts of things as well. And the just like our steel, spiders need different silks for the different jobs.  Let’s look at the common European garden spider: this lovely creature spins the beautiful round webs, using two types of silk.  The spokes of the web are made from dragline silk. This is strong and slightly stretchy, which means it’s good for making the main supports for the web.  The rest of the web is made from flag silk, which is less strong but very elastic, so it is really good at absorbing the shock when a great big fly smashes into the web.  But the champion constructor of the spider world is the Darwin bark spider. It produces huge webs, about the size of a kitchen table.  These are sometimes hung from trees with silk threads that stretch right across rivers. To make sure these webs stay in place, the spider uses super strong threads of silk.  Now, I’ve done some calculations, based on what scientists know about the strength of these different materials, to compare steels with spider silks and see just how strong they are.  Imagine we had a thread of each material, that was about one millimetre thick – that’s roughly the width of a pin head. Who could hang from them before they broke? The weakest is the flag line silk: a ten-year-old girl could probably swing from a thread of this, but nothing much heavier.  Next comes the high strength steel which would just about be OK if a chimpanzee hung from it.  The dragline silk would support a small adult – like Spiderman.  The Darwin bark spider silk is next, it would break if anything much bigger than a panda tried to climb it.  And finally, a gorilla would be fine dangling from a one millimetre-thick thread of maraging steel.  Which means that some the strongest steel is actually tougher than the champion spider silks. That is a shame, but all is not lost for the spiders: remember, some of their silks are still stronger than some steels.  More Curious Kids articles, written by academic experts: How do babies learn to talk? – Ella, aged nine, Melbourne, Australia. Our guinea pigs have dark eyes. Why do we have white eyes? - Rhoswen, aged three, Bristol, UK. What’s the point of nits?! – Connie, aged nine, Nambour, Australia."
"
Share this...FacebookTwitterDer Spiegel focuses again on failed international climate policy, and explores alternative policy paths being proposed by German sociologist Nico Stehr, and 13 other international authors of the Hartwell Paper, among them Roger A. Pielke Jr.
The Hartwell Paper is nothing new. It was first released in 2010 by the London School of Economics in cooperation with the University of Oxford. It was authored by 14 natural and social scientists from all over the world, among them Mike Hulme and Roger A. Pielke Jr.
But the fact that the paper is being brought up once again shows just how much everything is in disarray for the climate activists. When media outlets like Der Spiegel start having doubts, then you know the movement is in deep trouble. Spiegel begins with:
The UN climate conference in Berlin was a flop. Now there has to be a completely new start in international climate policy, says sociologist Nico Stehr.”
The UN, governments and activists have spent literally hundreds of billions of dollars on the senseless endeavor of trying to regulate the Earth’s temperature and taming storms by limiting emissions of a single trace gas. Not surprisingly, these attempts have failed completely, and never mind that temperatures have not risen in 15 years anyhow.
Spiegel writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The debacle is an immense chance for a climate policy to finally unfold. The main motivation of the Hartwell Paper:
1. Energy access for everyone;
2. Decarbonization, development of clean energy so that it is cheaper than fossil fuels;
3. Equip society so that it can cope with the risks and dangers associated with changing climate, whatever their cause may be.”
Clearly the Hartwell Paper authors propose a shift to more adaptation and less on mitigation. The Hartwell Paper supports decarbonization by promoting effective investment in other sources of energy so that they become cheaper than fossil fuels. There’s less focus on punishing environmental sinners.
What’s new here is that experts are once again asking: “When are you climate activists going to wake up and realize you’ve failed big time and that your plan has no chance of ever working in the future – no matter how hard you try?”
Nico Stehr is the owner of the Karl-Mannheim-Professur for cultural sciences at the Zeppelin University in Friedrichshafen. He is among Germany’s most renowned sociologists.
 
Share this...FacebookTwitter "
nan
"
By Steven Goddard
I found a computer  simulation of Arctic ice produced by The University Of Washington,  which struck me as being particularly disconnected from reality.
This group is forecasting that September extent will be lower than  last year.

Below is their simulation map.

http://psc.apl.washington.edu/zhang/IDAO/seasonal_outlook.html
After watching their map animate, I noticed something which bothered  me.  They are showing that by August 18, all ice will be gone north of  Barrow, AK.

The problem is that NSIDC shows 3+ year old ice in that region:


Cropped from : http://nsidc.org/images/arcticseaicenews/20100406_Figure6.png
The computer model is predicting that 3+ year old ice (which is  probably in excess of 10 feet thick) is going to melt by early August.  That seems rather far fetched.  Below is an overlay of the NSIDC map and  the U of W simulation for August 18.  Note all the multi-year ice that  needs to melt.

Last June, temperatures  in Barrow averaged 35F.  In July they averaged 44F.  It is a tall  order to melt 10 feet of ice at those temperatures.  This is how Barrow  looks today:

http://www.gi.alaska.edu/snowice/sea-lake-ice/barrow_webcam.html
I am a big fan of computer models – when they produce useful  information.  Garbage in, garbage out.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c5228d9',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterYesterday we read how EU and German bureaucrats want to force homeowners make costly home renovations, for the sole sake of saving some energy. This of course would seriously drive up rental rates for tenants, hitting the poor especially hard.

And if it isn’t difficult enough for the poor to pay for their housing, take a look at the cost for mobility. We learn today that this is already unaffordable for many – thanks to the high price of fuel from government policy.
The leftist German daily TAZ reports here on a survey by research institute Forsa published last Thursday. Over 3000 citizens were surveyed and results show that one quarter are reducing their use of public transportation or their automobiles because of costs.
According the TAZ:
24 percent of the 3212 persons surveyed from all German states are refraining from planned or necessary trips with automobile, bus, rail or planes because of cost reasons.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




These 24% of course are those with limited financial and income means. The middle class and rich will worry much less about the costs of travel as they are able to pay the prices. The energy policy is impacting mainly the poor – making their struggle to make ends meet even worse with each passing day.
There is now spiralling energy inflation in Germany. The TAZ adds:
‘Compared to cost of living increases of about 11 percent between 2005 and 2011, the prices for air and rail trave,l as well as fuel prices, have exploded,’ said Allianz-pro-Schiene Director Dirk Flege. Last year a German Railway train ticket cost 22 percent more than it did 6 years ago.
In the same time period, air travel costs rose 34 percent. Fuel prices for cars went up 28%. The reason for the price increases are rising energy costs.”
Already many of the poor are unable to afford electricity and now will neither have anywhere to go nor the means to travel. In response, the government is considering social programs to alleviate their plight. But these programs are ineffective and amount to pick-pocketing 5 euros from one pocket, and putting one euro in the other, and claiming to be good Samaritans for it.
The greens and environmentalists are of course pleased about 24% of the population cutting back, and they view it as progress for the climate. But they are demanding more – 95% if possible (5%, green officials, would be exempt and continue to fly to places like Bali, Cancun, Durban, etc.).
 
Share this...FacebookTwitter "
"
Guest Commentary by Paul Driessen
Figure 1. Chart from professional paper analyzing Michael Mann’s “hockey stick” graphs that purported to find average global temperatures suddenly skyrocketing at an exponential – and physically impossible – rate in recent decades. Willie Soon, David Legates and Sallie Baliunas, “Estimation and representation of long-term (>40 year) trends of Northern-Hemisphere-gridded surface temperature: A note of caution,” Geophysical Research Letters, Vol. 31, 2004. 
“Scientific debates should be played out in the academic arena,” insists University of Virginia environmental sciences professor David Carr. “If Michael Mann’s conclusions are unsupported by his data, his scientific critics will eventually demonstrate this.”
Carr and 809 other Virginia scientists and academics signed a petition launched by the activist Union of Concerned Scientists, protesting Commonwealth Attorney General Ken Cuccinelli’s investigation of former University of Virginia professor Michael Mann. The American Association of University Professors likewise opposes Cuccinelli, who is seeking documents from UVA, to determine whether there are grounds to prosecute Mann for violating the Fraud Against Taxpayers Act, by presenting false or misleading information in support of applications for state-funded research.
Carr claims Cuccinelli is attempting to “drown out” scientific debate.” Others have accused the AG of conducting a “witch hunt,” engaging in “McCarthyite” tactics, and “restricting academic freedom.”
It’s time to clear a few things up.
Mann is the former UVA professor, whose “hockey stick” temperature chart was used to promote claims that “sudden” and “unprecedented” manmade global warming “threatens” human civilization and Earth itself. The hockey stick was first broken by climatologists Willie Soon and Sallie Baliunas, who demonstrated that a Medieval Warm Period and Little Ice Age were clearly reflected in historic data across the globe, but redacted by Mann. Analysts Steve McIntyre and Ross McKitrick later showed that Mann’s computer program generated hockey-stick patterns regardless of what numbers were fed into it – even random telephone numbers; that explained why the global warming and cooling of the last millennium magically disappeared in Mann’s “temperature reconstruction.”
The Climategate emails revealed another deliberate “trick” that Mann used to generate a late twentieth-century temperature jump: he replaced tree ring data with thermometer measurements at the point in his timeline when the tree data no longer fit his climate disaster thesis.
Not surprisingly, he refused to share his data, computer codes and methodologies with skeptical scientists. Perhaps worse, Climategate emails indicate that Mann and others conspired to co-opt and corrupt the very scientific process that Carr asserts will ultimately condemn or vindicate them.
This behavior certainly gives Cuccinelli “probable cause” for launching an investigation. As the AG notes, “The same legal standards for fraud apply to the academic setting that apply elsewhere. The same rule of law, the same objective fact-finding process, will take place.” Some witch hunt.
There is simply no room in science, academia or public policy for manipulation, falsification or fraud. Academic freedom does not confer a right to engage in such practices, and both attorneys general and research institutions have a duty to root them out, especially in the case of climate change research.
Work by Mann and other alarmist scientists is not merely some theoretical exercise that can be permitted to “play itself out” over many years, if and when the “academic arena” gets around to it. These assertions of climate crisis are being used right now by Congress, states, courts and the Environmental Protection Agency to justify draconian restrictions on energy use and greenhouse emissions. They would shackle our freedoms and civil rights and hammer our jobs, economy, health, welfare and living standards.
If the science is wrong – or far worse, if it is manipulated, fabricated, fraudulent and covered up – then grave damage will be done to our nation, liberties and families, before the truth gets its boots on.
As to “scientific debate” over global warming, there has been virtually none in the academic arena. The science is viewed as “settled,” debate has been squelched, and those who seek to initiate debate are attacked, vilified, harassed and shipped off to academic Siberia.
Dr. Patrick Michaels, another former UVA climate researcher, was fired as Virginia State Climatologist by then-Governor Tim Kaine for raising inconvenient questions and facts on climate science. When Greenpeace demanded access to Michaels’ emails, UVA promptly acceded – before contesting AG Cuccinelli’s request for Mann’s.
The 810 protesters and their UCS and AAUP consorts were silent. Their principles and objections do not seem to apply to shrill activist groups infringing on the academic and scientific freedom of “politically incorrect” researchers, even when there is no suggestion of dishonesty. Other “skeptical” climate researchers have met with similar fates. The pungent scent of hypocrisy fills the air.
No surprise there. The massive US government climate change research gravy train alone totaled some $9 billion in grants during 2009, courtesy of hardworking taxpayers. IPCC, EU & Company climate grants – plus billions more for renewable energy research – fatten the larder still further. Now that money, prestige and power are threatened.
Climategate and other revelations about the lack of evidence for the “manmade climate disaster” thesis have sent belief in AlGorean gloom and doom plummeting. Global warming consistently comes in dead last on any list of environmental concerns. Three-fourths of Americans are unwilling to spend more than $100 a year to prevent climate change. China, India and other developing nations properly refuse to sign a carbon-cutting economic suicide pact.
The public is rightly concerned that in-house investigations by Penn State University (Mann’s current institution), East Anglia University (home of Phil Jones and the Climategate emails) and the IPCC have the patina of a Tom Sawyer whitewash. Independent investigations like Cuccinelli’s are absolutely essential, to ferret out fraud and misconduct – which may be rare but must be dealt with when it happens.
Dr. Andrew Wakefield falsified studies to create a connection between autism and trace mercury in vaccines against measles, mumps and rubella. Britain stripped him of his right to practice medicine. But meanwhile, a lingering stench remains over double standards; World Wildlife Fund press releases and rank speculation masquerading as peer-reviewed science; computer models enshrined as “proof” of looming climate disasters; and billions being squandered on research purporting to link global warming to nearly every malady and phenomenon known to man.
We the taxpayers are paying for this work. We the people will pay the price – in soaring energy bills, fewer jobs, lower living standards and lost freedoms – for draconian energy and emission laws enacted in the name of saving the planet.
We have a right to insist that the research be honest and aboveboard. That the work products stay in the public domain, available for scrutiny. That researchers share their data, computer codes and analytical methodologies, and engage in robust debate with skeptics and critics. That those who violate these fundamental precepts forfeit their access to future grants. And that our tax dollars no longer fund bogus acne-and-climate-change studies and alarmist propaganda. (Talk about budget cutting opportunities!)
It’s certainly understandable that scientists, academics, eco-activists and the AAUP and UVA would line up behind Mann and against Cuccinelli. There’s a lot of power, prestige and cash on the line. But it is essential that the attorney general and law-abiding citizens insist on transparency, integrity, credibility and accountability in the climate change arena.
We should support what Ken Cuccinelli is doing – and demand that Eric Holder and other state AGs take similar action.
Paul Driessen is senior policy advisor for the Committee For A Constructive Tomorrow (www.CFACT.org) and author of Eco-Imperialism: Green Power – Black Death.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b6c214d',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"
Share this...FacebookTwitterSo much for the notion that today’s climate is “unusual”. It turns out that some earlier interglacials were much warmer than the current one and that the variations cannot be explained by greenhouse gases alone.

Source: Alfred Wegener Instutute
A new temperature reconstruction suggests that (NATURAL) feedback mechanisms and amplifiers had to be at play.
Der Spiegel here has the story on a team of German scientists led by Martin Melles of the University of Cologne. In 2008/2009 his team extracted a sediment core from Lake El’gygytgyn in northeast Siberia, 100 miles north of the Arctic Circle. The team extracted a 135-meter long sediment core from the lake’s bottom, analyzed it and produced a temperature reconstruction going back 2.8 million years.
What makes this core unique is the lake’s history. It was formed 3.6 million years ago by a meteorite leaving a huge crater. The crater filled with water to form the lake and year by year the bottom accumulated sediment. Because the lake was not covered by a glacier during the ice ages, it sediment core is complete and without holes. Each layer of sediment provides a record like pages in a diary.
What has the reconstruction revealed?
The scientists reconstructed the climate from this core and found some big suprises. According to Der Spiegel there were “some extreme warm periods in the Arctic that up to now had been unknown.”
Der Spiegel adds
The core from Lake El’gygytgyn shows a regular change between warm and cold periods in the Arctic – thanks to changes in the Earth’s orbit, fluctuating greenhouse gases and changing solar activity. However from the back and forth in temperatures and precipitation, some extreme events stand out: The scientists have compared two “normal” warm periods – the current one, which has been ongoing for the last 12,00 years, and another one 125,000 years ago, and compared them to the so-called super warm periods. These occurred 400,000 and one million years ago.”
How warm was it? 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Der Spiegel reports on what the scientists found:
During the super warm times, the high temperatures were up to 5°C above the normal highs – that is at about 13°C. Moreover, about 600 liters of precipitation fell per square meter, about double what is normal. ‘For climatology, that’s worlds apart,’ Melles describes the differences. Around Lake El’gygytgyn, where today one finds tundra and little plant growth, green fir trees once grew. During these times, the scientists say, a large part of the Greenland ice sheet was gone.’
Also:
One sees a clear agreement between the super warm periods in the Arctic and the disappearance of the West Antarctic ice sheets,’ Melles says. Information on the retreat of this massive ice sheet was gathered from the ‘Andrill’ core in the Antarctic. It’s evaluation has shown that the West Antarctic was ice-free in warm times.
The question of course is what is the connection between the Arctic and Antarctic melting at the same time? Gee, that’s a tough one.
The Melles and his team speculate that melting water being conveyed by ocean currents, and thus coupling the two poles, could be a factor. Another theory they propose is that if sea level rises 5 meters or more, the water flow though the Bering Strait might be enough to warm the Arctic.
Amazing how what seems obvious eludes government-funded scientists. Maybe the connection is the sun?
The paper’s abstract adds:
Climate simulations show these extreme warm conditions are difficult to explain with greenhouse gas and astronomical forcing alone, implying the importance of amplifying feedbacks and far field influences. The timing of Arctic warming relative to West Antarctic Ice Sheet retreats implies strong interhemispheric climate connectivity.”
We all suspect that feedbacks and amplifiers are at play. But some scientists are doing all they can to ignore some of the mechanisms being proposed and supported by a growing body of evidence.
If there’s anything that can’t be ignored, it is that the study shows once again that scientists are more baffled than ever on how the climate really works, and so their models have to be considered accordingly.
 
Share this...FacebookTwitter "
"The US oil firm ExxonMobil met key European commission officials in an attempt to water down the European Green Deal in the weeks before it was agreed, according to a climate lobbying watchdog. Documents unearthed by InfluenceMap revealed that Exxon lobbyists met Brussels officials in November to urge the EU to extend its carbon-pricing scheme to “stationary” sources, such as power plants, to include tailpipe emissions from vehicles using petrol or diesel. Green groups believe this would be the least effective way to disincentive fossil fuel vehicles, and would rather allow countries to set their own emissions standards and targets for road emissions. The move appears to be an attempt to stall the rollout of electric vehicles by keeping a lid on the cost of driving a traditional combustion engine vehicle running on fossil fuels. The European commission stopped short of proposals to phase out combustion engine vehicles and has plans to consult on whether to include vehicles in its carbon-pricing scheme. Edward Collins, a director at InfluenceMap, said the document “represents yet another evidence piece” of ExxonMobil’s long-term strategy of delaying climate action by focusing on “long-term technical solutions” to try to avert “decisive regulatory action” that is urgently required to tackle the climate crisis. A Guardian investigation last year found that Exxon has spent €37.2m (£32.4m) lobbying the EU since 2010, more than any other major oil company, according to the EU’s transparency register. It revealed that Shell spent €36.5m and BP spent €18.1m lobbying Brussels officials to shape EU climate policy. Exxon is also facing legal action in the US courts after accusations that it misled investors over the business risks caused by regulations aimed at addressing the climate crisis. The lawsuit claims that Exxon scientists told the company’s management in 1977 there was an “overwhelming” consensus that fossil fuels were responsible for increasing the levels of carbon in the atmosphere that lead to global heating. In 1981, an internal company memo warned that “it is distinctly possible” that CO2 emissions from the company’s 50-year plan “will later produce effects which will indeed be catastrophic (at least for a substantial fraction of the Earth’s population)”. Exxon’s latest lobbying efforts have surfaced after documents emerged earlier this year showing that BP successfully lobbied US policymakers to weaken a landmark environmental law to clear the way for fossil fuel projects to move forward. A spokesman for ExxonMobil said the company “complies fully” with the EU’s transparency rules and supports the Paris climate agreement. He added that Exxon, “like many companies”, had “a responsibility” to engage in a public policy dialogue that impacted its business."
"
Share this...FacebookTwitterAnthony Watts, the king of skeptic climate science bloggers, made the unusual announcement yesterday that 1) blogging had been suspended until Sunday and 2) that he had something “controversial and unprecedented” to tell us.
The rest of us many backbenchers and observers, always hungry for any bit of news supporting our views, are now left to speculate 2 days long.
Here’s what we know:
1. It’s not something bad for him or his family. That’s good to know.
2. It’s nothing legal, political or social in nature.
…has nothing to do with FOIA issues or other sorts of political or social theories…”
But here we note Anthony left out the descriptive “scientific” and “business” terms. This narrows down the possibilities considerably. So is it scientific or business? Here’s what he writes originally:
…there will be a major announcement that I’m sure will attract a broad global interest due to its controversial and unprecedented nature.”
The key words to me here are global, controversial and unprecedented – especially telling is the word “controversial”. Well we know he tinkers around a lot and is inventive. But new products or innovation are rarely controversial, which therefore pretty much eliminates the possibility that it’s an exciting technical breakthrough, i.e. business-related.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And what we do not know:
Overall, that leaves that his “controversial and unprecedented” announcement is scientific in nature. Climate science today is controversial. Sounds to me like he has come up with hard results people aren’t going to like and someone big (like a renowned journal) has endorsed them.
Later he does seem to backpedal a bit on the implications of his announcement, writing that it has:
“…something to do with one of my many projects, it is still a ‘major announcement’ and it has important implications that I’m sure everyone will want to know about.”
Well, what is it that he has been working on for years that everyone will want to know about? Sounds a lot like it has something to do with his surface stations project, getting something published, or being appointed to an important position related to the subject. But surface stations have been pretty much covered and we know pretty much what there is to know about that.
So what’s left? There’s likely another topic he’s been researching and has not told us about yet, and has some surprising, hard results.
That’s my WAG. Next time, he should say nothing and just drop the bomb on us.
But now, until the bomb drops, we are left to speculate on what this “controversial and unprecedented” announcement of “global interest” could possibly be.
 
Share this...FacebookTwitter "
"
Guest Post by Willis Eschenbach
Following up on the excellent initiative of Dr. Judith Curry (see Judith’s  post and my  response ), I would like to see what I can do to rebuild the justifiably lost trust in climate science. I want to bring some clarity to terms which are used all the time but which don’t seem to have an agreed upon meaning. In the process, I want to detail my own beliefs about the climate and how it works.
Figure 1. Dr Judith Curry tries to warn the greenhouse warming scientists … from  Cartoons By Josh.
I don’t know about you, but I’m weary of the vague statements that characterise many of the discussions about climate change. These range from the subtle to the ridiculous. An example would be “I believe in climate change”. Given that the climate has been changing since there has been climate, what does that mean?
We also hear that there is a “consensus” … but when you ask for the actual content of the consensus, what exactly are the shared beliefs, a great silence ensues.
Often we see people being called unpleasant terms like “deniers”, with the ugly overtones of “Holocaust deniers”. I’ve been called that myself many times … but what is it that I am being accused of denying?
In an attempt to cut through the mashed potatoes and get to the meat, let me explain in question and answer format what I believe, and provide some citations for my claims. (These are only indicative citations from among many I could provide on each topic.) I will also indicate how much scientific agreement I think there is on the questions. First, some introductory questions.
Preface Question 1. Do you consider yourself an environmentalist?
I bring this up to get rid of the canard that people who don’t believe the “consensus science” on global warming are evil people who don’t care about the planet. I am a passionate environmentalist, and I have been so since 1962 when I first read Silent Spring upon its publication. I believe that we have an obligation to respect the natural ecosystems that we live among. My reasons are simple. First, we have a responsibility to be good guests and good stewards here on this amazing planet. Second, I worked extensively in my life as a commercial fisherman, and I would like for my grandchildren to have the same opportunity. The only way to do this is to monitor and be careful with our effects on the earth and the biosphere.
Preface Question 2. What single word would you choose to describe your position on climate science?
Heretic. I am neither an anthopogenic global warming (AGW) supporter nor a skeptic, I believe the entire current climate paradigm is incorrect.
Question 1. Does the earth have a preferred temperature which is actively maintained by the climate system?
To me this is the question that we should answer first. I believe that the answer is yes. Despite millennia-long volcanic eruptions, despite being struck by monstrous asteroids, despite changes in the position of the continents, as near as we can tell the average temperature of the earth has only varied by about plus or minus three percent in the last half-billion years. Over the last ten thousand years, the temperature has only varied by plus or minus one percent. Over the last 150 years, the average temperature has only varied by plus or minus 0.3%.  For a system as complex and ever-changing as the climate, this is nothing short of astounding.
Before asking any other questions about the climate, we must ask why the climate has been so stable. Until we answer that question, trying to calculate the climate sensitivity is an exercise in futility.
I have explained in “The Thermostat Hypothesis” what I think is the mechanism responsible for this unexplained stability. My explanation may be wrong, but there must be some mechanism which has kept the global temperature within plus or minus 1% for ten thousand years.
I am, however, definitely in the minority with this opinion.
Question 2. Regarding human effects on climate, what is the null hypothesis?
If we are trying to see if humans have affected the climate, the null hypothesis has to be that any changes in the climate (e.g. changes in temperature, rainfall, snow extent, sea ice coverage, drought occurrence and severity) are due to natural variations.
Question 3. What observations tend to support or reject the null hypothesis?
As I show in “Congenital Climate Abnormalities”, not only are there no “fingerprints” of human effects in the records, but I find nothing that is in any way unusual or anomalous. Yes, the earth’s temperature is changing slightly … but that has been true since the earth has had a temperature.
There is no indication that the recent warming is any different from past warmings. There is more and more  evidence that the Medieval Warm period was widespread, and  that it was warmer than the present.  The Greenland ice cores show that we are at the cold end of the Holocene (the current inter-glacial period). There have been no significant changes in rainfall, floods, sea level rise, Arctic temperatures, or other indicators.
In short, I find no climate metrics that show anything which is anomalous or outside of historical natural variations. In the absence of such evidence, we cannot reject the null hypothesis.
Question 4. Is the globe warming? 
This is a trick question. It is a perfect example of a frequently asked question which is totally meaningless. It shows up all the time on public opinion polls, but it is devoid of meaning. To make it meaningful, it needs to have a time period attached to it. Here are some examples of my views on the question:
1 During the last century, the earth warmed slightly (less than 1°C).
2 The earth has generally cooled over the last 12,000 years. We are currently at the cold end of the Holocene (the period since the end of the last Ice Age. See the  Greenland and  Vostok ice records.
3 The earth has generally warmed since the depths of the Little Ice Age around 1650, at a rate somewhere around a half a degree Celsius per century. See  Akasufo, the  Central England Temperature (CET), and the  Armagh records.
4 The largest warming in any instrumental record occurred around 1680 – 1730. See the CET and Armagh records.
5 The earth was either stable or cooled slightly from about 1945 to 1975.
6 The earth warmed slightly from about 1975 to 1998.
7 There has been no significant warming from 1995 to the present (Feb. 2010). See  The Reference Frame,  Phil Jones.
I would say that there is widespread scientific agreement on the existence of these general trends. The amount of the warming, however, is far less certain. There is current controversy about both the accuracy of the adjustments to the temperature measurements and the strength of local effects (UHI, poor station siting, warmth from irrigation, etc.). See e.g.  McKitrick,  Spencer,  Christy and Norris,  Ladochy et al..,  Watts,  SurfaceStations, and  Jones on these questions.
Question 5. Are humans responsible for global warming?
This is another trick question that often shows up on polls. The question suffers from two problems. First is the lack of a time period discussed above. The second is the question of the amount of responsibility. Generally, the period under discussion is the post-1900 warming. So let me rephrase the question as “Are humans responsible for some part of the late 20th century warming?”
To this question I would say “Yes”. Again, there is widespread scientific agreement on that simplistic question, but as usual, the devil is in the details discussed in Question 4.
Question 6. If the answer to Question 5 is “Yes”, how are humans affecting the climate?
I think that humans affect the climate in two main ways. The first is changes in land use/land cover, or what is called “LU/LC”. I believe that when you cut down a forest, you cut down the clouds. This mechanism has been implicated in e.g. the decline in the Kilimanjaro Glacier. When you introduce widespread irrigation, the additional water vapor both warms and moderates the climate. When you pave a parking lot, local temperatures rise. See e.g.  Christie and Norris,  Fall et al.,  Kilimanjaro.
The second main way humans affect climate is through soot, which I will broadly define as black and brown carbon. Black carbon comes mostly from burning of fossil fuels, while brown carbon comes mostly from the burning of biofuels. This affects the climate in two ways. In the air, the soot absorbs incoming solar radiation, and prevents it from striking the ground. This reduces the local temperature. In addition, when soot settles out on ice and snow, it accelerates the melting of the ice and snow. This increases the local temperature by reducing the surface albedo. See e.g.  Jacobson.
There is little scientific agreement on this question. A number of scientists implicate greenhouse gases as the largest contributor. Other scientists say that LU/LC is the major mover. The IPCC places values on these and other so-called “forcings”, but it admits that our scientific understanding of many of forcings is “low”.
Question 7. How much of the post 1980 temperature change is due to human activities?
Here we get into very murky waters. Is the overall balance of the warming and cooling effects of soot a warming or a cooling? I don’t know, and there is little scientific agreement on the effect of soot. In addition, as shown above there is no indication that the post 1980 temperature rise is in any way unusual. It is not statistically different from earlier periods of warming. As a result, I believe that humans have had little effect on the climate, other than locally. There is little scientific agreement on this question.
Next, some more general and theoretical questions.
Question 8. Does the evidence from the climate models show that humans are responsible for changes in the climate?
This is another trick question. Climate models do not produce evidence. Evidence is observable and measurable data about the real world. Climate model results are nothing more than the beliefs and prejudices of the programmers made tangible. While the results of climate models can be interesting and informative, they are not evidence.
Question 9. Are the models capable of projecting climate changes for 100 years?
My answer to this is a resounding “no”. The claim is often made that it is easier to project long-term climate changes than short-term weather changes. I see no reason to believe that is true. The IPCC says:
“Projecting changes in climate due to changes in greenhouse gases 50 years from now is a very different and much more easily solved problem than forecasting weather patterns just weeks from now. To put it another way, long-term variations brought about by changes in the composition of the atmosphere are much more predictable than individual weather events.” [from page 105, 2007 IPCC WG1, FAQ 1.2]
To me, that seems very doubtful. The problem with that theory is that climate models have to deal with many more variables than weather models. They have to model all of the variables that weather models contain, plus:
• Land biology
• Sea biology
• Ocean currents
• Ground freezing and thawing
• Changes in sea ice extent and area
• Aerosol changes
• Changes in solar intensity
• Average volcanic effects
• Snow accumulation, area, melt, and sublimation
• Effect of melt water pooling on ice
• Freezing and thawing of lakes
• Changes in oceanic salinity
• Changes in ice cap and glacier thickness and extent
• Changes in atmospheric trace gases
• Variations in soil moisture
• Alterations in land use/land cover
• Interactions between all of the above
• Mechanisms which tend to  maximise the sum of work and entropy according to the Constructal Law.
How can a more complex situation be modeled more easily and accurately than a simpler situation? That makes no sense at all.
Next, the problem with weather models has been clearly identified as the fact that weather is chaotic. This means that no matter how well the model starts out, within a short time it will go off the rails. But the same is true for climate, it is also chaotic. Thus, there is no reason to assume that we can predict it any better than we can predict the weather. See  Mandelbrot on the chaotic nature of climate.
Finally, climate models have done very poorly in the short-term. There has been no statistically significant warming in the last fifteen years. This was not predicted by a single climate model. People keep saying that the models do well in the long-term … but no one has ever identified when the changeover occurs. Are they unreliable up to twenty-five years and reliable thereafter? Fifty years?
Question 10. Are current climate theories capable of explaining the observations?
Again I say no. For example, the prevailing theory is that forcing is linearly related to climate, such that a change of X in forcing results in a change of Y in temperature. The size of this temperature change resulting from a given forcing is called the “climate sensitivity”. In 1980, based on early simple computer climate models, the temperature resulting from a change in forcing of 3.7 watts per square meter (W/m2) was estimated to result in a temperature change of between 1.5 and 4.5 degrees Celsius. See e.g.  Green and Armstrong  2007.
Since 1980, there has been a huge increase in computing power. Since 1980, there has also been a huge increase in the size and complexity of computer models. Since 1980, thousands of man hours and billions of dollars have been thrown at this question. Despite these advances, the modern estimate of the climate sensitivity is almost unchanged from its 1980 value.
To me, this lack of any advance in accuracy indicates that we have an incorrect understanding of the forces governing the climate. Otherwise, our bigger, faster and better models would have narrowed the uncertainty of the climate sensitivity. But they have not.
Question 11. Is the science settled?
To this one I would answer no, no, a thousand times no. We are just a the beginning of the study of climate. New information and new theories and new forcings are put forward on a regular basis. See e.g.  Lu. The data is poor, short, and full of holes. The signal is tiny and buried in a huge amount of noise. We don’t know if the earth has a thermostat. In short, the study of climate is an infant science which is still poorly understood.
Question 12. Is climate science a physical science?
Well, sort of. It is a very strange science, in that to my knowledge it is the only physical science whose object of study is not a thing, not a physical object or phenomenon, but an average. This is because climate is defined as the average of weather over a suitably long period of time (usually taken to be 30 years.) The implications of this are not widely appreciated. Inter alia, it means that statistics is one of the most important parts of climate science.
Unfortunately, a number of what I might call the “leading blights” of climate science, like Michael Mann with his HockeySchtick, have only the most rudimentary understanding of statistics. This initially got him into trouble in his foray into the area of paleoclimate statistics, trouble which he has only compounded by his later statistical errors.
Question 13. Is the current peer-review system inadequate, and if so, how can it be improved?
There are a number of problems with the current peer-review system, some of which are  highlighted in the abuses of that system  revealed in the CRU emails.
There are several easy changes we could make in peer review that would help things immensely:
1. Publish the names of the reviewers and their reviews along with the paper. The reviews are just as important as the paper, as they reveal the views of other scientists on the issues covered. This will stop the “stab in the back in the dark” kind of reviewing highlighted in the CRU emails.
2. Do not reveal the names of the authors to the reviewers. While some may be able to guess the names from various clues in the paper, the reviews should be “double-blind” (neither side knows the names of the others) until publication.
3. Do the reviewing online, in a password protected area. This will allow each reviewer to read, learn from, and discuss the reviews of others in real time. The process often takes way too long, and consists of monologues rather than a round-table discussion of the problems with the paper.
4. Include more reviewers. The CRU emails show that peer review is often just an “old-boys club”, with the reviewing done by two or three friends of the author. Each journal should allow a wide variety of scientists to comment on pending papers. This should include scientists from other disciplines. For example, climate science has suffered greatly from a lack of statisticians reviewing papers. As noted above, much of climate science is statistical analysis, yet on many papers either none or only the most cursory statistical review has been done. Also, engineers should be invited to review papers as well. Many theories would benefit from practical experience. Finally, “citizen scientists” such as myself should not be excluded from the process. The journals should solicit as wide a range of views on the subject as they can. This can only help the peer review process.
5. The journals must insist on the publication of data and computer codes. A verbal description of what mathematics has been done is totally inadequate. As we saw in the “HockeyStick”, what someone thinks or says they have done may not be what they actually did. Only an examination of the code can reveal that. Like my high science teacher used to say, “Show your work.”
Question 14. Regarding climate, what action (if any) should we take at this point?
I disagree with those who say that the “precautionary principle” means that we should act now. I detail my reasons for this assertion at “Climate Caution and Precaution”.  At that page I also list the type of actions that we should be taking, which are “no regrets” actions. These are actions which will have beneficial results whether or not the earth is warming.
So that is where I stand on the climate questions. I think that the earth actively maintains a preferred temperature. I think that man is having an effect on local climate in various places, but that globally man’s effect is swamped by the regulating action of clouds and thunderstorms. I think that the local effect is mainly through LU/LC changes and soot. I think that the climate regulating mechanism is much stronger than either of these forcings and is stronger than CO2 forcing. I think that at this point the actions we should take are “no regrets” actions.
Does that make me a “denier”? And if so, what am I denying?
Finally, I would like to invite Dr. Judith Curry in particular, and any other interested scientists, to publicly answer these same questions here on Watts Up With That. There has been far too much misunderstanding of everyone’s position on these important issues. A clear statement of what each of us thinks about the climate and the science will go a long way towards making the discussion both more focused and more pleasant, and perhaps it will tend to heal the well-earned distrust that many have of climate science.




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c8db2db',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**England enters a tougher version of its three tier system of restrictions on Wednesday, as a four-week lockdown ends.**
Northern Ireland has a two-week circuit-breaker lockdown, while Wales is banning the sale of alcohol in pubs, cafes and restaurants from Friday. Scotland has its own five-tier system.
Across the UK, some restrictions will be relaxed over Christmas, to allow three households to form a ""Christmas bubble"".
From just after midnight on Wednesday 2 December, areas will be placed in one of three tiers: medium, high and very high.
About 99% of England has been placed into the high and very high coronavirus risk category - tiers two and three.
The placing of areas in each tier will be reviewed every 14 days, with the first review on 16 December.
**Areas in tier two**
**Tier two (high) rules**
**Areas in tier three**
**Tier three (very high) rules**
Additional restrictions apply:
**Areas in tier one**
Only three areas have been placed in the lowest tier:
**Tier one (medium) rules**
Areas in the lowest tier will have some restrictions relaxed:
There are exceptions in all tiers for childcare and support bubbles. More details of the plan are here.
The new coronavirus tier restrictions will mean 55 million people will be banned from mixing with other households indoors. The decision about which tier to place an area in is based on:
Lockdown restrictions in Wales were eased on 9 November.
**The current rules say:**
People who you don't live with still cannot come into your home socially, unless you are in an extended household (bubble) with them. Tradespeople can enter your home to carry out work.
However, from **Friday 4 December:**
Read Wales' official guidance.
Northern Ireland started a two-week circuit-breaker lockdown from 00:01 GMT on Friday 27 November.
Read Northern Ireland's official guidance.
Each area of Scotland has been placed in one of five tiers.
Eleven local authority areas in west and central Scotland have recently moved from level three to level four, affecting two million people.
First Minister Nicola Sturgeon told MSPs the level four measures would be lifted at 18:00 GMT on Friday 11 December.
**Areas in level zero**
No areas have been placed in the lowest tier.
**Level zero (nearly normal) rules**
**Areas in level one**
**Level one (medium) rules**
Additional restrictions apply:
**Areas in level two**
**Level two (high) rules**
Additional restrictions apply:
**Areas in level three**
**Level three (very high) rules**
Additional restrictions apply:
**Areas in level four**
**Level four (lockdown) rules**
Additional restrictions apply:
Schools stay open in all levels, and here must also be no non-essential travel between Scotland the rest of the UK.
**Do you meet other people for exercise? Have you been out walking during the November lockdown? You can share your experiences by emailing**haveyoursay@bbc.co.uk **.**
Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways:"
"

Some of my favorite conservative commentators appear dismayed that the White House and press paid little attention to news that “Coalition forces have recovered approximately 500 weapons munitions [in Iraq] which contain degraded mustard or sarin nerve agent.” 



That item came from a one‐​page memo by John D. Negroponte, director of national intelligence, sent to placate Michigan Rep. Peter Hoekstra, chairman of the House Intelligence Committee. Pennsylvania Sen. Rick Santorum also got involved. Along with many Republican enthusiasts, they believe the president should stand up and shout: “See, I _told_ you so. Saddam really did have weapons of mass destruction!”



L. Brent Bozell III, the persuasive president of the Media Research Center, complained that major newspapers buried this story. Yet the media could not possibly have done that if the administration had trumpeted the news. Mr. Bozell suspects that “Team Bush” has been silenced “out of intimidation by the media.” Not likely. 



First, finding those 500 artillery shells was not much of a surprise. My column last November, “No Intelligence,” critiqued the 2002 CIA report about weapons of mass destruction (WMD) in Iraq. Among few concrete facts within that otherwise slippery report, I remarked, was that “Iraq has not accounted for … about 550 artillery shells filled with mustard agent.” 



That information came from the vilified U.N. Monitoring, Verification and Inspection Commission (UNMOVIC). I did not doubt such artillery shells might be left over from the 1991 Iraq war. But, I asked, how anyone could “actually imagine that terrorists could simply… fire artillery shells from cannons on U.S. streets?” 



Heavy artillery shells are battlefield weapons — not something easily hidden in terrorist suitcases. A 155‐​millimeter shell is more than 6 inches in diameter and requires a cannon 10 feet to 12 feet long. A mere tank will not suffice to launch such shells. A 155‐​millimeter German howitzer weighs 55 tons. 



The Negroponte memo concerns “Iraq’s filled and unfilled pre‐​Gulf war chemical munitions.” This refers to “sarin‐ and mustard‐​filled projectiles,” meaning 155‐​millimeter artillery shells. “While agents degrade over time,” the memo continues, “chemical warfare agents remain hazardous and potentially lethal.”



Most chemicals are hazardous waste. But “potentially lethal” could mean anything, including swallowing a pound of the stuff. The nerve gas sarin can certainly be lethal if it is fresh and nearby. Sarin was used in a 1995 terrorist attack on the Tokyo subway system that killed 12 and in a 1994 attack that killed seven in Matsumoto, Japan. 



Nineteen deaths are as close to “mass destruction” as the world has seen from terrorist use (as opposed to battlefield use) of chemical or biological agents. Yet sarin degrades very quickly. UNMOVIC concluded years ago it would be “unlikely that (Iraq’s sarin‐​filled munitions) would still be viable today.” 



What about the heavy artillery shells filled with old “mustard gas” (sulfur mustard)? That is hazardous waste material, to be sure — anyone who opened those shells without the proper gloves would still be badly blistered. But it is a highly unlikely weapon of mass destruction, particularly in this form at this late date. 



In 2000, the Federal Emergency Management Agency reported: “The United States Congress has directed that the U.S. Army destroy certain kinds of chemical weapons stockpiled at eight U.S. Army installations in the continental United States over the next several years. Experts believe the chance of an accident involving these obsolete chemical munitions is remote.” The U.S. quietly got rid of its obsolete sulfur mustard by February 2005 without any risk of mass destruction. 



Sulfur mustard is commonly called “mustard gas,” but it is neither mustard nor a gas. It is liquid at temperatures above 58 degrees Fahrenheit and called “mustard” because of its odor and color. It causes blisters and is potentially harmful to the lungs and eyes (which is why infantry carry gas masks). 



According to the Centers for Disease Control: “Exposure to sulfur mustard is usually not fatal. When sulfur mustard was used during World War I, it killed fewer than 5 percent of the people who were exposed and got medical care.” Most estimates of lethality range from 1 percent to 3 percent. 



Sulfur mustard inside Iraq’s old heavy artillery shells was a battlefield weapon. Its strategic value might have been to slow opposing troops by forcing them to wear protective suits and gas masks in Iraq’s extremely hot climate. 



Artillery shells of any sort are not terrorist weapons, but shells filled with conventional explosives are far deadlier than those with sulfur mustard. Any degraded sulfur mustard left inside such shells would be very difficult to remove without destroying the chemical agent (and the person doing the removal).



The reason sulfur mustard was banned by the Geneva Convention in 1925 was not because it was lethal (it is far less lethal than legal explosives), but because blistering caused extreme pain and sometimes blindness. 



The concept of antique mustard gas as some awesome new “weapon of mass destruction” appears traceable to an oft‐​repeated story about Kurdish deaths due to other causes (including sarin). The Council on Foreign Relations Web site says: “Saddam Hussein used mustard gas on the Kurds. … The worst attack occurred in March 1988 in the Kurdish village of Halabja; a combination of chemical agents including mustard gas and sarin killed 5,000 people.” Yet the October 2002 CIA report claimed only “hundreds” of casualties at Halabja and said the intended targets were Iranians. 



The Negroponte memo purports to be worried that “pre‐​Gulf war Iraqi chemical weapons could be sold on the black market. Use of these weapons by terrorists or insurgent groups would have implications for Coalition forces in Iraq. The possibility of use outside Iraq cannot be ruled out.” 



This is the same sort of devious “what if” conjecture that filled the 2002 CIA report. We cannot rule out the possibility aliens in flying saucers are about to take over the Earth. And we cannot rule out the possibility unicorns really do exist.



In reality, any “use of these weapons (artillery shells) by terrorists or insurgent groups” would require their possession of 55‐​ton self‐​propelled howitzers. Can you imagine finding one of those heavily armed vehicles cruising around unnoticed in Baghdad, much less in New York City? Even if terrorist could fire heavy artillery shells in either city, why would they want them filled with something that causes blisters much more often than death? 



The president was judicious to downplay this nonstory about finding a few hundred heavy artillery shells filled with pre‐​1991 sulfur mustard. To have done otherwise could have proved very embarrassing. His conservative critics would likewise be wise to drop it.
"
"On 27 June 2019, the energy and clean growth minister Chris Skidmore signed papers that committed the UK to reduce carbon emissions to effectively nothing by 2050. If we are to stand any chance of meeting this target, known as “net zero”, there is one enormous challenge that we will have to tackle: home heating. Warming our homes is responsible for between a quarter and a third of the UK’s greenhouse gas emissions. That’s more than 10 times the amount of CO2 created by the aviation industry. Around 85% of homes now use gas-fired central heating, and a large proportion of gas cooking still takes place. Greening this system is a huge challenge by any measure. But if recent reports are to be believed, there could be a simple and efficient way to do it: change from using natural gas to hydrogen gas.  Hydrogen is abundant in the natural world and according to its advocates could power the next generation of gas appliances cleanly and efficiently. “The attraction of hydrogen is that for a lot of consumers, they wouldn’t notice any difference. Customers would continue to use a boiler to heat their homes in a similar manner to natural gas,” says Robert Sansom of the Institution of Engineering and Technology’s energy policy panel. He is the lead author on a study conducted by the institute called Transitioning to Hydrogen. Together with colleagues, Sansom assessed the engineering risks and uncertainties associated with swapping our gas network to hydrogen. Their conclusion is that there is no reason why repurposing the gas network to hydrogen cannot be achieved. That’s not to say it would be easy, though. Technological and practical hurdles exist because there is no blueprint for such a conversion: there is nowhere in the world that supplies pure hydrogen to homes and businesses. The UK would have to pioneer everything. Interest in hydrogen as a way to heat homes began in 2016 with a report called H21. It was conducted by Northern Gas Networks, the gas distributor for the north of England, and looked at whether it was technically possible and economically viable to convert Leeds to 100% hydrogen instead of natural gas. “They went into a lot of detail, from the hydrogen production plants right the way down to people’s homes,” says Sansom. The report drew a parallel to the way the gas industry converted from town gas to natural gas in the 1960s and 70s. Town gas was a combination of hydrogen, carbon monoxide and methane. It was mostly produced from the distillation of coal and oil and had been used for the first 150 years of the UK’s gas industry. With the discovery of natural gas in the North Sea, which is predominantly methane, the UK undertook a nationwide programme to convert 40m appliances over a decade. Whole streets would be converted at a time. Engineers would inspect the gas appliances, and then convert them. Simultaneously, the town gas was disconnected and the pipelines were purged with an inert gas. Finally, the natural gas was pumped into the system and the engineers would make sure each appliance worked correctly before moving to the next street along. Some manufacturers are now so convinced that a similar thing can happen with hydrogen that they have already begun to develop new household appliances. In February, Worcester Bosch unveiled the prototype of its hydrogen-ready boiler. It would run first on natural gas and then, after a servicing visit, hydrogen. Also working in hydrogen’s favour is that for the past 20 years, the gas industry has been systematically replacing the metal pipes in its “iron mains” network with yellow polyethylene ones. Around 90% of the pipes will have been replaced by 2030. This is good news for hydrogen because the gas reacts with the old metal pipes, making them brittle. But the polyethylene is safe. “Effectively we started a programme of hydrogen-proofing our gas network without knowing we were doing it,” says Sansom, who found himself becoming more and more impressed by the concept. “From a personal point of view, I was very much on the fence when I kicked off with this work. But I found myself slipping down on the hydrogen side in terms of its viability as a low carbon alternative to natural gas,” he says. But not everyone is convinced by this sudden interest in hydrogen. Richard Lowes of the University of Exeter Energy Policy Group says that until recently the received wisdom had been that heating would have to be electrified in some way to meet our climate-crisis commitments. “That has basically come out of years and years of technical and economic modelling to look at how you get to fully decarbonised heating in the UK,” says Lowes. Switching heating from gas to electricity would mean relying on heat pumps. These use electricity to extract heat from either the air or the ground. In the case of an air source heat pump, it works like a fridge but instead of sucking heat out of a food compartment, it pulls it out of the air and channels it into the home, where it is used to heat water, which is piped to radiators for central heating, and stored in a tank for hot water. But because this technology works at a lower temperature than existing boilers, it requires many homes to be much better insulated, or to have larger radiators, capable of delivering more heating power. For those who have switched to heat-as-you-go combi boilers, it will necessitate the reinstallation of a hot water tank. It’s extensive work but worth it, according to Lowes, who has removed his own gas boiler and is now using an air source heat pump to heat his home. “It was a lot of work but my home and heating system are now a lot more efficient. It’s always warm, there’s always hot water and it’s basically the same cost to run as gas,” he says. The third approach is called district heating. It envisages water being heated at a central facility using waste heat from industry or green sources such as solar power. The hot water is then delivered to many homes simultaneously through a network of heavily insulated underground pipes. Both methods can significantly reduce the carbon footprint of home heating but the downside is that they require extensive work to roll them out on a national scale. District heating would require water pipes to be laid under homes, and the widespread use of heat pumps would necessitate the National Grid’s electricity circuits being upgraded. It is this kind of disruption that hydrogen’s advocates say could be avoided because much of the national infrastructure has already been upgraded. That argument cuts no ice with Lowes. “It seems a bit hypocritical for the gas industry to say we can’t dig up the roads when they’ve been doing it for the past 20 years,” he says. He points out that although the consumer may not experience so much disruption, significant challenges for the gas industry remain. For example, the National Transmission System, which is the network of pipes that supplies gas from the coastal terminals to the gas distribution companies and other major users, is made of metal. This would need to be protected from embrittlement in some way before any switch to hydrogen could take place. “Hydrogen is certainly not a silver bullet,” says Lowes. And if we get distracted by it, we could be getting ourselves into more trouble, missing the 2050 energy target altogether. But if there is so much uncertainty with hydrogen, why is the gas industry, which funds many of the studies, pushing it so hard? According to Chris Goodall, energy economist and author of What We Need to Do Now for a Zero Carbon Future, it is a matter of survival. “They do not wish for their industry to be eaten up by a switch to electricity for heating. So they are moving as fast as they can to persuade us about hydrogen,” he says. And it all comes down to how the gas is produced. Hydrogen is not found on Earth in a pure state. Instead, it has to be extracted from other substances, and the best one to extract it from is methane – in other words natural gas. Hence, the gas companies could effectively keep their current operations running. But the extra steps involved in extracting the hydrogen would push the price up. Additionally, the extraction creates carbon dioxide as a byproduct, so large scale carbon capture technology would need to be developed to prevent it escaping into the atmosphere. Although this is a technology that the UK will have to develop anyway in order to reach net zero by 2050, it will add to the cost. But natural gas is not the only substance that contains hydrogen. Water does too, and the hydrogen can be freed by a process called electrolysis, which doesn’t create any carbon dioxide. To make it totally green, which is the ultimate hope, electrolysis could be powered by wind farms. At the moment, however, the price of such electricity is expensive, and that would push the price of hydrogen up still further. Goodall hopes that the cost will decrease as technology improves, but warns: “You can be accused of mindless optimism just by saying this.” The UK’s future energy landscape is without doubt a difficult realm to navigate. Perhaps the best route will be revealed by not pitting the various solutions against one another. “All three have strengths and weaknesses and I expect that there’ll be a major role for each as a replacement for natural gas,” says Sansom. Even hydrogen’s detractors acknowledge this. “As a niche technology it can have real value,” says Lowes. He goes on to paraphrase the Heineken lager adverts of the 70s and 80s, saying that hydrogen could potentially reach the parts of the country that other energy solutions can’t. Goodall also sees a role for hydrogen to “store” energy generated from renewable resources such as wind and solar power. The idea is that in windy months, any extra electricity generated from renewables will be used to make hydrogen, which would then be stored. When there is extra demand on the National Grid, or a seasonal drop in the power produced from renewables, the hydrogen can be burned to produce electricity. The truth is that all options for us to decarbonise our heating systems will require significant disruption and cost. And while government continues to deliberate, the clock ticks towards 2050. “There is no need to wait. We can deploy stuff now that works fine,” says Lowes, referring to his own experience of changing his gas boiler for a heat pump. “The urgency of climate change means there really isn’t any reason to delay.” Others believe that there is a role for hydrogen and think it is worth taking a little more time to consider. But there is one truth that everyone agrees upon. “None of this is easy. If anyone is saying to you this is easy, they are misleading you,” says Lowes. Hydrogen can also power vehicles, but in a different way than it would heat houses. Instead of being burned, the hydrogen reacts with oxygen inside a device called a fuel cell. Electricity and water are produced. The electricity runs the car, the water drips from the exhaust pipe.An attempt to switch to hydrogen vehicles in the 1990s was thwarted byelectric cars, which store their energy in an onboard battery. But a new push for hydrogen vehicles is coming from Asia. China, Japan and South Korea have all set ambitious goals to have millions of hydrogen-powered vehicles on their roads by 2030.Toyota and Hyundai are both offering hydrogen vehicles in the UK, but there are currently less than 20 hydrogen filling stations across the UK, mostly clustered around the M25.“It will be really interesting to see what happens,” says Lowes. But he himself is not convinced: “Hydrogen is much more expensive than electricity, and the car is more expensive than the electric vehicle.”"
"
This press release is brought to you by our friends at the National Science Foundation, it is not a joke. However, it is too odd not to spoof a bit.
Here are some preliminary results, there’s more at the end of this article.
How to interpret this related to ""weather, not climate"": hail is imminentPress Release 10-243
Broken Glass Yields Clues to Climate Change

 
Ordinary drinking glasses and atmospheric dust particles break apart in similar patterns




The comparative sizes of dust particles in the atmosphere, from a dust storm satellite photo.
Credit and Larger Version



December 27, 2010
Clues to future climate may be found in the way an ordinary drinking glass shatters.
Results of a study published this week in the journal Proceedings of the National Academy of Sciences find that microscopic particles of dust can break apart in patterns  that are similar to the fragment patterns of broken glass and other  brittle objects.

The research, by National Center for Atmospheric  Research (NCAR) scientist Jasper Kok, suggests there are several times  more dust particles pumped into the atmosphere than previously believed,  since shattered dust appears to produce an unexpectedly high number of  large fragments.
The finding has implications for understanding  future climate change because dust plays a significant role in  controlling the amount of solar energy in the atmosphere.
Depending  on their size and other characteristics, some dust particles reflect  solar energy and cool the planet, while others trap energy as heat.
“As  small as they are, conglomerates of dust particles in soils behave the  same way on impact as a glass dropped on a kitchen floor,” Kok says.  “Knowing this pattern can help us put together a clearer picture of what  our future climate will look like.”
The study may also improve  the accuracy of weather forecasting, especially in dust-prone regions.  Dust particles affect clouds and precipitation, as well as temperature.
“This  research provides valuable new information on the nature and  distribution of dust aerosols in the atmosphere,” says Sarah Ruth,  program director in the National Science Foundation (NSF)’s Division of  Atmospheric and Geospace Sciences, which funds NCAR.
“The results may lead to improvements in our ability to model and predict both weather and climate.”
Kok’s research focused on a type of airborne particle known as mineral dust.
These particles are usually emitted when grains of sand are blown into soil, shattering dirt and sending fragments into the air.
The fragments can be as large as about 50 microns in diameter, or about the thickness of a fine strand of human hair.
The  smallest particles, which are classified as clay and are as tiny as 2  microns in diameter, remain in the atmosphere for about a week, circling  much of the globe and exerting a cooling influence by reflecting heat  from the Sun back into space.
Larger particles, classified as  silt, fall out of the atmosphere after a few days. The larger the  particle, the more it will tend to have a heating effect on the  atmosphere.
Kok’s research indicates that the ratio of silt  particles to clay particles is two to eight times greater than  represented in climate models.
Since climate scientists carefully  calibrate the models to simulate the actual number of clay particles in  the atmosphere, the paper suggests that models most likely err when it  comes to silt particles.
Most of these larger particles swirl in  the atmosphere within about 1,000 miles of desert regions, so adjusting  their quantity in computer models should generate better projections of  future climate in desert regions, such as the southwestern United States  and northern Africa.
Additional research will be needed to  determine whether future temperatures in those regions will increase as  much or more than currently indicated by computer models.
The  study results also suggest that marine ecosystems, which draw down  carbon dioxide from the atmosphere, may receive substantially more iron  from airborne particles than previously estimated.
The iron enhances biological activity, benefiting ocean food webs, including plants that take up carbon during photosynthesis.
In  addition to influencing the amount of solar heat in the atmosphere,  dust particles also are deposited on mountain snowpacks, where they  absorb heat and accelerate snowmelt.
Physicists have long known  that certain brittle objects, such as glass, rocks, or even atomic  nuclei, fracture in predictable patterns. The resulting fragments follow  a certain range of sizes, with a predictable distribution of small,  medium, and large pieces.
Scientists refer to this type of pattern as scale invariance or self-similarity.
Physicists  have devised mathematical formulas for the process by which cracks  propagate in predictable ways as a brittle object breaks.
Kok  theorized that it would be possible to use these formulas to estimate  the range of dust particle sizes. By applying the formulas for fracture  patterns of brittle objects to soil measurements, Kok determined the  size distribution of emitted dust particles.
To his surprise, the formulas described measurements of dust particle sizes almost exactly.
“The  idea that all these objects shatter in the same way is a beautiful  thing, actually,” Kok says. “It’s nature’s way of creating order in  chaos.”
-NSF-
==============================================================
Here are other ways to use broken glass to forecast and interpret your local climate issues:
Your Computer Climate Model is broken
The Arctic Sea Ice is ""rotten""
AGW is increasing the number of spiders globally
Solar minimum ahead -OR- your state is banning the bulb
Mercury vapor poisoning ahead
Your car is causing climate disruption
A drought is almost certain (95% confidence limit)
The climate gods are angry
﻿
The Goreacle is angry. Why aren't you listening ?!


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e869597bd',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterAwhile back I wrote about the climate alarmists’ latest tactic to get people scared about climate change – i.e., make it look like it’s a serious threat to public health.
Hat-tip: DirkH
Der Spiegel has wasted little time and has immediately pounced on the new paper appearing in Nature Climate Change, by Austin et al, which boldly claims man-made global warming “is reshaping the distribution of infectious disease across global scales”.
The authors illustrate possible associations between environmental changes in the Baltic area and the recent emergence of Vibrio infections. They also forecast future scenarios of the risk of infections with predicted warming trends. The authors don’t beat around the bush, implying that the Baltic, because it warmed 0.063–0.078 °C yr from 1982 (a cold time) to 2010 (a warm time), sea surface temperatures there may rise 7°C per century!
How scientific is that? The stock market went up 200 points last week, and so does that mean it will rise 10,000 points over the next year? Of course not. The silly extrapolation the authors imply reveals their true intent: to fan public fear. This paper is hardly above tabloid trash as far as quality goes.
Moreover, the authors think that 29 years of data (half a PDO or AMO oscillation) are enough to make a quantum leap of faith and to conclude:
This is among the first empirical evidence that anthropogenic climate change is driving the emergence of Vibrio disease in temperate regions through its impact on resident bacterial communities, implying that this process is reshaping the distribution of infectious diseases across global scales.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




That is just plain stupid. Where’s the science? What would these scientists think if we told them that CO2 and global temperature haven’t correlated in 15 years?
Of course the somewhat obviously dimwitted journalist at Der Spiegel took it in, hook, line and sinker. Der Spiegel warns:
Already more and more people are being infected in warm summers by Vibrio vulnificus, a contagion for wounds, diarrhea and blood poisoning an international team of scientists reported in “Nature Climate Change”. Also the very closely related Cholera bacterium , Vibrio Cholerae, is on the march.
During the extremely warm summers of 1994, 2003 and 2006 at the Baltic Sea coast, there were numerous reports of infected wounds and cases of Cholera. Alone in 2006, 67 people became infected while bathing or doing water sports; some even died.”
The authors add that the number of Vibrio infections will increase significantly, if the warming continues. Note there’s no mention that there’s been no real outbreak since 2006.
The authors also warn that more than 30 million people live near the Baltic Sea coast and that they, and cities like Stockholm and St. Petersburg, are all threatened.
So readers, you are urged to cancel your Baltic holidays and to spend them somewhere else – like the good old Mediterranean, where water temperatures are about 10°C warmer.
 
Share this...FacebookTwitter "
"**Christmas ""bubbles"" of three households in Scotland should contain no more than eight people over the age of 11, the Scottish government has said.**
The rule is part of the government's guidance for Christmas which temporarily relaxes some Covid-19 restrictions for five days.
Children under the age of 12 will not count towards the total number of people in the bubble.
The easing of Covid rules will apply across the UK from 23 to 27 December.
Opposition parties have accused the Scottish government of sending out ""mixed messages"" by allowing people to meet at Christmas while simultaneously urging them not to do so.
And many health experts have warned that the move is likely to lead to a spike in cases of the virus - and potentially deaths - in January
UK government guidance for people in England does not set a limit on the number of people in a bubble, but says this should be kept ""as small as possible"".
No separate guidance has been published for Wales or Northern Ireland at this stage, although people can travel to or from Northern Ireland on 22 and 28 December. The NI executive is meeting on Thursday to discuss the rules.
A UK-wide deal was agreed on Tuesday to permit people to meet up in ""bubbles"" over the festive period.
Travel restrictions will be lifted across all four nations from 23 to 27 December so people can visit close friends and relatives.
But Scotland's First Minister Nicola Sturgeon has that said the ""default advice"" and ""safest position"" was still that people should avoid contact.
The Scottish guidance states that the ""safest way to spend Christmas and the festive period is to stay within your own household, in your own home and your own local area"".
It adds: ""Wherever possible you should keep in touch with friends and family members from other households through technology - or, if you decide to meet in person, you should minimise the numbers and duration, and if possible meet out of doors.
""Consider a Christmas walk with family, rather than a meal indoors.""
Although three households will be allowed to meet indoors and stay overnight in the same home, the Scottish government says a two-metre distance should be kept between people from different households.
However, children under 12 will be exempt from the physical distancing rules.
Other guidance for different households staying in the same home includes:
Doors and windows should also be opened to let in as much fresh air as possible during and after visits.
Christmas bubbles in Scotland can only gather in a private home, outdoors or at a place of worship.
They will not be allowed to visit pubs, restaurants or go to shops together and staying in tourist accommodation as a group is banned as well.
Single households should also not travel in or out of level three or level four areas in Scotland to use tourist accommodation, the guidance says.
Scottish Greens co-leader Patrick Harvie highlighted warnings from public health experts that the easing of restrictions over Christmas was likely to lead to a third wave of infections, hospitals being overrun, more ""unnecessary"" deaths and potentially a nationwide lockdown in January.
Speaking in the Holyrood chamber, Mr Harvie also questioned why the Scottish government had apparently not carried out any risk assessments on the potential impact of easing the restrictions.
He added: ""I recognise that there were difficult judgements to make about relaxing the Covid rules over the holidays, especially after public expectations had been built up.
""But within a day of announcing the looser rules, the first minister is appealing to the public not to use them. It's a confusing message.""
**Use the form below to send us your questions and we could be in touch.**
_ **In some cases your question will be published, displaying your name and location as you provide it, unless you state otherwise. Your contact details will never be published. Please ensure you have read the terms and conditions.**_
If you are reading this page on the BBC News app, you will need to visit the mobile version of the BBC website to submit your question on this topic."
"
Share this...FacebookTwitterProphetic revelations of disturbing end of world visions…
PIK Makes The Ice Melt Away
By Meteorologist Klaus Eckart Puls
(Translated, condensed by P Gosselin)
The Potsdam Institute for Climate Impact Research (PIK) and the Universidad Complutense de Madrid recently came out with computer-model generated scenarios showing that Greenland would melt away [1]. This scenario of course was all designed to produce spectacular headlines of a coming apocalypse for the media. And that, it did. The PIK study contained the following core statement:
Here, using a fully coupled model, we show that this criterion systematically overestimates the temperature threshold and that the Greenland ice sheet is more sensitive to long-term climate change than previously thought. We estimate that the warming threshold leading to a monostable, essentially ice-free state is in the range of 0.8–3.2°C, with a best estimate of 1.6°C ” … For 2.0°C regional summer warming, which is just above the deglaciation threshold in the representative case, complete melting of the GIS takes about 50,000 years. In contrast, with warming of 4,0°C, the ice sheet needs about 8,000 years to melt completely, and for warming of 8°C, 20% of the ice sheet melts in just 500 years and the entire ice sheet melts within about 2,000 years.”
All of this is based on a model – written up to produce a desired result. And from the desired model results, the scientists concluded:
Therefore, if anthropogenic CO2 emissions in the coming century drive the temperature considerably above the deglaciation threshold, irreversible total loss of the GIS will be difficult to avoid, ensuring continued substantial sea-level rise for millennia.”
The PIK press release even went so far to claim that their scenarios for the future are likely spot on:
The Model has proven that it can not only correctly calculate today’s observed ice cover, but also its development all the way back to the last ice age. That’s why the simulation is also trusted to correctly estimate the future. All this makes the new estimations more reliable than the previous.”
So this produces the impression that anthropogenic CO2 leads to continued warming with the catastrophic consequences for Greenland ice and sea level.
Now is a good time to tell readers why the PIK’s model scenarios are a load of manure: First, we have models where nature always ends up doing everything completely different. What are model speculations for centuries and even millenia into the future worth when already the current trends are talking a completely different language?
(1) Not predicted by a single model: The Earth has not warmed in 14 years [3] .
(2) For 14 years there has not been any correlation between CO2 and global temperature.
(3) This correlation is fundamentally, hotly and increasingly disputed [2].
(4) Sea level rise shows that over the last years, and foremost now, there is no acceleration [7] – instead we have a deceleration.
(5) And the most absurd of all: the study and the press release are speculating thousands of years into the future, as if it were like next month.
All the speculation is based on a computer model. Models are computer scenarios, and are not prognoses. Just as prognoses– e.g. for economics, weather, social structure, etc. – for political, business and private decisions are fraught with uncertainty, model scenarios for decisions for far-reaching measures are useless.
Another important question amid all this is being avoided: How is it that the Greenland Ice Sheet never experienced extensive melting (let alone a complete meltdown) over the Holocene when at times it was warmer than today over hundreds of years, see figure below?



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Alpine glaciologist E. Patzelt [5] also writes:
Proxy temperature records for the temperature development show that 65% of the last 10,000 years the summer half-year was just as warm or warmer than today. The current temperature development is within the normal range of variability. Warm phases of this type have always been called ‘climate optimums’.”
One needs to take this much more into consideraion in the current climate discussion. This will not lead to a complete melting of the glaciers, neither in the Alps, nor in Greenland.
Finally, veteran meteorologist Dr. Wolfgang Thüne puts it in plain words (emphasis added) when asked what he thought about the PIK’s thousand-year model prognoses [6] :”
Nothing! Theoretically, you can think up anything, dress it up in formulae and calculate that the end of the world will occur in exactly 1900 years. In 2000 years, when it comes to an ice-free Greenland, man will have been defrauded. The Potsdam Institute for Climate Impact Research reminds me of the Greek ‘Oracle of Delphi’, or the ‘Book of Revelation’, the vision of the apocalypse with its prophetic picture sequences . The world was supposed to end already back in 1033 and the IPCC prophesied in 2007 a climate collapse for 2020. With their super computers the climate scientists would have us believe that they have opened up the ‘Seven Seals’ and revealed ‘God’s Plan’.”
References:
[1] http://www.pik-potsdam.de/aktuelles/pressemitteilungen/gronlands-eismassen-konnten-komplett-schmelzen-bei-1-6-grad-globaler-erwarmung; 11.03.2012
[2] A.Robinson, R.Calov and A.Ganopolski;  Multistability and critical thresholds of the Greenland ice sheet; NATURE CLIMATE CHANGE / ADVANCE ONLINE PUBLICATION, www.nature.com/natureclimatechange , © 2012 Macmillan
Publishers Limited. All rights reserved.
[3] http://www.eike-klima-energie.eu/news-cache/g-l-o-b-a-l-c-o-o-l-i-n-g-wo-bleibt-die-erderwaermung/; 25.02.2012
[4] F.Vahrenholt & S.Lüning, Die Kalte Sonne, Hoffmann u. Campe, (2012)
[5] G. Patzelt, Gletscherschwund und Vorzeitklima, Bergauf, 2 (2008), S. 34-35, Innsbruck
[6] Luxembg. Tageblatt,15. März 2012, Das Orakel von Delphi; http://www.tageblatt.lu/nachrichten/story/-Orakel-von-Delphi–11105134
Also read here: http://drtimball.com/2012/sensationalist-and-distorted-climate-stories-increase-as-climate-science-failures-exposed/
 
Share this...FacebookTwitter "
"**Suffolk will be placed in tier two when England's second lockdown ends on 2 December, it has been announced.**
People in this tier cannot socialise with other households indoors.
The rule of six will apply to gatherings outdoors and pubs and restaurants will shut at 23:00 GMT and only be allowed to serve alcohol as part of a meal.
Prior to England's second lockdown, Suffolk was in tier one, the lowest level of Covid-19 restrictions.
Most of England has been placed in the two toughest tiers of coronavirus restrictions when the national lockdown ends.
The hospitality sector had been hoping to recoup some of its losses in the festive period.
Ashley Stock, 32, director of Stock and Bailey, which runs The Ram in Hadleigh, Suffolk, and a wine bar in Colchester, said the move into tier two was not ideal.
""It is what it is, and we have to make it work,"" he said.
Co-director Paul Bailey, 43, said the business faced ""challenging times"" but they were well supported and he ""remained optimistic"".
But Andy Davis, 36, pub manager of The George in Hadleigh, said the next few weeks ""would be a bit of a struggle"".
""At the end of the day, we're a pub that serves food, we're not a restaurant, so I'm going to have to see,"" he said.
""It's going to be extremely hard to make the business viable and make every single person who walks through the door have a meal.""
Peter Aldous, Conservative MP for Waveney, said he hoped ""if things move in the right direction, we can be out of tier two in a month's time"".
He has appealed for help for the hospitality industry, which he said would be ""hit hardest"".
On Wednesday, Britain's major pub groups and brewers, including Suffolk-based Adnams and Greene King, wrote a letter to Prime Minister Boris Johnson asking him to save their industry, which was facing the ""darkest of moments"".
The letter accused the government of scapegoating pubs ""despite a lack of evidence"".
The pubs also demanded financial support in line with the first lockdown, immediate changes to business rates and a cut in beer duty, if restrictions were not relaxed.
Stuart Keeble, Suffolk's director of public health, said: ""We need to stick with it.
""With current infection rates and pressure being put on health services, we need to do more of what we have been doing.""
Suffolk's move to tier two restrictions means a maximum of 2,000 people can be admitted to Portman Road to watch Ipswich Town play in League One once lockdown ends.
The county's current infection rate of 85 cases per 100,000 people was more than double what it was when Suffolk entered tier one on 14 October, Suffolk Public Health said.
At the beginning of September, there were just five cases per 100,000 people.
Parts of Suffolk, especially Ipswich and Hadleigh, are seeing much higher numbers of positive cases than anticipated.
There were 116 Covid-19 patients in Suffolk hospital beds as of 23 November.
The Health Secretary and MP for West Suffolk, Matthew Hancock, said despite his own constituency having the lowest case rate for over-60s in the whole country, the county as a whole needed to be in tier two ""to get the virus further under control"".
""I hope Suffolk and so many other parts of the country can get to tier one soon and the more people stick to the rules the quicker that will happen,"" said Mr Hancock.
The government said it would be regularly reviewed and an area's tier level may change before Christmas. The first review is scheduled for 16 December.
The rates in all districts in Suffolk, except Ipswich, have fallen week-on-week.
The districts of Mid Suffolk, West Suffolk, and East Suffolk have had some of the lowest rates of Covid-19 since the end of the first lockdown.
_Find BBC News: East of England on_Facebook _,_Instagram _and_Twitter _. If you have a story suggestion email_eastofenglandnews@bbc.co.uk"
"Climate change is underway, and human activities such as urbanisation, industrialisation and food production are key contributors. Food production alone accounts for around 25% of global carbon emissions. Ironically, the changing weather patterns and more frequent extreme weather events resulting from climate change also put the world’s food supplies at risk.  Food production drives deforestation, meaning there are fewer trees to absorb carbon dioxide, which contributes to the greenhouse effect. What’s more, the fertilisers and pesticides used to protect crops have caused a dramatic decline in insect populations, and in soil fertility, by affecting the microbial organisms that enrich the soil and enable plants to gain nutrients.  At the same time, the world population is rising and there are expected to be more than 9.5 billion people on Earth by 2050. In response to these projections, the UN’s Food and Agriculture Organisation (FAO) is campaigning for a 60% increase in food production by 2050, by intensifying agriculture to be more productive and use fewer resources, all without increasing the amount of farm land.  It’s not yet clear exactly how this “intensification” should happen. Alternative methods, such as organic farming, are respectful of soil ecology and insect life and can restore soil fertility. But they cannot, at present, produce as much food as industrial agriculture.  Yet the idea that we need more food is debatable. Although, according to the FAO, there are 821m people globally suffering from hunger, the world produces 50% more food than is needed to feed the global population. Another estimate from biologist and author Colin Tudge suggests that the current food production can feed as many as 14 billion people. But one third of this food is wasted because of distorted supply systems, unjust food distribution and unhealthy and unsustainable diets. So, the efforts of experts in the food sector should not concentrate on agriculture intensification, but rather on strategies to change patterns of consumption and waste at a local and global level. My own research on urban agriculture and sustainable cities suggests there are three main areas where effective changes can be made.  Food consumption needs to become “circular”. This means that organic waste such as food scraps does not go to landfill, but is instead transformed into compost (which will be needed in a transition to organic agriculture) and biogas.  


      Read more:
      Ugly veg: supermarkets aren't the biggest food wasters – you are


 At present, organic waste is only recycled to a small extent, with some countries such as Germany and the Netherlands leading, while others including Italy and Belgium lag behind. But there are new technologies emerging to make this process easier.  For example, the Local Energy Adventure Partnership (LEAP) has created an anaerobic digester designed for an urban context: this machine can transform organic waste from residential or commercial buildings into compost and biogas that can fuel urban food growing.  Some experts also suggest that some food waste – if treated properly – could be used as animal fodder: a practice currently forbidden on hygiene grounds. If reinstated, this measure could reduce the environmental impact of grain cultivation, as less is grown to feed livestock.  Another option is to decrease demand for agricultural land by growing food in cities, where more people need it, thereby reducing the distances food has to travel. This would also allow producers to map and match consumers’ demand more effectively, by producing close to the places where food is consumed.  There is a lot of research on urban agriculture and how cities can support it, spanning from vertical farms - hydroponic systems enabling cultivation on vertical surfaces - to principles for planning cities that facilitate the use of land, rooftops and other spaces to grow food into a continuous green infrastructure.  


      Read more:
      How urban farmers are learning to grow food without soil or natural light


 In this area, too, it’s possible to find innovations designed to make urban farming easier and more sustainable. For example, The Farmhouse is a modular housing system suitable for vertical stacking that enables all residents to grow food. And Blockchain Domes is a patented system that uses excess heat from computer servers to provide optimal thermal conditions for greenhouses in colder climates.  The third option is to encourage people to change their diets. Growing middle-income groups in developing countries are consuming ever higher quantities of meat, cheese and eggs. In China, since 1990, consumption of beef and poultry has quadrupled. But the diet of farmed animals is heavy in grains, which instead could be used to feed people more efficiently. Also, cattle farming requires vast quantities of water and grassland, sometimes obtained through deforestation.   Getting people to eat less meat will help to ease the pressure on the world’s food system. In cities, governments, research institutions, communities and businesses can collaborate on food initiatives to give people healthier, cheaper and more sustainable choices – but this requires political will and organisation between different levels of government.   


      Read more:
      Bug burgers, anyone? Why we’re opening the UK’s first insect restaurant


 Clearly, each of these approaches has a limited scope of action, compared to agricultural techniques or strategies which can be deployed at an industrial level. But with so many promising proposals, there can be a many-pronged approach that that makes efficient use of the existing resources in cities, while also changing consumers’ habits. Together with these three changes, more effective policies for food justice and sovereignty can establish fairer food supply chains and more just distribution of food around the world."
"Anyone lucky enough to visit Ghana could do worse than order a plate of boiled yam and red-red – a stew made with beans and tomato paste. A Sunday morning treat in Europe might be homemade crepes and hazelnut chocolate spread. Both of these meals – though part of very different cuisines and eaten in different places – contain palm oil, an edible vegetable oil extracted from the fruit of the oil palm (Elaeis guineensis). The link between palm oil production and deforestation in the tropical regions where it is grown is well known, but few people realise how prevalent palm oil is in items consumed every day, such as cleaning products and biodiesel.  Global production of palm oil has increased rapidly since the 1990s, with plantations in Indonesia and Malaysia supplying around 85% of the global trade. 


      Read more:
      Message to the EU: you have the chance to stop fuelling devastation in the Amazon


 Many of these plantations have replaced natural forests and drained carbon-rich peatlands. In Indonesia alone, palm oil is cultivated by more than 4 million smallholder farmers, employing more than 7 million labourers throughout its supply chain, and in 2017 exports contributed over USD$23 billion to the country’s economy.  The European Parliament issued a resolution in 2017 to phase out and eventually ban biofuels made from palm oil. The proposed ban could reduce demand for palm oil, but many, including the International Union for the Conservation of Nature, aren’t sure it will be effective in stemming deforestation. Malaysian farmers meanwhile argue it will harm their livelihoods.. A ban could even harm the environment by ending efforts to work with countries that are developing sustainable palm oil production that can also reduce poverty.  Just under half of the EU’s palm oil imports are used for biodiesel. Despite the importance of palm oil to Indonesia’s economy, the impact of any EU ban would likely be small. Indonesia exports two thirds of its biodiesel production, but only around one fifth of that goes to EU countries.  Indonesia might compensate for lost sales in the EU by increasing sales to large importers such as India and China. An EU ban could set back Indonesia’s efforts to manage its forests and palm oil trade more sustainably as these customers aren’t currently committed to sustainable sourcing. Unintended consequences like these highlight why bans can be crude policy instruments.  The EU ruled that renewable fuels such as biodiesel must comprise 10% of transport fuel by 2020. This was intended as an implicit ban on fossil fuels comprising the final 10% of vehicle diesel, but banning particular crops like palm oil for biofuels and keeping a biofuel requirement simply diverts the problem. This is particularly so if the EU continues to meet the 10% requirement using “first generation” biofuels – those derived directly from food crops, such as soy or rapeseed. Replacing food crops to meet increased demand for bio-ethanol production places pressure on land and could increase global food prices, hurting low-income households most.  Better approaches would target the interconnected problems of carbon emissions, deforestation and poverty. EU countries could support the sustainable cultivation of palm oil, breaking the link between oil palm expansion and deforestation in producer countries. One way to do this is planting on degraded land rather than replacing forest. This avoids the negative impact of a ban on the livelihoods of millions of farmers. Demand for fossil fuels could be reduced more effectively by making public transport more accessible, affordable and reliable. Incentives for people to buy electric cars, through subsidy and a higher density of charging points, could also help. Indonesia and the EU have already worked together on this issue with some success. A voluntary partnership agreement between the two in 2003 helped Indonesia reduce illegal logging and export timber to the EU. But given that most of Indonesia’s palm oil exports go to countries outside of the EU, a global approach is needed.  The UN Environment World Conservation Monitoring Centre investigates the sustainable trade in forest products. It hopes to understand how incentives for supplier and producer countries can ensure trade improves livelihoods, prosperity and the natural environment. In an increasingly interconnected world, seemingly sensible decisions made in one place can have unintended consequences elsewhere. An EU palm oil ban, designed to protect tropical forests, might instead harm the livelihoods of farmers and increase forest loss if countries such as Indonesia and Malaysia switch to markets with fewer environmental checks and balances. This article was amended on May 9 2019 to make clearer that an EU ban has not yet been enacted."
"**All of Hertfordshire, Bedfordshire and Buckinghamshire will be in tier two when England's lockdown ends on 2 December.**
Luton will remain in tier two, where it was placed in the previous version of the tier system prior to the second lockdown.
All other areas were in tier one.
It means households cannot mix indoors and the rule of six applies outdoors, with exceptions for childcare and support bubbles.
Non-essential retail outlets, places of worship and leisure facilities will reopen in line with government guidance.
Hospitality settings that serve alcohol must close in tier two, unless they operate as restaurants and alcohol can only be served with substantial meals.
Prior to the second lockdown, Luton Borough Council placed the town in tier two after a ""worrying"" number of admissions to hospital and a rise in deaths.
It is one of the areas which has received the new rapid ""lateral flow"" tests, for mass testing.
Lucy Hubber, interim head of public health, said ""deprivation, and multi-generational households with lots of people living in them"" were factors in Luton's high case rate.
""While there has been a levelling off in the infection rates over the last week due to the sacrifices people are making, our rates are still too high with large numbers of new positive cases being reported each day,"" she said.
Luton's Labour council leader, Hazel Simmons, said the fact the town's rates had levelled off was ""encouraging"" but they had not decreased as much as other parts of the country during the current lockdown.
""As a town we have worked together in the past to lower infection rates and we are confident we can rise to the challenge again,"" she said.
The rate in Luton was just below 300 cases per 100,000 people in the week to 21 November - the highest in the Eastern region.
Luton has seen a fall in cases week-on-week, but now has the 61st highest rate in England.
All other districts in Bedfordshire, Buckinghamshire and Hertfordshire have fallen week-on-week.
The whole of Hertfordshire will be in the same tier, even though there is a range of case rates across the 10 district areas in the county.
David Williams, Conservative county council leader, said the decision was based on ""a series of indicators that reflect the continued prevalence of the virus in the county"".
""Now it is more important than ever that we redouble our efforts to ensure that the recent downward trend in our infection rates is sustained in order to secure a move to tier one as soon as possible,"" he said.
Peter Taylor, Liberal Democrat elected mayor of Watford, said: ""Despite seeing a plateau in the number of cases locally, the numbers are still higher than where we want them to be.
""But we have been making progress recently in ensuring the case numbers are not rising, so we must continue to do what we can to not go backwards.""
Andrei Lussmann, from the restaurant group Lussmanns, said: ""Restaurants are the safest social places in the country as far as Covid is concerned, with provable low transmission rates.
""Restaurants are just not where the problem is and all the evidence has shown this so I feel like the restaurant sector has been held to ransom unfairly and unnecessarily.""
Christo Tofalli, landlord of Ye Olde Fighting Cocks in St Albans, said: ""We will open and do the best that we can to welcome our families and guests in their bubbles over the festive period, but when we opened after the last lockdown, we only took 20% of our usual takings and this barely covers the costs of opening the doors.""
The government has chosen to divide Beds, Herts and Bucks up into counties for Covid restrictions, meaning everybody is in tier two.
The decision might seem harsh to people living in parts of Central Bedfordshire which has Covid rates per 100,000 people that are much lower than their neighbours in Luton.
In fact, Luton has rates that have topped 300, whilst Central Beds is down at 84.5, although the government doesn't just look at those rates when working the tier system out.
Hertfordshire is also combined, despite districts like Broxbourne being up at 207, whilst North Herts is down at 99.6.
The government plans to review the tier system at fortnightly intervals.
In his rationale for tier allocation, Health Secretary Matthew Hancock said Bedfordshire and Milton Keynes were in tier two because the overall case rate was still increasing and there was pressure on the local NHS.
He added there was a ""broadly stable or improving picture across Buckinghamshire"" with a case rate at 138 per 100,000 of the population, but the case rates remained too high for allocation to tier one.
Buckinghamshire's Conservative council leader Martin Tett said: ""Whilst it is disappointing not to have remained in tier one, we recognise that we must all cooperate in order to retain the advances made during the current lockdown and help save lives.""
Up to 2,000 people will be allowed in football stadiums in tier two areas, subject to stadium safety teams, local authorities and the English Football League (EFL) giving approval.
The EFL has been looking at the possibility of shifting some of next week's fixtures to take advantage of the plan.
Luton Town FC manager Nathan Jones said that potentially having 2,000 Hatters fans in the stadium on Wednesday was ""wonderful news if we can get all the processes in place"".
""We get just over 10,000 [fans usually] and it's like it's 45,000 so I'm sure 2,000 can do a great job,"" he said."
"October 9 2014 was a big day in eco-activism: Lego announced that it would not renew a product-placement deal with Shell, following concerted pressure from Greenpeace as part of a campaign to ban Arctic oil exploration by attacking firms associated with such activities. It is a common tactic of major energy companies to engage in collaborations with companies such as Lego as part of their quest for what they call a “social license” to operate. That means winning local, national and international community support.  For its part, Lego benefits from the money that comes with product placement; as per a James Bond movie, the producers defray their costs well in advance of sales to customers by accepting funding from firms that want to be associated with a happy, friendly, trustworthy image.  In this case, the firm is Greenpeace’s sworn enemy, Shell. As a sub-plot, Lego has been boasting of its green credentials. On July 1 2014, Lego said: “A co-promotion contract like the one with Shell is one of many ways we are able to bring Lego bricks into the hands of more children.” It went on: The Greenpeace campaign focuses on how Shell operates in a specific part of the world. We firmly believe that this matter must be handled between Shell and Greenpeace. We are saddened when the Lego brand is used as a tool in any dispute between organisations. Now, Lego’s tune differs: We continuously consider many different ways of how to deliver on our promise of bringing creative play to more children. We want to clarify that as things currently stand we will not renew the co-promotion contract with Shell when the present contract ends. We do not want to be part of Greenpeace’s campaign and we will not comment any further on the campaign. We will continue to deliver creative and inspiring Lego play experiences to children all over the world. This is, surely, one of those moments when a big but pusillanimous multinational corporation withers in the face of critique from a gallant but small non-government organisation – when activism trumps business, ethics triumphs over size, and scale is helpless in the face of righteousness. It has been hailed by Greenpeace true believers as “one of the most high-profile victories in its history” thanks to “guerrilla tactics”. The organisation itself immodestly announced in an email to its supporters that: “Today was a great day for the Arctic, and for people power.” But was it? Perhaps this was a smart, sophisticated, well-heeled multinational marketing campaign, undertaken via a vast network, using the services of advertising agencies and borrowing trademarks and copyrights to make a political point? Is this actually about what happens when multinationals fall out, when two vast companies (Shell and Lego) are separated by another powerful not-for-profit multinational (Greenpeace) revelling in the fantasy that it is David taking on Goliath? One version of these events might read: Greenpeace has not achieved very much in its critiques of Shell, so it went after a soft target. Lego caved in, the victim of a form of secondary boycott. While the charity argues that its grassroots campaign and direct-action pranks were crucial, one might also say that “wot won it” was a couple of ingenious videos. The first and most popular took music, words, images, and logos from one of the most successful films of the year, [The Lego Movie](http://www.boxofficemojo.com/movies/?id=lego.htm](http://www.boxofficemojo.com/movies/?id=lego.htm), to create a post-modern pastiche aimed at the heartstrings. The second, artier and less direct, was targeted at parents. The first, a brilliant video trope, worked magnificently and has become a case study for ad agencies. As the industry bible AdWeek put it, Greenpeace took “a page from Chipotle’s marketing playbook – haunting animation plus a distressing cover of a well-known song”. Other actions, such as a few children building anti-oil Lego figures in central London, some adults climbing models at a theme park and fun Lego figures placed in protests across major world cities, were minor irritants at best, drawing predictably minimal press coverage but incarnating a grassroots legitimacy that appeals to donors and old-fashioned activists from pre-social media eras. But even as the triumph occurred, Shell was luxuriating in Pele’s endorsement of it for providing “the world’s first player-powered community football pitch in the centre of Rio Di Janeiro’s favela”. It will take more than a sophisticated stunt by vanguardist apparatchiks to answer Pele. And it won’t be the action of a brave wee David against a big nasty Goliath – more a contest between rivals for multinational space and control. Greenpeace is well-placed to participate, thanks to its vast resources and smart links to ad agencies. But is people power one more marketing tool in this admittedly worthy struggle?"
"**Norfolk will be placed in the second tier of restrictions when England's second lockdown ends on 2 December, it has been announced.**
People in tier two areas, classed as high, cannot socialise with other households indoors.
Up to six people can meet outdoors, and pubs and restaurants must shut at 23:00 GMT.
Prior to England's second shutdown, Norfolk was in tier one, which was the lowest level of Covid restrictions.
Many have reacted with disappointment that Norfolk has not been placed in tier one, along with Cornwall, the Isles of Scilly and the Isle of Wight.
Norfolk County Council said there had not yet been a ""sustained"" decline in the virus, with the government reaching its decision based on rates in the over 60s and the capacity of hospitals, among other factors.
Cases among the over 60s are high at 100 per 100,000 and are increasing in South Norfolk and Norwich.
Currently, 162 people are being treated for coronavirus in Norfolk and Waveney hospitals, compared with 141 on 13 November.
Overall, every district in the county has seen rates fall, with the exception of North Norfolk, which previously had one of the lowest in the country.
There were 1,100 coronavirus cases in Norfolk in the week up to 21 November, down from 1,345 in the previous week.
At one point the case rate in South Norfolk had tripled week-on-week.
This was down to an outbreak in Wymondham, which was blamed on a ""lack of discipline"" by the local council.
County council leader Andrew Proctor said: ""People in Norfolk have worked so hard to pull together to protect each other and to protect our county and for this reason we had hoped we would be able to move into tier one from next week.
""However, in reaching the decision the government has looked at how the virus is progressing, rates in the over-60s and the capacity of local hospitals and concluded that the risk posed by household visits remains too high.
""The numbers are beginning to fall but we are not yet seeing a sustained decline in the virus.
""That means that we will move into tier two from next week, a decision that we accept but one that I know many people will find difficult.""
Conservative North Norfolk MP Duncan Baker said he was ""hugely disappointed"" about the tier two decision and said he would be making the case for Norfolk at a ministerial meeting later.
""Clearly the government has taken a very cautious approach,"" he said.
""What appears to have not gone in our favour is the percentage of those taking tests and being positive is too high and the case rate in the over-60s is too high.""
He said he would tell ministers that the majority of areas were improving and if the infection rate continued to fall, Norfolk should return to tier one as soon as possible, at the first review on 16 December.
Businesses affected by the decision must be given support, he added.
Norfolk Chief Constable Simon Bailey said: ""While we might all have our own opinions on these measures, we must take personal responsibility for making sure we adhere to them, the fact remains they are in place to protect us all and we need to follow them.
""As police, we don't make the rules, we enforce them and I would urge each and every one of you to do the right thing and play your part in being risk aware, protecting yourselves, your loved ones and the county as a whole by sticking to the regulations.""
Under tier two, pubs and bars must close unless operating as restaurants.
Businesses which can open include non-essential shops, gyms and leisure centres, hairdressers and cinemas.
Up to 2,000 spectators can attend Carrow Road to watch Norwich City play, and grass roots sports can return.
Norwich are yet to make a formal statement, but a spokesman said the club was ""incredibly proud"" of the work that went into its pilot fixture, when 1,000 fans watched the Canaries draw 2-2 with Preston North in September.
It was among the first Championship clubs to play in front of a crowd since the pandemic."
"
From a University of Leeds press release, comes this scary headline that seems to be picked up by the MSM. A Google search yields 16,400 hits on the title below.
Melting icebergs causing sea level rise
(Note: Be sure to see the reality punch line at the end of the article)

Scientists have discovered that changes in the amount  of ice floating in the polar oceans are causing sea levels to rise.

The research, published this week in  Geophysical Research Letters, is the first assessment of how quickly  floating ice is being lost today.
According to Archimedes’ principle, any floating object displaces  its own weight of fluid. For example, an ice cube in a glass of water  does not cause the glass to overflow as it melts.
But because sea water is warmer and more salty than floating ice,  changes in the amount of this ice are having an effect on global sea  levels.
The loss of floating ice is equivalent to 1.5 million Titanic-sized  icebergs each year.  However, the study shows that spread across the  global oceans, recent losses of floating ice amount to a sea level rise  of just 49 micrometers per year – about a hair’s breadth.
According to lead author Professor Andrew Shepherd, of the  University of Leeds, it would be unwise to discount this signal. “Over  recent decades there have been dramatic reductions in the quantity of  Earth’s floating ice, including collapses of Antarctic ice shelves and  the retreat of Arctic sea ice,” said Prof Shepherd.
“These changes have had major impacts on regional climate and,  because oceans are expected to warm considerably over the course of the  21st century, the melting of floating ice should be considered in future  assessments of sea level rise.”
Professor Shepherd and his team used a combination of satellite  observations and a computer model to make their assessment. They looked  at changes in the area and thickness of sea ice and ice shelves, and  found that the overall signal amounts to a 742 cubic kilometres per year  reduction in the volume of floating.
Because of differences in the density and temperature of ice and sea  water, the net effect is to increase sea level by 2.6% of this volume,  equivalent to 49 micrometers per year spread across the global oceans.
The greatest losses were due to the rapid retreat of Arctic Sea ice  and to the collapse and thinning of ice shelves at the Antarctic  Peninsula and in the Amundsen Sea.
For more information 
To arrange an interview with Prof Andy Shepherd, contact Hannah Isom  in the University of Leeds press office on 0113 343 4031 or email h.isom@leeds.ac.uk
Notes to editors 
“Recent loss of floating ice and the consequent sea level  contribution” by Andrew Shepherd, Duncan Wingham, David Wallis,  Katharine Giles, Seymour Laxon, and Aud Venke Sundal is published this  week in Geophysical Research Letters (doi:10.1029/2010GL042496).
ICE SHELVES are thick, floating platforms of ice that form where a  glacier or ice sheet flows down to a coastline and onto the ocean  surface. Ice shelves are found mainly in Antarctica , and range from  about 100 to 1000 metres in thickness.
SEA ICE is formed on the surface of sea water as the ocean freezes,  and is typically less than 3 metres in thickness. It is found  extensively in both the Arctic and Antarctic regions, and it’s extent  varies considerably over the seasons.
This study was funded by the UK National Centre for Earth  Observation and the Philip Leverhulme Trust.
==========================================
OK here’s the reality punch line:
Assuming their theory of 49 micrometers per year rise (this conversion equals 0.0019 inch or 0.00016 feet ) due to the differences is salty and fresh water holds true, then we can assess the threat level.
At this rate, to see an inch of sea level rise from melting icebergs we’d need:
1 inch/0.0019 inch/yr  = 526 years
Yeah, I’m worried about that.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8bd9a9ce',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Guest Post by Willis Eschenbach
Yesterday, I discussed the Shepherd et al. paper, “Recent loss of floating ice and the consequent sea level contribution” (which I will call S2010). I also posted up a spreadsheet of their Table 1, showing the arithmetic errors in their Table.
Today, I’d like to discuss the problems with their method of calculating the loss in the Arctic Ice Pack. To start with, how big is the loss? Here is a graphic showing the change in area of the Arctic ice pack from one year’s loss of ice, with the ice pack area represented by a circle:

Figure 1. One-year change in the area of the Arctic Ice Pack, using the average annual loss which occurred 1996–2007. Note the obligatory polar bears, included to increase the pathos.
OK, so how do they calculate the Arctic ice loss in S2010?

Here is their description from the paper:
We estimated the trend in volume of Arctic sea ice by considering the effects of changes in both area and thickness. According to ERS and Envisat satellite altimeter observations, the 1993-2001 (average wintertime) thickness of Arctic sea ice was estimated to be 273 cm (Laxon et al., 2003), the thickness decreased by 6.7 ± 1.9 cm yr-1 between 1992 and 2001 (Laxon et al., 2003), and the thickness decreased by 4.8 ± 0.5 cm yr-1 between 2003 and 2008 (Giles et al., 2009).
We combined these datasets to produce a new estimate of the 1994-2008 thickness change. Published satellite microwave imager observations (Comiso et al., 2008) show that the 1996-2007 Arctic sea ice area trend was -111 ± 8 x 10^3 km2 yr-1 and, based upon our own analysis of these data, we estimate that the 1990-1999 average wintertime area of Arctic sea was 11.9 x 10^6 km2.
The combined reductions in Arctic sea ice area and thickness amount to a decrease in volume of 851 ± 110 km3 yr-1 during the period 1994 to 2007, with changes in thickness and area accounting for 65 % and 35 % of the overall loss, respectively.
What is the problem with that method?
The problem is that they have assumed that the ice is the same thickness over the entire area. As a result, the reduction in area is causing a large loss of ice, 35% of the loss by their estimate.
But the ice is not all the same thickness. The perimeter of the ice, where the loss occurs, is quite thin. As a result, they have overestimated the loss. Here is a typical example of the thickness of winter ice, from yesterday’s excellent article by Steve Goddard and Anthony Watts:

Figure 2. Ice thickness for May 2010. Note that the thickness of the ice generally tapers, from ~ 3.5 metres in the center to zero at the edges.
So their method will greatly overestimate the loss at the perimeter of the ice. Instead of being 273 cm thick as they have assumed, it will be very thin.
There is another way to estimate the change in ice volume from the melt. This is to use a different conceptual model of the ice, which is a cone which is thickest in the middle, and tapers to zero at the edges. This is shown in Figure 3

Figure 3. An alternative model for estimating Arctic ice pack volume loss.
Upon looking at this drawing, I realized that there is a way to see if my model fits with the facts. This is to use my model to estimate how much of a thickness change would be necessary to create the 111,000 square kilometre loss. It turns out that to get that amount of loss of area, it would require a ~4 cm ice loss over the entire surface … which is a good match to their estimate of ~ 5 cm of loss.
So, what difference does this make in the S2010 estimate of a global loss of 746 cubic kilometres per year? Lets run the numbers. First, I’ll use their method. I have used estimates of their numbers, as their description is not complete enough to give exact numbers.
Thickness loss: (11,900,000 km^2 – 111,000 )* 5 cm / (100,000 cm/km) = 589 cubic km (66 % of total).
Area loss: 111,000 km^2 * 273 cm /  (100,000 cm/km) = 303 cubic km (34% of total)
Total: 892 cu km, which compares well with their answer of 851 cubic km. Also, the individual percentages I have calculated (66% and 34%)  compare well with their numbers (65% and 35%). The difference is likely due to the decreasing area over the period of the analysis, which I have not accounted for.
So if we use a more realistic conceptual model of the ice (a conical shaped ice pack that is thick in the middle, and thin at the edges), what do we get?
The formula for the volume of a cone is
V (volume) = 1/3 * A (area of base) * h (height)
or
V = 1/3 * A * h
The difference in volume of two cones, therefore, is
V = 1/3 * (A1*h1 – A2*h2)
This means that the volume lost is
V = 1/3 * (11900000 km^2 * 273 cm – 11789000 km2 * 268 cm) / (100000 cm/km)
= 297 cubic km
This is much smaller than their estimate, which was 851 cubic km. And as a result, their estimate of global ice loss, 746 km^3, is reduced by 851 – 297 = 554 km^3, to give a final estimate of global ice loss of 192 cubic kilometres.
FINAL THOUGHTS
1. Is my estimate more accurate than theirs? I think so, because the simplistic assumption that the ice pack is equally thick everywhere is untenable.
2. How accurate is my estimate? I would put the 95% confidence interval (95%CI) at no less than ± 25%, or about ± 75 km^3. If I applied that same metric (±25%) to their estimate of 851 km^3, it would give a 95%CI of ±210 km^3. They give a 95%CI in their paper of ±215 km^3. So we are in agreement that this is not a WAG*, it is a SWAG*.
3. This exercise reveals some pitfalls of this kind of generally useful “back-of-the-envelope” calculation. First, since the final number is based on assumptions rather than data, it is crucial to be very clear about exactly what assumptions were made for the calculations. For example, from reading the paper it is not immediately evident that they are assuming constant thickness for the ice pack. Second, the change in the assumptions can make a huge change in the results. In this case, using my assumptions reduces the final value to a quarter of their global estimate, a value which is well outside their 95%CI estimate.
To close, I want to return to a separate point I made in my last post. This is that the S2010 paper has very large estimates of both gains and losses in the thickness of the Antarctic ice shelves. Now, I’m not an ice jockey, I’m a tropical boy, but it seems unlikely to me that the Venable ice shelf would lose a quarter of a kilometre in thickness in 15 years, as they claim.
Now it’s possible my math is wrong, but I don’t think so. So you colder clime folks out there … does it make sense that an ice shelf would lose 240 metres thickness in fifteen years, and another would gain 130 metres thickness in the same period? Because that is what they are claiming.
As mentioned above, I have posted their table, and my spreadsheet showing my calculations, here. here I’d appreciate anyone taking a look to make sure I have done the math correctly.
PS:
* WAG – Wild Assed Guess, 95%CI = ±100%
* SWAG – Scientific Wild Assed Guess, 95%CI = ±25%
[UPDATE] My thanks to several readers who have pointed out that I should not use 273 cm as the peak thickness of the ice. So following this NASA graphic of submarine measured winter and summer ice, I have recalculated the peak as being about 4 metres.
Using this value, I get arctic ice loss of 344 km^3, and a global ice loss of 239 km^3.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b934ca4',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Dr. Roger Pielke Jr. explains why some leftist bloggers set themselves up for failure when they espouse their intellectual superiority. Screaming “hell, high water, global boiling, climate disruption, etc ” while at the same time saying “you’re too dumb to understand it” looks to be an epic “failure to communicate”.

He writes:
If  you spend anytime at all perusing the blogosphere, you will find a  common theme coming from self-described liberal or progressive bloggers,  and that is that those on the political right are ignoramuses. 
The  argument is that they are just too stupid to know what’s what – they are  even anti-science, rejecting knowledge itself — and consequently they  support dumb candidates advocating ignorant policies. Such arguments are  particularly evident in the corner of the blogosphere that discusses  the climate change issue.  This line of argument of course is a variant  of the thinking that if only people shared a common understanding of  scientific facts they would also share a common political orientation  (typically the political orientation of whomever is expressing these  views).
Read his whole post here where he explains why.
Or buy his book:
click for more
The Climate Fix: What Scientists and Politicians Won’t Tell You About Global Warming is now available at Amazon.com
Why has the world been unable to address global warming? Science  policy  expert Roger Pielke, Jr., says it’s not the fault of those who  reject  the Kyoto Protocol, but those who support it, and the magical  thinking  that the agreement represents.
In The Climate Fix,  Pielke offers  a way to repair climate policy, shifting the debate away  from  meaningless targets and toward a revolution in how the world’s  economy  is powered, while de-fanging the venomous politics surrounding  the  crisis. The debate on global warming has lost none of its power to   polarize and provoke in a haze of partisan vitriol. The Climate Fix will bring something new to the discussions: a commonsense perspective and practical actions better than any offered so far.
Editorial Reviews via Amazon
From Publishers Weekly
Pielke (The Honest Broker) presents a smart and hard-nosed analysis of  the politics and science of climate change and proposes  a commonsense  approach to climate policy.  According to Pielke, the  iron law of  climate policy  dictates that whenever  environmental and economic  objectives are placed in opposition to each other,  economics always  wins.  Climate policies must be made compatible with economic growth as a  precondition for their success,  he writes, and because the world will  need more energy in the future, an  oblique  approach supporting   causes,  such as developing affordable alternative energy sources rather  than  consequences,  such as controversial schemes like cap-and-trade,  is more likely to succeed.
Although some may protest on principle the  suggestion that we accept the inevitability of energy growth, Pielke’s  focus on adaptation to climate change refreshingly sidesteps the  unending debate over the reality of anthropogenic climate change, and  opens up the possibility for effective action that places  human dignity  and democratic ideals at the center of climate policies.
The book is available at Amazon.com and I think it is destined to be a best seller in the “Global Warming” category.

<a href=”http://www.amazon.com/Climate-Fix-Scientists-Politicians-Warming/dp/0465020526/&amp;tag=wattsupwithth-20″ target=”_blank”><img src=”http://3.bp.blogspot.com/_0ZFCv_xbfPo/S7SlIkFewJI/AAAAAAAAAUE/utA5rI7F5SU/s1600/Pielke-The+Climate+Fix.jpg” alt=”” width=”250″ height=”380″ /></a>click for more
The Climate Fix: What Scientists and Politicians Won’t Tell You About Global Warming is now available at <a href=”http://www.amazon.com/Climate-Fix-Scientists-Politicians-Warming/dp/0465020526/&amp;tag=wattsupwithth-20″ target=”_blank”>Amazon.com</a><!–more–>
Why has the world been unable to address global warming? Science  policy  expert Roger Pielke, Jr., says it’s not the fault of those who  reject  the Kyoto Protocol, but those who support it, and the magical  thinking  that the agreement represents.
In <em>The Climate Fix</em>,  Pielke offers  a way to repair climate policy, shifting the debate away  from  meaningless targets and toward a revolution in how the world’s  economy  is powered, while de-fanging the venomous politics surrounding  the  crisis. The debate on global warming has lost none of its power to   polarize and provoke in a haze of partisan vitriol. <em>The Climate Fix</em> will bring something new to the discussions: a commonsense perspective and practical actions better than any offered so far.
Editorial Reviews via Amazon
From Publishers Weekly
Pielke (The Honest Broker) presents a smart and hard-nosed analysis of  the politics and science of climate change and proposes  a commonsense  approach to climate policy.  According to Pielke, the  iron law of  climate policy  dictates that whenever  environmental and economic  objectives are placed in opposition to each other,  economics always  wins.  Climate policies must be made compatible with economic growth as a  precondition for their success,  he writes, and because the world will  need more energy in the future, an  oblique  approach supporting   causes,  such as developing affordable alternative energy sources rather  than  consequences,  such as controversial schemes like cap-and-trade,  is more likely to succeed.
Although some may protest on principle the  suggestion that we accept the inevitability of energy growth, Pielke’s  focus on adaptation to climate change refreshingly sidesteps the  unending debate over the reality of anthropogenic climate change, and  opens up the possibility for effective action that places  human dignity  and democratic ideals at the center of climate policies.
The book is available at <a href=”http://www.amazon.com/Climate-Fix-Scientists-Politicians-Warming/dp/0465020526/&amp;tag=wattsupwithth-20″ target=”_blank”>Amazon.com</a> and I think it is destined to be a best seller in the “Global Warming” cate



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e878f0215',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"
Share this...FacebookTwitterGermany’s flagship political newspaper the Frankfurter Allgemeine Zeitung has an online report on an EU internal memo that bubbled up to public attention.
An EU Commission internal strategy paper “calls for an end to subsidies for solar and wind energy by EU countries and that this should be done as soon as possible”. EU Energy Commissar Günther Oettinger wants to officially present the paper in Brussels. This, writes the FAZ, will provide the German government with cover for its plan to cut its own subsidies for solar energy by 30%.
Despite all the symbolism and lip service by Merkel’s coalition government in support of wind and solar energy, its actions tell a different story. They don’t want them any more!
Also according to the paper, the price of photovoltaic systems have dropped 48% over the last five years. So it’s strange how that now solar energy is approaching affordability, the US government now wants to slap massive tariffs on Chinese imports and make the price totally unaffordable again.
The consumer has had to bear the high price of subsidized solar energy in the EU. The FAZ writes:
…the strong expansion of solar and wind power has caused the costs for consumers, and in some cases for taxpayers, to rise quickly. Because of the bad economic situation, energy costs for many people is often too high. The prices of energy source such as sun and wind thus should be left to the market forces as quickly as possible.”
Even with the generous subsidies, solar energy in Germany has still failed as most of Germany’s solar module manufacturing has been crushed by foreign competition in Asia, shedding thousands of jobs. Eliminating subsidies altogether would be a certain death blow.
The Commission also calls for a uniform support system of other alternative energy sources, and criticizes Europe’s patchwork of different support programs for renewable energy. This has led to the inefficient use – for example massive solar systems being constructed in northern Germany where the sun hardly shines and windmills are built where the wind hardly blows.
Whatever happens, one thing is certain: Europe is beginning to realize that green energies aren’t what they were once made out to be.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe English language Swedish online news site The Local.se/ reports on how the weather in Sweden has been so far during the month of June: wet & cold.

Chilly June hits Sweden. (Photo from Wikipedia, taken by Mark A. Wilson, Department of Geology, The College of Wooster).
According to the Swedish Meteorological and Hydrological Institute (SMHI), temperatures have been well below average in June, at just 13.3 degrees Celsius. Normal is 15.2°C.
On June 2, the temperature in Stockholm rose only to 6°C, the coldest high in 84 years, read more here. Earlier in the month one town recorded a temperature of 6°C below zero – the coldest June temperature in Sweden in 20 years. Snow even blanketed parts of northern Sweden.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Normally in the month of June, the mercury rises to 25°C or more on just days 5 days on average. This June the mercury never reached that mark. In fact it didn’t even reach the 22°C mark. The high temperature for June in Stockholm was only 21.6°C. This is only the second time the temperature has failed to reach 25°C in June in 92 years.
What’s behind the unusual cool weather? An SMHI spokesman explains it to us:
Sweden’s climate has become both warmer and rainier because of global warming, and rainfall and storms have increased in recent years.”
I’m glad he cleared that up.
June has also been a very wet month. According to the SMHI, Stockholm recorded a record rainfall so far for the month: 145.8 millimetres, the most since records began in 1786.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAl Gore and others have shamelessly exploited public ignorance about the polar bear in order to spread fear. Ed Caryl tells us why the polar bear will do just fine.
================================================
The Polar Bear
by Ed Caryl
The climate change “team” regularly invoke the polar bear as the “poster-boy” for the supposed danger in catastrophic anthropogenic global warming.

Figure 1: Female polar bear (ursus maritimus) near Kaktovik, Barter Island, Alaska. (Source: Wikimedia Commons).
Origin
The polar bear, ursus maritimus, is descended from the Brown Bear, ursus arctos. The genetic split took place sometime between 300,000 and 600,000 years ago, but the split was never fully complete. Polar bear mitochondral DNA (mDNA) is descended from a female brown bear, perhaps from Ireland, which dates back to the middle of the last ice age, 50,000 to 100,000 years ago. During that encounter, a male polar bear mated with a female brown bear. The subsequent offspring then mated with polar bears, and the mDNA from that female spread across the population. That suggests that population pressure on polar bears doesn’t necessarily happen only when it warms up, but also when it gets very cold. Both conditions reduce the first-year sea ice that makes prime habitat for the seals that polar bears favor; cold covers it with glaciers and warm melts it.
There isn’t much genetic difference between polar bears and other brown bears. They can freely mate, and the offspring are fertile, indicating that they are the same species. The Latin name should be ursus arctos maritimus, similar to the grizzly bear ursus arctos horribilus. These “hybrids” happen often in the Canadian Arctic, and even have locally bestowed names, Grolar or Pizzly Bears. The environmentalists have decried these occurrences, claiming that it will lead to the demise of their favorite animal. In my opinion, this provides genetic diversity that has assisted survival in the past, and will in the future.
Diet


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Like all bears, polar bears are omnivorous. They eat anything organic. Except for man, they are the apex carnivore in the Arctic. They hunt and eat everything, sometimes
including man-flesh, sometimes including their own species. After a meal of seal blubber, they will sometimes seek out grass for a salad. In the summer, when they are ashore, they do not starve. They will hunt birds, forage for eggs, hunt and kill caribou and small mammals, eat lichen, moss, and mushrooms, forage on shrubbery and berries in season, harvest kelp and other seaweed, eat fish, shellfish, and other sea invertebrates, as well as sort through man’s local garbage. They have been seen hunting sea birds and ducks by swimming under them and ambushing them from below. They hunt and kill beluga whales, narwhales, and walrus twice their size. Obversely, the only animal that can kill a polar bear is man. Most carnivores kill by strangulation; polar bears kill by crushing the skull of their prey in their jaws.
The polar bear population is always food-limited. If food is plentiful, mother bears can raise more cubs and the population increases. The Arctic is not a place where food is easily obtained, so it takes 25,000 to 50,000 square kilometers to support a bear family. If food is plentiful, bear density may be limited by male bear predation on cubs
not their own. Cubs, if readily available, are an easier kill than seals. In recent years, seal and bear hunting in Arctic Canada has been curtailed, increasing both the seal and bear population. Bears are not being hunted (except for about 500 a year by natives in Nunavut, and illegal hunting in Russia) so the only mortality is old age, disease, parasitism (primarily trichinosis), and starvation. On autopsy, all four causes of death look very similar. Because of some hunting, the bear population in Nunavut seems to be the healthiest, and may be growing despite the hunting, due to the increasing number of seals.
Habits and Habitat
In the spring, polar bears prefer hunting seals on first-year sea ice. At that time of year, seals are almost the only food source available, plus they are high in fat, a prime source of energy. The bears hunt seals by staking out a breathing hole. Seals may have several holes each, so hunting is primarily a waiting game. As the sea ice melts, bears turn to seal haul-out locations and seal pups. As the season further advances, other species such as walrus, belugas, and narwhales may become available. Ursus maritimus lives up to the Latin name with ability to swim long distances. The record for a female wearing a GPS color is over 600 km in 9 days, though the mean distance and time for the bears in this study was about 100 km over three days. One female bear was tracked from Prudhoe Bay in Alaska to Greenland. (Factoid: only female bears are collared, because of the male bear anatomy. Male bears have such a muscular neck that a collar won’t stay on.)
The mating season is in the late spring, blastocyst (fertilized egg) implantation is delayed until fall. Bears den-up in October and the one to three one-pound pups are born in November or December. Mother and cubs do not emerge until March or April. Dens are in snowdrifts ashore or, north of Greenland, in multi-year ice where pressure ridges form shelters. Polar bears don’t really hibernate, but they do sleep a lot when denned. They also fast during this period. A female polar bear can fast for up to eight months and still be capable of nursing cubs and hunting. Cubs stay with their mother for two years in the low Arctic and up to three years in the high Arctic. During this period the cubs learn to hunt from their mothers.
All the above is similar to grizzly bears. Grizzly bears also hunt seals on sea ice, and polar bears will hunt caribou on land, just like grizzlies. The differences are fairly minor: grizzlies have a fat hump that polar bears lack; polar bears have clear, hollow shaft fur that appears white, black skin and thick fur on their paws which grizzlies lack. Pizzlies tend to have the clear fur, with black around the nose and eyes, with a grizzly head shape. The clear insulating fur and black skin is an adaptation to the Arctic that minimizes heat loss when it is dark and maximizes heat gain when it is sunny. For a polar bear, high energy efficiency means fewer seals are required to live and reproduce. The clear fur also provides camouflage, but this is only an advantage when stalking seals on ice.
The polar bear population is food-limited, not ice limited. Polar bears wander over wide areas. They do not have a fixed territory. The population freely intermingle. If sea ice recedes in one area, bears move to where it remains. When it all melts, they move to land. If they find themselves on an island with no food resources, they swim to the next spot of land. In the Arctic, polar bears and humans compete. If the bear and human populations use up the food resources in an area, both populations move somewhere else, or limit reproduction.
The polar bear population may be near the historic high at 20 to 25,000 animals. In the 1950’s and 60’s, the population may have been as low as 5,000. Sea-ice extent is cyclical. Bears have withstood many cycles of sea-ice shrinking and growing, including previous interglacials. The polar bear population is in no danger.
=========================
Also read an excellent article here: polar-bears-polemics-and-climate-warming/
Share this...FacebookTwitter "
"Six months on from the UN’s landmark 1.5°C report, which urged immediate global action to prevent global warming from rising beyond this dangerous level, the Committee on Climate Change (CCC) has advised the UK government to go zero-carbon by 2050. The committee’s report asserts that the target constitutes the country’s “highest possible ambition” and that it is not credible to aim for an earlier date. We disagree. While the report does challenge the government to step up its climate ambition, our view is that creative carbon accounting and an unwillingness to prioritise the planet’s health over economic growth leaves the committee’s target lacking the urgency truly required to combat the climate emergency recently declared by even the government itself. Before assessing whether 2050 is an appropriate date, its important to unpack exactly how the committee defines net zero. Based on international guidance from the UN’s Intergovernmental Panel on Climate Change, the UK’s target only includes territorial carbon emissions – those that are emitted directly within the country’s borders. The committee’s report highlights that the country’s territorial carbon footprint has fallen by 30% from 2008. But as Swedish campaigner Greta Thunberg highlighted to parliament, using this figure as a mark of the country’s climate leadership amounts to nothing more than creative carbon accounting, glossing over the UK’s role in emissions that occur outside its borders. The UK economy is primarily driven by its service sector, and the value of its imports is roughly triple that of its exports. The production and transport of these imported goods are a direct consequence of the UK’s consumption habits, but these emissions aren’t counted by the committee because they occur beyond its shores. Including these emissions and excluding emissions from exports to other countries, the UK’s carbon footprint is 70% higher than the figure used by the committee. Crucially, this alternative definition shows that emissions are still closely tied to the UK’s GDP, only notably reducing during the most recent financial crisis and remaining steady in recent years. The CCC does say that it will monitor the UK’s consumption-based emissions, and highlights that the country must avoid “offshoring” its territorial emissions by importing more goods. But it stops well short of addressing the fundamental elephant in the room – that to seriously tackle emissions, the UK must move away from an economy that prioritises short-term growth over radical emission reductions. On the surface, the most glaring omission in past carbon budgets at least appears to have been addressed. Emissions from international aviation and shipping have long been excluded from national targets in favour of international reduction efforts such as the UN’s CORSIA or the EU’s Emissions Trading Scheme. The committee now argues that “emissions from international aviation and shipping cannot be ignored”.  But it only recommends their inclusion in the UK’s carbon budget from 2033. This is 14 years too late. UK aviation emissions must not grow in the next decade if it is to prevent the worst effects of global warming. The time to act on aviation and shipping is now. Even placing accounting issues aside, the 2050 target is unambitious and gives a false impression that there is time to play with. Lord Deben, chair of the committee, is almost certainly right that Extinction Rebellion’s demand that the country reaches net zero by 2025 is physically impossible. Shedding the country’s attachment to growth does not on its own lead to a neutral carbon ledger. The massive amounts of investment, innovation and infrastructure required to get there would not take full effect within six years. But to say that anything earlier than a 2050 target isn’t credible is a grave and dangerous mistake. At current levels of emissions, the world will reach 1.5°C of warming in 12 years. Each year that the UK delays radical action, the necessary yearly emissions cuts to hit net zero become greater, making it ever harder to avoid catastrophic warming. Even with immediate action, the world is still pinning hopes on carbon capture and storage technologies that may never work at scale. Working towards an earlier target with steeper emissions cuts would require initial uncomfortable changes, but would massively lower our reliance on these incredibly uncertain technologies. The report’s claim that the 2050 target represents the UK’s “highest possible ambition” speaks more to the country’s economic priorities than to reality. Ten years ago, the committee wrote that an 80% reduction in emissions by 2050 (against 1990 levels) was at the limit of feasibility. Now, the committee has changed its mind, stating that net zero can be achieved by the same date, for the same price: 1-2% of GDP. This small percentage is seen as the maximum acceptable cost of mitigating climate change, even in the face of the trillion-pound losses that are forecast if we do not take sufficient action. Is this really all the fate of present and future generations at risk of climate change is worth? The report does hold some positives. It is unequivocal that current policy is insufficient to achieve even the UK’s existing targets and urges a ramping up in actionable efforts. It criticises plans to phase out fossil fuel powered cars by 2040 as too late and too vague, and calls for the government to confront failures to plant enough carbon-absorbing trees and decarbonise heating systems. But in focusing on what is “feasible” rather than necessary, the committee’s trajectories simply do not reflect the radical carbon reductions the UK can make, and will only end the UK’s contribution to global warming on paper. The year 2025 may be an unrealistic target, but missing that by a few years is much less dangerous than hitting a 2050 target comfortably. We need to take every leap we can and fast, even if it is into the dark. As Greta Thunberg says, if your house is on fire, you don’t tell people that the fire brigade will be along in a few hours – you act. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"
Share this...FacebookTwitterEnergy giant British Petroleum (BP) announced that it was shutting down its solar module business for good. In 2000 the corporation had announced that it would expand aggressively into promising renewable energies, and dubbed itself “Beyond Petroleum”.Today, according to the online leftist “TAZ” daily here:
Already last year the company shut down its own solar modules plants, and now also its business with project development is ended – 30 years after BP Solar was founded.
BP is the latest in the long string of failures that have swept over the solar industry recently. Massive subsidies by governments had caused a boom in solar installations, but with solar electricity costs still sky high, governments have recently cut back subsidies dramatically, thus making investment in solar modules less attractive. Massive competition from low-cost countries in Asia, including China, have led to plummeting prices and over capacity in solar module supply. The TAZ writes:
Annual production capacity is about 50 gigawatts, but the global demand this year is only about 21 gigawatts.”
This is certainly not good news for all the German solar plants that opened with much fanfare just few years ago, especially in East Germany – many with government support. These solar module plants were ballyhooed as high tech job machines and rescuers of the climate. Today you have to feel awfully sorry for the poor workers – duped again by bogus future scenarios and false promises.
Of course the German solar cell manufacturers are crying about “unfair trade practices” by Asian producers. You see, it’s not enough that their customers are opulently subsidized in the purchase of their solar modules, German manufacturers also want trade protection as well. Then the solar energy playing field would be level!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“It all comes down to reestablishing fair competition,” said Solarworld CEO Frank Asbeck. The TAZ also writes how things don’t look sunny for the German solar industry:
The solar industry in Germany faces a collapse. […] The Sarasin Bank puts companies Conergy, Q-Cells, Solar-Fabrik, and Sunways under the category of ‘endangered’.”
In summary, the very people who warned us of catastrophic global warming, climate change, global weirding, extreme weather events, also told us that solar energy was the future – the job machine! Indeed, just when everything solar is collapsing around them, many politicians are still cluelessly running around a preaching us the virtues of solar energy.
Don’t waste your breath telling these pols that global temperatures haven’t risen in over a decade.
Also also read more here at Bloomberg (The rest of the MSM is ignoring this embarrassment).
NEWS: German manufacturer Solar Millenium announces it is insolvent –Read at Der Spiegel!
Share this...FacebookTwitter "
"
Share this...FacebookTwitterDr. Wolfgand Thüne
As the science of the warmists gets exposed as woefully inadequate, slipshod and flawed, all they can do now is give each other awards in pompous ceremonies in an effort to generate a (fake) sense of achievement and contribution. They’ve been reduced to a pretend world.
One example is the Technical University of Berlin recently awarding Prof. Hans Joachim Schellnhuber an honorary doctorate. Schellnhuber is Director of the infamously über-alarmist Potsdam Institute for Climate Impact Research (PIK) and is chairman of the WBGU Advisory Council.
Last year Schellnhuber and his WBGU published a “masterplan” calling for the dilution of democracy worldwide and forcing societies to take up a highly restricted “sustainable path” that would keep the planet from reaching his nine mathematically concocted “dangerous tipping points”. In it he advocates indoctrination and “changes in awareness”.
Schellnhuber even once publicly stated that 1 billion people would be the ideal human population for the planet, which would be like eliminating all the world’s people except China and letting them have it all to themselves.
Schellnhuber, however, having clearly drifted from science to radical policy formulation and advising, is coming under increasing fire from number of scientists and critics.
For example, Dr. Wolfgang Thüne, a retired German meteorologist and member of the European Institute for Climate and Energy (EIKE) commented yesterday on Schellnhuber’s honorary doctorate:
That Professor Dr. Hans-Joachim Schellnhuber, the inventer of the “tipping elements”, is now being celebrated and awarded an honorary doctorate is amazing. But what’s even more amazing is that he received this from the TU Berlin for his ‘outstanding scientific achievements in the fields of climate impact research and policy counselling’. Did the TU Berlin, in its addiction to political attention, even stop to consider just how much it is damaging its excellent reputation among the professional world?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The climate science by Schellnhuber & Co. is pure voodoo-magic spreading fear among the public and reaching big time into the pockets of taxpayers.
The Potsdam Institute for Climate Impact Research (PIK) is senselessly wasting the money of taxpayers. ‘Climate protection’ is a scientific swindle because the weather is not something that can be protected.”
Thüne even demands that the PIK be shut down immediately.
That would be a small but effective step in preventing the national debt from getting out of control.“
Dr. Wolfgang Thüne is a certified meteorologist, who for years was a meteorology expert for ZDF television, and has written about the falsifiications and fraud surrounding the UN IPCC. He is the author of numerous books. His latest work is: “Prophets in the Struggle for the Climate Throne. How primal fear is used in the struggle for money and power.”
The latest German skeptic book exposes junk climate science and shady climate politics.
 
Share this...FacebookTwitter "
"In the past ten years the UK’s electricity mix has changed dramatically. Coal’s contribution has dropped from 40% to 6%. Wind, solar power and hydroelectric plants now generate more electricity than nuclear power stations, thanks to rapid growth. Demand for electricity has also fallen, reducing the country’s dependence on fossil fuels. Thanks to these three factors, the carbon intensity of Britain’s electricity has almost halved, from more than 500g of CO₂ per kilowatt-hour in 2006 to less than 270g in 2018. Progress has been so quick that a fully low-carbon power sector in Britain has transformed from a faint pipedream into a real possibility, according to the CEO of one of the UK’s “big six” energy companies. Indeed, the National Grid now expects to be able to operate a zero-carbon electricity system by 2025. Already approaching that milestone on windy, sunny days, the country’s first hours of 100% low-carbon electricity could soon be here – but staying at 100% throughout the year will be much more difficult to achieve. So what does the journey to decarbonisation look like? To paint the UK’s energy future, it is important to first understand how electricity is generated today. The graph below is a visualisation of British electricity generation in October 2018. Periods of strong wind (in red) and sun (yellow) combined with nuclear power (green) meant that on some days, more than 75% of electricity came from low-carbon sources. With solar prices still decreasing and the government recently agreeing a major deal for offshore wind to produce one-third of the UK’s power by 2030, the country’s first hours of low-carbon power could arrive within the next five years. But the graph also highlights the other side to the UK’s energy story. When the wind is weak and the skies dark, low-carbon sources provide less than 25% of electricity generation. On average, low-carbon technologies accounted for more than 45% of British electricity in 2018 – and almost half of that came from nuclear plants. Saying goodbye to fossil fuels quickly might mean accepting that the ever-controversial form of energy will play some role in the UK’s electricity mix in the medium term.  Even with the aid of nuclear power, electricity consumption in Britain is set to increase dramatically in the coming decade. As electric cars continue their journey to the mainstream, traditional transport fuels will be replaced by electricity. The yearly energy demand of transport fuels is currently more than double the UK’s national electricity consumption. Similarly, plans to decarbonise the UK’s heat generation – currently 66% is generated by gas – by converting to electric heating systems will also place huge pressures on demand. During winter months, heat can consume more than three times the daily energy demands of electricity – and over a full annual cycle it constitutes 50% of total energy demand. Collectively, these factors will move the goalposts for 100% low-carbon electricity further and further away.  While the huge efficiency increase of electric vehicles over internal combustion engines should cushion the impact of electric vehicles on the UK’s energy future, the country will need to diversify its energy mix as much as possible to bring those goalposts back into sight. This means continued growth in wind, solar, hydro, biomass, energy efficiency and energy storage to carry the country through the calm, grey days. Precisely how much growth is needed depends exactly on the future of energy demand, but to give some perspective of scale, more than 80% of the total UK energy supply, including electricity, land transport and heat, still comes from fossil fuels. The tens of billions of pounds already invested in low-carbon electricity is just the start of the UK’s journey to decarbonised energy. It also means seeking alternative, non-electric methods to replace fossil fuels in heat generation. Capturing waste heat from industrial processes, geothermal heat from the ground and heat extracted from water bodies could all limit demands on the electricity sector and make it easier to achieve more low-carbon heat and power. Southampton already heats much of its city centre geothermally – and many cities can and should follow suit. Recent work published by the BritGeothermal estimates that geothermal energy alone could meet the UK’s heat demand for at least 100 years. Concerted and sustained effort from both government and individuals is required if the UK is to achieve a low-carbon nirvana in heat, transport and power. State support of the renewables industry through ensuring long-term investment security and regulations to create energy-efficient and electricity-generating new homes will be essential in the UK’s decarbonisation journey. The UK population will need to consume less energy individually, use energy more efficiently and use their voices and money to support renewable solutions. They will also need to elect representatives with a genuine ambition to decarbonise the country – rather than to commission new coal mines and fracking sites. Large-scale changes are already in motion. Shell recently stated that it wants to become the world’s largest electricity supplier and is among many oil giants investing heavily in renewables. While the need for new forms of energy presents big challenges for the UK it also offers a wealth of opportunities for the current generation to be part of an energy revolution. If the UK embraces the task, it could be joining Costa Rica, New Zealand and Norway as low-carbon powerhouses before the middle of the century. As one specialist at the start of his career and another nearing the end of his, we say bring that challenge on. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
nan
"

When is it appropriate to privatize the work of public prosecutors? And does it make things better or worse when “cause” lawyering is at issue? As Jeff Patch reports at Real Clear Investigations, a project called the State Energy & Environmental Impact Center at New York University supplies seasoned lawyers to the offices of nine state attorney general offices, plus D.C. They serve there in such roles as special assistant attorney general while being paid by the NYU project, which is funded by and closely identified with former New York City Mayor Michael Bloomberg. The catch, which explains why the program is not likely to hold appeal for AGs in some other states: “Under terms of the arrangement, the fellows work solely to advance progressive environmental policy at a time when Democratic state attorneys general have investigated and sued ExxonMobil and other energy companies over alleged damages due to climate change.”   
  
  
Private funding of lawyers inside public prosecutors’ offices is not a new idea. Iowa’s AG office, for example, told Patch that it has employed legal talent from an American Bar Association‐​supported program. In another variation, it is not unusual for prosecutors to accept funding from the insurance industry for efforts to combat insurance fraud. Undergirding the political viability of these schemes is the (perhaps wobbly) premise that the state office is not farming out influence over politically or ideologically sensitive policy matters to outside groups that may have their own agenda.   
  
  
The AG offices participating in the program (Illinois, Maryland, Massachusetts, New Mexico, New York, Oregon, Pennsylvania, Virginia, and Washington state, as well as the District of Columbia) might plausibly argue that the projects they’re paying the Bloomberg embeds to work on are mostly ones they’d want to pursue zealously in any case, such as suing the EPA and other federal agencies over alleged lapses. Critics point to the ideologically fraught nature of the work and say the arrangement could violate some states’ ethics rules or generate improper conflicts of interest, as through an obligation to report activities back to the Bloomberg center.   
  
  
The spotlight on backstage doings at state AG offices arises from reports by Chris Horner of the Competitive Enterprise Institute based on public records requests that were fought tooth and nail by various AGs. (Besides the CEI report on attorneys general, Horner’s written a companion report on governors.) CEI is anything but a disinterested party in all this, of course, having been hit with a AG subpoena (later beaten back in court) over its supposedly wrongful advocacy on climate issues. That was itself part of a subpoena campaign targeting more than 100 research and advocacy groups, scientists, and private figures on the putatively wrong side of climate debates, which we and others decried at the time as a flagrant attack on rights protected by the First Amendment. 
"
"
Share this...FacebookTwitterA new paper authored by Reinhard Böhm of the Austrian Central Administration For Meteorology (ZAMG) refutes the notion that anthropogenic warming is causing an increase of climate extremes and making weather more variable and extreme.

Pressure – temperature – precipitation (Source ZAMG)
The paper uses the monthly resolved data of the HISTALP data collection, which provides 58 single series for three climate elements: air pressure, air temperature and precipitation, which start earlier than 1831 and extend back to 1760 in some cases.
The paper’s abstract writes:
The main goal is the analysis of trends or changes of high frequent interannual and interseasonal variability. In other words, it is features like extremely hot summers, very cold winters, excessively dry or wet seasons which the study aims at.”
The paper also concentrates on the recent three decades because “they are the first 30 years with dominating anthropogenic greenhouse gas forcing”.
Conclusion? No change!
The author of the warmist ZAMG doesn’t mince his words:
We can show that also this recent anthropogenic normal period shows no widening of the PDF (probability density function) compared to the preceding ones.”
Not only did the author find no change in variability, but he also detected a “centennial oscillating structure”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The abstract continues (emphasis added):
It shows that interannual variability changes show a clear centennial oscillating structure for all three climate elements in the region. For the time being we have no explanation for this empirical evidence.”
Please allow me to suggest one: take a look at the sun! As it stands, only an absolute moron can now remain oblivious to the huge, growing body of evidence pointing to solar activity cycles.
Böhm continues, reluctantly admitting there may be other mysterious factors out there playing a role:
We argue that it should not be an artifact of any remaining data problems, but of course a centennial cyclic effect based on 250 years of data only is not really well consolidated in terms of sample length. But it is at least an interesting new feature and the subject is open for scientific discussion and for further studies dealing with circulation effects, long-term memories in the oceans etc.”
Hooray! It seems they are beginning to acknowledge the oceans as a possible factor in climate change! Thus there’s hope that one day they’ll realize the sun may be involved as well.
Finally, CO2 Handel here writes:
Neither during the last 250 years nor the last 30 years, which have been strongly impacted by man, has the seasonal and annual fluctuation range hot-cold and dry-wet become greater.”
And
‘The results are certainly surprising for many,’ explains climatologist and study-author Reinhard Böhm. We often hear there are no longer any transitions between seasons and that spring and autumn, as well as winter and summer, are increasingly characterized by extreme cold-warm fluctuations. ‘Our study clearly shows that this is not the case.'”
That is quite an admission for an author from a warmist outfit like the ZAMG.
 
Share this...FacebookTwitter "
"Many of us know from personal experience that raising children can be stressful, but a new study reveals that stress can be enough to affect the quality of parenting – in mongooses, at least.  A recent study investigates the relationship between stress hormones and parental care in the banded mongoose, a small African mammal that lives in large family groups. The research team found that individual banded mongooses that spend a lot of time caring for pups lose weight and have elevated levels of stress hormones (glucocorticoids). This in turn affects the care they can invest in subsequent litters of pups. A feedback loop is created between care and stress, with attentive care leading to stress, and high stress levels then leading to a reduction in care. As is the case in humans, the decisions animals make will affect them later in life. In ecology this is called a “carry-over effect”. While this is a well-known concept in biology, little is known about the physiological mechanism that lies behind it. This study from Jenni Sanderson and colleagues shows stress hormones are likely to be responsible.  The mongoose is well-suited to the study because, unusually, it is a “cooperative breeder” that rears pups in large communal litters. Several females become pregnant at the same time and give birth together, down to the same night. The resulting litter of pups is reared communally by the group, with most adult members contributing something towards pup care. Also unusual is that, after weaning, each pup from the communal litter forms a bond with a single adult (not necessarily the parent) known as an escort. This adult feeds its escorted pup, but also carries, grooms and protects it from predators. Some adults are diligent escorts, others less so, or choose not to escort a pup at all. By controlling for factors such as age, sex, and quality of the territory they live in, the researchers found that the care each adult gives varies considerably, suggesting that stress hormone levels may be the cause. This research is possible because of a 20 year long research project on banded mongooses living wild in Queen Elizabeth National Park in Uganda, following the lives of individual mongooses from birth to death. All the mongooses in the study are accustomed to the presence of researchers, so observers can stand just metres away and still be ignored by their subjects. They have even been trained to step onto portable electronic scales so that they can be weighed and body condition monitored – essential for a study such as this one. Hormone levels are monitored by collecting and testing their droppings. The quality of care provided by escorts could have a huge effect on their pups: pups with good escorts get more food, grow faster and are more likely to survive than those with poor escorts. This stretches into adulthood, as better escorted pups start breeding earlier and so may have greater evolutionary fitness. The results of this study don’t only apply to mongooses, but are likely to apply to other species too (perhaps even humans). Links between stress hormones and reproduction have been shown in other species such as house sparrows. However, species where one or two parents care for offspring may differ from banded mongooses in their response to stress. For bi-parental species, stressed females may lead to smaller broods or litters, smaller eggs or young, or a reduced chance of conceiving. In contrast, carers in cooperative breeding species may have little ability to control what happens prior to the birth of the litter – instead stressed carers are limited to varying the care they give their pups. These effects may also apply to humans. Stress hormones have been shown to interfere with the human ovulatory cycle. However, the complexities of the presence of siblings of different ages, different needs, and the many ways in which parents care for their children would make studying this effect in humans extremely difficult."
"**Most of England is expected to be placed in the two toughest tiers of coronavirus restrictions when the national lockdown ends next Wednesday.**
Health Secretary Matt Hancock will set out the plans in the Commons later.
BBC political editor Laura Kuenssberg said she understood only a ""handful"" of areas would have the lowest level of restrictions, tier one.
Most areas, including London, would be in tier two with ""significant numbers"" in tier three - the highest level.
Differences between the tiers include limits on where households can meet up - for instance, in the new tier one, the rule of six applies indoors and out. In tier two, the rule of six remains outdoors but there is no household mixing indoors.
Chancellor Rishi Sunak told BBC Breakfast the new tiers represent a ""tangible change compared to the last four weeks"" of lockdown in England.
""There are significant differences to that - more of our life can resume, more of our economic activity can resume,"" he said.
The system will be regularly reviewed and an area's tier level may change before Christmas - the first review is scheduled for 16 December.
Decisions on tiers are based on public health recommendations informed by the following factors:
An area could be moved up a tier if these indicators are not improving, and likewise down to a lower one if they improve.
Mr Sunak said a meeting of the Cabinet would consider the new tiers on Thursday morning, before Mr Hancock addresses the Commons.
The final decisions will be made by Prime Minister Boris Johnson, the government said. He will lead a Downing Street news conference later.
The new system will be stricter than the previous one and more local authorities will be in higher tiers.
Mr Hancock has urged people to follow the rules so ""together we can get out of these tough measures"".
""I know for those of you faced with tier three restrictions this will be a particularly difficult time but I want to reassure you that we'll be supporting your areas with mass community testing and extra funding,"" he said.
Areas placed in tier three will be eligible for rapid or ""lateral flow"" tests - which give results in about 20 minutes without the need for a lab - to help bring down infections and reduce restrictions.
And they will be offered support by NHS Test and Trace and the armed forces to deliver a six-week rapid community testing programme.
Tier allocations will be reviewed for the first time by 16 December, allowing for ""the possibility of areas which continue to make progress in slowing the spread of the disease"" to be moved down a tier before Christmas, the government said.
On Wednesday, the government recorded another 696 UK deaths within 28 days of a positive Covid test, the highest daily figure reported since 5 May. Total deaths now stand at 56,533.
A further 18,213 lab-confirmed cases of coronavirus were also reported.
It is clear the government is taking a tougher approach to regional tiers post lockdown.
Not only has it beefed up the system - the top two tiers in particular have stricter rules for hospitality - but very few local authority areas will end up in the bottom tier with the most relaxed restrictions.
By the time England went into lockdown 170 local authority areas - well over half - were still in tier one, meaning mixing indoors was allowed.
Very few will start there this time.
That's because an analysis by the University of East Anglia found the bottom tier was not effective at suppressing the virus.
But it did find the top two tiers had an impact.
One of the problems, it said, was that the government was too slow to move areas up a tier when infection rates started to rise.
The government will be much more cautious this time, starting from the premise that it is better to have areas in higher tiers and move them down over time rather than the reverse.
But for the public it means post-lockdown life will still see some very strict restrictions for the immediate future.
London Mayor Sadiq Khan said it would be the ""right and sensible decision"" for the capital to be placed in tier two, as he warned that tier three would be a ""hammer blow"" to businesses.
Liverpool City Region Mayor Steve Rotheram said he hoped the area - which was the first area of England to enter the highest tier in October - would not return to tier three restrictions.
He said the city region had made ""remarkable"" progress since being put into tier three, with infection rates in two areas dropping from about 750 per 100,000 people ""to 180 across the city region"".
Mayor of Liverpool Joe Anderson told BBC Radio 4's Today programme the city's mass testing programme had enabled it to reduce infections.
He said the armed forces have been in the city for three weeks carrying out mass testing and bringing the virus ""back under control again"".
Meanwhile, Greater Manchester Mayor Andy Burnham said it was ""more likely than not"" his area would be put into tier three.
He said although infection numbers in Greater Manchester were still high, the rates were falling.
Elsewhere, Lancashire's council leaders have submitted a proposal to the government to divide the county into two different tiers when the lockdown ends next week - as coronavirus rates are lower in places like Lancaster and Wyre than they are in East Lancashire.
A request has been made for Hyndburn, Rossendale, Burnley, Pendle and Preston to go into tier three restrictions while Fylde, Wyre, Lancaster, Chorley, South Ribble, Ribble Valley and West Lancashire would go into tier two.
This would mean there would be different restrictions on socialising and the hospitality sector in different parts of Lancashire.
Meanwhile, the Nightingale Hospital in Exeter will receive its first coronavirus patients on Thursday, officials have confirmed.
The 116-bed hospital built on the site of a former retail unit will treat people with Covid-19, taking patients transferred from the Royal Devon and Exeter NHS Foundation Trust as it is ""very busy"".
Devolved administrations in Scotland, Wales and Northern Ireland have the power to set their own coronavirus regulations, though all four UK nations have agreed a joint plan for Christmas.
In Scotland, there is a new five-tier system of restrictions and all non-essential travel between Scotland and the rest of the UK is not allowed.
The Scottish government has also said that Christmas bubbles of three households there should contain no more than eight people. Children under 12 are not counted towards the eight.
In Wales, lockdown restrictions were eased on 9 November and current rules allow two households to form a bubble with up to 15 people able to meet for organised indoor activities.
And Northern Ireland will go into a two-week circuit-break lockdown from 00:00 GMT on Friday 27 November."
"**A tougher three-tiered system of local restrictions will come into force in England when the lockdown ends on 2 December, Downing Street has said.**
Boris Johnson is expected to set out his plan - including details of how families can see different households at Christmas - to MPs on Monday.
More areas are set to be placed into the higher tiers to keep the virus under control, No 10 said.
And some tiers will be strengthened to safeguard lockdown progress.
Some local measures will be the same as those in the previous three-tier system, which was in place in England until the current lockdown began.
But the government's Scientific Advisory Group for Emergencies (Sage) is expected to publish research on Monday saying the previous restrictions were not strong enough.
The government will identify the tiers that each area will be placed into on Thursday.
Chancellor Rishi Sunak told the BBC's Andrew Marr the 10pm closing time for pubs and restaurants was one of the things it was looking to ""refine"".
It is understood rules will be relaxed to give people an extra hour to finish their food and drinks after last orders at 10pm.
Kate Nicholls, chief executive of UK Hospitality, said this would help businesses - but would be ""meaningless"" unless people were allowed to socialise with friends and family, particularly over the crucial Christmas period.
Pre-lockdown, there were three tiers of restrictions - medium, high, and very high:
Newspaper reports suggest rules could be temporarily relaxed UK-wide over Christmas. Several families could be allowed to join in one ""bubble"" and mix between 22 and 28 December, according to the Daily Telegraph.
Ministers have made clear the festive season will be different to normal - with some restrictions expected to remain in place.
BBC political correspondent Nick Eardley said conversations about Christmas between the different nations of the UK were ongoing.
Sources believe a deal is probable later next week - but it is unlikely to be signed off before the prime minister's announcement on Monday.
The four nations have different Covid rules but ministers are hoping to agree a joint approach for the festive period.
Government ministers and advisers have been hinting about new tougher tiers over the past week.
Before lockdown there was some evidence that tiers two and three were having an impact, but not tier one.
Crucially, both the top two tiers involved banning mixing inside homes, so one option being discussed behind the scenes is introducing a ban across all the tiers until winter is over.
The exception will, of course, be Christmas.
That is a move that divides opinion. But the government sees it as a necessity, believing significant numbers of people will ignore any attempt to ban gatherings over the festive period.
It is also a recognition the public needs a break from the long hard slog of the pandemic.
Infection rates will of course rise, but that will be offset to some extent by a wider boost to wellbeing.
Prof Calum Semple, from the University of Liverpool, said he hoped it would be possible to relax rules over Christmas if the new tiered system worked but warned ""there will be a price"", including tighter restrictions in the future.
However, Prof Semple, who is a member of Sage, told Sky News's Sophy Ridge there was ""a lot to be optimistic about"".
He said he expected mass vaccination of the general population to happen towards next summer, which would give ""broad immunity"" and allow a ""return back to normal"".
MPs are expected to vote on the new tier system in the days before it comes into force.
Many Conservative MPs are opposed to stricter measures, with 70 signing a letter coordinated by the recently-formed Covid Recovery Group (CRG), saying they cannot support a tiered approach unless they see evidence measures ""will save more lives than they cost"".
Earlier this month, 32 Conservatives rebelled by voting against the current lockdown and 17 more, including former Prime Minister Theresa May, abstained.
In a letter to the prime minister on Saturday, the CRG, led by former chief whip Mark Harper and ex-Brexit minister Steve Baker, warned against inflicting ""huge health and economic costs"".
The letter said: ""We cannot live under such a series of damaging lockdowns and apparently arbitrary restrictions, and expect our constituents to be grateful for being let out to enjoy the festive season, only to have strict restrictions imposed on them afterwards that cause them health problems and destroy their livelihood.""
Asked whether he would publish a cost-benefit analysis of any future measures, as called for by the CRG, the chancellor told Sky News it was ""very hard to be precise"" on the economic impacts of individual restrictions.
Labour has so far supported the need for restrictions to slow the spread of Covid-19, making a Commons defeat on the plan unlikely.
But shadow chancellor Anneliese Dodds told the BBC her party wanted clarity from the government over how tiers would be decided and the support available for businesses.
On Saturday, the UK recorded another 19,875 new coronavirus cases and 341 deaths within 28 days of a positive test.
The number of deaths was down from 511 on Friday, and 462 on Saturday 14 November."
"British Gas has teamed up with Volkswagen to accelerate the rollout of its electric vehicles (EV) across UK roads by helping drivers to charge up at home at a lower price. The UK’s biggest energy company has agreed a three-year deal with the carmaker to offer owners of new electric VW vehicles a one-stop package to help plug into home charging. Under the exclusive agreement British Gas engineers will be responsible for installing the fastest home car-charger available, alongside an energy tariff that offers cheaper rates for nighttime charging. The tie-up could help make it easier for drivers to switch to an electric VW vehicle, and may also provide a new earnings stream for the embattled energy supplier, which fell to an all-time low last year. Alex Smith, the managing director of Volkswagen UK, said 2020 would be a “landmark year” for group, after launching the ID.3 model. It plans to produce 330,000 vehicles a year by 2021. The cars are capable of travelling for 205-340 miles on a single charge, and Smith believes the deal with British Gas could “give customers even more confidence, as they make the switch to emission-free driving”. The collaboration could help British Gas fend off rising competition from a string of challenger brands by relying more on energy services such as boiler repairs, insurance cover and home car charging to generate revenue. The agreement with VW comes less than a year after the owner of British Gas, Centrica, struck a deal with Ford to market its car chargers and EV-charging tariffs from US carmaker’s forecourts across the UK. A similar strategy is being pursued by Ovo Energy, the UK’s second-largest energy supplier, and Scottish Power, which have both collaborated with Nissan on small-scale deals to help install compatible home chargers for its Nissan Leaf model. Centrica is under pressure to prove to shareholders that its strategy will pay off, after reporting a loss of more than £1bn for 2019, after the government’s energy price cap cut earnings at British Gas to all-time lows. The chief executive, Iain Conn, is to step down this year and the company is yet to announce a successor. Sarwjit Sambhi, the head of Centrica’s consumer business, said it was committed to finding “a pathway for the energy transition”, which is in line with the Paris agreement by “helping our customers reduce their emissions, reducing the emissions of the energy system as a whole, and reducing our own”. “We made material progress on all of these during 2019 and are committed to a plan for delivering net zero by 2050,” he said."
"It is a global emergency that has already killed on a mass scale and threatens to send millions more to early graves. As its effects spread, it could destabilise entire economies and overwhelm poorer countries lacking resources and infrastructure. But this is the climate crisis, not the coronavirus. Governments are not assembling emergency national plans and you’re not getting push notifications transmitted to your phone breathlessly alerting you to dramatic twists and developments from South Korea to Italy. More than 3,000 people have succumbed to coronavirus yet, according to the World Health Organization, air pollution alone – just one aspect of our central planetary crisis – kills seven million people every year. There have been no Cobra meetings for the climate crisis, no sombre prime ministerial statements detailing the emergency action being taken to reassure the public. In time, we’ll overcome any coronavirus pandemic. With the climate crisis, we are already out of time, and are now left mitigating the inevitably disastrous consequences hurtling towards us.  While coronavirus is understandably treated as an imminent danger, the climate crisis is still presented as an abstraction whose consequences are decades away. Unlike an illness, it is harder to visualise how climate breakdown will affect us each as individuals. Perhaps when unprecedented wildfires engulfed parts of the Arctic last summer there could have been an urgent conversation about how the climate crisis was fuelling extreme weather, yet there wasn’t. In 2018, more than 60 million people suffered the consequences of extreme weather and climate change, including more than 1,600 who perished in Europe, Japan and the US because of heatwaves and wildfires. Mozambique, Malawi and Zimbabwe were devastated by cyclone Idai, while hurricanes Florence and Michael inflicted $24bn (£18.7bn) worth of damage on the US economy, according to the World Meteorological Organization. As the recent Yorkshire floods illustrate, extreme weather – with its terrible human and economic costs – is ever more a fact of British life. Antarctic ice is melting more than six times faster than it was four decades ago and Greenland’s ice sheet four times faster than previously thought. According to the UN, we have 10 years to prevent a 1.5C rise above pre-industrial temperature but, whatever happens, we will suffer. Pandemics and the climate crisis may go hand in hand, too: research suggests that changing weather patterns may drive species to higher altitudes, potentially putting them in contact with diseases for which they have little immunity. “It’s strange when people see the climate crisis as being in the future, compared to coronavirus, which we’re facing now,” says Friends of the Earth’s co-executive director, Miriam Turner. “It might be something that feels far away when sitting in an office in central London, but the emergency footing of the climate crisis is being felt by hundreds of millions already.” Imagine, then, that we felt the same sense of emergency about the climate crisis as we do about coronavirus. What action would we take? As the New Economic Foundation’s Alfie Stirling points out, a strict demarcation between the two crises in unwise. After all, coronavirus may trigger a global slowdown: the economic measures in response to this should be linked to solving the climate crisis. “What tends to happen in a recession is policy-makers panic about what the low-lying fruits are; it’s all supply chains and sticking plasters,” he tells me. During the 2008 crash, for example, there was an immediate cut in VAT and interest rates, but investment spending wasn’t hiked fast enough, and was then slashed in the name of austerity. According to NEF research, if the coalition government had funded additional zero-carbon infrastructure, it would not only have boosted the economy but could have reduced residential emissions by 30%. This time round, there’s little room to cut already low interest rates or boost quantitative easing; green fiscal policy must be the priority. What would be mentioned in that solemn prime ministerial speech on the steps of No 10, broadcast live across TV networks? All homes and businesses would be insulated, creating jobs, cutting fuel poverty and reducing emissions. Electric car charging points would be installed across the country. Britain currently lacks the skills to transform the nation’s infrastructure, for example replacing fuel pumps, says Stirling: an emergency training programme to train the workforce would be announced.  A frequent flyer levy for regular, overwhelmingly affluent air passengers would be introduced. As Turner says, all government policies will now be seen through the prism of coronavirus. A similar climate lens should be applied, and permanently. This would only be the start. Friends of the Earth calls for free bus travel for the under-30s, combined with urgent investment in the bus network. Renewable energy would be doubled, again producing new jobs, clean energy, and reducing deadly air pollution. The government would end all investments of taxpayers’ money in fossil fuel infrastructure and launch a new tree-planting programme to double the size of forests in Britain, one of Europe’s least densely forested nations. There is a key difference between coronavirus and climate crisis, of course, and it is shame. “We didn’t know coronavirus was coming,” says Stirling. “We’ve known the climate crisis was on the cards for 30 or 40 years.” And yet – despite being inadequately prepared because of an underfunded, under-resourced NHS – the government can swiftly announce an emergency pandemic plan. Coronavirus poses many challenges and threats, but few opportunities. A judicious response to global heating would provide affordable transport, well-insulated homes, skilled green jobs and clean air. Urgent action to prevent a pandemic is of course necessary and pressing. But the climate crisis represents a far graver and deadlier existential threat, and yet the same sense of urgency is absent. Coronavirus shows it can be done – but it needs determination and willpower, which, when it comes to the future of our planet, are desperately lacking. • Owen Jones is a Guardian columnist"
"The UK faces the possibility of blackouts due to electricity shortages in the near future – maybe even this winter. The country therefore needs a strong balanced mix of traditional and renewable energy more than ever.  As Scotland generates more electricity than it uses, most of these potential blackouts will be in England. Therefore it is all the more puzzling that the UK government has failed lamentably to ensure adequate support for offshore wind.  For a windy island nation, offshore wind power generation is vital; it not only complements traditional generation methods but does so in a more sustainable way. And yet projections have been significantly scaled back: UK government estimates of expected offshore wind generation by 2020 have gone from 18 gigawatts (DECC, back in 2012) down to just 10 GW (Crown Estate, June 2014). This short-sighted approach has seen many projects in Scottish waters being mothballed or cancelled altogether in the past couple of years. RWE, Scottish Power, Centrica and SSE – four of the UK’s “big six” energy suppliers – have all dropped out of new wind projects in the past year. The latest casualty is the French behemoth Technip which is withdrawing from offshore wind-power production in Scotland with a possible loss of 190 jobs. The cancellations have been caused by a variety of issues – political will, challenging ground conditions, potential environmental impacts. These factors combine to affect the economic viability of new wind farms. Accessing finance for these large, capital-intensive projects is a major challenge and investors don’t want to put their money into a sector with an uncertain future.  This is the worst of both worlds: fewer wind farms than expected, which in turn may be insufficient to drive costs down to the target of £100/MWh for offshore wind. It is at this rate the industry is viewed to be commercially viable – and innovative companies across the industry such as Technip have already made significant efforts to deliver wind power this cheaply. Government policy could address this but the coalition’s flagship initiative – Electricity Market Reform (EMR) – is in a state of disarray and has led to a hiatus in offshore wind investment. The pot of government money available does not appear to be sufficient to fund new and very expensive nuclear plants at the same time as offshore wind. Wind has been the sacrificial lamb, in favour of the Conservatives’ ideological preference for nuclear power. Under the coalition, the UK renewables programme faces stagnation, despite stronger public support for renewable energy over the nuclear option. What is particularly disappointing about the Technip announcement is that the company’s prior experience in building oil and gas rigs could have been useful in the development of floating offshore wind farms, which offer great potential for cost reduction and exploitation of wind resources further from shore in deeper water.  However, it’s clear that Technip just can’t see continued involvement as a good deal and this is of concern to the wider industry. After all a healthy supply chain depends on a succession of new offshore wind projects to stimulate demand and investment. Scots may have voted No to independence but the debates over devolution and powers to set policy aren’t going anywhere. An increased voice for Scotland on its energy policy may not come a moment too soon for offshore wind and national energy security, even if that nation is the UK."
"
Share this...FacebookTwitterWhat follows is a press release from Longmont, Colorado-based Abound Solar (emphasis added): Read here!


Abound Solar is yet another government subsidized solar company that gets burned.

Abound Solar Press Release excerpt:
Abound Solar’s closure is an unfortunate but very real consequence of the continued slide in crystalline silicon (c-Si) pricing and the increased competition for limited global demand of solar modules,” said MJ Shiao, Senior Analyst at GTM Research. “Abound was still in the earlier stages of technology and commercial development and despite over $220 million in private investment and $70 million drawn from its $400 million U.S. Department of Energy (DOE) loan guarantee, simply didn’t have the cost and downstream reach to survive in the tumultuous solar market.
Abound’s cadmium telluride (CdTe) product had little differentiation from First Solar and also suffered from lower efficiency,” said Shyam Mehta, a Senior Analyst at GTM. “Produced at lower scale and likely a higher cost, the chance for survival in the current market environment was always slim. Unfortunately, Abound and other module manufacturing closures including thin film and c-Si suppliers alike, is still just the tip of the iceberg. GTM Research forecasts at least 21 GW of PV module manufacturing capacity to retire by the end of 2015.”
For further comment from GTM Research, please contact VP of Research, Shayle Kann at kann@gtmresearch or by phone at +1 617 500 4216.”
Read more here. RINOs got in on the act too!
Abound also had support from the Republican side. Indiana’s GOP governor, Mitch Daniels, supported an $11.85 million tax credit for the firm, and “two Abound investors were major Republican donors who have given more than $100,000 to Republicans in the last few years.” according to reports in the National Review.”
 
Share this...FacebookTwitter "
"**There have been more than 1.6 million confirmed cases of coronavirus in the UK and about 60,000 people have died, government figures show.**
However, these figures include only people who have died within 28 days of testing positive for coronavirus and other measures suggest the number of deaths is higher.
**Find out how the pandemic has affected your area and how it compares with the national average:**
If you can't see the look-up click here.
After the first peak in April, cases started rising again in July, with the rate of growth increasing sharply in September and October, before falling again in the past two weeks.
On Wednesday, the government announced a further 16,170 confirmed cases.
It is thought the infection rate was much higher during the first peak in spring, but testing capacity at the time was too limited to detect the true number of daily cases.
The data for cases can also be broken down by region and comparing the change in those figures by week gives a sense of where there has been a recent increase in newly-reported infections.
Coronavirus infections in England have fallen by about a third during lockdown, according to a major study carried out by Imperial College London.
While some of the worst-hit areas saw the biggest improvements, cases have remained relatively high across England, according to the React-1 study, which is based on tests of more than 100,000 people between 13-24 November.
The latest figures from the Office for National Statistics (ONS), suggest about one in 185 (16,400 people) in Wales had the virus in the week ending 21 November.
In Northern Ireland rates are thought to be decreasing at around one in 145 people (about 12,700 people), while in Scotland, the figure was one in 115 (about 45,700 people).
The average number of daily deaths began to rise again in September, following the first peak in April.
On Wednesday, the government announced a further 648 deaths.
Of these, 555 deaths were in England, 51 in Wales, 38 in Scotland, and four in Northern Ireland.
Rules were amended over the summer to include deaths in the coronavirus total only if they occurred within 28 days of a positive test. Previously in England, all deaths after a positive test were included.
England has seen the majority of UK deaths from Covid-19. Using the 28-day cut-off, there have been more than 52,000.
Although hospital admissions for Covid-19 remain below the levels seen in the spring, there are big regional disparities.
The North West, North East and Yorkshire, and Midlands have seen the highest number of admissions but the situation in all three now appears to be improving.
Cases have risen across large parts of England, with other spikes in areas of Scotland, Wales and Northern Ireland.
The red areas on the map below are those currently seeing the highest number of cases per 100,000 people.
Restrictions have been tightened across the UK in an effort to tackle the number of rising cases.
In England, each local authority has been placed in one of the new three tiers following the end of the recent national lockdown.
Wales has announced a range of further measures, including a ban on pubs, restaurants and cafes serving alcohol, from Friday 4 December.
In Northern Ireland, a further two-week ""circuit-break"" lockdown began on 27 November.
Scotland has a five-tier system of alert levels with different measures in place in different parts of the country.
UK leaders have agreed to allow up to three households to meet indoors during a five-day Christmas period of 23-27 December.
When looking at the overall death toll from coronavirus, official figures count deaths in three different ways.
Government figures count people who died within 28 days of testing positive for coronavirus.
But there are two other measures.
The first includes all deaths where coronavirus was mentioned on the death certificate, even if the person had not been tested for the virus. The most recent figures suggest there had been almost 70,000 deaths by 20 November.
The second measure counts all deaths over and above the usual number at the time of year - that figure was more than 75,000 by 20 November.
The most recent figures available from the ONS are for the third week of November, which show there were 14,276 deaths registered in the UK.
Some 3,038 of these deaths involved Covid-19 - 199 more than the week before.
Deaths normally do rise at this time of the year, but the data from the ONS and its counterparts in Scotland and Northern Ireland show the second wave of the virus has pushed the death rate above the average seen over the past five years by about 21%.
Overall, the figures are still well below the peak of 9,495 deaths recorded in a week, reached on 17 April.
The ""R number"" is the average number of people an infected person will pass the disease on to.
If R is below one, then the number of people contracting the disease will fall; if it is above one, the number will grow.
The government's current estimate for the R number across the whole of the UK is 0.9 to 1.
The estimate for England is 0.9 to 1, while for Scotland it is 0.8 to 1. The estimate for Wales is 0.8 to 1 and in Northern Ireland it is 0.9 to 1.1.
The government has said in the past that the R number is one of the most important factors in making policy decisions."
"

From the NOAA National Weather Service Office in Miami comes this year end report:
2010 South Florida Weather Year in Review
Coldest December on Record Concludes Year of Extremes
December 30th, 2010: Temperature and precipitation extremes marked the weather of 2010 across South Florida. A cool and wet January through March was followed by the hottest summer on record, and then concluded with the coldest December on record for the main climate sites in South Florida (details on the above mentioned periods will be included below).
Here are December 2010 temperature averages for select sites (through 7 AM Dec 30th):
* Location of observations for each location have moved since the first year of record, but are representative of the city for record keeping purposes.
** Present Miami Beach and Moore Haven temperature data may not be totally comparable to historical data due to difference in time of daily reports which causes double-reporting of low temperatures.

Complete statistics of the record cold December for all sites above (except Moore Haven) will be provided in Record Reports which will be issued early on Jan 1, 2011.
The main culprit behind the cold temperatures in December 2010 was the same one which caused the cold winter of 2009-2010; a strongly negative North Atlantic Oscillation (NAO) and Arctic Oscillation (AO). When these atmospheric oscillations are in the strong negative phase, they essentially “flip” the weather pattern across North America, with upper-level high pressure and relative warmth over Greenland and Northeastern Canada and upper-level low pressure and cold over the eastern Continental United States, including Florida (Figure 1). This pattern forces the jet stream to plunge south from northern Canada into the southeastern U.S., transporting Arctic air masses into Florida.
A pronounced shift in the ENSO (El Niño Southern Oscillation) phase was noted in 2010, from a strong El Niño, or warm, phase to a borderline strong La Niña, or cold, phase. While this may appear at first glance to be a key contributor to the temperature extremes noted across South Florida during 2010, it is believed that it was the strongly negative NAO and AO, not the ENSO phase, which contributed to the cold temperatures in early and late 2010. A strongly phased NAO/AO operating on shorter time scales can override the longer-term ENSO phase.
As mentioned above, South Florida experienced its hottest summer on record in 2010 (with the exception of Naples which recorded its second hottest recorded summer). Despite the record hot summer, average yearly temperatures at the main climate sites will end up around 1 degree below normal, which will be the coolest calendar year since the early and mid 1980s, and among the top 10 on record (except for Miami). At secondary sites Miami Beach and Moore Haven, it was the coolest year on record (please note caveat below table).
Here are the 2010 temperature averages for the year for the primary climate sites through December 29:

** Present Miami Beach and Moore Haven temperature data may not be totally comparable to historical data due to difference in time of daily reports which causes double-reporting of low temperatures.
Some other interesting 2010 temperature statistics:
– Miami International Airport (MIA) observed 103 days of temperatures at or above 90 degrees, the 4th most on record. The average number of 90+ degree days per year is 51. MIA also had a record 45 days of low temperatures of 80 degrees or higher, besting the previous record of 39 set in 2009. The average number of 80+ degree low temperature days per year is 13. On the other end of the thermometer, MIA had 6 mornings with low temperatures below 40 degrees. This ties the 5th most number of sub-40 degree days on record. The average yearly number of sub-40 degree days is 2.
– Fort Lauderdale/Hollywood International Airport (FLL) observed 9 days of low temperatures below 40 degrees. This ties the 4th most number of sub-40 degree days on record. The average yearly number of sub-40 degree days is 3.
– Palm Beach International Airport (PBI) observed 106 days of temperatures at or above 90 degrees, the 8th most on record. The average number of 90+ degree days per year is 56. PBI also had a record 34 days of low temperatures of 80 degrees or higher, crushing the previous record of 17 set in 1900 and 2002. The average number of 80+ degree low temperature days per year is 6. On the other end of the thermometer, PBI had 18 mornings with low temperatures below 40 degrees. This easily breaks the previous record of 10 days set in 1920 and 1981. The average yearly number of sub-40 lows at PBI is 3. Six of the 18 days occurred in December, which breaks the previous monthly record for December of 5 set in 1962.
– Naples Regional Airport (APF) observed 125 days of temperatures at or above 90 degrees, the 12th most on record. The average number of 90+ degree days per year is 109. Naples also observed 13 days of low temperatures below 40 degrees. This ties the 5th most number of sub-40 degree days on record. The average yearly number of sub-40 degree days is 3. Eight of the 13 days occurred in December, which breaks the previous monthly record for December of 7 set in 1981.
Full report at NOAA/NWS here:
http://www.srh.noaa.gov/images/mfl/news/2010WxSummary.pdf
h/t to Joe D’Aleo
SEE ALSO:
USA record lows outpace record highs 19 to 1 this week
Update 1/1/11 1:11:11 PM:  obligatory Drudge Link screen-cap for Posterity:  great way to start 2011!



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e85d40741',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterAll the green jobs of the future that were promised – have now turned into dashed dreams. On the scrap heap along with the promises of communism, redistribution, third ways, etc.
FOCUS magazine here brings us up-to-speed on the trials and misery of Germany’s much maligned solar industry. The situation is worse than we thought.
It’s in a rapid death spiral, and it has claimed its latest victim: Solarhybrid AG. Last Tuesday evening, just a few dozen months after the company went public in 2008 amid the usual hoopla, it announced that it is bankrupt and is now seeking protection from its creditors. The sunny days are gone.
Solarhybrid’s collapse follows on the heels of Solon and Solar Millennium, who also recently went bust. The great German solar energy bubble has popped. With the current feed-in rates ending on April 1st, set to drop another 20%, the real monster crash still remains to come.
Solarhybrid was a specialist for large solar power plants, and was even optimistic about the future just as recently as October 2011. I bet the investors who jumped on board in October are really amused.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The German solar industry suffers from severe global over-capacity and falling government subsides, without which they can’t compete. Yet it should not be a surprise that it has come to this. Half of the world’s solar power generation capacity is installed in Germany, a country that gets as much sunshine as Alaska. It was only a matter of time before the reality of economics caught up. So far Germany has committed over €100 billion in solar subsidies over the next 20 years – for a power source that will hardly make a dent.
Other German solar companies such as giants Conergy und Q-Cells are beginning their death throes. Even once bullish Solarworld director Frank Asbeck, the die-hard optimist of the industry, is warning of really tough times ahead (emphasis added):
If the subsidy reductions continue, the entire branch will be forced to sell its products below cost. We can’t take this very long,’ he said Tuesday regarding the solar subsidy reductions. In the entire branch there is not a single company that is in the black. The same is true for Chinese manufacturers.”
If that doesn’t sound awful enough, then read what Klaus-Dieter Maubach, Technology Chairman at power giant Eon, is quoted as saying to Bloomberg (emphasis added):
In view of the competition from China, Germany’s solar industry will disappear completely within 5 years. Not a single employee will be working for a German solar company, because by then they will all have gone bankrupt.”
 
Share this...FacebookTwitter "
"When it comes to building sustainable buildings, humans have a lot to learn from termites. A recent study that colleagues and I published in Science Advances explains how some African termites maintain cool and stable temperatures in their nests throughout the year. The answer lies in the wall of the nests, composed of tiny but highly-connected pores. Today’s architects and builders are continuously seeking new and improved ways to cool buildings without using more energy. In fact, growing demand for air conditioners is one of the most critical blind spots in today’s energy debate – it has been projected that 10 new air-conditioning units will be sold every second for the next 30 years. As, the planet warms, people will increasingly need to build sustainable buildings that do not rely on vast amounts of energy for air conditioning. This is where termites come in. Termites – not to be confused with their distant relatives, ants – are insects with sophisticated social structures built on hierarchies – they have kings, queens, workers and soldiers. Like humans, these cockroach cousins prefer to build their own environment rather than adapting to one. For example, some termites have mastered sustainable fungus farming which helps them digest their food. One can also find termites living in arid regions that may be hostile to their bodies. To counteract this harsh environment (and in some cases to sustain fungus farming) they build structures that are sufficiently cool and humid – these are the famous mounds, or nests. For these reasons, termite nests have been widely studied as examples of effective ventilation and temperature control. Yet, exactly how they build their constructions has until recently remained somewhat poorly understood. Some species of termites, those that do farm fungus, build towering nests that are ventilated by a complex system of tunnels and openings. These tunnels regulate the nests’ ventilation the same way chimneys and windows work in a human house. In fact, a few buildings have been inspired by termite nests, such as the Eastgate Centre in Zimbabwe which successfully uses 90% less energy than a similarly sized building next door. But those termites that do not grow fungus build nests which appear smooth, and have no apparent openings. In spite of this, ventilation remains important for these termites. Until recently it wasn’t clear how these termites were able to keep air moving around their nests to avoid suffocating. That’s what colleagues and I – a team of biologists, engineers, and mathematicians in France and the UK – set out to investigate. Our research found that the tiny building blocks that make up the nests itself are optimised for these processes to occur naturally and effectively. We focused on a non-fungus-growing species, the grass harvesting termite, and began by excavating nests we found in Senegal and Guinea in West Africa. The nests are made of soil particles mixed with water and termite saliva. Despite not having apparent openings, the walls are composed of micrometre-sized pores.  We took tiny samples from the nests and put them under a micro X-ray scanner akin to that used in hospitals – but one which is capable of scanning with much finer resolutions. This revealed the termites build outer walls that actually contain both small pores and a series of slightly larger and interconnected pores. In fact, about 99% of the pore space was linked up.  Using the X-ray scans, we were able to build a digital version of the nests, much like the digital worlds that exist in computer games. We then simulated the nests in the conditions in which these termites live – dry in Senegal and wetter in Guinea.  We found that the links between the big pores allows air to “percolate” through the outer wall in the same way coffee is strained through a filter. This is key to ventilation and regulating temperatures.  By creating tiny ventilation passages, the pores of the nests manage gas exchange in a similar way to human lungs. But where a pair of lungs deflates and inflates to drive ventilation, in these nests the air is driven in and out by differences in temperature between the inner nest and the outside world. We still don’t know whether termites create these interconnected pores following simple construction rules, or as a consequence of physical constraints resulting from the way pellets of soil are packed together. But our research does suggest that it is the structure, not the material used, that is key to ventilation. Especially considering that samples from the two regions are composed predominantly of different materials (sand in Senegal and clay in Guinea). The challenge is now to derive the same design principles and scale them up for humans. No one wants to live in an exact copy of a termite’s nest, complete with fungus chambers. But learning from termites might involve creating new synthetic building materials with connected pores. It is important to remember that human ingenuity allows us to not merely copy forms found in nature, but to emulate the mechanism by which such forms emerge."
"
Share this...FacebookTwitterGerman geologist Dr. Sebastian Lüning and chemist Prof. Fritz Vahrenholt react to Anthony Watts’s press release concerning the quality of US temperature data at their blog.
Unlike myelf (I expected an unsurvivable nuclear bomb to be dropped), Sebastian Lüning and Fritz Vahrenholt find the implications of the new findings to be potentially devatsting. They write (excerpt):
A Shocking Development: Warming in the USA over the last 30 years is only half as much as previously assumed
Anthony Watts did not disappoint. Indeed it is about the release of an important new publication that involves the warming trend of the last 30 years. We had already introduced that problem here at this blog a few days ago (see our blog article “The wonderful world of temperature data corrections: And suddenly the trend reversed…“). It gets down to how justified are ‘corrections’ to the official data? We had reported that the data changes oddly always produced a signficant acceleration in warming with respect to the raw data, even though factors like the urban heat island effect intuitively suggest the oppsite correction is needed.
Authors in addition to Anthony Watts included Stephen McIntyre and John Christy. McIntyre is known because of his impressive error analyses of the famous hockey stick digram. Christy is a renowned expert for satellite temperature data at the University of Alabama in Huntsville. The manuscript will soon be submitted for publication by a journal. […}


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




[…] The result of the new study is shocking: Instead of correcting downwards temperatures that were heated by the urban heat island effect, the official US administration offices apparently corrected data from qualitively reliable stations upwards, which appears to be unjustifiable. If the result is confirmed, then it would be a shocking development. The warming in the USA over the last years would be far less rapid than what has always been assumed. And because similar errors are supected elsewhere, the issue could quickly gain global relevance.”
I asked Dr. Lüning to comment more on why this could have global implications. He kindly replied by e-mail:
Bit by bit others who might jump onto the train will now use the same methodology worldwide and will probably find that it really affects the global curve.”
Lüning and Vahrenholt also provide the press release in German at their site.
Take it from them; they’re experts. This could very well have global consequences. One thing is sure: It’s a an utter embarassment for the NOAA, and the perceived reliability of US and international data will be in question for years to come. Faith in the surface station data is crumbling.
 
Share this...FacebookTwitter "
"When we think of mass habitat extinction, colourful, diverse and highly visible ecosystems such as tropical rain forests and coral reefs come to mind. Approximately half of global shallow water coral reefs and forests have been lost over the last few hundred years, but there are glimmers of hope. Deforestation rates are declining and some corals have shown resilience to stress from climate change. A far less visible ecosystem crisis has occurred relatively recently beneath the ocean’s surface. A study revealed that 85% of global oyster reefs have been lost over the last 150 years. Of those remaining, over one third are so depleted that they no longer function as ecosystems, particularly those in Europe, North America and Australia. Only a few healthy oyster reefs remain in South America, and even these are 50% of their prior abundance, making oyster reefs one of the most threatened habitats on Earth. Oysters are “ecosystem engineers” like corals – they create three-dimensional structures as they settle and grow on each other. Left undisturbed, these oyster reefs provide a habitat for an incredible biodiversity of organisms, serving as a food source, nursery ground and refuge for many species, boosting fish stocks. Oysters also have an incredible ability to clean seawater. A single oyster can filter almost 200 litres of seawater daily, eating the phytoplankton and organic matter suspended within it. Oysters improve water quality and clarity, preventing large scale algal blooms and the potential consequences of mass fish mortality and deadzones due to depleted oxygen. Removing oyster reefs increases wave energy and erosion of saltmarshes and the corresponding coastline. Just as tropical coral reefs protect mangrove forests, oyster reefs provide coastal protection for important temperate ecosystems such as seagrass and saltmarshes.  As climate change and pollution destroy marine life, the need for vast oyster reefs has never been greater. Sadly, this vital habitat is at its nadir when we have almost no living memory of its natural state. Humans have been hand harvesting oysters since the Stone Age and cultivating them since Roman times. But oyster extraction reached fantastic proportions from the mid-1800s as mechanised fishing boats replaced older fleets.   Chesapeake Bay – meaning “great shellfish” – in the US was named by the Algonquin Indians because of the miles of incredibly dense oyster reefs that “lay thick as stones” in 1608. Between 1860 and 1920, three quarters of these reefs had been destroyed and by 1940 they had been almost entirely wiped out.  Across the Atlantic in Europe, oyster reefs were once plentiful and thought to be inexhaustible. The Olsen piscatorial atlas of 1883 depicts large oyster grounds at a depth of 34 metres in the North Sea, stretching from Helgoland, off the coast of Germany, to the Dogger Bank, between UK and Denmark, and through the English Channel. Though recently extirpated, oysters were once abundant in the Firth of Forth on Scotland’s east coast.  Roads and towns were built on shucked oyster shells in the US and Britain while shell piles towered one trillion tall in France. In 1864, 700m European oysters were consumed in London alone. The European native oyster (Ostrea edulis) population has declined by 95% since the 1950s, and oysters are now extinct in some regions of Europe, such as the Wadden Sea along the coast of Germany. Removing these vast ecosystems has deprived the sea of essential services, reducing water quality. There’s even speculation that the North Sea is especially murky today because oysters are no longer around. Destructive fishing that exceeds reproduction rates and removes habitat is the main cause of this ecosystem’s demise, but pollution, climate change, invasive species and shellfish diseases have further decimated remnant oyster stocks. It’s clear that active intervention is needed to turn the tide for oysters. Efforts to restore oyster reefs have already had success in the US and there are projects emerging in the UK and Europe. In southern England, the Solent Oyster Restoration Project was established in 2017 to reseed the Solent strait with 5m oysters. Since then, more than 20,000 oysters have been placed in novel restoration aquaculture cages, suspended underneath marina pontoons across the Solent. These cages are designed to pump out larvae which settle on the surrounding seabed, where 30,000 juvenile oysters reared in hatcheries have already been reintroduced. The Native Oyster Network in the UK and Ireland and the Native Oyster Restoration Alliance across Europe aim to restore native oysters around the north-west Atlantic. Both established in 2017, these networks are bringing together scientists, fishers, conservationists and governments to bring back a forgotten ecosystem.   Restoring European oyster beds and reefs is possible, but there is no quick fix. Work will take years and decades and depend on multinational cooperation and effective policy to protect habitats and regulate fishing. Nevertheless, recent efforts give hope we are at the beginning of a journey to restore a forgotten ecosystem to its once magnificent state."
"
Guest Post by Willis Eschenbach
Following on from Anthony’s article, here are my thoughts about the phytoplankton paper “Global phytoplankton decline over the past century”, by Daniel G. Boyce, Marlon R. Lewis & Boris Worm.
I started to write about this earlier, but I decided to wait until I had the actual paper. The paper in question is behind a paywall at Nature Magazine, but through my sub-oceanic channels (h/t to WS) I have obtained a copy. The paper makes two main claims, that: a) the numbers of phytoplankton have been cut by more than half since 1900, and b) the general warming of the global oceans is the reason for the declining numbers of phytoplankton.
First, what are phytoplankton when they are at home, and where is their home? Plankton are the ubiquitous soup of microscopic life in the ocean. Phytoplankon are the plant-like members of the plankton, the ones that contain chlorophyll and feed on sunshine. Phytoplankton are to the ocean what plant life is to the land. Almost all oceanic life depends on phytoplankton. Other than a thin strip of seaweeds and sea grasses along the coasts, phytoplankton are the microscopic plants that are the foundation of the vast entire oceanic food chain. Without phytoplankton there would be no deep water oceanic life to speak of. Figure 1 shows where you find phytoplankton:

Figure 1. Global distribution of phytoplankton. Lowest concentration is purple and blue, middle concentration is green, highest concentration is yellow and red. Source http://www.nasa.gov/vision/earth/environment/0702_planktoncloud.html
So where did the Nature paper go wrong?

The short answer is that I don’t know … but I don’t believe their results. The paper is very detailed, in particular the Supplementary Online Information (SOI). It all seems well thought out and investigated … but I don’t believe their results. They have noted and discussed various sources of error. They have compared the use of Secchi disks as a proxy, and covered most of the ground clearly … and I still don’t believe their results. Here’s exactly why I don’t believe them.
This is their abstract (emphasis mine):
In the oceans, ubiquitous microscopic phototrophs (phytoplankton) account for approximately half the production of organic matter on Earth. Analyses of satellite-derived phytoplankton concentration (available since 1979) have suggested decadal-scale fluctuations linked to climate forcing, but the length of this record is insufficient to resolve longer-term trends.
Here we combine available ocean transparency measurements and in situ chlorophyll observations to estimate the time dependence of phytoplankton biomass at local, regional and global scales since 1899. We observe declines in eight out of ten ocean regions, and estimate a global rate of decline of ~1% of the global median per year. Our analyses further reveal interannual to decadal phytoplankton fluctuations superimposed on long-term trends. These fluctuations are strongly correlated with basin-scale climate indices, whereas long-term declining trends are related to increasing sea surface temperatures. We conclude that global phytoplankton concentration has declined over the past century; this decline will need to be considered in future studies of marine ecosystems, geochemical cycling, ocean circulation and fisheries.
The first clue to where they went wrong is visible in Fig. 1. Although as you can see there is more phytoplankton in the cooler regions of the north, the same is not true in the corresponding regions in the south despite the ocean temperatures being very similar. In addition, there are many places where the ocean is warm (e.g. tropical coasts) that have lots of phytoplankton, while in other warm areas there is very little phytoplankton.
The rude truth of phytoplankton is this: phytoplankton growth is generally not limited by temperature. Instead, it is limited by nutrients. Where nutrients are plentiful, the phytoplankton grow regardless of temperature. Nutrients are more common along the coastline, where sub-oceanic currents come to the surface bringing nutrients from the deep ocean floor, and rivers bring nutrients from inland. For example, in Fig. 1 you can see the nutrients from the Amazon river causing the red area at the river mouth (north-east South American coast).
Indeed, the fact that phytoplankton are generally nutrient limited rather than temperature limited has been demonstrated in the “ocean fertilization”  experiments using rust. If you spread a shipload of rust (iron oxide) out into the tropical ocean, you generally get an immediate bloom of phytoplankton. Temperature is not the problem.
So to start with, the idea that increasing temperature automatically leads to decreasing phytoplankton is not generally true. There are vast areas of the ocean where higher temperatures are correlated with more phytoplankton. For example, the warmer deep tropics generally have more phytoplankton than the cooler adjacent subtropics.
The paper’s most unbelievable claim, however, is their calculation that since 1899, the density of phytoplankon has been decreasing annually by 0.006 milligrams per cubic metre (mg m-3). They give the current global density of phytoplankton as being 0.56 mg m-3. Thus they are claiming that globally the concentration of phytoplankton has dropped by more than 50% over the last century.
Now, a half century ago I learned to sail on San Francisco Bay. Since then I’ve spent a good chunk of my lifetime at sea, as a commercial fisherman from California to the Bering Sea, as a sailboat delivery crewman, as a commercial and sport diver, and as a surfer. And call me crazy, but I simply don’t believe that the sea only has half the phytoplankton that it had in 1900. If that were true, it would not take satellites and complex mathematical analysis to show it. People would have noticed it many years ago.
I say this because phytoplankton are the base of almost the entire mass of oceanic life. They are what almost all other life in the ocean ultimately feeds on, predators and prey as well. The authors of the study do not seem to realize that if the total amount of phytoplankton were cut by more than half as they claim, the total mass of almost all living creatures in the open ocean would be cut about in half as well. No way around it, every farmer knows the equation. Half the feed means half the weight of the animals.
And I see no evidence of that having happened over the last century. It certainly does not accord with my own extensive practical experience of the ocean. And I see no one else making the claim that we only have half the total mass of deep-water oceanic life that we had a century ago..
The other thing that makes their claimed temperature/phytoplankton link very doubtful is that according to the HadISST dataset, the global ocean surface temperature has only increased by four tenths of a degree C in the last hundred years.
Four tenths of a degree … an almost un-noticeable amount. Yet their paper says (emphasis mine):
Our analyses further reveal interannual to decadal phytoplankton fluctuations superimposed on long-term trends. These fluctuations are strongly correlated with basin-scale climate indices, whereas long-term declining trends are related to increasing sea surface temperatures.
These kinds of claims drive me nuts. Is there anyone out there that truly believes that a change of global average ocean temperature of four tenths of a degree C over the last hundred years has cut the total mass of phytoplankton, and thus the total mass of all oceanic creatures, in half? Really?
So that’s why I say I don’t know where their math went wrong, but I don’t believe their results. I don’t believe we’ve lost about half the total mass of all oceanic creatures. Half the planet’s open ocean dwellers? Where is the evidence to support that outrageous claim? And I don’t believe that an ocean temperature change of four tenths of a degree over a century has made much difference to phytoplankton levels, as they grow at all temperatures.
Why don’t I know where their math went wrong? Unfortunately, they have not posted up the data that they actually used. Nor have they shown any of their data in the form of graphs or tables. Instead, they have shown model results, and merely pointed to general websites where a variety of datasets are maintained. So we don’t know, for example, whether they used the 1° grid version or the 2.5° grid version of a given dataset. Nor have they posted the computer code that they used in the analysis. Plus, the very first link in their paper to the first and most important data source is dead.
Grrrr … but dead link or not, pointing to a website as the data source in their kind of paper is meaningless. To do the analysis, they must have created a database of all of the observations, with the meta data, and the details for the type etc. for each observation. If they would include that database and their code in the SOI, then someone might be able to figure out where their math went wrong … my guess is that it may be due to overfitting or misfitting of their GAM model, but that’s just a wild guess.
It is a shame that they did not post their data and code, because other than the lack of data and code it is a fascinating analysis of a very interesting dataset. I don’t accept their analysis of the data because it doesn’t pass the “reasonableness” test, but that doesn’t mean that the dataset does not contain valuable information.
[Update] An alert reader noted that the image in Figure 1 was of a particular month and not a yearly average. So I’ve made a short movie of the variations in plankton over the year.
Figure 2. Monthly movie of plankton concentrations. Click on image to see animation.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89ac300d',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Protests against a proposed waste incinerator power plant involving thousands of residents took place in southern China over two weekends in mid-September.  The demonstrations, in Boluo county, Guangdong province, were the largest yet against a project that has caused numerous smaller demonstrations since its environmental impact assessment was formally released two years ago. A government plan detailing the likely site for the plant was released in June this year, increasing opposition to the proposal. Investment in waste incinerators is seen as a solution to the inability of China’s infrastructure to handle the mountains of trash the country produces. The number of incineration projects has risen steadily and by last year between 15% and 20% of the country’s household waste was burned. The government intends to double this to 35% by 2015. As in Boluo, many of these projects also double as power generation plants. On the surface this seems ideal for a country that is not only the world’s largest consumer of energy but also its largest producer of rubbish, at about 300m tonnes per year. Because they generate power, the enthusiasm for waste incineration plants is also driven by financial incentives. One 2012 analysis said such plants could earn profits for up to 22 years. The Gao’antun plant in Beijing, the report said, earns up to US$16m from electricity sales annually. But this energy source comes with other costs – and waste incinerator plants are meeting growing resistance. Based on my social media analysis, at least 20 projects have sparked protests across China over the past three years, although the actual number may be even higher. Protesters’ primary grievance is pollution. In Boluo, residents fear that emissions will cause cancer and that the local water source, the Dongjiang River, would be polluted. Their concerns are warranted. Globally, the environmental impact of incinerators is somewhat debatable. In Sweden, where the government has said 99% of all household waste is recycled, of which 50% is burned at waste incineration plants to produce energy, the plants are not controversial. But in the US, proposals for new plants face significant hurdles due to opponents who argue they may worsen air pollution and harm recycling efforts. Even if there was a consensus that such projects in well-regulated environments are safe, “well-regulated” is not guaranteed in China. Many of the country’s waste incinerators are built to extremely low standards and are run by operators who fail to properly dispose of toxic by-products. And while some facilities may be installed with the proper air-pollution control systems, these are expensive to operate and many plants do not use them. As a result, Chinese waste incinerators might serve no purpose other than to trade one waste pollution problem off for another. In response to the recent protests, Boluo officials promised to listen to public opinion and have allowed the public three months to suggest alternative locations. However, because local residents have opposed the plant since the first public consultation period in November 2012, it seems unlikely that the new process will change things significantly. Officials have offered guarantees to residents that the proposed plant at Boluo will be safe but residents question the government’s honesty, a situation that is indicative of a much wider issue in China: a fundamental lack of trust in officialdom. For environmental protests, much of the distrust toward government claims stems from a lack of transparency on the controversial projects. The central government at least recognises transparency is an issue, and vice environmental minister Li Ganjie has called on local authorities to share more information with the public.  However, such “sharing” is only effective if the information is truly transparent. Boluo officials have arguably released enough information regarding the project and have gone through the motions of a public consultation process, but locals still do not trust the government’s word. Added to this is the issue of conflicting environmental priorities between central and local government. For the central government, maintaining social stability is closely linked to the Communist Party’s legitimacy, whereas local government officials tend to prioritise social stability when it impacts on economic stability. Therefore local governments have a strong incentive to push ahead with controversial projects if they can rely on them as even a short-term source of revenue. The ongoing events in Boluo, and similar protests elsewhere, are certainly disruptive in the short-term but their long-term effectiveness is more questionable. Even if protesters succeed in forcing a project’s suspension, they rarely force an outright cancellation. In the end the Boluo project may be relocated, possibly to an area where equally disgruntled villagers have less power. A solution of sorts, but one that leaves the fundamental issues unresolved. The only way to persuade the public that projects such as waste incinerators do not pose environmental and health hazards is to start meeting higher standards. Perhaps this process has already started. In January this year, the government released revised emissions standards for major industries, including pollution control at municipal solid waste incineration plants. Even so, this may not be enough to undermine unrest. Until China’s local governments prioritise the environment and social stability over short-term economic gain, the problems will persist and the proliferation of environmental protest will likely continue."
"
I have not read this book, but it has been raising some volume in Skeptic websites. What strikes me is the number of authors, it has (9 by my count).
Strangely, one of the authors, Oliver K. Manuel,  is a person I’ve banned from WUWT for carpet bombing threads with his vision of the Iron Sun Theory, which I personally think is nutty. So, that right there gives me some pause. But, I haven’t read the book, so it may have nothing to do with that. OTOH, he’s one of the most well mannered commenters you’ll ever find.
The main thrust of the book seems to be discovering what they say is a flaw in understanding and accounting for 13C/12C   isotopes within carbon dioxide, and this then points to a different signature related to human produced CO2.
Over at Climate Change Dispatch, they have this to say about it:

Newly  released science book revelation is set to heap further misery  on UN  global warming researchers. Will latest setback derail Cancun  Climate  conference?
Authors of a new book  ‘Slaying the Sky Dragon: Death of the Greenhouse Gas Theory’ claim they have debunked the widely established greenhouse gas theory   climate change. In the first of what they say will be a series of   sensational statements to promote the launch of their book, they attack a   cornerstone belief of the Intergovernmental Panel on Climate Change   (IPCC) – what is known as the “carbon isotope argument.”
Mišo  Alkalaj, is one of 24 expert authors of this two-volume  publication,  among them are qualified climatologists, prominent skeptic  scientists  and a world leading math professor. It is Alkalaj’s chapter  in the  second of the two books that exposes the fraud concerning the  isotopes 13C/12C found in carbon dioxide (CO2).
If  true, the disclosure may possibly derail last-ditch attempts at a   binding international treaty to ‘halt man-made global warming.’ At   minimum the story will be sure to trigger a fresh scandal for the   beleaguered United Nations body.
Do Human Emissions of Carbon Dioxide Exhibit a Distinct Signature?
The low-key internal study focused on the behavior of 13C/12C   isotopes within carbon dioxide (CO2) molecules and examined how the   isotopes decay over time. Its conclusions became the sole basis of   claims that ‘newer’ airborne CO2 exhibits a different and thus distinct   ‘human signature.’ The paper was employed by the IPCC to give a green   light to researchers to claim they could quantify the amount of human   versus natural proportions just from counting the number of isotopes   within that ‘greenhouse gas.’
Alkalaj, who is head of Center for Communication Infrastructure at the “J. Stefan” Institute, Slovenia says because of the nature of organic plant decay, that emits CO2, such   a mass spectrometry analysis is bogus. Therefore, it is argues, IPCC   researchers are either grossly incompetent or corrupt because it is   impossible to detect whether carbon dioxide (CO2) in the atmosphere is   of human or organic origin.
…
The  13C/12C argument being attacked by Mišo Alkalaj may be found in IPCC’s AR4 – The Physical Science Basis Working Group. The IPCC clarifies its position on Page 139 of that chapter.
According to Miso the fatal assumption made by the IPCC is that the atmospheric concentration of the 13C  isotope (distinctive in prehistoric plants) are fixed. They also assume  C3-type plants no longer exist so would need to be factored into the  equations. Indeed, as Miso points out such plants, “make up 95% of the  mass of all current plant life.”
Therefore, decay of 95% of present-day plant material is constantly emitting the 13C-deficient carbon dioxide supposedly characteristic of coal combustion—and CO2 emitted by plant decay is an order of magnitude greater than all human-generated emissions.
…
From Amazon.com:
Even before publication, Slaying the Sky Dragon was destined to be the  benchmark for future generations of climate researchers. This is the  world’s first and only full volume refutation of the greenhouse gas  theory of man-made global warming.
Nine leading international  experts methodically expose how willful fakery and outright incompetence  were hidden within the politicized realm of government climatology.  Applying a thoughtful and sympathetic writing style, the authors help  even the untrained mind to navigate the maze of atmospheric  thermodynamics. Step-by-step the reader is shown why the so-called  greenhouse effect cannot possibly exist in nature.
By deft  statistical analysis the cornerstones of climate equations – incorrectly  calculated by an incredible factor of three – are exposed then  shattered.
This volume is a scientific tour de force and the  game-changer for international environmental policymakers as well as  being a joy to read for hard-pressed taxpayers everywhere.
==============================================================
There is also a kindle version available on Amazon.com.
At this point I can’t recommend the book from either a pro or con perspective, I’m just making it known to WUWT readers.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8711d2e4',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Nick Stern is back with another report on climate change – colloquially known as Stern 2.0. It’s another offering from the Global Commission on the Economy and Climate. Since his 2006 review, Stern has been regularly in the news, claiming climate change is worse than we thought. The new report fits the mould. The summary was released before the main report and we are invited to believe its findings without inspecting the evidence. It seems, though, that Stern has produced another far-fetched piece of work.  The new report makes three claims, none of which stand up: that climate policy stimulates economic growth; that climate change is a threat to economic growth; and an international treaty is the way forward. “Well-designed policies … can make growth and climate objectives mutually reinforcing,” the report claims. The original Stern Review argued that it would cost about 1% of global GDP to stabilise the atmospheric concentrations of greenhouse gases around 525ppm CO2e. In its report last year the Intergovernmental Panel on Climate Change (IPCC) put the costs twice as high. The latest Stern report advocates a more stringent target of 450 ppm and finds that achieving this target would accelerate economic growth. This is implausible. Renewable energy is more expensive than fossil fuels, and their rapid expansion is because they are heavily subsidised rather than because they are commercially attractive. The renewables industry collapsed in countries where subsidies were withdrawn, as in Spain and Portugal. Raising the price of energy does not make people better off and higher taxes, to pay for subsidies, are a drag on the economy. Climate policy need not be expensive. Study after study has shown that it is possible to decarbonise at a modest cost and Stern has missed an opportunity to point this out.  But low-cost climate policy is far from guaranteed – it can also be very, very expensive. Europe has adopted a jumble of regulations that pose real costs for companies and households without doing much to reduce emissions. What is the point of the UK carbon price floor, for instance? Emissions are not affected because they are capped by the EU Emissions Trading Systems, but the price of electricity has gone up. The subsidies and market distortions that typify climate policy do, of course, create opportunities for the well-connected to enrich themselves at the expense of the rest of society. Perhaps Stern 2.0 mistook rent seeking for wealth creation. The report says that if, in the long run, “climate change is not tackled, growth itself will be at risk.” The new report claims climate change would be a threat to economic growth. The original Stern Review argued that the damage would be 5-20% of global income. In the worst case, we would not be four times as rich by the end of the century, but only 3.8 times. The IPCC reckons Stern 1.0 exaggerated the impacts by a factor 10 or more, while the new Stern report agrees that the old Stern was off by an order of magnitude, but in the opposite direction. Over the past two decades, economists have re-investigated the relationship between economic development and geography. This has not led to a revival of the climate determinism of Ellsworth Huntington – the Yale professor who argued that a nation’s prosperity could be predicted by its location and climate. On the contrary, most research finds that climate plays at most a minor role in economic growth, and that the impact of climate is moderated by technology and institutions. Just consider Iceland and Singapore. Stern 2.0 goes against the grain of a large body of literature. “A strong … international agreement is essential,” the Stern report says, calling for an international treaty with legally binding targets. Albert Einstein defined insanity as doing the same thing over and over again and expecting a different result. Since 1995, the parties to the UN Framework Convention on Climate Change have met year-after-year to try and agree on legally binding targets – and they have failed every time.  The reasons are simple. It is better if others reduce their emissions but you do not. No country likes to be bound by UN rules for its industrial, agricultural and transport policies. The international climate negotiations have been successful in creating new bureaucracies, but not in cutting emissions.  Stern also argues that “[d]eveloped countries will need to show leadership.” The EU has led international climate policy for two decades, but without winning any followers. The broken record that is Stern 2.0 is unlikely to inspire enthusiasm for more expensive energy. The Stone Age did not end because we ran out of stones, but because we found something better: bronze. The fossil fuel age will end when we find an alternative. The current renewables are simply not good enough – except for the happy few who profit from government largesse.  The environmental movement’s aversion to nuclear power and shale gas increases emissions and creates an impression of Luddism, whereas climate policy should focus on accelerating technological change in energy.  The unfounded claims in Stern’s new report do not build the confidence that investors and inventors need to take a punt on a carbon-free future. Exaggeration is great for headlines, but sober analysis is more convincing in the long run."
"**One man has been arrested and 14 people were fined after police were called to deal with house parties and anti-social behaviour in Belfast's Holyland area.**
A crowd of about 50 young people gathered in groups on Agincourt Street shortly after 02:00 GMT on Wednesday, according to police.
They arrested a 23-year-old man for assaulting police and other offences.
Earlier, officers visited two properties where they issued 14 Â£200 fines for breaching Covid restrictions.
A further six people who were in the properties were given formal warnings for breaching the rules about gatherings in private homes.
Ch Insp Gavin Kirkpatrick said it was the second night in a row that police responded to complaints about parties and anti-social behaviour in the Holyland area.
""I am sure many people will have seen the footage on social media showing the appalling behaviour of some people police had to deal with,"" he said.
""Police will robustly challenge and deal with people who are either disregarding the health regulations or engaging in this type of anti-social and criminal behaviour.""
The Holyland is a residential area popular with students and police have been called to the vicinity several times since term started in September to break up house parties.
Ch Insp Kirkpatrick said police patrols in the area have increased again and the PSNI ""will continue to liaise with the universities, colleges and other partners to address this issue"".
""Indeed, where appropriate, the universities and colleges will consider their own sanctions against any students involved.""
The officer added that Holyland residents ""do not want to be kept awake all night with parties, their property damaged, or the area left in a mess by a relatively small group of mainly young adults who are old enough to know better"".
""As huge numbers of people across the country make sacrifices - whether isolating, working from home or having to again temporarily close their businesses to try and prevent the spread of Covid 19 - those who are visiting or staying in this residential area must take responsibility for their behaviour.""
He also appealed to parents and guardians of young people living in the Holyland to ensure that ""they are behaving responsibly""."
"
Via email press release:
A new paper at SPPI looks at the history of extreme weather events.
The on-going claims of catastrophic anthropogenic global warming have  been ramped up again lately because of the opportunities presented by the heat  wave in Russia and the floods in Pakistan, which are also being claimed as  attributable to anthropogenic CO2. If the amount spent on global warming were to  be diverted to mitigating and preventing the worst effects of natural disasters,  then the desperate plight of the people of Pakistan would be relieved more  quickly.
The paper can be downloaded here: http://scienceandpublicpolicy.org/originals/extreme_weather_extreme_claims.html
The Author, Dennis Ambler, concludes:
Extreme Weather – The Blame Game 
The  Aztecs had sophisticated irrigation systems and “astrolonomical”  observatories, (apparently a mix of astrology and astronomy), to attempt to  predict the weather and reservoirs. But the unseasonal frosts and cold, followed  by severe, prolonged drought, may have taken them to the brink of collapse. Once  the climate became more benign again, they praised their gods with human  sacrifice. 
“When rainfall and agriculture had resumed, the Aztecs responded by massively increasing the number of  human sacrifices to their rain god Tlaloc. It  is thought that hundreds of thousands of people were sacrificed.”
In the Little Ice Age, witchcraft was blamed for the  devastating climate:
Fagan’s The Little Ice Age (Basic Books, 2000):
“Witchcraft accusations soared, as people accused  their neighbors of fabricating bad weather….  Sixty-three women were  burned to death as witches in the small town of Wisensteig in Germany in 1563 at  a time of intense debate over the authority of God over the  weather.”
“Almost invariably, a frenzy of prosecutions coincided with the coldest and  most difficult years of the Little Ice Age, when people demanded the eradication  of the witches they held responsible for their misfortunes.”
These days we don’t blame witchcraft for the weather, instead we blame it on  our emissions of carbon dioxide, describing it as a pollutant that must be  controlled by Government taxes and vilifying anyone who dares to challenge the  orthodoxy.
We ignore thousands of years of climate evidence, in favour of an agenda  based upon a century and a half of sometimes distorted and often-disputed  temperature records, coming out of a known Little Ice Age and we call it  “Science”.
Have we really left the Dark Ages behind?
###


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e88c23201',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"The Aral Sea has reached a new low, literally and figuratively; new satellite images from NASA show that, for the first time in its recorded history, the largest basin has completely dried up.  However, the Aral Sea has an interesting history – and as recently as 600-700 years ago it was as small, if not smaller, than today. The Aral recovered from that setback to become the world’s fourth largest lake, but things might not be so easy this time round. Today, more people than ever rely on irrigation from rivers that should instead flow into the sea, and the impact of irrigation is compounded by another new factor: climate change. Sandwiched between Kazakhstan and Uzbekistan, the Aral Sea is actually a lake, albeit a salty, terminal one. It is salty because evaporation of water from the lake surface is greater than the amount of water being replenishing through rivers flowing in. It is terminal because there is no outflowing river. This makes the Aral Sea very sensitive to variations in its water balance caused either by climate or by humans.  Indeed, the sea has long been a cause celebre in the world of environmental catastrophes, an exemplar of the devastating harm that ill thought-out economic policies can have on the environment. Intensive irrigation of cotton plantations in the deserts of the western Soviet Union prevented water reaching the Aral Sea, leading to the drastically low levels we see today. This in turn meant the highly-salty waters killed off many plants and animals. During early Soviet Union times, the Aral Sea and its fringing wetlands were a significant resource for the fishing industries, agriculture, animal husbandry and fur trapping. But in the 1950s, the extent of irrigated land used for “white gold” (cotton) increased dramatically from 4 million to 8 million hectares, with Uzbekistan becoming one of the world’s largest cotton producers. To feed cotton’s insatiable demand for water, the Karakum Canal was built out of the desert sands and because it was unlined, water losses were extremely high.  During the late 1960s, the amount of water evaporating from the Aral Sea become greater than the amount of water entering the lake, so lake levels declined dramatically in the 1970s and 1980s. More than 75% of the surface area and more than 90% of the lake’s volume has been lost. In 1987-1988, the lake split into two, and the Large and Small Aral Sea basins were created. International efforts have been made to protect the Small Aral Sea through the construction of dams, and this has meant that lake levels here have increased. The Large Aral Sea continued to shrink and subsequently split itself into two basins; a deeper, smaller west Large Aral and a more shallow, but expansive, east Large Aral. And it is this latter basin which NASA images show had dried out completely this summer. The environmental impact of the drying Aral has been devastating. Hundreds of thousands of people have been displaced and hundreds of species have disappeared. Toxic metals and agrochemicals (herbicides, pesticides, insecticides), used to prevent disease and pests from lowering cotton yields, found their way into the sea through its rivers. But because the Aral is a terminal lake, the pollutants were never washed out, and they instead sunk to the bottom sediments. Now these bottom sediments are exposed to the air, they are blown up into the atmosphere as toxic, salty dust storms, which can spread for many hundreds of kilometres causing increased deaths and chronic disease, especially the young. However, lower lake levels have also exposed ancient irrigation systems and mausoleums surrounded by settlements (some remains of which are still under water), built during the late Middle Ages. This means that in certain parts of the Aral, lake levels during 13th-14th century must have been lower.  We still aren’t sure exactly what caused such extreme regression, but a cooler, drier climate played a role. The 13th century Mongol invasion of central Asia also led to the Amu Dar'ya, one of two major rivers that feed the Aral, being diverted to the Caspian Sea. Clearly humans were a major factor in the Aral’s previous dry spell.   By the late 16th century, the Aral Sea started to fill up again, in part because irrigated channels meant the Amu Dar'ya once more flowed into the lake. A key question that remains today therefore is how much of the lake’s current regression is due to intensive irrigation and how much may be due to climate change over the past 50 years. Recent studies suggest only 14% of the shrinking of the Aral Sea since the 1960s was caused by climate change, with irrigation by far the biggest culprit.  Researchers looking at what will happen to Aral Sea levels with global warming over the next few decades have combined several model predictions together and expect net water loss to increase as more evaporation leads to less river inflow. However, if irrigation of the rivers continues, then net water loss will be even greater as river flow into the Aral Sea will essentially cease.  Climate change may be one of the world’s great problems but over-irrigation is at least possible to reverse with the right policy changes. But the two issues together make a disastrous combination. The future for much of the Aral Sea does not look great."
"**There's been a slight increase in Covid-19 infections in Africa over the past few weeks, according to the Africa Centres for Disease Control and Prevention (CDC) and the World Health Organization (WHO).**
The number of daily new cases overall has been rising gradually since late September _,_ although there's a lot of variation across the continent.
Africa accounts for just over two million of the more than 60 million confirmed cases across the world.
There was an average increase of 7.5% in new cases each week over the past month, according to data from the Africa CDC.
In the week up to 22 November:
The WHO says the latest increase is driven by north African countries, where temperatures are beginning to fall as winter approaches.
Morocco, Tunisia and Algeria are among the five countries reporting the highest number of new cases in the past week.
Other countries like Nigeria, Egypt, South Africa, DR Congo and Kenya have also seen increases, although some like Ethiopia have seen decreases.
Dr Nkengasong of the Africa CDC says there are three main trajectories in African countries:
""Overall, if you group these countries together, you see that the curve increased up to July, came down around September and stabilised, and now it is going up,"" he says.
Since the pandemic began, South Africa has had the highest recorded number of total cases in Africa.
Morocco, Egypt and Ethiopia are the only other African countries to officially record more than 100,000 cases.
Daily reported numbers have been rising after falling for about four months, and the government has expressed concern about a rise in infection rates in some areas, mostly in Eastern Cape and Western Cape provinces.
Doctors are also reporting a spike in hospital admissions in the two regions.
Eastern Cape accounted for 50% to 55% of new daily positive casesin South Africa on average, and hospital admissions have been rising for about a month.
Over the past week, Western Cape province recorded a 52.1% jump in new cases.
""There is also now established community transmission of the virus again in this province, which means that it is spreading within communities at a faster rate,"" a statement from the government says.
The reported death rate per capita on the continent has been low compared with other parts of the world, despite the weak health infrastructure in many African countries.
The WHO says this could be partly because of the relatively young population in Africa - more than 60% under the age of 25.
Covid-19 is known to have a higher mortality rate for older age groups, and among people with health problems like obesity and type 2 diabetes which are also less common in Africa.
Experts also say expertise in epidemic control from tackling other outbreaks, cross-immunity from other coronaviruses, low travel and outdoor living could also be contributing to Africa coping better.
There are also issues - as elsewhere in the world - over how countries record deaths, making comparisons between them difficult.
Research earlier this year from the South African Medical Research Council (SAMRC) indicated that the number of people who had died from the virus could have been higher than was reported.
It had looked at excess deaths - the difference between deaths over a particular period and the historical average - and estimated that a significant proportion were due to Covid-19.
The WHO says the testing level in Africa is still low compared to other regions.
Ten countries account for about 70% of the total tests conducted- South Africa, Morocco, Ethiopia, Egypt, Kenya, Nigeria, Cameroon, Rwanda, Uganda and Ghana.
And there are wide variations in testing rates, and while some countries have reduced testing, others have maintained or even increased it.
South Africa has been doing the most and Nigeria doing relatively few tests per capita, according to Our World in Data, a UK-based project which collates Covid-19 information.
By 19 November, South Africa had so far done just over 88 tests per 1,000 people, but that compares with more than 514 in the UK and 534 in the US.
Nigeria had carried out just 3.5 tests per 1,000 people.
A benchmark of doing at least 10 tests for every positive case is recommended by the Africa CDC, and currently there are 12 countries on the continent with a ratio lower than that.
In some countries, there's insufficient data available on testing to know how much is being done.
Read more from Reality Check
Send us your questions
Follow us on Twitter"
"Tensions at the Greek-Turkish border and the coronavirus show why the European Union needs a climate law that binds member states to net zero emissions by 2050, the EU’s top official on climate action has said. Frans Timmermans, a European commission vice-president who leads on the climate emergency, said the different crises facing Europe underscored the need for a climate law in order not to lose track of reducing emissions. The long-awaited climate law unveiled on Wednesday is the centrepiece of the European Green Deal, a plan to transform Europe’s economy, promised by the European commission president, Ursula von der Leyen, within her first 100 days. “It will be our compass for the next 30 years and it will guide us every step as we build a sustainable new growth model,” Von der Leyen said announcing the law.  Some political leaders have argued that the commission needs to focus on the protection of the EU’s external border, rather than the climate crisis – arguments that Timmermans rejected. “The focus this week should be completely on the happening in Syria, in Turkey and what is happening in Greece, should be on containing the coronavirus and solving it. That’s absolutely a priority,” he said. The climate law was “so important”, because “it allows you to focus on other things without losing track of what you need to do to reach climate neutrality”. “Even if the Eye of Sauron is on something else for a bit, the trajectory to 2050 will be clear,” he said, in a reference to the dark forces in the Lord of the Rings. “Because we discipline ourselves with the climate law.” Speaking to the Guardian and six other European newspapers shortly before the law was published, Timmermans said the proposal was revolutionary because all EU legislation would have to be in line with net zero emissions by the mid-century. Even before the text was officially released, the climate activist Greta Thunberg and teenage school strike leaders across Europe gave a blistering verdict, accusing the commission of ignoring climate science. Thunberg, who is meeting Von der Leyen, Timmermans and the rest of the commission’s top team, described the law as “surrender”. In an open letter, she said it failed to respect the goal of capping global heating at 1.5C above pre-industrial levels – an aspiration the EU signed up to in the 2015 Paris agreement. She repeated that message at a meeting with MEPs on the European parliament’s environment committee on Wednesday. “In November 2019 the European parliament declared a climate and environment emergency,” she said. “You stated that yes, the house is actually burning, this was no false alarm, but then you went back inside, finished your dinner and watched your movie and went to bed without even calling the fire department. “When your house is on fire you don’t wait a few more years to start putting it out, and yet this is what the commission are proposing today.” Earlier at a private meeting with EU commissioners the teenage activist was told by Timmermans that the movement she started was the reason the European Green Deal and climate law exists. European Union leaders in 2019 agreed to reduce greenhouse gas emissions to net zero by 2050, meaning more emissions will be removed than expelled into the atmosphere. The climate law proposed by the European commission makes that 2050 promise legally-binding. If an EU member state fails to make progress, the commission can take it to the European court of justice, which has the power to impose hefty daily fines for non-compliance. The commission, the body that drafts and enforces EU law, describes the draft regulation as revolutionary, because all EU legislation – whether farming, energy or transport – will have to be consistent with the 2050 climate target. Climate campaigners, notably Greta Thunberg who described the law as “surrender”, argue that it does not go far enough to reduce emissions in the next decade – a critical window if the world is to avoid climate breakdown that will come from overshooting the aspiration agreed at the 2015 Paris climate talks to keep warming to 1.5C above pre-industrial levels. The climate law does not include an emissions-reduction target for 2030, although the commission will table a proposal in September. EU governments are likely to object to the powers the commission wants to give itself to propose climate targets for 2035, 2040 and 2045. Under the powerful legal tool of “delegated acts”, the EU executive would be able to set targets with limited input from ministers and MEPs. That could prove tricky with governments and the European parliament, who must approve the climate law before it comes into force.  The climate scientist Jean-Pascal van Ypersele, a former vice-chair of the UN Intergovernmental Panel on Climate Change (IPCC), said the EU was aiming too low and its current targets on reducing emissions set in 2014 were not in line with the 1.5C goal. An IPCC report in 2018 showed that going beyond 1.5C, even by half a degree, would significantly increase the risks of drought, floods, extreme heat and poverty for millions of people. Van Ypersele said the EU should be aiming for carbon neutrality one decade earlier. “If a region as technologically rich, as scientifically rich as the EU is only able to achieve that by 2050 how can you imagine that the rest of the world will do that by the same year? I don’t think it’s very likely.” A dozen EU member states have also voiced reservations about Timmermans’ timetable for proposing an EU climate target for 2030, widely seen as a crucial goal if the world is not to exceed its carbon budget. Timmermans plans to set out the EU’s 2030 goal in September, but the dozen countries argue this is too late to galvanise the rest of the world to make commitments at crucial UN climate talks in Glasgow at the end of the year. The vice-president rejected these arguments, saying his officials needed the summer to do a thorough impact assessment of the 2030 goal. “If the commission were to come out with a not duly assessed number we would have months and months of discussion about a percentage and then the EU would not have a position either.” He said the EU’s 2030 target would be in time for the EU to have a position at the Cop26 talks in Glasgow. Timmermans also voiced confidence in the British government’s preparations for Cop26. Campaigners have been concerned about a shaky start, with the new Cop26 president – the business secretary, Alok Sharma – only appointed three weeks ago, after his predecessor was abruptly sacked. The UK has yet to set out a strategy or timetable for the cconference, widely seen as critical to getting the world back on track with the 2015 Paris goals. This is Europe is a new stream of Guardian journalism that investigates the big challenges that transcend national boundaries, and seeks out the solutions that could benefit us all. These are testing times, and crises are not limited by national borders. But then neither are we.  “The UK has formidable capacities in this area,” he said, adding that Brexit had not created a rift between the EU and UK over climate goals. “Brexit weakens the EU, full stop. And, in my view, weakens the UK, full stop,” he said. “I don’t see any object of discord, or disagreement or confrontation between EU and United Kingdom on this issue, of making a success of Glasgow.” But he is likely to face a tougher response from governments in central and eastern Europe that are wary of rapid action on the climate emergency, especially Poland, which generates 80% of its electricity from coal. The climate law means governments failing to meet targets could be taken to the European court of justice and fined. Timmermans said “the hardest, hardest thing we will have to do” is guaranteeing that the European Green Deal will benefit the whole of society. He said he was angered by claims that tackling climate change was against the poor, while acknowledging that a failure to benefit everyone carried risks. “If we are not able to show that it is done in a fair way more and more people will say no, we will give food to extremist parties, who will try to demonstrate that this is only a plan for Tesla-driving tofu eaters. “But the real victims of the climate crisis will be the poorest people in society. They have no other place to go.”"
"Landslides happen everywhere and in different geological locations. This can be because of flooding, which allows sodden soil to move, or rockfalls and slower, continuous movements of land due to gravity. Landslides are particularly dangerous when they happen without warning, as recently happened in India and Japan. Tens of thousands were killed in the Vargus disaster in Venezuela in 1999. Some places are prone to flooding – even, in the case of India, monsoons – but to know where a landslide will happen or when it might happen we need good tools. Currently equipment to measure landslides includes rain gauges, such as those used in the Chittagong region of Bangladesh, which record levels of rainfall that can then be compared to previous data of levels that triggered a landslide.  But many current systems use point-based sensors, in other words systems that rely on ground plugged devices that are able to monitor only from fixed positions. We’ve been working on a new way of measuring to predict landslides using optical fibres in cables as sensors. When installed, these sensors can permanently monitor changes happening to the land. The system, called Stimulated Brillouin Scattering, uses the interaction of light with acoustic waves. Basically, when the soil undergoes collapse or sliding, the embedded fibre stretches and we detect this. These sensing optical fibre cables can be embedded in shallow trenches in the ground to monitor both large landslides and slow slope movements through the elongation induced in the sensing fibre. If you imagine the land as a body, a distribution of these optical fibre sensors act as the “nerve system”. They have the ability to detect a change of one centimetre over a distance of a kilometre. Being able to measure and track early pre-failure soil movements, it is then possible to detect the signs of an imminent landslide. Unlike these conventional tools, optical fibres make measurements along the whole sensing cable which allows for a  fully  distributed measurement of land deformation. The advantage is the continuous monitoring of large areas with high  accuracy. They can also be used in difficult-to-access places, for example underneath bridges, outside the walls of tunnels, near dams and along pipelines and railways in remote rural areas. These sensors can also be used to cover very large areas (several square kilometres) with a single fibre cable and to pinpoint the location of failure signs. In traditional point-based systems you have to be lucky to place a sensor in the critical position where something happens otherwise you miss the event.  The optical fibres can also be controlled from a remote point, so fibres can be laid and left with no need for regular inspections, while the data is transmitted via wireless or optical fibre networks. They are also cheaper than traditional point sensors because a single fibre does the trick and no in-situ visits are required. Optical fibres have been used to measure creep in road boundaries and to monitor bridges and pipelines. So far, only small-scale tests have been used with regard to landslides. But we believe they could change the way we measure and predict these deadly occurrences."
nan
"
Anthony is traveling and offline for another day or too. So [insert witty ctm like comment here] here’s another open thread for fun and amusement.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8597e668',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"According to a recent major UN report, if we are to limit temperature rise to 1.5 °C and prevent the most catastrophic effects of climate change, we need to reduce global CO₂ emissions to net zero by 2050. This means eliminating fossil fuel use fast – but to cushion that transition and offset the areas in which there is currently no replacement for combustibles, we need to actively remove CO₂ from the atmosphere. Planting trees and rewilding are a large part of this solution, but we are highly likely to need further technological assistance if we are to prevent climate breakdown.  So when recent news emerged that Canadian company Carbon Engineering has harnessed some well-known chemistry to capture CO₂ from the atmosphere at a cost of less than $100 a tonne, many media sources hailed the milestone as a magic bullet. Unfortunately, the big picture isn’t as simple. Truly tipping the balance from carbon source to carbon sink is a delicate business, and our view is that the energy costs involved and likely downstream uses of captured CO₂ mean that Carbon Engineering’s “bullet” is anything but magic. Given that CO₂ only accounts for 0.04% of the molecules in our air, capturing it might seem like a technological marvel. But chemists have been doing it on small scales since the 18th century, and it can even be done – albeit inefficiently – with supplies from the local hardware store. As secondary school chemistry students will know, CO₂ reacts with limewater (calcium hydroxide solution) to give milky-white insoluble calcium carbonate. Other hydroxides capture CO₂ in the same way. Lithium hydroxide was the basis of the CO₂ absorbers that kept the astronauts on Apollo 13 alive, and potassium hydroxide captures CO₂ so efficiently that it can be used to measure the carbon content of a combusted substance. The 19th-century apparatus used in this latter procedure still features on the American Chemical Society’s logo. Unfortunately, this isn’t a small-scale problem anymore – we now need to capture billions of tonnes of CO₂, and fast. Carbon Engineering’s technique is hydroxide chemistry at its best. At its pilot plant in British Columbia, air is pulled in by large fans and exposed to potassium hydroxide, with which CO₂ reacts to form soluble potassium carbonate. This solution is then combined with calcium hydroxide, producing solid and easily separable calcium carbonate, along with potassium hydroxide solution, which can be reused. This part of the process costs relatively little energy and its product is essentially limestone – but making mountains of calcium carbonate doesn’t solve our problem. Though calcium carbonate has uses in agriculture and construction, this process would be far too expensive as a commercial source. It also isn’t a practical option for government-funded carbon storage due to the massive quantities of calcium hydroxide that would be required. To be feasible, direct air capture needs to produce concentrated CO₂ as its product, which can either be safely stored or put to use. Thus, the solid calcium carbonate is heated to 900 °C to recover pure CO₂. This last step requires a vast amount of energy. In Carbon Engineering’s natural gas-fired plant, the whole cycle generates half a tonne of CO₂ for every tonne captured from air. The plant does capture this extra CO₂, and of course could be powered by renewable energy for a healthier carbon balance – but the problem of what to do with all the captured gas remains. Swiss start-up company Climeworks is using similarly captured CO₂ to aid photosynthesis and improve crop yield in nearby greenhouses, but as yet the price is nowhere near competitive. CO₂ can be sourced elsewhere for as little as one-tenth of Carbon Engineering’s $100 bottom line. There are also much cheaper ways for governments to offset emissions: it is far easier to capture CO₂ at the emission source, where the concentration is much higher. So this technology is likely to mainly interest high-emitting industries which may stand to benefit from CO₂ with green credentials.  For example, one of the key investors in Carbon Engineering’s capture technology is Occidental Petroleum, a major user of Enhanced Oil Recovery methods. In one such method, CO₂ is pumped into oil wells to increase the amount of crude oil that can be recovered, thanks to increased well pressure and/or improving the flow characteristics of the oil itself. However, including the energy cost of transporting and refining this extra oil, using the technology in this way will likely increase net emissions, not decrease them.  Another key spoke of Carbon Engineering’s operations is its Air To Fuels technology, in which CO₂ is converted into combustible liquid fuel, ready to be burned again. Theoretically this provides a carbon-neutral fuel cycle, provided that each step of the process is powered with renewable energy. However, even this use is still a far cry from a negative emissions technology. There are promising alternatives on the horizon. Metal-organic frameworks are sponge-like solids that squeeze the equivalent CO₂ surface area of a football pitch into the size of a sugar cube. Using these surfaces for CO₂ capture requires far less energy – and companies have started exploring their commercial potential. However, large-scale production has not been perfected, and questions over their long-term stability for sustained CO₂ capture projects mean that their high cost is not yet merited. With little chance that technologies still in the laboratory will be ready for gigatonne-scale capture within the next decade, the methods employed by Carbon Engineering and Climeworks are the best we currently have. But it’s important to remember that they’re nowhere near perfect. We will need to switch to more efficient methods of CO₂ capture as soon as we are able. As Carbon Engineering’s founder David Keith himself points out, carbon removal technologies are overhyped by policymakers, and have received “extraordinarily little” research funding thus far. More generally, we must resist the temptation to see direct air capture as a magic bullet that saves us from having to address our carbon addiction. Reducing or neutralising the carbon burden in the life cycle of hydrocarbon fuels may be a step towards negative emissions technologies. But it is just that – a step. After being on the wrong side of the carbon ledger for so long, it’s past time to look beyond just breaking even. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"**There have been more than 1.6 million confirmed cases of coronavirus in the UK and about 60,000 people have died, government figures show.**
However, these figures include only people who have died within 28 days of testing positive for coronavirus and other measures suggest the number of deaths is higher.
**Find out how the pandemic has affected your area and how it compares with the national average:**
If you can't see the look-up click here.
After the first peak in April, cases started rising again in July, with the rate of growth increasing sharply in September and October, before falling again in the past two weeks.
On Wednesday, the government announced a further 16,170 confirmed cases.
It is thought the infection rate was much higher during the first peak in spring, but testing capacity at the time was too limited to detect the true number of daily cases.
The data for cases can also be broken down by region and comparing the change in those figures by week gives a sense of where there has been a recent increase in newly-reported infections.
Coronavirus infections in England have fallen by about a third during lockdown, according to a major study carried out by Imperial College London.
While some of the worst-hit areas saw the biggest improvements, cases have remained relatively high across England, according to the React-1 study, which is based on tests of more than 100,000 people between 13-24 November.
The latest figures from the Office for National Statistics (ONS), suggest about one in 185 (16,400 people) in Wales had the virus in the week ending 21 November.
In Northern Ireland rates are thought to be decreasing at around one in 145 people (about 12,700 people), while in Scotland, the figure was one in 115 (about 45,700 people).
The average number of daily deaths began to rise again in September, following the first peak in April.
On Wednesday, the government announced a further 648 deaths.
Of these, 555 deaths were in England, 51 in Wales, 38 in Scotland, and four in Northern Ireland.
Rules were amended over the summer to include deaths in the coronavirus total only if they occurred within 28 days of a positive test. Previously in England, all deaths after a positive test were included.
England has seen the majority of UK deaths from Covid-19. Using the 28-day cut-off, there have been more than 52,000.
Although hospital admissions for Covid-19 remain below the levels seen in the spring, there are big regional disparities.
The North West, North East and Yorkshire, and Midlands have seen the highest number of admissions but the situation in all three now appears to be improving.
Cases have risen across large parts of England, with other spikes in areas of Scotland, Wales and Northern Ireland.
The red areas on the map below are those currently seeing the highest number of cases per 100,000 people.
Restrictions have been tightened across the UK in an effort to tackle the number of rising cases.
In England, each local authority has been placed in one of the new three tiers following the end of the recent national lockdown.
Wales has announced a range of further measures, including a ban on pubs, restaurants and cafes serving alcohol, from Friday 4 December.
In Northern Ireland, a further two-week ""circuit-break"" lockdown began on 27 November.
Scotland has a five-tier system of alert levels with different measures in place in different parts of the country.
UK leaders have agreed to allow up to three households to meet indoors during a five-day Christmas period of 23-27 December.
When looking at the overall death toll from coronavirus, official figures count deaths in three different ways.
Government figures count people who died within 28 days of testing positive for coronavirus.
But there are two other measures.
The first includes all deaths where coronavirus was mentioned on the death certificate, even if the person had not been tested for the virus. The most recent figures suggest there had been almost 70,000 deaths by 20 November.
The second measure counts all deaths over and above the usual number at the time of year - that figure was more than 75,000 by 20 November.
The most recent figures available from the ONS are for the third week of November, which show there were 14,276 deaths registered in the UK.
Some 3,038 of these deaths involved Covid-19 - 199 more than the week before.
Deaths normally do rise at this time of the year, but the data from the ONS and its counterparts in Scotland and Northern Ireland show the second wave of the virus has pushed the death rate above the average seen over the past five years by about 21%.
Overall, the figures are still well below the peak of 9,495 deaths recorded in a week, reached on 17 April.
The ""R number"" is the average number of people an infected person will pass the disease on to.
If R is below one, then the number of people contracting the disease will fall; if it is above one, the number will grow.
The government's current estimate for the R number across the whole of the UK is 0.9 to 1.
The estimate for England is 0.9 to 1, while for Scotland it is 0.8 to 1. The estimate for Wales is 0.8 to 1 and in Northern Ireland it is 0.9 to 1.1.
The government has said in the past that the R number is one of the most important factors in making policy decisions."
nan
"
Share this...FacebookTwitterAnd thus he has a good shot of joining the elite ranks of Nobel Laureates along with the esteemed Al Gore and the IPCC. Hat-tip: Hot Air.
If anyone needed more evidence that climate change science has become completely irrational and idiotic, here’s another glittering jewel. It’s another sign of the spreading mental disorder that is fanned by the junk science of manmade climate change. Everything that is different today is now due to man-made climate change.
We’ve all heard the stereotype descriptions about jocks and brains. Unfortunately there are some out there who somehow find ways of setting back the debunking of such stereotypes 10 years or more. Ex-MLB player and now announcer Tim McCarver has single-handedly succeeded doing just that.
Listen to what he says concerning baseball players hitting homeruns: Click HERE.
Global warming Climate change, he theorizes on national TV, makes the air thinner and so the ball carries further when hit.
It has not been proven, but I think ultimately it will be proven that the air is thinner now. There have been climatic changes over the last 50 years in the world. I think that’s one of the reasons that balls are carrying much better now than I can remember.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Stupid! stupid! stupid!
But wait – McCarver’s Theory may actually be true. Planes indeed today are flying further than ever per litre of jet fuel – it must must because of the “thinner air” – clear evidence that McCarver’s Theory is undeniable. The same is true for cars and trucks, which today go further than ever on a litre of fuel, again thanks to reduced air resistance from thinner air.
Furnaces are also burning more efficiently, thus indicating it must have something to do with the air. Wind speeds are faster too, thanks to thinner air making air molecules fly faster. The body of evidence is growing!
I bet if NASA, Hadley or the PIK crunched the numbers with their sophisticated models and supercomputers, McCarver’s Theory would gain a consensus among the real scientific community, Royal Academy and the National Academy of Sciences.
Concerning the homerun records, perhaps the MLB could go back and adjust the statistics. Hank Aaron could be awarded another 30 homeruns because the air back then was “thicker”, and thus take back the record he lost to Barry Bonds, who unfairly set his record in “thin air”.
Also see WUWT for more on the story.
 
Share this...FacebookTwitter "
"More than £200m has been spent on failed waste management projects, according to a scathing report by a cross-party group of MPs. The Public Accounts Committee blamed “lax” and “poorly drafted” public-private funding arrangements. But though MPs are right to criticise these contracts, they fail to oppose the obsession with private finance itself. We shouldn’t be afraid to say it: waste management is simply cheaper and more effective in public hands. The problems date back to Private Finance Initiative (PFI) contracts signed in the late 90s. Under PFI, private businesses stump up the money to build new infrastructure and the public sector pays them back over time. Such schemes have proven controversial and MPs have in the past criticised PFI in roads, hospitals, schools and the London underground, as well as waste management.  In this case, some projects have simply not been finished. For instance the UK government has paid Surrey County Council £124m since 1999, tied to the council’s deal with a contractor to build two waste-to-energy plants. Fifteen years on, these plants have still not been built. And the money? If only waste could be incinerated this easily. The latest report shows how the commercial interest in profitable incinerators can distort policies for dealing with waste, at the expense of recycling and re-use. Waste disposal is rapidly developing and MPs are right to highlight how inflexible these contracts are in the face of such change. Fixed 25-30 year contracts are standard in PFI deals, but they struggle to factor in new technologies and uncertain forecasts of the amount of rubbish produced and the extent of recycling.  But these problems were predictable – and clearly identified by critics of privately financed incinerators. Friends of the Earth warned in 2008 that PFI waste operators were pressing councils to commit to high and growing future waste levels, despite evidence of a levelling-out and even decline. The problems with a proposed PFI waste incinerator in Norfolk, highlighted in the committee report, were very clearly set out several years ago by Chris Edwards of the University of East Anglia. Even waste management firms themselves sometimes admit there is excess incineration capacity across Europe.  The deals nevertheless went ahead, driven by the well-known problem of exaggerated demand forecasts in all kinds of public-private partnerships. Just as road and rail schemes come with excessive traffic forecasts, and new stadiums or sporting events exaggerate their supposed “economic impact”, so proposals for waste treatment plants come with unrealistic consumption projections. Such claims – usually made by consultants with a vested interest – make the projects more likely to be approved.  Exaggeration also raises the level of business guaranteed under PFI contracts – a further incentive. According to a survey by Danish academics, the distortion of forecasts is so consistent and widespread it was only explicable as: systematic misrepresentation, that is, lying … The problem of misinformation is an issue of power and profit and must be dealt with as such, using the mechanisms of transparency and accountability. The UK government was responding to the problems after they emerged, not challenging the projections or the investigating alternative possibilities beforehand. Even the EU, despite its own enthusiasm for uniting the public and private sectors, has proved capable of saying no. Earlier this year, for instance, it refused to subsidise a number of incinerators in the Czech republic where demand couldn’t justify the costs. One obvious solution to the whole financing mess would be for local councils to simply build, own and operate incinerators themselves. However, government credits are only available for PFI schemes, and the committee report is also silent about the option of direct public financing. Local authorities are effectively locked in to public-private deals for waste management if they want to get the benefit of government “PFI credits”. As the MPs report puts it, this “incentivises the use of PFI to construct waste management assets over other options for reducing the amount of waste sent to landfill”. In Sweden, Germany and Denmark, groups of municipalities have built and run incinerators themselves. Some local authorities in the US own their own incinerators too, including at least two in New York state. This reduces and shares risks, but it also erodes potential profits from the market and the dominance of the private companies. No surprises then that the waste-to-energy companies aren’t too pleased – but the European Court of Justice rejected a legal challenge against an inter-municipal incinerator set up by a group of local authorities around Hamburg.  The core reason to build new infrastructure with public funds is financial. It is intrinsically less expensive than PFI or other public-private partnerships and avoids the risk of expensive and inflexible long-term commitments. Even the Republican governor of Alaska – successor to Sarah Palin – has recently scrapped a public-private plan for a bridge in favour of direct government provision, because: “Having the state, rather than a private developer, fund the project could save hundreds of millions of dollars.” The UK, however, remains frozen in its commitment to private operators, in waste and elsewhere – as far as government support is concerned, there really is no alternative. The committee’s report does nothing to change this. It calls for the government to help “improve local authorities’ contracting capability”, but not to develop the capacity to run their own systems. It concludes that 25-30 year PFI contracts are too inflexible, but without acknowledging that the private sector will not build and operate incineration plants without such contracts.  While the report provides further evidence of the need for a break from the political orthodoxy of the past 25 years in order to recreate a mainstream option of direct municipal operations, the PAC itself does not make that break."
nan
"**A care home owner killed himself because of the ""incredible emotional pressure"" of coping with the pandemic, an inquest has heard.**
Vernon Hough, 61, was found dead at a North Wales Police station car park in Llay, Wrexham, on 21 May.
He ran Gwastad Hall Nursing Home in Wrexham with his wife, Helen, caring for 40 residents.
Mrs Hough told the inquest he had lost weight due to worrying about Covid-19. The coroner's conclusion was suicide.
In a statement to the inquest, Mrs Hough said running the care home during the pandemic was ""having an impact"" on her husband.
""He was panicked at times,"" she said. ""We would constantly talk about Covid-19.""
Mrs Hough told the coroner that Mr Hough ""wasn't afraid of catching it, he was afraid of spreading it because we weren't being tested. That's what his fear was.""
She described her husband as a ""worrier"" who had lost one-and-a-half stone (9.5kg) in weight ""due to the worry of Covid.""
Although Mr Hough had previously been prescribed anti-depressants by a GP for night sweats, his wife said he had never been diagnosed as having anxiety.
The inquest heard that he ""wasn't handling"" seeing people in distress.
""At the time we were struggling to get oxygen in the care home"" said Mrs Hough. ""I still cannot get oxygen and we're still in the middle of a pandemic.""
She also said they were having difficulties sourcing PPE and were ""trying to get it off Amazon"".
Coroner David Pojur said the pressure of working through the pandemic had ""overwhelmed"" Mr Hough and it had ""affected his mental health"".
""Running a care home is difficult in the best of circumstances, but during the pandemic that put him under significantly greater stress than it seemed he could cope with.""
Care Forum Wales chair Mario Kreft said Mr Hough's death ""illustrates the enormous pressure care home owners and their staff have been under as a result of the pandemic"".
""It's been such a terribly dark time for people working in the sector and the sense of responsibility felt by Vernon toward the residents of Gwastad Hall clearly became too much for him to bear,"" he said.
""Our thoughts are very much with Vernon's family, friends and staff at this extremely difficult time, not to mention the residents to whom he was utterly devoted."""
"
Share this...FacebookTwitterLast fall I wrote about how self-anointed environmental mastermind politicians in my homestate of Vermont bulldozed public opposition, lots of trees and finally the top of Lowell Mountain to make way for “climate-saving” 450-foot industrial wind turbines. Read here and here.
Here’s how environmental protection by these political environmental pimps appears so far, hat-tip: energizevermont.org.

Crushed stone pad for just one turbine to be installed. Many such sites are being prepared on Lowell Mountain to accommodate a series of turbines, 21 in all. 

How Vermont protects the environment – coming statewide (except Chittenden County, where the fat cats live).

Silent spring for Vermont wildlife.
The source of these photos is mountaintalk.com


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




VIEW ALL PHOTOS HERE
This is all “to save the planet” from the junk-science-based climate catastrophe fantasy.
How about a little prison time for the charlatans perpetuating the hoax? In a way it’s really good that I’m all the way across the big pond now.
Yes, we can thank these political whores for ruining a once beautiful area (please excuse my diplomacy). This of course is just one windpark of an entire series planned by the state.
The Green Wave
It’s just stunning how psychologically people just blindly herd behind a fad to the point where they just don’t even see the massive damage being inflicted. It’s like the story “The Wave“. It’s totally out of control. All you need are a few clever manipulators, and lots of dupes.
According to state senator Joe Benning, also a duped climate-science believer, but at least still sober enough to see the damage:
And more wind farms are coming as corporate investors, motivated by tax incentives and artificially inflated electric rates, seduce small towns with infusions of cash. Since wind is intermittent and has no storage capacity, our policy alone will require more wind farms and many miles of transmission lines to achieve our energy goal. Regulatory authorities are failing to insist on decommissioning plans, meaning our ridgelines will end up littered with forty story rusting hulks when this technology becomes obsolete. These new wind farms are encroaching on our wildlife corridors, destroying pristine mountain environments and radically changing the aesthetics of our state. They pit citizens of towns against each other, and towns against towns in a given region.”
Even if CO2 were a problem, the operation of heavy equipment, the massive earthwork and all the deforestation creates a carbon footprint that likely will never be erased – never mind the permanent disfigurement of the landscape.
Vermont’s children and grandchildren someday are going to ask: What the hell was in Vermont’s drinking water back then?
Share this...FacebookTwitter "
"
Share this...FacebookTwitterYesterday I posted on a new study written by Reinhard Böhm of Austria’s Leading Weather and Climate Agency ZAMG.
His comprehensive, peer-reviewed paper found that there has been no increase in weather extremes in the Austrian Alps – surprising the world’s climate scientists. This study in my view is really big, and is upsetting the Climate Establishment in Europe. Dr. Böhm is quickly becoming the new enfant terrible.
Geologist Sebastian Lüning now provides additional details at his Die kalte Sonne website. I’ve translated his essay (with some editing).
===============================================
Surprise! Fewer Weather Extremes in the Alps Region
By Dr. Sebastian Lüning
The climate is going crazy and everything is getting more extreme. It’s only a question of time before the planet gets destroyed. This is what experts close to the IPCC have been telling us for some years now. But now a scientist has taken a closer look at the hard data and has found something truly amazing. Reinhard Böhm of the Central Administration for Meteorology and Geodynamics in Vienna has examined dataseries from 58 locations in the Alps, some of which go back to the year 1760. All the data is available in the Internet. Böhm published the study in the European Physical Journal.“
As expected also in Austria there has been a warming over the last 200 years, like almost everywhere else on the planet. That is expected and simply represents the transition from the Little Ice Age to the Modern Warm Period. The question that Böhm investigated, however, is: Did the weather get more cranky and more extreme during this time?
Austrian newspaper Die Presse here wrote:
Whether it is snowfall, heavy rains, storms or dry spells: After every notable weather event the media and experts are quick to explain that the increased frequency of extreme events of the recent past and of the coming future is due to man-made climate change. Hardly anyone questioned this claim – except for one person: Reinhard Böhm […]. In his recent research work, he evaluated up to 250 years of old weather data of the Alps region. The result even surprised him. The core message: An increased frequency of weather extremes caused by climate change – at least in the Alps region – could not be detected.”
In a press release of the Institute the stunning results were more shown in more detail (Figure 1) (see the article in Der Standard):
[On] the often quoted increase in weather extremes, this however has not been the case in the Alps. Completely to the contrary: ‘The temperature fluctuations have even decreased over the last decades,‘ summed up climatologist and study author Reinhard Böhm. […] The results of the study have left the scientists amazed.
Result No. 1: Over the last 250 years, the seasonal and annual fluctuation ranges of hot-cold, dry-wet have not gotten more extreme.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Result No. 2: Also over the last 30 years, which have been greatly impacted by man, there has been no trend to more variability when compared to the decades before.
And finally Result No. 3: The long-term development of temperature, precipitation and atmospheric pressure show two long waves of variability with a cycle of about 100 years. The climate was more variable (‘crazier”) in the middle of both past centuries, less variable (‘quieter’) at the start and end of the centuries.“
The last point is very important. As geological studies of the past 10,000 years have shown, natural cycles play an important role in the variability of the climate (see our past blog articles.

Figure 1: Changes in climate variability in southern central Europe over the past two centuries. Attention: NOT shown are the absolute values. Only the anomalies. Graphic source: ZMAG.
For the IPCC faithful, these results are quite unexpected. For years they have been claiming just the opposite. Austrian television ORF here writes:
Böhm’s study stands in contradiction to other studies that show a global increase in weather events is detected. The Potsdam Institute for Climate Impact Research spoke of a “Decade of Weather Extremes”. Also in March 2012 a Report by the IPCC showed more extreme weather events and, among other things, it is highly likely that periods of drought will occur more often over the coming decades  – in many regions of the world, among them also Central Europe.“
Böhm takes these these alarmist colleagues especially to task. What is it that is driving some scientists to always want to observe everywhere only a worsening of the climate? Die Presse writes:
Böhm doesn’t hold back on criticizing the PR work of some colleagues. To save the world from climate change, one needs lots of attention. Claims that weather extremes accompany temperature increase may be wonderful for marketing yourself, but it has got nothing to do with reality.’ “
It is wonderful to see that there is a push-back by climate scientists and that solid data and evidence is slowly gaining the upper hand. The study shows once again the importance of datasets that go far back into the past. Today’s climate can only be properly assessed when put in a historical context.
============================================
 
Share this...FacebookTwitter "
"

The neoconservative call to ostracise Russia by kicking her out of the G8 and denying her membership in the World Trade Organisation is deeply mistaken. Washington’s desire to lash out economically and diplomatically at Russian misbehaviour in the Caucasus is trumping rational thinking on the future of a vital strategic relationship.



Washington’s fundamental error is to mislabel Russia as a democratic country in the 1990s that suddenly turned undemocratic during the past decade. It is mistakenly presumed, therefore, that Russia can be incentivised to appreciate the error of her recently authoritarian ways and sheepishly return to a state of democratic bliss and constructive multilateralism.



The trouble is that post‐​Communist Russia has never been democratic in the liberal, Western sense. Rather, in zigzag fashion the Russian political system has been slowly transitioning away from totalitarianism towards a democratic system compatible, one hopes, with Russian history and cultural traditions.



Consequently, asking in the wake of Russia’s intervention in Georgia, ‘Why did Russia go wrong?’ is the wrong question. The awkward question Americans should be asking, not of the Russians, but of themselves, is, ‘What can the West do to encourage and to sustain Russia’s political transition?’



The Bush administration needs to avoid a holier‐​than‐​thou attitude in these matters. Unless and until the U.S. revises its critique of Russian politics, it runs the risk of applying a democratic double standard to U.S.-Russia relations.



One observes, for example, the Bush administration’s marked impatience with the pace of Russian democratisation. Yet, it continues to exhibit tremendous patience with democratisation’s meandering (to put it charitably) pace in countries such as Egypt and Saudi Arabia, not to mention the lengthy indulgence of Pakistan.



Economic development is the catalyst for Russia’s long‐​term political maturation, as it has proven to be in most countries. Hence, the best way to foster Russian democracy and, consequently, calm Moscow’s approach to international relations, is not to threaten Moscow but, less dramatically and more realistically, to help foster economic growth in Russia.



The larger irony is that the world’s greatest liberal democracy is itself becoming increasingly illiberal. Both domestically and internationally, there is a need to refocus on a broader definition of democracy than American politicians are comfortable employing in public, especially when lecturing their Russian counterparts.



In practice, a myriad of economic and personal freedoms form integral pillars of a strong and stable liberal democracy. Simply put, political freedom is not sustainable without the foundations supplied by economic and personal freedom.



Yet, American liberal democracy is in the process of being replaced by a bully‐​like Nanny State. Take, for example, health and environmental policy.



Here, one witnesses the rise of highly coercive, arguably fascistic, policies to control individual choices and restrict personal freedom over, for example, one’s diet and the consumption of a list of still‐​legal products, such as alcohol and tobacco.



More worrisome, perhaps, is the fact that U.S.-led international health and environmental organisations are initiating pseudo‐​scientific campaigns upon those middle‐​income countries with allegedly indulgent energy, and dangerous personal, consumption habits.



There are no prizes for guessing which former Eastern European superpower has been chosen as the World Health Organisation and the Intergovernmental Panel on Climate Change’s next big juicy target. The Russians know this and, consequently, are circling the diplomatic wagons.



Going forward, the U.S. needs to work with Russia as her strategic partner rather than acting as her strategic adversary.



Unlike the cartoonish rhetoric of recent days, the American critique of Russian behaviour should be informed and it should be candid. Above all, it should be constructive, if Washington’s sincere goal is no more than the betterment of the Russian people.



The Russians do not think the U.S. is sincere. Rather, they believe the critique of Russia’s actions is merely an instrument of American foreign policy.



Absent a belated U‐​turn, American foreign policy – conducted by those living in an democratic glass house – will continue to throw ever‐​larger political stones in Russia’s direction. Policymakers in Washington shall discover that this course of action damages not only the stones’ intended target, but also the stone thrower, herself.
"
"

This is curious. Greenpeace is giving away free pedometers at COP16 in Cancun. Watch the video below. I don’t really understand the point of all this, except maybe its some sort of guilt over the limousine largess from COP15 in Copenhagen, and they want people to walk to their hotels? Even so, they apparently are unaware of this Times Online article which points out, walking apparently produces more CO2 than driving:
Walking to the shops ‘damages planet more than going by car’
Walking does more than driving to cause global warming, a leading  environmentalist has calculated.
Food production is now so energy-intensive that more carbon is emitted  providing a person with enough calories to walk to the shops than a car  would emit over the same distance. The climate could benefit if people  avoided exercise, ate less and became couch potatoes. Provided, of course,  they remembered to switch off the TV rather than leaving it on standby.
…
{Goodhall says] “The troubling fact is that taking a lot of exercise and then eating a bit  more food is not good for the global atmosphere. Eating less and driving to  save energy would be better.”
Well, that’s inconvenient. Greenpeace says the opposite. They write on the Greenpeace More Walk Less Talk page:


COP 16 will be the seventh Conference of the Parties since the Kyoto  Protocol entered into force in February 2005. That’s a lot of talking.
The physical layout of these meetings means there is a great  deal of walking. Walking, as we all know is very good for you – it’s  credited with helping breathing, improving circulation, bolstering the  immune system, and helps people stay in shape.
It is also, of  course, good for the climate. But, as international climate negotiations  processes show, sadly so far – not enough governments are “Walking the  Talk.”
So, in Cancun – Greenpeace is hosting “More Walk, Less  Talk” – a competition to find the person and the country that covers the  most ground in Cancun.
Yes, the race to the future starts here. Grab your step-counter and go!

Well I’ve got no beef with the “walking improves health” message. I wonder what the winning prize is? Watch the promotional video:

And the battle continues over the issue of walking versus driving, the Pacific Institute wrote a rebuttal to the walking is worse versus driving story.
As noted by Goodall, what really stands out in this comparison is the astoundingly high GHG values for walking when the calories come from beef or dairy. The idea that moving a 2,853 pound Nissan Sentra42 plus a 189-pound driver could possibly generate fewer GHGs than if that driver simply walked the same distance underscores the staggering carbon intensity of beef and dairy production. To be fair to Goodall, this was in fact his underlying message: meat-intensive diets are energy intensive and greenhouse gas intensive.
So obviously, the message missing from the Greenpeace Pedometer message at COP16 is “walk but don’t eat meat or dairy”.
So much for those fancy Cancun dinners on whomever is funding the attendee. Bean burrito for you!
Of course the whole “walking to save the planet” idea gets negated by the simple fact that none of these people arrived by sailboat in Cancun, but used some fossil fuel gussling airplane and then maybe a train or taxi.
But at least they’ll feel better about themselves walking around hungry, right?


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e86ba4561',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**A further 28 people have died with coronavirus in Wales, taking the total to 2,474, according to the latest figures.**
Public Health Wales data also showed 1,251 more people had tested positive for Covid-19, taking the total to 75,986.
Each of Wales' seven health boards reported at least one new Covid-related death on Thursday.
Cwm Taf Morgannwg reported the highest number, with eight new deaths.
Across other health boards in Wales, Swansea Bay reported seven new deaths, while there were six in Aneurin Bevan and four in Betsi Cadwaladr.
Cardiff and Vale, Hwyel Dda and Powys all reported one new death.
Blaenau Gwent still has the highest case rate - the number of new cases per 100,000 people over seven days - of any county in Wales, measuring at 405.1 in the week up to 23 November.
It is slightly lower than yesterday's figure of 415.1.
It is followed by Torfaen (333.1), Newport (298.7) and Neath Port Talbot (294.5).
Gwynedd (23.1) and Conwy (28.2) have the lowest case rates in the country.
There has now been a total of 1,441,357 tests carried out in Wales since the start of the pandemic, with 14,564 carried out on Wednesday.
Acute patients from Powys are usually treated across the border at hospitals in England, so deaths of Powys residents usually only appear in registrations reported later by the Office for National Statistics (ONS).
Those ONS figures \- which are higher - also count both confirmed and suspected cases of Covid, as well as deaths in all settings, including care homes, hospices and people's own homes. The most recent weekly figures are the highest since May.
PHW reports new deaths daily, but these are usually from previous days.
**Find out how the pandemic has affected your area and how it compares with the national average:**
If you can't see the look-up click here.
The postcode search has been updated to replace data for health boards in Scotland with data for local councils. In England, data for county councils has been replaced with data for district councils. Figures for boroughs and unitary authorities remain unchanged."
"
Share this...FacebookTwitterThe insurance industry is one of the primary beneficiaries of the climate change panic.
The more people fear climate-related disaster, the more inclined they’ll be to buy up insurance or to pay higher premiums. No industry has a a greater interest in fanning climate panic than the insurance industry. Hat-tip: a reader.
German insurance industry moves to cash in
Check out this info-ad put out by a German insurance agent in the online Norderstedt Stadtmagazin, which I’ve translated in English.
€ ‘Unpredictable weather– protect yourselves!’
Norderstedt (em/mp) storm Kyrill or the summer flood on the Elbe: Over the last years the number of extreme weather events has increased. 
Many scientists trace it all back to climate change. For homeowners, these natural disasters mean damages in the billions. ‘Because of climate change we have to prepare ourselves for the increase in extreme weather events and natural catastrophes,’ insurance expert Finn Herbert knows. ‘Rain deluges, flooding, storms, hail and long-lasting cold snaps or intense snowfalls can lead to huge damage to your buildings and your personal belongings. Everyone is vulnerable. Heavy downpours can even cause flooding far away from rivers and lakes.’


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




A normal residential building – and a personal property insurance are not enough to protect yourself from the consequences of so-called natural perils. This can be only offered by insurance against the risks of fire, strom, hail, lightning strike, water pipes, and in personal property insurance also against breaking in and theft. ‘For the elementary perils such as flooding, water back-ups, downpours, snow loads, landslides, sinkholes, avalanches and volcanoes there is insurance against natural hazards,’ explains Finn Herbert. ‘These can be included in with your home and personal belongings insurance. Give us a call – We’ll gladly inform you.’
Ernst von der Reith GmbH”
Big Insurance penetrates the IPCC
You’ve got to wonder when scientists like Stefan Rahmstorf work hand in hand with the reinsurance industry, writing doomsday reports that help fatten the bottom line. Hartmut Grassl, a climate alarmist, is also connected to Munich Re, the world’s largest reinsurer.
Reader DirkH points out how the Munich Re has at least two more agents at the IPCC. Working Group II AR5 Writing Teams, Chapter 10 — Key economic sectors and services, Eberhard Faust, Munich Reinsurance Company and an excerpt from a report from Dr Sandra Schuster, meteorologist with Munich Re, Sydney, who has just been appointed as a Lead Author (WG2) for IPCC AR5.
It’s a real scam when the insurance industry buys up science and pays the science institutes and scientists to spread fear among its customers, stampeding them into the arms of their sales agents. Once again it’s the little guy getting the shaft.
The insurance industry oversight authorities ought to read “Die kalte Sonne – Warum die Klimakatastrophe nicht stattfindet” and start cracking down on this dubious business.
It would be interesting to know what your insurance agent says about the “increasing climate risks”. My agent doesn’t believe it, and he knows I’m not duped by the scam.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAs it becomes more and more evident that renewable energies such as solar and wind are turning out to be far costlier than ever anticipated, and will do nothing to the climate, the masterminds behind them don’t want to hear it. Now they are going to do whatever it takes to make them work – no matter the cost.
In Germany, BARD company, located in the northern seaport of Emden, has just announced it will lay off its 100 employees at its windmill rotor blade factory. The reason? Lack of demand. Offshore wind companies are hesitating to invest in offshore windparks due the high risks surrounding the technical challenges.
Hat-tip  EIKE, which writes:
Offshore company BARD is closing its rotor blade production in East Friesian Emden. ‘100 employees are impacted,’ said the Chairman of Management Bernd Ranneberg in Emden on Monday.”
So how do you encourage companies to invest in high risk renewable energy projects? Simple – you eliminate their risk. This is what a working group now advises the German government to do: It is the lowly consumers who should pick up the risks and costs for the adventurous business of offshore windparks. The companies investing in them won’t have to worry, and so can dive right in.
Germany daily Die Welt yesterday writes:
To bring the stalled offshore wind power back into gear, the State and power consumers will overtake the risks from the investors. This is the only way of assuring the construction of wind turbines needed for meeting the objectives of the country. The main point is the takeover of the liability risks of the power grid operating companies, which have been the main cause of delay.”
Socializing the risks and costs. Die Welt quotes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




‘To the extent that possible damages cannot be insured despite technical and organisational measures, the compensation for damage is to be socialized,’ says a paper produced by a working group that is represented by power grid companies, windpark operators, and suppliers such as Siemens, as well as the Ministry of Economics. Possible would be an intervention by the federal government, or rolling over all the power grid costs and fees onto the power customers.”
Astronomical costs ahead. As Die Welt writes, there are other costs:
Other possible cost drivers in connection with the energy transformation, such as high buying prices for power from the construction of new power plants, or the rising payments for renewable energies, are not included in the calculation. A study by the Technical University of Berlin summed up the direct and indirect costs of the Renewable Energy Feed-In Act until 2030 and pegged them at € 335 billion.”
Poor Germany. Finally, EIKE writes that the German Federal Power Grid Agency warns that power consumers need to expect “massive power price  hikes.” The German news agency DPA writes:
The reason the necessary expansion of the power grid for alternative energies…the investment range is from about 30 to 47.5 billion euros.”
High prices normally would drive companies out of Germany. But no problem here, too. Large power consumers like industries are exempt from paying high power prices. The entire costs will be borne by the lowly little consumers. The government saw to that last summer. The DPA writes:
Higher costs for consumers were assured by a law called the Power Grid Charge Regulation passed during the summer of 2011, where large power consumers can apply for a discount…more than 1600 applications have poured into the Federal Agency up to now. The discounts or full exemptions have a volume 400 million euros annually – money that will have to be paid by the remaining power consumers.”
Clearly huge costs are in the pipeline for German consumers. Call it fuel for social anger.
Share this...FacebookTwitter "
"When the UK Environmental Audit Committee investigated the issue of protecting our marine environment last month, it concluded that there had been a woeful lack of decisive action from the government so far. The committee, led by the MP for Stoke-on-Trent, Joan Walley, questioned the government’s commitment to introducing Marine Conservation Zones after less than a quarter of the 127 sites recommended by independent project groups were designated as conservation areas. And even in those that were established, there are serious concerns remaining over the adequacy of the enforcement provisions put in place. None of them, for example, ban the use of damaging fishing gear such as trawls and dredges, equipment that causes long-term damage to the sea bed and obliterates fish spawning areas. And as an example of why that’s such an important omission, the paper we’ve published, a scientific study of commercial fishing catches in the English Channel over the past 90 years, reveals the true impact that industrial fishing has had upon marine life. Fish landings from the Channel grew from 9,146 tonnes in 1920 to 50,924 tonnes in 1970, peaking at 177,793 tonnes in 1983 and stabilising around 130,000-150,000 tonnes over the last decade. In that time the amount of cod, haddock and hake dropped from 48% to just 4% of the catch. Sharks and rays fell from 34% of catch in 1920 to 6% in 2010. There’s been a huge decline in what is called white fish, those species that live near the sea bed such as cod, ling, hake and haddock which are prized for their delicious flakes of white flesh. Fish such as halibut that can grow as big as a man, and the common skate have disappeared completely off the southern coast of England and northern France.  When we examine the footprint of mobile fishing gear, like beam trawlers and scallop dredgers, the reason is screamingly obvious – Britain’s sea bed is repeatedly gouged by tonnes of heavy fishing gear. It’s no wonder that the only fish left are tiddlers. Our supermarkets stock cod and haddock freighted in from Iceland and Norway, where fishing with trawls and dredges is banned in coastal waters because of the damage it does to the fishes’ spawning areas. Most of the salmon, bass and bream we eat come from from fish farms, because we simply cannot catch enough of those species in UK waters to meet consumer demand. The ecological balance of the seas around us has changed dramatically. Intense fishing of the English Channel by fleets from all over Europe has wiped out stocks of larger fish, allowing commercially undesirable species – the cockroaches, rats and mice of the sea – to thrive. Perversely, business is booming for the scallop-dredging fleet since scallops have tough shells and thrive in heavily trawled areas. But most of this catch is destined for the export market – it seems crazy to export what we catch and import what we eat. A common misconception, one that is perpetuated by fisheries ministers throughout the European Union, is that there are too many fishermen catching too few fish. The problem is quite the opposite: there are too few fishermen catching too many fish. Large vessels manned by a skeleton crew trawl up vast quantities of sea life, burning fuel that is subsidised by the tax payer. I want to see harbours bustling with small fishing vessels catching delicious food in a sustainable manner. The only way to achieve that is to prevent widespread damaging activities. We know from our own research in south-west England that marine life soon recovers once the use of mobile gear is stopped in inshore waters. If you dive in shallow waters off the Azores or Norway, where the seabed is left alone, the seabed is teeming with life, with small fish that grow up to become the fish that feed the offshore fishing industry and, ultimately, feed us. As Walley concluded: “When a rare species or biodiverse stretch of sea bed is destroyed it may be lost forever. The government must therefore act on the best available evidence and base its decisions on new marine conservation zones on the precautionary principle, rather than demanding unobtainable evidence.” The scientific evidence is in. Now is the time for the government to act. Setting aside areas where marine life can recover makes sense and is the right thing to do."
"**Germany is seeking an agreement with EU countries to keep ski resorts closed until early January, in an attempt to curb the spread of coronavirus.**
Chancellor Angela Merkel told parliament that efforts were being made to reach a Europe-wide decision.
Italy and France have expressed support for a co-ordinated approach. But Austria has voiced concern.
Some of the early European coronavirus hotspots were at ski resorts, helping spread infections across the continent.
Last week, the World Health Organization (WHO) warned that Europe faced a ""tough"" six months , amid mounting cases. Renewed restrictions have led to a reduction in new infections in some countries, but there are fears the pandemic could worsen over the winter.
Like Germany, Italy has also stressed the need for a united approach on the issue of ski resorts, and Prime Minister Giuseppe Conte has already backed delaying the start of the ski season.
""If Italy decided to shut down all its ski lifts without any support from France, Austria and the other countries, then Italian tourists would risk going abroad and taking the contagion back home,"" he told La7 TV earlier this week.
Many Italians head for the slopes over the Christmas and New Year break and the period is a vital part of the local economy for ski resorts across Europe.
French President Emmanuel Macron has made clear that the country's ski resorts will stay shut until the New Year. Prime Minister Jean Castex said on Thursday he wanted to see the coronavirus rules for ski resorts ""harmonised at European level as much as possible"".
France plans to ease its current national lockdown in three phases through to the end of January. Most restrictions will be eased for a few days over Christmas. Mr Castex said ""this family celebration cannot take place without grandparents being present"".
But Austria has voiced concern over any EU-wide plan for ski resorts, with Finance Minister Gernot BlÃ¼mel saying that if the EU forced the resorts to remain closed, ""then they will have to pay for it"". Compensation would run into billions of euros.
Austria's government is already facing legal action over the Ischgl ski village, which was linked to cases in 45 countries after skiers brought the virus home with them.
Switzerland is not in the European Union and, unlike other Alpine destinations, its ski resorts are already open, so skiers unable to spend their winter breaks in neighbouring countries could head there instead.
Ski lifts are running, with a requirement to wear masks, prompting criticism from WHO Covid-19 envoy David Nabarro. ""Once infection rates sink, and they will sink, then we can be as free as we want. But right now? Should ski resorts open? Under what conditions?""
Meanwhile, Mrs Merkel has also defended the decision to extend Germany's partial lockdown until 20 December, announced on Wednesday.
The stricter rules will limit private gatherings to five people from two households coming into effect from next week - although children under the age of 14 are exempt.
German leaders have also unveiled plans for Christmas, with meetings of up to 10 people allowed from 23 December until 1 January.
Addressing the Bundestag - Germany's lower house - on Thursday, Mrs Merkel said the tight restrictions must remain for now because the goal was still to get down to a maximum weekly rate of 50 new infections per 100,000 inhabitants.
But in 62 areas, including Berlin, the figure was above 200, she said. ""Unfortunately we have to say that we cannot promise any relief for Christmas and the New Year,"" the chancellor said."
"**Cornwall and the Isles of Scilly are two of only three areas in England which will be in tier one from next Wednesday.**
MPs and businesses have welcomed the news and spoken of ""relief"" at ""the end of a difficult year"".
The Isle of Wight, Cornwall and the Isles of Scilly are the only areas in tier one.
One Cornwall MP warned against the grading being ""grounds for complacency"".
Amy Newland, from the White Hart pub in Chilsworthy, said: ""I'm extremely relieved, at least we know that we can trade normally.""
She added that she felt sorry for pubs in neighbouring Devon which will be under tougher tier two restrictions.
""It's mixed emotions but a huge relief for us,"" she said.
Paul Eaton, who runs the Royal Inn at Horsebridge, near Tavistock, just inside the Devon border, said: ""Some of my regulars are already planning where they can go in Cornwall.
""It's a long border, with pubs scattered both sides.""
Kim Conchie, chief executive of Cornwall Chamber of Commerce, said it had been ""a difficult year"" but this marked ""the first stage of securing jobs and companies for our future"".
Holiday homes letting agent Lin Wallis in Cornwall tweeted she had five inquiries in 10 minutes after the announcement.
In the seven days to last Saturday the rate of infections in Cornwall was 59 per 100,000 people, the England average was 169.
In the same period there were 337 new cases, down by 176 on the previous week.
Steve Double, Conservative MP for St Austell and Newquay, said Cornwall returning to tier one restrictions was ""particularly good news for the thousands of hospitality businesses"".
He added: ""However whilst we can welcome this news it should be no grounds for complacency.""
Tier one means people can meet indoors and out up to a maximum group of six, pubs and restaurants can re-open, closing at 23:00 GMT but people will still be encouraged to work from home.
Differences between the new tiers include restrictions on where households can meet up:
The system will be regularly reviewed and an area's tier level may change before Christmas - the first review is scheduled for 16 December."
"

 _Global Science Report_ _is a feature from the_ _Center for the Study of Science_ _, where we highlight one or two important new items in the scientific literature or the popular media. For broader and more technical perspectives, consult our monthly “Current Wisdom.”_   




Climate change has been called “the biggest market failure the world has seen” and “the mother of all externalities.”



you can pretty much guess what kind of SCC value van den Bergh and Botzen prefer.   
  
  
To support their apparent preference for a high SCC, they spend the bulk of their paper imagining bad climate outcomes—with high monetary damages—and are generally dismissive of positive climate impacts. For example:   




Nevertheless, our summary of the main effects provides a clear insight, namely that unquantified negative effects of climate change tend to domi­nate unquantified positive effects. The negative effects comprise large biodiversity losses, political instability, violent conflicts, large‐​scale migration, extreme weather events, natural disasters and the effect on long‐​term economic growth. Accounting for the latter is likely to increase the SCC because large impacts of cli­mate change are expected to reduce the rate of GDP growth, partly because of negative effects on labour and capital productivity.



Unsurprisingly, when you include a lot of negative impacts along with a low discount rate, the IAMs produce very high estimates of the SCC.   
  
  
In fact, van den Bergh and Botzen arrive at a “conservative” SCC value of $125. For comparison, value used by the Obama Administration for cost/​benefit analyses of new regulations is $36.   
  
  
Interestingly, in their “conservative” analysis, they never once mention the growing body of new and prominent scientific literature that produce updated estimates of the earth’s climate sensitivity—a measure of how much climate change we expect from carbon dioxide emissions—that are much lower and much more tightly constrained than the ones used in _all_ of the studies reviewed by van den Bergh and Botzen.   
  
  
The lower climate sensitivity estimates not only reduce the overall impacts from expected climate changes, but they do so primarily by reducing the chances of unexpected and catastrophic changes—the biggest drivers of the high SCC values in the IAMs. It has been repeatedly shown (see here, here, and here for example) that incorporating the new, lower climate sensitivity estimates reduce the IAMs’ SCC determinations by some 40 percent.   
  
  
And there are lots of other things, which, if better incorporated in the IAM’s, would lead to lower SCC values.   
  
  
If the positive benefits from carbon dioxide emissions on the planet’s crop production were better included in the IAM’s, the SCC value drops further. And if arguments for the use of a higher discount rate, rather than the very low one espoused by van den Bergh and Botzen win the day, the SCC drops further still.   
  
  
Add to the mix a more reasoned view of future climate extremes, and before you know it, it is an easy argument to make that the SCC value should fall significantly _below_ the Administration’s $36 rather than some three to four times higher.   
  
  
It is bad enough that van den Bergh and Botzen present a rather one‐​sided view of the science of climate change/​climate extremes and the economics concerning the choice of discount rate, but for them to term their analysis “conservative” is really taking things too far. “Alarmist” would be a more apt description.   
  
  
Our hope would have been that the reviewers for _Nature Climate Change_ would have caught the glaring oversight of the current climate sensitivity literature (with one of the most persuasive articles appearing in the sister journal _Nature Geosciences_ ), but that didn’t happen. We’ll withhold speculation as to why that was the case.   
  
  
**Reference:**   
  
  
Van den Bergh, J.C.J.M., and W.J.W. Botzen, 2014. A lower bound to the social cost of CO2 emissions. _Nature Climate Change_ , **4** , 253–258, doi:10.1038/NCLIMATE2135.
"
"The Mediterranean Sea holds some of the most heavily fished waters in the world, and a recent paper has revealed the extent to which the sea – which has 19 nations on its shores – has been exploited.  Academics from the Institute of Marine Biological Resources and Inland Waters in Greece, writing in the journal Current Biology, examined catches of nine species including hake, mullet, anchovy, sardine, sole and turbot from 1990-2010. The decline of the Mediterranean fisheries started much longer ago, but compared to the success of the EU Common Fisheries Policy in reversing the decline of fish stocks in parts of the North Atlantic and North Sea over the same period, current fishing patterns have prevented any recovery. With many stocks in continued decline, the authors argue this “skeleton in the closet” must be addressed, as the social and economic impact of a collapse of Mediterranean fisheries would be immense. The better managed North Atlantic fisheries benefit from three advantages over the Mediterranean. Most important is selecting for adult fish rather than juveniles, as the taking of young fish in the Mediterranean (using a minimum 40mm square or 50mm diamond net, compared with larger than 100mm used in the North Atlantic) is the main cause of over-exploitation. Greater fish species selectivity in the North Atlantic sees fishing concentrated on a few key stocks in specific areas, which minimises the problems of unwanted by-catch found in mixed fisheries. And fishing regulations are generally better implemented and enforced in the North Atlantic than in the Mediterranean.  The focus on large fish, characteristic of small-scale fisheries which are still very important in the Mediterranean, has affected species’ reproductive potential. By hunting only the larger fish, it’s possible to eradicate some of the best genetic material of the species – larger spawners also usually have higher fertility and better egg quality. So the strategy of “fishing for big ones” followed by some fishers in the Mediterranean must be well managed – something which is not yet happening.  For the millions of tourists heading to the Mediterranean in summer, a marine reserve or natural park means a beautiful place where they can enjoy the sea and its creatures during their holidays. But marine reserves are vital for fisheries management too, as they protect the fish inside, providing a safe haven for building up stocks of larvae and adults who then move behind their watery frontiers to replenish stocks elsewhere. Existing marine reserves are mostly coastal but new reserves to protect the deeper waters offshore should be planned. Large spawners – older, strong and fertile fish important for ensuring a strong subsequent generation – often inhabit particular habitats offshore that for many years functioned as refuges, with fishing pressure absent or low. But increasingly even these areas have been exploited, using techniques such as bottom long-lines to reach large fish, such as the hake found in underwater canyons in the Gulf of Lions in the northwest Mediterranean.  At the other end of the lifecycle, young fish also tend to concentrate in particular areas of the seabed. It’s vital to protect spawning grounds (where spawners come to breed) and nurseries (where juveniles concentrate) through the establishment of new Mediterranean marine protected areas. This should be part of an ecosystem-based management approach, together with technical requirements to improve fishing gear and techniques to ensure better selectivity of fish size and species. The small net mesh size used in the Mediterranean leads to a much higher rate of fish discards. The Common Fisheries Policy now aims to reduce unwanted by-catch and consequently reduce discards policy by requiring all catch to be landed. But the ecological benefits of this policy are very doubtful – fish that would otherwise be discarded may end up driving new markets for protein and oil, either for humans or as animal feed. The tide could turn against the discard policy if it provides incentives for fishers to target fish species or sizes that were previously ignored.  A final problem yet to be solved is that fisheries management is based on constraints and quotas set largely in accordance with social and political targets. Yet the seas are subject to ecological forces, many still largely uncontrolled. Unavoidable climate changes will lower productivity of certain stocks and favour others. Any changes we make through ecosystem-based management must maximise benefits today, but only if they don’t damage prospects for the future."
"
Share this...FacebookTwitterThe German media are reporting on a developing outbreak of the oak processionary caterpillar now spreading over the Eastern and Southern areas of Germany.
The caterpillars are pests in oak forests and they pose a health hazard because of their poisonous hairs which can cause skin irritation and asthma. Quite the nasty critter, indeed.
German daily Die Welt reports that the dangerous caterpillar develops especially well in warm and dry springs, adding:
Also climate change has likely contributed to the spread of the pest.”
Even though they don’t cite any information or data to back it up. I suspect they got their information from Wikipedia, who write:
The moths are widely distributed in central and southern Europe, and are occasionally found as far north as Sweden. In the southern countries of Europe the populations are controlled by natural predators, but these predators do not exist in northern Europe. Their range is expanding northward, possibly or partly as a result of global warming [clarification needed, citation needed]. The moths are posing an increasing threat to humans as their range is being extended by the warming European climate.[citation needed]. The backs of older caterpillars (3rd to 6th instars) are covered with up to 63,000 pointed defensive bristles containing an urticating toxin (thaumetopoein or closely related compounds). The setae break off readily, become airborne and can cause epidemic caterpillar dermatitis (lepidopterism), manifested as a papular rash, pruritus, conjunctivitis and, if inhaled, pharyngitis and respiratory distress, including asthma or even anaphylaxis.”
The oak processionary caterpillar has spread during other years as well.
Read more here.
Share this...FacebookTwitter "
"Parliament’s pension fund has made record investments in renewable energy and cut its exposure to fossil fuel companies to bring MPs’ pensions in line with the government’s climate action targets. A report from the £700m pension fund showed that almost a third is now being invested in low carbon and environmentally sustainable funds following calls from hundreds of MPs to align the fund with the government’s legally binding climate commitments.  The decision by the pension fund’s trustees to back a push for greener investment, first revealed by the Guardian last year, has resulted in renewable energy infrastructure investments making up 5% of the fund for the first time. The move is a victory for the 360 serving and former MPs who have been pushing for the pension fund’s investments to fall in line with the government’s climate agenda. The campaign was supported by all of the Labour party’s leadership candidates, the leaders of the Liberal Democrats and the SNP, and senior Conservatives including Guy Opperman, the minister for pensions and financial inclusion. However, the pension’s trustees have stopped short of divesting entirely from fossil fuel companies and retain multimillion-pound investments in the oil companies Royal Dutch Shell and BP. The annual report showed that the fund has decreased its investment in BP by almost two-thirds in the past year, to £4.4m, and cut its holdings in Shell by a quarter, to £8m. Caroline Lucas, the Green party MP behind the campaign, said the fund needs to fall in line with parliament’s decision last year to declare a climate emergency by divesting from all fossil fuels. “Investing in clean energy is clearly the right thing to do, financially and for the future of our planet, so I’m glad the Parliamentary Pension Fund is doing this. But it has to also stop investing in Shell and BP,” she said. “These investments cannot be justified on ethical, environmental or financial grounds, and they undermine MPs’ credibility in addressing the climate emergency. They have to stop.” The trustees wrote to Lucas last year, in correspondence seen by the Guardian, to confirm that the fund would reconsider its investment strategy but adding that it may choose to remain investors in oil companies in order to have a “voice” at investor meetings and shareholder votes."
"
Cites nearly half a million dollars in state grant-funded climate research  conducted while [Dr. Michael ] Mann— now director of the Earth System Science Center at  Penn State— was at UVA between 1999 and 2005.
Virgina Attorney General Ken Cuccinelli - Image: Cuccinelli Campaign
From The Hook, it seems satirical YouTube videos will be the least of Dr. Mann’s worries now.
=================
No one can accuse Virginia Attorney General Ken Cuccinelli of shying  from controversy. In his first four months in office, Cuccinelli   directed public universities to remove sexual orientation from their  anti-discrimination policies, attacked the Environmental Protection  Agency, and filed a lawsuit challenging federal health care reform. Now,  it appears, he may be preparing a legal assault on an embattled  proponent of global warming theory who used to teach at the University  of Virginia, Michael  Mann.
In papers sent to UVA April 23, Cuccinelli’s office commands the  university to produce a sweeping swath of documents relating to Mann’s  receipt of nearly half a million dollars in state grant-funded climate  research conducted while Mann— now director of the Earth System Science  Center at Penn State— was at UVA between 1999 and 2005.
If Cuccinelli succeeds in finding a smoking gun like the purloined emails that led to the international scandal  dubbed Climategate,  Cuccinelli could seek the return of all the research money, legal fees,  and trebled damages.
“Since it’s public money, there’s enough controversy to look in to  the possible manipulation of data,” says Dr. Charles Battig, president  of the nonprofit Piedmont Chapter Virginia Scientists and Engineers for  Energy and Environment, a group that doubts the underpinnings of climate  change theory.
…
The Attorney General has the right to make such demands for documents  under the Fraud Against  Taxpayers Act, a 2002 law designed to keep government workers honest.
=================
more at The  Hook
h/t to Chip Knappenberger


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c158e06',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Families on Universal Credit face ""agonising uncertainty"" after Rishi Sunak did not confirm what would happen to their benefits next year, campaigners say.**
Universal Credit claimants were given a Â£20-a-week boost in response to the coronavirus pandemic in April.
The temporary rise is due to come to an end in April 2021.
The chancellor did not say whether the increase would be extended, or cut, in his spending review.
Speaking after delivering his statement to MPs, he said the increased payment would continue until next spring.
He added: ""Let's get through winter, see where we are with the virus and what the economy looks and decide then how best to support people.
""Everyone can rest assured we remain committed to making sure we look after the most vulnerable in our society.""
Footballer and anti-poverty campaigner Marcus Rashford tweeted: ""Is the Universal Credit uplift going to be taken away in April?""
Paul Noblet, from youth homelessness charity Centrepoint, said: ""The government's failure to commit to retaining the current uplift in Universal Credit is hugely disappointing and will weigh heavily on the minds of millions of people for whom the Â£20 a week increase has made a huge difference.
""There is still time for the government to reflect on this issue between now and the end of March and we urge them to think again.""
The chancellor set out his spending priorities for the year ahead earlier, warning that unemployment is set to peak at 2.6 million next year, according to the Office for Budget Responsibility.
But he faced criticism from opposition MPs for not mentioning what would happen to benefit rates in his speech.
Labour MP Stephen Timms, chairman of the work and pensions committee, said: ""Millions of people on Universal Credit are now facing the Christmas period in agonising uncertainty, not knowing whether the government will cut their income by Â£20 a week next April.
""Meanwhile, those on older benefits, who have already missed out on the rise because the DWP's systems are too old-fashioned, will receive an increase of just 0.5% next year.
""The government must think again."""
"
The scientist behind the controversial ‘hockey stick’ graph has said it was ‘somewhat misplaced’ to make his work an ‘icon of the climate change debate’. 

From the Telegraph, By Louise Gray,  Environment Correspondent
Professor Michael Mann plotted a graph in the late 1990s that showed  global    temperatures for the last 1,000 years. It showed a sharp rise in  temperature    over the last 100 years as man made carbon emissions also increased,    creating the shape of a hockey stick.

The graph was used by Al Gore in his film ‘An Inconvenient Truth’ and  was    cited by the United Nations body the Intergovernmental Panel on  Climate    Change (IPCC) as evidence of the link between fossil fuel use and  global    warming.

But the graph was questioned by sceptics who pointed out that is it  impossible    to know for certain the global temperature going back beyond modern  times    because there were no accurate readings.
The issue became a central argument in the climate change debate and was     dragged into the ‘climategate’ scandal, as the sceptics accused Prof  Mann    and his supporters of exaggerating the extent of global warming.
However, speaking to the BBC recently, Prof Mann,  a climatologist at    Pennsylvania State University, said he had always made clear there  were “uncertainties”    in his work.
“I always thought it was somewhat misplaced to make it a central icon of     the climate change debate,” he said.
…


Professor John Christy, an atmospheric scientist from the University of    Huntsville in Alabama, said just a quarter of the current warming is  caused    by man made emissions. He said that 10 to 30 per cent of scientists  agree    with him and are fairly sceptical about the extent of man made global    warming.
==========
full story here




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8af0b419',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterDutch scientist and chemical engineer Dr. Arthur Rörsch has distributed a working paper to Dutch officials in his country to request a comprehensive review of the results and recommendations of the IPCC, especially its upcoming 5th assessment report.H/t: http://www.kaltesonne.de/?p=926:
In his paper Rörsch, former vice-president of the Netherlands Organisation for Applied Research, writes that the IPCC has “deviated from the traditional scientific principles”.  On man-made warming from CO2, he writes “that no indisputable scientific proof, or even strong empirical evidence, has been provided for such an effect, which therefore remains a matter of speculation.”
Read his entire working paper here.
He adds:
These reviews would best be undertaken by senior and established scientists whose reputation rests in the traditional enabling disciplines that underpin climate science, specifically physics, chemistry, geology and meteorology.”
The draft volume for WG1 AR5 is a summary and compilation of papers published in scientific journals up to 2011. Rörsch makes two observations:
– The prevailing hypothesis of the assessment report is that Dangerous Anthropogenic Global Warming (DAGW) is occurring; this hypothesis has been under challenge for many years by numerous independent scientists. These scientists were not invited to participate in the preparation of the AR5 report.
– The scientific literature cited in the draft AR5 is selective towards papers that support the DAGW hypothesis, and even the papers that are included are then selectively analysed towards the same ends. These two underlying biases set the tone of the message that the authors of the AR5 report want to transmit.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Rörsch particularly criticizes the following points:
1. The IPCC assumes that atmospheric CO2 is a dominant forcing agent for global temperature without providing evidence.
2. The report authors are instructed to express their conclusions in terms of a qualitative (i.e. opinion-based) probability scale.
3. The IPCC’s use of “self-appointed experts”.
4. There’s arrogance and intolerance for alternative views displayed by the self-appointed climate experts. These experts should be treated with extreme suspicion.
5. The style of the draft AR5 report marks it as a political rather than a scientific document, for it has been fashioned within the framework of a particular cultural paradigm.
Here’s what Dr. Rörsch concludes:
The IPCC’s draft AR5 report shows insufficient objectivity, and lacks the ‘traditional’ scientific balance necessary for it to be used as the basis for policy making. Regrettably, the report exemplifies some of the worst features of the ‘post-modern’ approach to science…”
 
Share this...FacebookTwitter "
"**Across the UK, three households will be allowed to create a temporary bubble this Christmas.**
All four nations say coronavirus rules will be relaxed for five days between 23-27 December to let families celebrate together.
Each ""Christmas bubble"" can meet at home, at a place of worship or an outdoor public place, but any existing, more restrictive rules on meeting in pubs and other hospitality venues will be maintained throughout the festive period.
There will be no limit to the number of people in a household joining a bubble in England, Wales and Northern Ireland, although the England guidance says it should be ""as small as possible"".
The Scottish government has said that Christmas bubbles can have a maximum of eight people, and should only contain one ""extended household"". Children under 12 will not count in the total.
A bubble is defined as a group of people with whom you have close physical contact.
The aim is to help people who've been cut off from friends and family.
Bubbles must be ""exclusive"". Once in one, you can't start another with a different household.
People in each bubble can stay overnight in each other's homes, visit outdoors places together and do not have to socially distance.
Support bubble counts as one household - which means for the Christmas period that bubble can join with two other households.
In England, single adults living alone - or single parents whose children are under 18 - can form a support bubble with one other household.
The second household can be of any size and can include ""at risk"" people who were previously shielding.
Wherever possible, the government recommends that a support bubble should be with another local household to avoid unnecessary travel. Anyone in the bubble contacted as part of England's test and trace programme must stay at home. If they develop coronavirus symptoms, everyone in the bubble must self-isolate.
Support bubbles have been allowed to continue during lockdown.
From 2 December, when England leaves lockdown and enters a tier system, people will be allowed to form support bubbles with those who live in an area with a higher tier rating.
Bubbles can be cross-border with Scotland and Wales, subject to local restrictions.
The government says it will be expanding the eligibility of support bubbles from 2 December to help families with very young children or people with continuous care needs, meaning households can form a support bubble with another household, if at least one of them has:
As well as the support bubble rules, the government in England also has a set of rules that apply to families with children under 14 (as well as to vulnerable adults).
They can form a childcare bubble with one other household to provide informal (unpaid and unregistered) childcare. This must always be between the same two households. They can provide the childcare in either or both of the homes from the two households.
Over Christmas, registered childcare and childcare bubbles are permitted.
Full government guidelines for England are here.
As of 9 November, two households of any size can form an exclusive bubble and meet in their own homes and gardens.
People in the same bubble can stay in each other's homes overnight. And they can meet up in groups of larger than four in some other outdoor places.
If you have been part of a temporary extended household during the firebreak period, or were in one before that, you are not required to stay in the same extended household. You can make a new bubble, instead. However, once you have agreed and joined that new extended household, neither household can leave to form a new one.
Under the five tier system in Scotland, people who live on their own or only with children under 18 can form an extended household with people from one other household.
This group of people can visit each other's homes and go inside. They do not have to stay 2m (6ft) apart and can stay overnight.
People in extended households are counted as one household, and so can continue to meet and socialise with each other despite general restrictions on households mixing.
Couples who do not live together can also form an extended household, which can include any children they each live with.
A household must not form an extended household with more than one other. However, one of them can end the arrangement at any time, and - as long as they wait at least 14 days - then form a new extended household with someone else.
If any member of an extended household develops symptoms or tests positive for Covid, everyone in the bubble must self-isolate.
Two households of any size can form a support bubble.
The members can spend time indoors and stay overnight with each other.
Under the latest restrictions, these bubbles are limited to a maximum of 10 people, including children, at any one time.
Read more from the Northern Ireland Executive here.
Schools are using year group and/or class bubbles to support social distancing and reduce close contact between pupils as much as possible.
Maintaining distinct groups which do not mix makes it quicker and easier when a positive case occurs to identify those who may need to self-isolate and minimise their number."
"
From NASA’s APOD:
 
 Dark Belt Reappearing on Jupiter 
 Credit:  NASA’s JPL, U. Oxford, UC Berkeley, Gemini Obs.  (North), USC Philippines
 Explanation:  Why are planet-circling clouds disappearing and reappearing on Jupiter?  Although the ultimate cause remains unknown, planetary meteorologists are beginning to better understand what is happening.  Earlier this year, unexpectedly, Jupiter’s dark Southern Equatorial Belt (SEB) disappeared.  
The changes were first noted by amateurs dedicated to watching Jupiter full time.  The South Equatorial Band has been seen to change colors before, although the change has  never been recorded in such detail.    Detailed professional observations revealed that high-flying light-colored ammonia-based clouds formed over the planet-circling dark belt.
Now those light clouds are dissipating, again unveiling the lower dark clouds.  Pictured above two weeks ago, far infrared images — depicted in false-color red — show a powerful storm system active above the returning dark belt.    Continued observations of Jupiter’s current cloud opera, and our understanding of it, is sure to continue.
h/t to Dr. Leif Svalgaard


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e87039b65',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Last century the Forestry Commission sparked anger with a mass planting of conifer trees designed to provide a national reserve of timber because the shortages of the first world war had highlighted a national need. Now a leading expert is calling for similar action again, arguing that if the UK is serious about offsetting its carbon dioxide emissions it must plant tens of millions of trees from imported species on open land.  John Healey, professor of forest sciences at Bangor University, says that relying on indigenous species such as oak and beech will make it impossible for the government to hit its climate goals. Britain will have no choice, he says, but to engage with the commercial sector in large-scale planting of imported conifers, despite fears of the impact on habitats and wildlife. Such a move risks incurring public anger, if its 20th-century precursor is anything to go by. “People felt it was bad for landscape, biodiversity and amenity,” said Healey. “Both the public and conservation professionals saw many negative effects on heathland; there was the notorious draining of the peat bogs of the Flow Country in the far north of Scotland; some really important habitats were left decimated by tree planting.” In 2017 the UK was the second largest net importer of forest products, behind China. Yet only 1,420 hectares of woodland were planted in England in the year to March 2019, against the government’s target of 5,000 hectares. Wales and Northern Ireland planted 520 hectares and 240 hectares respectively. The Committee on Climate Change has called for the planting of more trees and woodlands if the UK is to reach net-zero carbon emissions by 2050. It recommends increasing UK woodland cover from its current low level of 13% of total land cover to at least 17%, and possibly to 19% by 2050. In contrast, 38% of the average EU member state is wooded, a roughly similar percentage to the US. The Conservatives have pledged to plant 30 million trees a year between 2020 and 2025. But Healey said such targets faced stiff challenges. Indigenous species grow too slowly to be an efficient option for rapid carbon fixation, he said. Unharvested woodland eventually stops sequestering carbon when it reaches maturity. But conifer forests are harvested for timber, allowing new trees to be planted. He said: “The trees that produce this commercial timber and can grow in this country are virtually all non-native and are predominantly conifers from North America.” The need to plant more trees is now an urgent priority to tackle the climate emergency. Mature tropical forests in Africa and the Amazon are slowing their rate of carbon dioxide absorption from the atmosphere and may soon become a source of emissions, as trees die. Healey said it was time to be pragmatic. “Many people think we can have this huge expansion of tree planting in the UK and it will all happen without costing us as the taxpayer that much money. We also think it will all be nice, native species woodland of broadleaved trees and lots of biodiversity but it’s just economically impossible.” “People and politicians have got to face up to the fact that the vast majority of this tree planting, if it’s to occur at the scale they have talked about, is going to have to come from commercial investments, and forest and environmental policy has got to avoid getting in the way of that unnecessarily,” Healey said. “Planting is catastrophically slow in England and Wales, and many commercial investors feel that they are held back from acquiring land and converting it to woodland because of the way that the whole raft of environmental and other policy regulations are implemented.” Many endangered species – such as curlews and lapwings – depend on open habitats like moors and heaths. “Everyone agrees that the best of these habitats should be protected,” Healey said. “But a lot of them are in really poor condition. Is restoration the best use of all this land, or should some, instead, be converted to conifer plantations or native woodlands? We need to ask how much of our heathland we need to protect or restore and how much we can convert to rapid carbon sequestration.”"
"

On August 2, the Department of Transportation and Environmental Protection Agency made a joint proposal to reform the corporate average fuel economy (CAFE) standards. Originally adopted in 1978, when new cars were required to average all of 18 miles per gallon, the standards were increased by the Obama administration to a target of 54.5 mpg by 2025. (This 54.5 is actually an idealized number; as a practical matter, the real target for 2025 is about 47 mpg.)   
  
  
The new rule proposes to maintain the existing fuel economy standard, which rises to 37 mpg by 2020, and then freeze it at that level after that. By 2025, new automobiles meeting the Obama standard would be about 25 percent more fuel‐​efficient than under the Trump standard — though if fuel prices rise, consumers could end up buying more fuel‐​efficient cars than the standard anyway.   
  
  
Another change, as pointed out in a _Wall Street Journal_ article earlier this week by DOT secretary Elaine Chao and acting EPA administrator Andrew Wheeler, is that the administration wants “to create one national standard.” This means that California won’t be able to impose its own, stronger standards.   
  
  
As the Competitive Enterprise Institute’s Marlo Lewis observes, when Congress created the CAFE program in 1975, it specially forbade states from adopting their own stronger rules because this would greatly increase the costs of compliance to manufacturers. Despite that, the Obama administration decided to exempt California from the one‐​national‐​standard rule. The Trump administration is going back to the actual law.   
  
  
Obama’s adoption of the stricter standards was supported by many carmakers, including Ford, GM, and Chrysler (the latter two of which were under the government’s thumb due to corporate bailouts). However, Volkswagen strongly objected, saying that the standards were unfair to cars while overly generous to light trucks (pick ups, SUVs, and full‐​sized vans). This may be one reason why Ford has announced it is getting almost completely out of the car business, planning to make only light trucks plus the Mustang and a new China‐​made small car called the Focus Active.   
  
  
The Obama standards assumed that two thirds of vehicles sold would be cars, and only a third light trucks. In fact, it has been about half and half. For that reason alone, the EPA in 2016 (when Obama was still president) concluded that standards would have to be changed no matter who was in the White House. Changing them now gives Democrats one more tool to use to bash Trump, but another president would have had to make some changes anyway.   
  
  
Chao and Wheeler argue that rolling back the standards will reduce the cost of new cars by several thousand dollars and reduce total costs to consumers by $500 billion over the next 50 years. However, Americans currently spend about $1.1 trillion a year buying, operating, and insuring cars, so $500 billion over 50 years is less than a 1 percent savings on their driving bills.   
  
  
However, that 1 percent isn’t equitably distributed. To meet the Obama standard, automakers would have to build electric vehicles, sell them at a loss, and then sell their other vehicles for higher prices to make up the difference. Since electric vehicles are mostly purchased by high‐​end buyers, this imposes a regressive tax on lower‐​end auto buyers.   
  
  
Another important issue is that the CAFE program has suffered mission creep. When Congress created the program in 1975, the nation was suffering from politically induced energy shortages. But the standards weren’t needed to save energy; people responded to higher gas prices by buying more fuel‐​efficient cars without the government standards.   
  
  
Today, we have an abundance of energy: after adjusting for inflation, gas prices today are much lower than they were in 1975 and much less volatile. So there’s no need to keep the standards to save energy.   
  
  
Instead, environmentalists defend strict CAFE standards in order to reduce greenhouse gases. But there’s little reason to believe that the standards will have much of an effect on climate change, especially with the emphasis on electric vehicles. This is because most electricity in this country is still generated by burning fossil fuels. Due to losses in generation and transmission, it takes the combustion of three British thermal units (BTUs) of coal, gas, or other fuel to deliver one BTU of electricity to someone’s auto battery. Thus, the savings in greenhouse gas emissions will be far smaller than suggested by the differences in miles per gallon of the Obama and Trump standards.   
  
  
Even if you believe that we can increase the amount of electricity generated using means that don’t produce greenhouse gas, CAFE standards aren’t the best way to reduce carbon dioxide emissions. The McKinsey Report on greenhouse gases concluded that there are many ways of reducing emissions that are far more cost effective than trying to force cars to become more fuel efficient, most of them having to do with making existing and new buildings more energy efficient.   
  
  
Only Congress can repeal the law requiring the standards. In the meantime, rolling back the standards is worthwhile because it lets consumers choose how they are going to save money, save energy, and save the environment.
"
"We are inclined to think that trees are a renewable natural resource. Yet precious hardwood trees have already been almost completely logged out from many countries across the tropics. Myanmar is the latest country to experience the insatiable demand for its precious rosewood. Rosewood, also known as bois de rose, is an umbrella term for a whole group of tropical timber species, mostly from the genus Dalbergia, Pterocarpus, Diospyros, and Milletia, which all have a dark red hue and high quality timber in common. The vast majority of rosewood is imported to China where it’s fashioned into luxurious, highly-priced ornamental furniture in the Ming and Quing dynasty style. Myanmar, one of the most important biodiversity hotspots in Asia, has also several species of rosewood highly prized by the Chinese furniture trade. Even though Myanmar’s forest and hardwood stocks have been diminishing for several decades already (less than 10% of the land is now forested, the rosewood logging and smuggling has increased to an unprecedented level in the last three years.  In 2013 alone, Myanmar exported 237,000m3 of rosewood to China, triple the volume of the previous year. This amounts to one thirteenth of the estimated remaining rosewood stock of Myanmar – at current logging rates, Myanmar’s forests will have been stripped of rosewood in just 13 years. As Chinese hunger for the luxuriant, dark red timber grows and spreads across the greater Mekong region, rosewood species might face not only commercial extinction, but also final, biological extinction. It is hardly just the loss of a few species that is at stake. Forest overexploited for timber is likely to lose many species of animals, its ability to absorb carbon dioxide from the atmosphere deteriorates, and it is more likely to experience fires. Logging also brings about more hunting and increases the chances of complete deforestation. In Myanmar illegal logging also brings with it a raft of socioeconomic problems. Loggers undertake long and dangerous scouting expeditions into the forest, or take the risk of timber smuggling in conflict-ridden border regions, such as Kachin at the border with Yunnan province, China – one of the main rosewood smuggling routes. Not every logger returns from these expeditions. Besides the fact that logging in the tropics is rated as one of the most dangerous jobs, there is in Myanmar an added danger of being shot in a timber-related conflict. Moreover, loggers are often rewarded by various stimulating drugs. So why isn’t Myanmar establishing commercial rosewood plantations? Some tropical timber can indeed be mass-produced in plantations, especially faster growing species such as rubberwood, eucalyptus, or teak. But the extremely slow growing, high density rosewood trees take many decades to grow to a commercially viable size, requiring several generations of tree planters to wait for the profit. Such long-term investment is commendable, but unlikely in a conflict-ridden, poor country like Myanmar, with unstable land tenure and an explosive political climate. It is in Myanmar’s interest to completely stop the illegal logging and export of rosewood to China. As almost all processing of Burmese rosewood is done in China, no value is added in Myanmar. Worse still, almost no tax is generated: Myanmar lost an estimated US$6 billion through illegal logging between 2013 and 2014. Instead of the desperately needed cash for healthcare, education, and environmental protection, laundered rosewood money goes to corrupt officials and government cronies. If Myanmar wants to escape its rosewood crisis with at least some viable rosewood populations left, it should take lessons from other countries that have already undergone the “rosewood massacre”. On April 1 this year, the Myanmar government put in place a ban on raw timber export, but without enforcement this cannot be effective. Myanmar has to show its dedication to a permanent, non-negotiable, exception-free rosewood export ban. In Madagascar, we have an example of how temporary and unclear bans only lead to a more dynamic and thriving rosewood black market. During periods of temporary bans, illegal rosewood logging continues, and traders simply accumulate rosewood stockpiles. Meanwhile, rosewood prices go up, stimulating even bigger bouts of logging when the ban is lifted. However, even an effective national ban on rosewood export might not be enough to stop the rosewood crisis in Myanmar. In some cases, a national export ban caused China’s rosewood appetite to shift to a new country.  In other cases, for example Vietnam, China simply grabbed the opportunity of cheaper labour and moved its basic rosewood processing to Vietnam, effectively circumventing the raw timber export ban. This may bring some economic benefit to Vietnam, but does nothing to alleviate the pressure on the forests. Of the 33 species that pass China’s strict hongmu quality standards for rosewood, more than a third is already deemed vulnerable by the IUCN Red List of Threatened species and six are listed by the Convention on International Trade in Endangered Species (CITES). The convention binds signatory countries to regulate or stop trade in the listed species, depending on the degree of protection. Whereas China offers high levels of support to protect its growing rosewood industry, for customers and businesses, it appears to have a complete lack of interest in regulating the industry’s environmental impact or improving its sustainability. Europe, the US and Australia all tightened their regulations regarding rosewood import in recent years. But with Chinese domestic demand growing significantly since 2011, only stricter regulations in China can save Myanmar’s rosewood forests."
"

This week’s big global warming kerfluffle comes from the EPA’s Inspector General, who says the agency broke the law in preparation of its landmark 2009 “Endangerment Finding” from carbon dioxide and other greenhouse gases. Subsequent to making this finding, according to an infamous 2007 Supreme Court decision, the Agency must regulate emissions, presumably to the point which they no longer cause endangerment.



The IG believes that the EPA ran afoul of a rider to the 2001 appropriations bill that has been variously called the “Data Quality Act” or the “Information Quality Act”. Put simply, the accepted legal interpretation of this two‐​line piece of legislation is that a federal document that is a “highly influential science assessment” must undergo rigorous peer‐​review.



EPA based its endangerment finding on its own “Technical Support Document” (TSD), a weighty tome that drew heavily from the United Nations’ latest (2007) climate compendium, and also from a summary document from federal climatologists called “Global Climate Change Impacts on the United States”.



Like most groupthink projects, these two documents have numerous problems indicative of shoddy peer review. The UN report contained a purely fictional claim that the massive Himalayan ice field will disappear less than 25 years from now. It ultimately owned up to this whopper, with the author of the statement admitting that the alarmist nonsense was put in to try and shock India and China into reducing their carbon dioxide emissions. The other report is so full of holes that an entire counter‐​document, with the exact same format and subject matter, but with all the science that somehow got missed, is currently in the works and due out in a year or so.



Critics of the EPA’s Endangerment Finding launched several attempts to shut it down. I wrote one critique that—right at the beginning of 220 single‐​spaced pages—said that the TSD violated the Data Quality Act. It’s nice to see that the EPA’s IG agrees.



The IG states that the TSD was “highly influential” and therefore had a high bar for peer review that was not met. Further, one of 12 federal climatologists that reviewed it was in fact employed by the EPA. That’s no different than having one of your own colleagues at your university peer review your manuscript for an academic journal, something that simply isn’t done.



The EPA laughably contends that its TSD isn’t “highly influential science”, because it used information from other federal and international compendia, like the problematic United Nations report, which were properly peer reviewed. This is risible; the UN solicits peer review and then its own authors decide which (easy) comments to respond to and which (pesky) ones to ignore.



If something, like the TSD, which will be used as the excuse to tell everyone what kind of light bulb they can burn isn’t “highly influential”, then what is?



But weren’t there other reviewers? What of the reams of comments that wonks like me sent in? Isn’t that evidence for a very vigorous review process? Unfortunately, no. The EPA was under no obligation to address any comment from anyone who wasn’t a member of their Gang of 12.



The policy implications of the IG’s report are probably not as staggering as advocates opposed to the Endangerment Finding make it out to be. While many outside commenters complained that the science in the TSD (and the federal compendium that was used in its construction) was so bad that the peer‐​review process had to have been systematically compromised, the IG merely disagrees with the process and takes no position on the science.



Surely some petition will be presented in some court to require the EPA to re‐​submit the TSD to a broader review as a requirement before it can enforce carbon dioxide regulations. Unfortunately, all this requirement will likely do is delay them for a year or so. There are legions of federal climatologists to choose from, all dependent upon the global warming dole for career advancement. Getting the right review has never been a problem for alarmist climate science.



Perhaps the prospective petitioners could stipulate that the future reviewers not have any funds in the global warming game, but that would create a logical dilemma. The reigning myth is that federal money is the seal of professional accomplishment, so those not on this dole must be incompetent.



The IG’s finding brings to light, yet again, the problems that occur when science is funded like Canadian health care, by a single provider. Until we somehow diversify the funding base for climate science, flapdoodles like the EPA’s peer‐​review problem will continue to repeat, and the erosion of the public’s faith in climate science will continue unabated.
"
"Curious Kids is a series by The Conversation, which gives children of all ages the chance to have their questions about the world answered by experts. All questions are welcome: you or an adult can send them – along with your name, age and town or city where you live – to curiouskids@theconversation.com. We won’t be able to answer every question, but we’ll do our best. What makes the wind? - Eric, 94-year-old kid, Ipswich, UK. The wind has always been very important to us humans: from thousands of years ago, when sailors used the wind to cross the sea in ships, right up to today, as we make electricity from wind turbines. But it’s taken a long time for scientists to understand exactly how the wind is made. Although we can’t see it, the air is made up of billions and billions of tiny particles. There are lots of different types of particles in the air, but the most common ones are nitrogen and oxygen (which is what humans and other animals need to breathe). The wind blows when these air particles move around in the Earth’s atmosphere. The atmosphere is an envelope of gases, which surrounds the Earth. It’s around 100 kilometres thick, which is about the length of 4,000 blue whales.  Most of the particles that make up the Earth’s atmosphere are found closer to the surface. As you get further out into space, there are fewer and fewer particles, until finally, in outer space, there are none.  The weight of all of these particles stacked on top of each other pushes down on the Earth’s surface – and this force is called atmospheric pressure. Atmospheric pressure changes, depending on how warm or cold the Earth’s surface is. When the surface heats up, the air closest to it also gets warmer. And when the air gets warmer, the particles will tend to rise upwards and spread out.  When this happens, it leaves fewer air particles at the Earth’s surface, which lowers the atmospheric pressure.  So, you would expect the air over a very warm and sunny place, like a desert, to have lower atmospheric pressure than the air over a cold and dark place, like the North Pole.  When the warmer air rises, cold air particles – which are generally packed in closer together – will sink into those low pressure areas. This movement of air particles, driven by areas of heating and cooling, is what makes the wind.  How fast the wind blows depends on how much of a difference there is in pressure between a low pressure and a high pressure area of air. If there’s a bigger difference in the pressure, the wind will blow faster. There are 12 different levels of wind speed, measured on a scale called the Beaufort scale. The scale ranges from winds of less than one kilometre per hour (calm) to more than 118 kilometres per hour (hurricane).  Lighter winds are called “breezes”, stronger ones are called “gales”, and the very strongest winds are “hurricanes”.  You might also have heard the weather forecast talking about “easterly” or “northerly” winds. We describe which way the wind is blowing, by the direction it comes from. So an “easterly” blows from east to west, while a “northerly” blows from north to south.  More Curious Kids articles, written by academic experts: How do babies learn to talk? – Ella, aged nine, Melbourne, Australia. Our guinea pigs have dark eyes. Why do we have white eyes? - Rhoswen, aged three, Bristol, UK. What’s the point of nits?! – Connie, aged nine, Nambour, Australia."
"
Share this...FacebookTwitterWe’ve heard how the warmists have equated critical e-mails they’ve received to “threats to their personal safety”.
Well, German climate-catastrophe dissenter Prof. Fritz Vahrenholt, on the other hand, now reveals the real danger of open dissent on climate change science in Germany. He had to be protected by “personal security” from enviro-nutjobs and climate greenshirts.
German business magazine Schleswig-Holstein Manager recently conducted an interview with Vahrenholt concerning the climate-skeptical book he authored together with geologist Dr. Sebastian Lüning: Die kalte Sonne (see recommended book, right side bar). The book was published by renown publishing company Hoffmann & Campe in Hamburg and was released amid a storm of protest last February. Schleswig Holstein Manager magazine writes:
…critique by weekly newspaper “Die Zeit” was so harsh that its publisher, former German Chancellor Helmut Schmidt, personally invited the RWE manager (Vahrenholt] for a meeting. The debates in the meantime escalated to the point where Prof. Dr. Fritz Vahrenholt even needed personal security.”
I’d interpret that as bodyguards. Oh my, such a tolerant bunch these warmists are.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The article in the Schleswig-Holstein Manager magazine introduces Vahrenholt’s and Lüning’s book:
A controversial book. An author who has become the target of hostility. An interview about the book: ‘The development has gone completely out of control.'”
Schleswig-Holstein Manager also quotes chief editor Thomas Vašek of PM Magazine:
Also the business of science is vulnerable to herd mentality. Once a majority opinion crystalizes, it becomes increasingly difficult to express doubt. This is especially true for politically charged climate science.”
At least now we know on which side all the real threats and violence can be found.
 
Share this...FacebookTwitter "
"**Plans for a zip wire at the Principality stadium have been approved by Cardiff Council.**
The plans include a suspension wire bridge, a viewing platform and a zip line from the top of one of the 90m (300ft) high roof spires.
There were two objections on privacy grounds to the application, which has been through a consultation period.
Artist impressions show people walking along the roof and riding down the zip wire.
According to the application zip line riders will be attached to pulleys that will allow them to ride north to south across the stadium roof.
The stairway up to the roof will be built within the stadium.
Wheelchair users will also be able to reach the roof using a special hoist.
The Â£121m stadium opened in 1999. This year it was transformed into Dragon's Heart Hospital to deal with the impact of coronavirus, which saw its use as a sports and music venue halted in the spring."
"**South Africa, which had one of the world's earliest and strictest lockdowns, is marking a significant shift in its fight against coronavirus, writes BBC Africa correspondent Andrew Harding.**
It was hardly a ""mission accomplished"" moment.
South Africa's President Cyril Ramaphosa looked appropriately dour, and sounded appropriately cautious, as he appeared on national television this week to warn of the dangers of a second wave of infections and to urge the public against relaxing their guard against the virus.
And yet the president's key message was a simple, optimistic and impressive truth.
""We have succeeded in overcoming the worst phase of this epidemic,"" he declared.
As the infection rate here sinks below an important threshold of one new case per day per 100,000 people, South Africa is moving - with relief, and with some pride - into a new phase.
What the president and his scientific advisers describe as ""a new normal"".
With almost all economic activity resuming, the nation's borders slowly opening, and one of the world's earliest and strictest lockdowns ending, this feels like a significant moment - an opportunity to take stock, even to celebrate, and to explore the ever-thorny issue of who, or what, should share most credit for containing Covid-19.
""I had visions of Italyâ¦ that we're not ready, that we're going to get overwhelmed,"" recalled Professor Salim Abdool Karim - chair of the government's Covid-19 advisory panel and the public face of the scientific community - thinking back to March, and to what he and the government publicly warned was an oncoming viral ""storm"".
Instead, very few hospitals were overwhelmed, and the official death toll of some 15,000 is significantly lower than even the most optimistic modelling predicted.
Speaking on an internet link from his office in Durban, Prof Karim does not disguise the relief he feels.
But, like many scientists, his inclination is not to sit back and enjoy the good news, but rather to keep probing and testing hypotheses in order to better understand both Covid-19, and South Africa's response to it.
There is plenty of data to wade through now.
Much of it contradictory. Or rather, much of it still needing to be put in proper context.
Take South Africa's long battle against HIV and tuberculosis.
New evidence suggests TB patients are particularly vulnerable to Covid-19.
But, on the flip side, the systems put in place to cope with both pre-existing diseases, ""assisted us and better prepared us to cope with Covid,"" said Prof Karim.
And while South Africa may have good reason to celebrate its successes, there is plenty to criticise too.
""We've had a pretty bad epidemic,"" said Prof Karim.
""At one stage we were the fifth worst in the world. I wouldn't call that something to be proud of.
""I'd have been really proud if we'd been able to mitigate the impact to a much greater extent.""
As we've reported here in recent months, there have been instances of appalling mismanagement, alarming allegations of corruption, and some grave errors in handling the outbreak.
I will leave the economic impact of the lockdown - and the legitimate debate, enriched by hindsight, about whether the government got the balance right - to another day.
But what of the reasons for South Africa's relative success in fighting the virus?
Prof Karim has drawn up a list of nine factors, or hypotheses, which he applies not just to South Africa, but to other countries - not least on this continent - which appear to have been spared the worst.
Nine theories. But true to form, Prof Karim is not fully convinced by any of them, at least not without further proof.
""I doubt that any one of these is a major contributor that explains the entire difference [of why some countries have done better than others],"" he said.
""Even in combination, these would not explain the bulk of the difference we are seeing. It remains intriguing to me."""
"
Portland police say the masseuse failed a polygraph and the DNA didn’t match (because there was none).

Gore’s aides made a statement:
“Mr. Gore unequivocally and emphatically denied this accusation when he  first learned of its existence three years ago,” spokeswoman Kalee  Kreider said in a statement. “He respects and appreciates the thorough  and professional work of the Portland authorities and is pleased that  this matter has now been resolved.”
From KOIN TV in Portland the story
And another from the Associated Press


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89dbd19d',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
WUWT Flashback:
Royal Society to review climate consensus position
Posted on May 27, 2010
“I  don’t think they were very pleased. I don’t think this sort of thing  has  been done before in the history of the society.”


Society to review climate message
Today: (Via email press release from the GWPF) Royal Society Bows To Climate Change Sceptics


Wednesday, 29 September 2010 22:09		 		 			 			Ben Webster, The Times




Britain’s leading scientific institution has been forced to  rewrite its guide to climate change and admit that there is greater  uncertainty about future temperature increases than it had previously  suggested.
The Royal Society is publishing a new document today after a  rebellion by more than 40 of its fellows who questioned mankind’s  contribution to rising temperatures.

…
The new guide says: “The size of future temperature increases and  other aspects of climate change, especially at the regional scale, are  still subject to uncertainty.”
The Royal Society even appears to criticise scientists who have made  predictions about heatwaves and rising sea levels. It now says: “There  is little confidence in specific projections of future regional climate  change, except at continental scales.”
It adds: “It is not possible to determine exactly how much the Earth  will warm or exactly how the climate will change in the future.
“There remains the possibility that hitherto unknown aspects of the  climate and climate change could emerge and lead to significant  modifications in our understanding.”
The working group that produced the new guide took advice from two  Royal Society fellows who have links to the climate-sceptic think-tank  founded by Lord Lawson of Blaby.
Professor Anthony Kelly and Sir Alan Rudge are members of the  academic advisory council of the Global Warming Policy Foundation. They  were among 43 fellows who signed a petition sent to Lord Rees, the  society’s president, asking for its statement on climate change to be  rewritten to take more account of questions raised by sceptics.
…
Full article at The Times, 30 September 2010


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e88d66633',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"**Two pubs have been linked to a coronavirus outbreak which forced the closure of a number of schools and a college campus in a west Wales town.**
Ceredigion council said 55 new cases in the Cardigan area suggested there was ""significant community transmission"".
The council called on people who attended the Red Lion and Bell pubs on or after 9 November to be vigilant.
The closure of 13 schools in the area was blamed on ""super-spreader events"" such as ""parties"" and ""pub crawls"".
There have been 43 new coronavirus cases in the area in the past week, according to Public Health Wales.
In a statement, the council said its contact tracing team had identified in excess of 300 cases and contacts to date, adding the ""alarming rate of spread"" had affected a number of services in the area.
""We are asking all residents who attended The Red Lion and The Bell Inn public houses on or after 9 November to be extra vigilant and to self-isolate and book a test immediately if you have any symptoms.
""Businesses who have been found not complying with coronavirus regulations have been served with closure or improvement notices and further inspections will continue over the coming days.""
Earlier in the pandemic, Ceredigion council was widely praised for its response, which helped put its death rate second-lowest only to the Isles of Scilly across England and Wales.
But in recent months, the case rate has been creeping up with outbreaks linked to Aberystwyth University and a care home in the town.
Additional testing had been made available at the Fairfield Car Park, Cardigan, which could be booked through the government website or by calling 119.
Both the Red Lion and Bell pubs have been asked to comment."
"
click for more
(This IBD Editorial was sent to me by the authors)
By WILLIE SOON, ROBERT  CARTER AND DAVID LEGATES
This is a response  to “Why Can’t We Innovate Our Way To A Carbon-Free Energy Future?“, a  “Perspective” by Bjorn Lomborg that ran in this space a week ago.
Bjorn  Lomborg, author of “The Skeptical Environmentalist” and “Cool It,” is right  about the need to focus on critical health and economic priorities. But he is  wrong about human carbon dioxide emissions causing what is now being called  “global climate disruption.”
By demonizing the gas of life, in league  with Al Gore and Bill Gates, Lomborg commits several serious scientific errors.  As independent scientists, with broad training in mathematics, physics,  chemistry, geology and geography, we know CO2 is not a pollutant, and the notion  of “carbon-free” or “zero-carbon” energy is inherently harmful and  anti-scientific.

If nitrogen, oxygen, hydrogen, helium or any other  nontoxic gas is pumped into a chamber containing air and a growing plant, the  response is barely measurable. By contrast, if more CO2 is added, the plant and  its root system benefit enormously, displaying enhanced growth and more  efficient use of available water and nutrients.
Far from having  detrimental effects, carbon dioxide has decidedly beneficial impacts on plants,  aquatic and terrestrial alike, and a new study connects enhanced plant  productivity to greater bird species diversity in China. How, therefore, can  anyone conclude that human carbon dioxide is a pollutant that must be  eradicated?
These facts erect a formidable barrier for “zero-carbon”  advocates. By insisting that no human CO2 should be emitted, they are promoting  continued suboptimal growth of food plant species in the face of impending  global food shortages — and poorer functioning and less diversity in the global  ecosystem.
Zero-carbon activists respond to these facts by asserting that  human CO2 emissions cause “dangerous global warming.” They are wrong about this,  too.
If rising atmospheric CO2 levels drive global temperatures upward,  as they insist, why is Earth not suffering from the dangerous “fever” that Al  Gore predicted? Instead, after mild warming at the end of the twentieth century,  global temperatures have leveled off for the past decade, amid steadily rising  carbon dioxide levels.
Lomborg’s claim that we need to “cure” so-called  “unchecked climate change” is thus fallacious and contradicted by reality.  Reducing human CO2 emissions will likely have no measurable cooling effect on  planetary temperatures.
His insistence that we prioritize expenditures is  spot-on when applied to genuine environmental and societal problems. However, it  is irrelevant when the problems are mythical — or devised to advance ideological  agendas. Moreover, even if human impacts on the global climate can actually be  measured at some future date, humans currently lack the scientific and  engineering understanding and capability to deliberately “manage” Earth’s  constantly changing climate for the better.
Most certain of all,  atmospheric carbon dioxide is not the “climate control knob” that  anti-hydrocarbon alarmists assert, and it is irresponsible for Lomborg to claim  his socio-political agenda will provide a low-cost solution for the global  warming “problem.”
The scientific reality is that even the United Nations  Intergovernmental Panel on Climate Change has been unable to demonstrate a  cause-and-effect scientific connection between rising human CO2 emissions and  dangerous warming.. To support global limits on CO2 emissions, in the absence of  real-world data showing clear cause and effect, is scientific and policy  incompetence on the highest order.
Imagine a drug company seeking FDA  approval for a new drug, based on an analysis that says simply: “Our  supercomputers say the drug is safe and effective. We have no clinical data to  support this, but can think of no reason actual results would contradict what  our computers predict. Moreover, failure to license the drug will be disastrous  for patients suffering from the targeted disease.” Failing to demand actual  dose-and-response studies, before licensing the drug, would be gross negligence  on FDA’s part.
Between 2007 and 2009, U.S. carbon dioxide emissions  dropped approximately 10%, to their lowest level since 1995, largely because of  reduced energy consumption during the recession. Similar CO2 emission reductions  occurred in Britain, Germany, France and Japan.
Have their climates  gotten better or less dangerous? Are they now a better place, for having a lower  intensity carbon energy diet? Have global temperatures been statistically  unchanged since 1995 because, or in spite of, Chinese and Indian carbon dioxide  emissions increasing far more than the aforementioned countries reduced  theirs?
These are practical, not rhetorical questions. As far as we can  see, the only direct effect of decreasing CO2 levels via expensive renewable  energy programs has been to cost more American and European jobs than would  otherwise have been the case during the global economic recession.
The  central issue is not whether rising CO2 levels will cause a warmer planet. The  fundamental concern is whether globally warmer temperatures are factually worse  (or better) for human societies — and more (or less) damaging to the environment  — than colder temperatures (like those experienced during the ice ages and  Little Ice Age).
Bjorn Lomborg, Al Gore and Bill Gates need to consider  the likelihood that, driven by changes in solar activity and ocean circulation,  Earth will cool significantly over coming decades. Damaging the global economy  with ineffectual carbon dioxide controls, in a futile quest to “stop global  warming,” looks stupid now.
Viewed later, with hindsight, it will be  judged outrageously irresponsible.
• Soon studies sun-climate connections  at the Harvard-Smithsonian Center for Astrophysics.
• Carter is an  emeritus fellow of the Institute of Public Affairs and chief science advisor to  the International Climate Science Coalition.
• Legates is a  hydroclimatologist at the University of Delaware and serves as the state  climatologist of Delaware.
This editorial appeared at Investors Business Daily – here


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e87ef1397',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"The French Ministry of Ecology and Sustainable Energy Development has launched a trial scheme where commuters are paid to cycle to work. For six months, 20 companies with about 10,000 employees between them will offer tax-free payments of €0.25 per kilometre for employees to commute to and from work by bicycle, while data is collected to see what effect the scheme has. While this scheme has gained some attention, some countries already offer bicycle commuter benefits of one sort or another. Similar to the French scheme, employers in Belgium and the Netherlands can offer tax-free payment of €0.22, and €0.19 per kilometre of bike commuting respectively. In Germany commuters biking to work can deduct €0.30 per kilometre from their taxable income.  Other efforts are aimed at providing incentives to buy bicycles. For example, in the UK more than 10,000 companies use the cycle to work scheme that allows employees to purchase bikes using pre-tax income, thereby saving income tax and other deductions on their pay. The German federal government allows employers to offer “company-paid private bicycles” as a benefit to their employees – very much like popular company car programs in various European countries. Other programs subsidise bicycle-related expenditures in general.  In the US, cyclists can deduct a flat rate of US$20 per month from their taxable income for bicycle repair and maintenance. US employers can also provide cash incentives for employees who give up free car parking at work and choose to commute by other means. However, cash paid to non-driving employees is taxable, while the value of free parking is largely in the tax concession. Workplace wellness programs have incorporated bike commuting  as part of a more general recognition of the health benefits of regular physical activity. Some employers in the US, for example, have begun using an electronic tracking system for bike commuters, offering “wellness points” that reduce employee’s health insurance premiums. Increasingly bike-aware employers in Europe and North America also provide facilities such as showers, secure bike parking, and clothes lockers for storage. Despite growing interest in making bike commuting more popular, bicycle-related benefits are typically dwarfed by the benefits offered for travelling by other modes of transport, especially the car. For example, in the US free car parking is the most common commuter benefit offered – only about 5% of US commuters pay for car parking. The value of those free parking spaces at work is typically well above the US$20 a month awarded to cycle commuters. In Germany, drivers can take advantage of the same €0.30 per kilometre commuting deduction as cyclists, plus companies offer company cars. Distances travelled by car are longer than those by bicycle, and the higher values of cars compared to bicycles mean the benefits that accrue to drivers are worth more. A forthcoming study of commuter choice of transport and benefits in the Washington DC region confirms this, finding that available benefits to promote walking, cycling and taking public transport to work were rendered ineffective where there was free parking on offer. Besides the larger value of incentives for commuting by car, another problem with the schemes to promote alternative modes of transport is that employees are often required to choose one type of benefit and can’t claim for a combination of driving, taking public transport or cycling. For example, the new French trial scheme only allows commuters to combine cycling and public transport benefits if the two are regularly used together, for example cycling to a railway station. In the US, employees have to choose only one. A study of mobility policies in Belgium found that driving to work dominated despite incentives for alternative modes, suggesting that allowing the benefits to be combined would help cut car commutes. Perhaps a greater attraction to people thinking of cycling is an investment in facilities at work. For example, a recent study of bike commuting in the Washington DC region found that showers and lockers as well as secure bike parking are significantly correlated with increased cycling to work. Several studies have also found that bike infrastructure, such as dedicated on-street facilities and off-street paths, effectively encourage bike commuting.  So it appears that merely paying people to cycle to work is unlikely to cause a significant shift in their commuting behaviour. For this to happen will require a package of policies, including financial incentives for cycling, disincentives for driving, and investments in infrastructure and facilities, as well as efforts to encourage cycling. The French trial is a step forward in encouraging bike commuting, but by itself it’s just not enough."
"
Easy come, easy go.  Nicole was upgraded from TD16 at 11 AM and dissipated as a tropical storm at 5 PM.  Nicole joins Tropical Storm Chris from 2000 as the only other 6-hour 35-knot maximum sustained wind tropical storm [since 1970 & reliable satellite monitoring].  Nicole joins Bonnie and Gaston from this season as top-ten weakest storms on record.  By the way, when you do the post-season storm verification, Nicole + Bonnie + Gaston = 3 storms with a total ACE of less than 1.  Danielle + Earl +  Igor = 3 storms with a total ACE > 90.
About Chris (August 18, 2000):
There were too few forecasts associated with Chris to conduct a meaningful quantitative forecast evaluation.  Despite the prevailing wind-shear environment , all intensity guidance as well as the official forecast incorrectly suggested strengthening.

From the NHC Discussion on Nicole:
SATELLITE…AIRCRAFT…AND SURFACE DATA SHOW THAT THE CIRCULATION OF NICOLE HAS BECOME ELONGATED THIS AFTERNOON.  THE CENTER…WHICH WAS NEVER VERY WELL DEFINED…HAS BECOME UN-TRACKABLE AND
THIS WILL BE THE LAST NHC ADVISORY ON THIS SYSTEM.  THE 12Z GFS AND ECMWF MODELS ONCE AGAIN FORECAST THE DEVELOPMENT OF AN EXTRATROPICAL LOW OFF THE SOUTHEAST COAST OF THE UNITED STATES TONIGHT.  THIS NEW LOW…NOT CONSIDERED TO BE THE REMNANT OF NICOLE…IS FORECAST TO MOVE NORTHWARD ALONG THE EAST COAST OF THE UNITED STATES AS A GALE CENTER DURING THE NEXT COUPLE OF DAYS.
Over at Climate Audit, we described this type of storm as a “baby-whirl“.  The ACE of Nicole is 0.1225.  Here are the top 10-weakest storms from 1970 to 2009 according to ACE in the North Atlantic:   [year, name, ACE, max wind (knots)]
2000 CHRIS       0.1225     35.0
1999 KATRINA  0.245       35.0
2002 BERTHA   0.245       35.0
2005 LEE           0.245        35.0
1995 DEAN        0.2825      40.0
2005 BRET        0.3675      35.0
1988 ISAAC       0.405       40.0
1978 DEBRA      0.41          50.0
2005 JOSE        0.4475      45.0
1978 AMELIA   0.485        45.0
2010  GASTON  0.3675       35.0
2010  BONNIE    0.3675      35.0
2010  NICOLE       0.1225               35.0


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e88e95a3e',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Guest Post by Willis Eschenbach
Once again, I return to that endless font of misinformation, the Waxman Markey website. In this case, I look at their claims about Alaska. This one will be short and sweet. Their claim is that Alaska is roasting, as in the picture below:

Figure 1. The dessert known as “flaming baked Alaska”. Ice cream covered with meringue, doused with brandy, and set on fire. Sweet.
The Waxman Markey website page on Alaska  says:
Over the past 50 years, Alaska has warmed by 4 to 7 degrees Fahrenheit, much more than anywhere in the lower 48 states.  This dramatic temperature change is causing the landscape of Alaska to change faster than anywhere else in the United States, threatening infrastructure, wildlife, and Native Alaskan culture.
I fear that these numbers must from the well-known Government Misinformation Agency.

Figure 2 shows the real numbers:

Figure 2. Alaskan temperatures, as the average of all first-order stations in the state.
There are a few things we can see here. First, Fig. 1 clearly shows the dependence of Alaska temperatures on the Pacific Decadal Oscillation (PDO). The PDO is a long-term shift in Pacific sea surface temperatures. The PDO has a warm phase and a cool phase, as shown in Figure 3. It shifts from one phase to the other every thirty years or so.

Figure 3. Cool (positive) and warm (negative) phases of the PDO. IMAGE SOURCE
The PDO shifted to the cool phase in the late 1940s. It went back to the warm phase in 1976-77. And recently, it has gone back to the cool phase. This is clearly visible in the Alaska temperatures. As much as Waxman Markey wants to blame the shift in Alaskan temperatures on “global warming”, the science says otherwise. The changes are due to the shifts in the PDO.
Second, their claim that Alaska has “warmed by 4 to 7 degrees Fahrenheit” is not true. The largest trend to 2009 in the Alaska temperatures is 1954-2009, which is 3.24 degrees.
I also note that they are using a very different period from the one they used in their claims about the US Northeast, where they used the trend from “the 1970’s”. Obviously, they are picking their time period to exaggerate their claims …
The main point here is that because the PDO gives Alaska warm periods and cool periods, it is meaningless to use any trend starting from a cool period and ending in a warm period, or vice versa. Yes, you can get a positive trend from anywhere on the left half of the graph to anywhere on the right side of the graph … but that doesn’t tell us anything about what’s happening.
Short and sweet.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a7aca86',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

As I noted in an earlier post, I’m supportive of Bob’s legal argument that the President’s NSA surveillance program is illegal and unconstitutional. (My level of certainty on this: moderate). But for me this doesn’t settle the matter. There’s a separate question: What should the Supreme Court do about it?   
  
For me, this is the hard but all important question. In _Baker v. Carr_ , the Court suggested (in so many words) that justices may want to avoid resolution of a constitutional question if, for example, there is a significant chance another branch might ignore its decision. The reason for this seemingly weak-kneed approach to constitutional adjudication is straightforward. The Supreme Court, a tribunal of nine geriatric lawyers, doesn’t have much muscle. It can’t arrest a recalcitrant President. It relies on the force of its mystique as the oracle of our fundamental law and its soft political power to confer public legitimacy on political branch actions. That’s generally enough to compel the grudging respect and deference of Congress and the President. But in extraordinary times, its possible that a headstrong President convinced of the rightness of his mission, and backed by popular support and a waffling Congress, might simply ignore the Supreme Court. If that happens too often, the Court risks losing its power to command. And a disrespected Court that is repeatedly ignored is far, far worse for the long-term protection of liberty than a Court that occasionally ducks the wrong fight.   
  
So what should the Court do about the NSA surveillance program?   




There are seven red flags counseling caution: 


"
"
Share this...FacebookTwitterYesterday the Maybrit Illner talkshow on ZDF television was about Germany’s attempt to shift to renewable energy in the wake of the shutdown of 7 nuclear power reactors after the Fukushima tsunami disaster.
The political talkshow, moderated by Maybrit Illner, asked if consumers are being asked to pay too much for the transition to a power supply based on renewable energies. Electricity rates have jumped 15% in Germany in just 2 years. Interesting were the comments from German Environment Minister, Norbert Röttgen. In the past he always based the need to switch to renewable energy on “climate change”. Not anymore it seems. Except maybe once in passing, Röttgen didn’t mention the word “climate” once. In fact no one uttered it. It appears that protecting climate has lost its appeal.
So what could be driving the change over to renewable energy if it isn’t the climate? Röttgen cited two reasons: 1) The need to get off nuclear power and 2) the fact that fossil fuels are resources on Earth that are limited. No mention of climate. Suddenly climate change is losing its urgency.
The other members of the talkshow included a Karl Marx look-alike (Michael Sladek) who demands that power generation be taken away from big corporations and be decentralized by putting it in the hands of private individuals. Isn’t that what mankind did thousands of years ago when everyone had his own campfire?
Another guest was an anti-nuclear power activist who claimed that nuclear power was too dangerous and thus had to be stopped. She said the same thing about 10 times, but used different words each time.
The director EON was also a guest and he was content to perch himself high up on the fence, not taking any sides at all. I found his performance spineless. The other guest was Dirk Maxeiner, a long-time critic of the green movement. Citing biogas and windmills, he claimed that the green movement did more harm than good to the environment. He’s right of course.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Is Schellnhuber discretely changing the timescale?
Reader asmilwho informs that Hans Joachim Schellnhuber was interviewd on German radio this morning. As I listened to the director of the alamist fantasy factory Potsdam Institute of Climate Impact Research, I couldn’t help but notice that he seems to have modified his tune when it comes to a timetable for his envisioned “Great Transformation of Society” and climate urgency overall (emphasis added):
For the most part the course has to be set over the next 20 years for an almost carbon-free world economy.”
Now it’s two decades “to set the course” to transform society, and not to actually transform it. It turns out that some countries like Germany, Spain and Italy, all set their green course years ago, and all have since discovered that it’s too expensive to follow. Thus they’ve since begun to abandon these courses by cutting back on or eliminating the subsidies that had been designed to keep them on their courses to begin with. The “course” to transform society turned out to be a path to failure and had to be abandoned.
“Setting the course for a renewable energy economy” over the next 20 years is not going to curb global CO2 emissions at all. China, India and the rest of the booming developing world aren’t going to accept delaying any longer the prosperity that the western world has been enjoying for over half a century. Poverty cannot pay for expensive energy. The path to renewable energy can only go through prosperity, and the path to prosperity is paved with cheap energy. The developing world is not going to abstain from using cheap fossil fuels. Thus CO2 concentrations will certainly continue their rise. In 10 years it’ll be clear what the real impact of CO2 on climate truly is.
Another misleading comment Schellnhuber makes is claiming that “surveys show globally that 90% of the population wants the transition renewable energies”. Well if they’re cheap and plentiful, who doesn’t? But the reality is that these energy sources are still astronomically expensive and cause more environmental destruction than protection. They cannot lift countries out of poverty.
 
Share this...FacebookTwitter "
"


Engineering a cooler Earth
Researchers brainstorm radical ways  to counter climate  change

By Erika  Engelhaupt
None of the scientists in the room so much as blinked when David  Keith suggested saving the world with spy planes spraying sulfuric acid.
Keith,  a physicist at the University of Calgary in Canada, was facing an  audience not likely to be shocked: nearly 200 other researchers, some of  whom had their own radical ideas for fighting global warming. His  concept was to spray a mist of sulfuric acid high in the stratosphere to  form particles called sulfate aerosols, which would act like a  sprinkling of tiny sunshades for the overheating Earth.
Keith’s  idea may sound outrageous, but it is just one of many proposals for  bumping the global thermostat down a couple of degrees by tinkering  directly with the planet’s heating and cooling systems. Plans to cool  the Earth range from shading it to fertilizing it, from seeding clouds  to building massive supersuckers that filter greenhouse gases from the  air. The schemes are all part of a growing field known as  geoengineering: a subject once taboo for all but the scientific fringe,  but now beginning to go mainstream.
So far the tinkering happens  mainly in computer models, where researchers are trying to figure out  geoengineering’s potential side effects. Yet some technologies are in  the prototype stage, governments are starting to consider geoengineering  seriously and budding geoengineers are working out how to proceed  safely, and ethically, with real-world experiments.
“It truly is  asking giant questions which nobody really knows the answers to,” Keith  says — “like how we manage the whole Earth.”
In March, Keith and  other experts met in a dimly lit chapel-turned-auditorium at the  Asilomar resort near Monterey, Calif. In 1975, molecular biologists met  at the same resort to write landmark guidelines to regulate DNA  experiments. This time around, cloud physicists, legal scholars and  government bureaucrats debated the relative merits of brightening clouds  versus building artificial trees. In the end, the meeting-goers  concluded that geoengineering research should cautiously proceed, in  case Earth’s climate proves broken beyond the current means of repair:  ratcheting down fossil fuel use.
Researchers have kicked around  the idea of large-scale climate manipulation since at least the 1960s,  when Soviet scientists suggested damming the Bering Strait as part of a  scheme to warm Siberia and free shipping lanes of sea ice. But  mainstream scientific attention began only about five years ago.
===================
read the rest at Science News Engineering  a cooler Earth


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b7e95ad',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Issued today 4/28/2010
Lisa P. Jackson - EPA
EPA Press Office
press@epa.gov
202-564-4355
FOR IMMEDIATE RELEASE
April 28, 2010
Statement of Lisa P. Jackson Administrator, U.S. Environmental  Protection Agency
Legislative Hearing on Clean Energy Policies That Reduce Our  Dependence on Oil
House Subcommittee on Energy and the Environment
WASHINGTON – Chairmen Markey and Waxman, Ranking Members Upton and  Barton, Chairman Emeritus Dingell, and Members of the Subcommittee,  thank you for inviting me to testify about the Environmental Protection  Agency’s work to reduce America’s oil dependence and greenhouse gas  emissions. That work stems from two seminal events.
First, in April 2007, the U.S. Supreme Court concluded in  Massachusetts v. EPA that the Clean Air Act’s definition of air  pollution includes greenhouse gases. The Court rejected  then-Administrator Johnson’s refusal to determine whether that pollution  from motor vehicles endangers public health or welfare.
In response to the Supreme Court’s decision, and based on the best  available science and EPA’s review of thousands of public comments, I  found in December 2009 that motor-vehicle greenhouse gas emissions do  endanger Americans’ health and welfare.
I am not alone in reaching that conclusion. Scientists at the 13  federal agencies that make up the U.S. Global Change Research Program  have reported that unchecked greenhouse gas emissions pose significant  risks to the wellbeing of the American public. The National Academy of  Sciences has stated that the climate is changing, that the changes are  mainly caused by human interference with the atmosphere, and that those  changes will transform the environmental conditions on Earth unless  counter-measures are taken.
The second pivotal event was the agreement President Obama announced  in May 2009 between EPA, the Department of Transportation, the nation’s  automakers, America’s autoworkers, and the State of California to seek  harmonized, nationwide limits on the fuel consumption and greenhouse gas  emissions of new cars and light trucks.
My endangerment finding in December satisfied the prerequisite in the  Clean Air Act for establishing a greenhouse gas emissions standard for  cars and light trucks of Model Years 2012 through 2016.  So I was able  to issue that final standard earlier this month, on the same day that  Secretary of Transportation Ray LaHood signed a final fuel efficiency  standard for the same vehicles.
Using existing technologies, manufacturers can configure new cars and  light trucks to satisfy both standards at the same time. And vehicles  complying with the federal standards will automatically comply with the  greenhouse gas emissions standard established by California and adopted  by 13 other states.  This harmonized and nationally uniform program  achieves the goal the President announced last May.
Moreover, the EPA and DOT standards will reduce the lifetime oil use  of the covered vehicles by more than 1.8 billion barrels. That will do  away with more than a billion barrels of imported oil, assuming the  current ratio of domestic production to imports does not improve. The  standards also will eliminate more than 960 million metric tons of  greenhouse gas pollution.
But if Congress now nullified EPA’s finding that greenhouse gas  pollution endangers the American public, that action would remove the  legal basis for a federal greenhouse gas emissions standard for motor  vehicles. Eliminating the EPA standard would forfeit one quarter of the  combined EPA-DOT program’s fuel savings and one third of its greenhouse  gas emissions cuts. California and the other states that have adopted  California’s greenhouse gas emissions standard would almost certainly  respond by enforcing that standard within their jurisdictions, leaving  the automobile industry without the nationwide uniformity that it has  described as vital to its business.
I would like to mention one more action that EPA has taken to reduce  America’s oil dependence and greenhouse gas emissions. In February, I  signed a final renewable fuels standard.  It substantially increases the  volume of renewable products – including cellulosic bio-fuel – that  refiners must blend into transportation fuel. EPA will implement the  standard fully by the end of 2022. In that year alone, the standard will  decrease America’s oil imports by 41 and a half billion dollars. And  U.S. greenhouse gas emissions that year will be 138 million metric tons  lower thanks to the standard.
EPA’s recent work on vehicles and fuels shows that enhancing  America’s energy security and reducing America’s greenhouse gas  pollution are two sides of the same coin.
R133
==============================
h/t to WUWT reader Michael C. Roberts


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c66e3af',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterBy Ed Caryl
The recent issuing of four papers by Dr. Richard Muller, et al, has increased the on-line discussions of temperatures over the last decade. There are several claims in the first of these papers that deserve study:
1. “…The global land mean temperature has increased by 0.911 ±0.042 C since the 1950s…”
2. “The World Meteorological Organization (WMO) gives an operational definition of climate as the average weather over a period of 30 years (Arguez and Vose 2011).”
3. “No part of the Earth’s land surface shows appreciable cooling.”
These assertions will be addressed in the course of this article. For material, 83 locations were selected from the GISS database. In an attempt to limit urban warming affects and the “adjustments” applied by GISS, a strict selection process was used. The selection criteria were: less than 10,000 population, as much as possible, a continuous record from 1940 or before to the present, and no splicing of records. Fifty-six of these locations are in the U. S. in four regions. Twenty-two stations were in the mid-west, in Kansas, Nebraska, and Iowa; fifteen stations in the north-west “inland empire,” eastern Oregon, Washington, and western Idaho; nine stations in the desert south-west, southern Utah and New Mexico; and ten stations in the south-east, Alabama and Georgia.
In the rest of the world, ten stations were found in the Arctic and Siberia, six stations bordering the North Atlantic Ocean, and thirteen stations in the southern hemisphere, in South American, Australia, the south Atlantic, and south Pacific. All of these stations are well away from any population centers and are isolated or in or close to very small towns and villages. These will be explored in Part 2.
For each station, a temperature anomaly was computed, using the average temperature from 1930 to 1980 as the baseline. This baseline was chosen because it is in the middle of the period for many of the records, and because it includes both a warm and a cold era. Figure 1 shows the result for the 22 stations in the U.S. mid-west.

Figure 1. This is the temperature anomaly from a 1930-1980 baseline for 22 mid-western small-town locations. The bold black trace is the average for those stations.
It can be seen that for this region, the highest temperature occurred in 1934, the next highest in 1921, and the third highest in 1931. The year 2000 was only the fourth highest in the twentieth century. Since 1930, the mid-west U.S. temperature trend has been cooling by about 0.1° C. (Figure 2)

Figure 2: This is the average anomaly and a linear trend plot from 1930 to 2011 for the mid-western U.S. showing about 0.15 degrees C cooling over that period. Since 2005 the cooling has been about 1.5 degrees C.

Figure 3. The Temperature Anomalies for 15 northwest U.S. stations. The bold black trace is the average anomaly for those stations.
In Figure 3, the trend for the last century has been warming, but taken in 30-year periods described at the top of this article, the first 30 years was flat, followed by a sudden warming, then cooling until 1980, then another sudden warming, followed by a sudden cooling since 2003. The warmest year was again 1934, almost a degree warmer than 1992, 1998, and 2003.

Figure 4: These are the temperature anomalies for 9 stations in the southwest U.S. The bold trace is the average temperature anomaly for the SW U.S.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In Figure 4, the situation is the same as the other regions: flat from 1900 to 1930, a sudden warming to the warmest year, 1934, cooling until 1980, warming to 2000, then cooling in the last decade.

Figure 5: Temperature anomalies in the SE region of the U.S. The bold black traces are the average anomaly and a linear trend line applied to that average.
In Figure 5, the trend for the entire 20th century has been cooling in this region by nearly half a degree C. The four warmest years are all in the 1920’s, 1921, 22, 25, and 27. The next warmest is 1933. 1998 and 99 are not even in the top 10.
If all 56 locations are averaged together, the trend is warming from the late 19th century to the late 1930’s. After that date, the trend is cooling until 1980, and then warming by the same amount to 2000. See figure 6, showing the temperature anomaly for all the U. S. locations examined, with a trend line from 1934 to 2000, one complete cycle of the 66-year peak-to-peak temperature cycle.

 
Figure 6: The average U.S. temperature anomaly for 56 rural stations from 1934 to 2000, with a linear trend line plotted. The trend over that period is about -0.06° C, or -0.074° C per century cooling.
Conclusion
Now, let’s revisit the claims by Dr. Richard Muller:
 …The global land mean temperature has increased by 0.911 ±0.042 C since the 1950s…”
Strictly speaking, that claim is true. But what is left out is that the same amount of cooling took place from the late 1930’s to the late 1950’s. The temperature is cycling with a period of about 66 years, with about one degree amplitude. Dr Muller is only looking at one-half of the temperature cycle.
The World Meteorological Organization (WMO) gives an operational definition of climate as the average weather over a period of 30 years (Arguez and Vose 2011).”
See 1 above. That definition is too short by at least a factor of two. There are many cycles seen in the temperature record. See this paper from the Chinese Science Bulletin. They mention 110, 199, 800, and 1324-year cycles; and their Fourier
analysis plot shows other cycles at 66 (one third of the 199 year cycle) and about 38 years. The 66-year cycle is clearly seen in the above plots. The 38-year signal may reflect the slower cooling part of the cycle followed by quicker warming. This author submits that any attempt to define climate as some time-average weather is a futile exercise.
No part of the Earth’s land surface shows appreciable cooling.”
Dr. Muller did not define appreciable, or a time period. For over 80 years, the SE and mid-west U. S. are cooling. Over the last decade, the U.S. and Canada are cooling. Anthony Watts here, and Matti Vooro here, have described this phenomenon. The so-called climate scientists must get over thinking that the linear trend over the last thirty years is telling them anything about the climate.
In Part II, the other (global) 27 rural and isolated stations will be analyzed.
 
 
Share this...FacebookTwitter "
nan
"

If a scientific paper appeared in a major journal saying that the planet has warmed twice as much as previously thought, that would be front‐​page news in every major paper around the planet. But what would happen if a paper was published demonstrating that the planet may have warmed up only half as much as previously thought?



Nothing. Earlier this month, Ross McKitrick from Canada’s University of Guelph and I published a manuscript in the _Journal of Geophysical Research‐​Atmospheres_ saying precisely that.



Scientists have known for years that temperature records can be contaminated by so‐​called “urban warming,” which results from the fact that long‐​term temperature histories tend to have originated at points of commerce. The bricks, buildings, and pavement of cities retain the heat of the day and impede the flow of ventilating winds.



For example, downtown Washington is warmer than nearby (and more rural) Dulles Airport. As government and services expand down the Dulles Access road, it, too, is beginning to warm compared to more rural sites to the west.



Adjusting data for this effect, or using only rural stations, the United Nations’ Intergovernmental Panel on Climate Change states with confidence that less than 10% of the observed warming in long‐​term climate histories is due to urbanization.



That’s a wonderful hypothesis, and Ross and I decided to test it.



We noted that other types of bias must still be affecting historical climate records. What about the quality of a national network and the competence of the observers? Other factors include movement or closing of weather stations and modification of local land surfaces, such as replacing a forest with a cornfield.



Many of these are socioeconomic, so we built a computer model that included both regional climatic factors, such as latitude, as well as socioeconomic indicators like GDP and applied it to the IPCC’s temperature history.



Weather equipment is very high‐​maintenance. The standard temperature shelter is painted white. If the paint wears or discolors, the shelter absorbs more of the sun’s heat and the thermometer inside will read artificially high. But keeping temperature stations well painted probably isn’t the highest priority in a poor country.



IPCC divides the world into latitude‐​longitude boxes, and for each of these we supplied information on GDP, literacy, amount of missing data (a measure of quality), population change, economic growth and change in coal consumption (the more there is, the cooler the area).



Guess what. Almost all the socioeconomic variables were important. We found the data were of highest quality in North America and that they were very contaminated in Africa and South America. Overall, we found that the socioeconomic biases “likely add up to a net warming bias at the global level that may explain as much as half the observed land‐​based warming trend.”





[S]ocioeconomic biases “likely add up to a net warming bias at the global level that may explain as much as half the observed land‐​based warming trend.”



We then modified IPCC’s temperature data for these biases and compared the statistical distribution of the warming to the original IPCC data and to satellite measures of lower atmospheric temperature that have been available since 1979. Since these are from a single source (the U.S. government), and they don’t have any urban contamination, they are likely to be affected very little by economic factors.



Indeed. The adjusted IPCC data now looks a lot like the satellite data. The biggest change was that the high (very warm) end of the distribution in the IPCC data was knocked off by the unbiasing process.



Where was the press? A Google search reveals that with the exception of a few blog citations, the only major story ran in Canada’s _Financial Post_.



There are several reasons why the press provides so little coverage to science indicating that global warming isn’t the end of the world. One has to do with bias in the scientific literature itself. Theoretically, assuming unbiased climate research, every new finding should have an equal probability of indicating that things are going to be more or less warm, or worse‐​than‐​we‐​thought vs. not‐​so‐​bad.



But, when someone finds that there’s only half as much warming as we thought, and the story is completely ignored, what does this say about the nature of the coverage itself? Somehow, you’d think that would have been newsworthy.
"
"**The number of domestic abuse offences recorded by police in England and Wales has increased during the pandemic.**
But the Office for National Statistics said such offences gradually rose in recent years so it cannot be determined if it was related to the pandemic.
Police recorded 259,324 domestic abuse offences between March and June - 7% up on the same period in 2019.
During and after the first lockdown in April, May and June, roughly one-fifth of offences involved domestic abuse.
The ONS data, released on Wednesday, includes information from a range of sources - including police forces' own figures on the number of offences recorded and then flagged as related to domestic abuse.
Domestic abuse is not a specific criminal offence, so police record incidents under the type of offence (for example, assault with injury) but then flag that it is related to domestic abuse.
In April, May and June - which covers the period during and immediately after the first national coronavirus lockdown - domestic abuse offences took up a larger proportion of all offences compared to previous years.
Around 20% of all offences recorded by police were flagged as domestic abuse related during these months - compared to less than 15% in previous years.
The number of offences also rose each month, the figures showed.
One woman, Davina, told the BBC that it was increased time at home with her abuser that made her seek help.
""Lockdown was the worst time in my life,"" she told BBC Scotland's The Nine programme. ""That was when I first paid attention to Women's Aid, I wondered if they could get me out the situation, so took the number from the television.
""I wasn't allowed to use the phone in the house so I took the number and went out with the dog and I phoned it.
""I wasn't ready to go but they had nowhere for me anyway. But I was in constant contact with Rebecca from Women's Aid and she helped me eventually leave.
""If it hadn't been for them I don't know what would have happened. I think eventually I would be dead. Mentally, physically, emotionally - I couldn't do it any more.""
Davina was allocated a place in a refuge and although she says it took her a month to stop waking up in the night crying, she finally feels safe.
Read more here.
As the lockdown eased, the proportion of offences flagged as domestic abuse went down. But this was likely because the overall amount of criminal offences increased when lockdown was lifted.
Between March and June, police recorded 206,492 ""violence against the person"" offences that were flagged as domestic abuse - a 9% rise on the same period in 2019.
The ""violence against the person"" category includes offences such as harassment, assault and murder. Other offences outside this category can also be flagged as linked to domestic abuse, such as sexual offences.
And provisional data showed there were 64 domestic homicides in England and Wales recorded by police between January and June 2020 - 30 of them in the period between April and June.
This is nearly 10 more than the same period in 2019, although the figure is slightly lower than in 2018.
""The number of domestic abuse-related crimes recorded by the police continued to increase in the year ending March 2020; this may reflect improvements in police recording and an increase in victims' willingness to come forward,"" said Helen Ross, from the ONS's Centre for Crime and Justice.
""Up-to-date evidence shows this increase continued into the lockdown period - however, it cannot be determined whether this can be directly attributed to the coronavirus pandemic.""
Ms Ross added that data showed there had been an increase in demand for domestic abuse support services during the pandemic, particularly following the easing of lockdown measures.
""Data suggests that experiences of domestic abuse may have intensified during the lockdown and that victims faced difficulties in safely seeking support under these conditions,"" she said.
Charities dealing with domestic abuse have reported a surge in appeals for help since the start of the pandemic.
Earlier this week, train companies and charity Women's Aid confirmed they were extending a scheme that offers free travel to people fleeing domestic abuse.
The ""Rail to Refuge"" scheme - which provides free tickets for women, men and children travelling to refuge services - will continue until March next year.
The charity New Era, which helps victims in Staffordshire and Stoke-on-Trent, said the ONS figures was ""more disturbing"" evidence and showed there was ""more to do to tackle and end relationship abuse"".
Meanwhile, London Mayor Sadiq Khan has announced that Â£3.7m of City Hall and government money would be invested in measures to support victims of domestic abuse.
He said it would be funding new ""safe spaces"" for victims, training for police and schemes focused on perpetrators, adding: ""Sadly, we already know that during lockdown home is not always a safe place for everyone."""
"**Most of England will be in the two toughest levels of measures when the national lockdown ends next week.**
The new coronavirus tier restrictions will mean 55 million people remain banned from mixing with other households indoors from 2 December.
Large parts of the Midlands, North East and North West, including Manchester, as well as Kent, are in tier three.
A majority of places are in the second highest level - tier two - including London, and Liverpool city region.
The Isle of Wight, Cornwall and the Isles of Scilly - where there have been no recorded cases in the past week - will be the only areas of England in the lowest level of curbs - tier one.
The system will be regularly reviewed, with the first scheduled for 16 December, so an area's tier level may change before Christmas.
Prime Minister Boris Johnson told a Downing Street press conference that the tougher rules would ""strike a balance"", adding that ""every area has the means of escape"".
Health Secretary Matt Hancock set out the reasoning behind the tier decisions for each area in a written ministerial statement.
He told the Commons: ""Hope is on the horizon but we still have further to go. So we must all dig deep.""
Mr Hancock added that people ""should see these restrictions not as a boundary to push but as a limit on what the public health advice says we can safely do in any area.""
Around 23 million people across 21 local authority areas will be in the highest level - tier three - including Birmingham, Leeds, Sheffield, Tees Valley Combined Authority and North East Combined Authority.
Lancashire, Leicester, Lincolnshire, Slough, Bristol, Kent and Medway will also be in tier three.
Earlier, a rush for details of the tier allocations saw the government website repeatedly crash.
On Thursday, another 498 deaths within 28 days of a positive test were reported in the UK, and a further 17,555 positive cases, the latest figures showed.
Differences between the new tiers include restrictions on where households can meet up:
Gyms and close-contact beauty services like hairdressers will be able to open in all tiers. Guidance said people in all tiers who can work from home, should continue to do so.
Pubs in tier two can only open to serve ""substantial meals"", while those in tier three can only operate as a takeaway or delivery service.
Hospitality bosses said nearly nine in 10 venues believed they ""are not viable to operate"" within tiers two and three.
Make no mistake, this is only a gradual step out of lockdown.
At the start of November nearly half the country was in tier one, meaning households could mix indoors in people's homes and in pubs and restaurants as long as they kept to the rule of six.
Now that is only possible in Cornwall, the Isle of Wight and Isles of Scilly.
Infection rates are showing early signs of coming down, but the government is erring on the side of caution.
Research suggests they were too slow to put areas in higher tiers before lockdown.
They do not want to make that mistake again - and so are starting off high in the hope they can move areas down the tiers.
But it is not only about which area is in which tier.
The top two tiers have been beefed up, particularly in regards to hospitality.
One ray of hope, the government says, is the experience of Liverpool.
Before lockdown it was in tier three and seeing among the highest infection rates in the country.
Today it has now been put in tier two with infection levels pretty close to the national average.
BBC analysis showed 713,573 people live in the new tier one areas, 32.2 million in tier two, and 23.3 million in tier three.
This is compared to 23.5 million in tier one pre-lockdown, 24 million in tier two, and 8.7 million in tier three.
The new tier restrictions will be voted on by MPs next week, with the government already facing opposition from its own backbenchers.
Leading Conservative MP Sir Graham Brady told BBC Radio 4's World at One he would vote against the measures, saying: ""I do think that the policies have been far too authoritarian.""
And former Brexit minister Steve Baker, deputy chairman of the recently-formed Covid Recovery Group (CRG), called for the government to publish analysis - ahead of the vote - of the impact restrictions were likely to have on controlling Covid, as well as the non-Covid health impact and the effect on ""society, people's livelihoods and businesses"".
He said he was ""open"" to supporting measures ""where it can clearly be demonstrated that the government intervention will save more lives than it costs"".
Meanwhile, there was a mixed reaction from regional leaders following the announcement of tier allocations.
MPs and businesses in Cornwall expressed ""huge relief"" at being one of only three areas in England to be placed in tier one.
Mayor of Liverpool Joe Anderson said the city region's move from tier three to tier two was the result of ""hard work, dedication and sacrifice"".
He said: ""We embraced tier three restrictions and worked fast to deliver the testing pilot, bringing in the Army to help us deliver an efficient service.""
And Mayor of London Sadiq Khan said the decision to place the capital in the second highest level - tier two \- was the result of people's ""monumental sacrifice"" and would be a ""welcome boost"" for businesses.
But there was anger among politicians in Lancashire that the whole county had been placed into the highest tier of restrictions, after council leaders asked for it to be split into different tiers to reflect varying rates.
Elsewhere, Leicester MPs and businesses said the city's tier three restrictions were ""extremely difficult to hear"" following 150 days of lockdown.
And Greater Manchester's mayor, Andy Burnham, said he hoped the region would be moved down from tier three in a couple of weeks.
Decisions on tiers are based on public health recommendations informed by a series of public health data, including Covid-19 cases among the over-60s, positivity rates, pressure on the NHS and how quickly cases are rising or falling.
Areas placed in tier three will be eligible for rapid or ""lateral flow"" tests - which give results in about 20 minutes without the need for a lab - to help bring down infections and reduce restrictions.
And they will be offered support by NHS Test and Trace and the armed forces to deliver a six-week rapid community testing programme.
Devolved administrations in Scotland, Wales and Northern Ireland have the power to set their own coronavirus regulations, though all four UK nations have agreed a joint plan for Christmas.
Earlier, data from the Office for National Statistics showed coronavirus infection rates in England were continuing to show signs of levelling off.
**Are you a business owner? How will your business be affected by the latest rules? Share your experiences by emailing**haveyoursay@bbc.co.uk **.**
Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways:
If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or comment or you can email us at HaveYourSay@bbc.co.uk. Please include your name, age and location with any submission."
"
No mention of missing “M’s” here in this press release from University of Melbourne
This data visualization from the AMSR-E instrument on the Aqua satellite show the maximum sea ice extent for 2008-09, which occurred on Feb. 28, 2009. Credit: NASA Goddard's Scientific Visualization Studio
Melting sea ice has been shown  to be a major cause of warming in the Arctic according to a University  of Melbourne study.
 Findings published in  Nature today reveal the rapid melting of sea ice has dramatically  increased the levels of warming in the region in the last two decades.
Lead author Dr James Screen of the School of Earth Sciences at the  University of Melbourne says the increased Arctic warming was due to a  positive feedback between sea ice melting and atmospheric warming.
“The sea ice acts like a shiny lid on the Arctic Ocean. When it is  heated, it reflects most of the incoming sunlight back into space. When  the sea ice melts, more heat is absorbed by the water. The warmer water  then heats the atmosphere above it.”
“What we found is this feedback system has warmed the atmosphere at a  faster rate than it would otherwise,” he says.
Using the latest observational data from the European Centre for  Medium-Range Weather Forecasting, Dr Screen was able to uncover a  distinctive pattern of warming, highly consistent with the loss of sea  ice.
“In the study, we investigated at what level in the atmosphere the  warming was occurring. What stood out was how highly concentrated the  warming was in the lower atmosphere than anywhere else. I was then able  to make the link between the warming pattern and the melting of the sea  ice.”
The findings question previous thought that warmer air transported  from lower latitudes toward the pole, or changes in cloud cover, are the  primary causes of enhanced Arctic warming.
Dr Screen says prior to this latest data set being available there  was a lot of contrasting information and inconclusive data.
“This current data has provided a fuller picture of what is happening  in the region,” he says.
Over the past 20 years the Arctic has experienced the fastest warming  of any region on the planet. Researchers around the globe have been  trying to find out why.
Researchers say warming has been partly caused by increasing human  greenhouse gas emissions. At the same time, the Arctic sea ice has been  declining dramatically. In summer 2007 the Arctic had the lowest sea ice  cover on record. Since then levels have recovered a little but the  long-term trend is still one of decreasing ice.
Professor Ian Simmonds, of the University’s School of Earth Sciences  and coauthor on the paper says the findings are significant.
“It was previously thought that loss of sea ice could cause further  warming. Now we have confirmation this is already happening.”


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8bfe41d0',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"
Share this...FacebookTwitterIn terms of deaths, this is worse than Fukushima.
Yet, we never hear a peep from the media about the dark side of this “safe and environmentally gentle energy”. Imagine if this had happened at a nuclear power plant.
“Building offshore wind parks can be a deadly occupation. Three construction workers have already drowned whilst working on German projects in the North and Baltic Seas. 80 serious accidents have been registered, it was reported Sunday.
A total of three men, including a Polish worker and a Swedish diver have already lost their lives whilst working on offshore wind farms 120 kilometres off the East Frisian coast near Emden, reported the online edition of the Focus magazine on Sunday.
Both workers drowned while working on the BardOffshore wind farm.
Leader of the German Central Command for Maritime Emergencies Hans Werner Monsees told the magazine that only “a better and tighter rescue system” would prevent the number of deaths…” Continue reading…
Original story in FOCUS here, which adds (emphasis added):
The energy transition has had deadly consequences: According to FOCUS information, there have already been 80 serious accidents on German offshore wind park construction sites. Three men have been killed – and more have died.“
More have died? How many? Seems nobody wants to tell us.
Of course any construction site is hazardous and deaths are inevitable. But what irks me is that for one industry it’s acceptable, but not for another (e.g. nuclear).
Share this...FacebookTwitter "
"

Dr. Ben Ho’s piece in Tuesday’s _New York Times_ entitled “The Conservative Case for Solar Subsidies” is certain to raise a few eyebrows amongst the conservative crowd. But Ho asks a valid question that I’m not sure conservatives have seen fit to fully address in the last few years: What, precisely, should free market denizens hold true about energy policy?   
  
The facile response--that there should simply be no government role--doesn’t quite work here. To be fair, few conservatives suggest such a thing. Ho points out that when there are negative externalities to the production of a good or service the economically efficient policy response requires a tax, and our carbon-based fuels emit a variety of pollutants when burned. This holds true regardless of one’s opinion about the verities of carbon emissions and climate change: Smog--which results mainly from automobile emissions--remains a key contributor to myriad health problems in the United States, and particulate matter resulting from coal burning bedevils asthmatics.   
  
But the libertarian solution is not quite as simple as imposing a tax that covers the socialized pollution costs of burning fossil fuels. We have a nationwide energy grid, one that the federal government played an integral role in conceiving and constructing. Without eminent domain, such a thing would have been all but impossible. The federal government’s regulatory apparatus also has an integral role in regulating power providers, and since the provision of power is a natural monopoly, it’s hard to conceive of an alternative, at least for the moment.



One victory libertarians managed to achieve in the last twenty years has been to convince regulators that the inherent natural monopoly lies solely in the distribution and not the production of energy, so the two have been disconnected in most states. These days, most utility customers can choose from where to get their power, which is a good thing, but it still leaves us with a fundamental economic problem: How do we get a natural monopoly--the operators of the energy grid--to behave as if it were subject to competition?   
  
The basic regulatory solution is to allow the utilities to charge a price to recoup their costs plus some incremental profit. This may sound reasonable, but it creates lousy incentives--namely, the utility has zero incentive to control costs under such a scheme. In fact, they have an incentive to _increase_ their costs and capital investments, since this boosts their attendant profits.   
  
Dr. Ho alluded to the profound potential impact that solar energy could have on this monopoly in the future. With the advent of Tesla’s home battery, it is possible that within the next decade (provided the batteries continue to improve--far from a sure thing) we could see some houses begin to go off the grid entirely, with solar energy producing all the energy they need. If this were to occur at a large scale, we might see utilities being forced to act as if they were a competitive firm and strive to boost efficiency where possible in order to distribute energy at the lowest possible costs to keep customers from cutting the power cord.   
  
The other possibility in such an environment is a downward spiral: as people leave the grid, the costs of maintaining it gets spread over fewer people, boosting the cost and, in turn, nudging more people to get off the grid until only those without any other viable energy option are left holding the bag and paying sharply higher costs for energy.   
  
The answer to such a potentiality is to embrace technology and apply a modicum of foresight to regulatory activities. While the utilities would prefer that home solar just go away, Ho points out that its costs are now competitive with gas and coal, and prices seem poised to drop further in the future. The potential of solar energy--and solar energy that can be stored--is that it can allow utilities to dramatically reduce their investments. If energy storage were to allow utilities to close marginal power plants that produce only at the peak demand each day, the savings to power companies would be enormous. What’s more, having distributed power across the grid would also allow utilities to reduce their own capital investment along the grid by smoothing out the fluctuations in power distribution: in essence, doing one of the utilities’ jobs for them.   
  
We are entering a brave new world in energy production, one that threatens to upend the century-old regulated utilities monopoly and replace it with something that could be much less expensive to run--but only if we get the right policies in place to let it develop. The one worry is that the biggest player in this market has absolutely no incentive for these changes to happen, and its regulator more often than not takes its cues thusly. This is the conservative’s task for the next decade--keep a watch on regulators to act in the long-term interests of the customers and not the utilities. It’s easier said than done.   
  



"
"Brazilians head to the polls in October to decide on their new president. The country’s votes always produce surprises such as the election of a clown in 2010 and in 1959 the election of a rhinoceros named Cacareco with 100,000 votes as a city councillor of São Paulo.   Cacareco was arguably Brazil’s first celebrity animal but the Belo Horizonte Zoo, through captive breeding, has produced the first two “Brazilian” gorillas in the past month.  Once their names have been chosen, these baby gorillas will no doubt become celebrities. The zoo just needs to be careful with the naming – after a public competition in the 1970s its first gorilla was called Idi Amin Dada, after the African dictator. London Zoo’s most famous resident Guy the Gorilla became a national icon in the 60s and 70s; he too was named after an infamous character, 17th century would-be terrorist Guy Fawkes. Superstar zoo animals long pre-date social media and demonstrate that animal celebrity culture is nothing new.  But modern zoos find it difficult to balance celebs with conservation. Celebrity culture is all about the individual and species conservation is all about the population. Thus, zoos need to strike a happy medium between public (over-)interest in certain star attractions and doing what is right for the whole species. The problem is it takes a lot of captive animals to save a certain species from extinction, and most zoos are too small to do this by themselves. For large mammals with long lives, for example, we need approximately 250 individuals in captivity to maintain a genetically healthy population. When it comes species’ with shorter generation times (birth to sexual maturity) we need even more individuals in captivity to avoid the loss of genetic diversity: so to save a small rodent with a generation interval of a few months we would need thousands of individuals.   Paradoxically it can be more expensive to save a territorial mouse species from extinction than a species of elephant because of the need to construct hundreds, if not thousands, of mouse enclosures. Genetic diversity is important because it allows species to adapt to their environment. But zoo animals in captivity are not subject to natural selection. Despite this, the goal of many zoos is to create a safety net population of species to guarantee the survival of their wild counterparts; this might be by reintroducing animals to the wild. Zoos get over the numbers problem by thinking globally. International co-operation means all the gorillas in zoos participating in the captive breeding programme are managed as a metapopulation. That is, although each zoo has its own group of gorillas they are managed as if they are part of a single global population – and issues such as genetic diversity or gender balance are considered in terms of the 850+ in the programme rather than the five or six in any particular zoo. A studbook keeper uses genetic management software to decide who should breed, who should not breed and who should be paired with who. A digital-age cupid if you like. But here decisions are based on the genetic value of the individual not their celebrity or good looks.  The more genetically important the individual, the greater the chance he will be given the nod to breed.  Studbook keepers also select against individuals with genetic illnesses. An individual is genetically important if there are few copies of their genes among others: the aim being to maintain as much genetic diversity in the captive population as possible for as long as possible. This approach has been incredibly successful – the Przewalski horse, for instance, the only surviving breed of truly “wild” (never domesticated, non-feral) horse, was once down to as few as 13 individuals. Thanks to captive breeding it was brought back from the brink of extinction to number in the thousands and is now being reintroduced to Mongolia. Reproductive technologies such as artificial insemination can help with captive breeding, but in general zoos still favour producing offspring the old fashioned way. Mainly because this exposes the animals to less risk; that is, no need for it to participate in an invasive medical procedure. But this does imply that we need to move animals around the world for dating purposes. Leon, the male gorilla at the Belo Horizonte Zoo, came from Spain – and the two females, Imbi and Loulou came from the UK. These animals are on loan as part of the international gorilla captive breeding programme. Loaning animals across international borders could be a legal nightmare; if there were some sort of dispute in this case – the ownership of the baby gorilla, for instance – which of the three legal systems should be followed in the case of a dispute?  In the spirit of co-operation this problem has been solved in a simple means by zoos through the use of what are essentially gentlemen’s agreements. In this day and age when lawyers seem to run the world it is refreshing to know that trust can win out for species conservation."
"**Cumbria is to be placed in tier two - high alert - when lockdown ends on 2 December, the government has announced.**
The rules mean households cannot mix indoors and people must follow the rule of six if meeting outdoors, while pubs serving ""substantial meals"" can reopen.
In the week to 21 November, there was a small rise in cases in the Carlisle and South Lakeland District Council areas, blamed on a ""large school outbreak"".
However, elsewhere in the county cases had gone down.
The system will be regularly reviewed, with the first scheduled for 16 December.
Many areas have been put into tier three, including all of the North East.
The Department for Health and Social Care said in a statement: ""The picture in Cumbria is broadly improving although case rates in Carlisle and South Lakeland are increasing - with increases likely due to a large school outbreak.
""Case rates in over 60s are above 100 per 100,000 in Carlisle and Barrow-in-Furness.
""These case rates are too high for allocation to tier one but Cumbria's trajectory does currently not warrant inclusion in tier three.""
Throughout the county, pubs and restaurants which serve ""substantial meals"" will be allowed to be operate with table service, but must stop serving by 10pm and close by 11pm.
Spectators will be allowed at outdoor and indoor sport events, or at performances and shows, but with a maximum crowd capacity outdoors of 50% or 2,000 people, whichever is smaller, and indoor 1,000 people.
Make no mistake, this is only a gradual step out of lockdown.
At the start of November more than half the country was in tier one, meaning households could mix indoors in people's homes and in pubs and restaurants as long as they kept to the rule of six.
Now that is only possible in Cornwall, the Isle of Wight and Isles of Scilly.
Infection rates are showing early signs of coming down, but the government is erring on the side of caution.
Research suggests they were too slow to put areas in higher tiers before lockdown.
They do not want to make that mistake again - and so are starting off high in the hope they can move areas down the tiers.
But it is not only about which area is in which tier.
The top two tiers have been beefed up, particularly in regards to hospitality.
One ray of hope, the government says, is the experience of Liverpool.
Before lockdown it was in tier three and seeing among the highest infection rates in the country.
Today it has now been put in tier two with infection levels pretty close to the national average.
Health Secretary Matt Hancock said: ""Thanks to the hard work and sacrifice made by people up and down the country, we are able to move out of national lockdown and into more targeted local, tiered restrictions.
""By following the rules together we can get out of these tough measures.""
_Follow BBC North East & Cumbria on _Twitter _,_Facebook _and_Instagram _. Send your story ideas to_northeastandcumbria@bbc.co.uk _._"
"

Immunizing Mosquitoes To Fight Malaria
By Jesse Emspak, International Business Times
 
(Photo: Wikipedia / Tim Vickers)
A diagram showing the life cycle of  malaria parasites. Researchers are proposing that the disease be  attacked via immunizing the mosquitoes against the plasmodium parasite,  so that it cannot be transmitted from person to person.


Millions of people in the tropics suffer from malaria, a  mosquito-borne disease that has been difficult to treat and which costs  many developing countries millions of dollars per year in lost  productivity. Up to now, efforts at controlling it have focused on  attacking the parasites that cause it, keeping mosquitoes from biting,  or killing the insects.
But at Johns Hopkins University, Rhoel Dinglasan, an entomologist and  biologist, decided to try another tack: immunizing mosquitoes.

Mosquitoes carry a species of parasite called plasmodium. The  parasite lives in the mosquito’s gut. The parasites then spread to the  mosquito’s salivary glands, and when the insect bites an uninfected  person, they enter the bloodstream. At that point the plasmodium goes  from the blood to a person’s liver, where it matures, escaping to the  bloodstream to infect the red blood cells in a form called a merozoite.
Once in the blood cells, the parasite reproduces until the red cell  bursts, releasing more merozoites. This cycle repeating itself causes  the characteristic fever, chills and ache associated with the disease.
…
When a mosquito bites an infected human, it takes up some of the  gametocytes.They aren’t dangerous to people at that stage. Since  plasmodium is vulnerable there, and that is the point that Dinglasan  chose to attack.
Full story here
================================
Here’s the very first Press Release from Johns Hopkins university citing this idea:
Vaccine Blocks Malaria Transmission in Lab Experiments
Researchers  at the Johns Hopkins Malaria Research Institute have for the first time  produced a malarial protein (Pfs48/45) in the proper conformation and  quantity to generate a significant immune response in mice and non-human  primates for use in a potential transmission-blocking vaccine.  Antibodies induced by Pfs48/45 protein vaccine effectively blocked the  sexual development of the malaria-causing parasite, Plasmodium,  as it grows within the mosquito. Sexual development is a critical step  in the parasite’s life cycle and necessary for continued transmission of  malaria from mosquitoes to humans. The study is published in the July  22 edition of the journal PLoS ONE.
“Development  of a successful transmission-blocking vaccine is an essential step in  efforts to control the global spread of malaria. In our study, we  demonstrate the relative ease of expression and induction of potent  transmission-blocking antibodies in mice and non-human primates. This  approach provides a compelling rationale and basis for testing a  transmission-blocking vaccine in humans,” said Nirbhay Kumar, PhD, senior author of the study and professor in Johns Hopkins Bloomberg School of Public Health’s W. Harry Feinstone Department of Molecular Microbiology and Immunology.
For the study, the research team expressed full-length Pfs48/45 in E. coli bacteria to produce the vaccine. Previous attempts to fully express the  protein had not been successful. The vaccine was first given to mice in  the laboratory. The vaccine was also tested in non-human primates  (Olive baboons) in Kenya with similar results. According to the study, a  single-dose vaccine provided a 93 percent transmission-blocking immune  response, reaching greater than 98 percent after a booster given several  months later.
“This is an exciting beginning to what might  become an important tool in the arsenal for malaria control and  progressive elimination of malaria transmission,” said Kumar. There is  no animal reservoir for human malaria and in that regard it is possible  to gradually reduce malaria transmission to a point of almost  eradication. However, Kumar cautioned that more research is needed to  achieve that goal. For one, similar research efforts are needed to  reduce transmission of Plasmodium vivax, another major human malaria parasite.
Malaria  affects greater than 500 million people worldwide and is estimated to  kill over one million people each year, most of whom are children living  in Africa.
In addition to Kumar, “A Potent Malaria  Transmission-Blocking Vaccine Based on Condon Harmonized Full Length  Pfs48/45 Expressed in E. Coli” was published by Debabani Roy Chowdhury, a  postdoctoral fellow of the Johns Hopkins Bloomberg School of Public  Health; Evelina Angov of the U.S. Military Malaria Vaccine Program; and  Thomas Kariuki of the Institute of Primate Research in Nairobi, Kenya.
The research was supported by grants from the National Institutes of Health and the Johns Hopkins Malaria Research Institute.




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8806b176',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**For months now, coronavirus restrictions have dictated where millions of Europeans can travel to and who they can see when they get there.**
So with Christmas fast approaching, governments are having to make tough decisions on whether to ease restrictions in time for the holiday period.
Here's a breakdown of what's been announced so far.
Italy is currently seeing the highest number of deaths since the end of March and Prime Minister Giuseppe Conte has told Italians to expect a ""more sober Christmas, without Christmas Eve gatherings, hugs and kisses"".
Many Italian regions are under partial lockdown and travel between them is restricted. These measures will remain in place until 3 December, but reports suggest an emergency decree may see the rules relaxed after this date.
The exact details of the decree are still being discussed by ministers. It is thought there will not be an official limit on social gatherings, but the government has recommended people ""plan to be as few as possible"".
Churches are free to remain open, but a 22:00 nationwide curfew means the traditional midnight mass is unlikely to happen. The beloved Italian Christmas market, meanwhile, has already been banned.
""We think we need to introduce greater precautions to prevent a surge in infections,"" Mr Conte said.
But it is not all bad news: Mr Conte has reassured children that _Babbo Natale_ (Father Christmas) will definitely be visiting as he is exempt from global travel restrictions. Phew.
Many Europeans head to the ski slopes over Christmas, but the continent is divided over whether to keep the resorts open.
**Italian** Prime Minister Conte has warned against these traditional breaks. ""We cannot afford it,"" he said. He is one of several EU leaders, including **German** Chancellor Angela Merkel and **French** President Emmanuel Macron, who have tried to co-ordinate a Europe-wide deal to postpone the ski season.
All three countries have closed their ski lifts over Christmas.
These widespread closures mean popular resorts in the Alps and Dolomites will lose out on billions of euros in revenue. Tourism officials were quick to criticise the plan, with the president of one French tourism body asking: ""So 400 people on a Paris metro won't get infected, but four people on a ski lift will?""
**Austria** believes it can offer safe holidays once restrictions are eased and skiing will be allowed there from 24 December, although quarantine rules could mean it's mainly domestic. **Swiss** resorts have been told they are free to stay open with safety measures in place.
Some fear that - without consensus - holidaymakers will travel long distances to visit the open resorts. In France, there will be random border checks to prevent holidaymakers going to ski in neighbouring countries such as Switzerland.
After weeks of national lockdown, President Emmanuel Macron has said restrictions will start being eased from 28 November. But the majority of lockdown measures will stay in place until just ahead of the festive break on 15 December.
Shops, theatres and cinemas will reopen in time for Christmas and people will be able to visit their families over the festive period. ""We will be able to travel without authorisation, including between regions,"" Mr Macron said in a TV address.
It is worth noting that France has been under a second national lockdown since late October. But on 15 December, this will be replaced by a nationwide curfew from 21:00 to 07:00. The curfew will not apply on Christmas Eve and New Year's Eve, however.
Restaurants and schools will not reopen until at least 20 January, and this is dependent on daily cases dropping below 5,000. Bars, cafes and nightclubs are closed indefinitely.
Religious services will be free to take place from 28 November with a limit of 30 people.
The decision to keep France's hugely popular ski resorts shut has come as a huge disappointment, with local mayors complaining of months of work wiped out. Mr Macron said they could reopen in January ""under favourable conditions"".
Chancellor Merkel has said Germany's ""lockdown light"" is likely to continue until January. Bars, restaurants and entertainment venues are closed but schools and shops are open. ""Daily cases are still far too high, and our intensive care units are still very full,"" she said.
Restrictions have been tightened ahead of the festive period, with masks being introduced more widely in schools and travel strongly discouraged. Moreover, from 1 December, the limit on social gatherings will be reduced to two households and a maximum of five people.
There will, however, be a temporary relaxation of the rules over the Christmas period. Up to 10 people will be able to meet between 23 December and 1 January, although Mrs Merkel has urged Germans to think hard before meeting in groups of this size.
Children aged under 14 are not included in the limit.
Mrs Merkel also said that - beyond the social gathering cap - any further easing of restrictions before Christmas was unlikely because the number of cases remains ""far too high"". She also said the so-called Christmas amnesty was dependant on cases falling.
Most major Christmas markets in Germany have already been cancelled, but some local ones are outlining plans to go ahead on a reduced scale.
As for New Year, fireworks displays have been cancelled while letting them off in the street is likely to be discouraged.
The Spanish government is planning a ""different"" festive period with a limit of six people allowed at parties, reports say.
It is set to recommend that social gatherings in the run-up to Christmas be held on restaurant terraces or other outdoor locations.
Spanish families also traditionally celebrate the Feast of the Three Kings with a parade on the evening on 5 January and the government will recommend that celebrations do not take place.
The plan also recommends ventilating indoor spaces and maintaining social distancing where necessary. But more broadly, Health Minister Salvador Illa has said ""nothing is set in stone"".
""We need to find consensus about [Christmas restrictions]. When it's decided we will announce the measures,"" he said.
Catalonia's government is hoping to allow gatherings of up to 10 people for Christmas. ""We will make our own decisions,"" a spokeswoman for the region said.
While in Madrid, officials are asking the government to approve a mass testing programme at pharmacies in the run-up to Christmas to allow people to meet safely over the festive period.
Austria is under a second national lockdown until 7 December, but there are hopes restrictions could then be eased in time for Christmas.
""The next two weeks are critical,"" Health Minister Rudolf Anschober told Kronen Zeitung newspaper on 23 November. ""Lockdown must not be extended.""
The government has ordered at least seven million antigen tests, and it is hoped a mass testing programme will provide Austrians with a route out of lockdown.
Hundreds of thousands of teachers and police officers will be tested first in early December, along with people in areas with high infection rates. Voluntary mass testing will then be rolled out nationwide in the week before Christmas.
Chancellor Sebastian Kurz has stressed that the country's Christmas measures would be guided by the data. ""Whether there will be regulations for Christmas and New Year's Eve... on how many people you can meet will depend heavily on the number of infections,"" he said.
It is thought schools and non-essential shops will open first, once the lockdown ends on 7 December, but questions remain over whether gatherings will be capped.
The country's traditional Christmas markets, however, will be closed over the festive season.
And while skiing will be allowed from 24 December, hotels will stay closed until 7 January. People visiting from countries with more than 100 cases per 100,000 - which include Germany and Italy - will have to quarantine.
In Russia, the main festive celebrations usually take place on New Year's Eve with many people holding all-night parties.
But over the past two decades there has been an increase in celebrations of Christmas, which the country's Orthodox Christian majority marks on 7 January.
Even so, restrictions are likely to dampen celebrations across the holiday period.
In the capital, Moscow, officials announced new measures that will last until 15 January. These include early closing times for restaurants and cafes and a 25% capacity limit at cinemas and theatres. Residents over the age of 65 and those in high-risk groups must also self-isolate until this date.
The city's month-long festive street festival is also likely to be cancelled, local media report.
Other regions have introduced similar restrictions of their own.
It comes after health officials warned that the situation remains unstable and the epidemic has not peaked yet nationwide. Virus cases have surged in recent weeks, and a record daily tally was recorded on 26 November."
"That eating beef is environmentally costly is by now widely appreciated. But little has been done to curtail the amount of cattle farmed for meat consumption. To try and address this, my colleagues and I decided to calculate just how costly beef production is for the environment, and how it stacks up against pork, poultry, dairy and eggs. Our hope is that better knowledge of the environmental costs of raising animals for food will help improve both the dietary choices people make and agricultural policies. Our research, which was published in the Proceedings of the National Academy of Sciences of the US, found that raising beef cattle is far more environmentally costly than poultry, pork, dairy or eggs. Per calorie, cattle requires on average 28 times more land and 11 times more water to farm. Farming cattle releases five times more greenhouse gases and uses six times as much nitrogen as the average of other animal products.  When compared with staple plant foods, these ratios roughly double. So, a beef calorie requires about 50 times more land than a wheat calorie. By comparison, pork, poultry and eggs are all roughly on the same level of environmental cost. In terms of greenhouse gas emissions, water use and the levels of nitrogen discharge from fertiliser run-off, dairy is comparable to pork, poultry and eggs.  While it’s long been clear that vegetarian diets produce lower environmental costs than ones involving produce from animals, people are still intent on eating food derived from animals – and with ever-increasing gusto. Taking note of this, we sought to identify the types of animal-based food that are least environmentally harmful. Though numerous studies have addressed elements of this issue, they have mostly used data from individual farms, typically one or at most a handful. But farms differ markedly geographically, from season to season and year to year, and are thus not necessarily representative of the big picture.  By contrast, we used the reverse, top-down approach by analysing national level data. While previous studies mostly addressed one environmental burden at a time (typically greenhouse gas emissions, but also water or land use), we simultaneously addressed each of them in order to offer a multi-dimensional view of the environmental performance of the livestock industry in the US.  We measured greenhouse gas emissions, water and land use, and reactive nitrogen discharge levels from manure or fertiliser. Reactive nitrogen is environmentally important because it is the most common cause of degradation in freshwater ponds, streams and lakes, and around coastlines where fertiliser run-off washed into rivers reaches the sea. We address the five main animal based products in the American diet: dairy, beef, poultry, pork and eggs, calculating the environmental costs per nutritional unit, calorie or gram protein. Our key challenge was devising accurate values of how much land, water, and reactive nitrogen livestock required, and the amount of greenhouse gasses they emit. Working out these estimates required navigating numerous subtleties. For example, grazing cattle in the arid to semi-arid western US uses an enormous amount of land, but little or no irrigation. Grain-fed feedlot cattle, by contrast, use much less land, but require cultivated grains that depend strongly on nitrogen fertiliser. We needed to fairly account for these differences across the country, while determining figures that reflect, approximately, the true environmental costs. These findings have a number of implications. First, this research can inform environmentally minded individuals so they can make environmentally better dietary choices. Perhaps more importantly, the paper can also help inform agricultural policy, in the US and worldwide. In a companion paper in the Journal of Agricultural Science (forthcoming) we have laid down a foundation for analysing the environmental costs of any diet, including plant-based diets and those of other nations.  Perhaps our key contribution is to highlight areas in which improvement is most likely, and where a focused effort is likely to yield the most desirable change. Applying these methods to global diets can help improve long term global food security in light of the effects of climate change, water and land shortage, and rising population."
"Russian hoaxers who apparently tricked Prince Harry into offering help to take penguins to the North Pole have raised serious questions over security and screening measures for the Duke and Duchess of Sussex as they leave the royal fold, a royal expert said.  Pretending to be putting through the Swedish activist Greta Thunberg and her father, Svante, hoaxers Vladimir Kuznetsov and Alexey Stolyarov managed to reach Harry on his landline at his rented Vancouver Island mansion on New Year’s Eve and on 22 January, it has been reported.  The royal, seemingly duped into thinking he was talking to the Thunbergs, also criticised Donald Trump and spoke of a “bullying” tabloid media trying to “sink” him and wife Meghan. A spokeswoman for the Sussexes declined to comment when asked if there was any doubt the voice was that of Harry. A former press secretary to the Queen, Dickie Arbiter, claimed the fact that the hoaxers, known as Vovan and Lexus, had reached Harry exposed weaknesses in their personal security. “As long as Harry and Meghan are over there, they’re out of the protection of the system,” he said. “For all its faults, the system does, and is there to, protect.” He said the hoaxers would not have been able to get through the Buckingham Palace switchboard. “They’re pretty vigilant,” he said, adding: “If you’re outside the system, you’re open to anything and everything.” The couple has a 15-strong team of staff based at Buckingham Palace, but they will be disbanded when the couple transition on 31 March, with some staff being made redundant and others redeployed in other royal households. No details about any staff in Canada have been made public. Arbiter spoke as the Sun, which published excerpts of the conversations, reported more details of the hoax calls. Harry failed to spot he was being pranked when the fake Greta and her father said they had 50 penguins that were stuck in land-locked Belarus and they were after a ship to transport them to the north pole, even though the animals are native to the south pole. When asked if he had any contacts to help, the duke is said to have suggested: “I’ve got one person who is a polar guide in the north pole … he may be able to help you, he knows all the right people.” “Greta” also asked if Harry could help her marry into the royal family and suggested she was interested in Prince George, the Sun reported. It said Harry replied: “I can assure you, marrying a prince or princess is not all it’s made up to be.” When the hoaxers suggested there were discussions in Russia that Harry could become head of a restored monarchy, he replied chuckling: “Well there you go, maybe that’s our new purpose: to be able to take over Russia.” The hoaxers joked about Harry smoking “weed” with hippies on Thunberg’s eco-catamaran, and also of forming a celebrity movement called “Stars Save the Earth” with Leonardo DiCaprio and Angelina Jolie. During one call they tricked him into believing mining companies close to Trump were exploiting the fictional island of Chunga-Changa – the name of a Russian children’s song.  The rights to the audio recordings had been “transferred” to British media, the hoaxers said as they confirmed the Sun’s report in response to a Guardian inquiry. In the audio, a person, reportedly Harry, says of the decision to stand down as a senior royal: “Sometimes the right decision isn’t always the easy one. And this decision certainly wasn’t the easy one, but it was the right decision for our family, the right decision to be able to protect my son. And I think there’s a hell of a lot of people around the world that can identify and respect us for putting our family first.” On Trump, he says: “I think the mere fact that Donald Trump is pushing the coal industry so big in America, he has blood on his hands.” He says he is confident “things will change” on the climate agenda within 10 years: “But we can’t wait five to 10 years, so I think if Donald Trump can become president of the United States of America, then anything’s possible, right?” He continues: “You forget, I was in the military for 10 years so I’m more normal than my family would like to believe … But certainly, being in a different position now gives us the ability to say things and do things that we might not have been able to do.” On Prince Andrew, who has stepped down from public duties over his friendship with the convicted sex offender Jeffrey Epstein, he says: “I have very little to say on that. But whatever he has done or hasn’t done, is completely separate from me and my wife.” Harry speaks of Boris Johnson being a “good man”, and tells the person posing as Thunberg: “So you are one of the few people who can reach into his soul and get him to feel and believe in you. But you have to understand that because he has been around for so long like all of these other people, they are already set in their ways.” In separate quotes, published by Mail Online, Harry reportedly says he has been “part of a family and part of a country that is scared of the tabloid media because they have so much power and influence and no morals. “From the moment that I found a wife that was strong enough to be able to stand up for what we believe in together, [that] has basically scared them so much that they’ve now come out incredibly angry, they’ve come out fighting, and all they will try and do now is try and destroy our reputation and try and, you know, sink us.” He adds: “It hasn’t been very nice. It’s been horrible, but we will come out of it stronger people.” Kuznetsov and Stolyarov have previously targeted Elton John, the Turkish president, Recep Tayyip Erdoğan, and the US senator and Democratic presidential hopeful Bernie Sanders."
"
Share this...FacebookTwitter600,000! Say what! This will certainly be the reaction of many readers here.
Not to worry, that bogus 600,000 sq km number comes from the leftist TAZ, whose journalists obviously lack fundamental education on rudimentary mathematics. They are not able to do simple subtraction. Or maybe the TAZ expects that its equally enlightened readers cannot. The TAZ writes:
According to Arctic monitoring agency Jaxa, sea ice covered an area of 4.19 million square kilometers on Friday. The previous minimum of ice extent had been recorded at the end of September 2007. Back then ice extent was 4.25 million square kilometers.”
Let’s see: 4,250,000 – 4,190,000 = 60,000.  I even did that in my head! Maybe the TAZ miscarried over a zero, can happen to anyone.
But a little later, the TAZ tries to give its lefty, intellectually superior readers an idea of just how big 4.25 million minus 4.19 million square meters really is. It writes:
Already now the ice extent of the Arctic Ocean is about 600,000 sq. km. less than the minimum measured back then [2007]– that corresponds to an area that is larger than Spain.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Now we see that they not only cannot do math, but that they did not even bother to to check their sources, to compare satellite photos and sea ice sources. But hey, when you’re writing pure propaganda, who needs to let inconvenient things like mathematics, data and facts get in the way?
Yes, some activist media will do whatever it takes to produce a sensational headline. The TAZ calls the Arctic sea ice development “dramatic” and a “sign of racing climate change” and that “the ice is melting from underneath” And the polar bears are going to starve, too:
While shipping routes will be much shorter […] polar bears will suffer under melting ice. Their hunt for seals will be made more difficult; they often have to swim hundreds of kilometres in order to reach hunting grounds, completely exhausted.”
That of course, is assuming the TAZ did the maths right: 60 km minus 30 km, is, duhhh, let me see here…300! 🙂
By now we have a good idea of how well-informed and intellectual TAZ readers must be. It’s no wonder they drive anything they run straight into bankruptcy.
And don’t worry TAZ, I have a screen shot of your piece of brilliant journalism.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOilprice.com has conducted a very interesting interview with the well known climatologist Judith Curry, who runs the excellent Climate Etc. blogsite.
You’ll recall that Professor Curry was once a staunch AGW proponent. Later the scientific evidence cooled her down to lukewarm.
The interview is balanced and readers may be interested in reading about Judith’s concerns for climate science, how climate change is affecting the planet, reasons for the increase in scepticism and why climate scientists have lost touch with the public.
The IPCC might have outlived its usefulness. Let’s see what the next assessment report comes up with. But we are getting diminishing returns from these assessments, and they take up an enormous amount of scientists’ time.”
You can read the full interview at: http://oilprice.com An-Interview-with-Judith-Curry.
Some of Judy’s quotes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Because of recent criticisms of the IPCC and a growing understanding that the climate system is not easily understood, an increasing number of scientists are becoming emboldened to challenge some of the basic conclusions of the IPCC, and I think this is a healthy thing for the science.”
and on the IPCC:
…we put the CO2 stabilization policy ‘cart’ way before the scientific horse.”
and on the green industrial complex (emphasis added):
Yet, we have allowed it to dictate global policy and form a trillion dollar green industrial complex – all without applying a single quality system, without a single performance standard for climate models, without a single test laboratory result and without a single national independent auditor or regulator. It all lives only in the well known inbred, fad-driven world of peer review.
You can read the full interview at: http://oilprice.com An-Interview-with-Judith-Curry
 
Share this...FacebookTwitter "
"Milikini Failautusi, 30, lives on the Pacific island of Tuvalu. She has become virtually a nomad in her own country after rising tides forced her to leave her ancestral atoll and move to the main island, Funafuti. She is now a climate activist. She can no longer visit her home island, yet remains committed to her country with a burning desire to prevent her own children from inheriting an underwater ghost town. This is not just Milikini’s story.  While climate change threatens livelihoods and security around the world, it is women who are bearing the brunt. Women predominate in the workforces of many sectors that are most vulnerable to climate change such as agriculture, livestock and fishing. To make things worse, inequalities mean women are more likely to suffer dislocation to their lives as a result of flooding and drought. According to the UN, about 80% of people displaced by climate change are women. More than 70% of those displaced by the 2010 flooding in Pakistan were women and children. Among those who lost their lives in India, Indonesia and Sri Lanka as a result of the 2004 Indian Ocean tsunami, three times more women died than men. But why? Rigid gender roles in the region meant men in the region were more likely to be able to swim than women. Furthermore, women were more likely to be caring for children and family members during the critical evacuation time. Women who do survive such disasters often end up in unclean evacuation centres where they can be exposed to gender-based violence and cannot access health services. Research by the International Union for Conservation of Nature found climate change and environmental impacts are increasing violence against women and girls including domestic abuse, child marriage and sexual assault. In many societies, encouraging progress is being made towards gender equality, but climate change can stop or even reverse this progress. If business-as-usual climate action continues, there are dangers that the gains of gender equality will be lost. There is a risk that as climate change accelerates, gender roles could become more entrenched. More men may be forced to move in search of better job opportunities, while women are left behind to care for members of their extended families and bear the burden of household responsibilities. Those who have to remain in more disaster-prone or vulnerable locations as a result are then likely to experience greater poverty, have their livelihoods destroyed and suffer increasing health issues. We know that any attempts to restore environmental degradation and lower the risks posed by global heating are likely to fail if they do not take into account gender inequality. We know, from a report published last week by WaterAid, that climate finance is still not reaching the poorest and most vulnerable people, who are likely to be most affected by climate change. – about half of all countries receive less than $5 (£3.86) a year for each person.  In 2016, a UN report found that only 0.01% of all worldwide funding went towards projects addressing both climate change and gender, despite specific provisions in the 2015 Paris agreement for women’s empowerment.  Such statistics are sobering, but there are some encouraging signs of progress. Developed countries have pledged $100bn a year in climate finance by 2020 to help developing nations cut emissions and adapt to problems such as worsening droughts, flooding and sea-level rise. The Green Climate Fund, the main channel through which climate finance is dispersed, stipulates that all grants must treat women’s needs as a priority. The Commonwealth Climate Finance Access Hub, based in Mauritius, is already making impressive progress in unlocking much-needed resources for countries and communities that would not otherwise have the capacity to lodge successful applications for funding already pledged.  At the Commonwealth heads of government meeting in Rwanda in June, we can expect leaders to consider further innovative approaches to tackle environmental priorities, including the strategy proposed by women’s affairs ministers, which focuses on gender and climate change. The strategy is designed to encourage countries to collect and analyse data disaggregated according to criteria such as sex and age in order to devise improved climate solutions and to target them more accurately. Women like Milikini need more than speeches, however sincere. They need urgent collective action to tackle all aspects and impacts of the global climate crisis. Women on the frontline must be on an equal footing at all levels so that they, their families, their communities and the nations in which they live and work can survive and thrive. In the Commonwealth, we are working towards just that."
"

Media Contact: (202) 789‑5200





WASHINGTON–On Wednesday, the Supreme Court will hear oral argument in _Massachusetts v. EPA_. Filed by a group of states and environmental groups, the case asks the justices to decide whether the Environmental Protection Agency must regulate American carmakers’ contributions to “global warming.” 



Cato scholars have filed two _amicus_ briefs on the EPA’s behalf, one addressing the scientific claims of global warming alarmists and the other addressing the legal questions in the case. The first, science‐​oriented brief, authored by Cato senior fellow Patrick J. Michaels and filed by the Competitive Enterprise Institute, questions the notion that global warming will exert a net negative impact on human health and welfare. 



“Our brief repeatedly stresses that no comprehensive analysis of the net costs and/​or benefits of reasonably projected climate change has ever been performed”, said Michaels. “Regulation without a commensurate basis in scientific fact is hardly what our founders, such as Thomas Jefferson, would have wanted”. 



Cato’s brief on the legal issues, filed on behalf of the Cato Institute by Cato lawyers Tim Lynch and Mark Moller, argues that federal law provides no mandate for global warming regulation and that the Constitution requires petitioners to direct their broad complaints about global warming to Congress, not courts. Cato’s brief is authored by environmental law professor Jonathan Adler and joined by law professors James L. Huffman and Andrew Morriss.



“The stakes in this case are very large,” explains Cato senior fellow Mark Moller, a co‐​counsel for Cato in the case. “If the petitioners win, American carmakers may face the equivalent of Kyoto global warming standards, imposed by judicial fiat, despite Congress’s umpteen rejections of the Kyoto regime. Complex regulatory decisions of this magnitude should be made by Congress, not federal judges.”
"
"
The only lower price than today’s closing price on a ton of carbon is ZERO
 
Perhaps reacting to the news yesterday about the IPCC getting taken to the woodshed, the growing number of stories in the MSM about the IPCC failure, and the recent layoffs at CCX, carbon trading has once again been devalued by the market. Amazingly, it lost 50% of it’s value for 2006, 2007, and 2008 “carbon instruments” today. Here’s the CCX front page graph at closing today: 

The CCX end of day table really says it all, 50% off, from a dime to a nickel in a day:
CCX end of day, August 31, 2010
It must have really killed the person to have to put in a nickel for the closing value today.
Charcoal briquettes and coal have more value than a ton of CCX carbon instruments these days.
Unless CCX starts making adjustments in single cents, the next downward adjustment is zero. The latest CCX advisory says they will be closed for labor day, and will reopen for trading September 7th. One wonders.

Sponsored IT training links:
Learn what is exactly need for LX0-101 exam. We offer self study 1z0-051 products including 412-79 dumps so you will pass real exam on first try.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89150f5f',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

In his State of the Union address, President Bush spoke a lot about energy independence and alternative energy sources such as ethanol. According to the president, ethanol is the magical elixir that will solve virtually every economic, environmental, and foreign policy problem on the horizon. In reality, it’s enormously expensive and wasteful. 



Untruths and misconceptions about ethanol include: 



**Ethanol will lead to energy independence.** If all the corn produced in America last year were dedicated to ethanol production (14.3 percent of it was), U.S. gasoline consumption would drop by 12 percent. For corn ethanol to completely displace gasoline consumption in this country, we would need to appropriate all U.S. cropland, turn it completely over to corn‐​ethanol production, and then find 20 percent more land for cultivation on top of that. 



The U.S. Energy Information Administration believes that the practical limit for domestic ethanol production is about 700,000 barrels per day, a figure they don’t think is realistic until 2030. That translates to about 6 percent of the U.S. transportation fuels market in 2030. 



**Ethanol is economically competitive now.** According to a 2005 report issued by the Agriculture Department, corn ethanol costs an average of $2.53 to produce, or several times what it costs to produce a gallon of gasoline. Without the subsidies, costs would be higher still. A study last fall from the International Institute for Sustainable Development found that ethanol subsidies amount to $1.05-$1.38 per gallon, or 42 percent to 55 percent of ethanol’s wholesale market price. 



**Ethanol reduces gasoline prices.** If you lived in California and other areas that used reformulated gasoline last summer – that’s the environmentally “clean” gasoline required for areas with air pollution problems, and that’s where most of that ethanol went – you might have paid up to 60 cents a gallon more for gasoline than you would have otherwise. That’s because the federal government required oil refineries to use 4 billion gallons of ethanol in 2006 regardless of price, and gasoline pump prices last summer reflected the fact that ethanol was twice as expensive as wholesale conventional gasoline. 



**Ethanol is a renewable fuel.** According to a group of academics from UC Berkeley who published in _Science_ magazine last year, 5 percent to 26 percent of the energy content of ethanol is “renewable.” The balance of ethanol’s energy actually comes from the staggering amount of coal, natural gas and nuclear power necessary to produce corn and process it into ethanol. 



**Ethanol reduces air pollution.** A review of the literature by Australian academic Robert Niven found that, when evaporative emissions are taken into account, E10 (fuel that’s 10 percent ethanol and 90 percent gasoline, the standard mix) increases emissions of total hydrocarbons, nonmethane organic compounds, and air toxics compared to conventional gasoline. The result is greater concentrations of photochemical smog and toxic compounds. 



**Ethanol reduces greenhouse gas emissions.** At best, E10 reduces greenhouse gas emissions by from zero to 5 percent; pure ethanol by 12 percent. The International Energy Agency, however, estimates that it costs about $250 to reduce a ton of greenhouse gases this way, or more than 10 times what Yale economist William Nordhaus thinks is economically sensible given the economics of climate change. Ethanol as an anti‐​warming policy is what academics refer to as “crazy talk.” 



**Ethanol subsidies are necessary to “level the playing field.”** Petroleum subsidies are something less than $1 billion a year – six to eight times less than ethanol subsidies – and work out to about 0.3 cents per gallon. 



**Switchgrass (aka, “cellulosic ethanol”) will set us free.** Guy Caruso, the head of the EIA, noted in a speech last December that the capital costs associated with cellulosic ethanol production were five times greater than those associated with conventional corn ethanol production. Estimates like that are a bit soft, however, because there is no cellulosic ethanol industry in existence at present, so data is hard to come by. Betting the farm on an industry that doesn’t yet exist to produce a product that is known to be staggeringly expensive isn’t the best use of tax dollars. 



If ethanol has commercial merit, it doesn’t need the subsidy. If it doesn’t, no amount of subsidy will bestow it. And that’s the truth. 
"
"**Leicester and Leicestershire will be subject to the toughest tier of restrictions after the national lockdown ends on 2 December.**
The city and county will move from tier two to three, meaning very high risk, the government announced.
It means household mixing is banned and pubs and restaurants will close except for delivery and takeaways.
The city and parts of the county were subject to the UK's first local lockdown in June.
The neighbouring county of Rutland will go into tier two of the government's three-tier system.
Leicester has been subject to some level of coronavirus restrictions since the first national lockdown in March.
The government has set out the reasoning behind the tier decisions for each area.
In a written ministerial statement, the government said of Leicester and Leicestershire: ""Improvements have been seen in overall case rates in all but one lower tier local authority, but remain very high at 355 per 100,000, including in over 60s at 250 per 100k. The pressure on the local NHS remains very high.""
Health Secretary Matt Hancock told the Commons: ""I know how tough this is, both for areas that have been in restrictions for a long time like Leicester and Greater Manchester, and also for areas where cases have risen sharply.""
The system will be regularly reviewed - with the first scheduled for 16 December.
The new allocations will put some areas under significantly tighter restrictions than before the second lockdown started.
Places like Market Harborough and Lutterworth have managed to remain in tier one since the system was first introduced, but they along with the rest of the county will go into tier three.
Reacting to the news, the county's director of public health Mike Sandys said: ""Over the past few days, rates have started to fall and we've made some progress. But it's important to put this into perspective.
""Figures are over 20% down compared to this time last week but they're still worse than the day we went into lockdown.
""Leicestershire's average is significantly higher than the national level so there is still work to do.""
In a joint statement, the three Labour MPs for the city - Claudia Webbe, Liz Kendall and shadow health secretary Jonathan Ashworth - said: ""The news that Leicester will go into tier three - on top of the 150 days of our extra lockdown - is extremely difficult to hear.
""The government must now spell out how we can get out of tier three, and the measures they will use to review Leicester's position, to give people hope their sacrifices will make a difference.""
Meanwhile, the Conservative MP for Rutland and Melton said she is pleased about the decision to put Rutland into tier two.
Alicia Kearns said: ""I welcome that Rutland has been respected as the independent county it is and therefore tiered separately.""
But she added she was ""deeply disappointed"" the likes of Melton and Harborough had been grouped with all of Leicestershire.
Leicester had a seven-day coronavirus infection rate of 398.3 per 100,000 people for the week to 21 November - the 14th highest rate in England.
The number of confirmed cases in the same week was 1,411, down from 1,857 in the seven days up to 14 November. The infection rate is also down from 524.2.
The borough of Oadby and Wigston has the county's highest rate of 417.4 - putting it 11th nationally - but the rate has also decreased from 526.2.
The average for the whole of England is 208.7.
The Christmas lights might be up in Leicester, but let's be honest, not many people are going to see them.
It has the title that no city wants - it has been in Covid-restrictive measures for longer than anywhere else in the country.
Today's news from Health Secretary Matt Hancock has confirmed what Leicester's mayor Sir Peter Soulsby and many people here feared - that the city is going into the highest tier.
That's tough news for those here and means it has been eight months since people have not been allowed to have family and friends in their homes.
Some non-urgent operations in Leicester have been cancelled, with one local health boss fearing the second wave of the virus will be worse than the first.
The Leicester, Leicestershire and Rutland's clinical commissioning groups (CCGs) said their hospitals were treating 260 people with coronavirus, compared with 204 at the peak in April.
Last week Leicester mayor Sir Peter Soulsby said the ""hopeless"" performance of the national test and trace system had contributed to the recent surge in city cases.
Both the city and county have been sent thousands of rapid result lateral flow tests to help bolster Covid-19 testing.
_Follow BBC East Midlands on_Facebook _,_Twitter _, or_Instagram _. Send your story ideas to_eastmidsnews@bbc.co.uk _._"
nan
"I have eagerly awaited the final season of Game of Thrones, and its strange blend of fictive medieval Britain, supernatural monsters and pornography. Over the seasons the plot has gained speed and focus while the pornography has vanished and – incredible as it seems – we can also detect that George R.R. Martin’s fantastic story has a message. Perhaps we can explain its enormous success by considering how, at a subconscious, dreamlike level, it deals with humanity’s most profound problem. I want to believe that my interpretation is more than a pathetic attempt to legitimise all those hours of passive TV-watching. Just as the great anthropologist Claude Lévi-Strauss was able to expose central problems of specific Amerindian peoples by analysing their myths, we can analyse our own tales in order to discern the contradictions and apparently unsolvable dilemmas that torment our subconscious.  What Lévi-Strauss called “mythemes” are abstractions of central elements of stories – the basic themes which express their essential messages. Using his method for dissecting myths, we can unearth submerged meanings in fantasy and science fiction. And these dreamy worlds tell us more about ourselves than we generally realise. Film director James Cameron’s blockbusters Aliens (1986) and Avatar (2009), for instance, reflected a fundamental transformation in the predominant worldview of movie audiences. In the quarter of a century that separated the two movies, the signs had been reversed regarding nature, diversity and technology. In the final scene of Aliens, Sigourney Weaver – inside a machine which gives her superhuman strength – battles with a monstrous organism from another planet. With the help of technology she defeats an evil Nature. The monster from outer space symbolises an untamed and threatening biological diversity. Only with the help of the machine can humankind survive. Two decades later the roles were reversed. The final scene in “Avatar” instead shows an evil male capitalist, dressed in similar technological armour, being defeated by a benevolent Nature. The entire ecosystem of the planet Pandora is mobilised in the battle against the human exploiters. Now it is the machines, rather than the monsters, who come from another planet. In this story, technology loses the battle against nature. Only by stopping the machine can nature survive. A similar analysis reveals the real threat against the warring medieval kingdoms in Martin’s imaginary continent of Westeros. The White Walkers’ army of dead beings threatening to destroy the world of humans, accompanied by ongoing climate change (“winter is coming”), is an allegorical representation of fossil fuels. Today, the energy that propels our technological civilisation derives from countless billions of dead organisms whose extinguished sparks have been buried in the Earth’s crust. The metaphor is not at all far-fetched: in both cases, fossil energy is at war with life itself. Fear of the Night King’s murderous corpses could of course be interpreted simply as the existential fear of death which might unite all people. But the connection between the dead army and climate change is sufficiently distinct to make a more political allegory convincing. The forces animating the dead beings threaten to lead to the collapse of civilisation as a whole, beyond the lives of individual humans. As smuggler-turned-knight Davos Seaworth points out to Daenerys: “If we don’t put aside our enmities and band together we will die. And then it doesn’t matter whose skeleton sits on the Iron Throne.” Although the intuition that the approaching White Walkers’ winter could be seen as a metaphor for climate change may be fairly widespread among followers of Game of Thrones, the literal identification of dead (fossil) energy as a lethal threat to humanity appears to have escaped most analyses. The army of zombies evokes modern society’s stock of machines animated by long-dead inorganic energy in the form of coal, oil or gas. Like pre-modern people confronted with such technical contraptions, the inhabitants of Westeros are shocked by the magical capacity of dead objects to move and to wage war on the living. George R.R. Martin’s message is that the continuous human competition for power must be set aside in a joint effort to defeat the threat from the army of the dead. The message from Game of Thrones appears familiar and urgent at a time when humanity is subconsciously struggling with its paradoxical ability to sweep the climate crisis under the carpet while preoccupying itself with everything else. As in a dream, we try to make sense of the contradiction between our awareness of the approaching catastrophe and our remarkable capacity to ignore it. Dreams and fantasies prompt us to reflect on matters that we suppress. In that sense, Game of Thrones is a tale for our times. Read more: Game of Thrones: why hasn’t Westeros had an industrial revolution?"
nan
"When my six-year-old daughter is stressed she bites her fingernails. Children in maths lessons often respond to the anxiety that doing mathematics causes by swinging their legs. Arturo the polar bear at Mendoza Zoo in Argentina responds to stress by pacing up and down whilst swinging his head from side to side.  So why does Arturo’s abnormal behaviour lead to outcries concerning his psychological well-being? The difference between Arturo and my daughter or reluctant children in maths lessons is that that the stress-related behaviour is no longer related to its triggers. What does this expression of abnormal behaviour from Arturo tell us about his psychological state? Such behaviour in animals is indicative of a state of poor welfare. In effect, his behaviour tells us there is something wrong. It is common to see such behaviour in animals kept in un-stimulating environments such as barren cages in poor quality zoos. Referred to as stereotypic behaviour, defined by its repetitive movements, unvarying and with no apparent function, it may indicate that the animal is depressed. Studies have shown that changes in the brain chemistry of certain animal species performing such behaviours are similar to those observed in the brains of depressed humans. Infamously, in the 1990s the Calgary Zoo tried to treat its stereotypic polar bears with Prozac. Stereotypic animal behaviour often looks like obsessive compulsive behaviours in humans, and certain types of abnormal behaviour such as body rocking, pacing, skin picking and hair plucking are common to distressed animals and humans. In fact, Kathy Carlstead at the Honolulu Zoo once made a documentary on abnormal behaviour in captive bears and afterwards received letters from American prisoners saying they did the same thing when locked in their cells.   Some anti-zoo protesters have tried to claim that such abnormal behaviour shows that animals are going mad. This is going too far. These animals are using a strategy to cope with a situation that has negatively affected their sense of well-being. In fact there is behavioural and physiological evidence that this is, in fact, a coping strategy, possibly mediated through the release of neurotransmitters that make creatures feel better. For example leg swinging by children in class is a natural beta-blocker, reducing heart rate and making them feel less anxious.  Thus, some argue the animal is coping with its environment. A university professor and the father of two small children, I can cope with lots of stress over prolonged periods of time, but no-one – least of all I – would argue that such a situation is good for my well-being (whether or not I mitigate the sense of the walls closing in by pacing around my office). A lot of my sense of well-being is highly dependent on how I see my situation.  Is the glass half empty or half full?  This is something easy to ask a human, but we cannot ask an animal. Mike Mendl at the University of Bristol came up with a simple method to find out animals’ attitudes. He trained animals that if they went to a point on one side of a room they would get a reward from a bucket, and if they went to the other side the bucket would contain something unpleasant.  Placing the bucket in the middle of the room between the two points creates an ambiguous situation. An animal that runs quickly towards the bucket therefore feels there will be something worth having, despite the lack of evidence either way – an optimistic outlook. Mendl found that animals from enriched, stimulating environments run more quickly towards the bucket than those from barren environments. Dogs that wreck their owner’s home when left alone only slowly approach the ambiguous option compared to those that are not home-wreckers. The test gives an opportunity to sense an animal’s outlook, whether optimistic or pessimistic. The well-being of animals is not a simple thing to measure or define, and so it is very difficult to encapsulate in law. In the UK, animal welfare laws are based on the Five Freedoms, which require that animals must be free from hunger and thirst; discomfort; pain, injury or disease; fear and distress; and should be free to express their natural patterns of behaviour. Should any of these freedoms be restricted, it’s fair to say the animal’s well-being is eroded. I run 8km every morning because prevention is better than cure; the same applies to animal welfare – we need to avoid animals developing problems, and this can be done by applying the Five Freedoms and by ensuring rich environment for them to inhabit. Animals with welfare problems like Arturo can be helped by this approach, but it may be that their view of the world is too dark to fully recover."
"Over the past few years I have become an academic expert in “sewage sludge” – the residual, semi-solid mix of excrement packed with microorganisms that is left behind within wastewater treatment plants. Every year the UK alone produces approximately 1.4m tonnes of the stuff. About 80% of it is spread on fields as manure, but this still leaves us with a headache – what do we do with the rest? Despite widespread recognition that a proper management plan is needed, there is one major hurdle that still needs to be overcome. Sludge is near-worthless, in terms of monetary value, and sewage companies sometimes struggle even to give it away. A big part of the problem is that sewage sludge from different treatment plants can have wildly different nutrient values. Not having a product with consistent characteristics significantly undermines its value, especially for agriculture, as farmers could never be sure what it is they’re actually buying. Another problem is that when stacked up against the competition, it’s actually quite poor as fertiliser. Both food waste and manure from farm animals serve the purpose much better and contain fewer pollutants that can find their way into the food chain. So, what should we do with the sludge? After all, we have to do something. In many cases across Europe, the water utility companies simply pay for final disposal or give it away free to farmers – a cost which is no doubt passed on to the farmers’ customers. Even in cases where the utilities manage to actually sell the treated sewage sludge, they do so at a rock bottom price of between £1 and £2 per tonne. That’s a very poor return when you consider the cost of processing a tonne of dry sludge can be £200 or more.  What about just burning it then? It’s not very environmentally friendly, sure, but could it be a solution? The burning of feedstock such as sewage sludge results in the production of energy which is measured in calories. The more calories, the more energy that is produced. Well, even “dewatered” sludge contains approximately 75% water, which means energy is required to evaporate it. And even once it’s dried out, 1 kg of dried sludge contains only 3,300 kilocalories (kcal) of energy – far less than the 4,500 kcal found in 1 kg of food waste, or even the 8,300 kcal found in 1 kg of car tyres. Consequently, incineration is not an attractive option for sewage sludge. Luckily though, when we look at sludge as the sum of its parts, the picture becomes slightly more optimistic. Around 2 to 4% of sludge contains phosphorus, from which struvite – the substance kidney stones are made out of – can be recovered and sold for as much as £300 per tonne for use as fertiliser. Calcium carbonate too is found in significant quantities. The cellulose contained in flushed toilet paper is also recoverable for those with the will to recover it, as is the organic content of sewage which can be recovered as bioplastic, a valuable alternative to conventional, petroleum-derived plastics. Both are expensive to extract, however. The adoption of extraction technology could also be helped along by increasingly strict limits on the use of phosphorus in fertilisers. In fact, a recent EU proposal to regulate fertilisers included manure and food waste collected at source, but excluded compost derived from sludge. Sewage sludge contains phosphorus, mostly from detergents used for washing clothes and dishes. This phosphorus is much more valuable than sludge and could eventually be used in agriculture. Could we therefore be about to see the birth of a booming sludge industry? Could wastewater treatment plants become producers of brown gold? Maybe. Maybe not. There are currently a plethora of directives, codes of practice, quality protocols, publicly available specifications and assurance schemes covering the different aspects of sludge, each of which adds an additional layer to an already complex legislative framework. Such complexity is a deterring factor for investors and makes attracting new players tricky. However, there is enough value in sludge that, with the right will and effort, we can start to put it to really positive use. While few people like to think about what happens after we pull the flush, working out what to do with the waste is of real importance. We need to work out how best to extract the value out of sludge, because at the moment it’s literally being flushed down the toilet."
"

A few days ago, the British government released the Stern report, a voluminous study arguing that the costs associated with stabilizing carbon dioxide concentrations at 550 parts per million were far less than the costs associated with doing nothing. Although the study acknowledged rather large bounds of uncertainty, the median estimates therein suggested that business as usual (that is, we do nothing) would mean a loss of 5–10% of global GDP every year forever. Most of those harms, however, could be avoided if we spent 1% of global GDP to cut back on greenhouse gas emissions.   
  
There are very good reasons to suspect that Stern's estimates regarding the cost of cutting back on greenhouse gas emissions are too low and that the damages forecast by Stern are too high. The underlying assumptions of the analysis producing Stern's estimates have been well dissected by statistician Bjorn Lomborg, climate scientist Roger Pielke, Jr., and economist Richard Tol. But for the moment, let's put those complaints aside.   
  
My colleague Peter Van Doren and I have done three present value calculations assuming that business as usual (BAU) will reduce global GDP by 2%, 5%, and 10% beginning in 2056 and then in each and every year through the end of time. Don't worry about the silliness of such a proposition. Oddly enough, once you try calculating beyond 200 years, the numbers don't really change much given the need to discount future costs and benefits by 5%.   
  
First, we calculated the cost of using 1% of GDP every year through the end of time to reduce greenhouse gas emissions. The net present value of that cost is $15,541 per person in the United States.   
  
Then, we calculated the benefits for U.S. citizens (global GDP figures are pretty dodgy, so we stuck with U.S. GDP figures for the purposes of this exercise). They amount to $36,447 is you accept -10% GDP as your BAU scenario, $18,239 if you accept -5% GDP as your BAU scenario, and $7,295 if you accept -2% GDP as your BAU scenario.   
  
In other words, Stern's investment advice makes sense only if you think that warming will hammer GDP by 10% a year. You don't gain much at all from emission cuts, however, if you think GDP will only drop by 5% a year if we do nothing. And if you think warming will only cost the global economy 2% of GDP every year (the ""concensus"" belief among economists, which comes from a widely cited analysis from Yale economist William Nordhaus), then Stern's investment advice is shere lunacy.   




And that's not even taking into consideration the fact that reducing greenhouse gas emissions might produce no benefits at all. The latest IPCC report — as all other reports before it — acknowledge that the evidence that anthropogenic emissions are primarily driving the warming we’ve detected is strong but circumstantial. Scientists disagree about how large the chances are that we're wasting our time cutting greenhouse gas emissions, but there’s no disagreement within the latest IPCC report that there’s a chance that anthropogenic emissions are not particularly important factors in climate at present.   
  
Is global warming insurance a good buy? Probably not. And that's particularly true given the fact that the relative poor (us) will pay the premium so that the relatively rich (our children and grandchildren) will get the benefits if there are any. For example, since 1950 real GDP per capita has increased by about 2% per year. Given that growth rate, U.S. GDP per capita in 100 years would be $321,684 in current dollars, or more than seven times higher than it is at present ($44,403). If global warming cuts GDP by even 10%, then GDP per capita will be $289,515 in 2106 rather than $321,684. Would anyone, let alone liberals, ever propose a 1% tax on those who make $44,000 to create benefits for those who make $289,000?


"
"
Borrowing a phrase from NSIDC’s Dr. Mark Serreze, Phytoplankton are now apparently in a “Death Spiral”. See Death spiral of the oceans and the original press release about an article in Nature from a PhD candidate at Dalhousie University, which started all this. I’m a bit skeptical of the method which they describe in the PR here:
A simple tool known as a Secchi disk as been used by scientists since  1899 to determine the transparency of the world’s oceans. The Secchi  disk is a round disk, about the size of a dinner plate, marked with a  black and white alternating pattern. It’s attached to a long string of  rope which researchers slowly lower into the water. The depth at which  the pattern is no longer visible is recorded and scientists use the data  to determine the amount of algae present in the water.
Hmmm. A Secchi disk is a proxy, not a direct measurement of phytoplankton. It measures turbidity, which can be due to quite a number of factors, including but not limited to Phytoplankton. While they claim to also do chlorophyll measurements, the accuracy of a SD measurements made by thousands of observers is the central question.

From the literature: The Secchi disk transparency measurement is  perhaps one of the oldest and simplest of all measurements. But there is  grave danger of errors in such measurements where a water telescope is  not utilized, as well as in the presence of water color and inorganic  turbidity (source: Vollenweider and Kerekes, 1982). I’ll have more on this later. – Anthony
======================================================
Diatoms are one of the most common types of phytoplankton.
Phytoplankton need cap and trade
By Steve Goddard
Yesterday, Joe Romm reported :
Nature Stunner: “Global warming blamed for 40% decline in the ocean’s phytoplankton”
“Microscopic life crucial to the marine food chain is dying out. The consequences could be catastrophic.”
That sounds scary. Does it make any sense? Phytoplankton thrive everywhere on the planet from the Arctic to the tropics.  One of the primary goals of this year’s Catlin expedition was to study  the effect of increased CO2 on phytoplankton in the Arctic. They reported:

Uptake of CO2 by phytoplankton increases as ocean acidity increases
That sounds like good news for Joe!  We also know that phytoplankton have been around for billions of years, surviving average global temperatures 10C higher and CO2 levels 20X higher than the present.

http://ff.org/centers/csspp/library/co2weekly/2005-08-18/dioxide.htm
Phytoplankton growth/reduction in the tropics correlates closely with ENSO. El Nñio causes populations to reduce, and La Niña causes the populations to increase.
During an El Niño year, warm waters  from the Western Pacific Ocean spread out over much of the basin as  upwelling subsides in the Eastern Pacific Ocean. Upwelling brings cool,  nutrient-rich water from the deep ocean up to the surface. So, when  upwelling weakens, phytoplankton do not get enough nutrients to maintain  their growth. As a result, surface waters turn into “marine deserts”  with unusually low populations of phytoplankton and other tiny  organisms. With less food, fish cannot survive in the surface water,  which then also deprives seabirds of food.
During La Niña conditions, the opposite effect occurs as the easterly  trade winds pick up and upwelling intensifies, bringing nutrients to the  surface waters, which fuels phytoplankton growth. Sometimes, the growth  can take place quickly, developing into what scientists call  phytoplankton “blooms.”
The phytoplankton must be loving life now!

The author of this study (Boris Worm) also reported last year “if fishing continued at the same rate, all the world’s seafood stocks would collapse by 2048”
So we know that phytoplankton have survived for billions of years in a  vast range of climates, temperatures and CO2 levels. Apparently they  have become very sensitive of late – perhaps from all the estrogens  being dumped in the oceans? Or maybe they have been watching too much  Oprah?
The standard cure for hyperventilation is to increase your CO2 levels by putting a bag over your head.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a3de143',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**The North East will face the toughest Covid-19 restrictions**when the national lockdown ends **, it has been confirmed.**
All 12 council areas across the region will be placed under tier three from 2 December.
Residents will still be banned from socialising indoors with people they do not live with, apart from support bubbles.
Pubs and restaurants will remain closed except for delivery and takeaway.
The government has set out the reasoning behind the tier decisions for each area in a written ministerial statement.
The news, while not unexpected, will come as a blow to the region's hospitality industry.
Helen Greer, landlady of The Feathers Inn pub in Stocksfield, Northumberland, had to adapt during the second lockdown by offering takeaways and also opened a Christmas shop to keep her business going.
""It's just exhausting, it's exhausting mentally, it's exhausting physically,"" she said.
She added that being placed in tier three long-term would be ""financially horrendous"" and tier two would be a ""non-viable"" model.
""Tier three is going to be hard because it means we have to continue doing the takeaway and that's not easy because we are a rural pub, we are long way from big centres of people, so it's difficult.""
Hotels in tier three will also have to close.
Bed and breakfast owner Claire Shield, who only opened her business this year in Newton-by-the-Sea, Northumberland, said it was the ""not knowing"" that was difficult.
""I was on a bit of a high yesterday, briefly, and then when tier three was announced again today it was back down again. Even though it was expected it was just actually hearing it, and thinking 'ok, here we go again'.""
South Shields Labour MP Emma Lewell-Buck told the Commons hospitality in the town was going to be ""absolutely battered"".
Health Secretary Matt Hancock, urged her to work with local authorities to ""embrace"" community testing, in order to help the North East out of tier three.
The government has released a list of the restrictions each tier area will face, although shops, hairdressers and gyms will be allowed to reopen.
Some rules will be relaxed at Christmas to allow three households to form a bubble.
North East areas affected:
Other areas of England, including Cumbria, have been put into tier two, while just three areas will be in the lowest level of restrictions.
Labour Chief Whip and Newcastle East MP Nick Brown has written to Mr Hancock to ask why Newcastle had been put in tier three, despite it having a lower infection rate than Havering in London, which will be tier two.
Martin Gannon, leader of Labour-controlled Gateshead Council, said councils had ""simply been told"" what was happening and there had been no negotiation.
Covid infection rates across the region have been falling over the past week, according to government figures.
Conservative Stockton South MP Matt Vickers tweeted that while he was not surprised the area had been placed in tier three due to the number of cases, it was ""bitterly disappointing"".
Mr Hancock thanked people for the ""hard work and sacrifice"" which allowed England to move out of a national lockdown.
""I know for those of you faced with tier three restrictions this will be a particularly difficult time but I want to reassure you that we'll be supporting your areas with mass community testing and extra funding,"" he said.
Tier allocations will be reviewed on 16 December, allowing for ""the possibility of areas which continue to make progress in slowing the spread of the disease"" to be moved down a tier before Christmas, the government said.
Unlike some parts of England, spectators will not be allowed back into football stadiums or to other large events.
Residents will still be banned from socialising indoors with anyone outside their household or social bubble, although people will be allowed to meet in groups of up to six in outdoor public spaces, and non-essential shops will reopen.
Redcar and Cleveland Borough Council's leader Mary Lanigan, an Independent, acknowledged that the local infection rate had ""been too high"".
""The ongoing restrictions put a huge strain on people's lives and threaten the prosperity of our borough as businesses cannot trade freely or plan with any confidence for the future,"" she said.
In a joint statement, local authority leaders across Tyneside, Wearside and Northumberland reminded residents that infection rates remained high, particularly as shops prepare to reopen.
However they said that despite the region being put into tier three, the national lockdown did not count for nothing, as rates did fall.
""The reopening of shops and retail outlets is certainly welcome but we know this will result in busy town and city centres as people head out for their Christmas shopping,"" they said.
""It is important that we support local independent businesses and if you head to the larger, busier outlets please follow the guidance and stick to hands, face, space at all times.""
_Follow BBC North East & Cumbria on _Twitter _,_Facebook _and_Instagram _. Send your story ideas to_northeastandcumbria@bbc.co.uk _._"
"
Share this...FacebookTwitterFood prices have been in the headlines lately, with more than enough stories blaming the crop shortages on climate change. That’s what the German greens would like to have us believe.
Today, with huge swaths of land being covered and devoured by industrial-scale biofuels agriculture and food prices rapidly climbing to politically dangerous levels, the greens are now calling for an end to biofuels. This marks a course reversal for the greens, though they refuse to admit it. Indeed, just a few years ago, the greens ignored all the warnings and were big proponents of biofuels: They played the key role in mandating the disastrous biofuels debacle in Germany.
Jan Fleischhauer of Der Spiegel recently wrote:
Anyone expecting an apology from the responsible persons, or at least an admission they had gotten carried away by their eco-optimism, does not know the greens very well. Even the hardest of realities are no match against the green conscience.”
Fleischhauer reminds us how in November, 2005, German Green party boss, then Minister of Environment, Jürgen Trittin said:
Fields will become the oil wells of the 21st century, the farmer will become an energy businessman.”
In the same year, green Minister of Agriculture Renate Künast boldly proclaimed:
We want to clear the way for farmers for biofuels, and to accelerate their introduction to the market.”
This, of course, was done through massive subsidies and mandating Germany’s E10 ethanol fuel.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Bärbel Höhn, a green leader of North Rhine Westphalia, Germany’s most populated state, went so far, Fleischhauer writes, to declare “bioenergy as a national security issue” because oil is a raw material that wars have been fought over time and again, and thus she ranked the promotion of bioenergy as having crucial importance for German society. It was: “World peace through German biogas,” Fleischhauer writes, sarcastically.
Today no greens want to be reminded of their enthusiastic support for burning food in gas tanks while the world’s poor go hungry.
Renate Künast (far right)
Renate Künast recently told an audience of millions, with a straight face, on Germany’s ARD public television: “We were always against E10”. (E10 is now on the verge of being eliminated after years of failure).
Now that the greens have changed their minds and suddenly “have always been” against agrofuels, they need to come up with an alternative. No problem, Bärbel Höhn has a new solution: Fuel from wild herbs! Fleischhauer writes:
‘Fields of flowers instead of corn’, is the new slogan. Let’s hope this does not again turn into yet another state reform program. Otherwise picking dandelions will be fined soon – for violating the energy security of the Federal Republic of Germany.”
The greens have run out of ideas.
Also read:
http://www.spiegel.de/international/business/drought-not-the-only-factor-driving-up-agricultural-prices-a-851068.html
 
Share this...FacebookTwitter "
"**Politicians in Lancashire have reacted angrily after the whole county was placed into the highest tier of restrictions.**
Council leaders had asked for it to be split into different tiers to reflect lower Covid-19 rates in parts of central, west and north Lancashire.
Lancaster and Fleetwood MP Cat Smith said she was ""furious"". South Ribble Borough Council leader Paul Foster said he was ""livid"".
Lancaster City Council is calling for local not regional assessments.
From Wednesday, when the national lockdown ends, Lancashire will be in tier three.
It means people can only meet other households in outdoor public spaces where the rule of six applies and hospitality businesses like pubs, bars and restaurants will have to stay closed.
Gyms and close-contact beauty services like hairdressers will be able to open in all tiers.
Health Secretary Matt Hancock set out the reasoning behind the tier decisions in a written ministerial statement.
The government said the system would be regularly reviewed and an area's tier level may change before Christmas, with the first review scheduled for 16 December.
Council leaders had requested areas with lower infection rates such as Lancaster, Blackpool and the Fylde and Chorley go into tier two, while Blackburn with Darwen, Hyndburn, Rossendale, Burnley, Pendle, Preston - where cases are higher - go into the top tier.
The latest data show Hyndburn had 432 cases per 100,000 people for the week to 21 November. Burnley had 362, Chorley had 211, while Lancaster had the county's lowest number of infections, with 97 cases per 100,000.
A spokesperson for the Department of Health and Social Care said: ""While there have been improvements in some areas, case rates and the proportion of tests which are positive for Covid-19 remain high.
""Case rates in over 60s are very high (over 200 per 100,000) in six lower tier local authorities. There is still pressure on the NHS in this region.""
Councillor Lynn Williams, leader of Blackpool Council, said the authority was ""bitterly disappointed"", adding that tier three status was ""inappropriate"".
""The government has not recognised the significant improvements we have made in reducing infection rates - or the impact tier three will have on our economy and people's livelihoods,"" she said.
""It is difficult to see how we can ever exit tier three if we are always going to be tied into areas of the county that do not have comparable circumstances.""
Labour MP Cat Smith tweeted she was ""furious"" Lancaster and Fleetwood had been put in tier three.
She added: ""Lancaster has a lower infection rate than all bar one London borough. Yet London has been put into tier 2. This makes no sense.""
The Labour leader of Lancaster City Council, Dr Erica Lewis, is calling for a reassessment, ""based on local figures and local risk"".
She tweeted: ""We did not deserve tier 3.
""The campaign for a local rather than regional assessment starts now.""
South Ribble Borough Council leader Paul Foster, who also represents Labour, tweeted: ""I'm livid."" He said cases of the virus in central Lancashire were ""decreasing significantly"".
""This news provides no hope for so many.""
Conservative leader of Wyre Council, David Henderson, said he had proposed the west of Lancashire be placed into tier two so being placed in tier three was ""very disappointing""
He thanked Wyre residents ""for their sacrifices and commitment to sticking to the guidance.""
The tiers would be reassessed in two weeks, he said, adding: ""We must now take this time to bring down the rates even further"".
Preston council leader, Labour's Matthew Brown said he was ""really disappointed"" and worried about the ""continued effect"" it would have on residents and struggling businesses.
A pub owner from Bamber Bridge, Preston, described the news as a ""disaster"" for hospitality.
""It's a massive blow for the hospitality industry,"" Sarah Locke, owner of Ye Olde Hob Inn, said.
""I wish we were put in tier two. This is the busiest time of year and we are back into the unknown again,"" she added.
""Pub owners are stuffed; many won't survive.""
_Why not follow BBC North West on_Facebook _,_Twitter _and_Instagram _? You can also send story ideas to_northwest.newsonline@bbc.co.uk"
"Decades of chronic underfunding of water infrastructure is putting many countries at worse risk in the coronavirus crisis, with more than half the global population lacking access to safely managed sanitation, experts said as the UN marked World Water Day on Sunday. Good hygiene – soap and water – are the first line of defence against coronavirus and a vast range of other diseases, yet three quarters of households in developing countries do not have access to somewhere to wash with soap and water, according to Tim Wainwright, chief executive of the charity WaterAid. A third of healthcare facilities in developing countries also lack access to clean water on site.  “It’s really obvious that in Africa and parts of Asia we should be very fearful of what is to come,” he said. “The coronavirus crisis highlights how vulnerable the world is.” The UN World Water Development report, published on Sunday, pointed to the underfunding of water infrastructure around the world, despite its importance. Richard Connor, editor-in-chief of the report, told the Observer that water was often overlooked for spending and investment because the economic benefits of better water and sanitation were not emphasised. The coronavirus crisis sheds new light on those mistakes. “One of the reasons underlying the investment gap in water and sanitation is that these services are perceived mainly as a social - and in some cases environmental - issue, rather than an economic one, like energy,” he said. “Yet the economic costs of an outbreak [such as Covid-19] are enormous, both in terms of national economies and stock markets, as well as in terms of household revenue - when people cannot work because of sickness or lockdowns. Realising the economic importance of water and sanitation should provide an additional catalyst for greater investment.” Another reason for the neglect of water and sanitation is that people are generally willing to pay for the water coming into their homes, but not for transporting and treating afterwards. “Once it is flushed down the toilet, it disappears and becomes someone else’s problem,” said Connor. “Treating wastewater is several times more expensive than treating the source water in the first place. So without a willingness to pay on the part of users, it falls on governments to foot the bill, and since they do not recognise the economic value of wastewater treatment – which is perceived as more of an environmental issue - the political will behind such spending is low.” Yet improving access to water and sanitation has clear benefits – in the coronavirus crisis, and beyond. Connor quotes evidence that suggests that the return on investment in water and sanitation can be high, with a global average benefit–cost ratio of 5.5 for improved sanitation and 2.0 for improved drinking water, when broader macroeconomic benefits are taken into account. Water use has increased sixfold in the past century and is rising by about 1% a year owing to rising populations and increasing demand, while climate breakdown means that more areas of the world will see stress on their water supplies, including regions where supplies were previously abundant, such as many parts of Europe, Asia and north America. One possible source for renewed investment in water is through a better understanding of the links between water issues and water infrastructure and the climate crisis, the UN report suggests. While trillions in investment have been poured into reducing greenhouse gas emissions around the world in the last decade, through clean energy and low-carbon technology, few resources have been devoted to the water supply. This year’s UN water report has found that opportunities are being missed to use water projects to cut greenhouse gas emissions while improving access to clean water. Sewage treatment is a clear example: wastewater gives rise to between 3% and 7% of all greenhouse gas emissions globally, more than flying. Processing sewage can turn wastewater from a source of carbon to a source of clean energy, if the methane is captured and used in place of natural gas. Currently, between 80% and 90% of wastewater around the world is discharged to the environment with no treatment. Farming methods can also be adapted to use water more efficiently and cut carbon at the same time, because when soils are better managed they hold more organic matter, more carbon and more water – rendering them more fertile as well as sequestering greenhouse gases. That makes investing in water a “win-win-win”, in terms of improving people’s lives, generating economic growth and helping to cut carbon, the report found. Yet of the hundreds of billions in climate finance devoted to developing countries in recent years, projects involving water made up less than 1% in 2016, the latest year for which full figures were available, according to the report. “Water does not need to be a problem – it can be part of the solution [to the climate crisis],” said Audrey Azoulay, director-general of Unesco. “Water can support efforts to both [reduce greenhouse gases] and adapt to climate change.” Wainwright said the key ingredient for success in fixing the world’s water problems, alongside funding, was improving governance and how water supplies are managed. “Water needs good governance,” he said. “That is usually what is missing. The world is not running out of water, but there is water stress. There is competition for water resources, but making sure that the people who need water get it is a good investment.”"
"As ships resume the search for missing Malaysian Airlines flight MH370 in the depths of the Indian Ocean this week, we often hear that the oceans are “95% unexplored” and that we know more about the surface of the Moon or Mars than the ocean floor.  But is that true, and what do we really mean by “explored”? The entire ocean floor has now been mapped to a maximum resolution of around 5km, which means we can see most features larger than 5km across in those maps. That’s the resolution of a new global map of the seafloor published recently by David Sandwell of Scripps Institute of Oceanography in San Diego and colleagues, who used some nifty tricks with satellites to estimate the landscape of the sea floor and even reveal some features of the Earth’s crust lurking beneath sea-floor sediments. Unlike mapping the land, we can’t measure the landscape of the sea floor directly from satellites using radar, because sea water blocks those radio waves. But satellites can use radar to measure the height of the sea’s surface very accurately. And if there are enough measurements to subtract the effects of waves and tides, satellites can actually measure bumps and dips in the sea surface that result from the underlying landscape of the ocean floor. Where there’s a large underwater mountain or ridge, for example, the tiny local increase in gravity resulting from its mass pulls sea water into a slight bump above it. If instead there is an ocean trench, the weaker local gravity produces a comparative dip in the ocean surface. Reading those bumps and dips in the sea’s surface is an astounding feat of precision measurement, involving lasers to track the trajectory of the measuring satellite and inevitably a lot of maths to process the data. The new map uses data from the Cryosat-2 and Jason-1 satellites and shows features not seen in earlier maps using data from older satellites. The previous global map of the ocean floor, created using the same techniques and published in 1997, had a resolution of about 20km. So we do actually have a map of 100% of the ocean floor to a resolution of around 5km. From that, we can see the main features of its hidden landscape, such as the mid-ocean ridges and ocean trenches – and, in that sense, the ocean floor is certainly not “95% unexplored”. But that global map of the ocean floor is admittedly less detailed than maps of Mars, the Moon, or Venus, because of our planet’s watery veil. NASA’s Magellan spacecraft mapped 98% of the surface of Venus to a resolution of around 100 metres. The entire Martian surface has also been mapped at that resolution and just over 60% of the Red Planet has now been mapped at around 20m resolution. Meanwhile, selenographers have mapped all of the lunar surface at around 100 metre resolution and now even at seven metre resolution. To map the ocean floor back home in greater detail, we have to use sonar instead of satellites. Modern sonar systems aboard ships can map the ocean floor to a resolution of around 100 metres across a narrow strip below the ship. Those more detailed maps now cover about 10%-15% of the oceans, an area roughly the size of Africa. Mapping from ships at the level of detail achievable by ship’s sonar systems still reveals plenty of surprises. The first phase of searching for Malaysian Airlines flight MH370 in the Indian Ocean, which involved mapping from ships to plan future surveys by underwater vehicles, found underwater mountains and other features that were not shown on satellite-derived maps for the area. But if we want to detect things just a few metres in size on the ocean floor, such as the wreckage of missing aircraft or the mineral spires of undersea volcanic vents that my team investigates, we need to take our sonar systems much closer to the sea bed using underwater vehicles or towed instruments. So far, less than 0.05% of the ocean floor has been mapped to that highest level of detail by sonar, which is an area roughly equivalent in size to Tasmania.  And of course, actually to see the sea floor using cameras or our own eyes means getting even closer, using remotely operated vehicles or manned submersibles. So the “95% unexplored” meme doesn’t really tell the full story of our exploration of the oceans. When it comes to having a large-scale map, the ocean floor is perhaps not as unexplored as we might think, with 100% coverage to a resolution of 5km and 10%-15% coverage at around 100m resolution.  That 10%-15% is similar in resolution to the current global maps of Mars and Venus. But our exploration of the oceans depends on what we want to know about them. If our questions are: “What does it look like down there?” or: “What’s going on down there?”, then the area that has been “explored” is arguably even less than the 0.05% mapped so far at the very highest resolution by sonar. Philosophically, when it comes to exploring anywhere on our dynamic world, how and when do we decide that somewhere has “been explored”? Do we declare “mission accomplished” once we’ve seen a location for the first time? The local woods where I walk my dog look very different in winter compared with summer, with different species flourishing at different times. Should I have considered them “explored” after my first visit in just one season?  Exploring our world starts with mapping, but perhaps doesn’t really have an end.   The University of Southampton is running a free online course (a “MOOC”) on Exploring Our Oceans."
nan
"
What were the most viewed stories of 2010 on WUWT? Our WordPress stats counter shows the most viewed stories: 

And here they are with links, should you wish to visit or bookmark:



Sea Ice Page


484,896


Widget


119,405


Climategate


77,362


New paper makes a hockey sticky wicket of Mann et al 98/99/08


76,398


The Gulf oil rig explosion – on the scene photos


57,589


Solar geomagnetic index reaches unprecedented low – only “zero” could be lower – in a month when sunspots became more active


52,110


Hal Lewis: My Resignation From The American Physical Society – an important moment in science history


51,589


Cancun COP16 attendees fall for the old “dihydrogen monoxide” petition as well as signing up to cripple the U.S. Economy


49,040


ENSO/Sea Level/Sea Surface Temperature Page


43,025


You ask, I provide. November 2nd, 1922. Arctic Ocean Getting Warm; Seals Vanish and Icebergs Melt.


39,685


Arctic Sea Ice about to hit ‘normal’ – what will the news say?


39,309


Lord Monckton wins global warming debate at Oxford Union


38,047


The scandal deepens – IPCC AR4 riddled with non peer reviewed WWF papers


32,645


BBC swaps “coldest December since 1981” headline


31,447


Climate change: proposed personal briefing


30,591





			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e85e924d0',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"The UK should reduce its greenhouse gas emissions to net zero by 2050, according to a major new report by the Committee on Climate Change, the government’s official advisers. It’s an ambitious target, but others say the country could go further. Friends of the Earth and other NGOs support a target of net zero by 2045, while activist group Extinction Rebellion want it by 2025.  The committee recognises that setting an earlier date might “send a stronger signal internationally”, but states that 2050 is the “earliest credible date”.  Had the world begun to take serious action back in the early 1990s, when the UN first discussed the problem, the transition away from business as usual would have been much gentler. We now face a much larger task, as global emissions have continued to grow and a fossil fuel-friendly economic structure has become ever more embedded into everyday operations.  So when should – and indeed could – the UK aim to reach net zero?  The question really hangs on how you believe politics works. Either you feel that a tough but “uncredible” target is the only way to get politicians and businesses to actually step up and start the transformation, or you believe that nudging the economy onto the right trajectory will then create an unstoppable momentum.  The first thing to recognise is there is a difference between what might be considered politically “credible”, financially feasible, societally acceptable or even physically possible. We’ll start with finances. Achieving net zero, or indeed any significant reductions in carbon emissions, will require a huge investment in renewable energy and sustainable transport. The European Commission estimates upgrading pipelines and electricity grids alone will cost €200 billion. Bringing forward that investment to achieve net zero in a five year time horizon, as opposed to a 30 year one, is daunting.  There are many significant barriers to achieving even the relatively slow transition recommended by the CCC. In particular, investors want clear and consistent commitments from governments, but past changes in low carbon policies (such as the UK government scrapping its household solar subsidy scheme) have led to a lack of trust. To achieve net zero, grid infrastructure will need to radically change and the UK will need to be better connected to mainland Europe so that renewable technologies, and energy storage options, can be located in the most optimal places across the continent. Europe has already identified several priority projects which would support the transition to low carbon. However, even fast tracked projects can take more than three years to get permission. One of the four priority projects identified is the North Sea offshore grid (NSOG) which would connect renewable generation in the North Sea, Irish Sea, English Channel and Baltic Sea to areas of electricity consumption and storage.  A key challenge here is to really understand how deploying tidal projects and thousands or millions of solar panels and wind turbines, along with the associated infrastructure, might impact on another demand of Extinction Rebellion – biodiversity protection. To do all this in five years would mean our entire electricity infrastructure would need to be redesigned in just a few months.  To be politically acceptable, any target is likely to need to meet two demands. The first, as stated by the Committee on Climate Change, is that is it “credible”. This is a very subjective term, of course, and visions of universal suffrage or an end to slavery also started out as utopian. A 2025 target could be perfectly credible if there was the political leadership to deliver it.  But political acceptability also depends on social impact. It is true to say that mitigating climate change is a benefit for society. But in the short term, if planned incorrectly, tackling climate change could make energy and food more expensive, and increase inequality. While it may be possible to show bold political leadership and deploy technology much more rapidly, is it possible to achieve the societal change that is needed?  Some of this will involve relatively simple asks. The CCC says biodegradable waste should no longer go to landfill, for instance. But other asks will be much more difficult, such as drastically reducing or stopping all aviation, while the UK currently faces a skills crisis and will struggle to train enough engineers, planners and biodiversity assessors. Net zero by 2025 is not physically impossible. There is no real barrier to deploying the technology required or to achieving the necessary changes in behaviour. But to achieve this, it is not a question of physical possibility but rather whether you believe it is possible to change the economic structure and political decision making of the UK (and EU and world) overnight to allow us to deploy all possible solutions over the next five years. Given that Brexit has so far taken a little over two years, politics is, unfortunately, a much more difficult challenge that cannot be fixed simply with technological solutions.  Reach for the stars of 2025 and we might just hit the moon in 2035 or 45. But reaching for the stars may also frighten government into believing that a space race is too expensive. The Extinction Rebellion, alongside school strikes and David Attenborough’s “Climate Change: The Facts” have brought a welcome focus to the urgency of climate change and the UK government must now back a net zero target, even the less ambitious 2050 target. But, more importantly, it must significantly ramp up those policies that will shape our transition to net zero.  Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"Since the night that Notre Dame was devastated in a fire, most people have assumed that the Gothic cathedral at the centre of Paris should be lovingly restored – and more than a billion euros have been pledged towards restoration.  Experts have estimated that the work would take between 20 and 40 years – by which time the UN’s climate agency estimates that we will have long exceeded dangerous levels of global warming, if current levels of emissions continue. On the same day that Notre Dame was blazing, protesters shut down parts of London, urging emergency action against climate collapse. Nations and coastal cities are starting to disappear under rising oceans. Densely populated regions are becoming too hot for humans. Many people in the global south are staring the collapse of functioning society in the face. It therefore seems a strange time to restore at such cost a monument to the western civilisation that helped create these conditions. It is time to take a hard look at buildings such as Notre Dame and ask what they represent, and whether we should still be treasuring them. Our current ideas on climate, environment, and inequality are partly the product of medieval Christian states. They saw humanity as dominant over and separate from nature, rather than part of it. Religious teaching emphasised that Earth was a place of sin, unhappiness and temptation. Good Christians should turn their thoughts to God, obey their priests, and look for justice only in the afterlife. The world would end before long, which meant it would be destroyed and replaced with a new, perfect place in which saved souls would live forever. Church authorities regularly described neighbouring populations as irrational “pagans” who were too close to nature, who worshipped trees, thunder and lightning. This was a justification for invading their lands, converting them to Christianity, and cutting down their sacred trees.   The remnants of these ideas persist in various forms today, from harmful land management practices through to the idea that it is rational to prioritise the economic goals of the state over addressing environment collapse. The reluctance of wealthy nations to deviate from these attitudes is a major cause of climate and ecological breakdown.  So let’s not restore Notre Dame. Instead, let it stand as a symbol of the damage that our climate denial and environmental entitlement have already caused our planet; a reminder of the much greater losses that will follow, and a call to action. Given the emotions around this cathedral and the great love expressed for it by so many people, it may seem strange to target Notre Dame for such a gesture. But when its history is considered, it becomes apparent that Notre Dame and the causes of climate and environmental breakdown are far from strangers. During the nearly 200 years that Notre Dame was being built, the kingdom of France became increasingly powerful and closely governed. This was a crucial stage in the emergence of the modern nation. The ruling dynasty, the Capetians, were skilled propagandists. The new cathedral was built to assert royal and religious prestige. It was a place from which crusades were announced, and the population was taught that God valued obedience from the people. Social inequality was the human condition, and injustices were to be endured. The construction, which began in 1163, was financed through taxes, tithes – 10% of annual income that all laypeople were required to hand over to the church – and labour from the peasant majority. Many of these people were serfs tied to the land they lived on, required by their lords to intensify the ongoing clearing of woodland and draining of marshland to extract the maximum from the terrain. In these areas, ecologies were disrupted and biodiversity declined. Soil erosion, flooding and silting of rivers resulted. The coercive, extractive rule on which Capetian France was founded – and on which Notre Dame was sanctioned – drove a wider exploitation of nature. For example, demand among the elite for furs and other luxuries led to severe reductions in animal, bird and fish populations. Beavers, wildcats and most other fur-bearing animals bigger than a weasel, together with sturgeon and some native salmon, were rare after the 12th century.   In areas where the rule of nobles was weaker and peasant farmers more independent, biodiversity was far better maintained. Peasants were not forced to focus on growing cereal crops to feed nobles and their animals, and so had more varied diets. They were healthier and the risks of famine in the population were lower. There are very clear connections between the strength of the French church and state’s coercive rule and the degree of ecological damage, unscrupulous extraction and social inequality. The most compelling critique of plans to pour money into the restoration of Notre Dame has come from the “gilets jaunes”. They asserted that their protests against rising poverty and inequality had been largely ignored by the same wealthy elites who could find, overnight, a billion euros for the state-launched fundraiser in aid of the prestigious cathedral.  From this perspective, it seems that when making decisions about what matters, the priorities and values of the French state and elite have changed little. The main difference is that it is no longer just the poor of France whose interests are at stake. To adapt to the challenges of the future, we need to take a radically different view of Europe’s past. We must recognise how deeply the roots of western civilisation and our contemporary way of life are entangled with sharp social injustice and environmental destruction. Notre Dame could become a symbol of that recognition. For people of faith, clearing it for worship but not indulging in an expensive restoration could be a powerful way to act on Pope Francis’s call for a drastic transformation of how humans treat the planet. It might seem dramatic, but only a strategic surrender of our damaging ways of living and thinking will enable us to respond to the fierce demands of the coming decades."
"

Ashton Carter, who took office as Secretary of Defense this week, and the heads of the military services all insist that it is impossible to execute the nation’s security strategy without busting through the $499 billion cap that law imposes on next year’s Pentagon budget. The military leaders warn that if Congress will not raise the cap and provide the $534 billon in non‐​war funds that they requested earlier this month for fiscal year 2016 — and get rid of future years’ caps — the United States will require a cheaper security strategy.



If only that were true.



What passes for American security strategy these days is a mixture of militarized global profligacy and national self‐​worship. The latest example is the “National Security Strategy,” which the White House released Feb. 6. It lists eight “top‐​strategic risks,” including non‐​security ills such as disease, economic slowdown, and climate change. But having eight top priorities really means having none. The document’s mentions “hard choices” and warns against “overreach” but then declares that “there are no global problems that cannot be solved without the United States.” It imagines that US military power can be everywhere to promote stability, democracy, and even equality. 





What passes for American security strategy these days is a mixture of militarized global profligacy and national self‐​worship.



Strategy is the prioritization of goals by assignment of resources. Hawks, like Senator John McCain, occasionally insist otherwise and call for military strategy’s liberation from budgetary constraints. But that is like suggesting that aircraft designs ignore physics. Strategy lacks meaning without budgetary context. 



The White House then has not actually produced a security strategy. It has just affixed that title to a florid defense of US leadership and a list of nice things, which collectively define global good as a requirement of US security. Take that standard seriously and you get a permanent sense of insecurity. 



It’d be easy to blame the authors, but recent Pentagon and national strategy documents share the problem. All fail to guide budgetary choice. Nor is writing alone at fault. American security policy, as reflected in budgets, cannot totally avoid prioritization, but somehow policy makers still try. There is no earthly region, with the possible exception of Antarctica, that the Pentagon has not labeled vital while justifying some garrison, alliance, or program there. Pentagon budgets have long avoided much shifting of money across military services, or even within them, though that is what implementing strategy requires.



Austerity, in theory, is a thorough auditor and creative reformer. For people and federal departments, wealth limits competition among desires, making their relative value academic. Belt‐​tightening, short of bankruptcy, demands choices, analysis to inform them, and sometimes innovative ways to do more for less.



Windfall defense budget growth in the 2000s — more than 50 percent, even adjusting for inflation — helped Pentagon leaders take a holiday from strategy. Counterinsurgency was the priority in Afghanistan and Iraq but not Washington, which preferred to fund wars with debt rather than limit investments in future wars linked to stateside jobs. The rising tide of largesse lifted all boats, fighter jets, four‐​star commands, and the like.



You would think austerity made this decade different. Annual Pentagon spending has fallen 25 percent over the past five years, accounting for inflation. Reduced war funds account for the bulk of the drop. Non‐​war Pentagon spending dropped 7 percent in 2013, the one year that the Budget Control Act of 2011 required sequestration, equally‐​applied, across‐​the‐​board cuts. Congress then slightly raised the spending caps that law had imposed for fiscal years 2014 and 2015 and passed budgets that did not exceed them. That avoided further sequestration and kept military spending level.



This relative poverty required some sacrifice. Mostly because of declining war funds, active‐​duty Army end‐​strength dropped from 570,000 to 475,000 troops and is supposed to hit 450,000 in 2018. The Navy and Air Force got fewer new ships and aircraft than they wanted. Base construction slowed. Reduced operational funding caused a Pentagon civilian hiring freeze, curtailed some training exercises, and produced slight reductions in management costs — despite much talk of efficiency. 



Still, strategic change has not come. The end of occupational warfare in the Middle East allowed plans for an Asian pivot, a euphemism for shifting forces to deter China. But funds for troops in Europe and the Middle East (minus the war zones) and their combatant commands have not pivoted. The Navy and Air Force — the forces most relevant to fighting China — did not grab non‐​war funding at the expense of the ground forces. The pivot, relabeled as rebalance, ultimately amounted to little more than words. Rather than change course, the Pentagon is doing a bit less of everything, except grousing. 



Whatever the chiefs say, that is unlikely to change, for two reasons. One is that current austerity is not that austere. 2015 Pentagon spending authority, adjusted for inflation, roughly matches 2004’s, the midpoint of the recent upswing. During the Cold War, spending was higher only in 1952 and 1985, the heights of the Korean War and Reagan buildup.



War budgets — officially, Overseas Contingency Operations funds — also limit pressure on the Pentagon. The 2016 request of $51 billion, ostensibly to fight the Islamic State and keep troops in Afghanistan, would be 21 percent less than 2015, but war budgets are declining slower than war costs. 



Because budget caps do not apply to OCO, the Pentagon and Congress have increasingly hidden non‐​war expenses there. That off‐​book accounting now makes up roughly half of OCO funds. That’s $25 billion of proposed cushioning against austerity next year, more than the cut that the Pentagon would suffer by complying with the cap. The administration insists on keeping this slush fund as long as caps constrain military spending.



Beltway elites are a bigger obstacle to strategic reappraisal. Military leaders long ago learned not to push for funds at the expense of other services. This cartel, which they call jointness, stymies civilian efforts to change strategy.



Few are inclined to try. Foreign‐​policy makers in both parties, especially those vying to be president or get named to a top post by one, proclaim, almost in chorus, that stability everywhere depends on American military presence or actions. Recent experience has made everyone charier of occupying restive states, but Washington’s preferred alternatives are bombing, lethal aid, military training, or oaths of support backed by threats — not staying out and at peace. US leaders are today intellectually immune to real strategies, which require actual choices about what dangers to meet with what defenses.



Absent lower caps or better leaders, hard choices will remain, for Pentagon, just a slogan advertising slight discipline. With a trim here and an accounting trick there, the Department of Defense will muddle along its present course, while elected leaders justify it with paeans about American military power’s indispensability to every pleasant noun that “global” can modify. We that object might take solace in the fact that our hubris is a luxury that our fortune affords. Only blessed nations can worry so much about their safety while confusing it with everything they want.
"
"**Here are five things you need to know about the coronavirus pandemic this Thursday evening. We'll have another update for you on Friday morning.**
Every area of England has the means to ""escape"" the toughest tiers of Covid restrictions, Boris Johnson has said, after the government confirmed most of country would be placed into the two toughest levels when the national lockdown ends on 2 December. Speaking at a Downing Street briefing, the prime minister said the extent of the restrictions would ""bring a great deal of heartbreak and frustration, especially for our vital hospitality sector"". But he suggested rapid community testing could make it easier for areas to move down the levels of rules, adding ""your tier is not your destiny"".
Under the revised local Covid tiers, the majority of England - including London and the Liverpool city region - will be in tier two, while large swathes of the Midlands, North East and North West, including Manchester, as well as Kent, will face the toughest tier three restrictions. It means about 55 million people will remain banned from mixing with other households indoors. Health Secretary Matt Hancock said placing most of the country into the toughest two tiers was ""not easy"" but had been done according to the ""best clinical advice"". You can use the BBC's tool here to check which tier you're in, and you can read our explainer here on what the new rules will be.
There is further evidence coronavirus infections are levelling off in England. Data from the Office for National Statistics suggests infection rates are falling in a number of parts of England, including the North West, London and the South West but rising in the Midlands and the North East. However, it's a mixed picture across the UK, with Wales and Northern Ireland seeing a fall in infections and Scotland an apparent rise. You can check the infection levels in your area here.
Further details have emerged about what Christmas will look like for Scotland following news this week that ""bubbles"" of three households will be able to mix for five days over the festive season. The Scottish government has published new guidance confirming the bubbles are limited to no more than eight people over the age of 11. In contrast, the UK government has set no limits for the number of people in a bubble in England, saying only they should be ""as small as possible"", while no guidance has been published yet for Wales and Northern Ireland. Read our explainer here on what the rules are at Christmas and who you're allowed to see.
Nativity plays and outdoor carolling will be able to go ahead in England after the national lockdown ends on 2 December, MPs have been told. Tory MP Andrew Selous - who speaks for the Church of England - said ""churches and cathedrals can now approach Advent and Christmas with certainty"". Indoor singing will be limited to ""formal performers"", he said, but everyone can take part outdoors. Children's church nativity plays will be allowed if they follow Covid rules.
Get a longer daily news briefing from the BBC in your inbox, each weekday morning, by signing up here.
You can find more information, advice and guides on our coronavirus page.
Here's a rundown of the rules around Christmas across the UK, restrictions for the various tiers in England and Scotland, and details of what's allowed in Wales and Northern Ireland.
**What questions do you have about coronavirus?**
_ **In some cases, your question will be published, displaying your name, age and location as you provide it, unless you state otherwise. Your contact details will never be published. Please ensure you have read our**_terms & conditions _ **and**_privacy policy.
Use this form to ask your question:
If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or send them via email to YourQuestions@bbc.co.uk. Please include your name, age and location with any question you send in."
"**Lincolnshire's move into the highest coronavirus tier could have ""a crippling effect on our hospitality sector"", a council leader has said.**
Martin Hill, leader of Lincolnshire County Council, said it was ""a big blow"" for the whole county to be placed in tier three on 2 December.
He said it made no sense as infection rates had fallen and some districts were ""well below the national average"".
The government has been approached for a comment.
Lincolnshire will face tighter restrictions as it enters the ""very high alert"" tier once the nationwide lockdown ends, meaning households can only meet in public spaces like parks, where the rule of six applies.
Health Secretary Matt Hancock set out the reasoning behind the tier decisions for each area in a written ministerial statement.
Mr Hill said: ""It's very disappointing that the whole of Lincolnshire has gone into tier three as we are seeing infection rates fall, especially in those few districts that were previously causing concern, and this could have a crippling effect on our hospitality sector.
""Although our figures have been high in some districts and lower elsewhere, there's a clear levelling-off and drop in the numbers as the lockdown restrictions and the considerable efforts of our residents begin to take effect.
""While some of our districts have infection rates well below the England average, why should the whole of Lincolnshire go into tier three for the sake of higher rates in some districts? It doesn't make sense.""
He said the hospitality sector was ""an important aspect of our economy"" and the council would seek additional support for local businesses.
He said infection rates in four of the seven districts were below the England average and ""I'm expecting the drop in those other areas to continue"".
""We'll be looking to move out of tier three as soon as possible if the picture continues to improve.""
One of the districts with the lowest infection rate is South Holland.
Leader of South Holland District Council Lord Gary Porter said: ""Clearly the government has left sight of the science and just gone with using the lines on a map to sort it.
""Clearly it could have worked as districts. The whole point of having boundaries is that. We should have worked on local administration areas.""
_Follow BBC East Yorkshire and Lincolnshire on_Facebook _,_Twitter _, and_Instagram _. Send your story ideas to_yorkslincs.news@bbc.co.uk _._"
"This winter has been by far the hottest recorded in Europe, scientists have announced, with the climate crisis likely to have supercharged the heat. The EU’s Copernicus Climate Change Service (C3S) data dates back to 1855. It said the average temperature for December, January and February was 1.4C above the previous winter record, which was set in 2015-16. New regional climate records are usually passed by only a fraction of a degree. Europe’s winter was 3.4C hotter than the average from 1981-2010.  The unseasonal heat has led to the failure of the ice-wine harvest in Germany and snow having to be imported for sporting events in Sweden and Russia. In Helsinki, Finland, the average temperature for January and February was more than 6C higher than the 1981-2010 average. In the UK, serious flooding is likely to have been made worse by higher temperatures, as in 2015. “Whilst this winter was a truly extreme event in its own right, it is likely that these sorts of events have been made more extreme by the global warming trend,” said Carlo Buontempo, director of C3S. But he added: “Seeing such a warm winter is disconcerting, but does not represent a climate trend as such. Seasonal temperatures, especially outside the tropics vary significantly from year to year.” Nonetheless, scientists expect global heating to increase the number of temperature extremes and this is continuing around the world. Australia, which has suffered catastrophic bushfires, has just recorded its second-hottest summer on record, only a little cooler than the record set the year before. In Antarctica, the temperature rose above 20C for the first time on record in February, almost a full degree higher than the previous record set in 1982. Across the globe as a whole, 2019 was the second hottest on record for the planet’s surface and both the past five years and the past decade were the hottest in 150 years. The previous hottest year was in 2016, but temperatures were boosted that year by a natural El Niño event. The heat in the world’s oceans reached a new record level in 2019, showing “irrefutable and accelerating” heating of the planet, according to scientists. In the UK, the Met Office said in January that a series of high temperature records were broken in 2019 as a consequence of the climate crisis. This included the hottest temperature ever recorded in the country: 38.7C on 25 July in Cambridge. 2020 is a crucial year in the fight to halt the climate emergency and prevent the damaging impacts worsening. The UK is hosting a vital UN climate summit in November at which the world’s nations must dramatically increase their pledges to cut carbon emissions to avoid a disastrous 3-4C rise in global temperatures."
nan
"**Cambridgeshire will be in tier two when England's second lockdown ends on 2 December, it has been announced.**
The county had been in tier one - the lowest tier - prior to the latest shutdown but will move up to match much of the rest of the country.
It means households cannot mix indoors and the rule of six applies outdoors.
Pubs and bars can only open if they serve substantial meals and limited numbers of spectators will be allowed at sports events.
Shops, gyms and personal care services, such as hairdressing salons, can reopen if they are Covid-secure.
In a written statement, Health Secretary Matt Hancock said there was an ""improving picture"" across Cambridgeshire and Peterborough but the case rate was ""still high"" at 123 cases per 100,000 people.
Conservative MP Anthony Browne said he was ""disappointed"" his South Cambridgeshire constituency had been categorised in tier two.
He added: ""The government has categorised the whole of Cambridgeshire and Peterborough together, and the rates are pushed up by much higher levels of infection in Cambridge City and Peterborough.""
But the Liberal Democrat leader of South Cambridgeshire District Council, Bridget Smith, said it was ""absolutely not the time to be divisive and to blame other districts for the tier we find ourselves in"".
""It is the time to follow the experts' advice. South Cambridgeshire wraps all around Cambridge city with many people living or working in both districts so it would be ludicrous for us to be in different tiers,"" she said.
Meanwhile, the Conservative leader of Huntingdonshire District Council, Ryan Fuller, said his area had one of the lowest infection rates in the country.
Mr Fuller said: ""I sympathise with many who feel frustrated with the continuation of restrictions; however, we have come too far to give up now and we must therefore continue to follow national guidance for the tier we are in.""
Conservative Huntingdon MP Jonathan Djanogly said he would need to see the government's evidence for putting his constituency into tier two before MPs get a chance to vote on the new rules.
The Labour MP for Cambridge, Daniel Zeichner, called for a package of economic support to the ""many Cambridge pubs, bars and restaurants"" who were ""desperately worried as we enter the crucial Christmas period"".
Stuart Clements, who runs the White Horse Pub in Eaton Socon, said he hoped to be in tier one but was not surprised to be in tier two.
He said: ""The biggest implication is you can't have social groups mixing so where a group of six friends might come out to enjoy an evening's food and drink and maybe some music, those six people can't now sit together on one table.
""Whilst we'll still get families coming out for dinner, because you can't mix social groups unless you're in the same support bubble, it will have an implication on those people coming out.""
_Find BBC News: East of England on_Facebook _,_Instagram _and_Twitter _. If you have a story suggestion email_eastofenglandnews@bbc.co.uk"
"**Tougher restrictions in Wales are being considered for the run up to Christmas, the first minister has confirmed.**
Mark Drakeford said he is ""looking carefully"" at similar coronavirus rules to those that will be in place in areas in the upper end of the tier systems of England and Scotland.
However he said they would ""most likely"" be imposed on a Wales-wide basis, rather than a tier system.
The Welsh Government cabinet is due to discuss the matter on Thursday.
Mr Drakeford told BBC Wales Live he believes, unless further action is taken, ""we could end up at Christmas with a virus really heading very fast in the wrong direction"".
He said: ""We're looking carefully at the tier system that they've got now in Scotland and in England, looking at what further restrictions they have at that point in the tier system where it begins to be effective, seeing if there's anything more we can take from that for Wales.
""Let me be clear I'm not talking about using a tiered system.
""I'm looking to see what measures are in place at, say, tier three in Scotland and England.
""Are there things that they do there that we're not doing here in Wales, that we would do, most likely, on a Wales-wide basisâ¦ in the run up to Christmas. We've got four weeks left.""
England's new tier system comes into force when its lockdown ends next week, with Tier 3 being the highest level of restrictions.
Under Tier 3, people must not meet indoors or in most outdoor places with people they do not live with or who are not in their support bubble, pubs and restaurants are closed except for takeaway and hotels and indoor entertainment venues must close.
Scotland has a five-level system that runs from 0 to four. At Level 3 alcohol sales are not allowed and cafes and restaurants can only serve food and non-alcoholic drinks and must close at 18:00.
Mr Drakeford said preventing people getting together would have helped moves to control the spread of coronavirus.
However he admitted that Christmas was ""too important"" to people to ask them to not celebrate.
""If we could have persuaded people that this wasn't the year to get together over Christmas that would have been better from the virus's perspective, but we were never going to be able to do that,"" he said.
""In an incredibly difficult year we weren't going to be able to persuade people that they could just act as though Christmas wasn't happening.""
Asked whether Wales was ready to distribute a coronavirus vaccine, Mr Drakeford said: ""We have everything in place once a vaccine gets regulatory approval.""
He added: ""Even the most promising vaccine is yet to have approval by the regulator. Once it gets it, within a week we are ready to start vaccinating people in Wales.""
If Wales were to use the Pfizer vaccine, which has to be stored at -70 degrees, he said the plan is to use equipment from the Welsh Blood Service.
""We can use the equipment the Wales Blood service already has to store material at that temperature and we can make it available for this vaccine,"" he said.
""The vaccine will have limitations, it will be difficult to transport but we will find ways of doing it. Whatever vaccine comes our way, we will want to use here in Wales."""
"Are animals jealous? How would we know? Scientists are educated to have a deep scepticism about attributing sophisticated mental abilities to non-human animals. Anthropomorphism is regarded as a scientific sin. However, the paradox is that scientists are all Darwinists, and Darwin’s great contribution to psychology was the argument for the continuity of mind across species, not the uniqueness of humans. He was explicit that animals and humans shared a wide range of emotions, including jealousy. Many contemporary theories of jealousy focus on its development during infancy and childhood. A paper published in the journal PLOS One takes a leaf out of such studies to conduct an experiment with dogs. The paper’s findings suggest that dogs show behaviour indicative of jealousy when their owners interacted with lifelike stuffed dogs, and not when they interacted with other, non-doglike objects. Jealousy is thought to develop after basic emotions such as anger and fear, and is thought to require relatively sophisticated cognitive capacities including elements of self-consciousness. The requirement of self-consciousness, in combination with the natural reluctance of scientists to be caught anthropomorphising, makes any claim of jealousy in animals controversial. The scepticism over the existence of sophisticated emotions such as jealousy, guilt or empathy in animals is on reflection odd. Most scientists are happy to grant animals basic emotions such as anger and fear. It would not be anthropomorphic to say that an animal is angry or scared. Anger and fear have a clear evolutionary function for animals and humans, and even though animals may not experience such emotions in precisely the same way as humans, there is a clear continuity. When we consider the function of jealousy it would seem equally important for many social species. All jealousy shares the characteristic of being focused on relationships. Jealousy in essence is a reaction to a threat to a social relationship whether that is parental, sexual or a friendship or alliance. All such relationships are potentially vital in social species.  We know animals form alliances and bonds (contemporary scientists are deeply reluctant to talk about animal friendships even though Darwin frequently did) as they are often vital to survival in hierarchical social species. We all need allies. To have a mechanism that makes animals sensitive to potential threats to such alliances provides a clear evolutionary advantage. It would be foolish to claim that animals experience the existential pain that can be part of the human experience of jealousy. But given the functional necessity of something like jealousy in any social species, it seems equally unlikely that jealousy emerged from a clear blue sky as a uniquely human adaptation. Emotions are the functional adaptations that help organise behaviour, and jealousy has a similar function across a range of species. Jealousy is classed as a secondary or social emotion, in contrast to primary or basic emotions. Secondary emotions such as empathy, pride, embarrassment and guilt and are thought to be important for maintaining stable social structures, rather than providing the immediate survival benefits of basic emotions such as fear. There is very clear evidence that basic emotions are tied to particular sites in the brain, and these are the same across species. The same link of emotion to location is not the case with secondary emotions. This may be because secondary emotions are the result of more distributed networks of neurons than primary emotions. However, mammal brains (including humans) are remarkably similar in structure and have all the same bits in all the same places, so from an anatomical point of view there is no reason to preclude animals having secondary emotions. Humans do not seem to be uniquely designed to support secondary emotions.    Being certain about the mental state of any person (let alone a member of another species) other than ourselves is problematic as we cannot know their mental states directly. This is known as the problem of other minds. However, we can have reasonable confidence that a range of species experience basic emotions such as anger, as the behaviour and even facial expressions associated with basic emotions are consistent and recognisable across species. But emotions such as jealousy do not have any unique behaviours or facial expressions associated with them. Jealousy can manifest as anger or as distress, for example. Despite all the folk psychology and human projection that often suggests otherwise, there will always be arguments about whether a dog can show jealousy, empathy, or guilt, because of the difficulty of measuring emotion in any non-human animal. "
"
My parents used to talk about rationing during the war with great apprehension. Clearly the nutters in and supporting Cancun are clueless as to how such a scheme would be viewed by the public. My inbox has lit up today from all around the world over this issue. Short of Climategate itself, I haven’t quite seen any other similar reaction.

Excerpts from the Telegraph: Cancun climate change summit: scientists call for rationing in developed world
Global warming is now such a serious threat to mankind that climate change    experts are calling for Second World War-style rationing in rich countries    to bring down carbon emissions.

…
In a series of papers published by the Royal Society, physicists and chemists    from some of world’s most respected scientific institutions, including    Oxford University and the Met Office, agreed that current plans to tackle    global warming are not enough.
…
In one paper Professor Kevin Anderson, Director of the Tyndall Centre for    Climate Change Research, said the only way to reduce global emissions    enough, while allowing the poor nations to continue to grow, is to halt    economic growth in the rich world over the next twenty years.
…
Prof Anderson admitted it “would not be easy” to persuade people to reduce    their consumption of goods
He said politicians should consider a rationing system similar to the one    introduced during the last “time of crisis” in the 1930s and 40s.
This could mean a limit on electricity so people are forced to turn the    heating down, turn off the lights and replace old electrical goods like huge    fridges with more efficient models. Food that has travelled from abroad may    be limited and goods that require a lot of energy to manufacture.
“The Second World War and the concept of rationing is something we need to    seriously consider if we are to address the scale of the problem we face,”    he said.
Full story here: Cancun climate change summit: scientists call for rationing in developed world
==============================================================
Does anyone really want to see a ration stamp like this?

For anyone that wishes to get the Royal Society’s papers referenced in the article, they are available for a limited time download here:
http://rsta.royalsocietypublishing.org/content/369/1934.toc#content-block


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e872687e8',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterControversy is swirling over new upcoming skeptic book.
It begins with DIE ZEIT’s latest article on the controversial new skeptic book authored by Prof Dr. Fritz Vahrenholt (renewable energy expert) and Dr. Sebastian Lüning (expert geologist) which will hit the bookstores on February 6, published by the renown Hoffmann & Campe in Hamburg. It has the warmist activists scared out of their wits.

The book German warmists fear.
An old saying goes: Better to remain quiet and let people think you may be dumb, than to open your mouth and to confirm it. Two authors at the German online DIE ZEIT nationwide weekly, Stefan Schmitt and Christian Tenbrock, not only confirmed it, but they also jumped right into it, feet first, in their latest hit piece here.
DIE ZEIT labels skeptic scientists “deniers”
Worse, the once respectable DIE ZEIT weekly, which Wikipedia calls “highly respected for its quality journalism”, stooped into the gutter and maliciously labelled scientists who doubt the catastrophic global warming religion as “deniers”. We all know why the word denier was chosen, and not “skeptic”. They ought to be served papers for defamation.
They haven’t even read the book
Schmitt und Tenbrock’s article is filled with Rahmstorfian-type falsehoods. What’s remarkable is that they go after the book and its two authors without having ever read it! (book release is February 6). If they had waited a little longer to read it, they would have spared themselves all the embarrassment of their ridiculous claims, falsehoods, and thus confirmation of some dumbness.
Lüning and Vahrenholt are luke-warmers
Their only crime of course is that the book’s authors are open-minded and have also evaluated skeptic arguments in their overall assessment. Their book Die kalte Sonne cites more than 800 sources from both sides, and from the middle. In fact, Vahrenholt was once a more or less a devout warmist – until he dug deeper. Yet, DIE ZEIT writes at the very beginning:
“RWE manager Fritz Vahrenholt doubts further global warming.”
He does not. Indeed it helps to read the book first.
Schmitt and Tenbrock then claim Vahrenholt and Lüning insist the impacts of CO2 emissions can be neglected. But anyone who is familiar with the contents of the book, as I am, can say that this is also false. The truth is that Drs. Lüning and Vahrnholt clearly state that CO2 is responsible for perhaps half of the warming. This is in line with what Prof. Mojib Latif believes. DIE ZEIT is trying to frame it as a yes-or-no issue. Their sole interest is starting a food-fight, and preventing a discussion.
DIE ZEIT imposes a thought-ban
Schmitt and Tenbrock of DIE ZEIT also blast the two authors for attending a skeptic conference in Munich last November. What’s wrong with that?  Why not listen to both sides of the argument? Has a thought-ban been enacted in Germany? Or is this something one finds only at DIE ZEIT? Are we only to march like drones, never questioning green dogma?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




It just happens that some of the speakers at the Munich Conference are also guest authors of the book and who happen to be distinguished scientists, among them Henrik Svensmark and Nir Shaviv. If Schmitt and Tenbrock had waited and read the book first, they would have known of their contribution to the book, and certainly would have learned to spell their names correctly. Tells you what they really know about climate science.
Ignorant when it comes to the CERN CLOUD experiment
Schmitt und Tenbrock are also not only unaware of the book’s contents, but also of what CLOUD project at CERN is about. They claim that CLOUD results don’t confirm anything, and make it sound like the experiment is finished.  They appear not to know that only Phase I is completed. And preliminary results indeed do fit Svensmark’s theory – like a glove. The next phase of the experiment will test to see if the tiny aerosols can form into larger ones, and is expected to end in 2014. Not only should they wait and read the book, they also ought to wait for the results of CLOUD before opening their mouths and confirming more dumbness.
Lüning and Vahrenholt “against 1000s of scientists”
DIE ZEIT (Schmitt and Tenbrock) use the old worn out consensus argument. The global warming sham is in reality perpetuated by a only few dozen scientists who have high stakes in the game. As I already wrote, Lüning and Vahrenholt cite hundreds of sources, many peer-reviewed, that challenge the AGW hypothesis and which the IPCC simply ignores. And what did the Wall Street Journal just publish? Obviously Schmitt and Tenbrock have not read that either. Do they read at all?
On page 2, DIE ZEIT uses the unfortunate “denier” slur to criminalize skeptic scientific views. I wonder if they would say that to Nir Shaviv’s face. Obviously that has backfired big time and it fully exposes their real, malicious, agenda.
Finally Schmitt and Tenbrock claim:
At the latest since the 1980s, the Earth has been warming differently than it did in pre-industrial times, and no longer in sync with solar activity.“
Last I’ve looked, the Earth hasn’t warmed at all over the last 15 years. And if they had waited and read the book, the DIE ZEIT authors would have seen that the 22nd and 23rd solar cycles were intense ones. And, like the IPCC, DIE ZEIT simply ignores the major roles played by oceanic cycles.
To judge a book, it first helps to read it
It’s obvious that Schmitt und Tenbrock, who appear to be hopelessly biased, have long closed their minds. They were never interested at all in finding out the truth. If they had been, they would have waited and read the book – or at least interviewed Lüning and Vahrenholt.
And so with such journalists, the question arises of whether DIE ZEIT is to be taken as an open, intellectual weekly, or if it has devolved itself to being a narrow-minded purveyor of dogmatism. Can we really take DIE ZEIT seriously?
To answer that question. let’s hope Vahrenholt and Lüning send a letter of rebuttal to Die Zeit. If they are truly open, DIE ZEIT will publish it, and have alittle talk with their journalists.  But I’d bet a king’s fortune they won’t. I can tell you the answer already, I had the chance of reading the book’s  manuscript, and I know Lüning and Vahrenholt would take the DIE ZEIT piece apart in short order. Papers are not in the habit of further embarrassing themselves.
DIE ZEIT’s modus operandi
These types of journalists appear underworld-like. Journalistic drive-by shootings are sadly no longer new at DIE ZEIT and now appear to be their modus operandi. They did the same with Fred Singer, read here.
Hopefully, DIE ZEIT will someday get back to the practice of intelligent journalism, and end the cheap character assassinations and smearing. Now would be a good time for DIE ZEIT to keep their mouths closed – and to not reopen them until after February 6th.
Surely between now and then they’ll find something intelligent to say.
Share this...FacebookTwitter "
nan
"**Publicans and politicians have said they are ""disappointed"" that all of Devon will be placed in Tier 2 coronavirus restrictions.**
Health Secretary Matt Hancock made the announcement to place the county in the ""High alert"" category on Thursday.
The restrictions mean households cannot mix indoors, and pubs can only serve alcohol with substantive meals.
Plymouth MP Luke Pollard said: ""We must not spend a moment longer in tier two than we have to.""
He wants the restrictions, which start on 2 December, to be reviewed in two weeks and said ""our city's hospitality businesses face a grim future"".
He believes Plymouth, Devon and Torbay Councils should be ""dealt with as separate areas and not lumped together"".
The government said the reason for the tier rating is an infection rate of 121 per 100,000 in Devon, and said ""there is pressure at the Royal Devon and Exeter Hospital"".
The Blue Anchor in Teignmouth is one pub that will not be able to reopen because they do not serve food.
On Facebook they said ""we are feeling pretty disheartened"" describing the strategy as ""like expelling a whole school because one kid has done something wrong. It's lazy"".
Teignbridge has the lowest infection rate in England - of 52.9 per 100,000.
This is lower than in Tier 1 Cornwall, where it is 62.4 per 100,000.
The town's MP Anne Marie Morris said: ""I am very unhappy - this is not the right decision for Teignbridge.
""The rate of infection is so low, how can this be justified?""
Alan Connett, leader of Teignbridge Council said: ""I'm hugely disappointed for us in Teignbridge and even more saddened for businesses, and in particular we have wet only pubs who will be viewing this in desperation"".
Michelle Chambers, the landlady of the Dolphin pub in Plymouth, said she is ""disappointed"" and said the decision ""will hit us hard in the pocket but my main worry is about our staff, and how they will be looked after"".
The government said the system will be regularly reviewed and an area's tier level may change before Christmas - the first review is scheduled for 16 December."
"When commercial whaling was banned in 1986 it put an end to a harvest that threatened the existence of some of the most majestic animals on Earth. With several species reduced to tiny fractions of their original populations, once the moratorium was introduced the expectation was that whale populations would recover. But in the decades since, only some have. There are many possible reasons why this might be, including chemical pollution, climate change, man-made noise, and loss of cultural knowledge among whales that prevent their descendants returning to habitats in their former range. A further risk, highlighted by a new study of blue whales off the coast of California, is deaths and injury caused by being struck by ships. In most populations, we don’t yet know how big a problem it is, but for some it is almost certainly holding back recovery. In recent years reports of the arrival of large vessels into port with the carcass of a large whale pinned to the bow bulb have become a regular occurrence in the news. Of course, these are only those cases that make it to port – an unknown number of strikes leave their victims at sea, and are sometimes encountered by chance. In fact the impact on the vessel is so insignificant that the crew is typically unaware that it has happened until it reaches port. But why this apparent increase in numbers? Is there just more interest, or are there now more whales to hit, are newer ships somehow more dangerous (modern, more efficient technology is often quieter), or are the whales moving into more dangerous busy shipping lanes? We don’t know, which is why studies like one published in the journal PLoS One are so important. Oregon State University researcher Ladd Irvine and his colleagues attached satellite tags to 171 blue whales over a period of 15 years starting in 1993. For a study of whales this is a huge dataset representing a massive investment, largely in terms of researcher time, and provides a really robust insight into the whale’s habitat use.  They found two core areas heavily used by the whales, in the Gulf of the Farralones off San Francisco Bay, and north of the Channel Islands, near Los Angeles. The whales’ presence there wasn’t year-round, but heavily concentrated between July and October as they followed high concentrations of their food, krill, that accumulate after the spring plankton bloom in these productive waters. Some individuals returned to the same spots at the same times over many years, suggesting the whales relied on their knowledge and sense of location rather than an ability to track prey, highlighting the important role that habitat knowledge plays in these animals’ lives. By plotting the whale distribution maps against those of heavily-used shipping lanes along the California coast, the problem is clear. The shipping lanes run through some of the areas most heavily used by the whales, putting them at high risk of ship strikes. The shipping lanes are typically placed where they are heavily used and most economical, such as the shortest distance between two points. No shipping companies would change their routes and incur costs without solid evidence of a problem, and this is exactly the kind of evidence this study provides. It’s hard to comprehend in an age when we are mapping the surface of Mars just how ignorant we are about these huge ocean creatures. How do you figure out how many blue whales there are in the deeply inhospitable Southern Ocean? Sometimes technology can help, such as the satellite tags used for this study. Shipping lanes into Boston on the eastern US seaboard are now equipped with acoustic buoys that report detections of critically endangered right whales in near real-time, hopefully reducing significant numbers of deaths from ship strikes. Of course, we could find out more – it just takes money. The constraint is economic and political, not a lack of technology or ingenuity. Scientists are accumulating evidence that might help us appreciate just how much healthy whale populations could be doing for us. As large, apex predators they structure the ecosystems in which they live, they provide ecosystem services by recycling nutrients throughout the water column, and their huge carcasses fuel entire deep-sea ecosystems for years. Even their excrement plays a vital role in fertilising nutrient-poor surface waters, seeding the seas with iron, which boosts phytoplankton growth and potentially plays a part in the dynamics of climate change.  It seems that marine habitats with healthy whale populations might actually be more productive than ones without. It’s never made more sense to invest in saving the whales."
"

To help you keep an eye on it, I have the satellite imagery here along with animated loops.

Click image for full size or animate this image: Click for loop>>> 
============

WTNT31 KNHC 300231
TCPAT1
BULLETIN
HURRICANE ALEX ADVISORY NUMBER  18
NWS TPC/NATIONAL HURRICANE CENTER MIAMI FL    AL012010
1000 PM CDT TUE JUN 29 2010
…ALEX BECOMES THE FIRST HURRICANE OF THE 2010 SEASON AND THE FIRST JUNE ATLANTIC HURRICANE SINCE 1995…

SUMMARY OF 1000 PM CDT…0300 UTC…INFORMATION
———————————————–
LOCATION…23.1N 94.8W
ABOUT 195 MI…315 KM ESE OF LA PESCA MEXICO
ABOUT 255 MI…415 KM SE OF BROWNSVILLE TEXAS
MAXIMUM SUSTAINED WINDS…75 MPH…120 KM/HR
PRESENT MOVEMENT…W OR 280 DEGREES AT 9 MPH…15 KM/HR
MINIMUM CENTRAL PRESSURE…973 MB…28.73 INCHES
WATCHES AND WARNINGS
——————–
CHANGES WITH THIS ADVISORY…
NONE.
SUMMARY OF WATCHES AND WARNINGS IN EFFECT…
A HURRICANE WARNING IS IN EFFECT FOR…
* THE COAST OF TEXAS SOUTH OF BAFFIN BAY TO THE MOUTH OF THE RIO
GRANDE
* THE COAST OF MEXICO FROM THE MOUTH OF THE RIO GRANDE TO LA CRUZ
A TROPICAL STORM WARNING IN IN EFFECT FOR…
* THE COAST OF TEXAS FROM BAFFIN BAY TO PORT OCONNOR
* THE COAST OF MEXICO SOUTH OF LA CRUZ TO CABO ROJO
FOR STORM INFORMATION SPECIFIC TO YOUR AREA IN THE UNITED
STATES…INCLUDING POSSIBLE INLAND WATCHES AND WARNINGS…PLEASE
MONITOR PRODUCTS ISSUED BY YOUR LOCAL NATIONAL WEATHER SERVICE
FORECAST OFFICE. FOR STORM INFORMATION SPECIFIC TO YOUR AREA OUTSIDE
UNITED STATES…PLEASE MONITOR PRODUCTS ISSUED BY YOUR NATIONAL
METEOROLOGICAL SERVICE.
DISCUSSION AND 48-HOUR OUTLOOK
——————————
AT 1000 PM CDT…0300 UTC…THE CENTER OF HURRICANE ALEX WAS LOCATED
NEAR LATITUDE 23.1 NORTH…LONGITUDE 94.8 WEST.  ALEX HAS MOVED
MOSTLY WESTWARD NEAR 9 MPH…15 KM/HR…OVER THE PAST FEW HOURS BUT
A GENERAL WEST-NORTHWESTWARD MOTION IS EXPECTED OVER THE NEXT 24 TO
48 HOURS.  ON THE FORECAST TRACK…THE CENTER OF ALEX WILL APPROACH
THE COAST OF NORTHEASTERN MEXICO OR SOUTHERN TEXAS ON WEDNESDAY AND
MAKE LANDFALL IN THE HURRICANE WARNING AREA LATE WEDNESDAY OR
WEDNESDAY NIGHT.
MAXIMUM SUSTAINED WINDS HAVE INCREASED TO NEAR 75 MPH…120
KM/HR…WITH HIGHER GUSTS.  ALEX IS A CATEGORY ONE HURRICANE ON THE
SAFFIR-SIMPSON HURRICANE WIND SCALE.  ADDITIONAL STRENGTHENING IS
FORECAST PRIOR TO LANDFALL.  ALEX WILL BEGIN TO WEAKEN AFTER ITS
CENTER CROSSES THE COASTLINE.
HURRICANE FORCE WINDS EXTEND OUTWARD UP TO 15 MILES…30 KM…FROM
THE CENTER…AND TROPICAL STORM FORCE WINDS EXTEND OUTWARD UP TO 175
MILES…280 KM.
THE MINIMUM CENTRAL PRESSURE REPORTED BY AN AIR FORCE HURRICANE
HUNTER PLANE WAS 973 MB…28.73 INCHES.
HAZARDS AFFECTING LAND
———————-
RAINFALL…ALEX IS EXPECTED TO PRODUCE TOTAL RAINFALL ACCUMULATIONS
OF 6 TO 12 INCHES OVER PORTIONS OF NORTHEASTERN MEXICO AND SOUTHERN
TEXAS…WITH ISOLATED MAXIMUM AMOUNTS OF 20 INCHES.  THESE RAINS
COULD CAUSE LIFE-THREATENING FLASH FLOODS AND MUD SLIDES…
ESPECIALLY IN MOUNTAINOUS TERRAIN.  RAINBANDS ASSOCIATED WITH ALEX
ARE SPREADING ONSHORE IN NORTHEASTERN MEXICO AND SOUTHERN TEXAS.
WIND…TROPICAL STORM CONDITIONS ARE EXPECTED TO REACH THE COAST
WITHIN THE HURRICANE AND TROPICAL STORM WARNING AREAS BEGINNING LATE
TONIGHT OR EARLY WEDNESDAY…MAKING OUTSIDE PREPARATIONS DIFFICULT
OR DANGEROUS.
STORM SURGE…A DANGEROUS STORM SURGE WILL RAISE WATER LEVELS BY
AS MUCH AS 3 TO 5 FEET ABOVE GROUND LEVEL ALONG THE IMMEDIATE COAST
TO THE NORTH OF WHERE THE CENTER MAKES LANDFALL.  THE SURGE COULD
PENETRATE INLAND AS FAR AS SEVERAL MILES FROM THE SHORE WITH DEPTH
GENERALLY DECREASING AS THE WATER MOVES INLAND.  NEAR THE COAST…
THE SURGE WILL BE ACCOMPANIED BY LARGE AND DESTRUCTIVE WAVES.
TORNADOES…ISOLATED TORNADOES ARE POSSIBLE OVER PORTIONS OF EXTREME
SOUTHERN TEXAS ON WEDNESDAY.
NEXT ADVISORY
————-
NEXT INTERMEDIATE ADVISORY…100 AM CDT.
NEXT COMPLETE ADVISORY…400 AM CDT.
============================================
I find it amazing that today the world connectivity allows me to get notified of this bulletin, publish this post, and include live satellite content all from a coin operated net kiosk at Melbourne Airport.
We live in interesting times.
Anthony


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ab3a750',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Exeter's Nightingale hospital will open to coronavirus patients for the first time on Thursday.**
The emergency field hospital will get patients from the Royal Devon and Exeter Hospital ""which is very busy"", said an NHS spokesperson.
It is one of seven Nightingale Hospitals built in England, set up in the spring as an insurance policy in case the NHS became overwhelmed.
The 116-bed hospital has also been used for vaccine trials.
On Twitter, Exeter MP Ben Bradshaw said the opening was ""very good news"".
He added it will ""take pressure off the RD&E hospitals and other local NHS services"".
The Labour MP noted he recently raised the issue with Health Secretary Matt Hancock.
A total of 540 people have died with coronavirus in South West hospitals, with four dying in Devon on Wednesday.
A Nightingale hospital spokesperson said: ""We would ask that the public continue to observe the government's advice on observing the lockdown and social distancing so that we can keep patients safe.""
**How will your Christmas plans be affected?**haveyoursay@bbc.co.uk **.**
Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways:
If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or comment or you can email us at HaveYourSay@bbc.co.uk. Please include your name, age and location with any submission."
"**Criminal gangs used Personal Protective Equipment (PPE) shipments in an attempt to smuggle illegal drugs in Northern Ireland, the justice minister has said.**
Naomi Long revealed the attempts in her annual report on organised crime.
Mrs Long said organised crime groups had also exploited the need for PPE, including selling non-existent stock online.
She said it was ""reprehensible"" criminals had exploited the Covid-19 pandemic.
""The fact that criminals would stoop so low as to exploit the circumstances created by a pandemic shows they care about nothing other than lining their own pockets,"" she added.
""PPE is an essential part of keeping people safe from the virus so to use shipments of it to conceal drugs is beyond reprehensible.""
The Organised Crime Task Force annual report also said drugs were found concealed in flooring packaging and in washing powder.
The taskforce had helped rescue ""111 potential victims of modern slavery"", the report added.
The report also revealed 5.7m cigarettes, 65,000 litres of alcohol and more than 2,000 items of counterfeit goods ""had been prevented from entering Northern Ireland"".
""It is critical that we strive to make organised crime unprofitable and to bring criminals to justice,"" Mrs Long added.
""Next year, new legislation will be introduced to enhance powers for law enforcement agencies here, bringing Northern Ireland into line with the rest of the UK.
""Unexplained Wealth Orders, account freezing and forfeiture powers, and the ability to seize criminal assets are just three of the additional measures that will be available to strengthen collective efforts to tackle organised crime.
""In addition work will continue on proposals for new organised crime offences.""
PSNI crime department Assistant Chief Constable Barbara Gray said the criminality of organised crime gangs ""knows no bounds as has been witnessed during the Covid-19 pandemic when they have continued to make money regardless of the pressures on the lives of others"".
""The Organised Crime Task Force is committed to disrupting and frustrating the criminal gangs involved.
""This year's annual report recognises the contribution and significant successes of the law enforcement agencies over the past 12 months including the seizure of illegal drugs, rescuing victims of human trafficking, and seizing counterfeit goods.""
The Organised Crime Task Force was established in 2000 and includes the Police Service of Northern Ireland, An Garda SÃ­ochÃ¡na (Irish police), the Department of Justice and Her Majesty's Revenue and Customs."
"Boris Johnson’s government must spend an additional £33bn a year on measures to tackle the climate emergency if it is to meet its target of cutting carbon of emissions to zero by 2050, according to a detailed analysis published on Sunday.  Investment in low-carbon transport – including more infrastructure for charging electric vehicles, improved railways and better facilities for cyclists – would have to rise by £12bn a year, and spending on low-carbon homes and other buildings would need to be increased by £10bn annually.  The huge sums of extra spending required have been produced before Wednesday’s budget by the Institute for Public Policy Research thinktank, which says the necessary measures would not only help tackle climate change but would also deliver an economic boost and help Johnson’s ambition to “level up” the country. Last summer the government signed into law a commitment requiring the UK to bring all greenhouse gas emissions to net zero, replacing the previous pledge to reduce them by at least 80% compared with 1990 levels. But the IPPR argues in its study that in order to do so ministers will have to loosen their own fiscal rules, which cap borrowing for investment at 3% of GDP annually. The former Labour leader Ed Miliband, a co-chair of the IPPR’s environmental justice commission, said the budget needed to put climate change at its heart. “This will take investment but making these decisions will create hundreds of thousands of jobs, improve our natural environment, cut air pollution and make Britain a better place to love,” he said. “It makes economic and environmental sense.” In order to hit net zero within 30 years, the UK will need to be running on renewable energy with industry using mostly carbon-free processes. All homes and other buildings will have to be fully insulated and public transport will need to be greener and more efficient. Currently the government spends about £17bn a year on measures related to the climate and environment, which, the study shows, would not even be sufficient for it to meet its previous target of an 80% reduction in greenhouse gas emissions by 2050. The IPPR calculates it would need to spend an additional £11bn just to meet that previous target. The Green MP Caroline Lucas, another co-chair of the environmental justice commission said that the economic shock to the economy from the coronavirus made investment in the green economy even more necessary. “This budget will be a litmus test of whether the government understand the climate crisis, and on the basis of the evidence they are falling terrifyingly short of what is needed,” Lucas said. “With likely shocks to the economy because of the coronavirus outbreak, and the accelerating climate emergency, investing in a green new deal is now more important than ever. “It wouldn’t only help us address the climate and nature emergencies, it would transform almost every aspect of our economy and society and deliver on government promises to level up the nation by making our economy fairer and fit for the future.”"
"Ice sheets respond slowly to changes in climate, because they are so massive that they themselves dominate the climate conditions over and around them. But once they start flowing faster towards the shore and melting into the ocean the process takes centuries to reverse. Ice sheets are nature’s freight trains: tough to start moving, even harder to stop. We know this process has been going back and forth throughout history – it’s why we’ve had ice ages and warm periods. But until now we haven’t known exactly how quickly ice sheets retreated and reformed. New research published in the journal Nature Communications gives us an answer, and it isn’t great news.  It turns out sea levels often rose at scary rates in response to natural climate changes, long before mankind began pumping carbon into the atmosphere. In the short-term sea level is affected by ocean warming and so-called “thermal expansion”, or melting glaciers based on land. These changes can occur quickly – within a decade – but their impact on sea level is relatively small, in the tens of centimetres. The drivers of longer-term sea level rise, over decades or centuries, are the continental ice sheets of Greenland and Antarctica.  On the fringes of these ice sheets are “ice shelves” stretching far out into the ocean. Ice shelves can be hundreds of meters thick and, because 90% of ice in water floats below the surface, they remain “grounded” on the sea floor as long as the sea is less deep than 90% of the ice shelf thickness. Where the sea floor is deeper or the ice shelf gets thinner, there will be an area of floating land ice; here, warming ocean water can get underneath and melt the ice. Once sufficiently destabilised, an ice shelf can break up catastrophically.  Such an ice shelf collapse takes the brakes off the ice stream that feeds into the ice shelf, and land ice starts to flow much quicker towards the ocean.  Ice flow is a relatively slow process, and it takes some forcing to get a major ice sheet to systematically respond (like trying to set a fully loaded freight train into motion). Once moving, however, it will be equally hard to arrest that movement (like trying to stop a moving, fully loaded freight train).  Still, we cannot ignore it, because the sheer volume of land ice on Earth is enormous – equivalent to more than 65m of global sea level rise; Greenland alone accounts for 6 to 7m, West Antarctica for some 5-6m, and East Antarctica for the remainder. These melting ice sheets will dominate major sea level changes for centuries to come.  We can learn something about what to expect by examining sea level changes during the past five ice-age cycles (past half million years), especially through comparing them with the total amount of ice on the planet at the time. During a peak ice age, Earth held almost three times as much land ice as it holds today. For instance, during the most recent ice age the ice sheet over North America was 10-20% larger than the one we see today over all of Antarctica. During warm periods in between ice ages the sea was often close to its present level but occasionally reached up to 8 or 9m above today’s shoreline – the equivalent of melting 1.3 Greenlands today. To get a sense of how quickly the sea went up and down, we need highly detailed and well-dated records. Over the past decade I’ve led a team of scientists at the University of Southampton and the Australian National University who have developed such records using data from the Red Sea. The Red Sea has a very shallow and narrow connection with the open Indian Ocean. It also evaporates quickly – the equivalent of 2m of water each year – so new water must constantly flow in to top up sea levels and to avoid it getting too salty.  But such inflow is restricted by the tiny gap between Djibouti and Yemen, and in the past that connection was even smaller. As a result, the Red Sea was much saltier during previous ice ages, when sea level stood more than 100m below the present. Using microfossils from drill cores from the sea floor we can measure salinity through time and translate this to sea level changes in the Red Sea connection with the Indian Ocean. We were able to assess timings more accurately by comparing these sea level records to climate records from caves, which can be precisely dated by looking at radioactive decay in uranium. So now we had a detailed sea level record, with a well-defined timescale. Finally, we could work out rates of past sea level changes, and compare changing sea levels with well-dated reconstructions of temperature and CO2 changes (from ice cores). This allowed us to assess the speed of some 120 sea level rises in the past. Previously, this was possible only for one recent event. Now, for the first time, we had the information to look at how sea levels responded to natural climate change. It appears the sea level could rise as quickly as 5.5m per century. However this only happened at the abrupt endings of ice ages, starting with about three times the modern ice volume. When starting with double the modern ice volume or less, sea levels did not rise faster than 2m per century. When global ice volume was similar to the present, the sea typically rose less than 1 to 1.5m per century.  So it seems the fastest losses of ice occur when there is more ice. Not much of a surprise, perhaps, but now at least we have some real numbers to say how fast, and how much ice. And the speed the sea can rise during periods with modern ice volumes is still worrying – a 1m rise this century would hugely affect millions of people. Given that Earth has achieved these rates even when warming was much slower than today, such a rise is very possible. In the 120 different events we looked at, ice sheets went from initial change to maximum retreat within 400 years 68% of the time, and within 1100 years for 95%. In other words: once triggered, ice sheet reduction (and therefore sea level rise) kept accelerating relentlessly for many centuries.  Research we carried out previously found that modern sea level rise seems to be conforming to what we would expect from (high end) natural responses to warming. That is: after 150 years of increasing (man made) warming, the ice sheets would only recently be reaching the point where they start making a noticeable contribution to sea level rise.  But that time has come and, once ice sheets start to melt, the freight train is in motion. It will then keep moving for many centuries to come, no matter how hard we stamp on the brakes."
"**The covid crisis is on track to cut average pay packets by Â£1,200 a year by 2025, according to new analysis.**
The prediction comes from the Resolution Foundation, a think tank focused on improving living standards for people on low-to-middle incomes.
It comes a day after Chancellor Rishi Sunak warned unemployment could surge to 2.6 million by mid-2021.
The economic downturn will continue to squeeze living standards in Britain warned the foundation.
""The Covid crisis is causing immense damage to the public finances, and permanent damage to family finances too, with pay packets on track to be Â£1,200 a year lower than pre-pandemic expectations,"" warned Torsten Bell, chief executive of the Resolution Foundation.
Its new research published on Thursday, Here Today, Gone Tomorrow, says that ""the combined effects of weaker pay growth and higher unemployment will serve to prolong Britain's living standards squeeze"".
Its analysis shows household incomes have been growing at a slower pace even before the pandemic.
They are on course to grow just 10% during the 15 years from the start of the 2008 global financial crisis until 2023.
But household incomes grew by a much higher 40% in the 15 years leading up to the financial crisis.
The Resolution Foundation says further pressure will come next April, when about six million households will lose more than Â£1,000 through reduced Universal Credit payments.
It also warned the bulk of the government's extra spending to deal with the ""economic emergency"" will need to come from tax rises.
""While the priority now is to support the economy, the permanent damage to the public finances mean taxes will rise in future,"" added Mr Bell.
""The pandemic is just the latest of three 'once in a lifetime' economic shocks the UK experienced in a little over a decade, following the financial crisis and Brexit,"" he added.
""The result is an unprecedented 15-year living standards squeeze.""
In Mr Sunak's Spending Review he pledged Â£280bn this year to help get the country through the pandemic downturn.
""But which taxes those will be, like which Brexit we can expect, are questions the chancellor left for another day.""
The chancellor told MPs the UK economy is predicted to shrink by 11.3% in 2020, which has been described as the ""largest fall in output for more than 300 years""."
"**A series of portraits of school leavers dressed for proms that never took place because of the coronavirus pandemic has won a Â£15,000 prize for photography.**
The judges of this year's Taylor Wessing Prize felt Alys Tomlinson's Lost Summer ""spoke to the events of 2020... without being heavy handed.""
London-based Tomlinson said she wanted to show her subjects' ""vulnerability, sadness [and] resilience"".
It is the first time that all three winners have been women.
The prize has been running for 18 years, and this year's chosen competition entries can be viewed online until 31 March.
The exhibition \- which features 54 portraits from 37 artists - is displayed in a virtual gallery space that replicates the rooms of London's National Portrait Gallery.
A second prize worth Â£3,000 went to Lydia Goldblatt for Eden, part of a series which draws on mothering and family life.
The artist used four people within a 50-metre radius of her London home to create the series, which includes her winning image of a child in a tent.
The judges, who included British Vogue editor Edward Enninful, felt the image ""embodied the psychological complexity of the events of this year"".
Goldblatt said her photo of ""a child protected but alone... articulate[s] a psychological suspension in which both joy and fear oscillate.""
Another competition entry, Yolanda Y Liou's portrait of plus-size model Enam Asiama, was chosen to receive a third prize worth Â£2,000.
The Taiwan-born photographer, now based in London and Brighton, said she wanted to capture her subject's ""confidence and charisma"".
According to the judges, her ""empowering"" and ""confident"" portrait conveys ""a sense of authentic identity, collaboration and trust"".
Asiama, who Identifies as ""a Black, African-British, fat, queer and femme individual,"" uses social media to fight for inclusivity and visibility for plus-size role models.
This year's contest saw 5,531 submissions entered by 2,169 photographers from 75 countries.
_Follow us on_Facebook _, or on Twitter_@BBCNewsEnts _. If you have a story suggestion email_entertainment.news@bbc.co.uk _._"
"

Economists agree that as long as energy prices are accurate (that is, as long as prices reflect total costs), the “right” (optimal) amount of investment in alternative energy will occur because capitalists like profits. If alternative energy makes economic sense, market actors will quickly figure that out from the price signals they receive and invest accordingly. Only if prices are inaccurate is there the possibility that government can improve market outcomes through taxes on or subsidies of particular energy sources.



Thus, the case for government promotion of alternative energy depends solely on the existence of inaccurate price signals in energy markets. Many argue that the cost of environmental pollution is not reflected in the price of energy. But governments aggressively regulate environmental emissions affecting air, land, and water quality. Those regulations impose costs that are then passed on to consumers. George Mason University economist John Nye persuasively argues that existing empirical work is incapable of telling us whether energy prices are “wrong” or, if so, how wrong they might be.1



Are the environmental regulatory costs embedded in final energy prices greater than, less than, or equal to the environmental damages imposed by energy consumption? No one knows for sure. Estimates of the environmental damages associated with energy consumption vary widely because health and medical professionals remain uncertain about the implications of long‐​term exposure to small concentrations of pollutants.2 Vanderbilt regulatory specialist W. Kip Viscusi, however, has found that — if we accept EPA assessments of these matters — oil prices fully reflect environmental costs, natural gas prices are overly high given the disparity between the external environmental costs associated with gas consumption and the regulations in place to control those emissions, and coal prices are too low because the regulations controlling coal emissions are not strict enough relative to the environmental damages that follow.3



Viscusi’s findings are not definitive, however, because the EPA might well be wrong about the health effects of conventional pollutants. The literature provides plenty of evidence for those who want to argue that true environmental damages are higher or lower than EPA believes. And Viscusi doesn’t consider greenhouse gas emissions in his calculations. But a recent survey of the literature by climate economist Richard Tol finds peer‐​reviewed estimates of the marginal impact of greenhouse gas emissions also vary widely because of scientific, technological, and socio‐​economic uncertainties about the future.4 Moreover, those widely disparate cost estimates are largely driven by different beliefs about how to best price (discount) impacts that will occur in the distant future.5



The argument that energy prices are wrong because they don’t account for the national security costs associated with energy imports is even weaker.6 While it is probably true that U.S. military expenditures would be lower were the Pentagon not charged with the task of protecting friendly oil producing states and international oil shipping lanes, those expenditures are unnecessary. If the U.S. didn’t provide oil security services for oil producers, oil producers would provide those services themselves as long as the marginal benefit of oil security expenditures exceeded the marginal benefits associated with alternative expenditures.



A separate national security issue is whether money spent on oil abroad worsens the problem of international terrorism. Conventional wisdom would answer yes, but we have analyzed the data and concluded there is zero correlation — none! — between oil profits and either the number of fatalities or the number of attacks from Islamic terrorists. Oil revenues fatten the coffers of anti‐​American regimes abroad, but there is no relationship between oil profits and anti‐​American actions from hostile states.



Finally, some argue that the reliance on imports leaves America vulnerable to embargoes. But once oil leaves the territory of the oil producer market agents — not the producer — decide where the oil goes. Fears of producer blackmail are greatly overblown because oil producing economies are far less diversified than oil consuming economies. For example, 85 percent of Iran’s government revenue comes from the oil sector whereas only about 3 percent of U.S. disposable income is spent on oil and gas.7 Unilateral production cut‐​backs to achieve foreign policy goals would prove far more economically harmful to producers than to consumers.



Even if we think that prices for conventional energy are too low because they don’t account for environmental or national security externalities, governmental intervention to promote alternative energy sources would not be the best remedy. Better would be an explicit or implicit tax on conventional energy to get prices “right.” Correcting price signals allows the market rather than the government to pick industry winners. 



Getting prices right would change the energy status quo but allow actors to find the best option through trial and error with their own money. We don’t know whether alternative fuels (solar or wind), better controls on existing fuels (clean coal), a different mix of existing fuels (more nuclear), or energy conservation is more cost effective, and thus markets rather than government should decide. And even if we were confident about such things given the current state of knowledge, allowing markets to sort through the choices allows for a rapid change in investment patterns should technology change. Markets respond more quickly and more efficiently to changing economic conditions than do political or regulatory bodies.



If you are bullish about economics and future potential of alternative energy, then rigging the market to promote alternative energy is unnecessary. If you are more skeptical, then rigging energy markets to favor alternative energy is counterproductive. No school of serious thought, however, leads us to the conclusion that targeted assistance is the best policy. 



_This piece was submitted as the initial argument in a Google Knol debate. The full debate, including opposing arguments and rebuttal, can be foundhere._



  

"
"**Nottinghamshire will return to the highest tier of Covid-19 restrictions, it has been confirmed.**
The move comes after a four-week England-wide lockdown, which has seen Nottingham city and the county's infection rates drop.
Unlike last time, when the county agreed additional restrictions, tier rules will be the same across England.
The council said they understood this means measures such as the 21:00 alcohol sale curfew have been dropped.
Though the Department of Health and Social Care acknowledged ""an improvement"" in infection rates in the city and county, it highlighted the ""very high"" levels among those over 60 (211 per 100,000) and a ""high"" proportion of hospital beds taken up by Covid patients.
Health Secretary Matt Hancock said tier levels will be reviewed ""in a fortnight"" and kept ""regularly under review after that"".
Nottingham became one of the first areas in the country earmarked for tier three restrictions after it ended up with the highest infection rate across the UK in early October.
After lengthy discussions, it was then agreed to put the whole county into the same tier, which came into force from 30 October and included extra rules such as the ban on late night alcohol sales.
One day later, Prime Minister Boris Johnson then announced all of England would enter lockdown, which began on 5 November and ends on 2 December.
Tattoo parlours, tanning and nail salons and some businesses such as betting shops and auction houses also had to close.
Nottinghamshire County Council said they understand local rule variations will no longer apply.
Nottingham City Council leader David Mellen, who had written to the prime minister to stress the work done to cut rates, expressed disappointment at the area's tier placing.
""It's a bitter blow for people in Nottingham who have done the right thing, followed the rules and done an incredible job of driving down the rate of Covid infections from the highest in the country to below the national average,"" he said.
""We had hoped that this would have meant we would be spared going into tier three and the extra restrictions that come with that being imposed on local people and struggling local businesses.
""We will need [central] government to provide further support for businesses, especially hospitality where they will be particularly badly hit, to see them through this as the amounts offered so far won't be enough.""
John Clarke, leader of Gedling Borough Council, said he was ""very angry"" at the move.
""They might as well put up a big sign saying Nottinghamshire is closed,"" he told the Local Democracy Reporting Service.
""I appreciate the problems health-wise and everything else, but the damage to the economy - God knows when we're going to be able to repair it, or even start to repair it.""
After the students returned in September, Nottingham saw a massive increase in rates.
Since then, the rates have been steadily falling and the hope was locally that they would avoid the worst restrictions this time round after lockdown but it appears that is not going to be the case.
Meanwhile, outside of the city, Nottinghamshire will also be going into tier three.
Again, rates have been steadily falling in recent weeks but they are still quite high in some parts of the county, particularly in the north.
Politicians there have been appealing for them to avoid the worst of the measures but it appears those appeals have fallen on deaf ears.
According to the latest figures, the infection rate in the seven days up to 21 November is 203.1 per 100,000 people in Nottingham.
In the previous week, the rate was 262.2, while at its highest the rate was nearly 1,000.
Neighbouring authorities have also recorded decreasing rates, with Broxtowe, Gedling and Rushcliffe all now under 200 cases per 100,000 people.
In the north of the county, Mansfield's infection rate has dropped from 334.8 in the week up to 14 November to 280.8, while Ashfield has gone from 302.5 down to 257.2 and Newark and Sherwood has dropped from 248.3 to 195.2.
Earlier this month, Nottingham and Nottinghamshire Clinical Commissioning Group's Dr Amanda Sullivan said the county's hospitals are treating 50% more people with Covid-19 compared to the first wave.
_Follow BBC East Midlands on_Facebook _,_Twitter _, or_Instagram _. Send your story ideas to_ eastmidsnews@bbc.co.uk _._"
"
Share this...FacebookTwitterToday we have learned that a true champion and warrior in the fight against global warming and CO2 emissions has passed away, read, and see video here.
Kim Jong Il, The Great Climate Protection Leader Jr., died of a heart attack at the age of 69. No leader had done more in capping CO2 emissions, saving energy, and taking responsibility for rescuing the world climate than Kim Jong Il. See for yourself:
This North Korean society, led by the guiding hand of an all-knowing leader and class, is the perfect role model for true global warming activists. This is climate protection at its best. Has the IPCC put out a statement on the Great Climate Leader’s death?
James Hansen not long ago praised China‘s autocratic regime as a beacon of hope, for example. There, sustainable living could be decreed by law. No doubt Hansen, along with Gore, Schellnhuber, and their likes, are all deeply moved by North Korea’s exemplary social austerity, all benefiting the climate.
Hysterical collective mourning like hysterical climate fear in the west
When you get down to it, the propaganda methods used by North Korea to herd its people into a mass collective mourning are hardly different than those used by the extreme climate alarmists in herding people into climate fear today.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




When I saw the images of people collectively weeping and sobbing hysterically in the Reuters report linked above or the clip that follows, it immediately reminded me of how collective hysteria has swept through the ill-informed – dis-informed – here in our society, people all drugged up with propaganda.
Isn’t the North Korean mourning hysteria eerily similar to the extreme weather hysteria we are witnessing today among the multitudes of kooks of our society today? The hysteria is in fact being fanned by the duped media, duped politicians, and leading “scientists”. When are people going to wake up from this trance?
Look at the kook warmists today – running around with carbon calculators, a copy of AIT at home, fretting about every gram of emitted CO2, worrying about the weather in 100 years, thinking every weather anomaly is caused by SUV-driving, changing their entire lifestyles thinking that it’ll render us nice weather.
My daughter today had to watch “The Day After Tomorrow” at the Gymnasium upper secondary school. The teacher thinks its real! Just like in North Korea. In a few months she’ll complete her A-levels and be out of that nuthouse.
In the meantime they have to be as dis-informed and nutty as those sobbing hysterically over the loss of a brutal tyrant.
UPDATE: Excellent documentary of life in Utopia.

Share this...FacebookTwitter "
"Aditya Chakrabortty’s analysis of the budget (Johnsonism’s first budget is floating on hype and hot air, 12 March) does an excellent job of explaining that while it may be a move away from the austerity politics of the last 10 years, it is certainly not what we would have hoped for from a Labour budget in terms of helping the have-nots rather than the haves. I’m less sure this can be called Johnsonism, at least not yet. Thatcherism, a term used by the late Stuart Hall and others around Marxism Today in the 1980s, signified a new Tory policy of “authoritarian populism” as they saw it. Perhaps that does capture Johnson’s perspective. The significant change, however, was a move from looking to the manufacturing industry as the key source of riches for the wealthy towards the financial and services sector. By contrast Johnson’s policies seem to reflect a well-funded Micawberism. Something will turn up to allow him to stay in office and he’ll back whatever that may be. It hardly amounts to a coherent ideology.Keith FlettLondon  • In 1972, the then chancellor of the exchequer, Anthony Barber, delivered his now infamous “Barber boom” budget injecting the then unheard-of amount of £1.8bn into the economy. This confounded Harold Wilson’s Labour opposition who were at the time tearing themselves apart over, amongst other things, their poor economic growth performance while in government in 1964-1970. Like Sunak’s budget on Wednesday, the Tories were stealing Labour’s policy of Keynesian-driven growth. However, it all ended very badly for both the Tories and Britain, with the first recession since the second world war, rapid inflation, higher unemployment and the largest balance of payments deficit ever previously recorded. But by then it was Wilson’s problem as the Tories lost the February 1974 election. Will history judge Sunak’s budget in the same way it judges Barber’s?Alan BancroftLondon • It has long been acknowledged that the funding of social care is inadequate, that the system is in need of a major overhaul and NHS performance is intimately linked to care services. However, yet again – and despite earlier claims that Mr Johnson is a “man with a plan” – the issue has been ignored by a chancellor who found no difficulty spraying public money around. The health and social care secretary may justify his colleague’s inaction by telling us that he is convening cross-party discussions to arrive at a consensus, but surely even he can see that one of the ways of oiling the wheels of collaboration is to provide a budget against which sustainable solutions can be developed and introduced.Les BrightExeter • The chancellor’s announcement of a “green gas levy” might appear to be a welcome step in battling the climate emergency (UK takes first small steps to tackle carbon from worst polluters, 12 March), though it’s worth noting that the non-domestic renewable heat incentive (RHI) has subsidised the production of “green” natural gas (biomethane) for a number of years, and is funded from general taxation. So potentially this isn’t a new measure, and is just moving the funding from indirect taxation to a regressive direct tax.Simon RichardsBeaconsfield, Buckinghamshire • Budget day was a wonderful opportunity for the chancellor to have an impact on the country’s carbon output by increasing the fuel duty at a time when the price of fuel was falling. When is the government going to take the climate crisis seriously?Dr David RoweNewcastle upon Tyne • Let’s state the position in simple words: a budget that is just repairing the damage to the British economy and social wellbeing brought about by 10 years of unnecessary Tory austerity government. Few will understand that, far too many will be taken in.Les SummersKidlington, Oxfordshire • All these extra billions to spend on infrastructure and broadband; did Labour win the election, or are the Conservatives now communists?Pete DoreyBath, Somerset • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition  "
"The UK’s biggest fund manager has bowed to client pressure and agreed to launch its first fossil fuel-free ethical pension fund later this year. Legal & General Investment Management (LGIM), which has been one of the most outspoken fund managers over the climate crisis, made the decision after a number of clients raised concerns that stocks such as Shell were still being included in its range of ethical funds. Those clients include PensionBee – an online pension provider that handles £750m-worth of client assets for more than 75,000 customers – which is expected to be among the new fund’s first investors. It wrote to LGIM last year after being inundated with questions from its own customers about the fact that Shell was among the top 10 holdings in one of the investment firm’s ethically focused Future World funds. PensionBee is believed to be one of the fund’s top five owners, with more than £60m invested. “It is clear that there is increasingly strong demand for pension products that give customers the choice to divest from oil,” PensionBee said. While the full stock list for the new fossil fuel-free fund has not yet been confirmed, it will exclude oil companies and take a wider ethical stance by barring investments in tobacco, weapons makers and pure coal manufacturers. Emma Douglas, the head of defined contribution at LGIM, said: “Based on our funds in our Future World range, the new fund will be driven by long-term thematic analysis, the integration of environmental, social and governance (ESG) considerations and active ownership, which means engaging to bring about real, positive change in the companies we invest in.” LGIM, which has more than £1tn in assets, said the fund will be open to corporate pension schemes and individuals. The investment firm has defended holding Shell in its Future World range of funds. Those funds are governed by its climate impact pledge, meaning it is willing to exclude companies over poor governance and weak climate disclosures, as well as for lobbying politicians on policies that risk accelerating the climate crisis. LGIM has said it needs to balance environmental and financial concerns when putting together the investment portfolio, previously noting that Shell is one of the largest payers of dividends in the UK. Its climate pledge has led LGIM to dump stakes in China Construction Bank, Rosneft Oil, Japan Post Holdings, Subaru, Loblaw and Sysco Corporation in 2018. Last year, it cut a further five stocks from the ethical funds, including the oil corporation ExxonMobil, the insurer MetLife, the maker of Spam, Hormel Foods, the US retailer Kroger and Korea Electric Power Corporation (Kepco) last year. However, a Guardian analysis last year also found LGIM as a whole had spent about $367m (£285m) between January and November, increasing its stake in those companies in other parts of the business, even when accounting for the divestments. LGIM openly admits it continues to hold stakes in companies excluded from those environmentally and socially focused funds, saying it gives them the opportunity to engage with the board and ultimately influence company behaviour. Commenting on the launch of the fossil fuel-free fund, PensionBee said: “We hope this is just the start of all savers using their investments to transform the world they live in – for the better of the planet, society and their retirement.”"
"
Guest Post by Willis Eschenbach
Having spent a reasonable amount of time there, I have the highest regard for Australia and Australians. In general they are good, level-headed folks.
Unfortunately, the same can’t be said for the people who wrote the Waxman-Markey website page on Australia. I discussed the first of their “Impact Zones” here, please read it for an overview of the Waxman Markey site. This thread discusses why you need to be very careful with the Waxman Markey “facts” about Australia – they bite.

Figure 1. An Australian example of what we surfers call “the man in the gray suit”.
The website says:
Drought
Global warming is a major contributor to Australian drought. Record high temperatures are increasing evaporation, damaging vegetation and reducing water for irrigation in the continent’s agricultural basin. Sustained high temperatures are as hazardous for people as they are for plants. The average annual death toll from heat waves is over 1,100 people in Australia and that number only stands to increase.
In 2006, Australia experienced its worst drought in the last millennium. The Murray-Darling River System, which produces well over half of the country’s water supply, dropped 54 percent below its record low.
BZZZZT! Bad website, no cookies! Another factual error, and another big lie.

First, the factual error. The website links the claim of the “worst drought in the last millennium” to that noted scientific journal, the Guardian newspaper. It in turn says:
Australia suffers worst drought in 1,000 years
Australia’s blistering summer has only just begun but reservoir levels are dropping fast, crop forecasts have been slashed, and great swaths of the continent are entering what scientists yesterday called a “one in a thousand years drought”.
With many regions in their fifth year of drought, the government yesterday called an emergency water summit in Canberra. The meeting between the prime minister, John Howard, and the leaders of New South Wales, Victoria, South Australia, and Queensland was told that more than half of Australia’s farmland was experiencing drought.
David Dreverman, head of the Murray-Darling river basin commission, said: “This is more typical of a one in a 1,000-year drought, or possibly even drier, than it is of a one in 100-year event.”
What’s wrong with their statement? A number of things. First, “scientists” didn’t say anything about a one in a thousand year drought. That was said by David Dreverman, who is the head of the local Murray-Darling river commission.
Second, Mr. Dreverman did not base that statement on a thousand years of drought records preserved in tree rings, or on other proxies, or on any observations at all. It was simply a mathematical estimate of what is called a “return period” based on a probability distribution, not a scientific statement of historical fact. Here is a link (PDF) to how it was calculated.
Third, his statement was only peripherally connected to the drought. He was actually talking, not about the drought, but about the return period of the flow of the Murray River.
Fourth, he either didn’t notice or didn’t want to comment on the other reasons why the Murray River is so low.  Here (PDF) are some of the reasons:
So why is there less water?
The amount of water that ends up in the Murray river has changed because:
•	More farm dams have reduced run-off by between 660 and 2,400 gigalitres (Gl) per year
•	Groundwater pumping has reduced run-off by 327 gigalitres per year
•	regrowth from the bushfires in early 2003, when over a million hectares of
native forest was burnt, could reduce run-off by 430 gigalitres by 2020
•	new plantations could have further reduced inflows by 1,100-1,400 gigalitres per year
•	farmers have increased the water holding capacity of their soil by adopting minimum tillage.
So that’s the factual error. The 2006 drought was serious, there’s no question about that. But there is no scientific evidence that it was the biggest drought in a thousand years. That’s just alarmist hype.
If that’s the factual error, where’s the big lie?
The big lie is that global warming is making Australia drier. Or as the website says:
Global warming is a major contributor to Australian drought. Record high temperatures are … reducing water for irrigation in the continent’s agricultural basin.
Why is that a big lie? Because Australia has has been getting wetter as the globe warmed over the last century.
How do I know that? Well, that’s what the Australian Bureau of Meteorology says. Here’s their information about Australian rainfall, from their website.

Figure 2. Changes in rainfall, Australia, 1900-2009
No sign of a problem there, rainfall is increasing. It has increased by about 80 mm (3″) over the last century. Note that (as has been true for millennia), the rainfall in Australia comes in fits and starts. It is not uncommon for a year to have twice the rain of an adjacent year.
Now I can hear you thinking “But what about the places that were hit by the drought? The Murray-Darling River basin (of “1,000 year drought” fame) and West Australia and South Australia were all hit very hard in 2006. They must be drying out.”
We are nothing if not a full service website:

Figure 3. Changes in rainfall, Murray Darling Basin

Figure 4. Changes in rainfall, South Australia.

Figure 5. Changes in rainfall, West Australia.
No reduction in rainfall there either. Yes, there was very little rainfall in 2006 in South Australia and the Murray Darling Basin and West Australia … but in all cases, there have been worse years in the historical record.
Finally, there must be some areas of Australia that are getting dryer, aren’t there? Of course. It’s a big place. Here’s an overview of the country, showing the changes since 1900:

The overwhelming majority of the country has gotten wetter. A few places have dried slightly.
SUMMARY: Their web page contains one misrepresentation of fact about droughts, and one big lie.
Misrepresentation of fact: the 2006 drought was not the biggest in a thousand years. Most places it was not even the biggest drought in the historical record.
THE BIG LIE: When you look at the full record for Australia, it is evident that as the globe warms, Australia is not drying out. It is getting wetter.
The big lie is that “global warming” is reducing the rainfall in Australia. In fact, it is increasing the rainfall … go figure.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8aa28569',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Extinction Rebellion burst onto everybody’s screens with disruptions and mass arrests across the UK and around the world in protest against government inaction on climate change. Radical disruptions have been at the heart of Extinction Rebellion’s activism since it was founded in 2018 – from January’s disruption of London Fashion Week, to the infamous naked protest in Parliament at the beginning of April. But the scale of the most recent actions has finally succeeded in forcing mainstream news cycles to start giving the politics of climate change the attention it deserves. One could argue that Extinction Rebellion’s week of action was fortunately timed – the extension of Article 50 to October has created something of a news vacuum while everyone takes a momentary breather from Brexit. Nevertheless, activists would rightly claim that climate change is the bigger looming catastrophe.  In October 2018, the UN’s climate agency published grave projections of the enormity of the challenge ahead if we are to limit the most catastrophic consequences of climate change. For both Extinction Rebellion and the Fridays for Future school strike movement, the piecemeal response of nations at the UN’s annual climate change conference in Poland in December 2018 made it clear that there is no more time to lose. The aim, then, is to force the issue. Through their blockades of iconic central London sites, Extinction Rebellion is keeping climate change at the forefront of the public and politicians’ lips, making the seemingly abstract problem facing all of us feel real. And rather than just warning of this climate emergency, it offers a vision of an alternative future, where a Citizens’ Assembly takes the lead in reducing UK emissions to net zero. Perhaps inevitably, Extinction Rebellion’s actions have been met with a familiar backlash from some political commentators – witness Adam Boulton’s sneering performance on Sky News, and David Blunkett’s indignant authoritarianism in the Daily Mail. But while activists say they regret the disruption caused to working people, they consider their actions a necessary evil in order to change the conversation. Older activists will surely point to the impact and legacy of 1999’s Battle of Seattle, when the Global Justice Movement successfully closed down the World Trade Organisation’s annual meeting. Not only was this extremely empowering for those involved, it crucially helped make resistance to a largely abstract neoliberal governance structure seem concrete and real. Much like the Occupy demonstrations seven years ago, Extinction Rebellion’s latest eye-catching protests have been friendly and open, laden with artistic performances, talks and human connection. This good-natured spirit has so far meant that the movement has gained significant traction – not only on the airwaves, but on the streets too. Extinction Rebellion’s efforts are aimed at building momentum and are based in political science – their website highlights that it takes just 3.5% of a nation’s population engaged in sustained nonviolent resistance to topple a dictatorship. In the UK, that’s less than 2.5m people. 
Their clear demands and principles give the movement a clarity and focus that the Occupy movement may have lacked, and they are growing week by week – Extinction Rebellion says that 50,000 people have joined the movement since the protests started. But contemporary mainstream news cycles are fast and fickle, so the movement will have to act quickly and carefully to maximise use of its new-found public platform. It’s extremely important that the movement’s purpose does not become overshadowed by its tactics. Extinction Rebellion has ransacked the playbook of direct action repertoires – blocking roads, using fake blood, recreating funeral marches, and surprise nakedness. While these have so far been successful in bringing the movement’s name and cause to the fore, using such tactics ad nauseum can quickly lose the public’s imagination and support. This was evident in the Global Justice Movement of the 2000s, as the desire to recreate the euphoria of Seattle resulted in tactical “summit hopping” with diminishing returns. State agencies also learn quickly how to police repeated mobilisations more ruthlessly and extremely – although Extinction Rebellion’s “trademark” repertoire, the tactical use of mass arrests, so far appears to be combating this threat effectively. Police have powers to disperse protesters, but the sheer number of people now willing to be arrested shifts the balance of power between the public and the state. For example, police have so far been unable to clear any of the four sites in central London, as spates of arrests were closely followed by new wave of protesters arriving to entrench control. The city’s police stations do not have the capacity to hold hundreds of arrested protesters for long periods, and court costs will discourage officers from pursuing charges, limiting the punitive power of the state. At the same time, Extinction Rebellion’s tactics risk fetishising the act of being arrested as a symbol of participants’ commitment to the cause. The movement’s co-founder, Roger Hallam, recently told the BBC that in order to achieve its goal of “getting in the room with government”, it may need to create a law and order crisis on the scale of 1,000 arrests. Such an arbitrary target is problematic, as it may encourage activists to take more risk in pursuit of a goal that is by no means guaranteed. Even if one is critical of the politics seemingly behind many “aggravated trespass” charges, a criminal record can be extremely costly and cause significant problems for many younger activists – especially people of colour. This contrasts with the relative risks posed to seasoned activists whose job, lifestyle or privilege allows them to ride the consequences. It is crucial that Extinction Rebellion fulfils a duty of care to support those who are prepared to put their bodies on the line but, with more than 900 arrested already, its an expensive, high-risk game should multiple criminal charges be brought. For now, Extinction Rebellion activists will consider recent events as a runaway success. They have gained visibility and traction – and have at least temporarily steered media attention away from Brexit. Most importantly, they have put climate change squarely in the middle of public conversation. Let’s hope it stays there. Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"Once again the concern is for economic growth (Tories splash the cash, but will it hit the right targets?, 12 March). When will rich countries like ours recognise that growth is damaging the planet and prejudicing the lives of our grandchildren? Rishi Sunak’s budget has allocated £27bn for roadbuilding and a further £4.2bn to eight local authorities for transport projects (Report, 12 March). He hasn’t said (and may not know) how much carbon dioxide these measures, and the resultant traffic, will add to the already overloaded atmosphere and the concomitant heating of the planet.  A rich country? According to the Social Metrics Commission, using government data, there are 14.3 million people living in poverty in the UK. On 11 March you reported that “food banks gave out more than 1.6m parcels last year”. What a national disgrace. It may be claimed that our economy needs to grow in order to support the poor, but there is little evidence that this happens. What is needed is a redistribution of existing wealth, not a grab for more. This could be achieved by the government legislating for citizen’s income, paid to every citizen as an entitlement, and recovered from the better-off by taxation. The Labour party is beginning to talk of this, the Tories should as well.Michael BasseyNewark, Nottinghamshire • I think I got a bit carried away with the idea that the 40-odd years of malingering Thatcherite neoliberalism was finally dead. There are still elements of the Conservative DNA and free-market ideology that persist (Journal, 12 March). Then there is the small matter of the power of the corporations that control our lives and the billionaires who control our media. Not quite time to give up the struggle for a socialist government.John AirsLiverpool • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitterThe Wall Street Journal Germany has an in depth analysis of the collapse of German solar module giant, Q-Cells: Too Close to the Sun – The Rise and Fall of Q-Cells.
It’s worse than we thought!
Last Tuesday the solar company based in Thalheim in Saxony-Anhalt, once the largest module manufacturer in the world, very quietly announced its results for 2011 – a blood bath. The company lost 850 million euros and is now teetering on the brink of bankruptcy, with no hope of a rescue. It is the latest in a series of spectacular solar company failures now ripping through the industry. The number of weird economic events keeps surging.
The Wall Street Journal reports how the company was founded by engineers in 1999 amid flourishing hope and optimism in what was supposed to become the cornerstone of Germany’s dreamed “Solar Valley”. The newly elected Socialist-Green coalition government, led by the newly elected Gerhard Schroeder, hailed it as the beginning of a new industrial era would sweep Germany into the 21st century. That future was secured by the passage of the Energy Feed-in Act (EEG) in 2000, which guaranteed producers of green energy fixed rates for 20 years and cheap low-cost credits for solar systems. This led to a boom in the solar industry and wind industry over the decade that followed.
Among the solar companies that sprouted overnight was Q-Cells. By 2005 the company had grown to 750 employees with annual sales of €300 million. Consulting company Ernst & Young named then Chief Executive Milner as Entrepreneur of the Year. Q-Cells expanded production and opened plants overseas, one in USA.
By 2007 the company had grown to over 1700 employees and sales of €860 million and profits of €150 million. Green energy seemed to be the way to go.
Today things don’t look rosy at at all. Q-Cells shares today can be bought for a €0.23, down from its peak of over €80 a few years back (click on 5 J., which is 5 years). Insolvency appears imminent. What happened? Everything seemed to be going right just a couple of years ago. But as the Wall Street Journal writes, everything actually had gone wrong.
As the industry boomed in Germany, thanks to mandatory feed-in rates paid to solar power producers, cheap manufacturers from China got into the act. Asian manufacturers tooled up on a massive scale and produced the modules at far lower prices. The price of solar modules on the global market plummeted. Then came the crash of 2009, the government rolled back the feed-in rates, Q-Cells had also neglected to invest in R&D. Single woes compounded and caught up. Now the company looks hopelessly doomed.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Wall Street Journal writes:
2011 – the prices dropped further – Q-Cells succumbed to high operating costs. Old production lines at its headquarters were no longer profitable. They are going to be closed, written off, the employees will have to go. By the end of the year the company had booked a loss of €850 million. Even worse: The company doesn’t see any profit until the year 2014. What remains is pure desperation.”
Is there a chance of a rescue? Stephan Wulf of Warburg Research is gloomy. For him the question is “whether Q-Cells can avoid insolvency and if it will be able to find a place on the global photovoltaic market. Looking at the strong competition from China, I have considerable doubt. about the prospects of Q-Cells surviving. ”
Those are hardly words that will encourage investors.
The Tagesspiegel also has a report  on how many renewable energy companies rode the gravy train for years, but did not bother to invest in R&D. Now it’s time to pay the piper.
Warmist scientist on supervisory board
By the way, one of Q-Cells supervisory board members is Prof. Dr. Eicke Weber, Director of the Fraunhofer Institute for Solar Energy Systems ISE, Freiburg. and a harsh critic of Fritz Vahrenholt’s and Sebastian Lüning’s skeptic book “Die kalte Sonne“. I guess there’s a lot we could learn from Prof. Weber.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Ed Caryl
In the BEST paper Influence of Urban Heating on the Global Temperature Land Average Using Rural Sites Identified from MODIS Classifications. Red dots are warming trend sites and blue are cooling trend sites. This article will show that Dr. Richard Muller did not go far enough in looking at that influence, and failed to account for winter temperatures as one moves further north.

Figure 1. This is Figure 4 from the BEST paper.

Figure 2. This is the Annual Mean temperature in North America. Source
Most of the temperature measuring sites examined by Dr. Richard Muller et al are in the U. S. In the paper cited above, they determined that 33% of the sites were cooling, and found a Gaussian distribution (Figure 3 below) in the heating and cooling that they blamed on measurement error. This seems odd, because the cooling sites shown on the map above do not have a random distribution, as they would if the Gaussian distribution was due to random error. Many are concentrated in the southeast quadrant of the U. S. It is very obvious that the red dot concentration around urban areas is due to Urban Heat Island (UHI) effect. But what is causing the blue, cooling effect in the southeast? Figure 2 is another map, the annual mean temperature in North America from 1950 to 2000. Note that the cooling area in Figure 1 is the warm area in Figure 2. Dr. Muller offered no explanation for the cooling in Figure 1.

Figure 3. From the BEST paper cited above showing the Gaussian trend distribution.
This author downloaded data from 71 sites with long, continuous, records (at least 1930 to 2000) scattered across the U.S. and Canada, concentrating on the cooling region and the areas north and west of it. Each location was (if possible) examined at Anthony Watts’ SurfaceStations.org web site, for metadata, especially the distance from the thermometer to the closest heated building. The populations of the surrounding areas were obtained from Wikipedia. The December, January, and February (winter) temperatures were downloaded from GISS, and the temperature trends from 1934 to 2000 were calculated for each site, as well as the average winter temperatures. Figure 4 is a plot of the average winter temperature versus the winter temperature trend for 71 locations.

Figure 4. This is the average winter temperature for 71 sites versus the warming or cooling trend over the period from 1934 to 2000. The average winter temperature was calculated over the period from 1930 to 1980.
The warming trend is obvious for locations with cold winters. The extreme example is Edmonton, Alberta, Canada, with 4.4 degrees C warming, with an average winter temperature of –11.9° C. The warming is, of course due to UHI. Edmonton grew from about 80,000 people in 1931 to 666,000 in 2001. The cold winter temperatures exaggerate the UHI effect. Figure 5 is a plot of warming versus current population.

Figure 5. This is a combined plot of the winter temperature trend (1934 to 2000) versus population (blue) and the distance from the thermometer to the nearest heated building, usually a residence (pink).
It seemed clear to this author before this study was begun, that a heated building close to the thermometer might skew the readings in a warm direction, and that this could be detected with a large sample. Figure 5 shows this is not generally true. The large surrounding population makes a large warming effect. This is exaggerated in the winter due to the difference between inside and outside temperatures causing more heat lost to the outside. This is not noticeable for single structures close by. The numbers were tortured until they confessed; there is little warming due to one farmer’s house 3 meters away, but several thousand homes in the immediate area produces a “heat bubble” that makes a difference. Heat going up chimneys far outweighs heat escaping from walls.
There are exceptions, of course. Figure 6 shows one notable one.

Figure 6. This is the weather station at Grand Forks, North Dakota. It is located at the NOAA/NWS Eastern North Dakota Weather Forecast Office. The Cotton Region Shelter (CRS) is located about 3 meters in front of the vent on the office heating/cooling plant. The Photo is from SurfaceStations.org.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The winter temperature trend at the Grand Forks NWS office is 2.9° C warming, about 1.5° C above what the population alone would account for. Another exception is the site at Albert Lea, Minnesota. (Figure 7.) The winter warming at Albert Lea is about 2.5°C over what the population would cause.

Figure 7. This is the water treatment plant at Albert Lea, MN. Buildings, water tanks, and waste-treatment ponds surround the MMTS. The Photo is from SurfaceStations.org.
These exceptions, and other locations like them, along with cities with large and growing populations, account for the red dots in figure one. The blue dots represent what the climate is really doing… cooling. The measured cooling does not extend into the cooler north and west because UHI warms these areas more than the south. UHI is exaggerated by the colder winters.
Is UHI a problem with rural sites with smaller populations, under 10,000? From the site collection, 50 sites with populations below 10,000 were sorted. These were in turn sorted into two groups by winter average temperatures. Figure 8 is the cooler group, Figure 9 the warmer.

Figure 8. These are plots of Winter Temperature and Temperature Trend versus Population at 25 sites with winter temperatures between 0°C and –10°C.

Figure 9. These are plots of Winter Temperature and Temperature Trend versus population at 25 sites with winter temperatures between 0°C and 10 °C.
Both Figures 8 and 9 show no change in temperature trend from 1934 to 2000 due to population. The average winter warming in both groups from 1934 to 2000 is about 0.5°C. But, there is significant winter temperature difference in both groups due to population. For locations with populations over 1000, winters are warmer, not getting warmer, but warmer all along. Why? These are all small towns and villages. They have been growing slowly, if at all, since the thermometers were installed. Population growth has been paced by improvements in heating system and insulation efficiency. But size is important. The absolute temperature in the winter is also important. BEST (and GISS) should recognize the need to reduce their rural population limit to 1000. Just looking for lights in the vicinity by satellite isn’t good enough. They must actually research the population and the location metadata. For locations with winters with average temperatures below freezing, special care should be taken to avoid close-by heat sources. It may be handy to locate a MMTS at the local water treatment plant, but it isn’t a good idea when measuring temperature.
What happened in the last decade? For a global view, GISS has a trend mapping application on their site. This was set to map the trend from 2001 to the end of 2011. Figure 10 shows the result.

Figure 10. The GISS map of annual (January to December) temperature trend (change) from 2001 to 2011. The –0.01 in the top right corner is the global trend figure, 0.01°C cooling. Source.
In Figure 10, the red grids showing 2°C to 4°C warming represent about 10 measuring sites, most on the Siberian Arctic coast. Those are warming because the wind is moving the ice away from the Siberian coast. Compare Figure 10 with Figure 1. Many red dots in figure 1 fall in the cooling area in Figure 10 above, the opposite of what the BEST paper shows. Those sites may have been warming over the period BEST used, but they are cooling now.
Note that in Figure 10, the continents appear to be cooling, with only land stations on the Arctic coast showing warming. The Pacific Ocean and the North Atlantic are mostly cooling. They will cool further as the continents continue cooling. We are now ten years into the next cycle in the regular 60 to 70 year warming and cooling cycles, and at the
end of a 200 year cycle that the earth has been experiencing since the Dalton Minimum (1790 to 1830). If the sun is indeed going into another Grand Minimum, similar to the Dalton or Maunder Minimums, and it looks like it will be most like the latter, the cooling may be very deep, and last for 40 or 50 years.
The USDA just released a plant hardiness zone map, moving the growing season northward by about one zone compared to the previous map. They may want to rethink that move. Last winter in southern New Mexico and west Texas the cold killed many Mexican palms trees, and other tropical plants, that had survived up to 100 years of previous winters. Thermometers may be made to lie, but plants can’t be fooled.
Conclusion
In the BEST paper, Dr. Muller failed to notice the change in UHI effect in northern stations, and thus missed the fact that cooling is really taking place in the continental U. S. as for myself, I wonder how cold it will be before Berkeley Earth discovers the cooling.
 
Share this...FacebookTwitter "
nan
"

Readers of recent news reports may think it’s news that U.S. emissions of carbon dioxide, the main global‐​warming gas, are at an all‐​time high. The real news would be if they dropped steeply, which could only occur with a very warm winter (less space heating), a very cold summer (less air conditioning) or a huge recession, because it takes energy to make things. 



Carbon dioxide has been called breath of our civilization, and as we are technologically constituted, it most certainly is. We burn fossil fuels (which combust mainly to carbon dioxide and water) for manufacturing, to go places, and to produce electrical power. While we could certainly substitute in more nuclear fuels for power production, the same forces that are so exercised about global warming being caused by carbon dioxide, in general, won’t permit the nuclear option. (That being the definition of environmental insincerity.) 



So it is not news at all that our emissions are at a record high along with GDP. What is more newsworthy is how the emissions per unit of GDP — the economic bang for the energy buck — continue their steady decline. We now produce a constant dollar’s worth of goods and services with only 78% of the energy we used in 1990. In 1990, we used about two‐​thirds of the energy we used in 1970 for the same dollar’s worth. These are remarkable increases in efficiency in the last 35 years. 



The New York Times recently reported that the 2004 change in overall emissions was nearly double the annual average, neglecting to report that single‐​year statistics are virtually meaningless. If one had taken the average of the last five years and compared that to figures generated back to the mid-‘90s, percent changes in emissions of carbon dioxide turn out to be remarkably constant. 



For 1999–2004 the increase averaged 0.8% per year. From 1996 through 2001 the change averaged 1.0%. Given year‐​to‐​year fluctuations, these numbers are indistinguishable from each other. 



The same applies on a global scale. Our computer models for global warming have assumed, for decades, that carbon dioxide would increase at 1% per year in the atmosphere. For those decades the real rate of increase has been quite constant, and less than half of 1%. In the ten years ending in 2004, the average rate of increase was 0.49%. Ten years before it was 0.41%, and ten years before that, 0.42%. This is why climate models have generally predicted too much warming, too fast — about twice as much, in fact. 



Taken together, all of these facts mean that most of the assumptions about the growth of global warming gases in the atmosphere have to be thrown out. There’s little, if any, exponential increase, and the vibrant economies continue to produce more and more things with fewer increments of carbon dioxide. 



But, if carbon dioxide is the cost of economic growth, it would seem obvious that it will continue its upwards ascent for the foreseeable future. 



Will it? The answer lies in the well‐​established trends towards increasing efficiency in economies such as the United States’ (despite the large number of SUV’s panting in increasingly long traffic jams). This did not happen here because of concerns about global warming — because no one really gave much of a care about it until New Orleans got smacked by a Category 3 (yes, it’s been downgraded) hurricane. 



Instead, the increases in efficiency resulted because businesses compete with each other to produce things that cost less to run and build. And, if they are built, people will come. And so do investors. 



As an example of this process, get on your Yahoo financial tracker and plot the stock performance of Honda, Toyota, GM and Ford for the last two years. You’ll find the share price of the producers of the Accord and the Camry up an average of 40% while the American companies have dropped 50% in value. 



This creates a snowball effect in a warming world. People in vibrant economies have capital to invest in increasingly efficient companies, which rewards them with more capital, which is re‐​invested etc. 



The prospering companies are efficient in many ways. They use less energy to produce cars in their newer plants. Their cars use less energy on the road. Their labor forces tend to be relatively young and they haven’t been promised the moon in benefits and retirement with 40% of their time on earth left to run. 



As these companies accumulate capital, they have been reinvesting it in development of even more efficient vehicles, some of which may emit no carbon dioxide at all, which means that some day the pressures for efficiency may indeed drive carbon dioxide emissions down. But, without investment in those technologies — made by private individuals in publicly traded corporations — be assured that development of the clean machines of the future will be delayed until the planet gets warmer than some might want it. 



(Disclosure: The author owns shares in Honda and Toyota, sold all of his shares of Ford in 2002, and a GMAC bond in 2005.)
"
"

Tony Blair is deeply unpopular and has already announced that he will soon step down as England’s prime minister. But that does not mean he will go quietly into that good night. As reported by the _Daily Mail_ , the UK government has announced a series of totalitarian steps to compel less energy use: 



Homeowners who refuse to make their properties energy efficient will face financial penalties under drastic government plans to transform Britain into the world's first 'green' economy. …The Government said that every new home should be ""carbon neutral"" within ten years — and existing properties subject to a ""home energy audit"" to assess how green they are.



Critics correctly note this is a massive intrusion into the private lives of homeowners:   
  
Blair Gibbs, of the Taxpayers' Alliance, said: ""It's bad enough that politicians want to take so much of our money away in tax. For them also to intrude into our homes in order to have the ability to penalize us even further is simply unacceptable.""   
  
But the government is undaunted, and, in a classic case of the pot calling the kettle black, Tony Blair even has the gall to state that his totalitarian initiative is akin to the fight against fascism:



People are to be encouraged to make ""more sustainable"" travel choices, including greater use of public transport, walking and cycling. The Government is also to invest in solar, wind and wave power. …Mr Blair compared the fight against climate change to the battle against fascism.



Sadly, the British people cannot count on the Tories to defend individual freedom. Under the feckless leadership of David Cameron, the Conservative Party is even further to the left than Labor. The Party of Margaret Thatcher has become a hollow shell, judging from the _Daily Mail_ 's reporting: 



Opposition politicians and green campaigners said the Government's proposals did not go far enough, insisting binding targets on emissions should be annual. Tory spokesman Peter Ainsworth said: ""There is a danger that the fiveyear approach will enable responsibility for failure to be shunted on from one government to another.""


"
"

Ten senators — seven Democrats, two Republicans, and one independent — have just returned with differing views from a tour of Greenland.



Bernie Sanders (I-VT) talked about the risk of Greenland’s ice sheet “being lost.” Barbara Mikulski (D-MD) said “melting Greenland ice would cause a 23‐​foot rise in sea levels worldwide.” Bob Corker (R-TN) was more circumspect, saying only that “we’re digging in to understand this issue.”



Sanders’ and Mikulski’s statements are reminiscent of Al Gore’s movie, _An Inconvenient Truth_ , which contains a montage showing much of Florida disappearing as Greenland melts away. This wacko scenario has never enjoyed much respect from the broad scientific community, and newly published research casts even more doubt on it.



Nonetheless, this climatological legend continues to beget junkets, and serve as the basis for carbon dioxide‐​reduction bills, currently before congressional committees, just as scary as Gore’s flick.



Take Senator Dick Durbin (D-IL)‘s “Global Climate Change Security Oversight Act.” It cites a United Nations Intergovernmental Panel on Climate Change projection that if, as is commonly projected, the earth’s mean surface temperature rises an additional 2–5 degrees F by 2100, the melting of Greenland will cause a sea‐​level rise of 6.5 to 13 feet.



The IPCC makes no such forecast whatsoever. On page 820 of its spanking‐​new compendium on climate change, it projects that the melting of Greenland will cause a rise in sea levels of between half an inch and 4.5 inches by 2100. If there were any acceleration of ice loss under a Gore‐​like scenario, the IPCC says there could be an additional sea‐​level rise of 8 inches.



Similarly, Senator John Kerry (D-MA) and Rep. Henry Waxman (D-CA), both find that “Risks associated with an additional temperature increase [of 1.8 degrees F] are grave, including the disintegration of the Greenland Ice Sheet.”



James Hansen, NASA’s chief climate modeler, espoused this scenario in a sworn deposition last year, but when asked whether he could cite a single scientist who agreed with him, he named no one.



And yet that gruesome scene is bullying Congress into passing hasty, ill‐​conceived policies on climate change.



In fact, the UN Intergovernmental Panel on Climate Change even _lowered_ its estimate of maximum likely sea‐​level rise for this century. The range used to be from 5 to 27 inches, but in the final version of its most recent climate compendium, the top figure is down to 19 inches. Those estimates assume that carbon dioxide emissions continue to rise at the average rate projected by a large number of future simulations.



The IPCC is very circumspect about its sea‐​level rise projections. “Models used to date do not include uncertainties in the climate‐​carbon cycle feedback nor do they include the full effects of changes in ice sheet flow, _because a basis in published literature is lacking_ ,” it reports. “The projections include a contribution due to increased ice flow from Greenland and Antarctica at the rates observed for 1993 to 2003, _but these flow rates could increase or decrease in the future_ [emphases added].



The most recent research certainly bears out the UN’s caution. Writing in _Science_ last month, Eske Willerslev of the University of Copenhagen and several colleagues demonstrated that there was still ice in south‐​central Greenland during the height of the last interglacial (warm) period, between 116,000 and 130,000 years ago.



During this period, Greenland’s temperatures were about 9 degrees F higher than they’ll get in the next century. Given that Greenland maintained this temperature for 15,000 years, how can one ever support the notion that less than 2 degrees of warming will cause it to lose most of its ice?



Speaking scientific reserve, Willerslev said his work “suggests a problem with the models” predicting a massive loss of Greenland’s ice.



Indeed. But even those models take about 800 years or so for Greenland to lose half of its ice, not a mere century. They assume that human activity will somehow quadruple the amount of carbon dioxide in the air, and keep it at that concentration for a millennium. The actual increase, to date, has been 36%. It’s a little cheeky, to say the least, to assume that in the year 2500 we will be burning fossil fuels at a rate several times greater than we are now.



Another corollary to the current Greenland hysteria is that once it loses its ice, it will never get it back. Willerslev and his colleagues hit that one out of the park. They found that in a previous non‐​glacial period — around 500,000 years or so ago — southern Greenland looked a lot like New England, complete with trees and forests found there today. But the ice obviously came back.



One can only hope that these new findings will compel Congress to cool it on global warming. These are reassuring, rather than inconvenient, truths.
"
"

If nothing else, the latest report of the United States National Intelligence Council (NIC) makes a prophet of Kishore Mahbubani. His book, _The New Asian Hemisphere: The Irresistible Shift of Global Power to the East_ published at the beginning of the year foreshadowed one of the main conclusions of the NIC report released last week. 



Among the assessments of the report, _Global Trends 2025: A Transformed World_ , is that “the unprecedented transfer of wealth roughly from West to East now underway will continue for the foreseeable future.” 



This projection coincides with US president‐​elect Barack Obama’s announcement of an economic team with deep experience of managing international economic crises in the past decade. His string of appointees, including Timothy Geithner as Treasury secretary, may be a strong indication of Obama’s awareness of the changing world — as well as how he intends to govern. 



Geithner, appointed just days after the release of the Global Trends reports, worked previously at the International Monetary Fund, and was under secretary of the Treasury for international affairs during the administration of Bill Clinton, where he played a key role in dealing with the Asian financial crisis of 1997–8.



Global Trends is the fourth unclassified report prepared by the NIC in recent years that takes a long‐​term view of the future. Like previous reports, it was prepared to stimulate strategic thinking about the future by identifying key trends, the factors that drive them, where they seem to be headed, and how they might interact.



Like the old Chinese curse, the not‐​so‐​far‐​distant future looks to be a very interesting time, with both opportunities and perils. And the Asian region is going to be a very big part of it. 



Among the report’s “relative certainties” is that “a global multipolar system is emerging with the rise of China, India and others.” Similarly, among the key “uncertainties” are: 



If the report is correct, the world finds itself in the midst of a transition to a place where the political and economic structure will be markedly different. The report finds that the “international system — as constructed following World War II — will be almost unrecognizable by 2025, owing to the rise of emerging powers, a globalizing economy, an historic transfer of relative wealth and economic power from West to East, and the growing influence of non‐​state actors. By 2025, the international system will be a global multipolar one with gaps in national power continuing to narrow between developed and developing countries.” 



And therein lies a danger. The report notes that historically, emerging multipolar systems have been more unstable than bipolar or unipolar ones. While it doesn’t predict the destruction of the international order, like the one that led to World War I, it does not rule out a 19th century‐​like scenario of arms races, territorial expansion and military rivalries.



Economically, in the future when Asia speaks the world will attentively listen. Growth projections for Brazil, Russia, India and China (the BRIC countries) indicate they will collectively match the original Group of Seven’s share of global gross domestic product (GDP) by 2040–2050. 



Asia will also be the region producing the major share of the future middle class. Over the next several decades, the number of people considered to be in the “global middle class” is projected to swell from 440 million to 1.2 billion — or from 7.6% of the world’s population to 16.1%, according to the World Bank. Most of the new entrants will come from China and India. 



In a sense, China and India are restoring the positions they held two centuries ago when China produced approximately 30% and India 15% of the world’s wealth. 



China is poised to have more impact on the world over the next 20 years than any other country. If current trends persist, by 2025 China will have the world’s second largest economy. Both China and India’s gross national product (GNP) is expected to exceed that of the US in 2035, but they will continue to lag in per capita income for decades. 



But it will not be an Adam Smith‐​type economy. Generally, China, India and Russia are not following the West’s liberal model for self‐​development, but instead are using a different model, “state capitalism”; the system of economic management that gives a prominent role to the state. 



And, if demography is destiny, Asia will also be where the future lies. World population is projected to grow by about 1.2 billion between 2009 and 2025, from 6.8 billion to around 8 billion people. Demographers project that Asia and Africa will account for most of the population growth until 2025, while less than 3% of the growth will occur in the “West.” 



The largest increase will occur in India, representing about one‐​fifth of all growth. India’s population is projected to climb by around 240 million by 2025, reaching approximately 1.45 billion people. From 2009 to 2025, China, is projected to add more than 100 million to its current population of over 1.3 billion. 



That is not to say there won’t be problems. Around 2015, the size of China’s working‐​age population will start to decline. The onset of larger proportions of retirees and relatively fewer workers is being accelerated by decades of policies that have limited childbirth and by a tradition of early retirement. By opting to slow population growth dramatically to dampen growing demand for energy, water and food, China is hastening the aging of its population. 



By 2025, a large proportion of China’s population will be retired or entering retirement. About the same time, due to growth in India’s densely populated northern states, its population is projected to overtake China’s. 



Asia is also projected to be the region where various conflicts might erupt. The report states that over the next 15–20 years, reactions to the decisions Iran makes about its nuclear program could cause a number of regional states to intensify these efforts and consider actively pursuing nuclear weapons. 



On the plus side, the report says, “We see a unified Korea as likely by 2025 — if not as a unitary state, than in some form of North‐​South confederation.” 



In this future world the United States will find itself as just one of a number of important actors on the world stage, albeit still the most powerful military nation. But advances by others states in science and technology, expanded adoption of irregular warfare tactics by both state and non‐​state actors, and proliferation of long‐​range precision weapons, and growing use of cyber warfare attacks increasingly will constrict US freedom of action. 



This constrained US role raises questions about how effectively new agenda issues will be addressed. Despite the recent rise in anti‐​Americanism — which the report now thinks is beginning to wane somewhat — the US probably will continue to be seen as a much‐​needed regional balancer in the Middle East and Asia. 



Other countries still expect the United States to play a significant role in using its military power to counter global terrorism or provide leadership on climate change. Yet the future proliferation of influential actors and distrust of vast power mean less room for the US to call the shots without the support of strong partnerships. 



Thus Barack Obama and future US presidents will need to be doing a lot of talking with other national leaders in the future. 
"
"As we work to tackle the Covid-19 pandemic, all of us – individuals, families, communities, and the worlds of business, finance and government – are reminded of the importance of thinking, planning and budgeting for the long term. It is essential to deal with coronavirus as it is – a global emergency – but it is clear we must work harder to predict and prepare for the existential risks we face. Not only the threat of pandemics, but the climate crisis and unchecked technological advancements.  This week, as parliament scrutinises emergency Covid-19 legislation, Caroline Lucas will introduce a much longer-term proposal, the wellbeing of future generations bill. As co-sponsors of the bill, our aim is to enshrine long-term thinking, and the voices of future generations, at the heart of decision-making. The bill, which is also being steered through the House of Lords by John Bird, is inspired by the model in Wales, where their future generations commissioner is taking long-term thinking into the mainstream. This bill represents the need for cultural shift, which will take time. But with the eyes of future generations upon us, it also presents parliament with an opportunity to act today for tomorrow, and level up opportunity between current and future generations. Caroline Lucas MP Green, Bob Blackman MP Conservative, Bambos Charalambous MP Labour, Simon Fell MP Conservative, Claire Hanna MP Social Democratic and Labour party, Wera Hobhouse MP Liberal Democrat, Kevin Hollinrake MP Conservative, Anna McMorrin MP Labour, Abena Oppong-Asare MP Labour, Liz Saville Roberts MP Plaid Cymru, Alex Sobel MP Labour Co-operative, Philippa Whitford MP Scottish National party"
"

My crazy brother Tom — yeah, _that_ one, the first guy to commercialize production of the Black Truffle — used to call them “organos.” Back in his graduate school days at Oregon State he would rail at the sanctimony of the beans‐​and‐​rice crowd, and opine that “everything they knew was wrong.” Passing the salad bar, he would mutter, “empty vitamins.”



And they were pretty wrong. Acid rain didn’t kill the Black Forest. Small could be ugly. The Population Bomb never exploded.



Since our halcyon times in Oregon I’ve been waiting for the definitive tome on the systematic errors of organoism, and I have finally found it in Todd Myers’ new book _Eco‐​fads_.



Myers isn’t running for the president of the young curmudgeon’s club like Tom was. He thinks global warming might be important, but that the “solutions” ginned up by the political process are counterproductive. For example, in the name of climate change we subsidize solar energy so that its cost in 2016 will be an “astounding $396.10 per MWh”(Megawatt-hour) compared to about $79 for natural gas. (My other brother, Bob, who is in fact a curmudgeon, testified last month to Congress that solar will be even _more_ expensive than that).





G]overnments are just very bad at picking winners and losers in the energy world.



Why did we listen to environmental activists and become the first nation in human history to burn up its food supply to power automobiles? Why did we allow horrendously bad science — see the spotted owl — destroy the livelihood (and some of the lives) of so many in the Pacific Northwest? Why are environmental journalists so obsessed with horror stories and so repelled by good news? Why do we succumb to so many eco‐​fads, from grass‐​fed beef to locavorism to passive solar homes that leak heat like sieves?



If you ask Myers, he’ll probably answer “it’s complicated”. But it gets down, largely, to incentives, summarized by his PPP model: personal, popular and phony.



Personal: a Prius emits sanctimony (while a Chevy Volt confers sainthood). Popular: Green is the modern religion, and heretics are shunned. Phony: that new hybrid _adds_ carbon dioxide emissions, because that Accord it was traded in for is going to be on the road another decade.



Personal: “green buildings”, such as new schools that sprouted all over Washington. Popular: who would be against this? Phony: most of them consume more energy than their conventional counterparts.



In a former life, Myers was Communications Director for the Washington Department of Natural Resources, where he no doubt got up close and personal with most of the organo cults. Now he’s the Environmental Director for the Washington Policy Center in Seattle, proving that all ecotopian garden parties need a skunk.



Myers’ DNR beat was forest management, where he fought, somewhat successfully, the organo nostrum that forests left alone and protected from fires are healthy. In fact, they tend to be pretty sick, as the normal thinning from fires is suppressed, resulting in an unhealthy tree density, invasion and death from bark beetles, and then — surprise — a mega fire that takes down the entire woods.



Just about every organo sacrament withers under Myers’ scrutiny. “Buying local” often means more dreaded greenhouse gas emissions from inefficient short‐​term shipment compared to the economies of scale when carloads of spuds ride the Burlington Northern Santa Fe across the country. “Certified Organic” means so much paperwork and oversight that mom‐​and‐​pop farms (another organo icon) get pushed out by corporate agriculture, which can afford to spend the time and resources satisfying bureaucrats.



Then there are “green jobs.” Solyndra is no outlier; governments are just very bad at picking winners and losers in the energy world. Myers documents the decline and fall of biofuel plants throughout the northwest. Inefficiencies destroy jobs. The Teanaway “Solar Reserve”, supported by an ever‐​increasing feed of taxpayer dollars, was supposed to be the “world’s largest”, supplying power to a grand total of 45,000 homes. That’s all you get?



John Plaza, CEO of the failed biofuel facility Imperium Renewables (you would think a better name would have helped) thinks it’s all the government’s fault. “What the industry needs,” he said, “is a two‐​fold support, a mandated floor, and incentives and tax policy to get the outcomes we’re trying for.” In other words, more expensive energy subsidized by you and me, and the government rigging the market. That will create jobs!



What is missing here (and everywhere else) is a comprehensive analysis of how much money the organo fads, follies and delusions cost us. Hopefully that will be in Myers’ next book. The incredible constellation of policy errors, wrongheaded logic and downright stupidity has to be extracting a dear cost from our very sick economy. It’s time to stop this. It’s time for you to read this book.
"
"

In the last two years, a remarkable amount of disturbing news has been published concerning global warming, largely concentrating on melting of polar ice, tropical storms and hurricanes, and mass extinctions. The sheer volume of these stories appears to be moving the American political process toward some type of policy restricting emissions of carbon dioxide.



It is highly improbable, in a statistical sense, that new information added to any existing forecast is almost always “bad” or “good”; rather, each new finding has an equal probability of making a forecast worse or better. Consequently, the preponderance of bad news almost certainly means that something is missing, both in the process of science itself and in the reporting of science. This paper examines in detail both recent scientific reports on climate change and the communication of those reports.



Needless to say, the unreported information is usually counter to the bad news. Reports of rapid disintegration of Greenland’s ice ignore the fact that the region was warmer than it is now for several decades in the early 20th century, before humans could have had much influence on climate. Similar stories concerning Antarctica neglect the fact that the net temperature trend in recent decades is negative, or that warming the surrounding ocean can serve only to enhance snowfall, resulting in a gain in ice. Global warming affects hurricanes in both positive and negative fashions, and there is no relationship between the severity of storms and ocean‐​surface temperature, once a commonly exceeded threshold temperature is reached. Reports of massive species extinction also turn out to be impressively flawed.



This constellation of half‐​truths and misstatements is a predictable consequence of the way that science is now conducted, where issues compete with each other for public support. Unfortunately, this creates a culture of negativity that is reflected in the recent spate of global warming reports.
"
